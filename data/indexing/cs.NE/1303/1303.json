[{"id": "1303.0323", "submitter": "Wesam Elshamy", "authors": "Wesam Elshamy, Hassan M Emara, Ahmed Bahgat", "title": "Clubs-based Particle Swarm Optimization", "comments": "IEEE Swarm Intelligence Symposium 2007, Honolulu, HI", "journal-ref": null, "doi": "10.1109/SIS.2007.367950", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new dynamic neighborhood network for particle swarm\noptimization. In the proposed Clubs-based Particle Swarm Optimization (C-PSO)\nalgorithm, each particle initially joins a default number of what we call\n'clubs'. Each particle is affected by its own experience and the experience of\nthe best performing member of the clubs it is a member of. Clubs membership is\ndynamic, where the worst performing particles socialize more by joining more\nclubs to learn from other particles and the best performing particles are made\nto socialize less by leaving clubs to reduce their strong influence on other\nmembers. Particles return gradually to default membership level when they stop\nshowing extreme performance. Inertia weights of swarm members are made random\nwithin a predefined range. This proposed dynamic neighborhood algorithm is\ncompared with other two algorithms having static neighborhood topologies on a\nset of classic benchmark problems. The results showed superior performance for\nC-PSO regarding escaping local optima and convergence speed.\n", "versions": [{"version": "v1", "created": "Sat, 2 Mar 2013 00:05:26 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Elshamy", "Wesam", ""], ["Emara", "Hassan M", ""], ["Bahgat", "Ahmed", ""]]}, {"id": "1303.0460", "submitter": "Priya Dharshini", "authors": "N. Priyadharshini, M.S. Vijaya", "title": "Genetic Programming for Document Segmentation and Region Classification\n  Using Discipulus", "comments": "8 pages,13 figures", "journal-ref": "(IJARAI) International Journal of Advanced Research in Artificial\n  Intelligence, Vol. 2, No. 2, 2013", "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Document segmentation is a method of rending the document into distinct\nregions. A document is an assortment of information and a standard mode of\nconveying information to others. Pursuance of data from documents involves ton\nof human effort, time intense and might severely prohibit the usage of data\nsystems. So, automatic information pursuance from the document has become a big\nissue. It is been shown that document segmentation will facilitate to beat such\nproblems. This paper proposes a new approach to segment and classify the\ndocument regions as text, image, drawings and table. Document image is divided\ninto blocks using Run length smearing rule and features are extracted from\nevery blocks. Discipulus tool has been used to construct the Genetic\nprogramming based classifier model and located 97.5% classification accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2013 05:31:42 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Priyadharshini", "N.", ""], ["Vijaya", "M. S.", ""]]}, {"id": "1303.0462", "submitter": "M.M.A. Hashem", "authors": "Moslema Jahan, M. M. A. Hashem and Gazi Abdullah Shahriar", "title": "Distributed Evolutionary Computation: A New Technique for Solving Large\n  Number of Equations", "comments": null, "journal-ref": "International Journal of Parallel and Distributed Systems (IJPDS),\n  Vol. 2, No.6, pp.31-49,(2011)", "doi": "10.5121/ijdps.2011.2604", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary computation techniques have mostly been used to solve various\noptimization and learning problems successfully. Evolutionary algorithm is more\neffective to gain optimal solution(s) to solve complex problems than\ntraditional methods. In case of problems with large set of parameters,\nevolutionary computation technique incurs a huge computational burden for a\nsingle processing unit. Taking this limitation into account, this paper\npresents a new distributed evolutionary computation technique, which decomposes\ndecision vectors into smaller components and achieves optimal solution in a\nshort time. In this technique, a Jacobi-based Time Variant Adaptive (JBTVA)\nHybrid Evolutionary Algorithm is distributed incorporating cluster computation.\nMoreover, two new selection methods named Best All Selection (BAS) and Twin\nSelection (TS) are introduced for selecting best fit solution vector.\nExperimental results show that optimal solution is achieved for different kinds\nof problems having huge parameters and a considerable speedup is obtained in\nproposed distributed system.\n", "versions": [{"version": "v1", "created": "Sun, 3 Mar 2013 05:38:41 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Jahan", "Moslema", ""], ["Hashem", "M. M. A.", ""], ["Shahriar", "Gazi Abdullah", ""]]}, {"id": "1303.0818", "submitter": "Yann Ollivier", "authors": "Yann Ollivier", "title": "Riemannian metrics for neural networks I: feedforward networks", "comments": "(5th version, minor changes)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.IT cs.LG math.DG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe four algorithms for neural network training, each adapted to\ndifferent scalability constraints. These algorithms are mathematically\nprincipled and invariant under a number of transformations in data and network\nrepresentation, from which performance is thus independent. These algorithms\nare obtained from the setting of differential geometry, and are based on either\nthe natural gradient using the Fisher information matrix, or on Hessian\nmethods, scaled down in a specific way to allow for scalability while keeping\nsome of their key mathematical properties.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2013 20:41:09 GMT"}, {"version": "v2", "created": "Thu, 2 May 2013 16:07:30 GMT"}, {"version": "v3", "created": "Sun, 25 Aug 2013 20:34:13 GMT"}, {"version": "v4", "created": "Sat, 12 Jul 2014 14:37:30 GMT"}, {"version": "v5", "created": "Tue, 3 Feb 2015 18:24:30 GMT"}], "update_date": "2015-02-04", "authors_parsed": [["Ollivier", "Yann", ""]]}, {"id": "1303.1051", "submitter": "Imen Ayachi", "authors": "I. Ayachi (1)(2), R. Kammarti (1)(2), M. Ksouri (2), and P. Borne (1)\n  (1): LAGIS, Ecole Centrale de Lille (2): LACS, Ecole Nationale des Ingenieurs\n  de Tunis", "title": "A Genetic algorithm to solve the container storage space allocation\n  problem", "comments": "2010 International conference on Computational Intelligence and\n  Vehicular System (CIVS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper presented a genetic algorithm (GA) to solve the container storage\nproblem in the port. This problem is studied with different container types\nsuch as regular, open side, open top, tank, empty and refrigerated containers.\nThe objective of this problem is to determine an optimal containers\narrangement, which respects customers delivery deadlines, reduces the rehandle\noperations of containers and minimizes the stop time of the container ship. In\nthis paper, an adaptation of the genetic algorithm to the container storage\nproblem is detailed and some experimental results are presented and discussed.\nThe proposed approach was compared to a Last In First Out (LIFO) algorithm\napplied to the same problem and has recorded good results\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2013 14:45:30 GMT"}], "update_date": "2013-03-06", "authors_parsed": [["Ayachi", "I.", ""], ["Kammarti", "R.", ""], ["Ksouri", "M.", ""], ["Borne", "P.", ""], [":", "", ""], ["LAGIS", "", ""], ["de Lille", "Ecole Centrale", ""], [":", "", ""], ["LACS", "", ""], ["de Tunis", "Ecole Nationale des Ingenieurs", ""]]}, {"id": "1303.1243", "submitter": "M.M.A. Hashem", "authors": "Md. Amjad Hossain, Md. Kawser Hossain, and M.M.A. Hashem", "title": "A Generalized Hybrid Real-Coded Quantum Evolutionary Algorithm Based on\n  Particle Swarm Theory with Arithmetic Crossover", "comments": "http://airccse.org/journal/jcsit/0810ijcsit15.pdf", "journal-ref": "International Journal of Computers Science and Information\n  Technology (IJCSIT), Vol. 2, No. 4, pp.172-187, (2010)", "doi": "10.5121/ijcsit.2010.2415", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a generalized Hybrid Real-coded Quantum Evolutionary\nAlgorithm (HRCQEA) for optimizing complex functions as well as combinatorial\noptimization. The main idea of HRCQEA is to devise a new technique for mutation\nand crossover operators. Using the evolutionary equation of PSO a\nSingle-Multiple gene Mutation (SMM) is designed and the concept of Arithmetic\nCrossover (AC) is used in the new Crossover operator. In HRCQEA, each triploid\nchromosome represents a particle and the position of the particle is updated\nusing SMM and Quantum Rotation Gate (QRG), which can make the balance between\nexploration and exploitation. Crossover is employed to expand the search space,\nHill Climbing Selection (HCS) and elitism help to accelerate the convergence\nspeed. Simulation results on Knapsack Problem and five benchmark complex\nfunctions with high dimension show that HRCQEA performs better in terms of\nability to discover the global optimum and convergence speed.\n", "versions": [{"version": "v1", "created": "Wed, 6 Mar 2013 02:55:20 GMT"}], "update_date": "2013-03-07", "authors_parsed": [["Hossain", "Md. Amjad", ""], ["Hossain", "Md. Kawser", ""], ["Hashem", "M. M. A.", ""]]}, {"id": "1303.1868", "submitter": "Chusnul Arif", "authors": "Chusnul Arif, Masaru Mizoguchi, Budi Indra Setiawan, Ryoichi Doi", "title": "Estimation of soil moisture in paddy field using Artificial Neural\n  Networks", "comments": "5 Pages", "journal-ref": "International Journal of Advanced Research in Artificial\n  Intelligence (IJARAI), Vol. 1, No. 1:17-21, 2012", "doi": null, "report-no": null, "categories": "cs.NE physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In paddy field, monitoring soil moisture is required for irrigation\nscheduling and water resource allocation, management and planning. The current\nstudy proposes an Artificial Neural Networks (ANN) model to estimate soil\nmoisture in paddy field with limited meteorological data. Dynamic of ANN model\nwas adopted to estimate soil moisture with the inputs of reference\nevapotranspiration (ETo) and precipitation. ETo was firstly estimated using the\nmaximum, average and minimum values of air temperature as the inputs of model.\nThe models were performed under different weather conditions between the two\npaddy cultivation periods. Training process of model was carried out using the\nobservation data in the first period, while validation process was conducted\nbased on the observation data in the second period. Dynamic of ANN model\nestimated soil moisture with R2 values of 0.80 and 0.73 for training and\nvalidation processes, respectively, indicated that tight linear correlations\nbetween observed and estimated values of soil moisture were observed. Thus, the\nANN model reliably estimates soil moisture with limited meteorological data.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2013 01:31:53 GMT"}], "update_date": "2013-03-11", "authors_parsed": [["Arif", "Chusnul", ""], ["Mizoguchi", "Masaru", ""], ["Setiawan", "Budi Indra", ""], ["Doi", "Ryoichi", ""]]}, {"id": "1303.1913", "submitter": "Arun  Balaji Mr", "authors": "S.Arun Balaji and K.Baskaran", "title": "Design and Development of Artificial Neural Networking (ANN) system\n  using sigmoid activation function to predict annual rice production in\n  Tamilnadu", "comments": "19 pages, 7 figures, published in the International Journal of\n  Computer Science, Engineering and Information Technology (IJCSEIT), Vol.3,\n  No.1, February 2013", "journal-ref": "IJCSEIT, Vol.3, No.1, February 2013", "doi": null, "report-no": "International Journal of Computer Science, Engineering and\n  Information Technology (IJCSEIT), Vol.3, No.1, February 2013", "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of annual rice production in all the 31 districts of Tamilnadu is\nan important decision for the Government of Tamilnadu. Rice production is a\ncomplex process and non linear problem involving soil, crop, weather, pest,\ndisease, capital, labour and management parameters. ANN software was designed\nand developed with Feed Forward Back Propagation (FFBP) network to predict rice\nproduction. The input layer has six independent variables like area of\ncultivation and rice production in three seasons like Kuruvai, Samba and Kodai.\nThe popular sigmoid activation function was adopted to convert input data into\nsigmoid values. The hidden layer computes the summation of six sigmoid values\nwith six sets of weightages. The final output was converted into sigmoid values\nusing a sigmoid transfer function. ANN outputs are the predicted results. The\nerror between original data and ANN output values were computed. A threshold\nvalue of 10-9 was used to test whether the error is greater than the threshold\nlevel. If the error is greater than threshold then updating of weights was done\nall summations were done by back propagation. This process was repeated until\nerror equal to zero. The predicted results were printed and it was found to be\nexactly matching with the expected values. It shows that the ANN prediction was\n100% accurate.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2013 08:53:15 GMT"}], "update_date": "2013-03-11", "authors_parsed": [["Balaji", "S. Arun", ""], ["Baskaran", "K.", ""]]}, {"id": "1303.2017", "submitter": "Tunji Adebiyi", "authors": "A. Adebiyi, Johnnes Arreymbi and Chris Imafidon", "title": "Security Assessment of Software Design using Neural Network", "comments": "7 pages, 1 figure, 4 tables, (IJARAI) International Journal of\n  Advanced Research in Artificial Intelligence, Vol. 1(4), 2012, pp.1-7,\n  ISSN:2165-4069 (Online), ISSN:2165-4050 (Print)", "journal-ref": "(IJARAI) International Journal of Advanced Research in Artificial\n  Intelligence, Vol. 1(4), 2012, pp.1-7", "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security flaws in software applications today has been attributed mostly to\ndesign flaws. With limited budget and time to release software into the market,\nmany developers often consider security as an afterthought. Previous research\nshows that integrating security into software applications at a later stage of\nsoftware development lifecycle (SDLC) has been found to be more costly than\nwhen it is integrated during the early stages. To assist in the integration of\nsecurity early in the SDLC stages, a new approach for assessing security during\nthe design phase by neural network is investigated in this paper. Our findings\nshow that by training a back propagation neural network to identify attack\npatterns, possible attacks can be identified from design scenarios presented to\nit. The result of performance of the neural network is presented in this paper.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2013 15:09:53 GMT"}], "update_date": "2013-03-11", "authors_parsed": [["Adebiyi", "A.", ""], ["Arreymbi", "Johnnes", ""], ["Imafidon", "Chris", ""]]}, {"id": "1303.2096", "submitter": "Alfredo Garcia Woods Prog.", "authors": "Alfredo Garcia Woods", "title": "Gene-Machine, a new search heuristic algorithm", "comments": "GeneMachine uses the chromosome notion, genes and evolution, but it\n  differs from genetic algorithms, in that it does not use mutation, nor\n  population of individuals, neither the notion of generation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Gene-Machine, an efficient and new search heuristic\nalgorithm, based in the building-block hypothesis. It is inspired by natural\nevolution, but does not use some of the concepts present in genetic algorithms\nlike population, mutation and generation. This heuristic exhibits good\nperformance in comparison with genetic algorithms, and can be used to generate\nuseful solutions to optimization and search problems.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2013 20:16:02 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Woods", "Alfredo Garcia", ""]]}, {"id": "1303.2215", "submitter": "Maumita Bhattacharya", "authors": "Maumita Bhattacharya", "title": "Expensive Optimisation: A Metaheuristics Perspective", "comments": "7 pages", "journal-ref": "(IJACSA) International Journal of Advanced Computer Science and\n  Applications,ISSN-2156-5570(Online, Vol. 4, No. 2, 2013, pp. 203-209", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic, iterative search methods such as Evolutionary Algorithms (EAs)\nare proven to be efficient optimizers. However, they require evaluation of the\ncandidate solutions which may be prohibitively expensive in many real world\noptimization problems. Use of approximate models or surrogates is being\nexplored as a way to reduce the number of such evaluations. In this paper we\ninvestigated three such methods. The first method (DAFHEA) partially replaces\nan expensive function evaluation by its approximate model. The approximation is\nrealized with support vector machine (SVM) regression models. The second method\n(DAFHEA II) is an enhancement on DAFHEA to accommodate for uncertain\nenvironments. The third one uses surrogate ranking with preference learning or\nordinal regression. The fitness of the candidates is estimated by modeling\ntheir rank. The techniques' performances on some of the benchmark numerical\noptimization problems have been reported. The comparative benefits and\nshortcomings of both techniques have been identified.\n", "versions": [{"version": "v1", "created": "Sat, 9 Mar 2013 14:41:24 GMT"}], "update_date": "2013-03-12", "authors_parsed": [["Bhattacharya", "Maumita", ""]]}, {"id": "1303.2745", "submitter": "Maumita Bhattacharya", "authors": "Maumita Bhattacharya", "title": "Evolutionary Approaches to Expensive Optimisation", "comments": "7 pages", "journal-ref": "(IJARAI) International Journal of Advanced Research in Artificial\n  Intelligence,Vol. 2, No. 3, 2013, pp. 53-59", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surrogate assisted evolutionary algorithms (EA) are rapidly gaining\npopularity where applications of EA in complex real world problem domains are\nconcerned. Although EAs are powerful global optimizers, finding optimal\nsolution to complex high dimensional, multimodal problems often require very\nexpensive fitness function evaluations. Needless to say, this could brand any\npopulation-based iterative optimization technique to be the most crippling\nchoice to handle such problems. Use of approximate model or surrogates provides\na much cheaper option. However, naturally this cheaper option comes with its\nown price. This paper discusses some of the key issues involved with use of\napproximation in evolutionary algorithm, possible best practices and solutions.\nAnswers to the following questions have been sought: what type of fitness\napproximation to be used; which approximation model to use; how to integrate\nthe approximation model in EA; how much approximation to use; and how to ensure\nreliable approximation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Mar 2013 01:39:11 GMT"}], "update_date": "2013-03-13", "authors_parsed": [["Bhattacharya", "Maumita", ""]]}, {"id": "1303.3145", "submitter": "Pu  Wang", "authors": "Pu Wang, Michael Emmerich, Rui Li, Ke Tang, Thomas Ba\u007feck and Xin Yao", "title": "Convex Hull-Based Multi-objective Genetic Programming for Maximizing ROC\n  Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ROC is usually used to analyze the performance of classifiers in data mining.\nROC convex hull (ROCCH) is the least convex major-ant (LCM) of the empirical\nROC curve, and covers potential optima for the given set of classifiers.\nGenerally, ROC performance maximization could be considered to maximize the\nROCCH, which also means to maximize the true positive rate (tpr) and minimize\nthe false positive rate (fpr) for each classifier in the ROC space. However,\ntpr and fpr are conflicting with each other in the ROCCH optimization process.\nThough ROCCH maximization problem seems like a multi-objective optimization\nproblem (MOP), the special characters make it different from traditional MOP.\nIn this work, we will discuss the difference between them and propose convex\nhull-based multi-objective genetic programming (CH-MOGP) to solve ROCCH\nmaximization problems. Convex hull-based sort is an indicator based selection\nscheme that aims to maximize the area under convex hull, which serves as a\nunary indicator for the performance of a set of points. A selection procedure\nis described that can be efficiently implemented and follows similar design\nprinciples than classical hyper-volume based optimization algorithms. It is\nhypothesized that by using a tailored indicator-based selection scheme CH-MOGP\ngets more efficient for ROC convex hull approximation than algorithms which\ncompute all Pareto optimal points. To test our hypothesis we compare the new\nCH-MOGP to MOGP with classical selection schemes, including NSGA-II, MOEA/D)\nand SMS-EMOA. Meanwhile, CH-MOGP is also compared with traditional machine\nlearning algorithms such as C4.5, Naive Bayes and Prie. Experimental results\nbased on 22 well-known UCI data sets show that CH-MOGP outperforms\nsignificantly traditional EMOAs.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2013 12:51:31 GMT"}, {"version": "v2", "created": "Fri, 15 Mar 2013 01:10:53 GMT"}], "update_date": "2013-03-18", "authors_parsed": [["Wang", "Pu", ""], ["Emmerich", "Michael", ""], ["Li", "Rui", ""], ["Tang", "Ke", ""], ["Ba\u007feck", "Thomas", ""], ["Yao", "Xin", ""]]}, {"id": "1303.3154", "submitter": "Jun He", "authors": "Jun He, Wei Hou, Hongbin Dong and Feidun He", "title": "Mixed Strategy May Outperform Pure Strategy: An Initial Study", "comments": null, "journal-ref": null, "doi": "10.1109/CEC.2013.6557618", "report-no": null, "categories": "cs.NE cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In pure strategy meta-heuristics, only one search strategy is applied for all\ntime. In mixed strategy meta-heuristics, each time one search strategy is\nchosen from a strategy pool with a probability and then is applied. An example\nis classical genetic algorithms, where either a mutation or crossover operator\nis chosen with a probability each time. The aim of this paper is to compare the\nperformance between mixed strategy and pure strategy meta-heuristic algorithms.\nFirst an experimental study is implemented and results demonstrate that mixed\nstrategy evolutionary algorithms may outperform pure strategy evolutionary\nalgorithms on the 0-1 knapsack problem in up to 77.8% instances. Then\nComplementary Strategy Theorem is rigorously proven for applying mixed strategy\nat the population level. The theorem asserts that given two meta-heuristic\nalgorithms where one uses pure strategy 1 and another uses pure strategy 2, the\ncondition of pure strategy 2 being complementary to pure strategy 1 is\nsufficient and necessary if there exists a mixed strategy meta-heuristics\nderived from these two pure strategies and its expected number of generations\nto find an optimal solution is no more than that of using pure strategy 1 for\nany initial population, and less than that of using pure strategy 1 for some\ninitial population.\n", "versions": [{"version": "v1", "created": "Wed, 13 Mar 2013 13:28:36 GMT"}, {"version": "v2", "created": "Fri, 10 May 2013 10:26:15 GMT"}, {"version": "v3", "created": "Tue, 22 Apr 2014 09:23:26 GMT"}], "update_date": "2014-04-23", "authors_parsed": [["He", "Jun", ""], ["Hou", "Wei", ""], ["Dong", "Hongbin", ""], ["He", "Feidun", ""]]}, {"id": "1303.3469", "submitter": "Hassan Bashir A", "authors": "Hassan A. Bashir and Richard S. Neville", "title": "Hybrid Evolutionary Computation for Continuous Optimization", "comments": "Companion Publications for this Technical Memorandum, available at\n  IEEE Xplore, are: [1] H. A. Bashir and R. S. Neville, \"Convergence\n  measurement in evolutionary computation using Price's theorem,\" IEEE (CEC),\n  2012. [2] H. A. Bashir and R. S. Neville, \"A hybrid evolutionary computation\n  algorithm for global optimization,\" IEEE (CEC), 2012", "journal-ref": null, "doi": null, "report-no": "Technical Memorandum 2011-v.01", "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid optimization algorithms have gained popularity as it has become\napparent there cannot be a universal optimization strategy which is globally\nmore beneficial than any other. Despite their popularity, hybridization\nframeworks require more detailed categorization regarding: the nature of the\nproblem domain, the constituent algorithms, the coupling schema and the\nintended area of application. This report proposes a hybrid algorithm for\nsolving small to large-scale continuous global optimization problems. It\ncomprises evolutionary computation (EC) algorithms and a sequential quadratic\nprogramming (SQP) algorithm; combined in a collaborative portfolio. The SQP is\na gradient based local search method. To optimize the individual contributions\nof the EC and SQP algorithms for the overall success of the proposed hybrid\nsystem, improvements were made in key features of these algorithms. The report\nproposes enhancements in: i) the evolutionary algorithm, ii) a new convergence\ndetection mechanism was proposed; and iii) in the methods for evaluating the\nsearch directions and step sizes for the SQP local search algorithm. The\nproposed hybrid design aim was to ensure that the two algorithms complement\neach other by exploring and exploiting the problem search space. Preliminary\nresults justify that an adept hybridization of evolutionary algorithms with a\nsuitable local search method, could yield a robust and efficient means of\nsolving wide range of global optimization problems. Finally, a discussion of\nthe outcomes of the initial investigation and a review of the associated\nchallenges and inherent limitations of the proposed method is presented to\ncomplete the investigation. The report highlights extensive research,\nparticularly, some potential case studies and application areas.\n", "versions": [{"version": "v1", "created": "Thu, 14 Mar 2013 14:59:32 GMT"}], "update_date": "2013-03-15", "authors_parsed": [["Bashir", "Hassan A.", ""], ["Neville", "Richard S.", ""]]}, {"id": "1303.3901", "submitter": "Pekka Malo", "authors": "Ankur Sinha, Pekka Malo and Kalyanmoy Deb", "title": "Efficient Evolutionary Algorithm for Single-Objective Bilevel\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bilevel optimization problems are a class of challenging optimization\nproblems, which contain two levels of optimization tasks. In these problems,\nthe optimal solutions to the lower level problem become possible feasible\ncandidates to the upper level problem. Such a requirement makes the\noptimization problem difficult to solve, and has kept the researchers busy\ntowards devising methodologies, which can efficiently handle the problem.\nDespite the efforts, there hardly exists any effective methodology, which is\ncapable of handling a complex bilevel problem. In this paper, we introduce\nbilevel evolutionary algorithm based on quadratic approximations (BLEAQ) of\noptimal lower level variables with respect to the upper level variables. The\napproach is capable of handling bilevel problems with different kinds of\ncomplexities in relatively smaller number of function evaluations. Ideas from\nclassical optimization have been hybridized with evolutionary methods to\ngenerate an efficient optimization algorithm for generic bilevel problems. The\nefficacy of the algorithm has been shown on two sets of test problems. The\nfirst set is a recently proposed SMD test set, which contains problems with\ncontrollable complexities, and the second set contains standard test problems\ncollected from the literature. The proposed method has been evaluated against\ntwo benchmarks, and the performance gain is observed to be significant.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2013 20:30:57 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2013 01:07:57 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Sinha", "Ankur", ""], ["Malo", "Pekka", ""], ["Deb", "Kalyanmoy", ""]]}, {"id": "1303.4164", "submitter": "Garrett Evans", "authors": "Garrett N. Evans and John C. Collins", "title": "Neurally Implementable Semantic Networks", "comments": "32 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose general principles for semantic networks allowing them to be\nimplemented as dynamical neural networks. Major features of our scheme include:\n(a) the interpretation that each node in a network stands for a bound\nintegration of the meanings of all nodes and external events the node links\nwith; (b) the systematic use of nodes that stand for categories or types, with\nseparate nodes for instances of these types; (c) an implementation of\nrelationships that does not use intrinsically typed links between nodes.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2013 06:18:25 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Evans", "Garrett N.", ""], ["Collins", "John C.", ""]]}, {"id": "1303.4227", "submitter": "Nouh Sa\\\"id Mr", "authors": "Said Nouh and Mostafa Belkasmi", "title": "Genetic algorithms for finding the weight enumerator of binary linear\n  block codes", "comments": null, "journal-ref": "International Journal of Applied Research on Information\n  Technology and Computing (IJARITAC), 80-93, 2011", "doi": null, "report-no": null, "categories": "cs.IT cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new method for finding the weight enumerator of\nbinary linear block codes by using genetic algorithms. This method consists in\nfinding the binary weight enumerator of the code and its dual and to create\nfrom the famous MacWilliams identity a linear system (S) of integer variables\nfor which we add all known information obtained from the structure of the code.\nThe knowledge of some subgroups of the automorphism group, under which the code\nremains invariant, permits to give powerful restrictions on the solutions of\n(S) and to approximate the weight enumerator. By applying this method and by\nusing the stability of the Extended Quadratic Residue codes (ERQ) by the\nProjective Special Linear group PSL2, we find a list of all possible values of\nthe weight enumerators for the two ERQ codes of lengths 192 and 200. We also\nmade a good approximation of the true value for these two enumerators.\n", "versions": [{"version": "v1", "created": "Mon, 18 Mar 2013 12:31:54 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Nouh", "Said", ""], ["Belkasmi", "Mostafa", ""]]}, {"id": "1303.4566", "submitter": "Marc Harper", "authors": "Marc Harper", "title": "Inferring Fitness in Finite Populations with Moran-like dynamics", "comments": "Title update, minor edits, more references", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS cs.NE q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological fitness is not an observable quantity and must be inferred from\npopulation dynamics. Bayesian inference applied to the Moran process and\nvariants yields a robust inference method that can infer fitness in populations\nevolving via a Moran dynamic and generalizations. Information about fitness is\nderived solely from birth-events in birth-death and death-birth processes in\nwhich selection acts proportionally to fitness, which allows the method to be\napplied to populations on a network where the network itself may be changing in\ntime. Populations may also be allowed to change size while still allowing\nestimates for fitness to be inferred.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2013 12:24:00 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2013 04:04:09 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2013 01:37:07 GMT"}], "update_date": "2013-10-24", "authors_parsed": [["Harper", "Marc", ""]]}, {"id": "1303.5050", "submitter": "Bernard Yannou", "authors": "Fran\\c{c}ois Cluzel (LGI), Bernard Yannou (LGI), Markus Dihlmann (US)", "title": "Using evolutionary design to interactively sketch car silhouettes and\n  stimulate designer's creativity", "comments": null, "journal-ref": "Engineering Applications of Artificial Intelligence 25 (2012)\n  1413-1424", "doi": "10.1016/j.engappai.2012.02.011", "report-no": null, "categories": "cs.NE cs.HC physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Interactive Genetic Algorithm is proposed to progressively sketch the\ndesired side-view of a car profile. It adopts a Fourier decomposition of a 2D\nprofile as the genotype, and proposes a cross-over mechanism. In addition, a\nformula function of two genes' discrepancies is fitted to the perceived\ndissimilarity between two car profiles. This similarity index is intensively\nused, throughout a series of user tests, to highlight the added value of the\nIGA compared to a systematic car shape exploration, to prove its ability to\ncreate superior satisfactory designs and to stimulate designer's creativity.\nThese tests have involved six designers with a design goal defined by a\nsemantic attribute. The results reveal that if \"friendly\" is diversely\ninterpreted in terms of car shapes, \"sportive\" denotes a very conventional\nrepresentation which may be a limitation for shape renewal.\n", "versions": [{"version": "v1", "created": "Sun, 17 Mar 2013 19:33:57 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2013 07:13:14 GMT"}], "update_date": "2013-03-22", "authors_parsed": [["Cluzel", "Fran\u00e7ois", "", "LGI"], ["Yannou", "Bernard", "", "LGI"], ["Dihlmann", "Markus", "", "US"]]}, {"id": "1303.5778", "submitter": "Alex Graves", "authors": "Alex Graves, Abdel-rahman Mohamed and Geoffrey Hinton", "title": "Speech Recognition with Deep Recurrent Neural Networks", "comments": "To appear in ICASSP 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are a powerful model for sequential data.\nEnd-to-end training methods such as Connectionist Temporal Classification make\nit possible to train RNNs for sequence labelling problems where the\ninput-output alignment is unknown. The combination of these methods with the\nLong Short-term Memory RNN architecture has proved particularly fruitful,\ndelivering state-of-the-art results in cursive handwriting recognition. However\nRNN performance in speech recognition has so far been disappointing, with\nbetter results returned by deep feedforward networks. This paper investigates\n\\emph{deep recurrent neural networks}, which combine the multiple levels of\nrepresentation that have proved so effective in deep networks with the flexible\nuse of long range context that empowers RNNs. When trained end-to-end with\nsuitable regularisation, we find that deep Long Short-term Memory RNNs achieve\na test set error of 17.7% on the TIMIT phoneme recognition benchmark, which to\nour knowledge is the best recorded score.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2013 20:55:48 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Graves", "Alex", ""], ["Mohamed", "Abdel-rahman", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "1303.6145", "submitter": "Manuel Schmitt", "authors": "Manuel Schmitt and Rolf Wanka", "title": "Particles Prefer Walking Along the Axes: Experimental Insights into the\n  Behavior of a Particle Swarm", "comments": "Full version of poster on Genetic and Evolutionary Computation\n  Conference (GECCO) 13", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle swarm optimization (PSO) is a widely used nature-inspired\nmeta-heuristic for solving continuous optimization problems. However, when\nrunning the PSO algorithm, one encounters the phenomenon of so-called\nstagnation, that means in our context, the whole swarm starts to converge to a\nsolution that is not (even a local) optimum. The goal of this work is to point\nout possible reasons why the swarm stagnates at these non-optimal points. To\nachieve our results, we use the newly defined potential of a swarm. The total\npotential has a portion for every dimension of the search space, and it drops\nwhen the swarm approaches the point of convergence. As it turns out\nexperimentally, the swarm is very likely to come sometimes into \"unbalanced\"\nstates, i. e., almost all potential belongs to one axis. Therefore, the swarm\nbecomes blind for improvements still possible in any other direction. Finally,\nwe show how in the light of the potential and these observations, a slightly\nadapted PSO rebalances the potential and therefore increases the quality of the\nsolution.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2013 14:39:27 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2013 15:17:07 GMT"}], "update_date": "2013-08-09", "authors_parsed": [["Schmitt", "Manuel", ""], ["Wanka", "Rolf", ""]]}, {"id": "1303.6310", "submitter": "Iztok Fister", "authors": "Iztok Fister Jr., Du\\v{s}an Fister, Xin-She Yang", "title": "A hybrid bat algorithm", "comments": "Electrotechnical review, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swarm intelligence is a very powerful technique to be used for optimization\npurposes. In this paper we present a new swarm intelligence algorithm, based on\nthe bat algorithm. The Bat algorithm is hybridized with differential evolution\nstrategies. Besides showing very promising results of the standard benchmark\nfunctions, this hybridization also significantly improves the original bat\nalgorithm.\n", "versions": [{"version": "v1", "created": "Mon, 25 Mar 2013 20:53:09 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2013 12:21:44 GMT"}, {"version": "v3", "created": "Wed, 5 Jun 2013 15:46:53 GMT"}], "update_date": "2013-06-06", "authors_parsed": [["Fister", "Iztok", "Jr."], ["Fister", "Du\u0161an", ""], ["Yang", "Xin-She", ""]]}, {"id": "1303.7032", "submitter": "Zhe Yao", "authors": "Zhe Yao, Vincent Gripon and Michael G. Rabbat", "title": "A Massively Parallel Associative Memory Based on Sparse Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Associative memories store content in such a way that the content can be\nlater retrieved by presenting the memory with a small portion of the content,\nrather than presenting the memory with an address as in more traditional\nmemories. Associative memories are used as building blocks for algorithms\nwithin database engines, anomaly detection systems, compression algorithms, and\nface recognition systems. A classical example of an associative memory is the\nHopfield neural network. Recently, Gripon and Berrou have introduced an\nalternative construction which builds on ideas from the theory of error\ncorrecting codes and which greatly outperforms the Hopfield network in\ncapacity, diversity, and efficiency. In this paper we implement a variation of\nthe Gripon-Berrou associative memory on a general purpose graphical processing\nunit (GPU). The work of Gripon and Berrou proposes two retrieval rules,\nsum-of-sum and sum-of-max. The sum-of-sum rule uses only matrix-vector\nmultiplication and is easily implemented on the GPU. The sum-of-max rule is\nmuch less straightforward to implement because it involves non-linear\noperations. However, the sum-of-max rule gives significantly better retrieval\nerror rates. We propose a hybrid rule tailored for implementation on a GPU\nwhich achieves a 880-fold speedup without sacrificing any accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 28 Mar 2013 03:49:57 GMT"}, {"version": "v2", "created": "Sun, 21 Jul 2013 14:29:21 GMT"}], "update_date": "2013-07-23", "authors_parsed": [["Yao", "Zhe", ""], ["Gripon", "Vincent", ""], ["Rabbat", "Michael G.", ""]]}]