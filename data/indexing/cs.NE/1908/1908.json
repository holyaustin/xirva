[{"id": "1908.00187", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Graph Neural Networks for Small Graph and Giant Network Representation\n  Learning: An Overview", "comments": "30 pages. arXiv admin note: text overlap with arXiv:1908.00187", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks denote a group of neural network models introduced for\nthe representation learning tasks on graph data specifically. Graph neural\nnetworks have been demonstrated to be effective for capturing network structure\ninformation, and the learned representations can achieve the state-of-the-art\nperformance on node and graph classification tasks. Besides the different\napplication scenarios, the architectures of graph neural network models also\ndepend on the studied graph types a lot. Graph data studied in research can be\ngenerally categorized into two main types, i.e., small graphs vs. giant\nnetworks, which differ from each other a lot in the size, instance number and\nlabel annotation. Several different types of graph neural network models have\nbeen introduced for learning the representations from such different types of\ngraphs already. In this paper, for these two different types of graph data, we\nwill introduce the graph neural networks introduced in recent years. To be more\nspecific, the graph neural networks introduced in this paper include IsoNN,\nSDBN, LF&ER, GCN, GAT, DifNN, GNL, GraphSage and seGEN. Among these graph\nneural network models, IsoNN, SDBN and LF&ER are initially proposed for small\ngraphs and the remaining ones are initially proposed for giant networks\ninstead. The readers are also suggested to refer to these papers for detailed\ninformation when reading this tutorial paper.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 02:35:12 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "1908.00298", "submitter": "Yunyou Huang", "authors": "Yunyou Huang, Nana Wang, Wanling Gao, Xiaoxu Guo, Cheng Huang, Tianshu\n  Hao and Jianfeng Zhan", "title": "LoadCNN: A Low Training Cost Deep Learning Model for Day-Ahead\n  Individual Residential Load Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate day-ahead individual residential load forecasting is of great\nimportance to various applications of smart grid on day-ahead market. Deep\nlearning, as a powerful machine learning technology, has shown great advantages\nand promising application in load forecasting tasks. However, deep learning is\na computationally-hungry method, and requires high costs (e.g., time, energy\nand CO2 emission) to train a deep learning model, which aggravates the energy\ncrisis and incurs a substantial burden to the environment. As a consequence,\nthe deep learning methods are difficult to be popularized and applied in the\nreal smart grid environment. In this paper, we propose a low training cost\nmodel based on convolutional neural network, namely LoadCNN, for next-day load\nforecasting of individual resident with reduced training cost. The experiments\nshow that the training time of LoadCNN is only approximately 1/54 of the one of\nother state-of-the-art models, and energy consumption and CO2 emissions are\nonly approximate 1/45 of those of other state-of-the-art models based on the\nsame indicators. Meanwhile, the prediction accuracy of our model is equal to\nthat of current state-of-the-art models, making LoadCNN the first load\nforecasting model simultaneously achieving high prediction accuracy and low\ntraining costs. LoadCNN is an efficient green model that is able to be quickly,\ncost-effectively and environmentally-friendly deployed in a realistic smart\ngrid environment.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 09:51:01 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 09:17:40 GMT"}, {"version": "v3", "created": "Fri, 20 Dec 2019 01:55:40 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Huang", "Yunyou", ""], ["Wang", "Nana", ""], ["Gao", "Wanling", ""], ["Guo", "Xiaoxu", ""], ["Huang", "Cheng", ""], ["Hao", "Tianshu", ""], ["Zhan", "Jianfeng", ""]]}, {"id": "1908.00338", "submitter": "Ioannis Christou Ph.D.", "authors": "Ioannis T. Christou", "title": "Popt4jlib: A Parallel/Distributed Optimization Library for Java", "comments": "9 pages, 4 figures, 1 table, accepted in IEEE CEC 2018 (but is not in\n  IEEE Xplore as did not present paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the architectural design as well as key implementation\ndetails of the Open Source popt4jlib library\n(https://githhub.org/ioannischristou/popt4jlib) that contains a fairly large\nnumber of meta-heuristic and other exact optimization algorithms\nparallel/distributed Java implementations. Although we report on speedup and\nefficiency issues on some of the algorithms in the library, our main concern is\nto detail the design decisions for the key parallel/distributed infrastructure\nbuilt into the library, so as to make it easier for developers to develop their\nown parallel implementations of the algorithms of their choice, rather than\nsimply using it as an off-the-self application library.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 11:33:39 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Christou", "Ioannis T.", ""]]}, {"id": "1908.00387", "submitter": "Dylan Cashman", "authors": "Dylan Cashman and Adam Perer and Remco Chang and Hendrik Strobelt", "title": "Ablate, Variate, and Contemplate: Visual Analytics for Discovering\n  Neural Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models require the configuration of many layers and parameters\nin order to get good results. However, there are currently few systematic\nguidelines for how to configure a successful model. This means model builders\noften have to experiment with different configurations by manually programming\ndifferent architectures (which is tedious and time consuming) or rely on purely\nautomated approaches to generate and train the architectures (which is\nexpensive). In this paper, we present Rapid Exploration of Model Architectures\nand Parameters, or REMAP, a visual analytics tool that allows a model builder\nto discover a deep learning model quickly via exploration and rapid\nexperimentation of neural network architectures. In REMAP, the user explores\nthe large and complex parameter space for neural network architectures using a\ncombination of global inspection and local experimentation. Through a visual\noverview of a set of models, the user identifies interesting clusters of\narchitectures. Based on their findings, the user can run ablation and variation\nexperiments to identify the effects of adding, removing, or replacing layers in\na given architecture and generate new models accordingly. They can also\nhandcraft new models using a simple graphical interface. As a result, a model\nbuilder can build deep learning models quickly, efficiently, and without manual\nprogramming. We inform the design of REMAP through a design study with four\ndeep learning model builders. Through a use case, we demonstrate that REMAP\nallows users to discover performant neural network architectures efficiently\nusing visual exploration and user-defined semi-automated searches through the\nmodel space.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 18:41:03 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Cashman", "Dylan", ""], ["Perer", "Adam", ""], ["Chang", "Remco", ""], ["Strobelt", "Hendrik", ""]]}, {"id": "1908.00412", "submitter": "Huyen Pham", "authors": "Huyen Pham (LPSM (UMR\\_8001), UP, FiME Lab), Xavier Warin (EDF, FiME\n  Lab), Maximilien Germain (EDF, LPSM (UMR\\_8001))", "title": "Neural networks-based backward scheme for fully nonlinear PDEs", "comments": "to appear in SN Partial Differential Equations and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE math.AP math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a numerical method for solving high dimensional fully nonlinear\npartial differential equations (PDEs). Our algorithm estimates simultaneously\nby backward time induction the solution and its gradient by multi-layer neural\nnetworks, while the Hessian is approximated by automatic differentiation of the\ngradient at previous step. This methodology extends to the fully nonlinear case\nthe approach recently proposed in \\cite{HPW19} for semi-linear PDEs. Numerical\ntests illustrate the performance and accuracy of our method on several examples\nin high dimension with nonlinearity on the Hessian term including a linear\nquadratic control problem with control on the diffusion coefficient,\nMonge-Amp{\\`e}re equation and Hamilton-Jacobi-Bellman equation in portfolio\noptimization.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 08:09:13 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 13:28:26 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 15:12:30 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Pham", "Huyen", "", "LPSM"], ["Warin", "Xavier", "", "EDF, FiME\n  Lab"], ["Germain", "Maximilien", "", "EDF, LPSM"]]}, {"id": "1908.00452", "submitter": "Alexandre Monteiro Ribeiro", "authors": "Alexandre M. Ribeiro and Alexandra Moutinho and Andr\\'e R. Fioravanti\n  and Ely C. de Paiva", "title": "Estimation of Tire-Road Friction for Road Vehicles: a Time Delay Neural\n  Network Approach", "comments": "13 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The performance of vehicle active safety systems is dependent on the friction\nforce arising from the contact of tires and the road surface. Therefore, an\nadequate knowledge of the tire-road friction coefficient is of great importance\nto achieve a good performance of different vehicle control systems. This paper\ndeals with the tire-road friction coefficient estimation problem through the\nknowledge of lateral tire force. A time delay neural network (TDNN) is adopted\nfor the proposed estimation design. The TDNN aims at detecting road friction\ncoefficient under lateral force excitations avoiding the use of standard\nmathematical tire models, which may provide a more efficient method with robust\nresults. Moreover, the approach is able to estimate the road friction at each\nwheel independently, instead of using lumped axle models simplifications.\nSimulations based on a realistic vehicle model are carried out on different\nroad surfaces and driving maneuvers to verify the effectiveness of the proposed\nestimation method. The results are compared with a classical approach, a\nmodel-based method modeled as a nonlinear regression.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 15:11:51 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 20:45:31 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Ribeiro", "Alexandre M.", ""], ["Moutinho", "Alexandra", ""], ["Fioravanti", "Andr\u00e9 R.", ""], ["de Paiva", "Ely C.", ""]]}, {"id": "1908.00617", "submitter": "Armin Salimi-Badr", "authors": "Armin Salimi-Badr, Mohammad Mehdi Ebadzadeh", "title": "A self-organizing fuzzy neural network for sequence learning", "comments": null, "journal-ref": "IEEE Transactions on Cybernetics, 2020", "doi": "10.1109/TCYB.2020.2984646", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a new self-organizing fuzzy neural network model is presented\nwhich is able to learn and reproduce different sequences accurately. Sequence\nlearning is important in performing skillful tasks, such as writing and playing\npiano. The structure of the proposed network is composed of two parts:\n1-sequence identifier which computes a novel sequence identity value based on\ninitial samples of a sequence, and detects the sequence identity based on\nproper fuzzy rules, and 2-sequence locator, which locates the input sample in\nthe sequence. Therefore, by integrating outputs of these two parts in fuzzy\nrules, the network is able to produce the proper output based on current state\nof the sequence. To learn the proposed structure, a gradual learning procedure\nis proposed. First, learning is performed by adding new fuzzy rules, based on\ncoverage measure, using available correct data. Next, the initialized\nparameters are fine-tuned, by gradient descent algorithm, based on fed back\napproximated network output as the next input. The proposed method has a\ndynamic structure which is able to learn new sequences online. The proposed\nmethod is used to learn and reproduce different sequences simultaneously which\nis the novelty of this method.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 20:41:50 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 08:31:44 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Salimi-Badr", "Armin", ""], ["Ebadzadeh", "Mohammad Mehdi", ""]]}, {"id": "1908.00637", "submitter": "Sacha Sokoloski", "authors": "Sacha Sokoloski and Ruben Coen-Cagli", "title": "Conditional Finite Mixtures of Poisson Distributions for\n  Context-Dependent Neural Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel recordings of neural spike counts have revealed the existence of\ncontext-dependent noise correlations in neural populations. Theories of\npopulation coding have also shown that such correlations can impact the\ninformation encoded by neural populations about external stimuli. Although\nstudies have shown that these correlations often have a low-dimensional\nstructure, it has proven difficult to capture this structure in a model that is\ncompatible with theories of rate coding in correlated populations. To address\nthis difficulty we develop a novel model based on conditional finite mixtures\nof independent Poisson distributions. The model can be conditioned on context\nvariables (e.g. stimuli or task variables), and the number of mixture\ncomponents in the model can be cross-validated to estimate the dimensionality\nof the target correlations. We derive an expectation-maximization algorithm to\nefficiently fit the model to realistic amounts of data from large neural\npopulations. We then demonstrate that the model successfully captures\nstimulus-dependent correlations in the responses of macaque V1 neurons to\noriented gratings. Our model incorporates arbitrary nonlinear\ncontext-dependence, and can thus be applied to improve predictions of neural\nactivity based on deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 21:29:31 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 14:33:10 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Sokoloski", "Sacha", ""], ["Coen-Cagli", "Ruben", ""]]}, {"id": "1908.00751", "submitter": "Alexander Semenov", "authors": "Alexander A. Semenov", "title": "Merging variables: one technique of search in pseudo-Boolean\n  optimization", "comments": "This is a version of the paper accepted to MOTOR 2019 conference\n  (http://motor2019.uran.ru/). In this version we fixed a minor number of typos\n  and presented more detailed proof of Lemma 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper we describe new heuristic technique, which can be\napplied to the optimization of pseudo-Boolean functions including Black-Box\nfunctions. This technique is based on a simple procedure which consists in\ntransition from the optimization problem over Boolean hypercube to the\noptimization problem of auxiliary function in a specially constructed metric\nspace. It is shown that there is a natural connection between the points of the\noriginal Boolean hypercube and points from the new metric space. For the\nBoolean hypercube with fixed dimension it is possible to construct a number of\nsuch metric spaces. The proposed technique can be considered as a special case\nof Variable Neighborhood Search, which is focused on pseudo-Boolean\noptimization. Preliminary computational results show high efficiency of the\nproposed technique on some reasonably hard problems. Also it is shown that the\ndescribed technique in combination with the well-known (1+1)-Evolutionary\nAlgorithm allows to decrease the upper bound on the runtime of this algorithm\nfor arbitrary pseudo-Boolean functions.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 08:28:13 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Semenov", "Alexander A.", ""]]}, {"id": "1908.00936", "submitter": "Andreas Selmar Hauptmann", "authors": "Andreas Hauptmann, and Jonas Adler, and Simon Arridge, and Ozan\n  \\\"Oktem", "title": "Multi-Scale Learned Iterative Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.NA cs.NE math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based learned iterative reconstruction methods have recently been shown\nto outperform classical reconstruction algorithms. Applicability of these\nmethods to large scale inverse problems is however limited by the available\nmemory for training and extensive training times, the latter due to\ncomputationally expensive forward models. As a possible solution to these\nrestrictions we propose a multi-scale learned iterative reconstruction scheme\nthat computes iterates on discretisations of increasing resolution. This\nprocedure does not only reduce memory requirements, it also considerably speeds\nup reconstruction and training times, but most importantly is scalable to large\nscale inverse problems with non-trivial forward operators, such as those that\narise in many 3D tomographic applications. In particular, we propose a hybrid\nnetwork that combines the multi-scale iterative approach with a particularly\nexpressive network architecture which in combination exhibits excellent\nscalability in 3D.\n  Applicability of the algorithm is demonstrated for 3D cone beam computed\ntomography from real measurement data of an organic phantom. Additionally, we\nexamine scalability and reconstruction quality in comparison to established\nlearned reconstruction methods in two dimensions for low dose computed\ntomography on human phantoms.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 09:34:35 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 16:52:58 GMT"}, {"version": "v3", "created": "Mon, 20 Apr 2020 07:03:57 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Hauptmann", "Andreas", ""], ["Adler", "Jonas", ""], ["Arridge", "Simon", ""], ["\u00d6ktem", "Ozan", ""]]}, {"id": "1908.01052", "submitter": "Gabrielle Liu", "authors": "Gabrielle K. Liu", "title": "Weight Friction: A Simple Method to Overcome Catastrophic Forgetting and\n  Enable Continual Learning", "comments": "9 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, deep neural networks have found success in replicating\nhuman-level cognitive skills, yet they suffer from several major obstacles. One\nsignificant limitation is the inability to learn new tasks without forgetting\npreviously learned tasks, a shortcoming known as catastrophic forgetting. In\nthis research, we propose a simple method to overcome catastrophic forgetting\nand enable continual learning in neural networks. We draw inspiration from\nprinciples in neurology and physics to develop the concept of weight friction.\nWeight friction operates by a modification to the update rule in the gradient\ndescent optimization method. It converges at a rate comparable to that of the\nstochastic gradient descent algorithm and can operate over multiple task\ndomains. It performs comparably to current methods while offering improvements\nin computation and memory efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 20:55:46 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 20:41:24 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Liu", "Gabrielle K.", ""]]}, {"id": "1908.01270", "submitter": "Abhishek Halder", "authors": "Abhishek Halder, Kenneth F. Caluya, Bertrand Travacca, and Scott J.\n  Moura", "title": "Hopfield Neural Network Flow: A Geometric Viewpoint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide gradient flow interpretations for the continuous-time\ncontinuous-state Hopfield neural network (HNN). The ordinary and stochastic\ndifferential equations associated with the HNN were introduced in the\nliterature as analog optimizers, and were reported to exhibit good performance\nin numerical experiments. In this work, we point out that the deterministic HNN\ncan be transcribed into Amari's natural gradient descent, and thereby uncover\nthe explicit relation between the underlying Riemannian metric and the\nactivation functions. By exploiting an equivalence between the natural gradient\ndescent and the mirror descent, we show how the choice of activation function\ngoverns the geometry of the HNN dynamics.\n  For the stochastic HNN, we show that the so-called \"diffusion machine\", while\nnot a gradient flow itself, induces a gradient flow when lifted in the space of\nprobability measures. We characterize this infinite dimensional flow as the\ngradient descent of certain free energy with respect to a Wasserstein metric\nthat depends on the geodesic distance on the ground manifold. Furthermore, we\ndemonstrate how this gradient flow interpretation can be used for fast\ncomputation via recently developed proximal algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 04:23:36 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 23:21:37 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Halder", "Abhishek", ""], ["Caluya", "Kenneth F.", ""], ["Travacca", "Bertrand", ""], ["Moura", "Scott J.", ""]]}, {"id": "1908.01314", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu, Bo Zhang, Ruijun Xu", "title": "MoGA: Searching Beyond MobileNetV3", "comments": "Accepted by ICASSP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of MobileNets has laid a solid foundation for neural network\napplications on mobile end. With the latest MobileNetV3, neural architecture\nsearch again claimed its supremacy in network design. Unfortunately, till today\nall mobile methods mainly focus on CPU latencies instead of GPU, the latter,\nhowever, is much preferred in practice for it has faster speed, lower overhead\nand less interference. Bearing the target hardware in mind, we propose the\nfirst Mobile GPU-Aware (MoGA) neural architecture search in order to be\nprecisely tailored for real-world applications. Further, the ultimate objective\nto devise a mobile network lies in achieving better performance by maximizing\nthe utilization of bounded resources. Urging higher capability while\nrestraining time consumption is not reconcilable. We alleviate the tension by\nweighted evolution techniques. Moreover, we encourage increasing the number of\nparameters for higher representational power. With 200x fewer GPU days than\nMnasNet, we obtain a series of models that outperform MobileNetV3 under the\nsimilar latency constraints, i.e., MoGA-A achieves 75.9% top-1 accuracy on\nImageNet, MoGA-B meets 75.5% which costs only 0.5 ms more on mobile GPU. MoGA-C\nbest attests GPU-awareness by reaching 75.3% and being slower on CPU but faster\non GPU.The models and test code is made available here\nhttps://github.com/xiaomi-automl/MoGA.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 10:40:04 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 15:22:20 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 07:24:44 GMT"}, {"version": "v4", "created": "Tue, 3 Mar 2020 04:11:41 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Zhang", "Bo", ""], ["Xu", "Ruijun", ""]]}, {"id": "1908.01478", "submitter": "Yi-Hsiang Chang", "authors": "Yi-Hsiang Chang, Kuan-Yu Chang, Henry Kuo, Chun-Yi Lee", "title": "Reusability and Transferability of Macro Actions for Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional reinforcement learning (RL) typically determines an appropriate\nprimitive action at each timestep. However, by using a proper macro action,\ndefined as a sequence of primitive actions, an agent is able to bypass\nintermediate states to a farther state and facilitate its learning procedure.\nThe problem we would like to investigate is what associated beneficial\nproperties that macro actions may possess. In this paper, we unveil the\nproperties of reusability and transferability of macro actions. The first\nproperty, reusability, means that a macro action generated along with one RL\nmethod can be reused by another RL method for training, while the second one,\ntransferability, means that a macro action can be utilized for training agents\nin similar environments with different reward settings. In our experiments, we\nfirst generate macro actions along with RL methods. We then provide a set of\nanalyses to reveal the properties of reusability and transferability of the\ngenerated macro actions.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 05:59:40 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 06:04:26 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chang", "Yi-Hsiang", ""], ["Chang", "Kuan-Yu", ""], ["Kuo", "Henry", ""], ["Lee", "Chun-Yi", ""]]}, {"id": "1908.01720", "submitter": "Felipe Campelo", "authors": "Felipe Campelo, Elizabeth F. Wanner", "title": "Sample size calculations for the experimental comparison of multiple\n  algorithms on multiple problem instances", "comments": "31 pages. 7 Figures. Submitted to the Journal of Heuristics on 5\n  August 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a statistically principled method for estimating the\nrequired number of instances in the experimental comparison of multiple\nalgorithms on a given problem class of interest. This approach generalises\nearlier results by allowing researchers to design experiments based on the\ndesired best, worst, mean or median-case statistical power to detect\ndifferences between algorithms larger than a certain threshold. Holm's\nstep-down procedure is used to maintain the overall significance level\ncontrolled at desired levels, without resulting in overly conservative\nexperiments. This paper also presents an approach for sampling each algorithm\non each instance, based on optimal sample size ratios that minimise the total\nrequired number of runs subject to a desired accuracy in the estimation of\npaired differences. A case study investigating the effect of 21 variants of a\ncustom-tailored Simulated Annealing for a class of scheduling problems is used\nto illustrate the application of the proposed methods for sample size\ncalculations in the experimental comparison of algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 16:53:59 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Campelo", "Felipe", ""], ["Wanner", "Elizabeth F.", ""]]}, {"id": "1908.01765", "submitter": "Joseph Marvin Imperial", "authors": "Joseph Marvin Imperial, Jeyrome Orosco, Shiela Mae Mazo, Lany Maceda", "title": "Sentiment Analysis of Typhoon Related Tweets using Standard and\n  Bidirectional Recurrent Neural Networks", "comments": "5 figures, 2 tables, presented at the 14th National Natural Language\n  Processing Research Symposium - Student Research Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Philippines is a common ground to natural calamities like typhoons,\nfloods, volcanic eruptions and earthquakes. With Twitter as one of the most\nused social media platform in the Philippines, a total of 39,867 preprocessed\ntweets were obtained given a time frame starting from November 1, 2013 to\nJanuary 31, 2014. Sentiment analysis determines the underlying emotion given a\nseries of words. The main purpose of this study is to identify the sentiments\nexpressed in the tweets sent by the Filipino people before, during, and after\nTyphoon Yolanda using two variations of Recurrent Neural Networks; standard and\nbidirectional. The best generated models after training with various\nhyperparameters achieved a high accuracy of 81.79% for fine-grained\nclassification using standard RNN and 87.69% for binary classification using\nbidirectional RNN. Findings revealed that 51.1% of the tweets sent were\npositive expressing support, love, and words of courage to the victims; 19.8%\nwere negative stating sadness and despair for the loss of lives and hate for\ncorrupt officials; while the other 29% were neutral tweets from local news\nstations, announcements of relief operations, donation drives, and observations\nby citizens.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 23:48:05 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Imperial", "Joseph Marvin", ""], ["Orosco", "Jeyrome", ""], ["Mazo", "Shiela Mae", ""], ["Maceda", "Lany", ""]]}, {"id": "1908.01866", "submitter": "Peter He", "authors": "Peter He, Gerard Glowacki, Alexis Gkantiragas", "title": "Unsupervised Representations of Pollen in Bright-Field Microscopy", "comments": "Accepted at the Workshop on Computational Biology at the\n  International Conference on Machine Learning (ICML) in Long Beach, CA, USA on\n  June 14, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first unsupervised deep learning method for pollen analysis\nusing bright-field microscopy. Using a modest dataset of 650 images of pollen\ngrains collected from honey, we achieve family level identification of pollen.\nWe embed images of pollen grains into a low-dimensional latent space and\ncompare Euclidean and Riemannian metrics on these spaces for clustering. We\npropose this system for automated analysis of pollen and other microscopic\nbiological structures which have only small or unlabelled datasets available.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 21:29:51 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["He", "Peter", ""], ["Glowacki", "Gerard", ""], ["Gkantiragas", "Alexis", ""]]}, {"id": "1908.01867", "submitter": "Cengiz Pehlevan", "authors": "Cengiz Pehlevan, Dmitri B. Chklovskii", "title": "Neuroscience-inspired online unsupervised learning algorithms", "comments": "Accepted for publication in IEEE Signal Processing Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the currently popular deep learning networks achieve unprecedented\nperformance on some tasks, the human brain still has a monopoly on general\nintelligence. Motivated by this and biological implausibility of deep learning\nnetworks, we developed a family of biologically plausible artificial neural\nnetworks (NNs) for unsupervised learning. Our approach is based on optimizing\nprincipled objective functions containing a term that matches the pairwise\nsimilarity of outputs to the similarity of inputs, hence the name -\nsimilarity-based. Gradient-based online optimization of such similarity-based\nobjective functions can be implemented by NNs with biologically plausible local\nlearning rules. Similarity-based cost functions and associated NNs solve\nunsupervised learning tasks such as linear dimensionality reduction, sparse\nand/or nonnegative feature extraction, blind nonnegative source separation,\nclustering and manifold learning.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 21:30:35 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 23:02:01 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Pehlevan", "Cengiz", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "1908.02130", "submitter": "Aras Dargazany", "authors": "Aras R. Dargazany", "title": "Deep learning research landscape & roadmap in a nutshell: past, present\n  and future -- Towards deep cortical learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past, present and future of deep learning is presented in this work.\nGiven this landscape & roadmap, we predict that deep cortical learning will be\nthe convergence of deep learning & cortical learning which builds an artificial\ncortical column ultimately.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 16:57:38 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Dargazany", "Aras R.", ""]]}, {"id": "1908.02149", "submitter": "Amir Nakib", "authors": "Leo Souquet, Amir Nakib", "title": "Multi-node environment strategy for Parallel Deterministic\n  Multi-Objective Fractal Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CY cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new implementation of deterministic multiobjective (MO)\noptimization called Multiobjective Fractal Decomposition Algorithm (Mo-FDA).\nThe original algorithm was designed for mono-objective large scale continuous\noptimization problems. It is based on a divide and conquer strategy and a\ngeometric fractal decomposition of the search space using hyperspheres. Then,\nto deal with MO problems a scalarization approach is used. In this work, a new\napproach has been developed on a multi-node environment using containers. The\nperformance of Mo-FDA was compared to state of the art algorithms from the\nliterature on classical benchmark of multi-objective optimization\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 00:58:12 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Souquet", "Leo", ""], ["Nakib", "Amir", ""]]}, {"id": "1908.02240", "submitter": "Giri Krishnan", "authors": "Giri P Krishnan, Timothy Tadros, Ramyaa Ramyaa, Maxim Bazhenov", "title": "Biologically inspired sleep algorithm for artificial neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep plays an important role in incremental learning and consolidation of\nmemories in biological systems. Motivated by the processes that are known to be\ninvolved in sleep generation in biological networks, we developed an algorithm\nthat implements a sleep-like phase in artificial neural networks (ANNs). After\ninitial training phase, we convert the ANN to a spiking neural network (SNN)\nand simulate an offline sleep-like phase using spike-timing dependent\nplasticity rules to modify synaptic weights. The SNN is then converted back to\nthe ANN and evaluated or trained on new inputs. We demonstrate several\nperformance improvements after applying this processing to ANNs trained on\nMNIST, CUB200 and a motivating toy dataset. First, in an incremental learning\nframework, sleep is able to recover older tasks that were otherwise forgotten\nin the ANN without sleep phase due to catastrophic forgetting. Second, sleep\nresults in forward transfer learning of unseen tasks. Finally, sleep improves\ngeneralization ability of the ANNs to classify images with various types of\nnoise. We provide a theoretical basis for the beneficial role of the\nbrain-inspired sleep-like phase for the ANNs and present an algorithmic way for\nfuture implementations of the various features of sleep in deep learning ANNs.\nOverall, these results suggest that biological sleep can help mitigate a number\nof problems ANNs suffer from, such as poor generalization and catastrophic\nforgetting for incremental learning.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 04:23:49 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Krishnan", "Giri P", ""], ["Tadros", "Timothy", ""], ["Ramyaa", "Ramyaa", ""], ["Bazhenov", "Maxim", ""]]}, {"id": "1908.02386", "submitter": "Seyed Hamed Fatemi Langroudi", "authors": "Hamed F. Langroudi, Zachariah Carmichael, David Pastuch, Dhireesha\n  Kudithipudi", "title": "Cheetah: Mixed Low-Precision Hardware & Software Co-Design Framework for\n  DNNs on the Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-precision DNNs have been extensively explored in order to reduce the size\nof DNN models for edge devices. Recently, the posit numerical format has shown\npromise for DNN data representation and compute with ultra-low precision in\n[5..8]-bits. However, previous studies were limited to studying posit for DNN\ninference only. In this paper, we propose the Cheetah framework, which supports\nboth DNN training and inference using posits, as well as other commonly used\nformats. Additionally, the framework is amenable for different quantization\napproaches and supports mixed-precision floating point and fixed-point\nnumerical formats. Cheetah is evaluated on three datasets: MNIST, Fashion\nMNIST, and CIFAR-10. Results indicate that 16-bit posits outperform 16-bit\nfloating point in DNN training. Furthermore, performing inference with\n[5..8]-bit posits improves the trade-off between performance and\nenergy-delay-product over both [5..8]-bit float and fixed-point.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 22:28:29 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Langroudi", "Hamed F.", ""], ["Carmichael", "Zachariah", ""], ["Pastuch", "David", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "1908.02419", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Jiaoyang Huang", "title": "Gradient Descent Finds Global Minima for Generalizable Deep Neural\n  Networks of Practical Sizes", "comments": "Accepted. All the results remain the same. Additional explanations\n  were added", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we theoretically prove that gradient descent can find a global\nminimum of non-convex optimization of all layers for nonlinear deep neural\nnetworks of sizes commonly encountered in practice. The theory developed in\nthis paper only requires the practical degrees of over-parameterization unlike\nprevious theories. Our theory only requires the number of trainable parameters\nto increase linearly as the number of training samples increases. This allows\nthe size of the deep neural networks to be consistent with practice and to be\nseveral orders of magnitude smaller than that required by the previous\ntheories. Moreover, we prove that the linear increase of the size of the\nnetwork is the optimal rate and that it cannot be improved, except by a\nlogarithmic factor. Furthermore, deep neural networks with the trainability\nguarantee are shown to generalize well to unseen test samples with a natural\ndataset but not a random dataset.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 20:19:39 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 18:27:14 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 19:40:44 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Huang", "Jiaoyang", ""]]}, {"id": "1908.02472", "submitter": "Dmitri Strukov B", "authors": "Mohammad Bavandpour, Shubham Sahay, Mohammad Reza Mahmoodi, Dmitri B.\n  Strukov", "title": "3D-aCortex: An Ultra-Compact Energy-Efficient Neurocomputing Platform\n  Based on Commercial 3D-NAND Flash Memories", "comments": "14 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first contribution of this paper is the development of extremely dense,\nenergy-efficient mixed-signal vector-by-matrix-multiplication (VMM) circuits\nbased on the existing 3D-NAND flash memory blocks, without any need for their\nmodification. Such compatibility is achieved using time-domain-encoded VMM\ndesign. Our detailed simulations have shown that, for example, the 5-bit VMM of\n200-element vectors, using the commercially available 64-layer gate-all-around\nmacaroni-type 3D-NAND memory blocks designed in the 55-nm technology node, may\nprovide an unprecedented area efficiency of 0.14 um2/byte and energy efficiency\nof ~10 fJ/Op, including the input/output and other peripheral circuitry\noverheads. Our second major contribution is the development of 3D-aCortex, a\nmulti-purpose neuromorphic inference processor that utilizes the proposed\n3D-VMM blocks as its core processing units. We have performed rigorous\nperformance simulations of such a processor on both circuit and system levels,\ntaking into account non-idealities such as drain-induced barrier lowering,\ncapacitive coupling, charge injection, parasitics, process variations, and\nnoise. Our modeling of the 3D-aCortex performing several state-of-the-art\nneuromorphic-network benchmarks has shown that it may provide the\nrecord-breaking storage efficiency of 4.34 MB/mm2, the peak energy efficiency\nof 70.43 TOps/J, and the computational throughput up to 10.66 TOps/s. The\nstorage efficiency can be further improved seven-fold by aggressively sharing\nVMM peripheral circuits at the cost of slight decrease in energy efficiency and\nthroughput.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 07:38:34 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Bavandpour", "Mohammad", ""], ["Sahay", "Shubham", ""], ["Mahmoodi", "Mohammad Reza", ""], ["Strukov", "Dmitri B.", ""]]}, {"id": "1908.02658", "submitter": "Wenjian Luo", "authors": "Wenjian Luo, Chenwang Wu, Nan Zhou and Li Ni", "title": "Random Directional Attack for Fooling Deep Neural Networks", "comments": "13pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have been widely used in many fields such as\nimages processing, speech recognition; however, they are vulnerable to\nadversarial examples, and this is a security issue worthy of attention. Because\nthe training process of DNNs converge the loss by updating the weights along\nthe gradient descent direction, many gradient-based methods attempt to destroy\nthe DNN model by adding perturbations in the gradient direction. Unfortunately,\nas the model is nonlinear in most cases, the addition of perturbations in the\ngradient direction does not necessarily increase loss. Thus, we propose a\nrandom directed attack (RDA) for generating adversarial examples in this paper.\nRather than limiting the gradient direction to generate an attack, RDA searches\nthe attack direction based on hill climbing and uses multiple strategies to\navoid local optima that cause attack failure. Compared with state-of-the-art\ngradient-based methods, the attack performance of RDA is very competitive.\nMoreover, RDA can attack without any internal knowledge of the model, and its\nperformance under black-box attack is similar to that of the white-box attack\nin most cases, which is difficult to achieve using existing gradient-based\nattack methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 03:48:29 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Luo", "Wenjian", ""], ["Wu", "Chenwang", ""], ["Zhou", "Nan", ""], ["Ni", "Li", ""]]}, {"id": "1908.02830", "submitter": "Raphael Brito", "authors": "Raphael C. Brito and Hansenclever F. Bassani", "title": "Self-Organizing Maps with Variable Input Length for Motif Discovery and\n  Word Segmentation", "comments": null, "journal-ref": "IEEE International Joint Conference on Neural Networks (IJCNN),\n  1-8, July 2018", "doi": "10.1109/IJCNN.2018.8489090", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Time Series Motif Discovery (TSMD) is defined as searching for patterns that\nare previously unknown and appear with a given frequency in time series.\nAnother problem strongly related with TSMD is Word Segmentation. This problem\nhas received much attention from the community that studies early language\nacquisition in babies and toddlers. The development of biologically plausible\nmodels for word segmentation could greatly advance this field. Therefore, in\nthis article, we propose the Variable Input Length Map (VILMAP) for Motif\nDiscovery and Word Segmentation. The model is based on the Self-Organizing Maps\nand can identify Motifs with different lengths in time series. In our\nexperiments, we show that VILMAP presents good results in finding Motifs in a\nstandard Motif discovery dataset and can avoid catastrophic forgetting when\ntrained with datasets with increasing values of input size. We also show that\nVILMAP achieves results similar or superior to other methods in the literature\ndeveloped for the task of word segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 20:52:19 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Brito", "Raphael C.", ""], ["Bassani", "Hansenclever F.", ""]]}, {"id": "1908.02831", "submitter": "Scott Gigante", "authors": "Scott Gigante, Adam S. Charles, Smita Krishnaswamy, Gal Mishne", "title": "Visualizing the PHATE of Neural Networks", "comments": null, "journal-ref": "Neural Information Processing Systems (2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding why and how certain neural networks outperform others is key to\nguiding future development of network architectures and optimization methods.\nTo this end, we introduce a novel visualization algorithm that reveals the\ninternal geometry of such networks: Multislice PHATE (M-PHATE), the first\nmethod designed explicitly to visualize how a neural network's hidden\nrepresentations of data evolve throughout the course of training. We\ndemonstrate that our visualization provides intuitive, detailed summaries of\nthe learning dynamics beyond simple global measures (i.e., validation loss and\naccuracy), without the need to access validation data. Furthermore, M-PHATE\nbetter captures both the dynamics and community structure of the hidden units\nas compared to visualization based on standard dimensionality reduction methods\n(e.g., ISOMAP, t-SNE). We demonstrate M-PHATE with two vignettes: continual\nlearning and generalization. In the former, the M-PHATE visualizations display\nthe mechanism of \"catastrophic forgetting\" which is a major challenge for\nlearning in task-switching contexts. In the latter, our visualizations reveal\nhow increased heterogeneity among hidden units correlates with improved\ngeneralization performance. An implementation of M-PHATE, along with scripts to\nreproduce the figures in this paper, is available at\nhttps://github.com/scottgigante/M-PHATE.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 20:53:30 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Gigante", "Scott", ""], ["Charles", "Adam S.", ""], ["Krishnaswamy", "Smita", ""], ["Mishne", "Gal", ""]]}, {"id": "1908.02880", "submitter": "Thomas Gabor", "authors": "Thomas Gabor and Philipp Altmann", "title": "Benchmarking Surrogate-Assisted Genetic Recommender Systems", "comments": "Proceedings of the Genetic and Evolutionary Computation Conference\n  Companion. ACM, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach for building recommender systems by adapting\nsurrogate-assisted interactive genetic algorithms. A pool of user-evaluated\nitems is used to construct an approximative model which serves as a surrogate\nfitness function in a genetic algorithm for optimizing new suggestions. The\nsurrogate is used to recommend new items to the user, which are then evaluated\naccording to the user's liking and subsequently removed from the search space.\nBy updating the surrogate model after new recommendations have been evaluated\nby the user, we enable the model itself to evolve towards the user's\npreferences. In order to precisely evaluate the performance of that approach,\nthe human's subjective evaluation is replaced by common continuous objective\nbenchmark functions for evolutionary algorithms. The system's performance is\ncompared to a conventional genetic algorithm and random search. We show that\ngiven a very limited amount of allowed evaluations on the true objective, our\napproach outperforms these baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 00:05:51 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Gabor", "Thomas", ""], ["Altmann", "Philipp", ""]]}, {"id": "1908.03009", "submitter": "Danilo Comminiello", "authors": "Antonio Falvo, Danilo Comminiello, Simone Scardapane, Michele\n  Scarpiniti, Aurelio Uncini", "title": "A Multimodal Deep Network for the Reconstruction of T2W MR Images", "comments": "29th Italian Neural Networks Workshop (WIRN 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple sclerosis is one of the most common chronic neurological diseases\naffecting the central nervous system. Lesions produced by the MS can be\nobserved through two modalities of magnetic resonance (MR), known as T2W and\nFLAIR sequences, both providing useful information for formulating a diagnosis.\nHowever, long acquisition time makes the acquired MR image vulnerable to motion\nartifacts. This leads to the need of accelerating the execution of the MR\nanalysis. In this paper, we present a deep learning method that is able to\nreconstruct subsampled MR images obtained by reducing the k-space data, while\nmaintaining a high image quality that can be used to observe brain lesions. The\nproposed method exploits the multimodal approach of neural networks and it also\nfocuses on the data acquisition and processing stages to reduce execution time\nof the MR analysis. Results prove the effectiveness of the proposed method in\nreconstructing subsampled MR images while saving execution time.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 10:46:28 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 15:50:49 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Falvo", "Antonio", ""], ["Comminiello", "Danilo", ""], ["Scardapane", "Simone", ""], ["Scarpiniti", "Michele", ""], ["Uncini", "Aurelio", ""]]}, {"id": "1908.03015", "submitter": "Felix Berkhahn", "authors": "Felix Berkhahn, Richard Keys, Wajih Ouertani, Nikhil Shetty, and\n  Dominik Gei{\\ss}ler", "title": "Augmenting Variational Autoencoders with Sparse Labels: A Unified\n  Framework for Unsupervised, Semi-(un)supervised, and Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a new flavor of Variational Autoencoder (VAE) that interpolates\nseamlessly between unsupervised, semi-supervised and fully supervised learning\ndomains. We show that unlabeled datapoints not only boost unsupervised tasks,\nbut also the classification performance. Vice versa, every label not only\nimproves classification, but also unsupervised tasks. The proposed architecture\nis simple: A classification layer is connected to the topmost encoder layer,\nand then combined with the resampled latent layer for the decoder. The usual\nevidence lower bound (ELBO) loss is supplemented with a supervised loss target\non this classification layer that is only applied for labeled datapoints. This\nsimplicity allows for extending any existing VAE model to our proposed\nsemi-supervised framework with minimal effort. In the context of\nclassification, we found that this approach even outperforms a direct\nsupervised setup.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 11:07:22 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 13:58:00 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Berkhahn", "Felix", ""], ["Keys", "Richard", ""], ["Ouertani", "Wajih", ""], ["Shetty", "Nikhil", ""], ["Gei\u00dfler", "Dominik", ""]]}, {"id": "1908.03072", "submitter": "Minsoo Rhu", "authors": "Youngeun Kwon, Yunjae Lee, Minsoo Rhu", "title": "TensorDIMM: A Practical Near-Memory Processing Architecture for\n  Embeddings and Tensor Operations in Deep Learning", "comments": "Accepted for publication at the 52nd IEEE/ACM International Symposium\n  on Microarchitecture (MICRO-52), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies from several hyperscalars pinpoint to embedding layers as the\nmost memory-intensive deep learning (DL) algorithm being deployed in today's\ndatacenters. This paper addresses the memory capacity and bandwidth challenges\nof embedding layers and the associated tensor operations. We present our\nvertically integrated hardware/software co-design, which includes a custom DIMM\nmodule enhanced with near-data processing cores tailored for DL tensor\noperations. These custom DIMMs are populated inside a GPU-centric system\ninterconnect as a remote memory pool, allowing GPUs to utilize for scalable\nmemory bandwidth and capacity expansion. A prototype implementation of our\nproposal on real DL systems shows an average 6.2-17.6x performance improvement\non state-of-the-art recommender systems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 13:45:33 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 11:15:05 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Kwon", "Youngeun", ""], ["Lee", "Yunjae", ""], ["Rhu", "Minsoo", ""]]}, {"id": "1908.03185", "submitter": "Max Wilson", "authors": "Max Wilson, Sam Stromswold, Filip Wudarski, Stuart Hadfield, Norm M.\n  Tubman, Eleanor Rieffel", "title": "Optimizing quantum heuristics with meta-learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational quantum algorithms, a class of quantum heuristics, are promising\ncandidates for the demonstration of useful quantum computation. Finding the\nbest way to amplify the performance of these methods on hardware is an\nimportant task. Here, we evaluate the optimization of quantum heuristics with\nan existing class of techniques called `meta-learners'. We compare the\nperformance of a meta-learner to Bayesian optimization, evolutionary\nstrategies, L-BFGS-B and Nelder-Mead approaches, for two quantum heuristics\n(quantum alternating operator ansatz and variational quantum eigensolver), on\nthree problems, in three simulation environments. We show that the meta-learner\ncomes near to the global optima more frequently than all other optimizers we\ntested in a noisy parameter setting environment. We also find that the\nmeta-learner is generally more resistant to noise, for example seeing a smaller\nreduction in performance in Noisy and Sampling environments and performs better\non average by a `gain' metric than its closest comparable competitor L-BFGS-B.\nThese results are an important indication that meta-learning and associated\nmachine learning methods will be integral to the useful application of noisy\nnear-term quantum computers.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 17:31:28 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Wilson", "Max", ""], ["Stromswold", "Sam", ""], ["Wudarski", "Filip", ""], ["Hadfield", "Stuart", ""], ["Tubman", "Norm M.", ""], ["Rieffel", "Eleanor", ""]]}, {"id": "1908.03532", "submitter": "Leendert Remmelzwaal", "authors": "Leendert A Remmelzwaal, George F R Ellis, Jonathan Tapson, Amit K\n  Mishra", "title": "Biologically-inspired Salience Affected Artificial Neural Network (SANN)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper we introduce a novel Salience Affected Artificial Neural\nNetwork (SANN) that models the way neuromodulators such as dopamine and\nnoradrenaline affect neural dynamics in the human brain by being distributed\ndiffusely through neocortical regions, allowing both salience signals to\nmodulate cognition immediately, and one time learning to take place through\nstrengthening entire patterns of activation at one go. We present a model that\nis capable of one-time salience tagging in a neural network trained to classify\nobjects, and returns a salience response during classification (inference). We\nexplore the effects of salience on learning via its effect on the activation\nfunctions of each node, as well as on the strength of weights between nodes in\nthe network. We demonstrate that salience tagging can improve classification\nconfidence for both the individual image as well as the class of images it\nbelongs to. We also show that the computation impact of producing a salience\nresponse is minimal. This research serves as a proof of concept, and could be\nthe first step towards introducing salience tagging into Deep Learning Networks\nand robotics.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 16:40:52 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 06:43:09 GMT"}, {"version": "v3", "created": "Fri, 23 Aug 2019 07:59:29 GMT"}, {"version": "v4", "created": "Fri, 7 Feb 2020 13:56:30 GMT"}, {"version": "v5", "created": "Mon, 30 Nov 2020 07:50:48 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Remmelzwaal", "Leendert A", ""], ["Ellis", "George F R", ""], ["Tapson", "Jonathan", ""], ["Mishra", "Amit K", ""]]}, {"id": "1908.03891", "submitter": "Gregorz Dudek", "authors": "Grzegorz Dudek", "title": "Data-Driven Randomized Learning of Feedforward Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized methods of neural network learning suffer from a problem with the\ngeneration of random parameters as they are difficult to set optimally to\nobtain a good projection space. The standard method draws the parameters from a\nfixed interval which is independent of the data scope and activation function\ntype. This does not lead to good results in the approximation of the strongly\nnonlinear functions. In this work, a method which adjusts the random\nparameters, representing the slopes and positions of the sigmoids, to the\ntarget function features is proposed. The method randomly selects the input\nspace regions, places the sigmoids in these regions and then adjusts the\nsigmoid slopes to the local fluctuations of the target function. This brings\nvery good results in the approximation of the complex target functions when\ncompared to the standard fixed interval method and other methods recently\nproposed in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 12:07:31 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "1908.03930", "submitter": "Xiaohan Ding", "authors": "Xiaohan Ding, Yuchen Guo, Guiguang Ding, Jungong Han", "title": "ACNet: Strengthening the Kernel Skeletons for Powerful CNN via\n  Asymmetric Convolution Blocks", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As designing appropriate Convolutional Neural Network (CNN) architecture in\nthe context of a given application usually involves heavy human works or\nnumerous GPU hours, the research community is soliciting the\narchitecture-neutral CNN structures, which can be easily plugged into multiple\nmature architectures to improve the performance on our real-world applications.\nWe propose Asymmetric Convolution Block (ACB), an architecture-neutral\nstructure as a CNN building block, which uses 1D asymmetric convolutions to\nstrengthen the square convolution kernels. For an off-the-shelf architecture,\nwe replace the standard square-kernel convolutional layers with ACBs to\nconstruct an Asymmetric Convolutional Network (ACNet), which can be trained to\nreach a higher level of accuracy. After training, we equivalently convert the\nACNet into the same original architecture, thus requiring no extra computations\nanymore. We have observed that ACNet can improve the performance of various\nmodels on CIFAR and ImageNet by a clear margin. Through further experiments, we\nattribute the effectiveness of ACB to its capability of enhancing the model's\nrobustness to rotational distortions and strengthening the central skeleton\nparts of square convolution kernels.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 16:06:58 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 09:24:11 GMT"}, {"version": "v3", "created": "Sat, 31 Aug 2019 12:50:35 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ding", "Xiaohan", ""], ["Guo", "Yuchen", ""], ["Ding", "Guiguang", ""], ["Han", "Jungong", ""]]}, {"id": "1908.04085", "submitter": "Damien Querlioz", "authors": "Tifenn Hirtzlin, Bogdan Penkovsky, Jacques-Olivier Klein, Nicolas\n  Locatelli, Adrien F. Vincent, Marc Bocquet, Jean-Michel Portal and Damien\n  Querlioz", "title": "Implementing Binarized Neural Networks with Magnetoresistive RAM without\n  Error Correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most exciting applications of Spin Torque Magnetoresistive Random\nAccess Memory (ST-MRAM) is the in-memory implementation of deep neural\nnetworks, which could allow improving the energy efficiency of Artificial\nIntelligence by orders of magnitude with regards to its implementation on\ncomputers and graphics cards. In particular, ST-MRAM could be ideal for\nimplementing Binarized Neural Networks (BNNs), a type of deep neural networks\ndiscovered in 2016, which can achieve state-of-the-art performance with a\nhighly reduced memory footprint with regards to conventional artificial\nintelligence approaches. The challenge of ST-MRAM, however, is that it is prone\nto write errors and usually requires the use of error correction. In this work,\nwe show that these bit errors can be tolerated by BNNs to an outstanding level,\nbased on examples of image recognition tasks (MNIST, CIFAR-10 and ImageNet):\nbit error rates of ST-MRAM up to 0.1% have little impact on recognition\naccuracy. The requirements for ST-MRAM are therefore considerably relaxed for\nBNNs with regards to traditional applications. By consequence, we show that for\nBNNs, ST-MRAMs can be programmed with weak (low-energy) programming conditions,\nwithout error correcting codes. We show that this result can allow the use of\nlow energy and low area ST-MRAM cells, and show that the energy savings at the\nsystem level can reach a factor two.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 11:04:16 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Hirtzlin", "Tifenn", ""], ["Penkovsky", "Bogdan", ""], ["Klein", "Jacques-Olivier", ""], ["Locatelli", "Nicolas", ""], ["Vincent", "Adrien F.", ""], ["Bocquet", "Marc", ""], ["Portal", "Jean-Michel", ""], ["Querlioz", "Damien", ""]]}, {"id": "1908.04351", "submitter": "Brian Kenji Iwana", "authors": "Brian Kenji Iwana, Ryohei Kuroki, Seiichi Uchida", "title": "Explaining Convolutional Neural Networks using Softmax Gradient\n  Layer-wise Relevance Propagation", "comments": "Published at ICCV 2019 Workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) have become state-of-the-art in the field\nof image classification. However, not everything is understood about their\ninner representations. This paper tackles the interpretability and\nexplainability of the predictions of CNNs for multi-class classification\nproblems. Specifically, we propose a novel visualization method of pixel-wise\ninput attribution called Softmax-Gradient Layer-wise Relevance Propagation\n(SGLRP). The proposed model is a class discriminate extension to Deep Taylor\nDecomposition (DTD) using the gradient of softmax to back propagate the\nrelevance of the output probability to the input image. Through qualitative and\nquantitative analysis, we demonstrate that SGLRP can successfully localize and\nattribute the regions on input images which contribute to a target object's\nclassification. We show that the proposed method excels at discriminating the\ntarget objects class from the other possible objects in the images. We confirm\nthat SGLRP performs better than existing Layer-wise Relevance Propagation (LRP)\nbased methods and can help in the understanding of the decision process of\nCNNs.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 13:05:04 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 07:48:59 GMT"}, {"version": "v3", "created": "Thu, 7 Nov 2019 07:48:43 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Iwana", "Brian Kenji", ""], ["Kuroki", "Ryohei", ""], ["Uchida", "Seiichi", ""]]}, {"id": "1908.04355", "submitter": "Divyam Madaan", "authors": "Divyam Madaan, Jinwoo Shin, Sung Ju Hwang", "title": "Adversarial Neural Pruning with Latent Vulnerability Suppression", "comments": "Accepted to ICML 2020. Code available at\n  https://github.com/divyam3897/ANP_VS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the remarkable performance of deep neural networks on various\ncomputer vision tasks, they are known to be susceptible to adversarial\nperturbations, which makes it challenging to deploy them in real-world\nsafety-critical applications. In this paper, we conjecture that the leading\ncause of adversarial vulnerability is the distortion in the latent feature\nspace, and provide methods to suppress them effectively. Explicitly, we define\n\\emph{vulnerability} for each latent feature and then propose a new loss for\nadversarial learning, \\emph{Vulnerability Suppression (VS)} loss, that aims to\nminimize the feature-level vulnerability during training. We further propose a\nBayesian framework to prune features with high vulnerability to reduce both\nvulnerability and loss on adversarial samples. We validate our\n\\emph{Adversarial Neural Pruning with Vulnerability Suppression (ANP-VS)}\nmethod on multiple benchmark datasets, on which it not only obtains\nstate-of-the-art adversarial robustness but also improves the performance on\nclean examples, using only a fraction of the parameters used by the full\nnetwork. Further qualitative analysis suggests that the improvements come from\nthe suppression of feature-level vulnerability.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 19:33:58 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 08:48:00 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 07:14:39 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2020 13:47:36 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Madaan", "Divyam", ""], ["Shin", "Jinwoo", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1908.04655", "submitter": "Xi Chen", "authors": "Xi Chen, Farhan Feroz, Michael Hobson", "title": "Bayesian posterior repartitioning for nested sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO astro-ph.IM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Priors in Bayesian analyses often encode informative domain knowledge that\ncan be useful in making the inference process more efficient. Occasionally,\nhowever, priors may be unrepresentative of the parameter values for a given\ndataset, which can result in inefficient parameter space exploration, or even\nincorrect inferences, particularly for nested sampling (NS) algorithms. Simply\nbroadening the prior in such cases may be inappropriate or impossible in some\napplications. Hence our previous solution to this problem, known as posterior\nrepartitioning (PR), redefines the prior and likelihood while keeping their\nproduct fixed, so that the posterior inferences and evidence estimates remain\nunchanged, but the efficiency of the NS process is significantly increased. In\nits most practical form, PR raises the prior to some power $\\beta$, which is\nintroduced as an auxiliary variable that must be determined on a case-by-case\nbasis, usually by lowering $\\beta$ from unity according to some pre-defined\n`annealing schedule' until the resulting inferences converge to a consistent\nsolution. Here we present a very simple yet powerful alternative Bayesian\napproach, in which $\\beta$ is instead treated as a hyperparameter that is\ninferred from the data alongside the original parameters of the problem, and\nthen marginalised over to obtain the final inference. We show through numerical\nexamples that this Bayesian PR (BPR) method provides a very robust,\nself-adapting and computationally efficient `hands-off' solution to the problem\nof unrepresentative priors in Bayesian inference using NS. Moreover, unlike the\noriginal PR method, we show that even for representative priors BPR has a\nnegligible computational overhead relative to standard nesting sampling, which\nsuggests that it should be used as the default in all NS analyses.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 14:19:41 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 17:39:31 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Chen", "Xi", ""], ["Feroz", "Farhan", ""], ["Hobson", "Michael", ""]]}, {"id": "1908.04784", "submitter": "Jordan J. Bird", "authors": "Jordan J. Bird, Diego R. Faria, Luis J. Manso, Anik\\'o Ek\\'art,\n  Christopher D. Buckingham", "title": "A Deep Evolutionary Approach to Bioinspired Classifier Optimisation for\n  Brain-Machine Interaction", "comments": "14 pages, 12 figures", "journal-ref": null, "doi": "10.1155/2019/4316548", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study suggests a new approach to EEG data classification by exploring\nthe idea of using evolutionary computation to both select useful discriminative\nEEG features and optimise the topology of Artificial Neural Networks. An\nevolutionary algorithm is applied to select the most informative features from\nan initial set of 2550 EEG statistical features. Optimisation of a Multilayer\nPerceptron (MLP) is performed with an evolutionary approach before\nclassification to estimate the best hyperparameters of the network. Deep\nlearning and tuning with Long Short-Term Memory (LSTM) are also explored, and\nAdaptive Boosting of the two types of models is tested for each problem. Three\nexperiments are provided for comparison using different classifiers: one for\nattention state classification, one for emotional sentiment classification, and\na third experiment in which the goal is to guess the number a subject is\nthinking of. The obtained results show that an Adaptive Boosted LSTM can\nachieve an accuracy of 84.44%, 97.06%, and 9.94% on the attentional, emotional,\nand number datasets, respectively. An evolutionary-optimised MLP achieves\nresults close to the Adaptive Boosted LSTM for the two first experiments and\nsignificantly higher for the number-guessing experiment with an Adaptive\nBoosted DEvo MLP reaching 31.35%, while being significantly quicker to train\nand classify. In particular, the accuracy of the nonboosted DEvo MLP was of\n79.81%, 96.11%, and 27.07% in the same benchmarks. Two datasets for the\nexperiments were gathered using a Muse EEG headband with four electrodes\ncorresponding to TP9, AF7, AF8, and TP10 locations of the international EEG\nplacement standard. The EEG MindBigData digits dataset was gathered from the\nTP9, FP1, FP2, and TP10 locations.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 16:49:30 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Bird", "Jordan J.", ""], ["Faria", "Diego R.", ""], ["Manso", "Luis J.", ""], ["Ek\u00e1rt", "Anik\u00f3", ""], ["Buckingham", "Christopher D.", ""]]}, {"id": "1908.04909", "submitter": "Yan Xu", "authors": "Steven Gardner, Oleg Golovidov, Joshua Griffin, Patrick Koch, Wayne\n  Thompson, Brett Wujek and Yan Xu", "title": "Constrained Multi-Objective Optimization for Automated Machine Learning", "comments": "10 pages, 8 figures, accepted at DSAA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated machine learning has gained a lot of attention recently. Building\nand selecting the right machine learning models is often a multi-objective\noptimization problem. General purpose machine learning software that\nsimultaneously supports multiple objectives and constraints is scant, though\nthe potential benefits are great. In this work, we present a framework called\nAutotune that effectively handles multiple objectives and constraints that\narise in machine learning problems. Autotune is built on a suite of\nderivative-free optimization methods, and utilizes multi-level parallelism in a\ndistributed computing environment for automatically training, scoring, and\nselecting good models. Incorporation of multiple objectives and constraints in\nthe model exploration and selection process provides the flexibility needed to\nsatisfy trade-offs necessary in practical machine learning applications.\nExperimental results from standard multi-objective optimization benchmark\nproblems show that Autotune is very efficient in capturing Pareto fronts. These\nbenchmark results also show how adding constraints can guide the search to more\npromising regions of the solution space, ultimately producing more desirable\nPareto fronts. Results from two real-world case studies demonstrate the\neffectiveness of the constrained multi-objective optimization capability\noffered by Autotune.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 01:31:45 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Gardner", "Steven", ""], ["Golovidov", "Oleg", ""], ["Griffin", "Joshua", ""], ["Koch", "Patrick", ""], ["Thompson", "Wayne", ""], ["Wujek", "Brett", ""], ["Xu", "Yan", ""]]}, {"id": "1908.05164", "submitter": "Antoine Wehenkel", "authors": "Antoine Wehenkel and Gilles Louppe", "title": "Unconstrained Monotonic Neural Networks", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monotonic neural networks have recently been proposed as a way to define\ninvertible transformations. These transformations can be combined into powerful\nautoregressive flows that have been shown to be universal approximators of\ncontinuous probability distributions. Architectures that ensure monotonicity\ntypically enforce constraints on weights and activation functions, which\nenables invertibility but leads to a cap on the expressiveness of the resulting\ntransformations. In this work, we propose the Unconstrained Monotonic Neural\nNetwork (UMNN) architecture based on the insight that a function is monotonic\nas long as its derivative is strictly positive. In particular, this latter\ncondition can be enforced with a free-form neural network whose only constraint\nis the positiveness of its output. We evaluate our new invertible building\nblock within a new autoregressive flow (UMNN-MAF) and demonstrate its\neffectiveness on density estimation experiments. We also illustrate the ability\nof UMNNs to improve variational inference.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 15:11:31 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 14:25:18 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 10:01:36 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Wehenkel", "Antoine", ""], ["Louppe", "Gilles", ""]]}, {"id": "1908.05191", "submitter": "Sepehr Saadatmand", "authors": "Sepehr Saadatmand, Mohammad Saleh Sanjarinia, Pourya Shamsi, and Mehdi\n  Ferdowsi", "title": "Dual Heuristic Dynamic Programing Control of Grid-Connected\n  Synchronverters", "comments": "NAPS 2019 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a new approach to control a grid-connected synchronverter by\nusing a dual heuristic dynamic programing (DHP) design is presented. The\ndisadvantages of conventional synchronverter controller such as the challenges\nto cope with nonlinearity, uncertainties, and non-inductive grids are\ndiscussed.To deal with the aforementioned challenges a neural network based\nadaptive critic design is introduced to optimize the associated cost function.\nThe characteristic of the neural networks facilitates the performance under\nuncertainties and unknown parameters (for example different power angles). The\nproposed DHP design includes three neural networks: system NN, action NN, and\ncritic NN. The simulation results compare the performance of the proposed DHP\nwith a traditional PI-based design and with a neural network predictive\ncontroller. It is shown a well trained DHP design performs in a trajectory,\nwhich is more optimal compared to the other two controllers.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 16:06:58 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Saadatmand", "Sepehr", ""], ["Sanjarinia", "Mohammad Saleh", ""], ["Shamsi", "Pourya", ""], ["Ferdowsi", "Mehdi", ""]]}, {"id": "1908.05199", "submitter": "Sepehr Saadatmand", "authors": "Sepehr Saadatmand, Mohammad Saleh Sanjarinia, Pourya Shamsi, Mehdi\n  Ferdowsi, and Donald C. Wunsch", "title": "Neural Network Predictive Controller for Grid-Connected Virtual\n  Synchronous Generator", "comments": "NAPS 2019 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a neural network predictive controller is proposed to regulate\nthe active and the reactive power delivered to the grid generated by a\nthree-phase virtual inertia-based inverter. The concept of the conventional\nvirtual synchronous generator (VSG) is discussed, and it is shown that when the\ninverter is connected to non-inductive grids, the conventional PI-based VSGs\nare unable to perform acceptable tracking. The concept of the neural network\npredictive controller is also discussed to replace the traditional VSGs. This\nreplacement enables inverters to perform in both inductive and non-inductive\ngrids. The simulation results confirm that a well-trained neural network\npredictive controller illustrates can adapt to any grid impedance angle,\ncompared to the traditional PI-based virtual inertia controllers.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 16:17:31 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Saadatmand", "Sepehr", ""], ["Sanjarinia", "Mohammad Saleh", ""], ["Shamsi", "Pourya", ""], ["Ferdowsi", "Mehdi", ""], ["Wunsch", "Donald C.", ""]]}, {"id": "1908.05383", "submitter": "Pedro Braga", "authors": "Lucas R. C. de Farias, Pedro H. M. Braga, Hansenclever F. Bassani and\n  Aluizio F. R. Ara\\'ujo", "title": "MOEA/D with Uniformly Randomly Adaptive Weights", "comments": null, "journal-ref": "2018 Genetic and Evolutionary Computation Conference (GECCO)", "doi": "10.1145/3205455.3205648", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  When working with decomposition-based algorithms, an appropriate set of\nweights might improve quality of the final solution. A set of uniformly\ndistributed weights usually leads to well-distributed solutions on a Pareto\nfront. However, there are two main difficulties with this approach. Firstly, it\nmay fail depending on the problem geometry. Secondly, the population size\nbecomes not flexible as the number of objectives increases. In this paper, we\npropose the MOEA/D with Uniformly Randomly Adaptive Weights (MOEA/DURAW) which\nuses the Uniformly Randomly method as an approach to subproblems generation,\nallowing a flexible population size even when working with many objective\nproblems. During the evolutionary process, MOEA/D-URAW adds and removes\nsubproblems as a function of the sparsity level of the population. Moreover,\ninstead of requiring assumptions about the Pareto front shape, our method\nadapts its weights to the shape of the problem during the evolutionary process.\nExperimental results using WFG41-48 problem classes, with different Pareto\nfront shapes, shows that the present method presents better or equal results in\n77.5% of the problems evaluated from 2 to 6 objectives when compared with\nstate-of-the-art methods in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 00:52:06 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["de Farias", "Lucas R. C.", ""], ["Braga", "Pedro H. M.", ""], ["Bassani", "Hansenclever F.", ""], ["Ara\u00fajo", "Aluizio F. R.", ""]]}, {"id": "1908.05542", "submitter": "Gregorz Dudek", "authors": "Grzegorz Dudek", "title": "Improving Randomized Learning of Feedforward Neural Networks by\n  Appropriate Generation of Random Parameters", "comments": null, "journal-ref": "15th International Work-Conference on Artificial Neural Networks\n  IWANN 2019. LNCS, vol 11506. Springer, Cham", "doi": "10.1007/978-3-030-20521-8_43", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a method of random parameters generation for randomized\nlearning of a single-hidden-layer feedforward neural network is proposed. The\nmethod firstly, randomly selects the slope angles of the hidden neurons\nactivation functions from an interval adjusted to the target function, then\nrandomly rotates the activation functions, and finally distributes them across\nthe input space. For complex target functions the proposed method gives better\nresults than the approach commonly used in practice, where the random\nparameters are selected from the fixed interval. This is because it introduces\nthe steepest fragments of the activation functions into the input hypercube,\navoiding their saturation fragments.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 13:52:22 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "1908.05744", "submitter": "Sepehr Saadatmand", "authors": "Sepehr Saadatmand, Mohammad Saleh Sanjarinia, Pourya Shamsi, Mehdi\n  Ferdowsi, and Donald C. Wunsch", "title": "Heuristic Dynamic Programming for Adaptive Virtual Synchronous\n  Generators", "comments": "NAPS 2019 Conference. arXiv admin note: substantial text overlap with\n  arXiv:1908.05191; text overlap with arXiv:1908.05199", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a neural network heuristic dynamic programing (HDP) is used for\noptimal control of the virtual inertia based control of grid connected three\nphase inverters. It is shown that the conventional virtual inertia controllers\nare not suited for non inductive grids. A neural network based controller is\nproposed to adapt to any impedance angle. Applying an adaptive dynamic\nprogramming controller instead of a supervised controlled method enables the\nsystem to adjust itself to different conditions. The proposed HDP consists of\ntwo subnetworks, critic network and action network. These networks can be\ntrained during the same training cycle to decrease the training time. The\nsimulation results confirm that the proposed neural network HDP controller\nperforms better than the traditional direct fed voltage and reactive power\ncontrollers in virtual inertia control schemes.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 16:12:58 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Saadatmand", "Sepehr", ""], ["Sanjarinia", "Mohammad Saleh", ""], ["Shamsi", "Pourya", ""], ["Ferdowsi", "Mehdi", ""], ["Wunsch", "Donald C.", ""]]}, {"id": "1908.05759", "submitter": "Mohammad Shojafar", "authors": "Rahim Taheri, Meysam Ghahramani, Reza Javidan, Mohammad Shojafar,\n  Zahra Pooranian, Mauro Conti", "title": "Similarity-based Android Malware Detection Using Hamming Distance of\n  Static Binary Features", "comments": "20 pages, 8 figures, 11 tables, FGCS Elsevier journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we develop four malware detection methods using Hamming\ndistance to find similarity between samples which are first nearest neighbors\n(FNN), all nearest neighbors (ANN), weighted all nearest neighbors (WANN), and\nk-medoid based nearest neighbors (KMNN). In our proposed methods, we can\ntrigger the alarm if we detect an Android app is malicious. Hence, our\nsolutions help us to avoid the spread of detected malware on a broader scale.\nWe provide a detailed description of the proposed detection methods and related\nalgorithms. We include an extensive analysis to asses the suitability of our\nproposed similarity-based detection methods. In this way, we perform our\nexperiments on three datasets, including benign and malware Android apps like\nDrebin, Contagio, and Genome. Thus, to corroborate the actual effectiveness of\nour classifier, we carry out performance comparisons with some state-of-the-art\nclassification and malware detection algorithms, namely Mixed and Separated\nsolutions, the program dissimilarity measure based on entropy (PDME) and the\nFalDroid algorithms. We test our experiments in a different type of features:\nAPI, intent, and permission features on these three datasets. The results\nconfirm that accuracy rates of proposed algorithms are more than 90% and in\nsome cases (i.e., considering API features) are more than 99%, and are\ncomparable with existing state-of-the-art solutions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 03:53:54 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 07:26:15 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Taheri", "Rahim", ""], ["Ghahramani", "Meysam", ""], ["Javidan", "Reza", ""], ["Shojafar", "Mohammad", ""], ["Pooranian", "Zahra", ""], ["Conti", "Mauro", ""]]}, {"id": "1908.05864", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek", "title": "Generating Random Parameters in Feedforward Neural Networks with Random\n  Hidden Nodes: Drawbacks of the Standard Method and How to Improve It", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard method of generating random weights and biases in feedforward\nneural networks with random hidden nodes, selects them both from the uniform\ndistribution over the same fixed interval. In this work, we show the drawbacks\nof this approach and propose a new method of generating random parameters. This\nmethod ensures the most nonlinear fragments of sigmoids, which are most useful\nin modeling target function nonlinearity, are kept in the input hypercube. In\naddition, we show how to generate activation functions with uniformly\ndistributed slope angles.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 06:43:33 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 12:26:38 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "1908.05867", "submitter": "Zhaoyang Zhang", "authors": "Zhaoyang Zhang, Jingyu Li, Wenqi Shao, Zhanglin Peng, Ruimao Zhang,\n  Xiaogang Wang, Ping Luo", "title": "Differentiable Learning-to-Group Channels via Groupable Convolutional\n  Neural Networks", "comments": "accepted by ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group convolution, which divides the channels of ConvNets into groups, has\nachieved impressive improvement over the regular convolution operation.\nHowever, existing models, eg. ResNeXt, still suffers from the sub-optimal\nperformance due to manually defining the number of groups as a constant over\nall of the layers. Toward addressing this issue, we present Groupable ConvNet\n(GroupNet) built by using a novel dynamic grouping convolution (DGConv)\noperation, which is able to learn the number of groups in an end-to-end manner.\nThe proposed approach has several appealing benefits. (1) DGConv provides a\nunified convolution representation and covers many existing convolution\noperations such as regular dense convolution, group convolution, and depthwise\nconvolution. (2) DGConv is a differentiable and flexible operation which learns\nto perform various convolutions from training data. (3) GroupNet trained with\nDGConv learns different number of groups for different convolution layers.\nExtensive experiments demonstrate that GroupNet outperforms its counterparts\nsuch as ResNet and ResNeXt in terms of accuracy and computational complexity.\nWe also present introspection and reproducibility study, for the first time,\nshowing the learning dynamics of training group numbers.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 06:50:33 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 08:06:53 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Zhang", "Zhaoyang", ""], ["Li", "Jingyu", ""], ["Shao", "Wenqi", ""], ["Peng", "Zhanglin", ""], ["Zhang", "Ruimao", ""], ["Wang", "Xiaogang", ""], ["Luo", "Ping", ""]]}, {"id": "1908.05978", "submitter": "Sandra Ortega-Martorell", "authors": "Paulo J. G. Lisboa, Sandra Ortega-Martorell, Sadie Cashman, and Ivan\n  Olier", "title": "The Partial Response Network: a neural network nomogram", "comments": "23 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among interpretable machine learning methods, the class of Generalised\nAdditive Neural Networks (GANNs) is referred to as Self-Explaining Neural\nNetworks (SENN) because of the linear dependence on explicit functions of the\ninputs. In binary classification this shows the precise weight that each input\ncontributes towards the logit. The nomogram is a graphical representation of\nthese weights. We show that functions of individual and pairs of variables can\nbe derived from a functional Analysis of Variance (ANOVA) representation,\nenabling an efficient feature selection to be carried by application of the\nlogistic Lasso. This process infers the structure of GANNs which otherwise\nneeds to be predefined. As this method is particularly suited for tabular data,\nit starts by fitting a generic flexible model, in this case a Multi-layer\nPerceptron (MLP) to which the ANOVA decomposition is applied. This has the\nfurther advantage that the resulting GANN can be replicated as a SENN, enabling\nfurther refinement of the univariate and bivariate component functions to take\nplace. The component functions are partial responses hence the SENN is a\npartial response network. The Partial Response Network (PRN) is equally as\ntransparent as a traditional logistic regression model, but capable of\nnon-linear classification with comparable or superior performance to the\noriginal MLP. In other words, the PRN is a fully interpretable representation\nof the MLP, at the level of univariate and bivariate effects. The performance\nof the PRN is shown to be competitive for benchmark data, against\nstate-of-the-art machine learning methods including GBM, SVM and Random\nForests. It is also compared with spline-based Sparse Additive Models (SAM)\nshowing that a semi-parametric representation of the GAM as a neural network\ncan be as effective as the SAM though less constrained by the need to set\nspline nodes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 14:02:19 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 15:52:26 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 08:45:37 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Lisboa", "Paulo J. G.", ""], ["Ortega-Martorell", "Sandra", ""], ["Cashman", "Sadie", ""], ["Olier", "Ivan", ""]]}, {"id": "1908.06040", "submitter": "Felipe Moreno-Vera", "authors": "Felipe Moreno-Vera", "title": "Performing Deep Recurrent Double Q-Learning for Atari Games", "comments": "Accepted paper on LatinXinAI Workshop co-located with the\n  International Conference on Machine Learning (ICML) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, many applications in Machine Learning are based on define new\nmodels to extract more information about data, In this case Deep Reinforcement\nLearning with the most common application in video games like Atari, Mario, and\nothers causes an impact in how to computers can learning by himself with only\ninformation called rewards obtained from any action. There is a lot of\nalgorithms modeled and implemented based on Deep Recurrent Q-Learning proposed\nby DeepMind used in AlphaZero and Go. In this document, We proposed Deep\nRecurrent Double Q-Learning that is an implementation of Deep Reinforcement\nLearning using Double Q-Learning algorithms and Recurrent Networks like LSTM\nand DRQN.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 15:56:16 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 21:45:01 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Moreno-Vera", "Felipe", ""]]}, {"id": "1908.06088", "submitter": "Andrei Ivanov", "authors": "Andrei Ivanov, Sergei Andrianov", "title": "Matrix Lie Maps and Neural Networks for Solving Differential Equations", "comments": "11 pages, 5 figures. arXiv admin note: text overlap with\n  arXiv:1802.01353", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.NA math.DS math.NA physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coincidence between polynomial neural networks and matrix Lie maps is\ndiscussed in the article. The matrix form of Lie transform is an approximation\nof the general solution of the nonlinear system of ordinary differential\nequations. It can be used for solving systems of differential equations more\nefficiently than traditional step-by-step numerical methods. Implementation of\nthe Lie map as a polynomial neural network provides a tool for both simulation\nand data-driven identification of dynamical systems. If the differential\nequation is provided, training a neural network is unnecessary. The weights of\nthe network can be directly calculated from the equation. On the other hand,\nfor data-driven system learning, the weights can be fitted without any\nassumptions in view of differential equations. The proposed technique is\ndiscussed in the examples of both ordinary and partial differential equations.\nThe building of a polynomial neural network that simulates the Van der Pol\noscillator is discussed. For this example, we consider learning the dynamics\nfrom a single solution of the system. We also demonstrate the building of the\nneural network that describes the solution of Burgers' equation that is a\nfundamental partial differential equation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 08:51:53 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Ivanov", "Andrei", ""], ["Andrianov", "Sergei", ""]]}, {"id": "1908.06232", "submitter": "Faizal Hafiz", "authors": "Faizal Hafiz and Akshya Swain and Eduardo MAM Mendes", "title": "Multi-Objective Evolutionary Framework for Non-linear System\n  Identification: A Comprehensive Investigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study proposes a multi-objective framework for structure\nselection of nonlinear systems which are represented by polynomial NARX models.\nThis framework integrates the key components of Multi-Criteria Decision Making\n(MCDM) which include preference handling, Multi-Objective Evolutionary\nAlgorithms (MOEAs) and a posteriori selection. To this end, three well-known\nMOEAs such as NSGA-II, SPEA-II and MOEA/D are thoroughly investigated to\ndetermine if there exists any significant difference in their search\nperformance. The sensitivity of all these MOEAs to various qualitative and\nquantitative parameters, such as the choice of recombination mechanism,\ncrossover and mutation probabilities, is also studied. These issues are\ncritically analyzed considering seven discrete-time and a continuous-time\nbenchmark nonlinear system as well as a practical case study of non-linear\nwave-force modeling. The results of this investigation demonstrate that MOEAs\ncan be tailored to determine the correct structure of nonlinear systems.\nFurther, it has been established through frequency domain analysis that it is\npossible to identify multiple valid discrete-time models for continuous-time\nsystems. A rigorous statistical analysis of MOEAs via performance sweet spots\nin the parameter space convincingly demonstrates that these algorithms are\nrobust over a wide range of control parameters.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 03:59:11 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Hafiz", "Faizal", ""], ["Swain", "Akshya", ""], ["Mendes", "Eduardo MAM", ""]]}, {"id": "1908.06326", "submitter": "Rahul Vashisht", "authors": "Rahul Vashisht, H.Viji, T.Sundararajan, D.Mohankumar, S.Sumitra", "title": "Structural Health Monitoring of Cantilever Beam, a Case Study -- Using\n  Bayesian Neural Network AND Deep Learning", "comments": "10 Pages", "journal-ref": null, "doi": "10.1007/978-981-13-8767-8_64", "report-no": "11", "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancement of machine learning algorithms has opened a wide scope for\nvibration-based SHM (Structural Health Monitoring). Vibration-based SHM is\nbased on the fact that damage will alter the dynamic properties viz.,\nstructural response, frequencies, mode shapes, etc of the structure. The\nresponses measured using sensors, which are high dimensional in nature, can be\nintelligently analyzed using machine learning techniques for damage assessment.\nNeural networks employing multilayer architectures are expressive models\ncapable of capturing complex relationships between input-output pairs but do\nnot account for uncertainty in network outputs. A BNN (Bayesian Neural Network)\nrefers to extending standard networks with posterior inference. It is a neural\nnetwork with a prior distribution on its weights. Deep learning architectures\nlike CNN (Convolutional neural network) and LSTM(Long Short Term Memory) are\ngood candidates for representation learning from high dimensional data. The\nadvantage of using CNN over multi-layer neural networks is that they are good\nfeature extractors as well as classifiers, which eliminates the need for\ngenerating hand-engineered features. LSTM networks are mainly used for sequence\nmodeling. This paper presents both a Bayesian multi-layer perceptron and deep\nlearning-based approach for damage detection and location identification in\nbeam-like structures. Raw frequency response data simulated using finite\nelement analysis is fed as the input of the network. As part of this, frequency\nresponse was generated for a series of simulations in the cantilever beam\ninvolving different damage scenarios. This case study shows the effectiveness\nof the above approaches to predict bending rigidity with an acceptable error\nrate.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 17:47:24 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Vashisht", "Rahul", ""], ["Viji", "H.", ""], ["Sundararajan", "T.", ""], ["Mohankumar", "D.", ""], ["Sumitra", "S.", ""]]}, {"id": "1908.06347", "submitter": "Trong Nguyen Nguyen", "authors": "Trong Nguyen Nguyen, Jean Meunier", "title": "Hybrid Deep Network for Anomaly Detection", "comments": "Paper accepted for BMVC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a deep convolutional neural network (CNN) for\nanomaly detection in surveillance videos. The model is adapted from a typical\nauto-encoder working on video patches under the perspective of sparse\ncombination learning. Our CNN focuses on (unsupervisedly) learning common\ncharacteristics of normal events with the emphasis of their spatial locations\n(by supervised losses). To our knowledge, this is the first work that directly\nadapts the patch position as the target of a classification sub-network. The\nmodel is capable to provide a score of anomaly assessment for each video frame.\nOur experiments were performed on 4 benchmark datasets with various anomalous\nevents and the obtained results were competitive with state-of-the-art studies.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 23:08:30 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Nguyen", "Trong Nguyen", ""], ["Meunier", "Jean", ""]]}, {"id": "1908.06351", "submitter": "Trong Nguyen Nguyen", "authors": "Trong Nguyen Nguyen, Jean Meunier", "title": "Anomaly Detection in Video Sequence with Appearance-Motion\n  Correspondence", "comments": "Paper accepted for ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection in surveillance videos is currently a challenge because of\nthe diversity of possible events. We propose a deep convolutional neural\nnetwork (CNN) that addresses this problem by learning a correspondence between\ncommon object appearances (e.g. pedestrian, background, tree, etc.) and their\nassociated motions. Our model is designed as a combination of a reconstruction\nnetwork and an image translation model that share the same encoder. The former\nsub-network determines the most significant structures that appear in video\nframes and the latter one attempts to associate motion templates to such\nstructures. The training stage is performed using only videos of normal events\nand the model is then capable to estimate frame-level scores for an unknown\ninput. The experiments on 6 benchmark datasets demonstrate the competitive\nperformance of the proposed approach with respect to state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 23:52:22 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Nguyen", "Trong Nguyen", ""], ["Meunier", "Jean", ""]]}, {"id": "1908.06376", "submitter": "Denys Matthies", "authors": "Shamane Siriwardhana, Rivindu Weerasakera, Denys J.C. Matthies,\n  Suranga Nanayakkara", "title": "VUSFA:Variational Universal Successor Features Approximator to Improve\n  Transfer DRL for Target Driven Visual Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how novel transfer reinforcement learning techniques\ncan be applied to the complex task of target driven navigation using the\nphotorealistic AI2THOR simulator. Specifically, we build on the concept of\nUniversal Successor Features with an A3C agent. We introduce the novel\narchitectural contribution of a Successor Feature Dependant Policy (SFDP) and\nadopt the concept of Variational Information Bottlenecks to achieve state of\nthe art performance. VUSFA, our final architecture, is a straightforward\napproach that can be implemented using our open source repository. Our approach\nis generalizable, showed greater stability in training, and outperformed recent\napproaches in terms of transfer learning ability.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 04:24:08 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Siriwardhana", "Shamane", ""], ["Weerasakera", "Rivindu", ""], ["Matthies", "Denys J. C.", ""], ["Nanayakkara", "Suranga", ""]]}, {"id": "1908.06378", "submitter": "Wenrui Zhang", "authors": "Wenrui Zhang, Peng Li", "title": "Spike-Train Level Backpropagation for Training Deep Recurrent Spiking\n  Neural Networks", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": "In Advances in Neural Information Processing Systems, pp. 7800-7811.\n  2019", "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) well support spatiotemporal learning and\nenergy-efficient event-driven hardware neuromorphic processors. As an important\nclass of SNNs, recurrent spiking neural networks (RSNNs) possess great\ncomputational power. However, the practical application of RSNNs is severely\nlimited by challenges in training. Biologically-inspired unsupervised learning\nhas limited capability in boosting the performance of RSNNs. On the other hand,\nexisting backpropagation (BP) methods suffer from high complexity of unrolling\nin time, vanishing and exploding gradients, and approximate differentiation of\ndiscontinuous spiking activities when applied to RSNNs. To enable supervised\ntraining of RSNNs under a well-defined loss function, we present a novel\nSpike-Train level RSNNs Backpropagation (ST-RSBP) algorithm for training deep\nRSNNs. The proposed ST-RSBP directly computes the gradient of a rated-coded\nloss function defined at the output layer of the network w.r.t tunable\nparameters. The scalability of ST-RSBP is achieved by the proposed spike-train\nlevel computation during which temporal effects of the SNN is captured in both\nthe forward and backward pass of BP. Our ST-RSBP algorithm can be broadly\napplied to RSNNs with a single recurrent layer or deep RSNNs with multiple\nfeed-forward and recurrent layers. Based upon challenging speech and image\ndatasets including TI46, N-TIDIGITS, Fashion-MNIST and MNIST, ST-RSBP is able\nto train RSNNs with an accuracy surpassing that of the current state-of-art SNN\nBP algorithms and conventional non-spiking deep learning models.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 04:57:46 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 08:51:34 GMT"}, {"version": "v3", "created": "Sun, 3 Nov 2019 04:35:49 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Zhang", "Wenrui", ""], ["Li", "Peng", ""]]}, {"id": "1908.06527", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr", "title": "The Runtime of the Compact Genetic Algorithm on Jump Functions", "comments": "Revised version of the journal version of my GECCO 2019\n  (arXiv:1903.10983) and FOGA 2019 (arXiv:1904.08415) papers", "journal-ref": null, "doi": "10.1007/s00453-020-00780-w", "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the first and so far only mathematical runtime analysis of an\nestimation-of-distribution algorithm (EDA) on a multimodal problem, Hasen\\\"ohrl\nand Sutton (GECCO 2018) showed for any $k = o(n)$ that the compact genetic\nalgorithm (cGA) with any hypothetical population size $\\mu = \\Omega(ne^{4k} +\nn^{3.5+\\varepsilon})$ with high probability finds the optimum of the\n$n$-dimensional jump function with jump size $k$ in time $O(\\mu n^{1.5} \\log\nn)$.\n  We significantly improve this result for small jump sizes $k \\le \\frac 1 {20}\n\\ln n -1$. In this case, already for $\\mu = \\Omega(\\sqrt n \\log n) \\cap\n\\text{poly}(n)$ the runtime of the cGA with high probability is only $O(\\mu\n\\sqrt n)$. For the smallest admissible values of $\\mu$, our result gives a\nruntime of $O(n \\log n)$, whereas the previous one only shows\n$O(n^{5+\\varepsilon})$. Since it is known that the cGA with high probability\nneeds at least $\\Omega(\\mu \\sqrt n)$ iterations to optimize the unimodal OneMx\nfunction, our result shows that the cGA in contrast to most classic\nevolutionary algorithms here is able to cross moderate-sized valleys of low\nfitness at no extra cost.\n  For large $k$, we show that the exponential (in $k$) runtime guarantee of\nHasen\\\"ohrl and Sutton is tight and cannot be improved, also not by using a\nsmaller hypothetical population size. We prove that any choice of the\nhypothetical population size leads to a runtime that, with high probability, is\nat least exponential in the jump size $k$. This result might be the first\nnon-trivial exponential lower bound for EDAs that holds for arbitrary parameter\nsettings.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 22:45:18 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 13:36:56 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Doerr", "Benjamin", ""]]}, {"id": "1908.06724", "submitter": "Shreyas Kolala Venkataramanaiah", "authors": "Shreyas Kolala Venkataramanaiah, Yufei Ma, Shihui Yin, Eriko\n  Nurvithadhi, Aravind Dasu, Yu Cao, Jae-sun Seo", "title": "Automatic Compiler Based FPGA Accelerator for CNN Training", "comments": "6 pages, 9 figures, paper accepted at FPL2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training of convolutional neural networks (CNNs)on embedded platforms to\nsupport on-device learning is earning vital importance in recent days.\nDesigning flexible training hard-ware is much more challenging than inference\nhardware, due to design complexity and large computation/memory requirement. In\nthis work, we present an automatic compiler-based FPGA accelerator with 16-bit\nfixed-point precision for complete CNNtraining, including Forward Pass (FP),\nBackward Pass (BP) and Weight Update (WU). We implemented an optimized RTL\nlibrary to perform training-specific tasks and developed an RTL compiler to\nautomatically generate FPGA-synthesizable RTL based on user-defined\nconstraints. We present a new cyclic weight storage/access scheme for on-chip\nBRAM and off-chip DRAMto efficiently implement non-transpose and transpose\noperations during FP and BP phases, respectively. Representative CNNs for\nCIFAR-10 dataset are implemented and trained on Intel Stratix 10-GX FPGA using\nproposed hardware architecture, demonstrating up to 479 GOPS performance.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 18:49:38 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Venkataramanaiah", "Shreyas Kolala", ""], ["Ma", "Yufei", ""], ["Yin", "Shihui", ""], ["Nurvithadhi", "Eriko", ""], ["Dasu", "Aravind", ""], ["Cao", "Yu", ""], ["Seo", "Jae-sun", ""]]}, {"id": "1908.06836", "submitter": "Weiheng Jiang", "authors": "Weiheng Jiang, Xiaogang Wu, Yi Gong, Wanxin Yu, Xinhui Zhong", "title": "Monthly electricity consumption forecasting by the fruit fly\n  optimization algorithm enhanced Holt-Winters smoothing method", "comments": "9 pages, 12 figures, submitted for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NE cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The electricity consumption forecasting is a critical component of the\nintelligent power system. And accurate monthly electricity consumption\nforecasting, as one of the the medium and long term electricity consumption\nforecasting problems, plays an important role in dispatching and management for\nelectric power systems. Although there are many studies for this problem, large\nsample data set is generally required to obtain higher prediction accuracy, and\nthe prediction performance become worse when only a little data is available.\nHowever, in practical, mostly we experience the problem of insufficient sample\ndata and how to accurately forecast the monthly electricity consumption with\nlimited sample data is a challenge task. The Holt-Winters exponential smoothing\nmethod often used to forecast periodic series due to low demand for training\ndata and high accuracy for forecasting. In this paper, based on Holt-Winters\nexponential smoothing method, we propose a hybrid forecasting model named\nFOA-MHW. The main idea is that, we use fruit fly optimization algorithm to\nselect smoothing parameters for Holt-Winters exponential smoothing method.\nBesides, electricity consumption data of a city in China is used to\ncomprehensively evaluate the forecasting performance of the proposed model. The\nresults indicate that our model can significantly improve the accuracy of\nmonthly electricity consumption forecasting even in the case that only a small\nnumber of training data is available.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 00:53:25 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Jiang", "Weiheng", ""], ["Wu", "Xiaogang", ""], ["Gong", "Yi", ""], ["Yu", "Wanxin", ""], ["Zhong", "Xinhui", ""]]}, {"id": "1908.06886", "submitter": "Anton Muravev", "authors": "Anton Muravev, Jenni Raitoharju and Moncef Gabbouj", "title": "Neural Architecture Search by Estimation of Network Structure\n  Distributions", "comments": "16 pages, 4 figures, 3 tables", "journal-ref": "in IEEE Access, vol. 9, pp. 15304-15319, 2021", "doi": "10.1109/ACCESS.2021.3052996", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The influence of deep learning is continuously expanding across different\ndomains, and its new applications are ubiquitous. The question of neural\nnetwork design thus increases in importance, as traditional empirical\napproaches are reaching their limits. Manual design of network architectures\nfrom scratch relies heavily on trial and error, while using existing pretrained\nmodels can introduce redundancies or vulnerabilities. Automated neural\narchitecture design is able to overcome these problems, but the most successful\nalgorithms operate on significantly constrained design spaces, assuming the\ntarget network to consist of identical repeating blocks. While such approach\nallows for faster search, it does so at the cost of expressivity. We instead\npropose an alternative probabilistic representation of a whole neural network\nstructure under the assumption of independence between layer types. Our matrix\nof probabilities is equivalent to the population of models, but allows for\ndiscovery of structural irregularities, while being simple to interpret and\nanalyze. We construct an architecture search algorithm, inspired by the\nestimation of distribution algorithms, to take advantage of this\nrepresentation. The probability matrix is tuned towards generating\nhigh-performance models by repeatedly sampling the architectures and evaluating\nthe corresponding networks, while gradually increasing the model depth. Our\nalgorithm is shown to discover non-regular models which cannot be expressed via\nblocks, but are competitive both in accuracy and computational cost, while not\nutilizing complex dataflows or advanced training techniques, as well as\nremaining conceptually simple and highly extensible.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 15:43:22 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 14:26:33 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 16:01:20 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Muravev", "Anton", ""], ["Raitoharju", "Jenni", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1908.07034", "submitter": "Peter Turney", "authors": "Peter D. Turney", "title": "Symbiosis Promotes Fitness Improvements in the Game of Life", "comments": "Changes to Sections 1, 3, 4, 5, and 6. Figures and tables appear at\n  the end of the document", "journal-ref": "Artificial Life, 26(3): 338-365 (2020)", "doi": "10.1162/artl_a_00326", "report-no": null, "categories": "cs.NE q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computational simulation of evolving entities that includes\nsymbiosis with shifting levels of selection. Evolution by natural selection\nshifts from the level of the original entities to the level of the new\nsymbiotic entity. In the simulation, the fitness of an entity is measured by a\nseries of one-on-one competitions in the Immigration Game, a two-player\nvariation of Conway's Game of Life. Mutation, reproduction, and symbiosis are\nimplemented as operations that are external to the Immigration Game. Because\nthese operations are external to the game, we are able to freely manipulate the\noperations and observe the effects of the manipulations. The simulation is\ncomposed of four layers, each layer building on the previous layer. The first\nlayer implements a simple form of asexual reproduction, the second layer\nintroduces a more sophisticated form of asexual reproduction, the third layer\nadds sexual reproduction, and the fourth layer adds symbiosis. The experiments\nshow that a small amount of symbiosis, added to the other layers, significantly\nincreases the fitness of the population. We suggest that the model may provide\nnew insights into symbiosis in biological and cultural evolution.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 19:18:47 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 20:28:18 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 19:06:54 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Turney", "Peter D.", ""]]}, {"id": "1908.07060", "submitter": "Thanh Pham Dinh", "authors": "Huynh Thi Thanh Binh and Pham Dinh Thanh and Ta Bao Thang", "title": "New Approach for Solving The Clustered Shortest-Path Tree Problem Based\n  on Reducing The Search Space of Evolutionary Algorithm", "comments": "27 pages, 7 figures", "journal-ref": null, "doi": "10.1016/j.knosys.2019.05.015", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with the development of manufacture and services, the problem of\ndistribution network optimization has been growing in importance, thus\nreceiving much attention from the research community. One of the most recently\nintroduced network optimization problems is the Clustered Shortest-Path Tree\nProblem (CluSTP). Since the problem is NP-Hard, recent approaches often prefer\nto use approximation algorithms to solve it, several of which used Evolutionary\nAlgorithms (EAs) and have been proven to be effective. However, most of the\nprior studies directly applied EAs to the whole CluSTP problem, which leads to\na great amount of resource consumption, especially when the problem size is\nlarge. To overcome these limitations, this paper suggests a method for reducing\nthe search space of the EAs applied to CluSTP by decomposing the original\nproblem into two sub-problems, the solution to one of which is found by an EAs\nand that to the other is found by another method. The goal of the first\nsub-problem is to determine a spanning tree which connects among the clusters,\nwhile the goal of the second sub-problem is to determine the best spanning tree\nfor each cluster. In addition, this paper proposes a new EAs, which can be\napplied to solve the first sub-problem and suggests using the Dijkstra's\nalgorithm to solve the second sub-problem. The proposed approach is\ncomprehensively experimented and compared with existing methods. Experimental\nresults prove that our method is more efficient and more importantly, it can\nobtain results which are close to the optimal results.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 03:56:17 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Binh", "Huynh Thi Thanh", ""], ["Thanh", "Pham Dinh", ""], ["Thang", "Ta Bao", ""]]}, {"id": "1908.07062", "submitter": "Nesma M. Rezk", "authors": "Nesma M. Rezk, Madhura Purnaprajna, Tomas Nordstr\\\"om, Zain Ul-Abdin", "title": "Recurrent Neural Networks: An Embedded Computing Perspective", "comments": "Accepted for publication in IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2020.2982416", "report-no": null, "categories": "cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are a class of machine learning algorithms\nused for applications with time-series and sequential data. Recently, there has\nbeen a strong interest in executing RNNs on embedded devices. However,\ndifficulties have arisen because RNN requires high computational capability and\na large memory space. In this paper, we review existing implementations of RNN\nmodels on embedded platforms and discuss the methods adopted to overcome the\nlimitations of embedded systems.\n  We will define the objectives of mapping RNN algorithms on embedded platforms\nand the challenges facing their realization. Then, we explain the components of\nRNN models from an implementation perspective. We also discuss the\noptimizations applied to RNNs to run efficiently on embedded platforms.\nFinally, we compare the defined objectives with the implementations and\nhighlight some open research questions and aspects currently not addressed for\nembedded RNNs.\n  Overall, applying algorithmic optimizations to RNN models and decreasing the\nmemory access overhead is vital to obtain high efficiency. To further increase\nthe implementation efficiency, we point up the more promising optimizations\nthat could be applied in future research. Additionally, this article observes\nthat high performance has been targeted by many implementations, while\nflexibility has, as yet, been attempted less often. Thus, the article provides\nsome guidelines for RNN hardware designers to support flexibility in a better\nmanner.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 11:28:57 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 11:53:51 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 18:26:17 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Rezk", "Nesma M.", ""], ["Purnaprajna", "Madhura", ""], ["Nordstr\u00f6m", "Tomas", ""], ["Ul-Abdin", "Zain", ""]]}, {"id": "1908.07063", "submitter": "Xuanlin Liu", "authors": "Xuanlin Liu, Mingzhe Chen, Changchuan Yin, Walid Saad", "title": "Analysis of Memory Capacity for Deep Echo State Networks", "comments": "6 pages, 8 figures, Published in 2018 17th IEEE International\n  Conference on Machine Learning and Applications (ICMLA)", "journal-ref": null, "doi": "10.1109/ICMLA.2018.00072", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the echo state network (ESN) memory capacity, which represents\nthe amount of input data an ESN can store, is analyzed for a new type of deep\nESNs. In particular, two deep ESN architectures are studied. First, a parallel\ndeep ESN is proposed in which multiple reservoirs are connected in parallel\nallowing them to average outputs of multiple ESNs, thus decreasing the\nprediction error. Then, a series architecture ESN is proposed in which ESN\nreservoirs are placed in cascade that the output of each ESN is the input of\nthe next ESN in the series. This series ESN architecture can capture more\nfeatures between the input sequence and the output sequence thus improving the\noverall prediction accuracy. Fundamental analysis shows that the memory\ncapacity of parallel ESNs is equivalent to that of a traditional shallow ESN,\nwhile the memory capacity of series ESNs is smaller than that of a traditional\nshallow ESN.In terms of normalized root mean square error, simulation results\nshow that the parallel deep ESN achieves 38.5% reduction compared to the\ntraditional shallow ESN while the series deep ESN achieves 16.8% reduction.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 09:16:54 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Liu", "Xuanlin", ""], ["Chen", "Mingzhe", ""], ["Yin", "Changchuan", ""], ["Saad", "Walid", ""]]}, {"id": "1908.07124", "submitter": "Akinari Onishi", "authors": "Akinari Onishi", "title": "Landmark Map: An Extension of the Self-Organizing Map for a\n  User-Intended Nonlinear Projection", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2019.12.125", "report-no": null, "categories": "cs.NE cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The self-organizing map (SOM) is an unsupervised artificial neural network\nthat is widely used in, e.g., data mining and visualization. Supervised and\nsemi-supervised learning methods have been proposed for the SOM. However, their\nteacher labels do not describe the relationship between the data and the\nlocation of nodes. This study proposes a landmark map (LAMA), which is an\nextension of the SOM that utilizes several landmarks, e.g., pairs of nodes and\ndata points. LAMA is designed to obtain a user-intended nonlinear projection to\nachieve, e.g., the landmark-oriented data visualization. To reveal the learning\nproperties of LAMA, the Zoo dataset from the UCI Machine Learning Repository\nand an artificial formant dataset were analyzed. The analysis results of the\nZoo dataset indicated that LAMA could provide a new data view such as the\nlandmark-centered data visualization. Furthermore, the artificial formant data\nanalysis revealed that LAMA successfully provided the intended nonlinear\nprojection associating articular movement with vertical and horizontal movement\nof a computer cursor. Potential applications of LAMA include data mining,\nrecommendation systems, and human-computer interaction.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 01:51:14 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Onishi", "Akinari", ""]]}, {"id": "1908.07656", "submitter": "Alexander Glandon", "authors": "Mahbubul Alam, Manar D. Samad, Lasitha Vidyaratne, Alexander Glandon,\n  and Khan M. Iftekharuddin", "title": "Survey on Deep Neural Networks in Speech and Vision Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE cs.SD eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey presents a review of state-of-the-art deep neural network\narchitectures, algorithms, and systems in vision and speech applications.\nRecent advances in deep artificial neural network algorithms and architectures\nhave spurred rapid innovation and development of intelligent vision and speech\nsystems. With availability of vast amounts of sensor data and cloud computing\nfor processing and training of deep neural networks, and with increased\nsophistication in mobile and embedded technology, the next-generation\nintelligent systems are poised to revolutionize personal and commercial\ncomputing. This survey begins by providing background and evolution of some of\nthe most successful deep learning models for intelligent vision and speech\nsystems to date. An overview of large-scale industrial research and development\nefforts is provided to emphasize future trends and prospects of intelligent\nvision and speech systems. Robust and efficient intelligent systems demand\nlow-latency and high fidelity in resource-constrained hardware platforms such\nas mobile devices, robots, and automobiles. Therefore, this survey also\nprovides a summary of key challenges and recent successes in running deep\nneural networks on hardware-restricted platforms, i.e. within limited memory,\nbattery life, and processing capabilities. Finally, emerging applications of\nvision and speech across disciplines such as affective computing, intelligent\ntransportation, and precision medicine are discussed. To our knowledge, this\npaper provides one of the most comprehensive surveys on the latest developments\nin intelligent vision and speech applications from the perspectives of both\nsoftware and hardware systems. Many of these emerging technologies using deep\nneural networks show tremendous promise to revolutionize research and\ndevelopment for future vision and speech systems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 16:40:49 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 03:30:37 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Alam", "Mahbubul", ""], ["Samad", "Manar D.", ""], ["Vidyaratne", "Lasitha", ""], ["Glandon", "Alexander", ""], ["Iftekharuddin", "Khan M.", ""]]}, {"id": "1908.07896", "submitter": "Mohammad Reza Keshtkaran", "authors": "Mohammad Reza Keshtkaran and Chethan Pandarinath", "title": "Enabling hyperparameter optimization in sequential autoencoders for\n  spiking neural data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuing advances in neural interfaces have enabled simultaneous monitoring\nof spiking activity from hundreds to thousands of neurons. To interpret these\nlarge-scale data, several methods have been proposed to infer latent dynamic\nstructure from high-dimensional datasets. One recent line of work uses\nrecurrent neural networks in a sequential autoencoder (SAE) framework to\nuncover dynamics. SAEs are an appealing option for modeling nonlinear dynamical\nsystems, and enable a precise link between neural activity and behavior on a\nsingle-trial basis. However, the very large parameter count and complexity of\nSAEs relative to other models has caused concern that SAEs may only perform\nwell on very large training sets. We hypothesized that with a method to\nsystematically optimize hyperparameters (HPs), SAEs might perform well even in\ncases of limited training data. Such a breakthrough would greatly extend their\napplicability. However, we find that SAEs applied to spiking neural data are\nprone to a particular form of overfitting that cannot be detected using\nstandard validation metrics, which prevents standard HP searches. We develop\nand test two potential solutions: an alternate validation method (\"sample\nvalidation\") and a novel regularization method (\"coordinated dropout\"). These\ninnovations prevent overfitting quite effectively, and allow us to test whether\nSAEs can achieve good performance on limited data through large-scale HP\noptimization. When applied to data from motor cortex recorded while monkeys\nmade reaches in various directions, large-scale HP optimization allowed SAEs to\nbetter maintain performance for small dataset sizes. Our results should greatly\nextend the applicability of SAEs in extracting latent dynamics from sparse,\nmultidimensional data, such as neural population spiking activity.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 14:40:14 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 15:21:31 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Keshtkaran", "Mohammad Reza", ""], ["Pandarinath", "Chethan", ""]]}, {"id": "1908.07899", "submitter": "Tobias Hinz", "authors": "Marcus Soll, Tobias Hinz, Sven Magg, Stefan Wermter", "title": "Evaluating Defensive Distillation For Defending Text Processing Neural\n  Networks Against Adversarial Examples", "comments": "Published at the International Conference on Artificial Neural\n  Networks (ICANN) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are artificially modified input samples which lead to\nmisclassifications, while not being detectable by humans. These adversarial\nexamples are a challenge for many tasks such as image and text classification,\nespecially as research shows that many adversarial examples are transferable\nbetween different classifiers. In this work, we evaluate the performance of a\npopular defensive strategy for adversarial examples called defensive\ndistillation, which can be successful in hardening neural networks against\nadversarial examples in the image domain. However, instead of applying\ndefensive distillation to networks for image classification, we examine, for\nthe first time, its performance on text classification tasks and also evaluate\nits effect on the transferability of adversarial text examples. Our results\nindicate that defensive distillation only has a minimal impact on text\nclassifying neural networks and does neither help with increasing their\nrobustness against adversarial examples nor prevent the transferability of\nadversarial examples between neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 14:50:13 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Soll", "Marcus", ""], ["Hinz", "Tobias", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "1908.07942", "submitter": "Insik Yoon", "authors": "Insik Yoon, Matthew Jerry, Suman Datta, Arijit Raychowdhury", "title": "Design space exploration of Ferroelectric FET based Processing-in-Memory\n  DNN Accelerator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we quantify the impact of device limitations on the\nclassification accuracy of an artificial neural network, where the synaptic\nweights are implemented in a Ferroelectric FET (FeFET) based in-memory\nprocessing architecture. We explore a design-space consisting of the resolution\nof the analog-to-digital converter, number of bits per FeFET cell, and the\nneural network depth. We show how the system architecture, training models and\noverparametrization can address some of the device limitations.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 18:26:06 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Yoon", "Insik", ""], ["Jerry", "Matthew", ""], ["Datta", "Suman", ""], ["Raychowdhury", "Arijit", ""]]}, {"id": "1908.08005", "submitter": "No\\\"elie Cherrier", "authors": "No\\\"elie Cherrier, Jean-Philippe Poli, Maxime Defurne and Franck\n  Sabati\\'e", "title": "Consistent Feature Construction with Constrained Genetic Programming for\n  Experimental Physics", "comments": "Accepted in this version to CEC 2019", "journal-ref": "Proceedings of 2019 IEEE Congress on Evolutionary Computation\n  (CEC), Wellington, New Zealand, 2019, pp. 1650-1658", "doi": "10.1109/CEC.2019.8789937", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A good feature representation is a determinant factor to achieve high\nperformance for many machine learning algorithms in terms of classification.\nThis is especially true for techniques that do not build complex internal\nrepresentations of data (e.g. decision trees, in contrast to deep neural\nnetworks). To transform the feature space, feature construction techniques\nbuild new high-level features from the original ones. Among these techniques,\nGenetic Programming is a good candidate to provide interpretable features\nrequired for data analysis in high energy physics. Classically, original\nfeatures or higher-level features based on physics first principles are used as\ninputs for training. However, physicists would benefit from an automatic and\ninterpretable feature construction for the classification of particle collision\nevents.\n  Our main contribution consists in combining different aspects of Genetic\nProgramming and applying them to feature construction for experimental physics.\nIn particular, to be applicable to physics, dimensional consistency is enforced\nusing grammars.\n  Results of experiments on three physics datasets show that the constructed\nfeatures can bring a significant gain to the classification accuracy. To the\nbest of our knowledge, it is the first time a method is proposed for\ninterpretable feature construction with units of measurement, and that experts\nin high-energy physics validate the overall approach as well as the\ninterpretability of the built features.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 10:55:15 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Cherrier", "No\u00eblie", ""], ["Poli", "Jean-Philippe", ""], ["Defurne", "Maxime", ""], ["Sabati\u00e9", "Franck", ""]]}, {"id": "1908.08006", "submitter": "Farid Ghareh Mohammadi", "authors": "Farid Ghareh Mohammadi, M. Hadi Amini, and Hamid R. Arabnia", "title": "Evolutionary Computation, Optimization and Learning Algorithms for Data\n  Science", "comments": "40 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A large number of engineering, science and computational problems have yet to\nbe solved in a computationally efficient way. One of the emerging challenges is\nhow evolving technologies grow towards autonomy and intelligent decision\nmaking. This leads to collection of large amounts of data from various sensing\nand measurement technologies, e.g., cameras, smart phones, health sensors,\nsmart electricity meters, and environment sensors. Hence, it is imperative to\ndevelop efficient algorithms for generation, analysis, classification, and\nillustration of data. Meanwhile, data is structured purposefully through\ndifferent representations, such as large-scale networks and graphs. We focus on\ndata science as a crucial area, specifically focusing on a curse of\ndimensionality (CoD) which is due to the large amount of\ngenerated/sensed/collected data. This motivates researchers to think about\noptimization and to apply nature-inspired algorithms, such as evolutionary\nalgorithms (EAs) to solve optimization problems. Although these algorithms look\nun-deterministic, they are robust enough to reach an optimal solution.\nResearchers do not adopt evolutionary algorithms unless they face a problem\nwhich is suffering from placement in local optimal solution, rather than global\noptimal solution. In this chapter, we first develop a clear and formal\ndefinition of the CoD problem, next we focus on feature extraction techniques\nand categories, then we provide a general overview of meta-heuristic\nalgorithms, its terminology, and desirable properties of evolutionary\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 17:16:16 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Mohammadi", "Farid Ghareh", ""], ["Amini", "M. Hadi", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "1908.08007", "submitter": "Aleem Akhtar Asif", "authors": "Aleem Akhtar", "title": "Evolution of Ant Colony Optimization Algorithm -- A Brief Literature\n  Review", "comments": "11 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ant Colony Optimization (ACO) is a metaheuristic proposed by Marco Dorigo in\n1991 based on behavior of biological ants. Pheromone laying and selection of\nshortest route with the help of pheromone inspired development of first ACO\nalgorithm. Since, presentation of first such algorithm, many researchers have\nworked and published their research in this field. Though initial results were\nnot so promising but recent developments have made this metaheuristic a\nsignificant algorithm in Swarm Intelligence. This research presents a brief\noverview of recent developments carried out in ACO algorithms in terms of both\napplications and algorithmic developments. For application developments,\nmulti-objective optimization, continuous optimization and time-varying NP-hard\nproblems have been presented. While to review articles based on algorithmic\ndevelopment, hybridization and parallel architectures have been investigated.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 07:42:49 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 14:54:21 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Akhtar", "Aleem", ""]]}, {"id": "1908.08010", "submitter": "Samaneh Azari", "authors": "Samaneh Azari, Bing Xue, Mengjie Zhang, Lifeng Peng", "title": "Improving the Results of De novo Peptide Identification via Tandem Mass\n  Spectrometry Using a Genetic Programming-based Scoring Function for\n  Re-ranking Peptide-Spectrum Matches", "comments": "13 pages, conference paper, containing 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  De novo peptide sequencing algorithms have been widely used in proteomics to\nanalyse tandem mass spectra (MS/MS) and assign them to peptides, but\nquality-control methods to evaluate the confidence of de novo peptide\nsequencing are lagging behind. A fundamental part of a quality-control method\nis the scoring function used to evaluate the quality of peptide-spectrum\nmatches (PSMs). Here, we propose a genetic programming (GP) based method,\ncalled GP-PSM, to learn a PSM scoring function for improving the rate of\nconfident peptide identification from MS/MS data. The GP method learns from\nthousands of MS/MS spectra. Important characteristics about goodness of the\nmatches are extracted from the learning set and incorporated into the GP\nscoring functions. We compare GP-PSM with two methods including Support Vector\nRegression (SVR) and Random Forest (RF). The GP method along with RF and SVR,\neach is used for post-processing the results of peptide identification by\nPEAKS, a commonly used de novo sequencing method. The results show that GP-PSM\noutperforms RF and SVR and discriminates accurately between correct and\nincorrect PSMs. It correctly assigns peptides to 10% more spectra on an\nevaluation dataset containing 120 MS/MS spectra and decreases the false\npositive rate (FPR) of peptide identification.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 00:46:36 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Azari", "Samaneh", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""], ["Peng", "Lifeng", ""]]}, {"id": "1908.08011", "submitter": "Tae Jong Choi", "authors": "Tae Jong Choi, Julian Togelius, Yun-Gyung Cheong", "title": "A Fast and Efficient Stochastic Opposition-Based Learning for\n  Differential Evolution in Numerical Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fast and efficient stochastic opposition-based learning (OBL) variant is\nproposed in this paper. OBL is a machine learning concept to accelerate the\nconvergence of soft computing algorithms, which consists of simultaneously\ncalculating an original solution and its opposite. Recently, a stochastic OBL\nvariant called BetaCOBL was proposed, which is capable of controlling the\ndegree of opposite solutions, preserving useful information held by original\nsolutions, and preventing the waste of fitness evaluations. While it has shown\noutstanding performance compared to several state-of-the-art OBL variants, the\nhigh computational cost of BetaCOBL may hinder it from cost-sensitive\noptimization problems. Also, as it assumes that the decision variables of a\ngiven problem are independent, BetaCOBL may be ineffective for optimizing\ninseparable problems. In this paper, we propose an improved BetaCOBL that\nmitigates all the limitations. The proposed algorithm called iBetaCOBL reduces\nthe computational cost from $O(NP^{2} \\cdot D)$ to $O(NP \\cdot D)$ ($NP$ and\n$D$ stand for population size and a dimension, respectively) using a linear\ntime diversity measure. Also, the proposed algorithm preserves strongly\ndependent variables that are adjacent to each other using multiple exponential\ncrossover. We used differential evolution (DE) variants to evaluate the\nperformance of the proposed algorithm. The results of the performance\nevaluations on a set of 58 test functions show the excellent performance of\niBetaCOBL compared to ten state-of-the-art OBL variants, including BetaCOBL.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 22:12:02 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 06:52:29 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Choi", "Tae Jong", ""], ["Togelius", "Julian", ""], ["Cheong", "Yun-Gyung", ""]]}, {"id": "1908.08012", "submitter": "Tian Zhang", "authors": "Tian Zhang, Jia Wang, Yihang Dan, Yuxiang Lanqiu, Jian Dai, Xu Han,\n  Xiaojuan Sun and Kun Xu", "title": "Efficient training and design of photonic neural network through\n  neuroevolution", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": "10.1364/OE.27.037150", "report-no": null, "categories": "cs.NE physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, optical neural networks (ONNs) integrated in photonic chips has\nreceived extensive attention because they are expected to implement the same\npattern recognition tasks in the electronic platforms with high efficiency and\nlow power consumption. However, the current lack of various learning algorithms\nto train the ONNs obstructs their further development. In this article, we\npropose a novel learning strategy based on neuroevolution to design and train\nthe ONNs. Two typical neuroevolution algorithms are used to determine the\nhyper-parameters of the ONNs and to optimize the weights (phase shifters) in\nthe connections. In order to demonstrate the effectiveness of the training\nalgorithms, the trained ONNs are applied in the classification tasks for iris\nplants dataset, wine recognition dataset and modulation formats recognition.\nThe calculated results exhibit that the training algorithms based on\nneuroevolution are competitive with other traditional learning algorithms on\nboth accuracy and stability. Compared with previous works, we introduce an\nefficient training method for the ONNs and demonstrate their broad application\nprospects in pattern recognition, reinforcement learning and so on.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 14:45:07 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Zhang", "Tian", ""], ["Wang", "Jia", ""], ["Dan", "Yihang", ""], ["Lanqiu", "Yuxiang", ""], ["Dai", "Jian", ""], ["Han", "Xu", ""], ["Sun", "Xiaojuan", ""], ["Xu", "Kun", ""]]}, {"id": "1908.08014", "submitter": "Amir Nakib", "authors": "Asmaa Ghoumari, Amir Nakib", "title": "Graph based adaptive evolutionary algorithm for continuous optimization", "comments": null, "journal-ref": "OLA conference 2018", "doi": null, "report-no": null, "categories": "cs.NE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  he greatest weakness of evolutionary algorithms, widely used today, is the\npremature convergence due to the loss of population diversity over generations.\nTo overcome this problem, several algorithms have been proposed, such as the\nGraph-based Evolutionary Algorithm (GEA) \\cite{1} which uses graphs to model\nthe structure of the population, but also memetic or differential evolution\nalgorithms \\cite{2,3}, or diversity-based ones \\cite{4,5} have been designed.\nThese algorithms are based on multi-populations, or often rather focus on the\nself-tuning parameters, however, they become complex to tune because of their\nhigh number of parameters. In this paper, our approach consists of an\nevolutionary algorithm that allows a dynamic adaptation of the search operators\nbased on a graph in order to limit the loss of diversity and reduce the design\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 15:50:05 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Ghoumari", "Asmaa", ""], ["Nakib", "Amir", ""]]}, {"id": "1908.08015", "submitter": "Jiyang Bai", "authors": "Jiyang Bai and Yuxiang Ren and Jiawei Zhang", "title": "BGADAM: Boosting based Genetic-Evolutionary ADAM for Neural Network\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For various optimization methods, gradient descent-based algorithms can\nachieve outstanding performance and have been widely used in various tasks.\nAmong those commonly used algorithms, ADAM owns many advantages such as fast\nconvergence with both the momentum term and the adaptive learning rate.\nHowever, since the loss functions of most deep neural networks are non-convex,\nADAM also shares the drawback of getting stuck in local optima easily. To\nresolve such a problem, the idea of combining genetic algorithm with base\nlearners is introduced to rediscover the best solutions. Nonetheless, from our\nanalysis, the idea of combining genetic algorithm with a batch of base learners\nstill has its shortcomings. The effectiveness of genetic algorithm can hardly\nbe guaranteed if the unit models converge to close or the same solutions. To\nresolve this problem and further maximize the advantages of genetic algorithm\nwith base learners, we propose to implement the boosting strategy for input\nmodel training, which can subsequently improve the effectiveness of genetic\nalgorithm. In this paper, we introduce a novel optimization algorithm, namely\nBoosting based Genetic ADAM (BGADAM). With both theoretic analysis and\nempirical experiments, we will show that adding the boosting strategy into the\nBGADAM model can help models jump out the local optima and converge to better\nsolutions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 02:44:33 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 16:09:00 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Bai", "Jiyang", ""], ["Ren", "Yuxiang", ""], ["Zhang", "Jiawei", ""]]}, {"id": "1908.08017", "submitter": "Alexander V Terekhov", "authors": "Alexander V. Terekhov and Guglielmo Montone and J. Kevin O'Regan", "title": "Knowledge transfer in deep block-modular neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep neural networks (DNNs) have demonstrated impressive results\nduring the last decade, they remain highly specialized tools, which are trained\n-- often from scratch -- to solve each particular task. The human brain, in\ncontrast, significantly re-uses existing capacities when learning to solve new\ntasks. In the current study we explore a block-modular architecture for DNNs,\nwhich allows parts of the existing network to be re-used to solve a new task\nwithout a decrease in performance when solving the original task. We show that\nnetworks with such architectures can outperform networks trained from scratch,\nor perform comparably, while having to learn nearly 10 times fewer weights than\nthe networks trained from scratch.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 18:02:53 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Terekhov", "Alexander V.", ""], ["Montone", "Guglielmo", ""], ["O'Regan", "J. Kevin", ""]]}, {"id": "1908.08018", "submitter": "Jesus L. Lobo", "authors": "Jesus L. Lobo, Izaskun Oregi, Albert Bifet, Javier Del Ser", "title": "Exploiting a Stimuli Encoding Scheme of Spiking Neural Networks for\n  Stream Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stream data processing has gained progressive momentum with the arriving of\nnew stream applications and big data scenarios. One of the most promising\ntechniques in stream learning is the Spiking Neural Network, and some of them\nuse an interesting population encoding scheme to transform the incoming stimuli\ninto spikes. This study sheds lights on the key issue of this encoding scheme,\nthe Gaussian receptive fields, and focuses on applying them as a pre-processing\ntechnique to any dataset in order to gain representativeness, and to boost the\npredictive performance of the stream learning methods. Experiments with\nsynthetic and real data sets are presented, and lead to confirm that our\napproach can be applied successfully as a general pre-processing technique in\nmany real cases.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 09:48:50 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Lobo", "Jesus L.", ""], ["Oregi", "Izaskun", ""], ["Bifet", "Albert", ""], ["Del Ser", "Javier", ""]]}, {"id": "1908.08019", "submitter": "Jesus L. Lobo", "authors": "Jesus L. Lobo, Javier Del Ser, Albert Bifet, Nikola Kasabov", "title": "Spiking Neural Networks and Online Learning: An Overview and\n  Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications that generate huge amounts of data in the form of fast streams\nare becoming increasingly prevalent, being therefore necessary to learn in an\nonline manner. These conditions usually impose memory and processing time\nrestrictions, and they often turn into evolving environments where a change may\naffect the input data distribution. Such a change causes that predictive models\ntrained over these stream data become obsolete and do not adapt suitably to new\ndistributions. Specially in these non-stationary scenarios, there is a pressing\nneed for new algorithms that adapt to these changes as fast as possible, while\nmaintaining good performance scores. Unfortunately, most off-the-shelf\nclassification models need to be retrained if they are used in changing\nenvironments, and fail to scale properly. Spiking Neural Networks have revealed\nthemselves as one of the most successful approaches to model the behavior and\nlearning potential of the brain, and exploit them to undertake practical online\nlearning tasks. Besides, some specific flavors of Spiking Neural Networks can\novercome the necessity of retraining after a drift occurs. This work intends to\nmerge both fields by serving as a comprehensive overview, motivating further\ndevelopments that embrace Spiking Neural Networks for online learning\nscenarios, and being a friendly entry point for non-experts.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 09:18:28 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Lobo", "Jesus L.", ""], ["Del Ser", "Javier", ""], ["Bifet", "Albert", ""], ["Kasabov", "Nikola", ""]]}, {"id": "1908.08020", "submitter": "Leo Cazenille Dr", "authors": "Leo Cazenille", "title": "Comparing reliability of grid-based Quality-Diversity algorithms using\n  artificial landscapes", "comments": "3 pages, 2 figures", "journal-ref": "Genetic and Evolutionary Computation Conference Companion (GECCO\n  '19 Companion), July 13--17, 2019, Prague, Czech Republic", "doi": "10.1145/3319619.3321895", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality-Diversity (QD) algorithms are a recent type of optimisation methods\nthat search for a collection of both diverse and high performing solutions.\nThey can be used to effectively explore a target problem according to features\ndefined by the user. However, the field of QD still does not possess extensive\nmethodologies and reference benchmarks to compare these algorithms. We propose\na simple benchmark to compare the reliability of QD algorithms by optimising\nthe Rastrigin function, an artificial landscape function often used to test\nglobal optimisation methods.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 03:08:08 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Cazenille", "Leo", ""]]}, {"id": "1908.08021", "submitter": "Xavier Porte", "authors": "Xavier Porte, Louis Andreoli, Maxime Jacquot, Laurent Larger, Daniel\n  Brunner", "title": "Reservoir-size dependent learning in analogue neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The implementation of artificial neural networks in hardware substrates is a\nmajor interdisciplinary enterprise. Well suited candidates for physical\nimplementations must combine nonlinear neurons with dedicated and efficient\nhardware solutions for both connectivity and training. Reservoir computing\naddresses the problems related with the network connectivity and training in an\nelegant and efficient way. However, important questions regarding impact of\nreservoir size and learning routines on the convergence-speed during learning\nremain unaddressed. Here, we study in detail the learning process of a recently\ndemonstrated photonic neural network based on a reservoir. We use a greedy\nalgorithm to train our neural network for the task of chaotic signals\nprediction and analyze the learning-error landscape. Our results unveil\nfundamental properties of the system's optimization hyperspace. Particularly,\nwe determine the convergence speed of learning as a function of reservoir size\nand find exceptional, close to linear scaling. This linear dependence, together\nwith our parallel diffractive coupling, represent optimal scaling conditions\nfor our photonic neural network scheme.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 14:56:03 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Porte", "Xavier", ""], ["Andreoli", "Louis", ""], ["Jacquot", "Maxime", ""], ["Larger", "Laurent", ""], ["Brunner", "Daniel", ""]]}, {"id": "1908.08022", "submitter": "Shalin Shah", "authors": "Shalin Shah", "title": "Genetic Algorithm for the 0/1 Multidimensional Knapsack Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 0/1 multidimensional knapsack problem is the 0/1 knapsack problem with m\nconstraints which makes it difficult to solve using traditional methods like\ndynamic programming or branch and bound algorithms. We present a genetic\nalgorithm for the multidimensional knapsack problem with Java and C++ code that\nis able to solve publicly available instances in a very short computational\nduration. Our algorithm uses iteratively computed Lagrangian multipliers as\nconstraint weights to augment the greedy algorithm for the multidimensional\nknapsack problem and uses that information in a greedy crossover in a genetic\nalgorithm. The algorithm uses several other hyperparameters which can be set in\nthe code to control convergence. Our algorithm improves upon the algorithm by\nChu and Beasley in that it converges to optimum or near optimum solutions much\nfaster.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 23:53:41 GMT"}, {"version": "v2", "created": "Sun, 26 Jan 2020 18:23:05 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Shah", "Shalin", ""]]}, {"id": "1908.08024", "submitter": "Anup Das", "authors": "Anup Das and Yuefeng Wu and Khanh Huynh and Francesco Dell'Anna and\n  Francky Catthoor and Siebren Schaafsma", "title": "Mapping of Local and Global Synapses on Spiking Neuromorphic Hardware", "comments": "17 pages, 7 figures, published in 2018 Design, Automation & Test in\n  Europe Conference & Exhibition (DATE)", "journal-ref": null, "doi": "10.23919/DATE.2018.8342201", "report-no": null, "categories": "q-bio.NC cs.ET cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spiking Neural Networks (SNNs) are widely deployed to solve complex pattern\nrecognition, function approximation and image classification tasks. With the\ngrowing size and complexity of these networks, hardware implementation becomes\nchallenging because scaling up the size of a single array (crossbar) of fully\nconnected neurons is no longer feasible due to strict energy budget. Modern\nneromorphic hardware integrates small-sized crossbars with time-multiplexed\ninterconnects. Partitioning SNNs becomes essential in order to map them on\nneuromorphic hardware with the major aim to reduce the global communication\nlatency and energy overhead. To achieve this goal, we propose our instantiation\nof particle swarm optimization, which partitions SNNs into local synapses\n(mapped on crossbars) and global synapses (mapped on time-multiplexed\ninterconnects), with the objective of reducing spike communication on the\ninterconnect. This improves latency, power consumption as well as application\nperformance by reducing inter-spike interval distortion and spike disorders.\nOur framework is implemented in Python, interfacing CARLsim, a GPU-accelerated\napplication-level spiking neural network simulator with an extended version of\nNoxim, for simulating time-multiplexed interconnects. Experiments are conducted\nwith realistic and synthetic SNN-based applications with different computation\nmodels, topologies and spike coding schemes. Using power numbers from in-house\nneuromorphic chips, we demonstrate significant reductions in energy consumption\nand spike latency over PACMAN, the widely-used partitioning technique for SNNs\non SpiNNaker.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 23:28:35 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Das", "Anup", ""], ["Wu", "Yuefeng", ""], ["Huynh", "Khanh", ""], ["Dell'Anna", "Francesco", ""], ["Catthoor", "Francky", ""], ["Schaafsma", "Siebren", ""]]}, {"id": "1908.08026", "submitter": "David Shriver", "authors": "David Shriver, Dong Xu, Sebastian Elbaum, Matthew B. Dwyer", "title": "Refactoring Neural Networks for Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) are growing in capability and applicability. Their\neffectiveness has led to their use in safety critical and autonomous systems,\nyet there is a dearth of cost-effective methods available for reasoning about\nthe behavior of a DNN. In this paper, we seek to expand the applicability and\nscalability of existing DNN verification techniques through DNN refactoring. A\nDNN refactoring defines (a) the transformation of the DNN's architecture, i.e.,\nthe number and size of its layers, and (b) the distillation of the learned\nrelationships between the input features and function outputs of the original\nto train the transformed network. Unlike with traditional code refactoring, DNN\nrefactoring does not guarantee functional equivalence of the two networks, but\nrather it aims to preserve the accuracy of the original network while producing\na simpler network that is amenable to more efficient property verification. We\npresent an automated framework for DNN refactoring, and demonstrate its\npotential effectiveness through three case studies on networks used in\nautonomous systems.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 21:51:05 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Shriver", "David", ""], ["Xu", "Dong", ""], ["Elbaum", "Sebastian", ""], ["Dwyer", "Matthew B.", ""]]}, {"id": "1908.08118", "submitter": "Yang Li", "authors": "Yang Li, Shihao Ji", "title": "Neural Plasticity Networks", "comments": "Published as a conference paper at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural plasticity is an important functionality of human brain, in which\nnumber of neurons and synapses can shrink or expand in response to stimuli\nthroughout the span of life. We model this dynamic learning process as an\n$L_0$-norm regularized binary optimization problem, in which each unit of a\nneural network (e.g., weight, neuron or channel, etc.) is attached with a\nstochastic binary gate, whose parameters determine the level of activity of a\nunit in the network. At the beginning, only a small portion of binary gates\n(therefore the corresponding neurons) are activated, while the remaining\nneurons are in a hibernation mode. As the learning proceeds, some neurons might\nbe activated or deactivated if doing so can be justified by the cost-benefit\ntradeoff measured by the $L_0$-norm regularized objective. As the training gets\nmature, the probability of transition between activation and deactivation will\ndiminish until a final hardening stage. We demonstrate that all of these\nlearning dynamics can be modulated by a single parameter $k$ seamlessly. Our\nneural plasticity network (NPN) can prune or expand a network depending on the\ninitial capacity of network provided by the user; it also unifies dropout (when\n$k=0$), traditional training of DNNs (when $k=\\infty$) and interpolates between\nthese two. To the best of our knowledge, this is the first learning framework\nthat unifies network sparsification and network expansion in an end-to-end\ntraining pipeline. Extensive experiments on synthetic dataset and multiple\nimage classification benchmarks demonstrate the superior performance of NPN. We\nshow that both network sparsification and network expansion can yield compact\nmodels of similar architectures, while retaining competitive accuracies of the\noriginal networks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 18:57:30 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 17:45:55 GMT"}, {"version": "v3", "created": "Sun, 2 May 2021 03:23:16 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Li", "Yang", ""], ["Ji", "Shihao", ""]]}, {"id": "1908.08380", "submitter": "Zachariah Carmichael", "authors": "Zachariah Carmichael, Humza Syed, Dhireesha Kudithipudi", "title": "Analysis of Wide and Deep Echo State Networks for Multiscale\n  Spatiotemporal Time Series Forecasting", "comments": "10 pages, 10 figures, Proceedings of the Neuro-inspired Computational\n  Elements Workshop (NICE '19), March 26-28, 2019, Albany, NY, USA", "journal-ref": null, "doi": "10.1145/3320288.3320303", "report-no": null, "categories": "eess.SP cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Echo state networks are computationally lightweight reservoir models inspired\nby the random projections observed in cortical circuitry. As interest in\nreservoir computing has grown, networks have become deeper and more intricate.\nWhile these networks are increasingly applied to nontrivial forecasting tasks,\nthere is a need for comprehensive performance analysis of deep reservoirs. In\nthis work, we study the influence of partitioning neurons given a budget and\nthe effect of parallel reservoir pathways across different datasets exhibiting\nmulti-scale and nonlinear dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 20:39:08 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Carmichael", "Zachariah", ""], ["Syed", "Humza", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "1908.08563", "submitter": "Farid Ghareh Mohammadi", "authors": "Farid Ghareh Mohammadi, M. Hadi Amini, and Hamid R. Arabnia", "title": "Applications of Nature-Inspired Algorithms for Dimension Reduction:\n  Enabling Efficient Data Analytics", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In [1], we have explored the theoretical aspects of feature selection and\nevolutionary algorithms. In this chapter, we focus on optimization algorithms\nfor enhancing data analytic process, i.e., we propose to explore applications\nof nature-inspired algorithms in data science. Feature selection optimization\nis a hybrid approach leveraging feature selection techniques and evolutionary\nalgorithms process to optimize the selected features. Prior works solve this\nproblem iteratively to converge to an optimal feature subset. Feature selection\noptimization is a non-specific domain approach. Data scientists mainly attempt\nto find an advanced way to analyze data n with high computational efficiency\nand low time complexity, leading to efficient data analytics. Thus, by\nincreasing generated/measured/sensed data from various sources, analysis,\nmanipulation and illustration of data grow exponentially. Due to the large\nscale data sets, Curse of dimensionality (CoD) is one of the NP-hard problems\nin data science. Hence, several efforts have been focused on leveraging\nevolutionary algorithms (EAs) to address the complex issues in large scale data\nanalytics problems. Dimension reduction, together with EAs, lends itself to\nsolve CoD and solve complex problems, in terms of time complexity, efficiently.\nIn this chapter, we first provide a brief overview of previous studies that\nfocused on solving CoD using feature extraction optimization process. We then\ndiscuss practical examples of research studies are successfully tackled some\napplication domains, such as image processing, sentiment analysis, network\ntraffics / anomalies analysis, credit score analysis and other benchmark\nfunctions/data sets analysis.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 19:01:09 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Mohammadi", "Farid Ghareh", ""], ["Amini", "M. Hadi", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "1908.08655", "submitter": "Alexander Ororbia", "authors": "Alexander Ororbia", "title": "Spiking Neural Predictive Coding for Continual Learning from Data\n  Streams", "comments": "Revised version of manuscript -- includes updated experimental\n  results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For energy-efficient computation in specialized neuromorphic hardware, we\npresent the Spiking Neural Coding Network, an instantiation of a family of\nartificial neural models strongly motivated by the theory of predictive coding.\nThe model, in essence, works by operating in a never-ending process of\n\"guess-and-check\", where neurons predict the activity values of one another and\nthen immediately adjust their own activities to make better future predictions.\nThe interactive, iterative nature of our neural system fits well into the\ncontinuous time formulation of data sensory stream prediction and, as we show,\nthe model's structure yields a simple, local synaptic update rule, which could\nbe used to complement or replace online spike-timing dependent plasticity. In\nthis article, we experiment with an instantiation of our model that consists of\nleaky integrate-and-fire units. However, the general framework within which our\nmodel is situated can naturally incorporate more complex, formal neurons such\nas the Hodgkin-Huxley model. Our experimental results in pattern recognition\ndemonstrate the potential of the proposed model when binary spike trains are\nthe primary paradigm for inter-neuron communication. Notably, our model is\ncompetitive in terms of classification performance, can conduct online\nsemi-supervised learning, naturally experiences less forgetting when learning\nfrom a sequence of tasks, and is more computationally economical and\nbiologically-plausible than popular artificial neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 03:44:27 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 20:30:45 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Ororbia", "Alexander", ""]]}, {"id": "1908.08681", "submitter": "Diganta Misra", "authors": "Diganta Misra", "title": "Mish: A Self Regularized Non-Monotonic Activation Function", "comments": "Accepted to BMVC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose $\\textit{Mish}$, a novel self-regularized non-monotonic activation\nfunction which can be mathematically defined as: $f(x)=x\\tanh(softplus(x))$. As\nactivation functions play a crucial role in the performance and training\ndynamics in neural networks, we validated experimentally on several well-known\nbenchmarks against the best combinations of architectures and activation\nfunctions. We also observe that data augmentation techniques have a favorable\neffect on benchmarks like ImageNet-1k and MS-COCO across multiple\narchitectures. For example, Mish outperformed Leaky ReLU on YOLOv4 with a\nCSP-DarkNet-53 backbone on average precision ($AP_{50}^{val}$) by 2.1$\\%$ in\nMS-COCO object detection and ReLU on ResNet-50 on ImageNet-1k in Top-1 accuracy\nby $\\approx$1$\\%$ while keeping all other network parameters and\nhyperparameters constant. Furthermore, we explore the mathematical formulation\nof Mish in relation with the Swish family of functions and propose an intuitive\nunderstanding on how the first derivative behavior may be acting as a\nregularizer helping the optimization of deep neural networks. Code is publicly\navailable at https://github.com/digantamisra98/Mish.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 06:22:06 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 16:59:14 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 05:42:12 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Misra", "Diganta", ""]]}, {"id": "1908.08686", "submitter": "Anton Eremeev", "authors": "Duc-Cuong Dang, Anton Eremeev, Per Kristian Lehre", "title": "Runtime Analysis of Fitness-Proportionate Selection on Linear Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the runtime analysis of non-elitist evolutionary\nalgorithms (EAs) with fitness-proportionate selection from the simple OneMax\nfunction to the linear functions. Not only does our analysis cover a larger\nclass of fitness functions, it also holds for a wider range of mutation rates.\nWe show that with overwhelmingly high probability, no linear function can be\noptimised in less than exponential time, assuming bitwise mutation rate\n$\\Theta(1/n)$ and population size $\\lambda=n^k$ for any constant $k>2$. In\ncontrast to this negative result, we also show that for any linear function\nwith polynomially bounded weights, the EA achieves a polynomial expected\nruntime if the mutation rate is reduced to $\\Theta(1/n^2)$ and the population\nsize is sufficiently large. Furthermore, the EA with mutation rate\n$\\chi/n=\\Theta(1/n)$ and modest population size $\\lambda=\\Omega(\\ln n)$\noptimises the scaled fitness function $e^{(\\chi+\\varepsilon)f(x)}$ for any\nlinear function $f$ and any $\\varepsilon>0$ in expected time\n$O(n\\lambda\\ln\\lambda+n^2)$. These upper bounds also extend to some additively\ndecomposed fitness functions, such as the Royal Road functions. We expect that\nthe obtained results may be useful not only for the development of the theory\nof evolutionary algorithms, but also for biological applications, such as the\ndirected evolution.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 06:39:25 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Dang", "Duc-Cuong", ""], ["Eremeev", "Anton", ""], ["Lehre", "Per Kristian", ""]]}, {"id": "1908.08783", "submitter": "Shantanu Mandal", "authors": "Shantanu Mandal, Todd A. Anderson, Javier S. Turek, Justin\n  Gottschlich, Shengtian Zhou, Abdullah Muzahid", "title": "Learning Fitness Functions for Machine Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of automatic software generation is known as Machine Programming.\nIn this work, we propose a framework based on genetic algorithms to solve this\nproblem. Although genetic algorithms have been used successfully for many\nproblems, one criticism is that hand-crafting its fitness function, the test\nthat aims to effectively guide its evolution, can be notably challenging. Our\nframework presents a novel approach to learn the fitness function using neural\nnetworks to predict values of ideal fitness functions. We also augment the\nevolutionary process with a minimally intrusive search heuristic. This\nheuristic improves the framework's ability to discover correct programs from\nones that are approximately correct and does so with negligible computational\noverhead. We compare our approach with several state-of-the-art program\nsynthesis methods and demonstrate that it finds more correct programs with\nfewer candidate program generations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:47:34 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 09:24:21 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 17:11:08 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 00:03:58 GMT"}, {"version": "v5", "created": "Sat, 23 Jan 2021 21:48:02 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Mandal", "Shantanu", ""], ["Anderson", "Todd A.", ""], ["Turek", "Javier S.", ""], ["Gottschlich", "Justin", ""], ["Zhou", "Shengtian", ""], ["Muzahid", "Abdullah", ""]]}, {"id": "1908.08993", "submitter": "Dmitry Krotov", "authors": "Leopold Grinberg, John Hopfield, Dmitry Krotov", "title": "Local Unsupervised Learning for Image Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Hebbian learning is believed to be inferior in performance to\nend-to-end training using a backpropagation algorithm. We question this popular\nbelief by designing a local algorithm that can learn convolutional filters at\nscale on large image datasets. These filters combined with patch normalization\nand very steep non-linearities result in a good classification accuracy for\nshallow networks trained locally, as opposed to end-to-end. The filters learned\nby our algorithm contain both orientation selective units and unoriented color\nunits, resembling the responses of pyramidal neurons located in the cytochrome\noxidase 'interblob' and 'blob' regions in the primary visual cortex of\nprimates. It is shown that convolutional networks with patch normalization\nsignificantly outperform standard convolutional networks on the task of\nrecovering the original classes when shadows are superimposed on top of\nstandard CIFAR-10 images. Patch normalization approximates the retinal\nadaptation to the mean light intensity, important for human vision. We also\ndemonstrate a successful transfer of learned representations between CIFAR-10\nand ImageNet 32x32 datasets. All these results taken together hint at the\npossibility that local unsupervised training might be a powerful tool for\nlearning general representations (without specifying the task) directly from\nunlabeled data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 17:42:11 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Grinberg", "Leopold", ""], ["Hopfield", "John", ""], ["Krotov", "Dmitry", ""]]}, {"id": "1908.09942", "submitter": "Adrian De Wynter", "authors": "Adrian de Wynter", "title": "On the Bounds of Function Approximations", "comments": "Accepted as a full paper at ICANN 2019. The final, authenticated\n  publication will be available at https://doi.org/10.1007/978-3-030-30487-4_32", "journal-ref": "In: Tetko, I. V. et al. (eds.) ICANN 2019. LNCS, vol 11727.\n  Springer, Heidelberg, pp. 401-417", "doi": "10.1007/978-3-030-30487-4_32", "report-no": null, "categories": "cs.LG cs.CC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within machine learning, the subfield of Neural Architecture Search (NAS) has\nrecently garnered research attention due to its ability to improve upon\nhuman-designed models. However, the computational requirements for finding an\nexact solution to this problem are often intractable, and the design of the\nsearch space still requires manual intervention. In this paper we attempt to\nestablish a formalized framework from which we can better understand the\ncomputational bounds of NAS in relation to its search space. For this, we first\nreformulate the function approximation problem in terms of sequences of\nfunctions, and we call it the Function Approximation (FA) problem; then we show\nthat it is computationally infeasible to devise a procedure that solves FA for\nall functions to zero error, regardless of the search space. We show also that\nsuch error will be minimal if a specific class of functions is present in the\nsearch space. Subsequently, we show that machine learning as a mathematical\nproblem is a solution strategy for FA, albeit not an effective one, and further\ndescribe a stronger version of this approach: the Approximate Architectural\nSearch Problem (a-ASP), which is the mathematical equivalent of NAS. We\nleverage the framework from this paper and results from the literature to\ndescribe the conditions under which a-ASP can potentially solve FA as well as\nan exhaustive search, but in polynomial time.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:32:33 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["de Wynter", "Adrian", ""]]}, {"id": "1908.10017", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Geng Yuan, Sheng Lin, Caiwen Ding, Fuxun Yu, Tao Liu,\n  Wujie Wen, Xiang Chen, Yanzhi Wang", "title": "Tiny but Accurate: A Pruned, Quantized and Optimized Memristor Crossbar\n  Framework for Ultra Efficient DNN Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-art DNN structures involve intensive computation and high memory\nstorage. To mitigate the challenges, the memristor crossbar array has emerged\nas an intrinsically suitable matrix computation and low-power acceleration\nframework for DNN applications. However, the high accuracy solution for extreme\nmodel compression on memristor crossbar array architecture is still waiting for\nunraveling. In this paper, we propose a memristor-based DNN framework which\ncombines both structured weight pruning and quantization by incorporating\nalternating direction method of multipliers (ADMM) algorithm for better pruning\nand quantization performance. We also discover the non-optimality of the ADMM\nsolution in weight pruning and the unused data path in a structured pruned\nmodel. Motivated by these discoveries, we design a software-hardware\nco-optimization framework which contains the first proposed Network\nPurification and Unused Path Removal algorithms targeting on post-processing a\nstructured pruned model after ADMM steps. By taking memristor hardware\nconstraints into our whole framework, we achieve extreme high compression ratio\non the state-of-art neural network structures with minimum accuracy loss. For\nquantizing structured pruned model, our framework achieves nearly no accuracy\nloss after quantizing weights to 8-bit memristor weight representation. We\nshare our models at anonymous link https://bit.ly/2VnMUy0.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 04:19:05 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ma", "Xiaolong", ""], ["Yuan", "Geng", ""], ["Lin", "Sheng", ""], ["Ding", "Caiwen", ""], ["Yu", "Fuxun", ""], ["Liu", "Tao", ""], ["Wen", "Wujie", ""], ["Chen", "Xiang", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1908.10122", "submitter": "Varun Ojha", "authors": "Varun Ojha, Ajith Abraham, Vaclav Snasel", "title": "Heuristic design of fuzzy inference systems: A review of three decades\n  of research", "comments": "53 pages, 16 figures", "journal-ref": null, "doi": "10.1016/j.engappai.2019.08.010", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an in-depth review of the optimal design of type-1 and\ntype-2 fuzzy inference systems (FIS) using five well known computational\nframeworks: genetic-fuzzy systems (GFS), neuro-fuzzy systems (NFS),\nhierarchical fuzzy systems (HFS), evolving fuzzy systems (EFS), and\nmulti-objective fuzzy systems (MFS), which is in view that some of them are\nlinked to each other. The heuristic design of GFS uses evolutionary algorithms\nfor optimizing both Mamdani-type and Takagi-Sugeno-Kang-type fuzzy systems.\nWhereas, the NFS combines the FIS with neural network learning systems to\nimprove the approximation ability. An HFS combines two or more low-dimensional\nfuzzy logic units in a hierarchical design to overcome the curse of\ndimensionality. An EFS solves the data streaming issues by evolving the system\nincrementally, and an MFS solves the multi-objective trade-offs like the\nsimultaneous maximization of both interpretability and accuracy. This paper\noffers a synthesis of these dimensions and explores their potentials,\nchallenges, and opportunities in FIS research. This review also examines the\ncomplex relations among these dimensions and the possibilities of combining one\nor more computational frameworks adding another dimension: deep fuzzy systems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 10:45:15 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Ojha", "Varun", ""], ["Abraham", "Ajith", ""], ["Snasel", "Vaclav", ""]]}, {"id": "1908.10331", "submitter": "Heriberto Cuay\\'ahuitl", "authors": "Heriberto Cuay\\'ahuitl, Donghyeon Lee, Seonghan Ryu, Sungja Choi,\n  Inchul Hwang, Jihie Kim", "title": "Deep Reinforcement Learning for Chatbots Using Clustered Actions and\n  Human-Likeness Rewards", "comments": "In International Joint Conference of Neural Networks (IJCNN), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training chatbots using the reinforcement learning paradigm is challenging\ndue to high-dimensional states, infinite action spaces and the difficulty in\nspecifying the reward function. We address such problems using clustered\nactions instead of infinite actions, and a simple but promising reward function\nbased on human-likeness scores derived from human-human dialogue data. We train\nDeep Reinforcement Learning (DRL) agents using chitchat data in raw\ntext---without any manual annotations. Experimental results using different\nsplits of training data report the following. First, that our agents learn\nreasonable policies in the environments they get familiarised with, but their\nperformance drops substantially when they are exposed to a test set of unseen\ndialogues. Second, that the choice of sentence embedding size between 100 and\n300 dimensions is not significantly different on test data. Third, that our\nproposed human-likeness rewards are reasonable for training chatbots as long as\nthey use lengthy dialogue histories of >=10 sentences.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 17:06:15 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Cuay\u00e1huitl", "Heriberto", ""], ["Lee", "Donghyeon", ""], ["Ryu", "Seonghan", ""], ["Choi", "Sungja", ""], ["Hwang", "Inchul", ""], ["Kim", "Jihie", ""]]}, {"id": "1908.10673", "submitter": "Chang Wei Loh", "authors": "Changwei Loh, Daniel Schneegass, Pengwei Tian", "title": "A Search for the Underlying Equation Governing Similar Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a data-driven approach to discover the underlying structural form of\nthe mathematical equation governing the dynamics of multiple but similar\nsystems induced by the same mechanisms. This approach hinges on theories that\nwe lay out involving arguments based on the nature of physical systems. In the\nsame vein, we also introduce a metric to search for the best candidate equation\nusing the datasets generated from the systems. This approach involves symbolic\nregression by means of genetic programming and regressions to compute the\nstrength of the interplay between the extrinsic parameters in a candidate\nequation. We relate these extrinsic parameters to the hidden properties of the\ndata-generating systems. The behavior of a new similar system can be predicted\neasily by utilizing the discovered structural form of the general equation. As\nillustrations, we apply the approach to identify candidate structural forms of\nthe underlying equation governing two cases: the changes in a sensor\nmeasurement of degrading engines; and the search for the governing equation of\nsystems with known variations of an intrinsic parameter.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 04:54:41 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Loh", "Changwei", ""], ["Schneegass", "Daniel", ""], ["Tian", "Pengwei", ""]]}, {"id": "1908.10714", "submitter": "Steven Abreu", "authors": "Steven Abreu", "title": "Automated Architecture Design for Deep Neural Networks", "comments": "Undergraduate Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Machine learning has made tremendous progress in recent years and received\nlarge amounts of public attention. Though we are still far from designing a\nfull artificially intelligent agent, machine learning has brought us many\napplications in which computers solve human learning tasks remarkably well.\nMuch of this progress comes from a recent trend within machine learning, called\ndeep learning. Deep learning models are responsible for many state-of-the-art\napplications of machine learning. Despite their success, deep learning models\nare hard to train, very difficult to understand, and often times so complex\nthat training is only possible on very large GPU clusters. Lots of work has\nbeen done on enabling neural networks to learn efficiently. However, the design\nand architecture of such neural networks is often done manually through trial\nand error and expert knowledge. This thesis inspects different approaches,\nexisting and novel, to automate the design of deep feedforward neural networks\nin an attempt to create less complex models with good performance that take\naway the burden of deciding on an architecture and make it more efficient to\ndesign and train such deep networks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 00:57:45 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Abreu", "Steven", ""]]}, {"id": "1908.10823", "submitter": "Teawon Han", "authors": "Teawon Han, Dimitar Filev, and Umit Ozguner", "title": "An Online Evolving Framework for Modeling the Safe Autonomous Vehicle\n  Control System via Online Recognition of Latent Risks", "comments": "Under review in the Transportation Research Record: Journal of the\n  Transportation Research Board", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An online evolving framework is proposed to support modeling the safe\nAutomated Vehicle (AV) control system by making the controller able to\nrecognize unexpected situations and react appropriately by choosing a better\naction. Within the framework, the evolving Finite State Machine (e-FSM), which\nis an online model able to (1) determine states uniquely as needed, (2)\nrecognize states, and (3) identify state-transitions, is introduced.\n  In this study, the e-FSM's capabilities are explained and illustrated by\nsimulating a simple car-following scenario. As a vehicle controller, the\nIntelligent Driver Model (IDM) is implemented, and different sets of IDM\nparameters are assigned to the following vehicle for simulating various\nsituations (including the collision). While simulating the car-following\nscenario, e-FSM recognizes and determines the states and identifies the\ntransition matrices by suggested methods.\n  To verify if e-FSM can recognize and determine states uniquely, we analyze\nwhether the same state is recognized under the identical situation. The\ndifference between probability distributions of predicted and recognized states\nis measured by the Jensen-Shannon divergence (JSD) method to validate the\naccuracy of identified transition-matrices. As shown in the results, the\nDead-End state which has latent-risk of the collision is uniquely determined\nand consistently recognized. Also, the probability distributions of the\npredicted state are significantly similar to the recognized state, declaring\nthat the state-transitions are precisely identified.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 16:46:47 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Han", "Teawon", ""], ["Filev", "Dimitar", ""], ["Ozguner", "Umit", ""]]}, {"id": "1908.11263", "submitter": "Angelo Garofalo", "authors": "Angelo Garofalo, Manuele Rusci, Francesco Conti, Davide Rossi, Luca\n  Benini", "title": "PULP-NN: Accelerating Quantized Neural Networks on Parallel\n  Ultra-Low-Power RISC-V Processors", "comments": "13 pages, 11 figures, 2 tables", "journal-ref": null, "doi": "10.1098/rsta.2019.0155", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PULP-NN, an optimized computing library for a parallel\nultra-low-power tightly coupled cluster of RISC-V processors. The key\ninnovation in PULP-NN is a set of kernels for Quantized Neural Network (QNN)\ninference, targeting byte and sub-byte data types, down to INT-1, tuned for the\nrecent trend toward aggressive quantization in deep neural network inference.\nThe proposed library exploits both the digital signal processing (DSP)\nextensions available in the PULP RISC-V processors and the cluster's\nparallelism, achieving up to 15.5 MACs/cycle on INT-8 and improving performance\nby up to 63x with respect to a sequential implementation on a single RISC-V\ncore implementing the baseline RV32IMC ISA. Using PULP-NN, a CIFAR-10 network\non an octa-core cluster runs in 30x and 19.6x less clock cycles than the\ncurrent state-of-the-art ARM CMSIS-NN library, running on STM32L4 and STM32H7\nMCUs, respectively. The proposed library, when running on GAP-8 processor,\noutperforms by 36.8x and by 7.45x the execution on energy efficient MCUs such\nas STM32L4 and high-end MCUs such as STM32H7 respectively, when operating at\nthe maximum frequency. The energy efficiency on GAP-8 is 14.1x higher than\nSTM32L4 and 39.5x higher than STM32H7, at the maximum efficiency operating\npoint.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 14:42:39 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Garofalo", "Angelo", ""], ["Rusci", "Manuele", ""], ["Conti", "Francesco", ""], ["Rossi", "Davide", ""], ["Benini", "Luca", ""]]}, {"id": "1908.11691", "submitter": "Geng Yuan", "authors": "Geng Yuan, Xiaolong Ma, Caiwen Ding, Sheng Lin, Tianyun Zhang, Zeinab\n  S. Jalali, Yilong Zhao, Li Jiang, Sucheta Soundarajan, Yanzhi Wang", "title": "An Ultra-Efficient Memristor-Based DNN Framework with Structured Weight\n  Pruning and Quantization Using ADMM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high computation and memory storage of large deep neural networks (DNNs)\nmodels pose intensive challenges to the conventional Von-Neumann architecture,\nincurring substantial data movements in the memory hierarchy. The memristor\ncrossbar array has emerged as a promising solution to mitigate the challenges\nand enable low-power acceleration of DNNs. Memristor-based weight pruning and\nweight quantization have been seperately investigated and proven effectiveness\nin reducing area and power consumption compared to the original DNN model.\nHowever, there has been no systematic investigation of memristor-based\nneuromorphic computing (NC) systems considering both weight pruning and weight\nquantization. In this paper, we propose an unified and systematic\nmemristor-based framework considering both structured weight pruning and weight\nquantization by incorporating alternating direction method of multipliers\n(ADMM) into DNNs training. We consider hardware constraints such as crossbar\nblocks pruning, conductance range, and mismatch between weight value and real\ndevices, to achieve high accuracy and low power and small area footprint. Our\nframework is mainly integrated by three steps, i.e., memristor-based ADMM\nregularized optimization, masked mapping and retraining. Experimental results\nshow that our proposed framework achieves 29.81X (20.88X) weight compression\nratio, with 98.38% (96.96%) and 98.29% (97.47%) power and area reduction on\nVGG-16 (ResNet-18) network where only have 0.5% (0.76%) accuracy loss, compared\nto the original DNN models. We share our models at link http://bit.ly/2Jp5LHJ.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 03:32:41 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Yuan", "Geng", ""], ["Ma", "Xiaolong", ""], ["Ding", "Caiwen", ""], ["Lin", "Sheng", ""], ["Zhang", "Tianyun", ""], ["Jalali", "Zeinab S.", ""], ["Zhao", "Yilong", ""], ["Jiang", "Li", ""], ["Soundarajan", "Sucheta", ""], ["Wang", "Yanzhi", ""]]}]