[{"id": "1906.00052", "submitter": "Souma Chowdhury", "authors": "Amir Behjat, Krushang Gabani, Souma Chowdhury", "title": "Training Detection-Range-Frugal Cooperative Collision Avoidance Models\n  for Quadcopters via Neuroevolution", "comments": "Accepted for presentation in (and publication in the proceedings of)\n  2019 AIAA AVIATION Forum and Exposition (2019 Air Traffic Operations,\n  Management, and Systems Conference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative autonomous approaches to avoiding collisions among small Unmanned\nAerial Vehicles (UAVs) is central to safe integration of UAVs within the\ncivilian airspace. One potential online cooperative approach is the concept of\nreciprocal actions, where both UAVs take pre-trained mutually coherent actions\nthat do not require active online coordination (thereby avoiding the\ncomputational burden and risk associated with it). This paper presents a\nlearning based approach to train such reciprocal maneuvers. Neuroevolution,\nwhich uses evolutionary algorithms to simultaneously optimize the topology and\nweights of neural networks, is used as the learning method -- which operates\nover a set of sample approach scenarios. Unlike most existing work (that\nminimize travel distance, energy or risk), the training process here focuses on\nthe objective of minimizing the required detection range; this has important\npractical implications w.r.t. alleviating the dependency on sophisticated\nsensing and their reliability under various environments. A specialized design\nof experiments and line search is used to identify the minimum detection range\nfor each sample scenarios. In order to allow an efficient training process, a\nclassifier is used to discard actions (without simulating them) where the\ncontroller would fail. The model obtained via neuroevolution is observed to\ngeneralize well to (i.e., successful collision avoidance over) unseen approach\nscenarios.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 20:02:09 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Behjat", "Amir", ""], ["Gabani", "Krushang", ""], ["Chowdhury", "Souma", ""]]}, {"id": "1906.00092", "submitter": "Anik Chattopadhyay", "authors": "Anik Chattopadhyay, Arunava Banerjee", "title": "Signal Coding and Perfect Reconstruction using Spike Trains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many animal sensory pathways, the transformation from external stimuli to\nspike trains is essentially deterministic. In this context, a new mathematical\nframework for coding and reconstruction, based on a biologically plausible\nmodel of the spiking neuron, is presented. The framework considers encoding of\na signal through spike trains generated by an ensemble of neurons via a\nstandard convolve-then-threshold mechanism. Neurons are distinguished by their\nconvolution kernels and threshold values. Reconstruction is posited as a convex\noptimization minimizing energy. Formal conditions under which perfect\nreconstruction of the signal from the spike trains is possible are then\nidentified in this setup. Finally, a stochastic gradient descent mechanism is\nproposed to achieve these conditions. Simulation experiments are presented to\ndemonstrate the strength and efficacy of the framework\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 21:53:42 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 19:40:29 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Chattopadhyay", "Anik", ""], ["Banerjee", "Arunava", ""]]}, {"id": "1906.00097", "submitter": "Elliot Meyerson", "authors": "Elliot Meyerson and Risto Miikkulainen", "title": "Modular Universal Reparameterization: Deep Multi-task Learning Across\n  Diverse Domains", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), 16 pages, including Supplemental Material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep learning applications continue to become more diverse, an interesting\nquestion arises: Can general problem solving arise from jointly learning\nseveral such diverse tasks? To approach this question, deep multi-task learning\nis extended in this paper to the setting where there is no obvious overlap\nbetween task architectures. The idea is that any set of (architecture,task)\npairs can be decomposed into a set of potentially related subproblems, whose\nsharing is optimized by an efficient stochastic algorithm. The approach is\nfirst validated in a classic synthetic multi-task learning benchmark, and then\napplied to sharing across disparate architectures for vision, NLP, and genomics\ntasks. It discovers regularities across these domains, encodes them into\nsharable modules, and combines these modules systematically to improve\nperformance in the individual tasks. The results confirm that sharing learned\nfunctionality across diverse domains and architectures is indeed beneficial,\nthus establishing a key ingredient for general problem solving in the future.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 22:00:43 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 17:51:14 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Meyerson", "Elliot", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "1906.00307", "submitter": "Andrew Habib", "authors": "Andrew Habib and Michael Pradel", "title": "Neural Bug Finding: A Study of Opportunities and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Static analysis is one of the most widely adopted techniques to find software\nbugs before code is put in production. Designing and implementing effective and\nefficient static analyses is difficult and requires high expertise, which\nresults in only a few experts able to write such analyses. This paper explores\nthe opportunities and challenges of an alternative way of creating static bug\ndetectors: neural bug finding. The basic idea is to formulate bug detection as\na classification problem, and to address this problem with neural networks\ntrained on examples of buggy and non-buggy code. We systematically study the\neffectiveness of this approach based on code examples labeled by a\nstate-of-the-art, static bug detector. Our results show that neural bug finding\nis surprisingly effective for some bug patterns, sometimes reaching a precision\nand recall of over 80%, but also that it struggles to understand some program\nproperties obvious to a traditional analysis. A qualitative analysis of the\nresults provides insights into why neural bug finders sometimes work and\nsometimes do not work. We also identify pitfalls in selecting the code examples\nused to train and validate neural bug finders, and propose an algorithm for\nselecting effective training data.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 23:06:11 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Habib", "Andrew", ""], ["Pradel", "Michael", ""]]}, {"id": "1906.00399", "submitter": "Yang Chuanguang", "authors": "Chuanguang Yang and Zhulin An and Chao Li and Boyu Diao and Yongjun Xu", "title": "Multi-Objective Pruning for CNNs Using Genetic Algorithm", "comments": "6 pages,3 figures,Accepted as a conference paper at ICANN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a heuristic genetic algorithm (GA) for pruning\nconvolutional neural networks (CNNs) according to the multi-objective trade-off\namong error, computation and sparsity. In our experiments, we apply our\napproach to prune pre-trained LeNet across the MNIST dataset, which reduces\n95.42% parameter size and achieves 16$\\times$ speedups of convolutional layer\ncomputation with tiny accuracy loss by laying emphasis on sparsity and\ncomputation, respectively. Our empirical study suggests that GA is an\nalternative pruning approach for obtaining a competitive compression\nperformance. Additionally, compared with state-of-the-art approaches, GA is\ncapable of automatically pruning CNNs based on the multi-objective importance\nby a pre-defined fitness function.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 13:17:37 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 12:29:27 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Yang", "Chuanguang", ""], ["An", "Zhulin", ""], ["Li", "Chao", ""], ["Diao", "Boyu", ""], ["Xu", "Yongjun", ""]]}, {"id": "1906.00402", "submitter": "Wenji Li", "authors": "Zhun Fan, Zhaojun Wang, Wenji Li, Yutong Yuan, Yugen You, Zhi Yang,\n  Fuzan Sun, Jie Ruan, Zhaocheng Li", "title": "Push and Pull Search Embedded in an M2M Framework for Solving\n  Constrained Multi-objective Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In dealing with constrained multi-objective optimization problems (CMOPs), a\nkey issue of multi-objective evolutionary algorithms (MOEAs) is to balance the\nconvergence and diversity of working populations.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 13:44:45 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Fan", "Zhun", ""], ["Wang", "Zhaojun", ""], ["Li", "Wenji", ""], ["Yuan", "Yutong", ""], ["You", "Yugen", ""], ["Yang", "Zhi", ""], ["Sun", "Fuzan", ""], ["Ruan", "Jie", ""], ["Li", "Zhaocheng", ""]]}, {"id": "1906.00499", "submitter": "Xiujun Li", "authors": "Zhirui Zhang and Xiujun Li and Jianfeng Gao and Enhong Chen", "title": "Budgeted Policy Learning for Task-Oriented Dialogue Systems", "comments": "10 pages, 7 figures, ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach that extends Deep Dyna-Q (DDQ) by\nincorporating a Budget-Conscious Scheduling (BCS) to best utilize a fixed,\nsmall amount of user interactions (budget) for learning task-oriented dialogue\nagents. BCS consists of (1) a Poisson-based global scheduler to allocate budget\nover different stages of training; (2) a controller to decide at each training\nstep whether the agent is trained using real or simulated experiences; (3) a\nuser goal sampling module to generate the experiences that are most effective\nfor policy learning. Experiments on a movie-ticket booking task with simulated\nand real users show that our approach leads to significant improvements in\nsuccess rate over the state-of-the-art baselines given the fixed budget.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2019 22:53:33 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Zhang", "Zhirui", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Chen", "Enhong", ""]]}, {"id": "1906.00586", "submitter": "Mitchell Wortsman", "authors": "Mitchell Wortsman, Ali Farhadi, Mohammad Rastegari", "title": "Discovering Neural Wirings", "comments": "NeurIPS 2019 Camera Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of neural networks has driven a shift in focus from feature\nengineering to architecture engineering. However, successful networks today are\nconstructed using a small and manually defined set of building blocks. Even in\nmethods of neural architecture search (NAS) the network connectivity patterns\nare largely constrained. In this work we propose a method for discovering\nneural wirings. We relax the typical notion of layers and instead enable\nchannels to form connections independent of each other. This allows for a much\nlarger space of possible networks. The wiring of our network is not fixed\nduring training -- as we learn the network parameters we also learn the\nstructure itself. Our experiments demonstrate that our learned connectivity\noutperforms hand engineered and randomly wired networks. By learning the\nconnectivity of MobileNetV1we boost the ImageNet accuracy by 10% at ~41M FLOPs.\nMoreover, we show that our method generalizes to recurrent and continuous time\nnetworks. Our work may also be regarded as unifying core aspects of the neural\narchitecture search problem with sparse neural network learning. As NAS becomes\nmore fine grained, finding a good architecture is akin to finding a sparse\nsubnetwork of the complete graph. Accordingly, DNW provides an effective\nmechanism for discovering sparse subnetworks of predefined architectures in a\nsingle training run. Though we only ever use a small percentage of the weights\nduring the forward pass, we still play the so-called initialization lottery\nwith a combinatorial number of subnetworks. Code and pretrained models are\navailable at https://github.com/allenai/dnw while additional visualizations may\nbe found at https://mitchellnw.github.io/blog/2019/dnw/.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 05:58:33 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 22:49:47 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 23:16:39 GMT"}, {"version": "v4", "created": "Mon, 28 Oct 2019 04:04:44 GMT"}, {"version": "v5", "created": "Sun, 17 Nov 2019 02:54:50 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Wortsman", "Mitchell", ""], ["Farhadi", "Ali", ""], ["Rastegari", "Mohammad", ""]]}, {"id": "1906.00748", "submitter": "Kazuki Takamura", "authors": "Kazuki Takamura and Satoshi Yamane", "title": "Improving Minimal Gated Unit for Sequential Data", "comments": "2 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to obtain a model which can process sequential data related to\nmachine translation and speech recognition faster and more accurately, we\npropose adopting Chrono Initializer as the initialization method of Minimal\nGated Unit. We evaluated the method with two tasks: adding task and copy task.\nAs a result of the experiment, the effectiveness of the proposed method was\nconfirmed.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 07:09:12 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Takamura", "Kazuki", ""], ["Yamane", "Satoshi", ""]]}, {"id": "1906.00793", "submitter": "Souma Chowdhury", "authors": "Payam Ghassemi, Sumeet Sanjay Lulekar, Souma Chowdhury", "title": "Adaptive Model Refinement with Batch Bayesian Sampling for Optimization\n  of Bio-inspired Flow Tailoring", "comments": "Accepted for presentation in (and publication in the proceedings of)\n  2019 AIAA AVIATION Forum and Exposition (2019 Multidisciplinary Analysis and\n  Optimization Conference). arXiv admin note: text overlap with\n  arXiv:1806.01159 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an advancement to an approach for model-independent\nsurrogate-based optimization with adaptive batch sampling, known as Adaptive\nModel Refinement (AMR). While the original AMR method provides unique decisions\nwith regards to \"when\" to sample and \"how many\" samples to add (to preserve the\ncredibility of the optimization search process), it did not provide specific\ndirection towards \"where\" to sample in the design variable space. This paper\nthus introduces the capability to identify optimum location to add new samples.\nThe location of the infill points is decided by integrating a Gaussian\nProcess-based criteria (\"q-EI\"), adopted from Bayesian optimization. The\nconsideration of a penalization term to mitigate interaction among samples (in\na batch) is crucial to effective integration of the q-EI criteria into AMR. The\nnew AMR method, called AMR with Penalized Batch Bayesian Sampling (AMR-PBS) is\ntested on benchmark functions, demonstrating better performance compared to\nBayesian EGO. In addition, it is successfully applied to design surface riblets\nfor bio-inspired passive flow control (where high-fidelity samples are given by\ncostly RANS CFD simulations), leading to a 10% drag reduction over the\ncorresponding baseline (i.e., riblet-free aerodynamic surface).\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 15:12:01 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Ghassemi", "Payam", ""], ["Lulekar", "Sumeet Sanjay", ""], ["Chowdhury", "Souma", ""]]}, {"id": "1906.00851", "submitter": "Johannes Christian Thiele", "authors": "Johannes Christian Thiele, Olivier Bichler, Antoine Dupret", "title": "SpikeGrad: An ANN-equivalent Computation Model for Implementing\n  Backpropagation with Spikes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event-based neuromorphic systems promise to reduce the energy consumption of\ndeep learning tasks by replacing expensive floating point operations on dense\nmatrices by low power sparse and asynchronous operations on spike events. While\nthese systems can be trained increasingly well using approximations of the\nback-propagation algorithm, these implementations usually require high\nprecision errors for training and are therefore incompatible with the typical\ncommunication infrastructure of neuromorphic circuits. In this work, we analyze\nhow the gradient can be discretized into spike events when training a spiking\nneural network. To accelerate our simulation, we show that using a special\nimplementation of the integrate-and-fire neuron allows us to describe the\naccumulated activations and errors of the spiking neural network in terms of an\nequivalent artificial neural network, allowing us to largely speed up training\ncompared to an explicit simulation of all spike events. This way we are able to\ndemonstrate that even for deep networks, the gradients can be discretized\nsufficiently well with spikes if the gradient is properly rescaled. This form\nof spike-based backpropagation enables us to achieve equivalent or better\naccuracies on the MNIST and CIFAR10 dataset than comparable state-of-the-art\nspiking neural networks trained with full precision gradients. The algorithm,\nwhich we call SpikeGrad, is based on accumulation and comparison operations and\ncan naturally exploit sparsity in the gradient computation, which makes it an\ninteresting choice for a spiking neuromorphic systems with on-chip learning\ncapacities.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 15:01:52 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Thiele", "Johannes Christian", ""], ["Bichler", "Olivier", ""], ["Dupret", "Antoine", ""]]}, {"id": "1906.00889", "submitter": "Benjamin Lansdell", "authors": "Benjamin James Lansdell, Prashanth Ravi Prakash, Konrad Paul Kording", "title": "Learning to solve the credit assignment problem", "comments": "18 pages; 4 figures. (ICLR 2020 version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation is driving today's artificial neural networks (ANNs).\nHowever, despite extensive research, it remains unclear if the brain implements\nthis algorithm. Among neuroscientists, reinforcement learning (RL) algorithms\nare often seen as a realistic alternative: neurons can randomly introduce\nchange, and use unspecific feedback signals to observe their effect on the cost\nand thus approximate their gradient. However, the convergence rate of such\nlearning scales poorly with the number of involved neurons. Here we propose a\nhybrid learning approach. Each neuron uses an RL-type strategy to learn how to\napproximate the gradients that backpropagation would provide. We provide proof\nthat our approach converges to the true gradient for certain classes of\nnetworks. In both feedforward and convolutional networks, we empirically show\nthat our approach learns to approximate the gradient, and can match or the\nperformance of exact gradient-based learning. Learning feedback weights\nprovides a biologically plausible mechanism of achieving good performance,\nwithout the need for precise, pre-specified learning rules.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 15:48:38 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 12:06:38 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 14:11:01 GMT"}, {"version": "v4", "created": "Wed, 22 Apr 2020 20:19:19 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Lansdell", "Benjamin James", ""], ["Prakash", "Prashanth Ravi", ""], ["Kording", "Konrad Paul", ""]]}, {"id": "1906.00945", "submitter": "Dimitris Tsipras", "authors": "Logan Engstrom, Andrew Ilyas, Shibani Santurkar, Dimitris Tsipras,\n  Brandon Tran, Aleksander Madry", "title": "Adversarial Robustness as a Prior for Learned Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important goal in deep learning is to learn versatile, high-level feature\nrepresentations of input data. However, standard networks' representations seem\nto possess shortcomings that, as we illustrate, prevent them from fully\nrealizing this goal. In this work, we show that robust optimization can be\nre-cast as a tool for enforcing priors on the features learned by deep neural\nnetworks. It turns out that representations learned by robust models address\nthe aforementioned shortcomings and make significant progress towards learning\na high-level encoding of inputs. In particular, these representations are\napproximately invertible, while allowing for direct visualization and\nmanipulation of salient input features. More broadly, our results indicate\nadversarial robustness as a promising avenue for improving learned\nrepresentations. Our code and models for reproducing these results is available\nat https://git.io/robust-reps .\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 17:55:20 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 17:39:54 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Engstrom", "Logan", ""], ["Ilyas", "Andrew", ""], ["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Tran", "Brandon", ""], ["Madry", "Aleksander", ""]]}, {"id": "1906.01035", "submitter": "Sjoerd van Steenkiste", "authors": "Sjoerd van Steenkiste, Klaus Greff, J\\\"urgen Schmidhuber", "title": "A Perspective on Objects and Systematic Generalization in Model-Based RL", "comments": "Accepted to the ICML 2019 workshop on Workshop on Generative Modeling\n  and Model-Based Reasoning for Robotics and AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to meet the diverse challenges in solving many real-world problems,\nan intelligent agent has to be able to dynamically construct a model of its\nenvironment. Objects facilitate the modular reuse of prior knowledge and the\ncombinatorial construction of such models. In this work, we argue that\ndynamically bound features (objects) do not simply emerge in connectionist\nmodels of the world. We identify several requirements that need to be fulfilled\nin overcoming this limitation and highlight corresponding inductive biases.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:29:12 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["van Steenkiste", "Sjoerd", ""], ["Greff", "Klaus", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1906.01039", "submitter": "Guruprasad Raghavan", "authors": "Guruprasad Raghavan, Matt Thomson", "title": "Neural networks grown and self-organized by noise", "comments": "21 pages (including 11 pages of appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Living neural networks emerge through a process of growth and\nself-organization that begins with a single cell and results in a brain, an\norganized and functional computational device. Artificial neural networks,\nhowever, rely on human-designed, hand-programmed architectures for their\nremarkable performance. Can we develop artificial computational devices that\ncan grow and self-organize without human intervention? In this paper, we\npropose a biologically inspired developmental algorithm that can 'grow' a\nfunctional, layered neural network from a single initial cell. The algorithm\norganizes inter-layer connections to construct a convolutional pooling layer, a\nkey constituent of convolutional neural networks (CNN's). Our approach is\ninspired by the mechanisms employed by the early visual system to wire the\nretina to the lateral geniculate nucleus (LGN), days before animals open their\neyes. The key ingredients for robust self-organization are an emergent\nspontaneous spatiotemporal activity wave in the first layer and a local\nlearning rule in the second layer that 'learns' the underlying activity pattern\nin the first layer. The algorithm is adaptable to a wide-range of input-layer\ngeometries, robust to malfunctioning units in the first layer, and so can be\nused to successfully grow and self-organize pooling architectures of different\npool-sizes and shapes. The algorithm provides a primitive procedure for\nconstructing layered neural networks through growth and self-organization.\nBroadly, our work shows that biologically inspired developmental algorithms can\nbe applied to autonomously grow functional 'brains' in-silico.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 19:33:39 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Raghavan", "Guruprasad", ""], ["Thomson", "Matt", ""]]}, {"id": "1906.01094", "submitter": "Cecilia Jarne", "authors": "C. Jarne and R. Laje", "title": "Graceful degradation of recurrent neural networks as a function of\n  network size, memory length, and connectivity damage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) are frequently used to model aspects of\nbrain function and structure. In this work, we trained small fully-connected\nRNNs to perform temporal and flow control tasks with time-varying stimuli. Our\nresults show that different RNNs can solve the same task by converging to\ndifferent underlying dynamics and that the performance gracefully degrades\neither as network size is decreased, interval duration is increased, or\nconnectivity is damaged. Our results are useful to quantify different aspects\nof the models, which are normally used as black boxes and need to be understood\nin advance to modeling the biological response of cerebral cortex areas.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 21:56:48 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 16:23:44 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2019 14:18:27 GMT"}, {"version": "v4", "created": "Mon, 21 Dec 2020 14:04:01 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Jarne", "C.", ""], ["Laje", "R.", ""]]}, {"id": "1906.01102", "submitter": "Mariano Tepper", "authors": "Mariano Tepper", "title": "Do place cells dream of conditional probabilities? Learning Neural\n  Nystr\\\"om representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We posit that hippocampal place cells encode information about future\nlocations under a transition distribution observed as an agent explores a given\n(physical or conceptual) space. The encoding of information about the current\nlocation, usually associated with place cells, then emerges as a necessary step\nto achieve this broader goal. We formally derive a biologically-inspired neural\nnetwork from Nystr\\\"om kernel approximations and empirically demonstrate that\nthe network successfully approximates transition distributions. The proposed\nnetwork yields representations that, just like place cells, soft-tile the input\nspace with highly sparse and localized receptive fields. Additionally, we show\nthat the proposed computational motif can be extended to handle supervised\nproblems, creating class-specific place cells while exhibiting low sample\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 22:11:10 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 23:35:09 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Tepper", "Mariano", ""]]}, {"id": "1906.01241", "submitter": "Evandro Luquini", "authors": "Evandro Luquini and Nizam Omar", "title": "Kinetic Market Model: An Evolutionary Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research proposes the econophysics kinetic market model as an\nevolutionary algorithm's instance. The immediate results from this proposal is\na new replacement rule for family competition genetic algorithms. It also\nrepresents a starting point to adding evolvable entities to kinetic market\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 07:20:37 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Luquini", "Evandro", ""], ["Omar", "Nizam", ""]]}, {"id": "1906.01470", "submitter": "Alexander Vezhnevets", "authors": "Alexander Sasha Vezhnevets, Yuhuai Wu, Remi Leblond, Joel Z. Leibo", "title": "Options as responses: Grounding behavioural hierarchies in multi-agent\n  RL", "comments": "First two authors contributed equally", "journal-ref": "International Conference on Machine Learning 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates generalisation in multi-agent games, where the\ngenerality of the agent can be evaluated by playing against opponents it hasn't\nseen during training. We propose two new games with concealed information and\ncomplex, non-transitive reward structure (think rock/paper/scissors). It turns\nout that most current deep reinforcement learning methods fail to efficiently\nexplore the strategy space, thus learning policies that generalise poorly to\nunseen opponents. We then propose a novel hierarchical agent architecture,\nwhere the hierarchy is grounded in the game-theoretic structure of the game --\nthe top level chooses strategic responses to opponents, while the low level\nimplements them into policy over primitive actions. This grounding facilitates\ncredit assignment across the levels of hierarchy. Our experiments show that the\nproposed hierarchical agent is capable of generalisation to unseen opponents,\nwhile conventional baselines fail to generalise whatsoever.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 14:18:47 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 15:10:59 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 13:31:16 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Vezhnevets", "Alexander Sasha", ""], ["Wu", "Yuhuai", ""], ["Leblond", "Remi", ""], ["Leibo", "Joel Z.", ""]]}, {"id": "1906.01493", "submitter": "Indranil Chakraborty", "authors": "Indranil Chakraborty, Deboleena Roy, Isha Garg, Aayush Ankit and\n  Kaushik Roy", "title": "Constructing Energy-efficient Mixed-precision Neural Networks through\n  Principal Component Analysis for Edge Intelligence", "comments": "14 pages, 4 figures, 8 tables", "journal-ref": "Nature Machine Intelligence, 2, 43-55 (2020)", "doi": "10.1038/s42256-019-0134-0", "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The `Internet of Things' has brought increased demand for AI-based edge\ncomputing in applications ranging from healthcare monitoring systems to\nautonomous vehicles. Quantization is a powerful tool to address the growing\ncomputational cost of such applications, and yields significant compression\nover full-precision networks. However, quantization can result in substantial\nloss of performance for complex image classification tasks. To address this, we\npropose a Principal Component Analysis (PCA) driven methodology to identify the\nimportant layers of a binary network, and design mixed-precision networks. The\nproposed Hybrid-Net achieves a more than 10% improvement in classification\naccuracy over binary networks such as XNOR-Net for ResNet and VGG architectures\non CIFAR-100 and ImageNet datasets while still achieving up to 94% of the\nenergy-efficiency of XNOR-Nets. This work furthers the feasibility of using\nhighly compressed neural networks for energy-efficient neural computing in edge\ndevices.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 15:02:30 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 02:05:07 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Chakraborty", "Indranil", ""], ["Roy", "Deboleena", ""], ["Garg", "Isha", ""], ["Ankit", "Aayush", ""], ["Roy", "Kaushik", ""]]}, {"id": "1906.01558", "submitter": "Drew Linsley", "authors": "Junkyung Kim, Drew Linsley, Kalpit Thakkar, Thomas Serre", "title": "Disentangling neural mechanisms for perceptual grouping", "comments": "Published in ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forming perceptual groups and individuating objects in visual scenes is an\nessential step towards visual intelligence. This ability is thought to arise in\nthe brain from computations implemented by bottom-up, horizontal, and top-down\nconnections between neurons. However, the relative contributions of these\nconnections to perceptual grouping are poorly understood. We address this\nquestion by systematically evaluating neural network architectures featuring\ncombinations bottom-up, horizontal, and top-down connections on two synthetic\nvisual tasks, which stress low-level \"Gestalt\" vs. high-level object cues for\nperceptual grouping. We show that increasing the difficulty of either task\nstrains learning for networks that rely solely on bottom-up connections.\nHorizontal connections resolve straining on tasks with Gestalt cues by\nsupporting incremental grouping, whereas top-down connections rescue learning\non tasks with high-level object cues by modifying coarse predictions about the\nposition of the target object. Our findings dissociate the computational roles\nof bottom-up, horizontal and top-down connectivity, and demonstrate how a model\nfeaturing all of these interactions can more flexibly learn to form perceptual\ngroups.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:21:46 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 15:53:55 GMT"}], "update_date": "2020-10-29", "authors_parsed": [["Kim", "Junkyung", ""], ["Linsley", "Drew", ""], ["Thakkar", "Kalpit", ""], ["Serre", "Thomas", ""]]}, {"id": "1906.01563", "submitter": "Sam Greydanus", "authors": "Sam Greydanus, Misko Dzamba, Jason Yosinski", "title": "Hamiltonian Neural Networks", "comments": "Conference paper at NeurIPS 2019. Main paper has 8 pages and 5\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though neural networks enjoy widespread use, they still struggle to\nlearn the basic laws of physics. How might we endow them with better inductive\nbiases? In this paper, we draw inspiration from Hamiltonian mechanics to train\nmodels that learn and respect exact conservation laws in an unsupervised\nmanner. We evaluate our models on problems where conservation of energy is\nimportant, including the two-body problem and pixel observations of a pendulum.\nOur model trains faster and generalizes better than a regular neural network.\nAn interesting side effect is that our model is perfectly reversible in time.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 16:27:55 GMT"}, {"version": "v2", "created": "Sun, 7 Jul 2019 22:49:26 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 04:20:28 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Greydanus", "Sam", ""], ["Dzamba", "Misko", ""], ["Yosinski", "Jason", ""]]}, {"id": "1906.01594", "submitter": "Yiding Hao", "authors": "William Merrill, Lenny Khazan, Noah Amsel, Yiding Hao, Simon\n  Mendelsohn, Robert Frank", "title": "Finding Syntactic Representations in Neural Stacks", "comments": "To appear in the Proceedings of the 2019 ACL Workshop BlackboxNLP:\n  Analyzing and Interpreting Neural Networks for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network architectures have been augmented with differentiable stacks\nin order to introduce a bias toward learning hierarchy-sensitive regularities.\nIt has, however, proven difficult to assess the degree to which such a bias is\neffective, as the operation of the differentiable stack is not always\ninterpretable. In this paper, we attempt to detect the presence of latent\nrepresentations of hierarchical structure through an exploration of the\nunsupervised learning of constituency structure. Using a technique due to Shen\net al. (2018a,b), we extract syntactic trees from the pushing behavior of stack\nRNNs trained on language modeling and classification objectives. We find that\nour models produce parses that reflect natural language syntactic\nconstituencies, demonstrating that stack RNNs do indeed infer linguistically\nrelevant hierarchical structure.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 17:14:26 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Merrill", "William", ""], ["Khazan", "Lenny", ""], ["Amsel", "Noah", ""], ["Hao", "Yiding", ""], ["Mendelsohn", "Simon", ""], ["Frank", "Robert", ""]]}, {"id": "1906.01668", "submitter": "Sandeep Madireddy", "authors": "Sandeep Madireddy, Angel Yanguas-Gil, Prasanna Balaprakash", "title": "Neuromorphic Architecture Optimization for Task-Specific Dynamic\n  Learning", "comments": null, "journal-ref": "Proceedings of the International Conference on Neuromorphic\n  Systems 2019. ACM, New York, NY, USA, Article 5, 5 pages", "doi": "10.1145/3354265.3354270", "report-no": "ANL/MCS-P9175-0419", "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn and adapt in real time is a central feature of\nbiological systems. Neuromorphic architectures demonstrating such versatility\ncan greatly enhance our ability to efficiently process information at the edge.\nA key challenge, however, is to understand which learning rules are best suited\nfor specific tasks and how the relevant hyperparameters can be fine-tuned. In\nthis work, we introduce a conceptual framework in which the learning process is\nintegrated into the network itself. This allows us to cast meta-learning as a\nmathematical optimization problem. We employ DeepHyper, a scalable,\nasynchronous model-based search, to simultaneously optimize the choice of\nmeta-learning rules and their hyperparameters. We demonstrate our approach with\ntwo different datasets, MNIST and FashionMNIST, using a network architecture\ninspired by the learning center of the insect brain. Our results show that\noptimal learning rules can be dataset-dependent even within similar tasks. This\ndependency demonstrates the importance of introducing versatility and\nflexibility in the learning algorithms. It also illuminates experimental\nfindings in insect neuroscience that have shown a heterogeneity of learning\nrules within the insect mushroom body.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 18:20:23 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Madireddy", "Sandeep", ""], ["Yanguas-Gil", "Angel", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "1906.01700", "submitter": "Andreas Brink-Kj{\\ae}r", "authors": "Andreas Brink-Kjaer, Alexander Neergaard Olesen, Paul E. Peppard,\n  Katie L. Stone, Poul Jennum, Emmanuel Mignot, Helge B.D. Sorensen", "title": "Automatic Detection of Cortical Arousals in Sleep and their Contribution\n  to Daytime Sleepiness", "comments": "40 pages, 13 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical arousals are transient events of disturbed sleep that occur\nspontaneously or in response to stimuli such as apneic events. The gold\nstandard for arousal detection in human polysomnographic recordings (PSGs) is\nmanual annotation by expert human scorers, a method with significant\ninterscorer variability. In this study, we developed an automated method, the\nMultimodal Arousal Detector (MAD), to detect arousals using deep learning\nmethods. The MAD was trained on 2,889 PSGs to detect both cortical arousals and\nwakefulness in 1 second intervals. Furthermore, the relationship between\nMAD-predicted labels on PSGs and next day mean sleep latency (MSL) on a\nmultiple sleep latency test (MSLT), a reflection of daytime sleepiness, was\nanalyzed in 1447 MSLT instances in 873 subjects. In a dataset of 1,026 PSGs,\nthe MAD achieved a F1 score of 0.76 for arousal detection, while wakefulness\nwas predicted with an accuracy of 0.95. In 60 PSGs scored by multiple human\nexpert technicians, the MAD significantly outperformed the average human scorer\nfor arousal detection with a difference in F1 score of 0.09. After controlling\nfor other known covariates, a doubling of the arousal index was associated with\nan average decrease in MSL of 40 seconds ($\\beta$ = -0.67, p = 0.0075). The MAD\noutperformed the average human expert and the MAD-predicted arousals were shown\nto be significant predictors of MSL, which demonstrate clinical validity the\nMAD.\n", "versions": [{"version": "v1", "created": "Fri, 15 Mar 2019 10:11:32 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Brink-Kjaer", "Andreas", ""], ["Olesen", "Alexander Neergaard", ""], ["Peppard", "Paul E.", ""], ["Stone", "Katie L.", ""], ["Jennum", "Poul", ""], ["Mignot", "Emmanuel", ""], ["Sorensen", "Helge B. D.", ""]]}, {"id": "1906.01733", "submitter": "Dimitrios Alikaniotis", "authors": "Dimitrios Alikaniotis and Vipul Raheja", "title": "The Unreasonable Effectiveness of Transformer Language Models in\n  Grammatical Error Correction", "comments": "7 pages, 3 tables, accepted at the 14th Workshop on Innovative Use of\n  NLP for Building Educational Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Recent work on Grammatical Error Correction (GEC) has highlighted the\nimportance of language modeling in that it is certainly possible to achieve\ngood performance by comparing the probabilities of the proposed edits. At the\nsame time, advancements in language modeling have managed to generate\nlinguistic output, which is almost indistinguishable from that of\nhuman-generated text. In this paper, we up the ante by exploring the potential\nof more sophisticated language models in GEC and offer some key insights on\ntheir strengths and weaknesses. We show that, in line with recent results in\nother NLP tasks, Transformer architectures achieve consistently high\nperformance and provide a competitive baseline for future machine learning\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 21:28:31 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Alikaniotis", "Dimitrios", ""], ["Raheja", "Vipul", ""]]}, {"id": "1906.01892", "submitter": "Mohammad Ibrahim Sarker", "authors": "Mohammad Ibraim Sarker, Yali Nie, Hong Yongki, Hyongsuk Kim", "title": "Genetic Random Weight Change Algorithm for the Learning of Multilayer\n  Neural Networks", "comments": "4 pages, Published in ISITC 2016 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new method to improve the performance of Random weight change (RWC)\nalgorithm based on a simple genetic algorithm, namely, Genetic random weight\nchange (GRWC) is proposed. It is to find the optimal values of global minima\nvia learning. In contrast to Random Weight Change (RWC), GRWC contains an\neffective optimization procedure which are good at exploring a large and\ncomplex space in an intellectual strategies influenced by the GA/RWC synergy.\nBy implementing our simple GA in RWC we achieve an astounding accuracy of\nfinding global minima.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 09:08:58 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Sarker", "Mohammad Ibraim", ""], ["Nie", "Yali", ""], ["Yongki", "Hong", ""], ["Kim", "Hyongsuk", ""]]}, {"id": "1906.02010", "submitter": "Sujit Khanna", "authors": "Sujit Pramod Khanna and Alexander Ororbia II", "title": "A Hybrid Algorithm for Metaheuristic Optimization", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel, flexible algorithm for combining together\nmetaheuristicoptimizers for non-convex optimization problems. Our approach\ntreatsthe constituent optimizers as a team of complex agents that\ncommunicateinformation amongst each other at various intervals during the\nsimulationprocess. The information produced by each individual agent can be\ncombinedin various ways via higher-level operators. In our experiments on\nkeybenchmark functions, we investigate how the performance of our\nalgorithmvaries with respect to several of its key modifiable properties.\nFinally,we apply our proposed algorithm to classification problems involving\ntheoptimization of support-vector machine classifiers.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 10:45:58 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Khanna", "Sujit Pramod", ""], ["Ororbia", "Alexander", "II"]]}, {"id": "1906.02076", "submitter": "David Calhas", "authors": "David Calhas, Enrique Romero, Rui Henriques", "title": "On the use of Pairwise Distance Learning for Brain Signal Classification\n  with Limited Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE eess.SP q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The increasing access to brain signal data using electroencephalography\ncreates new opportunities to study electrophysiological brain activity and\nperform ambulatory diagnoses of neuronal diseases. This work proposes a\npairwise distance learning approach for Schizophrenia classification relying on\nthe spectral properties of the signal. Given the limited number of observations\n(i.e. the case and/or control individuals) in clinical trials, we propose a\nSiamese neural network architecture to learn a discriminative feature space\nfrom pairwise combinations of observations per channel. In this way, the\nmultivariate order of the signal is used as a form of data augmentation,\nfurther supporting the network generalization ability. Convolutional layers\nwith parameters learned under a cosine contrastive loss are proposed to\nadequately explore spectral images derived from the brain signal. Results on a\ncase-control population show that the features extracted using the proposed\nneural network lead to an improved Schizophrenia diagnosis (+10pp in accuracy\nand sensitivity) against spectral features, thus suggesting the existence of\nnon-trivial, discriminative electrophysiological brain patterns.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 15:36:57 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 11:40:27 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Calhas", "David", ""], ["Romero", "Enrique", ""], ["Henriques", "Rui", ""]]}, {"id": "1906.02386", "submitter": "Kaiwen Li", "authors": "Kaiwen Li, Tao Zhang, and Rui Wang", "title": "Deep Reinforcement Learning for Multi-objective Optimization", "comments": null, "journal-ref": "IEEE Transactions on Cybernetics, 1-12 (18 March 2020)", "doi": "10.1109/TCYB.2020.2977661", "report-no": null, "categories": "cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes an end-to-end framework for solving multi-objective\noptimization problems (MOPs) using Deep Reinforcement Learning (DRL), that we\ncall DRL-MOA. The idea of decomposition is adopted to decompose the MOP into a\nset of scalar optimization subproblems. Then each subproblem is modelled as a\nneural network. Model parameters of all the subproblems are optimized\ncollaboratively according to a neighborhood-based parameter-transfer strategy\nand the DRL training algorithm. Pareto optimal solutions can be directly\nobtained through the trained neural network models. In specific, the\nmulti-objective travelling salesman problem (MOTSP) is solved in this work\nusing the DRL-MOA method by modelling the subproblem as a Pointer Network.\nExtensive experiments have been conducted to study the DRL-MOA and various\nbenchmark methods are compared with it. It is found that, once the trained\nmodel is available, it can scale to newly encountered problems with no need of\nre-training the model. The solutions can be directly obtained by a simple\nforward calculation of the neural network; thereby, no iteration is required\nand the MOP can be always solved in a reasonable time. The proposed method\nprovides a new way of solving the MOP by means of DRL. It has shown a set of\nnew characteristics, e.g., strong generalization ability and fast solving speed\nin comparison with the existing methods for multi-objective optimizations.\nExperimental results show the effectiveness and competitiveness of the proposed\nmethod in terms of model performance and running time.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 02:24:06 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 04:03:47 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Li", "Kaiwen", ""], ["Zhang", "Tao", ""], ["Wang", "Rui", ""]]}, {"id": "1906.02446", "submitter": "Payam Siyari", "authors": "Payam Siyari, Bistra Dilkina, Constantine Dovrolis", "title": "Evolution of Hierarchical Structure & Reuse in iGEM Synthetic DNA\n  Sequences", "comments": "arXiv admin note: substantial text overlap with arXiv:1805.04924", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.SI stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many complex systems, both in technology and nature, exhibit hierarchical\nmodularity: smaller modules, each of them providing a certain function, are\nused within larger modules that perform more complex functions. Previously, we\nhave proposed a modeling framework, referred to as Evo-Lexis, that provides\ninsight to some fundamental questions about evolving hierarchical systems.\n  The predictions of the Evo-Lexis model should be tested using real data from\nevolving systems in which the outputs can be well represented by sequences. In\nthis paper, we investigate the time series of iGEM synthetic DNA dataset\nsequences, and whether the resulting iGEM hierarchies exhibit the qualitative\nproperties predicted by the Evo-Lexis framework. Contrary to Evo-Lexis, in iGEM\nthe amount of reuse decreases during the timeline of the dataset. Although this\nresults in development of less cost-efficient and less deep Lexis-DAGs, the\ndataset exhibits a bias in reusing specific nodes more often than others. This\nresults in the Lexis-DAGs to take the shape of an hourglass with relatively\nhigh H-score values and stable set of core nodes. Despite the reuse bias and\nstability of the core set, the dataset presents a high amount of diversity\namong the targets which is in line with modeling of Evo-Lexis.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 07:15:33 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Siyari", "Payam", ""], ["Dilkina", "Bistra", ""], ["Dovrolis", "Constantine", ""]]}, {"id": "1906.02474", "submitter": "Sini\\v{s}a Dru\\v{z}eta", "authors": "Sini\\v{s}a Dru\\v{z}eta, Stefan Ivi\\'c, Luka Grb\\v{c}i\\'c, Ivana\n  Lu\\v{c}in", "title": "Introducing languid particle dynamics to a selection of PSO variants", "comments": "13 pages, 10 tables, 1 figure. Egyptian Informatics Journal, 2019", "journal-ref": null, "doi": "10.1016/j.eij.2019.11.005", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research showed that conditioning a PSO agent's movement based on\nits personal fitness improvement enhances the standard PSO method. In this\narticle, languid particle dynamics (LPD) technique is used on five adequate and\nwidely used PSO variants. Five unmodified PSO variants were tested against\ntheir LPD-implemented counterparts on three search space dimensionalities (10,\n20, and 50 dimensions) and 30 test functions of the CEC 2014 benchmark test. In\nthe preliminary phase of the testing four of the five tested PSO variants\nshowed improvement in accuracy. The worst and best-achieving variants from\npreliminary test went through detailed investigation on 220 and 770\ncombinations of method parameters, where both variants showed overall gains in\naccuracy when enhanced with LPD. Finally, the results obtained with best\nachieving PSO parameters were subject to statistical analysis which showed that\nthe two variants give statistically significant improvements in accuracy for\n13-50% of the test functions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 08:28:39 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Dru\u017eeta", "Sini\u0161a", ""], ["Ivi\u0107", "Stefan", ""], ["Grb\u010di\u0107", "Luka", ""], ["Lu\u010din", "Ivana", ""]]}, {"id": "1906.02487", "submitter": "Qiulei Dong", "authors": "Qiulei Dong and Bo Liu and Zhanyi Hu", "title": "Non-uniqueness phenomenon of object representation in modelling IT\n  cortex by deep convolutional neural network (DCNN)", "comments": "24 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently DCNN (Deep Convolutional Neural Network) has been advocated as a\ngeneral and promising modelling approach for neural object representation in\nprimate inferotemporal cortex. In this work, we show that some inherent\nnon-uniqueness problem exists in the DCNN-based modelling of image object\nrepresentations. This non-uniqueness phenomenon reveals to some extent the\ntheoretical limitation of this general modelling approach, and invites due\nattention to be taken in practice.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 09:08:21 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Dong", "Qiulei", ""], ["Liu", "Bo", ""], ["Hu", "Zhanyi", ""]]}, {"id": "1906.02568", "submitter": "Felix Wiewel", "authors": "Felix Wiewel and Bin Yang", "title": "Localizing Catastrophic Forgetting in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks (ANNs) suffer from catastrophic forgetting when\ntrained on a sequence of tasks. While this phenomenon was studied in the past,\nthere is only very limited recent research on this phenomenon. We propose a\nmethod for determining the contribution of individual parameters in an ANN to\ncatastrophic forgetting. The method is used to analyze an ANNs response to\nthree different continual learning scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 13:18:03 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Wiewel", "Felix", ""], ["Yang", "Bin", ""]]}, {"id": "1906.02671", "submitter": "Nicholas Waytowich", "authors": "Nicholas Waytowich, Sean L. Barton, Vernon Lawhern, Ethan Stump and\n  Garrett Warnell", "title": "Grounding Natural Language Commands to StarCraft II Game States for\n  Narration-Guided Reinforcement Learning", "comments": "10 pages, 3 figures. Published at SPIE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CL cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep reinforcement learning techniques have led to agents that are\nsuccessfully able to learn to perform a number of tasks that had been\npreviously unlearnable, these techniques are still susceptible to the\nlongstanding problem of {\\em reward sparsity}. This is especially true for\ntasks such as training an agent to play StarCraft II, a real-time strategy game\nwhere reward is only given at the end of a game which is usually very long.\nWhile this problem can be addressed through reward shaping, such approaches\ntypically require a human expert with specialized knowledge. Inspired by the\nvision of enabling reward shaping through the more-accessible paradigm of\nnatural-language narration, we investigate to what extent we can contextualize\nthese narrations by grounding them to the goal-specific states. We present a\nmutual-embedding model using a multi-input deep-neural network that projects a\nsequence of natural language commands into the same high-dimensional\nrepresentation space as corresponding goal states. We show that using this\nmodel we can learn an embedding space with separable and distinct clusters that\naccurately maps natural-language commands to corresponding game states . We\nalso discuss how this model can allow for the use of narrations as a robust\nform of reward shaping to improve RL performance and efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 17:43:40 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Waytowich", "Nicholas", ""], ["Barton", "Sean L.", ""], ["Lawhern", "Vernon", ""], ["Stump", "Ethan", ""], ["Warnell", "Garrett", ""]]}, {"id": "1906.02680", "submitter": "Andrey Velichko", "authors": "Andrei Velichko", "title": "A Method for Evaluating Chimeric Synchronization of Coupled Oscillators\n  and Its Application for Creating a Neural Network Information Converter", "comments": "25 pages, 20 figures", "journal-ref": "Electronics 2019, 8(7), 756", "doi": "10.3390/electronics8070756", "report-no": null, "categories": "nlin.AO cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a new method for evaluating the synchronization of\nquasi-periodic oscillations of two oscillators, termed \"chimeric\nsynchronization\". The family of metrics is proposed to create a neural network\ninformation converter based on a network of pulsed oscillators. In addition to\ntransforming input information from digital to analogue, the converter can\nperform information processing after training the network by selecting control\nparameters. In the proposed neural network scheme, the data arrives at the\ninput layer in the form of current levels of the oscillators and is converted\ninto a set of non-repeating states of the chimeric synchronization of the\noutput oscillator. By modelling a thermally coupled VO2-oscillator circuit, the\nnetwork setup is demonstrated through the selection of coupling strength, power\nsupply levels, and the synchronization efficiency parameter. The distribution\nof solutions depending on the operating mode of the oscillators, sub-threshold\nmode, or generation mode are revealed. Technological approaches for the\nimplementation of a neural network information converter are proposed, and\nexamples of its application for image filtering are demonstrated. The proposed\nmethod helps to significantly expand the capabilities of neuromorphic and\nlogical devices based on synchronization effects.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 16:26:41 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 13:24:11 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Velichko", "Andrei", ""]]}, {"id": "1906.02698", "submitter": "Malte J. Rasch", "authors": "Malte J. Rasch and Tayfun Gokmen and Wilfried Haensch", "title": "Training large-scale ANNs on simulated resistive crossbar arrays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerating training of artificial neural networks (ANN) with analog\nresistive crossbar arrays is a promising idea. While the concept has been\nverified on very small ANNs and toy data sets (such as MNIST), more\nrealistically sized ANNs and datasets have not yet been tackled. However, it is\nto be expected that device materials and hardware design constraints, such as\nnoisy computations, finite number of resistive states of the device materials,\nsaturating weight and activation ranges, and limited precision of\nanalog-to-digital converters, will cause significant challenges to the\nsuccessful training of state-of-the-art ANNs. By using analog hardware aware\nANN training simulations, we here explore a number of simple algorithmic\ncompensatory measures to cope with analog noise and limited weight and output\nranges and resolutions, that dramatically improve the simulated training\nperformances on RPU arrays on intermediately to large-scale ANNs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 16:56:28 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Rasch", "Malte J.", ""], ["Gokmen", "Tayfun", ""], ["Haensch", "Wilfried", ""]]}, {"id": "1906.02768", "submitter": "Ari Morcos", "authors": "Haonan Yu, Sergey Edunov, Yuandong Tian, and Ari S. Morcos", "title": "Playing the lottery with rewards and multiple languages: lottery tickets\n  in RL and NLP", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lottery ticket hypothesis proposes that over-parameterization of deep\nneural networks (DNNs) aids training by increasing the probability of a \"lucky\"\nsub-network initialization being present rather than by helping the\noptimization process (Frankle & Carbin, 2019). Intriguingly, this phenomenon\nsuggests that initialization strategies for DNNs can be improved substantially,\nbut the lottery ticket hypothesis has only previously been tested in the\ncontext of supervised learning for natural image tasks. Here, we evaluate\nwhether \"winning ticket\" initializations exist in two different domains:\nnatural language processing (NLP) and reinforcement learning (RL).For NLP, we\nexamined both recurrent LSTM models and large-scale Transformer models (Vaswani\net al., 2017). For RL, we analyzed a number of discrete-action space tasks,\nincluding both classic control and pixel control. Consistent with workin\nsupervised image classification, we confirm that winning ticket initializations\ngenerally outperform parameter-matched random initializations, even at extreme\npruning rates for both NLP and RL. Notably, we are able to find winning ticket\ninitializations for Transformers which enable models one-third the size to\nachieve nearly equivalent performance. Together, these results suggest that the\nlottery ticket hypothesis is not restricted to supervised learning of natural\nimages, but rather represents a broader phenomenon in DNNs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 18:38:38 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 17:33:34 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 21:50:07 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Yu", "Haonan", ""], ["Edunov", "Sergey", ""], ["Tian", "Yuandong", ""], ["Morcos", "Ari S.", ""]]}, {"id": "1906.02773", "submitter": "Ari Morcos", "authors": "Ari S. Morcos, Haonan Yu, Michela Paganini, and Yuandong Tian", "title": "One ticket to win them all: generalizing lottery ticket initializations\n  across datasets and optimizers", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of lottery ticket initializations (Frankle and Carbin, 2019)\nsuggests that small, sparsified networks can be trained so long as the network\nis initialized appropriately. Unfortunately, finding these \"winning ticket\"\ninitializations is computationally expensive. One potential solution is to\nreuse the same winning tickets across a variety of datasets and optimizers.\nHowever, the generality of winning ticket initializations remains unclear.\nHere, we attempt to answer this question by generating winning tickets for one\ntraining configuration (optimizer and dataset) and evaluating their performance\non another configuration. Perhaps surprisingly, we found that, within the\nnatural images domain, winning ticket initializations generalized across a\nvariety of datasets, including Fashion MNIST, SVHN, CIFAR-10/100, ImageNet, and\nPlaces365, often achieving performance close to that of winning tickets\ngenerated on the same dataset. Moreover, winning tickets generated using larger\ndatasets consistently transferred better than those generated using smaller\ndatasets. We also found that winning ticket initializations generalize across\noptimizers with high performance. These results suggest that winning ticket\ninitializations generated by sufficiently large datasets contain inductive\nbiases generic to neural networks more broadly which improve training across\nmany settings and provide hope for the development of better initialization\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 18:46:39 GMT"}, {"version": "v2", "created": "Sun, 27 Oct 2019 18:10:27 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Morcos", "Ari S.", ""], ["Yu", "Haonan", ""], ["Paganini", "Michela", ""], ["Tian", "Yuandong", ""]]}, {"id": "1906.02796", "submitter": "Wilkie Olin-Ammentorp", "authors": "Wilkie Olin-Ammentorp, Karsten Beckmann, Catherine D. Schuman, James\n  S. Plank, Nathaniel C. Cady", "title": "Stochasticity and Robustness in Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks normally require precise weights to operate,\ndespite their origins in biological systems, which can be highly variable and\nnoisy. When implementing artificial networks which utilize analog 'synaptic'\ndevices to encode weights, however, inherent limits are placed on the accuracy\nand precision with which these values can be encoded. In this work, we\ninvestigate the effects that inaccurate synapses have on spiking neurons and\nspiking neural networks. Starting with a mathematical analysis of\nintegrate-and-fire (IF) neurons, including different non-idealities (such as\nleakage and channel noise), we demonstrate that noise can be used to make the\nbehavior of IF neurons more robust to synaptic inaccuracy. We then train\nspiking networks which utilize IF neurons with and without noise and leakage,\nand experimentally confirm that the noisy networks are more robust. Lastly, we\nshow that a noisy network can tolerate the inaccuracy expected when\nhafnium-oxide based resistive random-access memory is used to encode synaptic\nweights.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 20:16:46 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Olin-Ammentorp", "Wilkie", ""], ["Beckmann", "Karsten", ""], ["Schuman", "Catherine D.", ""], ["Plank", "James S.", ""], ["Cady", "Nathaniel C.", ""]]}, {"id": "1906.02876", "submitter": "Urmish Thakker", "authors": "Urmish Thakker, Jesse Beu, Dibakar Gope, Chu Zhou, Igor Fedorov,\n  Ganesh Dasika, Matthew Mattina", "title": "Compressing RNNs for IoT devices by 15-38x using Kronecker Products", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNN) can be difficult to deploy on resource\nconstrained devices due to their size.As a result, there is a need for\ncompression techniques that can significantly compress RNNs without negatively\nimpacting task accuracy. This paper introduces a method to compress RNNs for\nresource constrained environments using Kronecker product (KP). KPs can\ncompress RNN layers by 15-38x with minimal accuracy loss. By quantizing the\nresulting models to 8-bits, we further push the compression factor to 50x. We\nshow that KP can beat the task accuracy achieved by other state-of-the-art\ncompression techniques across 5 benchmarks spanning 3 different applications,\nwhile simultaneously improving inference run-time. We show that the KP\ncompression mechanism does introduce an accuracy loss, which can be mitigated\nby a proposed hybrid KP (HKP) approach. Our HKP algorithm provides fine-grained\ncontrol over the compression ratio, enabling us to regain accuracy lost during\ncompression by adding a small number of model parameters.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 03:09:23 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 02:00:13 GMT"}, {"version": "v3", "created": "Tue, 18 Jun 2019 23:24:24 GMT"}, {"version": "v4", "created": "Sun, 5 Jan 2020 21:35:07 GMT"}, {"version": "v5", "created": "Fri, 31 Jan 2020 05:36:19 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Thakker", "Urmish", ""], ["Beu", "Jesse", ""], ["Gope", "Dibakar", ""], ["Zhou", "Chu", ""], ["Fedorov", "Igor", ""], ["Dasika", "Ganesh", ""], ["Mattina", "Matthew", ""]]}, {"id": "1906.02909", "submitter": "Wei Wen", "authors": "Wei Wen, Feng Yan, Yiran Chen, Hai Li", "title": "AutoGrow: Automatic Layer Growing in Deep Convolutional Networks", "comments": "KDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depth is a key component of Deep Neural Networks (DNNs), however, designing\ndepth is heuristic and requires many human efforts. We propose AutoGrow to\nautomate depth discovery in DNNs: starting from a shallow seed architecture,\nAutoGrow grows new layers if the growth improves the accuracy; otherwise, stops\ngrowing and thus discovers the depth. We propose robust growing and stopping\npolicies to generalize to different network architectures and datasets. Our\nexperiments show that by applying the same policy to different network\narchitectures, AutoGrow can always discover near-optimal depth on various\ndatasets of MNIST, FashionMNIST, SVHN, CIFAR10, CIFAR100 and ImageNet. For\nexample, in terms of accuracy-computation trade-off, AutoGrow discovers a\nbetter depth combination in ResNets than human experts. Our AutoGrow is\nefficient. It discovers depth within similar time of training a single DNN. Our\ncode is available at https://github.com/wenwei202/autogrow.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 05:54:41 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 01:57:53 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 00:04:22 GMT"}, {"version": "v4", "created": "Wed, 10 Jun 2020 17:06:41 GMT"}, {"version": "v5", "created": "Mon, 15 Jun 2020 18:09:02 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Wen", "Wei", ""], ["Yan", "Feng", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "1906.03139", "submitter": "Karel Lenc", "authors": "Karel Lenc, Erich Elsen, Tom Schaul, Karen Simonyan", "title": "Non-Differentiable Supervised Learning with Evolution Strategies and\n  Hybrid Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we show that Evolution Strategies (ES) are a viable method for\nlearning non-differentiable parameters of large supervised models. ES are\nblack-box optimization algorithms that estimate distributions of model\nparameters; however they have only been used for relatively small problems so\nfar. We show that it is possible to scale ES to more complex tasks and models\nwith millions of parameters. While using ES for differentiable parameters is\ncomputationally impractical (although possible), we show that a hybrid approach\nis practically feasible in the case where the model has both differentiable and\nnon-differentiable parameters. In this approach we use standard gradient-based\nmethods for learning differentiable weights, while using ES for learning\nnon-differentiable parameters - in our case sparsity masks of the weights. This\nproposed method is surprisingly competitive, and when parallelized over\nmultiple devices has only negligible training time overhead compared to\ntraining with gradient descent. Additionally, this method allows to train\nsparse models from the first training step, so they can be much larger than\nwhen using methods that require training dense models first. We present results\nand analysis of supervised feed-forward models (such as MNIST and CIFAR-10\nclassification), as well as recurrent models, such as SparseWaveRNN for\ntext-to-speech.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 14:52:19 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Lenc", "Karel", ""], ["Elsen", "Erich", ""], ["Schaul", "Tom", ""], ["Simonyan", "Karen", ""]]}, {"id": "1906.03181", "submitter": "Haibin Zheng", "authors": "Jinyin Chen, Mengmeng Su, Shijing Shen, Hui Xiong, Haibin Zheng", "title": "POBA-GA: Perturbation Optimized Black-Box Adversarial Attacks via\n  Genetic Algorithm", "comments": null, "journal-ref": "Computers and Security, Volume 85, August 2019, Pages 89-106", "doi": "10.1016/j.cose.2019.04.014", "report-no": null, "categories": "cs.CR cs.LG cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep learning models are easily vulnerable to adversarial attacks.\nVarious adversarial attacks are designed to evaluate the robustness of models\nand develop defense model. Currently, adversarial attacks are brought up to\nattack their own target model with their own evaluation metrics. And most of\nthe black-box adversarial attack algorithms cannot achieve the expected success\nrate compared with white-box attacks. In this paper, comprehensive evaluation\nmetrics are brought up for different adversarial attack methods. A novel\nperturbation optimized black-box adversarial attack based on genetic algorithm\n(POBA-GA) is proposed for achieving white-box comparable attack performances.\nApproximate optimal adversarial examples are evolved through evolutionary\noperations including initialization, selection, crossover and mutation. Fitness\nfunction is specifically designed to evaluate the example individual in both\naspects of attack ability and perturbation control. Population diversity\nstrategy is brought up in evolutionary process to promise the approximate\noptimal perturbations obtained. Comprehensive experiments are carried out to\ntestify POBA-GA's performances. Both simulation and application results prove\nthat our method is better than current state-of-art black-box attack methods in\naspects of attack capability and perturbation control.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 05:18:53 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Chen", "Jinyin", ""], ["Su", "Mengmeng", ""], ["Shen", "Shijing", ""], ["Xiong", "Hui", ""], ["Zheng", "Haibin", ""]]}, {"id": "1906.03186", "submitter": "Thomas Carroll", "authors": "Thomas L. Carroll", "title": "Mutual Information and the Edge of Chaos in Reservoir Computers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A reservoir computer is a dynamical system that may be used to perform\ncomputations. A reservoir computer usually consists of a set of nonlinear nodes\ncoupled together in a network so that there are feedback paths. Training the\nreservoir computer consists of inputing a signal of interest and fitting the\ntime series signals of the reservoir computer nodes to a training signal that\nis related to the input signal. It is believed that dynamical systems function\nmost efficiently as computers at the \"edge of chaos\", the point at which the\nlargest Lyapunov exponent of the dynamical system transitions from negative to\npositive. In this work I simulate several different reservoir computers and ask\nif the best performance really does come at this edge of chaos. I find that\nwhile it is possible to get optimum performance at the edge of chaos, there may\nalso be parameter values where the edge of chaos regime produces poor\nperformance. This ambiguous parameter dependance has implications for building\nreservoir computers from analog physical systems, where the parameter range is\nrestricted.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 16:08:23 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 13:47:33 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Carroll", "Thomas L.", ""]]}, {"id": "1906.03223", "submitter": "Jialong Shi", "authors": "Jialong Shi, Jianyong Sun, Qingfu Zhang, Kai Ye", "title": "Homotopic Convex Transformation: A New Landscape Smoothing Method for\n  the Traveling Salesman Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel landscape smoothing method for the symmetric\nTraveling Salesman Problem (TSP). We first define the Homotopic Convex (HC)\ntransformation of a TSP as a convex combination of a well-constructed simple\nTSP and the original TSP. The simple TSP, called the convex-hull TSP, is\nconstructed by transforming a known local or global optimum. We observe that\ncontrolled by the coefficient of the convex combination, with local or global\noptimum, (i) the landscape of the HC transformed TSP is smoothed in terms that\nits number of local optima is reduced compared to the original TSP; (ii) the\nfitness distance correlation of the HC transformed TSP is increased. Further,\nwe observe that the smoothing effect of the HC transformation depends highly on\nthe quality of the used optimum. A high-quality optimum leads to a better\nsmoothing effect than a low-quality optimum. We then propose an iterative\nalgorithmic framework in which the proposed HC transformation is combined\nwithin a heuristic TSP solver. It works as an escaping scheme from local optima\naiming to improve the global search ability of the combined heuristic. Case\nstudies using the 3-Opt and the Lin-Kernighan local search as the heuristic\nsolver show that the resultant algorithms significantly outperform their\ncounterparts and two other smoothing-based TSP heuristic solvers on most of the\ntest instances with up to 20,000 cities.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:48:21 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 03:14:24 GMT"}, {"version": "v3", "created": "Sat, 14 Mar 2020 10:08:49 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Shi", "Jialong", ""], ["Sun", "Jianyong", ""], ["Zhang", "Qingfu", ""], ["Ye", "Kai", ""]]}, {"id": "1906.03280", "submitter": "James McDermott", "authors": "James McDermott", "title": "When and Why Metaheuristics Researchers Can Ignore \"No Free Lunch\"\n  Theorems", "comments": null, "journal-ref": "Springer Metaheuristics 2019", "doi": "10.1007/s42257-019-00002-6", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The No Free Lunch (NFL) theorem for search and optimisation states that\naveraged across all possible objective functions on a fixed search space, all\nsearch algorithms perform equally well. Several refined versions of the theorem\nfind a similar outcome when averaging across smaller sets of functions. This\npaper argues that NFL results continue to be misunderstood by many researchers,\nand addresses this issue in several ways. Existing arguments against real-world\nimplications of NFL results are collected and re-stated for accessibility, and\nnew ones are added. Specific misunderstandings extant in the literature are\nidentified, with speculation as to how they may have arisen. This paper\npresents an argument against a common paraphrase of NFL findings -- that\nalgorithms must be specialised to problem domains in order to do well -- after\nproblematising the usually undefined term \"domain\". It provides novel concrete\ncounter-examples illustrating cases where NFL theorems do not apply. In\nconclusion it offers a novel view of the real meaning of NFL, incorporating the\nanthropic principle and justifying the position that in many common situations\nresearchers can ignore NFL.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 18:11:11 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["McDermott", "James", ""]]}, {"id": "1906.03291", "submitter": "Wenqian Ronny Huang", "authors": "W. Ronny Huang, Zeyad Emam, Micah Goldblum, Liam Fowl, Justin K.\n  Terry, Furong Huang, Tom Goldstein", "title": "Understanding Generalization through Visualizations", "comments": "8 pages (excluding acknowledgments and references), 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The power of neural networks lies in their ability to generalize to unseen\ndata, yet the underlying reasons for this phenomenon remain elusive. Numerous\nrigorous attempts have been made to explain generalization, but available\nbounds are still quite loose, and analysis does not always lead to true\nunderstanding. The goal of this work is to make generalization more intuitive.\nUsing visualization methods, we discuss the mystery of generalization, the\ngeometry of loss landscapes, and how the curse (or, rather, the blessing) of\ndimensionality causes optimizers to settle into minima that generalize well.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 18:43:20 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 07:35:35 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 06:25:25 GMT"}, {"version": "v4", "created": "Tue, 16 Jul 2019 20:23:52 GMT"}, {"version": "v5", "created": "Sun, 28 Jun 2020 03:04:17 GMT"}, {"version": "v6", "created": "Sun, 15 Nov 2020 00:16:15 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Huang", "W. Ronny", ""], ["Emam", "Zeyad", ""], ["Goldblum", "Micah", ""], ["Fowl", "Liam", ""], ["Terry", "Justin K.", ""], ["Huang", "Furong", ""], ["Goldstein", "Tom", ""]]}, {"id": "1906.03314", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Secrets of the Brain: An Introduction to the Brain Anatomical Structure\n  and Biological Function", "comments": "34 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we will provide an introduction to the brain structure and\nfunction. Brain is an astonishing living organ inside our heads, weighing about\n1.5kg, consisting of billions of tiny cells. The brain enables us to sense the\nworld around us (to touch, to smell, to see and to hear, etc.), to think and to\nrespond to the world as well. The main obstacles that prevent us from creating\na machine which can behavior like real-world creatures are due to our limited\nknowledge about the brain in both its structure and its function. In this\npaper, we will focus introducing the brain anatomical structure and biological\nfunction, as well as its surrounding sensory systems. Many of the materials\nused in this paper are from wikipedia and several other neuroscience\nintroductory articles, which will be properly cited in this article. This is\nthe first of the three tutorial articles about the brain (the other two are\n[26] and [27]). In the follow-up two articles, we will further introduce the\nlow-level composition basis structures (e.g., neuron, synapse and action\npotential) and the high-level cognitive functions (e.g., consciousness,\nattention, learning and memory) of the brain, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 03:07:33 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "1906.03417", "submitter": "Aydogan Ozcan", "authors": "Jingxi Li, Deniz Mengu, Yi Luo, Yair Rivenson, Aydogan Ozcan", "title": "Class-specific Differential Detection in Diffractive Optical Neural\n  Networks Improves Inference Accuracy", "comments": "21 pages, 6 Figures, 3 Tables", "journal-ref": "Advanced Photonics (2019)", "doi": "10.1117/1.AP.1.4.046001", "report-no": null, "categories": "cs.NE cs.LG eess.IV physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffractive deep neural networks have been introduced earlier as an optical\nmachine learning framework that uses task-specific diffractive surfaces\ndesigned by deep learning to all-optically perform inference, achieving\npromising performance for object classification and imaging. Here we\ndemonstrate systematic improvements in diffractive optical neural networks\nbased on a differential measurement technique that mitigates the non-negativity\nconstraint of light intensity. In this scheme, each class is assigned to a\nseparate pair of photodetectors, behind a diffractive network, and the class\ninference is made by maximizing the normalized signal difference between the\ndetector pairs. Moreover, by utilizing the inherent parallelization capability\nof optical systems, we reduced the signal coupling between the positive and\nnegative detectors of each class by dividing their optical path into two\njointly-trained diffractive neural networks that work in parallel. We further\nmade use of this parallelization approach, and divided individual classes among\nmultiple jointly-trained differential diffractive neural networks. Using this\nclass-specific differential detection in jointly-optimized diffractive\nnetworks, our simulations achieved testing accuracies of 98.52%, 91.48% and\n50.82% for MNIST, Fashion-MNIST and grayscale CIFAR-10 datasets, respectively.\nSimilar to ensemble methods practiced in machine learning, we also\nindependently-optimized multiple differential diffractive networks that\noptically project their light onto a common detector plane, and achieved\ntesting accuracies of 98.59%, 91.06% and 51.44% for MNIST, Fashion-MNIST and\ngrayscale CIFAR-10, respectively. Through these systematic advances in\ndesigning diffractive neural networks, the reported classification accuracies\nset the state-of-the-art for an all-optical neural network design.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 08:31:04 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 20:38:21 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Li", "Jingxi", ""], ["Mengu", "Deniz", ""], ["Luo", "Yi", ""], ["Rivenson", "Yair", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "1906.03504", "submitter": "Michael Iuzzolino", "authors": "Michael Iuzzolino, Yoram Singer, Michael C. Mozer", "title": "Convolutional Bipartite Attractor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In human perception and cognition, a fundamental operation that brains\nperform is interpretation: constructing coherent neural states from noisy,\nincomplete, and intrinsically ambiguous evidence. The problem of interpretation\nis well matched to an early and often overlooked architecture, the attractor\nnetwork---a recurrent neural net that performs constraint satisfaction,\nimputation of missing features, and clean up of noisy data via energy\nminimization dynamics. We revisit attractor nets in light of modern deep\nlearning methods and propose a convolutional bipartite architecture with a\nnovel training loss, activation function, and connectivity constraints. We\ntackle larger problems than have been previously explored with attractor nets\nand demonstrate their potential for image completion and super-resolution. We\nargue that this architecture is better motivated than ever-deeper feedforward\nmodels and is a viable alternative to more costly sampling-based generative\nmethods on a range of supervised and unsupervised tasks.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 19:13:26 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 03:20:12 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 23:39:37 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Iuzzolino", "Michael", ""], ["Singer", "Yoram", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1906.03959", "submitter": "Jean-Philippe Bruneton", "authors": "J.-P. Bruneton, L. Cazenille, A. Douin, V. Reverdy", "title": "Exploration and Exploitation in Symbolic Regression using\n  Quality-Diversity and Evolutionary Strategies Algorithms", "comments": "11 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By combining Genetic Programming, MAP-Elites and Covariance Matrix Adaptation\nEvolution Strategy, we demonstrate very high success rates in Symbolic\nRegression problems. MAP-Elites is used to improve exploration while preserving\ndiversity and avoiding premature convergence and bloat. Then, a Covariance\nMatrix Adaptation-Evolution Strategy is used to evaluate free scalars through a\nnon-gradient-based black-box optimizer. Although this evaluation approach is\nnot computationally scalable to high dimensional problems, our algorithm is\nable to find exactly most of the $31$ targets extracted from the literature on\nwhich we evaluate it.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 13:03:16 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Bruneton", "J. -P.", ""], ["Cazenille", "L.", ""], ["Douin", "A.", ""], ["Reverdy", "V.", ""]]}, {"id": "1906.03967", "submitter": "Adrien Laversanne-Finot", "authors": "Adrien Laversanne-Finot and Alexandre P\\'er\\'e and Pierre-Yves Oudeyer", "title": "Autonomous Goal Exploration using Learned Goal Spaces for Visuomotor\n  Skill Acquisition in Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automatic and efficient discovery of skills, without supervision, for\nlong-living autonomous agents, remains a challenge of Artificial Intelligence.\nIntrinsically Motivated Goal Exploration Processes give learning agents a\nhuman-inspired mechanism to sequentially select goals to achieve. This approach\ngives a new perspective on the lifelong learning problem, with promising\nresults on both simulated and real-world experiments. Until recently, those\nalgorithms were restricted to domains with experimenter-knowledge, since the\nGoal Space used by the agents was built on engineered feature extractors. The\nrecent advances of deep representation learning, enables new ways of designing\nthose feature extractors, using directly the agent experience. Recent work has\nshown the potential of those methods on simple yet challenging simulated\ndomains. In this paper, we present recent results showing the applicability of\nthose principles on a real-world robotic setup, where a 6-joint robotic arm\nlearns to manipulate a ball inside an arena, by choosing goals in a space\nlearned from its past experience.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 13:31:12 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Laversanne-Finot", "Adrien", ""], ["P\u00e9r\u00e9", "Alexandre", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1906.03973", "submitter": "Jaakko Lehtinen", "authors": "Markus Kettunen, Erik H\\\"ark\\\"onen, Jaakko Lehtinen", "title": "E-LPIPS: Robust Perceptual Image Similarity via Random Transformation\n  Ensembles", "comments": "Code and supplemental material available at\n  https://github.com/mkettune/elpips/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  It has been recently shown that the hidden variables of convolutional neural\nnetworks make for an efficient perceptual similarity metric that accurately\npredicts human judgment on relative image similarity assessment. First, we show\nthat such learned perceptual similarity metrics (LPIPS) are susceptible to\nadversarial attacks that dramatically contradict human visual similarity\njudgment. While this is not surprising in light of neural networks' well-known\nweakness to adversarial perturbations, we proceed to show that self-ensembling\nwith an infinite family of random transformations of the input --- a technique\nknown not to render classification networks robust --- is enough to turn the\nmetric robust against attack, while retaining predictive power on human\njudgments. Finally, we study the geometry imposed by our our novel\nself-ensembled metric (E-LPIPS) on the space of natural images. We find\nevidence of \"perceptual convexity\" by showing that convex combinations of\nsimilar-looking images retain appearance, and that discrete geodesics yield\nmeaningful frame interpolation and texture morphing, all without explicit\ncorrespondences.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 13:40:37 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2019 08:58:35 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Kettunen", "Markus", ""], ["H\u00e4rk\u00f6nen", "Erik", ""], ["Lehtinen", "Jaakko", ""]]}, {"id": "1906.03997", "submitter": "Christoph Salge", "authors": "Daniel Ashlock and Christoph Salge", "title": "The Riddle of Togelby", "comments": "8 pages, in proceedings of 2019 IEEE Conference on Games, COG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the 2017 Artificial and Computational Intelligence in Games meeting at\nDagstuhl, Julian Togelius asked how to make spaces where every way of filling\nin the details yielded a good game. This study examines the possibility of\nenriching search spaces so that they contain very high rates of interesting\nobjects, specifically game elements. While we do not answer the full challenge\nof finding good games throughout the space, this study highlights a number of\npotential avenues. These include naturally rich spaces, a simple technique for\nmodifying a representation to search only rich parts of a larger search space,\nand representations that are highly expressive and so exhibit highly restricted\nand consequently enriched search spaces.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 14:16:02 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Ashlock", "Daniel", ""], ["Salge", "Christoph", ""]]}, {"id": "1906.04050", "submitter": "Hormoz Shahrzad", "authors": "Hormoz Shahrzad, Babak Hodjat, Camille Doll\\'e, Andrei Denissov, Simon\n  Lau, Donn Goodhew, Justin Dyer, Risto Miikkulainen", "title": "Enhanced Optimization with Composite Objectives and Novelty Pulsation", "comments": "arXiv admin note: substantial text overlap with arXiv:1803.03744", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important benefit of multi-objective search is that it maintains a diverse\npopulation of candidates, which helps in deceptive problems in particular. Not\nall diversity is useful, however: candidates that optimize only one objective\nwhile ignoring others are rarely helpful. A recent solution is to replace the\noriginal objectives by their linear combinations, thus focusing the search on\nthe most useful trade-offs between objectives. To compensate for the loss of\ndiversity, this transformation is accompanied by a selection mechanism that\nfavors novelty. This paper improves this approach further by introducing\nnovelty pulsation, i.e. a systematic method to alternate between novelty\nselection and local optimization. In the highly deceptive problem of\ndiscovering minimal sorting networks, it finds state-of-the-art solutions\nsignificantly faster than before. In fact, our method so far has established a\nnew world record for the 20-lines sorting network with 91 comparators. In the\nreal-world problem of stock trading, it discovers solutions that generalize\nsignificantly better on unseen data. Composite Novelty Pulsation is therefore a\npromising approach to solving deceptive real-world problems through\nmulti-objective optimization.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 17:39:34 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 02:07:59 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Shahrzad", "Hormoz", ""], ["Hodjat", "Babak", ""], ["Doll\u00e9", "Camille", ""], ["Denissov", "Andrei", ""], ["Lau", "Simon", ""], ["Goodhew", "Donn", ""], ["Dyer", "Justin", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "1906.04059", "submitter": "Kyongmin Yeo", "authors": "Kyongmin Yeo", "title": "Data-driven Reconstruction of Nonlinear Dynamics from Sparse Observation", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2019.06.039", "report-no": null, "categories": "cs.NE physics.comp-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a data-driven model to reconstruct nonlinear dynamics from a very\nsparse times series data, which relies on the strength of the echo state\nnetwork (ESN) in learning nonlinear representation of data. With an assumption\nof the universal function approximation capability of ESN, it is shown that the\nreconstruction problem can be formulated as a fixed-point problem, in which the\ntrajectory of the dynamical system is a fixed point of the ESN. An\nunder-relaxed fixed-point iteration is proposed to reconstruct the nonlinear\ndynamics from a sparse observation. The proposed fixed-point ESN is tested\nagainst both univariate and multivariate chaotic dynamical systems by randomly\nremoving up to 95% of the data. It is shown that the fixed-point ESN is able to\nreconstruct the complex dynamics from only 5 ~ 10% of the data. For a\nrelatively simple non-chaotic dynamical system, the numerical experiments on a\nforced van der Pol oscillator show that it is possible to reconstruct the\nnonlinear dynamics from only 1~2% of the data.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 15:04:14 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Yeo", "Kyongmin", ""]]}, {"id": "1906.04173", "submitter": "Wang Yifan", "authors": "Wang Yifan, Felice Serena, Shihao Wu, Cengiz \\\"Oztireli, Olga\n  Sorkine-Hornung", "title": "Differentiable Surface Splatting for Point-based Geometry Processing", "comments": "This version is contains camera-ready manuscript for SIGGRAPH Asia\n  2019", "journal-ref": null, "doi": "10.1145/3355089.3356513", "report-no": null, "categories": "cs.GR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Differentiable Surface Splatting (DSS), a high-fidelity\ndifferentiable renderer for point clouds. Gradients for point locations and\nnormals are carefully designed to handle discontinuities of the rendering\nfunction. Regularization terms are introduced to ensure uniform distribution of\nthe points on the underlying surface. We demonstrate applications of DSS to\ninverse rendering for geometry synthesis and denoising, where large scale\ntopological changes, as well as small scale detail modifications, are\naccurately and robustly handled without requiring explicit connectivity,\noutperforming state-of-the-art techniques. The data and code are at\nhttps://github.com/yifita/DSS.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 12:30:27 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 16:10:54 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2019 06:34:40 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Yifan", "Wang", ""], ["Serena", "Felice", ""], ["Wu", "Shihao", ""], ["\u00d6ztireli", "Cengiz", ""], ["Sorkine-Hornung", "Olga", ""]]}, {"id": "1906.04232", "submitter": "Mohammad Hamed Mozaffari", "authors": "M. Hamed Mozaffari and Won-Sook Lee", "title": "BowNet: Dilated Convolution Neural Network for Ultrasound Tongue Contour\n  Extraction", "comments": "23 pages, 15 figures, 10 tables", "journal-ref": "BowNet: Dilated convolutional neural network for ultrasound tongue\n  contour extraction, 2019, The Journal of the Acoustical Society of America,\n  pages 2940-2941, volume 146, number 4", "doi": "10.1121/1.5137212", "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.NE cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ultrasound imaging is safe, relatively affordable, and capable of real-time\nperformance. One application of this technology is to visualize and to\ncharacterize human tongue shape and motion during a real-time speech to study\nhealthy or impaired speech production. Due to the noisy nature of ultrasound\nimages with low-contrast characteristic, it might require expertise for\nnon-expert users to recognize organ shape such as tongue surface (dorsum). To\nalleviate this difficulty for quantitative analysis of tongue shape and motion,\ntongue surface can be extracted, tracked, and visualized instead of the whole\ntongue region. Delineating the tongue surface from each frame is a cumbersome,\nsubjective, and error-prone task. Furthermore, the rapidity and complexity of\ntongue gestures have made it a challenging task, and manual segmentation is not\na feasible solution for real-time applications. Employing the power of\nstate-of-the-art deep neural network models and training techniques, it is\nfeasible to implement new fully-automatic, accurate, and robust segmentation\nmethods with the capability of real-time performance, applicable for tracking\nof the tongue contours during the speech. This paper presents two novel deep\nneural network models named BowNet and wBowNet benefits from the ability of\nglobal prediction of decoding-encoding models, with integrated multi-scale\ncontextual information, and capability of full-resolution (local) extraction of\ndilated convolutions. Experimental results using several ultrasound tongue\nimage datasets revealed that the combination of both localization and\nglobalization searching could improve prediction result significantly.\nAssessment of BowNet models using both qualitatively and quantitatively studies\nshowed them outstanding achievements in terms of accuracy and robustness in\ncomparison with similar techniques.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 19:04:09 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Mozaffari", "M. Hamed", ""], ["Lee", "Won-Sook", ""]]}, {"id": "1906.04358", "submitter": "David Ha", "authors": "Adam Gaier and David Ha", "title": "Weight Agnostic Neural Networks", "comments": "To appear at NeurIPS 2019, selected for a spotlight presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Not all neural network architectures are created equal, some perform much\nbetter than others for certain tasks. But how important are the weight\nparameters of a neural network compared to its architecture? In this work, we\nquestion to what extent neural network architectures alone, without learning\nany weight parameters, can encode solutions for a given task. We propose a\nsearch method for neural network architectures that can already perform a task\nwithout any explicit weight training. To evaluate these networks, we populate\nthe connections with a single shared weight parameter sampled from a uniform\nrandom distribution, and measure the expected performance. We demonstrate that\nour method can find minimal neural network architectures that can perform\nseveral reinforcement learning tasks without weight training. On a supervised\nlearning domain, we find network architectures that achieve much higher than\nchance accuracy on MNIST using random weights. Interactive version of this\npaper at https://weightagnostic.github.io/\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 02:40:11 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 07:54:07 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Gaier", "Adam", ""], ["Ha", "David", ""]]}, {"id": "1906.04392", "submitter": "Ziang Yan", "authors": "Ziang Yan, Yiwen Guo, Changshui Zhang", "title": "Subspace Attack: Exploiting Promising Subspaces for Query-Efficient\n  Black-box Attacks", "comments": "10 pages + 3 pages supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike the white-box counterparts that are widely studied and readily\naccessible, adversarial examples in black-box settings are generally more\nHerculean on account of the difficulty of estimating gradients. Many methods\nachieve the task by issuing numerous queries to target classification systems,\nwhich makes the whole procedure costly and suspicious to the systems. In this\npaper, we aim at reducing the query complexity of black-box attacks in this\ncategory. We propose to exploit gradients of a few reference models which\narguably span some promising search subspaces. Experimental results show that,\nin comparison with the state-of-the-arts, our method can gain up to 2x and 4x\nreductions in the requisite mean and medium numbers of queries with much lower\nfailure rates even if the reference models are trained on a small and\ninadequate dataset disjoint to the one for training the victim model. Code and\nmodels for reproducing our results will be made publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 04:55:18 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Yan", "Ziang", ""], ["Guo", "Yiwen", ""], ["Zhang", "Changshui", ""]]}, {"id": "1906.04403", "submitter": "Claus Aranha", "authors": "Icaro Marcelino Miranda, Claus Aranha, Marcelo Ladeira", "title": "Classification of EEG Signals using Genetic Programming for Feature\n  Construction", "comments": "9 pages, accepted to the GECCO 2019 conference", "journal-ref": null, "doi": "10.1145/3321707.3321737", "report-no": null, "categories": "cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of electroencephalogram (EEG) waves is of critical importance\nfor the diagnosis of sleep disorders, such as sleep apnea and insomnia, besides\nthat, seizures, epilepsy, head injuries, dizziness, headaches and brain tumors.\nIn this context, one important task is the identification of visible structures\nin the EEG signal, such as sleep spindles and K-complexes. The identification\nof these structures is usually performed by visual inspection from human\nexperts, a process that can be error prone and susceptible to biases. Therefore\nthere is interest in developing technologies for the automated analysis of EEG.\nIn this paper, we propose a new Genetic Programming (GP) framework for feature\nconstruction and dimensionality reduction from EEG signals. We use these\nfeatures to automatically identify spindles and K-complexes on data from the\nDREAMS project. Using 5 different classifiers, the set of attributes produced\nby GP obtained better AUC scores than those obtained from PCA or the full set\nof attributes. Also, the results obtained from the proposed framework obtained\na better balance of Specificity and Recall than other models recently proposed\nin the literature. Analysis of the features most used by GP also suggested\nimprovements for data acquisition protocols in future EEG examinations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 05:59:32 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Miranda", "Icaro Marcelino", ""], ["Aranha", "Claus", ""], ["Ladeira", "Marcelo", ""]]}, {"id": "1906.04493", "submitter": "Juergen Schmidhuber", "authors": "Juergen Schmidhuber", "title": "Generative Adversarial Networks are Special Cases of Artificial\n  Curiosity (1990) and also Closely Related to Predictability Minimization\n  (1991)", "comments": "15 pages, 1 figure, 104 references", "journal-ref": "Neural Networks, Volume 127, July 2020, Pages 58-66", "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I review unsupervised or self-supervised neural networks playing minimax\ngames in game-theoretic settings: (i) Artificial Curiosity (AC, 1990) is based\non two such networks. One network learns to generate a probability distribution\nover outputs, the other learns to predict effects of the outputs. Each network\nminimizes the objective function maximized by the other. (ii) Generative\nAdversarial Networks (GANs, 2010-2014) are an application of AC where the\neffect of an output is 1 if the output is in a given set, and 0 otherwise.\n(iii) Predictability Minimization (PM, 1990s) models data distributions through\na neural encoder that maximizes the objective function minimized by a neural\npredictor of the code components. I correct a previously published claim that\nPM is not based on a minimax game.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 10:53:22 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2019 18:25:12 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 17:36:05 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Schmidhuber", "Juergen", ""]]}, {"id": "1906.04554", "submitter": "Florent Krzakala", "authors": "Julien Launay, Iacopo Poli and Florent Krzakala", "title": "Principled Training of Neural Networks with Direct Feedback Alignment", "comments": "10 pages, 4 figures, 4 tables, github repo at:\n  https://github.com/lightonai/principled-dfa-training", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The backpropagation algorithm has long been the canonical training method for\nneural networks. Modern paradigms are implicitly optimized for it, and numerous\nguidelines exist to ensure its proper use. Recently, synthetic gradients\nmethods -where the error gradient is only roughly approximated - have garnered\ninterest. These methods not only better portray how biological brains are\nlearning, but also open new computational possibilities, such as updating\nlayers asynchronously. Even so, they have failed to scale past simple tasks\nlike MNIST or CIFAR-10. This is in part due to a lack of standards, leading to\nill-suited models and practices forbidding such methods from performing to the\nbest of their abilities. In this work, we focus on direct feedback alignment\nand present a set of best practices justified by observations of the alignment\nangles. We characterize a bottleneck effect that prevents alignment in narrow\nlayers, and hypothesize it may explain why feedback alignment methods have yet\nto scale to large convolutional networks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 13:08:19 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Launay", "Julien", ""], ["Poli", "Iacopo", ""], ["Krzakala", "Florent", ""]]}, {"id": "1906.04678", "submitter": "Soumya Sarkar", "authors": "Soumya Sarkar, Bhanu Prakash Reddy, Sandipan Sikdar, Animesh Mukherjee", "title": "StRE: Self Attentive Edit Quality Prediction in Wikipedia", "comments": "Accepted in ACL 2019 , 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wikipedia can easily be justified as a behemoth, considering the sheer volume\nof content that is added or removed every minute to its several projects. This\ncreates an immense scope, in the field of natural language processing towards\ndeveloping automated tools for content moderation and review. In this paper we\npropose Self Attentive Revision Encoder (StRE) which leverages orthographic\nsimilarity of lexical units toward predicting the quality of new edits. In\ncontrast to existing propositions which primarily employ features like page\nreputation, editor activity or rule based heuristics, we utilize the textual\ncontent of the edits which, we believe contains superior signatures of their\nquality. More specifically, we deploy deep encoders to generate representations\nof the edits from its text content, which we then leverage to infer quality. We\nfurther contribute a novel dataset containing 21M revisions across 32K\nWikipedia pages and demonstrate that StRE outperforms existing methods by a\nsignificant margin at least 17% and at most 103%. Our pretrained model achieves\nsuch result after retraining on a set as small as 20% of the edits in a\nwikipage. This, to the best of our knowledge, is also the first attempt towards\nemploying deep language models to the enormous domain of automated content\nmoderation and review in Wikipedia.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 16:19:11 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Sarkar", "Soumya", ""], ["Reddy", "Bhanu Prakash", ""], ["Sikdar", "Sandipan", ""], ["Mukherjee", "Animesh", ""]]}, {"id": "1906.04818", "submitter": "Hossein Sangrody", "authors": "Arghavan Zare-Noghabi and Morteza Shabanzadeh and Hossein Sangrody", "title": "Medium-Term Load Forecasting Using Support Vector Regression, Feature\n  Selection, and Symbiotic Organism Search Optimization", "comments": "2019 IEEE PES General Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate load forecasting has always been one of the main indispensable\nparts in the operation and planning of power systems. Among different time\nhorizons of forecasting, while short-term load forecasting (STLF) and long-term\nload forecasting (LTLF) have respectively got benefits of accurate predictors\nand probabilistic forecasting, medium-term load forecasting (MTLF) demands more\nattention due to its vital role in power system operation and planning such as\noptimal scheduling of generation units, robust planning program for customer\nservice, and economic supply. In this study, a hybrid method, composed of\nSupport Vector Regression (SVR) and Symbiotic Organism Search Optimization\n(SOSO) method, is proposed for MTLF. In the proposed forecasting model, SVR is\nthe main part of the forecasting algorithm while SOSO is embedded into it to\noptimize the parameters of SVR. In addition, a minimum redundancy-maximum\nrelevance feature selection algorithm is used to in the preprocessing of input\ndata. The proposed method is tested on EUNITE competition dataset to\ndemonstrate its proper performance. Furthermore, it is compared with some\nprevious works to show eligibility of our method.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 20:58:25 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Zare-Noghabi", "Arghavan", ""], ["Shabanzadeh", "Morteza", ""], ["Sangrody", "Hossein", ""]]}, {"id": "1906.04886", "submitter": "Urmish Thakker", "authors": "Urmish Thakker, Jesse Beu, Dibakar Gope, Ganesh Dasika, Matthew\n  Mattina", "title": "Run-Time Efficient RNN Compression for Inference on Edge Devices", "comments": "Published at 4th edition of Workshop on Energy Efficient Machine\n  Learning and Cognitive Computing for Embedded Applications at International\n  Symposium of Computer Architecture 2019, Phoenix, Arizona\n  (https://www.emc2-workshop.com/isca-19) colocated with ISCA 2019", "journal-ref": "2019 2nd Workshop on Energy Efficient Machine Learning and\n  Cognitive Computing for Embedded Applications (EMC2)", "doi": "10.1109/EMC249363.2019.00013", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks can be large and compute-intensive, yet many\napplications that benefit from RNNs run on small devices with very limited\ncompute and storage capabilities while still having run-time constraints. As a\nresult, there is a need for compression techniques that can achieve significant\ncompression without negatively impacting inference run-time and task accuracy.\nThis paper explores a new compressed RNN cell implementation called Hybrid\nMatrix Decomposition (HMD) that achieves this dual objective. This scheme\ndivides the weight matrix into two parts - an unconstrained upper half and a\nlower half composed of rank-1 blocks. This results in output features where the\nupper sub-vector has \"richer\" features while the lower-sub vector has\n\"constrained features\". HMD can compress RNNs by a factor of 2-4x while having\na faster run-time than pruning (Zhu &Gupta, 2017) and retaining more model\naccuracy than matrix factorization (Grachev et al., 2017). We evaluate this\ntechnique on 5 benchmarks spanning 3 different applications, illustrating its\ngenerality in the domain of edge computing.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 01:59:44 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 23:13:15 GMT"}, {"version": "v3", "created": "Sun, 5 Jan 2020 21:54:18 GMT"}, {"version": "v4", "created": "Wed, 12 Aug 2020 22:36:34 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Thakker", "Urmish", ""], ["Beu", "Jesse", ""], ["Gope", "Dibakar", ""], ["Dasika", "Ganesh", ""], ["Mattina", "Matthew", ""]]}, {"id": "1906.05175", "submitter": "Alberto Alvarez", "authors": "Alberto Alvarez, Steve Dahlskog, Jose Font, Julian Togelius", "title": "Empowering Quality Diversity in Dungeon Design with Interactive\n  Constrained MAP-Elites", "comments": "8 pages, Accepted and to appear in proceedings of 2019 IEEE\n  Conference on Games, COG 2019", "journal-ref": null, "doi": "10.1109/CIG.2019.8848022", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the use of quality-diversity algorithms for mixed-initiative game\ncontent generation. This idea is implemented as a new feature of the\nEvolutionary Dungeon Designer, a system for mixed-initiative design of the type\nof levels you typically find in computer role playing games. The feature uses\nthe MAP-Elites algorithm, an illumination algorithm which divides the\npopulation into a number of cells depending on their values along several\nbehavioral dimensions. Users can flexibly and dynamically choose relevant\ndimensions of variation, and incorporate suggestions produced by the algorithm\nin their map designs. At the same time, any modifications performed by the\nhuman feed back into MAP-Elites, and are used to generate further suggestions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 14:39:07 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Alvarez", "Alberto", ""], ["Dahlskog", "Steve", ""], ["Font", "Jose", ""], ["Togelius", "Julian", ""]]}, {"id": "1906.05201", "submitter": "Xu He", "authors": "Xu He, Jakub Sygnowski, Alexandre Galashov, Andrei A. Rusu, Yee Whye\n  Teh, Razvan Pascanu", "title": "Task Agnostic Continual Learning via Meta Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural networks are powerful function approximators, they suffer from\ncatastrophic forgetting when the data distribution is not stationary. One\nparticular formalism that studies learning under non-stationary distribution is\nprovided by continual learning, where the non-stationarity is imposed by a\nsequence of distinct tasks. Most methods in this space assume, however, the\nknowledge of task boundaries, and focus on alleviating catastrophic forgetting.\nIn this work, we depart from this view and move the focus towards faster\nremembering -- i.e measuring how quickly the network recovers performance\nrather than measuring the network's performance without any adaptation. We\nargue that in many settings this can be more effective and that it opens the\ndoor to combining meta-learning and continual learning techniques, leveraging\ntheir complementary advantages. We propose a framework specific for the\nscenario where no information about task boundaries or task identity is given.\nIt relies on a separation of concerns into what task is being solved and how\nthe task should be solved. This framework is implemented by differentiating\ntask specific parameters from task agnostic parameters, where the latter are\noptimized in a continual meta learning fashion, without access to multiple\ntasks at the same time. We showcase this framework in a supervised learning\nscenario and discuss the implication of the proposed formalism.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 15:17:47 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["He", "Xu", ""], ["Sygnowski", "Jakub", ""], ["Galashov", "Alexandre", ""], ["Rusu", "Andrei A.", ""], ["Teh", "Yee Whye", ""], ["Pascanu", "Razvan", ""]]}, {"id": "1906.05301", "submitter": "Zohar Ringel", "authors": "Omry Cohen, Or Malka, and Zohar Ringel", "title": "Learning Curves for Deep Neural Networks: A Gaussian Field Theory\n  Perspective", "comments": null, "journal-ref": "Phys. Rev. Research 3, 023034 (2021)", "doi": "10.1103/PhysRevResearch.3.023034", "report-no": null, "categories": "cs.LG cond-mat.stat-mech cs.NE physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, deep neural networks (DNNs) came to the fore as the\nleading machine learning algorithms for a variety of tasks. Their raise was\nfounded on market needs and engineering craftsmanship, the latter based more on\ntrial and error than on theory. While still far behind the application\nforefront, the theoretical study of DNNs has recently made important\nadvancements in analyzing the highly over-parameterized regime where some exact\nresults have been obtained. Leveraging these ideas and adopting a more\nphysics-like approach, here we construct a versatile field-theory formalism for\nsupervised deep learning, involving renormalization group, Feynman diagrams and\nreplicas. In particular we show that our approach leads to highly accurate\npredictions of learning curves of truly deep DNNs trained on polynomial\nregression tasks and that these predictions can be used for efficient\nhyper-parameter optimization. In addition, they explain how DNNs generalize\nwell despite being highly over-parameterized, this due to an entropic bias to\nsimple functions which, for the case of fully-connected DNNs with data sampled\non the hypersphere, are low order polynomials in the input vector. Being a\ncomplex interacting system of artificial neurons, we believe that such tools\nand methodologies borrowed from condensed matter physics would prove essential\nfor obtaining an accurate quantitative understanding of deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 18:00:10 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 07:25:52 GMT"}, {"version": "v3", "created": "Sun, 17 May 2020 14:22:48 GMT"}, {"version": "v4", "created": "Thu, 26 Nov 2020 12:02:04 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Cohen", "Omry", ""], ["Malka", "Or", ""], ["Ringel", "Zohar", ""]]}, {"id": "1906.05323", "submitter": "Mahesh Subedar", "authors": "Ranganath Krishnan and Mahesh Subedar and Omesh Tickoo", "title": "Specifying Weight Priors in Bayesian Deep Neural Networks with Empirical\n  Bayes", "comments": "To be published at AAAI 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variational inference for Bayesian deep neural network (DNN)\nrequires specifying priors and approximate posterior distributions over neural\nnetwork weights. Specifying meaningful weight priors is a challenging problem,\nparticularly for scaling variational inference to deeper architectures\ninvolving high dimensional weight space. We propose MOdel Priors with Empirical\nBayes using DNN (MOPED) method to choose informed weight priors in Bayesian\nneural networks. We formulate a two-stage hierarchical modeling, first find the\nmaximum likelihood estimates of weights with DNN, and then set the weight\npriors using empirical Bayes approach to infer the posterior with variational\ninference. We empirically evaluate the proposed approach on real-world tasks\nincluding image classification, video activity recognition and audio\nclassification with varying complex neural network architectures. We also\nevaluate our proposed approach on diabetic retinopathy diagnosis task and\nbenchmark with the state-of-the-art Bayesian deep learning techniques. We\ndemonstrate MOPED method enables scalable variational inference and provides\nreliable uncertainty quantification.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 18:26:52 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 17:50:23 GMT"}, {"version": "v3", "created": "Sat, 28 Dec 2019 15:09:13 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Krishnan", "Ranganath", ""], ["Subedar", "Mahesh", ""], ["Tickoo", "Omesh", ""]]}, {"id": "1906.05370", "submitter": "Tingwu Wang", "authors": "Tingwu Wang, Yuhao Zhou, Sanja Fidler, Jimmy Ba", "title": "Neural Graph Evolution: Towards Efficient Automatic Robot Design", "comments": "ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite the recent successes in robotic locomotion control, the design of\nrobot relies heavily on human engineering. Automatic robot design has been a\nlong studied subject, but the recent progress has been slowed due to the large\ncombinatorial search space and the difficulty in evaluating the found\ncandidates. To address the two challenges, we formulate automatic robot design\nas a graph search problem and perform evolution search in graph space. We\npropose Neural Graph Evolution (NGE), which performs selection on current\ncandidates and evolves new ones iteratively. Different from previous\napproaches, NGE uses graph neural networks to parameterize the control\npolicies, which reduces evaluation cost on new candidates with the help of\nskill transfer from previously evaluated designs. In addition, NGE applies\nGraph Mutation with Uncertainty (GM-UC) by incorporating model uncertainty,\nwhich reduces the search space by balancing exploration and exploitation. We\nshow that NGE significantly outperforms previous methods by an order of\nmagnitude. As shown in experiments, NGE is the first algorithm that can\nautomatically discover kinematically preferred robotic graph structures, such\nas a fish with two symmetrical flat side-fins and a tail, or a cheetah with\nathletic front and back legs. Instead of using thousands of cores for weeks,\nNGE efficiently solves searching problem within a day on a single 64 CPU-core\nAmazon EC2 machine.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 20:41:18 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Wang", "Tingwu", ""], ["Zhou", "Yuhao", ""], ["Fidler", "Sanja", ""], ["Ba", "Jimmy", ""]]}, {"id": "1906.05516", "submitter": "Mojtaba Moattari", "authors": "Mojtaba Moattari, Emad Roshandel, Shima Kamyab, Zohreh Azimifar", "title": "A New Approach for Optimizing Highly Nonlinear Problems Based on the\n  Observer Effect Concept", "comments": "29 pages, 10 figures, 9 pages, 11 formulas", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lot of real-world engineering problems represent dynamicity with nests of\nnonlinearities due to highly complex network of exponential functions or large\nnumber of differential equations interacting together. Such search spaces are\nprovided with multiple convex regions peaked with diverse nonlinear slopes and\nin non-homogenous ways. To find global optima, a new meta-heuristic algorithm\nis proposed based on Observer Effect concepts for controlling memory usage per\nlocalities without pursuing Tabu-like cut-off approaches. Observer effect in\nphysics (or psychology) regards bias in measurement (or perception) due to the\ninterference of instrument (or knowledge). Performance analysis of the proposed\nalgorithms is sought in two real-world engineering applications, i.e.,\nElectroencephalogram feature learning and Distributed Generator parameter\ntuning, each of which having nonlinearity and complex multi-modal peaks\ndistributions as their characteristics. In addition, the effect of version\nimprovement has been assessed. The performance comparison with other optimizers\nin the same context suggests that proposed algorithm is useful both solely and\nin hybrid Gradient Descent settings where problem's search space is\nnonhomogeneous in terms of local peaks density.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 07:29:22 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 17:00:26 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Moattari", "Mojtaba", ""], ["Roshandel", "Emad", ""], ["Kamyab", "Shima", ""], ["Azimifar", "Zohreh", ""]]}, {"id": "1906.05560", "submitter": "Hung-Hsuan Chen", "authors": "Yu-Wei Kao and Hung-Hsuan Chen", "title": "Associated Learning: Decomposing End-to-end Backpropagation based on\n  Auto-encoders and Target Propagation", "comments": "34 pages, 6 figures, 7 tables", "journal-ref": "MIT Neural Computation 33(1), 2021", "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation (BP) is the cornerstone of today's deep learning algorithms,\nbut it is inefficient partially because of backward locking, which means\nupdating the weights of one layer locks the weight updates in the other layers.\nConsequently, it is challenging to apply parallel computing or a pipeline\nstructure to update the weights in different layers simultaneously. In this\npaper, we introduce a novel learning structure called associated learning (AL),\nwhich modularizes the network into smaller components, each of which has a\nlocal objective. Because the objectives are mutually independent, AL can learn\nthe parameters in different layers independently and simultaneously, so it is\nfeasible to apply a pipeline structure to improve the training throughput.\nSpecifically, this pipeline structure improves the complexity of the training\ntime from O(nl), which is the time complexity when using BP and stochastic\ngradient descent (SGD) for training, to O(n + l), where n is the number of\ntraining instances and l is the number of hidden layers. Surprisingly, even\nthough most of the parameters in AL do not directly interact with the target\nvariable, training deep models by this method yields accuracies comparable to\nthose from models trained using typical BP methods, in which all parameters are\nused to predict the target variable. Consequently, because of the scalability\nand the predictive power demonstrated in the experiments, AL deserves further\nstudy to determine the better hyperparameter settings, such as activation\nfunction selection, learning rate scheduling, and weight initialization, to\naccumulate experience, as we have done over the years with the typical BP\nmethod. Additionally, perhaps our design can also inspire new network designs\nfor deep learning. Our implementation is available at\nhttps://github.com/SamYWK/Associated_Learning.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 09:21:10 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 12:18:47 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2020 15:37:02 GMT"}, {"version": "v4", "created": "Tue, 9 Feb 2021 07:40:50 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Kao", "Yu-Wei", ""], ["Chen", "Hung-Hsuan", ""]]}, {"id": "1906.05616", "submitter": "Thomas Kent", "authors": "Thomas E. Kent and Arthur G. Richards", "title": "Decentralised Multi-Demic Evolutionary Approach to the Dynamic\n  Multi-Agent Travelling Salesman Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Travelling Salesman and its variations are some of the most well known NP\nhard optimisation problems. This paper looks to use both centralised and\ndecentralised implementations of Evolutionary Algorithms (EA) to solve a\ndynamic variant of the Multi-Agent Travelling Salesman Problem (MATSP). The\nproblem is dynamic, requiring an on-line solution, whereby tasks are completed\nduring simulation with new tasks added and completed ones removed. The problem\nis allocating an active set of tasks to a set of agents whilst simultaneously\nplanning the route for each agent. The allocation and routing are closely\ncoupled parts of the same problem making it difficult to decompose, instead\nthis paper uses multiple populations with well defined interactions to exploit\nthe problem structure. This work attempts to align the real world\nimplementation demands of a decentralised solution, where agents are far apart\nand have communication limits, to that of the structure of the multi-demic EA\nsolution process, ultimately allowing decentralised parts of the problem to be\nsolved `on board' agents and allow for robust communication and exchange of\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 11:49:44 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Kent", "Thomas E.", ""], ["Richards", "Arthur G.", ""]]}, {"id": "1906.05838", "submitter": "Carlos Florensa", "authors": "Yiming Ding, Carlos Florensa, Mariano Phielipp, Pieter Abbeel", "title": "Goal-conditioned Imitation Learning", "comments": "Published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing rewards for Reinforcement Learning (RL) is challenging because it\nneeds to convey the desired task, be efficient to optimize, and be easy to\ncompute. The latter is particularly problematic when applying RL to robotics,\nwhere detecting whether the desired configuration is reached might require\nconsiderable supervision and instrumentation. Furthermore, we are often\ninterested in being able to reach a wide range of configurations, hence setting\nup a different reward every time might be unpractical. Methods like Hindsight\nExperience Replay (HER) have recently shown promise to learn policies able to\nreach many goals, without the need of a reward. Unfortunately, without tricks\nlike resetting to points along the trajectory, HER might require many samples\nto discover how to reach certain areas of the state-space. In this work we\ninvestigate different approaches to incorporate demonstrations to drastically\nspeed up the convergence to a policy able to reach any goal, also surpassing\nthe performance of an agent trained with other Imitation Learning algorithms.\nFurthermore, we show our method can also be used when the available expert\ntrajectories do not contain the actions, which can leverage kinesthetic or\nthird person demonstration. The code is available at\nhttps://sites.google.com/view/goalconditioned-il/.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 17:39:52 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 18:37:00 GMT"}, {"version": "v3", "created": "Wed, 27 May 2020 06:47:07 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Ding", "Yiming", ""], ["Florensa", "Carlos", ""], ["Phielipp", "Mariano", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1906.05862", "submitter": "Alexander Li", "authors": "Alexander C. Li, Carlos Florensa, Ignasi Clavera, Pieter Abbeel", "title": "Sub-policy Adaptation for Hierarchical Reinforcement Learning", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical reinforcement learning is a promising approach to tackle\nlong-horizon decision-making problems with sparse rewards. Unfortunately, most\nmethods still decouple the lower-level skill acquisition process and the\ntraining of a higher level that controls the skills in a new task. Leaving the\nskills fixed can lead to significant sub-optimality in the transfer setting. In\nthis work, we propose a novel algorithm to discover a set of skills, and\ncontinuously adapt them along with the higher level even when training on a new\ntask. Our main contributions are two-fold. First, we derive a new hierarchical\npolicy gradient with an unbiased latent-dependent baseline, and we introduce\nHierarchical Proximal Policy Optimization (HiPPO), an on-policy method to\nefficiently train all levels of the hierarchy jointly. Second, we propose a\nmethod for training time-abstractions that improves the robustness of the\nobtained skills to environment changes. Code and results are available at\nsites.google.com/view/hippo-rl\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 16:59:48 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 23:18:29 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 17:59:41 GMT"}, {"version": "v4", "created": "Wed, 13 May 2020 23:32:41 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Li", "Alexander C.", ""], ["Florensa", "Carlos", ""], ["Clavera", "Ignasi", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1906.05890", "submitter": "Kaifeng Lyu", "authors": "Kaifeng Lyu, Jian Li", "title": "Gradient Descent Maximizes the Margin of Homogeneous Neural Networks", "comments": "52 pages, 9 figures; Published in ICLR 2020; Corrected typos and\n  added a few references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the implicit regularization of the gradient descent\nalgorithm in homogeneous neural networks, including fully-connected and\nconvolutional neural networks with ReLU or LeakyReLU activations. In\nparticular, we study the gradient descent or gradient flow (i.e., gradient\ndescent with infinitesimal step size) optimizing the logistic loss or\ncross-entropy loss of any homogeneous model (possibly non-smooth), and show\nthat if the training loss decreases below a certain threshold, then we can\ndefine a smoothed version of the normalized margin which increases over time.\nWe also formulate a natural constrained optimization problem related to margin\nmaximization, and prove that both the normalized margin and its smoothed\nversion converge to the objective value at a KKT point of the optimization\nproblem. Our results generalize the previous results for logistic regression\nwith one-layer or multi-layer linear networks, and provide more quantitative\nconvergence results with weaker assumptions than previous results for\nhomogeneous smooth neural networks. We conduct several experiments to justify\nour theoretical finding on MNIST and CIFAR-10 datasets. Finally, as margin is\nclosely related to robustness, we discuss potential benefits of training longer\nfor improving the robustness of the model.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 18:52:00 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 05:24:48 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 17:18:19 GMT"}, {"version": "v4", "created": "Tue, 29 Dec 2020 05:33:37 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Lyu", "Kaifeng", ""], ["Li", "Jian", ""]]}, {"id": "1906.05948", "submitter": "Tri Huynh", "authors": "Tri Huynh, Michael Maire, Matthew R. Walter", "title": "Multigrid Neural Memory", "comments": "ICML 2020; Project Website:\n  http://people.cs.uchicago.edu/~trihuynh/multigrid_mem", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel approach to endowing neural networks with emergent,\nlong-term, large-scale memory. Distinct from strategies that connect neural\nnetworks to external memory banks via intricately crafted controllers and\nhand-designed attentional mechanisms, our memory is internal, distributed,\nco-located alongside computation, and implicitly addressed, while being\ndrastically simpler than prior efforts. Architecting networks with multigrid\nstructure and connectivity, while distributing memory cells alongside\ncomputation throughout this topology, we observe the emergence of coherent\nmemory subsystems. Our hierarchical spatial organization, parameterized\nconvolutionally, permits efficient instantiation of large-capacity memories,\nwhile multigrid topology provides short internal routing pathways, allowing\nconvolutional networks to efficiently approximate the behavior of fully\nconnected networks. Such networks have an implicit capacity for internal\nattention; augmented with memory, they learn to read and write specific memory\nlocations in a dynamic data-dependent manner. We demonstrate these capabilities\non exploration and mapping tasks, where our network is able to self-organize\nand retain long-term memory for trajectories of thousands of time steps. On\ntasks decoupled from any notion of spatial geometry: sorting, associative\nrecall, and question answering, our design functions as a truly generic memory\nand yields excellent results.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 22:10:01 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 21:18:45 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 22:26:05 GMT"}, {"version": "v4", "created": "Sat, 15 Aug 2020 21:12:15 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Huynh", "Tri", ""], ["Maire", "Michael", ""], ["Walter", "Matthew R.", ""]]}, {"id": "1906.06026", "submitter": "Shashank Kotyan", "authors": "Shashank Kotyan, Danilo Vasconcellos Vargas", "title": "Adversarial Robustness Assessment: Why both $L_0$ and $L_\\infty$ Attacks\n  Are Necessary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exists a vast number of adversarial attacks and defences for machine\nlearning algorithms of various types which makes assessing the robustness of\nalgorithms a daunting task. To make matters worse, there is an intrinsic bias\nin these adversarial algorithms. Here, we organise the problems faced: a) Model\nDependence, b) Insufficient Evaluation, c) False Adversarial Samples, and d)\nPerturbation Dependent Results). Based on this, we propose a model agnostic\ndual quality assessment method, together with the concept of robustness levels\nto tackle them. We validate the dual quality assessment on state-of-the-art\nneural networks (WideResNet, ResNet, AllConv, DenseNet, NIN, LeNet and CapsNet)\nas well as adversarial defences for image classification problem. We further\nshow that current networks and defences are vulnerable at all levels of\nrobustness. The proposed robustness assessment reveals that depending on the\nmetric used (i.e., $L_0$ or $L_\\infty$), the robustness may vary significantly.\nHence, the duality should be taken into account for a correct evaluation.\nMoreover, a mathematical derivation, as well as a counter-example, suggest that\n$L_1$ and $L_2$ metrics alone are not sufficient to avoid spurious adversarial\nsamples. Interestingly, the threshold attack of the proposed assessment is a\nnovel $L_\\infty$ black-box adversarial method which requires even less\nperturbation than the One-Pixel Attack (only $12\\%$ of One-Pixel Attack's\namount of perturbation) to achieve similar results.\n  Code is available at http://bit.ly/DualQualityAssessment.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 05:11:12 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2019 08:30:06 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 13:44:38 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Kotyan", "Shashank", ""], ["Vargas", "Danilo Vasconcellos", ""]]}, {"id": "1906.06627", "submitter": "Shashank Kotyan", "authors": "Shashank Kotyan, Danilo Vasconcellos Vargas, and Moe Matsuki", "title": "Representation Quality Of Neural Networks Links To Adversarial Attacks\n  and Defences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have been shown vulnerable to a variety of adversarial\nalgorithms. A crucial step to understanding the rationale for this lack of\nrobustness is to assess the potential of the neural networks' representation to\nencode the existing features. Here, we propose a method to understand the\nrepresentation quality of the neural networks using a novel test based on\nZero-Shot Learning, entitled Raw Zero-Shot. The principal idea is that, if an\nalgorithm learns rich features, such features should be able to interpret\n\"unknown\" classes as an aggregate of previously learned features. This is\nbecause unknown classes usually share several regular features with recognised\nclasses, given the features learned are general enough. We further introduce\ntwo metrics to assess these learned features to interpret unknown classes. One\nis based on inter-cluster validation technique (Davies-Bouldin Index), and the\nother is based on the distance to an approximated ground-truth. Experiments\nsuggest that adversarial defences improve the representation of the\nclassifiers, further suggesting that to improve the robustness of the\nclassifiers, one has to improve the representation quality also. Experiments\nalso reveal a strong association (a high Pearson Correlation and low p-value)\nbetween the metrics and adversarial attacks. Interestingly, the results\nindicate that dynamic routing networks such as CapsNet have better\nrepresentation while current deeper neural networks are trading off\nrepresentation quality for accuracy.\n  Code available at http://bit.ly/RepresentationMetrics.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 23:32:33 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 05:27:20 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 09:39:43 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2020 20:56:36 GMT"}, {"version": "v5", "created": "Thu, 16 Jul 2020 14:49:14 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Kotyan", "Shashank", ""], ["Vargas", "Danilo Vasconcellos", ""], ["Matsuki", "Moe", ""]]}, {"id": "1906.06635", "submitter": "Min Lin", "authors": "Min Lin, Jie Fu, Yoshua Bengio", "title": "Conditional Computation for Continual Learning", "comments": "NeurIPS 2018 Continual Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting of connectionist neural networks is caused by the\nglobal sharing of parameters among all training examples. In this study, we\nanalyze parameter sharing under the conditional computation framework where the\nparameters of a neural network are conditioned on each input example. At one\nextreme, if each input example uses a disjoint set of parameters, there is no\nsharing of parameters thus no catastrophic forgetting. At the other extreme, if\nthe parameters are the same for every example, it reduces to the conventional\nneural network. We then introduce a clipped version of maxout networks which\nlies in the middle, i.e. parameters are shared partially among examples. Based\non the parameter sharing analysis, we can locate a limited set of examples that\nare interfered when learning a new example. We propose to perform rehearsal on\nthis set to prevent forgetting, which is termed as conditional rehearsal.\nFinally, we demonstrate the effectiveness of the proposed method in an online\nnon-stationary setup, where updates are made after each new example and the\ndistribution of the received example shifts over time.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 02:11:39 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Lin", "Min", ""], ["Fu", "Jie", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1906.06818", "submitter": "Adam Kosiorek", "authors": "Adam R. Kosiorek, Sara Sabour, Yee Whye Teh, Geoffrey E. Hinton", "title": "Stacked Capsule Autoencoders", "comments": "NeurIPS 2019; 14 pages, 7 figures, 4 tables, code is available at\n  https://github.com/google-research/google-research/tree/master/stacked_capsule_autoencoders", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objects are composed of a set of geometrically organized parts. We introduce\nan unsupervised capsule autoencoder (SCAE), which explicitly uses geometric\nrelationships between parts to reason about objects. Since these relationships\ndo not depend on the viewpoint, our model is robust to viewpoint changes. SCAE\nconsists of two stages. In the first stage, the model predicts presences and\nposes of part templates directly from the image and tries to reconstruct the\nimage by appropriately arranging the templates. In the second stage, SCAE\npredicts parameters of a few object capsules, which are then used to\nreconstruct part poses. Inference in this model is amortized and performed by\noff-the-shelf neural encoders, unlike in previous capsule networks. We find\nthat object capsule presences are highly informative of the object class, which\nleads to state-of-the-art results for unsupervised classification on SVHN (55%)\nand MNIST (98.7%). The code is available at\nhttps://github.com/google-research/google-research/tree/master/stacked_capsule_autoencoders\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 02:31:37 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 16:29:43 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Kosiorek", "Adam R.", ""], ["Sabour", "Sara", ""], ["Teh", "Yee Whye", ""], ["Hinton", "Geoffrey E.", ""]]}, {"id": "1906.06847", "submitter": "Liangjian Wen PhD.", "authors": "Liangjian Wen, Xuanyang Zhang, Haoli Bai, Zenglin Xu", "title": "Structured Pruning of Recurrent Neural Networks through Neuron Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have recently achieved remarkable successes\nin a number of applications. However, the huge sizes and computational burden\nof these models make it difficult for their deployment on edge devices. A\npractically effective approach is to reduce the overall storage and computation\ncosts of RNNs by network pruning techniques. Despite their successful\napplications, those pruning methods based on Lasso either produce irregular\nsparse patterns in weight matrices, which is not helpful in practical speedup.\nTo address these issues, we propose structured pruning method through neuron\nselection which can reduce the sizes of basic structures of RNNs. More\nspecifically, we introduce two sets of binary random variables, which can be\ninterpreted as gates or switches to the input neurons and the hidden neurons,\nrespectively. We demonstrate that the corresponding optimization problem can be\naddressed by minimizing the L0 norm of the weight matrix. Finally, experimental\nresults on language modeling and machine reading comprehension tasks have\nindicated the advantages of the proposed method in comparison with\nstate-of-the-art pruning competitors. In particular, nearly 20 x practical\nspeedup during inference was achieved without losing performance for language\nmodel on the Penn TreeBank dataset, indicating the promising performance of the\nproposed method\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 05:23:36 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 04:37:54 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Wen", "Liangjian", ""], ["Zhang", "Xuanyang", ""], ["Bai", "Haoli", ""], ["Xu", "Zenglin", ""]]}, {"id": "1906.06873", "submitter": "Chao Qian", "authors": "Chao Bian, Chao Qian, Ke Tang", "title": "Running Time Analysis of the (1+1)-EA for Robust Linear Optimization", "comments": "17 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms (EAs) have found many successful real-world\napplications, where the optimization problems are often subject to a wide range\nof uncertainties. To understand the practical behaviors of EAs theoretically,\nthere are a series of efforts devoted to analyzing the running time of EAs for\noptimization under uncertainties. Existing studies mainly focus on noisy and\ndynamic optimization, while another common type of uncertain optimization,\ni.e., robust optimization, has been rarely touched. In this paper, we analyze\nthe expected running time of the (1+1)-EA solving robust linear optimization\nproblems (i.e., linear problems under robust scenarios) with a cardinality\nconstraint $k$. Two common robust scenarios, i.e., deletion-robust and\nworst-case, are considered. Particularly, we derive tight ranges of the robust\nparameter $d$ or budget $k$ allowing the (1+1)-EA to find an optimal solution\nin polynomial running time, which disclose the potential of EAs for robust\noptimization.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 07:18:58 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Bian", "Chao", ""], ["Qian", "Chao", ""], ["Tang", "Ke", ""]]}, {"id": "1906.07038", "submitter": "Alessio Quaglino PhD", "authors": "Alessio Quaglino, Marco Gallieri, Jonathan Masci, Jan Koutn\\'ik", "title": "SNODE: Spectral Discretization of Neural ODEs for System Identification", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the use of spectral element methods\n\\citep{canuto_spectral_1988} for fast and accurate training of Neural Ordinary\nDifferential Equations (ODE-Nets; \\citealp{Chen2018NeuralOD}) for system\nidentification. This is achieved by expressing their dynamics as a truncated\nseries of Legendre polynomials. The series coefficients, as well as the network\nweights, are computed by minimizing the weighted sum of the loss function and\nthe violation of the ODE-Net dynamics. The problem is solved by coordinate\ndescent that alternately minimizes, with respect to the coefficients and the\nweights, two unconstrained sub-problems using standard backpropagation and\ngradient methods. The resulting optimization scheme is fully time-parallel and\nresults in a low memory footprint. Experimental comparison to standard methods,\nsuch as backpropagation through explicit solvers and the adjoint technique\n\\citep{Chen2018NeuralOD}, on training surrogate models of small and\nmedium-scale dynamical systems shows that it is at least one order of magnitude\nfaster at reaching a comparable value of the loss function. The corresponding\ntesting MSE is one order of magnitude smaller as well, suggesting\ngeneralization capabilities increase.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 13:54:30 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 14:43:34 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Quaglino", "Alessio", ""], ["Gallieri", "Marco", ""], ["Masci", "Jonathan", ""], ["Koutn\u00edk", "Jan", ""]]}, {"id": "1906.07067", "submitter": "Thomas Cleland", "authors": "Nabil Imam, Thomas A. Cleland", "title": "Rapid online learning and robust recall in a neuromorphic olfactory\n  circuit", "comments": "52 text pages; 8 figures. Version 3 includes a new figure and\n  additional details", "journal-ref": "Nature Machine Intelligence 2 (2020): 181-191", "doi": "10.1038/s42256-020-0159-4", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neural algorithm for the rapid online learning and\nidentification of odorant samples under noise, based on the architecture of the\nmammalian olfactory bulb and implemented on the Intel Loihi neuromorphic\nsystem. As with biological olfaction, the spike timing-based algorithm utilizes\ndistributed, event-driven computations and rapid (one-shot) online learning.\nSpike timing-dependent plasticity rules operate iteratively over sequential\ngamma-frequency packets to construct odor representations from the activity of\nchemosensor arrays mounted in a wind tunnel. Learned odorants then are reliably\nidentified despite strong destructive interference. Noise resistance is further\nenhanced by neuromodulation and contextual priming. Lifelong learning\ncapabilities are enabled by adult neurogenesis. The algorithm is applicable to\nany signal identification problem in which high-dimensional signals are\nembedded in unknown backgrounds.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 14:51:06 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 14:05:11 GMT"}, {"version": "v3", "created": "Thu, 23 Jan 2020 10:32:54 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Imam", "Nabil", ""], ["Cleland", "Thomas A.", ""]]}, {"id": "1906.07160", "submitter": "Malav Bateriwala", "authors": "Malav Bateriwala and Pierrick Bourgeat", "title": "Enforcing temporal consistency in Deep Learning segmentation of brain MR\n  images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Longitudinal analysis has great potential to reveal developmental\ntrajectories and monitor disease progression in medical imaging. This process\nrelies on consistent and robust joint 4D segmentation. Traditional techniques\nare dependent on the similarity of images over time and the use of\nsubject-specific priors to reduce random variation and improve the robustness\nand sensitivity of the overall longitudinal analysis. This is however slow and\ncomputationally intensive as subject-specific templates need to be rebuilt\nevery time. The focus of this work to accelerate this analysis with the use of\ndeep learning. The proposed approach is based on deep CNNs and incorporates\nsemantic segmentation and provides a longitudinal relationship for the same\nsubject. The proposed approach is based on deep CNNs and incorporates semantic\nsegmentation and provides a longitudinal relationship for the same subject. The\nstate of art using 3D patches as inputs to modified Unet provides results\naround ${0.91 \\pm 0.5}$ Dice and using multi-view atlas in CNNs provide around\nthe same results. In this work, different models are explored, each offers\nbetter accuracy and fast results while increasing the segmentation quality.\nThese methods are evaluated on 135 scans from the EADC-ADNI Harmonized\nHippocampus Protocol. Proposed CNN based segmentation approaches demonstrate\nhow 2D segmentation using prior slices can provide similar results to 3D\nsegmentation while maintaining good continuity in the 3D dimension and improved\nspeed. Just using 2D modified sagittal slices provide us a better Dice and\nlongitudinal analysis for a given subject. For the ADNI dataset, using the\nsimple UNet CNN technique gives us ${0.84 \\pm 0.5}$ and while using modified\nCNN techniques on the same input yields ${0.89 \\pm 0.5}$. Rate of atrophy and\nRMS error are calculated for several test cases using various methods and\nanalyzed.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 08:33:23 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Bateriwala", "Malav", ""], ["Bourgeat", "Pierrick", ""]]}, {"id": "1906.07357", "submitter": "Wentao Zhu", "authors": "Wentao Zhu, Yufang Huang, Mani A Vannan, Shizhen Liu, Daguang Xu, Wei\n  Fan, Zhen Qian, Xiaohui Xie", "title": "Neural Multi-Scale Self-Supervised Registration for Echocardiogram Dense\n  Tracking", "comments": "Blood tracking video: https://youtu.be/pEA6ZmtTNuQ Muscle tracking\n  video: https://youtu.be/NvLrCaqCiAE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Echocardiography has become routinely used in the diagnosis of cardiomyopathy\nand abnormal cardiac blood flow. However, manually measuring myocardial motion\nand cardiac blood flow from echocardiogram is time-consuming and error-prone.\nComputer algorithms that can automatically track and quantify myocardial motion\nand cardiac blood flow are highly sought after, but have not been very\nsuccessful due to noise and high variability of echocardiography. In this work,\nwe propose a neural multi-scale self-supervised registration (NMSR) method for\nautomated myocardial and cardiac blood flow dense tracking. NMSR incorporates\ntwo novel components: 1) utilizing a deep neural net to parameterize the\nvelocity field between two image frames, and 2) optimizing the parameters of\nthe neural net in a sequential multi-scale fashion to account for large\nvariations within the velocity field. Experiments demonstrate that NMSR yields\nsignificantly better registration accuracy than state-of-the-art methods, such\nas advanced normalization tools (ANTs) and VoxelMorph, for both myocardial and\ncardiac blood flow dense tracking. Our approach promises to provide a fully\nautomated method for fast and accurate analyses of echocardiograms.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 03:05:47 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Zhu", "Wentao", ""], ["Huang", "Yufang", ""], ["Vannan", "Mani A", ""], ["Liu", "Shizhen", ""], ["Xu", "Daguang", ""], ["Fan", "Wei", ""], ["Qian", "Zhen", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1906.07590", "submitter": "Tobias Jacobs", "authors": "Prabhant Singh and Tobias Jacobs and Sebastien Nicolas and Mischa\n  Schmidt", "title": "A Study of the Learning Progress in Neural Architecture Search\n  Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural architecture search, the structure of the neural network to best\nmodel a given dataset is determined by an automated search process. Efficient\nNeural Architecture Search (ENAS), proposed by Pham et al. (2018), has recently\nreceived considerable attention due to its ability to find excellent\narchitectures within a comparably short search time. In this work, which is\nmotivated by the quest to further improve the learning speed of architecture\nsearch, we evaluate the learning progress of the controller which generates the\narchitectures in ENAS. We measure the progress by comparing the architectures\ngenerated by it at different controller training epochs, where architectures\nare evaluated after having re-trained them from scratch. As a surprising\nresult, we find that the learning curves are completely flat, i.e., there is no\nobservable progress of the controller in terms of the performance of its\ngenerated architectures. This observation is consistent across the CIFAR-10 and\nCIFAR-100 datasets and two different search spaces. We conclude that the high\nquality of the models generated by ENAS is a result of the search space design\nrather than the controller training, and our results indicate that one-shot\narchitecture design is an efficient alternative to architecture search by ENAS.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 14:00:19 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Singh", "Prabhant", ""], ["Jacobs", "Tobias", ""], ["Nicolas", "Sebastien", ""], ["Schmidt", "Mischa", ""]]}, {"id": "1906.07848", "submitter": "Sohrab Towfighi", "authors": "Sohrab Towfighi", "title": "Symbolic regression by uniform random global search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic regression (SR) is a data analysis problem where we search for the\nmathematical expression that best fits a numerical dataset. It is a global\noptimization problem. The most popular approach to SR is by genetic programming\n(SRGP). It is a common paradigm to compare an algorithm's performance to that\nof random search, but the data comparing SRGP to random search is lacking. We\ndescribe a novel algorithm for SR, namely SR by uniform random global search\n(SRURGS), also known as pure random search. We conduct experiments comparing\nSRURGS with SRGP using 100 randomly generated equations. Our results suggest\nthat a SRGP is faster than SRURGS in producing equations with good R^2 for\nsimple problems. However, our experiments suggest that SRURGS is more robust\nthan SRGP, able to produce good output in more challenging problems. As SRURGS\nis arguably the simplest global search algorithm, we believe it should serve as\na control algorithm against which other symbolic regression algorithms are\ncompared. SRURGS has only one tuning parameter, and is conceptually very\nsimple, making it a useful tool in solving SR problems. The method produces\nrandom equations, which is useful for the generation of symbolic regression\nbenchmark problems. We have released well documented and open-source python\ncode, currently under formal peer-review, so that interested researchers can\ndeploy the tool in practice.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 23:39:12 GMT"}, {"version": "v2", "created": "Sun, 7 Jul 2019 23:54:35 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2019 04:21:37 GMT"}, {"version": "v4", "created": "Mon, 18 Nov 2019 02:01:03 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Towfighi", "Sohrab", ""]]}, {"id": "1906.08167", "submitter": "Maryam Parsa", "authors": "Maryam Parsa, Aayush Ankit, Amirkoushyar Ziabari, Kaushik Roy", "title": "PABO: Pseudo Agent-Based Multi-Objective Bayesian Hyperparameter\n  Optimization for Efficient Neural Accelerator Design", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever increasing computational cost of Deep Neural Networks (DNN) and the\ndemand for energy efficient hardware for DNN acceleration has made accuracy and\nhardware cost co-optimization for DNNs tremendously important, especially for\nedge devices. Owing to the large parameter space and cost of evaluating each\nparameter in the search space, manually tuning of DNN hyperparameters is\nimpractical. Automatic joint DNN and hardware hyperparameter optimization is\nindispensable for such problems. Bayesian optimization-based approaches have\nshown promising results for hyperparameter optimization of DNNs. However, most\nof these techniques have been developed without considering the underlying\nhardware, thereby leading to inefficient designs. Further, the few works that\nperform joint optimization are not generalizable and mainly focus on CMOS-based\narchitectures. In this work, we present a novel pseudo agent-based\nmulti-objective hyperparameter optimization (PABO) for maximizing the DNN\nperformance while obtaining low hardware cost. Compared to the existing\nmethods, our work poses a theoretically different approach for joint\noptimization of accuracy and hardware cost and focuses on memristive\ncrossbar-based accelerators. PABO uses a supervisor agent to establish\nconnections between the posterior Gaussian distribution models of network\naccuracy and hardware cost requirements. The agent reduces the mathematical\ncomplexity of the co-optimization problem by removing unnecessary computations\nand updates of acquisition functions, thereby achieving significant speed-ups\nfor the optimization procedure. PABO outputs a Pareto frontier that underscores\nthe trade-offs between designing high-accuracy and hardware efficiency. Our\nresults demonstrate a superior performance compared to the state-of-the-art\nmethods both in terms of accuracy and computational speed (~100x speed up).\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 14:57:54 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Parsa", "Maryam", ""], ["Ankit", "Aayush", ""], ["Ziabari", "Amirkoushyar", ""], ["Roy", "Kaushik", ""]]}, {"id": "1906.08416", "submitter": "Emin Orhan", "authors": "A. Emin Orhan, Brenden M. Lake", "title": "Improving the robustness of ImageNet classifiers using elements of human\n  visual cognition", "comments": "v2 involves reformating and stylistic changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the robustness properties of image recognition models equipped\nwith two features inspired by human vision, an explicit episodic memory and a\nshape bias, at the ImageNet scale. As reported in previous work, we show that\nan explicit episodic memory improves the robustness of image recognition models\nagainst small-norm adversarial perturbations under some threat models. It does\nnot, however, improve the robustness against more natural, and typically\nlarger, perturbations. Learning more robust features during training appears to\nbe necessary for robustness in this second sense. We show that features derived\nfrom a model that was encouraged to learn global, shape-based representations\n(Geirhos et al., 2019) do not only improve the robustness against natural\nperturbations, but when used in conjunction with an episodic memory, they also\nprovide additional robustness against adversarial perturbations. Finally, we\naddress three important design choices for the episodic memory: memory size,\ndimensionality of the memories and the retrieval method. We show that to make\nthe episodic memory more compact, it is preferable to reduce the number of\nmemories by clustering them, instead of reducing their dimensionality.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 02:28:19 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 16:29:21 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Orhan", "A. Emin", ""], ["Lake", "Brenden M.", ""]]}, {"id": "1906.08482", "submitter": "Antonio H. Ribeiro", "authors": "Ant\\^onio H. Ribeiro and Koen Tiels and Luis A. Aguirre and Thomas B.\n  Sch\\\"on", "title": "Beyond exploding and vanishing gradients: analysing RNN training using\n  attractors and smoothness", "comments": "To appear in the Proceedings of the 23rd International Conference on\n  Artificial Intelligence and Statistics (AISTATS), 2020. PMLR: Volume 108.\n  This paper was previously titled \"The trade-off between long-term memory and\n  smoothness for recurrent networks\". The current version subsumes all previous\n  versions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploding and vanishing gradient problem has been the major conceptual\nprinciple behind most architecture and training improvements in recurrent\nneural networks (RNNs) during the last decade. In this paper, we argue that\nthis principle, while powerful, might need some refinement to explain recent\ndevelopments. We refine the concept of exploding gradients by reformulating the\nproblem in terms of the cost function smoothness, which gives insight into\nhigher-order derivatives and the existence of regions with many close local\nminima. We also clarify the distinction between vanishing gradients and the\nneed for the RNN to learn attractors to fully use its expressive power. Through\nthe lens of these refinements, we shed new light on recent developments in the\nRNN field, namely stable RNN and unitary (or orthogonal) RNNs.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 07:53:31 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 17:10:26 GMT"}, {"version": "v3", "created": "Thu, 5 Mar 2020 13:55:39 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Ribeiro", "Ant\u00f4nio H.", ""], ["Tiels", "Koen", ""], ["Aguirre", "Luis A.", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1906.08557", "submitter": "Wei Huang", "authors": "Wei Huang, Youcheng Sun, Xiaowei Huang and James Sharp", "title": "testRNN: Coverage-guided Testing on Recurrent Neural Networks", "comments": "Summited to ASE 2019 Demonstrations Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.SE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Recurrent neural networks (RNNs) have been widely applied to various\nsequential tasks such as text processing, video recognition, and molecular\nproperty prediction. We introduce the first coverage-guided testing tool,\ncoined testRNN, for the verification and validation of a major class of RNNs,\nlong short-term memory networks (LSTMs). The tool implements a generic\nmutation-based test case generation method, and it empirically evaluates the\nrobustness of a network using three novel LSTM structural test coverage\nmetrics. Moreover, it is able to help the model designer go through the\ninternal data flow processing of the LSTM layer. The tool is available through:\nhttps://github.com/TrustAI/testRNN under the BSD 3-Clause licence.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 11:09:44 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Huang", "Wei", ""], ["Sun", "Youcheng", ""], ["Huang", "Xiaowei", ""], ["Sharp", "James", ""]]}, {"id": "1906.08587", "submitter": "Nikolay Nikitin", "authors": "Pavel Vychuzhanin, Nikolay O. Nikitin, Anna V. Kalyuzhnaya", "title": "REBEC: Robust Evolutionary-based Calibration Approach for the Numerical\n  Wind Wave Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG physics.ao-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adaptation of numerical wind wave models to the local time-spatial\nconditions is a problem that can be solved by using various calibration\ntechniques. However, the obtained sets of physical parameters become over-tuned\nto specific events if there is a lack of observations. In this paper, we\npropose a robust evolutionary calibration approach that allows to build the\nstochastic ensemble of perturbed models and use it to achieve the trade-off\nbetween quality and robustness of the target model. The implemented robust\nensemble-based evolutionary calibration (REBEC) approach was compared to the\nbaseline SPEA2 algorithm in a set of experiments with the SWAN wind wave model\nconfiguration for the Kara Sea domain. Provided metrics for the set of\nscenarios confirm the effectiveness of the REBEC approach for the majority of\ncalibration scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 19 Mar 2019 14:25:19 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Vychuzhanin", "Pavel", ""], ["Nikitin", "Nikolay O.", ""], ["Kalyuzhnaya", "Anna V.", ""]]}, {"id": "1906.08804", "submitter": "Alianna Maren", "authors": "Alianna J. Maren", "title": "Derivation of the Variational Bayes Equations", "comments": "62 pages, 7 figures (one new); typos corrected, minor corrections to\n  equations, explanatory material added/revised, references added", "journal-ref": null, "doi": null, "report-no": "Themasis Technical Report TR-2019-01v4 (ajm)", "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The derivation of key equations for the variational Bayes approach is\nwell-known in certain circles. However, translating the fundamental derivations\n(e.g., as found in Beal (2003)) to the notation of Friston (2013, 2015) is\nsomewhat delicate. Further, the notion of using variational Bayes in the\ncontext of a system with Markov blankets requires special attention. This\nTechnical Report presents the derivation in detail. It further illustrates how\nthe variational Bayes method provides a framework for a new computational\nengine, incorporating the 2-D cluster variation method (CVM), which provides a\nnecessary free energy equation that can be minimized across both the external\nand representational systems' states, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 18:43:47 GMT"}, {"version": "v2", "created": "Mon, 24 Jun 2019 23:23:45 GMT"}, {"version": "v3", "created": "Wed, 26 Jun 2019 01:41:22 GMT"}, {"version": "v4", "created": "Tue, 30 Jul 2019 02:38:14 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Maren", "Alianna J.", ""]]}, {"id": "1906.08851", "submitter": "Yz Peng", "authors": "Chuyan Deng, Yuzhong Peng, Hongya Li, Daoqing Gong, Hao Zhang, Zhiping\n  Liu", "title": "A Seft-adaptive Multicellular GEP Algorithm Based On Fuzzy Control For\n  Function Optimization", "comments": "in Chinese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To improve the global optimization ability of traditional GEP algorithm, a\nMulticellular gene expression programming algorithm based on fuzzy control\n(Multicellular GEP Algorithm Based On Fuzzy Control, MGEP-FC) is proposed. The\nMGEP-FC algorithm describes the size of cross rate, mutation rate and real\nnumber mutation rate by constructing fuzzy membership function. According to\nthe concentration and dispersion of individual fitness values in population,\nthe crossover rate, mutation rate and real number set mutation rate of genetic\noperation are dynamically adjusted. In order to make the diversity of the\npopulation continue in the iterative process, a new genetic operation scheme is\ndesigned, which combines the new individuals with the parent population to\nbuild a temporary population, and the diversity of the temporary and\nsubpopulation are optimized. The results of 12 Benchmark optimization\nexperiments show that the MGEP-FC algorithm has been greatly improved in\nstability, global convergence and optimization speed.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 09:18:51 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Deng", "Chuyan", ""], ["Peng", "Yuzhong", ""], ["Li", "Hongya", ""], ["Gong", "Daoqing", ""], ["Zhang", "Hao", ""], ["Liu", "Zhiping", ""]]}, {"id": "1906.08852", "submitter": "Yz Peng", "authors": "Hongya Li, Yuzhong Peng, Chuyan Deng, Yonghua Pan, Daoqing Gong, Hao\n  Zhang", "title": "A Hybrid Precipitation Prediction Method based on Multicellular Gene\n  Expression Programming", "comments": "in Chinese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Prompt and accurate precipitation forecast is very important for development\nmanagement of regional water resource, flood disaster prevention and people's\ndaily activity and production plan; however, non-linear and nonstationary\ncharacteristics of precipitation data and noise seriously affect forecast\naccuracy. This paper combines multicellular gene expression programming with\nmore powerful function mining ability and wavelet analysis with more powerful\ndenoising and extracting data fine feature capability for precipitation\nforecast modeling, proposing to estimate meteorological precipitation with\nWTGEPRP algorithm. Comparative result for simulation experiment with actual\nprecipitation data in Zhengzhou, Nanning and Melbourne in Australia indicated\nthat: fitting and forecasting performance of WTGEPRP algorithm is better than\nthe algorithm Multicellular Gene Expression Programming-based Hybrid Model for\nPrecipitation Prediction Coupled with EMD, Supporting Vector Regression, BP\nNeural Network, Multicellular Gene Expression Programming and Gene Expression\nProgramming, and has good application prospect.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 09:36:05 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Li", "Hongya", ""], ["Peng", "Yuzhong", ""], ["Deng", "Chuyan", ""], ["Pan", "Yonghua", ""], ["Gong", "Daoqing", ""], ["Zhang", "Hao", ""]]}, {"id": "1906.08853", "submitter": "Roshan Gopalakrishnan", "authors": "Roshan Gopalakrishnan and Yansong Chua and Ashish Jith Sreejith Kumar", "title": "Hardware-friendly Neural Network Architecture for Neuromorphic Computing", "comments": "18 pages, 14 figures, 4 tables, submitted to Frontiers in\n  Neuroscience", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hardware-software co-optimization of neural network architectures is\nbecoming a major stream of research especially due to the emergence of\ncommercial neuromorphic chips such as the IBM Truenorth and Intel Loihi.\nDevelopment of specific neural network architectures in tandem with the design\nof the neuromorphic hardware considering the hardware constraints will make a\nhuge impact in the complete system level application. In this paper, we study\nvarious neural network architectures and propose one that is hardware-friendly\nfor a neuromorphic hardware with crossbar array of synapses. Considering the\nhardware constraints, we demonstrate how one may design the neuromorphic\nhardware so as to maximize classification accuracy in the trained network\narchitecture, while concurrently, we choose a neural network architecture so as\nto maximize utilization in the neuromorphic cores. We also proposed a framework\nfor mapping a neural network onto a neuromorphic chip named as the Mapping and\nDebugging (MaD) framework. The MaD framework is designed to be generic in the\nsense that it is a Python wrapper which in principle can be integrated with any\nsimulator tool for neuromorphic chips.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 09:47:00 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Gopalakrishnan", "Roshan", ""], ["Chua", "Yansong", ""], ["Kumar", "Ashish Jith Sreejith", ""]]}, {"id": "1906.08854", "submitter": "Nam Le", "authors": "Nam Le", "title": "Evolving Self-taught Neural Networks: The Baldwin Effect and the\n  Emergence of Intelligence", "comments": "12 pages, 7 figures, AISB Convention Falmouth UK 2019. arXiv admin\n  note: text overlap with arXiv:1906.08865", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The so-called Baldwin Effect generally says how learning, as a form of\nontogenetic adaptation, can influence the process of phylogenetic adaptation,\nor evolution. This idea has also been taken into computation in which evolution\nand learning are used as computational metaphors, including evolving neural\nnetworks. This paper presents a technique called evolving self-taught neural\nnetworks - neural networks that can teach themselves without external\nsupervision or reward. The self-taught neural network is intrinsically\nmotivated. Moreover, the self-taught neural network is the product of the\ninterplay between evolution and learning. We simulate a multi-agent system in\nwhich neural networks are used to control autonomous agents. These agents have\nto forage for resources and compete for their own survival. Experimental\nresults show that the interaction between evolution and the ability to teach\noneself in self-taught neural networks outperform evolution and self-teaching\nalone. More specifically, the emergence of an intelligent foraging strategy is\nalso demonstrated through that interaction. Indications for future work on\nevolving neural networks are also presented.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 15:57:08 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Le", "Nam", ""]]}, {"id": "1906.08855", "submitter": "Bestoun Ahmed Dr.", "authors": "Kamal Z.Zamli and Fakhrud Din and Salmi Baharom and Bestoun S.Ahmed", "title": "Fuzzy adaptive teaching learning-based optimization strategy for the\n  problem of generating mixed strength t-way test suites", "comments": null, "journal-ref": "2017 Engineering Applications of Artificial Intelligence", "doi": "10.1016/j.engappai.2016.12.014", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The teaching learning-based optimization (TLBO) algorithm has shown\ncompetitive performance in solving numerous real-world optimization problems.\nNevertheless, this algorithm requires better control for exploitation and\nexploration to prevent premature convergence (i.e., trapped in local optima),\nas well as enhance solution diversity. Thus, this paper proposes a new TLBO\nvariant based on Mamdani fuzzy inference system, called ATLBO, to permit\nadaptive selection of its global and local search operations. In order to\nassess its performances, we adopt ATLBO for the mixed strength t-way test\ngeneration problem. Experimental results reveal that ATLBO exhibits competitive\nperformances against the original TLBO and other meta-heuristic counterparts.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 06:58:08 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Zamli", "Kamal Z.", ""], ["Din", "Fakhrud", ""], ["Baharom", "Salmi", ""], ["Ahmed", "Bestoun S.", ""]]}, {"id": "1906.08856", "submitter": "Wei Luo", "authors": "Wei Luo and Feng Yu", "title": "Learning Longer-term Dependencies via Grouped Distributor Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning long-term dependencies still remains difficult for recurrent neural\nnetworks (RNNs) despite their success in sequence modeling recently. In this\npaper, we propose a novel gated RNN structure, which contains only one gate.\nHidden states in the proposed grouped distributor unit (GDU) are partitioned\ninto groups. For each group, the proportion of memory to be overwritten in each\nstate transition is limited to a constant and is adaptively distributed to each\ngroup member. In other word, every separate group has a fixed overall update\nrate, yet all units are allowed to have different paces. Information is\ntherefore forced to be latched in a flexible way, which helps the model to\ncapture long-term dependencies in data. Besides having a simpler structure, GDU\nis demonstrated experimentally to outperform LSTM and GRU on tasks including\nboth pathological problems and natural data set.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 02:08:27 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Luo", "Wei", ""], ["Yu", "Feng", ""]]}, {"id": "1906.08857", "submitter": "Sebastian Risi", "authors": "Sebastian Risi, Kenneth O. Stanley", "title": "Deep Neuroevolution of Recurrent and Discrete World Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architectures inspired by our own human cognitive system, such as the\nrecently introduced world models, have been shown to outperform traditional\ndeep reinforcement learning (RL) methods in a variety of different domains.\nInstead of the relatively simple architectures employed in most RL experiments,\nworld models rely on multiple different neural components that are responsible\nfor visual information processing, memory, and decision-making. However, so far\nthe components of these models have to be trained separately and through a\nvariety of specialized training methods. This paper demonstrates the surprising\nfinding that models with the same precise parts can be instead efficiently\ntrained end-to-end through a genetic algorithm (GA), reaching a comparable\nperformance to the original world model by solving a challenging car racing\ntask. An analysis of the evolved visual and memory system indicates that they\ninclude a similar effective representation to the system trained through\ngradient descent. Additionally, in contrast to gradient descent methods that\nstruggle with discrete variables, GAs also work directly with such\nrepresentations, opening up opportunities for classical planning in latent\nspace. This paper adds additional evidence on the effectiveness of deep\nneuroevolution for tasks that require the intricate orchestration of multiple\ncomponents in complex heterogeneous architectures.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 10:00:59 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Risi", "Sebastian", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "1906.08859", "submitter": "Yulia Sandamirskaya", "authors": "Bodo R\\\"uckauer, Nicolas K\\\"anzig, Shih-Chii Liu, Tobi Delbruck, and\n  Yulia Sandamirskaya", "title": "Closing the Accuracy Gap in an Event-Based Visual Recognition Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile and embedded applications require neural networks-based pattern\nrecognition systems to perform well under a tight computational budget. In\ncontrast to commonly used synchronous, frame-based vision systems and CNNs,\nasynchronous, spiking neural networks driven by event-based visual input\nrespond with low latency to sparse, salient features in the input, leading to\nhigh efficiency at run-time. The discrete nature of the event-based data\nstreams makes direct training of asynchronous neural networks challenging. This\npaper studies asynchronous spiking neural networks, obtained by conversion from\na conventional CNN trained on frame-based data. As an example, we consider a\nCNN trained to steer a robot to follow a moving target. We identify possible\npitfalls of the conversion and demonstrate how the proposed solutions bring the\nclassification accuracy of the asynchronous network to only 3\\% below the\nperformance of the original synchronous CNN, while requiring 12x fewer\ncomputations. While being applied to a simple task, this work is an important\nstep towards low-power, fast, and embedded neural networks-based vision\nsolutions for robotic applications.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 12:11:05 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["R\u00fcckauer", "Bodo", ""], ["K\u00e4nzig", "Nicolas", ""], ["Liu", "Shih-Chii", ""], ["Delbruck", "Tobi", ""], ["Sandamirskaya", "Yulia", ""]]}, {"id": "1906.08860", "submitter": "Jason Bernard", "authors": "Jason Bernard, Ian McQuillan", "title": "Techniques for Inferring Context-Free Lindenmayer Systems With Genetic\n  Algorithm", "comments": "28 pages, 3 figures", "journal-ref": null, "doi": "10.1016/j.swevo.2021.100893", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lindenmayer systems (L-systems) are a formal grammar system, where the most\nnotable feature is a set of rewriting rules that are used to replace every\nsymbol in a string in parallel; by repeating this process, a sequence of\nstrings is produced. Some symbols in the strings may be interpreted as\ninstructions for simulation software. Thus, the sequence can be used to model\nthe steps of a process. Currently, creating an L-system for a specific process\nis done by hand by experts through much effort. The inductive inference problem\nattempts to infer an L-system from such a sequence of strings generated by an\nunknown system; this can be thought of as an intermediate step to inferring\nfrom a sequence of images. This paper evaluates and analyzes different genetic\nalgorithm encoding schemes and mathematical properties for the L-system\ninductive inference problem. A new tool, the Plant Model Inference Tool for\nContext-Free L-systems (PMIT-D0L) is implemented based on these techniques.\nPMIT-D0L has been successfully evaluated on 28 known L-systems, with alphabets\nup to 31 symbols and a total sum of 281 symbols across the rewriting rules.\nPMIT-D0L can infer even the largest of these L-systems in less than a few\nseconds.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 18:48:57 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 14:19:53 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Bernard", "Jason", ""], ["McQuillan", "Ian", ""]]}, {"id": "1906.08861", "submitter": "Deboleena Roy", "authors": "Deboleena Roy, Priyadarshini Panda, and Kaushik Roy", "title": "Synthesizing Images from Spatio-Temporal Representations using\n  Spike-based Backpropagation", "comments": "17 pages, 10 Figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) offer a promising alternative to current\nartificial neural networks to enable low-power event-driven neuromorphic\nhardware. Spike-based neuromorphic applications require processing and\nextracting meaningful information from spatio-temporal data, represented as\nseries of spike trains over time. In this paper, we propose a method to\nsynthesize images from multiple modalities in a spike-based environment. We use\nspiking auto-encoders to convert image and audio inputs into compact\nspatio-temporal representations that is then decoded for image synthesis. For\nthis, we use a direct training algorithm that computes loss on the membrane\npotential of the output layer and back-propagates it by using a sigmoid\napproximation of the neuron's activation function to enable differentiability.\nThe spiking autoencoders are benchmarked on MNIST and Fashion-MNIST and achieve\nvery low reconstruction loss, comparable to ANNs. Then, spiking autoencoders\nare trained to learn meaningful spatio-temporal representations of the data,\nacross the two modalities - audio and visual. We synthesize images from audio\nin a spike-based environment by first generating, and then utilizing such\nshared multi-modal spatio-temporal representations. Our audio to image\nsynthesis model is tested on the task of converting TI-46 digits audio samples\nto MNIST images. We are able to synthesize images with high fidelity and the\nmodel achieves competitive performance against ANNs.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 01:33:15 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Roy", "Deboleena", ""], ["Panda", "Priyadarshini", ""], ["Roy", "Kaushik", ""]]}, {"id": "1906.08862", "submitter": "Thai Hung Le", "authors": "Hung Le, Truyen Tran and Svetha Venkatesh", "title": "Neural Stored-program Memory", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks powered with external memory simulate computer behaviors.\nThese models, which use the memory to store data for a neural controller, can\nlearn algorithms and other complex tasks. In this paper, we introduce a new\nmemory to store weights for the controller, analogous to the stored-program\nmemory in modern computer architectures. The proposed model, dubbed Neural\nStored-program Memory, augments current memory-augmented neural networks,\ncreating differentiable machines that can switch programs through time, adapt\nto variable contexts and thus resemble the Universal Turing Machine. A wide\nrange of experiments demonstrate that the resulting machines not only excel in\nclassical algorithmic problems, but also have potential for compositional,\ncontinual, few-shot learning and question-answering tasks.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 06:30:11 GMT"}, {"version": "v2", "created": "Thu, 26 Dec 2019 00:44:44 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Le", "Hung", ""], ["Tran", "Truyen", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1906.08863", "submitter": "Amir Mosavi", "authors": "Shahaboddin Shamshirband, Amir Mosavi, Timon Rabczuk", "title": "Particle swarm optimization model to predict scour depth around bridge\n  pier", "comments": "18 pages, 5 figures, journal paper", "journal-ref": null, "doi": "10.20944/preprints201905.0121.v1", "report-no": null, "categories": "cs.NE cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scour depth around bridge piers plays a vital role in the safety and\nstability of the bridges. Existing methods to predict scour depth are mainly\nbased on regression models or black box models in which the first one lacks\nenough accuracy while the later one does not provide a clear mathematical\nexpression to easily employ it for other situations or cases. Therefore, this\npaper aims to develop new equations using particle swarm optimization as a\nmetaheuristic approach to predict scour depth around bridge piers. To improve\nthe efficiency of the proposed model, individual equations are derived for\nlaboratory and field data. Moreover, sensitivity analysis is conducted to\nachieve the most effective parameters in the estimation of scour depth for both\nexperimental and filed data sets. Comparing the results of the proposed model\nwith those of existing regression-based equations reveal the superiority of the\nproposed method in terms of accuracy and uncertainty. Moreover, the ratio of\npier width to flow depth and ratio of d50 (mean particle diameter) to flow\ndepth for the laboratory and field data were recognized as the most effective\nparameters, respectively. The derived equations can be used as a suitable proxy\nto estimate scour depth in both experimental and prototype scales.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 06:53:32 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Shamshirband", "Shahaboddin", ""], ["Mosavi", "Amir", ""], ["Rabczuk", "Timon", ""]]}, {"id": "1906.08864", "submitter": "Erol Gelenbe", "authors": "Khaled F. Hussain, Mohamed Yousef Bassyouni, and Erol Gelenbe", "title": "Accurate and Energy-Efficient Classification with Spiking Random Neural\n  Network: Corrected and Expanded Version", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Artificial Neural Network (ANN) based techniques have dominated\nstate-of-the-art results in most problems related to computer vision, audio\nrecognition, and natural language processing in the past few years, resulting\nin strong industrial adoption from all leading technology companies worldwide.\nOne of the major obstacles that have historically delayed large scale adoption\nof ANNs is the huge computational and power costs associated with training and\ntesting (deploying) them. In the mean-time, Neuromorphic Computing platforms\nhave recently achieved remarkable performance running more bio-realistic\nSpiking Neural Networks at high throughput and very low power consumption\nmaking them a natural alternative to ANNs. Here, we propose using the Random\nNeural Network (RNN), a spiking neural network with both theoretical and\npractical appealing properties, as a general purpose classifier that can match\nthe classification power of ANNs on a number of tasks while enjoying all the\nfeatures of a spiking neural network. This is demonstrated on a number of\nreal-world classification datasets.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2019 18:49:57 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Hussain", "Khaled F.", ""], ["Bassyouni", "Mohamed Yousef", ""], ["Gelenbe", "Erol", ""]]}, {"id": "1906.08865", "submitter": "Nam Le", "authors": "Nam Le", "title": "Evolving Self-supervised Neural Networks: Autonomous Intelligence from\n  Evolved Self-teaching", "comments": "11. arXiv admin note: text overlap with arXiv:1906.08854", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a technique called evolving self-supervised neural\nnetworks - neural networks that can teach themselves, intrinsically motivated,\nwithout external supervision or reward. The proposed method presents some\nsort-of paradigm shift, and differs greatly from both traditional\ngradient-based learning and evolutionary algorithms in that it combines the\nmetaphor of evolution and learning, more specifically self-learning, together,\nrather than treating these phenomena alternatively. I simulate a multi-agent\nsystem in which neural networks are used to control autonomous foraging agents\nwith little domain knowledge. Experimental results show that only evolved\nself-supervised agents can demonstrate some sort of intelligent behaviour, but\nnot evolution or self-learning alone. Indications for future work on evolving\nintelligence are also presented.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 20:18:41 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Le", "Nam", ""]]}, {"id": "1906.08866", "submitter": "Xiaocong Du", "authors": "Xiaocong Du, Gokul Krishnan, Abinash Mohanty, Zheng Li, Gouranga\n  Charan, Yu Cao", "title": "Towards Efficient Neural Networks On-a-chip: Joint Hardware-Algorithm\n  Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms have made significant advances in many\napplications. However, their hardware implementation on the state-of-the-art\nplatforms still faces several challenges and are limited by various factors,\nsuch as memory volume, memory bandwidth and interconnection overhead. The\nadoption of the crossbar architecture with emerging memory technology partially\nsolves the problem but induces process variation and other concerns. In this\npaper, we will present novel solutions to two fundamental issues in crossbar\nimplementation of Artificial Intelligence (AI) algorithms: device variation and\ninsufficient interconnections. These solutions are inspired by the statistical\nproperties of algorithms themselves, especially the redundancy in neural\nnetwork nodes and connections. By Random Sparse Adaptation and pruning the\nconnections following the Small-World model, we demonstrate robust and\nefficient performance on representative datasets such as MNIST and CIFAR-10.\nMoreover, we present Continuous Growth and Pruning algorithm for future\nlearning and adaptation on hardware.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 00:07:48 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Du", "Xiaocong", ""], ["Krishnan", "Gokul", ""], ["Mohanty", "Abinash", ""], ["Li", "Zheng", ""], ["Charan", "Gouranga", ""], ["Cao", "Yu", ""]]}, {"id": "1906.08867", "submitter": "Bernd Bassimir", "authors": "Bernd Bassimir, Manuel Schmitt, Rolf Wanka", "title": "Self-adaptive Potential-based Stopping Criteria for Particle Swarm\n  Optimization", "comments": null, "journal-ref": "Swarm Intelligence 14, 285-311 (2020)", "doi": "10.1007/s11721-020-00185-z", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the variant of Particle Swarm Optimization (PSO) that applies random\nvelocities in a dimension instead of the regular velocity update equations as\nsoon as the so-called potential of the swarm falls below a certain bound in\nthis dimension, arbitrarily set by the user. In this case, the swarm performs a\nforced move. In this paper, we are interested in how, by counting the forced\nmoves, the swarm can decide for itself to stop its movement because it is\nimprobable to find better solution candidates as it already has found. We\nformally prove that when the swarm is close to a (local) optimum, it behaves\nlike a blind-searching cloud, and that the frequency of forced moves exceeds a\ncertain, objective function-independent value. Based on this observation, we\ndefine stopping criteria and evaluate them experimentally showing that good\nsolution candidates can be found much faster than applying other criteria.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 13:14:12 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Bassimir", "Bernd", ""], ["Schmitt", "Manuel", ""], ["Wanka", "Rolf", ""]]}, {"id": "1906.08868", "submitter": "Yunhao Tang", "authors": "Yunhao Tang, Krzysztof Choromanski, Alp Kucukelbir", "title": "Variance Reduction for Evolution Strategies via Structured Control\n  Variates", "comments": "Accepted to AISTATS (International Conference on Artificial\n  Intelligence and Statistics), 2020 in Palermo, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution Strategies (ES) are a powerful class of blackbox optimization\ntechniques that recently became a competitive alternative to state-of-the-art\npolicy gradient (PG) algorithms for reinforcement learning (RL). We propose a\nnew method for improving accuracy of the ES algorithms, that as opposed to\nrecent approaches utilizing only Monte Carlo structure of the gradient\nestimator, takes advantage of the underlying MDP structure to reduce the\nvariance. We observe that the gradient estimator of the ES objective can be\nalternatively computed using reparametrization and PG estimators, which leads\nto new control variate techniques for gradient estimation in ES optimization.\nWe provide theoretical insights and show through extensive experiments that\nthis RL-specific variance reduction approach outperforms general purpose\nvariance reduction methods.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 20:48:28 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 13:20:01 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Tang", "Yunhao", ""], ["Choromanski", "Krzysztof", ""], ["Kucukelbir", "Alp", ""]]}, {"id": "1906.08870", "submitter": "Andrew Sloss", "authors": "Andrew N. Sloss, Steven Gustafson", "title": "2019 Evolutionary Algorithms Review", "comments": "36 pages, 5 figures, Genetic Programming Theory & Practice 2019\n  (Presented)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithm research and applications began over 50 years ago.\nLike other artificial intelligence techniques, evolutionary algorithms will\nlikely see increased use and development due to the increased availability of\ncomputation, more robust and available open source software libraries, and the\nincreasing demand for artificial intelligence techniques. As these techniques\nbecome more adopted and capable, it is the right time to take a perspective of\ntheir ability to integrate into society and the human processes they intend to\naugment. In this review, we explore a new taxonomy of evolutionary algorithms\nand resulting classifications that look at five main areas: the ability to\nmanage the control of the environment with limiters, the ability to explain and\nrepeat the search process, the ability to understand input and output causality\nwithin a solution, the ability to manage algorithm bias due to data or user\ndesign, and lastly, the ability to add corrective measures. These areas are\nmotivated by today's pressures on industry to conform to both societies\nconcerns and new government regulatory rules. As many reviews of evolutionary\nalgorithms exist, after motivating this new taxonomy, we briefly classify a\nbroad range of algorithms and identify areas of future research.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 20:48:57 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Sloss", "Andrew N.", ""], ["Gustafson", "Steven", ""]]}, {"id": "1906.09047", "submitter": "Carsten Witt", "authors": "Hsien-Kuei Hwang and Carsten Witt", "title": "Sharp Bounds on the Runtime of the (1+1) EA via Drift Analysis and\n  Analytic Combinatorial Tools", "comments": "33 pages; preprint of a paper that will be published in the\n  proceedings of FOGA 2019; v2: minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expected running time of the classical (1+1) EA on the OneMax benchmark\nfunction has recently been determined by Hwang et al. (2018) up to additive\nerrors of $O((\\log n)/n)$. The same approach proposed there also leads to a\nfull asymptotic expansion with errors of the form $O(n^{-K}\\log n)$ for any\n$K>0$. This precise result is obtained by matched asymptotics with rigorous\nerror analysis (or by solving asymptotically the underlying recurrences via\ninductive approximation arguments), ideas radically different from\nwell-established techniques for the running time analysis of evolutionary\ncomputation such as drift analysis. This paper revisits drift analysis for the\n(1+1) EA on OneMax and obtains that the expected running time $E(T)$, starting\nfrom $\\lceil n/2\\rceil$ one-bits, is determined by the sum of inverse drifts up\nto logarithmic error terms, more precisely $$\\sum_{k=1}^{\\lfloor\nn/2\\rfloor}\\frac{1}{\\Delta(k)} - c_1\\log n \\le E(T) \\le \\sum_{k=1}^{\\lfloor\nn/2\\rfloor}\\frac{1}{\\Delta(k)} - c_2\\log n,$$ where $\\Delta(k)$ is the drift\n(expected increase of the number of one-bits from the state of $n-k$ ones) and\n$c_1,c_2 >0$ are explicitly computed constants. This improves the previous\nasymptotic error known for the sum of inverse drifts from $\\tilde{O}(n^{2/3})$\nto a logarithmic error and gives for the first time a non-asymptotic error\nbound. Using standard asymptotic techniques, the difference between $E(T)$ and\nthe sum of inverse drifts is found to be $(e/2)\\log n+O(1)$.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 10:25:39 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 06:51:25 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Hwang", "Hsien-Kuei", ""], ["Witt", "Carsten", ""]]}, {"id": "1906.09264", "submitter": "Baihan Lin", "authors": "Baihan Lin, Marieke Mur, Tim Kietzmann, Nikolaus Kriegeskorte", "title": "Visualizing Representational Dynamics with Multidimensional Scaling\n  Alignment", "comments": "CCN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representational similarity analysis (RSA) has been shown to be an effective\nframework to characterize brain-activity profiles and deep neural network\nactivations as representational geometry by computing the pairwise distances of\nthe response patterns as a representational dissimilarity matrix (RDM).\nHowever, how to properly analyze and visualize the representational geometry as\ndynamics over the time course from stimulus onset to offset is not well\nunderstood. In this work, we formulated the pipeline to understand\nrepresentational dynamics with RDM movies and Procrustes-aligned\nMultidimensional Scaling (pMDS), and applied it to neural recording of monkey\nIT cortex. Our results suggest that the the multidimensional scaling alignment\ncan genuinely capture the dynamics of the category-specific representation\nspaces with multiple visualization possibilities, and that object\ncategorization may be hierarchical, multi-staged, and oscillatory (or\nrecurrent).\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 03:46:18 GMT"}, {"version": "v2", "created": "Sun, 28 Jul 2019 12:07:06 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Lin", "Baihan", ""], ["Mur", "Marieke", ""], ["Kietzmann", "Tim", ""], ["Kriegeskorte", "Nikolaus", ""]]}, {"id": "1906.09453", "submitter": "Dimitris Tsipras", "authors": "Shibani Santurkar, Dimitris Tsipras, Brandon Tran, Andrew Ilyas, Logan\n  Engstrom, Aleksander Madry", "title": "Image Synthesis with a Single (Robust) Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the basic classification framework alone can be used to tackle\nsome of the most challenging tasks in image synthesis. In contrast to other\nstate-of-the-art approaches, the toolkit we develop is rather minimal: it uses\na single, off-the-shelf classifier for all these tasks. The crux of our\napproach is that we train this classifier to be adversarially robust. It turns\nout that adversarial robustness is precisely what we need to directly\nmanipulate salient features of the input. Overall, our findings demonstrate the\nutility of robustness in the broader machine learning context. Code and models\nfor our experiments can be found at https://git.io/robust-apps.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 09:12:08 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 15:47:42 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Tran", "Brandon", ""], ["Ilyas", "Andrew", ""], ["Engstrom", "Logan", ""], ["Madry", "Aleksander", ""]]}, {"id": "1906.09477", "submitter": "Dmitry Yarotsky", "authors": "Dmitry Yarotsky, Anton Zhevnerchuk", "title": "The phase diagram of approximation rates for deep neural networks", "comments": "The final version published at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the phase diagram of approximation rates for deep neural networks\nand prove several new theoretical results. In particular, we generalize the\nexisting result on the existence of deep discontinuous phase in ReLU networks\nto functional classes of arbitrary positive smoothness, and identify the\nboundary between the feasible and infeasible rates. Moreover, we show that all\nnetworks with a piecewise polynomial activation function have the same phase\ndiagram. Next, we demonstrate that standard fully-connected architectures with\na fixed width independent of smoothness can adapt to smoothness and achieve\nalmost optimal rates. Finally, we consider deep networks with periodic\nactivations (\"deep Fourier expansion\") and prove that they have very fast,\nnearly exponential approximation rates, thanks to the emerging capability of\nthe network to implement efficient lookup operations.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 17:56:14 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 22:28:06 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Yarotsky", "Dmitry", ""], ["Zhevnerchuk", "Anton", ""]]}, {"id": "1906.09480", "submitter": "Eszter V\\'ertes", "authors": "Eszter Vertes and Maneesh Sahani", "title": "A neurally plausible model learns successor representations in partially\n  observable environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals need to devise strategies to maximize returns while interacting with\ntheir environment based on incoming noisy sensory observations. Task-relevant\nstates, such as the agent's location within an environment or the presence of a\npredator, are often not directly observable but must be inferred using\navailable sensory information. Successor representations (SR) have been\nproposed as a middle-ground between model-based and model-free reinforcement\nlearning strategies, allowing for fast value computation and rapid adaptation\nto changes in the reward function or goal locations. Indeed, recent studies\nsuggest that features of neural responses are consistent with the SR framework.\nHowever, it is not clear how such representations might be learned and computed\nin partially observed, noisy environments. Here, we introduce a neurally\nplausible model using distributional successor features, which builds on the\ndistributed distributional code for the representation and computation of\nuncertainty, and which allows for efficient value function computation in\npartially observed environments via the successor representation. We show that\ndistributional successor features can support reinforcement learning in noisy\nenvironments in which direct learning of successful policies is infeasible.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 18:05:07 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Vertes", "Eszter", ""], ["Sahani", "Maneesh", ""]]}, {"id": "1906.09524", "submitter": "Jian Wang", "authors": "Yi-Fei PU, Jian Wang", "title": "Fractional-order Backpropagation Neural Networks: Modified\n  Fractional-order Steepest Descent Method for Family of Backpropagation Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper offers a novel mathematical approach, the modified\nFractional-order Steepest Descent Method (FSDM) for training BackPropagation\nNeural Networks (BPNNs); this differs from the majority of the previous\napproaches and as such. A promising mathematical method, fractional calculus,\nhas the potential to assume a prominent role in the applications of neural\nnetworks and cybernetics because of its inherent strengths such as long-term\nmemory, nonlocality, and weak singularity. Therefore, to improve the\noptimization performance of classic first-order BPNNs, in this paper we study\nwhether it could be possible to modified FSDM and generalize classic\nfirst-order BPNNs to modified FSDM based Fractional-order Backpropagation\nNeural Networks (FBPNNs). Motivated by this inspiration, this paper proposes a\nstate-of-the-art application of fractional calculus to implement a modified\nFSDM based FBPNN whose reverse incremental search is in the negative directions\nof the approximate fractional-order partial derivatives of the square error. At\nfirst, the theoretical concept of a modified FSDM based FBPNN is described\nmathematically. Then, the mathematical proof of the fractional-order global\noptimal convergence, an assumption of the structure, and the fractional-order\nmulti-scale global optimization of a modified FSDM based FBPNN are analysed in\ndetail. Finally, we perform comparative experiments and compare a modified FSDM\nbased FBPNN with a classic first-order BPNN, i.e., an example function\napproximation, fractional-order multi-scale global optimization, and two\ncomparative performances with real data. The more efficient optimal searching\ncapability of the fractional-order multi-scale global optimization of a\nmodified FSDM based FBPNN to determine the global optimal solution is the major\nadvantage being superior to a classic first-order BPNN.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 00:30:23 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 08:05:57 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["PU", "Yi-Fei", ""], ["Wang", "Jian", ""]]}, {"id": "1906.09531", "submitter": "Aditya Grover", "authors": "Aditya Grover, Jiaming Song, Alekh Agarwal, Kenneth Tran, Ashish\n  Kapoor, Eric Horvitz, Stefano Ermon", "title": "Bias Correction of Learned Generative Models using Likelihood-Free\n  Importance Weighting", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A learned generative model often produces biased statistics relative to the\nunderlying data distribution. A standard technique to correct this bias is\nimportance sampling, where samples from the model are weighted by the\nlikelihood ratio under model and true distributions. When the likelihood ratio\nis unknown, it can be estimated by training a probabilistic classifier to\ndistinguish samples from the two distributions. We employ this likelihood-free\nimportance weighting method to correct for the bias in generative models. We\nfind that this technique consistently improves standard goodness-of-fit metrics\nfor evaluating the sample quality of state-of-the-art deep generative models,\nsuggesting reduced bias. Finally, we demonstrate its utility on representative\napplications in a) data augmentation for classification using generative\nadversarial networks, and b) model-based policy evaluation using off-policy\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 01:57:29 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2019 08:27:22 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Grover", "Aditya", ""], ["Song", "Jiaming", ""], ["Agarwal", "Alekh", ""], ["Tran", "Kenneth", ""], ["Kapoor", "Ashish", ""], ["Horvitz", "Eric", ""], ["Ermon", "Stefano", ""]]}, {"id": "1906.09807", "submitter": "Cristian Bodnar", "authors": "Cristian Bodnar, Ben Day, Pietro Li\\'o", "title": "Proximal Distilled Evolutionary Reinforcement Learning", "comments": "Camera-ready version for AAAI-20. Contains 10 pages, 11 figures", "journal-ref": "Vol 34 No 04: AAAI 2020 Technical Track on Machine Learning\n  3283-3290", "doi": "10.1609/aaai.v34i04.5728", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) has achieved impressive performance in many\ncomplex environments due to the integration with Deep Neural Networks (DNNs).\nAt the same time, Genetic Algorithms (GAs), often seen as a competing approach\nto RL, had limited success in scaling up to the DNNs required to solve\nchallenging tasks. Contrary to this dichotomic view, in the physical world,\nevolution and learning are complementary processes that continuously interact.\nThe recently proposed Evolutionary Reinforcement Learning (ERL) framework has\ndemonstrated mutual benefits to performance when combining the two methods.\nHowever, ERL has not fully addressed the scalability problem of GAs. In this\npaper, we show that this problem is rooted in an unfortunate combination of a\nsimple genetic encoding for DNNs and the use of traditional\nbiologically-inspired variation operators. When applied to these encodings, the\nstandard operators are destructive and cause catastrophic forgetting of the\ntraits the networks acquired. We propose a novel algorithm called Proximal\nDistilled Evolutionary Reinforcement Learning (PDERL) that is characterised by\na hierarchical integration between evolution and learning. The main innovation\nof PDERL is the use of learning-based variation operators that compensate for\nthe simplicity of the genetic representation. Unlike traditional operators, our\nproposals meet the functional requirements of variation operators when applied\non directly-encoded DNNs. We evaluate PDERL in five robot locomotion settings\nfrom the OpenAI gym. Our method outperforms ERL, as well as two\nstate-of-the-art RL algorithms, PPO and TD3, in all tested environments.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 09:31:09 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 23:22:47 GMT"}, {"version": "v3", "created": "Thu, 28 Nov 2019 21:19:53 GMT"}, {"version": "v4", "created": "Tue, 7 Jul 2020 10:29:57 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Bodnar", "Cristian", ""], ["Day", "Ben", ""], ["Li\u00f3", "Pietro", ""]]}, {"id": "1906.09972", "submitter": "Daniel Rivero", "authors": "Daniel Rivero, Enrique Fernandez-Blanco, Alejandro Pazos", "title": "Classical Music Prediction and Composition by means of Variational\n  Autoencoders", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.NE eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new model for music prediction based on Variational\nAutoencoders (VAEs). In this work, VAEs are used in a novel way in order to\naddress two different problems: music representation into the latent space, and\nusing this representation to make predictions of the future values of the\nmusical piece. This approach was trained with different songs of a classical\ncomposer. As a result, the system can represent the music in the latent space,\nand make accurate predictions. Therefore, the system can be used to compose new\nmusic either from an existing piece or from a random starting point. An\nadditional feature of this system is that a small dataset was used for\ntraining. However, results show that the system is able to return accurate\nrepresentations and predictions in unseen data.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 15:44:12 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Rivero", "Daniel", ""], ["Fernandez-Blanco", "Enrique", ""], ["Pazos", "Alejandro", ""]]}, {"id": "1906.10015", "submitter": "Pablo Lanillos", "authors": "Pablo Lanillos, Daniel Oliva, Anja Philippsen, Yuichi Yamashita, Yukie\n  Nagai, Gordon Cheng", "title": "A Review on Neural Network Models of Schizophrenia and Autism Spectrum\n  Disorder", "comments": "Preprint submitted to Neural Networks. Research not referenced in the\n  manuscript within the field of NN models of SZ and ASD are encouraged to\n  contact the corresponding authors", "journal-ref": "Neural Networks 122 (2020) 338-363", "doi": "10.1016/j.neunet.2019.10.014", "report-no": null, "categories": "q-bio.NC cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey presents the most relevant neural network models of autism\nspectrum disorder and schizophrenia, from the first connectionist models to\nrecent deep network architectures. We analyzed and compared the most\nrepresentative symptoms with its neural model counterpart, detailing the\nalteration introduced in the network that generates each of the symptoms, and\nidentifying their strengths and weaknesses. We additionally cross-compared\nBayesian and free-energy approaches, as they are widely applied to modeling\npsychiatric disorders and share basic mechanisms with neural networks. Models\nof schizophrenia mainly focused on hallucinations and delusional thoughts using\nneural dysconnections or inhibitory imbalance as the predominating alteration.\nModels of autism rather focused on perceptual difficulties, mainly excessive\nattention to environment details, implemented as excessive inhibitory\nconnections or increased sensory precision. We found an excessive tight view of\nthe psychopathologies around one specific and simplified effect, usually\nconstrained to the technical idiosyncrasy of the used network architecture.\nRecent theories and evidence on sensorimotor integration and body perception\ncombined with modern neural network architectures could offer a broader and\nnovel spectrum to approach these psychopathologies. This review emphasizes the\npower of artificial neural networks for modeling some symptoms of neurological\ndisorders but also calls for further developing these techniques in the field\nof computational psychiatry.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 15:10:44 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 09:25:59 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Lanillos", "Pablo", ""], ["Oliva", "Daniel", ""], ["Philippsen", "Anja", ""], ["Yamashita", "Yuichi", ""], ["Nagai", "Yukie", ""], ["Cheng", "Gordon", ""]]}, {"id": "1906.10189", "submitter": "Joel Lehman", "authors": "Joel Lehman", "title": "Evolutionary Computation and AI Safety: Research Problems Impeding\n  Routine and Safe Real-world Application of Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in artificial intelligence and machine learning have\nspurred interest in the growing field of AI safety, which studies how to\nprevent human-harming accidents when deploying AI systems. This paper thus\nexplores the intersection of AI safety with evolutionary computation, to show\nhow safety issues arise in evolutionary computation and how understanding from\nevolutionary computational and biological evolution can inform the broader\nstudy of AI safety.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 19:26:10 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 17:49:07 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Lehman", "Joel", ""]]}, {"id": "1906.10592", "submitter": "Pablo Lanillos", "authors": "Michael Deistler, Yagmur Yener, Florian Bergner, Pablo Lanillos, and\n  Gordon Cheng", "title": "Tactile Hallucinations on Artificial Skin Induced by Homeostasis in a\n  Deep Boltzmann Machine", "comments": "Submitted to 2019 IEEE International Conference on Cyborg and Bionic\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perceptual hallucinations are present in neurological and psychiatric\ndisorders and amputees. While the hallucinations can be drug-induced, it has\nbeen described that they can even be provoked in healthy subjects.\nUnderstanding their manifestation could thus unveil how the brain processes\nsensory information and might evidence the generative nature of perception. In\nthis work, we investigate the generation of tactile hallucinations on\nbiologically inspired, artificial skin. To model tactile hallucinations, we\napply homeostasis, a change in the excitability of neurons during sensory\ndeprivation, in a Deep Boltzmann Machine (DBM). We find that homeostasis\nprompts hallucinations of previously learned patterns on the artificial skin in\nthe absence of sensory input. Moreover, we show that homeostasis is capable of\ninducing the formation of meaningful latent representations in a DBM and that\nit significantly increases the quality of the reconstruction of these latent\nstates. Through this, our work provides a possible explanation for the nature\nof tactile hallucinations and highlights homeostatic processes as a potential\nunderlying mechanism.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 15:14:49 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 11:20:03 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Deistler", "Michael", ""], ["Yener", "Yagmur", ""], ["Bergner", "Florian", ""], ["Lanillos", "Pablo", ""], ["Cheng", "Gordon", ""]]}, {"id": "1906.10852", "submitter": "Sadaqat ur Rehman", "authors": "Sadaqat ur Rehman, Zhongliang Yang, Muhammad Shahid, Nan Wei, Yongfeng\n  Huang, Muhammad Waqas, Shanshan Tu, Obaid ur Rehman", "title": "Water Preservation in Soan River Basin using Deep Learning Techniques", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Water supplies are crucial for the development of living beings. However,\nchange in the hydrological process i.e. climate and land usage are the key\nissues. Sustaining water level and accurate estimating for dynamic conditions\nis a critical job for hydrologists, but predicting hydrological extremes is an\nopen issue. In this paper, we proposed two deep learning techniques and three\nmachine learning algorithms to predict stream flow, given the present climate\nconditions. The results showed that the Recurrent Neural Network (RNN) or Long\nShort-term Memory (LSTM), an artificial neural network based method, outperform\nother conventional and machine-learning algorithms for predicting stream flow.\nFurthermore, we analyzed that stream flow is directly affected by\nprecipitation, land usage, and temperature. These indexes are critical, which\ncan be used by hydrologists to identify the potential for stream flow. We make\nthe dataset publicly available (https://github.com/sadaqat007/Dataset) so that\nothers should be able to replicate and build upon the results published.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 05:26:31 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Rehman", "Sadaqat ur", ""], ["Yang", "Zhongliang", ""], ["Shahid", "Muhammad", ""], ["Wei", "Nan", ""], ["Huang", "Yongfeng", ""], ["Waqas", "Muhammad", ""], ["Tu", "Shanshan", ""], ["Rehman", "Obaid ur", ""]]}, {"id": "1906.10918", "submitter": "Bart Bussmann", "authors": "Bart Bussmann, Jacqueline Heinerman, Joel Lehman", "title": "Towards Empathic Deep Q-Learning", "comments": "To be presented as a poster at the IJCAI-19 AI Safety Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As reinforcement learning (RL) scales to solve increasingly complex tasks,\ninterest continues to grow in the fields of AI safety and machine ethics. As a\ncontribution to these fields, this paper introduces an extension to Deep\nQ-Networks (DQNs), called Empathic DQN, that is loosely inspired both by\nempathy and the golden rule (\"Do unto others as you would have them do unto\nyou\"). Empathic DQN aims to help mitigate negative side effects to other agents\nresulting from myopic goal-directed behavior. We assume a setting where a\nlearning agent coexists with other independent agents (who receive unknown\nrewards), where some types of reward (e.g. negative rewards from physical harm)\nmay generalize across agents. Empathic DQN combines the typical (self-centered)\nvalue with the estimated value of other agents, by imagining (by its own\nstandards) the value of it being in the other's situation (by considering\nconstructed states where both agents are swapped). Proof-of-concept results in\ntwo gridworld environments highlight the approach's potential to decrease\ncollateral harms. While extending Empathic DQN to complex environments is\nnon-trivial, we believe that this first step highlights the potential of\nbridge-work between machine ethics and RL to contribute useful priors for\nnorm-abiding RL agents.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 08:59:02 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Bussmann", "Bart", ""], ["Heinerman", "Jacqueline", ""], ["Lehman", "Joel", ""]]}, {"id": "1906.11122", "submitter": "Luca Magri", "authors": "Nguyen Anh Khoa Doan, Wolfgang Polifke, Luca Magri", "title": "Physics-Informed Echo State Networks for Chaotic Systems Forecasting", "comments": "7 pages, 3 figures", "journal-ref": "Computational Science - ICCS 2019. ICCS 2019. Lecture Notes in\n  Computer Science, vol 11539. Springer, Cham", "doi": "10.1007/978-3-030-22747-0_15", "report-no": null, "categories": "physics.soc-ph cs.ET cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a physics-informed Echo State Network (ESN) to predict the\nevolution of chaotic systems. Compared to conventional ESNs, the\nphysics-informed ESNs are trained to solve supervised learning tasks while\nensuring that their predictions do not violate physical laws. This is achieved\nby introducing an additional loss function during the training of the ESNs,\nwhich penalizes non-physical predictions without the need of any additional\ntraining data. This approach is demonstrated on a chaotic Lorenz system, where\nthe physics-informed ESNs improve the predictability horizon by about two\nLyapunov times as compared to conventional ESNs. The proposed framework shows\nthe potential of using machine learning combined with prior physical knowledge\nto improve the time-accurate prediction of chaotic dynamical systems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 10:01:56 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Doan", "Nguyen Anh Khoa", ""], ["Polifke", "Wolfgang", ""], ["Magri", "Luca", ""]]}, {"id": "1906.11290", "submitter": "Aurelio F. Bariviera", "authors": "Augusto Villa-Monte, Laura Lanzarini, Aurelio F. Bariviera, Jos\\'e A.\n  Olivas", "title": "User-Oriented Summaries Using a PSO Based Scoring Optimization Method", "comments": null, "journal-ref": "Entropy. 2019; 21(6):617", "doi": "10.3390/e21060617", "report-no": null, "categories": "cs.LG cs.IR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic text summarization tools have a great impact on many fields, such\nas medicine, law, and scientific research in general. As information overload\nincreases, automatic summaries allow handling the growing volume of documents,\nusually by assigning weights to the extracted phrases based on their\nsignificance in the expected summary. Obtaining the main contents of any given\ndocument in less time than it would take to do that manually is still an issue\nof interest. In~this~ article, a new method is presented that allows\nautomatically generating extractive summaries from documents by adequately\nweighting sentence scoring features using \\textit{Particle Swarm Optimization}.\nThe key feature of the proposed method is the identification of those features\nthat are closest to the criterion used by the individual when summarizing. The\nproposed method combines a binary representation and a continuous one, using an\noriginal variation of the technique developed by the authors of this paper. Our\npaper shows that using user labeled information in the training set helps to\nfind better metrics and weights. The empirical results yield an improved\naccuracy compared to previous methods used in this field\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 18:27:54 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Villa-Monte", "Augusto", ""], ["Lanzarini", "Laura", ""], ["Bariviera", "Aurelio F.", ""], ["Olivas", "Jos\u00e9 A.", ""]]}, {"id": "1906.11626", "submitter": "Shiwei Liu", "authors": "Shiwei Liu, Decebal Constantin Mocanu, Mykola Pechenizkiy", "title": "On improving deep learning generalization with adaptive sparse\n  connectivity", "comments": "ICML 2019 Workshop on Understanding and Improving Generalization in\n  Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large neural networks are very successful in various tasks. However, with\nlimited data, the generalization capabilities of deep neural networks are also\nvery limited. In this paper, we empirically start showing that intrinsically\nsparse neural networks with adaptive sparse connectivity, which by design have\na strict parameter budget during the training phase, have better generalization\ncapabilities than their fully-connected counterparts. Besides this, we propose\na new technique to train these sparse models by combining the Sparse\nEvolutionary Training (SET) procedure with neurons pruning. Operated on\nMultiLayer Perceptron (MLP) and tested on 15 datasets, our proposed technique\nzeros out around 50% of the hidden neurons during training, while having a\nlinear number of parameters to optimize with respect to the number of neurons.\nThe results show a competitive classification and generalization performance.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 13:31:30 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Liu", "Shiwei", ""], ["Mocanu", "Decebal Constantin", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1906.11667", "submitter": "Shashank Kotyan", "authors": "Shashank Kotyan and Danilo Vasconcellos Vargas", "title": "Evolving Robust Neural Architectures to Defend from Adversarial Attacks", "comments": "Pre-print of the published article in Proceedings of the Workshop on\n  Artificial Intelligence Safety 2020, co-located with the 29th International\n  Joint Conference on Artificial Intelligence and the 17th Pacific Rim\n  International Conference on Artificial Intelligence (IJCAI-PRICAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CR cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks are prone to misclassify slightly modified input images.\nRecently, many defences have been proposed, but none have improved the\nrobustness of neural networks consistently. Here, we propose to use adversarial\nattacks as a function evaluation to search for neural architectures that can\nresist such attacks automatically. Experiments on neural architecture search\nalgorithms from the literature show that although accurate, they are not able\nto find robust architectures. A significant reason for this lies in their\nlimited search space. By creating a novel neural architecture search with\noptions for dense layers to connect with convolution layers and vice-versa as\nwell as the addition of concatenation layers in the search, we were able to\nevolve an architecture that is inherently accurate on adversarial samples.\nInterestingly, this inherent robustness of the evolved architecture rivals\nstate-of-the-art defences such as adversarial training while being trained only\non the non-adversarial samples. Moreover, the evolved architecture makes use of\nsome peculiar traits which might be useful for developing even more robust\nones. Thus, the results here confirm that more robust architectures exist as\nwell as opens up a new realm of feasibilities for the development and\nexploration of neural networks.\n  Code available at http://bit.ly/RobustArchitectureSearch.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 14:12:52 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 20:46:26 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 13:34:50 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Kotyan", "Shashank", ""], ["Vargas", "Danilo Vasconcellos", ""]]}, {"id": "1906.11684", "submitter": "Spencer Kent", "authors": "Spencer J. Kent, E. Paxon Frady, Friedrich T. Sommer, Bruno A.\n  Olshausen", "title": "Resonator Networks outperform optimization methods at solving\n  high-dimensional vector factorization", "comments": "arXiv's LaTeX compiler contains a compatibility issue with the\n  subcaption package, screwing up the placement of Figure 6 (and subsequent\n  figures) in V3. This update simply remedies that issue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop theoretical foundations of Resonator Networks, a new type of\nrecurrent neural network introduced in Frady et al. (2020) to solve a\nhigh-dimensional vector factorization problem arising in Vector Symbolic\nArchitectures. Given a composite vector formed by the Hadamard product between\na discrete set of high-dimensional vectors, a Resonator Network can efficiently\ndecompose the composite into these factors. We compare the performance of\nResonator Networks against optimization-based methods, including Alternating\nLeast Squares and several gradient-based algorithms, showing that Resonator\nNetworks are superior in several important ways. This advantage is achieved by\nleveraging a combination of nonlinear dynamics and \"searching in\nsuperposition,\" by which estimates of the correct solution are formed from a\nweighted superposition of all possible solutions. While the alternative methods\nalso search in superposition, the dynamics of Resonator Networks allow them to\nstrike a more effective balance between exploring the solution space and\nexploiting local information to drive the network toward probable solutions.\nResonator Networks are not guaranteed to converge, but within a particular\nregime they almost always do. In exchange for relaxing this guarantee of global\nconvergence, Resonator Networks are dramatically more effective at finding\nfactorizations than all alternative approaches considered.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 13:18:03 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 00:47:36 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2020 21:52:31 GMT"}, {"version": "v4", "created": "Tue, 14 Jul 2020 19:04:13 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Kent", "Spencer J.", ""], ["Frady", "E. Paxon", ""], ["Sommer", "Friedrich T.", ""], ["Olshausen", "Bruno A.", ""]]}, {"id": "1906.11770", "submitter": "Tomoki Kurikawa", "authors": "Tomoki Kurikawa, Omri Barak, Kunihiko Kaneko", "title": "Repeated sequential learning increases memory capacity via effective\n  decorrelation in a recurrent neural network", "comments": null, "journal-ref": "Phys. Rev. Research 2, 023307 (2020)", "doi": "10.1103/PhysRevResearch.2.023307", "report-no": null, "categories": "nlin.AO cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memories in neural system are shaped through the interplay of neural and\nlearning dynamics under external inputs. By introducing a simple local learning\nrule to a neural network, we found that the memory capacity is drastically\nincreased by sequentially repeating the learning steps of input-output\nmappings. The origin of this enhancement is attributed to the generation of a\nPsuedo-inverse correlation in the connectivity. This is associated with the\nemergence of spontaneous activity that intermittently exhibits neural patterns\ncorresponding to embedded memories. Stablization of memories is achieved by a\ndistinct bifurcation from the spontaneous activity under the application of\neach input.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 13:47:33 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kurikawa", "Tomoki", ""], ["Barak", "Omri", ""], ["Kaneko", "Kunihiko", ""]]}, {"id": "1906.11826", "submitter": "Hananel Hazan", "authors": "Hananel Hazan, Daniel J. Saunders, Darpan T. Sanghavi, Hava\n  Siegelmann, and Robert Kozma", "title": "Lattice Map Spiking Neural Networks (LM-SNNs) for Clustering and\n  Classifying Image Data", "comments": "Original Manuscript Submitted: October 30, 2018. Revised: May 28,\n  2019. Special Issue: \"Cognition and Neurocomputation\" of Annals of\n  Mathematics and Artificial Intelligence. arXiv admin note: text overlap with\n  arXiv:1807.09374", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Spiking neural networks (SNNs) with a lattice architecture are introduced in\nthis work, combining several desirable properties of SNNs and self-organized\nmaps (SOMs). Networks are trained with biologically motivated, unsupervised\nlearning rules to obtain a self-organized grid of filters via cooperative and\ncompetitive excitatory-inhibitory interactions. Several inhibition strategies\nare developed and tested, such as (i) incrementally increasing inhibition level\nover the course of network training, and (ii) switching the inhibition level\nfrom low to high (two-level) after an initial training segment. During the\nlabeling phase, the spiking activity generated by data with known labels is\nused to assign neurons to categories of data, which are then used to evaluate\nthe network's classification ability on a held-out set of test data. Several\nbiologically plausible evaluation rules are proposed and compared, including a\npopulation-level confidence rating, and an $n$-gram inspired method. The\neffectiveness of the proposed self-organized learning mechanism is tested using\nthe MNIST benchmark dataset, as well as using images produced by playing the\nAtari Breakout game.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2019 18:44:22 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Hazan", "Hananel", ""], ["Saunders", "Daniel J.", ""], ["Sanghavi", "Darpan T.", ""], ["Siegelmann", "Hava", ""], ["Kozma", "Robert", ""]]}, {"id": "1906.11878", "submitter": "Hossein Ghayoumi Zadeh", "authors": "Mehdi Abbaszadeh, Aliakbar Rahimifard, Mohammadali Eftekhari, Hossein\n  Ghayoumi Zadeh, Ali Fayazi, Ali Dini, Mostafa Danaeian", "title": "Deep Learning-Based Classification Of the Defective Pistachios Via Deep\n  Autoencoder Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pistachio nut is mainly consumed as raw, salted or roasted because of its\nhigh nutritional properties and favorable taste. Pistachio nuts with shell and\nkernel defects, besides not being acceptable for a consumer, are also prone to\ninsects damage, mold decay, and aflatoxin contamination. In this research, a\ndeep learning-based imaging algorithm was developed to improve the sorting of\nnuts with shell and kernel defects that indicate the risk of aflatoxin\ncontamination, such as dark stains, oily stains, adhering hull, fungal decay\nand Aspergillus molds. This paper presents an unsupervised learning method to\nclassify defective and unpleasant pistachios based on deep Auto-encoder neural\nnetworks. The testing of the designed neural network on a validation dataset\nshowed that nuts having dark stain, oily stain or adhering hull with an\naccuracy of 80.3% can be distinguished from normal nuts. Due to the limited\nmemory available in the HPC of university, the results are reasonable and\njustifiable.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 13:02:50 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Abbaszadeh", "Mehdi", ""], ["Rahimifard", "Aliakbar", ""], ["Eftekhari", "Mohammadali", ""], ["Zadeh", "Hossein Ghayoumi", ""], ["Fayazi", "Ali", ""], ["Dini", "Ali", ""], ["Danaeian", "Mostafa", ""]]}, {"id": "1906.11912", "submitter": "Luna Zhang", "authors": "Luna M. Zhang", "title": "A New Compensatory Genetic Algorithm-Based Method for Effective\n  Compressed Multi-function Convolutional Neural Network Model Selection with\n  Multi-Objective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there have been many popular Convolutional Neural Networks\n(CNNs), such as Google's Inception-V4, that have performed very well for\nvarious image classification problems. These commonly used CNN models usually\nuse the same activation function, such as RELU, for all neurons in the\nconvolutional layers; they are \"Single-function CNNs.\" However, SCNNs may not\nalways be optimal. Thus, a \"Multi-function CNN\" (MCNN), which uses different\nactivation functions for different neurons, has been shown to outperform a\nSCNN. Also, CNNs typically have very large architectures that use a lot of\nmemory and need a lot of data in order to be trained well. As a result, they\ntend to have very high training and prediction times too. An important research\nproblem is how to automatically and efficiently find the best CNN with both\nhigh classification performance and compact architecture with high training and\nprediction speeds, small power usage, and small memory size for any image\nclassification problem. It is very useful to intelligently find an effective,\nfast, energy-efficient, and memory-efficient \"Compressed Multi-function CNN\"\n(CMCNN) from a large number of candidate MCNNs. A new compensatory algorithm\nusing a new genetic algorithm (GA) is created to find the best CMCNN with an\nideal compensation between performance and architecture size. The optimal CMCNN\nhas the best performance and the smallest architecture size. Simulations using\nthe CIFAR10 dataset showed that the new compensatory algorithm could find\nCMCNNs that could outperform non-compressed MCNNs in terms of classification\nperformance (F1-score), speed, power usage, and memory usage. Other effective,\nfast, power-efficient, and memory-efficient CMCNNs based on popular CNN\narchitectures will be developed for image classification problems in important\nreal-world applications, such as brain informatics and biomedical imaging.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jun 2019 04:09:19 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Zhang", "Luna M.", ""]]}, {"id": "1906.12045", "submitter": "Dmitri Strukov B", "authors": "Hyungjin Kim, Hussein Nili, Mahmood Mahmoodi, and Dmitri Strukov", "title": "4K-Memristor Analog-Grade Passive Crossbar Circuit", "comments": "18 pages, 4 figures in main text, 4 figures in SI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The superior density of passive analog-grade memristive crossbars may enable\nstoring large synaptic weight matrices directly on specialized neuromorphic\nchips, thus avoiding costly off-chip communication. To ensure efficient use of\nsuch crossbars in neuromorphic computing circuits, variations of\ncurrent-voltage characteristics of crosspoint devices must be substantially\nlower than those of memory cells with select transistors. Apparently, this\nrequirement explains why there were so few demonstrations of neuromorphic\nsystem prototypes using passive crossbars. Here we report a 64x64 passive\nmetal-oxide memristor crossbar circuit with ~99% device yield, based on a\nfoundry-compatible fabrication process featuring etch-down patterning and\nlow-temperature budget, conducive to vertical integration. The achieved ~26%\nvariations of switching voltages of our devices were sufficient for programming\n4K-pixel gray-scale patterns with an average tuning error smaller than 4%. The\nanalog properties were further verified by experimentally demonstrating MNIST\npattern classification with a fidelity close to the software-modeled limit for\na network of this size, with an ~1% average error of import of\nex-situ-calculated synaptic weights. We believe that our work is a significant\nimprovement over the state-of-the-art passive crossbar memories in both\ncomplexity and analog properties.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 00:31:48 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Kim", "Hyungjin", ""], ["Nili", "Hussein", ""], ["Mahmoodi", "Mahmood", ""], ["Strukov", "Dmitri", ""]]}, {"id": "1906.12087", "submitter": "Zhangheng Li", "authors": "Zhangheng Li, Jia-Xing Zhong, Jingjia Huang, Tao Zhang, Thomas Li and\n  Ge Li", "title": "ARMIN: Towards a More Efficient and Light-weight Recurrent Memory\n  Network", "comments": "Published in IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, memory-augmented neural networks(MANNs) have shown promising\npower to enhance the memory ability of neural networks for sequential\nprocessing tasks. However, previous MANNs suffer from complex memory addressing\nmechanism, making them relatively hard to train and causing computational\noverheads. Moreover, many of them reuse the classical RNN structure such as\nLSTM for memory processing, causing inefficient exploitations of memory\ninformation. In this paper, we introduce a novel MANN, the Auto-addressing and\nRecurrent Memory Integrating Network (ARMIN) to address these issues. The ARMIN\nonly utilizes hidden state ht for automatic memory addressing, and uses a novel\nRNN cell for refined integration of memory information. Empirical results on a\nvariety of experiments demonstrate that the ARMIN is more light-weight and\nefficient compared to existing memory networks. Moreover, we demonstrate that\nthe ARMIN can achieve much lower computational overhead than vanilla LSTM while\nkeeping similar performances. Codes are available on github.com/zoharli/armin.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 08:21:49 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Li", "Zhangheng", ""], ["Zhong", "Jia-Xing", ""], ["Huang", "Jingjia", ""], ["Zhang", "Tao", ""], ["Li", "Thomas", ""], ["Li", "Ge", ""]]}, {"id": "1906.12282", "submitter": "Fredrik Sandin", "authors": "Fredrik Sandin, Mattias Nilsson", "title": "Synaptic Delays for Temporal Feature Detection in Dynamic Neuromorphic\n  Processors", "comments": "22 pages, 10 figures", "journal-ref": "Frontiers in Neuroscience; Neuromorphic Engineering (2020)", "doi": "10.3389/fnins.2020.00150", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks implemented in dynamic neuromorphic processors are\nwell suited for spatiotemporal feature detection and learning, for example in\nultra low-power embedded intelligence and deep edge applications. Such pattern\nrecognition networks naturally involve a combination of dynamic delay\nmechanisms and coincidence detection. Inspired by an auditory feature detection\ncircuit in crickets, featuring a delayed excitation by postinhibitory rebound,\nwe investigate disynaptic delay elements formed by inhibitory-excitatory pairs\nof dynamic synapses. We configure such disynaptic delay elements in the\nDYNAP-SE neuromorphic processor and characterize the distribution of delayed\nexcitations resulting from device mismatch. Furthermore, we present a network\nthat mimics the auditory feature detection circuit of crickets and demonstrate\nhow varying synapse weights, input noise and processor temperature affects the\ncircuit. Interestingly, we find that the disynaptic delay elements can be\nconfigured such that the timing and magnitude of the delayed postsynaptic\nexcitation depend mainly on the efficacy of the inhibitory and excitatory\nsynapses, respectively. Delay elements of this kind can be implemented in other\nreconfigurable dynamic neuromorphic processors and opens up for synapse level\ntemporal feature tuning with large fan-in and flexible delays of order 10-100\nms.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 16:06:09 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Sandin", "Fredrik", ""], ["Nilsson", "Mattias", ""]]}, {"id": "1906.12332", "submitter": "Telmo Menezes", "authors": "Telmo Menezes (CMB), Camille Roth (CMB)", "title": "Automatic Discovery of Families of Network Generative Processes", "comments": null, "journal-ref": "DOOCN 2017: Dynamics On and Of Complex Networks III, pp.83-111,\n  2019, 978-3-030-14682-5", "doi": "10.1007/978-3-030-14683-2_4", "report-no": null, "categories": "cs.SI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing plausible network models typically requires scholars to form a\npriori intuitions on the key drivers of network formation. Oftentimes, these\nintuitions are supported by the statistical estimation of a selection of\nnetwork evolution processes which will form the basis of the model to be\ndeveloped. Machine learning techniques have lately been introduced to assist\nthe automatic discovery of generative models. These approaches may more broadly\nbe described as \"symbolic regression\", where fundamental network dynamic\nfunctions, rather than just parameters, are evolved through genetic\nprogramming. This chapter first aims at reviewing the principles, efforts and\nthe emerging literature in this direction, which is very much aligned with the\nidea of creating artificial scientists. Our contribution then aims more\nspecifically at building upon an approach recently developed by us [Menezes \\&\nRoth, 2014] in order to demonstrate the existence of families of networks that\nmay be described by similar generative processes. In other words, symbolic\nregression may be used to group networks according to their inferred genotype\n(in terms of generative processes) rather than their observed phenotype (in\nterms of statistical/topological features). Our empirical case is based on an\noriginal data set of 238 anonymized ego-centered networks of Facebook friends,\nfurther yielding insights on the formation of sociability networks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 12:09:27 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Menezes", "Telmo", "", "CMB"], ["Roth", "Camille", "", "CMB"]]}, {"id": "1906.12338", "submitter": "Chris Yakopcic", "authors": "Chris Yakopcic, Nayim Rahman, Tanvir Atahary, Tarek M. Taha, Alex\n  Beigh, and Scott Douglass", "title": "High Speed Cognitive Domain Ontologies for Asset Allocation Using Loihi\n  Spiking Neurons", "comments": "Accepted and to appear in the proceedings of the 2019 IEEE-INNS\n  International Joint Conference on Neural Networks. Citation: C. Yakopcic, T.\n  Atahary, N. Rahman, T. M. Taha, A. Beigh, and S. Douglass, High Speed\n  Approximate Cognitive Domain Ontologies for Asset Allocation Using Loihi\n  Spiking Neurons, IEEE-INNS International Joint Conference on Neural Networks,\n  Budapest, Hungary, July, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive agents are typically utilized in autonomous systems for automated\ndecision making. These systems interact at real time with their environment and\nare generally heavily power constrained. Thus, there is a strong need for a\nreal time agent running on a low power platform. The agent examined is the\nCognitively Enhanced Complex Event Processing (CECEP) architecture. This is an\nautonomous decision support tool that reasons like humans and enables enhanced\nagent-based decision-making. It has applications in a large variety of domains\nincluding autonomous systems, operations research, intelligence analysis, and\ndata mining. One of the key components of CECEP is the mining of knowledge from\na repository described as a Cognitive Domain Ontology (CDO). One problem that\nis often tasked to CDOs is asset allocation. Given the number of possible\nsolutions in this allocation problem, determining the optimal solution via CDO\ncan be very time consuming. In this work we show that a grid of isolated\nspiking neurons is capable of generating solutions to this problem very\nquickly, although some degree of approximation is required to achieve the\nspeedup. However, the approximate spiking approach presented in this work was\nable to complete all allocation simulations with greater than 99.9% accuracy.\nTo show the feasibility of low power implementation, this algorithm was\nexecuted using the Intel Loihi manycore neuromorphic processor. Given the vast\nincrease in speed (greater than 1000 times in larger allocation problems), as\nwell as the reduction in computational requirements, the presented algorithm is\nideal for moving asset allocation to low power, portable, embedded hardware.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 17:41:46 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Yakopcic", "Chris", ""], ["Rahman", "Nayim", ""], ["Atahary", "Tanvir", ""], ["Taha", "Tarek M.", ""], ["Beigh", "Alex", ""], ["Douglass", "Scott", ""]]}]