[{"id": "1408.0101", "submitter": "Sandeep Kumar", "authors": "Sandeep Kumar, Vivek Kumar Sharma, Rajani Kumari", "title": "Memetic Search in Differential Evolution Algorithm", "comments": null, "journal-ref": null, "doi": "10.5120/15582-4406", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential Evolution (DE) is a renowned optimization stratagem that can\neasily solve nonlinear and comprehensive problems. DE is a well known and\nuncomplicated population based probabilistic approach for comprehensive\noptimization. It has apparently outperformed a number of Evolutionary\nAlgorithms and further search heuristics in the vein of Particle Swarm\nOptimization at what time of testing over both yardstick and actual world\nproblems. Nevertheless, DE, like other probabilistic optimization algorithms,\nfrom time to time exhibits precipitate convergence and stagnates at suboptimal\nposition. In order to stay away from stagnation behavior while maintaining an\nexcellent convergence speed, an innovative search strategy is introduced, named\nmemetic search in DE. In the planned strategy, positions update equation\ncustomized as per a memetic search stratagem. In this strategy a better\nsolution participates more times in the position modernize procedure. The\nposition update equation is inspired from the memetic search in artificial bee\ncolony algorithm. The proposed strategy is named as Memetic Search in\nDifferential Evolution (MSDE). To prove efficiency and efficacy of MSDE, it is\ntested over 8 benchmark optimization problems and three real world optimization\nproblems. A comparative analysis has also been carried out among proposed MSDE\nand original DE. Results show that the anticipated algorithm go one better than\nthe basic DE and its recent deviations in a good number of the experiments.\n", "versions": [{"version": "v1", "created": "Fri, 1 Aug 2014 08:45:14 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Kumar", "Sandeep", ""], ["Sharma", "Vivek Kumar", ""], ["Kumari", "Rajani", ""]]}, {"id": "1408.0102", "submitter": "Sandeep Kumar", "authors": "Sandeep Kumar, Vivek Kumar Sharma, Rajani Kumari", "title": "Randomized Memetic Artificial Bee Colony Algorithm", "comments": "arXiv admin note: text overlap with arXiv:1407.5574", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Bee Colony (ABC) optimization algorithm is one of the recent\npopulation based probabilistic approach developed for global optimization. ABC\nis simple and has been showed significant improvement over other Nature\nInspired Algorithms (NIAs) when tested over some standard benchmark functions\nand for some complex real world optimization problems. Memetic Algorithms also\nbecome one of the key methodologies to solve the very large and complex\nreal-world optimization problems. The solution search equation of Memetic ABC\nis based on Golden Section Search and an arbitrary value which tries to balance\nexploration and exploitation of search space. But still there are some chances\nto skip the exact solution due to its step size. In order to balance between\ndiversification and intensification capability of the Memetic ABC, it is\nrandomized the step size in Memetic ABC. The proposed algorithm is named as\nRandomized Memetic ABC (RMABC). In RMABC, new solutions are generated nearby\nthe best so far solution and it helps to increase the exploitation capability\nof Memetic ABC. The experiments on some test problems of different complexities\nand one well known engineering optimization application show that the proposed\nalgorithm outperforms over Memetic ABC (MeABC) and some other variant of ABC\nalgorithm(like Gbest guided ABC (GABC),Hooke Jeeves ABC (HJABC), Best-So-Far\nABC (BSFABC) and Modified ABC (MABC) in case of almost all the problems.\n", "versions": [{"version": "v1", "created": "Fri, 1 Aug 2014 08:49:25 GMT"}], "update_date": "2014-10-15", "authors_parsed": [["Kumar", "Sandeep", ""], ["Sharma", "Vivek Kumar", ""], ["Kumari", "Rajani", ""]]}, {"id": "1408.0614", "submitter": "Nelson  Dzupire", "authors": "Nelson Christopher Dzupire, Yaw Nkansah-Gyekye", "title": "A Multi-Stage Supply Chain Network Optimization Using Genetic Algorithms", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's global business market place, individual firms no longer compete\nas independent entities with unique brand names but as integral part of supply\nchain links. Key to success of any business is satisfying customer's demands on\ntime which may result in cost reductions and increase in service level. In\nsupply chain networks decisions are made with uncertainty about product's\ndemands, costs, prices, lead times, quality in a competitive and collaborative\nenvironment. If poor decisions are made, they may lead to excess inventories\nthat are costly or to insufficient inventory that cannot meet customer's\ndemands. In this work we developed a bi-objective model that minimizes system\nwide costs of the supply chain and delays on delivery of products to\ndistribution centers for a three echelon supply chain. Picking a set of Pareto\nfront for multi-objective optimization problems require robust and efficient\nmethods that can search an entire space. We used evolutionary algorithms to\nfind the set of Pareto fronts which have proved to be effective in finding the\nentire set of Pareto fronts.\n", "versions": [{"version": "v1", "created": "Mon, 4 Aug 2014 09:05:53 GMT"}], "update_date": "2014-08-05", "authors_parsed": [["Dzupire", "Nelson Christopher", ""], ["Nkansah-Gyekye", "Yaw", ""]]}, {"id": "1408.0689", "submitter": "Gong Yue-Jiao", "authors": "Yue-Jiao Gong and Jun Zhang", "title": "Real-Time Traffic Signal Control for Modern Roundabouts by Using\n  Particle Swarm Optimization-Based Fuzzy Controller", "comments": null, "journal-ref": null, "doi": null, "report-no": "SYSU -- 201103", "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Due to that the existing traffic facilities can hardly be extended,\ndeveloping traffic signal control methods is the most important way to improve\nthe traffic efficiency of modern roundabouts. This paper proposes a novel\ntraffic signal controller with two fuzzy layers for signalizing the roundabout.\nThe outer layer of the controller computes urgency degrees of all the phase\nsubsets and then activates the most urgent subset. This mechanism helps to\ninstantly respond to the current traffic condition of the roundabout so as to\nimprove real-timeness. The inner layer of the controller computes extension\ntime of the current phase. If the extension value is larger than a threshold\nvalue, the current phase is maintained; otherwise the next phase in the running\nphase subset (selected by the outer layer) is activated. The inner layer adopts\nwell-designed phase sequences, which helps to smooth the traffic flows and to\navoid traffic jam. In general, the proposed traffic signal controller is\ncapable of improving real-timeness as well as reducing traffic congestion.\nMoreover, an offline particle swarm optimization (PSO) algorithm is developed\nto optimize the membership functions adopted in the proposed controller. By\nusing optimal membership functions, the performance of the controller can be\nfurther improved. Simulation results demonstrate that the proposed controller\noutperforms previous traffic signal controllers in terms of improving the\ntraffic efficiency of modern roundabouts.\n", "versions": [{"version": "v1", "created": "Mon, 4 Aug 2014 14:08:53 GMT"}, {"version": "v2", "created": "Tue, 5 Aug 2014 07:23:58 GMT"}], "update_date": "2014-08-06", "authors_parsed": [["Gong", "Yue-Jiao", ""], ["Zhang", "Jun", ""]]}, {"id": "1408.0848", "submitter": "Xiao-Lei Zhang", "authors": "Xiao-Lei Zhang", "title": "Multilayer bootstrap networks", "comments": "accepted for publication by Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilayer bootstrap network builds a gradually narrowed multilayer nonlinear\nnetwork from bottom up for unsupervised nonlinear dimensionality reduction.\nEach layer of the network is a nonparametric density estimator. It consists of\na group of k-centroids clusterings. Each clustering randomly selects data\npoints with randomly selected features as its centroids, and learns a one-hot\nencoder by one-nearest-neighbor optimization. Geometrically, the nonparametric\ndensity estimator at each layer projects the input data space to a\nuniformly-distributed discrete feature space, where the similarity of two data\npoints in the discrete feature space is measured by the number of the nearest\ncentroids they share in common. The multilayer network gradually reduces the\nnonlinear variations of data from bottom up by building a vast number of\nhierarchical trees implicitly on the original data space. Theoretically, the\nestimation error caused by the nonparametric density estimator is proportional\nto the correlation between the clusterings, both of which are reduced by the\nrandomization steps.\n", "versions": [{"version": "v1", "created": "Tue, 5 Aug 2014 02:13:50 GMT"}, {"version": "v2", "created": "Tue, 27 Jan 2015 04:26:21 GMT"}, {"version": "v3", "created": "Sun, 1 Feb 2015 03:11:40 GMT"}, {"version": "v4", "created": "Tue, 10 Feb 2015 09:09:46 GMT"}, {"version": "v5", "created": "Mon, 4 Jan 2016 17:50:27 GMT"}, {"version": "v6", "created": "Thu, 7 Jan 2016 08:07:44 GMT"}, {"version": "v7", "created": "Mon, 6 Jun 2016 18:00:32 GMT"}, {"version": "v8", "created": "Tue, 6 Mar 2018 15:59:10 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Zhang", "Xiao-Lei", ""]]}, {"id": "1408.0889", "submitter": "Vahid Moosavi", "authors": "Vahid Moosavi", "title": "Computing With Contextual Numbers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self Organizing Map (SOM) has been applied into several classical modeling\ntasks including clustering, classification, function approximation and\nvisualization of high dimensional spaces. The final products of a trained SOM\nare a set of ordered (low dimensional) indices and their associated high\ndimensional weight vectors. While in the above-mentioned applications, the\nfinal high dimensional weight vectors play the primary role in the\ncomputational steps, from a certain perspective, one can interpret SOM as a\nnonparametric encoder, in which the final low dimensional indices of the\ntrained SOM are pointer to the high dimensional space. We showed how using a\none-dimensional SOM, which is not common in usual applications of SOM, one can\ndevelop a nonparametric mapping from a high dimensional space to a continuous\none-dimensional numerical field. These numerical values, called contextual\nnumbers, are ordered in a way that in a given context, similar numbers refer to\nsimilar high dimensional states. Further, as these numbers can be treated\nsimilarly to usual continuous numbers, they can be replaced with their\ncorresponding high dimensional states within any data driven modeling problem.\nAs a potential application, we showed how using contextual numbers could be\nused for the problem of high dimensional spatiotemporal dynamics.\n", "versions": [{"version": "v1", "created": "Tue, 5 Aug 2014 08:37:11 GMT"}, {"version": "v2", "created": "Wed, 6 Aug 2014 04:22:26 GMT"}], "update_date": "2014-08-07", "authors_parsed": [["Moosavi", "Vahid", ""]]}, {"id": "1408.0998", "submitter": "Sebastian Risi", "authors": "Sebastian Risi, Jinhong Zhang, Rasmus Taarnby, Peter Greve, Jan\n  Piskur, Antonios Liapis, Julian Togelius", "title": "The Case for a Mixed-Initiative Collaborative Neuroevolution Approach", "comments": "Presented at WebAL-1: Workshop on Artificial Life and the Web 2014\n  (arXiv:1406.2507)", "journal-ref": null, "doi": null, "report-no": "WebAL1/2014/06", "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is clear that the current attempts at using algorithms to create\nartificial neural networks have had mixed success at best when it comes to\ncreating large networks and/or complex behavior. This should not be unexpected,\nas creating an artificial brain is essentially a design problem. Human design\ningenuity still surpasses computational design for most tasks in most domains,\nincluding architecture, game design, and authoring literary fiction. This leads\nus to ask which the best way is to combine human and machine design capacities\nwhen it comes to designing artificial brains. Both of them have their strengths\nand weaknesses; for example, humans are much too slow to manually specify\nthousands of neurons, let alone the billions of neurons that go into a human\nbrain, but on the other hand they can rely on a vast repository of common-sense\nunderstanding and design heuristics that can help them perform a much better\nguided search in design space than an algorithm. Therefore, in this paper we\nargue for a mixed-initiative approach for collaborative online brain building\nand present first results towards this goal.\n", "versions": [{"version": "v1", "created": "Tue, 5 Aug 2014 15:18:13 GMT"}], "update_date": "2014-08-06", "authors_parsed": [["Risi", "Sebastian", ""], ["Zhang", "Jinhong", ""], ["Taarnby", "Rasmus", ""], ["Greve", "Peter", ""], ["Piskur", "Jan", ""], ["Liapis", "Antonios", ""], ["Togelius", "Julian", ""]]}, {"id": "1408.1245", "submitter": "Saeed Afshar", "authors": "Saeed Afshar (1), Libin George (1,2), Jonathan Tapson (1), Andre van\n  Schaik (1), Tara Julia Hamilton (1,2) ((1) University of Western Sydney, (2)\n  University of New South Wales)", "title": "Racing to Learn: Statistical Inference and Learning in a Single Spiking\n  Neuron with Adaptive Kernels", "comments": "In submission to Frontiers in Neuroscience", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper describes the Synapto-dendritic Kernel Adapting Neuron (SKAN), a\nsimple spiking neuron model that performs statistical inference and\nunsupervised learning of spatiotemporal spike patterns. SKAN is the first\nproposed neuron model to investigate the effects of dynamic synapto-dendritic\nkernels and demonstrate their computational power even at the single neuron\nscale. The rule-set defining the neuron is simple there are no complex\nmathematical operations such as normalization, exponentiation or even\nmultiplication. The functionalities of SKAN emerge from the real-time\ninteraction of simple additive and binary processes. Like a biological neuron,\nSKAN is robust to signal and parameter noise, and can utilize both in its\noperations. At the network scale neurons are locked in a race with each other\nwith the fastest neuron to spike effectively hiding its learnt pattern from its\nneighbors. The robustness to noise, high speed and simple building blocks not\nonly make SKAN an interesting neuron model in computational neuroscience, but\nalso make it ideal for implementation in digital and analog neuromorphic\nsystems which is demonstrated through an implementation in a Field Programmable\nGate Array (FPGA).\n", "versions": [{"version": "v1", "created": "Wed, 6 Aug 2014 11:11:41 GMT"}, {"version": "v2", "created": "Thu, 7 Aug 2014 02:02:13 GMT"}, {"version": "v3", "created": "Wed, 20 Aug 2014 06:12:16 GMT"}, {"version": "v4", "created": "Sat, 15 Nov 2014 16:40:51 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Afshar", "Saeed", ""], ["George", "Libin", ""], ["Tapson", "Jonathan", ""], ["van Schaik", "Andre", ""], ["Hamilton", "Tara Julia", ""]]}, {"id": "1408.1297", "submitter": "Arnab Roy", "authors": "Arnab Roy, J. David Schaffer, Craig B. Laramee", "title": "New crossover operators for multiple subset selection tasks", "comments": "19 Pages, 8 Figures, 3 Tables. More information can be found in (A.\n  Roy (2014). Evolving spike neural network based spatio-temporal pattern\n  classifiers with an application to identifying the alcoholic brain. Ph.D.\n  dissertation, Department of Bioengineering, Binghamton University,\n  Binghamton, NY-13902, U.S.A.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have introduced two crossover operators, MMX-BLXexploit and\nMMX-BLXexplore, for simultaneously solving multiple feature/subset selection\nproblems where the features may have numeric attributes and the subset sizes\nare not predefined. These operators differ on the level of exploration and\nexploitation they perform; one is designed to produce convergence controlled\nmutation and the other exhibits a quasi-constant mutation rate. We illustrate\nthe characteristic of these operators by evolving pattern detectors to\ndistinguish alcoholics from controls using their visually evoked response\npotentials (VERPs). This task encapsulates two groups of subset selection\nproblems; choosing a subset of EEG leads along with the lead-weights (features\nwith attributes) and the other that defines the temporal pattern that\ncharacterizes the alcoholic VERPs. We observed better generalization\nperformance from MMX-BLXexplore. Perhaps, MMX-BLXexploit was handicapped by not\nhaving a restart mechanism. These operators are novel and appears to hold\npromise for solving simultaneous feature selection problems.\n", "versions": [{"version": "v1", "created": "Wed, 6 Aug 2014 14:41:04 GMT"}], "update_date": "2014-08-07", "authors_parsed": [["Roy", "Arnab", ""], ["Schaffer", "J. David", ""], ["Laramee", "Craig B.", ""]]}, {"id": "1408.1906", "submitter": "Randal Olson", "authors": "Randal S. Olson, Patrick B. Haley, Fred C. Dyer, Christoph Adami", "title": "Exploring the evolution of a trade-off between vigilance and foraging in\n  group-living organisms", "comments": "26 pages (double-spaced, single column), 6 figures, 2 SI figures", "journal-ref": "Royal Society open science 2 (2015) 150135", "doi": "10.1098/rsos.150135", "report-no": null, "categories": "q-bio.PE cs.GT cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the fact that grouping behavior has been actively studied for over a\ncentury, the relative importance of the numerous proposed fitness benefits of\ngrouping remain unclear. We use a digital model of evolving prey under\nsimulated predation to directly explore the evolution of gregarious foraging\nbehavior according to one such benefit, the \"many eyes\" hypothesis. According\nto this hypothesis, collective vigilance allows prey in large groups to detect\npredators more efficiently by making alarm signals or behavioral cues to each\nother, thereby allowing individuals within the group to spend more time\nforaging. Here, we find that collective vigilance is sufficient to select for\ngregarious foraging behavior as long there is not a direct cost for grouping\n(e.g., competition for limited food resources), even when controlling for\nconfounding factors such as the dilution effect. Further, we explore the role\nof the genetic relatedness and reproductive strategy of the prey, and find that\nhighly related groups of prey with a semelparous reproductive strategy are the\nmost likely to evolve gregarious foraging behavior mediated by the benefit of\nvigilance. These findings, combined with earlier studies with evolving digital\norganisms, further sharpen our understanding of the factors favoring grouping\nbehavior.\n", "versions": [{"version": "v1", "created": "Fri, 8 Aug 2014 16:37:03 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Olson", "Randal S.", ""], ["Haley", "Patrick B.", ""], ["Dyer", "Fred C.", ""], ["Adami", "Christoph", ""]]}, {"id": "1408.2004", "submitter": "Bo Han", "authors": "Bo Han, Bo He, Mengmeng Ma, Tingting Sun, Tianhong Yan, Amaury\n  Lendasse", "title": "RMSE-ELM: Recursive Model based Selective Ensemble of Extreme Learning\n  Machines for Robustness Improvement", "comments": "Accepted for publication in Mathematical Problems in Engineering,\n  09/22/2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extreme learning machine (ELM) as an emerging branch of shallow networks has\nshown its excellent generalization and fast learning speed. However, for\nblended data, the robustness of ELM is weak because its weights and biases of\nhidden nodes are set randomly. Moreover, the noisy data exert a negative\neffect. To solve this problem, a new framework called RMSE-ELM is proposed in\nthis paper. It is a two-layer recursive model. In the first layer, the\nframework trains lots of ELMs in different groups concurrently, then employs\nselective ensemble to pick out an optimal set of ELMs in each group, which can\nbe merged into a large group of ELMs called candidate pool. In the second\nlayer, selective ensemble is recursively used on candidate pool to acquire the\nfinal ensemble. In the experiments, we apply UCI blended datasets to confirm\nthe robustness of our new approach in two key aspects (mean square error and\nstandard deviation). The space complexity of our method is increased to some\ndegree, but the results have shown that RMSE-ELM significantly improves\nrobustness with slightly computational time compared with representative\nmethods (ELM, OP-ELM, GASEN-ELM, GASEN-BP and E-GASEN). It becomes a potential\nframework to solve robustness issue of ELM for high-dimensional blended data in\nthe future.\n", "versions": [{"version": "v1", "created": "Sat, 9 Aug 2014 01:36:03 GMT"}, {"version": "v2", "created": "Wed, 27 Aug 2014 02:35:11 GMT"}, {"version": "v3", "created": "Tue, 23 Sep 2014 07:48:35 GMT"}], "update_date": "2014-09-24", "authors_parsed": [["Han", "Bo", ""], ["He", "Bo", ""], ["Ma", "Mengmeng", ""], ["Sun", "Tingting", ""], ["Yan", "Tianhong", ""], ["Lendasse", "Amaury", ""]]}, {"id": "1408.2288", "submitter": "Raja Jurdak", "authors": "Philip Valencia, Aiden Haak, Alban Cotillon, and Raja Jurdak", "title": "Genetic Programming for Smart Phone Personalisation", "comments": "43 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalisation in smart phones requires adaptability to dynamic context\nbased on user mobility, application usage and sensor inputs. Current\npersonalisation approaches, which rely on static logic that is developed a\npriori, do not provide sufficient adaptability to dynamic and unexpected\ncontext. This paper proposes genetic programming (GP), which can evolve program\nlogic in realtime, as an online learning method to deal with the highly dynamic\ncontext in smart phone personalisation. We introduce the concept of\ncollaborative smart phone personalisation through the GP Island Model, in order\nto exploit shared context among co-located phone users and reduce convergence\ntime. We implement these concepts on real smartphones to demonstrate the\ncapability of personalisation through GP and to explore the benefits of the\nIsland Model. Our empirical evaluations on two example applications confirm\nthat the Island Model can reduce convergence time by up to two-thirds over\nstandalone GP personalisation.\n", "versions": [{"version": "v1", "created": "Mon, 11 Aug 2014 00:52:39 GMT"}], "update_date": "2014-08-12", "authors_parsed": [["Valencia", "Philip", ""], ["Haak", "Aiden", ""], ["Cotillon", "Alban", ""], ["Jurdak", "Raja", ""]]}, {"id": "1408.2873", "submitter": "Andrew Maas", "authors": "Awni Y. Hannun, Andrew L. Maas, Daniel Jurafsky, Andrew Y. Ng", "title": "First-Pass Large Vocabulary Continuous Speech Recognition using\n  Bi-Directional Recurrent DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to perform first-pass large vocabulary continuous speech\nrecognition using only a neural network and language model. Deep neural network\nacoustic models are now commonplace in HMM-based speech recognition systems,\nbut building such systems is a complex, domain-specific task. Recent work\ndemonstrated the feasibility of discarding the HMM sequence modeling framework\nby directly predicting transcript text from audio. This paper extends this\napproach in two ways. First, we demonstrate that a straightforward recurrent\nneural network architecture can achieve a high level of accuracy. Second, we\npropose and evaluate a modified prefix-search decoding algorithm. This approach\nto decoding enables first-pass speech recognition with a language model,\ncompletely unaided by the cumbersome infrastructure of HMM-based systems.\nExperiments on the Wall Street Journal corpus demonstrate fairly competitive\nword error rates, and the importance of bi-directional network recurrence.\n", "versions": [{"version": "v1", "created": "Tue, 12 Aug 2014 22:40:21 GMT"}, {"version": "v2", "created": "Mon, 8 Dec 2014 20:21:52 GMT"}], "update_date": "2014-12-09", "authors_parsed": [["Hannun", "Awni Y.", ""], ["Maas", "Andrew L.", ""], ["Jurafsky", "Daniel", ""], ["Ng", "Andrew Y.", ""]]}, {"id": "1408.2889", "submitter": "Alceu de Souza Britto Jr", "authors": "Albert H. R. Ko, Robert Sabourin, Alceu S. Britto Jr, Luiz E. S.\n  Oliveira", "title": "A Classifier-free Ensemble Selection Method based on Data Diversity in\n  Random Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ensemble of Classifiers (EoC) has been shown to be effective in improving\nthe performance of single classifiers by combining their outputs, and one of\nthe most important properties involved in the selection of the best EoC from a\npool of classifiers is considered to be classifier diversity. In general,\nclassifier diversity does not occur randomly, but is generated systematically\nby various ensemble creation methods. By using diverse data subsets to train\nclassifiers, these methods can create diverse classifiers for the EoC. In this\nwork, we propose a scheme to measure data diversity directly from random\nsubspaces, and explore the possibility of using it to select the best data\nsubsets for the construction of the EoC. Our scheme is the first ensemble\nselection method to be presented in the literature based on the concept of data\ndiversity. Its main advantage over the traditional framework (ensemble creation\nthen selection) is that it obviates the need for classifier training prior to\nensemble selection. A single Genetic Algorithm (GA) and a Multi-Objective\nGenetic Algorithm (MOGA) were evaluated to search for the best solutions for\nthe classifier-free ensemble selection. In both cases, objective functions\nbased on different clustering diversity measures were implemented and tested.\nAll the results obtained with the proposed classifier-free ensemble selection\nmethod were compared with the traditional classifier-based ensemble selection\nusing Mean Classifier Error (ME) and Majority Voting Error (MVE). The\napplicability of the method is tested on UCI machine learning problems and NIST\nSD19 handwritten numerals.\n", "versions": [{"version": "v1", "created": "Wed, 13 Aug 2014 00:38:41 GMT"}], "update_date": "2014-08-14", "authors_parsed": [["Ko", "Albert H. R.", ""], ["Sabourin", "Robert", ""], ["Britto", "Alceu S.", "Jr"], ["Oliveira", "Luiz E. S.", ""]]}, {"id": "1408.2938", "submitter": "Wenbin Li", "authors": "Wenbin Li, Mario Fritz", "title": "Learning Multi-Scale Representations for Material Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent progress in sparse coding and deep learning has made unsupervised\nfeature learning methods a strong competitor to hand-crafted descriptors. In\ncomputer vision, success stories of learned features have been predominantly\nreported for object recognition tasks. In this paper, we investigate if and how\nfeature learning can be used for material recognition. We propose two\nstrategies to incorporate scale information into the learning procedure\nresulting in a novel multi-scale coding procedure. Our results show that our\nlearned features for material recognition outperform hand-crafted descriptors\non the FMD and the KTH-TIPS2 material classification benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Aug 2014 08:27:12 GMT"}], "update_date": "2014-08-14", "authors_parsed": [["Li", "Wenbin", ""], ["Fritz", "Mario", ""]]}, {"id": "1408.3215", "submitter": "Timothy Molter", "authors": "M. Alexander Nugent, Timothy W. Molter", "title": "Cortical Processing with Thermodynamic-RAM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AHaH computing forms a theoretical framework from which a\nbiologically-inspired type of computing architecture can be built where, unlike\nvon Neumann systems, memory and processor are physically combined. In this\npaper we report on an incremental step beyond the theoretical framework of AHaH\ncomputing toward the development of a memristor-based physical neural\nprocessing unit (NPU), which we call Thermodynamic-RAM (kT-RAM). While the\npower consumption and speed dominance of such an NPU over von Neumann\narchitectures for machine learning applications is well appreciated,\nThermodynamic-RAM offers several advantages over other hardware approaches to\nadaptation and learning. Benefits include general-purpose use, a simple yet\nflexible instruction set and easy integration into existing digital platforms.\nWe present a high level design of kT-RAM and a formal definition of its\ninstruction set. We report the completion of a kT-RAM emulator and the\nsuccessful port of all previous machine learning benchmark applications\nincluding unsupervised clustering, supervised and unsupervised classification,\ncomplex signal prediction, unsupervised robotic actuation and combinatorial\noptimization. Lastly, we extend a previous MNIST hand written digits benchmark\napplication, to show that an extra step of reading the synaptic states of AHaH\nnodes during the train phase (healing) alone results in plasticity that\nimproves the classifier's performance, bumping our best F1 score up to 99.5%.\n", "versions": [{"version": "v1", "created": "Thu, 14 Aug 2014 08:39:15 GMT"}], "update_date": "2014-08-15", "authors_parsed": [["Nugent", "M. Alexander", ""], ["Molter", "Timothy W.", ""]]}, {"id": "1408.3264", "submitter": "Mohammad Ali Keyvanrad", "authors": "Mohammad Ali Keyvanrad, Mohammad Mehdi Homayounpour", "title": "A brief survey on deep belief networks and introducing a new object\n  oriented toolbox (DeeBNet)", "comments": "Technical Report 27 pages, Ver3.0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, this is very popular to use the deep architectures in machine\nlearning. Deep Belief Networks (DBNs) are deep architectures that use stack of\nRestricted Boltzmann Machines (RBM) to create a powerful generative model using\ntraining data. DBNs have many ability like feature extraction and\nclassification that are used in many applications like image processing, speech\nprocessing and etc. This paper introduces a new object oriented MATLAB toolbox\nwith most of abilities needed for the implementation of DBNs. In the new\nversion, the toolbox can be used in Octave. According to the results of the\nexperiments conducted on MNIST (image), ISOLET (speech), and 20 Newsgroups\n(text) datasets, it was shown that the toolbox can learn automatically a good\nrepresentation of the input from unlabeled data with better discrimination\nbetween different classes. Also on all datasets, the obtained classification\nerrors are comparable to those of state of the art classifiers. In addition,\nthe toolbox supports different sampling methods (e.g. Gibbs, CD, PCD and our\nnew FEPCD method), different sparsity methods (quadratic, rate distortion and\nour new normal method), different RBM types (generative and discriminative),\nusing GPU, etc. The toolbox is a user-friendly open source software and is\nfreely available on the website\nhttp://ceit.aut.ac.ir/~keyvanrad/DeeBNet%20Toolbox.html .\n", "versions": [{"version": "v1", "created": "Thu, 14 Aug 2014 12:37:57 GMT"}, {"version": "v2", "created": "Mon, 8 Dec 2014 14:44:02 GMT"}, {"version": "v3", "created": "Thu, 9 Jul 2015 12:44:01 GMT"}, {"version": "v4", "created": "Fri, 10 Jul 2015 13:21:02 GMT"}, {"version": "v5", "created": "Wed, 22 Jul 2015 14:25:13 GMT"}, {"version": "v6", "created": "Mon, 7 Sep 2015 14:44:47 GMT"}, {"version": "v7", "created": "Wed, 6 Jan 2016 13:20:11 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Keyvanrad", "Mohammad Ali", ""], ["Homayounpour", "Mohammad Mehdi", ""]]}, {"id": "1408.3735", "submitter": "Mohammad AlHawarat Dr.", "authors": "Mohammad Alhawarat, Waleed Nazih, Mohammad Eldesouki", "title": "Analysis of a chaotic spiking neural model: The NDS neuron", "comments": "Computer Science & Information Technology, 2013, Vol. 4 No. 3", "journal-ref": null, "doi": "10.5121/csit.2013.3412", "report-no": null, "categories": "cs.NE nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Further analysis and experimentation is carried out in this paper for a\nchaotic dynamic model, viz. the Nonlinear Dynamic State neuron (NDS). The\nanalysis and experimentations are performed to further understand the\nunderlying dynamics of the model and enhance it as well. Chaos provides many\ninteresting properties that can be exploited to achieve computational tasks.\nSuch properties are sensitivity to initial conditions, space filling, control\nand synchronization.Chaos might play an important role in information\nprocessing tasks in human brain as suggested by biologists. If artificial\nneural networks (ANNs) is equipped with chaos then it will enrich the dynamic\nbehaviours of such networks. The NDS model has some limitations and can be\novercome in different ways. In this paper different approaches are followed to\npush the boundaries of the NDS model in order to enhance it. One way is to\nstudy the effects of scaling the parameters of the chaotic equations of the NDS\nmodel and study the resulted dynamics. Another way is to study the method that\nis used in discretization of the original R\\\"{o}ssler that the NDS model is\nbased on. These approaches have revealed some facts about the NDS attractor and\nsuggest why such a model can be stabilized to large number of unstable periodic\norbits (UPOs) which might correspond to memories in phase space.\n", "versions": [{"version": "v1", "created": "Sat, 16 Aug 2014 12:50:45 GMT"}], "update_date": "2014-08-19", "authors_parsed": [["Alhawarat", "Mohammad", ""], ["Nazih", "Waleed", ""], ["Eldesouki", "Mohammad", ""]]}, {"id": "1408.3750", "submitter": "S\\'ebastien Ouellet", "authors": "S\\'ebastien Ouellet", "title": "Real-time emotion recognition for gaming using deep convolutional\n  network features", "comments": "6 pages, 8 figures, IEEE style", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of the present study is to explore the application of deep\nconvolutional network features to emotion recognition. Results indicate that\nthey perform similarly to other published models at a best recognition rate of\n94.4%, and do so with a single still image rather than a video stream. An\nimplementation of an affective feedback game is also described, where a\nclassifier using these features tracks the facial expressions of a player in\nreal-time.\n", "versions": [{"version": "v1", "created": "Sat, 16 Aug 2014 17:11:44 GMT"}], "update_date": "2014-08-19", "authors_parsed": [["Ouellet", "S\u00e9bastien", ""]]}, {"id": "1408.4077", "submitter": "Laszlo Kish", "authors": "Laszlo B. Kish, Claes-Goran Granqvist, Sergey M. Bezrukov and Tamas\n  Horvath", "title": "Brain: Biological noise-based logic", "comments": "paper in press", "journal-ref": "Advances in Cognitive Neurodynamics 2015, pp 319-322", "doi": "10.1007/978-94-017-9548-7_45", "report-no": null, "categories": "cs.NE cs.ET", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Neural spikes in the brain form stochastic sequences, i.e., belong to the\nclass of pulse noises. This stochasticity is a counterintuitive feature because\nextracting information - such as the commonly supposed neural information of\nmean spike frequency - requires long times for reasonably low error\nprobability. The mystery could be solved by noise-based logic, wherein\nrandomness has an important function and allows large speed enhancements for\nspecial-purpose tasks, and the same mechanism is at work for the brain logic\nversion of this concept.\n", "versions": [{"version": "v1", "created": "Mon, 18 Aug 2014 17:49:28 GMT"}], "update_date": "2015-03-31", "authors_parsed": [["Kish", "Laszlo B.", ""], ["Granqvist", "Claes-Goran", ""], ["Bezrukov", "Sergey M.", ""], ["Horvath", "Tamas", ""]]}, {"id": "1408.4143", "submitter": "Mohammed Abdelsamea", "authors": "Marghny H. Mohamed and Mohammed M. Abdelsamea", "title": "Self Organization Map based Texture Feature Extraction for Efficient\n  Medical Image Categorization", "comments": "In Proceedings of the 4th ACM International Conference on Intelligent\n  Computing and Information Systems, ICICIS 2009, Cairo, Egypt 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Texture is one of the most important properties of visual surface that helps\nin discriminating one object from another or an object from background. The\nself-organizing map (SOM) is an excellent tool in exploratory phase of data\nmining. It projects its input space on prototypes of a low-dimensional regular\ngrid that can be effectively utilized to visualize and explore properties of\nthe data. This paper proposes an enhancement extraction method for accurate\nextracting features for efficient image representation it based on SOM neural\nnetwork. In this approach, we apply three different partitioning approaches as\na region of interested (ROI) selection methods for extracting different\naccurate textural features from medical image as a primary step of our\nextraction method. Fisherfaces feature selection is used, for selecting\ndiscriminated features form extracted textural features. Experimental result\nshowed the high accuracy of medical image categorization with our proposed\nextraction method. Experiments held on Mammographic Image Analysis Society\n(MIAS) dataset.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jul 2014 13:43:19 GMT"}], "update_date": "2014-08-20", "authors_parsed": [["Mohamed", "Marghny H.", ""], ["Abdelsamea", "Mohammed M.", ""]]}, {"id": "1408.4222", "submitter": "Rafael Alvarado-Corona RAC", "authors": "Cinthya Mota-Hernandez, Luis Esquivel-Rodriguez and Rafael\n  Alvarado-Corona", "title": "Can Artificial Neural Networks be Applied in Seismic Predicition?\n  Preliminary Analysis Applying Radial Topology. Case: Mexico", "comments": "4 pages, Conference, in Spanish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tectonic earthquakes of high magnitude can cause considerable losses in terms\nof human lives, economic and infrastructure, among others. According to an\nevaluation published by the U.S. Geological Survey, 30 is the number of\nearthquakes which have greatly impacted Mexico from the end of the XIX century\nto this one. Based upon data from the National Seismological Service, on the\nperiod between January 1, 2006 and May 1, 2013 there have occurred 5,826\nearthquakes which magnitude has been greater than 4.0 degrees on the Richter\nmagnitude scale (25.54% of the total of earthquakes registered on the national\nterritory), being the Pacific Plate and the Cocos Plate the most important\nones. This document describes the development of an Artificial Neural Network\n(ANN) based on the radial topology which seeks to generate a prediction with an\nerror margin lower than 20% which can inform about the probability of a future\nearthquake one of the main questions is: can artificial neural networks be\napplied in seismic forecasting? It can be argued that research has the\npotential to bring in the forecast seismic, more research is needed to\nconsolidate data and help mitigate the impact caused by such events linked with\nsociety. Keywords--- Analysis, Mexico, Neural Artificial Networks, Seismicity.\n", "versions": [{"version": "v1", "created": "Tue, 19 Aug 2014 06:44:04 GMT"}], "update_date": "2014-08-20", "authors_parsed": [["Mota-Hernandez", "Cinthya", ""], ["Esquivel-Rodriguez", "Luis", ""], ["Alvarado-Corona", "Rafael", ""]]}, {"id": "1408.4487", "submitter": "Mahdi Zamani", "authors": "Mahnush Movahedi and Mahdi Zamani", "title": "On Optimal Decision-Making in Ant Colonies", "comments": "Workshop on Biological Distributed Algorithms (BDA 2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Colonies of ants can collectively choose the best of several nests, even when\nmany of the active ants who organize the move visit only one site.\nUnderstanding such a behavior can help us design efficient distributed decision\nmaking algorithms. Marshall et al. propose a model for house-hunting in\ncolonies of ant Temnothorax albipennis. Unfortunately, their model does not\nachieve optimal decision-making while laboratory experiments show that, in\nfact, colonies usually achieve optimality during the house-hunting process. In\nthis paper, we argue that the model of Marshall et al. can achieve optimality\nby including nest size information in their mathematical model. We use lab\nresults of Pratt et al. to re-define the differential equations of Marshall et\nal. Finally, we sketch our strategy for testing the optimality of the new\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 19 Aug 2014 21:46:04 GMT"}], "update_date": "2014-08-21", "authors_parsed": [["Movahedi", "Mahnush", ""], ["Zamani", "Mahdi", ""]]}, {"id": "1408.4587", "submitter": "Pier Stanislao Paolucci", "authors": "Pier Stanislao Paolucci, Iuliana Bacivarov, Devendra Rai, Lars Schor,\n  Lothar Thiele, Hoeseok Yang, Elena Pastorelli, Roberto Ammendola, Andrea\n  Biagioni, Ottorino Frezza, Francesca Lo Cicero, Alessandro Lonardo, Francesco\n  Simula, Laura Tosoratto, Piero Vicini", "title": "EURETILE D7.3 - Dynamic DAL benchmark coding, measurements on MPI\n  version of DPSNN-STDP (distributed plastic spiking neural net) and\n  improvements to other DAL codes", "comments": "34 pages. arXiv admin note: substantial text overlap with\n  arXiv:1310.8478", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE cs.MS cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The EURETILE project required the selection and coding of a set of dedicated\nbenchmarks. The project is about the software and hardware architecture of\nfuture many-tile distributed fault-tolerant systems. We focus on dynamic\nworkloads characterised by heavy numerical processing requirements. The\nambition is to identify common techniques that could be applied to both the\nEmbedded Systems and HPC domains. This document is the first public deliverable\nof Work Package 7: Challenging Tiled Applications.\n", "versions": [{"version": "v1", "created": "Wed, 20 Aug 2014 10:00:15 GMT"}], "update_date": "2014-08-21", "authors_parsed": [["Paolucci", "Pier Stanislao", ""], ["Bacivarov", "Iuliana", ""], ["Rai", "Devendra", ""], ["Schor", "Lars", ""], ["Thiele", "Lothar", ""], ["Yang", "Hoeseok", ""], ["Pastorelli", "Elena", ""], ["Ammendola", "Roberto", ""], ["Biagioni", "Andrea", ""], ["Frezza", "Ottorino", ""], ["Cicero", "Francesca Lo", ""], ["Lonardo", "Alessandro", ""], ["Simula", "Francesco", ""], ["Tosoratto", "Laura", ""], ["Vicini", "Piero", ""]]}, {"id": "1408.4792", "submitter": "Adnan Anwar", "authors": "Adnan Anwar, Abdun Naser Mahmood", "title": "Enhanced Estimation of Autoregressive Wind Power Prediction Model Using\n  Constriction Factor Particle Swarm Optimization", "comments": "The 9th IEEE Conference on Industrial Electronics and Applications\n  (ICIEA) 2014", "journal-ref": null, "doi": "10.1109/ICIEA.2014.6931336", "report-no": null, "categories": "cs.CE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate forecasting is important for cost-effective and efficient monitoring\nand control of the renewable energy based power generation. Wind based power is\none of the most difficult energy to predict accurately, due to the widely\nvarying and unpredictable nature of wind energy. Although Autoregressive (AR)\ntechniques have been widely used to create wind power models, they have shown\nlimited accuracy in forecasting, as well as difficulty in determining the\ncorrect parameters for an optimized AR model. In this paper, Constriction\nFactor Particle Swarm Optimization (CF-PSO) is employed to optimally determine\nthe parameters of an Autoregressive (AR) model for accurate prediction of the\nwind power output behaviour. Appropriate lag order of the proposed model is\nselected based on Akaike information criterion. The performance of the proposed\nPSO based AR model is compared with four well-established approaches;\nForward-backward approach, Geometric lattice approach, Least-squares approach\nand Yule-Walker approach, that are widely used for error minimization of the AR\nmodel. To validate the proposed approach, real-life wind power data of\n\\textit{Capital Wind Farm} was obtained from Australian Energy Market Operator.\nExperimental evaluation based on a number of different datasets demonstrate\nthat the performance of the AR model is significantly improved compared with\nbenchmark methods.\n", "versions": [{"version": "v1", "created": "Thu, 21 Aug 2014 00:46:51 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Anwar", "Adnan", ""], ["Mahmood", "Abdun Naser", ""]]}, {"id": "1408.4849", "submitter": "Adnan Anwar", "authors": "Adnan Anwar, A. N. Mahmood", "title": "Swarm Intelligence Based Multi-phase OPF For Peak Power Loss Reduction\n  In A Smart Grid", "comments": "IEEE PES GM 2014, Washington DC, USA", "journal-ref": null, "doi": "10.1109/PESGM.2014.6939824", "report-no": null, "categories": "cs.CE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been increasing interest in improving smart grids\nefficiency using computational intelligence. A key challenge in future smart\ngrid is designing Optimal Power Flow tool to solve important planning problems\nincluding optimal DG capacities. Although, a number of OPF tools exists for\nbalanced networks there is a lack of research for unbalanced multi-phase\ndistribution networks. In this paper, a new OPF technique has been proposed for\nthe DG capacity planning of a smart grid. During the formulation of the\nproposed algorithm, multi-phase power distribution system is considered which\nhas unbalanced loadings, voltage control and reactive power compensation\ndevices. The proposed algorithm is built upon a co-simulation framework that\noptimizes the objective by adapting a constriction factor Particle Swarm\noptimization. The proposed multi-phase OPF technique is validated using IEEE\n8500-node benchmark distribution system.\n", "versions": [{"version": "v1", "created": "Thu, 21 Aug 2014 00:55:35 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Anwar", "Adnan", ""], ["Mahmood", "A. N.", ""]]}, {"id": "1408.5093", "submitter": "Yangqing Jia", "authors": "Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey Karayev, Jonathan\n  Long, Ross Girshick, Sergio Guadarrama, Trevor Darrell", "title": "Caffe: Convolutional Architecture for Fast Feature Embedding", "comments": "Tech report for the Caffe software at http://github.com/BVLC/Caffe/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Caffe provides multimedia scientists and practitioners with a clean and\nmodifiable framework for state-of-the-art deep learning algorithms and a\ncollection of reference models. The framework is a BSD-licensed C++ library\nwith Python and MATLAB bindings for training and deploying general-purpose\nconvolutional neural networks and other deep models efficiently on commodity\narchitectures. Caffe fits industry and internet-scale media needs by CUDA GPU\ncomputation, processing over 40 million images a day on a single K40 or Titan\nGPU ($\\approx$ 2.5 ms per image). By separating model representation from\nactual implementation, Caffe allows experimentation and seamless switching\namong platforms for ease of development and deployment from prototyping\nmachines to cloud environments. Caffe is maintained and developed by the\nBerkeley Vision and Learning Center (BVLC) with the help of an active community\nof contributors on GitHub. It powers ongoing research projects, large-scale\nindustrial applications, and startup prototypes in vision, speech, and\nmultimedia.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jun 2014 23:00:32 GMT"}], "update_date": "2014-08-22", "authors_parsed": [["Jia", "Yangqing", ""], ["Shelhamer", "Evan", ""], ["Donahue", "Jeff", ""], ["Karayev", "Sergey", ""], ["Long", "Jonathan", ""], ["Girshick", "Ross", ""], ["Guadarrama", "Sergio", ""], ["Darrell", "Trevor", ""]]}, {"id": "1408.5316", "submitter": "Xin-She Yang", "authors": "Xin-She Yang and Suash Deb", "title": "Cuckoo Search: Recent Advances and Applications", "comments": "9 pages", "journal-ref": "X. S. Yang and S. Deb, Cuckoo search: recent advances and\n  applications, Neural Computing and Applications, vol. 24, No. 1, pp. 169-174\n  (2014)", "doi": "10.1007/s00521-013-1367-1", "report-no": null, "categories": "math.OC cs.NE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cuckoo search (CS) is a relatively new algorithm, developed by Yang and Deb\nin 2009, and CS is efficient in solving global optimization problems. In this\npaper, we review the fundamental ideas of cuckoo search and the latest\ndevelopments as well as its applications. We analyze the algorithm and gain\ninsight into its search mechanisms and find out why it is efficient. We also\ndiscuss the essence of algorithms and its link to self-organizing systems, and\nfinally we propose some important topics for further research.\n", "versions": [{"version": "v1", "created": "Fri, 22 Aug 2014 15:08:23 GMT"}], "update_date": "2014-08-25", "authors_parsed": [["Yang", "Xin-She", ""], ["Deb", "Suash", ""]]}, {"id": "1408.5320", "submitter": "Xin-She Yang", "authors": "Xin-She Yang, M. Karamanoglu, T. O. Ting and Y. X. Zhao", "title": "Applications and Analysis of Bio-Inspired Eagle Strategy for Engineering\n  Optimization", "comments": "14 pages 1 figure", "journal-ref": "Neural Computing and Applications, vol. 25, No. 2, pp. 411-420\n  (2014)", "doi": "10.1007/s00521-013-1508-6", "report-no": null, "categories": "math.OC cs.NE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All swarm-intelligence-based optimization algorithms use some stochastic\ncomponents to increase the diversity of solutions during the search process.\nSuch randomization is often represented in terms of random walks. However, it\nis not yet clear why some randomization techniques (and thus why some\nalgorithms) may perform better than others for a given set of problems. In this\nwork, we analyze these randomization methods in the context of nature-inspired\nalgorithms. We also use eagle strategy to provide basic observations and relate\nstep sizes and search efficiency using Markov theory. Then, we apply our\nanalysis and observations to solve four design benchmarks, including the\ndesigns of a pressure vessel, a speed reducer, a PID controller and a heat\nexchanger. Our results demonstrate that eagle strategy with L\\'evy flights can\nperform extremely well in reducing the overall computational efforts.\n", "versions": [{"version": "v1", "created": "Fri, 22 Aug 2014 15:23:35 GMT"}], "update_date": "2014-08-25", "authors_parsed": [["Yang", "Xin-She", ""], ["Karamanoglu", "M.", ""], ["Ting", "T. O.", ""], ["Zhao", "Y. X.", ""]]}, {"id": "1408.5332", "submitter": "Xin-She Yang", "authors": "Xin-She Yang, M. Karamanoglu, X. S. He", "title": "Flower Pollination Algorithm: A Novel Approach for Multiobjective\n  Optimization", "comments": "17 pages 8 figures. arXiv admin note: substantial text overlap with\n  arXiv:1404.0695", "journal-ref": "X. S. Yang, M. Karamanoglu, X. S. He, Flower Pollination\n  Algorithm: A Novel Approach for Multiobjective Optimization, Engineering\n  Optimization, 46 (9), pp. 1222 - 1237 (2014)", "doi": "10.1080/0305215X.2013.832237", "report-no": null, "categories": "math.OC cs.NE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiobjective design optimization problems require multiobjective\noptimization techniques to solve, and it is often very challenging to obtain\nhigh-quality Pareto fronts accurately. In this paper, the recently developed\nflower pollination algorithm (FPA) is extended to solve multiobjective\noptimization problems. The proposed method is used to solve a set of\nmultobjective test functions and two bi-objective design benchmarks, and a\ncomparison of the proposed algorithm with other algorithms has been made, which\nshows that FPA is efficient with a good convergence rate. Finally, the\nimportance for further parametric studies and theoretical analysis are\nhighlighted and discussed.\n", "versions": [{"version": "v1", "created": "Fri, 22 Aug 2014 15:41:22 GMT"}], "update_date": "2014-08-25", "authors_parsed": [["Yang", "Xin-She", ""], ["Karamanoglu", "M.", ""], ["He", "X. S.", ""]]}, {"id": "1408.5343", "submitter": "Xin-She Yang", "authors": "I. Fister Jr., X. S. Yang, D. Fister, I. Fister", "title": "Cuckoo Search: A Brief Literature Review", "comments": "14 pages 3 figures", "journal-ref": "Cuckoo Search and Firefly Algorithm: Theory and Applications,\n  Studies in Computational Intelligence, vol. 516, pp. 49-62 (2014)", "doi": "10.1007/978-3-319-02141-6_3", "report-no": null, "categories": "math.OC cs.NE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cuckoo search (CS) was introduced in 2009, and it has attracted great\nattention due to its promising efficiency in solving many optimization problems\nand real-world applications. In the last few years, many papers have been\npublished regarding cuckoo search, and the relevant literature has expanded\nsignificantly. This chapter summarizes briefly the majority of the literature\nabout cuckoo search in peer-reviewed journals and conferences found so far.\nThese references can be systematically classified into appropriate categories,\nwhich can be used as a basis for further research.\n", "versions": [{"version": "v1", "created": "Fri, 22 Aug 2014 16:05:13 GMT"}], "update_date": "2014-08-25", "authors_parsed": [["Fister", "I.", "Jr."], ["Yang", "X. S.", ""], ["Fister", "D.", ""], ["Fister", "I.", ""]]}, {"id": "1408.5348", "submitter": "Xin-She Yang", "authors": "Xin-She Yang, Suash Deb and Simon Fong", "title": "Bat Algorithm is Better Than Intermittent Search Strategy", "comments": "11 pages 1 figure. Available as X. S. Yang, S. Deb, S. Fong, Bat\n  Algorithm is Better Than Intermittent Search Strategy, Multiple-Valued Logic\n  and Soft Computing, 22 (3), 223-237 (2014). arXiv admin note: substantial\n  text overlap with arXiv:1308.3898", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficiency of any metaheuristic algorithm largely depends on the way of\nbalancing local intensive exploitation and global diverse exploration. Studies\nshow that bat algorithm can provide a good balance between these two key\ncomponents with superior efficiency. In this paper, we first review some\ncommonly used metaheuristic algorithms, and then compare the performance of bat\nalgorithm with the so-called intermittent search strategy. From simulations, we\nfound that bat algorithm is better than the optimal intermittent search\nstrategy. We also analyse the comparison results and their implications for\nhigher dimensional optimization problems. In addition, we also apply bat\nalgorithm in solving business optimization and engineering design problems.\n", "versions": [{"version": "v1", "created": "Fri, 22 Aug 2014 16:18:09 GMT"}], "update_date": "2014-08-25", "authors_parsed": [["Yang", "Xin-She", ""], ["Deb", "Suash", ""], ["Fong", "Simon", ""]]}, {"id": "1408.5350", "submitter": "Anna Kononova", "authors": "Anna V. Kononova and David W. Corne and Philippe De Wilde and Vsevolod\n  Shneer and Fabio Caraffini", "title": "Structural bias in population-based algorithms", "comments": null, "journal-ref": null, "doi": "10.1016/j.ins.2014.11.035", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Challenging optimisation problems are abundant in all areas of science. Since\nthe 1950s, scientists have developed ever-diversifying families of black box\noptimisation algorithms designed to address any optimisation problem, requiring\nonly that quality of a candidate solution is calculated via a fitness function\nspecific to the problem. For such algorithms to be successful, at least three\nproperties are required: an effective informed sampling strategy, that guides\ngeneration of new candidates on the basis of fitnesses and locations of\npreviously visited candidates; mechanisms to ensure efficiency, so that same\ncandidates are not repeatedly visited; absence of structural bias, which, if\npresent, would predispose the algorithm towards limiting its search to some\nregions of solution space. The first two of these properties have been\nextensively investigated, however the third is little understood. In this\narticle we provide theoretical and empirical analyses that contribute to the\nunderstanding of structural bias. We prove a theorem concerning dynamics of\npopulation variance in the case of real-valued search spaces. This reveals how\nstructural bias can manifest as non-uniform clustering of population over time.\nTheory predicts that structural bias is exacerbated with increasing population\nsize and problem difficulty. These predictions reveal two previously\nunrecognised aspects of structural bias. Respectively, increasing population\nsize, though ostensibly promoting diversity, will magnify any inherent\nstructural bias, and effects of structural bias are more apparent when faced\nwith difficult problems. Our theoretical result also suggests that two commonly\nused approaches to enhancing exploration, increasing population size and\nincreasing disruptiveness of search operators, have quite distinct implications\nin terms of structural bias.\n", "versions": [{"version": "v1", "created": "Fri, 22 Aug 2014 16:25:43 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Kononova", "Anna V.", ""], ["Corne", "David W.", ""], ["De Wilde", "Philippe", ""], ["Shneer", "Vsevolod", ""], ["Caraffini", "Fabio", ""]]}, {"id": "1408.5403", "submitter": "Peilei Liu", "authors": "Peilei Liu, Ting Wang", "title": "Neural Mechanism of Language", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is based on our previous work on neural coding. It is a\nself-organized model supported by existing evidences. Firstly, we briefly\nintroduce this model in this paper, and then we explain the neural mechanism of\nlanguage and reasoning with it. Moreover, we find that the position of an area\ndetermines its importance. Specifically, language relevant areas are in the\ncapital position of the cortical kingdom. Therefore they are closely related\nwith autonomous consciousness and working memories. In essence, language is a\nminiature of the real world. Briefly, this paper would like to bridge the gap\nbetween molecule mechanism of neurons and advanced functions such as language\nand reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 22 Aug 2014 12:15:54 GMT"}], "update_date": "2014-08-26", "authors_parsed": [["Liu", "Peilei", ""], ["Wang", "Ting", ""]]}, {"id": "1408.5405", "submitter": "Khalid Raza", "authors": "Khalid Raza and Mansaf Alam", "title": "Recurrent Neural Network Based Hybrid Model of Gene Regulatory Network", "comments": "18 pages, 9 figures and 4 tables", "journal-ref": "Computational Biology and Chemistry, 64: 322-334, 2016", "doi": "10.1016/j.compbiolchem.2016.08.002", "report-no": null, "categories": "cs.NE cs.CE q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems biology is an emerging interdisciplinary area of research that\nfocuses on study of complex interactions in a biological system, such as gene\nregulatory networks. The discovery of gene regulatory networks leads to a wide\nrange of applications, such as pathways related to a disease that can unveil in\nwhat way the disease acts and provide novel tentative drug targets. In\naddition, the development of biological models from discovered networks or\npathways can help to predict the responses to disease and can be much useful\nfor the novel drug development and treatments. The inference of regulatory\nnetworks from biological data is still in its infancy stage. This paper\nproposes a recurrent neural network (RNN) based gene regulatory network (GRN)\nmodel hybridized with generalized extended Kalman filter for weight update in\nbackpropagation through time training algorithm. The RNN is a complex neural\nnetwork that gives a better settlement between the biological closeness and\nmathematical flexibility to model GRN. The RNN is able to capture complex,\nnon-linear and dynamic relationship among variables. Gene expression data are\ninherently noisy and Kalman filter performs well for estimation even in noisy\ndata. Hence, non-linear version of Kalman filter, i.e., generalized extended\nKalman filter has been applied for weight update during network training. The\ndeveloped model has been applied on DNA SOS repair network, IRMA network, and\ntwo synthetic networks from DREAM Challenge. We compared our results with other\nstate-of-the-art techniques that show superiority of our model. Further, 5%\nGaussian noise has been added in the dataset and result of the proposed model\nshows negligible effect of noise on the results.\n", "versions": [{"version": "v1", "created": "Fri, 22 Aug 2014 18:35:27 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2015 12:38:53 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Raza", "Khalid", ""], ["Alam", "Mansaf", ""]]}, {"id": "1408.5882", "submitter": "Yoon Kim", "authors": "Yoon Kim", "title": "Convolutional Neural Networks for Sentence Classification", "comments": "To appear in EMNLP 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on a series of experiments with convolutional neural networks (CNN)\ntrained on top of pre-trained word vectors for sentence-level classification\ntasks. We show that a simple CNN with little hyperparameter tuning and static\nvectors achieves excellent results on multiple benchmarks. Learning\ntask-specific vectors through fine-tuning offers further gains in performance.\nWe additionally propose a simple modification to the architecture to allow for\nthe use of both task-specific and static vectors. The CNN models discussed\nherein improve upon the state of the art on 4 out of 7 tasks, which include\nsentiment analysis and question classification.\n", "versions": [{"version": "v1", "created": "Mon, 25 Aug 2014 19:48:04 GMT"}, {"version": "v2", "created": "Wed, 3 Sep 2014 03:09:02 GMT"}], "update_date": "2014-09-04", "authors_parsed": [["Kim", "Yoon", ""]]}, {"id": "1408.6741", "submitter": "Yuriy Pershin", "authors": "Y. V. Pershin and M. Di Ventra", "title": "Memcomputing and Swarm Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.mes-hall cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the relation between memcomputing, namely computing with and in\nmemory, and swarm intelligence algorithms. In particular, we show that one can\ndesign memristive networks to solve short-path optimization problems that can\nalso be solved by ant-colony algorithms. By employing appropriate memristive\nelements one can demonstrate an almost one-to-one correspondence between\nmemcomputing and ant colony optimization approaches. However, the memristive\nnetwork has the capability of finding the solution in one deterministic step,\ncompared to the stochastic multi-step ant colony optimization. This result\npaves the way for nanoscale hardware implementations of several swarm\nintelligence algorithms that are presently explored, from scheduling problems\nto robotics.\n", "versions": [{"version": "v1", "created": "Thu, 28 Aug 2014 14:55:16 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Pershin", "Y. V.", ""], ["Di Ventra", "M.", ""]]}]