[{"id": "1605.00064", "submitter": "Rohollah Soltani", "authors": "Rohollah Soltani and Hui Jiang", "title": "Higher Order Recurrent Neural Networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study novel neural network structures to better model long\nterm dependency in sequential data. We propose to use more memory units to keep\ntrack of more preceding states in recurrent neural networks (RNNs), which are\nall recurrently fed to the hidden layers as feedback through different weighted\npaths. By extending the popular recurrent structure in RNNs, we provide the\nmodels with better short-term memory mechanism to learn long term dependency in\nsequences. Analogous to digital filters in signal processing, we call these\nstructures as higher order RNNs (HORNNs). Similar to RNNs, HORNNs can also be\nlearned using the back-propagation through time method. HORNNs are generally\napplicable to a variety of sequence modelling tasks. In this work, we have\nexamined HORNNs for the language modeling task using two popular data sets,\nnamely the Penn Treebank (PTB) and English text8 data sets. Experimental\nresults have shown that the proposed HORNNs yield the state-of-the-art\nperformance on both data sets, significantly outperforming the regular RNNs as\nwell as the popular LSTMs.\n", "versions": [{"version": "v1", "created": "Sat, 30 Apr 2016 05:04:08 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Soltani", "Rohollah", ""], ["Jiang", "Hui", ""]]}, {"id": "1605.00097", "submitter": "{\\L}ukasz Pater", "authors": "Lukasz Pater", "title": "Application of artificial neural networks and genetic algorithms for\n  crude fractional distillation process modeling", "comments": "Publication has 9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents the application of the artificial neural networks, trained\nand structurally optimized by genetic algorithms, for modeling of crude\ndistillation process at PKN ORLEN S.A. refinery. Models for the main\nfractionator distillation column products were developed using historical data.\nQuality of the fractions were predicted based on several chosen process\nvariables. The performance of the model was validated using test data. Neural\nnetworks used in companion with genetic algorithms proved that they can\naccurately predict fractions quality shifts, reproducing the results of the\nstandard laboratory analysis. Simple knowledge extraction method from neural\nnetwork model built was also performed. Genetic algorithms can be successfully\nutilized in efficient training of large neural networks and finding their\noptimal structures.\n", "versions": [{"version": "v1", "created": "Sat, 30 Apr 2016 11:46:58 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Pater", "Lukasz", ""]]}, {"id": "1605.00404", "submitter": "Ming Li", "authors": "Ming Li", "title": "Simple2Complex: Global Optimization by Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method named simple2complex for modeling and training deep neural networks\nis proposed. Simple2complex train deep neural networks by smoothly adding more\nand more layers to the shallow networks, as the learning procedure going on,\nthe network is just like growing. Compared with learning by end2end,\nsimple2complex is with less possibility trapping into local minimal, namely,\nowning ability for global optimization. Cifar10 is used for verifying the\nsuperiority of simple2complex.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 09:33:46 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Li", "Ming", ""]]}, {"id": "1605.00591", "submitter": "Gianluca Calcagni", "authors": "Gianluca Calcagni", "title": "The geometry of learning", "comments": "17 pages, 7 figures, 1 table. v2: new sections, figures and\n  references added, including discussions on random fractals and their\n  applications and on 1/f cognitive noise models; v3: consequences and\n  predictions of the theory added, typos corrected", "journal-ref": "J. Math. Psychol. 84 (2018) 74", "doi": "10.1016/j.jmp.2018.03.007", "report-no": null, "categories": "q-bio.QM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a correspondence between Pavlovian conditioning processes and\nfractals. The association strength at a training trial corresponds to a point\nin a disconnected set at a given iteration level. In this way, one can\nrepresent a training process as a hopping on a fractal set, instead of the\ntraditional learning curve as a function of the trial. The main advantage of\nthis novel perspective is to provide an elegant classification of associative\ntheories in terms of the geometric features of fractal sets. In particular, the\ndimension of fractals can measure the efficiency of conditioning models. We\nillustrate the correspondence with the examples of the Hull, Rescorla-Wagner,\nand Mackintosh models and show that they are equivalent to a Cantor set. More\ngenerally, conditioning programs are described by the geometry of their\nassociated fractal, which gives much more information than just its dimension.\nWe show this in several examples of random fractals and also comment on a\npossible relation between our formalism and other \"fractal\" findings in the\ncognitive literature.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 18:11:17 GMT"}, {"version": "v2", "created": "Sat, 17 Dec 2016 11:39:44 GMT"}, {"version": "v3", "created": "Sun, 22 Apr 2018 18:28:16 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Calcagni", "Gianluca", ""]]}, {"id": "1605.00942", "submitter": "Seppo Enarvi", "authors": "Seppo Enarvi, Mikko Kurimo", "title": "TheanoLM - An Extensible Toolkit for Neural Network Language Modeling", "comments": null, "journal-ref": "Proc. Interspeech 2016, pp. 3052-3056", "doi": "10.21437/Interspeech.2016-618", "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new tool for training neural network language models (NNLMs),\nscoring sentences, and generating text. The tool has been written using Python\nlibrary Theano, which allows researcher to easily extend it and tune any aspect\nof the training process. Regardless of the flexibility, Theano is able to\ngenerate extremely fast native code that can utilize a GPU or multiple CPU\ncores in order to parallelize the heavy numerical computations. The tool has\nbeen evaluated in difficult Finnish and English conversational speech\nrecognition tasks, and significant improvement was obtained over our best\nback-off n-gram models. The results that we obtained in the Finnish task were\ncompared to those from existing RNNLM and RWTHLM toolkits, and found to be as\ngood or better, while training times were an order of magnitude shorter.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 15:20:31 GMT"}, {"version": "v2", "created": "Mon, 8 Aug 2016 08:04:04 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Enarvi", "Seppo", ""], ["Kurimo", "Mikko", ""]]}, {"id": "1605.01369", "submitter": "Shuai Zheng", "authors": "Shuai Zheng, Abhinav Vishnu, Chris Ding", "title": "Accelerating Deep Learning with Shrinkage and Recall", "comments": "The 22nd IEEE International Conference on Parallel and Distributed\n  Systems (ICPADS 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning is a very powerful machine learning model. Deep Learning trains\na large number of parameters for multiple layers and is very slow when data is\nin large scale and the architecture size is large. Inspired from the shrinking\ntechnique used in accelerating computation of Support Vector Machines (SVM)\nalgorithm and screening technique used in LASSO, we propose a shrinking Deep\nLearning with recall (sDLr) approach to speed up deep learning computation. We\nexperiment shrinking Deep Learning with recall (sDLr) using Deep Neural Network\n(DNN), Deep Belief Network (DBN) and Convolution Neural Network (CNN) on 4 data\nsets. Results show that the speedup using shrinking Deep Learning with recall\n(sDLr) can reach more than 2.0 while still giving competitive classification\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 18:17:37 GMT"}, {"version": "v2", "created": "Mon, 19 Sep 2016 19:27:39 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Zheng", "Shuai", ""], ["Vishnu", "Abhinav", ""], ["Ding", "Chris", ""]]}, {"id": "1605.01514", "submitter": "Michal Gregor", "authors": "Michal Gregor and Juraj Spalek", "title": "Fitness-based Adaptive Control of Parameters in Genetic Programming:\n  Adaptive Value Setting of Mutation Rate and Flood Mechanisms", "comments": "in 2011 IEEE International Conference on Intelligent Computing and\n  Intelligent Systems (ICIS 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns applications of genetic algorithms and genetic\nprogramming to tasks for which it is difficult to find a representation that\ndoes not map to a highly complex and discontinuous fitness landscape. In such\ncases the standard algorithm is prone to getting trapped in local extremes. The\npaper proposes several adaptive mechanisms that are useful in preventing the\nsearch from getting trapped.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 07:30:02 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Gregor", "Michal", ""], ["Spalek", "Juraj", ""]]}, {"id": "1605.01713", "submitter": "Avanti Shrikumar", "authors": "Avanti Shrikumar, Peyton Greenside, Anna Shcherbina, Anshul Kundaje", "title": "Not Just a Black Box: Learning Important Features Through Propagating\n  Activation Differences", "comments": "6 pages, 3 figures, this is an older version; see\n  https://arxiv.org/abs/1704.02685 for the newer version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Note: This paper describes an older version of DeepLIFT. See\nhttps://arxiv.org/abs/1704.02685 for the newer version. Original abstract\nfollows: The purported \"black box\" nature of neural networks is a barrier to\nadoption in applications where interpretability is essential. Here we present\nDeepLIFT (Learning Important FeaTures), an efficient and effective method for\ncomputing importance scores in a neural network. DeepLIFT compares the\nactivation of each neuron to its 'reference activation' and assigns\ncontribution scores according to the difference. We apply DeepLIFT to models\ntrained on natural images and genomic data, and show significant advantages\nover gradient-based methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 19:52:32 GMT"}, {"version": "v2", "created": "Sun, 8 May 2016 21:34:42 GMT"}, {"version": "v3", "created": "Tue, 11 Apr 2017 15:58:48 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Shrikumar", "Avanti", ""], ["Greenside", "Peyton", ""], ["Shcherbina", "Anna", ""], ["Kundaje", "Anshul", ""]]}, {"id": "1605.01746", "submitter": "Nikolaus Hansen", "authors": "Dimo Brockhoff, Tea Tu\\v{s}ar, Dejan Tu\\v{s}ar, Tobias Wagner,\n  Nikolaus Hansen, Anne Auger", "title": "Biobjective Performance Assessment with the COCO Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document details the rationales behind assessing the performance of\nnumerical black-box optimizers on multi-objective problems within the COCO\nplatform and in particular on the biobjective test suite bbob-biobj. The\nevaluation is based on a hypervolume of all non-dominated solutions in the\narchive of candidate solutions and measures the runtime until the hypervolume\nvalue succeeds prescribed target values.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 20:15:47 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Brockhoff", "Dimo", ""], ["Tu\u0161ar", "Tea", ""], ["Tu\u0161ar", "Dejan", ""], ["Wagner", "Tobias", ""], ["Hansen", "Nikolaus", ""], ["Auger", "Anne", ""]]}, {"id": "1605.01855", "submitter": "Andrew Connor", "authors": "Andy M. Connor and Amit Shah", "title": "Resource allocation using metaheuristic search", "comments": "Proceedings of the Fourth International Conference on Computer\n  Science & Information Technology 2014", "journal-ref": null, "doi": "10.5121/csit.2014.4230", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research is focused on solving problems in the area of software project\nmanagement using metaheuristic search algorithms and as such is research in the\nfield of search based software engineering. The main aim of this research is to\nevaluate the performance of different metaheuristic search techniques in\nresource allocation and scheduling problems that would be typical of software\ndevelopment projects. This paper reports a set of experiments which evaluate\nthe performance of three algorithms, namely simulated annealing, tabu search\nand genetic algorithms. The experimental results indicate that all of the\nmetaheuristics search techniques can be used to solve problems in resource\nallocation and scheduling within a software project. Finally, a comparative\nanalysis suggests that overall the genetic algorithm had performed better than\nsimulated annealing and tabu search.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 08:14:13 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Connor", "Andy M.", ""], ["Shah", "Amit", ""]]}, {"id": "1605.01988", "submitter": "Andrew Pulver", "authors": "Andrew Pulver, Siwei Lyu", "title": "LSTM with Working Memory", "comments": "Accepted at IJCNN 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous RNN architectures have largely been superseded by LSTM, or \"Long\nShort-Term Memory\". Since its introduction, there have been many variations on\nthis simple design. However, it is still widely used and we are not aware of a\ngated-RNN architecture that outperforms LSTM in a broad sense while still being\nas simple and efficient. In this paper we propose a modified LSTM-like\narchitecture. Our architecture is still simple and achieves better performance\non the tasks that we tested on. We also introduce a new RNN performance\nbenchmark that uses the handwritten digits and stresses several important\nnetwork capabilities.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 16:11:45 GMT"}, {"version": "v2", "created": "Fri, 13 May 2016 16:47:41 GMT"}, {"version": "v3", "created": "Thu, 30 Mar 2017 18:24:55 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Pulver", "Andrew", ""], ["Lyu", "Siwei", ""]]}, {"id": "1605.02486", "submitter": "Cedric De Boom", "authors": "Cedric De Boom, Sam Leroux, Steven Bohez, Pieter Simoens, Thomas\n  Demeester, Bart Dhoedt", "title": "Efficiency Evaluation of Character-level RNN Training Schedules", "comments": "3 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present four training and prediction schedules from the same\ncharacter-level recurrent neural network. The efficiency of these schedules is\ntested in terms of model effectiveness as a function of training time and\namount of training data seen. We show that the choice of training and\nprediction schedule potentially has a considerable impact on the prediction\neffectiveness for a given training budget.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 09:12:11 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["De Boom", "Cedric", ""], ["Leroux", "Sam", ""], ["Bohez", "Steven", ""], ["Simoens", "Pieter", ""], ["Demeester", "Thomas", ""], ["Dhoedt", "Bart", ""]]}, {"id": "1605.02619", "submitter": "Daniel Figueiredo", "authors": "Daniel R. Figueiredo, Michele Garetto", "title": "On the Emergence of Shortest Paths by Reinforced Random Walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The co-evolution between network structure and functional performance is a\nfundamental and challenging problem whose complexity emerges from the intrinsic\ninterdependent nature of structure and function. Within this context, we\ninvestigate the interplay between the efficiency of network navigation (i.e.,\npath lengths) and network structure (i.e., edge weights). We propose a simple\nand tractable model based on iterative biased random walks where edge weights\nincrease over time as function of the traversed path length. Under mild\nassumptions, we prove that biased random walks will eventually only traverse\nshortest paths in their journey towards the destination. We further\ncharacterize the transient regime proving that the probability to traverse\nnon-shortest paths decays according to a power-law. We also highlight various\nproperties in this dynamic, such as the trade-off between exploration and\nconvergence, and preservation of initial network plasticity. We believe the\nproposed model and results can be of interest to various domains where biased\nrandom walks and decentralized navigation have been applied.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 15:18:15 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Figueiredo", "Daniel R.", ""], ["Garetto", "Michele", ""]]}, {"id": "1605.02720", "submitter": "Ilya Loshchilov", "authors": "Ilya Loshchilov and Tobias Glasmachers", "title": "Anytime Bi-Objective Optimization with a Hybrid Multi-Objective CMA-ES\n  (HMO-CMA-ES)", "comments": "BBOB workshop of GECCO'2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multi-objective optimization algorithm aimed at achieving good\nanytime performance over a wide range of problems. Performance is assessed in\nterms of the hypervolume metric. The algorithm called HMO-CMA-ES represents a\nhybrid of several old and new variants of CMA-ES, complemented by BOBYQA as a\nwarm start. We benchmark HMO-CMA-ES on the recently introduced bi-objective\nproblem suite of the COCO framework (COmparing Continuous Optimizers),\nconsisting of 55 scalable continuous optimization problems, which is used by\nthe Black-Box Optimization Benchmarking (BBOB) Workshop 2016.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 19:58:29 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Loshchilov", "Ilya", ""], ["Glasmachers", "Tobias", ""]]}, {"id": "1605.02766", "submitter": "Chengxi Ye", "authors": "Chengxi Ye, Chen Zhao, Yezhou Yang, Cornelia Fermuller, Yiannis\n  Aloimonos", "title": "LightNet: A Versatile, Standalone Matlab-based Environment for Deep\n  Learning", "comments": "Accepted to ACM MULTIMEDIA 2016 Open Source Software Competition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LightNet is a lightweight, versatile and purely Matlab-based deep learning\nframework. The idea underlying its design is to provide an easy-to-understand,\neasy-to-use and efficient computational platform for deep learning research.\nThe implemented framework supports major deep learning architectures such as\nMultilayer Perceptron Networks (MLP), Convolutional Neural Networks (CNN) and\nRecurrent Neural Networks (RNN). The framework also supports both CPU and GPU\ncomputation, and the switch between them is straightforward. Different\napplications in computer vision, natural language processing and robotics are\ndemonstrated as experiments.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 20:33:30 GMT"}, {"version": "v2", "created": "Fri, 13 May 2016 00:20:14 GMT"}, {"version": "v3", "created": "Tue, 2 Aug 2016 04:00:30 GMT"}], "update_date": "2016-08-03", "authors_parsed": [["Ye", "Chengxi", ""], ["Zhao", "Chen", ""], ["Yang", "Yezhou", ""], ["Fermuller", "Cornelia", ""], ["Aloimonos", "Yiannis", ""]]}, {"id": "1605.02914", "submitter": "Vasileios Belagiannis", "authors": "Vasileios Belagiannis and Andrew Zisserman", "title": "Recurrent Human Pose Estimation", "comments": "FG 2017, More Info and Demo:\n  http://www.robots.ox.ac.uk/~vgg/software/keypoint_detection/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel ConvNet model for predicting 2D human body poses in an\nimage. The model regresses a heatmap representation for each body keypoint, and\nis able to learn and represent both the part appearances and the context of the\npart configuration. We make the following three contributions: (i) an\narchitecture combining a feed forward module with a recurrent module, where the\nrecurrent module can be run iteratively to improve the performance, (ii) the\nmodel can be trained end-to-end and from scratch, with auxiliary losses\nincorporated to improve performance, (iii) we investigate whether keypoint\nvisibility can also be predicted. The model is evaluated on two benchmark\ndatasets. The result is a simple architecture that achieves performance on par\nwith the state of the art, but without the complexity of a graphical model\nstage (or layers).\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 09:58:11 GMT"}, {"version": "v2", "created": "Sat, 25 Feb 2017 09:45:32 GMT"}, {"version": "v3", "created": "Sat, 5 Aug 2017 11:56:51 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Belagiannis", "Vasileios", ""], ["Zisserman", "Andrew", ""]]}, {"id": "1605.03560", "submitter": "Nikolaus Hansen", "authors": "Nikolaus Hansen, Anne Auger, Dimo Brockhoff, Dejan Tu\\v{s}ar, Tea\n  Tu\\v{s}ar", "title": "COCO: Performance Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an any-time performance assessment for benchmarking numerical\noptimization algorithms in a black-box scenario, applied within the COCO\nbenchmarking platform. The performance assessment is based on runtimes measured\nin number of objective function evaluations to reach one or several quality\nindicator target values. We argue that runtime is the only available measure\nwith a generic, meaningful, and quantitative interpretation. We discuss the\nchoice of the target values, runlength-based targets, and the aggregation of\nresults by using simulated restarts, averages, and empirical distribution\nfunctions.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 19:49:43 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Hansen", "Nikolaus", ""], ["Auger", "Anne", ""], ["Brockhoff", "Dimo", ""], ["Tu\u0161ar", "Dejan", ""], ["Tu\u0161ar", "Tea", ""]]}, {"id": "1605.03639", "submitter": "Ali Mollahosseini", "authors": "Ali Mollahosseini, Behzad Hassani, Michelle J. Salvador, Hojjat\n  Abdollahi, David Chan, and Mohammad H. Mahoor", "title": "Facial Expression Recognition from World Wild Web", "comments": null, "journal-ref": null, "doi": "10.1109/CVPRW.2016.188", "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing facial expression in a wild setting has remained a challenging\ntask in computer vision. The World Wide Web is a good source of facial images\nwhich most of them are captured in uncontrolled conditions. In fact, the\nInternet is a Word Wild Web of facial images with expressions. This paper\npresents the results of a new study on collecting, annotating, and analyzing\nwild facial expressions from the web. Three search engines were queried using\n1250 emotion related keywords in six different languages and the retrieved\nimages were mapped by two annotators to six basic expressions and neutral. Deep\nneural networks and noise modeling were used in three different training\nscenarios to find how accurately facial expressions can be recognized when\ntrained on noisy images collected from the web using query terms (e.g. happy\nface, laughing man, etc)? The results of our experiments show that deep neural\nnetworks can recognize wild facial expressions with an accuracy of 82.12%.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 23:45:00 GMT"}, {"version": "v2", "created": "Fri, 20 May 2016 04:38:42 GMT"}, {"version": "v3", "created": "Thu, 5 Jan 2017 18:07:46 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Mollahosseini", "Ali", ""], ["Hassani", "Behzad", ""], ["Salvador", "Michelle J.", ""], ["Abdollahi", "Hojjat", ""], ["Chan", "David", ""], ["Mahoor", "Mohammad H.", ""]]}, {"id": "1605.03764", "submitter": "Artem Chernodub N", "authors": "Artem Chernodub", "title": "Direct Method for Training Feed-forward Neural Networks using Batch\n  Extended Kalman Filter for Multi-Step-Ahead Predictions", "comments": null, "journal-ref": "Proceedings of ICANN'2013-LCNS Series, Volume 8131.\n  Springer-Verlag New York, Inc., 2013, P. 138-145", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is dedicated to the long-term, or multi-step-ahead, time series\nprediction problem. We propose a novel method for training feed-forward neural\nnetworks, such as multilayer perceptrons, with tapped delay lines. Special\nbatch calculation of derivatives called Forecasted Propagation Through Time and\nbatch modification of the Extended Kalman Filter are introduced. Experiments\nwere carried out on well-known time series benchmarks, the Mackey-Glass chaotic\nprocess and the Santa Fe Laser Data Series. Recurrent and feed-forward neural\nnetworks were evaluated.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 11:39:14 GMT"}], "update_date": "2016-05-13", "authors_parsed": [["Chernodub", "Artem", ""]]}, {"id": "1605.04614", "submitter": "Amund Tveit", "authors": "Amund Tveit, Torbj{\\o}rn Morland and Thomas Brox R{\\o}st", "title": "DeepLearningKit - an GPU Optimized Deep Learning Framework for Apple's\n  iOS, OS X and tvOS developed in Metal and Swift", "comments": "9 pages, 12 figures, open source documentation and code at\n  deeplearningkit.org and github.com/deeplearningkit", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present DeepLearningKit - an open source framework that\nsupports using pretrained deep learning models (convolutional neural networks)\nfor iOS, OS X and tvOS. DeepLearningKit is developed in Metal in order to\nutilize the GPU efficiently and Swift for integration with applications, e.g.\niOS-based mobile apps on iPhone/iPad, tvOS-based apps for the big screen, or OS\nX desktop applications. The goal is to support using deep learning models\ntrained with popular frameworks such as Caffe, Torch, TensorFlow, Theano,\nPylearn, Deeplearning4J and Mocha. Given the massive GPU resources and time\nrequired to train Deep Learning models we suggest an App Store like model to\ndistribute and download pretrained and reusable Deep Learning models.\n", "versions": [{"version": "v1", "created": "Sun, 15 May 2016 23:19:48 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Tveit", "Amund", ""], ["Morland", "Torbj\u00f8rn", ""], ["R\u00f8st", "Thomas Brox", ""]]}, {"id": "1605.04639", "submitter": "Akira Imakura", "authors": "Tetsuya Sakurai, Akira Imakura, Yuto Inoue and Yasunori Futamura", "title": "Alternating optimization method based on nonnegative matrix\n  factorizations for deep neural networks", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The backpropagation algorithm for calculating gradients has been widely used\nin computation of weights for deep neural networks (DNNs). This method requires\nderivatives of objective functions and has some difficulties finding\nappropriate parameters such as learning rate. In this paper, we propose a novel\napproach for computing weight matrices of fully-connected DNNs by using two\ntypes of semi-nonnegative matrix factorizations (semi-NMFs). In this method,\noptimization processes are performed by calculating weight matrices\nalternately, and backpropagation (BP) is not used. We also present a method to\ncalculate stacked autoencoder using a NMF. The output results of the\nautoencoder are used as pre-training data for DNNs. The experimental results\nshow that our method using three types of NMFs attains similar error rates to\nthe conventional DNNs with BP.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 03:11:17 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Sakurai", "Tetsuya", ""], ["Imakura", "Akira", ""], ["Inoue", "Yuto", ""], ["Futamura", "Yasunori", ""]]}, {"id": "1605.04655", "submitter": "Petr Baudi\\v{s}", "authors": "Petr Baudis, Silvestr Stanko and Jan Sedivy", "title": "Joint Learning of Sentence Embeddings for Relevance and Entailment", "comments": "repl4nlp workshop at ACL Berlin 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of Recognizing Textual Entailment within an\nInformation Retrieval context, where we must simultaneously determine the\nrelevancy as well as degree of entailment for individual pieces of evidence to\ndetermine a yes/no answer to a binary natural language question.\n  We compare several variants of neural networks for sentence embeddings in a\nsetting of decision-making based on evidence of varying relevance. We propose a\nbasic model to integrate evidence for entailment, show that joint training of\nthe sentence embeddings to model relevance and entailment is feasible even with\nno explicit per-evidence supervision, and show the importance of evaluating\nstrong baselines. We also demonstrate the benefit of carrying over text\ncomprehension model trained on an unrelated task for our small datasets.\n  Our research is motivated primarily by a new open dataset we introduce,\nconsisting of binary questions and news-based evidence snippets. We also apply\nthe proposed relevance-entailment model on a similar task of ranking\nmultiple-choice test answers, evaluating it on a preliminary dataset of school\ntest questions as well as the standard MCTest dataset, where we improve the\nneural model state-of-art.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 05:50:54 GMT"}, {"version": "v2", "created": "Wed, 22 Jun 2016 22:41:26 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Baudis", "Petr", ""], ["Stanko", "Silvestr", ""], ["Sedivy", "Jan", ""]]}, {"id": "1605.04859", "submitter": "Ming Tu", "authors": "Ming Tu, Visar Berisha, Yu Cao, Jae-sun Seo", "title": "Reducing the Model Order of Deep Neural Networks Using Information\n  Theory", "comments": "To appear in ISVLSI 2016 special session", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are typically represented by a much larger number of\nparameters than shallow models, making them prohibitive for small footprint\ndevices. Recent research shows that there is considerable redundancy in the\nparameter space of deep neural networks. In this paper, we propose a method to\ncompress deep neural networks by using the Fisher Information metric, which we\nestimate through a stochastic optimization method that keeps track of\nsecond-order information in the network. We first remove unimportant parameters\nand then use non-uniform fixed point quantization to assign more bits to\nparameters with higher Fisher Information estimates. We evaluate our method on\na classification task with a convolutional neural network trained on the MNIST\ndata set. Experimental results show that our method outperforms existing\nmethods for both network pruning and quantization.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 18:12:45 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Tu", "Ming", ""], ["Berisha", "Visar", ""], ["Cao", "Yu", ""], ["Seo", "Jae-sun", ""]]}, {"id": "1605.05216", "submitter": "Justin Chen", "authors": "Justin Chen", "title": "Combinatorially Generated Piecewise Activation Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the neuroevolution literature, research has primarily focused on evolving\nthe number of nodes, connections, and weights in artificial neural networks.\nFew attempts have been made to evolve activation functions. Research in\nevolving activation functions has mainly focused on evolving function\nparameters, and developing heterogeneous networks by selecting from a fixed\npool of activation functions. This paper introduces a novel technique for\nevolving heterogeneous artificial neural networks through combinatorially\ngenerating piecewise activation functions to enhance expressive power. I\ndemonstrate this technique on NeuroEvolution of Augmenting Topologies using\nArcTan and Sigmoid, and show that it outperforms the original algorithm on\nnon-Markovian double pole balancing. This technique expands the landscape of\nunconventional activation functions by demonstrating that they are competitive\nwith canonical choices, and introduces a purview for further exploration of\nautomatic model selection for artificial neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 15:45:08 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Chen", "Justin", ""]]}, {"id": "1605.05239", "submitter": "Benjamin Migliori", "authors": "Benjamin Migliori, Riley Zeller-Townson, Daniel Grady, Daniel Gebhardt", "title": "Biologically Inspired Radio Signal Feature Extraction with Sparse\n  Denoising Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic modulation classification (AMC) is an important task for modern\ncommunication systems; however, it is a challenging problem when signal\nfeatures and precise models for generating each modulation may be unknown. We\npresent a new biologically-inspired AMC method without the need for models or\nmanually specified features --- thus removing the requirement for expert prior\nknowledge. We accomplish this task using regularized stacked sparse denoising\nautoencoders (SSDAs). Our method selects efficient classification features\ndirectly from raw in-phase/quadrature (I/Q) radio signals in an unsupervised\nmanner. These features are then used to construct higher-complexity abstract\nfeatures which can be used for automatic modulation classification. We\ndemonstrate this process using a dataset generated with a software defined\nradio, consisting of random input bits encoded in 100-sample segments of\nvarious common digital radio modulations. Our results show correct\nclassification rates of > 99% at 7.5 dB signal-to-noise ratio (SNR) and > 92%\nat 0 dB SNR in a 6-way classification test. Our experiments demonstrate a\ndramatically new and broadly applicable mechanism for performing AMC and\nrelated tasks without the need for expert-defined or modulation-specific signal\ninformation.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 17:03:02 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Migliori", "Benjamin", ""], ["Zeller-Townson", "Riley", ""], ["Grady", "Daniel", ""], ["Gebhardt", "Daniel", ""]]}, {"id": "1605.05296", "submitter": "Michael Bukatin", "authors": "Michael Bukatin and Steve Matthews and Andrey Radul", "title": "Dataflow matrix machines as programmable, dynamically expandable,\n  self-referential generalized recurrent neural networks", "comments": "9 pages (v2 - update references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dataflow matrix machines are a powerful generalization of recurrent neural\nnetworks. They work with multiple types of linear streams and multiple types of\nneurons, including higher-order neurons which dynamically update the matrix\ndescribing weights and topology of the network in question while the network is\nrunning. It seems that the power of dataflow matrix machines is sufficient for\nthem to be a convenient general purpose programming platform. This paper\nexplores a number of useful programming idioms and constructions arising in\nthis context.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 19:29:37 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 02:24:27 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Bukatin", "Michael", ""], ["Matthews", "Steve", ""], ["Radul", "Andrey", ""]]}, {"id": "1605.05359", "submitter": "Aravind Srinivas", "authors": "Aravind Srinivas, Ramnandan Krishnamurthy, Peeyush Kumar and Balaraman\n  Ravindran", "title": "Option Discovery in Hierarchical Reinforcement Learning using\n  Spatio-Temporal Clustering", "comments": "Revised version of ICML 16 Abstraction in Reinforcement Learning\n  workshop paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an automated skill acquisition framework in\nreinforcement learning which involves identifying a hierarchical description of\nthe given task in terms of abstract states and extended actions between\nabstract states. Identifying such structures present in the task provides ways\nto simplify and speed up reinforcement learning algorithms. These structures\nalso help to generalize such algorithms over multiple tasks without relearning\npolicies from scratch. We use ideas from dynamical systems to find metastable\nregions in the state space and associate them with abstract states. The\nspectral clustering algorithm PCCA+ is used to identify suitable abstractions\naligned to the underlying structure. Skills are defined in terms of the\nsequence of actions that lead to transitions between such abstract states. The\nconnectivity information from PCCA+ is used to generate these skills or\noptions. These skills are independent of the learning task and can be\nefficiently reused across a variety of tasks defined over the same model. This\napproach works well even without the exact model of the environment by using\nsample trajectories to construct an approximate estimate. We also present our\napproach to scaling the skill acquisition framework to complex tasks with large\nstate spaces for which we perform state aggregation using the representation\nlearned from an action conditional video prediction network and use the skill\nacquisition framework on the aggregated state space.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 20:44:19 GMT"}, {"version": "v2", "created": "Tue, 20 Sep 2016 19:14:20 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 22:18:31 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Srinivas", "Aravind", ""], ["Krishnamurthy", "Ramnandan", ""], ["Kumar", "Peeyush", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1605.05365", "submitter": "Aravind Srinivas", "authors": "Aravind Srinivas, Sahil Sharma and Balaraman Ravindran", "title": "Dynamic Frame skip Deep Q Network", "comments": "IJCAI 2016 Workshop on Deep Reinforcement Learning: Frontiers and\n  Challenges; 6 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning methods have achieved state of the art\nperformance in learning control policies for the games in the Atari 2600\ndomain. One of the important parameters in the Arcade Learning Environment\n(ALE) is the frame skip rate. It decides the granularity at which agents can\ncontrol game play. A frame skip value of $k$ allows the agent to repeat a\nselected action $k$ number of times. The current state of the art architectures\nlike Deep Q-Network (DQN) and Dueling Network Architectures (DuDQN) consist of\na framework with a static frame skip rate, where the action output from the\nnetwork is repeated for a fixed number of frames regardless of the current\nstate. In this paper, we propose a new architecture, Dynamic Frame skip Deep\nQ-Network (DFDQN) which makes the frame skip rate a dynamic learnable\nparameter. This allows us to choose the number of times an action is to be\nrepeated based on the current state. We show empirically that such a setting\nimproves the performance on relatively harder games like Seaquest.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 20:58:41 GMT"}, {"version": "v2", "created": "Sat, 11 Jun 2016 01:04:13 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 22:20:49 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Srinivas", "Aravind", ""], ["Sharma", "Sahil", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1605.05368", "submitter": "Kin Gwn Lore", "authors": "Kin Gwn Lore, Daniel Stoecklein, Michael Davies, Baskar\n  Ganapathysubramanian, Soumik Sarkar", "title": "Deep Action Sequence Learning for Causal Shape Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning became the method of choice in recent year for solving a wide\nvariety of predictive analytics tasks. For sequence prediction, recurrent\nneural networks (RNN) are often the go-to architecture for exploiting\nsequential information where the output is dependent on previous computation.\nHowever, the dependencies of the computation lie in the latent domain which may\nnot be suitable for certain applications involving the prediction of a\nstep-wise transformation sequence that is dependent on the previous computation\nonly in the visible domain. We propose that a hybrid architecture of\nconvolution neural networks (CNN) and stacked autoencoders (SAE) is sufficient\nto learn a sequence of actions that nonlinearly transforms an input shape or\ndistribution into a target shape or distribution with the same support. While\nsuch a framework can be useful in a variety of problems such as robotic path\nplanning, sequential decision-making in games, and identifying material\nprocessing pathways to achieve desired microstructures, the application of the\nframework is exemplified by the control of fluid deformations in a microfluidic\nchannel by deliberately placing a sequence of pillars. Learning of a multistep\ntopological transform has significant implications for rapid advances in\nmaterial science and biomedical applications.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 21:07:18 GMT"}, {"version": "v2", "created": "Fri, 20 May 2016 02:01:37 GMT"}, {"version": "v3", "created": "Tue, 8 Nov 2016 20:48:47 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Lore", "Kin Gwn", ""], ["Stoecklein", "Daniel", ""], ["Davies", "Michael", ""], ["Ganapathysubramanian", "Baskar", ""], ["Sarkar", "Soumik", ""]]}, {"id": "1605.05396", "submitter": "Scott Reed", "authors": "Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt\n  Schiele, Honglak Lee", "title": "Generative Adversarial Text to Image Synthesis", "comments": "ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic synthesis of realistic images from text would be interesting and\nuseful, but current AI systems are still far from this goal. However, in recent\nyears generic and powerful recurrent neural network architectures have been\ndeveloped to learn discriminative text feature representations. Meanwhile, deep\nconvolutional generative adversarial networks (GANs) have begun to generate\nhighly compelling images of specific categories, such as faces, album covers,\nand room interiors. In this work, we develop a novel deep architecture and GAN\nformulation to effectively bridge these advances in text and image model- ing,\ntranslating visual concepts from characters to pixels. We demonstrate the\ncapability of our model to generate plausible images of birds and flowers from\ndetailed text descriptions.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 23:09:15 GMT"}, {"version": "v2", "created": "Sun, 5 Jun 2016 13:39:27 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Reed", "Scott", ""], ["Akata", "Zeynep", ""], ["Yan", "Xinchen", ""], ["Logeswaran", "Lajanugen", ""], ["Schiele", "Bernt", ""], ["Lee", "Honglak", ""]]}, {"id": "1605.05448", "submitter": "Aish Fenton", "authors": "Aish Fenton", "title": "The Bees Algorithm for the Vehicle Routing Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis we present a new algorithm for the Vehicle Routing Problem\ncalled the Enhanced Bees Algorithm. It is adapted from a fairly recent\nalgorithm, the Bees Algorithm, which was developed for continuous optimisation\nproblems. We show that the results obtained by the Enhanced Bees Algorithm are\ncompetitive with the best meta-heuristics available for the Vehicle Routing\nProblem (within 0.5% of the optimal solution for common benchmark problems). We\nshow that the algorithm has good runtime performance, producing results within\n2% of the optimal solution within 60 seconds, making it suitable for use within\nreal world dispatch scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 05:53:44 GMT"}], "update_date": "2016-05-19", "authors_parsed": [["Fenton", "Aish", ""]]}, {"id": "1605.05509", "submitter": "Simone Scardapane", "authors": "Simone Scardapane, Michele Scarpiniti, Danilo Comminiello, Aurelio\n  Uncini", "title": "Learning activation functions from data using cubic spline interpolation", "comments": "Submitted to the 27th Italian Workshop on Neural Networks (WIRN 2017)", "journal-ref": "Neural Advances in Processing Nonlinear Dynamic Signals, 2017", "doi": "10.1007/978-3-319-95098-3_7", "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks require a careful design in order to perform properly on a\ngiven task. In particular, selecting a good activation function (possibly in a\ndata-dependent fashion) is a crucial step, which remains an open problem in the\nresearch community. Despite a large amount of investigations, most current\nimplementations simply select one fixed function from a small set of\ncandidates, which is not adapted during training, and is shared among all\nneurons throughout the different layers. However, neither two of these\nassumptions can be supposed optimal in practice. In this paper, we present a\nprincipled way to have data-dependent adaptation of the activation functions,\nwhich is performed independently for each neuron. This is achieved by\nleveraging over past and present advances on cubic spline interpolation,\nallowing for local adaptation of the functions around their regions of use. The\nresulting algorithm is relatively cheap to implement, and overfitting is\ncounterbalanced by the inclusion of a novel damping criterion, which penalizes\nunwanted oscillations from a predefined shape. Experimental results validate\nthe proposal over two well-known benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 10:46:01 GMT"}, {"version": "v2", "created": "Thu, 11 May 2017 07:28:06 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Scardapane", "Simone", ""], ["Scarpiniti", "Michele", ""], ["Comminiello", "Danilo", ""], ["Uncini", "Aurelio", ""]]}, {"id": "1605.05782", "submitter": "Andrew Connor", "authors": "Andy M. Connor and Kristina Shea", "title": "A comparison of semi-deterministic and stochastic search techniques", "comments": "In I.C. Parmee [Ed.] Evolutionary Design & Manufacture (Selected\n  Papers from ACDM'00), pp 287-298. Springer-Verlag: London (2000)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an investigation of two search techniques, tabu search\n(TS) and simulated annealing (SA), to assess their relative merits when applied\nto engineering design optimisation. Design optimisation problems are generally\ncharacterised as having multi-modal search spaces and discontinuities making\nglobal optimisation techniques beneficial. Both techniques claim to be capable\nof locating globally optimum solutions on a range of problems but this\ncapability is derived from different underlying philosophies. While tabu search\nuses a semi-deterministic approach to escape local optima, simulated annealing\nuses a complete stochastic approach. The performance of each technique is\ninvestigated using a structural optimisation problem. These performances are\nthen compared to each other as and to a steepest descent (SD) method.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 23:06:23 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Connor", "Andy M.", ""], ["Shea", "Kristina", ""]]}, {"id": "1605.05815", "submitter": "Abdul Kayom Md Khairuzzaman", "authors": "Abdul kayom Md Khairuzzaman", "title": "Bacterial foraging optimization based brain magnetic resonance image\n  segmentation", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Segmentation partitions an image into its constituent parts. It is\nessentially the pre-processing stage of image analysis and computer vision. In\nthis work, T1 and T2 weighted brain magnetic resonance images are segmented\nusing multilevel thresholding and bacterial foraging optimization (BFO)\nalgorithm. The thresholds are obtained by maximizing the between class variance\n(multilevel Otsu method) of the image. The BFO algorithm is used to optimize\nthe threshold searching process. The edges are then obtained from the\nthresholded image by comparing the intensity of each pixel with its eight\nconnected neighbourhood. Post processing is performed to remove spurious\nresponses in the segmented image. The proposed segmentation technique is\nevaluated using edge detector evaluation parameters such as figure of merit,\nRand Index and variation of information. The proposed brain MR image\nsegmentation technique outperforms the traditional edge detectors such as canny\nand sobel.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 05:39:13 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Khairuzzaman", "Abdul kayom Md", ""]]}, {"id": "1605.06047", "submitter": "Gerasimos Spanakis", "authors": "Gerasimos Spanakis, Gerhard Weiss", "title": "AMSOM: Adaptive Moving Self-organizing Map for Clustering and\n  Visualization", "comments": "ICAART 2016 accepted full paper", "journal-ref": null, "doi": "10.5220/0005704801290140", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-Organizing Map (SOM) is a neural network model which is used to obtain a\ntopology-preserving mapping from the (usually high dimensional) input/feature\nspace to an output/map space of fewer dimensions (usually two or three in order\nto facilitate visualization). Neurons in the output space are connected with\neach other but this structure remains fixed throughout training and learning is\nachieved through the updating of neuron reference vectors in feature space.\nDespite the fact that growing variants of SOM overcome the fixed structure\nlimitation they increase computational cost and also do not allow the removal\nof a neuron after its introduction. In this paper, a variant of SOM is proposed\ncalled AMSOM (Adaptive Moving Self-Organizing Map) that on the one hand creates\na more flexible structure where neuron positions are dynamically altered during\ntraining and on the other hand tackles the drawback of having a predefined grid\nby allowing neuron addition and/or removal during training. Experiments using\nmultiple literature datasets show that the proposed method improves training\nperformance of SOM, leads to a better visualization of the input dataset and\nprovides a framework for determining the optimal number and structure of\nneurons.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 16:41:00 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Spanakis", "Gerasimos", ""], ["Weiss", "Gerhard", ""]]}, {"id": "1605.06069", "submitter": "Iulian Vlad Serban", "authors": "Iulian Vlad Serban, Alessandro Sordoni, Ryan Lowe, Laurent Charlin,\n  Joelle Pineau, Aaron Courville, Yoshua Bengio", "title": "A Hierarchical Latent Variable Encoder-Decoder Model for Generating\n  Dialogues", "comments": "15 pages, 5 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential data often possesses a hierarchical structure with complex\ndependencies between subsequences, such as found between the utterances in a\ndialogue. In an effort to model this kind of generative process, we propose a\nneural network-based generative architecture, with latent stochastic variables\nthat span a variable number of time steps. We apply the proposed model to the\ntask of dialogue response generation and compare it with recent neural network\narchitectures. We evaluate the model performance through automatic evaluation\nmetrics and by carrying out a human evaluation. The experiments demonstrate\nthat our model improves upon recently proposed models and that the latent\nvariables facilitate the generation of long outputs and maintain the context.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 17:59:02 GMT"}, {"version": "v2", "created": "Fri, 20 May 2016 16:02:30 GMT"}, {"version": "v3", "created": "Tue, 14 Jun 2016 02:21:04 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Serban", "Iulian Vlad", ""], ["Sordoni", "Alessandro", ""], ["Lowe", "Ryan", ""], ["Charlin", "Laurent", ""], ["Pineau", "Joelle", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1605.06402", "submitter": "Philipp Gysel", "authors": "Philipp Gysel", "title": "Ristretto: Hardware-Oriented Approximation of Convolutional Neural\n  Networks", "comments": "Master's Thesis, University of California, Davis; 73 pages and 29\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNN) have achieved major breakthroughs in\nrecent years. Their performance in computer vision have matched and in some\nareas even surpassed human capabilities. Deep neural networks can capture\ncomplex non-linear features; however this ability comes at the cost of high\ncomputational and memory requirements. State-of-art networks require billions\nof arithmetic operations and millions of parameters. To enable embedded devices\nsuch as smartphones, Google glasses and monitoring cameras with the astonishing\npower of deep learning, dedicated hardware accelerators can be used to decrease\nboth execution time and power consumption. In applications where fast\nconnection to the cloud is not guaranteed or where privacy is important,\ncomputation needs to be done locally. Many hardware accelerators for deep\nneural networks have been proposed recently. A first important step of\naccelerator design is hardware-oriented approximation of deep networks, which\nenables energy-efficient inference. We present Ristretto, a fast and automated\nframework for CNN approximation. Ristretto simulates the hardware arithmetic of\na custom hardware accelerator. The framework reduces the bit-width of network\nparameters and outputs of resource-intense layers, which reduces the chip area\nfor multiplication units significantly. Alternatively, Ristretto can remove the\nneed for multipliers altogether, resulting in an adder-only arithmetic. The\ntool fine-tunes trimmed networks to achieve high classification accuracy. Since\ntraining of deep neural networks can be time-consuming, Ristretto uses highly\noptimized routines which run on the GPU. This enables fast compression of any\ngiven network. Given a maximum tolerance of 1%, Ristretto can successfully\ncondense CaffeNet and SqueezeNet to 8-bit. The code for Ristretto is available.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 15:22:29 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Gysel", "Philipp", ""]]}, {"id": "1605.06431", "submitter": "Andreas Veit", "authors": "Andreas Veit, Michael Wilber, Serge Belongie", "title": "Residual Networks Behave Like Ensembles of Relatively Shallow Networks", "comments": "NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a novel interpretation of residual networks showing\nthat they can be seen as a collection of many paths of differing length.\nMoreover, residual networks seem to enable very deep networks by leveraging\nonly the short paths during training. To support this observation, we rewrite\nresidual networks as an explicit collection of paths. Unlike traditional\nmodels, paths through residual networks vary in length. Further, a lesion study\nreveals that these paths show ensemble-like behavior in the sense that they do\nnot strongly depend on each other. Finally, and most surprising, most paths are\nshorter than one might expect, and only the short paths are needed during\ntraining, as longer paths do not contribute any gradient. For example, most of\nthe gradient in a residual network with 110 layers comes from paths that are\nonly 10-34 layers deep. Our results reveal one of the key characteristics that\nseem to enable the training of very deep networks: Residual networks avoid the\nvanishing gradient problem by introducing short paths which can carry gradient\nthroughout the extent of very deep networks.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 16:44:03 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 00:43:58 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Veit", "Andreas", ""], ["Wilber", "Michael", ""], ["Belongie", "Serge", ""]]}, {"id": "1605.06457", "submitter": "Adrien Gaidon", "authors": "Adrien Gaidon, Qiao Wang, Yohann Cabon, Eleonora Vig", "title": "Virtual Worlds as Proxy for Multi-Object Tracking Analysis", "comments": "CVPR 2016, Virtual KITTI dataset download at\n  http://www.xrce.xerox.com/Research-Development/Computer-Vision/Proxy-Virtual-Worlds", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern computer vision algorithms typically require expensive data\nacquisition and accurate manual labeling. In this work, we instead leverage the\nrecent progress in computer graphics to generate fully labeled, dynamic, and\nphoto-realistic proxy virtual worlds. We propose an efficient real-to-virtual\nworld cloning method, and validate our approach by building and publicly\nreleasing a new video dataset, called Virtual KITTI (see\nhttp://www.xrce.xerox.com/Research-Development/Computer-Vision/Proxy-Virtual-Worlds),\nautomatically labeled with accurate ground truth for object detection,\ntracking, scene and instance segmentation, depth, and optical flow. We provide\nquantitative experimental evidence suggesting that (i) modern deep learning\nalgorithms pre-trained on real data behave similarly in real and virtual\nworlds, and (ii) pre-training on virtual data improves performance. As the gap\nbetween real and virtual worlds is small, virtual worlds enable measuring the\nimpact of various weather and imaging conditions on recognition performance,\nall other things being equal. We show these factors may affect drastically\notherwise high-performing deep models for tracking.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 18:03:07 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Gaidon", "Adrien", ""], ["Wang", "Qiao", ""], ["Cabon", "Yohann", ""], ["Vig", "Eleonora", ""]]}, {"id": "1605.06465", "submitter": "Saurabh Singh", "authors": "Saurabh Singh, Derek Hoiem and David Forsyth", "title": "Swapout: Learning an ensemble of deep architectures", "comments": "Submitted to NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe Swapout, a new stochastic training method, that outperforms\nResNets of identical network structure yielding impressive results on CIFAR-10\nand CIFAR-100. Swapout samples from a rich set of architectures including\ndropout, stochastic depth and residual architectures as special cases. When\nviewed as a regularization method swapout not only inhibits co-adaptation of\nunits in a layer, similar to dropout, but also across network layers. We\nconjecture that swapout achieves strong regularization by implicitly tying the\nparameters across layers. When viewed as an ensemble training method, it\nsamples a much richer set of architectures than existing methods such as\ndropout or stochastic depth. We propose a parameterization that reveals\nconnections to exiting architectures and suggests a much richer set of\narchitectures to be explored. We show that our formulation suggests an\nefficient training method and validate our conclusions on CIFAR-10 and\nCIFAR-100 matching state of the art accuracy. Remarkably, our 32 layer wider\nmodel performs similar to a 1001 layer ResNet model.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 18:39:33 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Singh", "Saurabh", ""], ["Hoiem", "Derek", ""], ["Forsyth", "David", ""]]}, {"id": "1605.06489", "submitter": "Yani Ioannou", "authors": "Yani Ioannou, Duncan Robertson, Roberto Cipolla, Antonio Criminisi", "title": "Deep Roots: Improving CNN Efficiency with Hierarchical Filter Groups", "comments": "Updated full version of paper, in full letter paper two-column paper.\n  Includes many textual changes, updated CIFAR10 results, and new analysis of\n  inter/intra-layer correlation", "journal-ref": null, "doi": "10.1109/CVPR.2017.633", "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for creating computationally efficient and compact\nconvolutional neural networks (CNNs) using a novel sparse connection structure\nthat resembles a tree root. This allows a significant reduction in\ncomputational cost and number of parameters compared to state-of-the-art deep\nCNNs, without compromising accuracy, by exploiting the sparsity of inter-layer\nfilter dependencies. We validate our approach by using it to train more\nefficient variants of state-of-the-art CNN architectures, evaluated on the\nCIFAR10 and ILSVRC datasets. Our results show similar or higher accuracy than\nthe baseline architectures with much less computation, as measured by CPU and\nGPU timings. For example, for ResNet 50, our model has 40% fewer parameters,\n45% fewer floating point operations, and is 31% (12%) faster on a CPU (GPU).\nFor the deeper ResNet 200 our model has 25% fewer floating point operations and\n44% fewer parameters, while maintaining state-of-the-art accuracy. For\nGoogLeNet, our model has 7% fewer parameters and is 21% (16%) faster on a CPU\n(GPU).\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 19:51:37 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 17:29:01 GMT"}, {"version": "v3", "created": "Wed, 30 Nov 2016 15:32:03 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Ioannou", "Yani", ""], ["Robertson", "Duncan", ""], ["Cipolla", "Roberto", ""], ["Criminisi", "Antonio", ""]]}, {"id": "1605.06560", "submitter": "Lei Shi", "authors": "Lei Shi and Shikun Feng and Zhifan Zhu", "title": "Functional Hashing for Compressing Neural Networks", "comments": "submitted to NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the complexity of deep neural networks (DNNs) trend to grow to absorb the\nincreasing sizes of data, memory and energy consumption has been receiving more\nand more attentions for industrial applications, especially on mobile devices.\nThis paper presents a novel structure based on functional hashing to compress\nDNNs, namely FunHashNN. For each entry in a deep net, FunHashNN uses multiple\nlow-cost hash functions to fetch values in the compression space, and then\nemploys a small reconstruction network to recover that entry. The\nreconstruction network is plugged into the whole network and trained jointly.\nFunHashNN includes the recently proposed HashedNets as a degenerated case, and\nbenefits from larger value capacity and less reconstruction loss. We further\ndiscuss extensions with dual space hashing and multi-hops. On several benchmark\ndatasets, FunHashNN demonstrates high compression ratios with little loss on\nprediction accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 23:44:19 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Shi", "Lei", ""], ["Feng", "Shikun", ""], ["Zhu", "Zhifan", ""]]}, {"id": "1605.06640", "submitter": "Matko Bo\\v{s}njak", "authors": "Matko Bo\\v{s}njak, Tim Rockt\\\"aschel, Jason Naradowsky, Sebastian\n  Riedel", "title": "Programming with a Differentiable Forth Interpreter", "comments": "34th International Conference on Machine Learning (ICML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given that in practice training data is scarce for all but a small set of\nproblems, a core question is how to incorporate prior knowledge into a model.\nIn this paper, we consider the case of prior procedural knowledge for neural\nnetworks, such as knowing how a program should traverse a sequence, but not\nwhat local actions should be performed at each step. To this end, we present an\nend-to-end differentiable interpreter for the programming language Forth which\nenables programmers to write program sketches with slots that can be filled\nwith behaviour trained from program input-output data. We can optimise this\nbehaviour directly through gradient descent techniques on user-specified\nobjectives, and also integrate the program into any larger neural computation\ngraph. We show empirically that our interpreter is able to effectively leverage\ndifferent levels of prior program structure and learn complex behaviours such\nas sequence sorting and addition. When connected to outputs of an LSTM and\ntrained jointly, our interpreter achieves state-of-the-art accuracy for\nend-to-end reasoning about quantities expressed in natural language stories.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 13:24:14 GMT"}, {"version": "v2", "created": "Sat, 5 Nov 2016 19:15:44 GMT"}, {"version": "v3", "created": "Sun, 23 Jul 2017 09:20:48 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Bo\u0161njak", "Matko", ""], ["Rockt\u00e4schel", "Tim", ""], ["Naradowsky", "Jason", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1605.06710", "submitter": "Agostinho Rosa", "authors": "Nuno Ramos, Sergio Salgado and Agostinho C Rosa", "title": "Chess Player by Co-Evolutionary Algorithm", "comments": "8 pages, 11 figures and 12 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A co-evolutionary algorithm (CA) based chess player is presented.\nImplementation details of the algorithms, namely coding, population, variation\noperators are described. The alpha-beta or mini-max like behaviour of the\nplayer is achieved through two competitive or cooperative populations. Special\nattention is given to the fitness function evaluation (the heart of the\nsolution). Test results on algorithms vs. algorithms or human player is\nprovided.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 23:45:38 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Ramos", "Nuno", ""], ["Salgado", "Sergio", ""], ["Rosa", "Agostinho C", ""]]}, {"id": "1605.06714", "submitter": "Agostinho Rosa", "authors": "Marco AR Erra, Pedro MM Mitra, Agostinho C Rosa", "title": "Evolutionary Demographic Algorithms", "comments": "4 pages and 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the problems in genetic algorithms are very complex and demand a\nlarge amount of resources that current technology can not offer. Our purpose\nwas to develop a Java-JINI distributed library that implements Genetic\nAlgorithms with sub-populations (coarse grain) and a graphical interface in\norder to configure and follow the evolution of the search. The sub-populations\nare simulated/evaluated in personal computers connected trough a network,\nkeeping in mind different models of sub-populations, migration policies and\nnetwork topologies. We show that this model delays the convergence of the\npopulation keeping a higher level of genetic diversity and allows a much\ngreater number of evaluations since they are distributed among several\ncomputers compared with the traditional Genetic Algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 00:09:04 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Erra", "Marco AR", ""], ["Mitra", "Pedro MM", ""], ["Rosa", "Agostinho C", ""]]}, {"id": "1605.06722", "submitter": "Yi Wang", "authors": "Peng Guo, Wenming Cheng, Yi Wang", "title": "Hybrid evolutionary algorithm with extreme machine learning fitness\n  function evaluation for two-stage capacitated facility location problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the two-stage capacitated facility location problem\n(TSCFLP) in which products manufactured in plants are delivered to customers\nvia storage depots. Customer demands are satisfied subject to limited plant\nproduction and limited depot storage capacity. The objective is to determine\nthe locations of plants and depots in order to minimize the total cost\nincluding the fixed cost and transportation cost. A hybrid evolutionary\nalgorithm (HEA) with genetic operations and local search is proposed. To avoid\nthe expensive calculation of fitness of population in terms of computational\ntime, the HEA uses extreme machine learning to approximate the fitness of most\nof the individuals. Moreover, two heuristics based on the characteristic of the\nproblem is incorporated to generate a good initial population.\n  Computational experiments are performed on two sets of test instances from\nthe recent literature. The performance of the proposed algorithm is evaluated\nand analyzed. Compared with the state-of-the-art genetic algorithm, the\nproposed algorithm can find the optimal or near-optimal solutions in a\nreasonable computational time.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 01:09:41 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Guo", "Peng", ""], ["Cheng", "Wenming", ""], ["Wang", "Yi", ""]]}, {"id": "1605.06743", "submitter": "Nadav Cohen", "authors": "Nadav Cohen and Amnon Shashua", "title": "Inductive Bias of Deep Convolutional Networks through Pooling Geometry", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our formal understanding of the inductive bias that drives the success of\nconvolutional networks on computer vision tasks is limited. In particular, it\nis unclear what makes hypotheses spaces born from convolution and pooling\noperations so suitable for natural images. In this paper we study the ability\nof convolutional networks to model correlations among regions of their input.\nWe theoretically analyze convolutional arithmetic circuits, and empirically\nvalidate our findings on other types of convolutional networks as well.\nCorrelations are formalized through the notion of separation rank, which for a\ngiven partition of the input, measures how far a function is from being\nseparable. We show that a polynomially sized deep network supports\nexponentially high separation ranks for certain input partitions, while being\nlimited to polynomial separation ranks for others. The network's pooling\ngeometry effectively determines which input partitions are favored, thus serves\nas a means for controlling the inductive bias. Contiguous pooling windows as\ncommonly employed in practice favor interleaved partitions over coarse ones,\norienting the inductive bias towards the statistics of natural images. Other\npooling schemes lead to different preferences, and this allows tailoring the\nnetwork to data that departs from the usual domain of natural imagery. In\naddition to analyzing deep networks, we show that shallow ones support only\nlinear separation ranks, and by this gain insight into the benefit of functions\nbrought forth by depth - they are able to efficiently model strong correlation\nunder favored partitions of the input.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 06:15:31 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2016 16:06:20 GMT"}, {"version": "v3", "created": "Wed, 14 Dec 2016 10:29:18 GMT"}, {"version": "v4", "created": "Mon, 17 Apr 2017 18:36:08 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Cohen", "Nadav", ""], ["Shashua", "Amnon", ""]]}, {"id": "1605.06894", "submitter": "Chao Wang", "authors": "Chao Wang, Qi Yu, Lei Gong, Xi Li, Yuan Xie, Xuehai Zhou", "title": "DLAU: A Scalable Deep Learning Accelerator Unit on FPGA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the emerging field of machine learning, deep learning shows excellent\nability in solving complex learning problems. However, the size of the networks\nbecomes increasingly large scale due to the demands of the practical\napplications, which poses significant challenge to construct a high performance\nimplementations of deep learning neural networks. In order to improve the\nperformance as well to maintain the low power cost, in this paper we design\nDLAU, which is a scalable accelerator architecture for large-scale deep\nlearning networks using FPGA as the hardware prototype. The DLAU accelerator\nemploys three pipelined processing units to improve the throughput and utilizes\ntile techniques to explore locality for deep learning applications.\nExperimental results on the state-of-the-art Xilinx FPGA board demonstrate that\nthe DLAU accelerator is able to achieve up to 36.1x speedup comparing to the\nIntel Core2 processors, with the power consumption at 234mW.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 04:56:04 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Wang", "Chao", ""], ["Yu", "Qi", ""], ["Gong", "Lei", ""], ["Li", "Xi", ""], ["Xie", "Yuan", ""], ["Zhou", "Xuehai", ""]]}, {"id": "1605.06921", "submitter": "Luka Crnkovic-Friis", "authors": "Luka Crnkovic-Friis, Louise Crnkovic-Friis", "title": "Generative Choreography using Deep Learning", "comments": "This article will be presented at the 7th International Conference on\n  Computational Creativity, ICCC2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning have enabled the extraction of high-level\nfeatures from raw sensor data which has opened up new possibilities in many\ndifferent fields, including computer generated choreography. In this paper we\npresent a system chor-rnn for generating novel choreographic material in the\nnuanced choreographic language and style of an individual choreographer. It\nalso shows promising results in producing a higher level compositional\ncohesion, rather than just generating sequences of movement. At the core of\nchor-rnn is a deep recurrent neural network trained on raw motion capture data\nand that can generate new dance sequences for a solo dancer. Chor-rnn can be\nused for collaborative human-machine choreography or as a creative catalyst,\nserving as inspiration for a choreographer.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 07:36:49 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Crnkovic-Friis", "Luka", ""], ["Crnkovic-Friis", "Louise", ""]]}, {"id": "1605.07009", "submitter": "Abdullah Al-Dujaili", "authors": "Abdullah Al-Dujaili and S. Suresh", "title": "BMOBench: Black-Box Multi-Objective Optimization Benchmarking Platform", "comments": "supplement materials for Multi-Objective Simultaneous Optimistic\n  Optimization (Information Sciences)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document briefly describes the Black-Box Multi-Objective Optimization\nBenchmarking (BMOBench) platform. It presents the test problems, evaluation\nprocedure, and experimental setup. To this end, the BMOBench is demonstrated by\ncomparing recent multi-objective solvers from the literature, namely SMS-EMOA,\nDMS, and MO-SOO.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 13:31:59 GMT"}, {"version": "v2", "created": "Sat, 1 Jul 2017 16:45:35 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Al-Dujaili", "Abdullah", ""], ["Suresh", "S.", ""]]}, {"id": "1605.07145", "submitter": "Devansh Arpit", "authors": "Devansh Arpit, Yingbo Zhou, Hung Q. Ngo, Nils Napp, Venu Govindaraju", "title": "On Optimality Conditions for Auto-Encoder Signal Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto-Encoders are unsupervised models that aim to learn patterns from\nobserved data by minimizing a reconstruction cost. The useful representations\nlearned are often found to be sparse and distributed. On the other hand,\ncompressed sensing and sparse coding assume a data generating process, where\nthe observed data is generated from some true latent signal source, and try to\nrecover the corresponding signal from measurements. Looking at auto-encoders\nfrom this \\textit{signal recovery perspective} enables us to have a more\ncoherent view of these techniques. In this paper, in particular, we show that\nthe \\textit{true} hidden representation can be approximately recovered if the\nweight matrices are highly incoherent with unit $ \\ell^{2} $ row length and the\nbias vectors takes the value (approximately) equal to the negative of the data\nmean. The recovery also becomes more and more accurate as the sparsity in\nhidden signals increases. Additionally, we empirically demonstrate that\nauto-encoders are capable of recovering the data generating dictionary when\nonly data samples are given.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:21:53 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 16:25:15 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Arpit", "Devansh", ""], ["Zhou", "Yingbo", ""], ["Ngo", "Hung Q.", ""], ["Napp", "Nils", ""], ["Govindaraju", "Venu", ""]]}, {"id": "1605.07146", "submitter": "Sergey Zagoruyko", "authors": "Sergey Zagoruyko, Nikos Komodakis", "title": "Wide Residual Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep residual networks were shown to be able to scale up to thousands of\nlayers and still have improving performance. However, each fraction of a\npercent of improved accuracy costs nearly doubling the number of layers, and so\ntraining very deep residual networks has a problem of diminishing feature\nreuse, which makes these networks very slow to train. To tackle these problems,\nin this paper we conduct a detailed experimental study on the architecture of\nResNet blocks, based on which we propose a novel architecture where we decrease\ndepth and increase width of residual networks. We call the resulting network\nstructures wide residual networks (WRNs) and show that these are far superior\nover their commonly used thin and very deep counterparts. For example, we\ndemonstrate that even a simple 16-layer-deep wide residual network outperforms\nin accuracy and efficiency all previous deep residual networks, including\nthousand-layer-deep networks, achieving new state-of-the-art results on CIFAR,\nSVHN, COCO, and significant improvements on ImageNet. Our code and models are\navailable at https://github.com/szagoruyko/wide-residual-networks\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:27:13 GMT"}, {"version": "v2", "created": "Mon, 28 Nov 2016 19:59:22 GMT"}, {"version": "v3", "created": "Tue, 17 Jan 2017 15:35:14 GMT"}, {"version": "v4", "created": "Wed, 14 Jun 2017 06:06:48 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Zagoruyko", "Sergey", ""], ["Komodakis", "Nikos", ""]]}, {"id": "1605.07154", "submitter": "Behnam Neyshabur", "authors": "Behnam Neyshabur, Yuhuai Wu, Ruslan Salakhutdinov, Nathan Srebro", "title": "Path-Normalized Optimization of Recurrent Neural Networks with ReLU\n  Activations", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the parameter-space geometry of recurrent neural networks\n(RNNs), and develop an adaptation of path-SGD optimization method, attuned to\nthis geometry, that can learn plain RNNs with ReLU activations. On several\ndatasets that require capturing long-term dependency structure, we show that\npath-SGD can significantly improve trainability of ReLU RNNs compared to RNNs\ntrained with SGD, even with various recently suggested initialization schemes.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:40:50 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Neyshabur", "Behnam", ""], ["Wu", "Yuhuai", ""], ["Salakhutdinov", "Ruslan", ""], ["Srebro", "Nathan", ""]]}, {"id": "1605.07156", "submitter": "Sasha Targ", "authors": "Laura Deming, Sasha Targ, Nate Sauder, Diogo Almeida, Chun Jimmie Ye", "title": "Genetic Architect: Discovering Genomic Structure with Learned Neural\n  Architectures", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Each human genome is a 3 billion base pair set of encoding instructions.\nDecoding the genome using deep learning fundamentally differs from most tasks,\nas we do not know the full structure of the data and therefore cannot design\narchitectures to suit it. As such, architectures that fit the structure of\ngenomics should be learned not prescribed. Here, we develop a novel search\nalgorithm, applicable across domains, that discovers an optimal architecture\nwhich simultaneously learns general genomic patterns and identifies the most\nimportant sequence motifs in predicting functional genomic outcomes. The\narchitectures we find using this algorithm succeed at using only RNA expression\ndata to predict gene regulatory structure, learn human-interpretable\nvisualizations of key sequence motifs, and surpass state-of-the-art results on\nbenchmark genomics challenges.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:43:08 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Deming", "Laura", ""], ["Targ", "Sasha", ""], ["Sauder", "Nate", ""], ["Almeida", "Diogo", ""], ["Ye", "Chun Jimmie", ""]]}, {"id": "1605.07262", "submitter": "Osbert Bastani", "authors": "Osbert Bastani, Yani Ioannou, Leonidas Lampropoulos, Dimitrios\n  Vytiniotis, Aditya Nori, Antonio Criminisi", "title": "Measuring Neural Net Robustness with Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite having high accuracy, neural nets have been shown to be susceptible\nto adversarial examples, where a small perturbation to an input can cause it to\nbecome mislabeled. We propose metrics for measuring the robustness of a neural\nnet and devise a novel algorithm for approximating these metrics based on an\nencoding of robustness as a linear program. We show how our metrics can be used\nto evaluate the robustness of deep neural nets with experiments on the MNIST\nand CIFAR-10 datasets. Our algorithm generates more informative estimates of\nrobustness metrics compared to estimates based on existing algorithms.\nFurthermore, we show how existing approaches to improving robustness \"overfit\"\nto adversarial examples generated using a specific algorithm. Finally, we show\nthat our techniques can be used to additionally improve neural net robustness\nboth according to the metrics that we propose, but also according to previously\nproposed metrics.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 02:18:21 GMT"}, {"version": "v2", "created": "Fri, 16 Jun 2017 11:58:51 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Bastani", "Osbert", ""], ["Ioannou", "Yani", ""], ["Lampropoulos", "Leonidas", ""], ["Vytiniotis", "Dimitrios", ""], ["Nori", "Aditya", ""], ["Criminisi", "Antonio", ""]]}, {"id": "1605.07427", "submitter": "Sarath Chandar", "authors": "Sarath Chandar, Sungjin Ahn, Hugo Larochelle, Pascal Vincent, Gerald\n  Tesauro, Yoshua Bengio", "title": "Hierarchical Memory Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory networks are neural networks with an explicit memory component that\ncan be both read and written to by the network. The memory is often addressed\nin a soft way using a softmax function, making end-to-end training with\nbackpropagation possible. However, this is not computationally scalable for\napplications which require the network to read from extremely large memories.\nOn the other hand, it is well known that hard attention mechanisms based on\nreinforcement learning are challenging to train successfully. In this paper, we\nexplore a form of hierarchical memory network, which can be considered as a\nhybrid between hard and soft attention memory networks. The memory is organized\nin a hierarchical structure such that reading from it is done with less\ncomputation than soft attention over a flat memory, while also being easier to\ntrain than hard attention over a flat memory. Specifically, we propose to\nincorporate Maximum Inner Product Search (MIPS) in the training and inference\nprocedures for our hierarchical memory network. We explore the use of various\nstate-of-the art approximate MIPS techniques and report results on\nSimpleQuestions, a challenging large scale factoid question answering task.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 12:48:19 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Chandar", "Sarath", ""], ["Ahn", "Sungjin", ""], ["Larochelle", "Hugo", ""], ["Vincent", "Pascal", ""], ["Tesauro", "Gerald", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1605.07740", "submitter": "Antonio Jose Jimeno Yepes", "authors": "Antonio Jimeno Yepes and Jianbin Tang", "title": "Improving energy efficiency and classification accuracy of neuromorphic\n  chips by learning binary synaptic crossbars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNN) have achieved human level performance in many\nimage analytics tasks but DNNs are mostly deployed to GPU platforms that\nconsume a considerable amount of power. Brain-inspired spiking neuromorphic\nchips consume low power and can be highly parallelized. However, for deploying\nDNNs to energy efficient neuromorphic chips the incompatibility between\ncontinuous neurons and synaptic weights of traditional DNNs, discrete spiking\nneurons and synapses of neuromorphic chips has to be overcome. Previous work\nhas achieved this by training a network to learn continuous probabilities and\ndeployment to a neuromorphic architecture by random sampling these\nprobabilities. An ensemble of sampled networks is needed to approximate the\nperformance of the trained network.\n  In the work presented in this paper, we have extended previous research by\ndirectly learning binary synaptic crossbars. Results on MNIST show that better\nperformance can be achieved with a small network in one time step (92.7%\nmaximum observed accuracy vs 95.98% accuracy in our work). Top results on a\nlarger network are similar to previously published results (99.42% maximum\nobserved accuracy vs 99.45% accuracy in our work). More importantly, in our\nwork a smaller ensemble is needed to achieve similar or better accuracy than\nprevious work, which translates into significantly decreased energy consumption\nfor both networks. Results of our work are stable since they do not require\nrandom sampling.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 06:09:42 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Yepes", "Antonio Jimeno", ""], ["Tang", "Jianbin", ""]]}, {"id": "1605.07918", "submitter": "Byungsoo Kim", "authors": "Byungsoo Kim, Hwanjo Yu, Gary Geunbae Lee", "title": "Automatic Open Knowledge Acquisition via Long Short-Term Memory Networks\n  with Feedback Negative Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies in Open Information Extraction (Open IE) are mainly based on\nextraction patterns. They manually define patterns or automatically learn them\nfrom a large corpus. However, these approaches are limited when grasping the\ncontext of a sentence, and they fail to capture implicit relations. In this\npaper, we address this problem with the following methods. First, we exploit\nlong short-term memory (LSTM) networks to extract higher-level features along\nthe shortest dependency paths, connecting headwords of relations and arguments.\nThe path-level features from LSTM networks provide useful clues regarding\ncontextual information and the validity of arguments. Second, we constructed\nsamples to train LSTM networks without the need for manual labeling. In\nparticular, feedback negative sampling picks highly negative samples among\nnon-positive samples through a model trained with positive samples. The\nexperimental results show that our approach produces more precise and abundant\nextractions than state-of-the-art open IE systems. To the best of our\nknowledge, this is the first work to apply deep learning to Open IE.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 14:59:46 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Kim", "Byungsoo", ""], ["Yu", "Hwanjo", ""], ["Lee", "Gary Geunbae", ""]]}, {"id": "1605.08104", "submitter": "William Lotter", "authors": "William Lotter, Gabriel Kreiman, David Cox", "title": "Deep Predictive Coding Networks for Video Prediction and Unsupervised\n  Learning", "comments": "Code and example video clips can be found here:\n  https://coxlab.github.io/prednet/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While great strides have been made in using deep learning algorithms to solve\nsupervised learning tasks, the problem of unsupervised learning - leveraging\nunlabeled examples to learn about the structure of a domain - remains a\ndifficult unsolved challenge. Here, we explore prediction of future frames in a\nvideo sequence as an unsupervised learning rule for learning about the\nstructure of the visual world. We describe a predictive neural network\n(\"PredNet\") architecture that is inspired by the concept of \"predictive coding\"\nfrom the neuroscience literature. These networks learn to predict future frames\nin a video sequence, with each layer in the network making local predictions\nand only forwarding deviations from those predictions to subsequent network\nlayers. We show that these networks are able to robustly learn to predict the\nmovement of synthetic (rendered) objects, and that in doing so, the networks\nlearn internal representations that are useful for decoding latent object\nparameters (e.g. pose) that support object recognition with fewer training\nviews. We also show that these networks can scale to complex natural image\nstreams (car-mounted camera videos), capturing key aspects of both egocentric\nmovement and the movement of objects in the visual scene, and the\nrepresentation learned in this setting is useful for estimating the steering\nangle. Altogether, these results suggest that prediction represents a powerful\nframework for unsupervised learning, allowing for implicit learning of object\nand scene structure.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 23:58:55 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2016 14:36:09 GMT"}, {"version": "v3", "created": "Tue, 30 Aug 2016 00:08:34 GMT"}, {"version": "v4", "created": "Wed, 31 Aug 2016 16:06:03 GMT"}, {"version": "v5", "created": "Wed, 1 Mar 2017 01:00:54 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Lotter", "William", ""], ["Kreiman", "Gabriel", ""], ["Cox", "David", ""]]}, {"id": "1605.08153", "submitter": "Alexander Anderson", "authors": "Alexander G. Anderson, Cory P. Berg, Daniel P. Mossing, Bruno A.\n  Olshausen", "title": "DeepMovie: Using Optical Flow and Deep Neural Networks to Stylize Movies", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent paper by Gatys et al. describes a method for rendering an image in\nthe style of another image. First, they use convolutional neural network\nfeatures to build a statistical model for the style of an image. Then they\ncreate a new image with the content of one image but the style statistics of\nanother image. Here, we extend this method to render a movie in a given\nartistic style. The naive solution that independently renders each frame\nproduces poor results because the features of the style move substantially from\none frame to the next. The other naive method that initializes the optimization\nfor the next frame using the rendered version of the previous frame also\nproduces poor results because the features of the texture stay fixed relative\nto the frame of the movie instead of moving with objects in the scene. The main\ncontribution of this paper is to use optical flow to initialize the style\ntransfer optimization so that the texture features move with the objects in the\nvideo. Finally, we suggest a method to incorporate optical flow explicitly into\nthe cost function.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 05:52:10 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Anderson", "Alexander G.", ""], ["Berg", "Cory P.", ""], ["Mossing", "Daniel P.", ""], ["Olshausen", "Bruno A.", ""]]}, {"id": "1605.08254", "submitter": "Jure Sokolic", "authors": "Jure Sokolic, Raja Giryes, Guillermo Sapiro, Miguel R. D. Rodrigues", "title": "Robust Large Margin Deep Neural Networks", "comments": "accepted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2017.2708039", "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalization error of deep neural networks via their classification\nmargin is studied in this work. Our approach is based on the Jacobian matrix of\na deep neural network and can be applied to networks with arbitrary\nnon-linearities and pooling layers, and to networks with different\narchitectures such as feed forward networks and residual networks. Our analysis\nleads to the conclusion that a bounded spectral norm of the network's Jacobian\nmatrix in the neighbourhood of the training samples is crucial for a deep\nneural network of arbitrary depth and width to generalize well. This is a\nsignificant improvement over the current bounds in the literature, which imply\nthat the generalization error grows with either the width or the depth of the\nnetwork. Moreover, it shows that the recently proposed batch normalization and\nweight normalization re-parametrizations enjoy good generalization properties,\nand leads to a novel network regularizer based on the network's Jacobian\nmatrix. The analysis is supported with experimental results on the MNIST,\nCIFAR-10, LaRED and ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 12:19:09 GMT"}, {"version": "v2", "created": "Mon, 3 Oct 2016 15:54:33 GMT"}, {"version": "v3", "created": "Tue, 23 May 2017 11:45:31 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Sokolic", "Jure", ""], ["Giryes", "Raja", ""], ["Sapiro", "Guillermo", ""], ["Rodrigues", "Miguel R. D.", ""]]}, {"id": "1605.08283", "submitter": "Thomas Wiatowski", "authors": "Thomas Wiatowski and Michael Tschannen and Aleksandar Stani\\'c and\n  Philipp Grohs and Helmut B\\\"olcskei", "title": "Discrete Deep Feature Extraction: A Theory and New Architectures", "comments": "Proc. of International Conference on Machine Learning (ICML), New\n  York, USA, June 2016, to appear", "journal-ref": "Proc. of International Conference on Machine Learning (ICML), New\n  York, USA, pp. 2149-2158, June 2016", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT cs.NE math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First steps towards a mathematical theory of deep convolutional neural\nnetworks for feature extraction were made---for the continuous-time case---in\nMallat, 2012, and Wiatowski and B\\\"olcskei, 2015. This paper considers the\ndiscrete case, introduces new convolutional neural network architectures, and\nproposes a mathematical framework for their analysis. Specifically, we\nestablish deformation and translation sensitivity results of local and global\nnature, and we investigate how certain structural properties of the input\nsignal are reflected in the corresponding feature vectors. Our theory applies\nto general filters and general Lipschitz-continuous non-linearities and pooling\noperators. Experiments on handwritten digit classification and facial landmark\ndetection---including feature importance evaluation---complement the\ntheoretical findings.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 13:55:07 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Wiatowski", "Thomas", ""], ["Tschannen", "Michael", ""], ["Stani\u0107", "Aleksandar", ""], ["Grohs", "Philipp", ""], ["B\u00f6lcskei", "Helmut", ""]]}, {"id": "1605.08361", "submitter": "Daniel Soudry", "authors": "Daniel Soudry, Yair Carmon", "title": "No bad local minima: Data independent training error guarantees for\n  multilayer neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use smoothed analysis techniques to provide guarantees on the training\nloss of Multilayer Neural Networks (MNNs) at differentiable local minima.\nSpecifically, we examine MNNs with piecewise linear activation functions,\nquadratic loss and a single output, under mild over-parametrization. We prove\nthat for a MNN with one hidden layer, the training error is zero at every\ndifferentiable local minimum, for almost every dataset and dropout-like noise\nrealization. We then extend these results to the case of more than one hidden\nlayer. Our theoretical guarantees assume essentially nothing on the training\ndata, and are verified numerically. These results suggest why the highly\nnon-convex loss of such MNNs can be easily optimized using local updates (e.g.,\nstochastic gradient descent), as observed empirically.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 16:51:05 GMT"}, {"version": "v2", "created": "Mon, 30 May 2016 04:33:39 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Soudry", "Daniel", ""], ["Carmon", "Yair", ""]]}, {"id": "1605.08396", "submitter": "Simon Durand", "authors": "S. Durand, J. P. Bello, B. David and G. Richard", "title": "Robust Downbeat Tracking Using an Ensemble of Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel state of the art system for automatic\ndownbeat tracking from music signals. The audio signal is first segmented in\nframes which are synchronized at the tatum level of the music. We then extract\ndifferent kind of features based on harmony, melody, rhythm and bass content to\nfeed convolutional neural networks that are adapted to take advantage of each\nfeature characteristics. This ensemble of neural networks is combined to obtain\none downbeat likelihood per tatum. The downbeat sequence is finally decoded\nwith a flexible and efficient temporal model which takes advantage of the\nmetrical continuity of a song. We then perform an evaluation of our system on a\nlarge base of 9 datasets, compare its performance to 4 other published\nalgorithms and obtain a significant increase of 16.8 percent points compared to\nthe second best system, for altogether a moderate cost in test and training.\nThe influence of each step of the method is studied to show its strengths and\nshortcomings.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 18:27:56 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Durand", "S.", ""], ["Bello", "J. P.", ""], ["David", "B.", ""], ["Richard", "G.", ""]]}, {"id": "1605.08412", "submitter": "Tobias Strau{\\ss}", "authors": "Gundram Leifert and Tobias Strau{\\ss} and Tobias Gr\\\"uning and Roger\n  Labahn", "title": "CITlab ARGUS for historical handwritten documents", "comments": "Description of CITlab's System for the HTRtS 2015 Task : Handwritten\n  Text Recognition on the tranScriptorium Dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe CITlab's recognition system for the HTRtS competition attached to\nthe 13. International Conference on Document Analysis and Recognition, ICDAR\n2015. The task comprises the recognition of historical handwritten documents.\nThe core algorithms of our system are based on multi-dimensional recurrent\nneural networks (MDRNN) and connectionist temporal classification (CTC). The\nsoftware modules behind that as well as the basic utility technologies are\nessentially powered by PLANET's ARGUS framework for intelligent text\nrecognition and image processing.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 19:19:43 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Leifert", "Gundram", ""], ["Strau\u00df", "Tobias", ""], ["Gr\u00fcning", "Tobias", ""], ["Labahn", "Roger", ""]]}, {"id": "1605.08512", "submitter": "Milad Mohammadi", "authors": "Milad Mohammadi, Subhasis Das", "title": "SNN: Stacked Neural Networks", "comments": "8pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been proven that transfer learning provides an easy way to achieve\nstate-of-the-art accuracies on several vision tasks by training a simple\nclassifier on top of features obtained from pre-trained neural networks. The\ngoal of this work is to generate better features for transfer learning from\nmultiple publicly available pre-trained neural networks. To this end, we\npropose a novel architecture called Stacked Neural Networks which leverages the\nfast training time of transfer learning while simultaneously being much more\naccurate. We show that using a stacked NN architecture can result in up to 8%\nimprovements in accuracy over state-of-the-art techniques using only one\npre-trained network for transfer learning. A second aim of this work is to make\nnetwork fine- tuning retain the generalizability of the base network to unseen\ntasks. To this end, we propose a new technique called \"joint fine-tuning\" that\nis able to give accuracies comparable to finetuning the same network\nindividually over two datasets. We also show that a jointly finetuned network\ngeneralizes better to unseen tasks when compared to a network finetuned over a\nsingle task.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 06:02:48 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Mohammadi", "Milad", ""], ["Das", "Subhasis", ""]]}, {"id": "1605.08535", "submitter": "Xiaodong Gu", "authors": "Xiaodong Gu, Hongyu Zhang, Dongmei Zhang, Sunghun Kim", "title": "Deep API Learning", "comments": "The paper is accepted at FSE 2016 (the 24th ACM SIGSOFT International\n  Symposium on the Foundations of Software Engineering)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developers often wonder how to implement a certain functionality (e.g., how\nto parse XML files) using APIs. Obtaining an API usage sequence based on an\nAPI-related natural language query is very helpful in this regard. Given a\nquery, existing approaches utilize information retrieval models to search for\nmatching API sequences. These approaches treat queries and APIs as bag-of-words\n(i.e., keyword matching or word-to-word alignment) and lack a deep\nunderstanding of the semantics of the query.\n  We propose DeepAPI, a deep learning based approach to generate API usage\nsequences for a given natural language query. Instead of a bags-of-words\nassumption, it learns the sequence of words in a query and the sequence of\nassociated APIs. DeepAPI adapts a neural language model named RNN\nEncoder-Decoder. It encodes a word sequence (user query) into a fixed-length\ncontext vector, and generates an API sequence based on the context vector. We\nalso augment the RNN Encoder-Decoder by considering the importance of\nindividual APIs. We empirically evaluate our approach with more than 7 million\nannotated code snippets collected from GitHub. The results show that our\napproach generates largely accurate API sequences and outperforms the related\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 08:27:18 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 09:38:35 GMT"}, {"version": "v3", "created": "Fri, 14 Jul 2017 01:22:18 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Gu", "Xiaodong", ""], ["Zhang", "Hongyu", ""], ["Zhang", "Dongmei", ""], ["Kim", "Sunghun", ""]]}, {"id": "1605.08543", "submitter": "Sam Leroux", "authors": "Sam Leroux, Steven Bohez, Cedric De Boom, Elias De Coninck, Tim\n  Verbelen, Bert Vankeirsbilck, Pieter Simoens, Bart Dhoedt", "title": "Lazy Evaluation of Convolutional Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a technique which avoids the evaluation of certain\nconvolutional filters in a deep neural network. This allows to trade-off the\naccuracy of a deep neural network with the computational and memory\nrequirements. This is especially important on a constrained device unable to\nhold all the weights of the network in memory.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 08:49:21 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Leroux", "Sam", ""], ["Bohez", "Steven", ""], ["De Boom", "Cedric", ""], ["De Coninck", "Elias", ""], ["Verbelen", "Tim", ""], ["Vankeirsbilck", "Bert", ""], ["Simoens", "Pieter", ""], ["Dhoedt", "Bart", ""]]}, {"id": "1605.08803", "submitter": "Laurent Dinh", "authors": "Laurent Dinh, Jascha Sohl-Dickstein, Samy Bengio", "title": "Density estimation using Real NVP", "comments": "10 pages of main content, 3 pages of bibliography, 18 pages of\n  appendix. Accepted at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised learning of probabilistic models is a central yet challenging\nproblem in machine learning. Specifically, designing models with tractable\nlearning, sampling, inference and evaluation is crucial in solving this task.\nWe extend the space of such models using real-valued non-volume preserving\n(real NVP) transformations, a set of powerful invertible and learnable\ntransformations, resulting in an unsupervised learning algorithm with exact\nlog-likelihood computation, exact sampling, exact inference of latent\nvariables, and an interpretable latent space. We demonstrate its ability to\nmodel natural images on four datasets through sampling, log-likelihood\nevaluation and latent variable manipulations.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 21:24:32 GMT"}, {"version": "v2", "created": "Mon, 14 Nov 2016 21:37:10 GMT"}, {"version": "v3", "created": "Mon, 27 Feb 2017 23:21:10 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Dinh", "Laurent", ""], ["Sohl-Dickstein", "Jascha", ""], ["Bengio", "Samy", ""]]}, {"id": "1605.09114", "submitter": "Miguel \\'A. Carreira-Perpi\\~n\\'an", "authors": "Miguel \\'A. Carreira-Perpi\\~n\\'an and Mehdi Alizadeh", "title": "ParMAC: distributed optimisation of nested functions, with application\n  to learning binary autoencoders", "comments": "40 pages, 13 figures. The abstract appearing here is slightly shorter\n  than the one in the PDF file because of the arXiv's limitation of the\n  abstract field to 1920 characters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many powerful machine learning models are based on the composition of\nmultiple processing layers, such as deep nets, which gives rise to nonconvex\nobjective functions. A general, recent approach to optimise such \"nested\"\nfunctions is the method of auxiliary coordinates (MAC). MAC introduces an\nauxiliary coordinate for each data point in order to decouple the nested model\ninto independent submodels. This decomposes the optimisation into steps that\nalternate between training single layers and updating the coordinates. It has\nthe advantage that it reuses existing single-layer algorithms, introduces\nparallelism, and does not need to use chain-rule gradients, so it works with\nnondifferentiable layers. With large-scale problems, or when distributing the\ncomputation is necessary for faster training, the dataset may not fit in a\nsingle machine. It is then essential to limit the amount of communication\nbetween machines so it does not obliterate the benefit of parallelism. We\ndescribe a general way to achieve this, ParMAC. ParMAC works on a cluster of\nprocessing machines with a circular topology and alternates two steps until\nconvergence: one step trains the submodels in parallel using stochastic\nupdates, and the other trains the coordinates in parallel. Only submodel\nparameters, no data or coordinates, are ever communicated between machines.\nParMAC exhibits high parallelism, low communication overhead, and facilitates\ndata shuffling, load balancing, fault tolerance and streaming data processing.\nWe study the convergence of ParMAC and propose a theoretical model of its\nruntime and parallel speedup. We develop ParMAC to learn binary autoencoders\nfor fast, approximate image retrieval. We implement it in MPI in a distributed\nsystem and demonstrate nearly perfect speedups in a 128-processor cluster with\na training set of 100 million high-dimensional points.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 06:31:14 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Carreira-Perpi\u00f1\u00e1n", "Miguel \u00c1.", ""], ["Alizadeh", "Mehdi", ""]]}, {"id": "1605.09186", "submitter": "Ozan \\c{C}a\\u{g}layan", "authors": "Ozan Caglayan, Walid Aransa, Yaxing Wang, Marc Masana, Mercedes\n  Garc\\'ia-Mart\\'inez, Fethi Bougares, Lo\\\"ic Barrault, Joost van de Weijer", "title": "Does Multimodality Help Human and Machine for Translation and Image\n  Captioning?", "comments": "7 pages, 2 figures, v4: Small clarification in section 4 title and\n  content", "journal-ref": null, "doi": "10.18653/v1/W16-2358", "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the systems developed by LIUM and CVC for the WMT16\nMultimodal Machine Translation challenge. We explored various comparative\nmethods, namely phrase-based systems and attentional recurrent neural networks\nmodels trained using monomodal or multimodal data. We also performed a human\nevaluation in order to estimate the usefulness of multimodal data for human\nmachine translation and image description generation. Our systems obtained the\nbest results for both tasks according to the automatic evaluation metrics BLEU\nand METEOR.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 11:47:00 GMT"}, {"version": "v2", "created": "Thu, 2 Jun 2016 13:52:45 GMT"}, {"version": "v3", "created": "Mon, 13 Jun 2016 15:33:11 GMT"}, {"version": "v4", "created": "Tue, 16 Aug 2016 12:11:29 GMT"}], "update_date": "2016-08-17", "authors_parsed": [["Caglayan", "Ozan", ""], ["Aransa", "Walid", ""], ["Wang", "Yaxing", ""], ["Masana", "Marc", ""], ["Garc\u00eda-Mart\u00ednez", "Mercedes", ""], ["Bougares", "Fethi", ""], ["Barrault", "Lo\u00efc", ""], ["van de Weijer", "Joost", ""]]}, {"id": "1605.09232", "submitter": "Raja Giryes", "authors": "Raja Giryes and Yonina C. Eldar and Alex M. Bronstein and Guillermo\n  Sapiro", "title": "Tradeoffs between Convergence Speed and Reconstruction Accuracy in\n  Inverse Problems", "comments": "To appear in IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving inverse problems with iterative algorithms is popular, especially for\nlarge data. Due to time constraints, the number of possible iterations is\nusually limited, potentially affecting the achievable accuracy. Given an error\none is willing to tolerate, an important question is whether it is possible to\nmodify the original iterations to obtain faster convergence to a minimizer\nachieving the allowed error without increasing the computational cost of each\niteration considerably. Relying on recent recovery techniques developed for\nsettings in which the desired signal belongs to some low-dimensional set, we\nshow that using a coarse estimate of this set may lead to faster convergence at\nthe cost of an additional reconstruction error related to the accuracy of the\nset approximation. Our theory ties to recent advances in sparse recovery,\ncompressed sensing, and deep learning. Particularly, it may provide a possible\nexplanation to the successful approximation of the l1-minimization solution by\nneural networks with layers representing iterations, as practiced in the\nlearned iterative shrinkage-thresholding algorithm (LISTA).\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 13:43:59 GMT"}, {"version": "v2", "created": "Thu, 18 May 2017 17:43:20 GMT"}, {"version": "v3", "created": "Thu, 15 Feb 2018 10:53:57 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Giryes", "Raja", ""], ["Eldar", "Yonina C.", ""], ["Bronstein", "Alex M.", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1605.09304", "submitter": "Anh Nguyen", "authors": "Anh Nguyen, Alexey Dosovitskiy, Jason Yosinski, Thomas Brox, Jeff\n  Clune", "title": "Synthesizing the preferred inputs for neurons in neural networks via\n  deep generator networks", "comments": "29 pages, 35 figures, NIPS camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have demonstrated state-of-the-art results on\nmany pattern recognition tasks, especially vision classification problems.\nUnderstanding the inner workings of such computational brains is both\nfascinating basic science that is interesting in its own right - similar to why\nwe study the human brain - and will enable researchers to further improve DNNs.\nOne path to understanding how a neural network functions internally is to study\nwhat each of its neurons has learned to detect. One such method is called\nactivation maximization (AM), which synthesizes an input (e.g. an image) that\nhighly activates a neuron. Here we dramatically improve the qualitative state\nof the art of activation maximization by harnessing a powerful, learned prior:\na deep generator network (DGN). The algorithm (1) generates qualitatively\nstate-of-the-art synthetic images that look almost real, (2) reveals the\nfeatures learned by each neuron in an interpretable way, (3) generalizes well\nto new datasets and somewhat well to different network architectures without\nrequiring the prior to be relearned, and (4) can be considered as a\nhigh-quality generative method (in this case, by generating novel, creative,\ninteresting, recognizable images).\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 16:22:54 GMT"}, {"version": "v2", "created": "Fri, 3 Jun 2016 15:52:04 GMT"}, {"version": "v3", "created": "Mon, 6 Jun 2016 17:34:59 GMT"}, {"version": "v4", "created": "Thu, 27 Oct 2016 22:16:07 GMT"}, {"version": "v5", "created": "Wed, 23 Nov 2016 18:41:12 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Nguyen", "Anh", ""], ["Dosovitskiy", "Alexey", ""], ["Yosinski", "Jason", ""], ["Brox", "Thomas", ""], ["Clune", "Jeff", ""]]}, {"id": "1605.09332", "submitter": "Ludovic Trottier", "authors": "Ludovic Trottier, Philippe Gigu\\`ere, Brahim Chaib-draa", "title": "Parametric Exponential Linear Unit for Deep Convolutional Neural\n  Networks", "comments": "16th IEEE International Conference On Machine Learning And\n  Applications, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object recognition is an important task for improving the ability of visual\nsystems to perform complex scene understanding. Recently, the Exponential\nLinear Unit (ELU) has been proposed as a key component for managing bias shift\nin Convolutional Neural Networks (CNNs), but defines a parameter that must be\nset by hand. In this paper, we propose learning a parameterization of ELU in\norder to learn the proper activation shape at each layer in the CNNs. Our\nresults on the MNIST, CIFAR-10/100 and ImageNet datasets using the NiN,\nOverfeat, All-CNN and ResNet networks indicate that our proposed Parametric ELU\n(PELU) has better performances than the non-parametric ELU. We have observed as\nmuch as a 7.28% relative error improvement on ImageNet with the NiN network,\nwith only 0.0003% parameter increase. Our visual examination of the non-linear\nbehaviors adopted by Vgg using PELU shows that the network took advantage of\nthe added flexibility by learning different activations at different layers.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 17:16:40 GMT"}, {"version": "v2", "created": "Tue, 31 May 2016 19:24:04 GMT"}, {"version": "v3", "created": "Fri, 18 Nov 2016 20:26:25 GMT"}, {"version": "v4", "created": "Wed, 10 Jan 2018 15:18:48 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Trottier", "Ludovic", ""], ["Gigu\u00e8re", "Philippe", ""], ["Chaib-draa", "Brahim", ""]]}, {"id": "1605.09507", "submitter": "Yoonchang Han", "authors": "Yoonchang Han, Jaehun Kim, Kyogu Lee", "title": "Deep convolutional neural networks for predominant instrument\n  recognition in polyphonic music", "comments": "13 pages, 7 figures, accepted for publication in IEEE/ACM\n  Transactions on Audio, Speech, and Language Processing on 16-Nov-2016. This\n  is initial submission version. Fully edited version is available at\n  http://ieeexplore.ieee.org/document/7755799/", "journal-ref": "Published in: IEEE/ACM Transactions on Audio, Speech, and Language\n  Processing ( Volume: 25, Issue: 1, Jan. 2017 ) Page(s): 208 - 221", "doi": "10.1109/TASLP.2016.2632307", "report-no": null, "categories": "cs.SD cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying musical instruments in polyphonic music recordings is a\nchallenging but important problem in the field of music information retrieval.\nIt enables music search by instrument, helps recognize musical genres, or can\nmake music transcription easier and more accurate. In this paper, we present a\nconvolutional neural network framework for predominant instrument recognition\nin real-world polyphonic music. We train our network from fixed-length music\nexcerpts with a single-labeled predominant instrument and estimate an arbitrary\nnumber of predominant instruments from an audio signal with a variable length.\nTo obtain the audio-excerpt-wise result, we aggregate multiple outputs from\nsliding windows over the test audio. In doing so, we investigated two different\naggregation methods: one takes the average for each instrument and the other\ntakes the instrument-wise sum followed by normalization. In addition, we\nconducted extensive experiments on several important factors that affect the\nperformance, including analysis window size, identification threshold, and\nactivation functions for neural networks to find the optimal set of parameters.\nUsing a dataset of 10k audio excerpts from 11 instruments for evaluation, we\nfound that convolutional neural networks are more robust than conventional\nmethods that exploit spectral features and source separation with support\nvector machines. Experimental results showed that the proposed convolutional\nnetwork architecture obtained an F1 measure of 0.602 for micro and 0.503 for\nmacro, respectively, achieving 19.6% and 16.4% in performance improvement\ncompared with other state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 07:11:18 GMT"}, {"version": "v2", "created": "Fri, 18 Nov 2016 08:54:57 GMT"}, {"version": "v3", "created": "Mon, 26 Dec 2016 12:29:26 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Han", "Yoonchang", ""], ["Kim", "Jaehun", ""], ["Lee", "Kyogu", ""]]}, {"id": "1605.09782", "submitter": "Jeff Donahue", "authors": "Jeff Donahue, Philipp Kr\\\"ahenb\\\"uhl, Trevor Darrell", "title": "Adversarial Feature Learning", "comments": "Published as a conference paper at ICLR 2017. Changelog: (v7) Table 2\n  results improved 1-2% due to averaging predictions over 10 crops at test\n  time, as done in Noroozi & Favaro; Table 3 VOC classification results\n  slightly improved due to minor bugfix. (See v6 changelog for previous\n  versions.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of the Generative Adversarial Networks (GANs) framework to learn\ngenerative models mapping from simple latent distributions to arbitrarily\ncomplex data distributions has been demonstrated empirically, with compelling\nresults showing that the latent space of such generators captures semantic\nvariation in the data distribution. Intuitively, models trained to predict\nthese semantic latent representations given data may serve as useful feature\nrepresentations for auxiliary problems where semantics are relevant. However,\nin their existing form, GANs have no means of learning the inverse mapping --\nprojecting data back into the latent space. We propose Bidirectional Generative\nAdversarial Networks (BiGANs) as a means of learning this inverse mapping, and\ndemonstrate that the resulting learned feature representation is useful for\nauxiliary supervised discrimination tasks, competitive with contemporary\napproaches to unsupervised and self-supervised feature learning.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 19:37:29 GMT"}, {"version": "v2", "created": "Fri, 15 Jul 2016 19:52:42 GMT"}, {"version": "v3", "created": "Mon, 18 Jul 2016 03:25:03 GMT"}, {"version": "v4", "created": "Fri, 4 Nov 2016 18:40:47 GMT"}, {"version": "v5", "created": "Fri, 6 Jan 2017 02:49:57 GMT"}, {"version": "v6", "created": "Mon, 9 Jan 2017 05:38:18 GMT"}, {"version": "v7", "created": "Mon, 3 Apr 2017 20:34:36 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Donahue", "Jeff", ""], ["Kr\u00e4henb\u00fchl", "Philipp", ""], ["Darrell", "Trevor", ""]]}]