[{"id": "1703.00096", "submitter": "Zhenyao Zhu", "authors": "Hairong Liu, Zhenyao Zhu, Xiangang Li, Sanjeev Satheesh", "title": "Gram-CTC: Automatic Unit Selection and Target Decomposition for Sequence\n  Labelling", "comments": "Published at ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing sequence labelling models rely on a fixed decomposition of a\ntarget sequence into a sequence of basic units. These methods suffer from two\nmajor drawbacks: 1) the set of basic units is fixed, such as the set of words,\ncharacters or phonemes in speech recognition, and 2) the decomposition of\ntarget sequences is fixed. These drawbacks usually result in sub-optimal\nperformance of modeling sequences. In this pa- per, we extend the popular CTC\nloss criterion to alleviate these limitations, and propose a new loss function\ncalled Gram-CTC. While preserving the advantages of CTC, Gram-CTC automatically\nlearns the best set of basic units (grams), as well as the most suitable\ndecomposition of tar- get sequences. Unlike CTC, Gram-CTC allows the model to\noutput variable number of characters at each time step, which enables the model\nto capture longer term dependency and improves the computational efficiency. We\ndemonstrate that the proposed Gram-CTC improves CTC in terms of both\nperformance and efficiency on the large vocabulary speech recognition task at\nmultiple scales of data, and that with Gram-CTC we can outperform the\nstate-of-the-art on a standard speech benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 00:59:17 GMT"}, {"version": "v2", "created": "Sat, 12 Aug 2017 00:02:26 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Liu", "Hairong", ""], ["Zhu", "Zhenyao", ""], ["Li", "Xiangang", ""], ["Satheesh", "Sanjeev", ""]]}, {"id": "1703.00247", "submitter": "S\\'ebastien Ehrhardt", "authors": "Sebastien Ehrhardt, Aron Monszpart, Niloy J. Mitra and Andrea Vedaldi", "title": "Learning A Physical Long-term Predictor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution has resulted in highly developed abilities in many natural\nintelligences to quickly and accurately predict mechanical phenomena. Humans\nhave successfully developed laws of physics to abstract and model such\nmechanical phenomena. In the context of artificial intelligence, a recent line\nof work has focused on estimating physical parameters based on sensory data and\nuse them in physical simulators to make long-term predictions. In contrast, we\ninvestigate the effectiveness of a single neural network for end-to-end\nlong-term prediction of mechanical phenomena. Based on extensive evaluation, we\ndemonstrate that such networks can outperform alternate approaches having even\naccess to ground-truth physical simulators, especially when some physical\nparameters are unobserved or not known a-priori. Further, our network outputs a\ndistribution of outcomes to capture the inherent uncertainty in the data. Our\napproach demonstrates for the first time the possibility of making actionable\nlong-term predictions from sensor data without requiring to explicitly model\nthe underlying physical laws.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 11:44:18 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Ehrhardt", "Sebastien", ""], ["Monszpart", "Aron", ""], ["Mitra", "Niloy J.", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "1703.00522", "submitter": "Wojciech Czarnecki", "authors": "Wojciech Marian Czarnecki, Grzegorz \\'Swirszcz, Max Jaderberg, Simon\n  Osindero, Oriol Vinyals, Koray Kavukcuoglu", "title": "Understanding Synthetic Gradients and Decoupled Neural Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When training neural networks, the use of Synthetic Gradients (SG) allows\nlayers or modules to be trained without update locking - without waiting for a\ntrue error gradient to be backpropagated - resulting in Decoupled Neural\nInterfaces (DNIs). This unlocked ability of being able to update parts of a\nneural network asynchronously and with only local information was demonstrated\nto work empirically in Jaderberg et al (2016). However, there has been very\nlittle demonstration of what changes DNIs and SGs impose from a functional,\nrepresentational, and learning dynamics point of view. In this paper, we study\nDNIs through the use of synthetic gradients on feed-forward networks to better\nunderstand their behaviour and elucidate their effect on optimisation. We show\nthat the incorporation of SGs does not affect the representational strength of\nthe learning system for a neural network, and prove the convergence of the\nlearning system for linear and deep linear models. On practical problems we\ninvestigate the mechanism by which synthetic gradient estimators approximate\nthe true loss, and, surprisingly, how that leads to drastically different\nlayer-wise representations. Finally, we also expose the relationship of using\nsynthetic gradients to other error approximation techniques and find a unifying\nlanguage for discussion and comparison.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 21:41:09 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Czarnecki", "Wojciech Marian", ""], ["\u015awirszcz", "Grzegorz", ""], ["Jaderberg", "Max", ""], ["Osindero", "Simon", ""], ["Vinyals", "Oriol", ""], ["Kavukcuoglu", "Koray", ""]]}, {"id": "1703.00548", "submitter": "Risto Miikkulainen", "authors": "Risto Miikkulainen, Jason Liang, Elliot Meyerson, Aditya Rawal, Dan\n  Fink, Olivier Francon, Bala Raju, Hormoz Shahrzad, Arshak Navruzyan, Nigel\n  Duffy, Babak Hodjat", "title": "Evolving Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning depends on finding an architecture to fit the\ntask. As deep learning has scaled up to more challenging tasks, the\narchitectures have become difficult to design by hand. This paper proposes an\nautomated method, CoDeepNEAT, for optimizing deep learning architectures\nthrough evolution. By extending existing neuroevolution methods to topology,\ncomponents, and hyperparameters, this method achieves results comparable to\nbest human designs in standard benchmarks in object recognition and language\nmodeling. It also supports building a real-world application of automated image\ncaptioning on a magazine website. Given the anticipated increases in available\ncomputing power, evolution of deep networks is promising approach to\nconstructing deep learning applications in the future.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 23:40:42 GMT"}, {"version": "v2", "created": "Sat, 4 Mar 2017 23:13:05 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Miikkulainen", "Risto", ""], ["Liang", "Jason", ""], ["Meyerson", "Elliot", ""], ["Rawal", "Aditya", ""], ["Fink", "Dan", ""], ["Francon", "Olivier", ""], ["Raju", "Bala", ""], ["Shahrzad", "Hormoz", ""], ["Navruzyan", "Arshak", ""], ["Duffy", "Nigel", ""], ["Hodjat", "Babak", ""]]}, {"id": "1703.00556", "submitter": "Risto Miikkulainen", "authors": "Risto Miikkulainen, Neil Iscoe, Aaron Shagrin, Ron Cordell, Sam\n  Nazari, Cory Schoolland, Myles Brundage, Jonathan Epstein, Randy Dean,\n  Gurmeet Lamba", "title": "Conversion Rate Optimization through Evolutionary Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversion optimization means designing a web interface so that as many users\nas possible take a desired action on it, such as register or purchase. Such\ndesign is usually done by hand, testing one change at a time through A/B\ntesting, or a limited number of combinations through multivariate testing,\nmaking it possible to evaluate only a small fraction of designs in a vast\ndesign space. This paper describes Sentient Ascend, an automatic conversion\noptimization system that uses evolutionary optimization to create effective web\ninterface designs. Ascend makes it possible to discover and utilize\ninteractions between the design elements that are difficult to identify\notherwise. Moreover, evaluation of design candidates is done in parallel\nonline, i.e. with a large number of real users interacting with the system. A\ncase study on an existing media site shows that significant improvements (i.e.\nover 43%) are possible beyond human design. Ascend can therefore be seen as an\napproach to massively multivariate conversion optimization, based on a\nmassively parallel interactive evolution.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 23:54:28 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 21:16:02 GMT"}, {"version": "v3", "created": "Mon, 27 Mar 2017 18:30:16 GMT"}, {"version": "v4", "created": "Sun, 30 Apr 2017 20:51:21 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Miikkulainen", "Risto", ""], ["Iscoe", "Neil", ""], ["Shagrin", "Aaron", ""], ["Cordell", "Ron", ""], ["Nazari", "Sam", ""], ["Schoolland", "Cory", ""], ["Brundage", "Myles", ""], ["Epstein", "Jonathan", ""], ["Dean", "Randy", ""], ["Lamba", "Gurmeet", ""]]}, {"id": "1703.00573", "submitter": "Rong Ge", "authors": "Sanjeev Arora, Rong Ge, Yingyu Liang, Tengyu Ma, Yi Zhang", "title": "Generalization and Equilibrium in Generative Adversarial Nets (GANs)", "comments": "This is an updated version of an ICML'17 paper with the same title.\n  The main difference is that in the ICML'17 version the pure equilibrium\n  result was only proved for Wasserstein GAN. In the current version the result\n  applies to most reasonable training objectives. In particular, Theorem 4.3\n  now applies to both original GAN and Wasserstein GAN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that training of generative adversarial network (GAN) may not have\ngood generalization properties; e.g., training may appear successful but the\ntrained distribution may be far from target distribution in standard metrics.\nHowever, generalization does occur for a weaker metric called neural net\ndistance. It is also shown that an approximate pure equilibrium exists in the\ndiscriminator/generator game for a special class of generators with natural\ntraining objectives when generator capacity and training set sizes are\nmoderate.\n  This existence of equilibrium inspires MIX+GAN protocol, which can be\ncombined with any existing GAN training, and empirically shown to improve some\nof them.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 01:14:03 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 16:19:00 GMT"}, {"version": "v3", "created": "Tue, 4 Apr 2017 00:41:13 GMT"}, {"version": "v4", "created": "Sat, 17 Jun 2017 22:04:07 GMT"}, {"version": "v5", "created": "Tue, 1 Aug 2017 19:51:56 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Arora", "Sanjeev", ""], ["Ge", "Rong", ""], ["Liang", "Yingyu", ""], ["Ma", "Tengyu", ""], ["Zhang", "Yi", ""]]}, {"id": "1703.01041", "submitter": "Esteban Real", "authors": "Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon\n  Suematsu, Jie Tan, Quoc Le, Alex Kurakin", "title": "Large-Scale Evolution of Image Classifiers", "comments": "Accepted for publication at ICML 2017 (34th International Conference\n  on Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have proven effective at solving difficult problems but\ndesigning their architectures can be challenging, even for image classification\nproblems alone. Our goal is to minimize human participation, so we employ\nevolutionary algorithms to discover such networks automatically. Despite\nsignificant computational requirements, we show that it is now possible to\nevolve models with accuracies within the range of those published in the last\nyear. Specifically, we employ simple evolutionary techniques at unprecedented\nscales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting\nfrom trivial initial conditions and reaching accuracies of 94.6% (95.6% for\nensemble) and 77.0%, respectively. To do this, we use novel and intuitive\nmutation operators that navigate large search spaces; we stress that no human\nparticipation is required once evolution starts and that the output is a\nfully-trained model. Throughout this work, we place special emphasis on the\nrepeatability of results, the variability in the outcomes and the computational\nrequirements.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 05:41:30 GMT"}, {"version": "v2", "created": "Sun, 11 Jun 2017 08:42:28 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Real", "Esteban", ""], ["Moore", "Sherry", ""], ["Selle", "Andrew", ""], ["Saxena", "Saurabh", ""], ["Suematsu", "Yutaka Leon", ""], ["Tan", "Jie", ""], ["Le", "Quoc", ""], ["Kurakin", "Alex", ""]]}, {"id": "1703.01101", "submitter": "Volker Fischer", "authors": "Volker Fischer, Mummadi Chaithanya Kumar, Jan Hendrik Metzen, Thomas\n  Brox", "title": "Adversarial Examples for Semantic Image Segmentation", "comments": "ICLR 2017 workshop submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods in general and Deep Neural Networks in particular\nhave shown to be vulnerable to adversarial perturbations. So far this\nphenomenon has mainly been studied in the context of whole-image\nclassification. In this contribution, we analyse how adversarial perturbations\ncan affect the task of semantic segmentation. We show how existing adversarial\nattackers can be transferred to this task and that it is possible to create\nimperceptible adversarial perturbations that lead a deep network to misclassify\nalmost all pixels of a chosen class while leaving network prediction nearly\nunchanged outside this class.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 10:27:16 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Fischer", "Volker", ""], ["Kumar", "Mummadi Chaithanya", ""], ["Metzen", "Jan Hendrik", ""], ["Brox", "Thomas", ""]]}, {"id": "1703.01127", "submitter": "Dario Garcia-Gasulla PhD", "authors": "Dario Garcia-Gasulla, Ferran Par\\'es, Armand Vilalta, Jonatan Moreno,\n  Eduard Ayguad\\'e, Jes\\'us Labarta, Ulises Cort\\'es, Toyotaro Suzumura", "title": "On the Behavior of Convolutional Nets for Feature Extraction", "comments": "Published in the Journal of Artificial Intelligence Research (JAIR),\n  Special Track on Deep Learning, Knowledge Representation, and Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are representation learning techniques. During training,\na deep net is capable of generating a descriptive language of unprecedented\nsize and detail in machine learning. Extracting the descriptive language coded\nwithin a trained CNN model (in the case of image data), and reusing it for\nother purposes is a field of interest, as it provides access to the visual\ndescriptors previously learnt by the CNN after processing millions of images,\nwithout requiring an expensive training phase. Contributions to this field\n(commonly known as feature representation transfer or transfer learning) have\nbeen purely empirical so far, extracting all CNN features from a single layer\nclose to the output and testing their performance by feeding them to a\nclassifier. This approach has provided consistent results, although its\nrelevance is limited to classification tasks. In a completely different\napproach, in this paper we statistically measure the discriminative power of\nevery single feature found within a deep CNN, when used for characterizing\nevery class of 11 datasets. We seek to provide new insights into the behavior\nof CNN features, particularly the ones from convolutional layers, as this can\nbe relevant for their application to knowledge representation and reasoning.\nOur results confirm that low and middle level features may behave differently\nto high level features, but only under certain conditions. We find that all CNN\nfeatures can be used for knowledge representation purposes both by their\npresence or by their absence, doubling the information a single CNN feature may\nprovide. We also study how much noise these features may include, and propose a\nthresholding approach to discard most of it. All these insights have a direct\napplication to the generation of CNN embedding spaces.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 12:23:13 GMT"}, {"version": "v2", "created": "Fri, 10 Mar 2017 14:22:30 GMT"}, {"version": "v3", "created": "Mon, 13 Nov 2017 16:44:14 GMT"}, {"version": "v4", "created": "Mon, 29 Jan 2018 11:56:36 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Garcia-Gasulla", "Dario", ""], ["Par\u00e9s", "Ferran", ""], ["Vilalta", "Armand", ""], ["Moreno", "Jonatan", ""], ["Ayguad\u00e9", "Eduard", ""], ["Labarta", "Jes\u00fas", ""], ["Cort\u00e9s", "Ulises", ""], ["Suzumura", "Toyotaro", ""]]}, {"id": "1703.01780", "submitter": "Antti Tarvainen", "authors": "Antti Tarvainen and Harri Valpola", "title": "Mean teachers are better role models: Weight-averaged consistency\n  targets improve semi-supervised deep learning results", "comments": "In this version: Corrected hyperparameters of the 4000-label CIFAR-10\n  ResNet experiment. Changed Antti's contact info, Advances in Neural\n  Information Processing Systems 30 (NIPS 2017) pre-proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently proposed Temporal Ensembling has achieved state-of-the-art\nresults in several semi-supervised learning benchmarks. It maintains an\nexponential moving average of label predictions on each training example, and\npenalizes predictions that are inconsistent with this target. However, because\nthe targets change only once per epoch, Temporal Ensembling becomes unwieldy\nwhen learning large datasets. To overcome this problem, we propose Mean\nTeacher, a method that averages model weights instead of label predictions. As\nan additional benefit, Mean Teacher improves test accuracy and enables training\nwith fewer labels than Temporal Ensembling. Without changing the network\narchitecture, Mean Teacher achieves an error rate of 4.35% on SVHN with 250\nlabels, outperforming Temporal Ensembling trained with 1000 labels. We also\nshow that a good network architecture is crucial to performance. Combining Mean\nTeacher and Residual Networks, we improve the state of the art on CIFAR-10 with\n4000 labels from 10.55% to 6.28%, and on ImageNet 2012 with 10% of the labels\nfrom 35.24% to 9.11%.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 09:34:56 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 07:41:30 GMT"}, {"version": "v3", "created": "Thu, 30 Nov 2017 11:14:43 GMT"}, {"version": "v4", "created": "Mon, 18 Dec 2017 09:13:01 GMT"}, {"version": "v5", "created": "Mon, 8 Jan 2018 08:10:09 GMT"}, {"version": "v6", "created": "Mon, 16 Apr 2018 10:39:11 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Tarvainen", "Antti", ""], ["Valpola", "Harri", ""]]}, {"id": "1703.01789", "submitter": "Jongpil Lee", "authors": "Jongpil Lee, Jiyoung Park, Keunhyoung Luke Kim, Juhan Nam", "title": "Sample-level Deep Convolutional Neural Networks for Music Auto-tagging\n  Using Raw Waveforms", "comments": "7 pages, Sound and Music Computing Conference (SMC), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the end-to-end approach that learns hierarchical representations\nfrom raw data using deep convolutional neural networks has been successfully\nexplored in the image, text and speech domains. This approach was applied to\nmusical signals as well but has been not fully explored yet. To this end, we\npropose sample-level deep convolutional neural networks which learn\nrepresentations from very small grains of waveforms (e.g. 2 or 3 samples)\nbeyond typical frame-level input representations. Our experiments show how deep\narchitectures with sample-level filters improve the accuracy in music\nauto-tagging and they provide results comparable to previous state-of-the-art\nperformances for the Magnatagatune dataset and Million Song Dataset. In\naddition, we visualize filters learned in a sample-level DCNN in each layer to\nidentify hierarchically learned features and show that they are sensitive to\nlog-scaled frequency along layer, such as mel-frequency spectrogram that is\nwidely used in music classification systems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 09:49:48 GMT"}, {"version": "v2", "created": "Mon, 22 May 2017 04:46:36 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Lee", "Jongpil", ""], ["Park", "Jiyoung", ""], ["Kim", "Keunhyoung Luke", ""], ["Nam", "Juhan", ""]]}, {"id": "1703.01793", "submitter": "Jongpil Lee", "authors": "Jongpil Lee, Juhan Nam", "title": "Multi-Level and Multi-Scale Feature Aggregation Using Pre-trained\n  Convolutional Neural Networks for Music Auto-tagging", "comments": "5 pages, 5 figures, 2 tables", "journal-ref": null, "doi": "10.1109/LSP.2017.2713830", "report-no": null, "categories": "cs.NE cs.LG cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music auto-tagging is often handled in a similar manner to image\nclassification by regarding the 2D audio spectrogram as image data. However,\nmusic auto-tagging is distinguished from image classification in that the tags\nare highly diverse and have different levels of abstractions. Considering this\nissue, we propose a convolutional neural networks (CNN)-based architecture that\nembraces multi-level and multi-scaled features. The architecture is trained in\nthree steps. First, we conduct supervised feature learning to capture local\naudio features using a set of CNNs with different input sizes. Second, we\nextract audio features from each layer of the pre-trained convolutional\nnetworks separately and aggregate them altogether given a long audio clip.\nFinally, we put them into fully-connected networks and make final predictions\nof the tags. Our experiments show that using the combination of multi-level and\nmulti-scale features is highly effective in music auto-tagging and the proposed\nmethod outperforms previous state-of-the-arts on the MagnaTagATune dataset and\nthe Million Song Dataset. We further show that the proposed architecture is\nuseful in transfer learning.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 09:57:25 GMT"}, {"version": "v2", "created": "Wed, 7 Jun 2017 17:21:04 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Lee", "Jongpil", ""], ["Nam", "Juhan", ""]]}, {"id": "1703.01827", "submitter": "Di Xie", "authors": "Di Xie and Jiang Xiong and Shiliang Pu", "title": "All You Need is Beyond a Good Init: Exploring Better Solution for\n  Training Extremely Deep Convolutional Neural Networks with Orthonormality and\n  Modulation", "comments": "Updating experiments; CVPR2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network is difficult to train and this predicament becomes worse\nas the depth increases. The essence of this problem exists in the magnitude of\nbackpropagated errors that will result in gradient vanishing or exploding\nphenomenon. We show that a variant of regularizer which utilizes orthonormality\namong different filter banks can alleviate this problem. Moreover, we design a\nbackward error modulation mechanism based on the quasi-isometry assumption\nbetween two consecutive parametric layers. Equipped with these two ingredients,\nwe propose several novel optimization solutions that can be utilized for\ntraining a specific-structured (repetitively triple modules of Conv-BNReLU)\nextremely deep convolutional neural network (CNN) WITHOUT any shortcuts/\nidentity mappings from scratch. Experiments show that our proposed solutions\ncan achieve distinct improvements for a 44-layer and a 110-layer plain networks\non both the CIFAR-10 and ImageNet datasets. Moreover, we can successfully train\nplain CNNs to match the performance of the residual counterparts.\n  Besides, we propose new principles for designing network structure from the\ninsights evoked by orthonormality. Combined with residual structure, we achieve\ncomparative performance on the ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 11:54:43 GMT"}, {"version": "v2", "created": "Thu, 6 Apr 2017 08:22:09 GMT"}, {"version": "v3", "created": "Mon, 10 Apr 2017 02:12:29 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Xie", "Di", ""], ["Xiong", "Jiang", ""], ["Pu", "Shiliang", ""]]}, {"id": "1703.01887", "submitter": "Rohitash Chandra", "authors": "Rohitash Chandra, Yew-Soon Ong and Chi-Keong Goh", "title": "Co-evolutionary multi-task learning for dynamic time series prediction", "comments": "Applied Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series prediction typically consists of a data reconstruction phase\nwhere the time series is broken into overlapping windows known as the timespan.\nThe size of the timespan can be seen as a way of determining the extent of past\ninformation required for an effective prediction. In certain applications such\nas the prediction of wind-intensity of storms and cyclones, prediction models\nneed to be dynamic in accommodating different values of the timespan. These\napplications require robust prediction as soon as the event takes place. We\nidentify a new category of problem called dynamic time series prediction that\nrequires a model to give prediction when presented with varying lengths of the\ntimespan. In this paper, we propose a co-evolutionary multi-task learning\nmethod that provides a synergy between multi-task learning and co-evolutionary\nalgorithms to address dynamic time series prediction. The method features\neffective use of building blocks of knowledge inspired by dynamic programming\nand multi-task learning. It enables neural networks to retain modularity during\ntraining for making a decision in situations even when certain inputs are\nmissing. The effectiveness of the method is demonstrated using one-step-ahead\nchaotic time series and tropical cyclone wind-intensity prediction.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 02:19:51 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 12:50:01 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Chandra", "Rohitash", ""], ["Ong", "Yew-Soon", ""], ["Goh", "Chi-Keong", ""]]}, {"id": "1703.01909", "submitter": "Sebastian Schmitt", "authors": "Sebastian Schmitt, Johann Klaehn, Guillaume Bellec, Andreas Gruebl,\n  Maurice Guettler, Andreas Hartel, Stephan Hartmann, Dan Husmann, Kai Husmann,\n  Vitali Karasenko, Mitja Kleider, Christoph Koke, Christian Mauch, Eric\n  Mueller, Paul Mueller, Johannes Partzsch, Mihai A. Petrovici, Stefan\n  Schiefer, Stefan Scholze, Bernhard Vogginger, Robert Legenstein, Wolfgang\n  Maass, Christian Mayr, Johannes Schemmel and Karlheinz Meier", "title": "Neuromorphic Hardware In The Loop: Training a Deep Spiking Network on\n  the BrainScaleS Wafer-Scale System", "comments": "8 pages, 10 figures, submitted to IJCNN 2017", "journal-ref": null, "doi": "10.1109/IJCNN.2017.7966125", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emulating spiking neural networks on analog neuromorphic hardware offers\nseveral advantages over simulating them on conventional computers, particularly\nin terms of speed and energy consumption. However, this usually comes at the\ncost of reduced control over the dynamics of the emulated networks. In this\npaper, we demonstrate how iterative training of a hardware-emulated network can\ncompensate for anomalies induced by the analog substrate. We first convert a\ndeep neural network trained in software to a spiking network on the BrainScaleS\nwafer-scale neuromorphic system, thereby enabling an acceleration factor of 10\n000 compared to the biological time domain. This mapping is followed by the\nin-the-loop training, where in each training step, the network activity is\nfirst recorded in hardware and then used to compute the parameter updates in\nsoftware via backpropagation. An essential finding is that the parameter\nupdates do not have to be precise, but only need to approximately follow the\ncorrect gradient, which simplifies the computation of updates. Using this\napproach, after only several tens of iterations, the spiking network shows an\naccuracy close to the ideal software-emulated prototype. The presented\ntechniques show that deep spiking networks emulated on analog neuromorphic\ndevices can attain good computational performance despite the inherent\nvariations of the analog substrate.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 14:55:59 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Schmitt", "Sebastian", ""], ["Klaehn", "Johann", ""], ["Bellec", "Guillaume", ""], ["Gruebl", "Andreas", ""], ["Guettler", "Maurice", ""], ["Hartel", "Andreas", ""], ["Hartmann", "Stephan", ""], ["Husmann", "Dan", ""], ["Husmann", "Kai", ""], ["Karasenko", "Vitali", ""], ["Kleider", "Mitja", ""], ["Koke", "Christoph", ""], ["Mauch", "Christian", ""], ["Mueller", "Eric", ""], ["Mueller", "Paul", ""], ["Partzsch", "Johannes", ""], ["Petrovici", "Mihai A.", ""], ["Schiefer", "Stefan", ""], ["Scholze", "Stefan", ""], ["Vogginger", "Bernhard", ""], ["Legenstein", "Robert", ""], ["Maass", "Wolfgang", ""], ["Mayr", "Christian", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""]]}, {"id": "1703.02009", "submitter": "Lars Ruthotto", "authors": "Eldad Haber, Lars Ruthotto, Elliot Holtham, Seong-Hwan Jun", "title": "Learning across scales - A multiscale method for Convolution Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we establish the relation between optimal control and training\ndeep Convolution Neural Networks (CNNs). We show that the forward propagation\nin CNNs can be interpreted as a time-dependent nonlinear differential equation\nand learning as controlling the parameters of the differential equation such\nthat the network approximates the data-label relation for given training data.\nUsing this continuous interpretation we derive two new methods to scale CNNs\nwith respect to two different dimensions. The first class of multiscale methods\nconnects low-resolution and high-resolution data through prolongation and\nrestriction of CNN parameters. We demonstrate that this enables classifying\nhigh-resolution images using CNNs trained with low-resolution images and vice\nversa and warm-starting the learning process. The second class of multiscale\nmethods connects shallow and deep networks and leads to new training strategies\nthat gradually increase the depths of the CNN while re-using parameters for\ninitializations.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 18:15:40 GMT"}, {"version": "v2", "created": "Thu, 22 Jun 2017 16:39:14 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Haber", "Eldad", ""], ["Ruthotto", "Lars", ""], ["Holtham", "Elliot", ""], ["Jun", "Seong-Hwan", ""]]}, {"id": "1703.02065", "submitter": "Or Sharir", "authors": "Or Sharir and Amnon Shashua", "title": "On the Expressive Power of Overlapping Architectures of Deep Learning", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expressive efficiency refers to the relation between two architectures A and\nB, whereby any function realized by B could be replicated by A, but there\nexists functions realized by A, which cannot be replicated by B unless its size\ngrows significantly larger. For example, it is known that deep networks are\nexponentially efficient with respect to shallow networks, in the sense that a\nshallow network must grow exponentially large in order to approximate the\nfunctions represented by a deep network of polynomial size. In this work, we\nextend the study of expressive efficiency to the attribute of network\nconnectivity and in particular to the effect of \"overlaps\" in the convolutional\nprocess, i.e., when the stride of the convolution is smaller than its filter\nsize (receptive field). To theoretically analyze this aspect of network's\ndesign, we focus on a well-established surrogate for ConvNets called\nConvolutional Arithmetic Circuits (ConvACs), and then demonstrate empirically\nthat our results hold for standard ConvNets as well. Specifically, our analysis\nshows that having overlapping local receptive fields, and more broadly denser\nconnectivity, results in an exponential increase in the expressive capacity of\nneural networks. Moreover, while denser connectivity can increase the\nexpressive capacity, we show that the most common types of modern architectures\nalready exhibit exponential increase in expressivity, without relying on\nfully-connected layers.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 19:07:12 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 09:05:54 GMT"}, {"version": "v3", "created": "Fri, 27 Oct 2017 14:02:11 GMT"}, {"version": "v4", "created": "Sat, 24 Feb 2018 14:47:00 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Sharir", "Or", ""], ["Shashua", "Amnon", ""]]}, {"id": "1703.02245", "submitter": "Nima Dehghani", "authors": "Nima Dehghani", "title": "Design of the Artificial: lessons from the biological roots of general\n  intelligence", "comments": "Theoretical perspective on AGI (Artificial General Intelligence)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our desire and fascination with intelligent machines dates back to the\nantiquity's mythical automaton Talos, Aristotle's mode of mechanical thought\n(syllogism) and Heron of Alexandria's mechanical machines and automata.\nHowever, the quest for Artificial General Intelligence (AGI) is troubled with\nrepeated failures of strategies and approaches throughout the history. This\ndecade has seen a shift in interest towards bio-inspired software and hardware,\nwith the assumption that such mimicry entails intelligence. Though these steps\nare fruitful in certain directions and have advanced automation, their singular\ndesign focus renders them highly inefficient in achieving AGI. Which set of\nrequirements have to be met in the design of AGI? What are the limits in the\ndesign of the artificial? Here, a careful examination of computation in\nbiological systems hints that evolutionary tinkering of contextual processing\nof information enabled by a hierarchical architecture is the key to build AGI.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 07:20:30 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 15:29:05 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Dehghani", "Nima", ""]]}, {"id": "1703.02458", "submitter": "Jaegul Choo", "authors": "Min-je Choi, and Sehun Jeong and Hakjoo Oh, and Jaegul Choo", "title": "End-to-End Prediction of Buffer Overruns from Raw Source Code via Neural\n  Memory Networks", "comments": "6 pages + 1 appendix, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting buffer overruns from a source code is one of the most common and\nyet challenging tasks in program analysis. Current approaches have mainly\nrelied on rigid rules and handcrafted features devised by a few experts,\nlimiting themselves in terms of flexible applicability and robustness due to\ndiverse bug patterns and characteristics existing in sophisticated real-world\nsoftware programs. In this paper, we propose a novel, data-driven approach that\nis completely end-to-end without requiring any hand-crafted features, thus free\nfrom any program language-specific structural limitations. In particular, our\napproach leverages a recently proposed neural network model called memory\nnetworks that have shown the state-of-the-art performances mainly in\nquestion-answering tasks. Our experimental results using source codes\ndemonstrate that our proposed model is capable of accurately detecting simple\nbuffer overruns. We also present in-depth analyses on how a memory network can\nlearn to understand the semantics in programming languages solely from raw\nsource codes, such as tracing variables of interest, identifying numerical\nvalues, and performing their quantitative comparisons.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 16:33:35 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Choi", "Min-je", ""], ["Jeong", "Sehun", ""], ["Oh", "Hakjoo", ""], ["Choo", "Jaegul", ""]]}, {"id": "1703.02596", "submitter": "Benjamin Chamberlain", "authors": "Benjamin Paul Chamberlain, Angelo Cardoso, C.H. Bryan Liu, Roberto\n  Pagliari, Marc Peter Deisenroth", "title": "Customer Lifetime Value Prediction Using Embeddings", "comments": "10 pages, 11 figures", "journal-ref": "Proceedings of the 23rd ACM SIGKDD International Conference on\n  Knowledge Discovery and Data Mining Pages 1753-1762, 2017", "doi": "10.1145/3097983.3098123", "report-no": null, "categories": "cs.LG cs.CY cs.IR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the Customer LifeTime Value (CLTV) prediction system deployed at\nASOS.com, a global online fashion retailer. CLTV prediction is an important\nproblem in e-commerce where an accurate estimate of future value allows\nretailers to effectively allocate marketing spend, identify and nurture high\nvalue customers and mitigate exposure to losses. The system at ASOS provides\ndaily estimates of the future value of every customer and is one of the\ncornerstones of the personalised shopping experience. The state of the art in\nthis domain uses large numbers of handcrafted features and ensemble regressors\nto forecast value, predict churn and evaluate customer loyalty. Recently,\ndomains including language, vision and speech have shown dramatic advances by\nreplacing handcrafted features with features that are learned automatically\nfrom data. We detail the system deployed at ASOS and show that learning feature\nrepresentations is a promising extension to the state of the art in CLTV\nmodelling. We propose a novel way to generate embeddings of customers, which\naddresses the issue of the ever changing product catalogue and obtain a\nsignificant improvement over an exhaustive set of handcrafted features.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 21:18:11 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 12:20:06 GMT"}, {"version": "v3", "created": "Thu, 6 Jul 2017 16:40:44 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Chamberlain", "Benjamin Paul", ""], ["Cardoso", "Angelo", ""], ["Liu", "C. H. Bryan", ""], ["Pagliari", "Roberto", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "1703.02757", "submitter": "El Mahdi El Mhamdi", "authors": "Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, Julien Stainer", "title": "Byzantine-Tolerant Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth of data, the need for scalability and the complexity of models\nused in modern machine learning calls for distributed implementations. Yet, as\nof today, distributed machine learning frameworks have largely ignored the\npossibility of arbitrary (i.e., Byzantine) failures. In this paper, we study\nthe robustness to Byzantine failures at the fundamental level of stochastic\ngradient descent (SGD), the heart of most machine learning algorithms. Assuming\na set of $n$ workers, up to $f$ of them being Byzantine, we ask how robust can\nSGD be, without limiting the dimension, nor the size of the parameter space.\n  We first show that no gradient descent update rule based on a linear\ncombination of the vectors proposed by the workers (i.e, current approaches)\ntolerates a single Byzantine failure. We then formulate a resilience property\nof the update rule capturing the basic requirements to guarantee convergence\ndespite $f$ Byzantine workers. We finally propose Krum, an update rule that\nsatisfies the resilience property aforementioned. For a $d$-dimensional\nlearning problem, the time complexity of Krum is $O(n^2 \\cdot (d + \\log n))$.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 09:26:36 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Blanchard", "Peva", ""], ["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""], ["Stainer", "Julien", ""]]}, {"id": "1703.02806", "submitter": "Stefano Nichele", "authors": "Stefano Nichele and Andreas Molund", "title": "Deep Reservoir Computing Using Cellular Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) have been a prominent concept within\nartificial intelligence. They are inspired by Biological Neural Networks (BNNs)\nand provide an intuitive and abstract representation of how BNNs work. Derived\nfrom the more generic Artificial Neural Networks (ANNs), the recurrent ones are\nmeant to be used for temporal tasks, such as speech recognition, because they\nare capable of memorizing historic input. However, such networks are very time\nconsuming to train as a result of their inherent nature. Recently, Echo State\nNetworks and Liquid State Machines have been proposed as possible RNN\nalternatives, under the name of Reservoir Computing (RC). RCs are far more easy\nto train. In this paper, Cellular Automata are used as reservoir, and are\ntested on the 5-bit memory task (a well known benchmark within the RC\ncommunity). The work herein provides a method of mapping binary inputs from the\ntask onto the automata, and a recurrent architecture for handling the\nsequential aspects of it. Furthermore, a layered (deep) reservoir architecture\nis proposed. Performances are compared towards earlier work, in addition to its\nsingle-layer version. Results show that the single CA reservoir system yields\nsimilar results to state-of-the-art work. The system comprised of two layered\nreservoirs do show a noticeable improvement compared to a single CA reservoir.\nThis indicates potential for further research and provides valuable insight on\nhow to design CA reservoir systems.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 12:17:45 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Nichele", "Stefano", ""], ["Molund", "Andreas", ""]]}, {"id": "1703.02898", "submitter": "Biswa Sengupta", "authors": "B Sengupta, E Vazquez, M Sasdelli, Y Qian, M Peniak, L Netherton and G\n  Delfino", "title": "Large-scale image analysis using docker sandboxing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of specialized hardware such as Graphics Processing Units\n(GPUs), large scale image localization, classification and retrieval have seen\nincreased prevalence. Designing scalable software architecture that co-evolves\nwith such specialized hardware is a challenge in the commercial setting. In\nthis paper, we describe one such architecture (\\textit{Cortexica}) that\nleverages scalability of GPUs and sandboxing offered by docker containers. This\nallows for the flexibility of mixing different computer architectures as well\nas computational algorithms with the security of a trusted environment. We\nillustrate the utility of this framework in a commercial setting i.e.,\nsearching for multiple products in an image by combining image localisation and\nretrieval.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 09:40:48 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Sengupta", "B", ""], ["Vazquez", "E", ""], ["Sasdelli", "M", ""], ["Qian", "Y", ""], ["Peniak", "M", ""], ["Netherton", "L", ""], ["Delfino", "G", ""]]}, {"id": "1703.03130", "submitter": "Zhouhan Lin", "authors": "Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing\n  Xiang, Bowen Zhou, Yoshua Bengio", "title": "A Structured Self-attentive Sentence Embedding", "comments": "15 pages with appendix, 7 figures, 4 tables. Conference paper in 5th\n  International Conference on Learning Representations (ICLR 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new model for extracting an interpretable sentence\nembedding by introducing self-attention. Instead of using a vector, we use a\n2-D matrix to represent the embedding, with each row of the matrix attending on\na different part of the sentence. We also propose a self-attention mechanism\nand a special regularization term for the model. As a side effect, the\nembedding comes with an easy way of visualizing what specific parts of the\nsentence are encoded into the embedding. We evaluate our model on 3 different\ntasks: author profiling, sentiment classification, and textual entailment.\nResults show that our model yields a significant performance gain compared to\nother sentence embedding methods in all of the 3 tasks.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 04:42:30 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Lin", "Zhouhan", ""], ["Feng", "Minwei", ""], ["Santos", "Cicero Nogueira dos", ""], ["Yu", "Mo", ""], ["Xiang", "Bing", ""], ["Zhou", "Bowen", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1703.03334", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr, Huu Phuoc Le, R\\'egis Makhmara, Ta Duy Nguyen", "title": "Fast Genetic Algorithms", "comments": null, "journal-ref": "Proceedings of GECCO 2017", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For genetic algorithms using a bit-string representation of length~$n$, the\ngeneral recommendation is to take $1/n$ as mutation rate. In this work, we\ndiscuss whether this is really justified for multimodal functions. Taking jump\nfunctions and the $(1+1)$ evolutionary algorithm as the simplest example, we\nobserve that larger mutation rates give significantly better runtimes. For the\n$\\jump_{m,n}$ function, any mutation rate between $2/n$ and $m/n$ leads to a\nspeed-up at least exponential in $m$ compared to the standard choice.\n  The asymptotically best runtime, obtained from using the mutation rate $m/n$\nand leading to a speed-up super-exponential in $m$, is very sensitive to small\nchanges of the mutation rate. Any deviation by a small $(1 \\pm \\eps)$ factor\nleads to a slow-down exponential in $m$. Consequently, any fixed mutation rate\ngives strongly sub-optimal results for most jump functions.\n  Building on this observation, we propose to use a random mutation rate\n$\\alpha/n$, where $\\alpha$ is chosen from a power-law distribution. We prove\nthat the $(1+1)$ EA with this heavy-tailed mutation rate optimizes any\n$\\jump_{m,n}$ function in a time that is only a small polynomial (in~$m$)\nfactor above the one stemming from the optimal rate for this $m$.\n  Our heavy-tailed mutation operator yields similar speed-ups (over the best\nknown performance guarantees) for the vertex cover problem in bipartite graphs\nand the matching problem in general graphs.\n  Following the example of fast simulated annealing, fast evolution strategies,\nand fast evolutionary programming, we propose to call genetic algorithms using\na heavy-tailed mutation operator \\emph{fast genetic algorithms}.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 16:45:25 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 16:23:21 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Doerr", "Benjamin", ""], ["Le", "Huu Phuoc", ""], ["Makhmara", "R\u00e9gis", ""], ["Nguyen", "Ta Duy", ""]]}, {"id": "1703.03372", "submitter": "Dhanesh Ramachandram", "authors": "Dhanesh Ramachandram and Terrance DeVries", "title": "LesionSeg: Semantic segmentation of skin lesions using Deep\n  Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for skin lesion segmentation for the ISIC 2017 Skin\nLesion Segmentation Challenge. Our approach is based on a Fully Convolutional\nNetwork architecture which is trained end to end, from scratch, on a limited\ndataset. Our semantic segmentation architecture utilizes several recent\ninnovations in particularly in the combined use of (i) use of atrous\nconvolutions to increase the effective field of view of the network's receptive\nfield without increasing the number of parameters, (ii) the use of\nnetwork-in-network $1\\times1$ convolution layers to add capacity to the network\nand (iii) state-of-art super-resolution upsampling of predictions using\nsubpixel CNN layers. We reported a mean IOU score of 0.642 on the validation\nset provided by the organisers.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 17:52:28 GMT"}, {"version": "v2", "created": "Fri, 10 Mar 2017 19:56:40 GMT"}, {"version": "v3", "created": "Wed, 15 Mar 2017 01:37:18 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Ramachandram", "Dhanesh", ""], ["DeVries", "Terrance", ""]]}, {"id": "1703.03400", "submitter": "Chelsea Finn", "authors": "Chelsea Finn, Pieter Abbeel, Sergey Levine", "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks", "comments": "ICML 2017. Code at https://github.com/cbfinn/maml, Videos of RL\n  results at https://sites.google.com/view/maml, Blog post at\n  http://bair.berkeley.edu/blog/2017/07/18/learning-to-learn/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an algorithm for meta-learning that is model-agnostic, in the\nsense that it is compatible with any model trained with gradient descent and\napplicable to a variety of different learning problems, including\nclassification, regression, and reinforcement learning. The goal of\nmeta-learning is to train a model on a variety of learning tasks, such that it\ncan solve new learning tasks using only a small number of training samples. In\nour approach, the parameters of the model are explicitly trained such that a\nsmall number of gradient steps with a small amount of training data from a new\ntask will produce good generalization performance on that task. In effect, our\nmethod trains the model to be easy to fine-tune. We demonstrate that this\napproach leads to state-of-the-art performance on two few-shot image\nclassification benchmarks, produces good results on few-shot regression, and\naccelerates fine-tuning for policy gradient reinforcement learning with neural\nnetwork policies.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 18:58:03 GMT"}, {"version": "v2", "created": "Tue, 9 May 2017 17:14:08 GMT"}, {"version": "v3", "created": "Tue, 18 Jul 2017 16:45:29 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Finn", "Chelsea", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1703.03664", "submitter": "Scott Reed", "authors": "Scott Reed, A\\\"aron van den Oord, Nal Kalchbrenner, Sergio G\\'omez\n  Colmenarejo, Ziyu Wang, Dan Belov, Nando de Freitas", "title": "Parallel Multiscale Autoregressive Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PixelCNN achieves state-of-the-art results in density estimation for natural\nimages. Although training is fast, inference is costly, requiring one network\nevaluation per pixel; O(N) for N pixels. This can be sped up by caching\nactivations, but still involves generating each pixel sequentially. In this\nwork, we propose a parallelized PixelCNN that allows more efficient inference\nby modeling certain pixel groups as conditionally independent. Our new PixelCNN\nmodel achieves competitive density estimation and orders of magnitude speedup -\nO(log N) sampling instead of O(N) - enabling the practical generation of\n512x512 images. We evaluate the model on class-conditional image generation,\ntext-to-image synthesis, and action-conditional video generation, showing that\nour model achieves the best results among non-pixel-autoregressive density\nmodels that allow efficient sampling.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 12:58:23 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Reed", "Scott", ""], ["Oord", "A\u00e4ron van den", ""], ["Kalchbrenner", "Nal", ""], ["Colmenarejo", "Sergio G\u00f3mez", ""], ["Wang", "Ziyu", ""], ["Belov", "Dan", ""], ["de Freitas", "Nando", ""]]}, {"id": "1703.03768", "submitter": "John V Monaco", "authors": "John V. Monaco and Manuel M. Vindiola", "title": "Integer Factorization with a Neuromorphic Sieve", "comments": "Fixed typos in equation for modular roots (Section II, par. 6;\n  Section III, par. 2) and phase calculation (Section IV, par 2)", "journal-ref": "Monaco, John V., and Manuel M. Vindiola. \"Integer factorization\n  with a neuromorphic sieve.\" Circuits and Systems (ISCAS), 2017 IEEE\n  International Symposium on. IEEE, 2017", "doi": null, "report-no": null, "categories": "cs.NE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bound to factor large integers is dominated by the computational effort\nto discover numbers that are smooth, typically performed by sieving a\npolynomial sequence. On a von Neumann architecture, sieving has log-log\namortized time complexity to check each value for smoothness. This work\npresents a neuromorphic sieve that achieves a constant time check for\nsmoothness by exploiting two characteristic properties of neuromorphic\narchitectures: constant time synaptic integration and massively parallel\ncomputation. The approach is validated by modifying msieve, one of the fastest\npublicly available integer factorization implementations, to use the IBM\nNeurosynaptic System (NS1e) as a coprocessor for the sieving stage.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 17:15:29 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 18:55:29 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Monaco", "John V.", ""], ["Vindiola", "Manuel M.", ""]]}, {"id": "1703.03773", "submitter": "Frank Neumann", "authors": "Aneta Neumann, Zygmunt L. Szpak, Wojciech Chojnacki, Frank Neumann", "title": "Evolutionary Image Composition Using Feature Covariance Matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms have recently been used to create a wide range of\nartistic work. In this paper, we propose a new approach for the composition of\nnew images from existing ones, that retain some salient features of the\noriginal images. We introduce evolutionary algorithms that create new images\nbased on a fitness function that incorporates feature covariance matrices\nassociated with different parts of the images. This approach is very flexible\nin that it can work with a wide range of features and enables targeting\nspecific regions in the images. For the creation of the new images, we propose\na population-based evolutionary algorithm with mutation and crossover operators\nbased on random walks. Our experimental results reveal a spectrum of\naesthetically pleasing images that can be obtained with the aid of our\nevolutionary process.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 17:31:36 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Neumann", "Aneta", ""], ["Szpak", "Zygmunt L.", ""], ["Chojnacki", "Wojciech", ""], ["Neumann", "Frank", ""]]}, {"id": "1703.03854", "submitter": "Priyadarshini Panda", "authors": "Priyadarshini Panda, Gopalakrishnan Srinivasan, and Kaushik Roy", "title": "Convolutional Spike Timing Dependent Plasticity based Feature Learning\n  in Spiking Neural Networks", "comments": "11 pages, 10 figures, Under Consideration in Scientific Reports", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-inspired learning models attempt to mimic the cortical architecture and\ncomputations performed in the neurons and synapses constituting the human brain\nto achieve its efficiency in cognitive tasks. In this work, we present\nconvolutional spike timing dependent plasticity based feature learning with\nbiologically plausible leaky-integrate-and-fire neurons in Spiking Neural\nNetworks (SNNs). We use shared weight kernels that are trained to encode\nrepresentative features underlying the input patterns thereby improving the\nsparsity as well as the robustness of the learning model. We demonstrate that\nthe proposed unsupervised learning methodology learns several visual categories\nfor object recognition with fewer number of examples and outperforms\ntraditional fully-connected SNN architectures while yielding competitive\naccuracy. Additionally, we observe that the learning model performs out-of-set\ngeneralization further making the proposed biologically plausible framework a\nviable and efficient architecture for future neuromorphic applications.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 22:09:20 GMT"}, {"version": "v2", "created": "Mon, 20 Mar 2017 15:06:10 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Panda", "Priyadarshini", ""], ["Srinivasan", "Gopalakrishnan", ""], ["Roy", "Kaushik", ""]]}, {"id": "1703.03864", "submitter": "Tim Salimans", "authors": "Tim Salimans, Jonathan Ho, Xi Chen, Szymon Sidor, Ilya Sutskever", "title": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the use of Evolution Strategies (ES), a class of black box\noptimization algorithms, as an alternative to popular MDP-based RL techniques\nsuch as Q-learning and Policy Gradients. Experiments on MuJoCo and Atari show\nthat ES is a viable solution strategy that scales extremely well with the\nnumber of CPUs available: By using a novel communication strategy based on\ncommon random numbers, our ES implementation only needs to communicate scalars,\nmaking it possible to scale to over a thousand parallel workers. This allows us\nto solve 3D humanoid walking in 10 minutes and obtain competitive results on\nmost Atari games after one hour of training. In addition, we highlight several\nadvantages of ES as a black box optimization technique: it is invariant to\naction frequency and delayed rewards, tolerant of extremely long horizons, and\ndoes not need temporal discounting or value function approximation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 23:02:19 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 23:28:48 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Salimans", "Tim", ""], ["Ho", "Jonathan", ""], ["Chen", "Xi", ""], ["Sidor", "Szymon", ""], ["Sutskever", "Ilya", ""]]}, {"id": "1703.03939", "submitter": "Govardana Sachithanandam Ramachandran", "authors": "Govardana Sachithanandam Ramachandran, Ajay Sohmshetty", "title": "Ask Me Even More: Dynamic Memory Tensor Networks (Extended Model)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine Memory Networks for the task of question answering (QA), under\ncommon real world scenario where training examples are scarce and under weakly\nsupervised scenario, that is only extrinsic labels are available for training.\nWe propose extensions for the Dynamic Memory Network (DMN), specifically within\nthe attention mechanism, we call the resulting Neural Architecture as Dynamic\nMemory Tensor Network (DMTN). Ultimately, we see that our proposed extensions\nresults in over 80% improvement in the number of task passed against the\nbaselined standard DMN and 20% more task passed compared to state-of-the-art\nEnd-to-End Memory Network for Facebook's single task weakly trained 1K bAbi\ndataset.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 10:05:19 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Ramachandran", "Govardana Sachithanandam", ""], ["Sohmshetty", "Ajay", ""]]}, {"id": "1703.03943", "submitter": "Tatsuya Sasaki", "authors": "Hitoshi Yamamoto, Isamu Okada, Satoshi Uchida, Tatsuya Sasaki", "title": "A norm knockout method on indirect reciprocity to reveal indispensable\n  norms", "comments": "15 pages (incl. supplementary materials), 6 figures, 7 table", "journal-ref": "Scientific Reports 7, 44146 (2017)", "doi": "10.1038/srep44146", "report-no": null, "categories": "physics.soc-ph cs.MA cs.NE q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although various norms for reciprocity-based cooperation have been suggested\nthat are evolutionarily stable against invasion from free riders, the process\nof alternation of norms and the role of diversified norms remain unclear in the\nevolution of cooperation. We clarify the co-evolutionary dynamics of norms and\ncooperation in indirect reciprocity and also identify the indispensable norms\nfor the evolution of cooperation. Inspired by the gene knockout method, a\ngenetic engineering technique, we developed the norm knockout method and\nclarified the norms necessary for the establishment of cooperation. The results\nof numerical investigations revealed that the majority of norms gradually\ntransitioned to tolerant norms after defectors are eliminated by strict norms.\nFurthermore, no cooperation emerges when specific norms that are intolerant to\ndefectors are knocked out.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 10:29:57 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Yamamoto", "Hitoshi", ""], ["Okada", "Isamu", ""], ["Uchida", "Satoshi", ""], ["Sasaki", "Tatsuya", ""]]}, {"id": "1703.04071", "submitter": "Chunpeng Wu", "authors": "Chunpeng Wu, Wei Wen, Tariq Afzal, Yongmei Zhang, Yiran Chen, and Hai\n  Li", "title": "A Compact DNN: Approaching GoogLeNet-Level Accuracy of Classification\n  and Domain Adaptation", "comments": "2017 IEEE Conference on Computer Vision and Pattern Recognition\n  (CVPR'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, DNN model compression based on network architecture design, e.g.,\nSqueezeNet, attracted a lot attention. No accuracy drop on image classification\nis observed on these extremely compact networks, compared to well-known models.\nAn emerging question, however, is whether these model compression techniques\nhurt DNN's learning ability other than classifying images on a single dataset.\nOur preliminary experiment shows that these compression methods could degrade\ndomain adaptation (DA) ability, though the classification performance is\npreserved. Therefore, we propose a new compact network architecture and\nunsupervised DA method in this paper. The DNN is built on a new basic module\nConv-M which provides more diverse feature extractors without significantly\nincreasing parameters. The unified framework of our DA method will\nsimultaneously learn invariance across domains, reduce divergence of feature\nrepresentations, and adapt label prediction. Our DNN has 4.1M parameters, which\nis only 6.7% of AlexNet or 59% of GoogLeNet. Experiments show that our DNN\nobtains GoogLeNet-level accuracy both on classification and DA, and our DA\nmethod slightly outperforms previous competitive ones. Put all together, our DA\nstrategy based on our DNN achieves state-of-the-art on sixteen of total\neighteen DA tasks on popular Office-31 and Office-Caltech datasets.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 05:07:00 GMT"}, {"version": "v2", "created": "Sat, 25 Mar 2017 03:21:57 GMT"}, {"version": "v3", "created": "Wed, 29 Mar 2017 05:40:52 GMT"}, {"version": "v4", "created": "Mon, 3 Apr 2017 05:17:42 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Wu", "Chunpeng", ""], ["Wen", "Wei", ""], ["Afzal", "Tariq", ""], ["Zhang", "Yongmei", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "1703.04145", "submitter": "Mihai Alexandru Petrovici", "authors": "Mihai A. Petrovici, Anna Schroeder, Oliver Breitwieser, Andreas\n  Gr\\\"ubl, Johannes Schemmel, Karlheinz Meier", "title": "Robustness from structure: Inference with hierarchical spiking networks\n  on analog neuromorphic hardware", "comments": "accepted at IJCNN 2017", "journal-ref": "International Joint Conference on Neural Networks (IJCNN), 2017", "doi": "10.1109/IJCNN.2017.7966123", "report-no": null, "categories": "q-bio.NC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How spiking networks are able to perform probabilistic inference is an\nintriguing question, not only for understanding information processing in the\nbrain, but also for transferring these computational principles to neuromorphic\nsilicon circuits. A number of computationally powerful spiking network models\nhave been proposed, but most of them have only been tested, under ideal\nconditions, in software simulations. Any implementation in an analog, physical\nsystem, be it in vivo or in silico, will generally lead to distorted dynamics\ndue to the physical properties of the underlying substrate. In this paper, we\ndiscuss several such distortive effects that are difficult or impossible to\nremove by classical calibration routines or parameter training. We then argue\nthat hierarchical networks of leaky integrate-and-fire neurons can offer the\nrequired robustness for physical implementation and demonstrate this with both\nsoftware simulations and emulation on an accelerated analog neuromorphic\ndevice.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 17:29:11 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Petrovici", "Mihai A.", ""], ["Schroeder", "Anna", ""], ["Breitwieser", "Oliver", ""], ["Gr\u00fcbl", "Andreas", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""]]}, {"id": "1703.04309", "submitter": "Alex Kendall", "authors": "Alex Kendall, Hayk Martirosyan, Saumitro Dasgupta, Peter Henry, Ryan\n  Kennedy, Abraham Bachrach, Adam Bry", "title": "End-to-End Learning of Geometry and Context for Deep Stereo Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel deep learning architecture for regressing disparity from a\nrectified pair of stereo images. We leverage knowledge of the problem's\ngeometry to form a cost volume using deep feature representations. We learn to\nincorporate contextual information using 3-D convolutions over this volume.\nDisparity values are regressed from the cost volume using a proposed\ndifferentiable soft argmin operation, which allows us to train our method\nend-to-end to sub-pixel accuracy without any additional post-processing or\nregularization. We evaluate our method on the Scene Flow and KITTI datasets and\non KITTI we set a new state-of-the-art benchmark, while being significantly\nfaster than competing approaches.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 10:00:52 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Kendall", "Alex", ""], ["Martirosyan", "Hayk", ""], ["Dasgupta", "Saumitro", ""], ["Henry", "Peter", ""], ["Kennedy", "Ryan", ""], ["Bachrach", "Abraham", ""], ["Bry", "Adam", ""]]}, {"id": "1703.04496", "submitter": "Ashley Prater", "authors": "Ashley Prater", "title": "Comparison of echo state network output layer classification methods on\n  noisy data", "comments": "8 pages. International Joint Conference on Neural Networks (IJCNN\n  2017)", "journal-ref": null, "doi": "10.1109/IJCNN.2017.7966179", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Echo state networks are a recently developed type of recurrent neural network\nwhere the internal layer is fixed with random weights, and only the output\nlayer is trained on specific data. Echo state networks are increasingly being\nused to process spatiotemporal data in real-world settings, including speech\nrecognition, event detection, and robot control. A strength of echo state\nnetworks is the simple method used to train the output layer - typically a\ncollection of linear readout weights found using a least squares approach.\nAlthough straightforward to train and having a low computational cost to use,\nthis method may not yield acceptable accuracy performance on noisy data.\n  This study compares the performance of three echo state network output layer\nmethods to perform classification on noisy data: using trained linear weights,\nusing sparse trained linear weights, and using trained low-rank approximations\nof reservoir states. The methods are investigated experimentally on both\nsynthetic and natural datasets. The experiments suggest that using regularized\nleast squares to train linear output weights is superior on data with low\nnoise, but using the low-rank approximations may significantly improve accuracy\non datasets contaminated with higher noise levels.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 17:25:52 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Prater", "Ashley", ""]]}, {"id": "1703.04550", "submitter": "Steven Bohez", "authors": "Steven Bohez, Tim Verbelen, Elias De Coninck, Bert Vankeirsbilck,\n  Pieter Simoens, Bart Dhoedt", "title": "Sensor Fusion for Robot Control through Deep Reinforcement Learning", "comments": "6 pages, 6 figures, submitted to IROS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning is becoming increasingly popular for robot\ncontrol algorithms, with the aim for a robot to self-learn useful feature\nrepresentations from unstructured sensory input leading to the optimal\nactuation policy. In addition to sensors mounted on the robot, sensors might\nalso be deployed in the environment, although these might need to be accessed\nvia an unreliable wireless connection. In this paper, we demonstrate deep\nneural network architectures that are able to fuse information coming from\nmultiple sensors and are robust to sensor failures at runtime. We evaluate our\nmethod on a search and pick task for a robot both in simulation and the real\nworld.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 20:08:39 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Bohez", "Steven", ""], ["Verbelen", "Tim", ""], ["De Coninck", "Elias", ""], ["Vankeirsbilck", "Bert", ""], ["Simoens", "Pieter", ""], ["Dhoedt", "Bart", ""]]}, {"id": "1703.04561", "submitter": "Vin\\'icius Veloso De Melo", "authors": "Vin\\'icius Veloso de Melo and Wolfgang Banzhaf", "title": "Drone Squadron Optimization: a Self-adaptive Algorithm for Global\n  Numerical Optimization", "comments": "Short version - Full version published by Springer Neural Computing\n  and Applications", "journal-ref": "Neural Computing and Applications, 2017, pp 1-28", "doi": "10.1007/s00521-017-2881-3", "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Drone Squadron Optimization, a new self-adaptive\nmetaheuristic for global numerical optimization which is updated online by a\nhyper-heuristic. DSO is an artifact-inspired technique, as opposed to many\nalgorithms used nowadays, which are nature-inspired. DSO is very flexible\nbecause it is not related to behaviors or natural phenomena. DSO has two core\nparts: the semi-autonomous drones that fly over a landscape to explore, and the\nCommand Center that processes the retrieved data and updates the drones'\nfirmware whenever necessary. The self-adaptive aspect of DSO in this work is\nthe perturbation/movement scheme, which is the procedure used to generate\ntarget coordinates. This procedure is evolved by the Command Center during the\nglobal optimization process in order to adapt DSO to the search landscape. DSO\nwas evaluated on a set of widely employed benchmark functions. The statistical\nanalysis of the results shows that the proposed method is competitive with the\nother methods in the comparison, the performance is promising, but several\nfuture improvements are planned.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 01:37:21 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["de Melo", "Vin\u00edcius Veloso", ""], ["Banzhaf", "Wolfgang", ""]]}, {"id": "1703.04706", "submitter": "Tharindu Fernando", "authors": "Tharindu Fernando, Simon Denman, Aaron McFadyen, Sridha Sridharan and\n  Clinton Fookes", "title": "Tree Memory Networks for Modelling Long-term Temporal Dependencies", "comments": null, "journal-ref": "Neurocomputing, Volume 304, 23 August 2018, Pages 64-81", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the domain of sequence modelling, Recurrent Neural Networks (RNN) have\nbeen capable of achieving impressive results in a variety of application areas\nincluding visual question answering, part-of-speech tagging and machine\ntranslation. However this success in modelling short term dependencies has not\nsuccessfully transitioned to application areas such as trajectory prediction,\nwhich require capturing both short term and long term relationships. In this\npaper, we propose a Tree Memory Network (TMN) for modelling long term and short\nterm relationships in sequence-to-sequence mapping problems. The proposed\nnetwork architecture is composed of an input module, controller and a memory\nmodule. In contrast to related literature, which models the memory as a\nsequence of historical states, we model the memory as a recursive tree\nstructure. This structure more effectively captures temporal dependencies\nacross both short term and long term sequences using its hierarchical\nstructure. We demonstrate the effectiveness and flexibility of the proposed TMN\nin two practical problems, aircraft trajectory modelling and pedestrian\ntrajectory modelling in a surveillance setting, and in both cases we outperform\nthe current state-of-the-art. Furthermore, we perform an in depth analysis on\nthe evolution of the memory module content over time and provide visual\nevidence on how the proposed TMN is able to map both long term and short term\nrelationships efficiently via a hierarchical structure.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 21:13:28 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 05:18:59 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Fernando", "Tharindu", ""], ["Denman", "Simon", ""], ["McFadyen", "Aaron", ""], ["Sridharan", "Sridha", ""], ["Fookes", "Clinton", ""]]}, {"id": "1703.04813", "submitter": "Olga Wichrowska", "authors": "Olga Wichrowska, Niru Maheswaranathan, Matthew W. Hoffman, Sergio\n  Gomez Colmenarejo, Misha Denil, Nando de Freitas, Jascha Sohl-Dickstein", "title": "Learned Optimizers that Scale and Generalize", "comments": "Final ICML paper after reviewer suggestions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to learn has emerged as an important direction for achieving\nartificial intelligence. Two of the primary barriers to its adoption are an\ninability to scale to larger problems and a limited ability to generalize to\nnew tasks. We introduce a learned gradient descent optimizer that generalizes\nwell to new tasks, and which has significantly reduced memory and computation\noverhead. We achieve this by introducing a novel hierarchical RNN architecture,\nwith minimal per-parameter overhead, augmented with additional architectural\nfeatures that mirror the known structure of optimization tasks. We also develop\na meta-training ensemble of small, diverse optimization tasks capturing common\nproperties of loss landscapes. The optimizer learns to outperform RMSProp/ADAM\non problems in this corpus. More importantly, it performs comparably or better\nwhen applied to small convolutional neural networks, despite seeing no neural\nnetworks in its meta-training set. Finally, it generalizes to train Inception\nV3 and ResNet V2 architectures on the ImageNet dataset for thousands of steps,\noptimization problems that are of a vastly different scale than those it was\ntrained on. We release an open source implementation of the meta-training\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 23:05:54 GMT"}, {"version": "v2", "created": "Mon, 8 May 2017 21:55:33 GMT"}, {"version": "v3", "created": "Fri, 23 Jun 2017 22:22:38 GMT"}, {"version": "v4", "created": "Thu, 7 Sep 2017 23:38:09 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Wichrowska", "Olga", ""], ["Maheswaranathan", "Niru", ""], ["Hoffman", "Matthew W.", ""], ["Colmenarejo", "Sergio Gomez", ""], ["Denil", "Misha", ""], ["de Freitas", "Nando", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1703.04816", "submitter": "Dirk Weissenborn", "authors": "Dirk Weissenborn and Georg Wiese and Laura Seiffe", "title": "Making Neural QA as Simple as Possible but not Simpler", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent development of large-scale question answering (QA) datasets triggered\na substantial amount of research into end-to-end neural architectures for QA.\nIncreasingly complex systems have been conceived without comparison to simpler\nneural baseline systems that would justify their complexity. In this work, we\npropose a simple heuristic that guides the development of neural baseline\nsystems for the extractive QA task. We find that there are two ingredients\nnecessary for building a high-performing neural QA system: first, the awareness\nof question words while processing the context and second, a composition\nfunction that goes beyond simple bag-of-words modeling, such as recurrent\nneural networks. Our results show that FastQA, a system that meets these two\nrequirements, can achieve very competitive performance compared with existing\nmodels. We argue that this surprising finding puts results of previous systems\nand the complexity of recent QA datasets into perspective.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 23:09:45 GMT"}, {"version": "v2", "created": "Fri, 7 Apr 2017 07:40:23 GMT"}, {"version": "v3", "created": "Thu, 8 Jun 2017 14:12:35 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Weissenborn", "Dirk", ""], ["Wiese", "Georg", ""], ["Seiffe", "Laura", ""]]}, {"id": "1703.04818", "submitter": "Sujith Ravi", "authors": "Thang D. Bui, Sujith Ravi, Vivek Ramavajjala", "title": "Neural Graph Machines: Learning Neural Networks Using Graphs", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Label propagation is a powerful and flexible semi-supervised learning\ntechnique on graphs. Neural networks, on the other hand, have proven track\nrecords in many supervised learning tasks. In this work, we propose a training\nframework with a graph-regularised objective, namely \"Neural Graph Machines\",\nthat can combine the power of neural networks and label propagation. This work\ngeneralises previous literature on graph-augmented training of neural networks,\nenabling it to be applied to multiple neural architectures (Feed-forward NNs,\nCNNs and LSTM RNNs) and a wide range of graphs. The new objective allows the\nneural networks to harness both labeled and unlabeled data by: (a) allowing the\nnetwork to train using labeled data as in the supervised setting, (b) biasing\nthe network to learn similar hidden representations for neighboring nodes on a\ngraph, in the same vein as label propagation. Such architectures with the\nproposed objective can be trained efficiently using stochastic gradient descent\nand scaled to large graphs, with a runtime that is linear in the number of\nedges. The proposed joint training approach convincingly outperforms many\nexisting methods on a wide range of tasks (multi-label classification on social\ngraphs, news categorization, document classification and semantic intent\nclassification), with multiple forms of graph inputs (including graphs with and\nwithout node-level features) and using different types of neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 23:10:57 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Bui", "Thang D.", ""], ["Ravi", "Sujith", ""], ["Ramavajjala", "Vivek", ""]]}, {"id": "1703.04990", "submitter": "Chengxun Shu", "authors": "Chengxun Shu, Hongyu Zhang", "title": "Neural Programming by Example", "comments": "7 pages, Association for the Advancement of Artificial Intelligence\n  (AAAI)", "journal-ref": "AAAI-2017", "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming by Example (PBE) targets at automatically inferring a computer\nprogram for accomplishing a certain task from sample input and output. In this\npaper, we propose a deep neural networks (DNN) based PBE model called Neural\nProgramming by Example (NPBE), which can learn from input-output strings and\ninduce programs that solve the string manipulation problems. Our NPBE model has\nfour neural network based components: a string encoder, an input-output\nanalyzer, a program generator, and a symbol selector. We demonstrate the\neffectiveness of NPBE by training it end-to-end to solve some common string\nmanipulation problems in spreadsheet systems. The results show that our model\ncan induce string manipulation programs effectively. Our work is one step\ntowards teaching DNN to generate computer programs.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 07:57:51 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Shu", "Chengxun", ""], ["Zhang", "Hongyu", ""]]}, {"id": "1703.05051", "submitter": "Robin Tibor Schirrmeister", "authors": "Robin Tibor Schirrmeister, Jost Tobias Springenberg, Lukas Dominique\n  Josef Fiederer, Martin Glasstetter, Katharina Eggensperger, Michael\n  Tangermann, Frank Hutter, Wolfram Burgard, Tonio Ball", "title": "Deep learning with convolutional neural networks for EEG decoding and\n  visualization", "comments": "A revised manuscript (with the new title) has been accepted at Human\n  Brain Mapping, see http://onlinelibrary.wiley.com/doi/10.1002/hbm.23730/full", "journal-ref": null, "doi": "10.1002/hbm.23730", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PLEASE READ AND CITE THE REVISED VERSION at Human Brain Mapping:\nhttp://onlinelibrary.wiley.com/doi/10.1002/hbm.23730/full\n  Code available here: https://github.com/robintibor/braindecode\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 09:52:58 GMT"}, {"version": "v2", "created": "Mon, 10 Jul 2017 11:06:38 GMT"}, {"version": "v3", "created": "Mon, 7 Aug 2017 16:16:08 GMT"}, {"version": "v4", "created": "Tue, 8 Aug 2017 08:48:58 GMT"}, {"version": "v5", "created": "Fri, 8 Jun 2018 16:13:56 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Schirrmeister", "Robin Tibor", ""], ["Springenberg", "Jost Tobias", ""], ["Fiederer", "Lukas Dominique Josef", ""], ["Glasstetter", "Martin", ""], ["Eggensperger", "Katharina", ""], ["Tangermann", "Michael", ""], ["Hutter", "Frank", ""], ["Burgard", "Wolfram", ""], ["Ball", "Tonio", ""]]}, {"id": "1703.05364", "submitter": "Steven Young", "authors": "Thomas E. Potok, Catherine Schuman, Steven R. Young, Robert M. Patton,\n  Federico Spedalieri, Jeremy Liu, Ke-Thia Yao, Garrett Rose, Gangotree Chakma", "title": "A Study of Complex Deep Learning Networks on High Performance,\n  Neuromorphic, and Quantum Computers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current Deep Learning approaches have been very successful using\nconvolutional neural networks (CNN) trained on large graphical processing units\n(GPU)-based computers. Three limitations of this approach are: 1) they are\nbased on a simple layered network topology, i.e., highly connected layers,\nwithout intra-layer connections; 2) the networks are manually configured to\nachieve optimal results, and 3) the implementation of neuron model is expensive\nin both cost and power. In this paper, we evaluate deep learning models using\nthree different computing architectures to address these problems: quantum\ncomputing to train complex topologies, high performance computing (HPC) to\nautomatically determine network topology, and neuromorphic computing for a\nlow-power hardware implementation. We use the MNIST dataset for our experiment,\ndue to input size limitations of current quantum computers. Our results show\nthe feasibility of using the three architectures in tandem to address the above\ndeep learning limitations. We show a quantum computer can find high quality\nvalues of intra-layer connections weights, in a tractable time as the\ncomplexity of the network increases; a high performance computer can find\noptimal layer-based topologies; and a neuromorphic computer can represent the\ncomplex topology and weights derived from the other architectures in low power\nmemristive hardware.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 19:37:08 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 18:47:59 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Potok", "Thomas E.", ""], ["Schuman", "Catherine", ""], ["Young", "Steven R.", ""], ["Patton", "Robert M.", ""], ["Spedalieri", "Federico", ""], ["Liu", "Jeremy", ""], ["Yao", "Ke-Thia", ""], ["Rose", "Garrett", ""], ["Chakma", "Gangotree", ""]]}, {"id": "1703.05422", "submitter": "Travis Desell", "authors": "Travis Desell", "title": "Large Scale Evolution of Convolutional Neural Networks Using Volunteer\n  Computing", "comments": "17 pages, 13 figures. Submitted to the 2017 Genetic and Evolutionary\n  Computation Conference (GECCO 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a new algorithm called evolutionary exploration of\naugmenting convolutional topologies (EXACT), which is capable of evolving the\nstructure of convolutional neural networks (CNNs). EXACT is in part modeled\nafter the neuroevolution of augmenting topologies (NEAT) algorithm, with\nnotable exceptions to allow it to scale to large scale distributed computing\nenvironments and evolve networks with convolutional filters. In addition to\nmultithreaded and MPI versions, EXACT has been implemented as part of a BOINC\nvolunteer computing project, allowing large scale evolution. During a period of\ntwo months, over 4,500 volunteered computers on the Citizen Science Grid\ntrained over 120,000 CNNs and evolved networks reaching 98.32% test data\naccuracy on the MNIST handwritten digits dataset. These results are even\nstronger as the backpropagation strategy used to train the CNNs was fairly\nrudimentary (ReLU units, L2 regularization and Nesterov momentum) and these\nwere initial test runs done without refinement of the backpropagation\nhyperparameters. Further, the EXACT evolutionary strategy is independent of the\nmethod used to train the CNNs, so they could be further improved by advanced\ntechniques like elastic distortions, pretraining and dropout. The evolved\nnetworks are also quite interesting, showing \"organic\" structures and\nsignificant differences from standard human designed architectures.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 23:17:24 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Desell", "Travis", ""]]}, {"id": "1703.05807", "submitter": "Nathan McDonald", "authors": "Nathan McDonald", "title": "Reservoir Computing and Extreme Learning Machines using Pairs of\n  Cellular Automata Rules", "comments": "accepted to International Joint Conference on Neural Networks (IJCNN\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework for implementing reservoir computing (RC) and extreme learning\nmachines (ELMs), two types of artificial neural networks, based on 1D\nelementary Cellular Automata (CA) is presented, in which two separate CA rules\nexplicitly implement the minimum computational requirements of the reservoir\nlayer: hyperdimensional projection and short-term memory. CAs are cell-based\nstate machines, which evolve in time in accordance with local rules based on a\ncells current state and those of its neighbors. Notably, simple single cell\nshift rules as the memory rule in a fixed edge CA afforded reasonable success\nin conjunction with a variety of projection rules, potentially significantly\nreducing the optimal solution search space. Optimal iteration counts for the CA\nrule pairs can be estimated for some tasks based upon the category of the\nprojection rule. Initial results support future hardware realization, where CAs\npotentially afford orders of magnitude reduction in size, weight, and power\n(SWaP) requirements compared with floating point RC implementations.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 19:33:57 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["McDonald", "Nathan", ""]]}, {"id": "1703.05955", "submitter": "Ke Chen", "authors": "Ke Chen", "title": "Implicit Gradient Neural Networks with a Positive-Definite Mass Matrix\n  for Online Linear Equations Solving", "comments": "Submitted to Information Processing Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the advantages achieved by implicit analogue net for solving\nonline linear equations, a novel implicit neural model is designed based on\nconventional explicit gradient neural networks in this letter by introducing a\npositive-definite mass matrix. In addition to taking the advantages of the\nimplicit neural dynamics, the proposed implicit gradient neural networks can\nstill achieve globally exponential convergence to the unique theoretical\nsolution of linear equations and also global stability even under no-solution\nand multi-solution situations. Simulative results verify theoretical\nconvergence analysis on the proposed neural dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 10:46:23 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Chen", "Ke", ""]]}, {"id": "1703.06043", "submitter": "Mihai Alexandru Petrovici", "authors": "Mihai A. Petrovici, Sebastian Schmitt, Johann Kl\\\"ahn, David\n  St\\\"ockel, Anna Schroeder, Guillaume Bellec, Johannes Bill, Oliver\n  Breitwieser, Ilja Bytschok, Andreas Gr\\\"ubl, Maurice G\\\"uttler, Andreas\n  Hartel, Stephan Hartmann, Dan Husmann, Kai Husmann, Sebastian Jeltsch, Vitali\n  Karasenko, Mitja Kleider, Christoph Koke, Alexander Kononov, Christian Mauch,\n  Eric M\\\"uller, Paul M\\\"uller, Johannes Partzsch, Thomas Pfeil, Stefan\n  Schiefer, Stefan Scholze, Anand Subramoney, Vasilis Thanasoulis, Bernhard\n  Vogginger, Robert Legenstein, Wolfgang Maass, Ren\\'e Sch\\\"uffny, Christian\n  Mayr, Johannes Schemmel, Karlheinz Meier", "title": "Pattern representation and recognition with accelerated analog\n  neuromorphic systems", "comments": "accepted at ISCAS 2017", "journal-ref": "Circuits and Systems (ISCAS), 2017 IEEE International Symposium on", "doi": "10.1109/ISCAS.2017.8050530", "report-no": null, "categories": "q-bio.NC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite being originally inspired by the central nervous system, artificial\nneural networks have diverged from their biological archetypes as they have\nbeen remodeled to fit particular tasks. In this paper, we review several\npossibilites to reverse map these architectures to biologically more realistic\nspiking networks with the aim of emulating them on fast, low-power neuromorphic\nhardware. Since many of these devices employ analog components, which cannot be\nperfectly controlled, finding ways to compensate for the resulting effects\nrepresents a key challenge. Here, we discuss three different strategies to\naddress this problem: the addition of auxiliary network components for\nstabilizing activity, the utilization of inherently robust architectures and a\ntraining method for hardware-emulated networks that functions without perfect\nknowledge of the system's dynamics and parameters. For all three scenarios, we\ncorroborate our theoretical considerations with experimental results on\naccelerated analog neuromorphic platforms.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 14:59:17 GMT"}, {"version": "v2", "created": "Mon, 3 Jul 2017 15:16:43 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Petrovici", "Mihai A.", ""], ["Schmitt", "Sebastian", ""], ["Kl\u00e4hn", "Johann", ""], ["St\u00f6ckel", "David", ""], ["Schroeder", "Anna", ""], ["Bellec", "Guillaume", ""], ["Bill", "Johannes", ""], ["Breitwieser", "Oliver", ""], ["Bytschok", "Ilja", ""], ["Gr\u00fcbl", "Andreas", ""], ["G\u00fcttler", "Maurice", ""], ["Hartel", "Andreas", ""], ["Hartmann", "Stephan", ""], ["Husmann", "Dan", ""], ["Husmann", "Kai", ""], ["Jeltsch", "Sebastian", ""], ["Karasenko", "Vitali", ""], ["Kleider", "Mitja", ""], ["Koke", "Christoph", ""], ["Kononov", "Alexander", ""], ["Mauch", "Christian", ""], ["M\u00fcller", "Eric", ""], ["M\u00fcller", "Paul", ""], ["Partzsch", "Johannes", ""], ["Pfeil", "Thomas", ""], ["Schiefer", "Stefan", ""], ["Scholze", "Stefan", ""], ["Subramoney", "Anand", ""], ["Thanasoulis", "Vasilis", ""], ["Vogginger", "Bernhard", ""], ["Legenstein", "Robert", ""], ["Maass", "Wolfgang", ""], ["Sch\u00fcffny", "Ren\u00e9", ""], ["Mayr", "Christian", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""]]}, {"id": "1703.06217", "submitter": "Mason McGill", "authors": "Mason McGill and Pietro Perona", "title": "Deciding How to Decide: Dynamic Routing in Artificial Neural Networks", "comments": "ICML 2017. Code at https://github.com/MasonMcGill/multipath-nn Video\n  abstract at https://youtu.be/NHQsDaycwyQ", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and systematically evaluate three strategies for training\ndynamically-routed artificial neural networks: graphs of learned\ntransformations through which different input signals may take different paths.\nThough some approaches have advantages over others, the resulting networks are\noften qualitatively similar. We find that, in dynamically-routed networks\ntrained to classify images, layers and branches become specialized to process\ndistinct categories of images. Additionally, given a fixed computational\nbudget, dynamically-routed networks tend to perform better than comparable\nstatically-routed networks.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 23:52:14 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 22:14:36 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["McGill", "Mason", ""], ["Perona", "Pietro", ""]]}, {"id": "1703.06229", "submitter": "Jacopo Cavazza", "authors": "Pietro Morerio, Jacopo Cavazza, Riccardo Volpi, Rene Vidal, Vittorio\n  Murino", "title": "Curriculum Dropout", "comments": "Accepted at ICCV (International Conference on Computer Vision) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a very effective way of regularizing neural networks.\nStochastically \"dropping out\" units with a certain probability discourages\nover-specific co-adaptations of feature detectors, preventing overfitting and\nimproving network generalization. Besides, Dropout can be interpreted as an\napproximate model aggregation technique, where an exponential number of smaller\nnetworks are averaged in order to get a more powerful ensemble. In this paper,\nwe show that using a fixed dropout probability during training is a suboptimal\nchoice. We thus propose a time scheduling for the probability of retaining\nneurons in the network. This induces an adaptive regularization scheme that\nsmoothly increases the difficulty of the optimization problem. This idea of\n\"starting easy\" and adaptively increasing the difficulty of the learning\nproblem has its roots in curriculum learning and allows one to train better\nmodels. Indeed, we prove that our optimization strategy implements a very\ngeneral curriculum scheme, by gradually adding noise to both the input and\nintermediate feature representations within the network architecture.\nExperiments on seven image classification datasets and different network\narchitectures show that our method, named Curriculum Dropout, frequently yields\nto better generalization and, at worst, performs just as well as the standard\nDropout method.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 00:59:40 GMT"}, {"version": "v2", "created": "Thu, 3 Aug 2017 06:27:09 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Morerio", "Pietro", ""], ["Cavazza", "Jacopo", ""], ["Volpi", "Riccardo", ""], ["Vidal", "Rene", ""], ["Murino", "Vittorio", ""]]}, {"id": "1703.06263", "submitter": "Zhizhong Liu", "authors": "Zhi-Zhong Liu, Yong Wang, Shengxiang Yang, and Ke Tang", "title": "An Adaptive Framework to Tune the Coordinate Systems in Evolutionary\n  Algorithms", "comments": "This paper provides a new point of view toward how to describe an\n  evolutionary operator in the original coordinate system, and also offers a\n  convenient transformation from an evolutionary operator in the original\n  coordinate system to the corresponding evolutionary operator in the Eigen\n  coordinate system", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the evolutionary computation research community, the performance of most\nevolutionary algorithms (EAs) depends strongly on their implemented coordinate\nsystem. However, the commonly used coordinate system is fixed and not well\nsuited for different function landscapes, EAs thus might not search\nefficiently. To overcome this shortcoming, in this paper we propose a\nframework, named ACoS, to adaptively tune the coordinate systems in EAs. In\nACoS, an Eigen coordinate system is established by making use of the cumulative\npopulation distribution information, which can be obtained based on a\ncovariance matrix adaptation strategy and an additional archiving mechanism.\nSince the population distribution information can reflect the features of the\nfunction landscape to some extent, EAs in the Eigen coordinate system have the\ncapability to identify the modality of the function landscape. In addition, the\nEigen coordinate system is coupled with the original coordinate system, and\nthey are selected according to a probability vector. The probability vector\naims to determine the selection ratio of each coordinate system for each\nindividual, and is adaptively updated based on the collected information from\nthe offspring. ACoS has been applied to two of the most popular EA paradigms,\ni.e., particle swarm optimization (PSO) and differential evolution (DE), for\nsolving 30 test functions with 30 and 50 dimensions at the 2014 IEEE Congress\non Evolutionary Computation. The experimental studies demonstrate its\neffectiveness.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 07:41:08 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Liu", "Zhi-Zhong", ""], ["Wang", "Yong", ""], ["Yang", "Shengxiang", ""], ["Tang", "Ke", ""]]}, {"id": "1703.06264", "submitter": "Ramin M. Hasani", "authors": "Ramin M. Hasani, Magdalena Fuchs, Victoria Beneder and Radu Grosu", "title": "Non-Associative Learning Representation in the Nervous System of the\n  Nematode Caenorhabditis elegans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Caenorhabditis elegans (C. elegans) illustrated remarkable behavioral\nplasticities including complex non-associative and associative learning\nrepresentations. Understanding the principles of such mechanisms presumably\nleads to constructive inspirations for the design of efficient learning\nalgorithms. In the present study, we postulate a novel approach on modeling\nsingle neurons and synapses to study the mechanisms underlying learning in the\nC. elegans nervous system. In this regard, we construct a precise mathematical\nmodel of sensory neurons where we include multi-scale details from genes, ion\nchannels and ion pumps, together with a dynamic model of synapses comprised of\nneurotransmitters and receptors kinetics. We recapitulate mechanosensory\nhabituation mechanism, a non-associative learning process, in which elements of\nthe neural network tune their parameters as a result of repeated input stimuli.\nAccordingly, we quantitatively demonstrate the roots of such plasticity in the\nneuronal and synaptic-level representations. Our findings can potentially give\nrise to the development of new bio-inspired learning algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 07:45:51 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 15:55:30 GMT"}, {"version": "v3", "created": "Sat, 25 Mar 2017 13:24:29 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Hasani", "Ramin M.", ""], ["Fuchs", "Magdalena", ""], ["Beneder", "Victoria", ""], ["Grosu", "Radu", ""]]}, {"id": "1703.06270", "submitter": "Ramin M. Hasani", "authors": "Ramin M. Hasani, Victoria Beneder, Magdalena Fuchs, David Lung and\n  Radu Grosu", "title": "SIM-CE: An Advanced Simulink Platform for Studying the Brain of\n  Caenorhabditis elegans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SIM-CE, an advanced, user-friendly modeling and simulation\nenvironment in Simulink for performing multi-scale behavioral analysis of the\nnervous system of Caenorhabditis elegans (C. elegans). SIM-CE contains an\nimplementation of the mathematical models of C. elegans's neurons and synapses,\nin Simulink, which can be easily extended and particularized by the user. The\nSimulink model is able to capture both complex dynamics of ion channels and\nadditional biophysical detail such as intracellular calcium concentration. We\ndemonstrate the performance of SIM-CE by carrying out neuronal, synaptic and\nneural-circuit-level behavioral simulations. Such environment enables the user\nto capture unknown properties of the neural circuits, test hypotheses and\ndetermine the origin of many behavioral plasticities exhibited by the worm.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 08:27:42 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 15:49:11 GMT"}, {"version": "v3", "created": "Sat, 25 Mar 2017 13:19:14 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Hasani", "Ramin M.", ""], ["Beneder", "Victoria", ""], ["Fuchs", "Magdalena", ""], ["Lung", "David", ""], ["Grosu", "Radu", ""]]}, {"id": "1703.06272", "submitter": "Ramin M. Hasani", "authors": "Ramin M. Hasani, Guodong Wang and Radu Grosu", "title": "An Automated Auto-encoder Correlation-based Health-Monitoring and\n  Prognostic Method for Machine Bearings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies an intelligent ultimate technique for health-monitoring\nand prognostic of common rotary machine components, particularly bearings.\nDuring a run-to-failure experiment, rich unsupervised features from vibration\nsensory data are extracted by a trained sparse auto-encoder. Then, the\ncorrelation of the extracted attributes of the initial samples (presumably\nhealthy at the beginning of the test) with the succeeding samples is calculated\nand passed through a moving-average filter. The normalized output is named\nauto-encoder correlation-based (AEC) rate which stands for an informative\nattribute of the system depicting its health status and precisely identifying\nthe degradation starting point. We show that AEC technique well-generalizes in\nseveral run-to-failure tests. AEC collects rich unsupervised features form the\nvibration data fully autonomous. We demonstrate the superiority of the AEC over\nmany other state-of-the-art approaches for the health monitoring and prognostic\nof machine bearings.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 08:38:51 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Hasani", "Ramin M.", ""], ["Wang", "Guodong", ""], ["Grosu", "Radu", ""]]}, {"id": "1703.06290", "submitter": "Johannes Thiele", "authors": "Johannes Thiele, Peter Diehl, Matthew Cook", "title": "A wake-sleep algorithm for recurrent, spiking neural networks", "comments": "Presented at the NIPS 2016 workshop \"Computing with Spikes\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a recently proposed model for cortical computation which\nperforms relational inference. It consists of several interconnected,\nstructurally equivalent populations of leaky integrate-and-fire (LIF) neurons,\nwhich are trained in a self-organized fashion with spike-timing dependent\nplasticity (STDP). Despite its robust learning dynamics, the model is\nsusceptible to a problem typical for recurrent networks which use a correlation\nbased (Hebbian) learning rule: if trained with high learning rates, the\nrecurrent connections can cause strong feedback loops in the network dynamics,\nwhich lead to the emergence of attractor states. This causes a strong reduction\nin the number of representable patterns and a decay in the inference ability of\nthe network. As a solution, we introduce a conceptually very simple\n\"wake-sleep\" algorithm: during the wake phase, training is executed normally,\nwhile during the sleep phase, the network \"dreams\" samples from its generative\nmodel, which are induced by random input. This process allows us to activate\nthe attractor states in the network, which can then be unlearned effectively by\nan anti-Hebbian mechanism. The algorithm allows us to increase learning rates\nup to a factor of ten while avoiding clustering, which allows the network to\nlearn several times faster. Also for low learning rates, where clustering is\nnot an issue, it improves convergence speed and reduces the final inference\nerror.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 12:29:16 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Thiele", "Johannes", ""], ["Diehl", "Peter", ""], ["Cook", "Matthew", ""]]}, {"id": "1703.06490", "submitter": "Edward Choi", "authors": "Edward Choi, Siddharth Biswal, Bradley Malin, Jon Duke, Walter F.\n  Stewart, Jimeng Sun", "title": "Generating Multi-label Discrete Patient Records using Generative\n  Adversarial Networks", "comments": "Accepted at Machine Learning in Health Care (MLHC) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to electronic health record (EHR) data has motivated computational\nadvances in medical research. However, various concerns, particularly over\nprivacy, can limit access to and collaborative use of EHR data. Sharing\nsynthetic EHR data could mitigate risk. In this paper, we propose a new\napproach, medical Generative Adversarial Network (medGAN), to generate\nrealistic synthetic patient records. Based on input real patient records,\nmedGAN can generate high-dimensional discrete variables (e.g., binary and count\nfeatures) via a combination of an autoencoder and generative adversarial\nnetworks. We also propose minibatch averaging to efficiently avoid mode\ncollapse, and increase the learning efficiency with batch normalization and\nshortcut connections. To demonstrate feasibility, we showed that medGAN\ngenerates synthetic patient records that achieve comparable performance to real\ndata on many experiments including distribution statistics, predictive modeling\ntasks and a medical expert review. We also empirically observe a limited\nprivacy risk in both identity and attribute disclosure using medGAN.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 18:56:37 GMT"}, {"version": "v2", "created": "Sat, 17 Jun 2017 08:51:01 GMT"}, {"version": "v3", "created": "Thu, 11 Jan 2018 20:41:54 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Choi", "Edward", ""], ["Biswal", "Siddharth", ""], ["Malin", "Bradley", ""], ["Duke", "Jon", ""], ["Stewart", "Walter F.", ""], ["Sun", "Jimeng", ""]]}, {"id": "1703.06664", "submitter": "Sebasti\\'an Basterrech", "authors": "Sebasti\\'an Basterrech", "title": "Empirical Analysis of the Necessary and Sufficient Conditions of the\n  Echo State Property", "comments": "23 pages, 14 figures, accepted paper for the IEEE IJCNN, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Echo State Network (ESN) is a specific recurrent network, which has\ngained popularity during the last years. The model has a recurrent network\nnamed reservoir, that is fixed during the learning process. The reservoir is\nused for transforming the input space in a larger space. A fundamental property\nthat provokes an impact on the model accuracy is the Echo State Property (ESP).\nThere are two main theoretical results related to the ESP. First, a sufficient\ncondition for the ESP existence that involves the singular values of the\nreservoir matrix. Second, a necessary condition for the ESP. The ESP can be\nviolated according to the spectral radius value of the reservoir matrix. There\nis a theoretical gap between these necessary and sufficient conditions. This\narticle presents an empirical analysis of the accuracy and the projections of\nreservoirs that satisfy this theoretical gap. It gives some insights about the\ngeneration of the reservoir matrix. From previous works, it is already known\nthat the optimal accuracy is obtained near to the border of stability control\nof the dynamics. Then, according to our empirical results, we can see that this\nborder seems to be closer to the sufficient conditions than to the necessary\nconditions of the ESP.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 10:49:36 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Basterrech", "Sebasti\u00e1n", ""]]}, {"id": "1703.06692", "submitter": "Peter Karkus", "authors": "Peter Karkus, David Hsu, Wee Sun Lee", "title": "QMDP-Net: Deep Learning for Planning under Partial Observability", "comments": "NIPS 2017 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the QMDP-net, a neural network architecture for\nplanning under partial observability. The QMDP-net combines the strengths of\nmodel-free learning and model-based planning. It is a recurrent policy network,\nbut it represents a policy for a parameterized set of tasks by connecting a\nmodel with a planning algorithm that solves the model, thus embedding the\nsolution structure of planning in a network learning architecture. The QMDP-net\nis fully differentiable and allows for end-to-end training. We train a QMDP-net\non different tasks so that it can generalize to new ones in the parameterized\ntask set and \"transfer\" to other similar tasks beyond the set. In preliminary\nexperiments, QMDP-net showed strong performance on several robotic tasks in\nsimulation. Interestingly, while QMDP-net encodes the QMDP algorithm, it\nsometimes outperforms the QMDP algorithm in the experiments, as a result of\nend-to-end learning.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 11:44:00 GMT"}, {"version": "v2", "created": "Tue, 27 Jun 2017 12:59:39 GMT"}, {"version": "v3", "created": "Fri, 3 Nov 2017 03:31:43 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Karkus", "Peter", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "1703.06846", "submitter": "Nadav Cohen", "authors": "Nadav Cohen, Ronen Tamari, Amnon Shashua", "title": "Boosting Dilated Convolutional Networks with Mixed Tensor Decompositions", "comments": "Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The driving force behind deep networks is their ability to compactly\nrepresent rich classes of functions. The primary notion for formally reasoning\nabout this phenomenon is expressive efficiency, which refers to a situation\nwhere one network must grow unfeasibly large in order to realize (or\napproximate) functions of another. To date, expressive efficiency analyses\nfocused on the architectural feature of depth, showing that deep networks are\nrepresentationally superior to shallow ones. In this paper we study the\nexpressive efficiency brought forth by connectivity, motivated by the\nobservation that modern networks interconnect their layers in elaborate ways.\nWe focus on dilated convolutional networks, a family of deep models delivering\nstate of the art performance in sequence processing tasks. By introducing and\nanalyzing the concept of mixed tensor decompositions, we prove that\ninterconnecting dilated convolutional networks can lead to expressive\nefficiency. In particular, we show that even a single connection between\nintermediate layers can already lead to an almost quadratic gap, which in\nlarge-scale settings typically makes the difference between a model that is\npractical and one that is not. Empirical evaluation demonstrates how the\nexpressive efficiency of connectivity, similarly to that of depth, translates\ninto gains in accuracy. This leads us to believe that expressive efficiency may\nserve a key role in the development of new tools for deep network design.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 17:05:38 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 18:22:33 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 17:20:29 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Cohen", "Nadav", ""], ["Tamari", "Ronen", ""], ["Shashua", "Amnon", ""]]}, {"id": "1703.06891", "submitter": "Chris Donahue", "authors": "Chris Donahue, Zachary C. Lipton, Julian McAuley", "title": "Dance Dance Convolution", "comments": "Published as a conference paper at ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM cs.NE cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dance Dance Revolution (DDR) is a popular rhythm-based video game. Players\nperform steps on a dance platform in synchronization with music as directed by\non-screen step charts. While many step charts are available in standardized\npacks, players may grow tired of existing charts, or wish to dance to a song\nfor which no chart exists. We introduce the task of learning to choreograph.\nGiven a raw audio track, the goal is to produce a new step chart. This task\ndecomposes naturally into two subtasks: deciding when to place steps and\ndeciding which steps to select. For the step placement task, we combine\nrecurrent and convolutional neural networks to ingest spectrograms of low-level\naudio features to predict steps, conditioned on chart difficulty. For step\nselection, we present a conditional LSTM generative model that substantially\noutperforms n-gram and fixed-window approaches.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 18:00:13 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 07:44:55 GMT"}, {"version": "v3", "created": "Wed, 21 Jun 2017 00:45:51 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Donahue", "Chris", ""], ["Lipton", "Zachary C.", ""], ["McAuley", "Julian", ""]]}, {"id": "1703.06934", "submitter": "William La Cava", "authors": "William La Cava and Jason H. Moore", "title": "Ensemble representation learning: an analysis of fitness and survival\n  for wrapper-based genetic programming methods", "comments": "Genetic and Evolutionary Computation Conference (GECCO) 2017, Berlin,\n  Germany", "journal-ref": null, "doi": "10.1145/3071178/3071215", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently we proposed a general, ensemble-based feature engineering wrapper\n(FEW) that was paired with a number of machine learning methods to solve\nregression problems. Here, we adapt FEW for supervised classification and\nperform a thorough analysis of fitness and survival methods within this\nframework. Our tests demonstrate that two fitness metrics, one introduced as an\nadaptation of the silhouette score, outperform the more commonly used Fisher\ncriterion. We analyze survival methods and demonstrate that $\\epsilon$-lexicase\nsurvival works best across our test problems, followed by random survival which\noutperforms both tournament and deterministic crowding. We conduct a benchmark\ncomparison to several classification methods using a large set of problems and\nshow that FEW can improve the best classifier performance in several cases. We\nshow that FEW generates consistent, meaningful features for a biomedical\nproblem with different ML pairings.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 19:26:00 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 12:46:40 GMT"}, {"version": "v3", "created": "Thu, 3 Aug 2017 19:01:17 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["La Cava", "William", ""], ["Moore", "Jason H.", ""]]}, {"id": "1703.07122", "submitter": "Alexander Hagg", "authors": "Alexander Hagg, Maximilian Mensing, Alexander Asteroth", "title": "Evolving Parsimonious Networks by Mixing Activation Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroevolution methods evolve the weights of a neural network, and in some\ncases the topology, but little work has been done to analyze the effect of\nevolving the activation functions of individual nodes on network size, which is\nimportant when training networks with a small number of samples. In this work\nwe extend the neuroevolution algorithm NEAT to evolve the activation function\nof neurons in addition to the topology and weights of the network. The size and\nperformance of networks produced using NEAT with uniform activation in all\nnodes, or homogenous networks, is compared to networks which contain a mixture\nof activation functions, or heterogenous networks. For a number of regression\nand classification benchmarks it is shown that, (1) qualitatively different\nactivation functions lead to different results in homogeneous networks, (2) the\nheterogeneous version of NEAT is able to select well performing activation\nfunctions, (3) producing heterogeneous networks that are significantly smaller\nthan homogeneous networks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 10:10:56 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Hagg", "Alexander", ""], ["Mensing", "Maximilian", ""], ["Asteroth", "Alexander", ""]]}, {"id": "1703.07286", "submitter": "Johannes Schemmel", "authors": "Johannes Schemmel, Laura Kriener, Paul M\\\"uller, Karlheinz Meier", "title": "An Accelerated Analog Neuromorphic Hardware System Emulating NMDA- and\n  Calcium-Based Non-Linear Dendrites", "comments": "Accepted at IJCNN 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an extension of the BrainScaleS accelerated analog\nneuromorphic hardware model. The scalable neuromorphic architecture is extended\nby the support for multi-compartment models and non-linear dendrites. These\nfeatures are part of a \\SI{65}{\\nano\\meter} prototype ASIC. It allows to\nemulate different spike types observed in cortical pyramidal neurons: NMDA\nplateau potentials, calcium and sodium spikes. By replicating some of the\nstructures of these cells, they can be configured to perform coincidence\ndetection within a single neuron. Built-in plasticity mechanisms can modify not\nonly the synaptic weights, but also the dendritic synaptic composition to\nefficiently train large multi-compartment neurons. Transistor-level simulations\ndemonstrate the functionality of the analog implementation and illustrate\nanalogies to biological measurements.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 15:43:18 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Schemmel", "Johannes", ""], ["Kriener", "Laura", ""], ["M\u00fcller", "Paul", ""], ["Meier", "Karlheinz", ""]]}, {"id": "1703.07326", "submitter": "Yan Duan", "authors": "Yan Duan, Marcin Andrychowicz, Bradly C. Stadie, Jonathan Ho, Jonas\n  Schneider, Ilya Sutskever, Pieter Abbeel, Wojciech Zaremba", "title": "One-Shot Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning has been commonly applied to solve different tasks in\nisolation. This usually requires either careful feature engineering, or a\nsignificant number of samples. This is far from what we desire: ideally, robots\nshould be able to learn from very few demonstrations of any given task, and\ninstantly generalize to new situations of the same task, without requiring\ntask-specific engineering. In this paper, we propose a meta-learning framework\nfor achieving such capability, which we call one-shot imitation learning.\n  Specifically, we consider the setting where there is a very large set of\ntasks, and each task has many instantiations. For example, a task could be to\nstack all blocks on a table into a single tower, another task could be to place\nall blocks on a table into two-block towers, etc. In each case, different\ninstances of the task would consist of different sets of blocks with different\ninitial states. At training time, our algorithm is presented with pairs of\ndemonstrations for a subset of all tasks. A neural net is trained that takes as\ninput one demonstration and the current state (which initially is the initial\nstate of the other demonstration of the pair), and outputs an action with the\ngoal that the resulting sequence of states and actions matches as closely as\npossible with the second demonstration. At test time, a demonstration of a\nsingle instance of a new task is presented, and the neural net is expected to\nperform well on new instances of this new task. The use of soft attention\nallows the model to generalize to conditions and tasks unseen in the training\ndata. We anticipate that by training this model on a much greater variety of\ntasks and settings, we will obtain a general system that can turn any\ndemonstrations into robust policies that can accomplish an overwhelming variety\nof tasks.\n  Videos available at https://bit.ly/nips2017-oneshot .\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 17:22:29 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 00:24:03 GMT"}, {"version": "v3", "created": "Mon, 4 Dec 2017 21:53:23 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Duan", "Yan", ""], ["Andrychowicz", "Marcin", ""], ["Stadie", "Bradly C.", ""], ["Ho", "Jonathan", ""], ["Schneider", "Jonas", ""], ["Sutskever", "Ilya", ""], ["Abbeel", "Pieter", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "1703.07394", "submitter": "Shumeet Baluja", "authors": "Shumeet Baluja", "title": "Deep Learning for Explicitly Modeling Optimization Landscapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In all but the most trivial optimization problems, the structure of the\nsolutions exhibit complex interdependencies between the input parameters.\nDecades of research with stochastic search techniques has shown the benefit of\nexplicitly modeling the interactions between sets of parameters and the overall\nquality of the solutions discovered. We demonstrate a novel method, based on\nlearning deep networks, to model the global landscapes of optimization\nproblems. To represent the search space concisely and accurately, the deep\nnetworks must encode information about the underlying parameter interactions\nand their contributions to the quality of the solution. Once the networks are\ntrained, the networks are probed to reveal parameter combinations with high\nexpected performance with respect to the optimization task. These estimates are\nused to initialize fast, randomized, local search algorithms, which in turn\nexpose more information about the search space that is subsequently used to\nrefine the models. We demonstrate the technique on multiple optimization\nproblems that have arisen in a variety of real-world domains, including:\npacking, graphics, job scheduling, layout and compression. The problems include\ncombinatoric search spaces, discontinuous and highly non-linear spaces, and\nspan binary, higher-cardinality discrete, as well as continuous parameters.\nStrengths, limitations, and extensions of the approach are extensively\ndiscussed and demonstrated.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 19:12:35 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Baluja", "Shumeet", ""]]}, {"id": "1703.07655", "submitter": "Priyadarshini Panda", "authors": "Priyadarshini Panda, Jason M. Allred, Shriram Ramanathan and Kaushik\n  Roy", "title": "ASP: Learning to Forget with Adaptive Synaptic Plasticity in Spiking\n  Neural Networks", "comments": "14 pages, 14 figures", "journal-ref": "IEEE Journal on Emerging and Selected Topics in Circuits and\n  Systems (Volume: 8, Issue: 1, March 2018)", "doi": "10.1109/JETCAS.2017.2769684", "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental feature of learning in animals is the \"ability to forget\" that\nallows an organism to perceive, model and make decisions from disparate streams\nof information and adapt to changing environments. Against this backdrop, we\npresent a novel unsupervised learning mechanism ASP (Adaptive Synaptic\nPlasticity) for improved recognition with Spiking Neural Networks (SNNs) for\nreal time on-line learning in a dynamic environment. We incorporate an adaptive\nweight decay mechanism with the traditional Spike Timing Dependent Plasticity\n(STDP) learning to model adaptivity in SNNs. The leak rate of the synaptic\nweights is modulated based on the temporal correlation between the spiking\npatterns of the pre- and post-synaptic neurons. This mechanism helps in gradual\nforgetting of insignificant data while retaining significant, yet old,\ninformation. ASP, thus, maintains a balance between forgetting and immediate\nlearning to construct a stable-plastic self-adaptive SNN for continuously\nchanging inputs. We demonstrate that the proposed learning methodology\naddresses catastrophic forgetting while yielding significantly improved\naccuracy over the conventional STDP learning method for digit recognition\napplications. Additionally, we observe that the proposed learning model\nautomatically encodes selective attention towards relevant features in the\ninput data while eliminating the influence of background noise (or denoising)\nfurther improving the robustness of the ASP learning.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 13:48:47 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 20:17:33 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Panda", "Priyadarshini", ""], ["Allred", "Jason M.", ""], ["Ramanathan", "Shriram", ""], ["Roy", "Kaushik", ""]]}, {"id": "1703.07737", "submitter": "Lucas Beyer", "authors": "Alexander Hermans, and Lucas Beyer, and Bastian Leibe", "title": "In Defense of the Triplet Loss for Person Re-Identification", "comments": "Lucas Beyer and Alexander Hermans contributed equally. Updates: Minor\n  fixes, new SOTA comparisons, add CUHK03 results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, the field of computer vision has gone through a\nrevolution fueled mainly by the advent of large datasets and the adoption of\ndeep convolutional neural networks for end-to-end learning. The person\nre-identification subfield is no exception to this. Unfortunately, a prevailing\nbelief in the community seems to be that the triplet loss is inferior to using\nsurrogate losses (classification, verification) followed by a separate metric\nlearning step. We show that, for models trained from scratch as well as\npretrained ones, using a variant of the triplet loss to perform end-to-end deep\nmetric learning outperforms most other published methods by a large margin.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 16:34:29 GMT"}, {"version": "v2", "created": "Mon, 27 Mar 2017 13:39:01 GMT"}, {"version": "v3", "created": "Wed, 17 May 2017 10:50:01 GMT"}, {"version": "v4", "created": "Tue, 21 Nov 2017 15:35:07 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Hermans", "Alexander", ""], ["Beyer", "Lucas", ""], ["Leibe", "Bastian", ""]]}, {"id": "1703.07754", "submitter": "Kartik Audhkhasi", "authors": "Kartik Audhkhasi, Bhuvana Ramabhadran, George Saon, Michael Picheny,\n  David Nahamoo", "title": "Direct Acoustics-to-Word Models for English Conversational Speech\n  Recognition", "comments": "Submitted to Interspeech-2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on end-to-end automatic speech recognition (ASR) has shown that\nthe connectionist temporal classification (CTC) loss can be used to convert\nacoustics to phone or character sequences. Such systems are used with a\ndictionary and separately-trained Language Model (LM) to produce word\nsequences. However, they are not truly end-to-end in the sense of mapping\nacoustics directly to words without an intermediate phone representation. In\nthis paper, we present the first results employing direct acoustics-to-word CTC\nmodels on two well-known public benchmark tasks: Switchboard and CallHome.\nThese models do not require an LM or even a decoder at run-time and hence\nrecognize speech with minimal complexity. However, due to the large number of\nword output units, CTC word models require orders of magnitude more data to\ntrain reliably compared to traditional systems. We present some techniques to\nmitigate this issue. Our CTC word model achieves a word error rate of\n13.0%/18.8% on the Hub5-2000 Switchboard/CallHome test sets without any LM or\ndecoder compared with 9.6%/16.0% for phone-based CTC with a 4-gram LM. We also\npresent rescoring results on CTC word model lattices to quantify the\nperformance benefits of a LM, and contrast the performance of word and phone\nCTC models.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 17:17:16 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Audhkhasi", "Kartik", ""], ["Ramabhadran", "Bhuvana", ""], ["Saon", "George", ""], ["Picheny", "Michael", ""], ["Nahamoo", "David", ""]]}, {"id": "1703.07841", "submitter": "Maysum Panju", "authors": "Ri Wang, Maysum Panju, Mahmood Gohari", "title": "Classification-based RNN machine translation using GRUs", "comments": "7 pages, 1 figure; graduate course research project", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report the results of our classification-based machine translation model,\nbuilt upon the framework of a recurrent neural network using gated recurrent\nunits. Unlike other RNN models that attempt to maximize the overall conditional\nlog probability of sentences against sentences, our model focuses a\nclassification approach of estimating the conditional probability of the next\nword given the input sequence. This simpler approach using GRUs was hoped to be\ncomparable with more complicated RNN models, but achievements in this\nimplementation were modest and there remains a lot of room for improving this\nclassification approach.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 20:31:47 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Wang", "Ri", ""], ["Panju", "Maysum", ""], ["Gohari", "Mahmood", ""]]}, {"id": "1703.07914", "submitter": "Cengiz Pehlevan", "authors": "Cengiz Pehlevan, Anirvan Sengupta, Dmitri B. Chklovskii", "title": "Why do similarity matching objectives lead to Hebbian/anti-Hebbian\n  networks?", "comments": "Accepted for publication in Neural Computation", "journal-ref": null, "doi": "10.1162/neco_a_01018", "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling self-organization of neural networks for unsupervised learning using\nHebbian and anti-Hebbian plasticity has a long history in neuroscience. Yet,\nderivations of single-layer networks with such local learning rules from\nprincipled optimization objectives became possible only recently, with the\nintroduction of similarity matching objectives. What explains the success of\nsimilarity matching objectives in deriving neural networks with local learning\nrules? Here, using dimensionality reduction as an example, we introduce several\nvariable substitutions that illuminate the success of similarity matching. We\nshow that the full network objective may be optimized separately for each\nsynapse using local learning rules both in the offline and online settings. We\nformalize the long-standing intuition of the rivalry between Hebbian and\nanti-Hebbian rules by formulating a min-max optimization problem. We introduce\na novel dimensionality reduction objective using fractional matrix exponents.\nTo illustrate the generality of our approach, we apply it to a novel\nformulation of dimensionality reduction combined with whitening. We confirm\nnumerically that the networks with learning rules derived from principled\nobjectives perform better than those with heuristic learning rules.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 03:16:19 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 23:02:09 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Pehlevan", "Cengiz", ""], ["Sengupta", "Anirvan", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "1703.07943", "submitter": "Haiping Huang", "authors": "Haiping Huang", "title": "Role of zero synapses in unsupervised feature learning", "comments": "6 pages, 4 figures, to appear in J. Phys A as a LETTER", "journal-ref": null, "doi": "10.1088/1751-8121/aaa631", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cond-mat.stat-mech cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synapses in real neural circuits can take discrete values, including zero\n(silent or potential) synapses. The computational role of zero synapses in\nunsupervised feature learning of unlabeled noisy data is still unclear, thus it\nis important to understand how the sparseness of synaptic activity is shaped\nduring learning and its relationship with receptive field formation. Here, we\nformulate this kind of sparse feature learning by a statistical mechanics\napproach. We find that learning decreases the fraction of zero synapses, and\nwhen the fraction decreases rapidly around a critical data size, an\nintrinsically structured receptive field starts to develop. Further increasing\nthe data size refines the receptive field, while a very small fraction of zero\nsynapses remain to act as contour detectors. This phenomenon is discovered not\nonly in learning a handwritten digits dataset, but also in learning retinal\nneural activity measured in a natural-movie-stimuli experiment.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 06:19:47 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 08:07:52 GMT"}, {"version": "v3", "created": "Wed, 12 Jul 2017 05:13:42 GMT"}, {"version": "v4", "created": "Wed, 10 Jan 2018 06:57:00 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Huang", "Haiping", ""]]}, {"id": "1703.07950", "submitter": "Shaked Shammah", "authors": "Shai Shalev-Shwartz and Ohad Shamir and Shaked Shammah", "title": "Failures of Gradient-Based Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Deep Learning has become the go-to solution for a broad\nrange of applications, often outperforming state-of-the-art. However, it is\nimportant, for both theoreticians and practitioners, to gain a deeper\nunderstanding of the difficulties and limitations associated with common\napproaches and algorithms. We describe four types of simple problems, for which\nthe gradient-based algorithms commonly used in deep learning either fail or\nsuffer from significant difficulties. We illustrate the failures through\npractical experiments, and provide theoretical insights explaining their\nsource, and how they might be remedied.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 07:16:37 GMT"}, {"version": "v2", "created": "Wed, 26 Apr 2017 05:23:26 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Shalev-Shwartz", "Shai", ""], ["Shamir", "Ohad", ""], ["Shammah", "Shaked", ""]]}, {"id": "1703.08033", "submitter": "Akshay Mehotra", "authors": "Akshay Mehrotra, Ambedkar Dukkipati", "title": "Generative Adversarial Residual Pairwise Networks for One Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks achieve unprecedented performance levels over many tasks\nand scale well with large quantities of data, but performance in the low-data\nregime and tasks like one shot learning still lags behind. While recent work\nsuggests many hypotheses from better optimization to more complicated network\nstructures, in this work we hypothesize that having a learnable and more\nexpressive similarity objective is an essential missing component. Towards\novercoming that, we propose a network design inspired by deep residual networks\nthat allows the efficient computation of this more expressive pairwise\nsimilarity objective. Further, we argue that regularization is key in learning\nwith small amounts of data, and propose an additional generator network based\non the Generative Adversarial Networks where the discriminator is our residual\npairwise network. This provides a strong regularizer by leveraging the\ngenerated data samples. The proposed model can generate plausible variations of\nexemplars over unseen classes and outperforms strong discriminative baselines\nfor few shot classification tasks. Notably, our residual pairwise network\ndesign outperforms previous state-of-theart on the challenging mini-Imagenet\ndataset for one shot learning by getting over 55% accuracy for the 5-way\nclassification task over unseen classes.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 12:19:09 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Mehrotra", "Akshay", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "1703.08481", "submitter": "W B Langdon", "authors": "W. B. Langdon", "title": "Long-Term Evolution of Genetic Programming Populations", "comments": "Longer version of Langdon:2017:GECCO, July 2017, ACM, Berlin,\n  RN/17/05\n  http://www.cs.ucl.ac.uk/fileadmin/UCL-CS/research/Research_Notes/RN_17_05.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evolve binary mux-6 trees for up to 100000 generations evolving some\nprograms with more than a hundred million nodes. Our unbounded Long-Term\nEvolution Experiment LTEE GP appears not to evolve building blocks but does\nsuggests a limit to bloat. We do see periods of tens even hundreds of\ngenerations where the population is 100 percent functionally converged. The\ndistribution of tree sizes is not as predicted by theory.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 15:53:03 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Langdon", "W. B.", ""]]}, {"id": "1703.08535", "submitter": "Michael Fenton", "authors": "Michael Fenton, James McDermott, David Fagan, Stefan Forstenlechner,\n  Michael O'Neill, Erik Hemberg", "title": "PonyGE2: Grammatical Evolution in Python", "comments": "8 pages, 4 figures, submitted to the 2017 GECCO Workshop on\n  Evolutionary Computation Software Systems (EvoSoft)", "journal-ref": "In Proceedings of GECCO '17 Companion, Berlin, Germany, July\n  15-19, 2017, 8 pages", "doi": "10.1145/3067695.3082469", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grammatical Evolution (GE) is a population-based evolutionary algorithm,\nwhere a formal grammar is used in the genotype to phenotype mapping process.\nPonyGE2 is an open source implementation of GE in Python, developed at UCD's\nNatural Computing Research and Applications group. It is intended as an\nadvertisement and a starting-point for those new to GE, a reference for\nstudents and researchers, a rapid-prototyping medium for our own experiments,\nand a Python workout. As well as providing the characteristic genotype to\nphenotype mapping of GE, a search algorithm engine is also provided. A number\nof sample problems and tutorials on how to use and adapt PonyGE2 have been\ndeveloped.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 17:50:28 GMT"}, {"version": "v2", "created": "Wed, 26 Apr 2017 16:37:41 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Fenton", "Michael", ""], ["McDermott", "James", ""], ["Fagan", "David", ""], ["Forstenlechner", "Stefan", ""], ["O'Neill", "Michael", ""], ["Hemberg", "Erik", ""]]}, {"id": "1703.08577", "submitter": "Jacob Schrum", "authors": "Alex C. Rollins and Jacob Schrum", "title": "Balancing Selection Pressures, Multiple Objectives, and Neural\n  Modularity to Coevolve Cooperative Agent Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research using evolutionary computation in Multi-Agent Systems\nindicates that assigning fitness based on team vs.\\ individual behavior has a\nstrong impact on the ability of evolved teams of artificial agents to exhibit\nteamwork in challenging tasks. However, such research only made use of\nsingle-objective evolution. In contrast, when a multiobjective evolutionary\nalgorithm is used, populations can be subject to individual-level objectives,\nteam-level objectives, or combinations of the two. This paper explores the\nperformance of cooperatively coevolved teams of agents controlled by artificial\nneural networks subject to these types of objectives. Specifically, predator\nagents are evolved to capture scripted prey agents in a torus-shaped grid\nworld. Because of the tension between individual and team behaviors, multiple\nmodes of behavior can be useful, and thus the effect of modular neural networks\nis also explored. Results demonstrate that fitness rewarding individual\nbehavior is superior to fitness rewarding team behavior, despite being applied\nto a cooperative task. However, the use of networks with multiple modules\nallows predators to discover intelligent behavior, regardless of which type of\nobjectives are used.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 19:27:51 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Rollins", "Alex C.", ""], ["Schrum", "Jacob", ""]]}, {"id": "1703.08705", "submitter": "Franck Dernoncourt", "authors": "Sebastian Gehrmann, Franck Dernoncourt, Yeran Li, Eric T. Carlson, Joy\n  T. Wu, Jonathan Welt, John Foote Jr., Edward T. Moseley, David W. Grant,\n  Patrick D. Tyler, Leo Anthony Celi", "title": "Comparing Rule-Based and Deep Learning Models for Patient Phenotyping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: We investigate whether deep learning techniques for natural\nlanguage processing (NLP) can be used efficiently for patient phenotyping.\nPatient phenotyping is a classification task for determining whether a patient\nhas a medical condition, and is a crucial part of secondary analysis of\nhealthcare data. We assess the performance of deep learning algorithms and\ncompare them with classical NLP approaches.\n  Materials and Methods: We compare convolutional neural networks (CNNs),\nn-gram models, and approaches based on cTAKES that extract pre-defined medical\nconcepts from clinical notes and use them to predict patient phenotypes. The\nperformance is tested on 10 different phenotyping tasks using 1,610 discharge\nsummaries extracted from the MIMIC-III database.\n  Results: CNNs outperform other phenotyping algorithms in all 10 tasks. The\naverage F1-score of our model is 76 (PPV of 83, and sensitivity of 71) with our\nmodel having an F1-score up to 37 points higher than alternative approaches. We\nadditionally assess the interpretability of our model by presenting a method\nthat extracts the most salient phrases for a particular prediction.\n  Conclusion: We show that NLP methods based on deep learning improve the\nperformance of patient phenotyping. Our CNN-based algorithm automatically\nlearns the phrases associated with each patient phenotype. As such, it reduces\nthe annotation complexity for clinical domain experts, who are normally\nrequired to develop task-specific annotation rules and identify relevant\nphrases. Our method performs well in terms of both performance and\ninterpretability, which indicates that deep learning is an effective approach\nto patient phenotyping based on clinicians' notes.\n", "versions": [{"version": "v1", "created": "Sat, 25 Mar 2017 15:37:09 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Gehrmann", "Sebastian", ""], ["Dernoncourt", "Franck", ""], ["Li", "Yeran", ""], ["Carlson", "Eric T.", ""], ["Wu", "Joy T.", ""], ["Welt", "Jonathan", ""], ["Foote", "John", "Jr."], ["Moseley", "Edward T.", ""], ["Grant", "David W.", ""], ["Tyler", "Patrick D.", ""], ["Celi", "Leo Anthony", ""]]}, {"id": "1703.08825", "submitter": "Ricardo Bessa Dr.", "authors": "Rui Pinto, Ricardo Bessa and Manuel Matos", "title": "Multi-Period Flexibility Forecast for Low Voltage Prosumers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near-future electric distribution grids operation will have to rely on\ndemand-side flexibility, both by implementation of demand response strategies\nand by taking advantage of the intelligent management of increasingly common\nsmall-scale energy storage. The Home energy management system (HEMS), installed\nat low voltage residential clients, will play a crucial role on the flexibility\nprovision to both system operators and market players like aggregators.\nModeling and forecasting multi-period flexibility from residential prosumers,\nsuch as battery storage and electric water heater, while complying with\ninternal constraints (comfort levels, data privacy) and uncertainty is a\ncomplex task. This papers describes a computational method that is capable of\nefficiently learn and define the feasibility flexibility space from\ncontrollable resources connected to a HEMS. An Evolutionary Particle Swarm\nOptimization (EPSO) algorithm is adopted and reshaped to derive a set of\nfeasible temporal trajectories for the residential net-load, considering\nstorage, flexible appliances, and predefined costumer preferences, as well as\nload and photovoltaic (PV) forecast uncertainty. A support vector data\ndescription (SVDD) algorithm is used to build models capable of classifying\nfeasible and non-feasible HEMS operating trajectories upon request from an\noptimization/control algorithm operated by a DSO or market player.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 15:26:34 GMT"}, {"version": "v2", "created": "Mon, 15 May 2017 22:05:54 GMT"}, {"version": "v3", "created": "Tue, 23 May 2017 11:19:47 GMT"}, {"version": "v4", "created": "Wed, 8 Nov 2017 17:28:50 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["Pinto", "Rui", ""], ["Bessa", "Ricardo", ""], ["Matos", "Manuel", ""]]}, {"id": "1703.09035", "submitter": "No\\'e Casas", "authors": "Noe Casas", "title": "Deep Deterministic Policy Gradient for Urban Traffic Light Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic light timing optimization is still an active line of research despite\nthe wealth of scientific literature on the topic, and the problem remains\nunsolved for any non-toy scenario. One of the key issues with traffic light\noptimization is the large scale of the input information that is available for\nthe controlling agent, namely all the traffic data that is continually sampled\nby the traffic detectors that cover the urban network. This issue has in the\npast forced researchers to focus on agents that work on localized parts of the\ntraffic network, typically on individual intersections, and to coordinate every\nindividual agent in a multi-agent setup. In order to overcome the large scale\nof the available state information, we propose to rely on the ability of deep\nLearning approaches to handle large input spaces, in the form of Deep\nDeterministic Policy Gradient (DDPG) algorithm. We performed several\nexperiments with a range of models, from the very simple one (one intersection)\nto the more complex one (a big city section).\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 12:40:14 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 15:15:51 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Casas", "Noe", ""]]}, {"id": "1703.09137", "submitter": "Marc Tanti", "authors": "Marc Tanti (1), Albert Gatt (1), Kenneth P. Camilleri (1) ((1)\n  University of Malta)", "title": "Where to put the Image in an Image Caption Generator", "comments": "Accepted in JNLE Special Issue: Language for Images (24.3) (expanded\n  with content that was removed from journal paper in order to reduce number of\n  pages), 28 pages, 5 figures, 6 tables", "journal-ref": null, "doi": "10.1017/S1351324918000098", "report-no": null, "categories": "cs.NE cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a recurrent neural network language model is used for caption\ngeneration, the image information can be fed to the neural network either by\ndirectly incorporating it in the RNN -- conditioning the language model by\n`injecting' image features -- or in a layer following the RNN -- conditioning\nthe language model by `merging' image features. While both options are attested\nin the literature, there is as yet no systematic comparison between the two. In\nthis paper we empirically show that it is not especially detrimental to\nperformance whether one architecture is used or another. The merge architecture\ndoes have practical advantages, as conditioning by merging allows the RNN's\nhidden state vector to shrink in size by up to four times. Our results suggest\nthat the visual and linguistic modalities for caption generation need not be\njointly encoded by the RNN as that yields large, memory-intensive models with\nfew tangible advantages in performance; rather, the multimodal integration\nshould be delayed to a subsequent stage.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 15:13:49 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2018 08:56:53 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Tanti", "Marc", ""], ["Gatt", "Albert", ""], ["Camilleri", "Kenneth P.", ""]]}, {"id": "1703.09387", "submitter": "Shumeet Baluja", "authors": "Shumeet Baluja, Ian Fischer", "title": "Adversarial Transformation Networks: Learning to Generate Adversarial\n  Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple different approaches of generating adversarial examples have been\nproposed to attack deep neural networks. These approaches involve either\ndirectly computing gradients with respect to the image pixels, or directly\nsolving an optimization on the image pixels. In this work, we present a\nfundamentally new method for generating adversarial examples that is fast to\nexecute and provides exceptional diversity of output. We efficiently train\nfeed-forward neural networks in a self-supervised manner to generate\nadversarial examples against a target network or set of networks. We call such\na network an Adversarial Transformation Network (ATN). ATNs are trained to\ngenerate adversarial examples that minimally modify the classifier's outputs\ngiven the original input, while constraining the new classification to match an\nadversarial target class. We present methods to train ATNs and analyze their\neffectiveness targeting a variety of MNIST classifiers as well as the latest\nstate-of-the-art ImageNet classifier Inception ResNet v2.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 03:24:33 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Baluja", "Shumeet", ""], ["Fischer", "Ian", ""]]}, {"id": "1703.09439", "submitter": "Phillip Keung", "authors": "Yichao Lu, Phillip Keung, Shaonan Zhang, Jason Sun, Vikas Bhardwaj", "title": "A practical approach to dialogue response generation in closed domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a prototype dialogue response generation model for the customer\nservice domain at Amazon. The model, which is trained in a weakly supervised\nfashion, measures the similarity between customer questions and agent answers\nusing a dual encoder network, a Siamese-like neural network architecture.\nAnswer templates are extracted from embeddings derived from past agent answers,\nwithout turn-by-turn annotations. Responses to customer inquiries are generated\nby selecting the best template from the final set of templates. We show that,\nin a closed domain like customer service, the selected templates cover $>$70\\%\nof past customer inquiries. Furthermore, the relevance of the model-selected\ntemplates is significantly higher than templates selected by a standard tf-idf\nbaseline.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 07:47:27 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Lu", "Yichao", ""], ["Keung", "Phillip", ""], ["Zhang", "Shaonan", ""], ["Sun", "Jason", ""], ["Bhardwaj", "Vikas", ""]]}, {"id": "1703.09452", "submitter": "Santiago Pascual De La Puente", "authors": "Santiago Pascual, Antonio Bonafonte, Joan Serr\\`a", "title": "SEGAN: Speech Enhancement Generative Adversarial Network", "comments": "5 pages, 4 figures, accepted in INTERSPEECH 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current speech enhancement techniques operate on the spectral domain and/or\nexploit some higher-level feature. The majority of them tackle a limited number\nof noise conditions and rely on first-order statistics. To circumvent these\nissues, deep networks are being increasingly used, thanks to their ability to\nlearn complex functions from large example sets. In this work, we propose the\nuse of generative adversarial networks for speech enhancement. In contrast to\ncurrent techniques, we operate at the waveform level, training the model\nend-to-end, and incorporate 28 speakers and 40 different noise conditions into\nthe same model, such that model parameters are shared across them. We evaluate\nthe proposed model using an independent, unseen test set with two speakers and\n20 alternative noise conditions. The enhanced samples confirm the viability of\nthe proposed model, and both objective and subjective evaluations confirm the\neffectiveness of it. With that, we open the exploration of generative\narchitectures for speech enhancement, which may progressively incorporate\nfurther speech-centric design choices to improve their performance.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 08:39:06 GMT"}, {"version": "v2", "created": "Fri, 21 Apr 2017 12:37:03 GMT"}, {"version": "v3", "created": "Fri, 9 Jun 2017 11:34:06 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Pascual", "Santiago", ""], ["Bonafonte", "Antonio", ""], ["Serr\u00e0", "Joan", ""]]}, {"id": "1703.09469", "submitter": "Andrzej Jaszkiewicz", "authors": "Mansoureh Aghabeig, Andrzej Jaszkiewicz", "title": "Experimental Analysis of Design Elements of Scalarizing Functions-based\n  Multiobjective Evolutionary Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we systematically study the importance, i.e., the influence on\nperformance, of the main design elements that differentiate scalarizing\nfunctions-based multiobjective evolutionary algorithms (MOEAs). This class of\nMOEAs includes Multiobjecitve Genetic Local Search (MOGLS) and Multiobjective\nEvolutionary Algorithm Based on Decomposition (MOEA/D) and proved to be very\nsuccessful in multiple computational experiments and practical applications.\nThe two algorithms share the same common structure and differ only in two main\naspects. Using three different multiobjective combinatorial optimization\nproblems, i.e., the multiobjective symmetric traveling salesperson problem, the\ntraveling salesperson problem with profits, and the multiobjective set covering\nproblem, we show that the main differentiating design element is the mechanism\nfor parent selection, while the selection of weight vectors, either random or\nuniformly distributed, is practically negligible if the number of uniform\nweight vectors is sufficiently large.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 09:17:07 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Aghabeig", "Mansoureh", ""], ["Jaszkiewicz", "Andrzej", ""]]}, {"id": "1703.09833", "submitter": "Qianli Liao", "authors": "Qianli Liao and Tomaso Poggio", "title": "Theory II: Landscape of the Empirical Risk in Deep Learning", "comments": "Merged figures to make the main text more compact. Moved some similar\n  figures to the appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous theoretical work on deep learning and neural network optimization\ntend to focus on avoiding saddle points and local minima. However, the\npractical observation is that, at least in the case of the most successful Deep\nConvolutional Neural Networks (DCNNs), practitioners can always increase the\nnetwork size to fit the training data (an extreme example would be [1]). The\nmost successful DCNNs such as VGG and ResNets are best used with a degree of\n\"overparametrization\". In this work, we characterize with a mix of theory and\nexperiments, the landscape of the empirical risk of overparametrized DCNNs. We\nfirst prove in the regression framework the existence of a large number of\ndegenerate global minimizers with zero empirical error (modulo inconsistent\nequations). The argument that relies on the use of Bezout theorem is rigorous\nwhen the RELUs are replaced by a polynomial nonlinearity (which empirically\nworks as well). As described in our Theory III [2] paper, the same minimizers\nare degenerate and thus very likely to be found by SGD that will furthermore\nselect with higher probability the most robust zero-minimizer. We further\nexperimentally explored and visualized the landscape of empirical risk of a\nDCNN on CIFAR-10 during the entire training process and especially the global\nminima. Finally, based on our theoretical and experimental results, we propose\nan intuitive model of the landscape of DCNN's empirical loss surface, which\nmight not be as complicated as people commonly believe.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 22:47:04 GMT"}, {"version": "v2", "created": "Thu, 22 Jun 2017 09:33:35 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Liao", "Qianli", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1703.09865", "submitter": "Shengcai Liu", "authors": "Shengcai Liu, Ke Tang and Xin Yao", "title": "Experience-based Optimization: A Coevolutionary Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies improving solvers based on their past solving experiences,\nand focuses on improving solvers by offline training. Specifically, the key\nissues of offline training methods are discussed, and research belonging to\nthis category but from different areas are reviewed in a unified framework.\nExisting training methods generally adopt a two-stage strategy in which\nselecting the training instances and training instances are treated in two\nindependent phases. This paper proposes a new training method, dubbed LiangYi,\nwhich addresses these two issues simultaneously. LiangYi includes a training\nmodule for a population-based solver and an instance sampling module for\nupdating the training instances. The idea behind LiangYi is to promote the\npopulation-based solver by training it (with the training module) to improve\nits performance on those instances (discovered by the sampling module) on which\nit performs badly, while keeping the good performances obtained by it on\nprevious instances. An instantiation of LiangYi on the Travelling Salesman\nProblem is also proposed. Empirical results on a huge testing set containing\n10000 instances showed LiangYi could train solvers that perform significantly\nbetter than the solvers trained by other state-of-the-art training method.\nMoreover, empirical investigation of the behaviours of LiangYi confirmed it was\nable to continuously improve the solver through training.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 02:51:46 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 07:26:06 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Liu", "Shengcai", ""], ["Tang", "Ke", ""], ["Yao", "Xin", ""]]}, {"id": "1703.09902", "submitter": "Albert Gatt", "authors": "Albert Gatt and Emiel Krahmer", "title": "Survey of the State of the Art in Natural Language Generation: Core\n  tasks, applications and evaluation", "comments": "Published in Journal of AI Research (JAIR), volume 61, pp 75-170. 118\n  pages, 8 figures, 1 table", "journal-ref": "Journal of AI Research, volume 60, 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper surveys the current state of the art in Natural Language\nGeneration (NLG), defined as the task of generating text or speech from\nnon-linguistic input. A survey of NLG is timely in view of the changes that the\nfield has undergone over the past decade or so, especially in relation to new\n(usually data-driven) methods, as well as new applications of NLG technology.\nThis survey therefore aims to (a) give an up-to-date synthesis of research on\nthe core tasks in NLG and the architectures adopted in which such tasks are\norganised; (b) highlight a number of relatively recent research topics that\nhave arisen partly as a result of growing synergies between NLG and other areas\nof artificial intelligence; (c) draw attention to the challenges in NLG\nevaluation, relating them to similar challenges faced in other areas of Natural\nLanguage Processing, with an emphasis on different evaluation methods and the\nrelationships between them.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 06:51:00 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 18:13:29 GMT"}, {"version": "v3", "created": "Tue, 19 Dec 2017 20:11:03 GMT"}, {"version": "v4", "created": "Mon, 29 Jan 2018 16:09:38 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Gatt", "Albert", ""], ["Krahmer", "Emiel", ""]]}, {"id": "1703.09926", "submitter": "Alexander Hagg", "authors": "Alexander Hagg", "title": "Hierarchical Surrogate Modeling for Illumination Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary illumination is a recent technique that allows producing many\ndiverse, optimal solutions in a map of manually defined features. To support\nthe large amount of objective function evaluations, surrogate model assistance\nwas recently introduced. Illumination models need to represent many more,\ndiverse optimal regions than classical surrogate models. In this PhD thesis, we\npropose to decompose the sample set, decreasing model complexity, by\nhierarchically segmenting the training set according to their coordinates in\nfeature space. An ensemble of diverse models can then be trained to serve as a\nsurrogate to illumination.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 08:10:26 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Hagg", "Alexander", ""]]}, {"id": "1703.10062", "submitter": "Sofia Ira Ktena", "authors": "Sofia Ira Ktena, Salim Arslan, Sarah Parisot, Daniel Rueckert", "title": "Exploring Heritability of Functional Brain Networks with Inexact Graph\n  Matching", "comments": "accepted at ISBI 2017: International Symposium on Biomedical Imaging,\n  Apr 2017, Melbourne, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven brain parcellations aim to provide a more accurate representation\nof an individual's functional connectivity, since they are able to capture\nindividual variability that arises due to development or disease. This renders\ncomparisons between the emerging brain connectivity networks more challenging,\nsince correspondences between their elements are not preserved. Unveiling these\ncorrespondences is of major importance to keep track of local functional\nconnectivity changes. We propose a novel method based on graph edit distance\nfor the comparison of brain graphs directly in their domain, that can\naccurately reflect similarities between individual networks while providing the\nnetwork element correspondences. This method is validated on a dataset of 116\ntwin subjects provided by the Human Connectome Project.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 14:24:52 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Ktena", "Sofia Ira", ""], ["Arslan", "Salim", ""], ["Parisot", "Sarah", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1703.10089", "submitter": "Yagmur Gizem Cinar", "authors": "Yagmur G. Cinar, Hamid Mirisaee, Parantapa Goswami, Eric Gaussier, Ali\n  Ait-Bachir, and Vadim Strijov", "title": "Position-based Content Attention for Time Series Forecasting with\n  Sequence-to-sequence RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose here an extended attention model for sequence-to-sequence\nrecurrent neural networks (RNNs) designed to capture (pseudo-)periods in time\nseries. This extended attention model can be deployed on top of any RNN and is\nshown to yield state-of-the-art performance for time series forecasting on\nseveral univariate and multivariate time series.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 15:11:16 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 12:36:58 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Cinar", "Yagmur G.", ""], ["Mirisaee", "Hamid", ""], ["Goswami", "Parantapa", ""], ["Gaussier", "Eric", ""], ["Ait-Bachir", "Ali", ""], ["Strijov", "Vadim", ""]]}, {"id": "1703.10356", "submitter": "Lior Fritz", "authors": "Lior Fritz, David Burshtein", "title": "Simplified End-to-End MMI Training and Voting for ASR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simplified speech recognition system that uses the maximum mutual\ninformation (MMI) criterion is considered. End-to-end training using gradient\ndescent is suggested, similarly to the training of connectionist temporal\nclassification (CTC). We use an MMI criterion with a simple language model in\nthe training stage, and a standard HMM decoder. Our method compares favorably\nto CTC in terms of performance, robustness, decoding time, disk footprint and\nquality of alignments. The good alignments enable the use of a straightforward\nensemble method, obtained by simply averaging the predictions of several neural\nnetwork models, that were trained separately end-to-end. The ensemble method\nyields a considerable reduction in the word error rate.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 08:40:19 GMT"}, {"version": "v2", "created": "Sun, 16 Jul 2017 15:12:39 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Fritz", "Lior", ""], ["Burshtein", "David", ""]]}, {"id": "1703.10371", "submitter": "Andrea Soltoggio", "authors": "Andrea Soltoggio, Kenneth O. Stanley, Sebastian Risi", "title": "Born to Learn: the Inspiration, Progress, and Future of Evolved Plastic\n  Artificial Neural Networks", "comments": null, "journal-ref": "Neural Networks, 2018", "doi": "10.1016/j.neunet.2018.07.013", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological plastic neural networks are systems of extraordinary computational\ncapabilities shaped by evolution, development, and lifetime learning. The\ninterplay of these elements leads to the emergence of adaptive behavior and\nintelligence. Inspired by such intricate natural phenomena, Evolved Plastic\nArtificial Neural Networks (EPANNs) use simulated evolution in-silico to breed\nplastic neural networks with a large variety of dynamics, architectures, and\nplasticity rules: these artificial systems are composed of inputs, outputs, and\nplastic components that change in response to experiences in an environment.\nThese systems may autonomously discover novel adaptive algorithms, and lead to\nhypotheses on the emergence of biological adaptation. EPANNs have seen\nconsiderable progress over the last two decades. Current scientific and\ntechnological advances in artificial neural networks are now setting the\nconditions for radically new approaches and results. In particular, the\nlimitations of hand-designed networks could be overcome by more flexible and\ninnovative solutions. This paper brings together a variety of inspiring ideas\nthat define the field of EPANNs. The main methods and results are reviewed.\nFinally, new opportunities and developments are presented.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 09:10:09 GMT"}, {"version": "v2", "created": "Wed, 6 Dec 2017 19:10:46 GMT"}, {"version": "v3", "created": "Wed, 8 Aug 2018 09:33:24 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Soltoggio", "Andrea", ""], ["Stanley", "Kenneth O.", ""], ["Risi", "Sebastian", ""]]}, {"id": "1703.10458", "submitter": "Abhinav Madahar", "authors": "Abhinav Madahar, Yuze Ma, and Kunal Patel", "title": "Application of a Shallow Neural Network to Short-Term Stock Trading", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning is increasingly prevalent in stock market trading. Though\nneural networks have seen success in computer vision and natural language\nprocessing, they have not been as useful in stock market trading. To\ndemonstrate the applicability of a neural network in stock trading, we made a\nsingle-layer neural network that recommends buying or selling shares of a stock\nby comparing the highest high of 10 consecutive days with that of the next 10\ndays, a process repeated for the stock's year-long historical data. A\nchi-squared analysis found that the neural network can accurately and\nappropriately decide whether to buy or sell shares for a given stock, showing\nthat a neural network can make simple decisions about the stock market.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 13:18:35 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Madahar", "Abhinav", ""], ["Ma", "Yuze", ""], ["Patel", "Kunal", ""]]}, {"id": "1703.10642", "submitter": "Hyungjun Kim", "authors": "Hyungjun Kim, Taesu Kim, Jinseok Kim and Jae-Joon Kim", "title": "Deep Neural Network Optimized to Resistive Memory with Nonlinear\n  Current-Voltage Characteristics", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Network computation relies on intensive vector-matrix\nmultiplications. Recently, the emerging nonvolatile memory (NVM) crossbar array\nshowed a feasibility of implementing such operations with high energy\nefficiency, thus there are many works on efficiently utilizing emerging NVM\ncrossbar array as analog vector-matrix multiplier. However, its nonlinear I-V\ncharacteristics restrain critical design parameters, such as the read voltage\nand weight range, resulting in substantial accuracy loss. In this paper,\ninstead of optimizing hardware parameters to a given neural network, we propose\na methodology of reconstructing a neural network itself optimized to resistive\nmemory crossbar arrays. To verify the validity of the proposed method, we\nsimulated various neural network with MNIST and CIFAR-10 dataset using two\ndifferent specific Resistive Random Access Memory (RRAM) model. Simulation\nresults show that our proposed neural network produces significantly higher\ninference accuracies than conventional neural network when the synapse devices\nhave nonlinear I-V characteristics.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 19:04:55 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Kim", "Hyungjun", ""], ["Kim", "Taesu", ""], ["Kim", "Jinseok", ""], ["Kim", "Jae-Joon", ""]]}, {"id": "1703.10722", "submitter": "Oleksii Kuchaiev", "authors": "Oleksii Kuchaiev, Boris Ginsburg", "title": "Factorization tricks for LSTM networks", "comments": "accepted to ICLR 2017 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two simple ways of reducing the number of parameters and\naccelerating the training of large Long Short-Term Memory (LSTM) networks: the\nfirst one is \"matrix factorization by design\" of LSTM matrix into the product\nof two smaller matrices, and the second one is partitioning of LSTM matrix, its\ninputs and states into the independent groups. Both approaches allow us to\ntrain large LSTM networks significantly faster to the near state-of the art\nperplexity while using significantly less RNN parameters.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 00:50:37 GMT"}, {"version": "v2", "created": "Thu, 4 May 2017 17:17:55 GMT"}, {"version": "v3", "created": "Sat, 24 Feb 2018 22:04:52 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Kuchaiev", "Oleksii", ""], ["Ginsburg", "Boris", ""]]}, {"id": "1703.10754", "submitter": "Gerard Howard", "authors": "Gerard David Howard", "title": "On Self-Adaptive Mutation Restarts for Evolutionary Robotics with Real\n  Rotorcraft", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-adaptive parameters are increasingly used in the field of Evolutionary\nRobotics, as they allow key evolutionary rates to vary autonomously in a\ncontext-sensitive manner throughout the optimisation process. A significant\nlimitation to self-adaptive mutation is that rates can be set unfavourably,\nwhich hinders convergence. Rate restarts are typically employed to remedy this,\nbut thus far have only been applied in Evolutionary Robotics for mutation-only\nalgorithms. This paper focuses on the level at which evolutionary rate restarts\nare applied in population-based algorithms with more than 1 evolutionary\noperator. After testing on a real hexacopter hovering task, we conclude that\nindividual-level restarting results in higher fitness solutions without fitness\nstagnation, and population restarts provide a more stable rate evolution.\nWithout restarts, experiments can become stuck in suboptimal controller/rate\ncombinations which can be difficult to escape from.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 04:24:37 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 00:37:36 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Howard", "Gerard David", ""]]}, {"id": "1703.10757", "submitter": "Zhiguang Wang", "authors": "Zhiguang Wang, Jianbo Yang", "title": "Diabetic Retinopathy Detection via Deep Convolutional Networks for\n  Discriminative Localization and Visual Explanation", "comments": "AAAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We proposed a deep learning method for interpretable diabetic retinopathy\n(DR) detection. The visual-interpretable feature of the proposed method is\nachieved by adding the regression activation map (RAM) after the global\naveraging pooling layer of the convolutional networks (CNN). With RAM, the\nproposed model can localize the discriminative regions of an retina image to\nshow the specific region of interest in terms of its severity level. We believe\nthis advantage of the proposed deep learning model is highly desired for DR\ndetection because in practice, users are not only interested with high\nprediction performance, but also keen to understand the insights of DR\ndetection and why the adopted learning model works. In the experiments\nconducted on a large scale of retina image dataset, we show that the proposed\nCNN model can achieve high performance on DR detection compared with the\nstate-of-the-art while achieving the merits of providing the RAM to highlight\nthe salient regions of the input image.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 05:10:56 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 16:44:23 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 22:05:07 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Wang", "Zhiguang", ""], ["Yang", "Jianbo", ""]]}]