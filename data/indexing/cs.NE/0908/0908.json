[{"id": "0908.0516", "submitter": "Juan J. Merelo Pr.", "authors": "Juan J. Merelo Guervos", "title": "Still doing evolutionary algorithms with Perl", "comments": "Corrected version of the paper published in YAPC::EU::2009, Corporate\n  Perl, pp 83-97", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Algorithm::Evolutionary (A::E from now on) was introduced in 2002, after a\ntalk in YAPC::EU in Munich. 7 years later, A::E is in its 0.67 version (past\nits \"number of the beast\" 0.666), and has been used extensively, to the point\nof being the foundation of much of the (computer) science being done by our\nresearch group (and, admittedly, not many others). All is not done, however;\nnow A::E is being integrated with POE so that evolutionary algorithms (EAs) can\nbe combined with all kinds of servers and used in client, servers, and anything\nin between. In this companion to the talk I will explain what evolutionary\nalgorithms are, what they are being used for, how to do them with Perl (using\nthese or other fine modules found in CPAN) and what evolutionary algorithms can\ndo for Perl at large.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2009 19:16:14 GMT"}], "update_date": "2009-08-11", "authors_parsed": [["Guervos", "Juan J. Merelo", ""]]}, {"id": "0908.1453", "submitter": "R Doomun", "authors": "Roya Asadi, Norwati Mustapha, Nasir Sulaiman", "title": "Training Process Reduction Based On Potential Weights Linear Analysis To\n  Accelarate Back Propagation Network", "comments": "11 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact factor 0.423", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 3, No. 1, July 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning is the important property of Back Propagation Network (BPN) and\nfinding the suitable weights and thresholds during training in order to improve\ntraining time as well as achieve high accuracy. Currently, data pre-processing\nsuch as dimension reduction input values and pre-training are the contributing\nfactors in developing efficient techniques for reducing training time with high\naccuracy and initialization of the weights is the important issue which is\nrandom and creates paradox, and leads to low accuracy with high training time.\nOne good data preprocessing technique for accelerating BPN classification is\ndimension reduction technique but it has problem of missing data. In this\npaper, we study current pre-training techniques and new preprocessing technique\ncalled Potential Weight Linear Analysis (PWLA) which combines normalization,\ndimension reduction input values and pre-training. In PWLA, the first data\npreprocessing is performed for generating normalized input values and then\napplying them by pre-training technique in order to obtain the potential\nweights. After these phases, dimension of input values matrix will be reduced\nby using real potential weights. For experiment results XOR problem and three\ndatasets, which are SPECT Heart, SPECTF Heart and Liver disorders (BUPA) will\nbe evaluated. Our results, however, will show that the new technique of PWLA\nwill change BPN to new Supervised Multi Layer Feed Forward Neural Network\n(SMFFNN) model with high accuracy in one epoch without training cycle. Also\nPWLA will be able to have power of non linear supervised and unsupervised\ndimension reduction property for applying by other supervised multi layer feed\nforward neural network model in future work.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2009 05:30:01 GMT"}], "update_date": "2009-08-12", "authors_parsed": [["Asadi", "Roya", ""], ["Mustapha", "Norwati", ""], ["Sulaiman", "Nasir", ""]]}, {"id": "0908.1597", "submitter": "George Kesidis", "authors": "George Kesidis", "title": "A quantum diffusion network", "comments": null, "journal-ref": null, "doi": null, "report-no": "Technical Report Number CSE 09-012", "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wong's diffusion network is a stochastic, zero-input Hopfield network with a\nGibbs stationary distribution over a bounded, connected continuum. Previously,\nlogarithmic thermal annealing was demonstrated for the diffusion network and\ndigital versions of it were studied and applied to imaging. Recently, \"quantum\"\nannealed Markov chains have garnered significant attention because of their\nimproved performance over \"pure\" thermal annealing. In this note, a joint\nquantum and thermal version of Wong's diffusion network is described and its\nconvergence properties are studied. Different choices for \"auxiliary\" functions\nare discussed, including those of the kinetic type previously associated with\nquantum annealing.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2009 23:45:08 GMT"}], "update_date": "2009-11-02", "authors_parsed": [["Kesidis", "George", ""]]}, {"id": "0908.3025", "submitter": "David Corne", "authors": "David Corne and Joshua Knowles", "title": "Techniques for Highly Multiobjective Optimisation: Some Nondominated\n  Points are Better than Others", "comments": "8 pages, 2 tables", "journal-ref": "in Hod Lipson (Ed.): Genetic and Evolutionary Computation\n  Conference, GECCO 2007, Proceedings, London, England, UK, July 7-11, 2007.\n  ACM 2007, pp. 773--780, ISBN 978-1-59593-697-4", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research area of evolutionary multiobjective optimization (EMO) is\nreaching better understandings of the properties and capabilities of EMO\nalgorithms, and accumulating much evidence of their worth in practical\nscenarios. An urgent emerging issue is that the favoured EMO algorithms scale\npoorly when problems have many (e.g. five or more) objectives. One of the chief\nreasons for this is believed to be that, in many-objective EMO search,\npopulations are likely to be largely composed of nondominated solutions. In\nturn, this means that the commonly-used algorithms cannot distinguish between\nthese for selective purposes. However, there are methods that can be used\nvalidly to rank points in a nondominated set, and may therefore usefully\nunderpin selection in EMO search. Here we discuss and compare several such\nmethods. Our main finding is that simple variants of the often-overlooked\nAverage Ranking strategy usually outperform other methods tested, covering\nproblems with 5-20 objectives and differing amounts of inter-objective\ncorrelation.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2009 21:44:32 GMT"}], "update_date": "2009-08-24", "authors_parsed": [["Corne", "David", ""], ["Knowles", "Joshua", ""]]}, {"id": "0908.3148", "submitter": "Subhash Kak", "authors": "Subhash Kak", "title": "Another Look at Quantum Neural Computing", "comments": "10 pages, 4 figures; Based on lecture given at Czech Technical\n  University, Prague on June 25, 2009. This revision adds clarifying remarks\n  and corrects typographical errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The term quantum neural computing indicates a unity in the functioning of the\nbrain. It assumes that the neural structures perform classical processing and\nthat the virtual particles associated with the dynamical states of the\nstructures define the underlying quantum state. We revisit the concept and also\nsummarize new arguments related to the learning modes of the brain in response\nto sensory input that may be aggregated in three types: associative,\nreorganizational, and quantum. The associative and reorganizational types are\nquite apparent based on experimental findings; it is much harder to establish\nthat the brain as an entity exhibits quantum properties. We argue that the\nreorganizational behavior of the brain may be viewed as inner adjustment\ncorresponding to its quantum behavior at the system level. Not only neural\nstructures but their higher abstractions also may be seen as whole entities. We\nconsider the dualities associated with the behavior of the brain and how these\ndualities are bridged.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2009 15:17:36 GMT"}, {"version": "v2", "created": "Thu, 14 Mar 2013 15:37:45 GMT"}], "update_date": "2013-03-15", "authors_parsed": [["Kak", "Subhash", ""]]}, {"id": "0908.3184", "submitter": "Krishna Lingashetty", "authors": "Krishna Chaithanya Lingashetty", "title": "Location of Single Neuron Memories in a Hebbian Network", "comments": "7 pages, 11 figures, Presented at the Conference on Theoretical and\n  Applied Computer Science 2009(TACS'09), Stillwater, Oklahoma. Corrected\n  results and formatting changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports the results of an experiment on the use of Kak's B-Matrix\napproach to spreading activity in a Hebbian neural network. Specifically, it\nconcentrates on the memory retrieval from single neurons and compares the\nperformance of the B-Matrix approach to that of the traditional approach.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2009 19:53:54 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2009 18:31:27 GMT"}], "update_date": "2009-11-19", "authors_parsed": [["Lingashetty", "Krishna Chaithanya", ""]]}, {"id": "0908.3610", "submitter": "Thimo Rohlf", "authors": "Thimo Rohlf and Christopher R. Winkler", "title": "Emergent Network Structure, evolvable Robustness and non-linear Effects\n  of Point Mutations in an Artificial Genome Model", "comments": null, "journal-ref": "Advances in Complex Systems, Vol. 12, pp. 293 - 310 (2009)", "doi": null, "report-no": null, "categories": "q-bio.MN cond-mat.dis-nn cs.NE q-bio.GN q-bio.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic regulation is a key component in development, but a clear\nunderstanding of the structure and dynamics of genetic networks is not yet at\nhand. In this paper we investigate these properties within an artificial genome\nmodel originally introduced by Reil (1999). We analyze statistical properties\nof randomly generated genomes both on the sequence- and network level, and show\nthat this model correctly predicts the frequency of genes in genomes as found\nin experimental data. Using an evolutionary algorithm based on stabilizing\nselection for a phenotype, we show that dynamical robustness against single\nbase mutations, as well as against random changes in initial states of\nregulatory dynamics that mimic stochastic fluctuations in environmental\nconditions, can emerge in parallel. Point mutations at the sequence level have\nstrongly non-linear effects on network wiring, including as well structurally\nneutral mutations and simultaneous rewiring of multiple connections, which\noccasionally lead to strong reorganization of the attractor landscape and\nmetastability of evolutionary dynamics. Evolved genomes exhibit characteristic\npatterns on both sequence and network level.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2009 12:44:43 GMT"}], "update_date": "2009-08-26", "authors_parsed": [["Rohlf", "Thimo", ""], ["Winkler", "Christopher R.", ""]]}, {"id": "0908.3706", "submitter": "Somak Raychaudhury", "authors": "Juan C. Cuevas-Tello, Peter Tino, Somak Raychaudhury, Xin Yao, Markus\n  Harva", "title": "Uncovering delayed patterns in noisy and irregularly sampled time\n  series: an astronomy application", "comments": "36 pages, 10 figures, 16 tables, accepted for publication in Pattern\n  Recognition. This is a shortened version of the article: interested readers\n  are urged to refer to the published version", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.CO astro-ph.IM cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the time delay between two signals\nrepresenting delayed, irregularly sampled and noisy versions of the same\nunderlying pattern. We propose and demonstrate an evolutionary algorithm for\nthe (hyper)parameter estimation of a kernel-based technique in the context of\nan astronomical problem, namely estimating the time delay between two\ngravitationally lensed signals from a distant quasar. Mixed types (integer and\nreal) are used to represent variables within the evolutionary algorithm. We\ntest the algorithm on several artificial data sets, and also on real\nastronomical observations of quasar Q0957+561. By carrying out a statistical\nanalysis of the results we present a detailed comparison of our method with the\nmost popular methods for time delay estimation in astrophysics. Our method\nyields more accurate and more stable time delay estimates: for Q0957+561, we\nobtain 419.6 days for the time delay between images A and B. Our methodology\ncan be readily applied to current state-of-the-art optical monitoring data in\nastronomy, but can also be applied in other disciplines involving similar time\nseries data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2009 23:21:39 GMT"}], "update_date": "2009-08-27", "authors_parsed": [["Cuevas-Tello", "Juan C.", ""], ["Tino", "Peter", ""], ["Raychaudhury", "Somak", ""], ["Yao", "Xin", ""], ["Harva", "Markus", ""]]}, {"id": "0908.3902", "submitter": "Harm Hollestelle", "authors": "Harm Hollestelle", "title": "On the Expressiveness of Line Drawings", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can expressiveness of a drawing be traced with a computer? In this study a\nneural network (perceptron) and a support vector machine are used to classify\nline drawings. To do this the line drawings are attributed values according to\na kinematic model and a diffusion model for the lines they consist of. The\nvalues for both models are related to looking times. Extreme values according\nto these models, that is both extremely short and extremely long looking times,\nare interpreted as indicating expressiveness. The results strongly indicate\nthat expressiveness in this sense can be detected, at least with a neural\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2009 20:34:50 GMT"}], "update_date": "2009-08-28", "authors_parsed": [["Hollestelle", "Harm", ""]]}]