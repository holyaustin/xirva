[{"id": "2006.00294", "submitter": "Johannes Lederer", "authors": "Mahsa Taheri and Fang Xie and Johannes Lederer", "title": "Statistical Guarantees for Regularized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have become standard tools in the analysis of data, but they\nlack comprehensive mathematical theories. For example, there are very few\nstatistical guarantees for learning neural networks from data, especially for\nclasses of estimators that are used in practice or at least similar to such. In\nthis paper, we develop a general statistical guarantee for estimators that\nconsist of a least-squares term and a regularizer. We then exemplify this\nguarantee with $\\ell_1$-regularization, showing that the corresponding\nprediction error increases at most sub-linearly in the number of layers and at\nmost logarithmically in the total number of parameters. Our results establish a\nmathematical basis for regularized estimation of neural networks, and they\ndeepen our mathematical understanding of neural networks and deep learning more\ngenerally.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2020 15:28:47 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 09:18:34 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Taheri", "Mahsa", ""], ["Xie", "Fang", ""], ["Lederer", "Johannes", ""]]}, {"id": "2006.00544", "submitter": "Junbo Zhao", "authors": "Xingyu Lei, Zhifang Yang, Juan Yu, Junbo Zhao, Qian Gao, Hongxin Yu", "title": "Data-driven Optimal Power Flow: A Physics-Informed Machine Learning\n  Approach", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NE cs.SY eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a data-driven approach for optimal power flow (OPF) based\non the stacked extreme learning machine (SELM) framework. SELM has a fast\ntraining speed and does not require the time-consuming parameter tuning process\ncompared with the deep learning algorithms. However, the direct application of\nSELM for OPF is not tractable due to the complicated relationship between the\nsystem operating status and the OPF solutions. To this end, a data-driven OPF\nregression framework is developed that decomposes the OPF model features into\nthree stages. This not only reduces the learning complexity but also helps\ncorrect the learning bias. A sample pre-classification strategy based on active\nconstraint identification is also developed to achieve enhanced feature\nattractions. Numerical results carried out on IEEE and Polish benchmark systems\ndemonstrate that the proposed method outperforms other alternatives. It is also\nshown that the proposed method can be easily extended to address different test\nsystems by adjusting only a few hyperparameters.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 15:41:24 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Lei", "Xingyu", ""], ["Yang", "Zhifang", ""], ["Yu", "Juan", ""], ["Zhao", "Junbo", ""], ["Gao", "Qian", ""], ["Yu", "Hongxin", ""]]}, {"id": "2006.00546", "submitter": "Junbo Zhao", "authors": "Di Cao, Junbo Zhao, Weihao Hu, Fei Ding, Qi Huang, Zhe Chen", "title": "Distributed Voltage Regulation of Active Distribution System Based on\n  Enhanced Multi-agent Deep Reinforcement Learning", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NE cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a data-driven distributed voltage control approach based\non the spectrum clustering and the enhanced multi-agent deep reinforcement\nlearning (MADRL) algorithm. Via the unsupervised clustering, the whole\ndistribution system can be decomposed into several sub-networks according to\nthe voltage and reactive power sensitivity. Then, the distributed control\nproblem of each sub-network is modeled as Markov games and solved by the\nenhanced MADRL algorithm, where each sub-network is modeled as an adaptive\nagent. Deep neural networks are used in each agent to approximate the policy\nfunction and the action value function. All agents are centrally trained to\nlearn the optimal coordinated voltage regulation strategy while executed in a\ndistributed manner to make decisions based on only local information. The\nproposed method can significantly reduce the requirements of communications and\nknowledge of system parameters. It also effectively deals with uncertainties\nand can provide online coordinated control based on the latest local\ninformation. Comparison results with other existing model-based and data-driven\nmethods on IEEE 33-bus and 123-bus systems demonstrate the effectiveness and\nbenefits of the proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 15:48:27 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Cao", "Di", ""], ["Zhao", "Junbo", ""], ["Hu", "Weihao", ""], ["Ding", "Fei", ""], ["Huang", "Qi", ""], ["Chen", "Zhe", ""]]}, {"id": "2006.00836", "submitter": "Markku Luotamo", "authors": "Markku Luotamo, Sari Mets\\\"am\\\"aki, Arto Klami", "title": "Multi-scale Cloud Detection in Remote Sensing Images using a Dual\n  Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": "10.1109/TGRS.2020.3015272", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Semantic segmentation by convolutional neural networks (CNN) has advanced the\nstate of the art in pixel-level classification of remote sensing images.\nHowever, processing large images typically requires analyzing the image in\nsmall patches, and hence features that have large spatial extent still cause\nchallenges in tasks such as cloud masking. To support a wider scale of spatial\nfeatures while simultaneously reducing computational requirements for large\nsatellite images, we propose an architecture of two cascaded CNN model\ncomponents successively processing undersampled and full resolution images. The\nfirst component distinguishes between patches in the inner cloud area from\npatches at the cloud's boundary region. For the cloud-ambiguous edge patches\nrequiring further segmentation, the framework then delegates computation to a\nfine-grained model component. We apply the architecture to a cloud detection\ndataset of complete Sentinel-2 multispectral images, approximately annotated\nfor minimal false negatives in a land use application. On this specific task\nand data, we achieve a 16\\% relative improvement in pixel accuracy over a CNN\nbaseline based on patching.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 10:27:42 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Luotamo", "Markku", ""], ["Mets\u00e4m\u00e4ki", "Sari", ""], ["Klami", "Arto", ""]]}, {"id": "2006.00917", "submitter": "Peter Hillmann", "authors": "Tobias Uhlig and Peter Hillmann and Oliver Rose", "title": "Evaluation of the general applicability of Dragoon for the k-center\n  problem", "comments": null, "journal-ref": "Winter Simulation Conference 2016", "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CC cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-center problem is a fundamental problem we often face when considering\ncomplex service systems. Typical challenges include the placement of warehouses\nin logistics or positioning of servers for content delivery networks. We\npreviously have proposed Dragoon as an effective algorithm to approach the\nk-center problem. This paper evaluates Dragoon with a focus on potential worst\ncase behavior in comparison to other techniques. We use an evolutionary\nalgorithm to generate instances of the k-center problem that are especially\nchallenging for Dragoon. Ultimately, our experiments confirm the previous good\nresults of Dragoon, however, we also can reliably find scenarios where it is\nclearly outperformed by other approaches.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2020 16:54:17 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Uhlig", "Tobias", ""], ["Hillmann", "Peter", ""], ["Rose", "Oliver", ""]]}, {"id": "2006.00939", "submitter": "Ashish Gupta", "authors": "Chepuri Shri Krishna, Ashish Gupta, Swarnim Narayan, Himanshu Rai, and\n  Diksha Manchanda", "title": "Hyperparameter optimization with REINFORCE and Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning has yielded promising results for Neural Architecture\nSearch (NAS). In this paper, we demonstrate how its performance can be improved\nby using a simplified Transformer block to model the policy network. The\nsimplified Transformer uses a 2-stream attention-based mechanism to model\nhyper-parameter dependencies while avoiding layer normalization and position\nencoding. We posit that this parsimonious design balances model complexity\nagainst expressiveness, making it suitable for discovering optimal\narchitectures in high-dimensional search spaces with limited exploration\nbudgets. We demonstrate how the algorithm's performance can be further improved\nby a) using an actor-critic style algorithm instead of plain vanilla policy\ngradient and b) ensembling Transformer blocks with shared parameters, each\nblock conditioned on a different auto-regressive factorization order. Our\nalgorithm works well as both a NAS and generic hyper-parameter optimization\n(HPO) algorithm: it outperformed most algorithms on NAS-Bench-101, a public\ndata-set for benchmarking NAS algorithms. In particular, it outperformed RL\nbased methods that use alternate architectures to model the policy network,\nunderlining the value of using attention-based networks in this setting. As a\ngeneric HPO algorithm, it outperformed Random Search in discovering more\naccurate multi-layer perceptron model architectures across 2 regression tasks.\nWe have adhered to guidelines listed in Lindauer and Hutter while designing\nexperiments and reporting results.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 13:35:48 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 02:27:48 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 07:38:20 GMT"}, {"version": "v4", "created": "Thu, 5 Nov 2020 04:55:03 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Krishna", "Chepuri Shri", ""], ["Gupta", "Ashish", ""], ["Narayan", "Swarnim", ""], ["Rai", "Himanshu", ""], ["Manchanda", "Diksha", ""]]}, {"id": "2006.01010", "submitter": "Zequn Wang", "authors": "Zequn Wang and Mingyang Li", "title": "Semi-supervised deep learning for high-dimensional uncertainty\n  quantification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional uncertainty quantification methods usually lacks the capability\nof dealing with high-dimensional problems due to the curse of dimensionality.\nThis paper presents a semi-supervised learning framework for dimension\nreduction and reliability analysis. An autoencoder is first adopted for mapping\nthe high-dimensional space into a low-dimensional latent space, which contains\na distinguishable failure surface. Then a deep feedforward neural network (DFN)\nis utilized to learn the mapping relationship and reconstruct the latent space,\nwhile the Gaussian process (GP) modeling technique is used to build the\nsurrogate model of the transformed limit state function. During the training\nprocess of the DFN, the discrepancy between the actual and reconstructed latent\nspace is minimized through semi-supervised learning for ensuring the accuracy.\nBoth labeled and unlabeled samples are utilized for defining the loss function\nof the DFN. Evolutionary algorithm is adopted to train the DFN, then the Monte\nCarlo simulation method is used for uncertainty quantification and reliability\nanalysis based on the proposed framework. The effectiveness is demonstrated\nthrough a mathematical example.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 15:15:42 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Wang", "Zequn", ""], ["Li", "Mingyang", ""]]}, {"id": "2006.01095", "submitter": "SueYeon Chung", "authors": "Jonathan Mamou, Hang Le, Miguel Del Rio, Cory Stephenson, Hanlin Tang,\n  Yoon Kim, SueYeon Chung", "title": "Emergence of Separable Manifolds in Deep Language Representations", "comments": "9 pages. 10 figures. Accepted to ICML 2020. Included supplemental\n  materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have shown much empirical success in solving\nperceptual tasks across various cognitive modalities. While they are only\nloosely inspired by the biological brain, recent studies report considerable\nsimilarities between representations extracted from task-optimized DNNs and\nneural populations in the brain. DNNs have subsequently become a popular model\nclass to infer computational principles underlying complex cognitive functions,\nand in turn, they have also emerged as a natural testbed for applying methods\noriginally developed to probe information in neural populations. In this work,\nwe utilize mean-field theoretic manifold analysis, a recent technique from\ncomputational neuroscience that connects geometry of feature representations\nwith linear separability of classes, to analyze language representations from\nlarge-scale contextual embedding models. We explore representations from\ndifferent model families (BERT, RoBERTa, GPT, etc.) and find evidence for\nemergence of linguistic manifolds across layer depth (e.g., manifolds for\npart-of-speech tags), especially in ambiguous data (i.e, words with multiple\npart-of-speech tags, or part-of-speech classes including many words). In\naddition, we find that the emergence of linear separability in these manifolds\nis driven by a combined reduction of manifolds' radius, dimensionality and\ninter-manifold correlations.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 17:23:44 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 21:45:07 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 20:56:06 GMT"}, {"version": "v4", "created": "Wed, 8 Jul 2020 22:10:19 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Mamou", "Jonathan", ""], ["Le", "Hang", ""], ["Del Rio", "Miguel", ""], ["Stephenson", "Cory", ""], ["Tang", "Hanlin", ""], ["Kim", "Yoon", ""], ["Chung", "SueYeon", ""]]}, {"id": "2006.01112", "submitter": "Yuntian Deng", "authors": "Yuntian Deng, Alexander M. Rush", "title": "Cascaded Text Generation with Markov Transformers", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two dominant approaches to neural text generation are fully\nautoregressive models, using serial beam search decoding, and\nnon-autoregressive models, using parallel decoding with no output dependencies.\nThis work proposes an autoregressive model with sub-linear parallel time\ngeneration. Noting that conditional random fields with bounded context can be\ndecoded in parallel, we propose an efficient cascaded decoding approach for\ngenerating high-quality output. To parameterize this cascade, we introduce a\nMarkov transformer, a variant of the popular fully autoregressive model that\nallows us to simultaneously decode with specific autoregressive context\ncutoffs. This approach requires only a small modification from standard\nautoregressive training, while showing competitive accuracy/speed tradeoff\ncompared to existing methods on five machine translation datasets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 17:52:15 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 05:26:19 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Deng", "Yuntian", ""], ["Rush", "Alexander M.", ""]]}, {"id": "2006.01415", "submitter": "Bao Trung Nguyen", "authors": "Isidro M. Alvarez, Trung B. Nguyen, Will N. Browne, Mengjie Zhang", "title": "A Layered Learning Approach to Scaling in Learning Classifier Systems\n  for Boolean Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning classifier systems (LCSs) originated from cognitive-science research\nbut migrated such that LCS became powerful classification techniques. Modern\nLCSs can be used to extract building blocks of knowledge to solve more\ndifficult problems in the same or a related domain. Recent works on LCSs showed\nthat the knowledge reuse through the adoption of Code Fragments, GP-like\ntree-based programs, into LCSs could provide advances in scaling. However,\nsince solving hard problems often requires constructing high-level building\nblocks, which also results in an intractable search space, a limit of scaling\nwill eventually be reached. Inspired by human problem-solving abilities, XCSCF*\ncan reuse learned knowledge and learned functionality to scale to complex\nproblems by transferring them from simpler problems using layered learning.\nHowever, this method was unrefined and suited to only the Multiplexer problem\ndomain. In this paper, we propose improvements to XCSCF* to enable it to be\nrobust across multiple problem domains. This is demonstrated on the benchmarks\nMultiplexer, Carry-one, Majority-on, and Even-parity domains. The required base\naxioms necessary for learning are proposed, methods for transfer learning in\nLCSs developed and learning recast as a decomposition into a series of\nsubordinate problems. Results show that from a conventional tabula rasa, with\nonly a vague notion of what subordinate problems might be relevant, it is\npossible to capture the general logic behind the tested domains, so the\nadvanced system is capable of solving any individual n-bit Multiplexer, n-bit\nCarry-one, n-bit Majority-on, or n-bit Even-parity problem.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 06:43:44 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Alvarez", "Isidro M.", ""], ["Nguyen", "Trung B.", ""], ["Browne", "Will N.", ""], ["Zhang", "Mengjie", ""]]}, {"id": "2006.01578", "submitter": "Michael Fairbank Dr", "authors": "Michael Fairbank, Spyridon Samothrakis and Luca Citi", "title": "Deep Learning in Target Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning uses neural networks which are parameterised by their weights.\nThe neural networks are usually trained by tuning the weights to directly\nminimise a given loss function. In this paper we propose to reparameterise the\nweights into targets for the firing strengths of the individual nodes in the\nnetwork. Given a set of targets, it is possible to calculate the weights which\nmake the firing strengths best meet those targets. It is argued that using\ntargets for training addresses the problem of exploding gradients, by a process\nwhich we call cascade untangling, and makes the loss-function surface smoother\nto traverse, and so leads to easier, faster training, and also potentially\nbetter generalisation, of the neural network. It also allows for easier\nlearning of deeper and recurrent network structures. The necessary conversion\nof targets to weights comes at an extra computational expense, which is in many\ncases manageable. Learning in target space can be combined with existing\nneural-network optimisers, for extra gain. Experimental results show the speed\nof using target space, and examples of improved generalisation, for\nfully-connected networks and convolutional networks, and the ability to recall\nand process long time sequences and perform natural-language processing with\nrecurrent networks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 13:06:41 GMT"}, {"version": "v2", "created": "Sat, 7 Nov 2020 11:09:30 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Fairbank", "Michael", ""], ["Samothrakis", "Spyridon", ""], ["Citi", "Luca", ""]]}, {"id": "2006.01681", "submitter": "Niklas Heim", "authors": "Niklas Heim, Tom\\'a\\v{s} Pevn\\'y, V\\'aclav \\v{S}m\\'idl", "title": "Neural Power Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional Neural Networks can approximate simple arithmetic operations,\nbut fail to generalize beyond the range of numbers that were seen during\ntraining. Neural Arithmetic Units aim to overcome this difficulty, but current\narithmetic units are either limited to operate on positive numbers or can only\nrepresent a subset of arithmetic operations. We introduce the Neural Power Unit\n(NPU) that operates on the full domain of real numbers and is capable of\nlearning arbitrary power functions in a single layer. The NPU thus fixes the\nshortcomings of existing arithmetic units and extends their expressivity. We\nachieve this by using complex arithmetic without requiring a conversion of the\nnetwork to complex numbers. A simplification of the unit to the RealNPU yields\na highly transparent model. We show that the NPUs outperform their competitors\nin terms of accuracy and sparsity on artificial arithmetic datasets, and that\nthe RealNPU can discover the governing equations of a dynamical system only\nfrom data.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 14:58:07 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 12:23:45 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 18:44:55 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 14:40:50 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Heim", "Niklas", ""], ["Pevn\u00fd", "Tom\u00e1\u0161", ""], ["\u0160m\u00eddl", "V\u00e1clav", ""]]}, {"id": "2006.01795", "submitter": "Marco Ancona", "authors": "Marco Ancona and Cengiz \\\"Oztireli and Markus Gross", "title": "Shapley Value as Principled Metric for Structured Network Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured pruning is a well-known technique to reduce the storage size and\ninference cost of neural networks. The usual pruning pipeline consists of\nranking the network internal filters and activations with respect to their\ncontributions to the network performance, removing the units with the lowest\ncontribution, and fine-tuning the network to reduce the harm induced by\npruning. Recent results showed that random pruning performs on par with other\nmetrics, given enough fine-tuning resources. In this work, we show that this is\nnot true on a low-data regime when fine-tuning is either not possible or not\neffective. In this case, reducing the harm caused by pruning becomes crucial to\nretain the performance of the network. First, we analyze the problem of\nestimating the contribution of hidden units with tools suggested by cooperative\ngame theory and propose Shapley values as a principled ranking metric for this\ntask. We compare with several alternatives proposed in the literature and\ndiscuss how Shapley values are theoretically preferable. Finally, we compare\nall ranking metrics on the challenging scenario of low-data pruning, where we\ndemonstrate how Shapley values outperform other heuristics.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 17:26:49 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Ancona", "Marco", ""], ["\u00d6ztireli", "Cengiz", ""], ["Gross", "Markus", ""]]}, {"id": "2006.01981", "submitter": "Benjamin Scellier", "authors": "Jack Kendall, Ross Pantone, Kalpana Manickavasagam, Yoshua Bengio,\n  Benjamin Scellier", "title": "Training End-to-End Analog Neural Networks with Equilibrium Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a principled method to train end-to-end analog neural networks\nby stochastic gradient descent. In these analog neural networks, the weights to\nbe adjusted are implemented by the conductances of programmable resistive\ndevices such as memristors [Chua, 1971], and the nonlinear transfer functions\n(or `activation functions') are implemented by nonlinear components such as\ndiodes. We show mathematically that a class of analog neural networks (called\nnonlinear resistive networks) are energy-based models: they possess an energy\nfunction as a consequence of Kirchhoff's laws governing electrical circuits.\nThis property enables us to train them using the Equilibrium Propagation\nframework [Scellier and Bengio, 2017]. Our update rule for each conductance,\nwhich is local and relies solely on the voltage drop across the corresponding\nresistor, is shown to compute the gradient of the loss function. Our numerical\nsimulations, which use the SPICE-based Spectre simulation framework to simulate\nthe dynamics of electrical circuits, demonstrate training on the MNIST\nclassification task, performing comparably or better than equivalent-size\nsoftware-based neural networks. Our work can guide the development of a new\ngeneration of ultra-fast, compact and low-power neural networks supporting\non-chip learning.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 23:38:35 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 22:26:05 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Kendall", "Jack", ""], ["Pantone", "Ross", ""], ["Manickavasagam", "Kalpana", ""], ["Bengio", "Yoshua", ""], ["Scellier", "Benjamin", ""]]}, {"id": "2006.02003", "submitter": "Alexander Cao", "authors": "Alexander Cao, Yuan Luo, Diego Klabjan", "title": "Open-Set Recognition with Gaussian Mixture Variational Autoencoders", "comments": "12 pages including 8 figures and 4 tables, plus 6 pages of\n  supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In inference, open-set classification is to either classify a sample into a\nknown class from training or reject it as an unknown class. Existing deep\nopen-set classifiers train explicit closed-set classifiers, in some cases\ndisjointly utilizing reconstruction, which we find dilutes the latent\nrepresentation's ability to distinguish unknown classes. In contrast, we train\nour model to cooperatively learn reconstruction and perform class-based\nclustering in the latent space. With this, our Gaussian mixture variational\nautoencoder (GMVAE) achieves more accurate and robust open-set classification\nresults, with an average F1 improvement of 29.5%, through extensive experiments\naided by analytical results.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 01:15:19 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Cao", "Alexander", ""], ["Luo", "Yuan", ""], ["Klabjan", "Diego", ""]]}, {"id": "2006.02006", "submitter": "Chase Smith", "authors": "Chase Smith, Alex Rusnak", "title": "Proximity-based Networking: Small world overlays optimized with particle\n  swarm optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information dissemination is a fundamental and frequently occurring problem\nin large, dynamic, distributed systems. In order to solve this, there has been\nan increased interest in creating efficient overlay networks that can maintain\ndecentralized peer-to-peer networks. Within these overlay networks nodes take\nthe patterns of small world networks, whose connections are based on proximity.\nThese small-world systems can be incredibly useful in the dissemination and\nlookup of information within an internet network. The data can be efficiently\ntransferred and routing with minimal information loss through forward error\ncorrect (FEC) and the User Datagram Protocol (UDP). We propose a networking\nscheme that incorporates geographic location in chord for the organization of\npeers within each node's partitioned key space. When we combine this with a\nproximity-based neighborhood set {based on the small world structure} we can\nmimic the efficient of solutions designed to solve traditional small-world\nproblems, with the additional benefit of resilience and fault-tolerance.\nFurthermore, the routing and address book can be updated based on the\nneighborhood requirements. The flexibility of our proposed schemes enables a\nvariety of swarm models, and agents. This enables our network to as an\nunderlying networking model that can be applied to file-sharing, streaming, and\nsynchronization of networks.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 01:40:46 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 00:07:12 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Smith", "Chase", ""], ["Rusnak", "Alex", ""]]}, {"id": "2006.02049", "submitter": "Xiaoliang Dai", "authors": "Xiaoliang Dai, Alvin Wan, Peizhao Zhang, Bichen Wu, Zijian He, Zhen\n  Wei, Kan Chen, Yuandong Tian, Matthew Yu, Peter Vajda, Joseph E. Gonzalez", "title": "FBNetV3: Joint Architecture-Recipe Search using Predictor Pretraining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) yields state-of-the-art neural networks that\noutperform their best manually-designed counterparts. However, previous NAS\nmethods search for architectures under one set of training hyper-parameters\n(i.e., a training recipe), overlooking superior architecture-recipe\ncombinations. To address this, we present Neural Architecture-Recipe Search\n(NARS) to search both (a) architectures and (b) their corresponding training\nrecipes, simultaneously. NARS utilizes an accuracy predictor that scores\narchitecture and training recipes jointly, guiding both sample selection and\nranking. Furthermore, to compensate for the enlarged search space, we leverage\n\"free\" architecture statistics (e.g., FLOP count) to pretrain the predictor,\nsignificantly improving its sample efficiency and prediction reliability. After\ntraining the predictor via constrained iterative optimization, we run fast\nevolutionary searches in just CPU minutes to generate architecture-recipe pairs\nfor a variety of resource constraints, called FBNetV3. FBNetV3 makes up a\nfamily of state-of-the-art compact neural networks that outperform both\nautomatically and manually-designed competitors. For example, FBNetV3 matches\nboth EfficientNet and ResNeSt accuracy on ImageNet with up to 2.0x and 7.1x\nfewer FLOPs, respectively. Furthermore, FBNetV3 yields significant performance\ngains for downstream object detection tasks, improving mAP despite 18% fewer\nFLOPs and 34% fewer parameters than EfficientNet-based equivalents.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 05:20:21 GMT"}, {"version": "v2", "created": "Sun, 7 Jun 2020 02:38:18 GMT"}, {"version": "v3", "created": "Tue, 30 Mar 2021 14:54:08 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Dai", "Xiaoliang", ""], ["Wan", "Alvin", ""], ["Zhang", "Peizhao", ""], ["Wu", "Bichen", ""], ["He", "Zijian", ""], ["Wei", "Zhen", ""], ["Chen", "Kan", ""], ["Tian", "Yuandong", ""], ["Yu", "Matthew", ""], ["Vajda", "Peter", ""], ["Gonzalez", "Joseph E.", ""]]}, {"id": "2006.02231", "submitter": "Suranga Seneviratne", "authors": "Naveen Karunanayake, Jathushan Rajasegaran, Ashanie Gunathillake,\n  Suranga Seneviratne, Guillaume Jourjon", "title": "A Multi-modal Neural Embeddings Approach for Detecting Mobile\n  Counterfeit Apps: A Case Study on Google Play Store", "comments": "arXiv admin note: substantial text overlap with arXiv:1804.09882", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfeit apps impersonate existing popular apps in attempts to misguide\nusers to install them for various reasons such as collecting personal\ninformation or spreading malware. Many counterfeits can be identified once\ninstalled, however even a tech-savvy user may struggle to detect them before\ninstallation. To this end, this paper proposes to leverage the recent advances\nin deep learning methods to create image and text embeddings so that\ncounterfeit apps can be efficiently identified when they are submitted for\npublication. We show that a novel approach of combining content embeddings and\nstyle embeddings outperforms the baseline methods for image similarity such as\nSIFT, SURF, and various image hashing methods. We first evaluate the\nperformance of the proposed method on two well-known datasets for evaluating\nimage similarity methods and show that content, style, and combined embeddings\nincrease precision@k and recall@k by 10%-15% and 12%-25%, respectively when\nretrieving five nearest neighbours. Second, specifically for the app\ncounterfeit detection problem, combined content and style embeddings achieve\n12% and 14% increase in precision@k and recall@k, respectively compared to the\nbaseline methods. Third, we present an analysis of approximately 1.2 million\napps from Google Play Store and identify a set of potential counterfeits for\ntop-10,000 popular apps. Under a conservative assumption, we were able to find\n2,040 potential counterfeits that contain malware in a set of 49,608 apps that\nshowed high similarity to one of the top-10,000 popular apps in Google Play\nStore. We also find 1,565 potential counterfeits asking for at least five\nadditional dangerous permissions than the original app and 1,407 potential\ncounterfeits having at least five extra third party advertisement libraries.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 07:10:21 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Karunanayake", "Naveen", ""], ["Rajasegaran", "Jathushan", ""], ["Gunathillake", "Ashanie", ""], ["Seneviratne", "Suranga", ""], ["Jourjon", "Guillaume", ""]]}, {"id": "2006.02267", "submitter": "Junaid Malik", "authors": "Junaid Malik, Serkan Kiranyaz and Moncef Gabbouj", "title": "FastONN -- Python based open-source GPU implementation for Operational\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Operational Neural Networks (ONNs) have recently been proposed as a special\nclass of artificial neural networks for grid structured data. They enable\nheterogenous non-linear operations to generalize the widely adopted\nconvolution-based neuron model. This work introduces a fast GPU-enabled library\nfor training operational neural networks, FastONN, which is based on a novel\nvectorized formulation of the operational neurons. Leveraging on automatic\nreverse-mode differentiation for backpropagation, FastONN enables increased\nflexibility with the incorporation of new operator sets and customized gradient\nflows. Additionally, bundled auxiliary modules offer interfaces for performance\ntracking and checkpointing across different data partitions and customized\nmetrics.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 13:33:35 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Malik", "Junaid", ""], ["Kiranyaz", "Serkan", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "2006.02341", "submitter": "Anastasis Kratsios", "authors": "Anastasis Kratsios, Eugene Bilokopytov", "title": "Non-Euclidean Universal Approximation", "comments": "21 Pages", "journal-ref": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2020)", "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.DG math.GN stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modifications to a neural network's input and output layers are often\nrequired to accommodate the specificities of most practical learning tasks.\nHowever, the impact of such changes on architecture's approximation\ncapabilities is largely not understood. We present general conditions\ndescribing feature and readout maps that preserve an architecture's ability to\napproximate any continuous functions uniformly on compacts. As an application,\nwe show that if an architecture is capable of universal approximation, then\nmodifying its final layer to produce binary values creates a new architecture\ncapable of deterministically approximating any classifier. In particular, we\nobtain guarantees for deep CNNs and deep feed-forward networks. Our results\nalso have consequences within the scope of geometric deep learning.\nSpecifically, when the input and output spaces are Cartan-Hadamard manifolds,\nwe obtain geometrically meaningful feature and readout maps satisfying our\ncriteria. Consequently, commonly used non-Euclidean regression models between\nspaces of symmetric positive definite matrices are extended to universal DNNs.\nThe same result allows us to show that the hyperbolic feed-forward networks,\nused for hierarchical learning, are universal. Our result is also used to show\nthat the common practice of randomizing all but the last two layers of a DNN\nproduces a universal family of functions with probability one. We also provide\nconditions on a DNN's first (resp. last) few layer's connections and activation\nfunction which guarantee that these layers can have a width equal to the input\n(resp. output) space's dimension while not negatively affecting the\narchitecture's approximation capabilities.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 15:38:57 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 10:01:48 GMT"}, {"version": "v3", "created": "Sat, 7 Nov 2020 15:40:00 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Kratsios", "Anastasis", ""], ["Bilokopytov", "Eugene", ""]]}, {"id": "2006.02348", "submitter": "Venkata Devesh Reddy Seethi", "authors": "Venkata Devesh Reddy Seethi, Pratool Bharti", "title": "CNN-based Speed Detection Algorithm for Walking and Running using\n  Wrist-worn Wearable Sensors", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there have been a surge in ubiquitous technologies such as\nsmartwatches and fitness trackers that can track the human physical activities\neffortlessly. These devices have enabled common citizens to track their\nphysical fitness and encourage them to lead a healthy lifestyle. Among various\nexercises, walking and running are the most common ones people do in everyday\nlife, either through commute, exercise, or doing household chores. If done at\nthe right intensity, walking and running are sufficient enough to help\nindividual reach the fitness and weight-loss goals. Therefore, it is important\nto measure walking/ running speed to estimate the burned calories along with\npreventing them from the risk of soreness, injury, and burnout. Existing\nwearable technologies use GPS sensor to measure the speed which is highly\nenergy inefficient and does not work well indoors. In this paper, we design,\nimplement and evaluate a convolutional neural network based algorithm that\nleverages accelerometer and gyroscope sensory data from the wrist-worn device\nto detect the speed with high precision. Data from $15$ participants were\ncollected while they were walking/running at different speeds on a treadmill.\nOur speed detection algorithm achieved $4.2\\%$ and $9.8\\%$ MAPE (Mean Absolute\nError Percentage) value using $70-15-15$ train-test-evaluation split and\nleave-one-out cross-validation evaluation strategy respectively.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 15:53:46 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Seethi", "Venkata Devesh Reddy", ""], ["Bharti", "Pratool", ""]]}, {"id": "2006.02361", "submitter": "Akshunna S. Dogra", "authors": "Akshunna S. Dogra, William T Redman", "title": "Optimizing Neural Networks via Koopman Operator Theory", "comments": "11 main content pages (7 supplementary pages), 3 main content figures\n  (3 supplementary figures), 2 main content Tables (5 supplementary Tables).\n  34th Conference on Neural Information Processing Systems (NeurIPS 2020),\n  Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE eess.SP math.DS physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Koopman operator theory, a powerful framework for discovering the underlying\ndynamics of nonlinear dynamical systems, was recently shown to be intimately\nconnected with neural network training. In this work, we take the first steps\nin making use of this connection. As Koopman operator theory is a linear\ntheory, a successful implementation of it in evolving network weights and\nbiases offers the promise of accelerated training, especially in the context of\ndeep networks, where optimization is inherently a non-convex problem. We show\nthat Koopman operator theoretic methods allow for accurate predictions of\nweights and biases of feedforward, fully connected deep networks over a\nnon-trivial range of training time. During this window, we find that our\napproach is >10x faster than various gradient descent based methods (e.g. Adam,\nAdadelta, Adagrad), in line with our complexity analysis. We end by\nhighlighting open questions in this exciting intersection between dynamical\nsystems and neural network theory. We highlight additional methods by which our\nresults could be expanded to broader classes of networks and larger training\nintervals, which shall be the focus of future work.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 16:23:07 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 18:34:09 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 03:48:46 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Dogra", "Akshunna S.", ""], ["Redman", "William T", ""]]}, {"id": "2006.02505", "submitter": "Josep L. Rossello", "authors": "Christian F. Frasser, Carola de Benito, Vincent Canals, Miquel Roca,\n  Pedro J. Ballester and Josep L. Rossello", "title": "Stochastic-based Neural Network hardware acceleration for an efficient\n  ligand-based virtual screening", "comments": "14 pages, 9 Figures, 3 Tables. Paper submitted to an IEEE journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks (ANN) have been popularized in many science and\ntechnological areas due to their capacity to solve many complex pattern\nmatching problems. That is the case of Virtual Screening, a research area that\nstudies how to identify those molecular compounds with the highest probability\nto present biological activity for a therapeutic target. Due to the vast number\nof small organic compounds and the thousands of targets for which such\nlarge-scale screening can potentially be carried out, there has been an\nincreasing interest in the research community to increase both, processing\nspeed and energy efficiency in the screening of molecular databases. In this\nwork, we present a classification model describing each molecule with a single\nenergy-based vector and propose a machine-learning system based on the use of\nANNs. Different ANNs are studied with respect to their suitability to identify\nbiochemical similarities. Also, a high-performance and energy-efficient\nhardware acceleration platform based on the use of stochastic computing is\nproposed for the ANN implementation. This platform is of utility when screening\nvast libraries of compounds. As a result, the proposed model showed appreciable\nimprovements with respect previously published works in terms of the main\nrelevant characteristics (accuracy, speed and energy-efficiency).\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 20:18:15 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Frasser", "Christian F.", ""], ["de Benito", "Carola", ""], ["Canals", "Vincent", ""], ["Roca", "Miquel", ""], ["Ballester", "Pedro J.", ""], ["Rossello", "Josep L.", ""]]}, {"id": "2006.02591", "submitter": "Tae Jong Choi", "authors": "Tae Jong Choi and Chang Wook Ahn", "title": "An Improved LSHADE-RSP Algorithm with the Cauchy Perturbation:\n  iLSHADE-RSP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new method for improving the optimization performance of a state-of-the-art\ndifferential evolution (DE) variant is proposed in this paper. The technique\ncan increase the exploration by adopting the long-tailed property of the Cauchy\ndistribution, which helps the algorithm to generate a trial vector with great\ndiversity. Compared to the previous approaches, the proposed approach perturbs\na target vector instead of a mutant vector based on a jumping rate. We applied\nthe proposed approach to LSHADE-RSP ranked second place in the CEC 2018\ncompetition on single objective real-valued optimization. A set of 30 different\nand difficult optimization problems is used to evaluate the optimization\nperformance of the improved LSHADE-RSP. Our experimental results verify that\nthe improved LSHADE-RSP significantly outperformed not only its predecessor\nLSHADE-RSP but also several cutting-edge DE variants in terms of convergence\nspeed and solution accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 00:03:34 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Choi", "Tae Jong", ""], ["Ahn", "Chang Wook", ""]]}, {"id": "2006.02628", "submitter": "Monalisa Pal", "authors": "Monalisa Pal and Sanghamitra Bandyopadhyay", "title": "Decomposition in Decision and Objective Space for Multi-Modal\n  Multi-Objective Optimization", "comments": "Please visit\n  https://www.sciencedirect.com/science/article/abs/pii/S2210650221000031 or\n  https://doi.org/10.1016/j.swevo.2021.100842", "journal-ref": "Swarm and Evolutionary Computation, 100842 (2021)", "doi": "10.1016/j.swevo.2021.100842", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-modal multi-objective optimization problems (MMMOPs) have multiple\nsubsets within the Pareto-optimal Set, each independently mapping to the same\nPareto-Front. Prevalent multi-objective evolutionary algorithms are not purely\ndesigned to search for multiple solution subsets, whereas, algorithms designed\nfor MMMOPs demonstrate degraded performance in the objective space. This\nmotivates the design of better algorithms for addressing MMMOPs. The present\nwork identifies the crowding illusion problem originating from using crowding\ndistance globally over the entire decision space. Subsequently, an evolutionary\nframework, called graph Laplacian based Optimization using Reference vector\nassisted Decomposition (LORD), is proposed, which uses decomposition in both\nobjective and decision space for dealing with MMMOPs. Its filtering step is\nfurther extended to present LORD-II algorithm, which demonstrates its dynamics\non multi-modal many-objective problems. The efficacies of the frameworks are\nestablished by comparing their performance on test instances from the CEC 2019\nmulti-modal multi-objective test suite and polygon problems with the\nstate-of-the-art algorithms for MMMOPs and other multi- and many-objective\nevolutionary algorithms. The manuscript is concluded by mentioning the\nlimitations of the proposed frameworks and future directions to design still\nbetter algorithms for MMMOPs. The source code is available at\nhttps://worksupplements.droppages.com/lord.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 03:18:47 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 08:23:37 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 16:01:04 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Pal", "Monalisa", ""], ["Bandyopadhyay", "Sanghamitra", ""]]}, {"id": "2006.02642", "submitter": "Jinseok Kim", "authors": "Jinseok Kim, Kyungsu Kim, Jae-Joon Kim", "title": "Unifying Activation- and Timing-based Learning Rules for Spiking Neural\n  Networks", "comments": "To be published in NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the gradient computation across the time domain in Spiking Neural\nNetworks (SNNs) training, two different approaches have been independently\nstudied. The first is to compute the gradients with respect to the change in\nspike activation (activation-based methods), and the second is to compute the\ngradients with respect to the change in spike timing (timing-based methods). In\nthis work, we present a comparative study of the two methods and propose a new\nsupervised learning method that combines them. The proposed method utilizes\neach individual spike more effectively by shifting spike timings as in the\ntiming-based methods as well as generating and removing spikes as in the\nactivation-based methods. Experimental results showed that the proposed method\nachieves higher performance in terms of both accuracy and efficiency than the\nprevious approaches.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 04:47:01 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 00:44:38 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Kim", "Jinseok", ""], ["Kim", "Kyungsu", ""], ["Kim", "Jae-Joon", ""]]}, {"id": "2006.02655", "submitter": "AbdElRahman ElSaid", "authors": "AbdElRahman ElSaid, Joshua Karns, Alexander Ororbia II, Daniel Krutz,\n  Zimeng Lyu, Travis Desell", "title": "Neuroevolutionary Transfer Learning of Deep Recurrent Neural Networks\n  through Network-Aware Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning entails taking an artificial neural network (ANN) that is\ntrained on a source dataset and adapting it to a new target dataset. While this\nhas been shown to be quite powerful, its use has generally been restricted by\narchitectural constraints. Previously, in order to reuse and adapt an ANN's\ninternal weights and structure, the underlying topology of the ANN being\ntransferred across tasks must remain mostly the same while a new output layer\nis attached, discarding the old output layer's weights. This work introduces\nnetwork-aware adaptive structure transfer learning (N-ASTL), an advancement\nover prior efforts to remove this restriction. N-ASTL utilizes statistical\ninformation related to the source network's topology and weight distribution in\norder to inform how new input and output neurons are to be integrated into the\nexisting structure. Results show improvements over prior state-of-the-art,\nincluding the ability to transfer in challenging real-world datasets not\npreviously possible and improved generalization over RNNs trained without\ntransfer.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 06:07:30 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["ElSaid", "AbdElRahman", ""], ["Karns", "Joshua", ""], ["Ororbia", "Alexander", "II"], ["Krutz", "Daniel", ""], ["Lyu", "Zimeng", ""], ["Desell", "Travis", ""]]}, {"id": "2006.02716", "submitter": "Alexandr Grichshenko", "authors": "Alexandr Grichshenko, Luiz Jonata Pires de Araujo, Susanna Gimaeva,\n  Joseph Alexander Brown", "title": "Using Tabu Search Algorithm for Map Generation in the Terra Mystica\n  Tabletop Game", "comments": null, "journal-ref": "ISMSI '20: Proceedings of the 2020 4th International Conference on\n  Intelligent Systems, Metaheuristics & Swarm Intelligence", "doi": "10.1145/3396474.3396492", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tabu Search (TS) metaheuristic improves simple local search algorithms (e.g.\nsteepest ascend hill-climbing) by enabling the algorithm to escape local optima\npoints. It has shown to be useful for addressing several combinatorial\noptimization problems. This paper investigates the performance of TS and\nconsiders the effects of the size of the Tabu list and the size of the\nneighbourhood for a procedural content generation, specifically the generation\nof maps for a popular tabletop game called Terra Mystica. The results validate\nthe feasibility of the proposed method and how it can be used to generate maps\nthat improve existing maps for the game.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 09:15:46 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Grichshenko", "Alexandr", ""], ["de Araujo", "Luiz Jonata Pires", ""], ["Gimaeva", "Susanna", ""], ["Brown", "Joseph Alexander", ""]]}, {"id": "2006.02797", "submitter": "Vijay Pandey", "authors": "Vijay Pandey", "title": "Overcoming Overfitting and Large Weight Update Problem in Linear\n  Rectifiers: Thresholded Exponential Rectified Linear Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In past few years, linear rectified unit activation functions have shown its\nsignificance in the neural networks, surpassing the performance of sigmoid\nactivations. RELU (Nair & Hinton, 2010), ELU (Clevert et al., 2015), PRELU (He\net al., 2015), LRELU (Maas et al., 2013), SRELU (Jin et al., 2016),\nThresholdedRELU, all these linear rectified activation functions have its own\nsignificance over others in some aspect. Most of the time these activation\nfunctions suffer from bias shift problem due to non-zero output mean, and high\nweight update problem in deep complex networks due to unit gradient, which\nresults in slower training, and high variance in model prediction respectively.\nIn this paper, we propose, \"Thresholded exponential rectified linear unit\"\n(TERELU) activation function that works better in alleviating in overfitting:\nlarge weight update problem. Along with alleviating overfitting problem, this\nmethod also gives good amount of non-linearity as compared to other linear\nrectifiers. We will show better performance on the various datasets using\nneural networks, considering TERELU activation method compared to other\nactivations.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 11:55:47 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Pandey", "Vijay", ""]]}, {"id": "2006.02824", "submitter": "Andrei Velichko", "authors": "Andrei Velichko", "title": "Neural Network for Low-Memory IoT Devices and MNIST Image Recognition\n  Using Kernels Based on Logistic Map", "comments": "17 pages, 7 figures, 2 tables, 1 Appendix", "journal-ref": "Electronics 2020, 9(9), 1432", "doi": "10.3390/electronics9091432", "report-no": null, "categories": "cs.NE cs.ET nlin.AO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study presents a neural network which uses filters based on logistic\nmapping (LogNNet). LogNNet has a feedforward network structure, but possesses\nthe properties of reservoir neural networks. The input weight matrix, set by a\nrecurrent logistic mapping, forms the kernels that transform the input space to\nthe higher-dimensional feature space. The most effective recognition of a\nhandwritten digit from MNIST-10 occurs under chaotic behavior of the logistic\nmap. The correlation of classification accuracy with the value of the Lyapunov\nexponent was obtained. An advantage of LogNNet implementation on IoT devices is\nthe significant savings in memory used. At the same time, LogNNet has a simple\nalgorithm and performance indicators comparable to those of the best\nresource-efficient algorithms available at the moment. The presented network\narchitecture uses an array of weights with a total memory size from 1 to 29 kB\nand achieves a classification accuracy of 80.3-96.3%. Memory is saved due to\nthe processor, which sequentially calculates the required weight coefficients\nduring the network operation using the analytical equation of the logistic\nmapping. The proposed neural network can be used in implementations of\nartificial intelligence based on constrained devices with limited memory, which\nare integral blocks for creating ambient intelligence in modern IoT\nenvironments. From a research perspective, LogNNet can contribute to the\nunderstanding of the fundamental issues of the influence of chaos on the\nbehavior of reservoir-type neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 12:55:17 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 03:42:46 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Velichko", "Andrei", ""]]}, {"id": "2006.02957", "submitter": "Claudio Gallicchio", "authors": "Claudio Gallicchio", "title": "Sparsity in Reservoir Computing Neural Networks", "comments": "This paper is currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir Computing (RC) is a well-known strategy for designing Recurrent\nNeural Networks featured by striking efficiency of training. The crucial aspect\nof RC is to properly instantiate the hidden recurrent layer that serves as\ndynamical memory to the system. In this respect, the common recipe is to create\na pool of randomly and sparsely connected recurrent neurons. While the aspect\nof sparsity in the design of RC systems has been debated in the literature, it\nis nowadays understood mainly as a way to enhance the efficiency of\ncomputation, exploiting sparse matrix operations. In this paper, we empirically\ninvestigate the role of sparsity in RC network design under the perspective of\nthe richness of the developed temporal representations. We analyze both\nsparsity in the recurrent connections, and in the connections from the input to\nthe reservoir. Our results point out that sparsity, in particular in\ninput-reservoir connections, has a major role in developing internal temporal\nrepresentations that have a longer short-term memory of past inputs and a\nhigher dimension.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 15:38:17 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Gallicchio", "Claudio", ""]]}, {"id": "2006.02986", "submitter": "Callum Wilson", "authors": "Callum Wilson, Annalisa Riccardi, Edmondo Minisci", "title": "A Novel Update Mechanism for Q-Networks Based On Extreme Learning\n  Machines", "comments": "Accepted for IJCNN/WCCI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning is a popular machine learning paradigm which can find\nnear optimal solutions to complex problems. Most often, these procedures\ninvolve function approximation using neural networks with gradient based\nupdates to optimise weights for the problem being considered. While this common\napproach generally works well, there are other update mechanisms which are\nlargely unexplored in reinforcement learning. One such mechanism is Extreme\nLearning Machines. These were initially proposed to drastically improve the\ntraining speed of neural networks and have since seen many applications. Here\nwe attempt to apply extreme learning machines to a reinforcement learning\nproblem in the same manner as gradient based updates. This new algorithm is\ncalled Extreme Q-Learning Machine (EQLM). We compare its performance to a\ntypical Q-Network on the cart-pole task - a benchmark reinforcement learning\nproblem - and show EQLM has similar long-term learning performance to a\nQ-Network.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 16:16:13 GMT"}], "update_date": "2020-06-05", "authors_parsed": [["Wilson", "Callum", ""], ["Riccardi", "Annalisa", ""], ["Minisci", "Edmondo", ""]]}, {"id": "2006.03079", "submitter": "Tim Taylor", "authors": "Tim Taylor", "title": "The Importance of Open-Endedness (for the Sake of Open-Endedness)", "comments": "To appear in Proceedings of the Artificial Life Conference 2020\n  (ALIFE 2020), MIT Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A paper in the recent Artificial Life journal special issue on open-ended\nevolution (OEE) presents a simple evolving computational system that, it is\nclaimed, satisfies all proposed requirements for OEE (Hintze, 2019). Analysis\nand discussion of the system are used to support the further claims that\ncomplexity and diversity are the crucial features of open-endedness, and that\nwe should concentrate on providing proper definitions for those terms rather\nthan engaging in \"the quest for open-endedness for the sake of open-endedness\"\n(Hintze, 2019, p. 205). While I wholeheartedly support the pursuit of precise\ndefinitions of complexity and diversity in relation to OEE research, I\nemphatically reject the suggestion that OEE is not a worthy research topic in\nits own right. In the same issue of the journal, I presented a \"high-level\nconceptual framework to help orient the discussion and implementation of\nopen-endedness in evolutionary systems\" (Taylor, 2019). In the current brief\ncontribution I apply my framework to Hinzte's model to understand its\nlimitations. In so doing, I demonstrate the importance of studying\nopen-endedness for the sake of open-endedness.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 18:02:31 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Taylor", "Tim", ""]]}, {"id": "2006.03179", "submitter": "Garrett Bingham", "authors": "Garrett Bingham and Risto Miikkulainen", "title": "Discovering Parametric Activation Functions", "comments": "14 pages, 12 figures/tables, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that the choice of activation function can\nsignificantly affect the performance of deep learning networks. However, the\nbenefits of novel activation functions have been inconsistent and task\ndependent, and therefore the rectified linear unit (ReLU) is still the most\ncommonly used. This paper proposes a technique for customizing activation\nfunctions automatically, resulting in reliable improvements in performance.\nEvolutionary search is used to discover the general form of the function, and\ngradient descent to optimize its parameters for different parts of the network\nand over the learning process. Experiments with four different neural network\narchitectures on the CIFAR-10 and CIFAR-100 image classification datasets show\nthat this approach is effective. It discovers both general activation functions\nand specialized functions for different architectures, consistently improving\naccuracy over ReLU and other activation functions by significant margins. The\napproach can therefore be used as an automated optimization step in applying\ndeep learning to new tasks.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 00:25:33 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 15:33:14 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 19:28:47 GMT"}, {"version": "v4", "created": "Sat, 30 Jan 2021 02:17:20 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Bingham", "Garrett", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "2006.03226", "submitter": "Yujie Wu", "authors": "Yujie Wu, Rong Zhao, Jun Zhu, Feng Chen, Mingkun Xu, Guoqi Li, Sen\n  Song, Lei Deng, Guanrui Wang, Hao Zheng, Jing Pei, Youhui Zhang, Mingguo\n  Zhao, and Luping Shi", "title": "Brain-inspired global-local learning incorporated with neuromorphic\n  computing", "comments": "5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two main routes of learning methods exist at present including error-driven\nglobal learning and neuroscience-oriented local learning. Integrating them into\none network may provide complementary learning capabilities for versatile\nlearning scenarios. At the same time, neuromorphic computing holds great\npromise, but still needs plenty of useful algorithms and algorithm-hardware\nco-designs for exploiting the advantages. Here, we report a neuromorphic hybrid\nlearning model by introducing a brain-inspired meta-learning paradigm and a\ndifferentiable spiking model incorporating neuronal dynamics and synaptic\nplasticity. It can meta-learn local plasticity and receive top-down supervision\ninformation for multiscale synergic learning. We demonstrate the advantages of\nthis model in multiple different tasks, including few-shot learning, continual\nlearning, and fault-tolerance learning in neuromorphic vision sensors. It\nachieves significantly higher performance than single-learning methods, and\nshows promise in empowering neuromorphic applications revolution. We further\nimplemented the hybrid model in the Tianjic neuromorphic platform by exploiting\nalgorithm-hardware co-designs and proved that the model can fully utilize\nneuromorphic many-core architecture to develop hybrid computation paradigm.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 04:24:19 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 12:01:40 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 01:15:53 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Wu", "Yujie", ""], ["Zhao", "Rong", ""], ["Zhu", "Jun", ""], ["Chen", "Feng", ""], ["Xu", "Mingkun", ""], ["Li", "Guoqi", ""], ["Song", "Sen", ""], ["Deng", "Lei", ""], ["Wang", "Guanrui", ""], ["Zheng", "Hao", ""], ["Pei", "Jing", ""], ["Zhang", "Youhui", ""], ["Zhao", "Mingguo", ""], ["Shi", "Luping", ""]]}, {"id": "2006.03227", "submitter": "Christof Angermueller", "authors": "Christof Angermueller, David Belanger, Andreea Gane, Zelda Mariet,\n  David Dohan, Kevin Murphy, Lucy Colwell, D Sculley", "title": "Population-Based Black-Box Optimization for Biological Sequence Design", "comments": null, "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, Vienna, Austria, PMLR 119, 2020", "doi": "10.1111/j.1365-246X.2006.03227.x", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The use of black-box optimization for the design of new biological sequences\nis an emerging research area with potentially revolutionary impact. The cost\nand latency of wet-lab experiments requires methods that find good sequences in\nfew experimental rounds of large batches of sequences--a setting that\noff-the-shelf black-box optimization methods are ill-equipped to handle. We\nfind that the performance of existing methods varies drastically across\noptimization tasks, posing a significant obstacle to real-world applications.\nTo improve robustness, we propose Population-Based Black-Box Optimization\n(P3BO), which generates batches of sequences by sampling from an ensemble of\nmethods. The number of sequences sampled from any method is proportional to the\nquality of sequences it previously proposed, allowing P3BO to combine the\nstrengths of individual methods while hedging against their innate brittleness.\nAdapting the hyper-parameters of each of the methods online using evolutionary\noptimization further improves performance. Through extensive experiments on\nin-silico optimization tasks, we show that P3BO outperforms any single method\nin its population, proposing higher quality sequences as well as more diverse\nbatches. As such, P3BO and Adaptive-P3BO are a crucial step towards deploying\nML to real-world sequence design.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 04:28:55 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 00:33:03 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Angermueller", "Christof", ""], ["Belanger", "David", ""], ["Gane", "Andreea", ""], ["Mariet", "Zelda", ""], ["Dohan", "David", ""], ["Murphy", "Kevin", ""], ["Colwell", "Lucy", ""], ["Sculley", "D", ""]]}, {"id": "2006.03260", "submitter": "Jakob Bossek", "authors": "Jakob Bossek, Aneta Neumann, Frank Neumann", "title": "Optimising Tours for the Weighted Traveling Salesperson Problem and the\n  Traveling Thief Problem: A Structural Comparison of Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Traveling Salesperson Problem (TSP) is one of the best-known\ncombinatorial optimisation problems. However, many real-world problems are\ncomposed of several interacting components. The Traveling Thief Problem (TTP)\naddresses such interactions by combining two combinatorial optimisation\nproblems, namely the TSP and the Knapsack Problem (KP). Recently, a new problem\ncalled the node weight dependent Traveling Salesperson Problem (W-TSP) has been\nintroduced where nodes have weights that influence the cost of the tour. In\nthis paper, we compare W-TSP and TTP. We investigate the structure of the\noptimised tours for W-TSP and TTP and the impact of using each others fitness\nfunction. Our experimental results suggest (1) that the W-TSP often can be\nsolved better using the TTP fitness function and (2) final W-TSP and TTP\nsolutions show different distributions when compared with optimal TSP or\nweighted greedy solutions.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 07:07:28 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Bossek", "Jakob", ""], ["Neumann", "Aneta", ""], ["Neumann", "Frank", ""]]}, {"id": "2006.03523", "submitter": "Denis Antipov", "authors": "Denis Antipov, Benjamin Doerr", "title": "Runtime Analysis of a Heavy-Tailed $(1+(\\lambda,\\lambda))$ Genetic\n  Algorithm on Jump Functions", "comments": "An extended version of the same-titled paper from PPSN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It was recently observed that the $(1+(\\lambda,\\lambda))$ genetic algorithm\ncan comparably easily escape the local optimum of the jump functions benchmark.\nConsequently, this algorithm can optimize the jump function with jump size $k$\nin an expected runtime of only $n^{(k + 1)/2}k^{-k/2}e^{O(k)}$ fitness\nevaluations (Antipov, Doerr, Karavaev (GECCO 2020)). To obtain this\nperformance, however, a non-standard parameter setting depending on the jump\nsize $k$ was used.\n  To overcome this difficulty, we propose to choose two parameters of the\n$(1+(\\lambda,\\lambda))$ genetic algorithm randomly from a power-law\ndistribution. Via a mathematical runtime analysis, we show that this algorithm\nwith natural instance-independent choices of the distribution parameters on all\njump functions with jump size at most $n/4$ has a performance close to what the\nbest instance-specific parameters in the previous work obtained. This price for\ninstance-independence can be made as small as an $O(n\\log(n))$ factor. Given\nthe difficulty of the jump problem and the runtime losses from using mildly\nsuboptimal fixed parameters (also discussed in this work), this appears to be a\nfair price.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 15:57:55 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Antipov", "Denis", ""], ["Doerr", "Benjamin", ""]]}, {"id": "2006.03535", "submitter": "Alvin Chan", "authors": "Alvin Chan, Yew-Soon Ong, Bill Pung, Aston Zhang, Jie Fu", "title": "CoCon: A Self-Supervised Approach for Controlled Text Generation", "comments": "ICLR 2021 Camera-Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained Transformer-based language models (LMs) display remarkable natural\nlanguage generation capabilities. With their immense potential, controlling\ntext generation of such LMs is getting attention. While there are studies that\nseek to control high-level attributes (such as sentiment and topic) of\ngenerated text, there is still a lack of more precise control over its content\nat the word- and phrase-level. Here, we propose Content-Conditioner (CoCon) to\ncontrol an LM's output text with a content input, at a fine-grained level. In\nour self-supervised approach, the CoCon block learns to help the LM complete a\npartially-observed text sequence by conditioning with content inputs that are\nwithheld from the LM. Through experiments, we show that CoCon can naturally\nincorporate target content into generated texts and control high-level text\nattributes in a zero-shot manner.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 16:15:46 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 14:23:42 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Chan", "Alvin", ""], ["Ong", "Yew-Soon", ""], ["Pung", "Bill", ""], ["Zhang", "Aston", ""], ["Fu", "Jie", ""]]}, {"id": "2006.03662", "submitter": "Sam Ritter", "authors": "Sam Ritter, Ryan Faulkner, Laurent Sartran, Adam Santoro, Matt\n  Botvinick, David Raposo", "title": "Rapid Task-Solving in Novel Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the challenge of rapid task-solving in novel environments (RTS),\nwherein an agent must solve a series of tasks as rapidly as possible in an\nunfamiliar environment. An effective RTS agent must balance between exploring\nthe unfamiliar environment and solving its current task, all while building a\nmodel of the new environment over which it can plan when faced with later\ntasks. While modern deep RL agents exhibit some of these abilities in\nisolation, none are suitable for the full RTS challenge. To enable progress\ntoward RTS, we introduce two challenge domains: (1) a minimal RTS challenge\ncalled the Memory&Planning Game and (2) One-Shot StreetLearn Navigation, which\nintroduces scale and complexity from real-world data. We demonstrate that\nstate-of-the-art deep RL agents fail at RTS in both domains, and that this\nfailure is due to an inability to plan over gathered knowledge. We develop\nEpisodic Planning Networks (EPNs) and show that deep-RL agents with EPNs excel\nat RTS, outperforming the nearest baseline by factors of 2-3 and learning to\nnavigate held-out StreetLearn maps within a single episode. We show that EPNs\nlearn to execute a value iteration-like planning algorithm and that they\ngeneralize to situations beyond their training experience. algorithm and that\nthey generalize to situations beyond their training experience.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 20:09:20 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 16:28:57 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 18:00:46 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Ritter", "Sam", ""], ["Faulkner", "Ryan", ""], ["Sartran", "Laurent", ""], ["Santoro", "Adam", ""], ["Botvinick", "Matt", ""], ["Raposo", "David", ""]]}, {"id": "2006.03741", "submitter": "Sanjoy Dasgupta", "authors": "Sanjoy Dasgupta and Christopher Tosh", "title": "Expressivity of expand-and-sparsify representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple sparse coding mechanism appears in the sensory systems of several\norganisms: to a coarse approximation, an input $x \\in \\R^d$ is mapped to much\nhigher dimension $m \\gg d$ by a random linear transformation, and is then\nsparsified by a winner-take-all process in which only the positions of the top\n$k$ values are retained, yielding a $k$-sparse vector $z \\in \\{0,1\\}^m$. We\nstudy the benefits of this representation for subsequent learning.\n  We first show a universal approximation property, that arbitrary continuous\nfunctions of $x$ are well approximated by linear functions of $z$, provided $m$\nis large enough. This can be interpreted as saying that $z$ unpacks the\ninformation in $x$ and makes it more readily accessible. The linear functions\ncan be specified explicitly and are easy to learn, and we give bounds on how\nlarge $m$ needs to be as a function of the input dimension $d$ and the\nsmoothness of the target function. Next, we consider whether the representation\nis adaptive to manifold structure in the input space. This is highly dependent\non the specific method of sparsification: we show that adaptivity is not\nobtained under the winner-take-all mechanism, but does hold under a slight\nvariant. Finally we consider mappings to the representation space that are\nrandom but are attuned to the data distribution, and we give favorable\napproximation bounds in this setting.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 23:36:59 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Dasgupta", "Sanjoy", ""], ["Tosh", "Christopher", ""]]}, {"id": "2006.03804", "submitter": "Mohamoud Ali", "authors": "Mohamoud Ali, Yugyung Lee and Praveen Rao", "title": "Link Prediction for Temporally Consistent Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic networks have intrinsic structural, computational, and\nmultidisciplinary advantages. Link prediction estimates the next relationship\nin dynamic networks. However, in the current link prediction approaches, only\nbipartite or non-bipartite but homogeneous networks are considered. The use of\nadjacency matrix to represent dynamically evolving networks limits the ability\nto analytically learn from heterogeneous, sparse, or forming networks. In the\ncase of a heterogeneous network, modeling all network states using a\nbinary-valued matrix can be difficult. On the other hand, sparse or currently\nforming networks have many missing edges, which are represented as zeros, thus\nintroducing class imbalance or noise. We propose a time-parameterized matrix\n(TP-matrix) and empirically demonstrate its effectiveness in non-bipartite,\nheterogeneous networks. In addition, we propose a predictive influence index as\na measure of a node's boosting or diminishing predictive influence using\nbackward and forward-looking maximization over the temporal space of the\nn-degree neighborhood. We further propose a new method of canonically\nrepresenting heterogeneous time-evolving activities as a temporally\nparameterized network model (TPNM). The new method robustly enables activities\nto be represented as a form of a network, thus potentially inspiring new link\nprediction applications, including intelligent business process management\nsystems and context-aware workflow engines. We evaluated our model on four\ndatasets of different network systems. We present results that show the\nproposed model is more effective in capturing and retaining temporal\nrelationships in dynamically evolving networks. We also show that our model\nperformed better than state-of-the-art link prediction benchmark results for\nnetworks that are sensitive to temporal evolution.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 07:28:03 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Ali", "Mohamoud", ""], ["Lee", "Yugyung", ""], ["Rao", "Praveen", ""]]}, {"id": "2006.03824", "submitter": "Axel Laborieux", "authors": "Axel Laborieux, Maxence Ernoult, Benjamin Scellier, Yoshua Bengio,\n  Julie Grollier and Damien Querlioz", "title": "Scaling Equilibrium Propagation to Deep ConvNets by Drastically Reducing\n  its Gradient Estimator Bias", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equilibrium Propagation (EP) is a biologically-inspired algorithm for\nconvergent RNNs with a local learning rule that comes with strong theoretical\nguarantees. The parameter updates of the neural network during the credit\nassignment phase have been shown mathematically to approach the gradients\nprovided by Backpropagation Through Time (BPTT) when the network is\ninfinitesimally nudged toward its target. In practice, however, training a\nnetwork with the gradient estimates provided by EP does not scale to visual\ntasks harder than MNIST. In this work, we show that a bias in the gradient\nestimate of EP, inherent in the use of finite nudging, is responsible for this\nphenomenon and that cancelling it allows training deep ConvNets by EP. We show\nthat this bias can be greatly reduced by using symmetric nudging (a positive\nnudging and a negative one). We also generalize previous EP equations to the\ncase of cross-entropy loss (by opposition to squared error). As a result of\nthese advances, we are able to achieve a test error of 11.7% on CIFAR-10 by EP,\nwhich approaches the one achieved by BPTT and provides a major improvement with\nrespect to the standard EP approach with same-sign nudging that gives 86% test\nerror. We also apply these techniques to train an architecture with asymmetric\nforward and backward connections, yielding a 13.2% test error. These results\nhighlight EP as a compelling biologically-plausible approach to compute error\ngradients in deep neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 09:36:07 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Laborieux", "Axel", ""], ["Ernoult", "Maxence", ""], ["Scellier", "Benjamin", ""], ["Bengio", "Yoshua", ""], ["Grollier", "Julie", ""], ["Querlioz", "Damien", ""]]}, {"id": "2006.03944", "submitter": "Alexander Ra{\\ss}", "authors": "Bernd Bassimir, Alexander Ra{\\ss}, Rolf Wanka", "title": "The Convergence Indicator: Improved and completely characterized\n  parameter bounds for actual convergence of Particle Swarm Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle Swarm Optimization (PSO) is a meta-heuristic for continuous\nblack-box optimization problems. In this paper we focus on the convergence of\nthe particle swarm, i.e., the exploitation phase of the algorithm. We introduce\na new convergence indicator that can be used to calculate whether the particles\nwill finally converge to a single point or diverge. Using this convergence\nindicator we provide the actual bounds completely characterizing parameter\nregions that lead to a converging swarm. Our bounds extend the parameter\nregions where convergence is guaranteed compared to bounds induced by\nconverging variance which are usually used in the literature. To evaluate our\ncriterion we describe a numerical approximation using cubic spline\ninterpolation. Finally we provide experiments showing that our concept,\nformulas and the resulting convergence bounds represent the actual behavior of\nPSO.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 19:08:05 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Bassimir", "Bernd", ""], ["Ra\u00df", "Alexander", ""], ["Wanka", "Rolf", ""]]}, {"id": "2006.03996", "submitter": "Wei Zheng", "authors": "Jianyong Sun and Wei Zheng and Qingfu Zhang and Zongben Xu", "title": "Graph Neural Network Encoding for Community Detection in Attribute\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we first propose a graph neural network encoding method for\nmultiobjective evolutionary algorithm to handle the community detection problem\nin complex attribute networks. In the graph neural network encoding method,\neach edge in an attribute network is associated with a continuous variable.\nThrough non-linear transformation, a continuous valued vector (i.e. a\nconcatenation of the continuous variables associated with the edges) is\ntransferred to a discrete valued community grouping solution. Further, two\nobjective functions for single- and multi-attribute network are proposed to\nevaluate the attribute homogeneity of the nodes in communities, respectively.\nBased on the new encoding method and the two objectives, a multiobjective\nevolutionary algorithm (MOEA) based upon NSGA-II, termed as continuous encoding\nMOEA, is developed for the transformed community detection problem with\ncontinuous decision variables. Experimental results on single- and\nmulti-attribute networks with different types show that the developed algorithm\nperforms significantly better than some well-known evolutionary and\nnon-evolutionary based algorithms. The fitness landscape analysis verifies that\nthe transformed community detection problems have smoother landscapes than\nthose of the original problems, which justifies the effectiveness of the\nproposed graph neural network encoding method.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jun 2020 23:41:36 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 08:29:15 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Sun", "Jianyong", ""], ["Zheng", "Wei", ""], ["Zhang", "Qingfu", ""], ["Xu", "Zongben", ""]]}, {"id": "2006.04182", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge, Alexander Tschantz, Christopher L. Buckley", "title": "Predictive Coding Approximates Backprop along Arbitrary Computation\n  Graphs", "comments": "Submitted to NeurIPS 2020. Updated Acknowledgements. 11/06/20: fixed\n  typos in maths -- 11/07/20: minor corrections; 05/10/20: major rewrite for\n  ICLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation of error (backprop) is a powerful algorithm for training\nmachine learning architectures through end-to-end differentiation. However,\nbackprop is often criticised for lacking biological plausibility. Recently, it\nhas been shown that backprop in multilayer-perceptrons (MLPs) can be\napproximated using predictive coding, a biologically-plausible process theory\nof cortical computation which relies only on local and Hebbian updates. The\npower of backprop, however, lies not in its instantiation in MLPs, but rather\nin the concept of automatic differentiation which allows for the optimisation\nof any differentiable program expressed as a computation graph. Here, we\ndemonstrate that predictive coding converges asymptotically (and in practice\nrapidly) to exact backprop gradients on arbitrary computation graphs using only\nlocal learning rules. We apply this result to develop a straightforward\nstrategy to translate core machine learning architectures into their predictive\ncoding equivalents. We construct predictive coding CNNs, RNNs, and the more\ncomplex LSTMs, which include a non-layer-like branching internal graph\nstructure and multiplicative interactions. Our models perform equivalently to\nbackprop on challenging machine learning benchmarks, while utilising only local\nand (mostly) Hebbian plasticity. Our method raises the potential that standard\nmachine learning algorithms could in principle be directly implemented in\nneural circuitry, and may also contribute to the development of completely\ndistributed neuromorphic architectures.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 15:35:47 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 21:03:45 GMT"}, {"version": "v3", "created": "Thu, 11 Jun 2020 10:22:14 GMT"}, {"version": "v4", "created": "Sat, 11 Jul 2020 16:07:27 GMT"}, {"version": "v5", "created": "Mon, 5 Oct 2020 18:11:05 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Millidge", "Beren", ""], ["Tschantz", "Alexander", ""], ["Buckley", "Christopher L.", ""]]}, {"id": "2006.04270", "submitter": "Hojjat Salehinejad", "authors": "Hojjat Salehinejad and Shahrokh Valaee", "title": "EDropout: Energy-Based Dropout and Pruning of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a well-known regularization method by sampling a sub-network from\na larger deep neural network and training different sub-networks on different\nsubsets of the data. Inspired by the dropout concept, we propose EDropout as an\nenergy-based framework for pruning neural networks in classification tasks. In\nthis approach, a set of binary pruning state vectors (population) represents a\nset of corresponding sub-networks from an arbitrary provided original neural\nnetwork. An energy loss function assigns a scalar energy loss value to each\npruning state. The energy-based model stochastically evolves the population to\nfind states with lower energy loss. The best pruning state is then selected and\napplied to the original network. Similar to dropout, the kept weights are\nupdated using backpropagation in a probabilistic model. The energy-based model\nagain searches for better pruning states and the cycle continuous. Indeed, this\nprocedure is in fact switching between the energy model, which manages the\npruning states, and the probabilistic model, which updates the temporarily\nunpruned weights, in each iteration. The population can dynamically converge to\na pruning state. This can be interpreted as dropout leading to pruning the\nnetwork. From an implementation perspective, EDropout can prune typical neural\nnetworks without modification of the network architecture. We evaluated the\nproposed method on different flavours of ResNets, AlexNet, and SqueezeNet on\nthe Kuzushiji, Fashion, CIFAR-10, CIFAR-100, and Flowers datasets, and compared\nthe pruning rate and classification performance of the models. On average the\nnetworks trained with \\textit{EDropout} achieved a pruning rate of more than\n$50\\%$ of the trainable parameters with approximately $<5\\%$ and $<1\\%$ drop of\nTop-1 and Top-5 classification accuracy, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2020 21:09:44 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 05:53:19 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2020 22:36:02 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Salehinejad", "Hojjat", ""], ["Valaee", "Shahrokh", ""]]}, {"id": "2006.04436", "submitter": "Julius Ruseckas", "authors": "Eimantas Ledinauskas (1), Julius Ruseckas (1), Alfonsas Jur\\v{s}\\.enas\n  (1), Giedrius Bura\\v{c}as (2) ((1) Baltic Institute of Advanced Technology,\n  Lithuania, (2) SRI International, USA)", "title": "Training Deep Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation using brain-inspired spiking neural networks (SNNs) with\nneuromorphic hardware may offer orders of magnitude higher energy efficiency\ncompared to the current analog neural networks (ANNs). Unfortunately, training\nSNNs with the same number of layers as state of the art ANNs remains a\nchallenge. To our knowledge the only method which is successful in this regard\nis supervised training of ANN and then converting it to SNN. In this work we\ndirectly train deep SNNs using backpropagation with surrogate gradient and find\nthat due to implicitly recurrent nature of feed forward SNN's the exploding or\nvanishing gradient problem severely hinders their training. We show that this\nproblem can be solved by tuning the surrogate gradient function. We also\npropose using batch normalization from ANN literature on input currents of SNN\nneurons. Using these improvements we show that is is possible to train SNN with\nResNet50 architecture on CIFAR100 and Imagenette object recognition datasets.\nThe trained SNN falls behind in accuracy compared to analogous ANN but requires\nseveral orders of magnitude less inference time steps (as low as 10) to reach\ngood accuracy compared to SNNs obtained by conversion from ANN which require on\nthe order of 1000 time steps.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 09:47:05 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Ledinauskas", "Eimantas", ""], ["Ruseckas", "Julius", ""], ["Jur\u0161\u0117nas", "Alfonsas", ""], ["Bura\u010das", "Giedrius", ""]]}, {"id": "2006.04439", "submitter": "Ramin Hasani", "authors": "Ramin Hasani, Mathias Lechner, Alexander Amini, Daniela Rus, Radu\n  Grosu", "title": "Liquid Time-constant Networks", "comments": "Accepted to the Thirty-Fifth AAAI Conference on Artificial\n  Intelligence (AAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new class of time-continuous recurrent neural network models.\nInstead of declaring a learning system's dynamics by implicit nonlinearities,\nwe construct networks of linear first-order dynamical systems modulated via\nnonlinear interlinked gates. The resulting models represent dynamical systems\nwith varying (i.e., liquid) time-constants coupled to their hidden state, with\noutputs being computed by numerical differential equation solvers. These neural\nnetworks exhibit stable and bounded behavior, yield superior expressivity\nwithin the family of neural ordinary differential equations, and give rise to\nimproved performance on time-series prediction tasks. To demonstrate these\nproperties, we first take a theoretical approach to find bounds over their\ndynamics and compute their expressive power by the trajectory length measure in\nlatent trajectory space. We then conduct a series of time-series prediction\nexperiments to manifest the approximation capability of Liquid Time-Constant\nNetworks (LTCs) compared to classical and modern RNNs. Code and data are\navailable at https://github.com/raminmh/liquid_time_constant_networks\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 09:53:35 GMT"}, {"version": "v2", "created": "Sat, 12 Sep 2020 18:13:30 GMT"}, {"version": "v3", "created": "Fri, 20 Nov 2020 01:26:16 GMT"}, {"version": "v4", "created": "Mon, 14 Dec 2020 22:23:52 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Hasani", "Ramin", ""], ["Lechner", "Mathias", ""], ["Amini", "Alexander", ""], ["Rus", "Daniela", ""], ["Grosu", "Radu", ""]]}, {"id": "2006.04462", "submitter": "Jiashuo Shi", "authors": "Jiashuo Shi", "title": "A Diffractive Neural Network with Weight-Noise-Injection Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a diffractive neural network with strong robustness based on\nWeight Noise Injection training, which achieves accurate and fast optical-based\nclassification while diffraction layers have a certain amount of surface shape\nerror. To the best of our knowledge, it is the first time that using injection\nweight noise during training to reduce the impact of external interference on\ndeep learning inference results. In the proposed method, the diffractive neural\nnetwork learns the mapping between the input image and the label in Weight\nNoise Injection mode, making the network's weight insensitive to modest\nchanges, which improve the network's noise resistance at a lower cost. By\ncomparing the accuracy of the network under different noise, it is verified\nthat the proposed network (SRNN) still maintains a higher accuracy under\nserious noise.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 10:41:29 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 05:44:55 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 10:09:27 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Shi", "Jiashuo", ""]]}, {"id": "2006.04535", "submitter": "Abien Fred Agarap", "authors": "Abien Fred Agarap, Arnulfo P. Azcarraga", "title": "Improving k-Means Clustering Performance with Disentangled Internal\n  Representations", "comments": "To be presented at IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep clustering algorithms combine representation learning and clustering by\njointly optimizing a clustering loss and a non-clustering loss. In such\nmethods, a deep neural network is used for representation learning together\nwith a clustering network. Instead of following this framework to improve\nclustering performance, we propose a simpler approach of optimizing the\nentanglement of the learned latent code representation of an autoencoder. We\ndefine entanglement as how close pairs of points from the same class or\nstructure are, relative to pairs of points from different classes or\nstructures. To measure the entanglement of data points, we use the soft nearest\nneighbor loss, and expand it by introducing an annealing temperature factor.\nUsing our proposed approach, the test clustering accuracy was 96.2% on the\nMNIST dataset, 85.6% on the Fashion-MNIST dataset, and 79.2% on the EMNIST\nBalanced dataset, outperforming our baseline models.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 11:32:34 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Agarap", "Abien Fred", ""], ["Azcarraga", "Arnulfo P.", ""]]}, {"id": "2006.04573", "submitter": "Andreas Kamilaris", "authors": "Andreas Kamilaris, Andries Engelbrecht, Andreas Pitsillides and\n  Francesc X. Prenafeta-Boldu", "title": "Transfer of Manure from Livestock Farms to Crop Fields as Fertilizer\n  using an Ant Inspired Approach", "comments": "Proc. of the XXIVth International Society for Photogrammetry and\n  Remote Sensing (ISPRS) Congress, June 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intensive livestock production might have a negative environmental impact, by\nproducing large amounts of animal excrements, which, if not properly managed,\ncan contaminate nearby water bodies with nutrient excess. However, if animal\nmanure is exported to distant crop fields, to be used as organic fertilizer,\npollution can be mitigated. It is a single-objective optimization problem, in\nregards to finding the best solution for the logistics process of satisfying\nnutrient crops needs by means of livestock manure. This paper proposes a\ndynamic approach to solve the problem, based on a decentralized nature-inspired\ncooperative technique, inspired by the foraging behavior of ants (AIA). Results\nprovide important insights for policy-makers over the potential of using animal\nmanure as fertilizer for crop fields, while AIA solves the problem effectively,\nin a fair way to the farmers and well balanced in terms of average\ntransportation distances that need to be covered by each livestock farmer. Our\nwork constitutes the first application of a decentralized AIA to this\ninteresting real-world problem, in a domain where swarm intelligence methods\nare still under-exploited.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 11:46:10 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Kamilaris", "Andreas", ""], ["Engelbrecht", "Andries", ""], ["Pitsillides", "Andreas", ""], ["Prenafeta-Boldu", "Francesc X.", ""]]}, {"id": "2006.04597", "submitter": "Frances Laureano De Leon", "authors": "Frances Adriana Laureano De Leon and Florimond Gu\\'eniat and Harish\n  Tayyar Madabushi", "title": "CS-Embed at SemEval-2020 Task 9: The effectiveness of code-switched word\n  embeddings for sentiment analysis", "comments": "Accepted at SemEval-2020, COLING", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The growing popularity and applications of sentiment analysis of social media\nposts has naturally led to sentiment analysis of posts written in multiple\nlanguages, a practice known as code-switching. While recent research into\ncode-switched posts has focused on the use of multilingual word embeddings,\nthese embeddings were not trained on code-switched data. In this work, we\npresent word-embeddings trained on code-switched tweets, specifically those\nthat make use of Spanish and English, known as Spanglish. We explore the\nembedding space to discover how they capture the meanings of words in both\nlanguages. We test the effectiveness of these embeddings by participating in\nSemEval 2020 Task 9: ~\\emph{Sentiment Analysis on Code-Mixed Social Media\nText}. We utilised them to train a sentiment classifier that achieves an F-1\nscore of 0.722. This is higher than the baseline for the competition of 0.656,\nwith our team (codalab username \\emph{francesita}) ranking 14 out of 29\nparticipating teams, beating the baseline.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 13:48:17 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 10:39:45 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["De Leon", "Frances Adriana Laureano", ""], ["Gu\u00e9niat", "Florimond", ""], ["Madabushi", "Harish Tayyar", ""]]}, {"id": "2006.04663", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr", "title": "Runtime Analysis of Evolutionary Algorithms via Symmetry Arguments", "comments": "Minor changes compared to the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use an elementary argument building on group actions to prove that the\nselection-free steady state genetic algorithm analyzed by Sutton and Witt\n(GECCO 2019) takes an expected number of $\\Omega(2^n / \\sqrt n)$ iterations to\nfind any particular target search point. This bound is valid for all population\nsizes $\\mu$. Our result improves over the previous lower bound of\n$\\Omega(\\exp(n^{\\delta/2}))$ valid for population sizes $\\mu = O(n^{1/2 -\n\\delta})$, $0 < \\delta < 1/2$.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 15:04:51 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 11:32:39 GMT"}, {"version": "v3", "created": "Sat, 31 Oct 2020 10:42:28 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Doerr", "Benjamin", ""]]}, {"id": "2006.04716", "submitter": "Andrew Fountain", "authors": "Andrew Fountain and Cory Merkel", "title": "Energy Constraints Improve Liquid State Machine Performance", "comments": "8 pages, 5 figures. Submitted to ICONS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model of metabolic energy constraints is applied to a liquid state machine\nin order to analyze its effects on network performance. It was found that, in\ncertain combinations of energy constraints, a significant increase in testing\naccuracy emerged; an improvement of 4.25% was observed on a seizure detection\ntask using a digital liquid state machine while reducing overall reservoir\nspiking activity by 6.9%. The accuracy improvements appear to be linked to the\nenergy constraints' impact on the reservoir's dynamics, as measured through\nmetrics such as the Lyapunov exponent and the separation of the reservoir.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 16:13:16 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Fountain", "Andrew", ""], ["Merkel", "Cory", ""]]}, {"id": "2006.04720", "submitter": "Andrei Kucharavy", "authors": "Andrei Kucharavy (1), El Mahdi El Mhamdi (1) and Rachid Guerraoui (1)\n  ((1) Ecole Polytechnique Federale de Lausanne, Lausanne, Switzerland)", "title": "Host-Pathongen Co-evolution Inspired Algorithm Enables Robust GAN\n  Training", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.PE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are pairs of artificial neural\nnetworks that are trained one against each other. The outputs from a generator\nare mixed with the real-world inputs to the discriminator and both networks are\ntrained until an equilibrium is reached, where the discriminator cannot\ndistinguish generated inputs from real ones. Since their introduction, GANs\nhave allowed for the generation of impressive imitations of real-life films,\nimages and texts, whose fakeness is barely noticeable to humans. Despite their\nimpressive performance, training GANs remains to this day more of an art than a\nreliable procedure, in a large part due to training process stability.\nGenerators are susceptible to mode dropping and convergence to random patterns,\nwhich have to be mitigated by computationally expensive multiple restarts.\nCuriously, GANs bear an uncanny similarity to a co-evolution of a pathogen and\nits host's immune system in biology. In a biological context, the majority of\npotential pathogens indeed never make it and are kept at bay by the hots'\nimmune system. Yet some are efficient enough to present a risk of a serious\ncondition and recurrent infections. Here, we explore that similarity to propose\na more robust algorithm for GANs training. We empirically show the increased\nstability and a better ability to generate high-quality images while using less\ncomputational power.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 09:54:06 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 11:21:03 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Kucharavy", "Andrei", "", "Ecole Polytechnique Federale de Lausanne, Lausanne, Switzerland"], ["Mhamdi", "El Mahdi El", "", "Ecole Polytechnique Federale de Lausanne, Lausanne, Switzerland"], ["Guerraoui", "Rachid", "", "Ecole Polytechnique Federale de Lausanne, Lausanne, Switzerland"]]}, {"id": "2006.04751", "submitter": "Stefan Jaeger", "authors": "Stefan Jaeger", "title": "The Golden Ratio of Learning and Momentum", "comments": "10 pages, 3 figures, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent has been a central training principle for artificial neural\nnetworks from the early beginnings to today's deep learning networks. The most\ncommon implementation is the backpropagation algorithm for training\nfeed-forward neural networks in a supervised fashion. Backpropagation involves\ncomputing the gradient of a loss function, with respect to the weights of the\nnetwork, to update the weights and thus minimize loss. Although the mean square\nerror is often used as a loss function, the general stochastic gradient descent\nprinciple does not immediately connect with a specific loss function. Another\ndrawback of backpropagation has been the search for optimal values of two\nimportant training parameters, learning rate and momentum weight, which are\ndetermined empirically in most systems. The learning rate specifies the step\nsize towards a minimum of the loss function when following the gradient, while\nthe momentum weight considers previous weight changes when updating current\nweights. Using both parameters in conjunction with each other is generally\naccepted as a means to improving training, although their specific values do\nnot follow immediately from standard backpropagation theory. This paper\nproposes a new information-theoretical loss function motivated by neural signal\nprocessing in a synapse. The new loss function implies a specific learning rate\nand momentum weight, leading to empirical parameters often used in practice.\nThe proposed framework also provides a more formal explanation of the momentum\nterm and its smoothing effect on the training process. All results taken\ntogether show that loss, learning rate, and momentum are closely connected. To\nsupport these theoretical findings, experiments for handwritten digit\nrecognition show the practical usefulness of the proposed loss function and\ntraining parameters.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 17:08:13 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Jaeger", "Stefan", ""]]}, {"id": "2006.04765", "submitter": "Konstantinos Michmizos", "authors": "Ioannis Polykretis, Konstantinos P. Michmizos", "title": "An Astrocyte-Modulated Neuromorphic Central Pattern Generator for\n  Hexapod Robot Locomotion on Intel's Loihi", "comments": "8 pages, 7 figures, International Conference on Neuromorphic Systems\n  (ICONS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locomotion is a crucial challenge for legged robots that is addressed\n\"effortlessly\" by biological networks abundant in nature, named central pattern\ngenerators (CPG). The multitude of CPG network models that have so far become\nbiomimetic robotic controllers is not applicable to the emerging neuromorphic\nhardware, depriving mobile robots of a robust walking mechanism that would\nresult in inherently energy-efficient systems. Here, we propose a brain-morphic\nCPG controler based on a comprehensive spiking neural-astrocytic network that\ngenerates two gait patterns for a hexapod robot. Building on the recently\nidentified astrocytic mechanisms for neuromodulation, our proposed CPG\narchitecture is seamlessly integrated into Intel's Loihi neuromorphic chip by\nleveraging a real-time interaction framework between the chip and the robotic\noperating system (ROS) environment, that we also propose. Here, we demonstrate\nthat a Loihi-run CPG can be used to control a walking robot with robustness to\nsensory noise and varying speed profiles. Our results pave the way for scaling\nthis and other approaches towards Loihi-controlled locomotion in autonomous\nmobile robots.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 17:35:48 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Polykretis", "Ioannis", ""], ["Michmizos", "Konstantinos P.", ""]]}, {"id": "2006.04791", "submitter": "Przemek Witaszczyk", "authors": "Romuald A. Janik, Przemek Witaszczyk", "title": "Complexity for deep neural networks and other characteristics of deep\n  feature representations", "comments": "Significant extension including developments in neuroscience context\n  and more. 36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.NE hep-th stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a notion of complexity, which quantifies the nonlinearity of the\ncomputation of a neural network, as well as a complementary measure of the\neffective dimension of feature representations. We investigate these\nobservables both for trained networks for various datasets as well as explore\ntheir dynamics during training, uncovering in particular power law scaling.\nThese observables can be understood in a dual way as uncovering hidden internal\nstructure of the datasets themselves as a function of scale or depth. The\nentropic character of the proposed notion of complexity should allow to\ntransfer modes of analysis from neuroscience and statistical physics to the\ndomain of artificial neural networks. The introduced observables can be applied\nwithout any change to the analysis of biological neuronal systems.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 17:59:30 GMT"}, {"version": "v2", "created": "Wed, 17 Mar 2021 14:50:33 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Janik", "Romuald A.", ""], ["Witaszczyk", "Przemek", ""]]}, {"id": "2006.05033", "submitter": "Seongbin Oh", "authors": "Seongbin Oh, Dongseok Kwon, Gyuho Yeom, Won-Mook Kang, Soochang Lee,\n  Sung Yun Woo, Jang Saeng Kim, Min Kyu Park and Jong-Ho Lee", "title": "Hardware Implementation of Spiking Neural Networks Using\n  Time-To-First-Spike Encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware-based spiking neural networks (SNNs) are regarded as promising\ncandidates for the cognitive computing system due to low power consumption and\nhighly parallel operation. In this work, we train the SNN in which the firing\ntime carries information using temporal backpropagation. The temporally encoded\nSNN with 512 hidden neurons showed an accuracy of 96.90% for the MNIST test\nset. Furthermore, the effect of the device variation on the accuracy in\ntemporally encoded SNN is investigated and compared with that of the\nrate-encoded network. In a hardware configuration of our SNN, NOR-type analog\nmemory having an asymmetric floating gate is used as a synaptic device. In\naddition, we propose a neuron circuit including a refractory period generator\nfor temporally encoded SNN. The performance of the 2-layer neural network\nconsisting of synapses and proposed neurons is evaluated through circuit\nsimulation using SPICE. The network with 128 hidden neurons showed an accuracy\nof 94.9%, a 0.1% reduction compared to that of the system simulation of the\nMNIST dataset. Finally, the latency and power consumption of each block\nconstituting the temporal network is analyzed and compared with those of the\nrate-encoded network depending on the total time step. Assuming that the total\ntime step number of the network is 256, the temporal network consumes 15.12\ntimes lower power than the rate-encoded network and can make decisions 5.68\ntimes faster.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 03:31:15 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Oh", "Seongbin", ""], ["Kwon", "Dongseok", ""], ["Yeom", "Gyuho", ""], ["Kang", "Won-Mook", ""], ["Lee", "Soochang", ""], ["Woo", "Sung Yun", ""], ["Kim", "Jang Saeng", ""], ["Park", "Min Kyu", ""], ["Lee", "Jong-Ho", ""]]}, {"id": "2006.05159", "submitter": "Albert Dulian", "authors": "Albert Dulian and John C. Murray", "title": "Physically constrained short-term vehicle trajectory forecasting with\n  naive semantic maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban environments manifest a high level of complexity, and therefore it is\nof vital importance for safety systems embedded within autonomous vehicles\n(AVs) to be able to accurately predict the short-term future motion of nearby\nagents. This problem can be further understood as generating a sequence of\nfuture coordinates for a given agent based on its past motion data e.g.\nposition, velocity, acceleration etc, and whilst current approaches demonstrate\nplausible results they have a propensity to neglect a scene's physical\nconstrains. In this paper we propose the model based on a combination of the\nCNN and LSTM encoder-decoder architecture that learns to extract a relevant\nroad features from semantic maps as well as general motion of agents and uses\nthis learned representation to predict their short-term future trajectories. We\ntrain and validate the model on the publicly available dataset that provides\ndata from urban areas, allowing us to examine it in challenging and uncertain\nscenarios. We show that our model is not only capable of anticipating future\nmotion whilst taking into consideration road boundaries, but can also\neffectively and precisely predict trajectories for a longer time horizon than\ninitially trained for.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 09:52:44 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Dulian", "Albert", ""], ["Murray", "John C.", ""]]}, {"id": "2006.05238", "submitter": "Saehyun Ahn", "authors": "Saehyun Ahn, Jung-Woo Chang, and Suk-Ju Kang", "title": "An Efficient Accelerator Design Methodology for Deformable Convolutional\n  Networks", "comments": "IEEE International Conference on Image Processing (ICIP) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deformable convolutional networks have demonstrated outstanding performance\nin object recognition tasks with an effective feature extraction. Unlike\nstandard convolution, the deformable convolution decides the receptive field\nsize using dynamically generated offsets, which leads to an irregular memory\naccess. Especially, the memory access pattern varies both spatially and\ntemporally, making static optimization ineffective. Thus, a naive\nimplementation would lead to an excessive memory footprint. In this paper, we\npresent a novel approach to accelerate deformable convolution on FPGA. First,\nwe propose a novel training method to reduce the size of the receptive field in\nthe deformable convolutional layer without compromising accuracy. By optimizing\nthe receptive field, we can compress the maximum size of the receptive field by\n12.6 times. Second, we propose an efficient systolic architecture to maximize\nits efficiency. We then implement our design on FPGA to support the optimized\ndataflow. Experimental results show that our accelerator achieves up to 17.25\ntimes speedup over the state-of-the-art accelerator.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 13:16:44 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 10:40:25 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ahn", "Saehyun", ""], ["Chang", "Jung-Woo", ""], ["Kang", "Suk-Ju", ""]]}, {"id": "2006.05252", "submitter": "Nicolas Vecoven", "authors": "Nicolas Vecoven and Damien Ernst and Guillaume Drion", "title": "A bio-inspired bistable recurrent cell allows for long-lasting memory", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0252676", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) provide state-of-the-art performances in a\nwide variety of tasks that require memory. These performances can often be\nachieved thanks to gated recurrent cells such as gated recurrent units (GRU)\nand long short-term memory (LSTM). Standard gated cells share a layer internal\nstate to store information at the network level, and long term memory is shaped\nby network-wide recurrent connection weights. Biological neurons on the other\nhand are capable of holding information at the cellular level for an arbitrary\nlong amount of time through a process called bistability. Through bistability,\ncells can stabilize to different stable states depending on their own past\nstate and inputs, which permits the durable storing of past information in\nneuron state. In this work, we take inspiration from biological neuron\nbistability to embed RNNs with long-lasting memory at the cellular level. This\nleads to the introduction of a new bistable biologically-inspired recurrent\ncell that is shown to strongly improves RNN performance on time-series which\nrequire very long memory, despite using only cellular connections (all\nrecurrent connections are from neurons to themselves, i.e. a neuron state is\nnot influenced by the state of other neurons). Furthermore, equipping this cell\nwith recurrent neuromodulation permits to link them to standard GRU cells,\ntaking a step towards the biological plausibility of GRU.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 13:36:31 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Vecoven", "Nicolas", ""], ["Ernst", "Damien", ""], ["Drion", "Guillaume", ""]]}, {"id": "2006.05415", "submitter": "Edgar Galvan", "authors": "Edgar Galv\\'an and Peter Mooney", "title": "Neuroevolution in Deep Neural Networks: Current Trends and Future\n  Challenges", "comments": "20 pages (double column), 2 figures, 3 tables, 157 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of methods have been applied to the architectural configuration and\nlearning or training of artificial deep neural networks (DNN). These methods\nplay a crucial role in the success or failure of the DNN for most problems and\napplications. Evolutionary Algorithms (EAs) are gaining momentum as a\ncomputationally feasible method for the automated optimisation and training of\nDNNs. Neuroevolution is a term which describes these processes of automated\nconfiguration and training of DNNs using EAs. While many works exist in the\nliterature, no comprehensive surveys currently exist focusing exclusively on\nthe strengths and limitations of using neuroevolution approaches in DNNs.\nProlonged absence of such surveys can lead to a disjointed and fragmented field\npreventing DNNs researchers potentially adopting neuroevolutionary methods in\ntheir own research, resulting in lost opportunities for improving performance\nand wider application within real-world deep learning problems. This paper\npresents a comprehensive survey, discussion and evaluation of the\nstate-of-the-art works on using EAs for architectural configuration and\ntraining of DNNs. Based on this survey, the paper highlights the most pertinent\ncurrent issues and challenges in neuroevolution and identifies multiple\npromising future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2020 17:28:25 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Galv\u00e1n", "Edgar", ""], ["Mooney", "Peter", ""]]}, {"id": "2006.05624", "submitter": "Shrinu Kushagra", "authors": "Utkarsh Nath, Shrinu Kushagra", "title": "Better Together: Resnet-50 accuracy with $13 \\times$ fewer parameters\n  and at $3\\times$ speed", "comments": "Code available at: https://github.com/utkarshnath/Adjoint-Network.git", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on compressing deep neural networks has focused on reducing\nthe number of parameters. Smaller networks are easier to export and deploy on\nedge-devices. We introduce Adjoined networks as a training approach that can\nregularize and compress any CNN-based neural architecture. Our one-shot\nlearning paradigm trains both the original and the smaller networks together.\nThe parameters of the smaller network are shared across both the architectures.\nWe prove strong theoretical guarantees on the regularization behavior of the\nadjoint training paradigm. We complement our theoretical analysis by an\nextensive empirical evaluation of both the compression and regularization\nbehavior of adjoint networks. For resnet-50 trained adjointly on Imagenet, we\nare able to achieve a $13.7x$ reduction in the number of parameters (For size\ncomparison, we ignore the parameters in the last linear layer as it varies by\ndataset and are typically dropped during fine-tuning. Else, the reductions are\n$11.5x$ and $95x$ for imagenet and cifar-100 respectively.) and a $3x$\nimprovement in inference time without any significant drop in accuracy. For the\nsame architecture on CIFAR-100, we are able to achieve a $99.7x$ reduction in\nthe number of parameters and a $5x$ improvement in inference time. On both\nthese datasets, the original network trained in the adjoint fashion gains about\n$3\\%$ in top-1 accuracy as compared to the same network trained in the standard\nfashion.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 02:48:16 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 02:04:58 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 00:23:48 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Nath", "Utkarsh", ""], ["Kushagra", "Shrinu", ""]]}, {"id": "2006.05657", "submitter": "Vivek Parmar", "authors": "Sandeep Kaur Kingra, Vivek Parmar, Shubham Negi, Sufyan Khan, Boris\n  Hudec, Tuo-Hung Hou and Manan Suri", "title": "Methodology for Realizing VMM with Binary RRAM Arrays: Experimental\n  Demonstration of Binarized-ADALINE Using OxRAM Crossbar", "comments": "Accepted for presentation at the IEEE International Symposium on\n  Circuits and Systems (ISCAS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an efficient hardware mapping methodology for\nrealizing vector matrix multiplication (VMM) on resistive memory (RRAM) arrays.\nUsing the proposed VMM computation technique, we experimentally demonstrate a\nbinarized-ADALINE (Adaptive Linear) classifier on an OxRAM crossbar. An 8x8\nOxRAM crossbar with Ni/3-nm HfO2/7 nm Al-doped-TiO2/TiN device stack is used.\nWeight training for the binarized-ADALINE classifier is performed ex-situ on\nUCI cancer dataset. Post weight generation the OxRAM array is carefully\nprogrammed to binary weight-states using the proposed weight mapping technique\non a custom-built testbench. Our VMM powered binarized-ADALINE network achieves\na classification accuracy of 78% in simulation and 67% in experiments.\nExperimental accuracy was found to drop mainly due to crossbar inherent\nsneak-path issues and RRAM device programming variability.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 05:18:13 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Kingra", "Sandeep Kaur", ""], ["Parmar", "Vivek", ""], ["Negi", "Shubham", ""], ["Khan", "Sufyan", ""], ["Hudec", "Boris", ""], ["Hou", "Tuo-Hung", ""], ["Suri", "Manan", ""]]}, {"id": "2006.05664", "submitter": "Xiaotian Gao", "authors": "Xiaotian Gao, Cui Wei, Lintao Zhang and Mao Yang", "title": "OpEvo: An Evolutionary Method for Tensor Operator Optimization", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training and inference efficiency of deep neural networks highly rely on the\nperformance of tensor operators on hardware platforms. Manually optimizing\ntensor operators has limitations in terms of supporting new operators or\nhardware platforms. Therefore, automatically optimizing device code\nconfigurations of tensor operators is getting increasingly attractive. However,\ncurrent methods for tensor operator optimization usually suffer from poor\nsample-efficiency due to the combinatorial search space. In this work, we\npropose a novel evolutionary method, OpEvo, which efficiently explores the\nsearch spaces of tensor operators by introducing a topology-aware mutation\noperation based on q-random walk to leverage the topological structures over\nthe search spaces. Our comprehensive experiment results show that compared with\nstate-of-the-art (SOTA) methods OpEvo can find the best configuration with the\nlowest variance and least efforts in the number of trials and wall-clock time.\nAll code of this work is available online.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 05:33:33 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 08:02:18 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Gao", "Xiaotian", ""], ["Wei", "Cui", ""], ["Zhang", "Lintao", ""], ["Yang", "Mao", ""]]}, {"id": "2006.05725", "submitter": "Michael Gimelfarb Mr.", "authors": "Michael Gimelfarb, Scott Sanner, Chi-Guhn Lee", "title": "Bayesian Experience Reuse for Learning from Multiple Demonstrators", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from demonstrations (LfD) improves the exploration efficiency of a\nlearning agent by incorporating demonstrations from experts. However,\ndemonstration data can often come from multiple experts with conflicting goals,\nmaking it difficult to incorporate safely and effectively in online settings.\nWe address this problem in the static and dynamic optimization settings by\nmodelling the uncertainty in source and target task functions using\nnormal-inverse-gamma priors, whose corresponding posteriors are, respectively,\nlearned from demonstrations and target data using Bayesian neural networks with\nshared features. We use this learned belief to derive a quadratic programming\nproblem whose solution yields a probability distribution over the expert\nmodels. Finally, we propose Bayesian Experience Reuse (BERS) to sample\ndemonstrations in accordance with this distribution and reuse them directly in\nnew tasks. We demonstrate the effectiveness of this approach for static\noptimization of smooth functions, and transfer learning in a high-dimensional\nsupply chain problem with cost uncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 08:32:39 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Gimelfarb", "Michael", ""], ["Sanner", "Scott", ""], ["Lee", "Chi-Guhn", ""]]}, {"id": "2006.05832", "submitter": "Samuel Schmidgall", "authors": "Samuel Schmidgall", "title": "Adaptive Reinforcement Learning through Evolving Self-Modifying Neural\n  Networks", "comments": "GECCO'2020 Poster: Submitted and accepted", "journal-ref": "Proc. of GECCO 2020", "doi": "10.1145/3377929.3389901", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adaptive learning capabilities seen in biological neural networks are\nlargely a product of the self-modifying behavior emerging from online plastic\nchanges in synaptic connectivity. Current methods in Reinforcement Learning\n(RL) only adjust to new interactions after reflection over a specified time\ninterval, preventing the emergence of online adaptivity. Recent work addressing\nthis by endowing artificial neural networks with neuromodulated plasticity have\nbeen shown to improve performance on simple RL tasks trained using\nbackpropagation, but have yet to scale up to larger problems. Here we study the\nproblem of meta-learning in a challenging quadruped domain, where each leg of\nthe quadruped has a chance of becoming unusable, requiring the agent to adapt\nby continuing locomotion with the remaining limbs. Results demonstrate that\nagents evolved using self-modifying plastic networks are more capable of\nadapting to complex meta-learning learning tasks, even outperforming the same\nnetwork updated using gradient-based algorithms while taking less time to\ntrain.\n", "versions": [{"version": "v1", "created": "Fri, 22 May 2020 02:24:44 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Schmidgall", "Samuel", ""]]}, {"id": "2006.05868", "submitter": "Anup Das", "authors": "Shihao Song, Anup Das, Nagarajan Kandasamy", "title": "Improving Dependability of Neuromorphic Computing With Non-Volatile\n  Memory", "comments": "8 pages, 13 figures, accepted in 16th European Dependable Computing\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As process technology continues to scale aggressively, circuit aging in a\nneuromorphic hardware due to negative bias temperature instability (NBTI) and\ntime-dependent dielectric breakdown (TDDB) is becoming a critical reliability\nissue and is expected to proliferate when using non-volatile memory (NVM) for\nsynaptic storage. This is because an NVM requires high voltage and current to\naccess its synaptic weight, which further accelerates the circuit aging in a\nneuromorphic hardware. Current methods for qualifying reliability are overly\nconservative, since they estimate circuit aging considering worst-case\noperating conditions and unnecessarily constrain performance. This paper\nproposes RENEU, a reliability-oriented approach to map machine learning\napplications to neuromorphic hardware, with the aim of improving system-wide\nreliability without compromising key performance metrics such as execution time\nof these applications on the hardware. Fundamental to RENEU is a novel\nformulation of the aging of CMOS-based circuits in a neuromorphic hardware\nconsidering different failure mechanisms. Using this formulation, RENEU\ndevelops a system-wide reliability model which can be used inside a\ndesign-space exploration framework involving the mapping of neurons and\nsynapses to the hardware. To this end, RENEU uses an instance of Particle Swarm\nOptimization (PSO) to generate mappings that are Pareto-optimal in terms of\nperformance and reliability. We evaluate RENEU using different machine learning\napplications on a state-of-the-art neuromorphic hardware with NVM synapses. Our\nresults demonstrate an average 38\\% reduction in circuit aging, leading to an\naverage 18% improvement in the lifetime of the hardware compared to current\npractices. RENEU only introduces a marginal performance overhead of 5% compared\nto a performance-oriented state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 14:50:28 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Song", "Shihao", ""], ["Das", "Anup", ""], ["Kandasamy", "Nagarajan", ""]]}, {"id": "2006.05889", "submitter": "Furong Ye", "authors": "Furong Ye and Hao Wang and Carola Doerr and Thomas B\\\"ack", "title": "Benchmarking a $(\\mu+\\lambda)$ Genetic Algorithm with Configurable\n  Crossover Probability", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-58115-2_49", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a family of $(\\mu+\\lambda)$ Genetic Algorithms (GAs) which\ncreates offspring either from mutation or by recombining two randomly chosen\nparents. By scaling the crossover probability, we can thus interpolate from a\nfully mutation-only algorithm towards a fully crossover-based GA. We analyze,\nby empirical means, how the performance depends on the interplay of population\nsize and the crossover probability.\n  Our comparison on 25 pseudo-Boolean optimization problems reveals an\nadvantage of crossover-based configurations on several easy optimization tasks,\nwhereas the picture for more complex optimization problems is rather mixed.\nMoreover, we observe that the ``fast'' mutation scheme with its are power-law\ndistributed mutation strengths outperforms standard bit mutation on complex\noptimization tasks when it is combined with crossover, but performs worse in\nthe absence of crossover.\n  We then take a closer look at the surprisingly good performance of the\ncrossover-based $(\\mu+\\lambda)$ GAs on the well-known LeadingOnes benchmark\nproblem. We observe that the optimal crossover probability increases with\nincreasing population size $\\mu$. At the same time, it decreases with\nincreasing problem dimension, indicating that the advantages of the crossover\nare not visible in the asymptotic view classically applied in runtime analysis.\nWe therefore argue that a mathematical investigation for fixed dimensions might\nhelp us observe effects which are not visible when focusing exclusively on\nasymptotic performance bounds.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 15:22:44 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Ye", "Furong", ""], ["Wang", "Hao", ""], ["Doerr", "Carola", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2006.05918", "submitter": "Abenezer Girma Mr", "authors": "Abenezer Girma, Seifemichael Amsalu, Abrham Workineh, Mubbashar Khan,\n  Abdollah Homaifar", "title": "Deep Learning with Attention Mechanism for Predicting Driver Intention\n  at Intersection", "comments": "IEEE Intelligent Vehicles Symposium 2020 (IEEE IV 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a driver's intention prediction near a road intersection is\nproposed. Our approach uses a deep bidirectional Long Short-Term Memory (LSTM)\nwith an attention mechanism model based on a hybrid-state system (HSS)\nframework. As intersection is considered to be as one of the major source of\nroad accidents, predicting a driver's intention at an intersection is very\ncrucial. Our method uses a sequence to sequence modeling with an attention\nmechanism to effectively exploit temporal information out of the time-series\nvehicular data including velocity and yaw-rate. The model then predicts ahead\nof time whether the target vehicle/driver will go straight, stop, or take right\nor left turn. The performance of the proposed approach is evaluated on a\nnaturalistic driving dataset and results show that our method achieves high\naccuracy as well as outperforms other methods. The proposed solution is\npromising to be applied in advanced driver assistance systems (ADAS) and as\npart of active safety system of autonomous vehicles.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 16:12:00 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Girma", "Abenezer", ""], ["Amsalu", "Seifemichael", ""], ["Workineh", "Abrham", ""], ["Khan", "Mubbashar", ""], ["Homaifar", "Abdollah", ""]]}, {"id": "2006.06183", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "G5: A Universal GRAPH-BERT for Graph-to-Graph Transfer and Apocalypse\n  Learning", "comments": "Keywords: Graph-Bert; Representation Learning; Apocalypse Learning;\n  Transfer Learning; Graph Mining; Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent GRAPH-BERT model introduces a new approach to learning graph\nrepresentations merely based on the attention mechanism. GRAPH-BERT provides an\nopportunity for transferring pre-trained models and learned graph\nrepresentations across different tasks within the same graph dataset. In this\npaper, we will further investigate the graph-to-graph transfer of a universal\nGRAPH-BERT for graph representation learning across different graph datasets,\nand our proposed model is also referred to as the G5 for simplicity. Many\nchallenges exist in learning G5 to adapt the distinct input and output\nconfigurations for each graph data source, as well as the information\ndistributions differences. G5 introduces a pluggable model architecture: (a)\neach data source will be pre-processed with a unique input representation\nlearning component; (b) each output application task will also have a specific\nfunctional component; and (c) all such diverse input and output components will\nall be conjuncted with a universal GRAPH-BERT core component via an input size\nunification layer and an output representation fusion layer, respectively.\n  The G5 model removes the last obstacle for cross-graph representation\nlearning and transfer. For the graph sources with very sparse training data,\nthe G5 model pre-trained on other graphs can still be utilized for\nrepresentation learning with necessary fine-tuning. What's more, the\narchitecture of G5 also allows us to learn a supervised functional classifier\nfor data sources without any training data at all. Such a problem is also named\nas the Apocalypse Learning task in this paper. Two different label reasoning\nstrategies, i.e., Cross-Source Classification Consistency Maximization (CCCM)\nand Cross-Source Dynamic Routing (CDR), are introduced in this paper to address\nthe problem.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 04:19:18 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "2006.06192", "submitter": "Kanako Esaki", "authors": "Kanako Esaki, Tadayuki Matsumura, Kiyoto Ito and Hiroyuki Mizuno", "title": "Sensorimotor Visual Perception on Embodied System Using Free Energy\n  Principle", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an embodied system based on the free energy principle (FEP) for\nsensorimotor visual perception. We evaluated it in a character-recognition task\nusing the MNIST dataset. Although the FEP has successfully described a rule\nthat living things obey mathematically and claims that a biological system\ncontinues to change its internal models and behaviors to minimize the\ndifference in predicting sensory input, it is not enough to model sensorimotor\nvisual perception. An embodiment of the system is the key to achieving\nsensorimotor visual perception. The proposed embodied system is configured by a\nbody and memory. The body has an ocular motor system controlling the direction\nof eye gaze, which means that the eye can only observe a small focused area of\nthe environment. The memory is not photographic, but is a generative model\nimplemented with a variational autoencoder that contains prior knowledge about\nthe environment, and that knowledge is classified. By limiting body and memory\nabilities and operating according to the FEP, the embodied system repeatedly\ntakes action to obtain the next sensory input based on various potentials of\nfuture sensory inputs. In the evaluation, the inference of the environment was\nrepresented as an approximate posterior distribution of characters (0 - 9). As\nthe number of repetitions increased, the attention area moved continuously,\ngradually reducing the uncertainty of characters. Finally, the probability of\nthe correct character became the highest among the characters. Changing the\ninitial attention position provides a different final distribution, suggesting\nthat the proposed system has a confirmation bias.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 05:03:45 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Esaki", "Kanako", ""], ["Matsumura", "Tadayuki", ""], ["Ito", "Kiyoto", ""], ["Mizuno", "Hiroyuki", ""]]}, {"id": "2006.06282", "submitter": "Zhixi Li", "authors": "Zhixi Li and Vincent Tam", "title": "A Novel Meta-Heuristic Optimization Algorithm Inspired by the Spread of\n  Viruses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the no-free-lunch theorem, there is no single meta-heuristic\nalgorithm that can optimally solve all optimization problems. This motivates\nmany researchers to continuously develop new optimization algorithms. In this\npaper, a novel nature-inspired meta-heuristic optimization algorithm called\nvirus spread optimization (VSO) is proposed. VSO loosely mimics the spread of\nviruses among hosts, and can be effectively applied to solving many challenging\nand continuous optimization problems. We devise a new representation scheme and\nviral operations that are radically different from previously proposed\nvirus-based optimization algorithms. First, the viral RNA of each host in VSO\ndenotes a potential solution for which different viral operations will help to\ndiversify the searching strategies in order to largely enhance the solution\nquality. In addition, an imported infection mechanism, inheriting the searched\noptima from another colony, is introduced to possibly avoid the prematuration\nof any potential solution in solving complex problems. VSO has an excellent\ncapability to conduct adaptive neighborhood searches around the discovered\noptima for achieving better solutions. Furthermore, with a flexible infection\nmechanism, VSO can quickly escape from local optima. To clearly demonstrate\nboth its effectiveness and efficiency, VSO is critically evaluated on a series\nof well-known benchmark functions. Moreover, VSO is validated on its\napplicability through two real-world examples including the financial portfolio\noptimization and optimization of hyper-parameters of support vector machines\nfor classification problems. The results show that VSO has attained superior\nperformance in terms of solution fitness, convergence rate, scalability,\nreliability, and flexibility when compared to those results of the conventional\nas well as state-of-the-art meta-heuristic optimization algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 09:35:28 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Li", "Zhixi", ""], ["Tam", "Vincent", ""]]}, {"id": "2006.06367", "submitter": "Ping Guo", "authors": "Ping Guo, and Qian Yin", "title": "Synergetic Learning Systems: Concept, Architecture, and Algorithms", "comments": "This work is based on first principle for artificial intelligence.\n  Some terminologies and syntax errors are revised in this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drawing on the idea that brain development is a Darwinian process of\n``evolution + selection'' and the idea that the current state is a local\nequilibrium state of many bodies with self-organization and evolution processes\ndriven by the temperature and gravity in our universe, in this work, we\ndescribe an artificial intelligence system called the ``Synergetic Learning\nSystems''. The system is composed of two or more subsystems (models, agents or\nvirtual bodies), and it is an open complex giant system. Inspired by natural\nintelligence, the system achieves intelligent information processing and\ndecision-making in a given environment through cooperative/competitive\nsynergetic learning. The intelligence evolved by the natural law of ``it is not\nthe strongest of the species that survives, but the one most responsive to\nchange,'' while an artificial intelligence system should adopt the law of\n``human selection'' in the evolution process. Therefore, we expect that the\nproposed system architecture can also be adapted in human-machine synergy or\nmulti-agent synergetic systems. It is also expected that under our design\ncriteria, the proposed system will eventually achieve artificial general\nintelligence through long term coevolution.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 06:23:03 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 10:19:17 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Guo", "Ping", ""], ["Yin", "Qian", ""]]}, {"id": "2006.06431", "submitter": "Qinbing Fu", "authors": "Qinbing Fu and Shigang Yue", "title": "Complementary Visual Neuronal Systems Model for Collision Sensing", "comments": "7 pages, 6 figures. This work has been accepted for publication in a\n  future IEEE conference. Copyright has been transferred to the IEEE. This\n  version may no longer be accessible after the conference publication in IEEE\n  Xplore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by insects' visual brains, this paper presents original modelling of\na complementary visual neuronal systems model for real-time and robust\ncollision sensing. Two categories of wide-field motion sensitive neurons, i.e.,\nthe lobula giant movement detectors (LGMDs) in locusts and the lobula plate\ntangential cells (LPTCs) in flies, have been studied, intensively. The LGMDs\nhave specific selectivity to approaching objects in depth that threaten\ncollision; whilst the LPTCs are only sensitive to translating objects in\nhorizontal and vertical directions. Though each has been modelled and applied\nin various visual scenes including robot scenarios, little has been done on\ninvestigating their complementary functionality and selectivity when\nfunctioning together. To fill this vacancy, we introduce a hybrid model\ncombining two LGMDs (LGMD-1 and LGMD-2) with horizontally (rightward and\nleftward) sensitive LPTCs (LPTC-R and LPTC-L) specialising in fast collision\nperception. With coordination and competition between different activated\nneurons, the proximity feature by frontal approaching stimuli can be largely\nsharpened up by suppressing translating and receding motions. The proposed\nmethod has been implemented in ground micro-mobile robots as embedded systems.\nThe multi-robot experiments have demonstrated the effectiveness and robustness\nof the proposed model for frontal collision sensing, which outperforms previous\nsingle-type neuron computation methods against translating interference.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 13:40:59 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Fu", "Qinbing", ""], ["Yue", "Shigang", ""]]}, {"id": "2006.06438", "submitter": "Nasir Ahmad", "authors": "Nasir Ahmad, Marcel A. J. van Gerven, Luca Ambrogioni", "title": "GAIT-prop: A biologically plausible learning rule derived from\n  backpropagation of error", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional backpropagation of error, though a highly successful algorithm\nfor learning in artificial neural network models, includes features which are\nbiologically implausible for learning in real neural circuits. An alternative\ncalled target propagation proposes to solve this implausibility by using a\ntop-down model of neural activity to convert an error at the output of a neural\nnetwork into layer-wise and plausible 'targets' for every unit. These targets\ncan then be used to produce weight updates for network training. However, thus\nfar, target propagation has been heuristically proposed without demonstrable\nequivalence to backpropagation. Here, we derive an exact correspondence between\nbackpropagation and a modified form of target propagation (GAIT-prop) where the\ntarget is a small perturbation of the forward pass. Specifically,\nbackpropagation and GAIT-prop give identical updates when synaptic weight\nmatrices are orthogonal. In a series of simple computer vision experiments, we\nshow near-identical performance between backpropagation and GAIT-prop with a\nsoft orthogonality-inducing regularizer.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 13:52:03 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 08:36:36 GMT"}, {"version": "v3", "created": "Thu, 5 Nov 2020 18:07:34 GMT"}], "update_date": "2020-11-06", "authors_parsed": [["Ahmad", "Nasir", ""], ["van Gerven", "Marcel A. J.", ""], ["Ambrogioni", "Luca", ""]]}, {"id": "2006.06449", "submitter": "Stef Maree", "authors": "S. C. Maree, T. Alderliesten, P. A. N. Bosman", "title": "Ensuring smoothly navigable approximation sets by Bezier curve\n  parameterizations in evolutionary bi-objective optimization -- applied to\n  brachytherapy treatment planning for prostate cancer", "comments": "PPSN2020 (Parallel Problem Solving from Nature)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of bi-objective optimization is to obtain an approximation set of\n(near) Pareto optimal solutions. A decision maker then navigates this set to\nselect a final desired solution, often using a visualization of the\napproximation front. The front provides a navigational ordering of solutions to\ntraverse, but this ordering does not necessarily map to a smooth trajectory\nthrough decision space. This forces the decision maker to inspect the decision\nvariables of each solution individually, potentially making navigation of the\napproximation set unintuitive. In this work, we aim to improve approximation\nset navigability by enforcing a form of smoothness or continuity between\nsolutions in terms of their decision variables. Imposing smoothness as a\nrestriction upon common domination-based multi-objective evolutionary\nalgorithms is not straightforward. Therefore, we use the recently introduced\nuncrowded hypervolume (UHV) to reformulate the multi-objective optimization\nproblem as a single-objective problem in which parameterized approximation sets\nare directly optimized. We study here the case of parameterizing approximation\nsets as smooth Bezier curves in decision space. We approach the resulting\nsingle-objective problem with the gene-pool optimal mixing evolutionary\nalgorithm (GOMEA), and we call the resulting algorithm BezEA. We analyze the\nbehavior of BezEA and compare it to optimization of the UHV with GOMEA as well\nas the domination-based multi-objective GOMEA. We show that high-quality\napproximation sets can be obtained with BezEA, sometimes even outperforming the\ndomination- and UHV-based algorithms, while smoothness of the navigation\ntrajectory through decision space is guaranteed.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 13:57:33 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Maree", "S. C.", ""], ["Alderliesten", "T.", ""], ["Bosman", "P. A. N.", ""]]}, {"id": "2006.06493", "submitter": "Nataniel Ruiz", "authors": "Nataniel Ruiz, Sarah Adel Bargal, Stan Sclaroff", "title": "Protecting Against Image Translation Deepfakes by Leaking Universal\n  Perturbations from Black-Box Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop efficient disruptions of black-box image translation\ndeepfake generation systems. We are the first to demonstrate black-box deepfake\ngeneration disruption by presenting image translation formulations of attacks\ninitially proposed for classification models. Nevertheless, a naive adaptation\nof classification black-box attacks results in a prohibitive number of queries\nfor image translation systems in the real-world. We present a frustratingly\nsimple yet highly effective algorithm Leaking Universal Perturbations (LUP),\nthat significantly reduces the number of queries needed to attack an image. LUP\nconsists of two phases: (1) a short leaking phase where we attack the network\nusing traditional black-box attacks and gather information on successful\nattacks on a small dataset and (2) and an exploitation phase where we leverage\nsaid information to subsequently attack the network with improved efficiency.\nOur attack reduces the total number of queries necessary to attack GANimation\nand StarGAN by 30%.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 15:02:27 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Ruiz", "Nataniel", ""], ["Bargal", "Sarah Adel", ""], ["Sclaroff", "Stan", ""]]}, {"id": "2006.06494", "submitter": "Eric Guizzo", "authors": "Eric Guizzo, Tillman Weyde, Giacomo Tarroni", "title": "Anti-Transfer Learning for Task Invariance in Convolutional Neural\n  Networks for Speech Processing", "comments": "Neural Networks Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We introduce the novel concept of anti-transfer learning for speech\nprocessing with convolutional neural networks. While transfer learning assumes\nthat the learning process for a target task will benefit from re-using\nrepresentations learned for another task, anti-transfer avoids the learning of\nrepresentations that have been learned for an orthogonal task, i.e., one that\nis not relevant and potentially misleading for the target task, such as speaker\nidentity for speech recognition or speech content for emotion recognition. In\nanti-transfer learning, we penalize similarity between activations of a network\nbeing trained and another one previously trained on an orthogonal task, which\nyields more suitable representations. This leads to better generalization and\nprovides a degree of control over correlations that are spurious or\nundesirable, e.g. to avoid social bias. We have implemented anti-transfer for\nconvolutional neural networks in different configurations with several\nsimilarity metrics and aggregation functions, which we evaluate and analyze\nwith several speech and audio tasks and settings, using six datasets. We show\nthat anti-transfer actually leads to the intended invariance to the orthogonal\ntask and to more appropriate features for the target task at hand.\nAnti-transfer learning consistently improves classification accuracy in all\ntest cases. While anti-transfer creates computation and memory cost at training\ntime, there is relatively little computation cost when using pre-trained models\nfor orthogonal tasks. Anti-transfer is widely applicable and particularly\nuseful where a specific invariance is desirable or where trained models are\navailable and labeled data for orthogonal tasks are difficult to obtain.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 15:03:29 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2021 11:15:35 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Guizzo", "Eric", ""], ["Weyde", "Tillman", ""], ["Tarroni", "Giacomo", ""]]}, {"id": "2006.06586", "submitter": "Diederick Vermetten", "authors": "Diederick Vermetten, Hao Wang, Carola Doerr, Thomas B\\\"ack", "title": "Towards Dynamic Algorithm Selection for Numerical Black-Box\n  Optimization: Investigating BBOB as a Use Case", "comments": null, "journal-ref": null, "doi": "10.1145/3377930.3390189", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most challenging problems in evolutionary computation is to select\nfrom its family of diverse solvers one that performs well on a given problem.\nThis algorithm selection problem is complicated by the fact that different\nphases of the optimization process require different search behavior. While\nthis can partly be controlled by the algorithm itself, there exist large\ndifferences between algorithm performance. It can therefore be beneficial to\nswap the configuration or even the entire algorithm during the run. Long deemed\nimpractical, recent advances in Machine Learning and in exploratory landscape\nanalysis give hope that this dynamic algorithm configuration~(dynAC) can\neventually be solved by automatically trained configuration schedules. With\nthis work we aim at promoting research on dynAC, by introducing a simpler\nvariant that focuses only on switching between different algorithms, not\nconfigurations. Using the rich data from the Black Box Optimization\nBenchmark~(BBOB) platform, we show that even single-switch dynamic Algorithm\nselection (dynAS) can potentially result in significant performance gains. We\nalso discuss key challenges in dynAS, and argue that the BBOB-framework can\nbecome a useful tool in overcoming these.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 16:36:11 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Vermetten", "Diederick", ""], ["Wang", "Hao", ""], ["Doerr", "Carola", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2006.06629", "submitter": "Ali Akoglu", "authors": "John Mixter and Ali Akoglu", "title": "Growing Artificial Neural Networks", "comments": "14 pages, Accepted for publication in Springer Nature - Book Series:\n  Transactions on Computational Science and Computational Intelligence,\n  Advances in Artificial Intelligence and Applied Cognitive Computing -\n  Springer ID: 89066307 (Book ID: 495585_1_En)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning is a legitimate method for reducing the size of a neural network to\nfit in low SWaP hardware, but the networks must be trained and pruned offline.\nWe propose an algorithm, Artificial Neurogenesis (ANG), that grows rather than\nprunes the network and enables neural networks to be trained and executed in\nlow SWaP embedded hardware. ANG accomplishes this by using the training data to\ndetermine critical connections between layers before the actual training takes\nplace. Our experiments use a modified LeNet-5 as a baseline neural network that\nachieves a test accuracy of 98.74% using a total of 61,160 weights. An ANG\ngrown network achieves a test accuracy of 98.80% with only 21,211 weights.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 17:25:51 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Mixter", "John", ""], ["Akoglu", "Ali", ""]]}, {"id": "2006.06657", "submitter": "Matus Telgarsky", "authors": "Ziwei Ji and Matus Telgarsky", "title": "Directional convergence and alignment in deep learning", "comments": "To appear, NeuRIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that although the minimizers of cross-entropy and\nrelated classification losses are off at infinity, network weights learned by\ngradient flow converge in direction, with an immediate corollary that network\npredictions, training errors, and the margin distribution also converge. This\nproof holds for deep homogeneous networks -- a broad class of networks allowing\nfor ReLU, max-pooling, linear, and convolutional layers -- and we additionally\nprovide empirical support not just close to the theory (e.g., the AlexNet), but\nalso on non-homogeneous networks (e.g., the DenseNet). If the network further\nhas locally Lipschitz gradients, we show that these gradients also converge in\ndirection, and asymptotically align with the gradient flow path, with\nconsequences on margin maximization, convergence of saliency maps, and a few\nother settings. Our analysis complements and is distinct from the well-known\nneural tangent and mean-field theories, and in particular makes no requirements\non network width and initialization, instead merely requiring perfect\nclassification accuracy. The proof proceeds by developing a theory of unbounded\nnonsmooth Kurdyka-{\\L}ojasiewicz inequalities for functions definable in an\no-minimal structure, and is also applicable outside deep learning.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 17:50:11 GMT"}, {"version": "v2", "created": "Mon, 26 Oct 2020 09:28:42 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Ji", "Ziwei", ""], ["Telgarsky", "Matus", ""]]}, {"id": "2006.06676", "submitter": "Samuli Laine", "authors": "Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko\n  Lehtinen, Timo Aila", "title": "Training Generative Adversarial Networks with Limited Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training generative adversarial networks (GAN) using too little data\ntypically leads to discriminator overfitting, causing training to diverge. We\npropose an adaptive discriminator augmentation mechanism that significantly\nstabilizes training in limited data regimes. The approach does not require\nchanges to loss functions or network architectures, and is applicable both when\ntraining from scratch and when fine-tuning an existing GAN on another dataset.\nWe demonstrate, on several datasets, that good results are now possible using\nonly a few thousand training images, often matching StyleGAN2 results with an\norder of magnitude fewer images. We expect this to open up new application\ndomains for GANs. We also find that the widely used CIFAR-10 is, in fact, a\nlimited data benchmark, and improve the record FID from 5.59 to 2.42.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 17:06:34 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 17:09:24 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Karras", "Tero", ""], ["Aittala", "Miika", ""], ["Hellsten", "Janne", ""], ["Laine", "Samuli", ""], ["Lehtinen", "Jaakko", ""], ["Aila", "Timo", ""]]}, {"id": "2006.06730", "submitter": "Joseph Romano", "authors": "Joseph D. Romano, Trang T. Le, Weixuan Fu, and Jason H. Moore", "title": "Is deep learning necessary for simple classification tasks?", "comments": "14 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automated machine learning (AutoML) and deep learning (DL) are two\ncutting-edge paradigms used to solve a myriad of inductive learning tasks. In\nspite of their successes, little guidance exists for when to choose one\napproach over the other in the context of specific real-world problems.\nFurthermore, relatively few tools exist that allow the integration of both\nAutoML and DL in the same analysis to yield results combining both of their\nstrengths. Here, we seek to address both of these issues, by (1.) providing a\nhead-to-head comparison of AutoML and DL in the context of binary\nclassification on 6 well-characterized public datasets, and (2.) evaluating a\nnew tool for genetic programming-based AutoML that incorporates deep\nestimators. Our observations suggest that AutoML outperforms simple DL\nclassifiers when trained on similar datasets for binary classification but\nintegrating DL into AutoML improves classification performance even further.\nHowever, the substantial time needed to train AutoML+DL pipelines will likely\noutweigh performance advantages in many applications.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 18:41:47 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Romano", "Joseph D.", ""], ["Le", "Trang T.", ""], ["Fu", "Weixuan", ""], ["Moore", "Jason H.", ""]]}, {"id": "2006.06762", "submitter": "Lianmin Zheng", "authors": "Lianmin Zheng, Chengfan Jia, Minmin Sun, Zhao Wu, Cody Hao Yu, Ameer\n  Haj-Ali, Yida Wang, Jun Yang, Danyang Zhuo, Koushik Sen, Joseph E. Gonzalez,\n  Ion Stoica", "title": "Ansor : Generating High-Performance Tensor Programs for Deep Learning", "comments": "Published in OSDI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.PF cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-performance tensor programs are crucial to guarantee efficient execution\nof deep neural networks. However, obtaining performant tensor programs for\ndifferent operators on various hardware platforms is notoriously challenging.\nCurrently, deep learning systems rely on vendor-provided kernel libraries or\nvarious search strategies to get performant tensor programs. These approaches\neither require significant engineering effort to develop platform-specific\noptimization code or fall short of finding high-performance programs due to\nrestricted search space and ineffective exploration strategy.\n  We present Ansor, a tensor program generation framework for deep learning\napplications. Compared with existing search strategies, Ansor explores many\nmore optimization combinations by sampling programs from a hierarchical\nrepresentation of the search space. Ansor then fine-tunes the sampled programs\nwith evolutionary search and a learned cost model to identify the best\nprograms. Ansor can find high-performance programs that are outside the search\nspace of existing state-of-the-art approaches. In addition, Ansor utilizes a\ntask scheduler to simultaneously optimize multiple subgraphs in deep neural\nnetworks. We show that Ansor improves the execution performance of deep neural\nnetworks relative to the state-of-the-art on the Intel CPU, ARM CPU, and NVIDIA\nGPU by up to $3.8\\times$, $2.6\\times$, and $1.7\\times$, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 19:40:09 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 16:21:22 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2020 18:32:44 GMT"}, {"version": "v4", "created": "Wed, 4 Nov 2020 07:29:29 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Zheng", "Lianmin", ""], ["Jia", "Chengfan", ""], ["Sun", "Minmin", ""], ["Wu", "Zhao", ""], ["Yu", "Cody Hao", ""], ["Haj-Ali", "Ameer", ""], ["Wang", "Yida", ""], ["Yang", "Jun", ""], ["Zhuo", "Danyang", ""], ["Sen", "Koushik", ""], ["Gonzalez", "Joseph E.", ""], ["Stoica", "Ion", ""]]}, {"id": "2006.06777", "submitter": "Anup Das", "authors": "Adarsha Balaji and Thibaut Marty and Anup Das and Francky Catthoor", "title": "Run-time Mapping of Spiking Neural Networks to Neuromorphic Hardware", "comments": "Accepted in Springer Journal of Signal Processing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a design methodology to partition and map the\nneurons and synapses of online learning SNN-based applications to neuromorphic\narchitectures at {run-time}. Our design methodology operates in two steps --\nstep 1 is a layer-wise greedy approach to partition SNNs into clusters of\nneurons and synapses incorporating the constraints of the neuromorphic\narchitecture, and step 2 is a hill-climbing optimization algorithm that\nminimizes the total spikes communicated between clusters, improving energy\nconsumption on the shared interconnect of the architecture. We conduct\nexperiments to evaluate the feasibility of our algorithm using synthetic and\nrealistic SNN-based applications. We demonstrate that our algorithm reduces SNN\nmapping time by an average 780x compared to a state-of-the-art design-time\nbased SNN partitioning approach with only 6.25\\% lower solution quality.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 19:56:55 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Balaji", "Adarsha", ""], ["Marty", "Thibaut", ""], ["Das", "Anup", ""], ["Catthoor", "Francky", ""]]}, {"id": "2006.06780", "submitter": "Balint Daroczy", "authors": "B\\'alint Dar\\'oczy", "title": "Tangent Space Sensitivity and Distribution of Linear Regions in ReLU\n  Networks", "comments": "14 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent articles indicate that deep neural networks are efficient models for\nvarious learning problems. However they are often highly sensitive to various\nchanges that cannot be detected by an independent observer. As our\nunderstanding of deep neural networks with traditional generalization bounds\nstill remains incomplete, there are several measures which capture the\nbehaviour of the model in case of small changes at a specific state. In this\npaper we consider adversarial stability in the tangent space and suggest\ntangent sensitivity in order to characterize stability. We focus on a\nparticular kind of stability with respect to changes in parameters that are\ninduced by individual examples without known labels. We derive several easily\ncomputable bounds and empirical measures for feed-forward fully connected ReLU\n(Rectified Linear Unit) networks and connect tangent sensitivity to the\ndistribution of the activation regions in the input space realized by the\nnetwork. Our experiments suggest that even simple bounds and measures are\nassociated with the empirical generalization gap.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 20:02:51 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Dar\u00f3czy", "B\u00e1lint", ""]]}, {"id": "2006.06863", "submitter": "Yiyang Zhao", "authors": "Yiyang Zhao, Linnan Wang, Yuandong Tian, Rodrigo Fonseca, Tian Guo", "title": "Few-shot Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient evaluation of a network architecture drawn from a large search\nspace remains a key challenge in Neural Architecture Search (NAS). Vanilla NAS\nevaluates each architecture by training from scratch, which gives the true\nperformance but is extremely time-consuming. Recently, one-shot NAS\nsubstantially reduces the computation cost by training only one supernetwork,\na.k.a. supernet, to approximate the performance of every architecture in the\nsearch space via weight-sharing. However, the performance estimation can be\nvery inaccurate due to the co-adaption among operations. In this paper, we\npropose few-shot NAS that uses multiple supernetworks, called sub-supernet,\neach covering different regions of the search space to alleviate the undesired\nco-adaption. Compared to one-shot NAS, few-shot NAS improves the accuracy of\narchitecture evaluation with a small increase of evaluation cost. With only up\nto 7 sub-supernets, few-shot NAS establishes new SoTAs: on ImageNet, it finds\nmodels that reach 80.5% top-1 accuracy at 600 MB FLOPS and 77.5% top-1 accuracy\nat 238 MFLOPS; on CIFAR10, it reaches 98.72% top-1 accuracy without using extra\ndata or transfer learning. In Auto-GAN, few-shot NAS outperforms the previously\npublished results by up to 20%. Extensive experiments show that few-shot NAS\nsignificantly improves various one-shot methods, including 4 gradient-based and\n6 search-based methods on 3 different tasks in NasBench-201 and\nNasBench1-shot-1.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 22:36:01 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 16:15:04 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 14:18:34 GMT"}, {"version": "v4", "created": "Fri, 19 Jun 2020 15:49:05 GMT"}, {"version": "v5", "created": "Mon, 12 Oct 2020 23:52:46 GMT"}, {"version": "v6", "created": "Wed, 14 Oct 2020 02:43:28 GMT"}, {"version": "v7", "created": "Mon, 10 May 2021 01:34:27 GMT"}, {"version": "v8", "created": "Tue, 15 Jun 2021 19:02:34 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Zhao", "Yiyang", ""], ["Wang", "Linnan", ""], ["Tian", "Yuandong", ""], ["Fonseca", "Rodrigo", ""], ["Guo", "Tian", ""]]}, {"id": "2006.06880", "submitter": "Alexander Shekhovtsov", "authors": "Alexander Shekhovtsov, Viktor Yanush", "title": "Reintroducing Straight-Through Estimators as Principled Methods for\n  Stochastic Binary Networks", "comments": "30 pages, ICLR version (rejected)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training neural networks with binary weights and activations is a challenging\nproblem due to the lack of gradients and difficulty of optimization over\ndiscrete weights. Many successful experimental results have been achieved with\nempirical straight-through (ST) approaches, proposing a variety of ad-hoc rules\nfor propagating gradients through non-differentiable activations and updating\ndiscrete weights. At the same time, ST methods can be truly derived as\nestimators in the stochastic binary network (SBN) model with Bernoulli weights.\nWe advance these derivations to a more complete and systematic study. We\nanalyze properties, estimation accuracy, obtain different forms of correct ST\nestimators for activations and weights, explain existing empirical approaches\nand their shortcomings, explain how latent weights arise from the mirror\ndescent method when optimizing over probabilities. This allows to reintroduce,\nonce empirical, ST methods as sound approximations, apply them with clarity and\ndevelop further improvements.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2020 23:58:18 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 15:48:44 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Shekhovtsov", "Alexander", ""], ["Yanush", "Viktor", ""]]}, {"id": "2006.06893", "submitter": "Chandra Swarathesh Addanki", "authors": "Chandra Swarathesh Addanki", "title": "Online Sequential Extreme Learning Machines: Features Combined From\n  Hundreds of Midlayers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop an algorithm called hierarchal online sequential\nlearning algorithm (H-OS-ELM) for single feed feedforward network with features\ncombined from hundreds of midlayers, the algorithm can learn chunk by chunk\nwith fixed or varying block size, we believe that the diverse selectivity of\nneurons in top layers which consists of encoded distributed information\nproduced by the other neurons offers better computational advantage over\ninference accuracy. Thus this paper proposes a Hierarchical model framework\ncombined with Online-Sequential learning algorithm, Firstly the model consists\nof subspace feature extractor which consists of subnetwork neuron, using the\nsub-features which is result of the feature extractor in first layer of the\nhierarchy we get rid of irrelevant factors which are of no use for the learning\nand iterate this process so that to recast the the subfeatures into the\nhierarchical model to be processed into more acceptable cognition. Secondly by\nusing OS-Elm we are using non-iterative style for learning we are implementing\na network which is wider and shallow which plays a important role in\ngeneralizing the overall performance which in turn boosts up the learning speed\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 00:50:04 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Addanki", "Chandra Swarathesh", ""]]}, {"id": "2006.06902", "submitter": "Guruprasad Raghavan", "authors": "Guruprasad Raghavan, Cong Lin, Matt Thomson", "title": "Self-organization of multi-layer spiking neural networks", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Living neural networks in our brains autonomously self-organize into large,\ncomplex architectures during early development to result in an organized and\nfunctional organic computational device. A key mechanism that enables the\nformation of complex architecture in the developing brain is the emergence of\ntraveling spatio-temporal waves of neuronal activity across the growing brain.\nInspired by this strategy, we attempt to efficiently self-organize large neural\nnetworks with an arbitrary number of layers into a wide variety of\narchitectures. To achieve this, we propose a modular tool-kit in the form of a\ndynamical system that can be seamlessly stacked to assemble multi-layer neural\nnetworks. The dynamical system encapsulates the dynamics of spiking units,\ntheir inter/intra layer interactions as well as the plasticity rules that\ncontrol the flow of information between layers. The key features of our\ntool-kit are (1) autonomous spatio-temporal waves across multiple layers\ntriggered by activity in the preceding layer and (2) Spike-timing dependent\nplasticity (STDP) learning rules that update the inter-layer connectivity based\non wave activity in the connecting layers. Our framework leads to the\nself-organization of a wide variety of architectures, ranging from multi-layer\nperceptrons to autoencoders. We also demonstrate that emergent waves can\nself-organize spiking network architecture to perform unsupervised learning,\nand networks can be coupled with a linear classifier to perform classification\non classic image datasets like MNIST. Broadly, our work shows that a dynamical\nsystems framework for learning can be used to self-organize large computational\ndevices.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 01:44:48 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Raghavan", "Guruprasad", ""], ["Lin", "Cong", ""], ["Thomson", "Matt", ""]]}, {"id": "2006.06958", "submitter": "Seyed Iman Mirzadeh", "authors": "Seyed Iman Mirzadeh, Mehrdad Farajtabar, Razvan Pascanu, Hassan\n  Ghasemzadeh", "title": "Understanding the Role of Training Regimes in Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting affects the training of neural networks, limiting\ntheir ability to learn multiple tasks sequentially. From the perspective of the\nwell established plasticity-stability dilemma, neural networks tend to be\noverly plastic, lacking the stability necessary to prevent the forgetting of\nprevious knowledge, which means that as learning progresses, networks tend to\nforget previously seen tasks. This phenomenon coined in the continual learning\nliterature, has attracted much attention lately, and several families of\napproaches have been proposed with different degrees of success. However, there\nhas been limited prior work extensively analyzing the impact that different\ntraining regimes -- learning rate, batch size, regularization method-- can have\non forgetting. In this work, we depart from the typical approach of altering\nthe learning algorithm to improve stability. Instead, we hypothesize that the\ngeometrical properties of the local minima found for each task play an\nimportant role in the overall degree of forgetting. In particular, we study the\neffect of dropout, learning rate decay, and batch size, on forming training\nregimes that widen the tasks' local minima and consequently, on helping it not\nto forget catastrophically. Our study provides practical insights to improve\nstability via simple yet effective techniques that outperform alternative\nbaselines.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 06:00:27 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Mirzadeh", "Seyed Iman", ""], ["Farajtabar", "Mehrdad", ""], ["Pascanu", "Razvan", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "2006.07019", "submitter": "Carsten Witt", "authors": "Timo K\\\"otzing and Carsten Witt", "title": "Improved Fixed-Budget Results via Drift Analysis", "comments": "25 pages. An extended abstract of this paper will be published in the\n  proceedings of PPSN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fixed-budget theory is concerned with computing or bounding the fitness value\nachievable by randomized search heuristics within a given budget of fitness\nfunction evaluations. Despite recent progress in fixed-budget theory, there is\na lack of general tools to derive such results. We transfer drift theory, the\nkey tool to derive expected optimization times, to the fixed-budged\nperspective. A first and easy-to-use statement concerned with iterating drift\nin so-called greed-admitting scenarios immediately translates into bounds on\nthe expected function value. Afterwards, we consider a more general tool based\non the well-known variable drift theorem. Applications of this technique to the\nLeadingOnes benchmark function yield statements that are more precise than the\nprevious state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 09:04:37 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["K\u00f6tzing", "Timo", ""], ["Witt", "Carsten", ""]]}, {"id": "2006.07152", "submitter": "Akka Zemmari", "authors": "Miltiadis Poursanidis (LaBRI), Jenny Benois-Pineau (LaBRI), Akka\n  Zemmari (LaBRI), Boris Mansenca (LaBRI), Aymar de Rugy (INCIA)", "title": "Move-to-Data: A new Continual Learning approach with Deep CNNs,\n  Application for image-class recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-life tasks of application of supervised learning approaches, all\nthe training data are not available at the same time. The examples are lifelong\nimage classification or recognition of environmental objects during interaction\nof instrumented persons with their environment, enrichment of an\nonline-database with more images. It is necessary to pre-train the model at a\n\"training recording phase\" and then adjust it to the new coming data. This is\nthe task of incremental/continual learning approaches. Amongst different\nproblems to be solved by these approaches such as introduction of new\ncategories in the model, refining existing categories to sub-categories and\nextending trained classifiers over them, ... we focus on the problem of\nadjusting pre-trained model with new additional training data for existing\ncategories. We propose a fast continual learning layer at the end of the\nneuronal network. Obtained results are illustrated on the opensource CIFAR\nbenchmark dataset. The proposed scheme yields similar performances as\nretraining but with drastically lower computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 13:04:58 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Poursanidis", "Miltiadis", "", "LaBRI"], ["Benois-Pineau", "Jenny", "", "LaBRI"], ["Zemmari", "Akka", "", "LaBRI"], ["Mansenca", "Boris", "", "LaBRI"], ["de Rugy", "Aymar", "", "INCIA"]]}, {"id": "2006.07232", "submitter": "Jacob Menick", "authors": "Jacob Menick, Erich Elsen, Utku Evci, Simon Osindero, Karen Simonyan,\n  Alex Graves", "title": "A Practical Sparse Approximation for Real Time Recurrent Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current methods for training recurrent neural networks are based on\nbackpropagation through time, which requires storing a complete history of\nnetwork states, and prohibits updating the weights `online' (after every\ntimestep). Real Time Recurrent Learning (RTRL) eliminates the need for history\nstorage and allows for online weight updates, but does so at the expense of\ncomputational costs that are quartic in the state size. This renders RTRL\ntraining intractable for all but the smallest networks, even ones that are made\nhighly sparse.\n  We introduce the Sparse n-step Approximation (SnAp) to the RTRL influence\nmatrix, which only keeps entries that are nonzero within n steps of the\nrecurrent core. SnAp with n=1 is no more expensive than backpropagation, and we\nfind that it substantially outperforms other RTRL approximations with\ncomparable costs such as Unbiased Online Recurrent Optimization. For highly\nsparse networks, SnAp with n=2 remains tractable and can outperform\nbackpropagation through time in terms of learning speed when updates are done\nonline. SnAp becomes equivalent to RTRL when n is large.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 14:38:15 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Menick", "Jacob", ""], ["Elsen", "Erich", ""], ["Evci", "Utku", ""], ["Osindero", "Simon", ""], ["Simonyan", "Karen", ""], ["Graves", "Alex", ""]]}, {"id": "2006.07237", "submitter": "Leon Derczynski", "authors": "Leon Derczynski", "title": "Power Consumption Variation over Activation Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The power that machine learning models consume when making predictions can be\naffected by a model's architecture. This paper presents various estimates of\npower consumption for a range of different activation functions, a core factor\nin neural network model architecture design. Substantial differences in\nhardware performance exist between activation functions. This difference\ninforms how power consumption in machine learning models can be reduced.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 14:40:46 GMT"}], "update_date": "2020-06-15", "authors_parsed": [["Derczynski", "Leon", ""]]}, {"id": "2006.07239", "submitter": "Sebastian Billaudelle", "authors": "Benjamin Cramer, Sebastian Billaudelle, Simeon Kanya, Aron Leibfried,\n  Andreas Gr\\\"ubl, Vitali Karasenko, Christian Pehle, Korbinian Schreiber,\n  Yannik Stradmann, Johannes Weis, Johannes Schemmel, Friedemann Zenke", "title": "Surrogate gradients for analog neuromorphic computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To rapidly process temporal information at a low metabolic cost, biological\nneurons integrate inputs as an analog sum but communicate with spikes, binary\nevents in time. Analog neuromorphic hardware uses the same principles to\nemulate spiking neural networks with exceptional energy-efficiency. However,\ninstantiating high-performing spiking networks on such hardware remains a\nsignificant challenge due to device mismatch and the lack of efficient training\nalgorithms. Here, we introduce a general in-the-loop learning framework based\non surrogate gradients that resolves these issues. Using the BrainScaleS-2\nneuromorphic system, we show that learning self-corrects for device mismatch\nresulting in competitive spiking network performance on both vision and speech\nbenchmarks. Our networks display sparse spiking activity with, on average, far\nless than one spike per hidden neuron and input, perform inference at rates of\nup to 85 k frames/second, and consume less than 200 mW. In summary, our work\nsets several new benchmarks for low-energy spiking network processing on analog\nneuromorphic hardware and paves the way for future on-chip learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 14:45:12 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 17:52:22 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 14:13:26 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Cramer", "Benjamin", ""], ["Billaudelle", "Sebastian", ""], ["Kanya", "Simeon", ""], ["Leibfried", "Aron", ""], ["Gr\u00fcbl", "Andreas", ""], ["Karasenko", "Vitali", ""], ["Pehle", "Christian", ""], ["Schreiber", "Korbinian", ""], ["Stradmann", "Yannik", ""], ["Weis", "Johannes", ""], ["Schemmel", "Johannes", ""], ["Zenke", "Friedemann", ""]]}, {"id": "2006.07495", "submitter": "Joel Lehman", "authors": "Adrien Ecoffet and Jeff Clune and Joel Lehman", "title": "Open Questions in Creating Safe Open-ended AI: Tensions Between Control\n  and Creativity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial life originated and has long studied the topic of open-ended\nevolution, which seeks the principles underlying artificial systems that\ninnovate continually, inspired by biological evolution. Recently, interest has\ngrown within the broader field of AI in a generalization of open-ended\nevolution, here called open-ended search, wherein such questions of\nopen-endedness are explored for advancing AI, whatever the nature of the\nunderlying search algorithm (e.g. evolutionary or gradient-based). For example,\nopen-ended search might design new architectures for neural networks, new\nreinforcement learning algorithms, or most ambitiously, aim at designing\nartificial general intelligence. This paper proposes that open-ended evolution\nand artificial life have much to contribute towards the understanding of\nopen-ended AI, focusing here in particular on the safety of open-ended search.\nThe idea is that AI systems are increasingly applied in the real world, often\nproducing unintended harms in the process, which motivates the growing field of\nAI safety. This paper argues that open-ended AI has its own safety challenges,\nin particular, whether the creativity of open-ended systems can be productively\nand predictably controlled. This paper explains how unique safety problems\nmanifest in open-ended search, and suggests concrete contributions and research\nquestions to explore them. The hope is to inspire progress towards creative,\nuseful, and safe open-ended search algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 22:28:09 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ecoffet", "Adrien", ""], ["Clune", "Jeff", ""], ["Lehman", "Joel", ""]]}, {"id": "2006.07554", "submitter": "Yunhao Tang", "authors": "Yunhao Tang, Krzysztof Choromanski", "title": "Online Hyper-parameter Tuning in Off-policy Learning via Evolutionary\n  Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy learning algorithms have been known to be sensitive to the choice\nof hyper-parameters. However, unlike near on-policy algorithms for which\nhyper-parameters could be optimized via e.g. meta-gradients, similar techniques\ncould not be straightforwardly applied to off-policy learning. In this work, we\npropose a framework which entails the application of Evolutionary Strategies to\nonline hyper-parameter tuning in off-policy learning. Our formulation draws\nclose connections to meta-gradients and leverages the strengths of black-box\noptimization with relatively low-dimensional search spaces. We show that our\nmethod outperforms state-of-the-art off-policy learning baselines with static\nhyper-parameters and recent prior work over a wide range of continuous control\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 03:54:26 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Tang", "Yunhao", ""], ["Choromanski", "Krzysztof", ""]]}, {"id": "2006.07593", "submitter": "Vu Nguyen", "authors": "Vu Nguyen and Tam Le and Makoto Yamada and Michael A Osborne", "title": "Optimal Transport Kernels for Sequential and Parallel Neural\n  Architecture Search", "comments": "23 pages, camera ready ICML2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) automates the design of deep neural\nnetworks. One of the main challenges in searching complex and non-continuous\narchitectures is to compare the similarity of networks that the conventional\nEuclidean metric may fail to capture. Optimal transport (OT) is resilient to\nsuch complex structure by considering the minimal cost for transporting a\nnetwork into another. However, the OT is generally not negative definite which\nmay limit its ability to build the positive-definite kernels required in many\nkernel-dependent frameworks. Building upon tree-Wasserstein (TW), which is a\nnegative definite variant of OT, we develop a novel discrepancy for neural\narchitectures, and demonstrate it within a Gaussian process surrogate model for\nthe sequential NAS settings. Furthermore, we derive a novel parallel NAS, using\nquality k-determinantal point process on the GP posterior, to select diverse\nand high-performing architectures from a discrete set of candidates.\nEmpirically, we demonstrate that our TW-based approaches outperform other\nbaselines in both sequential and parallel NAS.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2020 08:44:41 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 21:39:48 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 06:55:22 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Nguyen", "Vu", ""], ["Le", "Tam", ""], ["Yamada", "Makoto", ""], ["Osborne", "Michael A", ""]]}, {"id": "2006.07809", "submitter": "Chiranjib Sur", "authors": "Chiranjib Sur", "title": "ReLGAN: Generalization of Consistency for GAN with Disjoint Constraints\n  and Relative Learning of Generative Processes for Multiple Transformation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image to image transformation has gained popularity from different research\ncommunities due to its enormous impact on different applications, including\nmedical. In this work, we have introduced a generalized scheme for consistency\nfor GAN architectures with two new concepts of Transformation Learning (TL) and\nRelative Learning (ReL) for enhanced learning image transformations.\nConsistency for GAN architectures suffered from inadequate constraints and\nfailed to learn multiple and multi-modal transformations, which is inevitable\nfor many medical applications. The main drawback is that it focused on creating\nan intermediate and workable hybrid, which is not permissible for the medical\napplications which focus on minute details. Another drawback is the weak\ninterrelation between the two learning phases and TL and ReL have introduced\nimproved coordination among them. We have demonstrated the capability of the\nnovel network framework on public datasets. We emphasized that our novel\narchitecture produced an improved neural image transformation version for the\nimage, which is more acceptable to the medical community. Experiments and\nresults demonstrated the effectiveness of our framework with enhancement\ncompared to the previous works.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 06:03:30 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Sur", "Chiranjib", ""]]}, {"id": "2006.08084", "submitter": "Yujun Yan", "authors": "Yujun Yan, Kevin Swersky, Danai Koutra, Parthasarathy Ranganathan,\n  Milad Hashemi", "title": "Neural Execution Engines: Learning to Execute Subroutines", "comments": "Accepted at 34th Conference on Neural Information Processing Systems\n  (NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A significant effort has been made to train neural networks that replicate\nalgorithmic reasoning, but they often fail to learn the abstract concepts\nunderlying these algorithms. This is evidenced by their inability to generalize\nto data distributions that are outside of their restricted training sets,\nnamely larger inputs and unseen data. We study these generalization issues at\nthe level of numerical subroutines that comprise common algorithms like\nsorting, shortest paths, and minimum spanning trees. First, we observe that\ntransformer-based sequence-to-sequence models can learn subroutines like\nsorting a list of numbers, but their performance rapidly degrades as the length\nof lists grows beyond those found in the training set. We demonstrate that this\nis due to attention weights that lose fidelity with longer sequences,\nparticularly when the input numbers are numerically similar. To address the\nissue, we propose a learned conditional masking mechanism, which enables the\nmodel to strongly generalize far outside of its training range with\nnear-perfect accuracy on a variety of algorithms. Second, to generalize to\nunseen data, we show that encoding numbers with a binary representation leads\nto embeddings with rich structure once trained on downstream tasks like\naddition or multiplication. This allows the embedding to handle missing data by\nfaithfully interpolating numbers not seen during training.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 01:51:37 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 00:44:56 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 22:20:54 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Yan", "Yujun", ""], ["Swersky", "Kevin", ""], ["Koutra", "Danai", ""], ["Ranganathan", "Parthasarathy", ""], ["Hashemi", "Milad", ""]]}, {"id": "2006.08156", "submitter": "Ke Shang", "authors": "Hisao Ishibuchi and Lie Meng Pang and Ke Shang", "title": "Solution Subset Selection for Final Decision Making in Evolutionary\n  Multi-Objective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In general, a multi-objective optimization problem does not have a single\noptimal solution but a set of Pareto optimal solutions, which forms the Pareto\nfront in the objective space. Various evolutionary algorithms have been\nproposed to approximate the Pareto front using a pre-specified number of\nsolutions. Hundreds of solutions are obtained by their single run. The\nselection of a single final solution from the obtained solutions is assumed to\nbe done by a human decision maker. However, in many cases, the decision maker\ndoes not want to examine hundreds of solutions. Thus, it is needed to select a\nsmall subset of the obtained solutions. In this paper, we discuss subset\nselection from a viewpoint of the final decision making. First we briefly\nexplain existing subset selection studies. Next we formulate an expected loss\nfunction for subset selection. We also show that the formulated function is the\nsame as the IGD plus indicator. Then we report experimental results where the\nproposed approach is compared with other indicator-based subset selection\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 06:26:58 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Ishibuchi", "Hisao", ""], ["Pang", "Lie Meng", ""], ["Shang", "Ke", ""]]}, {"id": "2006.08228", "submitter": "Tianlin Liu", "authors": "Tianlin Liu and Friedemann Zenke", "title": "Finding trainable sparse networks through Neural Tangent Transfer", "comments": "Accepted by ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have dramatically transformed machine learning, but\ntheir memory and energy demands are substantial. The requirements of real\nbiological neural networks are rather modest in comparison, and one feature\nthat might underlie this austerity is their sparse connectivity. In deep\nlearning, trainable sparse networks that perform well on a specific task are\nusually constructed using label-dependent pruning criteria. In this article, we\nintroduce Neural Tangent Transfer, a method that instead finds trainable sparse\nnetworks in a label-free manner. Specifically, we find sparse networks whose\ntraining dynamics, as characterized by the neural tangent kernel, mimic those\nof dense networks in function space. Finally, we evaluate our label-agnostic\napproach on several standard classification tasks and show that the resulting\nsparse networks achieve higher classification performance while converging\nfaster.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 08:58:01 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 08:12:02 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Liu", "Tianlin", ""], ["Zenke", "Friedemann", ""]]}, {"id": "2006.08380", "submitter": "\\'Alvaro Parafita Mart\\'inez", "authors": "\\'Alvaro Parafita and Jordi Vitri\\`a", "title": "Causal Inference with Deep Causal Graphs", "comments": "Supplementary material can be found in\n  https://github.com/aparafita/dcg-paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parametric causal modelling techniques rarely provide functionality for\ncounterfactual estimation, often at the expense of modelling complexity. Since\ncausal estimations depend on the family of functions used to model the data,\nsimplistic models could entail imprecise characterizations of the generative\nmechanism, and, consequently, unreliable results. This limits their\napplicability to real-life datasets, with non-linear relationships and high\ninteraction between variables. We propose Deep Causal Graphs, an abstract\nspecification of the required functionality for a neural network to model\ncausal distributions, and provide a model that satisfies this contract:\nNormalizing Causal Flows. We demonstrate its expressive power in modelling\ncomplex interactions and showcase applications of the method to machine\nlearning explainability and fairness, using true causal counterfactuals.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 13:03:33 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Parafita", "\u00c1lvaro", ""], ["Vitri\u00e0", "Jordi", ""]]}, {"id": "2006.08433", "submitter": "Francisco Mendez", "authors": "Francisco J. Mendez, Antonio Pasculli, Miguel A. Mendez, Nicola\n  Sciarra", "title": "Calibration of the von Wolffersdorff model using Genetic Algorithms", "comments": "16 pages, 10 figures, submitted to Acta Geotechnica", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cond-mat.mtrl-sci cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes an optimization framework, based on Genetic Algorithms\n(GA), to calibrate the constitutive law of von Wolffersdorff. This constitutive\nlaw is known as Sand Hypoplasticity (SH), and allows for robust and accurate\nmodeling of the soil behavior but requires a complex calibration involving\neight parameters. The proposed optimization can automatically fit these\nparameters from the results of an oedometric and a triaxial drained compression\ntest, by combining the GA with a numerical solver that integrates the SH in the\ntest conditions. By repeating the same calibration several times, the\nstochastic nature of the optimizer enables the uncertainty quantification of\nthe calibration parameters and allows studying their relative importance on the\nmodel prediction. After validating the numerical solver on the\nExCaliber-Laboratory software from the SoilModels' website, the GA calibration\nis tested on a synthetic dataset to analyze the convergence and the statistics\nof the results. In particular, a correlation analysis reveals that two couples\nof the eight model parameters are strongly correlated. Finally, the calibration\nprocedure is tested on the results from von Wolffersdorff, 1996, and Herle &\nGudehus, 1999, on the Hochstetten sand. The model parameters identified by the\nGenetic Algorithm optimization improves the matching with the experimental data\nand hence lead to a better calibration.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 20:07:55 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Mendez", "Francisco J.", ""], ["Pasculli", "Antonio", ""], ["Mendez", "Miguel A.", ""], ["Sciarra", "Nicola", ""]]}, {"id": "2006.08679", "submitter": "Justin Shenk", "authors": "Justin Shenk and Mats L. Richter and Wolf Byttner and Anders Arpteg\n  and Mikael Huss", "title": "Feature Space Saturation during Training", "comments": "23 pages, 26 figures, fix citation formatting, add link highlighting,\n  fix table formatting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose layer saturation - a simple, online-computable method for\nanalyzing the information processing in neural networks. First, we show that a\nlayer's output can be restricted to the eigenspace of its variance matrix\nwithout performance loss. We propose a computationally lightweight method for\napproximating the variance matrix during training. From the dimension of its\nlossless eigenspace we derive layer saturation - the ratio between the\neigenspace dimension and layer width. We show that saturation seems to indicate\nwhich layers contribute to network performance. We demonstrate how to alter\nlayer saturation in a neural network by changing network depth, filter sizes\nand input resolution. Furthermore, we show that well-chosen input resolution\nincreases network performance by distributing the inference process more evenly\nacross the network.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 18:28:21 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 15:07:19 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 09:24:39 GMT"}, {"version": "v4", "created": "Fri, 13 Nov 2020 19:17:39 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Shenk", "Justin", ""], ["Richter", "Mats L.", ""], ["Byttner", "Wolf", ""], ["Arpteg", "Anders", ""], ["Huss", "Mikael", ""]]}, {"id": "2006.08761", "submitter": "Sayeed Shafayet Chowdhury", "authors": "Sayeed Shafayet Chowdhury, Chankyu Lee and Kaushik Roy", "title": "Towards Understanding the Effect of Leak in Spiking Neural Networks", "comments": "Sayeed Shafayet Chowdhury and Chankyu Lee contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) are being explored to emulate the astounding\ncapabilities of human brain that can learn and compute functions robustly and\nefficiently with noisy spiking activities. A variety of spiking neuron models\nhave been proposed to resemble biological neuronal functionalities. With\nvarying levels of bio-fidelity, these models often contain a leak path in their\ninternal states, called membrane potentials. While the leaky models have been\nargued as more bioplausible, a comparative analysis between models with and\nwithout leak from a purely computational point of view demands attention. In\nthis paper, we investigate the questions regarding the justification of leak\nand the pros and cons of using leaky behavior. Our experimental results reveal\nthat leaky neuron model provides improved robustness and better generalization\ncompared to models with no leak. However, leak decreases the sparsity of\ncomputation contrary to the common notion. Through a frequency domain analysis,\nwe demonstrate the effect of leak in eliminating the high-frequency components\nfrom the input, thus enabling SNNs to be more robust against noisy\nspike-inputs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 20:56:31 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Chowdhury", "Sayeed Shafayet", ""], ["Lee", "Chankyu", ""], ["Roy", "Kaushik", ""]]}, {"id": "2006.08798", "submitter": "Matilde Tristany Farinha Miss", "authors": "Matilde Tristany Farinha, S\\'ergio Pequito, Pedro A. Santos, M\\'ario\n  A. T. Figueiredo", "title": "Equilibrium Propagation for Complete Directed Neural Networks", "comments": "6 pages, 6 images, accepted for ESANN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks, one of the most successful approaches to\nsupervised learning, were originally inspired by their biological counterparts.\nHowever, the most successful learning algorithm for artificial neural networks,\nbackpropagation, is considered biologically implausible. We contribute to the\ntopic of biologically plausible neuronal learning by building upon and\nextending the equilibrium propagation learning framework. Specifically, we\nintroduce: a new neuronal dynamics and learning rule for arbitrary network\narchitectures; a sparsity-inducing method able to prune irrelevant connections;\na dynamical-systems characterization of the models, using Lyapunov theory.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 22:12:30 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 10:23:51 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Farinha", "Matilde Tristany", ""], ["Pequito", "S\u00e9rgio", ""], ["Santos", "Pedro A.", ""], ["Figueiredo", "M\u00e1rio A. T.", ""]]}, {"id": "2006.08809", "submitter": "Micha{\\l} Okulewicz", "authors": "Micha{\\l} Okulewicz and Jacek Ma\\'ndziuk", "title": "A Particle Swarm Optimization hyper-heuristic for the Dynamic Vehicle\n  Routing Problem", "comments": "14 pages, presented at BIOMA 2016 conference, Bled, Slovenia", "journal-ref": "Proceedings of Bioinspired Optimization Methods and their\n  Applications, 215-227, Jozef Stefan Institute, 2016", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a method for choosing a Particle Swarm Optimization based\noptimizer for the Dynamic Vehicle Routing Problem on the basis of the initially\navailable data of a given problem instance. The optimization algorithm is\nchosen on the basis of a prediction made by a linear model trained on that data\nand the relative results obtained by the optimization algorithms. The achieved\nresults suggest that such a model can be used in a hyper-heuristic approach as\nit improved the average results, obtained on the set of benchmark instances, by\nchoosing the appropriate algorithm in 82% of significant cases. Two leading\nmulti-swarm Particle Swarm Optimization based algorithms for solving the\nDynamic Vehicle Routing Problem are used as the basic optimization algorithms:\nKhouadjia's et al. Multi-Environmental Multi-Swarm Optimizer and authors'\n2--Phase Multiswarm Particle Swarm Optimization.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 22:34:17 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Okulewicz", "Micha\u0142", ""], ["Ma\u0144dziuk", "Jacek", ""]]}, {"id": "2006.08819", "submitter": "Ioannis Ivrissimtzis", "authors": "Xin Zhang and Ning Jia and Ioannis Ivrissimtzis", "title": "A study of the effect of the illumination model on the generation of\n  synthetic training datasets", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of computer generated images to train Deep Neural Networks is a\nviable alternative to real images when the latter are scarce or expensive. In\nthis paper, we study how the illumination model used by the rendering software\naffects the quality of the generated images. We created eight training sets,\neach one with a different illumination model, and tested them on three\ndifferent network architectures, ResNet, U-Net and a combined architecture\ndeveloped by us. The test set consisted of photos of 3D printed objects\nproduced from the same CAD models used to generate the training set. The effect\nof the other parameters of the rendering process, such as textures and camera\nposition, was randomized.\n  Our results show that the effect of the illumination model is important,\ncomparable in significance to the network architecture. We also show that both\nlight probes capturing natural environmental light, and modelled lighting\nenvironments, can give good results. In the case of light probes, we identified\nas two significant factors affecting performance the similarity between the\nlight probe and the test environment, as well as the light probe's resolution.\nRegarding modelled lighting environment, similarity with the test environment\nwas again identified as a significant factor.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 23:22:24 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Zhang", "Xin", ""], ["Jia", "Ning", ""], ["Ivrissimtzis", "Ioannis", ""]]}, {"id": "2006.08924", "submitter": "Shuyue Jia", "authors": "Xiangmin Lun, Shuyue Jia, Yimin Hou, Yan Shi, Yang Li", "title": "GCNs-Net: A Graph Convolutional Neural Network Approach for Decoding\n  Time-resolved EEG Motor Imagery Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Towards developing effective and efficient brain-computer interface (BCI)\nsystems, precise decoding of brain activity measured by electroencephalogram\n(EEG), is highly demanded. Traditional works classify EEG signals without\nconsidering the topological relationship among electrodes. However,\nneuroscience research has increasingly emphasized network patterns of brain\ndynamics. Thus, the Euclidean structure of electrodes might not adequately\nreflect the interaction between signals. To fill the gap, a novel deep learning\nframework based on the graph convolutional neural networks (GCNs) was presented\nto enhance the decoding performance of raw EEG signals during different types\nof motor imagery (MI) tasks while cooperating with the functional topological\nrelationship of electrodes. Based on the absolute Pearson's matrix of overall\nsignals, the graph Laplacian of EEG electrodes was built up. The GCNs-Net\nconstructed by graph convolutional layers learns the generalized features. The\nfollowed pooling layers reduce dimensionality, and the fully-connected softmax\nlayer derives the final prediction. The introduced approach has been shown to\nconverge for both personalized and group-wise predictions. It has achieved the\nhighest averaged accuracy, 93.056% and 88.57% (PhysioNet Dataset), 96.24% and\n80.89% (High Gamma Dataset), at the subject and group level, respectively,\ncompared with existing studies, which suggests adaptability and robustness to\nindividual variability. Moreover, the performance was stably reproducible among\nrepetitive experiments for cross-validation. To conclude, the GCNs-Net filters\nEEG signals based on the functional topological relationship, which manages to\ndecode relevant features for brain motor imagery.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 04:57:12 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 03:18:06 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Lun", "Xiangmin", ""], ["Jia", "Shuyue", ""], ["Hou", "Yimin", ""], ["Shi", "Yan", ""], ["Li", "Yang", ""]]}, {"id": "2006.08947", "submitter": "Mohammadamin Tavakoli", "authors": "Mohammadamin Tavakoli, Forest Agostinelli, Pierre Baldi", "title": "SPLASH: Learnable Activation Functions for Improving Accuracy and\n  Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SPLASH units, a class of learnable activation functions shown to\nsimultaneously improve the accuracy of deep neural networks while also\nimproving their robustness to adversarial attacks. SPLASH units have both a\nsimple parameterization and maintain the ability to approximate a wide range of\nnon-linear functions. SPLASH units are: 1) continuous; 2) grounded (f(0) = 0);\n3) use symmetric hinges; and 4) the locations of the hinges are derived\ndirectly from the data (i.e. no learning required). Compared to nine other\nlearned and fixed activation functions, including ReLU and its variants, SPLASH\nunits show superior performance across three datasets (MNIST, CIFAR-10, and\nCIFAR-100) and four architectures (LeNet5, All-CNN, ResNet-20, and\nNetwork-in-Network). Furthermore, we show that SPLASH units significantly\nincrease the robustness of deep neural networks to adversarial attacks. Our\nexperiments on both black-box and open-box adversarial attacks show that\ncommonly-used architectures, namely LeNet5, All-CNN, ResNet-20, and\nNetwork-in-Network, can be up to 31% more robust to adversarial attacks by\nsimply using SPLASH units instead of ReLUs.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 06:45:55 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Tavakoli", "Mohammadamin", ""], ["Agostinelli", "Forest", ""], ["Baldi", "Pierre", ""]]}, {"id": "2006.09122", "submitter": "Andreas Kamilaris", "authors": "Andreas Kamilaris, Andries Engelbrecht, Andreas Pitsillides and\n  Francesc X. Prenafeta-Boldu", "title": "Transfer of Manure as Fertilizer from Livestock Farms to Crop Fields:\n  The Case of Catalonia", "comments": "Computers and Electronics in Agriculture Journal. arXiv admin note:\n  substantial text overlap with arXiv:2006.04573", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intensive livestock production might have a negative environmental impact, by\nproducing large amounts of animal manure, which, if not properly managed, can\ncontaminate nearby water bodies with nutrient excess. However, if animal manure\nis exported to nearby crop fields, to be used as organic fertilizer, pollution\ncan be mitigated. It is a single-objective optimization problem, in regards to\nfinding the best solution for the logistics process of satisfying nutrient\nneeds of crops by means of livestock manure. This paper proposes three\ndifferent approaches to solve the problem: a centralized optimal algorithm\n(COA), a decentralized nature-inspired cooperative technique, based on the\nforaging behaviour of ants (AIA), as well as a naive neighbour-based method\n(NBS), which constitutes the existing practice used today in an ad hoc,\nuncoordinated manner in Catalonia. Results show that the COA approach is 8.5%\nmore efficient than the AIA. However, the AIA approach is fairer to the farmers\nand more balanced in terms of average transportation distances that need to be\ncovered by each livestock farmer, while it is 1.07 times more eefficient than\nthe NBS. Our work constitutes the first application of a decentralized AIA to\nthis interesting real-world problem, in a domain where swarm intelligence\nmethods are still under-exploited.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 18:33:13 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Kamilaris", "Andreas", ""], ["Engelbrecht", "Andries", ""], ["Pitsillides", "Andreas", ""], ["Prenafeta-Boldu", "Francesc X.", ""]]}, {"id": "2006.09126", "submitter": "Amirhossein Rajabi", "authors": "Amirhossein Rajabi and Carsten Witt", "title": "Evolutionary Algorithms with Self-adjusting Asymmetric Mutation", "comments": "16 pages. An extended abstract of this paper will be published in the\n  proceedings of PPSN 2020", "journal-ref": null, "doi": "10.1007/978-3-030-58112-1_46", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary Algorithms (EAs) and other randomized search heuristics are\noften considered as unbiased algorithms that are invariant with respect to\ndifferent transformations of the underlying search space. However, if a certain\namount of domain knowledge is available the use of biased search operators in\nEAs becomes viable. We consider a simple (1+1) EA for binary search spaces and\nanalyze an asymmetric mutation operator that can treat zero- and one-bits\ndifferently. This operator extends previous work by Jansen and Sudholt (ECJ\n18(1), 2010) by allowing the operator asymmetry to vary according to the\nsuccess rate of the algorithm. Using a self-adjusting scheme that learns an\nappropriate degree of asymmetry, we show improved runtime results on the class\nof functions OneMax$_a$ describing the number of matching bits with a fixed\ntarget $a\\in\\{0,1\\}^n$.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 13:16:50 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Rajabi", "Amirhossein", ""], ["Witt", "Carsten", ""]]}, {"id": "2006.09363", "submitter": "Leslie Smith", "authors": "Leslie N. Smith, Adam Conovaloff", "title": "Building One-Shot Semi-supervised (BOSS) Learning up to Fully Supervised\n  Performance", "comments": "Revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reaching the performance of fully supervised learning with unlabeled data and\nonly labeling one sample per class might be ideal for deep learning\napplications. We demonstrate for the first time the potential for building\none-shot semi-supervised (BOSS) learning on Cifar-10 and SVHN up to attain test\naccuracies that are comparable to fully supervised learning. Our method\ncombines class prototype refining, class balancing, and self-training. A good\nprototype choice is essential and we propose a technique for obtaining iconic\nexamples. In addition, we demonstrate that class balancing methods\nsubstantially improve accuracy results in semi-supervised learning to levels\nthat allow self-training to reach the level of fully supervised learning\nperformance. Rigorous empirical evaluations provide evidence that labeling\nlarge datasets is not necessary for training deep neural networks. We made our\ncode available at https://github.com/lnsmith54/BOSS to facilitate replication\nand for use with future real-world applications.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 17:56:00 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 18:31:29 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Smith", "Leslie N.", ""], ["Conovaloff", "Adam", ""]]}, {"id": "2006.09510", "submitter": "Sergey Bochkanov", "authors": "Sergey Bochkanov", "title": "On sparse connectivity, adversarial robustness, and a novel model of the\n  artificial neuron", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved human-level accuracy on almost all\nperceptual benchmarks. It is interesting that these advances were made using\ntwo ideas that are decades old: (a) an artificial neuron based on a linear\nsummator and (b) SGD training.\n  However, there are important metrics beyond accuracy: computational\nefficiency and stability against adversarial perturbations. In this paper, we\npropose two closely connected methods to improve these metrics on contour\nrecognition tasks: (a) a novel model of an artificial neuron, a \"strong\nneuron,\" with low hardware requirements and inherent robustness against\nadversarial perturbations and (b) a novel constructive training algorithm that\ngenerates sparse networks with $O(1)$ connections per neuron.\n  We demonstrate the feasibility of our approach through experiments on SVHN\nand GTSRB benchmarks. We achieved an impressive 10x-100x reduction in\noperations count (10x when compared with other sparsification approaches, 100x\nwhen compared with dense networks) and a substantial reduction in hardware\nrequirements (8-bit fixed-point math was used) with no reduction in model\naccuracy. Superior stability against adversarial perturbations (exceeding that\nof adversarial training) was achieved without any counteradversarial measures,\nrelying on the robustness of strong neurons alone. We also proved that\nconstituent blocks of our strong neuron are the only activation functions with\nperfect stability against adversarial attacks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 20:45:08 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Bochkanov", "Sergey", ""]]}, {"id": "2006.09549", "submitter": "Jack Lindsey", "authors": "Jack Lindsey, Ashok Litwin-Kumar", "title": "Learning to Learn with Feedback and Local Plasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest in biologically inspired alternatives to backpropagation is driven\nby the desire to both advance connections between deep learning and\nneuroscience and address backpropagation's shortcomings on tasks such as\nonline, continual learning. However, local synaptic learning rules like those\nemployed by the brain have so far failed to match the performance of\nbackpropagation in deep networks. In this study, we employ meta-learning to\ndiscover networks that learn using feedback connections and local, biologically\ninspired learning rules. Importantly, the feedback connections are not tied to\nthe feedforward weights, avoiding biologically implausible weight transport.\nOur experiments show that meta-trained networks effectively use feedback\nconnections to perform online credit assignment in multi-layer architectures.\nSurprisingly, this approach matches or exceeds a state-of-the-art\ngradient-based online meta-learning algorithm on regression and classification\ntasks, excelling in particular at continual learning. Analysis of the weight\nupdates employed by these models reveals that they differ qualitatively from\ngradient descent in a way that reduces interference between updates. Our\nresults suggest the existence of a class of biologically plausible learning\nmechanisms that not only match gradient descent-based learning, but also\novercome its limitations.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 22:49:07 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Lindsey", "Jack", ""], ["Litwin-Kumar", "Ashok", ""]]}, {"id": "2006.09655", "submitter": "Fuad A. Ghaleb Dr", "authors": "Fuad A. Ghaleb, Bander Ali Saleh Al-rimy, Maznah Kamat, Mohd. Foad\n  Rohani, Shukor Abd Razak", "title": "Fairness-Oriented Semi-Chaotic Genetic Algorithm-Based Channel\n  Assignment Technique for Nodes Starvation Problem in Wireless Mesh Network", "comments": "18 pages, 10 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-Radio Multi-Channel Wireless Mesh Networks (WMNs) have emerged as a\nscalable, reliable, and agile wireless network that supports many types of\ninnovative technologies such as the Internet of Things (IoT) and vehicular\nnetworks. Due to the limited number of orthogonal channels, interference\nbetween channels adversely affects the fair distribution of bandwidth among\nmesh clients, causing node starvation in terms of insufficient bandwidth, which\nimpedes the adoption of WMN as an efficient access technology. Therefore, a\nfair channel assignment is crucial for the mesh clients to utilize the\navailable resources. However, the node starvation problem due to unfair channel\ndistribution has been vastly overlooked during channel assignment by the extant\nresearch. Instead, existing channel assignment algorithms either reduce the\ntotal network interference or maximize the total network throughput, which\nneither guarantees a fair distribution of the channels nor eliminates node\nstarvation. To this end, the Fairness-Oriented Semi-Chaotic Genetic\nAlgorithm-Based Channel Assignment Technique (FA-SCGA-CAA) was proposed in this\npaper for Nodes Starvation Problem in Wireless Mesh Networks. FA-SCGA-CAA\noptimizes fairness based on multiple-criterion using a modified version of the\nGenetic Algorithm (GA). The modification includes proposing a semi-chaotic\ntechnique for creating the primary chromosome with powerful genes. Such a\nchromosome was used to create a strong population that directs the search\ntowards the global minima in an effective and efficient way. The outcome is a\nnonlinear fairness oriented fitness function that aims at maximizing the link\nfairness while minimizing the link interference. Comparison with related work\nshows that the proposed FA_SCGA_CAA reduced the potential nodes starvation by\n22% and improved network capacity utilization by 23%.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 04:43:47 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Ghaleb", "Fuad A.", ""], ["Al-rimy", "Bander Ali Saleh", ""], ["Kamat", "Maznah", ""], ["Rohani", "Mohd. Foad", ""], ["Razak", "Shukor Abd", ""]]}, {"id": "2006.09844", "submitter": "Wei-Chang Yeh", "authors": "Wei-Chang Yeh", "title": "Simplified Swarm Optimization for Bi-Objection Active Reliability\n  Redundancy Allocation Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reliability redundancy allocation problem (RRAP) is a well-known tool in\nsystem design, development, and management. The RRAP is always modeled as a\nnonlinear mixed-integer non-deterministic polynomial-time hardness (NP-hard)\nproblem. To maximize the system reliability, the integer (component active\nredundancy level) and real variables (component reliability) must be determined\nto ensure that the cost limit and some nonlinear constraints are satisfied. In\nthis study, a bi-objective RRAP is formulated by changing the cost constraint\nas a new goal, because it is necessary to balance the reliability and cost\nimpact for the entire system in practical applications. To solve the proposed\nproblem, a new simplified swarm optimization (SSO) with a penalty function, a\nreal one-type solution structure, a number-based self-adaptive new update\nmechanism, a constrained nondominated-solution selection, and a new pBest\nreplacement policy is developed in terms of these structures selected from\nfull-factorial design to find the Pareto solutions efficiently and effectively.\nThe proposed SSO outperforms several metaheuristic state-of-the-art algorithms,\ne.g., nondominated sorting genetic algorithm II (NSGA-II) and multi-objective\nparticle swarm optimization (MOPSO), according to experimental results for four\nbenchmark problems involving the bi-objective active RRAP.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 13:15:44 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Yeh", "Wei-Chang", ""]]}, {"id": "2006.09855", "submitter": "Carola Doerr", "authors": "Anja Jankovic and Carola Doerr", "title": "Landscape-Aware Fixed-Budget Performance Regression and Algorithm\n  Selection for Modular CMA-ES Variants", "comments": "To appear in Proc. of Genetic and Evolutionary Computation Conference\n  (GECCO'20)", "journal-ref": null, "doi": "10.1145/3377930.3390183", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated algorithm selection promises to support the user in the decisive\ntask of selecting a most suitable algorithm for a given problem. A common\ncomponent of these machine-trained techniques are regression models which\npredict the performance of a given algorithm on a previously unseen problem\ninstance. In the context of numerical black-box optimization, such regression\nmodels typically build on exploratory landscape analysis (ELA), which\nquantifies several characteristics of the problem. These measures can be used\nto train a supervised performance regression model.\n  First steps towards ELA-based performance regression have been made in the\ncontext of a fixed-target setting. In many applications, however, the user\nneeds to select an algorithm that performs best within a given budget of\nfunction evaluations. Adopting this fixed-budget setting, we demonstrate that\nit is possible to achieve high-quality performance predictions with\noff-the-shelf supervised learning approaches, by suitably combining two\ndifferently trained regression models. We test this approach on a very\nchallenging problem: algorithm selection on a portfolio of very similar\nalgorithms, which we choose from the family of modular CMA-ES algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 13:34:57 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Jankovic", "Anja", ""], ["Doerr", "Carola", ""]]}, {"id": "2006.09875", "submitter": "Snehanshu Saha", "authors": "Rohan Mohapatra, Snehanshu Saha, Carlos A. Coello Coello, Anwesh\n  Bhattacharya, Soma S. Dhavala and Sriparna Saha", "title": "AdaSwarm: Augmenting Gradient-Based optimizers in Deep Learning with\n  Swarm Intelligence", "comments": "11 pages, 2 figures; Accepted at IEEE TETCI", "journal-ref": "IEEE Transactions on Emerging Topics in Computational Intelligence\n  2021", "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces AdaSwarm, a novel gradient-free optimizer which has\nsimilar or even better performance than the Adam optimizer adopted in neural\nnetworks. In order to support our proposed AdaSwarm, a novel Exponentially\nweighted Momentum Particle Swarm Optimizer (EMPSO), is proposed. The ability of\nAdaSwarm to tackle optimization problems is attributed to its capability to\nperform good gradient approximations. We show that, the gradient of any\nfunction, differentiable or not, can be approximated by using the parameters of\nEMPSO. This is a novel technique to simulate GD which lies at the boundary\nbetween numerical methods and swarm intelligence. Mathematical proofs of the\ngradient approximation produced are also provided. AdaSwarm competes closely\nwith several state-of-the-art (SOTA) optimizers. We also show that AdaSwarm is\nable to handle a variety of loss functions during backpropagation, including\nthe maximum absolute error (MAE).\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 19:17:38 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 14:30:20 GMT"}, {"version": "v3", "created": "Sun, 2 May 2021 05:39:28 GMT"}, {"version": "v4", "created": "Thu, 13 May 2021 06:40:46 GMT"}, {"version": "v5", "created": "Wed, 19 May 2021 07:47:55 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Mohapatra", "Rohan", ""], ["Saha", "Snehanshu", ""], ["Coello", "Carlos A. Coello", ""], ["Bhattacharya", "Anwesh", ""], ["Dhavala", "Soma S.", ""], ["Saha", "Sriparna", ""]]}, {"id": "2006.09980", "submitter": "Sergei Kozyrev", "authors": "S.V. Kozyrev", "title": "Genome as a functional program", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss a model of genome as a program with functional architecture and\nconsider the approach to Darwinian evolution as a learning problem for\nfunctional programming. In particular we introduce a model of learning for some\nclass of functional programs. This approach is related to information geometry\n-- the learning model uses some kind of distance in the information space (the\nreduction graph of the model), we consider statistical sum over paths in the\nreduction graph and discuss relation of this sum to temperature learning.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 07:58:50 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Kozyrev", "S. V.", ""]]}, {"id": "2006.09981", "submitter": "Mojtaba Moattari", "authors": "Mojtaba Moattari, Mohammad Hassan Moradi, Emad Roshandel", "title": "Uncertainty Principle based optimization; new metaheuristics framework", "comments": "18 pages, 2 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To more flexibly balance between exploration and exploitation, a new\nmeta-heuristic method based on Uncertainty Principle concepts is proposed in\nthis paper. UP is is proved effective in multiple branches of science. In the\nbranch of quantum mechanics, canonically conjugate observables such as position\nand momentum cannot both be distinctly determined in any quantum state. In the\nsame manner, the branch of Spectral filtering design implies that a nonzero\nfunction and its Fourier transform cannot both be sharply localized. After\ndelving into such concepts on Uncertainty Principle and their variations in\nquantum physics, Fourier analysis, and wavelet design, the proposed framework\nis described in terms of algorithm and flowchart. Our proposed optimizer's idea\nis based on an inherent uncertainty in performing local search versus global\nsolution search. A set of compatible metrics for each part of the framework is\nproposed to derive preferred form of algorithm. Evaluations and comparisons at\nthe end of paper show competency and distinct capability of the algorithm over\nsome of the well-known and recently proposed metaheuristics.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 16:20:42 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Moattari", "Mojtaba", ""], ["Moradi", "Mohammad Hassan", ""], ["Roshandel", "Emad", ""]]}, {"id": "2006.09982", "submitter": "Trevor E. Carlson", "authors": "Srivatsa P and Kyle Timothy Ng Chu and Burin Amornpaisannon and\n  Yaswanth Tavva and Venkata Pavan Kumar Miriyala and Jibin Wu and Malu Zhang\n  and Haizhou Li and Trevor E. Carlson", "title": "You Only Spike Once: Improving Energy-Efficient Neuromorphic Inference\n  to ANN-Level Accuracy", "comments": "10 pages, 4 figures. This work has been submitted to the IEEE for\n  possible publication. Copyright may be transferred without notice, after\n  which this version may no longer be accessible. This work is an extended\n  version of the paper accepted to the 2nd Workshop on Accelerated Machine\n  Learning (AccML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, advances in Artificial Neural Networks (ANNs) have\nallowed them to perform extremely well for a wide range of tasks. In fact, they\nhave reached human parity when performing image recognition, for example.\nUnfortunately, the accuracy of these ANNs comes at the expense of a large\nnumber of cache and/or memory accesses and compute operations. Spiking Neural\nNetworks (SNNs), a type of neuromorphic, or brain-inspired network, have\nrecently gained significant interest as power-efficient alternatives to ANNs,\nbecause they are sparse, accessing very few weights, and typically only use\naddition operations instead of the more power-intensive multiply-and-accumulate\n(MAC) operations. The vast majority of neuromorphic hardware designs support\nrate-encoded SNNs, where the information is encoded in spike rates.\nRate-encoded SNNs could be seen as inefficient as an encoding scheme because it\ninvolves the transmission of a large number of spikes. A more efficient\nencoding scheme, Time-To-First-Spike (TTFS) encoding, encodes information in\nthe relative time of arrival of spikes. While TTFS-encoded SNNs are more\nefficient than rate-encoded SNNs, they have, up to now, performed poorly in\nterms of accuracy compared to previous methods. Hence, in this work, we aim to\novercome the limitations of TTFS-encoded neuromorphic systems. To accomplish\nthis, we propose: (1) a novel optimization algorithm for TTFS-encoded SNNs\nconverted from ANNs and (2) a novel hardware accelerator for TTFS-encoded SNNs,\nwith a scalable and low-power design. Overall, our work in TTFS encoding and\ntraining improves the accuracy of SNNs to achieve state-of-the-art results on\nMNIST MLPs, while reducing power consumption by 1.46$\\times$ over the\nstate-of-the-art neuromorphic hardware.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2020 15:55:53 GMT"}, {"version": "v2", "created": "Sun, 8 Nov 2020 09:10:57 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["P", "Srivatsa", ""], ["Chu", "Kyle Timothy Ng", ""], ["Amornpaisannon", "Burin", ""], ["Tavva", "Yaswanth", ""], ["Miriyala", "Venkata Pavan Kumar", ""], ["Wu", "Jibin", ""], ["Zhang", "Malu", ""], ["Li", "Haizhou", ""], ["Carlson", "Trevor E.", ""]]}, {"id": "2006.09985", "submitter": "Alberto Marchisio", "authors": "Riccardo Massa, Alberto Marchisio, Maurizio Martina, Muhammad Shafique", "title": "An Efficient Spiking Neural Network for Recognizing Gestures with a DVS\n  Camera on the Loihi Neuromorphic Processor", "comments": "Accepted for publication at the 2020 International Joint Conference\n  on Neural Networks (IJCNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs), the third generation NNs, have come under the\nspotlight for machine learning based applications due to their biological\nplausibility and reduced complexity compared to traditional artificial Deep\nNeural Networks (DNNs). These SNNs can be implemented with extreme energy\nefficiency on neuromorphic processors like the Intel Loihi research chip, and\nfed by event-based sensors, such as DVS cameras. However, DNNs with many layers\ncan achieve relatively high accuracy on image classification and recognition\ntasks, as the research on learning rules for SNNs for real-world applications\nis still not mature. The accuracy results for SNNs are typically obtained\neither by converting the trained DNNs into SNNs, or by directly designing and\ntraining SNNs in the spiking domain. Towards the conversion from a DNN to an\nSNN, we perform a comprehensive analysis of such process, specifically designed\nfor Intel Loihi, showing our methodology for the design of an SNN that achieves\nnearly the same accuracy results as its corresponding DNN. Towards the usage of\nthe event-based sensors, we design a pre-processing method, evaluated for the\nDvsGesture dataset, which makes it possible to be used in the DNN domain.\nHence, based on the outcome of the first analysis, we train a DNN for the\npre-processed DvsGesture dataset, and convert it into the spike domain for its\ndeployment on Intel Loihi, which enables real-time gesture recognition. The\nresults show that our SNN achieves 89.64% classification accuracy and occupies\nonly 37 Loihi cores. The source code for generating our experiments is\navailable online at https://github.com/albertomarchisio/EfficientSNN.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2020 17:00:10 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 10:39:59 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Massa", "Riccardo", ""], ["Marchisio", "Alberto", ""], ["Martina", "Maurizio", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2006.09987", "submitter": "Liang Shen", "authors": "Xiaotao Huang, Liang Shen, Chongyi Fan, Jiahua zhu and Sixian Chen", "title": "Multilevel Image Thresholding Using a Fully Informed Cuckoo Search\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though effective in the segmentation, conventional multilevel thresholding\nmethods are computationally expensive as exhaustive search are used for optimal\nthresholds to optimize the objective functions. To overcome this problem,\npopulation-based metaheuristic algorithms are widely used to improve the\nsearching capacity. In this paper, we improve a popular metaheuristic called\ncuckoo search using a ring topology based fully informed strategy. In this\nstrategy, each individual in the population learns from its neighborhoods to\nimprove the cooperation of the population and the learning efficiency. Best\nsolution or best fitness value can be obtained from the initial random\nthreshold values, whose quality is evaluated by the correlation function.\nExperimental results have been examined on various numbers of thresholds. The\nresults demonstrate that the proposed algorithm is more accurate and efficient\nthan other four popular methods.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2020 13:22:27 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Huang", "Xiaotao", ""], ["Shen", "Liang", ""], ["Fan", "Chongyi", ""], ["zhu", "Jiahua", ""], ["Chen", "Sixian", ""]]}, {"id": "2006.09988", "submitter": "Sebastian Otte", "authors": "Manuel Traub, Martin V. Butz, R. Harald Baayen, Sebastian Otte", "title": "Learning Precise Spike Timings with Eligibility Traces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in the field of spiking neural networks (SNNs) has shown that\nrecurrent variants of SNNs, namely long short-term SNNs (LSNNs), can be trained\nvia error gradients just as effective as LSTMs. The underlying learning method\n(e-prop) is based on a formalization of eligibility traces applied to leaky\nintegrate and fire (LIF) neurons. Here, we show that the proposed approach\ncannot fully unfold spike timing dependent plasticity (STDP). As a consequence,\nthis limits in principle the inherent advantage of SNNs, that is, the potential\nto develop codes that rely on precise relative spike timings. We show that\nSTDP-aware synaptic gradients naturally emerge within the eligibility equations\nof e-prop when derived for a slightly more complex spiking neuron model, here\nat the example of the Izhikevich model. We also present a simple extension of\nthe LIF model that provides similar gradients. In a simple experiment we\ndemonstrate that the STDP-aware LIF neurons can learn precise spike timings\nfrom an e-prop-based gradient signal.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2020 09:19:59 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Traub", "Manuel", ""], ["Butz", "Martin V.", ""], ["Baayen", "R. Harald", ""], ["Otte", "Sebastian", ""]]}, {"id": "2006.09989", "submitter": "Elvis Dohmatob", "authors": "Elvis Dohmatob", "title": "Classifier-independent Lower-Bounds for Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We theoretically analyse the limits of robustness to test-time adversarial\nand noisy examples in classification. Our work focuses on deriving bounds which\nuniformly apply to all classifiers (i.e all measurable functions from features\nto labels) for a given problem. Our contributions are two-fold. (1) We use\noptimal transport theory to derive variational formulae for the Bayes-optimal\nerror a classifier can make on a given classification problem, subject to\nadversarial attacks. The optimal adversarial attack is then an optimal\ntransport plan for a certain binary cost-function induced by the specific\nattack model, and can be computed via a simple algorithm based on maximal\nmatching on bipartite graphs. (2) We derive explicit lower-bounds on the\nBayes-optimal error in the case of the popular distance-based attacks. These\nbounds are universal in the sense that they depend on the geometry of the\nclass-conditional distributions of the data, but not on a particular\nclassifier. Our results are in sharp contrast with the existing literature,\nwherein adversarial vulnerability of classifiers is derived as a consequence of\nnonzero ordinary test error.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 16:46:39 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 13:33:31 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 17:57:17 GMT"}, {"version": "v4", "created": "Tue, 23 Jun 2020 17:56:29 GMT"}, {"version": "v5", "created": "Tue, 7 Jul 2020 17:39:22 GMT"}, {"version": "v6", "created": "Tue, 10 Nov 2020 00:32:30 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Dohmatob", "Elvis", ""]]}, {"id": "2006.09996", "submitter": "Micha{\\l} Okulewicz", "authors": "Micha{\\l} Okulewicz and Jacek Ma\\'ndziuk", "title": "Dynamic Vehicle Routing Problem: A Monte Carlo approach", "comments": null, "journal-ref": "Information Technologies: Research and Their Interdisciplinary\n  Applications 2015, 119-138, Institute of Computer Science Polish Academy of\n  Sciences, ISBN 978-83-63159-23-8", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we solve the Dynamic Vehicle Routing Problem (DVRP). DVRP is a\nmodification of the Vehicle Routing Problem, in which the clients' requests\n(cities) number and location might not be known at the beginning of the working\nday Additionally, all requests must be served during one working day by a fleet\nof vehicles with limited capacity. In this work we propose a Monte Carlo method\n(MCTree), which directly approaches the dynamic nature of arriving requests in\nthe DVRP. The method is also hybridized (MCTree+PSO) with our previous\nTwo-Phase Multi-swarm Particle Swarm Optimization (2MPSO) algorithm.\n  Our method is based on two assumptions. First, that we know a bounding\nrectangle of the area in which the requests might appear. Second, that the\ninitial requests' sizes and frequency of appearance are representative for the\nyet unknown clients' requests. In order to solve the DVRP we divide the working\nday into several time slices in which we solve a static problem. In our Monte\nCarlo approach we randomly generate the unknown clients' requests with uniform\nspatial distribution over the bounding rectangle and requests' sizes uniformly\nsampled from the already known requests' sizes. The solution proposal is\nconstructed with the application of a clustering algorithm and a route\nconstruction algorithm.\n  The MCTree method is tested on a well established set of benchmarks proposed\nby Kilby et al. and is compared with the results achieved by applying our\nprevious 2MPSO algorithm and other literature results. The proposed MCTree\napproach achieves a better time to quality trade-off then plain heuristic\nalgorithms. Moreover, a hybrid MCTree+PSO approach achieves better time to\nquality trade-off then 2MPSO for small optimization time limits, making the\nhybrid a good candidate for handling real world scale goods delivery problems.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 23:10:00 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Okulewicz", "Micha\u0142", ""], ["Ma\u0144dziuk", "Jacek", ""]]}, {"id": "2006.10021", "submitter": "Daniele Castellana", "authors": "Daniele Castellana and Davide Bacciu", "title": "Generalising Recursive Neural Models by Tensor Decomposition", "comments": "Accepted at IEEE WCCI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most machine learning models for structured data encode the structural\nknowledge of a node by leveraging simple aggregation functions (in neural\nmodels, typically a weighted sum) of the information in the node's\nneighbourhood. Nevertheless, the choice of simple context aggregation\nfunctions, such as the sum, can be widely sub-optimal. In this work we\nintroduce a general approach to model aggregation of structural context\nleveraging a tensor-based formulation. We show how the exponential growth in\nthe size of the parameter space can be controlled through an approximation\nbased on the Tucker tensor decomposition. This approximation allows limiting\nthe parameters space size, decoupling it from its strict relation with the size\nof the hidden encoding space. By this means, we can effectively regulate the\ntrade-off between expressivity of the encoding, controlled by the hidden size,\ncomputational complexity and model generalisation, influenced by\nparameterisation. Finally, we introduce a new Tensorial Tree-LSTM derived as an\ninstance of our framework and we use it to experimentally assess our working\nhypotheses on tree classification scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 17:28:19 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Castellana", "Daniele", ""], ["Bacciu", "Davide", ""]]}, {"id": "2006.10330", "submitter": "Francois-Xavier Vialard", "authors": "Fran\\c{c}ois-Xavier Vialard (ligm), Roland Kwitt, Susan Wei, Marc\n  Niethammer", "title": "A Shooting Formulation of Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous-depth neural networks can be viewed as deep limits of discrete\nneural networks whose dynamics resemble a discretization of an ordinary\ndifferential equation (ODE). Although important steps have been taken to\nrealize the advantages of such continuous formulations, most current techniques\nare not truly continuous-depth as they assume \\textit{identical} layers.\nIndeed, existing works throw into relief the myriad difficulties presented by\nan infinite-dimensional parameter space in learning a continuous-depth neural\nODE. To this end, we introduce a shooting formulation which shifts the\nperspective from parameterizing a network layer-by-layer to parameterizing over\noptimal networks described only by a set of initial conditions. For\nscalability, we propose a novel particle-ensemble parametrization which fully\nspecifies the optimal weight trajectory of the continuous-depth neural network.\nOur experiments show that our particle-ensemble shooting formulation can\nachieve competitive performance, especially on long-range forecasting tasks.\nFinally, though the current work is inspired by continuous-depth neural\nnetworks, the particle-ensemble shooting formulation also applies to\ndiscrete-time networks and may lead to a new fertile area of research in deep\nlearning parametrization.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 07:36:04 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 15:43:57 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Vialard", "Fran\u00e7ois-Xavier", "", "ligm"], ["Kwitt", "Roland", ""], ["Wei", "Susan", ""], ["Niethammer", "Marc", ""]]}, {"id": "2006.10523", "submitter": "Pavel Matrenin", "authors": "Vadim Manusov, Pavel Matrenin", "title": "Optimization of Fuzzy Controller of a Wind Power Plant Based on the\n  Swarm Intelligence", "comments": null, "journal-ref": "13th International Scientific-Technical Conference on Actual\n  Problems of Electronics Instrument Engineering (APEIE), Novosibirsk, 2016", "doi": "10.1109/APEIE.2016.7806936", "report-no": null, "categories": "eess.SY cs.AI cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article considers the problem of the optimal control of a wind power\nplant based on fuzzy control and automation of generating the fuzzy rule base.\nFuzzy rules by experts do not always provide a maximum power output of the wind\nplant and fuzzy rule bases require an adjustment in the case of changing the\nparameters of the wind power plant or the environment. This research proposes\nthe method for optimizing the fuzzy rules base compiled by various experts. The\nmethod is based on balancing weights of fuzzy rules into the base by the\nParticle Swarm Optimization algorithm. The experiment has shown that the\nproposed method allows forming the fuzzy rule base as an exemplary optimal base\nfrom a non-optimized set of fuzzy rules. The optimal fuzzy rule base has been\ntaken under consideration for the concrete control loop of wind power plant and\nthe concrete fuzzy model of the wind.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2020 05:20:56 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Manusov", "Vadim", ""], ["Matrenin", "Pavel", ""]]}, {"id": "2006.10626", "submitter": "Ioannis Ivrissimtzis", "authors": "Latifah Abduh and Ioannis Ivrissimtzis", "title": "Use of in-the-wild images for anomaly detection in face anti-spoofing", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional approach to face anti-spoofing sees it as a binary\nclassification problem, and binary classifiers are trained and validated on\nspecialized anti-spoofing databases. One of the drawbacks of this approach is\nthat, due to the variability of face spoofing attacks, environmental factors,\nand the typically small sample size, such classifiers do not generalize well to\npreviously unseen databases. Anomaly detection, which approaches face\nanti-spoofing as a one-class classification problem, is emerging as an\nincreasingly popular alternative approach. Nevertheless, in all existing work\non anomaly detection for face anti-spoofing, the proposed training protocols\nutilize images from specialized anti-spoofing databases only, even though only\ncommon images of real faces are needed. Here, we explore the use of in-the-wild\nimages, and images from non-specialized face databases, to train one-class\nclassifiers for face anti-spoofing. Employing a well-established technique, we\ntrain a convolutional autoencoder on real faces and compare the reconstruction\nerror of the input against a threshold to classify a face image accordingly as\neither client or imposter.\n  Our results show that the inclusion in the training set of in-the-wild images\nincreases the discriminating power of the classifier significantly on an unseen\ndatabase, as evidenced by a large increase in the value of the Area Under the\nCurve. In a limitation of our approach, we note that the problem of finding a\nsuitable operating point on the unseen database remains a challenge, as\nevidenced by the values of the Half Total Error Rate.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 15:49:36 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Abduh", "Latifah", ""], ["Ivrissimtzis", "Ioannis", ""]]}, {"id": "2006.10748", "submitter": "Daniel Howard", "authors": "Daniel Howard", "title": "Genetic Programming visitation scheduling solution can deliver a less\n  austere COVID-19 pandemic population lockdown", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A computational methodology is introduced to minimize infection opportunities\nfor people suffering some degree of lockdown in response to a pandemic, as is\nthe 2020 COVID-19 pandemic. Persons use their mobile phone or computational\ndevice to request trips to places of their need or interest indicating a rough\ntime of day: `morning', `afternoon', `night' or `any time' when they would like\nto undertake these outings as well as the desired place to visit. An artificial\nintelligence methodology which is a variant of Genetic Programming studies all\nrequests and responds with specific time allocations for such visits that\nminimize the overall risks of infection, hospitalization and death of people. A\nnumber of alternatives for this computation are presented and results of\nnumerical experiments involving over 230 people of various ages and background\nhealth levels in over 1700 visits that take place over three consecutive days.\nA novel partial infection model is introduced to discuss these proof of concept\nsolutions which are compared to round robin uninformed time scheduling for\nvisits to places. The computations indicate vast improvements with far fewer\ndead and hospitalized. These auger well for a more realistic study using\naccurate infection models with the view to test deployment in the real world.\nThe input that drives the infection model is the degree of infection by\ntaxonomic class, such as the information that may arise from population testing\nfor COVID-19 or, alternatively, any contamination model. The taxonomy class\nassumed in the computations is the likely level of infection by age group.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 22:03:31 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Howard", "Daniel", ""]]}, {"id": "2006.10811", "submitter": "Ari Benjamin", "authors": "Ari S. Benjamin and Konrad P. Kording", "title": "Learning to infer in recurrent biological networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A popular theory of perceptual processing holds that the brain learns both a\ngenerative model of the world and a paired recognition model using variational\nBayesian inference. Most hypotheses of how the brain might learn these models\nassume that neurons in a population are conditionally independent given their\ncommon inputs. This simplification is likely not compatible with the type of\nlocal recurrence observed in the brain. Seeking an alternative that is\ncompatible with complex inter-dependencies yet consistent with known biology,\nwe argue here that the cortex may learn with an adversarial algorithm. Many\nobservable symptoms of this approach would resemble known neural phenomena,\nincluding wake/sleep cycles and oscillations that vary in magnitude with\nsurprise, and we describe how further predictions could be tested. We\nillustrate the idea on recurrent neural networks trained to model image and\nvideo datasets. This framework for learning brings variational inference closer\nto neuroscience and yields multiple testable hypotheses.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 19:04:47 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 17:33:06 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Benjamin", "Ari S.", ""], ["Kording", "Konrad P.", ""]]}, {"id": "2006.10848", "submitter": "Robin Tibor Schirrmeister", "authors": "Robin Tibor Schirrmeister, Yuxuan Zhou, Tonio Ball and Dan Zhang", "title": "Understanding Anomaly Detection with Deep Invertible Networks through\n  Hierarchies of Distributions and Features", "comments": "Published at NeurIPS 2020. Code can be found at\n  https://github.com/boschresearch/hierarchical_anomaly_detection", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative networks trained via maximum likelihood on a natural image\ndataset like CIFAR10 often assign high likelihoods to images from datasets with\ndifferent objects (e.g., SVHN). We refine previous investigations of this\nfailure at anomaly detection for invertible generative networks and provide a\nclear explanation of it as a combination of model bias and domain prior:\nConvolutional networks learn similar low-level feature distributions when\ntrained on any natural image dataset and these low-level features dominate the\nlikelihood. Hence, when the discriminative features between inliers and\noutliers are on a high-level, e.g., object shapes, anomaly detection becomes\nparticularly challenging. To remove the negative impact of model bias and\ndomain prior on detecting high-level differences, we propose two methods,\nfirst, using the log likelihood ratios of two identical models, one trained on\nthe in-distribution data (e.g., CIFAR10) and the other one on a more general\ndistribution of images (e.g., 80 Million Tiny Images). We also derive a novel\noutlier loss for the in-distribution network on samples from the more general\ndistribution to further improve the performance. Secondly, using a multi-scale\nmodel like Glow, we show that low-level features are mainly captured at early\nscales. Therefore, using only the likelihood contribution of the final scale\nperforms remarkably well for detecting high-level feature differences of the\nout-of-distribution and the in-distribution. This method is especially useful\nif one does not have access to a suitable general distribution. Overall, our\nmethods achieve strong anomaly detection performance in the unsupervised\nsetting, and only slightly underperform state-of-the-art classifier-based\nmethods in the supervised setting. Code can be found at\nhttps://github.com/boschresearch/hierarchical_anomaly_detection.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 20:56:14 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 17:09:58 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 17:27:25 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Schirrmeister", "Robin Tibor", ""], ["Zhou", "Yuxuan", ""], ["Ball", "Tonio", ""], ["Zhang", "Dan", ""]]}, {"id": "2006.10909", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Yatin Chaudhary and Thomas Runkler and Hinrich\n  Sch\\\"utze", "title": "Neural Topic Modeling with Continual Lifelong Learning", "comments": "ICML2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifelong learning has recently attracted attention in building machine\nlearning systems that continually accumulate and transfer knowledge to help\nfuture learning. Unsupervised topic modeling has been popularly used to\ndiscover topics from document collections. However, the application of topic\nmodeling is challenging due to data sparsity, e.g., in a small collection of\n(short) documents and thus, generate incoherent topics and sub-optimal document\nrepresentations. To address the problem, we propose a lifelong learning\nframework for neural topic modeling that can continuously process streams of\ndocument collections, accumulate topics and guide future topic modeling tasks\nby knowledge transfer from several sources to better deal with the sparse data.\nIn the lifelong process, we particularly investigate jointly: (1) sharing\ngenerative homologies (latent topics) over lifetime to transfer prior\nknowledge, and (2) minimizing catastrophic forgetting to retain the past\nlearning via novel selective data augmentation, co-training and topic\nregularization approaches. Given a stream of document collections, we apply the\nproposed Lifelong Neural Topic Modeling (LNTM) framework in modeling three\nsparse document collections as future tasks and demonstrate improved\nperformance quantified by perplexity, topic coherence and information retrieval\ntask.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 00:43:23 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Gupta", "Pankaj", ""], ["Chaudhary", "Yatin", ""], ["Runkler", "Thomas", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "2006.10935", "submitter": "Pavel Matrenin", "authors": "Pavel Matrenin, Viktor Sekaev", "title": "Particle Swarm Optimization with Velocity Restriction and Evolutionary\n  Parameters Selection for Scheduling Problem", "comments": null, "journal-ref": "2015 International Siberian Conference on Control and\n  Communications (SIBCON), 21-23 May 2015, Omsk, Russia", "doi": "10.1109/SIBCON.2015.7147143", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article presents a study of the Particle Swarm optimization method for\nscheduling problem. To improve the method's performance a restriction of\nparticles' velocity and an evolutionary meta-optimization were realized. The\napproach proposed uses the Genetic algorithms for selection of the parameters\nof Particle Swarm optimization. Experiments were carried out on test tasks of\nthe job-shop scheduling problem. This research proves the applicability of the\napproach and shows the importance of tuning the behavioral parameters of the\nswarm intelligence methods to achieve a high performance.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 02:28:57 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Matrenin", "Pavel", ""], ["Sekaev", "Viktor", ""]]}, {"id": "2006.10938", "submitter": "Pavel Matrenin", "authors": "Pavel Matrenin, Vadim Manusov", "title": "The cyclic job-shop scheduling problem: The new subclass of the job-shop\n  problem and applying the Simulated annealing to solve it", "comments": null, "journal-ref": "2016 2nd International Conference on Industrial Engineering,\n  Applications and Manufacturing (ICIEAM), 19-20 May 2016, Chelyabinsk, Russia", "doi": "10.1109/ICIEAM.2016.7911676", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper, the new approach to the scheduling problem are described. The\napproach deals with the problem of planning the cyclic production and proposes\nto consider such scheduling problem as the cyclic job-shop problem of the order\nk, where k is the number of reiterations. It was found out that planning of\nonly one iteration of the loop is less effective than planning of the entire\ncycle. To the experimental research, a number of test instances of the job-shop\nscheduling problem by Operation Research Library were used. The Simulated\nAnnealing was applied to solve the instances. The experiments proved that the\napproach proposed allows increasing the efficiency of cyclic scheduling\nsignificantly.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 02:36:29 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Matrenin", "Pavel", ""], ["Manusov", "Vadim", ""]]}, {"id": "2006.11026", "submitter": "Carola Doerr", "authors": "Arina Buzdalova, Carola Doerr, Anna Rodionova", "title": "Hybridizing the 1/5-th Success Rule with Q-Learning for Controlling the\n  Mutation Rate of an Evolutionary Algorithm", "comments": "To appear in the Proceedings of Parallel Problem Solving from Nature\n  (PPSN'2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that evolutionary algorithms (EAs) achieve peak performance\nonly when their parameters are suitably tuned to the given problem. Even more,\nit is known that the best parameter values can change during the optimization\nprocess. Parameter control mechanisms are techniques developed to identify and\nto track these values.\n  Recently, a series of rigorous theoretical works confirmed the superiority of\nseveral parameter control techniques over EAs with best possible static\nparameters. Among these results are examples for controlling the mutation rate\nof the $(1+\\lambda)$~EA when optimizing the OneMax problem. However, it was\nshown in [Rodionova et al., GECCO'19] that the quality of these techniques\nstrongly depends on the offspring population size $\\lambda$.\n  We introduce in this work a new hybrid parameter control technique, which\ncombines the well-known one-fifth success rule with Q-learning. We demonstrate\nthat our HQL mechanism achieves equal or superior performance to all techniques\ntested in [Rodionova et al., GECCO'19] and this -- in contrast to previous\nparameter control methods -- simultaneously for all offspring population sizes\n$\\lambda$. We also show that the promising performance of HQL is not restricted\nto OneMax, but extends to several other benchmark problems.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 09:12:49 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Buzdalova", "Arina", ""], ["Doerr", "Carola", ""], ["Rodionova", "Anna", ""]]}, {"id": "2006.11099", "submitter": "Michael G. M\\\"uller", "authors": "Agnes Korcsak-Gorzo, Michael G. M\\\"uller, Andreas Baumbach, Luziwei\n  Leng, Oliver Julien Breitwieser, Sacha J. van Albada, Walter Senn, Karlheinz\n  Meier, Robert Legenstein, Mihai A. Petrovici", "title": "Cortical oscillations implement a backbone for sampling-based\n  computation in spiking neural networks", "comments": "30 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brains need to deal with an uncertain world. Often, this requires visiting\nmultiple interpretations of the available information or multiple solutions to\nan encountered problem. This gives rise to the so-called mixing problem: since\nall of these \"valid\" states represent powerful attractors, but between\nthemselves can be very dissimilar, switching between such states can be\ndifficult. We propose that cortical oscillations can be effectively used to\novercome this challenge. By acting as an effective temperature, background\nspiking activity modulates exploration. Rhythmic changes induced by cortical\noscillations can then be interpreted as a form of simulated tempering. We\nprovide a rigorous mathematical discussion of this link and study some of its\nphenomenological implications in computer simulations. This identifies a new\ncomputational role of cortical oscillations and connects them to various\nphenomena in the brain, such as sampling-based probabilistic inference, memory\nreplay, multisensory cue combination and place cell flickering.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 12:18:43 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 17:18:34 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 16:26:15 GMT"}, {"version": "v4", "created": "Mon, 22 Mar 2021 20:24:02 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Korcsak-Gorzo", "Agnes", ""], ["M\u00fcller", "Michael G.", ""], ["Baumbach", "Andreas", ""], ["Leng", "Luziwei", ""], ["Breitwieser", "Oliver Julien", ""], ["van Albada", "Sacha J.", ""], ["Senn", "Walter", ""], ["Meier", "Karlheinz", ""], ["Legenstein", "Robert", ""], ["Petrovici", "Mihai A.", ""]]}, {"id": "2006.11135", "submitter": "Carola Doerr", "authors": "Quentin Renau, Carola Doerr, Johann Dreo, Benjamin Doerr", "title": "Exploratory Landscape Analysis is Strongly Sensitive to the Sampling\n  Strategy", "comments": "To appear in the proceedings of the 16th International Conference on\n  Parallel Problem Solving from Nature (PPSN 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploratory landscape analysis (ELA) supports supervised learning approaches\nfor automated algorithm selection and configuration by providing sets of\nfeatures that quantify the most relevant characteristics of the optimization\nproblem at hand. In black-box optimization, where an explicit problem\nrepresentation is not available, the feature values need to be approximated\nfrom a small number of sample points. In practice, uniformly sampled random\npoint sets and Latin hypercube constructions are commonly used sampling\nstrategies. In this work, we analyze how the sampling method and the sample\nsize influence the quality of the feature value approximations and how this\nquality impacts the accuracy of a standard classification task. While, not\nunexpectedly, increasing the number of sample points gives more robust\nestimates for the feature values, to our surprise we find that the feature\nvalue approximations for different sampling strategies do not converge to the\nsame value. This implies that approximated feature values cannot be interpreted\nindependently of the underlying sampling strategy. As our classification\nexperiments show, this also implies that the feature approximations used for\ntraining a classifier must stem from the same sampling strategy as those used\nfor the actual classification tasks. As a side result we show that classifiers\ntrained with feature values approximated by Sobol' sequences achieve higher\naccuracy than any of the standard sampling techniques. This may indicate\nimprovement potential for ELA-trained machine learning models.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 13:45:13 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Renau", "Quentin", ""], ["Doerr", "Carola", ""], ["Dreo", "Johann", ""], ["Doerr", "Benjamin", ""]]}, {"id": "2006.11282", "submitter": "Mantas Luko\\v{s}evi\\v{c}ius", "authors": "Mantas Luko\\v{s}evi\\v{c}ius and Arnas Uselis", "title": "Efficient implementations of echo state network cross-validation", "comments": "arXiv admin note: substantial text overlap with arXiv:1908.08450", "journal-ref": "Cognitive Computation, 2021", "doi": "10.1007/s12559-021-09849-2", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background/introduction: Cross-Validation (CV) is still uncommon in time\nseries modeling. Echo State Networks (ESNs), as a prime example of Reservoir\nComputing (RC) models, are known for their fast and precise one-shot learning,\nthat often benefit from good hyper-parameter tuning. This makes them ideal to\nchange the status quo.\n  Methods: We discuss CV of time series for predicting a concrete time interval\nof interest, suggest several schemes for cross-validating ESNs and introduce an\nefficient algorithm for implementing them. This algorithm is presented as two\nlevels of optimizations of doing $k$-fold CV. Training an RC model typically\nconsists of two stages: (i) running the reservoir with the data and (ii)\ncomputing the optimal readouts. The first level of our optimization addresses\nthe most computationally expensive part (i) and makes it remain constant\nirrespective of $k$. It dramatically reduces reservoir computations in any type\nof RC system and is enough if $k$ is small. The second level of optimization\nalso makes the (ii) part remain constant irrespective of large $k$, as long as\nthe dimension of the output is low. We discuss when the proposed validation\nschemes for ESNs could be beneficial, three options for producing the final\nmodel and empirically investigate them on six different real-world datasets, as\nwell as do empirical computation time experiments. We provide the code in an\nonline repository.\n  Results: Proposed CV schemes give better and more stable test performance in\nall the six different real-world datasets, three task types. Empirical run\ntimes confirm our complexity analysis.\n  Conclusions: In most situations $k$-fold CV of ESNs and many other RC models\ncan be done for virtually the same time and space complexity as a simple\nsingle-split validation. This enables CV to become a standard practice in RC.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 13:49:43 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 19:12:48 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Luko\u0161evi\u010dius", "Mantas", ""], ["Uselis", "Arnas", ""]]}, {"id": "2006.11305", "submitter": "Cem C. Tutum", "authors": "Cem C Tutum, Suhaib Abdulquddos, Risto Miikkulainen", "title": "Generalization of Agent Behavior through Explicit Representation of\n  Context", "comments": "7 pages, 6 figures, 3 tables. Revised with more comprehensive CARLA\n  results. arXiv admin note: substantial text overlap with arXiv:2002.05640", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to deploy autonomous agents in digital interactive environments,\nthey must be able to act robustly in unseen situations. The standard machine\nlearning approach is to include as much variation as possible into training\nthese agents. The agents can then interpolate within their training, but they\ncannot extrapolate much beyond it. This paper proposes a principled approach\nwhere a context module is coevolved with a skill module in the game. The\ncontext module recognizes the temporal variation in the game and modulates the\noutputs of the skill module so that the action decisions can be made robustly\neven in previously unseen situations. The approach is evaluated in the Flappy\nBird and LunarLander video games, as well as in the CARLA autonomous driving\nsimulation. The Context+Skill approach leads to significantly more robust\nbehavior in environments that require extrapolation beyond training. Such a\nprincipled generalization ability is essential in deploying autonomous agents\nin real-world tasks, and can serve as a foundation for continual adaptation as\nwell.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2020 04:35:22 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 21:51:41 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Tutum", "Cem C", ""], ["Abdulquddos", "Suhaib", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "2006.11444", "submitter": "Aneta Neumann", "authors": "Aneta Neumann and Frank Neumann", "title": "Optimising Monotone Chance-Constrained Submodular Functions Using\n  Evolutionary Multi-Objective Algorithms", "comments": "Paper accepted for publication in the proceedings of PPSN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world optimisation problems can be stated in terms of submodular\nfunctions. A lot of evolutionary multi-objective algorithms have recently been\nanalyzed and applied to submodular problems with different types of\nconstraints. We present a first runtime analysis of evolutionary\nmulti-objective algorithms for chance-constrained submodular functions. Here,\nthe constraint involves stochastic components and the constraint can only be\nviolated with a small probability of alpha. We show that the GSEMO algorithm\nobtains the same worst case performance guarantees as recently analyzed greedy\nalgorithms. Furthermore, we investigate the behavior of evolutionary\nmulti-objective algorithms such as GSEMO and NSGA-II on different submodular\nchance constrained network problems. Our experimental results show that this\nleads to significant performance improvements compared to the greedy algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 00:17:44 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Neumann", "Aneta", ""], ["Neumann", "Frank", ""]]}, {"id": "2006.11457", "submitter": "Maxim Buzdalov", "authors": "Maxim Buzdalov and Carola Doerr", "title": "Optimal Mutation Rates for the $(1+\\lambda)$ EA on OneMax", "comments": "This is an extended version of the paper accepted to the PPSN 2020\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The OneMax problem, alternatively known as the Hamming distance problem, is\noften referred to as the \"drosophila of evolutionary computation (EC)\", because\nof its high relevance in theoretical and empirical analyses of EC approaches.\nIt is therefore surprising that even for the simplest of all mutation-based\nalgorithms, Randomized Local Search and the (1+1) EA, the optimal mutation\nrates were determined only very recently, in a GECCO 2019 poster.\n  In this work, we extend the analysis of optimal mutation rates to two\nvariants of the $(1+\\lambda)$ EA and to the $(1+\\lambda)$ RLS. To do this, we\nuse dynamic programming and, for the $(1+\\lambda)$ EA, numeric optimization,\nboth requiring $\\Theta(n^3)$ time for problem dimension $n$. With this in hand,\nwe compute for all population sizes $\\lambda \\in \\{2^i \\mid 0 \\le i \\le 18\\}$\nand for problem dimension $n \\in \\{1000, 2000, 5000\\}$ which mutation rates\nminimize the expected running time and which ones maximize the expected\nprogress.\n  Our results do not only provide a lower bound against which we can measure\ncommon evolutionary approaches, but we also obtain insight into the structure\nof these optimal parameter choices. For example, we show that, for large\npopulation sizes, the best number of bits to flip is not monotone in the\ndistance to the optimum. We also observe that the expected remaining running\ntime are not necessarily unimodal for the $(1+\\lambda)$ EA$_{0 \\rightarrow 1}$\nwith shifted mutation.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 01:23:14 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Buzdalov", "Maxim", ""], ["Doerr", "Carola", ""]]}, {"id": "2006.11465", "submitter": "Junpei Zhong", "authors": "Junpei Zhong and Angelo Cangelosi and Stefan Wermter", "title": "Towards a self-organizing pre-symbolic neural model representing\n  sensorimotor primitives", "comments": null, "journal-ref": "Frontiers in behavioral neuroscience, 8, 22 (2014)", "doi": "10.3389/fnbeh.2014.00022", "report-no": null, "categories": "cs.NE cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The acquisition of symbolic and linguistic representations of sensorimotor\nbehavior is a cognitive process performed by an agent when it is executing\nand/or observing own and others' actions. According to Piaget's theory of\ncognitive development, these representations develop during the sensorimotor\nstage and the pre-operational stage. We propose a model that relates the\nconceptualization of the higher-level information from visual stimuli to the\ndevelopment of ventral/dorsal visual streams. This model employs neural network\narchitecture incorporating a predictive sensory module based on an RNNPB\n(Recurrent Neural Network with Parametric Biases) and a horizontal product\nmodel. We exemplify this model through a robot passively observing an object to\nlearn its features and movements. During the learning process of observing\nsensorimotor primitives, i.e. observing a set of trajectories of arm movements\nand its oriented object features, the pre-symbolic representation is\nself-organized in the parametric units. These representational units act as\nbifurcation parameters, guiding the robot to recognize and predict various\nlearned sensorimotor primitives. The pre-symbolic representation also accounts\nfor the learning of sensorimotor primitives in a latent learning context.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 01:58:28 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 04:30:56 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Zhong", "Junpei", ""], ["Cangelosi", "Angelo", ""], ["Wermter", "Stefan", ""]]}, {"id": "2006.11469", "submitter": "Takeshi Teshima", "authors": "Takeshi Teshima, Isao Ishikawa, Koichi Tojo, Kenta Oono, Masahiro\n  Ikeda, and Masashi Sugiyama", "title": "Coupling-based Invertible Neural Networks Are Universal Diffeomorphism\n  Approximators", "comments": "29 pages, 3 figures. Accepted at Thirty-fourth Conference on Neural\n  Information Processing Systems (NeurIPS 2020) for oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.CA math.DG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invertible neural networks based on coupling flows (CF-INNs) have various\nmachine learning applications such as image synthesis and representation\nlearning. However, their desirable characteristics such as analytic\ninvertibility come at the cost of restricting the functional forms. This poses\na question on their representation power: are CF-INNs universal approximators\nfor invertible functions? Without a universality, there could be a well-behaved\ninvertible transformation that the CF-INN can never approximate, hence it would\nrender the model class unreliable. We answer this question by showing a\nconvenient criterion: a CF-INN is universal if its layers contain affine\ncoupling and invertible linear functions as special cases. As its corollary, we\ncan affirmatively resolve a previously unsolved problem: whether normalizing\nflow models based on affine coupling can be universal distributional\napproximators. In the course of proving the universality, we prove a general\ntheorem to show the equivalence of the universality for certain diffeomorphism\nclasses, a theoretical insight that is of interest by itself.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 02:07:37 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 01:24:34 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Teshima", "Takeshi", ""], ["Ishikawa", "Isao", ""], ["Tojo", "Koichi", ""], ["Oono", "Kenta", ""], ["Ikeda", "Masahiro", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2006.11507", "submitter": "Yutaka Yamaguti", "authors": "Yutaka Yamaguti and Ichiro Tsuda", "title": "Functional differentiations in evolutionary reservoir computing networks", "comments": "Revised manuscript. 15 figures. This article has been submitted to\n  Chaos. After it is published, it will be found at\n  https://aip.scitation.org/journal/cha", "journal-ref": null, "doi": "10.1063/5.0019116", "report-no": null, "categories": "nlin.AO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extended reservoir computer that shows the functional\ndifferentiation of neurons. The reservoir computer is developed to enable\nchanging of the internal reservoir using evolutionary dynamics, and we call it\nan evolutionary reservoir computer. To develop neuronal units to show\nspecificity, depending on the input information, the internal dynamics should\nbe controlled to produce contracting dynamics after expanding dynamics.\nExpanding dynamics magnifies the difference of input information, while\ncontracting dynamics contributes to forming clusters of input information,\nthereby producing multiple attractors. The simultaneous appearance of both\ndynamics indicates the existence of chaos. In contrast, sequential appearance\nof these dynamics during finite time intervals may induce functional\ndifferentiations. In this paper, we show how specific neuronal units are\nyielded in the evolutionary reservoir computer.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 07:07:44 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 12:22:22 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Yamaguti", "Yutaka", ""], ["Tsuda", "Ichiro", ""]]}, {"id": "2006.11524", "submitter": "Saeed Amizadeh", "authors": "Saeed Amizadeh, Hamid Palangi, Oleksandr Polozov, Yichen Huang,\n  Kazuhito Koishida", "title": "Neuro-Symbolic Visual Reasoning: Disentangling \"Visual\" from \"Reasoning\"", "comments": "Published in Proceedings of the 37th International Conference on\n  Machine Learning (ICML), Online, PMLR 119, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.SC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual reasoning tasks such as visual question answering (VQA) require an\ninterplay of visual perception with reasoning about the question semantics\ngrounded in perception. However, recent advances in this area are still\nprimarily driven by perception improvements (e.g. scene graph generation)\nrather than reasoning. Neuro-symbolic models such as Neural Module Networks\nbring the benefits of compositional reasoning to VQA, but they are still\nentangled with visual representation learning, and thus neural reasoning is\nhard to improve and assess on its own. To address this, we propose (1) a\nframework to isolate and evaluate the reasoning aspect of VQA separately from\nits perception, and (2) a novel top-down calibration technique that allows the\nmodel to answer reasoning questions even with imperfect perception. To this\nend, we introduce a differentiable first-order logic formalism for VQA that\nexplicitly decouples question answering from visual perception. On the\nchallenging GQA dataset, this framework is used to perform in-depth,\ndisentangled comparisons between well-known VQA models leading to informative\ninsights regarding the participating models as well as the task.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 08:48:29 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 07:34:34 GMT"}, {"version": "v3", "created": "Tue, 25 Aug 2020 23:30:57 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Amizadeh", "Saeed", ""], ["Palangi", "Hamid", ""], ["Polozov", "Oleksandr", ""], ["Huang", "Yichen", ""], ["Koishida", "Kazuhito", ""]]}, {"id": "2006.11527", "submitter": "Mikhail Burtsev", "authors": "Mikhail S. Burtsev, Yuri Kuratov, Anton Peganov, Grigory V. Sapunov", "title": "Memory Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based models have achieved state-of-the-art results in many\nnatural language processing tasks. The self-attention architecture allows\ntransformer to combine information from all elements of a sequence into\ncontext-aware representations. However, information about the context is stored\nmostly in the same element-wise representations. This might limit the\nprocessing of properties related to the sequence as a whole more difficult.\nAdding trainable memory to selectively store local as well as global\nrepresentations of a sequence is a promising direction to improve the\nTransformer model. Memory-augmented neural networks (MANNs) extend traditional\nneural architectures with general-purpose memory for representations. MANNs\nhave demonstrated the capability to learn simple algorithms like Copy or\nReverse and can be successfully trained via backpropagation on diverse tasks\nfrom question answering to language modeling outperforming RNNs and LSTMs of\ncomparable complexity. In this work, we propose and study few extensions of the\nTransformer baseline (1) by adding memory tokens to store non-local\nrepresentations, (2) creating memory bottleneck for the global information, (3)\ncontrolling memory update with dedicated layer. We evaluate these memory\naugmented Transformers and demonstrate that presence of memory positively\ncorrelates with the model performance for machine translation and language\nmodelling tasks. Augmentation of pre-trained masked language model with memory\ntokens shows mixed results for tasks from GLUE benchmark. Visualization of\nattention patterns over the memory suggest that it improves the model's ability\nto process a global context.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 09:06:27 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 08:06:47 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Burtsev", "Mikhail S.", ""], ["Kuratov", "Yuri", ""], ["Peganov", "Anton", ""], ["Sapunov", "Grigory V.", ""]]}, {"id": "2006.11547", "submitter": "Pascal Kerschke", "authors": "Lennart Sch\\\"apermeier and Christian Grimme and Pascal Kerschke", "title": "One PLOT to Show Them All: Visualization of Efficient Sets in\n  Multi-Objective Landscapes", "comments": "This version has been accepted for publication at the 16th\n  International Conference on Parallel Problem Solving from Nature (PPSN XVI)", "journal-ref": "Proceedings of the 16th International Conference on Parallel\n  Problem Solving from Nature (PPSN XVI), pp. 154 - 167, Springer (2020)", "doi": "10.1007/978-3-030-58115-2_11", "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualization techniques for the decision space of continuous multi-objective\noptimization problems (MOPs) are rather scarce in research. For long, all\ntechniques focused on global optimality and even for the few available\nlandscape visualizations, e.g., cost landscapes, globality is the main\ncriterion. In contrast, the recently proposed gradient field heatmaps (GFHs)\nemphasize the location and attraction basins of local efficient sets, but\nignore the relation of sets in terms of solution quality.\n  In this paper, we propose a new and hybrid visualization technique, which\ncombines the advantages of both approaches in order to represent local and\nglobal optimality together within a single visualization. Therefore, we build\non the GFH approach but apply a new technique for approximating the location of\nlocally efficient points and using the divergence of the multi-objective\ngradient vector field as a robust second-order condition. Then, the relative\ndominance relationship of the determined locally efficient points is used to\nvisualize the complete landscape of the MOP. Augmented by information on the\nbasins of attraction, this Plot of Landscapes with Optimal Trade-offs (PLOT)\nbecomes one of the most informative multi-objective landscape visualization\ntechniques available.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 11:03:11 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Sch\u00e4permeier", "Lennart", ""], ["Grimme", "Christian", ""], ["Kerschke", "Pascal", ""]]}, {"id": "2006.11671", "submitter": "Elad Schneidman", "authors": "Benjamin Brazowski and Elad Schneidman", "title": "Collective Learning by Ensembles of Altruistic Diversifying Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining the predictions of collections of neural networks often outperforms\nthe best single network. Such ensembles are typically trained independently,\nand their superior `wisdom of the crowd' originates from the differences\nbetween networks. Collective foraging and decision making in socially\ninteracting animal groups is often improved or even optimal thanks to local\ninformation sharing between conspecifics. We therefore present a model for\nco-learning by ensembles of interacting neural networks that aim to maximize\ntheir own performance but also their functional relations to other networks. We\nshow that ensembles of interacting networks outperform independent ones, and\nthat optimal ensemble performance is reached when the coupling between networks\nincreases diversity and degrades the performance of individual networks. Thus,\neven without a global goal for the ensemble, optimal collective behavior\nemerges from local interactions between networks. We show the scaling of\noptimal coupling strength with ensemble size, and that networks in these\nensembles specialize functionally and become more `confident' in their\nassessments. Moreover, optimal co-learning networks differ structurally,\nrelying on sparser activity, a wider range of synaptic weights, and higher\nfiring rates - compared to independently trained networks. Finally, we explore\ninteractions-based co-learning as a framework for expanding and boosting\nensembles.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 22:53:32 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Brazowski", "Benjamin", ""], ["Schneidman", "Elad", ""]]}, {"id": "2006.11886", "submitter": "Rick Boks", "authors": "Rick Boks, Hao Wang, Thomas B\\\"ack", "title": "A Modular Hybridization of Particle Swarm Optimization and Differential\n  Evolution", "comments": "8 pages, 1 figure, to be published in GECCO 2020 Companion", "journal-ref": null, "doi": "10.1145/3377929.3398123", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In swarm intelligence, Particle Swarm Optimization (PSO) and Differential\nEvolution (DE) have been successfully applied in many optimization tasks, and a\nlarge number of variants, where novel algorithm operators or components are\nimplemented, has been introduced to boost the empirical performance. In this\npaper, we first propose to combine the variants of PSO or DE by modularizing\neach algorithm and incorporating the variants thereof as different options of\nthe corresponding modules. Then, considering the similarity between the inner\nworkings of PSO and DE, we hybridize the algorithms by creating two populations\nwith variation operators of PSO and DE respectively, and selecting individuals\nfrom those two populations. The resulting novel hybridization, called PSODE,\nencompasses most up-to-date variants from both sides, and more importantly\ngives rise to an enormous number of unseen swarm algorithms via different\ninstantiations of the modules therein.\n  In detail, we consider 16 different variation operators originating from\nexisting PSO- and DE algorithms, which, combined with 4 different selection\noperators, allow the hybridization framework to generate 800 novel algorithms.\nThe resulting set of hybrid algorithms, along with the combined 30 PSO- and DE\nalgorithms that can be generated with the considered operators, is tested on\nthe 24 problems from the well-known COCO/BBOB benchmark suite, across multiple\nfunction groups and dimensionalities.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2020 19:32:25 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Boks", "Rick", ""], ["Wang", "Hao", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2006.11958", "submitter": "Abdullah Zyarah", "authors": "Abdullah M. Zyarah, Kevin Gomez, and Dhireesha Kudithipudi", "title": "End-to-End Memristive HTM System for Pattern Recognition and Sequence\n  Prediction", "comments": null, "journal-ref": null, "doi": "10.1109/TC.2020.3000183", "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic systems that learn and predict from streaming inputs hold\nsignificant promise in pervasive edge computing and its applications. In this\npaper, a neuromorphic system that processes spatio-temporal information on the\nedge is proposed. Algorithmically, the system is based on hierarchical temporal\nmemory that inherently offers online learning, resiliency, and fault tolerance.\nArchitecturally, it is a full custom mixed-signal design with an underlying\ndigital communication scheme and analog computational modules. Therefore, the\nproposed system features reconfigurability, real-time processing, low power\nconsumption, and low-latency processing. The proposed architecture is\nbenchmarked to predict on real-world streaming data. The network's mean\nabsolute percentage error on the mixed-signal system is 1.129X lower compared\nto its baseline algorithm model. This reduction can be attributed to device\nnon-idealities and probabilistic formation of synaptic connections. We\ndemonstrate that the combined effect of Hebbian learning and network sparsity\nalso plays a major role in extending the overall network lifespan. We also\nillustrate that the system offers 3.46X reduction in latency and 77.02X\nreduction in power consumption when compared to a custom CMOS digital design\nimplemented at the same technology node. By employing specific low power\ntechniques, such as clock gating, we observe 161.37X reduction in power\nconsumption.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 01:12:14 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Zyarah", "Abdullah M.", ""], ["Gomez", "Kevin", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "2006.12155", "submitter": "Alejandro Hernandez Ruiz", "authors": "Alejandro Hernandez Ruiz, Armand Vilalta, Francesc Moreno-Noguer", "title": "Neural Cellular Automata Manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Very recently, the Neural Cellular Automata (NCA) has been proposed to\nsimulate the morphogenesis process with deep networks. NCA learns to grow an\nimage starting from a fixed single pixel. In this work, we show that the neural\nnetwork (NN) architecture of the NCA can be encapsulated in a larger NN. This\nallows us to propose a new model that encodes a manifold of NCA, each of them\ncapable of generating a distinct image. Therefore, we are effectively learning\nan embedding space of CA, which shows generalization capabilities. We\naccomplish this by introducing dynamic convolutions inside an Auto-Encoder\narchitecture, for the first time used to join two different sources of\ninformation, the encoding and cells environment information. In biological\nterms, our approach would play the role of the transcription factors,\nmodulating the mapping of genes into specific proteins that drive cellular\ndifferentiation, which occurs right before the morphogenesis. We thoroughly\nevaluate our approach in a dataset of synthetic emojis and also in real images\nof CIFAR10. Our model introduces a general-purpose network, which can be used\nin a broad range of problems beyond image generation.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 11:41:57 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 20:33:28 GMT"}, {"version": "v3", "created": "Tue, 2 Mar 2021 10:38:43 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Ruiz", "Alejandro Hernandez", ""], ["Vilalta", "Armand", ""], ["Moreno-Noguer", "Francesc", ""]]}, {"id": "2006.12161", "submitter": "Denis Antipov", "authors": "Denis Antipov, Maxim Buzdalov, Benjamin Doerr", "title": "First Steps Towards a Runtime Analysis When Starting With a Good\n  Solution", "comments": "The extended version of the PPSN 2020 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mathematical runtime analysis of evolutionary algorithms traditionally\nregards the time an algorithm needs to find a solution of a certain quality\nwhen initialized with a random population. In practical applications it may be\npossible to guess solutions that are better than random ones. We start a\nmathematical runtime analysis for such situations. We observe that different\nalgorithms profit to a very different degree from a better initialization. We\nalso show that the optimal parameterization of the algorithm can depend\nstrongly on the quality of the initial solutions. To overcome this difficulty,\nself-adjusting and randomized heavy-tailed parameter choices can be profitable.\nFinally, we observe a larger gap between the performance of the best\nevolutionary algorithm we found and the corresponding black-box complexity.\nThis could suggest that evolutionary algorithms better exploiting good initial\nsolutions are still to be found. These first findings stem from analyzing the\nperformance of the $(1+1)$ evolutionary algorithm and the static,\nself-adjusting, and heavy-tailed $(1 + (\\lambda,\\lambda))$ GA on the OneMax\nbenchmark, but we are optimistic that the question how to profit from good\ninitial solutions is interesting beyond these first examples.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 11:46:42 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 10:31:47 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Antipov", "Denis", ""], ["Buzdalov", "Maxim", ""], ["Doerr", "Benjamin", ""]]}, {"id": "2006.12169", "submitter": "Yao Lu", "authors": "Yao Lu, Stephen Gould, Thalaiyasingam Ajanthan", "title": "Bidirectionally Self-Normalizing Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of vanishing and exploding gradients has been a long-standing\nobstacle that hinders the effective training of neural networks. Despite\nvarious tricks and techniques that have been employed to alleviate the problem\nin practice, there still lacks satisfactory theories or provable solutions. In\nthis paper, we address the problem from the perspective of high-dimensional\nprobability theory. We provide a rigorous result that shows, under mild\nconditions, how the vanishing/exploding gradients problem disappears with high\nprobability if the neural networks have sufficient width. Our main idea is to\nconstrain both forward and backward signal propagation in a nonlinear neural\nnetwork through a new class of activation functions, namely Gaussian-Poincar\\'e\nnormalized functions, and orthogonal weight matrices. Experiments on both\nsynthetic and real-world data validate our theory and confirm its effectiveness\non very deep neural networks when applied in practice.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 12:07:29 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 21:57:02 GMT"}, {"version": "v3", "created": "Tue, 4 May 2021 08:02:46 GMT"}, {"version": "v4", "created": "Tue, 18 May 2021 08:20:36 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Lu", "Yao", ""], ["Gould", "Stephen", ""], ["Ajanthan", "Thalaiyasingam", ""]]}, {"id": "2006.12253", "submitter": "Victor Geadah", "authors": "Victor Geadah, Giancarlo Kerg, Stefan Horoi, Guy Wolf, Guillaume\n  Lajoie", "title": "Advantages of biologically-inspired adaptive neural activation in RNNs\n  during learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic adaptation in single-neuron response plays a fundamental role in\nneural coding in biological neural networks. Yet, most neural activation\nfunctions used in artificial networks are fixed and mostly considered as an\ninconsequential architecture choice. In this paper, we investigate nonlinear\nactivation function adaptation over the large time scale of learning, and\noutline its impact on sequential processing in recurrent neural networks. We\nintroduce a novel parametric family of nonlinear activation functions, inspired\nby input-frequency response curves of biological neurons, which allows\ninterpolation between well-known activation functions such as ReLU and sigmoid.\nUsing simple numerical experiments and tools from dynamical systems and\ninformation theory, we study the role of neural activation features in learning\ndynamics. We find that activation adaptation provides distinct task-specific\nsolutions and in some cases, improves both learning speed and performance.\nImportantly, we find that optimal activation features emerging from our\nparametric family are considerably different from typical functions used in the\nliterature, suggesting that exploiting the gap between these usual\nconfigurations can help learning. Finally, we outline situations where neural\nactivation adaptation alone may help mitigate changes in input statistics in a\ngiven task, suggesting mechanisms for transfer learning optimization.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 13:49:52 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Geadah", "Victor", ""], ["Kerg", "Giancarlo", ""], ["Horoi", "Stefan", ""], ["Wolf", "Guy", ""], ["Lajoie", "Guillaume", ""]]}, {"id": "2006.12309", "submitter": "Mathew Walter", "authors": "Mathew Walter, David Walker, Matthew Craven", "title": "Visualising Evolution History in Multi- and Many-Objective Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms are widely used to solve optimisation problems.\nHowever, challenges of transparency arise in both visualising the processes of\nan optimiser operating through a problem and understanding the problem features\nproduced from many-objective problems, where comprehending four or more spatial\ndimensions is difficult. This work considers the visualisation of a population\nas an optimisation process executes. We have adapted an existing visualisation\ntechnique to multi- and many-objective problem data, enabling a user to\nvisualise the EA processes and identify specific problem characteristics and\nthus providing a greater understanding of the problem landscape. This is\nparticularly valuable if the problem landscape is unknown, contains unknown\nfeatures or is a many-objective problem. We have shown how using this framework\nis effective on a suite of multi- and many-objective benchmark test problems,\noptimising them with NSGA-II and NSGA-III.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 14:45:03 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Walter", "Mathew", ""], ["Walker", "David", ""], ["Craven", "Matthew", ""]]}, {"id": "2006.12314", "submitter": "Dewei Wang", "authors": "Dewei Wang, Pavan Kumar Chundi, Sung Justin Kim, Minhao Yang, Joao\n  Pedro Cerqueira, Joonsung Kang, Seungchul Jung, Sangjoon Kim, Mingoo Seok", "title": "Always-On, Sub-300-nW, Event-Driven Spiking Neural Network based on\n  Spike-Driven Clock-Generation and Clock- and Power-Gating for an\n  Ultra-Low-Power Intelligent Device", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Always-on artificial intelligent (AI) functions such as keyword spotting\n(KWS) and visual wake-up tend to dominate total power consumption in ultra-low\npower devices. A key observation is that the signals to an always-on function\nare sparse in time, which a spiking neural network (SNN) classifier can\nleverage for power savings, because the switching activity and power\nconsumption of SNNs tend to scale with spike rate. Toward this goal, we present\na novel SNN classifier architecture for always-on functions, demonstrating\nsub-300nW power consumption at the competitive inference accuracy for a KWS and\nother always-on classification workloads.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 14:53:04 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 12:49:00 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Wang", "Dewei", ""], ["Chundi", "Pavan Kumar", ""], ["Kim", "Sung Justin", ""], ["Yang", "Minhao", ""], ["Cerqueira", "Joao Pedro", ""], ["Kang", "Joonsung", ""], ["Jung", "Seungchul", ""], ["Kim", "Sangjoon", ""], ["Seok", "Mingoo", ""]]}, {"id": "2006.12379", "submitter": "\\'Angel Gonz\\'alez-Prieto", "authors": "Jes\\'us Bobadilla, \\'Angel Gonz\\'alez-Prieto, Fernando Ortega, Ra\\'ul\n  Lara-Cabrera", "title": "Deep Learning feature selection to unhide demographic recommender\n  systems factors", "comments": "20 pages, 14 figures, 1 table", "journal-ref": "Neural Computing and Applications, 1-18, 2020", "doi": "10.1007/s00521-020-05494-2", "report-no": null, "categories": "cs.IR cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting demographic features from hidden factors is an innovative concept\nthat provides multiple and relevant applications. The matrix factorization\nmodel generates factors which do not incorporate semantic knowledge. This paper\nprovides a deep learning-based method: DeepUnHide, able to extract demographic\ninformation from the users and items factors in collaborative filtering\nrecommender systems. The core of the proposed method is the gradient-based\nlocalization used in the image processing literature to highlight the\nrepresentative areas of each classification class. Validation experiments make\nuse of two public datasets and current baselines. Results show the superiority\nof DeepUnHide to make feature selection and demographic classification,\ncompared to the state of art of feature selection methods. Relevant and direct\napplications include recommendations explanation, fairness in collaborative\nfiltering and recommendation to groups of users.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 17:36:48 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Bobadilla", "Jes\u00fas", ""], ["Gonz\u00e1lez-Prieto", "\u00c1ngel", ""], ["Ortega", "Fernando", ""], ["Lara-Cabrera", "Ra\u00fal", ""]]}, {"id": "2006.12439", "submitter": "Josep L. Rossello", "authors": "Christiam F. Frasser, Pablo Linares-Serrano, V. Canals, Miquel Roca,\n  T. Serrano-Gotarredona, Josep L. Rossello", "title": "Fully-parallel Convolutional Neural Network Hardware", "comments": "8 pages, 6 figures, to be submitted to an IEEE journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new trans-disciplinary knowledge area, Edge Artificial Intelligence or Edge\nIntelligence, is beginning to receive a tremendous amount of interest from the\nmachine learning community due to the ever increasing popularization of the\nInternet of Things (IoT). Unfortunately, the incorporation of AI\ncharacteristics to edge computing devices presents the drawbacks of being power\nand area hungry for typical machine learning techniques such as Convolutional\nNeural Networks (CNN). In this work, we propose a new power-and-area-efficient\narchitecture for implementing Articial Neural Networks (ANNs) in hardware,\nbased on the exploitation of correlation phenomenon in Stochastic Computing\n(SC) systems. The architecture purposed can solve the difficult implementation\nchallenges that SC presents for CNN applications, such as the high resources\nused in binary-tostochastic conversion, the inaccuracy produced by undesired\ncorrelation between signals, and the stochastic maximum function\nimplementation. Compared with traditional binary logic implementations,\nexperimental results showed an improvement of 19.6x and 6.3x in terms of speed\nperformance and energy efficiency, for the FPGA implementation. We have also\nrealized a full VLSI implementation of the proposed SC-CNN architecture\ndemonstrating that our optimization achieve a 18x area reduction over previous\nSC-DNN architecture VLSI implementation in a comparable technological node. For\nthe first time, a fully-parallel CNN as LENET-5 is embedded and tested in a\nsingle FPGA, showing the benefits of using stochastic computing for embedded\napplications, in contrast to traditional binary logic implementations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 17:19:09 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Frasser", "Christiam F.", ""], ["Linares-Serrano", "Pablo", ""], ["Canals", "V.", ""], ["Roca", "Miquel", ""], ["Serrano-Gotarredona", "T.", ""], ["Rossello", "Josep L.", ""]]}, {"id": "2006.12453", "submitter": "D Bayani", "authors": "David Bayani (1), Stefan Mitsch (1) ((1) Carnegie Mellon University)", "title": "Fanoos: Multi-Resolution, Multi-Strength, Interactive Explanations for\n  Learned Systems", "comments": "52 pages, 19 pages main body, 90 references, 3 figures, 5 tables, 12\n  pseudocode blocks Update 24 Sep. 2020 : Added a pointer to further, external\n  content: Append Section E. Update 20 Mar. 2021: Substantial additions.\n  Further explanations of process, with far more pseudocode. Some corrections\n  to a previous description; see errata section. Also briefly describe a few\n  implemented extensions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning becomes increasingly important to control the behavior of\nsafety and financially critical components in sophisticated environments, where\nthe inability to understand learned components in general, and neural nets in\nparticular, poses serious obstacles to their adoption. Explainability and\ninterpretability methods for learned systems have gained considerable academic\nattention, but the focus of current approaches on only one aspect of\nexplanation, at a fixed level of abstraction, and limited if any formal\nguarantees, prevents those explanations from being digestible by the relevant\nstakeholders (e.g., end users, certification authorities, engineers) with their\ndiverse backgrounds and situation-specific needs. We introduce Fanoos, a\nflexible framework for combining formal verification techniques, heuristic\nsearch, and user interaction to explore explanations at the desired level of\ngranularity and fidelity. We demonstrate the ability of Fanoos to produce and\nadjust the abstractness of explanations in response to user requests on a\nlearned controller for an inverted double pendulum and on a learned CPU usage\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 17:35:53 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 05:13:25 GMT"}, {"version": "v3", "created": "Sun, 25 Oct 2020 04:12:45 GMT"}, {"version": "v4", "created": "Sat, 20 Mar 2021 07:30:47 GMT"}, {"version": "v5", "created": "Wed, 14 Apr 2021 01:03:32 GMT"}, {"version": "v6", "created": "Tue, 27 Apr 2021 07:49:17 GMT"}, {"version": "v7", "created": "Wed, 28 Apr 2021 08:59:42 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Bayani", "David", "", "Carnegie Mellon University"], ["Mitsch", "Stefan", "", "Carnegie Mellon University"]]}, {"id": "2006.12486", "submitter": "Ajay Jain", "authors": "Ajay Jain and Pieter Abbeel and Deepak Pathak", "title": "Locally Masked Convolution for Autoregressive Models", "comments": "Published at Conference on Uncertainty in AI (UAI) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  High-dimensional generative models have many applications including image\ncompression, multimedia generation, anomaly detection and data completion.\nState-of-the-art estimators for natural images are autoregressive, decomposing\nthe joint distribution over pixels into a product of conditionals parameterized\nby a deep neural network, e.g. a convolutional neural network such as the\nPixelCNN. However, PixelCNNs only model a single decomposition of the joint,\nand only a single generation order is efficient. For tasks such as image\ncompletion, these models are unable to use much of the observed context. To\ngenerate data in arbitrary orders, we introduce LMConv: a simple modification\nto the standard 2D convolution that allows arbitrary masks to be applied to the\nweights at each location in the image. Using LMConv, we learn an ensemble of\ndistribution estimators that share parameters but differ in generation order,\nachieving improved performance on whole-image density estimation (2.89 bpd on\nunconditional CIFAR10), as well as globally coherent image completions. Our\ncode is available at https://ajayjain.github.io/lmconv.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 17:59:07 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 09:02:52 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2020 04:53:14 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Jain", "Ajay", ""], ["Abbeel", "Pieter", ""], ["Pathak", "Deepak", ""]]}, {"id": "2006.12575", "submitter": "Wentao Zhu", "authors": "Wentao Zhu, Can Zhao, Wenqi Li, Holger Roth, Ziyue Xu, Daguang Xu", "title": "LAMP: Large Deep Nets with Automated Model Parallelism for Image\n  Segmentation", "comments": "MICCAI 2020 Early Accepted paper. Code is\n  available\\footnote{https://monai.io/research/lamp-automated-model-parallelism}", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) models are becoming larger, because the increase in model\nsize might offer significant accuracy gain. To enable the training of large\ndeep networks, data parallelism and model parallelism are two well-known\napproaches for parallel training. However, data parallelism does not help\nreduce memory footprint per device. In this work, we introduce Large deep 3D\nConvNets with Automated Model Parallelism (LAMP) and investigate the impact of\nboth input's and deep 3D ConvNets' size on segmentation accuracy. Through\nautomated model parallelism, it is feasible to train large deep 3D ConvNets\nwith a large input patch, even the whole image. Extensive experiments\ndemonstrate that, facilitated by the automated model parallelism, the\nsegmentation accuracy can be improved through increasing model size and input\ncontext size, and large input yields significant inference speedup compared\nwith sliding window of small patches in the inference. Code is\navailable\\footnote{https://monai.io/research/lamp-automated-model-parallelism}.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 19:20:35 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 19:41:26 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 17:51:41 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Zhu", "Wentao", ""], ["Zhao", "Can", ""], ["Li", "Wenqi", ""], ["Roth", "Holger", ""], ["Xu", "Ziyue", ""], ["Xu", "Daguang", ""]]}, {"id": "2006.12703", "submitter": "Xueli Xiao", "authors": "Xueli Xiao, Ming Yan, Sunitha Basodi, Chunyan Ji, Yi Pan", "title": "Efficient Hyperparameter Optimization in Deep Learning Using a Variable\n  Length Genetic Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) have gained great success in many\nartificial intelligence tasks. However, finding a good set of hyperparameters\nfor a CNN remains a challenging task. It usually takes an expert with deep\nknowledge, and trials and errors. Genetic algorithms have been used in\nhyperparameter optimizations. However, traditional genetic algorithms with\nfixed-length chromosomes may not be a good fit for optimizing deep learning\nhyperparameters, because deep learning models have variable number of\nhyperparameters depending on the model depth. As the depth increases, the\nnumber of hyperparameters grows exponentially, and searching becomes\nexponentially harder. It is important to have an efficient algorithm that can\nfind a good model in reasonable time. In this article, we propose to use a\nvariable length genetic algorithm (GA) to systematically and automatically tune\nthe hyperparameters of a CNN to improve its performance. Experimental results\nshow that our algorithm can find good CNN hyperparameters efficiently. It is\nclear from our experiments that if more time is spent on optimizing the\nhyperparameters, better results could be achieved. Theoretically, if we had\nunlimited time and CPU power, we could find the optimized hyperparameters and\nachieve the best results in the future.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 02:37:14 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Xiao", "Xueli", ""], ["Yan", "Ming", ""], ["Basodi", "Sunitha", ""], ["Ji", "Chunyan", ""], ["Pan", "Yi", ""]]}, {"id": "2006.12745", "submitter": "Shuqi Yang", "authors": "Shuqi Yang, Xingzhe He, Bo Zhu", "title": "Learning Physical Constraints with Neural Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new family of neural networks to predict the behaviors of\nphysical systems by learning their underpinning constraints. A neural\nprojection operator lies at the heart of our approach, composed of a\nlightweight network with an embedded recursive architecture that interactively\nenforces learned underpinning constraints and predicts the various governed\nbehaviors of different physical systems. Our neural projection operator is\nmotivated by the position-based dynamics model that has been used widely in\ngame and visual effects industries to unify the various fast physics\nsimulators. Our method can automatically and effectively uncover a broad range\nof constraints from observation point data, such as length, angle, bending,\ncollision, boundary effects, and their arbitrary combinations, without any\nconnectivity priors. We provide a multi-group point representation in\nconjunction with a configurable network connection mechanism to incorporate\nprior inputs for processing complex physical systems. We demonstrated the\nefficacy of our approach by learning a set of challenging physical systems all\nin a unified and simple fashion including: rigid bodies with complex\ngeometries, ropes with varying length and bending, articulated soft and rigid\nbodies, and multi-object collisions with complex boundaries.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 04:19:04 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 23:08:33 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Yang", "Shuqi", ""], ["He", "Xingzhe", ""], ["Zhu", "Bo", ""]]}, {"id": "2006.12773", "submitter": "Anh Viet Do", "authors": "Anh Viet Do, Frank Neumann", "title": "Maximizing Submodular or Monotone Functions under Partition Matroid\n  Constraints by Multi-objective Evolutionary Algorithms", "comments": "Paper accepted for publication in the proceedings of PPSN 2020", "journal-ref": null, "doi": "10.1007/978-3-030-58115-2_41", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important problems can be regarded as maximizing submodular functions\nunder some constraints. A simple multi-objective evolutionary algorithm called\nGSEMO has been shown to achieve good approximation for submodular functions\nefficiently. While there have been many studies on the subject, most of\nexisting run-time analyses for GSEMO assume a single cardinality constraint. In\nthis work, we extend the theoretical results to partition matroid constraints\nwhich generalize cardinality constraints, and show that GSEMO can generally\nguarantee good approximation performance within polynomial expected run time.\nFurthermore, we conducted experimental comparison against a baseline GREEDY\nalgorithm in maximizing undirected graph cuts on random graphs, under various\npartition matroid constraints. The results show GSEMO tends to outperform\nGREEDY in quadratic run time.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 05:37:29 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 06:31:59 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Do", "Anh Viet", ""], ["Neumann", "Frank", ""]]}, {"id": "2006.12813", "submitter": "Eugene Lee", "authors": "Eugene Lee and Chen-Yi Lee", "title": "NeuralScale: Efficient Scaling of Neurons for Resource-Constrained Deep\n  Neural Networks", "comments": "17 pages, 11 figures, accepted by CVPR as oral paper", "journal-ref": "In Proceedings of the IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition (pp. 1478-1487) 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deciding the amount of neurons during the design of a deep neural network to\nmaximize performance is not intuitive. In this work, we attempt to search for\nthe neuron (filter) configuration of a fixed network architecture that\nmaximizes accuracy. Using iterative pruning methods as a proxy, we parameterize\nthe change of the neuron (filter) number of each layer with respect to the\nchange in parameters, allowing us to efficiently scale an architecture across\narbitrary sizes. We also introduce architecture descent which iteratively\nrefines the parameterized function used for model scaling. The combination of\nboth proposed methods is coined as NeuralScale. To prove the efficiency of\nNeuralScale in terms of parameters, we show empirical simulations on VGG11,\nMobileNetV2 and ResNet18 using CIFAR10, CIFAR100 and TinyImageNet as benchmark\ndatasets. Our results show an increase in accuracy of 3.04%, 8.56% and 3.41%\nfor VGG11, MobileNetV2 and ResNet18 on CIFAR10, CIFAR100 and TinyImageNet\nrespectively under a parameter-constrained setting (output neurons (filters) of\ndefault configuration with scaling factor of 0.25).\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 08:14:02 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Lee", "Eugene", ""], ["Lee", "Chen-Yi", ""]]}, {"id": "2006.12830", "submitter": "Donghyeon Han", "authors": "Donghyeon Han and Gwangtae Park and Junha Ryu and Hoi-jun Yoo", "title": "Extension of Direct Feedback Alignment to Convolutional and Recurrent\n  Neural Network for Bio-plausible Deep Learning", "comments": "Submitted to WACV2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Throughout this paper, we focus on the improvement of the direct feedback\nalignment (DFA) algorithm and extend the usage of the DFA to convolutional and\nrecurrent neural networks (CNNs and RNNs). Even though the DFA algorithm is\nbiologically plausible and has a potential of high-speed training, it has not\nbeen considered as the substitute for back-propagation (BP) due to the low\naccuracy in the CNN and RNN training. In this work, we propose a new DFA\nalgorithm for BP-level accurate CNN and RNN training. Firstly, we divide the\nnetwork into several modules and apply the DFA algorithm within the module.\nSecond, the DFA with the sparse backward weight is applied. It comes with a\nform of dilated convolution in the CNN case, and in a form of sparse matrix\nmultiplication in the RNN case. Additionally, the error propagation method of\nCNN becomes simpler through the group convolution. Finally, hybrid DFA\nincreases the accuracy of the CNN and RNN training to the BP-level while taking\nadvantage of the parallelism and hardware efficiency of the DFA algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 08:42:22 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Han", "Donghyeon", ""], ["Park", "Gwangtae", ""], ["Ryu", "Junha", ""], ["Yoo", "Hoi-jun", ""]]}, {"id": "2006.12878", "submitter": "Julien Launay", "authors": "Julien Launay, Iacopo Poli, Fran\\c{c}ois Boniface, Florent Krzakala", "title": "Direct Feedback Alignment Scales to Modern Deep Learning Tasks and\n  Architectures", "comments": "23 pages, 6 figures, 10 tables. For associated code, see\n  https://github.com/lightonai/dfa-scales-to-modern-deep-learning. Poster at\n  NeurIPS 2020", "journal-ref": "Advances in Neural Information Processing Systems, v33, pages\n  9346--9360, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite being the workhorse of deep learning, the backpropagation algorithm\nis no panacea. It enforces sequential layer updates, thus preventing efficient\nparallelization of the training process. Furthermore, its biological\nplausibility is being challenged. Alternative schemes have been devised; yet,\nunder the constraint of synaptic asymmetry, none have scaled to modern deep\nlearning tasks and architectures. Here, we challenge this perspective, and\nstudy the applicability of Direct Feedback Alignment to neural view synthesis,\nrecommender systems, geometric learning, and natural language processing. In\ncontrast with previous studies limited to computer vision tasks, our findings\nshow that it successfully trains a large range of state-of-the-art deep\nlearning architectures, with performance close to fine-tuned backpropagation.\nAt variance with common beliefs, our work supports that challenging tasks can\nbe tackled in the absence of weight transport.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 10:17:49 GMT"}, {"version": "v2", "created": "Fri, 11 Dec 2020 14:31:35 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Launay", "Julien", ""], ["Poli", "Iacopo", ""], ["Boniface", "Fran\u00e7ois", ""], ["Krzakala", "Florent", ""]]}, {"id": "2006.12940", "submitter": "Karoline Brucke", "authors": "Karoline Brucke, Stefan Arens, Jan-Simon Telle, Sunke~Schl\\\"uters,\n  Benedikt Hanke, Karsten von Maydell, Carsten Agert", "title": "Particle Swarm Optimization for Energy Disaggregation in Industrial and\n  Commercial Buildings", "comments": "10 pages, 13 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a formalization of the energy disaggregation problem for\nparticle swarm optimization and shows the successful application of particle\nswarm optimization for disaggregation in a multi-tenant commercial building.\nThe developed mathmatical description of the disaggregation problem using a\nstate changes matrix belongs to the group of non-event based methods for energy\ndisaggregation. This work includes the development of an objective function in\nthe power domain and the description of position and velocity of each particle\nin a high dimensional state space. For the particle swarm optimization, four\nadaptions have been applied to improve the results of disaggregation, increase\nthe robustness of the optimizer regarding local optima and reduce the\ncomputational time. The adaptions are varying movement constants, shaking of\nparticles, framing and an early stopping criterion. In this work we use two\nunlabelled power datasets with a granularity of 1 s. Therefore, the results are\nvalidated in the power domain in which good results regarding multiple error\nmeasures like root mean squared error or the percentage energy error can be\nshown.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 12:34:39 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Brucke", "Karoline", ""], ["Arens", "Stefan", ""], ["Telle", "Jan-Simon", ""], ["Sunke~Schl\u00fcters", "", ""], ["Hanke", "Benedikt", ""], ["von Maydell", "Karsten", ""], ["Agert", "Carsten", ""]]}, {"id": "2006.13138", "submitter": "Eric M\\\"uller", "authors": "Philipp Spilger, Eric M\\\"uller, Arne Emmel, Aron Leibfried, Christian\n  Mauch, Christian Pehle, Johannes Weis, Oliver Breitwieser, Sebastian\n  Billaudelle, Sebastian Schmitt, Timo C. Wunderlich, Yannik Stradmann,\n  Johannes Schemmel", "title": "hxtorch: PyTorch for BrainScaleS-2 -- Perceptrons on Analog Neuromorphic\n  Hardware", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present software facilitating the usage of the BrainScaleS-2 analog\nneuromorphic hardware system as an inference accelerator for artificial neural\nnetworks. The accelerator hardware is transparently integrated into the PyTorch\nmachine learning framework using its extension interface. In particular, we\nprovide accelerator support for vector-matrix multiplications and convolutions;\ncorresponding software-based autograd functionality is provided for\nhardware-in-the-loop training. Automatic partitioning of neural networks onto\none or multiple accelerator chips is supported. We analyze implementation\nruntime overhead during training as well as inference, provide measurements for\nexisting setups and evaluate the results in terms of the accelerator hardware\ndesign limitations. As an application of the introduced framework, we present a\nmodel that classifies activities of daily living with smartphone sensor data.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 16:33:49 GMT"}, {"version": "v2", "created": "Wed, 24 Jun 2020 15:32:17 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 08:17:31 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Spilger", "Philipp", ""], ["M\u00fcller", "Eric", ""], ["Emmel", "Arne", ""], ["Leibfried", "Aron", ""], ["Mauch", "Christian", ""], ["Pehle", "Christian", ""], ["Weis", "Johannes", ""], ["Breitwieser", "Oliver", ""], ["Billaudelle", "Sebastian", ""], ["Schmitt", "Sebastian", ""], ["Wunderlich", "Timo C.", ""], ["Stradmann", "Yannik", ""], ["Schemmel", "Johannes", ""]]}, {"id": "2006.13177", "submitter": "Eric M\\\"uller", "authors": "Johannes Weis, Philipp Spilger, Sebastian Billaudelle, Yannik\n  Stradmann, Arne Emmel, Eric M\\\"uller, Oliver Breitwieser, Andreas Gr\\\"ubl,\n  Joscha Ilmberger, Vitali Karasenko, Mitja Kleider, Christian Mauch, Korbinian\n  Schreiber, Johannes Schemmel", "title": "Inference with Artificial Neural Networks on Analog Neuromorphic\n  Hardware", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-66770-2_15", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neuromorphic BrainScaleS-2 ASIC comprises mixed-signal neurons and\nsynapse circuits as well as two versatile digital microprocessors. Primarily\ndesigned to emulate spiking neural networks, the system can also operate in a\nvector-matrix multiplication and accumulation mode for artificial neural\nnetworks. Analog multiplication is carried out in the synapse circuits, while\nthe results are accumulated on the neurons' membrane capacitors. Designed as an\nanalog, in-memory computing device, it promises high energy efficiency.\nFixed-pattern noise and trial-to-trial variations, however, require the\nimplemented networks to cope with a certain level of perturbations. Further\nlimitations are imposed by the digital resolution of the input values (5 bit),\nmatrix weights (6 bit) and resulting neuron activations (8 bit). In this paper,\nwe discuss BrainScaleS-2 as an analog inference accelerator and present\ncalibration as well as optimization strategies, highlighting the advantages of\ntraining with hardware in the loop. Among other benchmarks, we classify the\nMNIST handwritten digits dataset using a two-dimensional convolution and two\ndense layers. We reach 98.0% test accuracy, closely matching the performance of\nthe same network evaluated in software.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 17:25:06 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 07:03:05 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 15:57:35 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Weis", "Johannes", ""], ["Spilger", "Philipp", ""], ["Billaudelle", "Sebastian", ""], ["Stradmann", "Yannik", ""], ["Emmel", "Arne", ""], ["M\u00fcller", "Eric", ""], ["Breitwieser", "Oliver", ""], ["Gr\u00fcbl", "Andreas", ""], ["Ilmberger", "Joscha", ""], ["Karasenko", "Vitali", ""], ["Kleider", "Mitja", ""], ["Mauch", "Christian", ""], ["Schreiber", "Korbinian", ""], ["Schemmel", "Johannes", ""]]}, {"id": "2006.13314", "submitter": "Michele Merler", "authors": "Rameswar Panda, Michele Merler, Mayoore Jaiswal, Hui Wu, Kandan\n  Ramakrishnan, Ulrich Finkler, Chun-Fu Chen, Minsik Cho, David Kung, Rogerio\n  Feris, Bishwaranjan Bhattacharjee", "title": "NASTransfer: Analyzing Architecture Transferability in Large Scale\n  Neural Architecture Search", "comments": "19 pages, 19 Figures, 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) is an open and challenging problem in\nmachine learning. While NAS offers great promise, the prohibitive computational\ndemand of most of the existing NAS methods makes it difficult to directly\nsearch the architectures on large-scale tasks. The typical way of conducting\nlarge scale NAS is to search for an architectural building block on a small\ndataset (either using a proxy set from the large dataset or a completely\ndifferent small scale dataset) and then transfer the block to a larger dataset.\nDespite a number of recent results that show the promise of transfer from proxy\ndatasets, a comprehensive evaluation of different NAS methods studying the\nimpact of different source datasets has not yet been addressed. In this work,\nwe propose to analyze the architecture transferability of different NAS methods\nby performing a series of experiments on large scale benchmarks such as\nImageNet1K and ImageNet22K. We find that: (i) The size and domain of the proxy\nset does not seem to influence architecture performance on the target dataset.\nOn average, transfer performance of architectures searched using completely\ndifferent small datasets (e.g., CIFAR10) perform similarly to the architectures\nsearched directly on proxy target datasets. However, design of proxy sets has\nconsiderable impact on rankings of different NAS methods. (ii) While different\nNAS methods show similar performance on a source dataset (e.g., CIFAR10), they\nsignificantly differ on the transfer performance to a large dataset (e.g.,\nImageNet1K). (iii) Even on large datasets, random sampling baseline is very\ncompetitive, but the choice of the appropriate combination of proxy set and\nsearch strategy can provide significant improvement over it. We believe that\nour extensive empirical analysis will prove useful for future design of NAS\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 20:28:42 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 02:55:35 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Panda", "Rameswar", ""], ["Merler", "Michele", ""], ["Jaiswal", "Mayoore", ""], ["Wu", "Hui", ""], ["Ramakrishnan", "Kandan", ""], ["Finkler", "Ulrich", ""], ["Chen", "Chun-Fu", ""], ["Cho", "Minsik", ""], ["Kung", "David", ""], ["Feris", "Rogerio", ""], ["Bhattacharjee", "Bishwaranjan", ""]]}, {"id": "2006.13332", "submitter": "Laureline Logiaco", "authors": "Laureline Logiaco, G. Sean Escola", "title": "Thalamocortical motor circuit insights for more robust hierarchical\n  control of complex sequences", "comments": "14 pages, 5 figures. Submitted to NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study learning of recurrent neural networks that produce temporal\nsequences consisting of the concatenation of re-usable \"motifs\". In the context\nof neuroscience or robotics, these motifs would be the motor primitives from\nwhich complex behavior is generated. Given a known set of motifs, can a new\nmotif be learned without affecting the performance of the known set and then\nused in new sequences without first explicitly learning every possible\ntransition? Two requirements enable this: (i) parameter updates while learning\na new motif do not interfere with the parameters used for the previously\nacquired ones; and (ii) a new motif can be robustly generated when starting\nfrom the network state reached at the end of any of the other motifs, even if\nthat state was not present during training. We meet the first requirement by\ninvestigating artificial neural networks (ANNs) with specific architectures,\nand attempt to meet the second by training them to generate motifs from random\ninitial states. We find that learning of single motifs succeeds but that\nsequence generation is not robust: transition failures are observed. We then\ncompare these results with a model whose architecture and\nanalytically-tractable dynamics are inspired by the motor thalamocortical\ncircuit, and that includes a specific module used to implement motif\ntransitions. The synaptic weights of this model can be adjusted without\nrequiring stochastic gradient descent (SGD) on the simulated network outputs,\nand we have asymptotic guarantees that transitions will not fail. Indeed, in\nsimulations, we achieve single-motif accuracy on par with the previously\nstudied ANNs and have improved sequencing robustness with no transition\nfailures. Finally, we show that insights obtained by studying the transition\nsubnetwork of this model can also improve the robustness of transitioning in\nthe traditional ANNs previously studied.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 21:08:38 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Logiaco", "Laureline", ""], ["Escola", "G. Sean", ""]]}, {"id": "2006.13347", "submitter": "Roger Waleffe", "authors": "Roger Waleffe and Theodoros Rekatsinas", "title": "Principal Component Networks: Parameter Reduction Early in Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works show that overparameterized networks contain small subnetworks\nthat exhibit comparable accuracy to the full model when trained in isolation.\nThese results highlight the potential to reduce training costs of deep neural\nnetworks without sacrificing generalization performance. However, existing\napproaches for finding these small networks rely on expensive multi-round\ntrain-and-prune procedures and are non-practical for large data sets and\nmodels. In this paper, we show how to find small networks that exhibit the same\nperformance as their overparameterized counterparts after only a few training\nepochs. We find that hidden layer activations in overparameterized networks\nexist primarily in subspaces smaller than the actual model width. Building on\nthis observation, we use PCA to find a basis of high variance for layer inputs\nand represent layer weights using these directions. We eliminate all weights\nnot relevant to the found PCA basis and term these network architectures\nPrincipal Component Networks. On CIFAR-10 and ImageNet, we show that PCNs train\nfaster and use less energy than overparameterized models, without accuracy\nloss. We find that our transformation leads to networks with up to 23.8x fewer\nparameters, with equal or higher end-model accuracy---in some cases we observe\nimprovements up to 3%. We also show that ResNet-20 PCNs outperform deep\nResNet-110 networks while training faster.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 21:40:24 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Waleffe", "Roger", ""], ["Rekatsinas", "Theodoros", ""]]}, {"id": "2006.13546", "submitter": "Stefan Heinrich", "authors": "Stefan Heinrich, Yuan Yao, Tobias Hinz, Zhiyuan Liu, Thomas Hummel,\n  Matthias Kerzel, Cornelius Weber, and Stefan Wermter", "title": "Crossmodal Language Grounding in an Embodied Neurocognitive Model", "comments": null, "journal-ref": "Frontiers in Neurorobotics, vol 14(52), 2020", "doi": "10.3389/fnbot.2020.00052", "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Human infants are able to acquire natural language seemingly easily at an\nearly age. Their language learning seems to occur simultaneously with learning\nother cognitive functions as well as with playful interactions with the\nenvironment and caregivers. From a neuroscientific perspective, natural\nlanguage is embodied, grounded in most, if not all, sensory and sensorimotor\nmodalities, and acquired by means of crossmodal integration. However,\ncharacterising the underlying mechanisms in the brain is difficult and\nexplaining the grounding of language in crossmodal perception and action\nremains challenging. In this paper, we present a neurocognitive model for\nlanguage grounding which reflects bio-inspired mechanisms such as an implicit\nadaptation of timescales as well as end-to-end multimodal abstraction. It\naddresses developmental robotic interaction and extends its learning\ncapabilities using larger-scale knowledge-based data. In our scenario, we\nutilise the humanoid robot NICO in obtaining the EMIL data collection, in which\nthe cognitive robot interacts with objects in a children's playground\nenvironment while receiving linguistic labels from a caregiver. The model\nanalysis shows that crossmodally integrated representations are sufficient for\nacquiring language merely from sensory input through interaction with objects\nin an environment. The representations self-organise hierarchically and embed\ntemporal and spatial information through composition and decomposition. This\nmodel can also provide the basis for further crossmodal integration of\nperceptually grounded cognitive representations.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 08:12:09 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 08:27:34 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Heinrich", "Stefan", ""], ["Yao", "Yuan", ""], ["Hinz", "Tobias", ""], ["Liu", "Zhiyuan", ""], ["Hummel", "Thomas", ""], ["Kerzel", "Matthias", ""], ["Weber", "Cornelius", ""], ["Wermter", "Stefan", ""]]}, {"id": "2006.13682", "submitter": "Pedro Braga", "authors": "Pedro H. M. Braga, Heitor R. Medeiros and Hansenclever F. Bassani", "title": "Deep Categorization with Semi-Supervised Self-Organizing Maps", "comments": "Accepted for publication at the 2020 International Joint Conference\n  on Neural Networks (IJCNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Nowadays, with the advance of technology, there is an increasing amount of\nunstructured data being generated every day. However, it is a painful job to\nlabel and organize it. Labeling is an expensive, time-consuming, and difficult\ntask. It is usually done manually, which collaborates with the incorporation of\nnoise and errors to the data. Hence, it is of great importance to developing\nintelligent models that can benefit from both labeled and unlabeled data.\nCurrently, works on unsupervised and semi-supervised learning are still being\novershadowed by the successes of purely supervised learning. However, it is\nexpected that they become far more important in the longer term. This article\npresents a semi-supervised model, called Batch Semi-Supervised Self-Organizing\nMap (Batch SS-SOM), which is an extension of a SOM incorporating some advances\nthat came with the rise of Deep Learning, such as batch training. The results\nshow that Batch SS-SOM is a good option for semi-supervised classification and\nclustering. It performs well in terms of accuracy and clustering error, even\nwith a small number of labeled samples, as well as when presented to\nunsupervised data, and shows competitive results in transfer learning scenarios\nin traditional image classification benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 22:00:04 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Braga", "Pedro H. M.", ""], ["Medeiros", "Heitor R.", ""], ["Bassani", "Hansenclever F.", ""]]}, {"id": "2006.13760", "submitter": "Heinrich K\\\"uttler", "authors": "Heinrich K\\\"uttler and Nantas Nardelli and Alexander H. Miller and\n  Roberta Raileanu and Marco Selvatici and Edward Grefenstette and Tim\n  Rockt\\\"aschel", "title": "The NetHack Learning Environment", "comments": "28 pages. Accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Progress in Reinforcement Learning (RL) algorithms goes hand-in-hand with the\ndevelopment of challenging environments that test the limits of current\nmethods. While existing RL environments are either sufficiently complex or\nbased on fast simulation, they are rarely both. Here, we present the NetHack\nLearning Environment (NLE), a scalable, procedurally generated, stochastic,\nrich, and challenging environment for RL research based on the popular\nsingle-player terminal-based roguelike game, NetHack. We argue that NetHack is\nsufficiently complex to drive long-term research on problems such as\nexploration, planning, skill acquisition, and language-conditioned RL, while\ndramatically reducing the computational resources required to gather a large\namount of experience. We compare NLE and its task suite to existing\nalternatives, and discuss why it is an ideal medium for testing the robustness\nand systematic generalization of RL agents. We demonstrate empirical success\nfor early stages of the game using a distributed Deep RL baseline and Random\nNetwork Distillation exploration, alongside qualitative analysis of various\nagents trained in the environment. NLE is open source at\nhttps://github.com/facebookresearch/nle.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 14:12:56 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2020 11:05:57 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["K\u00fcttler", "Heinrich", ""], ["Nardelli", "Nantas", ""], ["Miller", "Alexander H.", ""], ["Raileanu", "Roberta", ""], ["Selvatici", "Marco", ""], ["Grefenstette", "Edward", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "2006.13858", "submitter": "Kai Xu", "authors": "Dengsheng Chen and Jun Li and Kai Xu", "title": "AReLU: Attention-based Rectified Linear Unit", "comments": "8-page main paper and 7-page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Element-wise activation functions play a critical role in deep neural\nnetworks via affecting the expressivity power and the learning dynamics.\nLearning-based activation functions have recently gained increasing attention\nand success. We propose a new perspective of learnable activation function\nthrough formulating them with element-wise attention mechanism. In each network\nlayer, we devise an attention module which learns an element-wise, sign-based\nattention map for the pre-activation feature map. The attention map scales an\nelement based on its sign. Adding the attention module with a rectified linear\nunit (ReLU) results in an amplification of positive elements and a suppression\nof negative ones, both with learned, data-adaptive parameters. We coin the\nresulting activation function Attention-based Rectified Linear Unit (AReLU).\nThe attention module essentially learns an element-wise residue of the\nactivated part of the input, as ReLU can be viewed as an identity\ntransformation. This makes the network training more resistant to gradient\nvanishing. The learned attentive activation leads to well-focused activation of\nrelevant regions of a feature map. Through extensive evaluations, we show that\nAReLU significantly boosts the performance of most mainstream network\narchitectures with only two extra learnable parameters per layer introduced.\nNotably, AReLU facilitates fast network training under small learning rates,\nwhich makes it especially suited in the case of transfer learning and meta\nlearning. Our source code has been released (see\nhttps://github.com/densechen/AReLU).\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 16:39:16 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 09:16:51 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Chen", "Dengsheng", ""], ["Li", "Jun", ""], ["Xu", "Kai", ""]]}, {"id": "2006.14253", "submitter": "Manon Flageat", "authors": "Manon Flageat, Antoine Cully", "title": "Fast and stable MAP-Elites in noisy domains using deep grids", "comments": "10 pages, 4 figures, to be published in the Proceedings of the 2020\n  Conference on Artificial Life", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality-Diversity optimisation algorithms enable the evolution of collections\nof both high-performing and diverse solutions. These collections offer the\npossibility to quickly adapt and switch from one solution to another in case it\nis not working as expected. It therefore finds many applications in real-world\ndomain problems such as robotic control. However, QD algorithms, like most\noptimisation algorithms, are very sensitive to uncertainty on the fitness\nfunction, but also on the behavioural descriptors. Yet, such uncertainties are\nfrequent in real-world applications. Few works have explored this issue in the\nspecific case of QD algorithms, and inspired by the literature in Evolutionary\nComputation, mainly focus on using sampling to approximate the \"true\" value of\nthe performances of a solution. However, sampling approaches require a high\nnumber of evaluations, which in many applications such as robotics, can quickly\nbecome impractical. In this work, we propose Deep-Grid MAP-Elites, a variant of\nthe MAP-Elites algorithm that uses an archive of similar previously encountered\nsolutions to approximate the performance of a solution. We compare our approach\nto previously explored ones on three noisy tasks: a standard optimisation task,\nthe control of a redundant arm and a simulated Hexapod robot. The experimental\nresults show that this simple approach is significantly more resilient to noise\non the behavioural descriptors, while achieving competitive performances in\nterms of fitness optimisation, and being more sample-efficient than other\nexisting approaches.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 08:47:23 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Flageat", "Manon", ""], ["Cully", "Antoine", ""]]}, {"id": "2006.14262", "submitter": "Chiranjib Sur", "authors": "Chiranjib Sur", "title": "SACT: Self-Aware Multi-Space Feature Composition Transformer for\n  Multinomial Attention for Video Captioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Video captioning works on the two fundamental concepts, feature detection and\nfeature composition. While modern day transformers are beneficial in composing\nfeatures, they lack the fundamental problems of selecting and understanding of\nthe contents. As the feature length increases, it becomes increasingly\nimportant to include provisions for improved capturing of the pertinent\ncontents. In this work, we have introduced a new concept of Self-Aware\nComposition Transformer (SACT) that is capable of generating Multinomial\nAttention (MultAtt) which is a way of generating distributions of various\ncombinations of frames. Also, multi-head attention transformer works on the\nprinciple of combining all possible contents for attention, which is good for\nnatural language classification, but has limitations for video captioning.\nVideo contents have repetitions and require parsing of important contents for\nbetter content composition. In this work, we have introduced SACT for more\nselective attention and combined them for different attention heads for better\ncapturing of the usable contents for any applications. To address the problem\nof diversification and encourage selective utilization, we propose the\nSelf-Aware Composition Transformer model for dense video captioning and apply\nthe technique on two benchmark datasets like ActivityNet and YouCookII.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 09:11:49 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Sur", "Chiranjib", ""]]}, {"id": "2006.14264", "submitter": "Chiranjib Sur", "authors": "Chiranjib Sur", "title": "Self-Segregating and Coordinated-Segregating Transformer for Focused\n  Deep Multi-Modular Network for Visual Question Answering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention mechanism has gained huge popularity due to its effectiveness in\nachieving high accuracy in different domains. But attention is opportunistic\nand is not justified by the content or usability of the content. Transformer\nlike structure creates all/any possible attention(s). We define segregating\nstrategies that can prioritize the contents for the applications for\nenhancement of performance. We defined two strategies: Self-Segregating\nTransformer (SST) and Coordinated-Segregating Transformer (CST) and used it to\nsolve visual question answering application. Self-segregation strategy for\nattention contributes in better understanding and filtering the information\nthat can be most helpful for answering the question and create diversity of\nvisual-reasoning for attention. This work can easily be used in many other\napplications that involve repetition and multiple frames of features and would\nreduce the commonality of the attentions to a great extent. Visual Question\nAnswering (VQA) requires understanding and coordination of both images and\ntextual interpretations. Experiments demonstrate that segregation strategies\nfor cascaded multi-head transformer attention outperforms many previous works\nand achieved considerable improvement for VQA-v2 dataset benchmark.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 09:17:03 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Sur", "Chiranjib", ""]]}, {"id": "2006.14270", "submitter": "Giacomo Indiveri", "authors": "Arianna Rubino, Can Livanelioglu, Ning Qiao, Melika Payvand, and\n  Giacomo Indiveri", "title": "Ultra-Low-Power FDSOI Neural Circuits for Extreme-Edge Neuromorphic\n  Intelligence", "comments": "11 pages, 9 figures, TCAS submission", "journal-ref": null, "doi": "10.1109/TCSI.2020.3035575", "report-no": null, "categories": "cs.ET cs.NE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen an increasing interest in the development of\nartificial intelligence circuits and systems for edge computing applications.\nIn-memory computing mixed-signal neuromorphic architectures provide promising\nultra-low-power solutions for edge-computing sensory-processing applications,\nthanks to their ability to emulate spiking neural networks in real-time. The\nfine-grain parallelism offered by this approach allows such neural circuits to\nprocess the sensory data efficiently by adapting their dynamics to the ones of\nthe sensed signals, without having to resort to the time-multiplexed computing\nparadigm of von Neumann architectures. To reduce power consumption even\nfurther, we present a set of mixed-signal analog/digital circuits that exploit\nthe features of advanced Fully-Depleted Silicon on Insulator (FDSOI)\nintegration processes. Specifically, we explore the options of advanced FDSOI\ntechnologies to address analog design issues and optimize the design of the\nsynapse integrator and of the adaptive neuron circuits accordingly. We present\ncircuit simulation results and demonstrate the circuit's ability to produce\nbiologically plausible neural dynamics with compact designs, optimized for the\nrealization of large-scale spiking neural networks in neuromorphic processors.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 09:31:29 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 07:17:17 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Rubino", "Arianna", ""], ["Livanelioglu", "Can", ""], ["Qiao", "Ning", ""], ["Payvand", "Melika", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "2006.14378", "submitter": "Anastasis Kratsios", "authors": "Anastasis Kratsios, Behnoosh Zamanlooy", "title": "A Canonical Transform for Strengthening the Local $L^p$-Type Universal\n  Approximation Property", "comments": "8 pages + 12 page appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most $L^p$-type universal approximation theorems guarantee that a given\nmachine learning model class $\\mathscr{F}\\subseteq\nC(\\mathbb{R}^d,\\mathbb{R}^D)$ is dense in\n$L^p_{\\mu}(\\mathbb{R}^d,\\mathbb{R}^D)$ for any suitable finite Borel measure\n$\\mu$ on $\\mathbb{R}^d$. Unfortunately, this means that the model's\napproximation quality can rapidly degenerate outside some compact subset of\n$\\mathbb{R}^d$, as any such measure is largely concentrated on some bounded\nsubset of $\\mathbb{R}^d$. This paper proposes a generic solution to this\napproximation theoretic problem by introducing a canonical transformation which\n\"upgrades $\\mathscr{F}$'s approximation property\" in the following sense. The\ntransformed model class, denoted by $\\mathscr{F}\\text{-tope}$, is shown to be\ndense in $L^p_{\\mu,\\text{strict}}(\\mathbb{R}^d,\\mathbb{R}^D)$ which is a\ntopological space whose elements are locally $p$-integrable functions and whose\ntopology is much finer than usual norm topology on\n$L^p_{\\mu}(\\mathbb{R}^d,\\mathbb{R}^D)$; here $\\mu$ is any suitable\n$\\sigma$-finite Borel measure $\\mu$ on $\\mathbb{R}^d$. Next, we show that if\n$\\mathscr{F}$ is any family of analytic functions then there is always a strict\n\"gap\" between $\\mathscr{F}\\text{-tope}$'s expressibility and that of\n$\\mathscr{F}$, since we find that $\\mathscr{F}$ can never dense in\n$L^p_{\\mu,\\text{strict}}(\\mathbb{R}^d,\\mathbb{R}^D)$. In the general case,\nwhere $\\mathscr{F}$ may contain non-analytic functions, we provide an abstract\nform of these results guaranteeing that there always exists some function space\nin which $\\mathscr{F}\\text{-tope}$ is dense but $\\mathscr{F}$ is not, while,\nthe converse is never possible. Applications to feedforward networks,\nconvolutional neural networks, and polynomial bases are explored.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2020 17:46:35 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 01:29:21 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 10:55:00 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Kratsios", "Anastasis", ""], ["Zamanlooy", "Behnoosh", ""]]}, {"id": "2006.14396", "submitter": "Kartic Subr", "authors": "Kartic Subr", "title": "Q-NET: A Network for Low-Dimensional Integrals of Neural Proxies", "comments": "11 pages (including appendix and references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications require the calculation of integrals of multidimensional\nfunctions. A general and popular procedure is to estimate integrals by\naveraging multiple evaluations of the function. Often, each evaluation of the\nfunction entails costly computations. The use of a \\emph{proxy} or surrogate\nfor the true function is useful if repeated evaluations are necessary. The\nproxy is even more useful if its integral is known analytically and can be\ncalculated practically. We propose the use of a versatile yet simple class of\nartificial neural networks -- sigmoidal universal approximators -- as a proxy\nfor functions whose integrals need to be estimated. We design a family of fixed\nnetworks, which we call Q-NETs, that operate on parameters of a trained proxy\nto calculate exact integrals over \\emph{any subset of dimensions} of the input\ndomain. We identify transformations to the input space for which integrals may\nbe recalculated without resampling the integrand or retraining the proxy. We\nhighlight the benefits of this scheme for a few applications such as inverse\nrendering, generation of procedural noise, visualization and simulation. The\nproposed proxy is appealing in the following contexts: the dimensionality is\nlow ($<10$D); the estimation of integrals needs to be decoupled from the\nsampling strategy; sparse, adaptive sampling is used; marginal functions need\nto be known in functional form; or when powerful Single Instruction Multiple\nData/Thread (SIMD/SIMT) pipelines are available for computation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 13:36:01 GMT"}, {"version": "v2", "created": "Tue, 30 Mar 2021 10:53:40 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Subr", "Kartic", ""]]}, {"id": "2006.14423", "submitter": "Pascal Kerschke", "authors": "Vera Steinhoff and Pascal Kerschke and Christian Grimme", "title": "Empirical Study on the Benefits of Multiobjectivization for Solving\n  Single-Objective Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When dealing with continuous single-objective problems, multimodality poses\none of the biggest difficulties for global optimization. Local optima are often\npreventing algorithms from making progress and thus pose a severe threat. In\nthis paper we analyze how single-objective optimization can benefit from\nmultiobjectivization by considering an additional objective. With the use of a\nsophisticated visualization technique based on the multi-objective gradients,\nthe properties of the arising multi-objective landscapes are illustrated and\nexamined. We will empirically show that the multi-objective optimizer MOGSA is\nable to exploit these properties to overcome local traps. The performance of\nMOGSA is assessed on a testbed of several functions provided by the COCO\nplatform. The results are compared to the local optimizer Nelder-Mead.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 14:04:37 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Steinhoff", "Vera", ""], ["Kerschke", "Pascal", ""], ["Grimme", "Christian", ""]]}, {"id": "2006.14536", "submitter": "Cihang Xie", "authors": "Cihang Xie, Mingxing Tan, Boqing Gong, Alan Yuille, Quoc V. Le", "title": "Smooth Adversarial Training", "comments": "tech report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is commonly believed that networks cannot be both accurate and robust,\nthat gaining robustness means losing accuracy. It is also generally believed\nthat, unless making networks larger, network architectural elements would\notherwise matter little in improving adversarial robustness. Here we present\nevidence to challenge these common beliefs by a careful study about adversarial\ntraining. Our key observation is that the widely-used ReLU activation function\nsignificantly weakens adversarial training due to its non-smooth nature. Hence\nwe propose smooth adversarial training (SAT), in which we replace ReLU with its\nsmooth approximations to strengthen adversarial training. The purpose of smooth\nactivation functions in SAT is to allow it to find harder adversarial examples\nand compute better gradient updates during adversarial training.\n  Compared to standard adversarial training, SAT improves adversarial\nrobustness for \"free\", i.e., no drop in accuracy and no increase in\ncomputational cost. For example, without introducing additional computations,\nSAT significantly enhances ResNet-50's robustness from 33.0% to 42.3%, while\nalso improving accuracy by 0.9% on ImageNet. SAT also works well with larger\nnetworks: it helps EfficientNet-L1 to achieve 82.2% accuracy and 58.6%\nrobustness on ImageNet, outperforming the previous state-of-the-art defense by\n9.5% for accuracy and 11.6% for robustness. Models are available at\nhttps://github.com/cihangxie/SmoothAdversarialTraining.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 16:34:39 GMT"}, {"version": "v2", "created": "Sun, 11 Jul 2021 00:56:58 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Xie", "Cihang", ""], ["Tan", "Mingxing", ""], ["Gong", "Boqing", ""], ["Yuille", "Alan", ""], ["Le", "Quoc V.", ""]]}, {"id": "2006.14548", "submitter": "Greg Yang", "authors": "Greg Yang", "title": "Tensor Programs II: Neural Tangent Kernel for Any Architecture", "comments": "11 pages of main text. 60 pages total. August 2020: Fixed \"BP-like\"\n  definition", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that a randomly initialized neural network of *any architecture* has\nits Tangent Kernel (NTK) converge to a deterministic limit, as the network\nwidths tend to infinity. We demonstrate how to calculate this limit. In prior\nliterature, the heuristic study of neural network gradients often assumes every\nweight matrix used in forward propagation is independent from its transpose\nused in backpropagation (Schoenholz et al. 2017). This is known as the\n*gradient independence assumption (GIA)*. We identify a commonly satisfied\ncondition, which we call *Simple GIA Check*, such that the NTK limit\ncalculation based on GIA is correct. Conversely, when Simple GIA Check fails,\nwe show GIA can result in wrong answers. Our material here presents the NTK\nresults of Yang (2019a) in a friendly manner and showcases the *tensor\nprograms* technique for understanding wide neural networks. We provide\nreference implementations of infinite-width NTKs of recurrent neural network,\ntransformer, and batch normalization at https://github.com/thegregyang/NTK4A.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 16:45:23 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 19:42:48 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2020 14:07:55 GMT"}, {"version": "v4", "created": "Mon, 30 Nov 2020 03:30:09 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Yang", "Greg", ""]]}, {"id": "2006.14560", "submitter": "Jeremy Bernstein", "authors": "Jeremy Bernstein, Jiawei Zhao, Markus Meister, Ming-Yu Liu, Anima\n  Anandkumar, Yisong Yue", "title": "Learning compositional functions via multiplicative weight updates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compositionality is a basic structural feature of both biological and\nartificial neural networks. Learning compositional functions via gradient\ndescent incurs well known problems like vanishing and exploding gradients,\nmaking careful learning rate tuning essential for real-world applications. This\npaper proves that multiplicative weight updates satisfy a descent lemma\ntailored to compositional functions. Based on this lemma, we derive Madam -- a\nmultiplicative version of the Adam optimiser -- and show that it can train\nstate of the art neural network architectures without learning rate tuning. We\nfurther show that Madam is easily adapted to train natively compressed neural\nnetworks by representing their weights in a logarithmic number system. We\nconclude by drawing connections between multiplicative weight updates and\nrecent findings about synapses in biology.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 17:05:19 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 17:34:41 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Bernstein", "Jeremy", ""], ["Zhao", "Jiawei", ""], ["Meister", "Markus", ""], ["Liu", "Ming-Yu", ""], ["Anandkumar", "Anima", ""], ["Yue", "Yisong", ""]]}, {"id": "2006.14599", "submitter": "Wei Hu", "authors": "Wei Hu, Lechao Xiao, Ben Adlam, Jeffrey Pennington", "title": "The Surprising Simplicity of the Early-Time Learning Dynamics of Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural networks are often regarded as complex black-box functions\nwhose behavior is difficult to understand owing to their nonlinear dependence\non the data and the nonconvexity in their loss landscapes. In this work, we\nshow that these common perceptions can be completely false in the early phase\nof learning. In particular, we formally prove that, for a class of well-behaved\ninput distributions, the early-time learning dynamics of a two-layer\nfully-connected neural network can be mimicked by training a simple linear\nmodel on the inputs. We additionally argue that this surprising simplicity can\npersist in networks with more layers and with convolutional architecture, which\nwe verify empirically. Key to our analysis is to bound the spectral norm of the\ndifference between the Neural Tangent Kernel (NTK) at initialization and an\naffine transform of the data kernel; however, unlike many previous results\nutilizing the NTK, we do not require the network to have disproportionately\nlarge width, and the network is allowed to escape the kernel regime later in\ntraining.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 17:42:49 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Hu", "Wei", ""], ["Xiao", "Lechao", ""], ["Adlam", "Ben", ""], ["Pennington", "Jeffrey", ""]]}, {"id": "2006.14652", "submitter": "Ojas Parekh", "authors": "Ojas Parekh, Cynthia A. Phillips, Conrad D. James, James B. Aimone", "title": "Constant-Depth and Subcubic-Size Threshold Circuits for Matrix\n  Multiplication", "comments": "Appears in the proceedings of the ACM Symposium on Parallelism in\n  Algorithms and Architectures (SPAA), 2018", "journal-ref": null, "doi": "10.1145/3210377.3210410", "report-no": null, "categories": "cs.DS cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean circuits of McCulloch-Pitts threshold gates are a classic model of\nneural computation studied heavily in the late 20th century as a model of\ngeneral computation. Recent advances in large-scale neural computing hardware\nhas made their practical implementation a near-term possibility. We describe a\ntheoretical approach for multiplying two $N$ by $N$ matrices that integrates\nthreshold gate logic with conventional fast matrix multiplication algorithms,\nthat perform $O(N^\\omega)$ arithmetic operations for a positive constant\n$\\omega < 3$. Our approach converts such a fast matrix multiplication algorithm\ninto a constant-depth threshold circuit with approximately $O(N^\\omega)$ gates.\nPrior to our work, it was not known whether the $\\Theta(N^3)$-gate barrier for\nmatrix multiplication was surmountable by constant-depth threshold circuits.\n  Dense matrix multiplication is a core operation in convolutional neural\nnetwork training. Performing this work on a neural architecture instead of\noff-loading it to a GPU may be an appealing option.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 18:28:10 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Parekh", "Ojas", ""], ["Phillips", "Cynthia A.", ""], ["James", "Conrad D.", ""], ["Aimone", "James B.", ""]]}, {"id": "2006.14887", "submitter": "Andreas Klos", "authors": "Andreas Klos, Marius Rosenbaum, Wolfram Schiffmann", "title": "Ensemble Transfer Learning for Emergency Landing Field Identification on\n  Moderate Resource Heterogeneous Kubernetes Cluster", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The full loss of thrust of an aircraft requires fast and reliable decisions\nof the pilot. If no published landing field is within reach, an emergency\nlanding field must be selected. The choice of a suitable emergency landing\nfield denotes a crucial task to avoid unnecessary damage of the aircraft, risk\nfor the civil population as well as the crew and all passengers on board.\nEspecially in case of instrument meteorological conditions it is indispensable\nto use a database of suitable emergency landing fields. Thus, based on public\navailable digital orthographic photos and digital surface models, we created\nvarious datasets with different sample sizes to facilitate training and testing\nof neural networks. Each dataset consists of a set of data layers. The best\ncompositions of these data layers as well as the best performing transfer\nlearning models are selected. Subsequently, certain hyperparameters of the\nchosen models for each sample size are optimized with Bayesian and Bandit\noptimization. The hyperparameter tuning is performed with a self-made\nKubernetes cluster. The models outputs were investigated with respect to the\ninput data by the utilization of layer-wise relevance propagation. With\noptimized models we created an ensemble model to improve the segmentation\nperformance. Finally, an area around the airport of Arnsberg in North\nRhine-Westphalia was segmented and emergency landing fields are identified,\nwhile the verification of the final approach's obstacle clearance is left\nunconsidered. These emergency landing fields are stored in a PostgreSQL\ndatabase.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 09:40:32 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 09:35:34 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Klos", "Andreas", ""], ["Rosenbaum", "Marius", ""], ["Schiffmann", "Wolfram", ""]]}, {"id": "2006.14894", "submitter": "Marcin Bia{\\l}as", "authors": "Marcin Bia{\\l}as, Marcin Micha{\\l} Miro\\'nczuk, Jacek Ma\\'ndziuk", "title": "Biologically Plausible Learning of Text Representation with Spiking\n  Neural Networks", "comments": "This article was originally submitted for Parallel Problem Solving\n  from Nature conference and will be available in Springer Lecture Notes in\n  Computer Science (LNCS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a novel biologically plausible mechanism for generating\nlow-dimensional spike-based text representation. First, we demonstrate how to\ntransform documents into series of spikes spike trains which are subsequently\nused as input in the training process of a spiking neural network (SNN). The\nnetwork is composed of biologically plausible elements, and trained according\nto the unsupervised Hebbian learning rule, Spike-Timing-Dependent Plasticity\n(STDP). After training, the SNN can be used to generate low-dimensional\nspike-based text representation suitable for text/document classification.\nEmpirical results demonstrate that the generated text representation may be\neffectively used in text classification leading to an accuracy of $80.19\\%$ on\nthe bydate version of the 20 newsgroups data set, which is a leading result\namongst approaches that rely on low-dimensional text representations.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 10:14:25 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Bia\u0142as", "Marcin", ""], ["Miro\u0144czuk", "Marcin Micha\u0142", ""], ["Ma\u0144dziuk", "Jacek", ""]]}, {"id": "2006.15078", "submitter": "Xu He", "authors": "Xu He, Min Lin", "title": "Continual Learning from the Perspective of Compression", "comments": "4th Lifelong Learning Workshop at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectionist models such as neural networks suffer from catastrophic\nforgetting. In this work, we study this problem from the perspective of\ninformation theory and define forgetting as the increase of description lengths\nof previous data when they are compressed with a sequentially learned model. In\naddition, we show that continual learning approaches based on variational\nposterior approximation and generative replay can be considered as\napproximations to two prequential coding methods in compression, namely, the\nBayesian mixture code and maximum likelihood (ML) plug-in code. We compare\nthese approaches in terms of both compression and forgetting and empirically\nstudy the reasons that limit the performance of continual learning methods\nbased on variational posterior approximation. To address these limitations, we\npropose a new continual learning method that combines ML plug-in and Bayesian\nmixture codes.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 16:15:49 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["He", "Xu", ""], ["Lin", "Min", ""]]}, {"id": "2006.15167", "submitter": "Span Spanbauer", "authors": "Span Spanbauer, Cameron Freer, Vikash Mansinghka", "title": "Deep Involutive Generative Models for Neural MCMC", "comments": "13 pages, 6 figures. Revised discussion of the Jacobian determinant\n  factor in the acceptance ratio", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce deep involutive generative models, a new architecture for deep\ngenerative modeling, and use them to define Involutive Neural MCMC, a new\napproach to fast neural MCMC. An involutive generative model represents a\nprobability kernel $G(\\phi \\mapsto \\phi')$ as an involutive (i.e.,\nself-inverting) deterministic function $f(\\phi, \\pi)$ on an enlarged state\nspace containing auxiliary variables $\\pi$. We show how to make these models\nvolume preserving, and how to use deep volume-preserving involutive generative\nmodels to make valid Metropolis-Hastings updates based on an auxiliary variable\nscheme with an easy-to-calculate acceptance ratio. We prove that deep\ninvolutive generative models and their volume-preserving special case are\nuniversal approximators for probability kernels. This result implies that with\nenough network capacity and training time, they can be used to learn\narbitrarily complex MCMC updates. We define a loss function and optimization\nalgorithm for training parameters given simulated data. We also provide initial\nexperiments showing that Involutive Neural MCMC can efficiently explore\nmulti-modal distributions that are intractable for Hybrid Monte Carlo, and can\nconverge faster than A-NICE-MC, a recently introduced neural MCMC technique.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 18:45:29 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 15:42:01 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Spanbauer", "Span", ""], ["Freer", "Cameron", ""], ["Mansinghka", "Vikash", ""]]}, {"id": "2006.15175", "submitter": "Sainath Ganesh", "authors": "Sainath G, Vignesh S, Siddarth S, G Suganya", "title": "Application of Neuroevolution in Autonomous Cars", "comments": "13 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the onset of Electric vehicles, and them becoming more and more popular,\nautonomous cars are the future in the travel/driving experience. The barrier to\nreaching level 5 autonomy is the difficulty in the collection of data that\nincorporates good driving habits and the lack thereof. The problem with current\nimplementations of self-driving cars is the need for massively large datasets\nand the need to evaluate the driving in the dataset. We propose a system that\nrequires no data for its training. An evolutionary model would have the\ncapability to optimize itself towards the fitness function. We have implemented\nNeuroevolution, a form of genetic algorithm, to train/evolve self-driving cars\nin a simulated virtual environment with the help of Unreal Engine 4, which\nutilizes Nvidia's PhysX Physics Engine to portray real-world vehicle dynamics\naccurately. We were able to observe the serendipitous nature of evolution and\nhave exploited it to reach our optimal solution. We also demonstrate the ease\nin generalizing attributes brought about by genetic algorithms and how they may\nbe used as a boilerplate upon which other machine learning techniques may be\nused to improve the overall driving experience.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 19:06:32 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["G", "Sainath", ""], ["S", "Vignesh", ""], ["S", "Siddarth", ""], ["Suganya", "G", ""]]}, {"id": "2006.15218", "submitter": "Nicolas Garcia Trillos", "authors": "Nicolas Garcia Trillos, Felix Morales, Javier Morales", "title": "Traditional and accelerated gradient descent for neural architecture\n  search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA cs.NE math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce two algorithms for neural architecture search\n(NASGD and NASAGD) following the theoretical work by two of the authors [5]\nwhich used the geometric structure of optimal transport to introduce the\nconceptual basis for new notions of traditional and accelerated gradient\ndescent algorithms for the optimization of a function on a semi-discrete space.\nOur algorithms, which use the network morphism framework introduced in [2] as a\nbaseline, can analyze forty times as many architectures as the hill climbing\nmethods [2, 14] while using the same computational resources and time and\nachieving comparable levels of accuracy. For example, using NASGD on CIFAR-10,\nour method designs and trains networks with an error rate of 4.06 in only 12\nhours on a single GPU.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2020 21:28:35 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 21:12:59 GMT"}, {"version": "v3", "created": "Sun, 14 Feb 2021 03:26:17 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Trillos", "Nicolas Garcia", ""], ["Morales", "Felix", ""], ["Morales", "Javier", ""]]}, {"id": "2006.15296", "submitter": "Rakshitha Godahewa", "authors": "Rakshitha Godahewa, Chang Deng, Arnaud Prouzeau, Christoph Bergmeir", "title": "Simulation and Optimisation of Air Conditioning Systems using Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In building management, usually static thermal setpoints are used to maintain\nthe inside temperature of a building at a comfortable level irrespective of its\noccupancy. This strategy can cause a massive amount of energy wastage and\ntherewith increase energy related expenses. This paper explores how to optimise\nthe setpoints used in a particular room during its unoccupied periods using\nmachine learning approaches. We introduce a deep-learning model based on\nRecurrent Neural Networks (RNN) that can predict the temperatures of a future\nperiod directly where a particular room is unoccupied and by using these\npredicted temperatures, we define the optimal thermal setpoints to be used\ninside the room during the unoccupied period. We show that RNNs are\nparticularly suitable for this learning task as they enable us to learn across\nmany relatively short series, which is necessary to focus on particular\noperation modes of the air conditioning (AC) system. We evaluate the prediction\naccuracy of our RNN model against a set of state-of-the-art models and are able\nto outperform those by a large margin. We furthermore analyse the usage of our\nRNN model in optimising the energy consumption of an AC system in a real-world\nscenario using the temperature data from a university lecture theatre. Based on\nthe simulations, we show that our RNN model can lead to savings around 20%\ncompared with the traditional temperature controlling model that does not use\noptimisation techniques.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 06:42:25 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Godahewa", "Rakshitha", ""], ["Deng", "Chang", ""], ["Prouzeau", "Arnaud", ""], ["Bergmeir", "Christoph", ""]]}, {"id": "2006.15604", "submitter": "Johannes Lederer", "authors": "Mohamed Hebiri and Johannes Lederer", "title": "Layer Sparsity in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity has become popular in machine learning, because it can save\ncomputational resources, facilitate interpretations, and prevent overfitting.\nIn this paper, we discuss sparsity in the framework of neural networks. In\nparticular, we formulate a new notion of sparsity that concerns the networks'\nlayers and, therefore, aligns particularly well with the current trend toward\ndeep networks. We call this notion layer sparsity. We then introduce\ncorresponding regularization and refitting schemes that can complement standard\ndeep-learning pipelines to generate more compact and accurate networks.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 13:41:59 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Hebiri", "Mohamed", ""], ["Lederer", "Johannes", ""]]}, {"id": "2006.15927", "submitter": "Jandre Albertyn", "authors": "Jandre Albertyn, Ling Cheng, Adnan M. Abu-Mahfouz", "title": "Solving MKP Applied to IoT in Smart Grid Using Meta-heuristics\n  Algorithms: A Parallel Processing Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing electricity prices in South Africa and the imminent threat of load\nshedding due to the overloaded power grid has led to a need for Demand Side\nManagement (DSM) devices like smart grids. For smart grids to perform to their\npeak, their energy management controller (EMC) systems need to be optimized.\nCurrent solutions for DSM and optimization of the Multiple Knapsack Problem\n(MKP) have been investigated in this paper to discover the current state of\ncommon DSM models. Solutions from other NP-Hard problems in the form of the\niterative Discrete Flower Pollination Algorithm (iDFPA) as well as possible\nfuture scalability options in the form of optimization through parallelization\nhave also been suggested.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 10:49:18 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Albertyn", "Jandre", ""], ["Cheng", "Ling", ""], ["Abu-Mahfouz", "Adnan M.", ""]]}, {"id": "2006.15948", "submitter": "Hendry F Chame", "authors": "Hendry F. Chame, Ahmadreza Ahmadi, Jun Tani", "title": "Towards hybrid primary intersubjectivity: a neural robotics library for\n  human science", "comments": null, "journal-ref": "Frontiers in psychology, 11 (2020)", "doi": "10.3389/fpsyg.2020.584869", "report-no": null, "categories": "cs.RO cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-robot interaction is becoming an interesting area of research in\ncognitive science, notably, for the study of social cognition. Interaction\ntheorists consider primary intersubjectivity a non-mentalist, pre-theoretical,\nnon-conceptual sort of processes that ground a certain level of communication\nand understanding, and provide support to higher-level cognitive skills. We\nargue this sort of low level cognitive interaction, where control is shared in\ndyadic encounters, is susceptible of study with neural robots. Hence, in this\nwork we pursue three main objectives. Firstly, from the concept of active\ninference we study primary intersubjectivity as a second person perspective\nexperience characterized by predictive engagement, where perception, cognition,\nand action are accounted for an hermeneutic circle in dyadic interaction.\nSecondly, we propose an open-source methodology named \\textit{neural robotics\nlibrary} (NRL) for experimental human-robot interaction, and a demonstration\nprogram for interacting in real-time with a virtual Cartesian robot (VCBot).\nLastly, through a study case, we discuss some ways human-robot (hybrid)\nintersubjectivity can contribute to human science research, such as to the\nfields of developmental psychology, educational technology, and cognitive\nrehabilitation.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 11:35:46 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Chame", "Hendry F.", ""], ["Ahmadi", "Ahmadreza", ""], ["Tani", "Jun", ""]]}, {"id": "2006.15960", "submitter": "Emmanuel Dauc\\'e", "authors": "Emmanuel Dauc\\'e", "title": "End-Effect Exploration Drive for Effective Motor Learning", "comments": "6 pages, 3 figures, submitted to IWAI 2020 (1st International\n  Workshop on Active Inference)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.RO q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stemming on the idea that a key objective in reinforcement learning is to\ninvert a target distribution of effects, end-effect drives are proposed as an\neffective way to implement goal-directed motor learning, in the absence of an\nexplicit forward model. An end-effect model relies on a simple statistical\nrecording of the effect of the current policy, here used as a substitute for\nthe more resource-demanding forward models. When combined with a reward\nstructure, it forms the core of a lightweight variational free energy\nminimization setup. The main difficulty lies in the maintenance of this\nsimplified effect model together with the online update of the policy. When the\nprior target distribution is uniform, it provides a ways to learn an efficient\nexploration policy, consistently with the intrinsic curiosity principles. When\ncombined with an extrinsic reward, our approach is finally shown to provide a\nfaster training than traditional off-policy techniques.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 11:59:34 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 14:43:05 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Dauc\u00e9", "Emmanuel", ""]]}, {"id": "2006.16204", "submitter": "James Borg", "authors": "Matt Grove, James M. Borg, Fiona Polack", "title": "Coloured noise time series as appropriate models for environmental\n  variation in artificial evolutionary systems", "comments": "8 pages, 4 figures, 2020 conference on Artificial Life", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.NE physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ecological, environmental and geophysical time series consistently exhibit\nthe characteristics of coloured (1/f^\\b{eta}) noise. Here we briefly survey the\nliterature on coloured noise, population persistence and related evolutionary\ndynamics, before introducing coloured noise as an appropriate model for\nenvironmental variation in artificial evolutionary systems. To illustrate and\nexplore the effects of different noise colours, a simple evolutionary model\nthat examines the trade-off between specialism and generalism in fluctuating\nenvironments is applied. The results of the model clearly demonstrate a need\nfor greater generalism as environmental variability becomes `whiter', whilst\nspecialisation is favoured as environmental variability becomes `redder'. Pink\nnoise, sitting midway between white and red noise, is shown to be the point at\nwhich the pressures for generalism and specialism balance, providing some\ninsight in to why `pinker' noise is increasingly being seen as an appropriate\nmodel of typical environmental variability. We go on to discuss how the results\npresented here feed in to a wider discussion on evolutionary responses to\nfluctuating environments. Ultimately we argue that Artificial Life as a field\nshould embrace the use of coloured noise to produce models of environmental\nvariability.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 17:14:29 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Grove", "Matt", ""], ["Borg", "James M.", ""], ["Polack", "Fiona", ""]]}, {"id": "2006.16302", "submitter": "Alexander Jones", "authors": "Alexander Jones and Rashmi Jha", "title": "A Compact Gated-Synapse Model for Neuromorphic Circuits", "comments": "Submitted to IEEE Transactions on Computer-Aided Design for\n  Integrated Circuits and Systems for review. \"This work has been submitted to\n  the IEEE for possible publication. Copyright may be transferred without\n  notice, after which this version may no longer be accessible.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work reports a compact behavioral model for gated-synaptic memory. The\nmodel is developed in Verilog-A for easy integration into computer-aided design\nof neuromorphic circuits using emerging memory. The model encompasses various\nforms of gated synapses within a single framework and is not restricted to only\na single type. The behavioral theory of the model is described in detail along\nwith a full list of the default parameter settings. The model includes\nparameters such as a device's ideal set time, threshold voltage, general\nevolution of the conductance with respect to time, decay of the device's state,\netc. Finally, the model's validity is shown via extensive simulation and\nfitting to experimentally reported data on published gated-synapses.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 18:22:11 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Jones", "Alexander", ""], ["Jha", "Rashmi", ""]]}, {"id": "2006.16498", "submitter": "Duo Xu", "authors": "Duo Xu, Mohit Agarwal, Ekansh Gupta, Faramarz Fekri, Raghupathy\n  Sivakumar", "title": "Accelerating Reinforcement Learning Agent with EEG-based Implicit Human\n  Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Providing Reinforcement Learning (RL) agents with human feedback can\ndramatically improve various aspects of learning. However, previous methods\nrequire human observer to give inputs explicitly (e.g., press buttons, voice\ninterface), burdening the human in the loop of RL agent's learning process.\nFurther, it is sometimes difficult or impossible to obtain the explicit human\nadvise (feedback), e.g., autonomous driving, disabled rehabilitation, etc. In\nthis work, we investigate capturing human's intrinsic reactions as implicit\n(and natural) feedback through EEG in the form of error-related potentials\n(ErrP), providing a natural and direct way for humans to improve the RL agent\nlearning. As such, the human intelligence can be integrated via implicit\nfeedback with RL algorithms to accelerate the learning of RL agent. We develop\nthree reasonably complex 2D discrete navigational games to experimentally\nevaluate the overall performance of the proposed work. Major contributions of\nour work are as follows,\n  (i) we propose and experimentally validate the zero-shot learning of ErrPs,\nwhere the ErrPs can be learned for one game, and transferred to other unseen\ngames, (ii) we propose a novel RL framework for integrating implicit human\nfeedbacks via ErrPs with RL agent, improving the label efficiency and\nrobustness to human mistakes, and (iii) compared to prior works, we scale the\napplication of ErrPs to reasonably complex environments, and demonstrate the\nsignificance of our approach for accelerated learning through real user\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 03:13:37 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 00:18:40 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 17:35:09 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Xu", "Duo", ""], ["Agarwal", "Mohit", ""], ["Gupta", "Ekansh", ""], ["Fekri", "Faramarz", ""], ["Sivakumar", "Raghupathy", ""]]}, {"id": "2006.16558", "submitter": "Vithursan Thangarasa", "authors": "Vithursan Thangarasa, Thomas Miconi, Graham W. Taylor", "title": "Enabling Continual Learning with Differentiable Hebbian Plasticity", "comments": "Published as a conference paper at IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning is the problem of sequentially learning new tasks or\nknowledge while protecting previously acquired knowledge. However, catastrophic\nforgetting poses a grand challenge for neural networks performing such learning\nprocess. Thus, neural networks that are deployed in the real world often\nstruggle in scenarios where the data distribution is non-stationary (concept\ndrift), imbalanced, or not always fully available, i.e., rare edge cases. We\npropose a Differentiable Hebbian Consolidation model which is composed of a\nDifferentiable Hebbian Plasticity (DHP) Softmax layer that adds a rapid\nlearning plastic component (compressed episodic memory) to the fixed (slow\nchanging) parameters of the softmax output layer; enabling learned\nrepresentations to be retained for a longer timescale. We demonstrate the\nflexibility of our method by integrating well-known task-specific synaptic\nconsolidation methods to penalize changes in the slow weights that are\nimportant for each target task. We evaluate our approach on the Permuted MNIST,\nSplit MNIST and Vision Datasets Mixture benchmarks, and introduce an imbalanced\nvariant of Permuted MNIST -- a dataset that combines the challenges of class\nimbalance and concept drift. Our proposed model requires no additional\nhyperparameters and outperforms comparable baselines by reducing forgetting.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 06:42:19 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Thangarasa", "Vithursan", ""], ["Miconi", "Thomas", ""], ["Taylor", "Graham W.", ""]]}, {"id": "2006.16599", "submitter": "Aydogan Ozcan", "authors": "Muhammed Veli, Deniz Mengu, Nezih T. Yardimci, Yi Luo, Jingxi Li, Yair\n  Rivenson, Mona Jarrahi, Aydogan Ozcan", "title": "Terahertz Pulse Shaping Using Diffractive Surfaces", "comments": "27 pages, 6 figures", "journal-ref": "Nature Communications (2021)", "doi": "10.1038/s41467-020-20268-z", "report-no": null, "categories": "physics.optics cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning have been providing non-intuitive solutions\nto various inverse problems in optics. At the intersection of machine learning\nand optics, diffractive networks merge wave-optics with deep learning to design\ntask-specific elements to all-optically perform various tasks such as object\nclassification and machine vision. Here, we present a diffractive network,\nwhich is used to shape an arbitrary broadband pulse into a desired optical\nwaveform, forming a compact pulse engineering system. We experimentally\ndemonstrate the synthesis of square pulses with different temporal-widths by\nmanufacturing passive diffractive layers that collectively control both the\nspectral amplitude and the phase of an input terahertz pulse. Our results\nconstitute the first demonstration of direct pulse shaping in terahertz\nspectrum, where a complex-valued spectral modulation function directly acts on\nterahertz frequencies. Furthermore, a Lego-like physical transfer learning\napproach is presented to illustrate pulse-width tunability by replacing part of\nan existing network with newly trained diffractive layers, demonstrating its\nmodularity. This learning-based diffractive pulse engineering framework can\nfind broad applications in e.g., communications, ultra-fast imaging and\nspectroscopy.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 08:27:36 GMT"}, {"version": "v2", "created": "Sat, 21 Nov 2020 03:34:48 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Veli", "Muhammed", ""], ["Mengu", "Deniz", ""], ["Yardimci", "Nezih T.", ""], ["Luo", "Yi", ""], ["Li", "Jingxi", ""], ["Rivenson", "Yair", ""], ["Jarrahi", "Mona", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "2006.16607", "submitter": "Cristian Axenie", "authors": "Du Xiaorui, Yavuzhan Erdem, Immanuel Schweizer, Cristian Axenie", "title": "A Framework for Learning Invariant Physical Relations in Multimodal\n  Sensory Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Perceptual learning enables humans to recognize and represent stimuli\ninvariant to various transformations and build a consistent representation of\nthe self and physical world. Such representations preserve the invariant\nphysical relations among the multiple perceived sensory cues. This work is an\nattempt to exploit these principles in an engineered system. We design a novel\nneural network architecture capable of learning, in an unsupervised manner,\nrelations among multiple sensory cues. The system combines computational\nprinciples, such as competition, cooperation, and correlation, in a neurally\nplausible computational substrate. It achieves that through a parallel and\ndistributed processing architecture in which the relations among the multiple\nsensory quantities are extracted from time-sequenced data. We describe the core\nsystem functionality when learning arbitrary non-linear relations in\nlow-dimensional sensory data. Here, an initial benefit rises from the fact that\nsuch a network can be engineered in a relatively straightforward way without\nprior information about the sensors and their interactions. Moreover,\nalleviating the need for tedious modelling and parametrization, the network\nconverges to a consistent description of any arbitrary high-dimensional\nmultisensory setup. We demonstrate this through a real-world learning problem,\nwhere, from standard RGB camera frames, the network learns the relations\nbetween physical quantities such as light intensity, spatial gradient, and\noptical flow, describing a visual scene. Overall, the benefits of such a\nframework lie in the capability to learn non-linear pairwise relations among\nsensory streams in an architecture that is stable under noise and missing\nsensor input.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 08:42:48 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Xiaorui", "Du", ""], ["Erdem", "Yavuzhan", ""], ["Schweizer", "Immanuel", ""], ["Axenie", "Cristian", ""]]}, {"id": "2006.16627", "submitter": "Cristian Ivan", "authors": "Cristian Ivan, Razvan Florian", "title": "Training highly effective connectivities within neural networks with\n  randomly initialized, fixed weights", "comments": "14 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present some novel, straightforward methods for training the connection\ngraph of a randomly initialized neural network without training the weights.\nThese methods do not use hyperparameters defining cutoff thresholds and\ntherefore remove the need for iteratively searching optimal values of such\nhyperparameters. We can achieve similar or higher performances than in the case\nof training all weights, with a similar computational cost as for standard\ntraining techniques. Besides switching connections on and off, we introduce a\nnovel way of training a network by flipping the signs of the weights. If we try\nto minimize the number of changed connections, by changing less than 10% of the\ntotal it is already possible to reach more than 90% of the accuracy achieved by\nstandard training. We obtain good results even with weights of constant\nmagnitude or even when weights are drawn from highly asymmetric distributions.\nThese results shed light on the over-parameterization of neural networks and on\nhow they may be reduced to their effective size.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 09:41:18 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 09:55:17 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Ivan", "Cristian", ""], ["Florian", "Razvan", ""]]}, {"id": "2006.16684", "submitter": "Simon Davidson", "authors": "Simon Davidson, Stephen B. Furber and Oliver Rhodes", "title": "Spiking Associative Memory for Spatio-Temporal Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spike Timing Dependent Plasticity is form of learning that has been\ndemonstrated in real cortical tissue, but attempts to use it for artificial\nsystems have not produced good results. This paper seeks to remedy this with\ntwo significant advances. The first is the development a simple stochastic\nlearning rule called cyclic STDP that can extract patterns encoded in the\nprecise spiking times of a group of neurons. We show that a population of\nneurons endowed with this learning rule can act as an effective short-term\nassociative memory, storing and reliably recalling a large set of pattern\nassociations over an extended period of time.\n  The second major theme examines the challenges associated with training a\nneuron to produce a spike at a precise time and for the fidelity of spike\nrecall time to be maintained as further learning occurs. The strong constraint\nof working with precisely-timed spikes (so-called temporal coding) is mandated\nby the learning rule but is also consistent with the believe in the necessity\nof such an encoding scheme to render a spiking neural network a competitive\nsolution for flexible intelligent systems in continuous learning environments.\n  The encoding and learning rules are demonstrated in the design of a\nsingle-layer associative memory (an input layer consisting of 3,200 spiking\nneurons fully-connected to a similar sized population of memory neurons), which\nwe simulate and characterise. Design considerations and clarification of the\nrole of parameters under the control of the designer are explored.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 11:08:31 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Davidson", "Simon", ""], ["Furber", "Stephen B.", ""], ["Rhodes", "Oliver", ""]]}, {"id": "2006.16709", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr and Frank Neumann", "title": "A Survey on Recent Progress in the Theory of Evolutionary Algorithms for\n  Discrete Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of evolutionary computation for discrete search spaces has made\nsignificant progress in the last ten years. This survey summarizes some of the\nmost important recent results in this research area. It discusses fine-grained\nmodels of runtime analysis of evolutionary algorithms, highlights recent\ntheoretical insights on parameter tuning and parameter control, and summarizes\nthe latest advances for stochastic and dynamic problems. We regard how\nevolutionary algorithms optimize submodular functions and we give an overview\nover the large body of recent results on estimation of distribution algorithms.\nFinally, we present the state of the art of drift analysis, one of the most\npowerful analysis technique developed in this field.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 12:03:40 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 07:42:19 GMT"}, {"version": "v3", "created": "Thu, 8 Jul 2021 06:15:26 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Doerr", "Benjamin", ""], ["Neumann", "Frank", ""]]}, {"id": "2006.16771", "submitter": "Tarik A. Rashid", "authors": "Godar J. Ibrahim, Tarik A. Rashid, Mobayode O. Akinsolu", "title": "An energy efficient service composition mechanism using a hybrid\n  meta-heuristic algorithm in a mobile cloud environment", "comments": "23 pages, Accepted. Journal of Parallel and Distributed Computing,\n  2020", "journal-ref": null, "doi": "10.1016/j.jpdc.2020.05.002", "report-no": null, "categories": "cs.NI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  By increasing mobile devices in technology and human life, using a runtime\nand mobile services has gotten more complex along with the composition of a\nlarge number of atomic services. Different services are provided by mobile\ncloud components to represent the non-functional properties as Quality of\nService (QoS), which is applied by a set of standards. On the other hand, the\ngrowth of the energy-source heterogeneity in mobile clouds is an emerging\nchallenge according to the energy-saving problem in mobile nodes. To mobile\ncloud service composition as an NP-Hard problem, an efficient selection method\nshould be taken by problem using optimal energy-aware methods that can extend\nthe deployment and interoperability of mobile cloud components. Also, an\nenergy-aware service composition mechanism is required to preserve high energy\nsaving scenarios for mobile cloud components. In this paper, an energy-aware\nmechanism is applied to optimize mobile cloud service composition using a\nhybrid Shuffled Frog Leaping Algorithm and Genetic Algorithm (SFGA).\nExperimental results capture that the proposed mechanism improves the\nfeasibility of the service composition with minimum energy consumption,\nresponse time, and cost for mobile cloud components against some current\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2020 21:38:55 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ibrahim", "Godar J.", ""], ["Rashid", "Tarik A.", ""], ["Akinsolu", "Mobayode O.", ""]]}, {"id": "2006.16823", "submitter": "Or Sharir", "authors": "Yoel Zeldes, Dan Padnos, Or Sharir, and Barak Peleg", "title": "Technical Report: Auxiliary Tuning and its Application to Conditional\n  Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple and efficient method, called Auxiliary Tuning, for\nadapting a pre-trained Language Model to a novel task; we demonstrate this\napproach on the task of conditional text generation. Our approach supplements\nthe original pre-trained model with an auxiliary model that shifts the output\ndistribution according to the target task. The auxiliary model is trained by\nadding its logits to the pre-trained model logits and maximizing the likelihood\nof the target task output. Our method imposes no constraints on the auxiliary\narchitecture. In particular, the auxiliary model can ingest additional input\nrelevant to the target task, independently from the pre-trained model's input.\nFurthermore, mixing the models at the logits level provides a natural\nprobabilistic interpretation of the method. Our method achieved similar results\nto training from scratch for several different tasks, while using significantly\nfewer resources for training; we share a specific example of text generation\nconditioned on keywords.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 14:00:48 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Zeldes", "Yoel", ""], ["Padnos", "Dan", ""], ["Sharir", "Or", ""], ["Peleg", "Barak", ""]]}, {"id": "2006.16848", "submitter": "Amir Mosavi Prof", "authors": "Akram Seifi, Mohammad Ehteram, Vijay P. Singh, Amir Mosavi", "title": "Modeling and Uncertainty Analysis of Groundwater Level Using Six\n  Evolutionary Optimization Algorithms Hybridized with ANFIS, SVM, and ANN", "comments": "42 pages, 11 figures", "journal-ref": "Sustainability 2020, 12, 4023", "doi": "10.3390/su12104023", "report-no": null, "categories": "eess.SP cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the present study, six meta-heuristic schemes are hybridized with\nartificial neural network (ANN), adaptive neuro-fuzzy interface system (ANFIS),\nand support vector machine (SVM), to predict monthly groundwater level (GWL),\nevaluate uncertainty analysis of predictions and spatial variation analysis.\nThe six schemes, including grasshopper optimization algorithm (GOA), cat swarm\noptimization (CSO), weed algorithm (WA), genetic algorithm (GA), krill\nalgorithm (KA), and particle swarm optimization (PSO), were used to hybridize\nfor improving the performance of ANN, SVM, and ANFIS models. Groundwater level\n(GWL) data of Ardebil plain (Iran) for a period of 144 months were selected to\nevaluate the hybrid models. The pre-processing technique of principal component\nanalysis (PCA) was applied to reduce input combinations from monthly time\nseries up to 12-month prediction intervals. The results showed that the\nANFIS-GOA was superior to the other hybrid models for predicting GWL in the\nfirst piezometer and third piezometer in the testing stage. The performance of\nhybrid models with optimization algorithms was far better than that of\nclassical ANN, ANFIS, and SVM models without hybridization. The percent of\nimprovements in the ANFIS-GOA versus standalone ANFIS in piezometer 10 were\n14.4%, 3%, 17.8%, and 181% for RMSE, MAE, NSE, and PBIAS in the training stage\nand 40.7%, 55%, 25%, and 132% in testing stage, respectively. The improvements\nfor piezometer 6 in train step were 15%, 4%, 13%, and 208% and in the test step\nwere 33%, 44.6%, 16.3%, and 173%, respectively, that clearly confirm the\nsuperiority of developed hybridization schemes in GWL modeling. Uncertainty\nanalysis showed that ANFIS-GOA and SVM had, respectively, the best and worst\nperformances among other models. In general, GOA enhanced the accuracy of the\nANFIS, ANN, and SVM models.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 11:06:53 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Seifi", "Akram", ""], ["Ehteram", "Mohammad", ""], ["Singh", "Vijay P.", ""], ["Mosavi", "Amir", ""]]}, {"id": "2006.16981", "submitter": "Sarthak Mittal", "authors": "Sarthak Mittal, Alex Lamb, Anirudh Goyal, Vikram Voleti, Murray\n  Shanahan, Guillaume Lajoie, Michael Mozer, Yoshua Bengio", "title": "Learning to Combine Top-Down and Bottom-Up Signals in Recurrent Neural\n  Networks with Attention over Modules", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust perception relies on both bottom-up and top-down signals. Bottom-up\nsignals consist of what's directly observed through sensation. Top-down signals\nconsist of beliefs and expectations based on past experience and short-term\nmemory, such as how the phrase `peanut butter and~...' will be completed. The\noptimal combination of bottom-up and top-down information remains an open\nquestion, but the manner of combination must be dynamic and both context and\ntask dependent. To effectively utilize the wealth of potential top-down\ninformation available, and to prevent the cacophony of intermixed signals in a\nbidirectional architecture, mechanisms are needed to restrict information flow.\nWe explore deep recurrent neural net architectures in which bottom-up and\ntop-down signals are dynamically combined using attention. Modularity of the\narchitecture further restricts the sharing and communication of information.\nTogether, attention and modularity direct information flow, which leads to\nreliable performance improvements in perceptual and language tasks, and in\nparticular improves robustness to distractions and noisy data. We demonstrate\non a variety of benchmarks in language modeling, sequential image\nclassification, video prediction and reinforcement learning that the\n\\emph{bidirectional} information flow can improve results over strong\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 17:26:19 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 05:51:03 GMT"}, {"version": "v3", "created": "Sun, 15 Nov 2020 18:34:53 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Mittal", "Sarthak", ""], ["Lamb", "Alex", ""], ["Goyal", "Anirudh", ""], ["Voleti", "Vikram", ""], ["Shanahan", "Murray", ""], ["Lajoie", "Guillaume", ""], ["Mozer", "Michael", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2006.16989", "submitter": "Amandeep Bhatia", "authors": "Amandeep Singh Bhatia, Mandeep Kaur Saggi, Shenggen Zheng, Soumya\n  Ranjan Nayak", "title": "QPSO-CD: Quantum-behaved Particle Swarm Optimization Algorithm with\n  Cauchy Distribution", "comments": "16 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by particle swarm optimization (PSO) and quantum computing theory,\nwe have presented a quantum variant of PSO (QPSO) mutated with Cauchy operator\nand natural selection mechanism (QPSO-CD) from evolutionary computations. The\nperformance of proposed hybrid quantum-behaved particle swarm optimization with\nCauchy distribution (QPSO-CD) is investigated and compared with its\ncounterparts based on a set of benchmark problems. Moreover, QPSO-CD is\nemployed in well-studied constrained engineering problems to investigate its\napplicability. Further, the correctness and time complexity of QPSO-CD are\nanalysed and compared with the classical PSO. It has been proven that QPSO-CD\nhandles such real-life problems efficiently and can attain superior solutions\nin most of the problems. The experimental results showed that QPSO associated\nwith Cauchy distribution and natural selection strategy outperforms other\nvariants in the context of stability and convergence.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 03:35:21 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Bhatia", "Amandeep Singh", ""], ["Saggi", "Mandeep Kaur", ""], ["Zheng", "Shenggen", ""], ["Nayak", "Soumya Ranjan", ""]]}]