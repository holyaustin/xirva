[{"id": "1306.0090", "submitter": "Imen Ayachi", "authors": "I. Ayachi (1),(2), R. Kammarti (2), M. Ksouri (2), P. Borne (1) (1)\n  Lagis Ecole Centrale de Lille (2) Lacs Ecole Nationale des Ingenieurs de\n  Tunis", "title": "Harmony search algorithm for the container storage problem", "comments": "7 pages, 8th International Conference of Modeling and Simulation -\n  MOSIM 10 - May 10-12, 2010 - Hammamet - Tunisia. arXiv admin note: text\n  overlap with arXiv:1305.7254", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Recently a new metaheuristic called harmony search was developed. It mimics\nthe behaviors of musicians improvising to find the better state harmony. In\nthis paper, this algorithm is described and applied to solve the container\nstorage problem in the harbor. The objective of this problem is to determine a\nvalid containers arrangement, which meets customers delivery deadlines, reduces\nthe number of container rehandlings and minimizes the ship idle time. In this\npaper, an adaptation of the harmony search algorithm to the container storage\nproblem is detailed and some experimental results are presented and discussed.\nThe proposed approach was compared to a genetic algorithm previously applied to\nthe same problem and recorded a good results.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jun 2013 09:44:01 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Ayachi", "I.", ""], ["Kammarti", "R.", ""], ["Ksouri", "M.", ""], ["Borne", "P.", ""], ["de Lille", "Lagis Ecole Centrale", ""], ["de Tunis", "Lacs Ecole Nationale des Ingenieurs", ""]]}, {"id": "1306.0225", "submitter": "Qing Hui", "authors": "Qing Hui, Haopeng Zhang", "title": "Convergence Analysis and Parallel Computing Implementation for the\n  Multiagent Coordination Optimization Algorithm", "comments": "51 pages, 34 figures", "journal-ref": null, "doi": null, "report-no": "CSEL-06-13", "categories": "math.OC cs.NE math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, a novel variation of Particle Swarm Optimization (PSO)\nalgorithm, called Multiagent Coordination Optimization (MCO), is implemented in\na parallel computing way for practical use by introducing MATLAB built-in\nfunction \"parfor\" into MCO. Then we rigorously analyze the global convergence\nof MCO by means of semistability theory. Besides sharing global optimal\nsolutions with the PSO algorithm, the MCO algorithm integrates cooperative\nswarm behavior of multiple agents into the update formula by sharing velocity\nand position information between neighbors to improve its performance.\nNumerical evaluation of the parallel MCO algorithm is provided in the report by\nrunning the proposed algorithm on supercomputers in the High Performance\nComputing Center at Texas Tech University. In particular, the optimal value and\nconsuming time are compared with PSO and serial MCO by solving several\nbenchmark functions in the literature, respectively. Based on the simulation\nresults, the performance of the parallel MCO is not only superb compared with\nPSO for solving many nonlinear, noncovex optimization problems, but also is of\nhigh efficiency by saving the computational time.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jun 2013 16:17:18 GMT"}, {"version": "v10", "created": "Sat, 29 Nov 2014 18:10:07 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2013 22:00:32 GMT"}, {"version": "v3", "created": "Tue, 13 Aug 2013 16:04:05 GMT"}, {"version": "v4", "created": "Tue, 10 Sep 2013 14:57:27 GMT"}, {"version": "v5", "created": "Wed, 30 Oct 2013 19:13:18 GMT"}, {"version": "v6", "created": "Thu, 31 Oct 2013 23:03:38 GMT"}, {"version": "v7", "created": "Fri, 8 Nov 2013 23:21:39 GMT"}, {"version": "v8", "created": "Sat, 7 Dec 2013 01:48:39 GMT"}, {"version": "v9", "created": "Thu, 20 Feb 2014 02:24:13 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Hui", "Qing", ""], ["Zhang", "Haopeng", ""]]}, {"id": "1306.0442", "submitter": "Imen Ayachi", "authors": "R. Kammarti (2), I. Ayachi (1), (2), M. Ksouri (2), P. Borne (1) ((1):\n  LAGIS, Ecole Centrale de Lille, Villeneuve dAscq, France (2): LACS, Ecole\n  Nationale des Ingenieurs de Tunis, Tunis - Belvedere. TUNISIE)", "title": "Evolutionary Approach for the Containers Bin-Packing Problem", "comments": "9 pages", "journal-ref": "Studies in Informatics and Control, Vol. 18, No. 4/2009, pages\n  315-324", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper deals with the resolution of combinatorial optimization problems,\nparticularly those concerning the maritime transport scheduling. We are\ninterested in the management platforms in a river port and more specifically in\ncontainer organisation operations with a view to minimizing the number of\ncontainer rehandlings. Subsequently, we rmeet customers delivery deadlines and\nwe reduce ship stoppage time In this paper, we propose a genetic algorithm to\nsolve this problem and we present some experiments and results.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 14:47:11 GMT"}], "update_date": "2013-06-04", "authors_parsed": [["Kammarti", "R.", ""], ["Ayachi", "I.", ""], ["Ksouri", "M.", ""], ["Borne", "P.", ""]]}, {"id": "1306.0514", "submitter": "Yann Ollivier", "authors": "Yann Ollivier", "title": "Riemannian metrics for neural networks II: recurrent networks and\n  learning symbolic data sequences", "comments": "4th version: some changes in notation, more experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are powerful models for sequential data, able to\nrepresent complex dependencies in the sequence that simpler models such as\nhidden Markov models cannot handle. Yet they are notoriously hard to train.\nHere we introduce a training procedure using a gradient ascent in a Riemannian\nmetric: this produces an algorithm independent from design choices such as the\nencoding of parameters and unit activities. This metric gradient ascent is\ndesigned to have an algorithmic cost close to backpropagation through time for\nsparsely connected networks. We use this procedure on gated leaky neural\nnetworks (GLNNs), a variant of recurrent neural networks with an architecture\ninspired by finite automata and an evolution equation inspired by\ncontinuous-time networks. GLNNs trained with a Riemannian gradient are\ndemonstrated to effectively capture a variety of structures in synthetic\nproblems: basic block nesting as in context-free grammars (an important feature\nof natural languages, but difficult to learn), intersections of multiple\nindependent Markov-type relations, or long-distance relationships such as the\ndistant-XOR problem. This method does not require adjusting the network\nstructure or initial parameters: the network used is a sparse random graph and\nthe initialization is identical for all problems considered.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 17:36:14 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2013 16:19:13 GMT"}, {"version": "v3", "created": "Sat, 12 Jul 2014 14:35:22 GMT"}, {"version": "v4", "created": "Tue, 3 Feb 2015 18:35:36 GMT"}], "update_date": "2015-02-04", "authors_parsed": [["Ollivier", "Yann", ""]]}, {"id": "1306.0543", "submitter": "Misha Denil", "authors": "Misha Denil, Babak Shakibi, Laurent Dinh, Marc'Aurelio Ranzato, Nando\n  de Freitas", "title": "Predicting Parameters in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that there is significant redundancy in the parameterization\nof several deep learning models. Given only a few weight values for each\nfeature it is possible to accurately predict the remaining values. Moreover, we\nshow that not only can the parameter values be predicted, but many of them need\nnot be learned at all. We train several different architectures by learning\nonly a small number of weights and predicting the rest. In the best case we are\nable to predict more than 95% of the weights of a network without any drop in\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2013 19:16:26 GMT"}, {"version": "v2", "created": "Mon, 27 Oct 2014 11:49:08 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Denil", "Misha", ""], ["Shakibi", "Babak", ""], ["Dinh", "Laurent", ""], ["Ranzato", "Marc'Aurelio", ""], ["de Freitas", "Nando", ""]]}, {"id": "1306.0896", "submitter": "Sugata Sanyal", "authors": "Siby Abraham, Sugata Sanyal, Mukund Sanglikar", "title": "Finding Numerical Solutions of Diophantine Equations using Ant Colony\n  Optimization", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper attempts to find numerical solutions of Diophantine equations, a\nchallenging problem as there are no general methods to find solutions of such\nequations. It uses the metaphor of foraging habits of real ants. The ant colony\noptimization based procedure starts with randomly assigned locations to a fixed\nnumber of artificial ants. Depending upon the quality of these positions, ants\ndeposit pheromone at the nodes. A successor node is selected from the\ntopological neighborhood of each of the nodes based on this stochastic\npheromone deposit. If an ant bumps into an already encountered node, the\npheromone is updated correspondingly. A suitably defined pheromone evaporation\nstrategy guarantees that premature convergence does not take place. The\nexperimental results, which compares with those of other machine intelligence\ntechniques, validate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2013 18:36:22 GMT"}], "update_date": "2013-06-06", "authors_parsed": [["Abraham", "Siby", ""], ["Sanyal", "Sugata", ""], ["Sanglikar", "Mukund", ""]]}, {"id": "1306.0897", "submitter": "Cyril Voyant", "authors": "Wani W. Tamas (SPE), Gilles Notton (SPE), Christophe Paoli (SPE),\n  Cyril Voyant (SPE, CHD Castellucio), Marie Laure Nivet (SPE), Aur\\'elia Balu\n  (SPE)", "title": "Urban ozone concentration forecasting with artificial neural network in\n  Corsica", "comments": "Sustainable Solutions for Energy and Environment. EENVIRO 2013,\n  Buchatrest : Romania (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atmospheric pollutants concentration forecasting is an important issue in air\nquality monitoring. Qualitair Corse, the organization responsible for\nmonitoring air quality in Corsica (France) region, needs to develop a\nshort-term prediction model to lead its mission of information towards the\npublic. Various deterministic models exist for meso-scale or local forecasting,\nbut need powerful large variable sets, a good knowledge of atmospheric\nprocesses, and can be inaccurate because of local climatical or geographical\nparticularities, as observed in Corsica, a mountainous island located in a\nMediterranean Sea. As a result, we focus in this study on statistical models,\nand particularly Artificial Neural Networks (ANN) that have shown good results\nin the prediction of ozone concentration at horizon h+1 with data measured\nlocally. The purpose of this study is to build a predictor to realize\npredictions of ozone and PM10 at horizon d+1 in Corsica in order to be able to\nanticipate pollution peak formation and to take appropriated prevention\nmeasures. Specific meteorological conditions are known to lead to particular\npollution event in Corsica (e.g. Saharan dust event). Therefore, several ANN\nmodels will be used, for meteorological conditions clustering and for\noperational forecasting.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jun 2013 18:42:57 GMT"}], "update_date": "2013-06-06", "authors_parsed": [["Tamas", "Wani W.", "", "SPE"], ["Notton", "Gilles", "", "SPE"], ["Paoli", "Christophe", "", "SPE"], ["Voyant", "Cyril", "", "SPE, CHD Castellucio"], ["Nivet", "Marie Laure", "", "SPE"], ["Balu", "Aur\u00e9lia", "", "SPE"]]}, {"id": "1306.1358", "submitter": "Eckhard Hitzer", "authors": "Eckhard Hitzer", "title": "Geometric operations implemented by conformal geometric algebra neural\n  nodes", "comments": "6 pages, 2 tables, 10 figures", "journal-ref": "Proc. SICE Symposium on Systems and Information 2008, 26-28 Nov.\n  2008, Himeji, Japan, pp. 357-362 (2008)", "doi": null, "report-no": null, "categories": "cs.CV cs.NE math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric algebra is an optimal frame work for calculating with vectors. The\ngeometric algebra of a space includes elements that represent all the its\nsubspaces (lines, planes, volumes, ...). Conformal geometric algebra expands\nthis approach to elementary representations of arbitrary points, point pairs,\nlines, circles, planes and spheres. Apart from including curved objects,\nconformal geometric algebra has an elegant unified quaternion like\nrepresentation for all proper and improper Euclidean transformations, including\nreflections at spheres, general screw transformations and scaling. Expanding\nthe concepts of real and complex neurons we arrive at the new powerful concept\nof conformal geometric algebra neurons. These neurons can easily take the above\nmentioned geometric objects or sets of these objects as inputs and apply a wide\nrange of geometric transformations via the geometric algebra valued weights.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2013 09:48:49 GMT"}], "update_date": "2013-06-07", "authors_parsed": [["Hitzer", "Eckhard", ""]]}, {"id": "1306.1653", "submitter": "Eckhard Hitzer", "authors": "Eckhard Hitzer", "title": "Non-constant bounded holomorphic functions of hyperbolic numbers -\n  Candidates for hyperbolic activation functions", "comments": "6 pages, 2 figures", "journal-ref": "in Y. Kuroe, T. Nitta (eds.), Proceedings of the First SICE\n  Symposium on Computational Intelligence [Concentrating on Clifford Neural\n  Computing], 30 Sep. 2011, KIT, Kyoto, Japan, catalogue no. 11PG0009, pp. 23 -\n  28, 2011", "doi": null, "report-no": null, "categories": "cs.NE cs.CV math.RA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Liouville theorem states that bounded holomorphic complex functions are\nnecessarily constant. Holomorphic functions fulfill the socalled Cauchy-Riemann\n(CR) conditions. The CR conditions mean that a complex $z$-derivative is\nindependent of the direction. Holomorphic functions are ideal for activation\nfunctions of complex neural networks, but the Liouville theorem makes them\nuseless. Yet recently the use of hyperbolic numbers, lead to the construction\nof hyperbolic number neural networks. We will describe the Cauchy-Riemann\nconditions for hyperbolic numbers and show that there exists a new interesting\ntype of bounded holomorphic functions of hyperbolic numbers, which are not\nconstant. We give examples of such functions. They therefore substantially\nexpand the available candidates for holomorphic activation functions for\nhyperbolic number neural networks.\n  Keywords: Hyperbolic numbers, Liouville theorem, Cauchy-Riemann conditions,\nbounded holomorphic functions\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2013 08:43:11 GMT"}], "update_date": "2013-06-10", "authors_parsed": [["Hitzer", "Eckhard", ""]]}, {"id": "1306.2257", "submitter": "Iztok Fister", "authors": "Iztok Fister, Iztok Fister Jr", "title": "Using the quaternion's representation of individuals in swarm\n  intelligence and evolutionary computation", "comments": "Technical Report on Faculty of Electrical Engineering and Computer\n  Science, Maribor, Slovenia, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel idea for representation of individuals using\nquaternions in swarm intelligence and evolutionary algorithms. Quaternions are\na number system, which extends complex numbers. They are successfully applied\nto problems of theoretical physics and to those areas needing fast rotation\ncalculations. We propose the application of quaternions in optimization, more\nprecisely, we have been using quaternions for representation of individuals in\nBat algorithm. The preliminary results of our experiments when optimizing a\ntest-suite consisting of ten standard functions showed that this new algorithm\nsignificantly improved the results of the original Bat algorithm. Moreover, the\nobtained results are comparable with other swarm intelligence and evolutionary\nalgorithms, like the artificial bees colony, and differential evolution. We\nbelieve that this representation could also be successfully applied to other\nswarm intelligence and evolutionary algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2013 17:43:28 GMT"}], "update_date": "2013-06-11", "authors_parsed": [["Fister", "Iztok", ""], ["Fister", "Iztok", "Jr"]]}, {"id": "1306.2801", "submitter": "KyungHyun Cho", "authors": "Kyunghyun Cho", "title": "Understanding Dropout: Training Multi-Layer Perceptrons with Auxiliary\n  Independent Stochastic Neurons", "comments": "ICONIP 2013: Special Session in Deep Learning (v4)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a simple, general method of adding auxiliary stochastic\nneurons to a multi-layer perceptron is proposed. It is shown that the proposed\nmethod is a generalization of recently successful methods of dropout (Hinton et\nal., 2012), explicit noise injection (Vincent et al., 2010; Bishop, 1995) and\nsemantic hashing (Salakhutdinov & Hinton, 2009). Under the proposed framework,\nan extension of dropout which allows using separate dropping probabilities for\ndifferent hidden neurons, or layers, is found to be available. The use of\ndifferent dropping probabilities for hidden layers separately is empirically\ninvestigated.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2013 12:38:40 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2013 15:09:29 GMT"}, {"version": "v3", "created": "Mon, 22 Jul 2013 11:42:18 GMT"}, {"version": "v4", "created": "Sun, 18 Aug 2013 21:39:12 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Cho", "Kyunghyun", ""]]}, {"id": "1306.2863", "submitter": "Jun Sun", "authors": "Jun Sun, Xiaojun Wu, Vasile Palade, Wei Fang, Yuhui Shi", "title": "Random Drift Particle Swarm Optimization", "comments": "The paper is the work in progress on particle swarm optimization. It\n  has 41 pages and 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The random drift particle swarm optimization (RDPSO) algorithm, inspired by\nthe free electron model in metal conductors placed in an external electric\nfield, is presented, systematically analyzed and empirically studied in this\npaper. The free electron model considers that electrons have both a thermal and\na drift motion in a conductor that is placed in an external electric field. The\nmotivation of the RDPSO algorithm is described first, and the velocity equation\nof the particle is designed by simulating the thermal motion as well as the\ndrift motion of the electrons, both of which lead the electrons to a location\nwith minimum potential energy in the external electric field. Then, a\ncomprehensive analysis of the algorithm is made, in order to provide a deep\ninsight into how the RDPSO algorithm works. It involves a theoretical analysis\nand the simulation of the stochastic dynamical behavior of a single particle in\nthe RDPSO algorithm. The search behavior of the algorithm itself is also\ninvestigated in detail, by analyzing the interaction between the particles.\nSome variants of the RDPSO algorithm are proposed by incorporating different\nrandom velocity components with different neighborhood topologies. Finally,\nempirical studies on the RDPSO algorithm are performed by using a set of\nbenchmark functions from the CEC2005 benchmark suite. Based on the theoretical\nanalysis of the particle's behavior, two methods of controlling the algorithmic\nparameters are employed, followed by an experimental analysis on how to select\nthe parameter values, in order to obtain a good overall performance of the\nRDPSO algorithm and its variants in real-world applications. A further\nperformance comparison between the RDPSO algorithms and other variants of PSO\nis made to prove the efficiency of the RDPSO algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2013 15:34:51 GMT"}], "update_date": "2013-06-13", "authors_parsed": [["Sun", "Jun", ""], ["Wu", "Xiaojun", ""], ["Palade", "Vasile", ""], ["Fang", "Wei", ""], ["Shi", "Yuhui", ""]]}, {"id": "1306.3018", "submitter": "Vitorino Ramos Dr.", "authors": "Vitorino Ramos, David M.S. Rodrigues, Jorge Lou\\c{c}\\~a", "title": "Second Order Swarm Intelligence", "comments": "10 pages, 5 figures, accepted to International Conference on Hybrid\n  Artificial Intelligence Systems (HAIS 2013), Lecture Notes in Artificial\n  Intelligence, LNAI Springer Series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  An artificial Ant Colony System (ACS) algorithm to solve general-purpose\ncombinatorial Optimization Problems (COP) that extends previous AC models [21]\nby the inclusion of a negative pheromone, is here described. Several Travelling\nSalesman Problem (TSP) were used as benchmark. We show that by using two\ndifferent sets of pheromones, a second-order co-evolved compromise between\npositive and negative feedbacks achieves better results than single positive\nfeedback systems. The algorithm was tested against known NP-complete\ncombinatorial Optimization Problems, running on symmetrical TSP's. We show that\nthe new algorithm compares favourably against these benchmarks, accordingly to\nrecent biological findings by Robinson [26,27], and Gruter [28] where \"No\nentry\" signals and negative feedback allows a colony to quickly reallocate the\nmajority of its foragers to superior food patches. This is the first time an\nextended ACS algorithm is implemented with these successful characteristics.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2013 04:07:52 GMT"}], "update_date": "2013-06-14", "authors_parsed": [["Ramos", "Vitorino", ""], ["Rodrigues", "David M. S.", ""], ["Lou\u00e7\u00e3", "Jorge", ""]]}, {"id": "1306.3036", "submitter": "Tara Hamilton", "authors": "Saeed Afshar, Gregory Cohen, Runchun Wang, Andre van Schaik, Jonathan\n  Tapson, Torsten Lehmann, Tara Julia Hamilton", "title": "The Ripple Pond: Enabling Spiking Networks to See", "comments": "Submitted to Frontiers in Neuromorphic Engineering (June 12, 2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the biologically inspired Ripple Pond Network (RPN),\na simply connected spiking neural network that, operating together with\nrecently proposed PolyChronous Networks (PCN), enables rapid, unsupervised,\nscale and rotation invariant object recognition using efficient spatio-temporal\nspike coding. The RPN has been developed as a hardware solution linking\npreviously implemented neuromorphic vision and memory structures capable of\ndelivering end-to-end high-speed, low-power and low-resolution recognition for\nmobile and autonomous applications where slow, highly sophisticated and power\nhungry signal processing solutions are ineffective. Key aspects in the proposed\napproach include utilising the spatial properties of physically embedded neural\nnetworks and propagating waves of activity therein for information processing,\nusing dimensional collapse of imagery information into amenable temporal\npatterns and the use of asynchronous frames for information binding.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2013 06:49:35 GMT"}], "update_date": "2013-06-14", "authors_parsed": [["Afshar", "Saeed", ""], ["Cohen", "Gregory", ""], ["Wang", "Runchun", ""], ["van Schaik", "Andre", ""], ["Tapson", "Jonathan", ""], ["Lehmann", "Torsten", ""], ["Hamilton", "Tara Julia", ""]]}, {"id": "1306.4592", "submitter": "Tirtharaj Dash", "authors": "Tirtharaj Dash", "title": "Time Efficient Approach To Offline Hand Written Character Recognition\n  Using Associative Memory Net", "comments": null, "journal-ref": "International Journal of Computing and Business Research (IJCBR)\n  ISSN (Online) : 2229-6166; Volume 3, Issue 3; September 2012", "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an efficient Offline Hand Written Character Recognition\nalgorithm is proposed based on Associative Memory Net (AMN). The AMN used in\nthis work is basically auto associative. The implementation is carried out\ncompletely in 'C' language. To make the system perform to its best with minimal\ncomputation time, a Parallel algorithm is also developed using an API package\nOpenMP. Characters are mainly English alphabets (Small (26), Capital (26))\ncollected from system (52) and from different persons (52). The characters\ncollected from system are used to train the AMN and characters collected from\ndifferent persons are used for testing the recognition ability of the net. The\ndetailed analysis showed that the network recognizes the hand written\ncharacters with recognition rate of 72.20% in average case. However, in best\ncase, it recognizes the collected hand written characters with 88.5%. The\ndeveloped network consumes 3.57 sec (average) in Serial implementation and 1.16\nsec (average) in Parallel implementation using OpenMP.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 16:01:29 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Dash", "Tirtharaj", ""]]}, {"id": "1306.4621", "submitter": "Tirtharaj Dash", "authors": "Tirtharaj Dash, Tanistha Nayak", "title": "English Character Recognition using Artificial Neural Network", "comments": "appeared in Proceedings of National Conference on Artificial\n  Intelligence, Robotics and Embedded Systems (AIRES-2012), Andhra University,\n  Vishakhapatnam, India (29-30 June, 2012), pp. 7-9", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work focuses on development of a Offline Hand Written English Character\nRecognition algorithm based on Artificial Neural Network (ANN). The ANN\nimplemented in this work has single output neuron which shows whether the\ntested character belongs to a particular cluster or not. The implementation is\ncarried out completely in 'C' language. Ten sets of English alphabets\n(small-26, capital-26) were used to train the ANN and 5 sets of English\nalphabets were used to test the network. The characters were collected from\ndifferent persons over duration of about 25 days. The algorithm was tested with\n5 capital letters and 5 small letter sets. However, the result showed that the\nalgorithm recognized English alphabet patterns with maximum accuracy of 92.59%\nand False Rejection Rate (FRR) of 0%.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 17:26:26 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Dash", "Tirtharaj", ""], ["Nayak", "Tanistha", ""]]}, {"id": "1306.4622", "submitter": "Tirtharaj Dash", "authors": "Tanistha Nayak, Tirtharaj Dash", "title": "Solution to Quadratic Equation Using Genetic Algorithm", "comments": "appeared in: Conf. Proceedings of National Conference on Artificial\n  Intelligence, Robotics and Embedded Systems (AIRES-2012), Andhra University,\n  Vishakhapatnam, India (29-30 June, 2012), pp. 10-13", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving Quadratic equation is one of the intrinsic interests as it is the\nsimplest nonlinear equations. A novel approach for solving Quadratic Equation\nbased on Genetic Algorithms (GAs) is presented. Genetic Algorithms (GAs) are a\ntechnique to solve problems which need optimization. Generation of trial\nsolutions have been formed by this method. Many examples have been worked out,\nand in most cases we find out the exact solution. We have discussed the effect\nof different parameters on the performance of the developed algorithm. The\nresults are concluded after rigorous testing on different equations.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 17:31:47 GMT"}], "update_date": "2013-06-20", "authors_parsed": [["Nayak", "Tanistha", ""], ["Dash", "Tirtharaj", ""]]}, {"id": "1306.4629", "submitter": "Tirtharaj Dash", "authors": "Tirtharaj Dash and Tanistha Nayak", "title": "Non-Correlated Character Recognition using Artificial Neural Network", "comments": "appeared in: proceedings of National Conference on Dynamics and\n  Prospects of Data Mining: Theory and Practices (DPDM)-2012; September 30,\n  2012, India; Publisher: OITS-BLS, Balasore Chapter; Proceeding ISBN:\n  987-93-81361-31-6, pp. 79-83", "journal-ref": "proc. National Conference on Dynamics and Prospects of Data\n  Mining: Theory and Practices (DPDM)-2012; September 30, 2012, India; ISBN:\n  987-93-81361-31-6, pp. 79-83", "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a method of Handwritten English Character Recognition\nusing Artificial Neural Network (ANN). This work has been done in offline\nEnvironment for non correlated characters, which do not possess any linear\nrelationships among them. We test that whether the particular tested character\nbelongs to a cluster or not. The implementation is carried out in Matlab\nenvironment and successfully tested. Fifty-two sets of English alphabets are\nused to train the ANN and test the network. The algorithms are tested with 26\ncapital letters and 26 small letters. The testing result showed that the\nproposed ANN based algorithm showed a maximum recognition rate of 85%.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2013 17:57:00 GMT"}], "update_date": "2013-06-24", "authors_parsed": [["Dash", "Tirtharaj", ""], ["Nayak", "Tanistha", ""]]}, {"id": "1306.4793", "submitter": "Larry Bull", "authors": "Larry Bull", "title": "Evolving Boolean Regulatory Networks with Epigenetic Control", "comments": "18 pages, 10 figures. arXiv admin note: substantial text overlap with\n  arXiv:1303.7220", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The significant role of epigenetic mechanisms within natural systems has\nbecome increasingly clear. This paper uses a recently presented abstract,\ntunable Boolean genetic regulatory network model to explore aspects of\nepigenetics. It is shown how dynamically controlling transcription via a DNA\nmethylation-inspired mechanism can be selected for by simulated evolution under\nvarious single and multiple cell scenarios. Further, it is shown that the\neffects of such control can be inherited without detriment to fitness.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2013 09:00:40 GMT"}], "update_date": "2013-06-21", "authors_parsed": [["Bull", "Larry", ""]]}, {"id": "1306.5070", "submitter": "Mina Farmanbar Ms", "authors": "Nasser Lotfi, Jamshid Tamouk, Mina Farmanbar", "title": "3-SAT Problem A New Memetic-PSO Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3-SAT problem is of great importance to many technical and scientific\napplications. This paper presents a new hybrid evolutionary algorithm for\nsolving this satisfiability problem. 3-SAT problem has the huge search space\nand hence it is known as a NP-hard problem. So, deterministic approaches are\nnot applicable in this context. Thereof, application of evolutionary processing\napproaches and especially PSO will be very effective for solving these kinds of\nproblems. In this paper, we introduce a new evolutionary optimization technique\nbased on PSO, Memetic algorithm and local search approaches. When some\nheuristics are mixed, their advantages are collected as well and we can reach\nto the better outcomes. Finally, we test our proposed algorithm over some\nbenchmarks used by some another available algorithms. Obtained results show\nthat our new method leads to the suitable results by the appropriate time.\nThereby, it achieves a better result in compared with the existent approaches\nsuch as pure genetic algorithm and some verified types\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2013 08:10:44 GMT"}], "update_date": "2013-06-24", "authors_parsed": [["Lotfi", "Nasser", ""], ["Tamouk", "Jamshid", ""], ["Farmanbar", "Mina", ""]]}, {"id": "1306.5667", "submitter": "W B Langdon", "authors": "W. B. Langdon and M. Harman", "title": "Using Genetic Programming to Model Software", "comments": "As UCL computer science Technical Report RN/13/12", "journal-ref": null, "doi": null, "report-no": "RN/13/12", "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a generic program to investigate the scope for automatically\ncustomising it for a vital current task, which was not considered when it was\nfirst written. In detail, we show genetic programming (GP) can evolve models of\naspects of BLAST's output when it is used to map Solexa Next-Gen DNA sequences\nto the human genome.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 16:35:37 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Langdon", "W. B.", ""], ["Harman", "M.", ""]]}, {"id": "1306.5702", "submitter": "Vijay Manikandan Janakiraman", "authors": "Vijay Manikandan Janakiraman, XuanLong Nguyen, Jeff Sterniak, and\n  Dennis Assanis", "title": "Modeling The Stable Operating Envelope For Partially Stable Combustion\n  Engines Using Class Imbalance Learning", "comments": "In a Journal review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced combustion technologies such as homogeneous charge compression\nignition (HCCI) engines have a narrow stable operating region defined by\ncomplex control strategies such as exhaust gas recirculation (EGR) and variable\nvalve timing among others. For such systems, it is important to identify the\noperating envelope or the boundary of stable operation for diagnostics and\ncontrol purposes. Obtaining a good model of the operating envelope using\nphysics becomes intractable owing to engine transient effects. In this paper, a\nmachine learning based approach is employed to identify the stable operating\nboundary of HCCI combustion directly from experimental data. Owing to imbalance\nin class proportions in the data, two approaches are considered. A re-sampling\n(under-sampling, over-sampling) based approach is used to develop models using\nexisting algorithms while a cost-sensitive approach is used to modify the\nlearning algorithm without modifying the data set. Support vector machines and\nrecently developed extreme learning machines are used for model development and\nresults compared against linear classification methods show that cost-sensitive\nversions of ELM and SVM algorithms are well suited to model the HCCI operating\nenvelope. The prediction results indicate that the models have the potential to\nbe used for predicting HCCI instability based on sensor measurement history.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2013 18:34:28 GMT"}], "update_date": "2013-06-25", "authors_parsed": [["Janakiraman", "Vijay Manikandan", ""], ["Nguyen", "XuanLong", ""], ["Sterniak", "Jeff", ""], ["Assanis", "Dennis", ""]]}, {"id": "1306.5998", "submitter": "Alireza Goudarzi", "authors": "Alireza Goudarzi, Matthew R. Lakin, Darko Stefanovic", "title": "DNA Reservoir Computing: A Novel Molecular Computing Approach", "comments": "14 pages, 7 figure", "journal-ref": "D. Soloveichik and B. Yurke (Eds.): DNA 2013, LNCS 8141, pp.\n  76--89", "doi": null, "report-no": null, "categories": "cs.NE cs.ET nlin.AO nlin.CD physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel molecular computing approach based on reservoir computing.\nIn reservoir computing, a dynamical core, called a reservoir, is perturbed with\nan external input signal while a readout layer maps the reservoir dynamics to a\ntarget output. Computation takes place as a transformation from the input space\nto a high-dimensional spatiotemporal feature space created by the transient\ndynamics of the reservoir. The readout layer then combines these features to\nproduce the target output. We show that coupled deoxyribozyme oscillators can\nact as the reservoir. We show that despite using only three coupled\noscillators, a molecular reservoir computer could achieve 90% accuracy on a\nbenchmark temporal problem.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2013 15:21:55 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Goudarzi", "Alireza", ""], ["Lakin", "Matthew R.", ""], ["Stefanovic", "Darko", ""]]}, {"id": "1306.6041", "submitter": "Alireza Goudarzi", "authors": "Alireza Goudarzi, Christof Teuscher, Natali Gulbahce, Thimo Rohlf", "title": "Learning, Generalization, and Functional Entropy in Random Automata\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn nlin.AO nlin.CD physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown \\citep{broeck90:physicalreview,patarnello87:europhys} that\nfeedforward Boolean networks can learn to perform specific simple tasks and\ngeneralize well if only a subset of the learning examples is provided for\nlearning. Here, we extend this body of work and show experimentally that random\nBoolean networks (RBNs), where both the interconnections and the Boolean\ntransfer functions are chosen at random initially, can be evolved by using a\nstate-topology evolution to solve simple tasks. We measure the learning and\ngeneralization performance, investigate the influence of the average node\nconnectivity $K$, the system size $N$, and introduce a new measure that allows\nto better describe the network's learning and generalization behavior. We show\nthat the connectivity of the maximum entropy networks scales as a power-law of\nthe system size $N$. Our results show that networks with higher average\nconnectivity $K$ (supercritical) achieve higher memorization and partial\ngeneralization. However, near critical connectivity, the networks show a higher\nperfect generalization on the even-odd task.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2013 17:28:53 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Goudarzi", "Alireza", ""], ["Teuscher", "Christof", ""], ["Gulbahce", "Natali", ""], ["Rohlf", "Thimo", ""]]}]