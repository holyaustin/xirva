[{"id": "1106.0118", "submitter": "Juan Juli\\'an Merelo-Guerv\\'os Pr.", "authors": "Juan-J. Merelo, Maribel Garc\\'ia-Arenas, Juan-Luis J. Laredo,\n  Francisco Fern\\'andez de la Vega (editors)", "title": "1st International Workshop on Distributed Evolutionary Computation in\n  Informal Environments", "comments": "Five papers, workshop took place together with CEC 2011 in New\n  Orleans (LA, USA). http://geneura.ugr.es/~iwdecie", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.ET cs.NI", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Online conference proceedings for the IWDECIE workshop, taking place in New\nOrleans on June 5th, 2011. The workshop focuses on non-conventional\nimplementations of bioinspired algorithms and its conceptual implications.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2011 08:29:28 GMT"}, {"version": "v2", "created": "Thu, 2 Jun 2011 08:23:54 GMT"}], "update_date": "2011-06-03", "authors_parsed": [["Merelo", "Juan-J.", "", "editors"], ["Garc\u00eda-Arenas", "Maribel", "", "editors"], ["Laredo", "Juan-Luis J.", "", "editors"], ["de la Vega", "Francisco Fern\u00e1ndez", "", "editors"]]}, {"id": "1106.0190", "submitter": "A.E.  Eiben", "authors": "A.E. Eiben and N. Ferreira and M. Schut and S. Kernbach", "title": "Evolution of Things", "comments": "Paper 5 for the First International Workshop of Distributed\n  Evolutionary computation in Informal Environments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution is one of the major omnipresent powers in the universe that has\nbeen studied for about two centuries. Recent scientific and technical\ndevelopments make it possible to make the transition from passively\nunderstanding to actively mastering evolution. As of today, the only area where\nhuman experimenters can design and manipulate evolutionary processes in full is\nthat of Evolutionary Computing, where evolutionary processes are carried out in\na digital space, inside computers, in simulation. We argue that in the near\nfuture it will be possible to move evolutionary computing outside such\nimaginary spaces and make it physically embodied. In other words, we envision\nthe \"Evolution of Things\", rather than just the evolution of code, leading to a\nnew field of Embodied Artificial Evolution (EAE). The main objective of the\npresent paper is to offer an umbrella term and vision in order to aid the\ndevelopment of this high potential research area. To this end, we introduce the\nnotion of EAE, discuss a few examples and applications, and elaborate on the\nexpected benefits as well as the grand challenges this developing field will\nhave to address.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2011 14:32:58 GMT"}], "update_date": "2011-06-02", "authors_parsed": [["Eiben", "A. E.", ""], ["Ferreira", "N.", ""], ["Schut", "M.", ""], ["Kernbach", "S.", ""]]}, {"id": "1106.0221", "submitter": "J. J. Grefenstette", "authors": "J. J. Grefenstette, D. E. Moriarty, A. C. Schultz", "title": "Evolutionary Algorithms for Reinforcement Learning", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 11, pages\n  241-276, 1999", "doi": "10.1613/jair.613", "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two distinct approaches to solving reinforcement learning problems,\nnamely, searching in value function space and searching in policy space.\nTemporal difference methods and evolutionary algorithms are well-known examples\nof these approaches. Kaelbling, Littman and Moore recently provided an\ninformative survey of temporal difference methods. This article focuses on the\napplication of evolutionary algorithms to the reinforcement learning problem,\nemphasizing alternative policy representations, credit assignment methods, and\nproblem-specific genetic operators. Strengths and weaknesses of the\nevolutionary approach to reinforcement learning are presented, along with a\nsurvey of representative applications.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2011 16:16:14 GMT"}], "update_date": "2011-06-02", "authors_parsed": [["Grefenstette", "J. J.", ""], ["Moriarty", "D. E.", ""], ["Schultz", "A. C.", ""]]}, {"id": "1106.1194", "submitter": "Angelos Anastassi", "authors": "Angelos A. Anastassi", "title": "Constructing Runge-Kutta Methods with the Use of Artificial Neural\n  Networks", "comments": "The final publication is available at link.springer.com", "journal-ref": null, "doi": "10.1007/2Fs00521-013-1476-x", "report-no": null, "categories": "cs.NE math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A methodology that can generate the optimal coefficients of a numerical\nmethod with the use of an artificial neural network is presented in this work.\nThe network can be designed to produce a finite difference algorithm that\nsolves a specific system of ordinary differential equations numerically. The\ncase we are examining here concerns an explicit two-stage Runge-Kutta method\nfor the numerical solution of the two-body problem. Following the\nimplementation of the network, the latter is trained to obtain the optimal\nvalues for the coefficients of the Runge-Kutta method. The comparison of the\nnew method to others that are well known in the literature proves its\nefficiency and demonstrates the capability of the network to provide efficient\nalgorithms for specific problems.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 20:37:55 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2013 15:08:32 GMT"}], "update_date": "2013-09-20", "authors_parsed": [["Anastassi", "Angelos A.", ""]]}, {"id": "1106.1570", "submitter": "Ismaail ElSawy", "authors": "Ismaail ElSawy, Hossam Hosny and Mohammed Abdel Razek", "title": "A Neural Network Model for Construction Projects Site Overhead Cost\n  Estimating in Egypt", "comments": "11 pages,IJCSI", "journal-ref": "International Journal of Computer Science Issues, Vol. 8, Issue 3,\n  May 2011, 273-283", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating of the overhead costs of building construction projects is an\nimportant task in the management of these projects. The quality of construction\nmanagement depends heavily on their accurate cost estimation. Construction\ncosts prediction is a very difficult and sophisticated task especially when\nusing manual calculation methods. This paper uses Artificial Neural Network\n(ANN) approach to develop a parametric cost-estimating model for site overhead\ncost in Egypt. Fifty-two actual real-life cases of building projects\nconstructed in Egypt during the seven year period 2002-2009 were used as\ntraining materials. The neural network architecture is presented for the\nestimation of the site overhead costs as a percentage from the total project\nprice.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2011 14:29:41 GMT"}], "update_date": "2011-06-09", "authors_parsed": [["ElSawy", "Ismaail", ""], ["Hosny", "Hossam", ""], ["Razek", "Mohammed Abdel", ""]]}, {"id": "1106.1975", "submitter": "Khaled Masmoudi Mr.", "authors": "Khaled Masmoudi and Marc Antonini and Pierre Kornprobst", "title": "Exact Reconstruction of the Rank Order Coding using Frames Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal is to revisit rank order coding by proposing an original exact\ndecoding procedure for it. Rank order coding was proposed by Simon Thorpe et\nal. who stated that the retina represents the visual stimulus by the order in\nwhich its cells are activated. A classical rank order coder/decoder was then\ndesigned on this basis [1]. Though, it appeared that the decoding procedure\nemployed yields reconstruction errors that limit the model Rate/Quality\nperformances when used as an image codec. The attempts made in the literature\nto overcome this issue are time consuming and alter the coding procedure, or\nare lacking mathematical support and feasibility for standard size images. Here\nwe solve this problem in an original fashion by using the frames theory, where\na frame of a vector space designates an extension for the notion of basis.\nFirst, we prove that the analyzing filter bank considered is a frame, and then\nwe define the corresponding dual frame that is necessary for the exact image\nreconstruction. Second, to deal with the problem of memory overhead, we design\na recursive out-of-core blockwise algorithm for the computation of this dual\nframe. Our work provides a mathematical formalism for the retinal model under\nstudy and defines a simple and exact reverse transform for it with up to 270 dB\nof PSNR gain compared to [1]. Furthermore, the framework presented here can be\nextended to several models of the visual cortical areas using redundant\nrepresentations.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2011 08:26:16 GMT"}, {"version": "v2", "created": "Fri, 1 Jul 2011 14:18:34 GMT"}], "update_date": "2011-07-04", "authors_parsed": [["Masmoudi", "Khaled", ""], ["Antonini", "Marc", ""], ["Kornprobst", "Pierre", ""]]}, {"id": "1106.2113", "submitter": "Jierui Xie", "authors": "Caixing Liu, Jierui Xie, Yueming Hu", "title": "Using Hopfield to Solve Resource-Leveling Problem", "comments": null, "journal-ref": "Proceedings of the 11th joint international computer\n  conference(JICC), November ,2005, pp:564-567", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the traditional permute matrix coming along with Hopfield is able to\ndescribe many common problems, it seems to have limitation in solving more\ncomplicated problem with more constrains, like resource leveling which is\nactually a NP problem. This paper tries to find a better solution for it by\nusing neural network. In order to give the neural network description of\nresource leveling problem, a new description method called Augmented permute\nmatrix is proposed by expending the ability of the traditional one. An Embedded\nHybrid Model combining Hopfield model and SA are put forward to improve the\noptimization in essence in which Hopfield servers as State Generator for the\nSA. The experiment results show that Augmented permute matrix is able to\ncompletely and appropriately describe the application. The energy function and\nhybrid model given in this study are also highly efficient in solving resource\nleveling problem.\n", "versions": [{"version": "v1", "created": "Sat, 28 May 2011 00:55:18 GMT"}], "update_date": "2011-06-13", "authors_parsed": [["Liu", "Caixing", ""], ["Xie", "Jierui", ""], ["Hu", "Yueming", ""]]}, {"id": "1106.2156", "submitter": "Axel Wismueller", "authors": "Axel Wism\\\"uller", "title": "A Computational Framework for Nonlinear Dimensionality Reduction of\n  Large Data Sets: The Exploratory Inspection Machine (XIM)", "comments": "20 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel computational framework for nonlinear\ndimensionality reduction which is specifically suited to process large data\nsets: the Exploratory Inspection Machine (XIM). XIM introduces a conceptual\ncross-link between hitherto separate domains of machine learning, namely\ntopographic vector quantization and divergence-based neighbor embedding\napproaches. There are three ways to conceptualize XIM, namely (i) as the\ninversion of the Exploratory Observation Machine (XOM) and its variants, such\nas Neighbor Embedding XOM (NE-XOM), (ii) as a powerful optimization scheme for\ndivergence-based neighbor embedding cost functions inspired by Stochastic\nNeighbor Embedding (SNE) and its variants, such as t-distributed SNE (t-SNE),\nand (iii) as an extension of topographic vector quantization methods, such as\nthe Self-Organizing Map (SOM). By preserving both global and local data\nstructure, XIM combines the virtues of classical and advanced recent embedding\nmethods. It permits direct visualization of large data collections without the\nneed for prior data reduction. Finally, XIM can contribute to many application\ndomains of data analysis and visualization important throughout the sciences\nand engineering, such as pattern matching, constrained incremental learning,\ndata clustering, and the analysis of non-metric dissimilarity data.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2011 19:48:01 GMT"}], "update_date": "2011-06-13", "authors_parsed": [["Wism\u00fcller", "Axel", ""]]}, {"id": "1106.2312", "submitter": "Rathipriya R", "authors": "R.Rathipriya, Dr. K.Thangavel and J.Bagyamani", "title": "Evolutionary Biclustering of Clickstream Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biclustering is a two way clustering approach involving simultaneous\nclustering along two dimensions of the data matrix. Finding biclusters of web\nobjects (i.e. web users and web pages) is an emerging topic in the context of\nweb usage mining. It overcomes the problem associated with traditional\nclustering methods by allowing automatic discovery of browsing pattern based on\na subset of attributes. A coherent bicluster of clickstream data is a local\nbrowsing pattern such that users in bicluster exhibit correlated browsing\npattern through a subset of pages of a web site. This paper proposed a new\napplication of biclustering to web data using a combination of heuristics and\nmeta-heuristics such as K-means, Greedy Search Procedure and Genetic Algorithms\nto identify the coherent browsing pattern. Experiment is conducted on the\nbenchmark clickstream msnbc dataset from UCI repository. Results demonstrate\nthe efficiency and beneficial outcome of the proposed method by correlating the\nusers and pages of a web site in high degree.This approach shows excellent\nperformance at finding high degree of overlapped coherent biclusters from web\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jun 2011 14:34:16 GMT"}], "update_date": "2011-06-14", "authors_parsed": [["Rathipriya", "R.", ""], ["Thangavel", "Dr. K.", ""], ["Bagyamani", "J.", ""]]}, {"id": "1106.3834", "submitter": "Suyong Choi", "authors": "Suyong Choi (Korea University)", "title": "Dimensionally Constrained Symbolic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.NE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe dimensionally constrained symbolic regression which has been\ndeveloped for mass measurement in certain classes of events in high-energy\nphysics (HEP). With symbolic regression, we can derive equations that are well\nknown in HEP. However, in problems with large number of variables, we find that\nby constraining the terms allowed in the symbolic regression, convergence\nbehavior is improved. Dimensionally constrained symbolic regression (DCSR)\nfinds solutions with much better fitness than is normally possible with\nsymbolic regression. In some cases, novel solutions are found.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2011 08:04:08 GMT"}], "update_date": "2011-06-21", "authors_parsed": [["Choi", "Suyong", "", "Korea University"]]}, {"id": "1106.4487", "submitter": "Tom Schaul", "authors": "Daan Wierstra, Tom Schaul, Tobias Glasmachers, Yi Sun and J\\\"urgen\n  Schmidhuber", "title": "Natural Evolution Strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Natural Evolution Strategies (NES), a recent family of\nalgorithms that constitute a more principled approach to black-box optimization\nthan established evolutionary algorithms. NES maintains a parameterized\ndistribution on the set of solution candidates, and the natural gradient is\nused to update the distribution's parameters in the direction of higher\nexpected fitness. We introduce a collection of techniques that address issues\nof convergence, robustness, sample complexity, computational complexity and\nsensitivity to hyperparameters. This paper explores a number of implementations\nof the NES family, ranging from general-purpose multi-variate normal\ndistributions to heavy-tailed and separable distributions tailored towards\nglobal optimization and search in high dimensional spaces, respectively.\nExperimental results show best published performance on various standard\nbenchmarks, as well as competitive performance on others.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2011 15:55:52 GMT"}], "update_date": "2011-06-23", "authors_parsed": [["Wierstra", "Daan", ""], ["Schaul", "Tom", ""], ["Glasmachers", "Tobias", ""], ["Sun", "Yi", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1106.4509", "submitter": "Amos Storkey", "authors": "Amos Storkey", "title": "Machine Learning Markets", "comments": "Proceedings of the Fourteenth International Conference on Artificial\n  Intelligence and Statistics 2011", "journal-ref": "Journal of Machine Learning Research W&CP 15(AISTATS):716-724,\n  2011", "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.NE q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction markets show considerable promise for developing flexible\nmechanisms for machine learning. Here, machine learning markets for\nmultivariate systems are defined, and a utility-based framework is established\nfor their analysis. This differs from the usual approach of defining static\nbetting functions. It is shown that such markets can implement model\ncombination methods used in machine learning, such as product of expert and\nmixture of expert approaches as equilibrium pricing models, by varying agent\nutility functions. They can also implement models composed of local potentials,\nand message passing methods. Prediction markets also allow for more flexible\ncombinations, by combining multiple different utility functions. Conversely,\nthe market mechanisms implement inference in the relevant probabilistic models.\nThis means that market mechanism can be utilized for implementing parallelized\nmodel building and inference for probabilistic modelling.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2011 17:12:42 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Storkey", "Amos", ""]]}, {"id": "1106.5917", "submitter": "Jitesh Dundas", "authors": "Jitesh Dundas and David Chik", "title": "Implementing Human-like Intuition Mechanism in Artificial Intelligence", "comments": "14 pages with 1 figure + 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human intuition has been simulated by several research projects using\nartificial intelligence techniques. Most of these algorithms or models lack the\nability to handle complications or diversions. Moreover, they also do not\nexplain the factors influencing intuition and the accuracy of the results from\nthis process. In this paper, we present a simple series based model for\nimplementation of human-like intuition using the principles of connectivity and\nunknown entities. By using Poker hand datasets and Car evaluation datasets, we\ncompare the performance of some well-known models with our intuition model. The\naim of the experiment was to predict the maximum accurate answers using\nintuition based models. We found that the presence of unknown entities,\ndiversion from the current problem scenario, and identifying weakness without\nthe normal logic based execution, greatly affects the reliability of the\nanswers. Generally, the intuition based models cannot be a substitute for the\nlogic based mechanisms in handling such problems. The intuition can only act as\na support for an ongoing logic based model that processes all the steps in a\nsequential manner. However, when time and computational cost are very strict\nconstraints, this intuition based model becomes extremely important and useful,\nbecause it can give a reasonably good performance. Factors affecting intuition\nare analyzed and interpreted through our model.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2011 12:03:33 GMT"}], "update_date": "2011-06-30", "authors_parsed": [["Dundas", "Jitesh", ""], ["Chik", "David", ""]]}, {"id": "1106.6185", "submitter": "Mark Rowan", "authors": "Mark Rowan", "title": "Effects of Compensation, Connectivity and Tau in a Computational Model\n  of Alzheimer's Disease", "comments": "8 pages, submitted to International Joint Conference on Neural\n  Networks 2011", "journal-ref": "The 2011 International Joint Conference on Neural Networks\n  (IJCNN), (2011) 543--550", "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work updates an existing, simplistic computational model of Alzheimer's\nDisease (AD) to investigate the behaviour of synaptic compensatory mechanisms\nin neural networks with small-world connectivity, and varying methods of\ncalculating compensation. It additionally introduces a method for simulating\ntau neurofibrillary pathology, resulting in a more dramatic damage profile.\nSmall-world connectivity is shown to have contrasting effects on capacity,\nretrieval time, and robustness to damage, whilst the use of more\neasily-obtained remote memories rather than recent memories for synaptic\ncompensation is found to lead to rapid network damage.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2011 11:08:05 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Rowan", "Mark", ""]]}, {"id": "1106.6223", "submitter": "Melvin Gauci", "authors": "Melvin Gauci, Tony J. Dodd and Roderich Gross", "title": "Why 'GSA: A Gravitational Search Algorithm' Is Not Genuinely Based on\n  the Law of Gravity", "comments": null, "journal-ref": null, "doi": "10.1007/s11047-012-9322-0", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Why 'GSA: A Gravitational Search Algorithm' Is Not Genuinely Based on the Law\nof Gravity\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2011 13:38:35 GMT"}], "update_date": "2016-03-17", "authors_parsed": [["Gauci", "Melvin", ""], ["Dodd", "Tony J.", ""], ["Gross", "Roderich", ""]]}]