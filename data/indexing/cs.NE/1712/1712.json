[{"id": "1712.00519", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr", "title": "An Elementary Analysis of the Probability That a Binomial Random\n  Variable Exceeds Its Expectation", "comments": "v2: Minor change in the presentation of previous works (took into\n  account the new version of Pel[16]). v3: Minor change in the presentation of\n  previous works (the proof of Lemma 6.4 in [RT11] gives a significantly\n  stronger result than what is stated in the Lemma itself). v4: Minor changes\n  (typos, mentioned the work of Slud)", "journal-ref": "Statistics and Probability Letters, 139:67-74, 2018", "doi": "10.1016/j.spl.2018.03.016", "report-no": null, "categories": "math.PR cs.DS cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an elementary proof of the fact that a binomial random variable $X$\nwith parameters $n$ and $0.29/n \\le p < 1$ with probability at least $1/4$\nstrictly exceeds its expectation. We also show that for $1/n \\le p < 1 - 1/n$,\n$X$ exceeds its expectation by more than one with probability at least\n$0.0370$. Both probabilities approach $1/2$ when $np$ and $n(1-p)$ tend to\ninfinity.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 23:24:52 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 12:22:42 GMT"}, {"version": "v3", "created": "Thu, 21 Dec 2017 15:39:10 GMT"}, {"version": "v4", "created": "Thu, 4 Jan 2018 12:49:19 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Doerr", "Benjamin", ""]]}, {"id": "1712.00557", "submitter": "Aaron Tuor", "authors": "Aaron Tuor, Ryan Baerwolf, Nicolas Knowles, Brian Hutchinson, Nicole\n  Nichols, Rob Jasper", "title": "Recurrent Neural Network Language Models for Open Vocabulary Event-Level\n  Cyber Anomaly Detection", "comments": "8 pages, To appear in proceedings of AAAI-2018 Artificial\n  Intelligence in Cyber Security Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated analysis methods are crucial aids for monitoring and defending a\nnetwork to protect the sensitive or confidential data it hosts. This work\nintroduces a flexible, powerful, and unsupervised approach to detecting\nanomalous behavior in computer and network logs, one that largely eliminates\ndomain-dependent feature engineering employed by existing methods. By treating\nsystem logs as threads of interleaved \"sentences\" (event log lines) to train\nonline unsupervised neural network language models, our approach provides an\nadaptive model of normal network behavior. We compare the effectiveness of both\nstandard and bidirectional recurrent neural network language models at\ndetecting malicious activity within network log data. Extending these models,\nwe introduce a tiered recurrent architecture, which provides context by\nmodeling sequences of users' actions over time. Compared to Isolation Forest\nand Principal Components Analysis, two popular anomaly detection algorithms, we\nobserve superior performance on the Los Alamos National Laboratory Cyber\nSecurity dataset. For log-line-level red team detection, our best performing\ncharacter-based model provides test set area under the receiver operator\ncharacteristic curve of 0.98, demonstrating the strong fine-grained anomaly\ndetection performance of this approach on open vocabulary logging sources.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 06:08:35 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Tuor", "Aaron", ""], ["Baerwolf", "Ryan", ""], ["Knowles", "Nicolas", ""], ["Hutchinson", "Brian", ""], ["Nichols", "Nicole", ""], ["Jasper", "Rob", ""]]}, {"id": "1712.00712", "submitter": "Wellington Pinheiro dos Santos", "authors": "Wellington Pinheiro dos Santos, Ricardo Emmanuel de Souza, Pl\\'inio B.\n  dos Santos Filho", "title": "Evaluation of Alzheimer's Disease by Analysis of MR Images using\n  Multilayer Perceptrons and Kohonen SOM Classifiers as an Alternative to the\n  ADC Maps", "comments": "29th Annual Conference of the IEEE Engineering in Medicine and\n  Biology Society - EMBC 2007", "journal-ref": null, "doi": "10.1109/IEMBS.2007.4352740", "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's disease is the most common cause of dementia, yet hard to\ndiagnose precisely without invasive techniques, particularly at the onset of\nthe disease. This work approaches image analysis and classification of\nsynthetic multispectral images composed by diffusion-weighted magnetic\nresonance (MR) cerebral images for the evaluation of cerebrospinal fluid area\nand measuring the advance of Alzheimer's disease. A clinical 1.5 T MR imaging\nsystem was used to acquire all images presented. The classification methods are\nbased on multilayer perceptrons and Kohonen Self-Organized Map classifiers. We\nassume the classes of interest can be separated by hyperquadrics. Therefore, a\n2-degree polynomial network is used to classify the original image, generating\nthe ground truth image. The classification results are used to improve the\nusual analysis of the apparent diffusion coefficient map.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 05:54:40 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Santos", "Wellington Pinheiro dos", ""], ["de Souza", "Ricardo Emmanuel", ""], ["Filho", "Pl\u00ednio B. dos Santos", ""]]}, {"id": "1712.00754", "submitter": "Juan-Pablo Ortega", "authors": "Lyudmila Grigoryeva and Juan-Pablo Ortega", "title": "Universal discrete-time reservoir computers with stochastic inputs and\n  linear readouts using non-homogeneous state-affine systems", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new class of non-homogeneous state-affine systems is introduced for use in\nreservoir computing. Sufficient conditions are identified that guarantee first,\nthat the associated reservoir computers with linear readouts are causal,\ntime-invariant, and satisfy the fading memory property and second, that a\nsubset of this class is universal in the category of fading memory filters with\nstochastic almost surely uniformly bounded inputs. This means that any\ndiscrete-time filter that satisfies the fading memory property with random\ninputs of that type can be uniformly approximated by elements in the\nnon-homogeneous state-affine family.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 11:32:17 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 09:04:50 GMT"}, {"version": "v3", "created": "Sun, 26 Aug 2018 17:18:09 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Grigoryeva", "Lyudmila", ""], ["Ortega", "Juan-Pablo", ""]]}, {"id": "1712.00789", "submitter": "Wellington Pinheiro dos Santos", "authors": "Valter Augusto de Freitas Barbosa, Reiga Ramalho Ribeiro, Allan\n  Rivalles Souza Feitosa, Victor Luiz Bezerra Ara\\'ujo da Silva, Arthur Diego\n  Dias Rocha, Rafaela Covello de Freitas, Ricardo Emmanuel de Souza, Wellington\n  Pinheiro dos Santos", "title": "Reconstruction of Electrical Impedance Tomography Using Fish School\n  Search, Non-Blind Search, and Genetic Algorithm", "comments": null, "journal-ref": "International Journal of Swarm Intelligence Research, Volume 8,\n  Issue 2, 2017", "doi": "10.4018/IJSIR.2017040102", "report-no": null, "categories": "physics.med-ph cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrical Impedance Tomography (EIT) is a noninvasive imaging technique that\ndoes not use ionizing radiation, with application both in environmental\nsciences and in health. Image reconstruction is performed by solving an inverse\nproblem and ill-posed. Evolutionary Computation and Swarm Intelligence have\nbecome a source of methods for solving inverse problems. Fish School Search\n(FSS) is a promising search and optimization method, based on the dynamics of\nschools of fish. In this article the authors present a method for\nreconstruction of EIT images based on FSS and Non-Blind Search (NBS). The\nmethod was evaluated using numerical phantoms consisting of electrical\nconductivity images with subjects in the center, between the center and the\nedge and on the edge of a circular section, with meshes of 415 finite elements.\nThe authors performed 20 simulations for each configuration. Results showed\nthat both FSS and FSS-NBS were able to converge faster than genetic algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 16:14:03 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Barbosa", "Valter Augusto de Freitas", ""], ["Ribeiro", "Reiga Ramalho", ""], ["Feitosa", "Allan Rivalles Souza", ""], ["da Silva", "Victor Luiz Bezerra Ara\u00fajo", ""], ["Rocha", "Arthur Diego Dias", ""], ["de Freitas", "Rafaela Covello", ""], ["de Souza", "Ricardo Emmanuel", ""], ["Santos", "Wellington Pinheiro dos", ""]]}, {"id": "1712.00948", "submitter": "Andrew Levy", "authors": "Andrew Levy, George Konidaris, Robert Platt, Kate Saenko", "title": "Learning Multi-Level Hierarchies with Hindsight", "comments": "ICLR 2019 Accepted Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical agents have the potential to solve sequential decision making\ntasks with greater sample efficiency than their non-hierarchical counterparts\nbecause hierarchical agents can break down tasks into sets of subtasks that\nonly require short sequences of decisions. In order to realize this potential\nof faster learning, hierarchical agents need to be able to learn their multiple\nlevels of policies in parallel so these simpler subproblems can be solved\nsimultaneously. Yet, learning multiple levels of policies in parallel is hard\nbecause it is inherently unstable: changes in a policy at one level of the\nhierarchy may cause changes in the transition and reward functions at higher\nlevels in the hierarchy, making it difficult to jointly learn multiple levels\nof policies. In this paper, we introduce a new Hierarchical Reinforcement\nLearning (HRL) framework, Hierarchical Actor-Critic (HAC), that can overcome\nthe instability issues that arise when agents try to jointly learn multiple\nlevels of policies. The main idea behind HAC is to train each level of the\nhierarchy independently of the lower levels by training each level as if the\nlower level policies are already optimal. We demonstrate experimentally in both\ngrid world and simulated robotics domains that our approach can significantly\naccelerate learning relative to other non-hierarchical and hierarchical\nmethods. Indeed, our framework is the first to successfully learn 3-level\nhierarchies in parallel in tasks with continuous state and action spaces.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 08:18:08 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 16:01:40 GMT"}, {"version": "v3", "created": "Wed, 28 Feb 2018 17:45:42 GMT"}, {"version": "v4", "created": "Fri, 1 Mar 2019 18:21:33 GMT"}, {"version": "v5", "created": "Tue, 3 Sep 2019 21:05:21 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Levy", "Andrew", ""], ["Konidaris", "George", ""], ["Platt", "Robert", ""], ["Saenko", "Kate", ""]]}, {"id": "1712.00964", "submitter": "Johannes Lengler", "authors": "Johannes Lengler", "title": "Drift Analysis", "comments": "This article will become a chapter in a book on Theory of\n  Evolutionary Algorithms that will be published by Springer, edited by\n  Benjamin Doerr and Frank Neumann", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drift analysis is one of the major tools for analysing evolutionary\nalgorithms and nature-inspired search heuristics. In this chapter we give an\nintroduction to drift analysis and give some examples of how to use it for the\nanalysis of evolutionary algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 09:13:16 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 07:13:08 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Lengler", "Johannes", ""]]}, {"id": "1712.00994", "submitter": "Francesco Conti", "authors": "Paolo Meloni, Alessandro Capotondi, Gianfranco Deriu, Michele Brian,\n  Francesco Conti, Davide Rossi, Luigi Raffo, Luca Benini", "title": "NEURAghe: Exploiting CPU-FPGA Synergies for Efficient and Flexible CNN\n  Inference Acceleration on Zynq SoCs", "comments": "22 pages, 14 figures, submitted to ACM Transactions on Reconfigurable\n  Technology and Systems", "journal-ref": "ACM Transactions on Reconfigurable Technology and Systems, Vol. 11\n  No. 3 (2018), Article 18", "doi": "10.1145/3284357", "report-no": null, "categories": "cs.NE cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) obtain outstanding results in tasks\nthat require human-level understanding of data, like image or speech\nrecognition. However, their computational load is significant, motivating the\ndevelopment of CNN-specialized accelerators. This work presents NEURAghe, a\nflexible and efficient hardware/software solution for the acceleration of CNNs\non Zynq SoCs. NEURAghe leverages the synergistic usage of Zynq ARM cores and of\na powerful and flexible Convolution-Specific Processor deployed on the\nreconfigurable logic. The Convolution-Specific Processor embeds both a\nconvolution engine and a programmable soft core, releasing the ARM processors\nfrom most of the supervision duties and allowing the accelerator to be\ncontrolled by software at an ultra-fine granularity. This methodology opens the\nway for cooperative heterogeneous computing: while the accelerator takes care\nof the bulk of the CNN workload, the ARM cores can seamlessly execute\nhard-to-accelerate parts of the computational graph, taking advantage of the\nNEON vector engines to further speed up computation. Through the companion\nNeuDNN SW stack, NEURAghe supports end-to-end CNN-based classification with a\npeak performance of 169 Gops/s, and an energy efficiency of 17 Gops/W. Thanks\nto our heterogeneous computing model, our platform improves upon the\nstate-of-the-art, achieving a frame rate of 5.5 fps on the end-to-end execution\nof VGG-16, and 6.6 fps on ResNet-18.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 10:41:53 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Meloni", "Paolo", ""], ["Capotondi", "Alessandro", ""], ["Deriu", "Gianfranco", ""], ["Brian", "Michele", ""], ["Conti", "Francesco", ""], ["Rossi", "Davide", ""], ["Raffo", "Luigi", ""], ["Benini", "Luca", ""]]}, {"id": "1712.01076", "submitter": "Yann Ollivier", "authors": "Ga\\'etan Marceau-Caron and Yann Ollivier", "title": "Natural Langevin Dynamics for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One way to avoid overfitting in machine learning is to use model parameters\ndistributed according to a Bayesian posterior given the data, rather than the\nmaximum likelihood estimator. Stochastic gradient Langevin dynamics (SGLD) is\none algorithm to approximate such Bayesian posteriors for large models and\ndatasets. SGLD is a standard stochastic gradient descent to which is added a\ncontrolled amount of noise, specifically scaled so that the parameter converges\nin law to the posterior distribution [WT11, TTV16]. The posterior predictive\ndistribution can be approximated by an ensemble of samples from the trajectory.\n  Choice of the variance of the noise is known to impact the practical behavior\nof SGLD: for instance, noise should be smaller for sensitive parameter\ndirections. Theoretically, it has been suggested to use the inverse Fisher\ninformation matrix of the model as the variance of the noise, since it is also\nthe variance of the Bayesian posterior [PT13, AKW12, GC11]. But the Fisher\nmatrix is costly to compute for large- dimensional models.\n  Here we use the easily computed Fisher matrix approximations for deep neural\nnetworks from [MO16, Oll15]. The resulting natural Langevin dynamics combines\nthe advantages of Amari's natural gradient descent and Fisher-preconditioned\nLangevin dynamics for large neural networks.\n  Small-scale experiments on MNIST show that Fisher matrix preconditioning\nbrings SGLD close to dropout as a regularizing technique.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 13:54:45 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Marceau-Caron", "Ga\u00e9tan", ""], ["Ollivier", "Yann", ""]]}, {"id": "1712.01208", "submitter": "Tim Kraska", "authors": "Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, Neoklis Polyzotis", "title": "The Case for Learned Index Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Indexes are models: a B-Tree-Index can be seen as a model to map a key to the\nposition of a record within a sorted array, a Hash-Index as a model to map a\nkey to a position of a record within an unsorted array, and a BitMap-Index as a\nmodel to indicate if a data record exists or not. In this exploratory research\npaper, we start from this premise and posit that all existing index structures\ncan be replaced with other types of models, including deep-learning models,\nwhich we term learned indexes. The key idea is that a model can learn the sort\norder or structure of lookup keys and use this signal to effectively predict\nthe position or existence of records. We theoretically analyze under which\nconditions learned indexes outperform traditional index structures and describe\nthe main challenges in designing learned index structures. Our initial results\nshow, that by using neural nets we are able to outperform cache-optimized\nB-Trees by up to 70% in speed while saving an order-of-magnitude in memory over\nseveral real-world data sets. More importantly though, we believe that the idea\nof replacing core components of a data management system through learned models\nhas far reaching implications for future systems designs and that this work\njust provides a glimpse of what might be possible.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 17:18:41 GMT"}, {"version": "v2", "created": "Mon, 11 Dec 2017 19:42:46 GMT"}, {"version": "v3", "created": "Mon, 30 Apr 2018 07:54:41 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Kraska", "Tim", ""], ["Beutel", "Alex", ""], ["Chi", "Ed H.", ""], ["Dean", "Jeffrey", ""], ["Polyzotis", "Neoklis", ""]]}, {"id": "1712.01507", "submitter": "Hardik Sharma", "authors": "Hardik Sharma, Jongse Park, Naveen Suda, Liangzhen Lai, Benson Chau,\n  Joon Kyung Kim, Vikas Chandra, Hadi Esmaeilzadeh", "title": "Bit Fusion: Bit-Level Dynamically Composable Architecture for\n  Accelerating Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully realizing the potential of acceleration for Deep Neural Networks (DNNs)\nrequires understanding and leveraging algorithmic properties. This paper builds\nupon the algorithmic insight that bitwidth of operations in DNNs can be reduced\nwithout compromising their classification accuracy. However, to prevent\naccuracy loss, the bitwidth varies significantly across DNNs and it may even be\nadjusted for each layer. Thus, a fixed-bitwidth accelerator would either offer\nlimited benefits to accommodate the worst-case bitwidth requirements, or lead\nto a degradation in final accuracy. To alleviate these deficiencies, this work\nintroduces dynamic bit-level fusion/decomposition as a new dimension in the\ndesign of DNN accelerators. We explore this dimension by designing Bit Fusion,\na bit-flexible accelerator, that constitutes an array of bit-level processing\nelements that dynamically fuse to match the bitwidth of individual DNN layers.\nThis flexibility in the architecture enables minimizing the computation and the\ncommunication at the finest granularity possible with no loss in accuracy. We\nevaluate the benefits of BitFusion using eight real-world feed-forward and\nrecurrent DNNs. The proposed microarchitecture is implemented in Verilog and\nsynthesized in 45 nm technology. Using the synthesis results and cycle accurate\nsimulation, we compare the benefits of Bit Fusion to two state-of-the-art DNN\naccelerators, Eyeriss and Stripes. In the same area, frequency, and process\ntechnology, BitFusion offers 3.9x speedup and 5.1x energy savings over Eyeriss.\nCompared to Stripes, BitFusion provides 2.6x speedup and 3.9x energy reduction\nat 45 nm node when BitFusion area and frequency are set to those of Stripes.\nScaling to GPU technology node of 16 nm, BitFusion almost matches the\nperformance of a 250-Watt Titan Xp, which uses 8-bit vector instructions, while\nBitFusion merely consumes 895 milliwatts of power.\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 07:20:33 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 14:56:34 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Sharma", "Hardik", ""], ["Park", "Jongse", ""], ["Suda", "Naveen", ""], ["Lai", "Liangzhen", ""], ["Chau", "Benson", ""], ["Kim", "Joon Kyung", ""], ["Chandra", "Vikas", ""], ["Esmaeilzadeh", "Hadi", ""]]}, {"id": "1712.01626", "submitter": "Pierre-Yves Oudeyer", "authors": "Pierre-Yves Oudeyer (Flowers)", "title": "Autonomous development and learning in artificial intelligence and\n  robotics: Scaling up deep learning to human--like learning", "comments": null, "journal-ref": "Behavioral and Brain Sciences, Cambridge University Press (CUP),\n  2017, 40", "doi": "10.1017/S0140525X17000243", "report-no": null, "categories": "cs.AI cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous lifelong development and learning is a fundamental capability of\nhumans, differentiating them from current deep learning systems. However, other\nbranches of artificial intelligence have designed crucial ingredients towards\nautonomous learning: curiosity and intrinsic motivation, social learning and\nnatural interaction with peers, and embodiment. These mechanisms guide\nexploration and autonomous choice of goals, and integrating them with deep\nlearning opens stimulating perspectives. Deep learning (DL) approaches made\ngreat advances in artificial intelligence, but are still far away from human\nlearning. As argued convincingly by Lake et al., differences include human\ncapabilities to learn causal models of the world from very little data,\nleveraging compositional representations and priors like intuitive physics and\npsychology. However, there are other fundamental differences between current DL\nsystems and human learning, as well as technical ingredients to fill this gap,\nthat are either superficially, or not adequately, discussed by Lake et al.\nThese fundamental mechanisms relate to autonomous development and learning.\nThey are bound to play a central role in artificial intelligence in the future.\nCurrent DL systems require engineers to manually specify a task-specific\nobjective function for every new task, and learn through off-line processing of\nlarge training databases. On the contrary, humans learn autonomously open-ended\nrepertoires of skills, deciding for themselves which goals to pursue or value,\nand which skills to explore, driven by intrinsic motivation/curiosity and\nsocial learning through natural interaction with peers. Such learning processes\nare incremental, online, and progressive. Human child development involves a\nprogressive increase of complexity in a curriculum of learning where skills are\nexplored, acquired, and built on each other, through particular ordering and\ntiming. Finally, human learning happens in the physical world, and through\nbodily and physical experimentation, under severe constraints on energy, time,\nand computational resources. In the two last decades, the field of\nDevelopmental and Cognitive Robotics (Cangelosi and Schlesinger, 2015, Asada et\nal., 2009), in strong interaction with developmental psychology and\nneuroscience, has achieved significant advances in computational\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 14:03:56 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Oudeyer", "Pierre-Yves", "", "Flowers"]]}, {"id": "1712.01636", "submitter": "Hojjat Salehinejad", "authors": "Hojjat Salehinejad, Shahrokh Valaee, Tim Dowdell, Errol Colak, Joseph\n  Barfett", "title": "Generalization of Deep Neural Networks for Chest Pathology\n  Classification in X-Rays Using Generative Adversarial Networks", "comments": "This paper is accepted for presentation at IEEE International\n  Conference on Acoustics, Speech and Signal Processing (IEEE ICASSP), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical datasets are often highly imbalanced with over-representation of\ncommon medical problems and a paucity of data from rare conditions. We propose\nsimulation of pathology in images to overcome the above limitations. Using\nchest X-rays as a model medical image, we implement a generative adversarial\nnetwork (GAN) to create artificial images based upon a modest sized labeled\ndataset. We employ a combination of real and artificial images to train a deep\nconvolutional neural network (DCNN) to detect pathology across five classes of\nchest X-rays. Furthermore, we demonstrate that augmenting the original\nimbalanced dataset with GAN generated images improves performance of chest\npathology classification using the proposed DCNN in comparison to the same DCNN\ntrained with the original dataset alone. This improved performance is largely\nattributed to balancing of the dataset using GAN generated images, where image\nclasses that are lacking in example images are preferentially augmented.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 14:26:01 GMT"}, {"version": "v2", "created": "Mon, 12 Feb 2018 18:25:28 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Salehinejad", "Hojjat", ""], ["Valaee", "Shahrokh", ""], ["Dowdell", "Tim", ""], ["Colak", "Errol", ""], ["Barfett", "Joseph", ""]]}, {"id": "1712.01682", "submitter": "Marcel Ausloos", "authors": "Maciej J. Mrowinski, Piotr Fronczak, Agata Fronczak, Marcel Ausloos,\n  and Olgica Nedic", "title": "Artificial intelligence in peer review: How can evolutionary computation\n  support journal editors?", "comments": "17 pages, 5 figures, 18 references, supplementary material\n  (algorithms and 2 data tables) in Appendix", "journal-ref": "PONE 0184711 (2017)", "doi": "10.1371/journal.pone.0184711", "report-no": null, "categories": "cs.DL cs.NE physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the volume of manuscripts submitted for publication growing every year,\nthe deficiencies of peer review (e.g. long review times) are becoming more\napparent. Editorial strategies, sets of guidelines designed to speed up the\nprocess and reduce editors workloads, are treated as trade secrets by\npublishing houses and are not shared publicly. To improve the effectiveness of\ntheir strategies, editors in small publishing groups are faced with undertaking\nan iterative trial-and-error approach. We show that Cartesian Genetic\nProgramming, a nature-inspired evolutionary algorithm, can dramatically improve\neditorial strategies. The artificially evolved strategy reduced the duration of\nthe peer review process by 30%, without increasing the pool of reviewers (in\ncomparison to a typical human-developed strategy). Evolutionary computation has\ntypically been used in technological processes or biological ecosystems. Our\nresults demonstrate that genetic programs can improve real-world social systems\nthat are usually much harder to understand and control than physical systems.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 14:52:20 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Mrowinski", "Maciej J.", ""], ["Fronczak", "Piotr", ""], ["Fronczak", "Agata", ""], ["Ausloos", "Marcel", ""], ["Nedic", "Olgica", ""]]}, {"id": "1712.01694", "submitter": "Wellington Pinheiro dos Santos", "authors": "Wellington Pinheiro dos Santos, Francisco Marcos de Assis, Ricardo\n  Emmanuel de Souza, Priscilla B. Mendes, Henrique S. S. Monteiro, Havana Diogo\n  Alves", "title": "Fuzzy-Based Dialectical Non-Supervised Image Classification and\n  Clustering", "comments": null, "journal-ref": "International Journal of Hybrid Intelligent Systems, v. 7, p.\n  115-124, 2010", "doi": "10.3233/HIS-2010-0108", "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The materialist dialectical method is a philosophical investigative method to\nanalyze aspects of reality. These aspects are viewed as complex processes\ncomposed by basic units named poles, which interact with each other. Dialectics\nhas experienced considerable progress in the 19th century, with Hegel's\ndialectics and, in the 20th century, with the works of Marx, Engels, and\nGramsci, in Philosophy and Economics. The movement of poles through their\ncontradictions is viewed as a dynamic process with intertwined phases of\nevolution and revolutionary crisis. In order to build a computational process\nbased on dialectics, the interaction between poles can be modeled using fuzzy\nmembership functions. Based on this assumption, we introduce the Objective\nDialectical Classifier (ODC), a non-supervised map for classification based on\nmaterialist dialectics and designed as an extension of fuzzy c-means\nclassifier. As a case study, we used ODC to classify 181 magnetic resonance\nsynthetic multispectral images composed by proton density, $T_1$- and\n$T_2$-weighted synthetic brain images. Comparing ODC to k-means, fuzzy c-means,\nand Kohonen's self-organized maps, concerning with image fidelity indexes as\nestimatives of quantization distortion, we proved that ODC can reach almost the\nsame quantization performance as optimal non-supervised classifiers like\nKohonen's self-organized maps.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 17:56:15 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Santos", "Wellington Pinheiro dos", ""], ["de Assis", "Francisco Marcos", ""], ["de Souza", "Ricardo Emmanuel", ""], ["Mendes", "Priscilla B.", ""], ["Monteiro", "Henrique S. S.", ""], ["Alves", "Havana Diogo", ""]]}, {"id": "1712.01695", "submitter": "Wellington Pinheiro dos Santos", "authors": "Higor Neto Lima, Wellington Pinheiro dos Santos, M\\^euser Jorge Silva\n  Valen\\c{c}a", "title": "Triagem virtual de imagens de imuno-histoqu\\'imica usando redes neurais\n  artificiais e espectro de padr\\~oes", "comments": "in Portuguese", "journal-ref": "Learning and Nonlinear Models, v. 8, p. 202-215, 2010", "doi": null, "report-no": null, "categories": "cs.CV cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of organizing medical images according to their nature,\napplication and relevance is increasing. Furhermore, a previous selection of\nmedical images can be useful to accelerate the task of analysis by\npathologists. Herein this work we propose an image classifier to integrate a\nCBIR (Content-Based Image Retrieval) selection system. This classifier is based\non pattern spectra and neural networks. Feature selection is performed using\npattern spectra and principal component analysis, whilst image classification\nis based on multilayer perceptrons and a composition of self-organizing maps\nand learning vector quantization. These methods were applied for content\nselection of immunohistochemical images of placenta and newdeads lungs. Results\ndemonstrated that this approach can reach reasonable classification\nperformance.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 18:06:22 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Lima", "Higor Neto", ""], ["Santos", "Wellington Pinheiro dos", ""], ["Valen\u00e7a", "M\u00eauser Jorge Silva", ""]]}, {"id": "1712.01697", "submitter": "Wellington Pinheiro dos Santos", "authors": "Wellington Pinheiro dos Santos, Francisco Marcos de Assis, Ricardo\n  Emmanuel de Souza, Pl\\'inio Batista dos Santos Filho, Fernando Buarque de\n  Lima Neto", "title": "Dialectical Multispectral Classification of Diffusion-Weighted Magnetic\n  Resonance Images as an Alternative to Apparent Diffusion Coefficients Maps to\n  Perform Anatomical Analysis", "comments": null, "journal-ref": "Computerized Medical Imaging and Graphics, v. 33, p. 442-460, 2009", "doi": "10.1016/j.compmedimag.2009.04.004", "report-no": null, "categories": "cs.CV cs.GR cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multispectral image analysis is a relatively promising field of research with\napplications in several areas, such as medical imaging and satellite\nmonitoring. A considerable number of current methods of analysis are based on\nparametric statistics. Alternatively, some methods in Computational\nIntelligence are inspired by biology and other sciences. Here we claim that\nPhilosophy can be also considered as a source of inspiration. This work\nproposes the Objective Dialectical Method (ODM): a method for classification\nbased on the Philosophy of Praxis. ODM is instrumental in assembling evolvable\nmathematical tools to analyze multispectral images. In the case study described\nin this paper, multispectral images are composed of diffusion-weighted (DW)\nmagnetic resonance (MR) images. The results are compared to ground-truth images\nproduced by polynomial networks using a morphological similarity index. The\nclassification results are used to improve the usual analysis of the apparent\ndiffusion coefficient map. Such results proved that gray and white matter can\nbe distinguished in DW-MR multispectral analysis and, consequently, DW-MR\nimages can also be used to furnish anatomical information.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 18:23:33 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Santos", "Wellington Pinheiro dos", ""], ["de Assis", "Francisco Marcos", ""], ["de Souza", "Ricardo Emmanuel", ""], ["Filho", "Pl\u00ednio Batista dos Santos", ""], ["Neto", "Fernando Buarque de Lima", ""]]}, {"id": "1712.01743", "submitter": "Lukas Cavigelli", "authors": "Manuele Rusci, Lukas Cavigelli, Luca Benini", "title": "Design Automation for Binarized Neural Networks: A Quantum Leap\n  Opportunity?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OH cs.AR cs.CV cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design automation in general, and in particular logic synthesis, can play a\nkey role in enabling the design of application-specific Binarized Neural\nNetworks (BNN). This paper presents the hardware design and synthesis of a\npurely combinational BNN for ultra-low power near-sensor processing. We\nleverage the major opportunities raised by BNN models, which consist mostly of\nlogical bit-wise operations and integer counting and comparisons, for pushing\nultra-low power deep learning circuits close to the sensor and coupling it with\nbinarized mixed-signal image sensor data. We analyze area, power and energy\nmetrics of BNNs synthesized as combinational networks. Our synthesis results in\nGlobalFoundries 22nm SOI technology shows a silicon area of 2.61mm2 for\nimplementing a combinational BNN with 32x32 binary input sensor receptive field\nand weight parameters fixed at design time. This is 2.2x smaller than a\nsynthesized network with re-configurable parameters. With respect to other\ncomparable techniques for deep learning near-sensor processing, our approach\nfeatures a 10x higher energy efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 09:54:37 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Rusci", "Manuele", ""], ["Cavigelli", "Lukas", ""], ["Benini", "Luca", ""]]}, {"id": "1712.01977", "submitter": "Nand Sharma", "authors": "Nand Sharma", "title": "Single-trial P300 Classification using PCA with LDA, QDA and Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The P300 event-related potential (ERP), evoked in scalp-recorded\nelectroencephalography (EEG) by external stimuli, has proven to be a reliable\nresponse for controlling a BCI. The P300 component of an event related\npotential is thus widely used in brain-computer interfaces to translate the\nsubjects' intent by mere thoughts into commands to control artificial devices.\nThe main challenge in the classification of P300 trials in\nelectroencephalographic (EEG) data is the low signal-to-noise ratio (SNR) of\nthe P300 response. To overcome the low SNR of individual trials, it is common\npractice to average together many consecutive trials, which effectively\ndiminishes the random noise. Unfortunately, when more repeated trials are\nrequired for applications such as the P300 speller, the communication rate is\ngreatly reduced. This has resulted in a need for better methods to improve\nsingle-trial classification accuracy of P300 response. In this work, we use\nPrincipal Component Analysis (PCA) as a preprocessing method and use Linear\nDiscriminant Analysis (LDA)and neural networks for classification. The results\nshow that a combination of PCA with these methods provided as high as 13\\%\naccuracy gain for single-trial classification while using only 3 to 4 principal\ncomponents.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 00:21:07 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Sharma", "Nand", ""]]}, {"id": "1712.01990", "submitter": "Kyeong Soo (Joseph) Kim", "authors": "Kyeong Soo Kim, Sanghyuk Lee, Kaizhu Huang", "title": "A Scalable Deep Neural Network Architecture for Multi-Building and\n  Multi-Floor Indoor Localization Based on Wi-Fi Fingerprinting", "comments": "9 pages, 6 figures", "journal-ref": "Big Data Analytics, vol. 3, no. 4, pp. 1-17, Apr. 19, 2018", "doi": "10.1186/s41044-018-0031-2", "report-no": null, "categories": "cs.NI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the key technologies for future large-scale location-aware services\ncovering a complex of multi-story buildings --- e.g., a big shopping mall and a\nuniversity campus --- is a scalable indoor localization technique. In this\npaper, we report the current status of our investigation on the use of deep\nneural networks (DNNs) for scalable building/floor classification and\nfloor-level position estimation based on Wi-Fi fingerprinting. Exploiting the\nhierarchical nature of the building/floor estimation and floor-level\ncoordinates estimation of a location, we propose a new DNN architecture\nconsisting of a stacked autoencoder for the reduction of feature space\ndimension and a feed-forward classifier for multi-label classification of\nbuilding/floor/location, on which the multi-building and multi-floor indoor\nlocalization system based on Wi-Fi fingerprinting is built. Experimental\nresults for the performance of building/floor estimation and floor-level\ncoordinates estimation of a given location demonstrate the feasibility of the\nproposed DNN-based indoor localization system, which can provide near\nstate-of-the-art performance using a single DNN, for the implementation with\nlower complexity and energy consumption at mobile devices.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 01:06:01 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Kim", "Kyeong Soo", ""], ["Lee", "Sanghyuk", ""], ["Huang", "Kaizhu", ""]]}, {"id": "1712.02316", "submitter": "Mahdi Namazifar", "authors": "Mahdi Namazifar", "title": "Named Entity Sequence Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named Entity Recognition (NER) aims at locating and classifying named\nentities in text. In some use cases of NER, including cases where detected\nnamed entities are used in creating content recommendations, it is crucial to\nhave a reliable confidence level for the detected named entities. In this work\nwe study the problem of finding confidence levels for detected named entities.\nWe refer to this problem as Named Entity Sequence Classification (NESC). We\nframe NESC as a binary classification problem and we use NER as well as\nrecurrent neural networks to find the probability of candidate named entity is\na real named entity. We apply this approach to Tweet texts and we show how we\ncould find named entities with high confidence levels from Tweets.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 18:33:55 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Namazifar", "Mahdi", ""]]}, {"id": "1712.02328", "submitter": "Omid Poursaeed", "authors": "Omid Poursaeed, Isay Katsman, Bicheng Gao, Serge Belongie", "title": "Generative Adversarial Perturbations", "comments": "CVPR 2018, camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose novel generative models for creating adversarial\nexamples, slightly perturbed images resembling natural images but maliciously\ncrafted to fool pre-trained models. We present trainable deep neural networks\nfor transforming images to adversarial perturbations. Our proposed models can\nproduce image-agnostic and image-dependent perturbations for both targeted and\nnon-targeted attacks. We also demonstrate that similar architectures can\nachieve impressive results in fooling classification and semantic segmentation\nmodels, obviating the need for hand-crafting attack methods for each task.\nUsing extensive experiments on challenging high-resolution datasets such as\nImageNet and Cityscapes, we show that our perturbations achieve high fooling\nrates with small perturbation norms. Moreover, our attacks are considerably\nfaster than current iterative methods at inference time.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 18:52:12 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 01:18:08 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2018 06:50:03 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Poursaeed", "Omid", ""], ["Katsman", "Isay", ""], ["Gao", "Bicheng", ""], ["Belongie", "Serge", ""]]}, {"id": "1712.02501", "submitter": "Chen Huang", "authors": "Chen Huang, Chen Kong, and Simon Lucey", "title": "CNNs are Globally Optimal Given Multi-Layer Support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) is the central workhorse for training\nmodern CNNs. Although giving impressive empirical performance it can be slow to\nconverge. In this paper we explore a novel strategy for training a CNN using an\nalternation strategy that offers substantial speedups during training. We make\nthe following contributions: (i) replace the ReLU non-linearity within a CNN\nwith positive hard-thresholding, (ii) reinterpret this non-linearity as a\nbinary state vector making the entire CNN linear if the multi-layer support is\nknown, and (iii) demonstrate that under certain conditions a global optima to\nthe CNN can be found through local descent. We then employ a novel alternation\nstrategy (between weights and support) for CNN training that leads to\nsubstantially faster convergence rates, nice theoretical properties, and\nachieving state of the art results across large scale datasets (e.g. ImageNet)\nas well as other standard benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 06:06:52 GMT"}, {"version": "v2", "created": "Thu, 14 Dec 2017 14:21:43 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Huang", "Chen", ""], ["Kong", "Chen", ""], ["Lucey", "Simon", ""]]}, {"id": "1712.02779", "submitter": "Dimitris Tsipras", "authors": "Logan Engstrom, Brandon Tran, Dimitris Tsipras, Ludwig Schmidt,\n  Aleksander Madry", "title": "Exploring the Landscape of Spatial Robustness", "comments": "ICML 2019. Presented in NIPS 2017 Workshop on Machine Learning and\n  Computer Security as \"A Rotation and a Translation Suffice: Fooling CNNs with\n  Simple Transformations.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of adversarial robustness has so far largely focused on\nperturbations bound in p-norms. However, state-of-the-art models turn out to be\nalso vulnerable to other, more natural classes of perturbations such as\ntranslations and rotations. In this work, we thoroughly investigate the\nvulnerability of neural network--based classifiers to rotations and\ntranslations. While data augmentation offers relatively small robustness, we\nuse ideas from robust optimization and test-time input aggregation to\nsignificantly improve robustness. Finally we find that, in contrast to the\np-norm case, first-order methods cannot reliably find worst-case perturbations.\nThis highlights spatial robustness as a fundamentally different setting\nrequiring additional study. Code available at\nhttps://github.com/MadryLab/adversarial_spatial and\nhttps://github.com/MadryLab/spatial-pytorch.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 18:53:52 GMT"}, {"version": "v2", "created": "Mon, 11 Dec 2017 12:00:50 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 18:33:22 GMT"}, {"version": "v4", "created": "Mon, 16 Sep 2019 04:38:13 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Engstrom", "Logan", ""], ["Tran", "Brandon", ""], ["Tsipras", "Dimitris", ""], ["Schmidt", "Ludwig", ""], ["Madry", "Aleksander", ""]]}, {"id": "1712.02781", "submitter": "Kian Ahrabian", "authors": "Kian Ahrabian, Bagher Babaali", "title": "On Usage of Autoencoders and Siamese Networks for Online Handwritten\n  Signature Verification", "comments": "13 pages, 10 figures, Submitted to Neural Computing and Applications\n  journal", "journal-ref": null, "doi": "10.1007/s00521-018-3844-z", "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel writer-independent global feature\nextraction framework for the task of automatic signature verification which\naims to make robust systems for automatically distinguishing negative and\npositive samples. Our method consists of an autoencoder for modeling the sample\nspace into a fixed length latent space and a Siamese Network for classifying\nthe fixed-length samples obtained from the autoencoder based on the reference\nsamples of a subject as being \"Genuine\" or \"Forged.\" During our experiments,\nusage of Attention Mechanism and applying Downsampling significantly improved\nthe accuracy of the proposed framework. We evaluated our proposed framework\nusing SigWiComp2013 Japanese and GPDSsyntheticOnLineOffLineSignature datasets.\nOn the SigWiComp2013 Japanese dataset, we achieved 8.65% EER that means 1.2%\nrelative improvement compared to the best-reported result. Furthermore, on the\nGPDSsyntheticOnLineOffLineSignature dataset, we achieved average EERs of 0.13%,\n0.12%, 0.21% and 0.25% respectively for 150, 300, 1000 and 2000 test subjects\nwhich indicates improvement of relative EER on the best-reported result by\n95.67%, 95.26%, 92.9% and 91.52% respectively. Apart from the accuracy gain,\nbecause of the nature of our proposed framework which is based on neural\nnetworks and consequently is as simple as some consecutive matrix\nmultiplications, it has less computational cost than conventional methods such\nas DTW and could be used concurrently on devices such as GPU, TPU, etc.\n", "versions": [{"version": "v1", "created": "Thu, 7 Dec 2017 18:55:42 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 07:12:41 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Ahrabian", "Kian", ""], ["Babaali", "Bagher", ""]]}, {"id": "1712.03133", "submitter": "Kartik Audhkhasi", "authors": "Kartik Audhkhasi, Brian Kingsbury, Bhuvana Ramabhadran, George Saon,\n  Michael Picheny", "title": "Building competitive direct acoustics-to-word models for English\n  conversational speech recognition", "comments": "Submitted to IEEE International Conference on Acoustics, Speech and\n  Signal Processing (ICASSP), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct acoustics-to-word (A2W) models in the end-to-end paradigm have\nreceived increasing attention compared to conventional sub-word based automatic\nspeech recognition models using phones, characters, or context-dependent hidden\nMarkov model states. This is because A2W models recognize words from speech\nwithout any decoder, pronunciation lexicon, or externally-trained language\nmodel, making training and decoding with such models simple. Prior work has\nshown that A2W models require orders of magnitude more training data in order\nto perform comparably to conventional models. Our work also showed this\naccuracy gap when using the English Switchboard-Fisher data set. This paper\ndescribes a recipe to train an A2W model that closes this gap and is at-par\nwith state-of-the-art sub-word based models. We achieve a word error rate of\n8.8%/13.9% on the Hub5-2000 Switchboard/CallHome test sets without any decoder\nor language model. We find that model initialization, training data order, and\nregularization have the most impact on the A2W model performance. Next, we\npresent a joint word-character A2W model that learns to first spell the word\nand then recognize it. This model provides a rich output to the user instead of\nsimple word hypotheses, making it especially useful in the case of words unseen\nor rarely-seen during training.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 15:43:21 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Audhkhasi", "Kartik", ""], ["Kingsbury", "Brian", ""], ["Ramabhadran", "Bhuvana", ""], ["Saon", "George", ""], ["Picheny", "Michael", ""]]}, {"id": "1712.03166", "submitter": "Wei Chen", "authors": "Wei Chen and YingYing Cao and Shi Cheng and Yifei Sun and Qunfeng Liu\n  and Yun Li", "title": "Simplex Search Based Brain Storm Optimization", "comments": "25pages,6figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Through modeling human's brainstorming process, the brain storm optimization\n(BSO) algorithm has become a promising population-based evolutionary algorithm.\nHowever, BSO is pointed out that it possesses a degenerated L-curve phenomenon,\ni.e., it often gets near optimum quickly but needs much more cost to improve\nthe accuracy. To overcome this question in this paper, an excellent direct\nsearch based local solver, the Nelder-Mead Simplex (NMS) method is adopted in\nBSO. Through combining BSO's exploration ability and NMS's exploitation ability\ntogether, a simplex search based BSO (Simplex-BSO) is developed via a better\nbalance between global exploration and local exploitation. Simplex-BSO is shown\nto be able to eliminate the degenerated L-curve phenomenon on unimodal\nfunctions, and alleviate significantly this phenomenon on multimodal functions.\nLarge number of experimental results show that Simplex-BSO is a promising\nalgorithm for global optimization problems.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 01:07:42 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 02:25:40 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 07:42:15 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Chen", "Wei", ""], ["Cao", "YingYing", ""], ["Cheng", "Shi", ""], ["Sun", "Yifei", ""], ["Liu", "Qunfeng", ""], ["Li", "Yun", ""]]}, {"id": "1712.03351", "submitter": "Boyang Deng", "authors": "Boyang Deng, Junjie Yan, Dahua Lin", "title": "Peephole: Predicting Network Performance Before Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quest for performant networks has been a significant force that drives\nthe advancements of deep learning in recent years. While rewarding, improving\nnetwork design has never been an easy journey. The large design space combined\nwith the tremendous cost required for network training poses a major obstacle\nto this endeavor. In this work, we propose a new approach to this problem,\nnamely, predicting the performance of a network before training, based on its\narchitecture. Specifically, we develop a unified way to encode individual\nlayers into vectors and bring them together to form an integrated description\nvia LSTM. Taking advantage of the recurrent network's strong expressive power,\nthis method can reliably predict the performances of various network\narchitectures. Our empirical studies showed that it not only achieved accurate\npredictions but also produced consistent rankings across datasets -- a key\ndesideratum in performance prediction.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 07:50:27 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Deng", "Boyang", ""], ["Yan", "Junjie", ""], ["Lin", "Dahua", ""]]}, {"id": "1712.03541", "submitter": "Abien Fred Agarap", "authors": "Abien Fred Agarap", "title": "An Architecture Combining Convolutional Neural Network (CNN) and Support\n  Vector Machine (SVM) for Image Classification", "comments": "4 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional neural networks (CNNs) are similar to \"ordinary\" neural\nnetworks in the sense that they are made up of hidden layers consisting of\nneurons with \"learnable\" parameters. These neurons receive inputs, performs a\ndot product, and then follows it with a non-linearity. The whole network\nexpresses the mapping between raw image pixels and their class scores.\nConventionally, the Softmax function is the classifier used at the last layer\nof this network. However, there have been studies (Alalshekmubarak and Smith,\n2013; Agarap, 2017; Tang, 2013) conducted to challenge this norm. The cited\nstudies introduce the usage of linear support vector machine (SVM) in an\nartificial neural network architecture. This project is yet another take on the\nsubject, and is inspired by (Tang, 2013). Empirical data has shown that the\nCNN-SVM model was able to achieve a test accuracy of ~99.04% using the MNIST\ndataset (LeCun, Cortes, and Burges, 2010). On the other hand, the CNN-Softmax\nwas able to achieve a test accuracy of ~99.23% using the same dataset. Both\nmodels were also tested on the recently-published Fashion-MNIST dataset (Xiao,\nRasul, and Vollgraf, 2017), which is suppose to be a more difficult image\nclassification dataset than MNIST (Zalandoresearch, 2017). This proved to be\nthe case as CNN-SVM reached a test accuracy of ~90.72%, while the CNN-Softmax\nreached a test accuracy of ~91.86%. The said results may be improved if data\npreprocessing techniques were employed on the datasets, and if the base CNN\nmodel was a relatively more sophisticated than the one used in this study.\n", "versions": [{"version": "v1", "created": "Sun, 10 Dec 2017 14:50:28 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 06:25:08 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Agarap", "Abien Fred", ""]]}, {"id": "1712.04118", "submitter": "Haitao Zhao", "authors": "Haitao Zhao", "title": "Neural Component Analysis for Fault Detection", "comments": "10 pages,11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is largely adopted for chemical process\nmonitoring and numerous PCA-based systems have been developed to solve various\nfault detection and diagnosis problems. Since PCA-based methods assume that the\nmonitored process is linear, nonlinear PCA models, such as autoencoder models\nand kernel principal component analysis (KPCA), has been proposed and applied\nto nonlinear process monitoring. However, KPCA-based methods need to perform\neigen-decomposition (ED) on the kernel Gram matrix whose dimensions depend on\nthe number of training data. Moreover, prefixed kernel parameters cannot be\nmost effective for different faults which may need different parameters to\nmaximize their respective detection performances. Autoencoder models lack the\nconsideration of orthogonal constraints which is crucial for PCA-based\nalgorithms. To address these problems, this paper proposes a novel nonlinear\nmethod, called neural component analysis (NCA), which intends to train a\nfeedforward neural work with orthogonal constraints such as those used in PCA.\nNCA can adaptively learn its parameters through backpropagation and the\ndimensionality of the nonlinear features has no relationship with the number of\ntraining samples. Extensive experimental results on the Tennessee Eastman (TE)\nbenchmark process show the superiority of NCA in terms of missed detection rate\n(MDR) and false alarm rate (FAR). The source code of NCA can be found in\nhttps://github.com/haitaozhao/Neural-Component-Analysis.git.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 04:11:37 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Zhao", "Haitao", ""]]}, {"id": "1712.04170", "submitter": "Daniel Hein", "authors": "Daniel Hein, Steffen Udluft, Thomas A. Runkler", "title": "Interpretable Policies for Reinforcement Learning by Genetic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search for interpretable reinforcement learning policies is of high\nacademic and industrial interest. Especially for industrial systems, domain\nexperts are more likely to deploy autonomously learned controllers if they are\nunderstandable and convenient to evaluate. Basic algebraic equations are\nsupposed to meet these requirements, as long as they are restricted to an\nadequate complexity. Here we introduce the genetic programming for\nreinforcement learning (GPRL) approach based on model-based batch reinforcement\nlearning and genetic programming, which autonomously learns policy equations\nfrom pre-existing default state-action trajectory samples. GPRL is compared to\na straight-forward method which utilizes genetic programming for symbolic\nregression, yielding policies imitating an existing well-performing, but\nnon-interpretable policy. Experiments on three reinforcement learning\nbenchmarks, i.e., mountain car, cart-pole balancing, and industrial benchmark,\ndemonstrate the superiority of our GPRL approach compared to the symbolic\nregression method. GPRL is capable of producing well-performing interpretable\nreinforcement learning policies from pre-existing default trajectory data.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 08:31:51 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 07:23:57 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Hein", "Daniel", ""], ["Udluft", "Steffen", ""], ["Runkler", "Thomas A.", ""]]}, {"id": "1712.04185", "submitter": "Vsevolod Avrutskiy", "authors": "V.I. Avrutskiy", "title": "Backpropagation generalized for output derivatives", "comments": "Unpublished", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation algorithm is the cornerstone for neural network analysis.\nPaper extends it for training any derivatives of neural network's output with\nrespect to its input. By the dint of it feedforward networks can be used to\nsolve or verify solutions of partial or simple, linear or nonlinear\ndifferential equations. This method vastly differs from traditional ones like\nfinite differences on a mesh. It contains no approximations, but rather an\nexact form of differential operators. Algorithm is built to train a feed\nforward network with any number of hidden layers and any kind of sufficiently\nsmooth activation functions. It's presented in a form of matrix-vector products\nso highly parallel implementation is readily possible. First part derives the\nmethod for 2D case with first and second order derivatives, second part extends\nit to N-dimensional case with any derivatives. All necessary expressions for\nusing this method to solve most applied PDE can be found in Appendix D.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 09:34:52 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Avrutskiy", "V. I.", ""]]}, {"id": "1712.04195", "submitter": "Yoshihiro Nagano", "authors": "Yoshihiro Nagano, Ryo Karakida and Masato Okada", "title": "Concept Formation and Dynamics of Repeated Inference in Deep Generative\n  Models", "comments": "20 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are reported to be useful in broad applications\nincluding image generation. Repeated inference between data space and latent\nspace in these models can denoise cluttered images and improve the quality of\ninferred results. However, previous studies only qualitatively evaluated image\noutputs in data space, and the mechanism behind the inference has not been\ninvestigated. The purpose of the current study is to numerically analyze\nchanges in activity patterns of neurons in the latent space of a deep\ngenerative model called a \"variational auto-encoder\" (VAE). What kinds of\ninference dynamics the VAE demonstrates when noise is added to the input data\nare identified. The VAE embeds a dataset with clear cluster structures in the\nlatent space and the center of each cluster of multiple correlated data points\n(memories) is referred as the concept. Our study demonstrated that transient\ndynamics of inference first approaches a concept, and then moves close to a\nmemory. Moreover, the VAE revealed that the inference dynamics approaches a\nmore abstract concept to the extent that the uncertainty of input data\nincreases due to noise. It was demonstrated that by increasing the number of\nthe latent variables, the trend of the inference dynamics to approach a concept\ncan be enhanced, and the generalization ability of the VAE can be improved.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 09:55:11 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Nagano", "Yoshihiro", ""], ["Karakida", "Ryo", ""], ["Okada", "Masato", ""]]}, {"id": "1712.04248", "submitter": "Jonas Rauber", "authors": "Wieland Brendel, Jonas Rauber, Matthias Bethge", "title": "Decision-Based Adversarial Attacks: Reliable Attacks Against Black-Box\n  Machine Learning Models", "comments": "Published as a conference paper at the Sixth International Conference\n  on Learning Representations (ICLR 2018)\n  https://openreview.net/forum?id=SyZI0GWCZ", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning algorithms are vulnerable to almost imperceptible\nperturbations of their inputs. So far it was unclear how much risk adversarial\nperturbations carry for the safety of real-world machine learning applications\nbecause most methods used to generate such perturbations rely either on\ndetailed model information (gradient-based attacks) or on confidence scores\nsuch as class probabilities (score-based attacks), neither of which are\navailable in most real-world scenarios. In many such cases one currently needs\nto retreat to transfer-based attacks which rely on cumbersome substitute\nmodels, need access to the training data and can be defended against. Here we\nemphasise the importance of attacks which solely rely on the final model\ndecision. Such decision-based attacks are (1) applicable to real-world\nblack-box models such as autonomous cars, (2) need less knowledge and are\neasier to apply than transfer-based attacks and (3) are more robust to simple\ndefences than gradient- or score-based attacks. Previous attacks in this\ncategory were limited to simple models or simple datasets. Here we introduce\nthe Boundary Attack, a decision-based attack that starts from a large\nadversarial perturbation and then seeks to reduce the perturbation while\nstaying adversarial. The attack is conceptually simple, requires close to no\nhyperparameter tuning, does not rely on substitute models and is competitive\nwith the best gradient-based attacks in standard computer vision tasks like\nImageNet. We apply the attack on two black-box algorithms from Clarifai.com.\nThe Boundary Attack in particular and the class of decision-based attacks in\ngeneral open new avenues to study the robustness of machine learning models and\nraise new questions regarding the safety of deployed machine learning systems.\nAn implementation of the attack is available as part of Foolbox at\nhttps://github.com/bethgelab/foolbox .\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 11:36:26 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 14:40:42 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Brendel", "Wieland", ""], ["Rauber", "Jonas", ""], ["Bethge", "Matthias", ""]]}, {"id": "1712.04254", "submitter": "Nicola Milano", "authors": "Nicola Milano, Paolo Pagliuca and Stefano Nolfi", "title": "Robustness, Evolvability and Phenotypic Complexity: Insights from\n  Evolving Digital Circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how the characteristics of the evolutionary algorithm influence the\nevolvability of candidate solutions, i.e. the propensity of evolving\nindividuals to generate better solutions as a result of genetic variation. More\nspecifically, (1+{\\lambda}) evolutionary strategies largely outperform\n({\\mu}+1) evolutionary strategies in the context of the evolution of digital\ncircuits --- a domain characterized by a high level of neutrality. This\ndifference is due to the fact that the competition for robustness to mutations\namong the circuits evolved with ({\\mu}+1) evolutionary strategies leads to the\nselection of phenotypically simple but low evolvable circuits. These circuits\nachieve robustness by minimizing the number of functional genes rather than by\nrelying on redundancy or degeneracy to buffer the effects of mutations. The\nanalysis of these factors enabled us to design a new evolutionary algorithm,\nnamed Parallel Stochastic Hill Climber (PSHC), which outperforms the other two\nmethods considered.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 11:57:49 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Milano", "Nicola", ""], ["Pagliuca", "Paolo", ""], ["Nolfi", "Stefano", ""]]}, {"id": "1712.04473", "submitter": "Vsevolod Avrutskiy", "authors": "V.I. Avrutskiy", "title": "Enhancing approximation abilities of neural networks by training\n  derivatives", "comments": null, "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, 2020", "doi": "10.1109/TNNLS.2020.2979706", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method to increase the precision of feedforward networks is proposed. It\nrequires a prior knowledge of a target function derivatives of several orders\nand uses this information in gradient based training. Forward pass calculates\nnot only the values of the output layer of a network but also their\nderivatives. The deviations of those derivatives from the target ones are used\nin an extended cost function and then backward pass calculates the gradient of\nthe extended cost with respect to weights, which can then be used by any\nweights update algorithm. Despite a substantial increase in arithmetic\noperations per pattern (if compared to the conventional training), the extended\ncost allows to obtain 140--1000 times more accurate approximation for simple\ncases if the total number of operations is equal. This precision also happens\nto be out of reach for the regular cost function. The method fits well into the\nprocedure of solving differential equations with neural networks. Unlike\ntraining a network to match some target mapping, which requires an explicit use\nof the target derivatives in the extended cost function, the cost function for\nsolving a differential equation is based on the deviation of the equation's\nresidual from zero and thus can be extended by differentiating the equation\nitself, which does not require any prior knowledge. Solving an equation with\nsuch a cost resulted in 13 times more accurate result and could be done with 3\ntimes larger grid step. GPU-efficient algorithm for calculating the gradient of\nthe extended cost function is proposed.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 19:12:16 GMT"}, {"version": "v2", "created": "Sat, 20 Oct 2018 15:55:35 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 07:17:16 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Avrutskiy", "V. I.", ""]]}, {"id": "1712.04602", "submitter": "David Schwartz M", "authors": "David M. Schwartz and O. Ozan Koyluoglu", "title": "On the organization of grid and place cells: Neural de-noising via\n  subspace learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.IT cs.LG cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Place cells in the hippocampus are active when an animal visits a certain\nlocation (referred to as a place field) within an environment. Grid cells in\nthe medial entorhinal cortex (MEC) respond at multiple locations, with firing\nfields that form a periodic and hexagonal tiling of the environment. The joint\nactivity of grid and place cell populations, as a function of location, forms a\nneural code for space. An ensemble of codes is generated by varying grid and\nplace cell population parameters. For each code in this ensemble, codewords are\ngenerated by stimulating a network with a discrete set of locations. In this\nmanuscript, we develop an understanding of the relationships between coding\ntheoretic properties of these combined populations and code construction\nparameters. These relationships are revisited by measuring the performances of\nbiologically realizable algorithms implemented by networks of place and grid\ncell populations, as well as constraint neurons, which perform de-noising\noperations. Objectives of this work include the investigation of coding\ntheoretic limitations of the mammalian neural code for location and how\ncommunication between grid and place cell networks may improve the accuracy of\neach population's representation. Simulations demonstrate that de-noising\nmechanisms analyzed here can significantly improve fidelity of this neural\nrepresentation of space. Further, patterns observed in connectivity of each\npopulation of simulated cells suggest that\ninter-hippocampal-medial-entorhinal-cortical connectivity decreases downward\nalong the dorsoventral axis.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 03:48:27 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 21:07:55 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Schwartz", "David M.", ""], ["Koyluoglu", "O. Ozan", ""]]}, {"id": "1712.04604", "submitter": "Chase Gaudet", "authors": "Chase Gaudet, Anthony Maida", "title": "Deep Quaternion Networks", "comments": "IJCNN 2018, 8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of deep learning has seen significant advancement in recent years.\nHowever, much of the existing work has been focused on real-valued numbers.\nRecent work has shown that a deep learning system using the complex numbers can\nbe deeper for a fixed parameter budget compared to its real-valued counterpart.\nIn this work, we explore the benefits of generalizing one step further into the\nhyper-complex numbers, quaternions specifically, and provide the architecture\ncomponents needed to build deep quaternion networks. We develop the theoretical\nbasis by reviewing quaternion convolutions, developing a novel quaternion\nweight initialization scheme, and developing novel algorithms for quaternion\nbatch-normalization. These pieces are tested in a classification model by\nend-to-end training on the CIFAR-10 and CIFAR-100 data sets and a segmentation\nmodel by end-to-end training on the KITTI Road Segmentation data set. These\nquaternion networks show improved convergence compared to real-valued and\ncomplex-valued networks, especially on the segmentation task, while having\nfewer parameters\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 04:19:24 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 16:08:56 GMT"}, {"version": "v3", "created": "Sun, 29 Jul 2018 14:12:23 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Gaudet", "Chase", ""], ["Maida", "Anthony", ""]]}, {"id": "1712.05042", "submitter": "Yanan Sun", "authors": "Yanan Sun, Bing Xue, Mengjie Zhang and Gary G. Yen", "title": "A Particle Swarm Optimization-based Flexible Convolutional Auto-Encoder\n  for Image Classification", "comments": "Accepted by IEEE Transactions on Neural Networks and Learning\n  Systems, 2018", "journal-ref": null, "doi": "10.1109/TNNLS.2018.2881143", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional auto-encoders have shown their remarkable performance in\nstacking to deep convolutional neural networks for classifying image data\nduring past several years. However, they are unable to construct the\nstate-of-the-art convolutional neural networks due to their intrinsic\narchitectures. In this regard, we propose a flexible convolutional auto-encoder\nby eliminating the constraints on the numbers of convolutional layers and\npooling layers from the traditional convolutional auto-encoder. We also design\nan architecture discovery method by using particle swarm optimization, which is\ncapable of automatically searching for the optimal architectures of the\nproposed flexible convolutional auto-encoder with much less computational\nresource and without any manual intervention. We use the designed architecture\noptimization algorithm to test the proposed flexible convolutional auto-encoder\nthrough utilizing one graphic processing unit card on four extensively used\nimage classification datasets. Experimental results show that our work in this\npaper significantly outperform the peer competitors including the\nstate-of-the-art algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 23:20:54 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2018 02:48:54 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Sun", "Yanan", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""], ["Yen", "Gary G.", ""]]}, {"id": "1712.05043", "submitter": "Yanan Sun", "authors": "Yanan Sun, Gary G. Yen and Zhang Yi", "title": "Evolving Unsupervised Deep Neural Networks for Learning Meaningful\n  Representations", "comments": "This paper has been accepted by IEEE Transactions on Evolutionary\n  Computation", "journal-ref": null, "doi": "10.1109/TEVC.2018.2808689", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) aims at learning the \\emph{meaningful representations}. A\nmeaningful representation refers to the one that gives rise to significant\nperformance improvement of associated Machine Learning (ML) tasks by replacing\nthe raw data as the input. However, optimal architecture design and model\nparameter estimation in DL algorithms are widely considered to be intractable.\nEvolutionary algorithms are much preferable for complex and non-convex problems\ndue to its inherent characteristics of gradient-free and insensitivity to local\noptimum. In this paper, we propose a computationally economical algorithm for\nevolving \\emph{unsupervised deep neural networks} to efficiently learn\n\\emph{meaningful representations}, which is very suitable in the current Big\nData era where sufficient labeled data for training is often expensive to\nacquire. In the proposed algorithm, finding an appropriate architecture and the\ninitialized parameter values for a ML task at hand is modeled by one\ncomputational efficient gene encoding approach, which is employed to\neffectively model the task with a large number of parameters. In addition, a\nlocal search strategy is incorporated to facilitate the exploitation search for\nfurther improving the performance. Furthermore, a small proportion labeled data\nis utilized during evolution search to guarantee the learnt representations to\nbe meaningful. The performance of the proposed algorithm has been thoroughly\ninvestigated over classification tasks. Specifically, error classification rate\non MNIST with $1.15\\%$ is reached by the proposed algorithm consistently, which\nis a very promising result against state-of-the-art unsupervised DL algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 23:21:00 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 02:51:53 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Sun", "Yanan", ""], ["Yen", "Gary G.", ""], ["Yi", "Zhang", ""]]}, {"id": "1712.05067", "submitter": "Vsevolod Avrutskiy", "authors": "V.I. Avrutskiy", "title": "Neural networks catching up with finite differences in solving partial\n  differential equations in higher dimensions", "comments": null, "journal-ref": "Neural Computing and Applications, 2020", "doi": "10.1007/s00521-020-04743-8", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully connected multilayer perceptrons are used for obtaining numerical\nsolutions of partial differential equations in various dimensions. Independent\nvariables are fed into the input layer, and the output is considered as\nsolution's value. To train such a network one can use square of equation's\nresidual as a cost function and minimize it with respect to weights by gradient\ndescent. Following previously developed method, derivatives of the equation's\nresidual along random directions in space of independent variables are also\nadded to cost function. Similar procedure is known to produce nearly machine\nprecision results using less than 8 grid points per dimension for 2D case. The\nsame effect is observed here for higher dimensions: solutions are obtained on\nlow density grids, but maintain their precision in the entire region. Boundary\nvalue problems for linear and nonlinear Poisson equations are solved inside 2,\n3, 4, and 5 dimensional balls. Grids for linear cases have 40, 159, 512 and\n1536 points and for nonlinear 64, 350, 1536 and 6528 points respectively. In\nall cases maximum error is less than $8.8\\cdot10^{-6}$, and median error is\nless than $2.4\\cdot10^{-6}$. Very weak grid requirements enable neural networks\nto obtain solution of 5D linear problem within 22 minutes, whereas projected\nsolving time for finite differences on the same hardware is 50 minutes. Method\nis applied to second order equation, but requires little to none modifications\nto solve systems or higher order PDEs.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 01:24:04 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Avrutskiy", "V. I.", ""]]}, {"id": "1712.05249", "submitter": "Pierre-Yves Oudeyer", "authors": "Freek Stulp and Pierre-Yves Oudeyer", "title": "Proximodistal Exploration in Motor Learning as an Emergent Property of\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To harness the complexity of their high-dimensional bodies during\nsensorimotor development, infants are guided by patterns of freezing and\nfreeing of degrees of freedom. For instance, when learning to reach, infants\nfree the degrees of freedom in their arm proximodistally, i.e. from joints that\nare closer to the body to those that are more distant. Here, we formulate and\nstudy computationally the hypothesis that such patterns can emerge\nspontaneously as the result of a family of stochastic optimization processes\n(evolution strategies with covariance-matrix adaptation), without an innate\nencoding of a maturational schedule. In particular, we present simulated\nexperiments with an arm where a computational learner progressively acquires\nreaching skills through adaptive exploration, and we show that a proximodistal\norganization appears spontaneously, which we denote PDFF (ProximoDistal\nFreezing and Freeing of degrees of freedom). We also compare this emergent\norganization between different arm morphologies -- from human-like to quite\nunnatural ones -- to study the effect of different kinematic structures on the\nemergence of PDFF. Keywords: human motor learning; proximo-distal exploration;\nstochastic optimization; modelling; evolution strategies; cross-entropy\nmethods; policy search; morphology.}\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 14:31:51 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Stulp", "Freek", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1712.05284", "submitter": "Miguel Aguilera", "authors": "Miguel Aguilera and Manuel G. Bedia", "title": "Adaptation to criticality through organizational invariance in embodied\n  agents", "comments": "arXiv admin note: substantial text overlap with arXiv:1704.05255", "journal-ref": "Aguilera, M., & Bedia, M. G. (2018). Adaptation to criticality\n  through organizational invariance in embodied agents. Scientific reports,\n  8(1), 7723", "doi": "10.1038/s41598-018-25925-4", "report-no": null, "categories": "nlin.AO cond-mat.dis-nn cond-mat.stat-mech cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many biological and cognitive systems do not operate deep within one or other\nregime of activity. Instead, they are poised at critical points located at\nphase transitions in their parameter space. The pervasiveness of criticality\nsuggests that there may be general principles inducing this behaviour, yet\nthere is no well-founded theory for understanding how criticality is generated\nat a wide span of levels and contexts. In order to explore how criticality\nmight emerge from general adaptive mechanisms, we propose a simple learning\nrule that maintains an internal organizational structure from a specific family\nof systems at criticality. We implement the mechanism in artificial embodied\nagents controlled by a neural network maintaining a correlation structure\nrandomly sampled from an Ising model at critical temperature. Agents are\nevaluated in two classical reinforcement learning scenarios: the Mountain Car\nand the Acrobot double pendulum. In both cases the neural controller appears to\nreach a point of criticality, which coincides with a transition point between\ntwo regimes of the agent's behaviour. These results suggest that adaptation to\ncriticality could be used as a general adaptive mechanism in some\ncircumstances, providing an alternative explanation for the pervasive presence\nof criticality in biological and cognitive systems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 10:07:49 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 15:14:25 GMT"}, {"version": "v3", "created": "Fri, 1 Jun 2018 10:04:00 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Aguilera", "Miguel", ""], ["Bedia", "Manuel G.", ""]]}, {"id": "1712.05512", "submitter": "Saptarshi Sengupta", "authors": "Saptarshi Sengupta, Sanchita Basak, Richard Alan Peters II", "title": "Data Clustering using a Hybrid of Fuzzy C-Means and Quantum-behaved\n  Particle Swarm Optimization", "comments": "6 pages, 6 figures, 6 tables", "journal-ref": null, "doi": "10.1109/CCWC.2018.8301693", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fuzzy clustering has become a widely used data mining technique and plays an\nimportant role in grouping, traversing and selectively using data for user\nspecified applications. The deterministic Fuzzy C-Means (FCM) algorithm may\nresult in suboptimal solutions when applied to multidimensional data in\nreal-world, time-constrained problems. In this paper the Quantum-behaved\nParticle Swarm Optimization (QPSO) with a fully connected topology is coupled\nwith the Fuzzy C-Means Clustering algorithm and is tested on a suite of\ndatasets from the UCI Machine Learning Repository. The global search ability of\nthe QPSO algorithm helps in avoiding stagnation in local optima while the soft\nclustering approach of FCM helps to partition data based on membership\nprobabilities. Clustering performance indices such as F-Measure, Accuracy,\nQuantization Error, Intercluster and Intracluster distances are reported for\ncompetitive techniques such as PSO K-Means, QPSO K-Means and QPSO FCM over all\ndatasets considered. Experimental results indicate that QPSO FCM provides\ncomparable and in most cases superior results when compared to the others.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 02:47:57 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Sengupta", "Saptarshi", ""], ["Basak", "Sanchita", ""], ["Peters", "Richard Alan", "II"]]}, {"id": "1712.05695", "submitter": "Altaf Khan", "authors": "Altaf H. Khan", "title": "Lightweight Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the weights in a Lightweight Neural Network have a value of zero,\nwhile the remaining ones are either +1 or -1. These universal approximators\nrequire approximately 1.1 bits/weight of storage, posses a quick forward pass\nand achieve classification accuracies similar to conventional continuous-weight\nnetworks. Their training regimen focuses on error reduction initially, but\nlater emphasizes discretization of weights. They ignore insignificant inputs,\nremove unnecessary weights, and drop unneeded hidden neurons. We have\nsuccessfully tested them on the MNIST, credit card fraud, and credit card\ndefaults data sets using networks having 2 to 16 hidden layers and up to 4.4\nmillion weights.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 14:56:05 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Khan", "Altaf H.", ""]]}, {"id": "1712.05895", "submitter": "Tuo-Hung Hou", "authors": "Chih-Cheng Chang, Pin-Chun Chen, Teyuh Chou, I-Ting Wang, Boris Hudec,\n  Che-Chia Chang, Chia-Ming Tsai, Tian-Sheuan Chang, and Tuo-Hung Hou", "title": "Mitigating Asymmetric Nonlinear Weight Update Effects in Hardware Neural\n  Network based on Analog Resistive Synapse", "comments": "IEEE Journal on Emerging and Selected Topics in Circuits and Systems\n  2017", "journal-ref": null, "doi": "10.1109/JETCAS.2017.2771529", "report-no": null, "categories": "cs.LG cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asymmetric nonlinear weight update is considered as one of the major\nobstacles for realizing hardware neural networks based on analog resistive\nsynapses because it significantly compromises the online training capability.\nThis paper provides new solutions to this critical issue through\nco-optimization with the hardware-applicable deep-learning algorithms. New\ninsights on engineering activation functions and a threshold weight update\nscheme effectively suppress the undesirable training noise induced by\ninaccurate weight update. We successfully trained a two-layer perceptron\nnetwork online and improved the classification accuracy of MNIST handwritten\ndigit dataset to 87.8/94.8% by using 6-bit/8-bit analog synapses, respectively,\nwith extremely high asymmetric nonlinearity.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 02:45:02 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Chang", "Chih-Cheng", ""], ["Chen", "Pin-Chun", ""], ["Chou", "Teyuh", ""], ["Wang", "I-Ting", ""], ["Hudec", "Boris", ""], ["Chang", "Che-Chia", ""], ["Tsai", "Chia-Ming", ""], ["Chang", "Tian-Sheuan", ""], ["Hou", "Tuo-Hung", ""]]}, {"id": "1712.05934", "submitter": "Han Xiao Almighty", "authors": "Han Xiao", "title": "NDT: Neual Decision Tree Towards Fully Functioned Neural Graph", "comments": "This is the draft paper. I will refine the paper until accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though traditional algorithms could be embedded into neural architectures\nwith the proposed principle of \\cite{xiao2017hungarian}, the variables that\nonly occur in the condition of branch could not be updated as a special case.\nTo tackle this issue, we multiply the conditioned branches with Dirac symbol\n(i.e. $\\mathbf{1}_{x>0}$), then approximate Dirac symbol with the continuous\nfunctions (e.g. $1 - e^{-\\alpha|x|}$). In this way, the gradients of\ncondition-specific variables could be worked out in the back-propagation\nprocess, approximately, making a fully functioned neural graph. Within our\nnovel principle, we propose the neural decision tree \\textbf{(NDT)}, which\ntakes simplified neural networks as decision function in each branch and\nemploys complex neural networks to generate the output in each leaf. Extensive\nexperiments verify our theoretical analysis and demonstrate the effectiveness\nof our model.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 10:42:57 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Xiao", "Han", ""]]}, {"id": "1712.05954", "submitter": "Vasily Morzhakov", "authors": "Vasily Morzhakov, Alexey Redozubov", "title": "An Artificial Neural Network Architecture Based on Context\n  Transformations in Cortical Minicolumns", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical minicolumns are considered a model of cortical organization. Their\nfunction is still a source of research and not reflected properly in modern\narchitecture of nets in algorithms of Artificial Intelligence. We assume its\nfunction and describe it in this article. Furthermore, we show how this\nproposal allows to construct a new architecture, that is not based on\nconvolutional neural networks, test it on MNIST data and receive close to\nConvolutional Neural Network accuracy. We also show that the proposed\narchitecture possesses an ability to train on a small quantity of samples. To\nachieve these results, we enable the minicolumns to remember context\ntransformations.\n", "versions": [{"version": "v1", "created": "Sat, 16 Dec 2017 13:14:03 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Morzhakov", "Vasily", ""], ["Redozubov", "Alexey", ""]]}, {"id": "1712.06070", "submitter": "Andres Felipe Cruz Salinas", "authors": "Andres Felipe Cruz Salinas and Jonatan Gomez Perdomo", "title": "Self-adaptation of Genetic Operators Through Genetic Programming\n  Techniques", "comments": "Presented in GECCO 2017", "journal-ref": null, "doi": "10.1145/3071178.3071214", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Here we propose an evolutionary algorithm that self modifies its operators at\nthe same time that candidate solutions are evolved. This tackles convergence\nand lack of diversity issues, leading to better solutions. Operators are\nrepresented as trees and are evolved using genetic programming (GP) techniques.\nThe proposed approach is tested with real benchmark functions and an analysis\nof operator evolution is provided.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 07:53:36 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Salinas", "Andres Felipe Cruz", ""], ["Perdomo", "Jonatan Gomez", ""]]}, {"id": "1712.06087", "submitter": "Assaf Shocher", "authors": "Assaf Shocher, Nadav Cohen, Michal Irani", "title": "\"Zero-Shot\" Super-Resolution using Deep Internal Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has led to a dramatic leap in Super-Resolution (SR) performance\nin the past few years. However, being supervised, these SR methods are\nrestricted to specific training data, where the acquisition of the\nlow-resolution (LR) images from their high-resolution (HR) counterparts is\npredetermined (e.g., bicubic downscaling), without any distracting artifacts\n(e.g., sensor noise, image compression, non-ideal PSF, etc). Real LR images,\nhowever, rarely obey these restrictions, resulting in poor SR results by SotA\n(State of the Art) methods. In this paper we introduce \"Zero-Shot\" SR, which\nexploits the power of Deep Learning, but does not rely on prior training. We\nexploit the internal recurrence of information inside a single image, and train\na small image-specific CNN at test time, on examples extracted solely from the\ninput image itself. As such, it can adapt itself to different settings per\nimage. This allows to perform SR of real old photos, noisy images, biological\ndata, and other images where the acquisition process is unknown or non-ideal.\nOn such images, our method outperforms SotA CNN-based SR methods, as well as\nprevious unsupervised SR methods. To the best of our knowledge, this is the\nfirst unsupervised CNN-based SR method.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 11:00:30 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Shocher", "Assaf", ""], ["Cohen", "Nadav", ""], ["Irani", "Michal", ""]]}, {"id": "1712.06132", "submitter": "Sakyasingha Dasgupta", "authors": "Rudy Raymond, Takayuki Osogami and Sakyasingha Dasgupta", "title": "Dynamic Boltzmann Machines for Second Order Moments and Generalized\n  Gaussian Distributions", "comments": "7 pages, 3 figures. Accepted and presented in NIPS 2017 (time-series\n  workshop) at Long Beach, California", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Boltzmann Machine (DyBM) has been shown highly efficient to predict\ntime-series data. Gaussian DyBM is a DyBM that assumes the predicted data is\ngenerated by a Gaussian distribution whose first-order moment (mean)\ndynamically changes over time but its second-order moment (variance) is fixed.\nHowever, in many financial applications, the assumption is quite limiting in\ntwo aspects. First, even when the data follows a Gaussian distribution, its\nvariance may change over time. Such variance is also related to important\ntemporal economic indicators such as the market volatility. Second, financial\ntime-series data often requires learning datasets generated by the generalized\nGaussian distribution with an additional shape parameter that is important to\napproximate heavy-tailed distributions. Addressing those aspects, we show how\nto extend DyBM that results in significant performance improvement in\npredicting financial time-series data.\n", "versions": [{"version": "v1", "created": "Sun, 17 Dec 2017 16:08:53 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Raymond", "Rudy", ""], ["Osogami", "Takayuki", ""], ["Dasgupta", "Sakyasingha", ""]]}, {"id": "1712.06272", "submitter": "Sakyasingha Dasgupta", "authors": "Farhan Shafiq, Takato Yamada, Antonio T. Vilchez, and Sakyasingha\n  Dasgupta", "title": "Automated flow for compressing convolution neural networks for efficient\n  edge-computation with FPGA", "comments": "7 pages, 9 figures. Accepted and presented at MLPCD workshop, NIPS\n  2017 (LongBeach, California)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNN) based solutions are the current\nstate- of-the-art for computer vision tasks. Due to the large size of these\nmodels, they are typically run on clusters of CPUs or GPUs. However, power\nrequirements and cost budgets can be a major hindrance in adoption of CNN for\nIoT applications. Recent research highlights that CNN contain significant\nredundancy in their structure and can be quantized to lower bit-width\nparameters and activations, while maintaining acceptable accuracy. Low\nbit-width and especially single bit-width (binary) CNN are particularly\nsuitable for mobile applications based on FPGA implementation, due to the\nbitwise logic operations involved in binarized CNN. Moreover, the transition to\nlower bit-widths opens new avenues for performance optimizations and model\nimprovement. In this paper, we present an automatic flow from trained\nTensorFlow models to FPGA system on chip implementation of binarized CNN. This\nflow involves quantization of model parameters and activations, generation of\nnetwork and model in embedded-C, followed by automatic generation of the FPGA\naccelerator for binary convolutions. The automated flow is demonstrated through\nimplementation of binarized \"YOLOV2\" on the low cost, low power Cyclone- V FPGA\ndevice. Experiments on object detection using binarized YOLOV2 demonstrate\nsignificant performance benefit in terms of model size and inference speed on\nFPGA as compared to CPU and mobile CPU platforms. Furthermore, the entire\nautomated flow from trained models to FPGA synthesis can be completed within\none hour.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 07:02:07 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Shafiq", "Farhan", ""], ["Yamada", "Takato", ""], ["Vilchez", "Antonio T.", ""], ["Dasgupta", "Sakyasingha", ""]]}, {"id": "1712.06338", "submitter": "Sheng Xin Zhang", "authors": "Sheng Xin Zhang, Wing Shing Chan, Zi Kang Peng, Shao Yong Zheng, Kit\n  Sang Tang", "title": "Selective-Candidate Framework with Similarity Selection Rule for\n  Evolutionary Optimization", "comments": null, "journal-ref": "Swarm and Evolutionary Computation,\n  https://doi.org/10.1016/j.swevo.2020.100696", "doi": "10.1016/j.swevo.2020.100696", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achieving better exploitation and exploration capabilities (EEC) have always\nbeen an important yet challenging issue in the design of evolutionary\noptimization algorithm (EOA). The difficulties lie in obtaining a good balance\nin EEC, which is determined cooperatively by operations and parameters in an\nEOA. When deficiencies in exploitation or exploration are observed, most\nexisting works consider a piecemeal approach, either by designing new\noperations or by altering the parameters. Unfortunately, when different\nsituations are encountered, these proposals may fail to be the winner. To\naddress these problems, this paper proposes an explicit EEC control method\nnamed selective-candidate framework with similarity selection rule (SCSS). M (M\n> 1) candidates are first generated from each current solution with independent\noperations and parameters to enrich the search. Then, a similarity selection\nrule is designed to determine the final candidate by considering the fitness\nranking of the current solution and its Euclidian distance to each of these M\ncandidates. Superior current solutions will prefer the closest candidates for\nefficient local exploitation while inferior ones will favor the farthest for\nexploration purpose. In this way, the rule could synthesize exploitation and\nexploration, making the evolution more effective. When applied to three\nclassic, four state-of-the-art and four up-to-date EOAs from branches of\ndifferential evolution, evolution strategy and particle swarm optimization,\nsignificant enhancement in performance is achieved.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 11:09:36 GMT"}, {"version": "v2", "created": "Thu, 4 Jan 2018 23:18:55 GMT"}, {"version": "v3", "created": "Mon, 7 Jan 2019 13:12:49 GMT"}, {"version": "v4", "created": "Fri, 13 Sep 2019 04:43:41 GMT"}, {"version": "v5", "created": "Thu, 14 May 2020 12:08:39 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Zhang", "Sheng Xin", ""], ["Chan", "Wing Shing", ""], ["Peng", "Zi Kang", ""], ["Zheng", "Shao Yong", ""], ["Tang", "Kit Sang", ""]]}, {"id": "1712.06530", "submitter": "Brian Kenji Iwana", "authors": "Brian Kenji Iwana and Seiichi Uchida", "title": "Dynamic Weight Alignment for Temporal Convolutional Neural Networks", "comments": "Accepted to ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method of improving temporal Convolutional Neural\nNetworks (CNN) by determining the optimal alignment of weights and inputs using\ndynamic programming. Conventional CNN convolutions linearly match the shared\nweights to a window of the input. However, it is possible that there exists a\nmore optimal alignment of weights. Thus, we propose the use of Dynamic Time\nWarping (DTW) to dynamically align the weights to the input of the\nconvolutional layer. Specifically, the dynamic alignment overcomes issues such\nas temporal distortion by finding the minimal distance matching of the weights\nand the inputs under constraints. We demonstrate the effectiveness of the\nproposed architecture on the Unipen online handwritten digit and character\ndatasets, the UCI Spoken Arabic Digit dataset, and the UCI Activities of Daily\nLife dataset.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 17:16:07 GMT"}, {"version": "v2", "created": "Thu, 25 Jan 2018 14:35:19 GMT"}, {"version": "v3", "created": "Fri, 18 May 2018 17:23:54 GMT"}, {"version": "v4", "created": "Fri, 15 Jun 2018 12:37:06 GMT"}, {"version": "v5", "created": "Thu, 6 Sep 2018 06:50:57 GMT"}, {"version": "v6", "created": "Thu, 7 Feb 2019 08:10:19 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Iwana", "Brian Kenji", ""], ["Uchida", "Seiichi", ""]]}, {"id": "1712.06541", "submitter": "Ohad Shamir", "authors": "Noah Golowich, Alexander Rakhlin and Ohad Shamir", "title": "Size-Independent Sample Complexity of Neural Networks", "comments": "Fixed a bug in the proof of theorem 7 (not affecting theorem\n  statement), by slightly changing the construction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sample complexity of learning neural networks, by providing new\nbounds on their Rademacher complexity assuming norm constraints on the\nparameter matrix of each layer. Compared to previous work, these complexity\nbounds have improved dependence on the network depth, and under some additional\nassumptions, are fully independent of the network size (both depth and width).\nThese results are derived using some novel techniques, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 17:26:15 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 14:36:45 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 13:58:23 GMT"}, {"version": "v4", "created": "Wed, 6 Jun 2018 15:08:35 GMT"}, {"version": "v5", "created": "Sun, 17 Nov 2019 07:41:30 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Golowich", "Noah", ""], ["Rakhlin", "Alexander", ""], ["Shamir", "Ohad", ""]]}, {"id": "1712.06563", "submitter": "Joel Lehman", "authors": "Joel Lehman, Jay Chen, Jeff Clune, Kenneth O. Stanley", "title": "Safe Mutations for Deep and Recurrent Neural Networks through Output\n  Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neuroevolution (evolving neural networks) has a successful track record\nacross a variety of domains from reinforcement learning to artificial life, it\nis rarely applied to large, deep neural networks. A central reason is that\nwhile random mutation generally works in low dimensions, a random perturbation\nof thousands or millions of weights is likely to break existing functionality,\nproviding no learning signal even if some individual weight changes were\nbeneficial. This paper proposes a solution by introducing a family of safe\nmutation (SM) operators that aim within the mutation operator itself to find a\ndegree of change that does not alter network behavior too much, but still\nfacilitates exploration. Importantly, these SM operators do not require any\nadditional interactions with the environment. The most effective SM variant\ncapitalizes on the intriguing opportunity to scale the degree of mutation of\neach individual weight according to the sensitivity of the network's outputs to\nthat weight, which requires computing the gradient of outputs with respect to\nthe weights (instead of the gradient of error, as in conventional deep\nlearning). This safe mutation through gradients (SM-G) operator dramatically\nincreases the ability of a simple genetic algorithm-based neuroevolution method\nto find solutions in high-dimensional domains that require deep and/or\nrecurrent neural networks (which tend to be particularly brittle to mutation),\nincluding domains that require processing raw pixels. By improving our ability\nto evolve deep neural networks, this new safer approach to mutation expands the\nscope of domains amenable to neuroevolution.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 18:16:51 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 18:45:26 GMT"}, {"version": "v3", "created": "Tue, 1 May 2018 20:18:32 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Lehman", "Joel", ""], ["Chen", "Jay", ""], ["Clune", "Jeff", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "1712.06564", "submitter": "Jeff Clune", "authors": "Xingwen Zhang, Jeff Clune, Kenneth O. Stanley", "title": "On the Relationship Between the OpenAI Evolution Strategy and Stochastic\n  Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because stochastic gradient descent (SGD) has shown promise optimizing neural\nnetworks with millions of parameters and few if any alternatives are known to\nexist, it has moved to the heart of leading approaches to reinforcement\nlearning (RL). For that reason, the recent result from OpenAI showing that a\nparticular kind of evolution strategy (ES) can rival the performance of\nSGD-based deep RL methods with large neural networks provoked surprise. This\nresult is difficult to interpret in part because of the lingering ambiguity on\nhow ES actually relates to SGD. The aim of this paper is to significantly\nreduce this ambiguity through a series of MNIST-based experiments designed to\nuncover their relationship. As a simple supervised problem without domain noise\n(unlike in most RL), MNIST makes it possible (1) to measure the correlation\nbetween gradients computed by ES and SGD and (2) then to develop an SGD-based\nproxy that accurately predicts the performance of different ES population\nsizes. These innovations give a new level of insight into the real capabilities\nof ES, and lead also to some unconventional means for applying ES to supervised\nproblems that shed further light on its differences from SGD. Incorporating\nthese lessons, the paper concludes by demonstrating that ES can achieve 99%\naccuracy on MNIST, a number higher than any previously published result for any\nevolutionary method. While not by any means suggesting that ES should\nsubstitute for SGD in supervised learning, the suite of experiments herein\nenables more informed decisions on the application of ES within RL and other\nparadigms.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 18:17:21 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Zhang", "Xingwen", ""], ["Clune", "Jeff", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "1712.06567", "submitter": "Felipe Petroski Such", "authors": "Felipe Petroski Such, Vashisht Madhavan, Edoardo Conti, Joel Lehman,\n  Kenneth O. Stanley, Jeff Clune", "title": "Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative\n  for Training Deep Neural Networks for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep artificial neural networks (DNNs) are typically trained via\ngradient-based learning algorithms, namely backpropagation. Evolution\nstrategies (ES) can rival backprop-based algorithms such as Q-learning and\npolicy gradients on challenging deep reinforcement learning (RL) problems.\nHowever, ES can be considered a gradient-based algorithm because it performs\nstochastic gradient descent via an operation similar to a finite-difference\napproximation of the gradient. That raises the question of whether\nnon-gradient-based evolutionary algorithms can work at DNN scales. Here we\ndemonstrate they can: we evolve the weights of a DNN with a simple,\ngradient-free, population-based genetic algorithm (GA) and it performs well on\nhard deep RL problems, including Atari and humanoid locomotion. The Deep GA\nsuccessfully evolves networks with over four million free parameters, the\nlargest neural networks ever evolved with a traditional evolutionary algorithm.\nThese results (1) expand our sense of the scale at which GAs can operate, (2)\nsuggest intriguingly that in some cases following the gradient is not the best\nchoice for optimizing performance, and (3) make immediately available the\nmultitude of neuroevolution techniques that improve performance. We demonstrate\nthe latter by showing that combining DNNs with novelty search, which encourages\nexploration on tasks with deceptive or sparse reward functions, can solve a\nhigh-dimensional problem on which reward-maximizing algorithms (e.g.\\ DQN, A3C,\nES, and the GA) fail. Additionally, the Deep GA is faster than ES, A3C, and DQN\n(it can train Atari in ${\\raise.17ex\\hbox{$\\scriptstyle\\sim$}}$4 hours on one\ndesktop or ${\\raise.17ex\\hbox{$\\scriptstyle\\sim$}}$1 hour distributed on 720\ncores), and enables a state-of-the-art, up to 10,000-fold compact encoding\ntechnique.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 18:22:05 GMT"}, {"version": "v2", "created": "Thu, 4 Jan 2018 22:59:49 GMT"}, {"version": "v3", "created": "Fri, 20 Apr 2018 18:38:34 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Such", "Felipe Petroski", ""], ["Madhavan", "Vashisht", ""], ["Conti", "Edoardo", ""], ["Lehman", "Joel", ""], ["Stanley", "Kenneth O.", ""], ["Clune", "Jeff", ""]]}, {"id": "1712.06568", "submitter": "Joel Lehman", "authors": "Joel Lehman, Jay Chen, Jeff Clune, Kenneth O. Stanley", "title": "ES Is More Than Just a Traditional Finite-Difference Approximator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An evolution strategy (ES) variant based on a simplification of a natural\nevolution strategy recently attracted attention because it performs\nsurprisingly well in challenging deep reinforcement learning domains. It\nsearches for neural network parameters by generating perturbations to the\ncurrent set of parameters, checking their performance, and moving in the\naggregate direction of higher reward. Because it resembles a traditional\nfinite-difference approximation of the reward gradient, it can naturally be\nconfused with one. However, this ES optimizes for a different gradient than\njust reward: It optimizes for the average reward of the entire population,\nthereby seeking parameters that are robust to perturbation. This difference can\nchannel ES into distinct areas of the search space relative to gradient\ndescent, and also consequently to networks with distinct properties. This\nunique robustness-seeking property, and its consequences for optimization, are\ndemonstrated in several domains. They include humanoid locomotion, where\nnetworks from policy gradient-based reinforcement learning are significantly\nless robust to parameter perturbation than ES-based policies solving the same\ntask. While the implications of such robustness and robustness-seeking remain\nopen to further study, this work's main contribution is to highlight such\ndifferences and their potential importance.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 18:25:35 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 18:36:12 GMT"}, {"version": "v3", "created": "Tue, 1 May 2018 20:29:42 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Lehman", "Joel", ""], ["Chen", "Jay", ""], ["Clune", "Jeff", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "1712.07019", "submitter": "Ehsan Hemmati", "authors": "Mansour Sheikhan, Ehsan Hemmati", "title": "PSO-Optimized Hopfield Neural Network-Based Multipath Routing for Mobile\n  Ad-hoc Networks", "comments": "Mobile ad-hoc networks; Reliability; Multipath routing; Neural\n  networks; Particle swarm optimization (PSO)", "journal-ref": "International Journal of Computational Intelligence Systems, Year\n  2012, Volume 5, Number 3, Pages 568-581", "doi": "10.1080/18756891.2012.696921", "report-no": null, "categories": "cs.NE cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Mobile ad-hoc network (MANET) is a dynamic collection of mobile computers\nwithout the need for any existing infrastructure. Nodes in a MANET act as hosts\nand routers. Designing of robust routing algorithms for MANETs is a challenging\ntask. Disjoint multipath routing protocols address this problem and increase\nthe reliability, security and lifetime of network. However, selecting an\noptimal multipath is an NP-complete problem. In this paper, Hopfield neural\nnetwork (HNN) which its parameters are optimized by particle swarm optimization\n(PSO) algorithm is proposed as multipath routing algorithm. Link expiration\ntime (LET) between each two nodes is used as the link reliability estimation\nmetric. This approach can find either node-disjoint or link-disjoint paths in\nsingle phase route discovery. Simulation results confirm that PSO-HNN routing\nalgorithm has better performance as compared to backup path set selection\nalgorithm (BPSA) in terms of the path set reliability and number of paths in\nthe set.\n", "versions": [{"version": "v1", "created": "Thu, 16 Nov 2017 23:36:59 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Sheikhan", "Mansour", ""], ["Hemmati", "Ehsan", ""]]}, {"id": "1712.07040", "submitter": "Tom\\'a\\v{s} Ko\\v{c}isk\\'y", "authors": "Tom\\'a\\v{s} Ko\\v{c}isk\\'y, Jonathan Schwarz, Phil Blunsom, Chris Dyer,\n  Karl Moritz Hermann, G\\'abor Melis, Edward Grefenstette", "title": "The NarrativeQA Reading Comprehension Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading comprehension (RC)---in contrast to information retrieval---requires\nintegrating information and reasoning about events, entities, and their\nrelations across a full document. Question answering is conventionally used to\nassess RC ability, in both artificial agents and children learning to read.\nHowever, existing RC datasets and tasks are dominated by questions that can be\nsolved by selecting answers using superficial information (e.g., local context\nsimilarity or global term frequency); they thus fail to test for the essential\nintegrative aspect of RC. To encourage progress on deeper comprehension of\nlanguage, we present a new dataset and set of tasks in which the reader must\nanswer questions about stories by reading entire books or movie scripts. These\ntasks are designed so that successfully answering their questions requires\nunderstanding the underlying narrative rather than relying on shallow pattern\nmatching or salience. We show that although humans solve the tasks easily,\nstandard RC models struggle on the tasks presented here. We provide an analysis\nof the dataset and the challenges it presents.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 16:48:05 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Schwarz", "Jonathan", ""], ["Blunsom", "Phil", ""], ["Dyer", "Chris", ""], ["Hermann", "Karl Moritz", ""], ["Melis", "G\u00e1bor", ""], ["Grefenstette", "Edward", ""]]}, {"id": "1712.07116", "submitter": "Wellington Pinheiro dos Santos", "authors": "Sidney Marlon Lopes de Lima, Abel Guilhermino da Silva Filho,\n  Wellington Pinheiro dos Santos", "title": "Detection and classification of masses in mammographic images in a\n  multi-kernel approach", "comments": null, "journal-ref": "Computer Methods and Programs in Biomedicine, 134 (2016), 11-29", "doi": "10.1016/j.cmpb.2016.04.029", "report-no": null, "categories": "cs.CV cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the World Health Organization, breast cancer is the main cause\nof cancer death among adult women in the world. Although breast cancer occurs\nindiscriminately in countries with several degrees of social and economic\ndevelopment, among developing and underdevelopment countries mortality rates\nare still high, due to low availability of early detection technologies. From\nthe clinical point of view, mammography is still the most effective diagnostic\ntechnology, given the wide diffusion of the use and interpretation of these\nimages. Herein this work we propose a method to detect and classify\nmammographic lesions using the regions of interest of images. Our proposal\nconsists in decomposing each image using multi-resolution wavelets. Zernike\nmoments are extracted from each wavelet component. Using this approach we can\ncombine both texture and shape features, which can be applied both to the\ndetection and classification of mammary lesions. We used 355 images of fatty\nbreast tissue of IRMA database, with 233 normal instances (no lesion), 72\nbenign, and 83 malignant cases. Classification was performed by using SVM and\nELM networks with modified kernels, in order to optimize accuracy rates,\nreaching 94.11%. Considering both accuracy rates and training times, we defined\nthe ration between average percentage accuracy and average training time in a\nreverse order. Our proposal was 50 times higher than the ratio obtained using\nthe best method of the state-of-the-art. As our proposed model can combine high\naccuracy rate with low learning time, whenever a new data is received, our work\nwill be able to save a lot of time, hours, in learning process in relation to\nthe best method of the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 03:57:39 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["de Lima", "Sidney Marlon Lopes", ""], ["Filho", "Abel Guilhermino da Silva", ""], ["Santos", "Wellington Pinheiro dos", ""]]}, {"id": "1712.07165", "submitter": "Tyler Spears", "authors": "Tyler A. Spears, Brandon G. Jacques, Marc W. Howard, Per B. Sederberg", "title": "Scale-invariant temporal history (SITH): optimal slicing of the past in\n  an uncertain world", "comments": "Preprint for submission to Neural Computation. Submitted to Neural\n  Computation - Update 12/18/2018: revised based on reviewer comments,\n  resubmitted to Neural Computation on 15 December, 2018. Restructured\n  introduction and discussion, combined figures, added section for SITH\n  parameterization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In both the human brain and any general artificial intelligence (AI), a\nrepresentation of the past is necessary to predict the future. However, perfect\nstorage of all experiences is not feasible. One approach utilized in many\napplications, including reward prediction in reinforcement learning, is to\nretain recently active features of experience in a buffer. Despite its prior\nsuccesses, we show that the fixed length buffer renders Deep Q-learning\nNetworks (DQNs) fragile to changes in the scale over which information can be\nlearned. To enable learning when the relevant temporal scales in the\nenvironment are not known *a priori*, recent advances in psychology and\nneuroscience suggest that the brain maintains a compressed representation of\nthe past. Here we introduce a neurally-plausible, scale-free memory\nrepresentation we call Scale-Invariant Temporal History (SITH) for use with\nartificial agents. This representation covers an exponentially large period of\ntime by sacrificing temporal accuracy for events further in the past. We\ndemonstrate the utility of this representation by comparing the performance of\nagents given SITH, buffer, and exponential decay representations in learning to\nplay video games at different levels of complexity. In these environments, SITH\nexhibits better learning performance by storing information for longer\ntimescales than a fixed-size buffer, and representing this information more\nclearly than a set of exponentially decayed features. Finally, we discuss how\nthe application of SITH, along with other human-inspired models of cognition,\ncould improve reinforcement and machine learning algorithms in general.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 19:33:02 GMT"}, {"version": "v2", "created": "Sat, 11 Aug 2018 03:17:31 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 16:50:32 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Spears", "Tyler A.", ""], ["Jacques", "Brandon G.", ""], ["Howard", "Marc W.", ""], ["Sederberg", "Per B.", ""]]}, {"id": "1712.07199", "submitter": "Rajesh Bordawekar", "authors": "Rajesh Bordawekar and Bortik Bandyopadhyay and Oded Shmueli", "title": "Cognitive Database: A Step towards Endowing Relational Databases with\n  Artificial Intelligence Capabilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Cognitive Databases, an approach for transparently enabling\nArtificial Intelligence (AI) capabilities in relational databases. A novel\naspect of our design is to first view the structured data source as meaningful\nunstructured text, and then use the text to build an unsupervised neural\nnetwork model using a Natural Language Processing (NLP) technique called word\nembedding. This model captures the hidden inter-/intra-column relationships\nbetween database tokens of different types. For each database token, the model\nincludes a vector that encodes contextual semantic relationships. We seamlessly\nintegrate the word embedding model into existing SQL query infrastructure and\nuse it to enable a new class of SQL-based analytics queries called cognitive\nintelligence (CI) queries. CI queries use the model vectors to enable complex\nqueries such as semantic matching, inductive reasoning queries such as\nanalogies, predictive queries using entities not present in a database, and,\nmore generally, using knowledge from external sources. We demonstrate unique\ncapabilities of Cognitive Databases using an Apache Spark based prototype to\nexecute inductive reasoning CI queries over a multi-modal database containing\ntext and images. We believe our first-of-a-kind system exemplifies using AI\nfunctionality to endow relational databases with capabilities that were\npreviously very hard to realize in practice.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 20:49:26 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Bordawekar", "Rajesh", ""], ["Bandyopadhyay", "Bortik", ""], ["Shmueli", "Oded", ""]]}, {"id": "1712.07257", "submitter": "Naiyan Wang", "authors": "Jianfu Zhang, Naiyan Wang, Liqing Zhang", "title": "Multi-shot Pedestrian Re-identification via Sequential Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-shot pedestrian re-identification problem is at the core of\nsurveillance video analysis. It matches two tracks of pedestrians from\ndifferent cameras. In contrary to existing works that aggregate single frames\nfeatures by time series model such as recurrent neural network, in this paper,\nwe propose an interpretable reinforcement learning based approach to this\nproblem. Particularly, we train an agent to verify a pair of images at each\ntime. The agent could choose to output the result (same or different) or\nrequest another pair of images to verify (unsure). By this way, our model\nimplicitly learns the difficulty of image pairs, and postpone the decision when\nthe model does not accumulate enough evidence. Moreover, by adjusting the\nreward for unsure action, we can easily trade off between speed and accuracy.\nIn three open benchmarks, our method are competitive with the state-of-the-art\nmethods while only using 3% to 6% images. These promising results demonstrate\nthat our method is favorable in both efficiency and performance.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 23:24:04 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 02:53:06 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Zhang", "Jianfu", ""], ["Wang", "Naiyan", ""], ["Zhang", "Liqing", ""]]}, {"id": "1712.07312", "submitter": "Wellington Pinheiro dos Santos", "authors": "Filipe Rolim Cordeiro, Wellington Pinheiro dos Santos, Abel\n  Guilhermino da Silva Filho", "title": "Analysis of supervised and semi-supervised GrowCut applied to\n  segmentation of masses in mammography images", "comments": null, "journal-ref": "Computer Methods in Biomechanics and Biomedical Engineering:\n  Imaging & Visualization, v. 5, p. 1-19, 2017", "doi": "10.1080/21681163.2015.1127775", "report-no": null, "categories": "cs.CV cs.AI cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer is already one of the most common form of cancer worldwide.\nMammography image analysis is still the most effective diagnostic method to\npromote the early detection of breast cancer. Accurately segmenting tumors in\ndigital mammography images is important to improve diagnosis capabilities of\nhealth specialists and avoid misdiagnosis. In this work, we evaluate the\nfeasibility of applying GrowCut to segment regions of tumor and we propose two\nGrowCut semi-supervised versions. All the analysis was performed by evaluating\nthe application of segmentation techniques to a set of images obtained from the\nMini-MIAS mammography image database. GrowCut segmentation was compared to\nRegion Growing, Active Contours, Random Walks and Graph Cut techniques.\nExperiments showed that GrowCut, when compared to the other techniques, was\nable to acquire better results for the metrics analyzed. Moreover, the proposed\nsemi-supervised versions of GrowCut was proved to have a clinically\nsatisfactory quality of segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 03:50:15 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Cordeiro", "Filipe Rolim", ""], ["Santos", "Wellington Pinheiro dos", ""], ["Filho", "Abel Guilhermino da Silva", ""]]}, {"id": "1712.07447", "submitter": "Michael Bukatin", "authors": "Michael Bukatin, Jon Anthony", "title": "Dataflow Matrix Machines and V-values: a Bridge between Programs and\n  Neural Nets", "comments": "28 pages, 5 figures; appeared in \"K + K = 120: Papers dedicated to\n  Laszlo Kalman and Andras Kornai on the occasion of their 60th birthdays\"\n  Festschrift; http://www.nytud.hu/kk120", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  1) Dataflow matrix machines (DMMs) generalize neural nets by replacing\nstreams of numbers with linear streams (streams supporting linear\ncombinations), allowing arbitrary input and output arities for activation\nfunctions, countable-sized networks with finite dynamically changeable active\npart capable of unbounded growth, and a very expressive self-referential\nmechanism.\n  2) DMMs are suitable for general-purpose programming, while retaining the key\nproperty of recurrent neural networks: programs are expressed via matrices of\nreal numbers, and continuous changes to those matrices produce arbitrarily\nsmall variations in the associated programs.\n  3) Spaces of V-values (vector-like elements based on nested maps) are\nparticularly useful, enabling DMMs with variadic activation functions and\nconveniently representing conventional data structures.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 12:34:17 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 13:24:05 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Bukatin", "Michael", ""], ["Anthony", "Jon", ""]]}, {"id": "1712.08314", "submitter": "Ekaba Bisong", "authors": "Ekaba Bisong", "title": "Benchmarking Decoupled Neural Interfaces with Synthetic Gradients", "comments": "Serious issues with the content and not appropriate for high-level\n  academic distribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Artifical Neural Networks are a particular class of learning systems modeled\nafter biological neural functions with an interesting penchant for Hebbian\nlearning, that is \"neurons that wire together, fire together\". However, unlike\ntheir natural counterparts, artificial neural networks have a close and\nstringent coupling between the modules of neurons in the network. This coupling\nor locking imposes upon the network a strict and inflexible structure that\nprevent layers in the network from updating their weights until a full\nfeed-forward and backward pass has occurred. Such a constraint though may have\nsufficed for a while, is now no longer feasible in the era of very-large-scale\nmachine learning, coupled with the increased desire for parallelization of the\nlearning process across multiple computing infrastructures. To solve this\nproblem, synthetic gradients (SG) with decoupled neural interfaces (DNI) are\nintroduced as a viable alternative to the backpropagation algorithm. This paper\nperforms a speed benchmark to compare the speed and accuracy capabilities of\nSG-DNI as opposed to a standard neural interface using multilayer perceptron\nMLP. SG-DNI shows good promise, in that it not only captures the learning\nproblem, it is also over 3-fold faster due to it asynchronous learning\ncapabilities.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 06:28:28 GMT"}, {"version": "v2", "created": "Sat, 6 Jan 2018 23:16:33 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 14:06:52 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Bisong", "Ekaba", ""]]}, {"id": "1712.08319", "submitter": "Kushagra Rastogi", "authors": "Kushagra Rastogi, Navreet Saini", "title": "Virtual Sensor Modelling using Neural Networks with Coefficient-based\n  Adaptive Weights and Biases Search Algorithm for Diesel Engines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the explosion in the field of Big Data and introduction of more\nstringent emission norms every three to five years, automotive companies must\nnot only continue to enhance the fuel economy ratings of their products, but\nalso provide valued services to their customers such as delivering engine\nperformance and health reports at regular intervals. A reasonable solution to\nboth issues is installing a variety of sensors on the engine. Sensor data can\nbe used to develop fuel economy features and will directly indicate engine\nperformance. However, mounting a plethora of sensors is impractical in a very\ncost-sensitive industry. Thus, virtual sensors can replace physical sensors by\nreducing cost while capturing essential engine data.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 07:06:34 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Rastogi", "Kushagra", ""], ["Saini", "Navreet", ""]]}, {"id": "1712.08521", "submitter": "Luiza Mici", "authors": "Luiza Mici and German I. Parisi and Stefan Wermter", "title": "An Incremental Self-Organizing Architecture for Sensorimotor Learning\n  and Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  During visuomotor tasks, robots must compensate for temporal delays inherent\nin their sensorimotor processing systems. Delay compensation becomes crucial in\na dynamic environment where the visual input is constantly changing, e.g.,\nduring the interacting with a human demonstrator. For this purpose, the robot\nmust be equipped with a prediction mechanism for using the acquired perceptual\nexperience to estimate possible future motor commands. In this paper, we\npresent a novel neural network architecture that learns prototypical visuomotor\nrepresentations and provides reliable predictions on the basis of the visual\ninput. These predictions are used to compensate for the delayed motor behavior\nin an online manner. We investigate the performance of our method with a set of\nexperiments comprising a humanoid robot that has to learn and generate visually\nperceived arm motion trajectories. We evaluate the accuracy in terms of mean\nprediction error and analyze the response of the network to novel movement\ndemonstrations. Additionally, we report experiments with incomplete data\nsequences, showing the robustness of the proposed architecture in the case of a\nnoisy and faulty visual sensor.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 15:34:19 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 15:21:24 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Mici", "Luiza", ""], ["Parisi", "German I.", ""], ["Wermter", "Stefan", ""]]}, {"id": "1712.08608", "submitter": "Peter Sadowski", "authors": "Pierre Baldi, Peter Sadowski, Zhiqin Lu", "title": "Learning in the Machine: the Symmetries of the Deep Learning Channel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a physical neural system, learning rules must be local both in space and\ntime. In order for learning to occur, non-local information must be\ncommunicated to the deep synapses through a communication channel, the deep\nlearning channel. We identify several possible architectures for this learning\nchannel (Bidirectional, Conjoined, Twin, Distinct) and six symmetry challenges:\n1) symmetry of architectures; 2) symmetry of weights; 3) symmetry of neurons;\n4) symmetry of derivatives; 5) symmetry of processing; and 6) symmetry of\nlearning rules. Random backpropagation (RBP) addresses the second and third\nsymmetry, and some of its variations, such as skipped RBP (SRBP) address the\nfirst and the fourth symmetry. Here we address the last two desirable\nsymmetries showing through simulations that they can be achieved and that the\nlearning channel is particularly robust to symmetry variations. Specifically,\nrandom backpropagation and its variations can be performed with the same\nnon-linear neurons used in the main input-output forward channel, and the\nconnections in the learning channel can be adapted using the same algorithm\nused in the forward channel, removing the need for any specialized hardware in\nthe learning channel. Finally, we provide mathematical results in simple cases\nshowing that the learning equations in the forward and backward channels\nconverge to fixed points, for almost any initial conditions. In symmetric\narchitectures, if the weights in both channels are small at initialization,\nadaptation in both channels leads to weights that are essentially symmetric\nduring and after learning. Biological connections are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 18:43:58 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Baldi", "Pierre", ""], ["Sadowski", "Peter", ""], ["Lu", "Zhiqin", ""]]}, {"id": "1712.08702", "submitter": "Yan Ru Pei", "authors": "Yan Ru Pei, Fabio L. Traversa, and Massimiliano Di Ventra", "title": "On the Universality of Memcomputing Machines", "comments": "10 pages, 2 figures", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems (\n  Volume: 30 , Issue: 6 , June 2019 )", "doi": "10.1109/TNNLS.2018.2872676", "report-no": null, "categories": "cs.NE cs.ET", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Universal memcomputing machines (UMMs) [IEEE Trans. Neural Netw. Learn. Syst.\n26, 2702 (2015)] represent a novel computational model in which memory (time\nnon-locality) accomplishes both tasks of storing and processing of information.\nUMMs have been shown to be Turing-complete, namely they can simulate any Turing\nmachine. In this paper, using set theory and cardinality arguments, we compare\nthem with liquid-state machines (or \"reservoir computing\") and quantum machines\n(\"quantum computing\"). We show that UMMs can simulate both types of machines,\nhence they are both \"liquid-\" or \"reservoir-complete\" and \"quantum-complete\".\nOf course, these statements pertain only to the type of problems these machines\ncan solve, and not to the amount of resources required for such simulations.\nNonetheless, the method presented here provides a general framework in which to\ndescribe the relation between UMMs and any other type of computational model.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 02:30:25 GMT"}, {"version": "v2", "created": "Fri, 10 May 2019 21:16:11 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Pei", "Yan Ru", ""], ["Traversa", "Fabio L.", ""], ["Di Ventra", "Massimiliano", ""]]}, {"id": "1712.08969", "submitter": "Greg Yang", "authors": "Greg Yang, Samuel S. Schoenholz", "title": "Mean Field Residual Networks: On the Edge of Chaos", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn cs.LG math.DS nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study randomly initialized residual networks using mean field theory and\nthe theory of difference equations. Classical feedforward neural networks, such\nas those with tanh activations, exhibit exponential behavior on the average\nwhen propagating inputs forward or gradients backward. The exponential forward\ndynamics causes rapid collapsing of the input space geometry, while the\nexponential backward dynamics causes drastic vanishing or exploding gradients.\nWe show, in contrast, that by adding skip connections, the network will,\ndepending on the nonlinearity, adopt subexponential forward and backward\ndynamics, and in many cases in fact polynomial. The exponents of these\npolynomials are obtained through analytic methods and proved and verified\nempirically to be correct. In terms of the \"edge of chaos\" hypothesis, these\nsubexponential and polynomial laws allow residual networks to \"hover over the\nboundary between stability and chaos,\" thus preserving the geometry of the\ninput space and the gradient information flow. In our experiments, for each\nactivation function we study here, we initialize residual networks with\ndifferent hyperparameters and train them on MNIST. Remarkably, our\ninitialization time theory can accurately predict test time performance of\nthese networks, by tracking either the expected amount of gradient explosion or\nthe expected squared distance between the images of two input vectors.\nImportantly, we show, theoretically as well as empirically, that common\ninitializations such as the Xavier or the He schemes are not optimal for\nresidual networks, because the optimal initialization variances depend on the\ndepth. Finally, we have made mathematical contributions by deriving several new\nidentities for the kernels of powers of ReLU functions by relating them to the\nzeroth Bessel function of the second kind.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 21:51:08 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Yang", "Greg", ""], ["Schoenholz", "Samuel S.", ""]]}, {"id": "1712.09014", "submitter": "Michael Gagen Dr", "authors": "M. J. Gagen", "title": "Null Dynamical State Models of Human Cognitive Dysfunction", "comments": "17 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hard problem in artificial intelligence asks how the shuffling of\nsyntactical symbols in a program can lead to systems which experience semantics\nand qualia. We address this question in three stages. First, we introduce a new\nclass of human semantic symbols which appears when unexpected and drastic\nenvironmental change causes humans to become surprised, confused, uncertain,\nand in extreme cases, unresponsive, passive and dysfunctional. For this class\nof symbols, pre-learned programs become inoperative so these syntactical\nprograms cannot be the source of experienced qualia. Second, we model the\ndysfunctional human response to a radically changed environment as being the\nnatural response of any learning machine facing novel inputs from well outside\nits previous training set. In this situation, learning machines are unable to\nextract information from their input and will typically enter a dynamical state\ncharacterized by null outputs and a lack of response. This state immediately\npredicts and explains the characteristics of the semantic experiences of humans\nin similar circumstances. In the third stage, we consider learning machines\ntrained to implement multiple functions in simple sequential programs using\nenvironmental data to specify subroutine names, control flow instructions,\nmemory calls, and so on. Drastic change in any of these environmental inputs\ncan again lead to inoperative programs. By examining changes specific to people\nor locations we can model human cognitive symbols featuring these dependencies,\nsuch as attachment and grief. Our approach links known dynamical machines\nstates with human qualia and thus offers new insight into the hard problem of\nartificial intelligence.\n", "versions": [{"version": "v1", "created": "Mon, 25 Dec 2017 05:46:19 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Gagen", "M. J.", ""]]}, {"id": "1712.09206", "submitter": "Priyadarshini Panda", "authors": "Priyadarshini Panda, and Kaushik Roy", "title": "Chaos-guided Input Structuring for Improved Learning in Recurrent Neural\n  Networks", "comments": "11 pages with 5 figures including supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anatomical studies demonstrate that brain reformats input information to\ngenerate reliable responses for performing computations. However, it remains\nunclear how neural circuits encode complex spatio-temporal patterns. We show\nthat neural dynamics are strongly influenced by the phase alignment between the\ninput and the spontaneous chaotic activity. Input structuring along the\ndominant chaotic projections causes the chaotic trajectories to become stable\nchannels (or attractors), hence, improving the computational capability of a\nrecurrent network. Using mean field analysis, we derive the impact of input\nstructuring on the overall stability of attractors formed. Our results indicate\nthat input alignment determines the extent of intrinsic noise suppression and\nhence, alters the attractor state stability, thereby controlling the network's\ninference ability.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 08:29:32 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 15:53:23 GMT"}, {"version": "v3", "created": "Sun, 18 Feb 2018 18:58:48 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Panda", "Priyadarshini", ""], ["Roy", "Kaushik", ""]]}, {"id": "1712.09331", "submitter": "Subhash Kak", "authors": "Subhash Kak", "title": "Learning Based on CC1 and CC4 Neural Networks", "comments": "5 pages.arXiv admin note: text overlap with arXiv:0809.5087; text\n  overlap with arXiv:cs/0601129 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose that a general learning system should have three kinds of agents\ncorresponding to sensory, short-term, and long-term memory that implicitly will\nfacilitate context-free and context-sensitive aspects of learning. These three\nagents perform mututally complementary functions that capture aspects of the\nhuman cognition system. We investigate the use of CC1 and CC4 networks for use\nas models of short-term and sensory memory.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 19:30:51 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Kak", "Subhash", ""]]}, {"id": "1712.09662", "submitter": "Qiming Chen", "authors": "Qiming Chen, Ren Wu", "title": "CNN Is All You Need", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Convolution Neural Network (CNN) has demonstrated the unique advantage in\naudio, image and text learning; recently it has also challenged Recurrent\nNeural Networks (RNNs) with long short-term memory cells (LSTM) in\nsequence-to-sequence learning, since the computations involved in CNN are\neasily parallelizable whereas those involved in RNN are mostly sequential,\nleading to a performance bottleneck. However, unlike RNN, the native CNN lacks\nthe history sensitivity required for sequence transformation; therefore\nenhancing the sequential order awareness, or position-sensitivity, becomes the\nkey to make CNN the general deep learning model. In this work we introduce an\nextended CNN model with strengthen position-sensitivity, called PoseNet. A\nnotable feature of PoseNet is the asymmetric treatment of position information\nin the encoder and the decoder. Experiments shows that PoseNet allows us to\nimprove the accuracy of CNN based sequence-to-sequence learning significantly,\nachieving around 33-36 BLEU scores on the WMT 2014 English-to-German\ntranslation task, and around 44-46 BLEU scores on the English-to-French\ntranslation task.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 19:49:09 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Chen", "Qiming", ""], ["Wu", "Ren", ""]]}, {"id": "1712.09687", "submitter": "Tim Rockt\\\"aschel", "authors": "Tim Rockt\\\"aschel", "title": "Combining Representation Learning with Logic for Language Processing", "comments": "PhD Thesis, University College London, Submitted and accepted in 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current state-of-the-art in many natural language processing and\nautomated knowledge base completion tasks is held by representation learning\nmethods which learn distributed vector representations of symbols via\ngradient-based optimization. They require little or no hand-crafted features,\nthus avoiding the need for most preprocessing steps and task-specific\nassumptions. However, in many cases representation learning requires a large\namount of annotated training data to generalize well to unseen data. Such\nlabeled training data is provided by human annotators who often use formal\nlogic as the language for specifying annotations. This thesis investigates\ndifferent combinations of representation learning methods with logic for\nreducing the need for annotated training data, and for improving\ngeneralization.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 21:09:36 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Rockt\u00e4schel", "Tim", ""]]}, {"id": "1712.09709", "submitter": "Qiangeng Xu", "authors": "Qiangeng Xu, John Kender", "title": "Report: Dynamic Eye Movement Matching and Visualization Tool in Neuro\n  Gesture", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the research of the impact of gestures using by a lecturer, one\nchallenging task is to infer the attention of a group of audiences. Two\nimportant measurements that can help infer the level of attention are eye\nmovement data and Electroencephalography (EEG) data. Under the fundamental\nassumption that a group of people would look at the same place if they all pay\nattention at the same time, we apply a method, \"Time Warp Edit Distance\", to\ncalculate the similarity of their eye movement trajectories. Moreover, we also\ncluster eye movement pattern of audiences based on these pair-wised similarity\nmetrics. Besides, since we don't have a direct metric for the \"attention\"\nground truth, a visual assessment would be beneficial to evaluate the\ngesture-attention relationship. Thus we also implement a visualization tool.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 23:26:30 GMT"}, {"version": "v2", "created": "Sun, 7 Jan 2018 18:36:29 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Xu", "Qiangeng", ""], ["Kender", "John", ""]]}, {"id": "1712.09926", "submitter": "Tsendsuren Munkhdalai", "authors": "Tsendsuren Munkhdalai, Xingdi Yuan, Soroush Mehri, and Adam Trischler", "title": "Rapid Adaptation with Conditionally Shifted Neurons", "comments": "ICML 2018; Added: additional ablation and speed comparison with\n  MetaNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a mechanism by which artificial neural networks can learn rapid\nadaptation - the ability to adapt on the fly, with little data, to new tasks -\nthat we call conditionally shifted neurons. We apply this mechanism in the\nframework of metalearning, where the aim is to replicate some of the\nflexibility of human learning in machines. Conditionally shifted neurons modify\ntheir activation values with task-specific shifts retrieved from a memory\nmodule, which is populated rapidly based on limited task experience. On\nmetalearning benchmarks from the vision and language domains, models augmented\nwith conditionally shifted neurons achieve state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 16:47:13 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 15:27:42 GMT"}, {"version": "v3", "created": "Tue, 3 Jul 2018 18:04:34 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Munkhdalai", "Tsendsuren", ""], ["Yuan", "Xingdi", ""], ["Mehri", "Soroush", ""], ["Trischler", "Adam", ""]]}, {"id": "1712.10062", "submitter": "Aditya Gilra", "authors": "Marco Martinolli, Wulfram Gerstner and Aditya Gilra", "title": "Multi-timescale memory dynamics in a reinforcement learning network with\n  attention-gated memory", "comments": null, "journal-ref": "Frontiers in Computational Neuroscience, 12 July 2018 |\n  https://doi.org/10.3389/fncom.2018.00050", "doi": "10.3389/fncom.2018.00050", "report-no": null, "categories": "q-bio.NC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning and memory are intertwined in our brain and their relationship is at\nthe core of several recent neural network models. In particular, the\nAttention-Gated MEmory Tagging model (AuGMEnT) is a reinforcement learning\nnetwork with an emphasis on biological plausibility of memory dynamics and\nlearning. We find that the AuGMEnT network does not solve some hierarchical\ntasks, where higher-level stimuli have to be maintained over a long time, while\nlower-level stimuli need to be remembered and forgotten over a shorter\ntimescale. To overcome this limitation, we introduce hybrid AuGMEnT, with leaky\nor short-timescale and non-leaky or long-timescale units in memory, that allow\nto exchange lower-level information while maintaining higher-level one, thus\nsolving both hierarchical and distractor tasks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 21:26:43 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Martinolli", "Marco", ""], ["Gerstner", "Wulfram", ""], ["Gilra", "Aditya", ""]]}, {"id": "1712.10158", "submitter": "Aditya Gilra", "authors": "Aditya Gilra and Wulfram Gerstner", "title": "Non-linear motor control by local learning in spiking neural networks", "comments": null, "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:1773-1782, 2018", "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning weights in a spiking neural network with hidden neurons, using\nlocal, stable and online rules, to control non-linear body dynamics is an open\nproblem. Here, we employ a supervised scheme, Feedback-based Online Local\nLearning Of Weights (FOLLOW), to train a network of heterogeneous spiking\nneurons with hidden layers, to control a two-link arm so as to reproduce a\ndesired state trajectory. The network first learns an inverse model of the\nnon-linear dynamics, i.e. from state trajectory as input to the network, it\nlearns to infer the continuous-time command that produced the trajectory.\nConnection weights are adjusted via a local plasticity rule that involves\npre-synaptic firing and post-synaptic feedback of the error in the inferred\ncommand. We choose a network architecture, termed differential feedforward,\nthat gives the lowest test error from different feedforward and recurrent\narchitectures. The learned inverse model is then used to generate a\ncontinuous-time motor command to control the arm, given a desired trajectory.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 09:21:34 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Gilra", "Aditya", ""], ["Gerstner", "Wulfram", ""]]}]