[{"id": "1803.00052", "submitter": "Saptarshi Das", "authors": "Indranil Pan and Saptarshi Das", "title": "Evolving Chaos: Identifying New Attractors of the Generalised Lorenz\n  Family", "comments": "103 pages, 169 figures, Applied Mathematical Modelling, 2018", "journal-ref": null, "doi": "10.1016/j.apm.2018.01.015", "report-no": null, "categories": "nlin.CD cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper, we presented an intelligent evolutionary search technique\nthrough genetic programming (GP) for finding new analytical expressions of\nnonlinear dynamical systems, similar to the classical Lorenz attractor's which\nalso exhibit chaotic behaviour in the phase space. In this paper, we extend our\nprevious finding to explore yet another gallery of new chaotic attractors which\nare derived from the original Lorenz system of equations. Compared to the\nprevious exploration with sinusoidal type transcendental nonlinearity, here we\nfocus on only cross-product and higher-power type nonlinearities in the three\nstate equations. We here report over 150 different structures of chaotic\nattractors along with their one set of parameter values, phase space dynamics\nand the Largest Lyapunov Exponents (LLE). The expressions of these new\nLorenz-like nonlinear dynamical systems have been automatically evolved through\nmulti-gene genetic programming (MGGP). In the past two decades, there have been\nmany claims of designing new chaotic attractors as an incremental extension of\nthe Lorenz family. We provide here a large family of chaotic systems whose\nstructure closely resemble the original Lorenz system but with drastically\ndifferent phase space dynamics. This advances the state of the art knowledge of\ndiscovering new chaotic systems which can find application in many real-world\nproblems. This work may also find its archival value in future in the domain of\nnew chaotic system discovery.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jan 2018 14:21:52 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Pan", "Indranil", ""], ["Das", "Saptarshi", ""]]}, {"id": "1803.00152", "submitter": "Zhigang Ren", "authors": "An Chen, Yipeng Zhang, Zhigang Ren, Yongsheng Liang, Bei Pang", "title": "A Global Information Based Adaptive Threshold for Grouping Large Scale\n  Global Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By taking the idea of divide-and-conquer, cooperative coevolution (CC)\nprovides a powerful architecture for large scale global optimization (LSGO)\nproblems, but its efficiency relies highly on the decomposition strategy. It\nhas been shown that differential grouping (DG) performs well on decomposing\nLSGO problems by effectively detecting the interaction among decision\nvariables. However, its decomposition accuracy depends highly on the threshold.\nTo improve the decomposition accuracy of DG, a global information based\nadaptive threshold setting algorithm (GIAT) is proposed in this paper. On the\none hand, by reducing the sensitivity of the indicator in DG to the roundoff\nerror and the magnitude of contribution weight of subcomponent, we proposed a\nnew indicator for two variables which is much more sensitive to their\ninteraction. On the other hand, instead of setting the threshold only based on\none pair of variables, the threshold is generated from the interaction\ninformation for all pair of variables. By conducting the experiments on two\nsets of LSGO benchmark functions, the correctness and robustness of this new\nindicator and GIAT were verified.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 01:11:27 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Chen", "An", ""], ["Zhang", "Yipeng", ""], ["Ren", "Zhigang", ""], ["Liang", "Yongsheng", ""], ["Pang", "Bei", ""]]}, {"id": "1803.00227", "submitter": "Asit Mishra", "authors": "Asit Mishra and Debbie Marr", "title": "WRPN & Apprentice: Methods for Training and Inference using\n  Low-Precision Numerics", "comments": "Tech report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Today's high performance deep learning architectures involve large models\nwith numerous parameters. Low precision numerics has emerged as a popular\ntechnique to reduce both the compute and memory requirements of these large\nmodels. However, lowering precision often leads to accuracy degradation. We\ndescribe three schemes whereby one can both train and do efficient inference\nusing low precision numerics without hurting accuracy. Finally, we describe an\nefficient hardware accelerator that can take advantage of the proposed low\nprecision numerics.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 06:22:37 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Mishra", "Asit", ""], ["Marr", "Debbie", ""]]}, {"id": "1803.00338", "submitter": "Manuel Molano-Mazon", "authors": "Manuel Molano-Mazon, Arno Onken, Eugenio Piasini, Stefano Panzeri", "title": "Synthesizing realistic neural population activity patterns using\n  Generative Adversarial Networks", "comments": "Published as a conference paper at ICLR 2018 V2: minor changes in\n  supp. material", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to synthesize realistic patterns of neural activity is crucial\nfor studying neural information processing. Here we used the Generative\nAdversarial Networks (GANs) framework to simulate the concerted activity of a\npopulation of neurons. We adapted the Wasserstein-GAN variant to facilitate the\ngeneration of unconstrained neural population activity patterns while still\nbenefiting from parameter sharing in the temporal domain. We demonstrate that\nour proposed GAN, which we termed Spike-GAN, generates spike trains that match\naccurately the first- and second-order statistics of datasets of tens of\nneurons and also approximates well their higher-order statistics. We applied\nSpike-GAN to a real dataset recorded from salamander retina and showed that it\nperforms as well as state-of-the-art approaches based on the maximum entropy\nand the dichotomized Gaussian frameworks. Importantly, Spike-GAN does not\nrequire to specify a priori the statistics to be matched by the model, and so\nconstitutes a more flexible method than these alternative approaches. Finally,\nwe show how to exploit a trained Spike-GAN to construct 'importance maps' to\ndetect the most relevant statistical structures present in a spike train.\nSpike-GAN provides a powerful, easy-to-use technique for generating realistic\nspiking neural activity and for describing the most relevant features of the\nlarge-scale neural population recordings studied in modern systems\nneuroscience.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 12:30:22 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 08:26:53 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Molano-Mazon", "Manuel", ""], ["Onken", "Arno", ""], ["Piasini", "Eugenio", ""], ["Panzeri", "Stefano", ""]]}, {"id": "1803.00370", "submitter": "Masanori Suganuma", "authors": "Masanori Suganuma, Mete Ozay, Takayuki Okatani", "title": "Exploiting the Potential of Standard Convolutional Autoencoders for\n  Image Restoration by Evolutionary Search", "comments": "Our code is available at\n  https://github.com/sg-nm/Evolutionary-Autoencoders", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have applied deep neural networks to image restoration tasks, in\nwhich they proposed various network architectures, loss functions, and training\nmethods. In particular, adversarial training, which is employed in recent\nstudies, seems to be a key ingredient to success. In this paper, we show that\nsimple convolutional autoencoders (CAEs) built upon only standard network\ncomponents, i.e., convolutional layers and skip connections, can outperform the\nstate-of-the-art methods which employ adversarial training and sophisticated\nloss functions. The secret is to employ an evolutionary algorithm to\nautomatically search for good architectures. Training optimized CAEs by\nminimizing the $\\ell_2$ loss between reconstructed images and their ground\ntruths using the ADAM optimizer is all we need. Our experimental results show\nthat this approach achieves 27.8 dB peak signal to noise ratio (PSNR) on the\nCelebA dataset and 40.4 dB on the SVHN dataset, compared to 22.8 dB and 33.0 dB\nprovided by the former state-of-the-art methods, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 14:05:11 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Suganuma", "Masanori", ""], ["Ozay", "Mete", ""], ["Okatani", "Takayuki", ""]]}, {"id": "1803.00404", "submitter": "Ziang Yan", "authors": "Ziang Yan, Yiwen Guo, Changshui Zhang", "title": "Deep Defense: Training DNNs with Improved Adversarial Robustness", "comments": "Accepted by NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the efficacy on a variety of computer vision tasks, deep neural\nnetworks (DNNs) are vulnerable to adversarial attacks, limiting their\napplications in security-critical systems. Recent works have shown the\npossibility of generating imperceptibly perturbed image inputs (a.k.a.,\nadversarial examples) to fool well-trained DNN classifiers into making\narbitrary predictions. To address this problem, we propose a training recipe\nnamed \"deep defense\". Our core idea is to integrate an adversarial\nperturbation-based regularizer into the classification objective, such that the\nobtained models learn to resist potential attacks, directly and precisely. The\nwhole optimization problem is solved just like training a recursive network.\nExperimental results demonstrate that our method outperforms training with\nadversarial/Parseval regularizations by large margins on various datasets\n(including MNIST, CIFAR-10 and ImageNet) and different DNN architectures. Code\nand models for reproducing our results are available at\nhttps://github.com/ZiangYan/deepdefense.pytorch\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 05:02:59 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 01:59:20 GMT"}, {"version": "v3", "created": "Thu, 20 Dec 2018 01:53:51 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Yan", "Ziang", ""], ["Guo", "Yiwen", ""], ["Zhang", "Changshui", ""]]}, {"id": "1803.00412", "submitter": "Edward Frady", "authors": "E. Paxon Frady, Denis Kleyko, Friedrich T. Sommer", "title": "A theory of sequence indexing and working memory in recurrent neural\n  networks", "comments": "62 pages, 19 Figures, 85 equations, accepted in Neural Computation.\n  arXiv admin note: text overlap with arXiv:1707.01429", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To accommodate structured approaches of neural computation, we propose a\nclass of recurrent neural networks for indexing and storing sequences of\nsymbols or analog data vectors. These networks with randomized input weights\nand orthogonal recurrent weights implement coding principles previously\ndescribed in vector symbolic architectures (VSA), and leverage properties of\nreservoir computing. In general, the storage in reservoir computing is lossy\nand crosstalk noise limits the retrieval accuracy and information capacity. A\nnovel theory to optimize memory performance in such networks is presented and\ncompared with simulation experiments. The theory describes linear readout of\nanalog data, and readout with winner-take-all error correction of symbolic data\nas proposed in VSA models. We find that diverse VSA models from the literature\nhave universal performance properties, which are superior to what previous\nanalyses predicted. Further, we propose novel VSA models with the statistically\noptimal Wiener filter in the readout that exhibit much higher information\ncapacity, in particular for storing analog data.\n  The presented theory also applies to memory buffers, networks with gradual\nforgetting, which can operate on infinite data streams without memory overflow.\nInterestingly, we find that different forgetting mechanisms, such as\nattenuating recurrent weights or neural nonlinearities, produce very similar\nbehavior if the forgetting time constants are aligned. Such models exhibit\nextensive capacity when their forgetting time constant is optimized for given\nnoise conditions and network size. These results enable the design of new types\nof VSA models for the online processing of data streams.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 17:54:24 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Frady", "E. Paxon", ""], ["Kleyko", "Denis", ""], ["Sommer", "Friedrich T.", ""]]}, {"id": "1803.00447", "submitter": "Timoth\\'ee Masquelier Dr", "authors": "Timoth\\'ee Masquelier and Saeed Reza Kheradpisheh", "title": "Optimal localist and distributed coding of spatiotemporal spike patterns\n  through STDP and coincidence detection", "comments": "16 pages, 8 figures", "journal-ref": "Front. Comput. Neurosci. 12:74, 2018", "doi": "10.3389/fncom.2018.00074", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Repeating spatiotemporal spike patterns exist and carry information. Here we\ninvestigated how a single spiking neuron can optimally respond to one given\npattern (localist coding), or to either one of several patterns (distributed\ncoding, i.e. the neuron's response is ambiguous but the identity of the pattern\ncould be inferred from the response of multiple neurons), but not to random\ninputs. To do so, we extended a theory developed in a previous paper\n[Masquelier, 2017], which was limited to localist coding. More specifically, we\ncomputed analytically the signal-to-noise ratio (SNR) of a\nmulti-pattern-detector neuron, using a threshold-free leaky integrate-and-fire\n(LIF) neuron model with non-plastic unitary synapses and homogeneous Poisson\ninputs. Surprisingly, when increasing the number of patterns, the SNR decreases\nslowly, and remains acceptable for several tens of independent patterns.\n  In addition, we investigated whether spike-timing-dependent plasticity (STDP)\ncould enable a neuron to reach the theoretical optimal SNR. To this aim, we\nsimulated a LIF equipped with STDP, and repeatedly exposed it to multiple input\nspike patterns, embedded in equally dense Poisson spike trains. The LIF\nprogressively became selective to every repeating pattern with no supervision,\nand stopped discharging during the Poisson spike trains. Furthermore, using\ncertain STDP parameters, the resulting pattern detectors were optimal. Tens of\nindependent patterns could be learned by a single neuron using a low adaptive\nthreshold, in contrast with previous studies, in which higher thresholds led to\nlocalist coding only.\n  Taken together these results suggest that coincidence detection and STDP are\npowerful mechanisms, fully compatible with distributed coding. Yet we\nacknowledge that our theory is limited to single neurons, and thus also applies\nto feed-forward networks, but not to recurrent ones.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 15:34:01 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 08:09:58 GMT"}, {"version": "v3", "created": "Thu, 9 Aug 2018 12:22:17 GMT"}, {"version": "v4", "created": "Fri, 21 Sep 2018 08:41:51 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Masquelier", "Timoth\u00e9e", ""], ["Kheradpisheh", "Saeed Reza", ""]]}, {"id": "1803.00657", "submitter": "Dacheng Tao", "authors": "Chaoyue Wang, Chang Xu, Xin Yao, Dacheng Tao", "title": "Evolutionary Generative Adversarial Networks", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GAN) have been effective for learning\ngenerative models for real-world data. However, existing GANs (GAN and its\nvariants) tend to suffer from training problems such as instability and mode\ncollapse. In this paper, we propose a novel GAN framework called evolutionary\ngenerative adversarial networks (E-GAN) for stable GAN training and improved\ngenerative performance. Unlike existing GANs, which employ a pre-defined\nadversarial objective function alternately training a generator and a\ndiscriminator, we utilize different adversarial training objectives as mutation\noperations and evolve a population of generators to adapt to the environment\n(i.e., the discriminator). We also utilize an evaluation mechanism to measure\nthe quality and diversity of generated samples, such that only well-performing\ngenerator(s) are preserved and used for further training. In this way, E-GAN\novercomes the limitations of an individual adversarial training objective and\nalways preserves the best offspring, contributing to progress in and the\nsuccess of GANs. Experiments on several datasets demonstrate that E-GAN\nachieves convincing generative performance and reduces the training problems\ninherent in existing GANs.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 23:15:38 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Wang", "Chaoyue", ""], ["Xu", "Chang", ""], ["Yao", "Xin", ""], ["Tao", "Dacheng", ""]]}, {"id": "1803.00684", "submitter": "Boyuan Chen", "authors": "Boyuan Chen, Harvey Wu, Warren Mo, Ishanu Chattopadhyay, Hod Lipson", "title": "Autostacker: A Compositional Evolutionary Learning System", "comments": "Submitted to GECCO 2018 and currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an automatic machine learning (AutoML) modeling architecture\ncalled Autostacker, which combines an innovative hierarchical stacking\narchitecture and an Evolutionary Algorithm (EA) to perform efficient parameter\nsearch. Neither prior domain knowledge about the data nor feature preprocessing\nis needed. Using EA, Autostacker quickly evolves candidate pipelines with high\npredictive accuracy. These pipelines can be used as is or as a starting point\nfor human experts to build on. Autostacker finds innovative combinations and\nstructures of machine learning models, rather than selecting a single model and\noptimizing its hyperparameters. Compared with other AutoML systems on fifteen\ndatasets, Autostacker achieves state-of-art or competitive performance both in\nterms of test accuracy and time cost.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 02:02:38 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Chen", "Boyuan", ""], ["Wu", "Harvey", ""], ["Mo", "Warren", ""], ["Chattopadhyay", "Ishanu", ""], ["Lipson", "Hod", ""]]}, {"id": "1803.00838", "submitter": "Piotr Bialas", "authors": "P. Bialas, D. Nemeth, E. Richter-W\\k{a}s", "title": "A multi-instance deep neural network classifier: application to Higgs\n  boson CP measurement", "comments": "7 pages, 6 figures (fixed some misprints)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE hep-ex physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate properties of a classifier applied to the measurements of the\nCP state of the Higgs boson in $H\\rightarrow\\tau\\tau$ decays. The problem is\nframed as binary classifier applied to individual instances. Then the prior\nknowledge that the instances belong to the same class is used to define the\nmulti-instance classifier. Its final score is calculated as multiplication of\nsingle instance scores for a given series of instances. In the paper we discuss\nproperties of such classifier, notably its dependence on the number of\ninstances in the series. This classifier exhibits very strong random dependence\non the number of epochs used for training and requires careful tuning of the\nclassification threshold. We derive formula for this optimal threshold.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 13:13:04 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 15:41:46 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Bialas", "P.", ""], ["Nemeth", "D.", ""], ["Richter-W\u0105s", "E.", ""]]}, {"id": "1803.00906", "submitter": "Zhigang Ren", "authors": "Bei Pang, Zhigang Ren, Yongsheng Liang, An Chen", "title": "Enhancing Cooperative Coevolution for Large Scale Optimization by\n  Adaptively Constructing Surrogate Models", "comments": "arXiv admin note: text overlap with arXiv:1802.09746", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that cooperative coevolution (CC) can effectively deal with\nlarge scale optimization problems (LSOPs) through a divide-and-conquer\nstrategy. However, its performance is severely restricted by the current\ncontext-vector-based sub-solution evaluation method since this method needs to\naccess the original high dimensional simulation model when evaluating each\nsub-solution and thus requires many computation resources. To alleviate this\nissue, this study proposes an adaptive surrogate model assisted CC framework.\nThis framework adaptively constructs surrogate models for different\nsub-problems by fully considering their characteristics. For the single\ndimensional sub-problems obtained through decomposition, accurate enough\nsurrogate models can be obtained and used to find out the optimal solutions of\nthe corresponding sub-problems directly. As for the nonseparable sub-problems,\nthe surrogate models are employed to evaluate the corresponding sub-solutions,\nand the original simulation model is only adopted to reevaluate some good\nsub-solutions selected by surrogate models. By these means, the computation\ncost could be greatly reduced without significantly sacrificing evaluation\nquality. Empirical studies on IEEE CEC 2010 benchmark functions show that the\nconcrete algorithm based on this framework is able to find much better\nsolutions than the conventional CC algorithms and a non-CC algorithm even with\nmuch fewer computation resources.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 01:05:43 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Pang", "Bei", ""], ["Ren", "Zhigang", ""], ["Liang", "Yongsheng", ""], ["Chen", "An", ""]]}, {"id": "1803.00986", "submitter": "Zhigang Ren", "authors": "Yongsheng Liang, Zhigang Ren, Bei Pang, An Chen", "title": "Niching an Archive-based Gaussian Estimation of Distribution Algorithm\n  via Adaptive Clustering", "comments": "arXiv admin note: text overlap with arXiv:1802.08989", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a model-based evolutionary algorithm, estimation of distribution algorithm\n(EDA) possesses unique characteristics and has been widely applied to global\noptimization. However, traditional Gaussian EDA (GEDA) may suffer from\npremature convergence and has a high risk of falling into local optimum when\ndealing with multimodal problem. In this paper, we first attempts to improve\nthe performance of GEDA by utilizing historical solutions and develops a novel\narchive-based EDA variant. The use of historical solutions not only enhances\nthe search efficiency of EDA to a large extent, but also significantly reduces\nthe population size so that a faster convergence could be achieved. Then, the\narchive-based EDA is further integrated with a novel adaptive clustering\nstrategy for solving multimodal optimization problems. Taking the advantage of\nthe clustering strategy in locating different promising areas and the powerful\nexploitation ability of the archive-based EDA, the resultant algorithm is\nendowed with strong capability in finding multiple optima. To verify the\nefficiency of the proposed algorithm, we tested it on a set of well-known\nniching benchmark problems and compared it with several state-of-the-art\nniching algorithms. The experimental results indicate that the proposed\nalgorithm is competitive.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 01:38:03 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Liang", "Yongsheng", ""], ["Ren", "Zhigang", ""], ["Pang", "Bei", ""], ["Chen", "An", ""]]}, {"id": "1803.00997", "submitter": "Nima Dehghani", "authors": "Nima Dehghani, Ralf D. Wimmer", "title": "A computational perspective of the role of Thalamus in cognition", "comments": "A theoretical perspective on thalamic computation and its role in\n  cognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Thalamus has traditionally been considered as only a relay source of cortical\ninputs, with hierarchically organized cortical circuits serially transforming\nthalamic signals to cognitively-relevant representations. Given the absence of\nlocal excitatory connections within the thalamus, the notion of thalamic\n`relay' seemed like a reasonable description over the last several decades.\nRecent advances in experimental approaches and theory provide a broader\nperspective on the role of the thalamus in cognitively-relevant cortical\ncomputations, and suggest that only a subset of thalamic circuit motifs fit the\nrelay description. Here, we discuss this perspective and highlight the\npotential role for the thalamus -- and specifically mediodorsal (MD) nucleus --\nin dynamic selection of cortical representations through a combination of\nintrinsic thalamic computations and output signals that change cortical network\nfunctional parameters. We suggest that through the contextual modulation of\ncortical computation, thalamus and cortex jointly optimize the information/cost\ntradeoff in an emergent fashion. We emphasize that coordinated experimental and\ntheoretical efforts will provide a path to understanding the role of the\nthalamus in cognition, along with an understanding to augment cognitive\ncapacity in health and disease.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 18:58:41 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 05:10:17 GMT"}, {"version": "v3", "created": "Wed, 17 Oct 2018 00:48:10 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Dehghani", "Nima", ""], ["Wimmer", "Ralf D.", ""]]}, {"id": "1803.01097", "submitter": "Mingde Zhao", "authors": "Hongwei Ge, Mingde Zhao, Liang Sun, Zhen Wang, Guozhen Tan, Qiang\n  Zhang, C. L. Philip Chen", "title": "A Many-Objective Evolutionary Algorithm With Two Interacting Processes:\n  Cascade Clustering and Reference Point Incremental Learning", "comments": null, "journal-ref": "IEEE Transactions on Evolutionary Computation, 2019", "doi": "10.1109/TEVC.2018.2874465", "report-no": "IEEE Transactions on Evolutionary Computation (Volume: 23, Issue: 4,\n  Aug. 2019)", "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researches have shown difficulties in obtaining proximity while maintaining\ndiversity for many-objective optimization problems. Complexities of the true\nPareto front pose challenges for the reference vector-based algorithms for\ntheir insufficient adaptability to the diverse characteristics with no priori.\nThis paper proposes a many-objective optimization algorithm with two\ninteracting processes: cascade clustering and reference point incremental\nlearning (CLIA). In the population selection process based on cascade\nclustering (CC), using the reference vectors provided by the process based on\nincremental learning, the nondominated and the dominated individuals are\nclustered and sorted with different manners in a cascade style and are selected\nby round-robin for better proximity and diversity. In the reference vector\nadaptation process based on reference point incremental learning, using the\nfeedbacks from the process based on CC, proper distribution of reference points\nis gradually obtained by incremental learning. Experimental studies on several\nbenchmark problems show that CLIA is competitive compared with the\nstate-of-the-art algorithms and has impressive efficiency and versatility using\nonly the interactions between the two processes without incurring extra\nevaluations.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 02:53:09 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 03:26:30 GMT"}, {"version": "v3", "created": "Thu, 4 Oct 2018 01:01:35 GMT"}, {"version": "v4", "created": "Tue, 20 Aug 2019 07:51:59 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Ge", "Hongwei", ""], ["Zhao", "Mingde", ""], ["Sun", "Liang", ""], ["Wang", "Zhen", ""], ["Tan", "Guozhen", ""], ["Zhang", "Qiang", ""], ["Chen", "C. L. Philip", ""]]}, {"id": "1803.01425", "submitter": "Carola Doerr", "authors": "Carola Doerr and Markus Wagner", "title": "On the Effectiveness of Simple Success-Based Parameter Selection\n  Mechanisms for Two Classical Discrete Black-Box Optimization Benchmark\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant empirical and theoretically supported evidence that\nnon-static parameter choices can be strongly beneficial in evolutionary\ncomputation, the question how to best adjust parameter values plays only a\nmarginal role in contemporary research on discrete black-box optimization. This\nhas led to the unsatisfactory situation in which feedback-free parameter\nselection rules such as the cooling schedule of Simulated Annealing are\npredominant in state-of-the-art heuristics, while, at the same time, we\nunderstand very well that such time-dependent selection rules can only perform\nworse than adjustment rules that do take into account the evolution of the\noptimization process. A number of adaptive and self-adaptive parameter control\nstrategies have been proposed in the literature, but did not (yet) make their\nway to a broader public. A key obstacle seems to lie in their rather complex\nupdate rules.\n  The purpose of our work is to demonstrate that high-performing online\nparameter selection rules do not have to be very complicated. More precisely,\nwe experiment with a multiplicative, comparison-based update rule to adjust the\nmutation probability of a (1+1)~Evolutionary Algorithm. We show that this\nsimple self-adjusting rule outperforms the best static unary unbiased black-box\nalgorithm on LeadingOnes, achieving an almost optimal speedup of about~$18\\%$.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 21:29:56 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Doerr", "Carola", ""], ["Wagner", "Markus", ""]]}, {"id": "1803.01683", "submitter": "Brendan Cody-Kenny", "authors": "Brendan Cody-Kenny, Umberto Manganiello, John Farrelly, Adrian\n  Ronayne, Eoghan Considine, Thomas McGuire, Michael O'Neill", "title": "Investigating the Evolvability of Web Page Load Time", "comments": "8 Pages, to appear in EvoSET 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Client-side Javascript execution environments (browsers) allow anonymous\nfunctions and event-based programming concepts such as callbacks. We\ninvestigate whether a mutate-and-test approach can be used to optimise web page\nload time in these environments. First, we characterise a web page load issue\nin a benchmark web page and derive performance metrics from page load event\ntraces. We parse Javascript source code to an AST and make changes to method\ncalls which appear in a web page load event trace. We present an operator based\nsolely on code deletion and evaluate an existing \"community-contributed\"\nperformance optimising code transform. By exploring Javascript code changes and\nexploiting combinations of non-destructive changes, we can optimise page load\ntime by 41% in our benchmark web page.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 14:31:02 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Cody-Kenny", "Brendan", ""], ["Manganiello", "Umberto", ""], ["Farrelly", "John", ""], ["Ronayne", "Adrian", ""], ["Considine", "Eoghan", ""], ["McGuire", "Thomas", ""], ["O'Neill", "Michael", ""]]}, {"id": "1803.01686", "submitter": "Yuanhang Su", "authors": "Yuanhang Su, C.-C. Jay Kuo", "title": "On Extended Long Short-term Memory and Dependent Bidirectional Recurrent\n  Neural Network", "comments": "github repo: https://github.com/yuanhangsu/ELSTM-DBRNN", "journal-ref": "Neurocomputing 356 (2019): 151-161", "doi": "10.1016/j.neucom.2019.04.044", "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we first analyze the memory behavior in three recurrent neural\nnetworks (RNN) cells; namely, the simple RNN (SRN), the long short-term memory\n(LSTM) and the gated recurrent unit (GRU), where the memory is defined as a\nfunction that maps previous elements in a sequence to the current output. Our\nstudy shows that all three of them suffer rapid memory decay. Then, to\nalleviate this effect, we introduce trainable scaling factors that act like an\nattention mechanism to adjust memory decay adaptively. The new design is called\nthe extended LSTM (ELSTM). Finally, to design a system that is robust to\nprevious erroneous predictions, we propose a dependent bidirectional recurrent\nneural network (DBRNN). Extensive experiments are conducted on different\nlanguage tasks to demonstrate the superiority of the proposed ELSTM and DBRNN\nsolutions. The ELTSM has achieved up to 30% increase in the labeled attachment\nscore (LAS) as compared to LSTM and GRU in the dependency parsing (DP) task.\nOur models also outperform other state-of-the-art models such as bi-attention\nand convolutional sequence to sequence (convseq2seq) by close to 10% in the\nLAS. The code is released as an open source\n(https://github.com/yuanhangsu/ELSTM-DBRNN)\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 02:47:13 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2018 05:43:49 GMT"}, {"version": "v3", "created": "Sun, 3 Mar 2019 04:30:02 GMT"}, {"version": "v4", "created": "Tue, 14 May 2019 23:26:31 GMT"}, {"version": "v5", "created": "Sun, 17 Nov 2019 21:39:02 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Su", "Yuanhang", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "1803.01900", "submitter": "Rey Wiyatno", "authors": "Rey Wiyatno and Jeff Orchard", "title": "Style Memory: Making a Classifier Network Generative", "comments": "6 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks have shown great performance in classification tasks. However,\nthe parameters learned by the classifier networks usually discard stylistic\ninformation of the input, in favour of information strictly relevant to\nclassification. We introduce a network that has the capacity to do both\nclassification and reconstruction by adding a \"style memory\" to the output\nlayer of the network. We also show how to train such a neural network as a deep\nmulti-layer autoencoder, jointly minimizing both classification and\nreconstruction losses. The generative capacity of our network demonstrates that\nthe combination of style-memory neurons with the classifier neurons yield good\nreconstructions of the inputs when the classification is correct. We further\ninvestigate the nature of the style memory, and how it relates to composing\ndigits and letters. Finally, we propose that this architecture enables the\nbidirectional flow of information used in predictive coding, and that such\nbidirectional networks can help mitigate against being fooled by ambiguous or\nadversarial input.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 19:50:52 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Wiyatno", "Rey", ""], ["Orchard", "Jeff", ""]]}, {"id": "1803.02043", "submitter": "Savitha Ramasamy", "authors": "Savitha Ramasamy, Kanagasabai Rajaraman, Pavitra Krishnaswamy, Vijay\n  Chandrasekhar", "title": "Online Deep Learning: Growing RBM on the fly", "comments": "14 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel online learning algorithm for Restricted Boltzmann\nMachines (RBM), namely, the Online Generative Discriminative Restricted\nBoltzmann Machine (OGD-RBM), that provides the ability to build and adapt the\nnetwork architecture of RBM according to the statistics of streaming data. The\nOGD-RBM is trained in two phases: (1) an online generative phase for\nunsupervised feature representation at the hidden layer and (2) a\ndiscriminative phase for classification. The online generative training begins\nwith zero neurons in the hidden layer, adds and updates the neurons to adapt to\nstatistics of streaming data in a single pass unsupervised manner, resulting in\na feature representation best suited to the data. The discriminative phase is\nbased on stochastic gradient descent and associates the represented features to\nthe class labels. We demonstrate the OGD-RBM on a set of multi-category and\nbinary classification problems for data sets having varying degrees of\nclass-imbalance. We first apply the OGD-RBM algorithm on the multi-class MNIST\ndataset to characterize the network evolution. We demonstrate that the online\ngenerative phase converges to a stable, concise network architecture, wherein\nindividual neurons are inherently discriminative to the class labels despite\nunsupervised training. We then benchmark OGD-RBM performance to other machine\nlearning, neural network and ClassRBM techniques for credit scoring\napplications using 3 public non-stationary two-class credit datasets with\nvarying degrees of class-imbalance. We report that OGD-RBM improves accuracy by\n2.5-3% over batch learning techniques while requiring at least 24%-70% fewer\nneurons and fewer training samples. This online generative training approach\ncan be extended greedily to multiple layers for training Deep Belief Networks\nin non-stationary data mining applications without the need for a priori fixed\narchitectures.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 07:24:21 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Ramasamy", "Savitha", ""], ["Rajaraman", "Kanagasabai", ""], ["Krishnaswamy", "Pavitra", ""], ["Chandrasekhar", "Vijay", ""]]}, {"id": "1803.02627", "submitter": "Tobias Hinz", "authors": "Tobias Hinz, Stefan Wermter", "title": "Inferencing Based on Unsupervised Learning of Disentangled\n  Representations", "comments": "Accepted as a conference paper at the European Symposium on\n  Artificial Neural Networks, Computational Intelligence and Machine Learning\n  (ESANN) 2018, 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining Generative Adversarial Networks (GANs) with encoders that learn to\nencode data points has shown promising results in learning data representations\nin an unsupervised way. We propose a framework that combines an encoder and a\ngenerator to learn disentangled representations which encode meaningful\ninformation about the data distribution without the need for any labels. While\ncurrent approaches focus mostly on the generative aspects of GANs, our\nframework can be used to perform inference on both real and generated data\npoints. Experiments on several data sets show that the encoder learns\ninterpretable, disentangled representations which encode descriptive properties\nand can be used to sample images that exhibit specific characteristics.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 12:58:53 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Hinz", "Tobias", ""], ["Wermter", "Stefan", ""]]}, {"id": "1803.02738", "submitter": "Yan Anisimov", "authors": "Yan Anisimov, Alexandr Lysov, Dmitry Katsai", "title": "Neural network feedback controller for inertial platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper describes an algorithm for the synthesis of neural networks to\ncontrol gyro stabilizer. The neural network performs the role of observer for\nstate vector. The role of an observer in a feedback of gyro stabilizer is\nillustrated. Paper detail a problem specific features stage of classics\nalgorithm: choosing of network architecture, learning of neural network and\nverification of result feedback control. In the article presented optimal\nconfiguration of the neural network like a memory depth, the number of layers\nand neuron in these layers and activation functions in layers. Using the\ninformation of dynamic system for improving learning of neural network is\nprovided. A scheme creation of an optimal training sample is provided.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 16:08:11 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 14:11:05 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Anisimov", "Yan", ""], ["Lysov", "Alexandr", ""], ["Katsai", "Dmitry", ""]]}, {"id": "1803.02943", "submitter": "Sushil Louis", "authors": "Sushil J. Louis, Siming Liu", "title": "Multi-objective evolution for 3D RTS Micro", "comments": "Submitted to WCCI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We attack the problem of controlling teams of autonomous units during\nskirmishes in real-time strategy games. Earlier work had shown promise in\nevolving control algorithm parameters that lead to high performance team\nbehaviors similar to those favored by good human players in real-time strategy\ngames like Starcraft. This algorithm specifically encoded parameterized kiting\nand fleeing behaviors and the genetic algorithm evolved these parameter values.\nIn this paper we investigate using influence maps and potential fields alone to\ncompactly represent and control real-time team behavior for entities that can\nmaneuver in three dimensions. A two-objective fitness function that maximizes\ndamage done and minimizes damage taken guides our multi-objective evolutionary\nalgorithm. Preliminary results indicate that evolving friend and enemy unit\npotential field parameters for distance, weapon characteristics, and entity\nhealth suffice to produce complex, high performing, three-dimensional, team\ntactics.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 02:33:52 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Louis", "Sushil J.", ""], ["Liu", "Siming", ""]]}, {"id": "1803.03015", "submitter": "Chetan Singh Thakur", "authors": "Runchun Wang, Chetan Singh Thakur, Andre van Schaik", "title": "An FPGA-based Massively Parallel Neuromorphic Cortex Simulator", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a massively parallel and scalable neuromorphic cortex\nsimulator designed for simulating large and structurally connected spiking\nneural networks, such as complex models of various areas of the cortex. The\nmain novelty of this work is the abstraction of a neuromorphic architecture\ninto clusters represented by minicolumns and hypercolumns, analogously to the\nfundamental structural units observed in neurobiology. Without this approach,\nsimulating large-scale fully connected networks needs prohibitively large\nmemory to store look-up tables for point-to-point connections. Instead, we use\na novel architecture, based on the structural connectivity in the neocortex,\nsuch that all the required parameters and connections can be stored in on-chip\nmemory. The cortex simulator can be easily reconfigured for simulating\ndifferent neural networks without any change in hardware structure by\nprogramming the memory. A hierarchical communication scheme allows one neuron\nto have a fan-out of up to 200k neurons. As a proof-of-concept, an\nimplementation on one Altera Stratix V FPGA was able to simulate 20 million to\n2.6 billion leaky-integrate-and-fire (LIF) neurons in real time. We verified\nthe system by emulating a simplified auditory cortex (with 100 million\nneurons). This cortex simulator achieved a low power dissipation of 1.62 {\\mu}W\nper neuron. With the advent of commercially available FPGA boards, our system\noffers an accessible and scalable tool for the design, real-time simulation,\nand analysis of large-scale spiking neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 09:31:04 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Wang", "Runchun", ""], ["Thakur", "Chetan Singh", ""], ["van Schaik", "Andre", ""]]}, {"id": "1803.03232", "submitter": "Inigo Casanueva", "authors": "I\\~nigo Casanueva, Pawe{\\l} Budzianowski, Pei-Hao Su, Stefan Ultes,\n  Lina Rojas-Barahona, Bo-Hsiang Tseng and Milica Ga\\v{s}i\\'c", "title": "Feudal Reinforcement Learning for Dialogue Management in Large Domains", "comments": "Accepted as a short paper in NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is a promising approach to solve dialogue policy\noptimisation. Traditional RL algorithms, however, fail to scale to large\ndomains due to the curse of dimensionality. We propose a novel Dialogue\nManagement architecture, based on Feudal RL, which decomposes the decision into\ntwo steps; a first step where a master policy selects a subset of primitive\nactions, and a second step where a primitive action is chosen from the selected\nsubset. The structural information included in the domain ontology is used to\nabstract the dialogue state space, taking the decisions at each step using\ndifferent parts of the abstracted state. This, combined with an information\nsharing mechanism between slots, increases the scalability to large domains. We\nshow that an implementation of this approach, based on Deep-Q Networks,\nsignificantly outperforms previous state of the art in several dialogue domains\nand environments, without the need of any additional reward signal.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 18:05:18 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Casanueva", "I\u00f1igo", ""], ["Budzianowski", "Pawe\u0142", ""], ["Su", "Pei-Hao", ""], ["Ultes", "Stefan", ""], ["Rojas-Barahona", "Lina", ""], ["Tseng", "Bo-Hsiang", ""], ["Ga\u0161i\u0107", "Milica", ""]]}, {"id": "1803.03304", "submitter": "Ryan Pyle", "authors": "Ryan Pyle, Robert Rosenbaum", "title": "A model of reward-modulated motor learning with parallelcortical and\n  basal ganglia pathways", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent studies of the motor system are divided into two distinct\napproaches: Those that investigate how motor responses are encoded in cortical\nneurons' firing rate dynamics and those that study the learning rules by which\nmammals and songbirds develop reliable motor responses. Computationally, the\nfirst approach is encapsulated by reservoir computing models, which can learn\nintricate motor tasks and produce internal dynamics strikingly similar to those\nof motor cortical neurons, but rely on biologically unrealistic learning rules.\nThe more realistic learning rules developed by the second approach are often\nderived for simplified, discrete tasks in contrast to the intricate dynamics\nthat characterize real motor responses. We bridge these two approaches to\ndevelop a biologically realistic learning rule for reservoir computing. Our\nalgorithm learns simulated motor tasks on which previous reservoir computing\nalgorithms fail, and reproduces experimental findings including those that\nrelate motor learning to Parkinson's disease and its treatment.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 21:01:02 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 23:25:16 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Pyle", "Ryan", ""], ["Rosenbaum", "Robert", ""]]}, {"id": "1803.03453", "submitter": "Joel Lehman", "authors": "Joel Lehman, Jeff Clune, Dusan Misevic, Christoph Adami, Lee\n  Altenberg, Julie Beaulieu, Peter J. Bentley, Samuel Bernard, Guillaume\n  Beslon, David M. Bryson, Patryk Chrabaszcz, Nick Cheney, Antoine Cully,\n  Stephane Doncieux, Fred C. Dyer, Kai Olav Ellefsen, Robert Feldt, Stephan\n  Fischer, Stephanie Forrest, Antoine Fr\\'enoy, Christian Gagn\\'e, Leni Le\n  Goff, Laura M. Grabowski, Babak Hodjat, Frank Hutter, Laurent Keller, Carole\n  Knibbe, Peter Krcah, Richard E. Lenski, Hod Lipson, Robert MacCurdy, Carlos\n  Maestre, Risto Miikkulainen, Sara Mitri, David E. Moriarty, Jean-Baptiste\n  Mouret, Anh Nguyen, Charles Ofria, Marc Parizeau, David Parsons, Robert T.\n  Pennock, William F. Punch, Thomas S. Ray, Marc Schoenauer, Eric Shulte, Karl\n  Sims, Kenneth O. Stanley, Fran\\c{c}ois Taddei, Danesh Tarapore, Simon\n  Thibault, Westley Weimer, Richard Watson, Jason Yosinski", "title": "The Surprising Creativity of Digital Evolution: A Collection of\n  Anecdotes from the Evolutionary Computation and Artificial Life Research\n  Communities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological evolution provides a creative fount of complex and subtle\nadaptations, often surprising the scientists who discover them. However,\nbecause evolution is an algorithmic process that transcends the substrate in\nwhich it occurs, evolution's creativity is not limited to nature. Indeed, many\nresearchers in the field of digital evolution have observed their evolving\nalgorithms and organisms subverting their intentions, exposing unrecognized\nbugs in their code, producing unexpected adaptations, or exhibiting outcomes\nuncannily convergent with ones in nature. Such stories routinely reveal\ncreativity by evolution in these digital worlds, but they rarely fit into the\nstandard scientific narrative. Instead they are often treated as mere obstacles\nto be overcome, rather than results that warrant study in their own right. The\nstories themselves are traded among researchers through oral tradition, but\nthat mode of information transmission is inefficient and prone to error and\noutright loss. Moreover, the fact that these stories tend to be shared only\namong practitioners means that many natural scientists do not realize how\ninteresting and lifelike digital organisms are and how natural their evolution\ncan be. To our knowledge, no collection of such anecdotes has been published\nbefore. This paper is the crowd-sourced product of researchers in the fields of\nartificial life and evolutionary computation who have provided first-hand\naccounts of such cases. It thus serves as a written, fact-checked collection of\nscientifically important and even entertaining stories. In doing so we also\npresent here substantial evidence that the existence and importance of\nevolutionary surprises extends beyond the natural world, and may indeed be a\nuniversal property of all complex evolving systems.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 10:17:18 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 21:54:20 GMT"}, {"version": "v3", "created": "Tue, 14 Aug 2018 03:19:03 GMT"}, {"version": "v4", "created": "Thu, 21 Nov 2019 23:58:46 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Lehman", "Joel", ""], ["Clune", "Jeff", ""], ["Misevic", "Dusan", ""], ["Adami", "Christoph", ""], ["Altenberg", "Lee", ""], ["Beaulieu", "Julie", ""], ["Bentley", "Peter J.", ""], ["Bernard", "Samuel", ""], ["Beslon", "Guillaume", ""], ["Bryson", "David M.", ""], ["Chrabaszcz", "Patryk", ""], ["Cheney", "Nick", ""], ["Cully", "Antoine", ""], ["Doncieux", "Stephane", ""], ["Dyer", "Fred C.", ""], ["Ellefsen", "Kai Olav", ""], ["Feldt", "Robert", ""], ["Fischer", "Stephan", ""], ["Forrest", "Stephanie", ""], ["Fr\u00e9noy", "Antoine", ""], ["Gagn\u00e9", "Christian", ""], ["Goff", "Leni Le", ""], ["Grabowski", "Laura M.", ""], ["Hodjat", "Babak", ""], ["Hutter", "Frank", ""], ["Keller", "Laurent", ""], ["Knibbe", "Carole", ""], ["Krcah", "Peter", ""], ["Lenski", "Richard E.", ""], ["Lipson", "Hod", ""], ["MacCurdy", "Robert", ""], ["Maestre", "Carlos", ""], ["Miikkulainen", "Risto", ""], ["Mitri", "Sara", ""], ["Moriarty", "David E.", ""], ["Mouret", "Jean-Baptiste", ""], ["Nguyen", "Anh", ""], ["Ofria", "Charles", ""], ["Parizeau", "Marc", ""], ["Parsons", "David", ""], ["Pennock", "Robert T.", ""], ["Punch", "William F.", ""], ["Ray", "Thomas S.", ""], ["Schoenauer", "Marc", ""], ["Shulte", "Eric", ""], ["Sims", "Karl", ""], ["Stanley", "Kenneth O.", ""], ["Taddei", "Fran\u00e7ois", ""], ["Tarapore", "Danesh", ""], ["Thibault", "Simon", ""], ["Weimer", "Westley", ""], ["Watson", "Richard", ""], ["Yosinski", "Jason", ""]]}, {"id": "1803.03635", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle and Michael Carbin", "title": "The Lottery Ticket Hypothesis: Finding Sparse, Trainable Neural Networks", "comments": "ICLR camera ready", "journal-ref": "ICLR 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network pruning techniques can reduce the parameter counts of trained\nnetworks by over 90%, decreasing storage requirements and improving\ncomputational performance of inference without compromising accuracy. However,\ncontemporary experience is that the sparse architectures produced by pruning\nare difficult to train from the start, which would similarly improve training\nperformance.\n  We find that a standard pruning technique naturally uncovers subnetworks\nwhose initializations made them capable of training effectively. Based on these\nresults, we articulate the \"lottery ticket hypothesis:\" dense,\nrandomly-initialized, feed-forward networks contain subnetworks (\"winning\ntickets\") that - when trained in isolation - reach test accuracy comparable to\nthe original network in a similar number of iterations. The winning tickets we\nfind have won the initialization lottery: their connections have initial\nweights that make training particularly effective.\n  We present an algorithm to identify winning tickets and a series of\nexperiments that support the lottery ticket hypothesis and the importance of\nthese fortuitous initializations. We consistently find winning tickets that are\nless than 10-20% of the size of several fully-connected and convolutional\nfeed-forward architectures for MNIST and CIFAR10. Above this size, the winning\ntickets that we find learn faster than the original network and reach higher\ntest accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 18:51:28 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 19:58:09 GMT"}, {"version": "v3", "created": "Sun, 20 May 2018 19:46:47 GMT"}, {"version": "v4", "created": "Tue, 27 Nov 2018 20:03:01 GMT"}, {"version": "v5", "created": "Mon, 4 Mar 2019 15:51:11 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Frankle", "Jonathan", ""], ["Carbin", "Michael", ""]]}, {"id": "1803.03688", "submitter": "Alberto Delm\\'as", "authors": "Alberto Delmas, Patrick Judd, Dylan Malone Stuart, Zissis Poulos,\n  Mostafa Mahmoud, Sayeh Sharify, Milos Nikolic, Andreas Moshovos", "title": "Bit-Tactical: Exploiting Ineffectual Computations in Convolutional\n  Neural Networks: Which, Why, and How", "comments": "An earlier version of this work titled \"JaZ: Enabling Innovation\n  Towards Chaff-Free Deep Learning Computing\" was submitted for blind review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, during inference with Convolutional Neural Networks (CNNs),\nmore than 2x to $8x ineffectual work can be exposed if instead of targeting\nthose weights and activations that are zero, we target different combinations\nof value stream properties. We demonstrate a practical application with\nBit-Tactical (TCL), a hardware accelerator which exploits weight sparsity, per\nlayer precision variability and dynamic fine-grain precision reduction for\nactivations, and optionally the naturally occurring sparse effectual bit\ncontent of activations to improve performance and energy efficiency. TCL\nbenefits both sparse and dense CNNs, natively supports both convolutional and\nfully-connected layers, and exploits properties of all activations to reduce\nstorage, communication, and computation demands. While TCL does not require\nchanges to the CNN to deliver benefits, it does reward any technique that would\namplify any of the aforementioned weight and activation value properties.\nCompared to an equivalent data-parallel accelerator for dense CNNs, TCLp, a\nvariant of TCL improves performance by 5.05x and is 2.98x more energy efficient\nwhile requiring 22% more area.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 20:40:35 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Delmas", "Alberto", ""], ["Judd", "Patrick", ""], ["Stuart", "Dylan Malone", ""], ["Poulos", "Zissis", ""], ["Mahmoud", "Mostafa", ""], ["Sharify", "Sayeh", ""], ["Nikolic", "Milos", ""], ["Moshovos", "Andreas", ""]]}, {"id": "1803.03692", "submitter": "Zhinus Marzi", "authors": "Zhinus Marzi, Joao Hespanha and Upamanyu Madhow", "title": "On the information in spike timing: neural codes derived from\n  polychronous groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing evidence regarding the importance of spike timing in neural\ninformation processing, with even a small number of spikes carrying\ninformation, but computational models lag significantly behind those for rate\ncoding. Experimental evidence on neuronal behavior is consistent with the\ndynamical and state dependent behavior provided by recurrent connections. This\nmotivates the minimalistic abstraction investigated in this paper, aimed at\nproviding insight into information encoding in spike timing via recurrent\nconnections. We employ information-theoretic techniques for a simple reservoir\nmodel which encodes input spatiotemporal patterns into a sparse neural code,\ntranslating the polychronous groups introduced by Izhikevich into codewords on\nwhich we can perform standard vector operations. We show that the distance\nproperties of the code are similar to those for (optimal) random codes. In\nparticular, the code meets benchmarks associated with both linear\nclassification and capacity, with the latter scaling exponentially with\nreservoir size.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 20:53:31 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Marzi", "Zhinus", ""], ["Hespanha", "Joao", ""], ["Madhow", "Upamanyu", ""]]}, {"id": "1803.03737", "submitter": "Xin Qiu", "authors": "Xin Qiu and Risto Miikkulainen", "title": "Enhancing Evolutionary Conversion Rate Optimization via Multi-armed\n  Bandit Algorithms", "comments": "The Thirty-First Innovative Applications of Artificial Intelligence\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversion rate optimization means designing web interfaces such that more\nvisitors perform a desired action (such as register or purchase) on the site.\nOne promising approach, implemented in Sentient Ascend, is to optimize the\ndesign using evolutionary algorithms, evaluating each candidate design online\nwith actual visitors. Because such evaluations are costly and noisy, several\nchallenges emerge: How can available visitor traffic be used most efficiently?\nHow can good solutions be identified most reliably? How can a high conversion\nrate be maintained during optimization? This paper proposes a new technique to\naddress these issues. Traffic is allocated to candidate solutions using a\nmulti-armed bandit algorithm, using more traffic on those evaluations that are\nmost useful. In a best-arm identification mode, the best candidate can be\nidentified reliably at the end of evolution, and in a campaign mode, the\noverall conversion rate can be optimized throughout the entire evolution\nprocess. Multi-armed bandit algorithms thus improve performance and reliability\nof machine discovery in noisy real-world environments.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 02:07:46 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 18:52:46 GMT"}, {"version": "v3", "created": "Fri, 16 Nov 2018 06:05:29 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Qiu", "Xin", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "1803.03744", "submitter": "Hormoz Shahrzad", "authors": "Hormoz Shahrzad, Daniel Fink, Risto Miikkulainen", "title": "Enhanced Optimization with Composite Objectives and Novelty Selection", "comments": "7 pages", "journal-ref": "ALIFE 2018: The 2018 Conference on Artificial Life July 2018\n  p.616-622", "doi": "10.1162/isal_a_00113", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important benefit of multi-objective search is that it maintains a diverse\npopulation of candidates, which helps in deceptive problems in particular. Not\nall diversity is useful, however: candidates that optimize only one objective\nwhile ignoring others are rarely helpful. This paper proposes a solution: The\noriginal objectives are replaced by their linear combinations, thus focusing\nthe search on the most useful tradeoffs between objectives. To compensate for\nthe loss of diversity, this transformation is accompanied by a selection\nmechanism that favors novelty. In the highly deceptive problem of discovering\nminimal sorting networks, this approach finds better solutions, and finds them\nfaster and more consistently than standard methods. It is therefore a promising\napproach to solving deceptive problems through multi-objective optimization.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 02:32:39 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 23:26:24 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Shahrzad", "Hormoz", ""], ["Fink", "Daniel", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "1803.03745", "submitter": "Jason Liang", "authors": "Jason Liang, Elliot Meyerson, and Risto Miikkulainen", "title": "Evolutionary Architecture Search For Deep Multitask Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask learning, i.e. learning several tasks at once with the same neural\nnetwork, can improve performance in each of the tasks. Designing deep neural\nnetwork architectures for multitask learning is a challenge: There are many\nways to tie the tasks together, and the design choices matter. The size and\ncomplexity of this problem exceeds human design ability, making it a compelling\ndomain for evolutionary optimization. Using the existing state of the art soft\nordering architecture as the starting point, methods for evolving the modules\nof this architecture and for evolving the overall topology or routing between\nmodules are evaluated in this paper. A synergetic approach of evolving custom\nroutings with evolved, shared modules for each task is found to be very\npowerful, significantly improving the state of the art in the Omniglot\nmultitask, multialphabet character recognition domain. This result demonstrates\nhow evolution can be instrumental in advancing deep neural network and complex\nsystem design in general.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 03:02:09 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 18:46:05 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Liang", "Jason", ""], ["Meyerson", "Elliot", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "1803.04239", "submitter": "Konstantinos Pitas", "authors": "Konstantinos Pitas, Mike Davies, Pierre Vandergheynst", "title": "FeTa: A DCA Pruning Algorithm with Generalization Error Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent DNN pruning algorithms have succeeded in reducing the number of\nparameters in fully connected layers, often with little or no drop in\nclassification accuracy. However, most of the existing pruning schemes either\nhave to be applied during training or require a costly retraining procedure\nafter pruning to regain classification accuracy. We start by proposing a cheap\npruning algorithm for fully connected DNN layers based on difference of convex\nfunctions (DC) optimisation, that requires little or no retraining. We then\nprovide a theoretical analysis for the growth in the Generalization Error (GE)\nof a DNN for the case of bounded perturbations to the hidden layers, of which\nweight pruning is a special case. Our pruning method is orders of magnitude\nfaster than competing approaches, while our theoretical analysis sheds light to\npreviously observed problems in DNN pruning. Experiments on commnon feedforward\nneural networks validate our results.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 13:19:33 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Pitas", "Konstantinos", ""], ["Davies", "Mike", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "1803.04357", "submitter": "Cem Subakan", "authors": "Cem Subakan, Oluwasanmi Koyejo, Paris Smaragdis", "title": "Learning the Base Distribution in Implicit Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular generative model learning methods such as Generative Adversarial\nNetworks (GANs), and Variational Autoencoders (VAE) enforce the latent\nrepresentation to follow simple distributions such as isotropic Gaussian. In\nthis paper, we argue that learning a complicated distribution over the latent\nspace of an auto-encoder enables more accurate modeling of complicated data\ndistributions. Based on this observation, we propose a two stage optimization\nprocedure which maximizes an approximate implicit density model. We\nexperimentally verify that our method outperforms GANs and VAEs on two image\ndatasets (MNIST, CELEB-A). We also show that our approach is amenable to\nlearning generative model for sequential data, by learning to generate speech\nand music.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 16:24:33 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 22:40:35 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Subakan", "Cem", ""], ["Koyejo", "Oluwasanmi", ""], ["Smaragdis", "Paris", ""]]}, {"id": "1803.04439", "submitter": "Aditya Rawal", "authors": "Aditya Rawal and Risto Miikkulainen", "title": "From Nodes to Networks: Evolving Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gated recurrent networks such as those composed of Long Short-Term Memory\n(LSTM) nodes have recently been used to improve state of the art in many\nsequential processing tasks such as speech recognition and machine translation.\nHowever, the basic structure of the LSTM node is essentially the same as when\nit was first conceived 25 years ago. Recently, evolutionary and reinforcement\nlearning mechanisms have been employed to create new variations of this\nstructure. This paper proposes a new method, evolution of a tree-based encoding\nof the gated memory nodes, and shows that it makes it possible to explore new\nvariations more effectively than other methods. The method discovers nodes with\nmultiple recurrent paths and multiple memory cells, which lead to significant\nimprovement in the standard language modeling benchmark task. The paper also\nshows how the search process can be speeded up by training an LSTM network to\nestimate performance of candidate structures, and by encouraging exploration of\nnovel solutions. Thus, evolutionary design of complex neural network structures\npromises to improve performance of deep learning architectures beyond human\nability to do so.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 18:24:07 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 21:41:18 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Rawal", "Aditya", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "1803.04509", "submitter": "Tomas Gavenciak", "authors": "Tom\\'a\\v{s} Gaven\\v{c}iak, Barbara Geissmann, Johannes Lengler", "title": "Sorting by Swaps with Noisy Comparisons", "comments": "An extended abstract of this paper has been presented at Genetic and\n  Evolutionary Computation Conference (GECCO 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study sorting of permutations by random swaps if each comparison gives the\nwrong result with some fixed probability $p<1/2$. We use this process as\nprototype for the behaviour of randomized, comparison-based optimization\nheuristics in the presence of noisy comparisons. As quality measure, we compute\nthe expected fitness of the stationary distribution. To measure the runtime, we\ncompute the minimal number of steps after which the average fitness\napproximates the expected fitness of the stationary distribution.\n  We study the process where in each round a random pair of elements at\ndistance at most $r$ are compared. We give theoretical results for the extreme\ncases $r=1$ and $r=n$, and experimental results for the intermediate cases. We\nfind a trade-off between faster convergence (for large $r$) and better quality\nof the solution after convergence (for small $r$).\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 20:14:19 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Gaven\u010diak", "Tom\u00e1\u0161", ""], ["Geissmann", "Barbara", ""], ["Lengler", "Johannes", ""]]}, {"id": "1803.04773", "submitter": "Aditya Shukla", "authors": "Aditya Shukla, Sidharth Prasad, Sandip Lashkare, Udayan Ganguly", "title": "A case for multiple and parallel RRAMs as synaptic model for training\n  SNNs", "comments": "8 pages, 18 figures and 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To enable a dense integration of model synapses in a spiking neural networks\nhardware, various nano-scale devices are being considered. Such a device,\nbesides exhibiting spike-time dependent plasticity (STDP), needs to be highly\nscalable, have a large endurance and require low energy for transitioning\nbetween states. In this work, we first introduce and empirically determine two\nnew specifications for an synapse in SNNs: number of conductance levels per\nsynapse and maximum learning-rate. To the best of our knowledge, there are no\nRRAMs that meet the latter specification. As a solution, we propose the use of\nmultiple PCMO-RRAMs in parallel within a synapse. While synaptic reading, all\nPCMO-RRAMs are simultaneously read and for each synaptic conductance-change\nevent, the mechanism for conductance STDP is initiated for only one RRAM,\nrandomly picked from the set. Second, to validate our solution, we\nexperimentally demonstrate STDP of conductance of a PCMO-RRAM and then show\nthat due to a large learning-rate, a single PCMO-RRAM fails to model a synapse\nin the training of an SNN. As anticipated, network training improves as more\nPCMO-RRAMs are added to the synapse. Fourth, we discuss the\ncircuit-requirements for implementing such a scheme, to conclude that the\nrequirements are within bounds. Thus, our work presents specifications for\nsynaptic devices in trainable SNNs, indicates the shortcomings of state-of-art\nsynaptic contenders, and provides a solution to extrinsically meet the\nspecifications and discusses the peripheral circuitry that implements the\nsolution.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 13:13:59 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Shukla", "Aditya", ""], ["Prasad", "Sidharth", ""], ["Lashkare", "Sandip", ""], ["Ganguly", "Udayan", ""]]}, {"id": "1803.04813", "submitter": "Saptarshi Das", "authors": "Daya Shankar Pandey, Saptarshi Das, Indranil Pan, James J. Leahy,\n  Witold Kwapinski", "title": "Artificial neural network based modelling approach for municipal solid\n  waste gasification in a fluidized bed reactor", "comments": "34 pages, 11 figures", "journal-ref": "Waste Management (Elsevier), Volume 58, December 2016, Pages\n  202-213", "doi": "10.1016/j.wasman.2016.08.023", "report-no": null, "categories": "cs.LG cs.CE cs.NE physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, multi-layer feed forward neural networks are used to predict\nthe lower heating value of gas (LHV), lower heating value of gasification\nproducts including tars and entrained char (LHVp) and syngas yield during\ngasification of municipal solid waste (MSW) during gasification in a fluidized\nbed reactor. These artificial neural networks (ANNs) with different\narchitectures are trained using the Levenberg-Marquardt (LM) back-propagation\nalgorithm and a cross validation is also performed to ensure that the results\ngeneralise to other unseen datasets. A rigorous study is carried out on\noptimally choosing the number of hidden layers, number of neurons in the hidden\nlayer and activation function in a network using multiple Monte Carlo runs.\nNine input and three output parameters are used to train and test various\nneural network architectures in both multiple output and single output\nprediction paradigms using the available experimental datasets. The model\nselection procedure is carried out to ascertain the best network architecture\nin terms of predictive accuracy. The simulation results show that the ANN based\nmethodology is a viable alternative which can be used to predict the\nperformance of a fluidized bed gasifier.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 21:50:22 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Pandey", "Daya Shankar", ""], ["Das", "Saptarshi", ""], ["Pan", "Indranil", ""], ["Leahy", "James J.", ""], ["Kwapinski", "Witold", ""]]}, {"id": "1803.04884", "submitter": "Torsten Kilias", "authors": "Torsten Kilias, Alexander L\\\"oser, Felix A. Gers, Richard\n  Koopmanschap, Ying Zhang, Martin Kersten", "title": "IDEL: In-Database Entity Linking with Neural Embeddings", "comments": "This manuscript is a preprint for a paper submitted to VLDB2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CL cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel architecture, In-Database Entity Linking (IDEL), in which\nwe integrate the analytics-optimized RDBMS MonetDB with neural text mining\nabilities. Our system design abstracts core tasks of most neural entity linking\nsystems for MonetDB. To the best of our knowledge, this is the first defacto\nimplemented system integrating entity-linking in a database. We leverage the\nability of MonetDB to support in-database-analytics with user defined functions\n(UDFs) implemented in Python. These functions call machine learning libraries\nfor neural text mining, such as TensorFlow. The system achieves zero cost for\ndata shipping and transformation by utilizing MonetDB's ability to embed Python\nprocesses in the database kernel and exchange data in NumPy arrays. IDEL\nrepresents text and relational data in a joint vector space with neural\nembeddings and can compensate errors with ambiguous entity representations. For\ndetecting matching entities, we propose a novel similarity function based on\njoint neural embeddings which are learned via minimizing pairwise contrastive\nranking loss. This function utilizes a high dimensional index structures for\nfast retrieval of matching entities. Our first implementation and experiments\nusing the WebNLG corpus show the effectiveness and the potentials of IDEL.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 15:35:42 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Kilias", "Torsten", ""], ["L\u00f6ser", "Alexander", ""], ["Gers", "Felix A.", ""], ["Koopmanschap", "Richard", ""], ["Zhang", "Ying", ""], ["Kersten", "Martin", ""]]}, {"id": "1803.04967", "submitter": "Aaron Tuor", "authors": "Andy Brown, Aaron Tuor, Brian Hutchinson, Nicole Nichols", "title": "Recurrent Neural Network Attention Mechanisms for Interpretable System\n  Log Anomaly Detection", "comments": "Submitted to the First Workshop On Machine Learning for Computer\n  Systems, ACM HPDC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has recently demonstrated state-of-the art performance on key\ntasks related to the maintenance of computer systems, such as intrusion\ndetection, denial of service attack detection, hardware and software system\nfailures, and malware detection. In these contexts, model interpretability is\nvital for administrator and analyst to trust and act on the automated analysis\nof machine learning models. Deep learning methods have been criticized as black\nbox oracles which allow limited insight into decision factors. In this work we\nseek to \"bridge the gap\" between the impressive performance of deep learning\nmodels and the need for interpretable model introspection. To this end we\npresent recurrent neural network (RNN) language models augmented with attention\nfor anomaly detection in system logs. Our methods are generally applicable to\nany computer system and logging source.\n  By incorporating attention variants into our RNN language models we create\nopportunities for model introspection and analysis without sacrificing\nstate-of-the art performance.\n  We demonstrate model performance and illustrate model interpretability on an\nintrusion detection task using the Los Alamos National Laboratory (LANL) cyber\nsecurity dataset, reporting upward of 0.99 area under the receiver operator\ncharacteristic curve despite being trained only on a single day's worth of\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 08:09:20 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Brown", "Andy", ""], ["Tuor", "Aaron", ""], ["Hutchinson", "Brian", ""], ["Nichols", "Nicole", ""]]}, {"id": "1803.05006", "submitter": "Albert Lee", "authors": "Albert Lee, Bonnie Lam, Wenyuan Li, Hochul Lee, Wei-Hao Chen, Meng-Fan\n  Chang, and Kang. -L. Wang", "title": "Conditional Activation for Diverse Neurons in Heterogeneous Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new scheme for modelling the diverse behavior of\nneurons. We introduce the conditional activation, in which a neurons activation\nfunction is dynamically modified by a control signal. We apply this method to\nrecreate behavior of special neurons existing in the human auditory and visual\nsystem. A heterogeneous multilayered perceptron (MLP) incorporating the\ndeveloped models demonstrates simultaneous improvement in learning speed and\nperformance across a various number of hidden units and layers, compared to a\nhomogeneous network composed of the conventional neuron model. For similar\nperformance, the proposed model lowers the memory for storing network\nparameters significantly.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 18:59:05 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Lee", "Albert", ""], ["Lam", "Bonnie", ""], ["Li", "Wenyuan", ""], ["Lee", "Hochul", ""], ["Chen", "Wei-Hao", ""], ["Chang", "Meng-Fan", ""], ["Wang", "Kang. -L.", ""]]}, {"id": "1803.05030", "submitter": "ShiLiang Zhang", "authors": "Shiliang Zhang, Ming Lei, Zhijie Yan, Lirong Dai", "title": "Deep-FSMN for Large Vocabulary Continuous Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an improved feedforward sequential memory networks\n(FSMN) architecture, namely Deep-FSMN (DFSMN), by introducing skip connections\nbetween memory blocks in adjacent layers. These skip connections enable the\ninformation flow across different layers and thus alleviate the gradient\nvanishing problem when building very deep structure. As a result, DFSMN\nsignificantly benefits from these skip connections and deep structure. We have\ncompared the performance of DFSMN to BLSTM both with and without lower frame\nrate (LFR) on several large speech recognition tasks, including English and\nMandarin. Experimental results shown that DFSMN can consistently outperform\nBLSTM with dramatic gain, especially trained with LFR using CD-Phone as\nmodeling units. In the 2000 hours Fisher (FSH) task, the proposed DFSMN can\nachieve a word error rate of 9.4% by purely using the cross-entropy criterion\nand decoding with a 3-gram language model, which achieves a 1.5% absolute\nimprovement compared to the BLSTM. In a 20000 hours Mandarin recognition task,\nthe LFR trained DFSMN can achieve more than 20% relative improvement compared\nto the LFR trained BLSTM. Moreover, we can easily design the lookahead filter\norder of the memory blocks in DFSMN to control the latency for real-time\napplications.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 11:08:16 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Zhang", "Shiliang", ""], ["Lei", "Ming", ""], ["Yan", "Zhijie", ""], ["Dai", "Lirong", ""]]}, {"id": "1803.05109", "submitter": "Tao Liu", "authors": "Tao Liu, Lei Jiang, Yier Jin, Gang Quan, Wujie Wen", "title": "PT-Spike: A Precise-Time-Dependent Single Spike Neuromorphic\n  Architecture with Efficient Supervised Learning", "comments": "23rd Asia and South Pacific Design Automation Conference (ASP-DAC\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most exciting advancements in AI over the last decade is the wide\nadoption of ANNs, such as DNN and CNN, in many real-world applications.\nHowever, the underlying massive amounts of computation and storage requirement\ngreatly challenge their applicability in resource-limited platforms like the\ndrone, mobile phone, and IoT devices etc. The third generation of neural\nnetwork model--Spiking Neural Network (SNN), inspired by the working mechanism\nand efficiency of human brain, has emerged as a promising solution for\nachieving more impressive computing and power efficiency within light-weighted\ndevices (e.g. single chip). However, the relevant research activities have been\nnarrowly carried out on conventional rate-based spiking system designs for\nfulfilling the practical cognitive tasks, underestimating SNN's energy\nefficiency, throughput, and system flexibility. Although the time-based SNN can\nbe more attractive conceptually, its potentials are not unleashed in realistic\napplications due to lack of efficient coding and practical learning schemes. In\nthis work, a Precise-Time-Dependent Single Spike Neuromorphic Architecture,\nnamely \"PT-Spike\", is developed to bridge this gap. Three constituent\nhardware-favorable techniques: precise single-spike temporal encoding,\nefficient supervised temporal learning, and fast asymmetric decoding are\nproposed accordingly to boost the energy efficiency and data processing\ncapability of the time-based SNN at a more compact neural network model size\nwhen executing real cognitive tasks. Simulation results show that \"PT-Spike\"\ndemonstrates significant improvements in network size, processing efficiency\nand power consumption with marginal classification accuracy degradation when\ncompared with the rate-based SNN and ANN under the similar network\nconfiguration.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 02:37:42 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Liu", "Tao", ""], ["Jiang", "Lei", ""], ["Jin", "Yier", ""], ["Quan", "Gang", ""], ["Wen", "Wujie", ""]]}, {"id": "1803.05117", "submitter": "Tao Liu", "authors": "Tao Liu, Zihao Liu, Fuhong Lin, Yier Jin, Gang Quan, Wujie Wen", "title": "MT-Spike: A Multilayer Time-based Spiking Neuromorphic Architecture with\n  Temporal Error Backpropagation", "comments": "36th International Conference On Computer Aided Design (ICCAD 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep learning enabled artificial neural networks, such as Deep Neural\nNetwork (DNN) and Convolutional Neural Network (CNN), have achieved a series of\nbreaking records on a broad spectrum of recognition applications. However, the\nenormous computation and storage requirements associated with such deep and\ncomplex neural network models greatly challenge their implementations on\nresource-limited platforms. Time-based spiking neural network has recently\nemerged as a promising solution in Neuromorphic Computing System designs for\nachieving remarkable computing and power efficiency within a single chip.\nHowever, the relevant research activities have been narrowly concentrated on\nthe biological plausibility and theoretical learning approaches, causing\ninefficient neural processing and impracticable multilayer extension thus\nsignificantly limitations on speed and accuracy when handling the realistic\ncognitive tasks. In this work, a practical multilayer time-based spiking\nneuromorphic architecture, namely \"MT-Spike\", is developed to fill this gap.\nWith the proposed practical time-coding scheme, average delay response model,\ntemporal error backpropagation algorithm, and heuristic loss function,\n\"MT-Spike\" achieves more efficient neural processing through flexible neural\nmodel size reduction while offering very competitive classification accuracy\nfor realistic recognition tasks. Simulation results well validated that the\nalgorithmic power of deep multi-layer learning can be seamlessly merged with\nthe efficiency of time-based spiking neuromorphic architecture, demonstrating\ngreat potentials of \"MT-Spike\" in resource and power constrained embedded\nplatforms.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 03:01:19 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Liu", "Tao", ""], ["Liu", "Zihao", ""], ["Lin", "Fuhong", ""], ["Jin", "Yier", ""], ["Quan", "Gang", ""], ["Wen", "Wujie", ""]]}, {"id": "1803.05131", "submitter": "Alex James Dr", "authors": "Olga Krestinskaya, Alex Pappachen James", "title": "Feature extraction without learning in an analog Spatial Pooler\n  memristive-CMOS circuit design of Hierarchical Temporal Memory", "comments": null, "journal-ref": "Analog Integrated Circuits and Signal Processing, 2018", "doi": null, "report-no": null, "categories": "cs.ET cs.AI cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Temporal Memory (HTM) is a neuromorphic algorithm that emulates\nsparsity, hierarchy and modularity resembling the working principles of\nneocortex. Feature encoding is an important step to create sparse binary\npatterns. This sparsity is introduced by the binary weights and random weight\nassignment in the initialization stage of the HTM. We propose the alternative\ndeterministic method for the HTM initialization stage, which connects the HTM\nweights to the input data and preserves natural sparsity of the input\ninformation. Further, we introduce the hardware implementation of the\ndeterministic approach and compare it to the traditional HTM and existing\nhardware implementation. We test the proposed approach on the face recognition\nproblem and show that it outperforms the conventional HTM approach.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 04:18:47 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Krestinskaya", "Olga", ""], ["James", "Alex Pappachen", ""]]}, {"id": "1803.05132", "submitter": "Alex James Dr", "authors": "Aidana Irmanova, Alex Pappachen James", "title": "Neuron inspired data encoding memristive multi-level memory cell", "comments": null, "journal-ref": "Analog Integrated Circuits and Signal Processing, 2018", "doi": null, "report-no": null, "categories": "cs.ET cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mapping neuro-inspired algorithms to sensor backplanes of on-chip hardware\nrequire shifting the signal processing from digital to the analog domain,\ndemanding memory technologies beyond conventional CMOS binary storage units.\nUsing memristors for building analog data storage is one of the promising\napproaches amongst emerging non-volatile memory technologies. Recently, a\nmemristive multi-level memory (MLM) cell for storing discrete analog values has\nbeen developed in which memory system is implemented combining memristors in\nvoltage divider configuration. In given example, the memory cell of 3 sub-cells\nwith a memristor in each was programmed to store ternary bits which overall\nachieved 10 and 27 discrete voltage levels. However, for further use of\nproposed memory cell in analog signal processing circuits data encoder is\nrequired to generate control voltages for programming memristors to store\ndiscrete analog values. In this paper, we present the design and performance\nanalysis of data encoder that generates write pattern signals for 10 level\nmemristive memory.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 04:21:33 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Irmanova", "Aidana", ""], ["James", "Alex Pappachen", ""]]}, {"id": "1803.05174", "submitter": "Eivind Samuelsen", "authors": "Eivind Samuelsen, Kyrre Glette", "title": "Multi-objective Analysis of MAP-Elites Performance", "comments": "Text as submitted to, and rejected by ALIFE 2018, reformatted in\n  IEEEtran", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In certain complex optimization tasks, it becomes necessary to use multiple\nmeasures to characterize the performance of different algorithms. This paper\npresents a method that combines ordinal effect sizes with Pareto dominance to\nanalyze such cases. Since the method is ordinal, it can also generalize across\ndifferent optimization tasks even when the performance measurements are\ndifferently scaled. Through a case study, we show that this method can discover\nand quantify relations that would be difficult to deduce using a conventional\nmeasure-by-measure analysis. This case study applies the method to the\nevolution of robot controller repertoires using the MAP-Elites algorithm. Here,\nwe analyze the search performance across a large set of parametrizations;\nvarying mutation size and operator type, as well as map resolution, across four\ndifferent robot morphologies. We show that the average magnitude of mutations\nhas a bigger effect on outcomes than their precise distributions.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 09:26:32 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 12:19:42 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Samuelsen", "Eivind", ""], ["Glette", "Kyrre", ""]]}, {"id": "1803.05192", "submitter": "Andreas Selmar Hauptmann", "authors": "Andreas Hauptmann, Simon Arridge, Felix Lucka, Vivek Muthurangu, and\n  Jennifer A. Steeden", "title": "Real-time Cardiovascular MR with Spatio-temporal Artifact Suppression\n  using Deep Learning - Proof of Concept in Congenital Heart Disease", "comments": null, "journal-ref": null, "doi": "10.1002/mrm.27480", "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PURPOSE: Real-time assessment of ventricular volumes requires high\nacceleration factors. Residual convolutional neural networks (CNN) have shown\npotential for removing artifacts caused by data undersampling. In this study we\ninvestigated the effect of different radial sampling patterns on the accuracy\nof a CNN. We also acquired actual real-time undersampled radial data in\npatients with congenital heart disease (CHD), and compare CNN reconstruction to\nCompressed Sensing (CS).\n  METHODS: A 3D (2D plus time) CNN architecture was developed, and trained\nusing 2276 gold-standard paired 3D data sets, with 14x radial undersampling.\nFour sampling schemes were tested, using 169 previously unseen 3D 'synthetic'\ntest data sets. Actual real-time tiny Golden Angle (tGA) radial SSFP data was\nacquired in 10 new patients (122 3D data sets), and reconstructed using the 3D\nCNN as well as a CS algorithm; GRASP.\n  RESULTS: Sampling pattern was shown to be important for image quality, and\naccurate visualisation of cardiac structures. For actual real-time data,\noverall reconstruction time with CNN (including creation of aliased images) was\nshown to be more than 5x faster than GRASP. Additionally, CNN image quality and\naccuracy of biventricular volumes was observed to be superior to GRASP for the\nsame raw data.\n  CONCLUSION: This paper has demonstrated the potential for the use of a 3D CNN\nfor deep de-aliasing of real-time radial data, within the clinical setting.\nClinical measures of ventricular volumes using real-time data with CNN\nreconstruction are not statistically significantly different from the\ngold-standard, cardiac gated, BH techniques.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 10:25:35 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 21:27:41 GMT"}, {"version": "v3", "created": "Thu, 14 Jun 2018 13:03:43 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Hauptmann", "Andreas", ""], ["Arridge", "Simon", ""], ["Lucka", "Felix", ""], ["Muthurangu", "Vivek", ""], ["Steeden", "Jennifer A.", ""]]}, {"id": "1803.05383", "submitter": "Hisashi Iwade", "authors": "Hisashi Iwade, Kohei Nakajima, Takuma Tanaka, and Toshio Aoyagi", "title": "Use of recurrent infomax to improve the memory capability of\n  input-driven recurrent neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inherent transient dynamics of recurrent neural networks (RNNs) have been\nexploited as a computational resource in input-driven RNNs. However, the\ninformation processing capability varies from RNN to RNN, depending on their\nproperties. Many authors have investigated the dynamics of RNNs and their\nrelevance to the information processing capability. In this study, we present a\ndetailed analysis of the information processing capability of an RNN optimized\nby recurrent infomax (RI), which is an unsupervised learning scheme that\nmaximizes the mutual information of RNNs by adjusting the connection strengths\nof the network. Thus, we observe that a delay-line structure emerges from the\nRI and the network optimized by the RI possesses superior short-term memory,\nwhich is the ability to store the temporal information of the input stream in\nits transient dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 14 Feb 2018 02:45:26 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Iwade", "Hisashi", ""], ["Nakajima", "Kohei", ""], ["Tanaka", "Takuma", ""], ["Aoyagi", "Toshio", ""]]}, {"id": "1803.05796", "submitter": "Karlson Pfannschmidt", "authors": "Karlson Pfannschmidt, Pritha Gupta, Eyke H\\\"ullermeier", "title": "Deep Architectures for Learning Context-dependent Ranking Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object ranking is an important problem in the realm of preference learning.\nOn the basis of training data in the form of a set of rankings of objects,\nwhich are typically represented as feature vectors, the goal is to learn a\nranking function that predicts a linear order of any new set of objects.\nCurrent approaches commonly focus on ranking by scoring, i.e., on learning an\nunderlying latent utility function that seeks to capture the inherent utility\nof each object. These approaches, however, are not able to take possible\neffects of context-dependence into account, where context-dependence means that\nthe utility or usefulness of an object may also depend on what other objects\nare available as alternatives. In this paper, we formalize the problem of\ncontext-dependent ranking and present two general approaches based on two\nnatural representations of context-dependent ranking functions. Both approaches\nare instantiated by means of appropriate neural network architectures, which\nare evaluated on suitable benchmark task.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 15:14:16 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 16:44:26 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Pfannschmidt", "Karlson", ""], ["Gupta", "Pritha", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1803.05849", "submitter": "Renzo Andri", "authors": "Andrawes Al Bahou, Geethan Karunaratne, Renzo Andri, Lukas Cavigelli,\n  Luca Benini", "title": "XNORBIN: A 95 TOp/s/W Hardware Accelerator for Binary Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.AR cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying state-of-the-art CNNs requires power-hungry processors and off-chip\nmemory. This precludes the implementation of CNNs in low-power embedded\nsystems. Recent research shows CNNs sustain extreme quantization, binarizing\ntheir weights and intermediate feature maps, thereby saving 8-32\\x memory and\ncollapsing energy-intensive sum-of-products into XNOR-and-popcount operations.\n  We present XNORBIN, an accelerator for binary CNNs with computation tightly\ncoupled to memory for aggressive data reuse. Implemented in UMC 65nm technology\nXNORBIN achieves an energy efficiency of 95 TOp/s/W and an area efficiency of\n2.0 TOp/s/MGE at 0.8 V.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 15:41:28 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Bahou", "Andrawes Al", ""], ["Karunaratne", "Geethan", ""], ["Andri", "Renzo", ""], ["Cavigelli", "Lukas", ""], ["Benini", "Luca", ""]]}, {"id": "1803.05859", "submitter": "Oscar Chang", "authors": "Oscar Chang, Hod Lipson", "title": "Neural Network Quine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-replication is a key aspect of biological life that has been largely\noverlooked in Artificial Intelligence systems. Here we describe how to build\nand train self-replicating neural networks. The network replicates itself by\nlearning to output its own weights. The network is designed using a loss\nfunction that can be optimized with either gradient-based or non-gradient-based\nmethods. We also describe a method we call regeneration to train the network\nwithout explicit optimization, by injecting the network with predictions of its\nown parameters. The best solution for a self-replicating network was found by\nalternating between regeneration and optimization steps. Finally, we describe a\ndesign for a self-replicating neural network that can solve an auxiliary task\nsuch as MNIST image classification. We observe that there is a trade-off\nbetween the network's ability to classify images and its ability to replicate,\nbut training is biased towards increasing its specialization at image\nclassification at the expense of replication. This is analogous to the\ntrade-off between reproduction and other tasks observed in nature. We suggest\nthat a self-replication mechanism for artificial intelligence is useful because\nit introduces the possibility of continual improvement through natural\nselection.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 16:54:43 GMT"}, {"version": "v2", "created": "Sat, 17 Mar 2018 09:47:43 GMT"}, {"version": "v3", "created": "Sat, 31 Mar 2018 21:18:58 GMT"}, {"version": "v4", "created": "Thu, 24 May 2018 19:23:35 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Chang", "Oscar", ""], ["Lipson", "Hod", ""]]}, {"id": "1803.05945", "submitter": "Gabriel Dario Alvarado Barrios", "authors": "G. Alvarado Barrios, J. C. Retamal, E. Solano and M. Sanz", "title": "Analog simulator of integro-differential equations with classical\n  memristors", "comments": null, "journal-ref": "Scientific Reports 9, 12928 (2019)", "doi": "10.1038/s41598-019-49204-y", "report-no": null, "categories": "cs.ET cs.NE quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An analog computer makes use of continuously changeable quantities of a\nsystem, such as its electrical, mechanical, or hydraulic properties, to solve a\ngiven problem. While these devices are usually computationally more powerful\nthan their digital counterparts, they suffer from analog noise which does not\nallow for error control. We will focus on analog computers based on active\nelectrical networks comprised of resistors, capacitors, and operational\namplifiers which are capable of simulating any linear ordinary differential\nequation. However, the class of nonlinear dynamics they can solve is limited.\nIn this work, by adding memristors to the electrical network, we show that the\nanalog computer can simulate a large variety of linear and nonlinear\nintegro-differential equations by carefully choosing the conductance and the\ndynamics of the memristor state variable. To the best of our knowledge, this is\nthe first time that circuits based on memristors are proposed for simulations.\nWe study the performance of these analog computers by simulating\nintegro-differential models related to fluid dynamics, nonlinear Volterra\nequations for population growth, and quantum models describing non-Markovian\nmemory effects, among others. Finally, we perform stability tests by\nconsidering imperfect analog components, obtaining robust solutions with up to\n$13\\%$ relative error for relevant timescales.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 18:53:41 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 13:27:12 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 23:32:40 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Barrios", "G. Alvarado", ""], ["Retamal", "J. C.", ""], ["Solano", "E.", ""], ["Sanz", "M.", ""]]}, {"id": "1803.06127", "submitter": "Roman Kalkreuth", "authors": "Roman Kalkreuth", "title": "Towards Advanced Phenotypic Mutations in Cartesian Genetic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cartesian Genetic Programming is often used with a point mutation as the sole\ngenetic operator. In this paper, we propose two phenotypic mutation techniques\nand take a step towards advanced phenotypic mutations in Cartesian Genetic\nProgramming. The functionality of the proposed mutations is inspired by\nbiological evolution which mutates DNA sequences by inserting and deleting\nnucleotides. Experiments with symbolic regression and boolean functions\nproblems show a better search performance when the proposed mutations are in\nuse. The results of our experiments indicate that the use of phenotypic\nmutations could be beneficial for the use of Cartesian Genetic Programming.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 09:43:47 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Kalkreuth", "Roman", ""]]}, {"id": "1803.06226", "submitter": "Markus Quade", "authors": "Markus Quade and Julien Gout and Markus Abel", "title": "Glyph: Symbolic Regression Tools", "comments": "Submitted to JOSR. arXiv admin note: text overlap with\n  arXiv:1612.05276", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NE math.OC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Glyph - a Python package for genetic programming based symbolic\nregression. Glyph is designed for usage let by numerical simulations let by\nreal world experiments. For experimentalists, glyph-remote provides a\nseparation of tasks: a ZeroMQ interface splits the genetic programming\noptimization task from the evaluation of an experimental (or numerical) run.\nGlyph can be accessed at http://github.com/ambrosys/glyph . Domain experts are\nbe able to employ symbolic regression in their experiments with ease, even if\nthey are not expert programmers. The reuse potential is kept high by a generic\ninterface design. Glyph is available on PyPI and Github.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 21:57:49 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2018 10:06:54 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Quade", "Markus", ""], ["Gout", "Julien", ""], ["Abel", "Markus", ""]]}, {"id": "1803.06282", "submitter": "Yingyu Zhang", "authors": "Yingyu Zhang, Bing Zeng, Yuanzhen Li and Junqing Li", "title": "A mullti- or many- objective evolutionary algorithm with global loop\n  update", "comments": "14 pages, 5 figures and 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi- or many-objective evolutionary algorithm- s(MOEAs), especially the\ndecomposition-based MOEAs have been widely concerned in recent years. The\ndecomposition-based MOEAs emphasize convergence and diversity in a simple model\nand have made a great success in dealing with theoretical and practical multi-\nor many-objective optimization problems. In this paper, we focus on update\nstrategies of the decomposition- based MOEAs, and their criteria for comparing\nsolutions. Three disadvantages of the decomposition-based MOEAs with local\nupdate strategies and several existing criteria for comparing solutions are\nanalyzed and discussed. And a global loop update strategy and two hybrid\ncriteria are suggested. Subsequently, an evolutionary algorithm with the global\nloop update is implement- ed and compared to several of the best multi- or\nmany-objective optimization algorithms on two famous unconstraint test suites\nwith up to 15 objectives. Experimental results demonstrate that unlike\nevolutionary algorithms with local update strategies, the population of our\nalgorithm does not degenerate at any generation of its evolution, which\nguarantees the diversity of the resulting population. In addition, our\nalgorithm wins in most instances of the two test suites, indicating that it is\nvery compet- itive in terms of convergence and diversity. Running results of\nour algorithm with different criteria for comparing solutions are also\ncompared. Their differences are very significant, indicating that the\nperformance of our algorithm is affected by the criterion it adopts.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 00:14:51 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Zhang", "Yingyu", ""], ["Zeng", "Bing", ""], ["Li", "Yuanzhen", ""], ["Li", "Junqing", ""]]}, {"id": "1803.06492", "submitter": "Bin Wang", "authors": "Bin Wang, Yanan Sun, Bing Xue and Mengjie Zhang", "title": "Evolving Deep Convolutional Neural Networks by Variable-length Particle\n  Swarm Optimization for Image Classification", "comments": "accepted by IEEE CEC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are one of the most effective deep\nlearning methods to solve image classification problems, but the best\narchitecture of a CNN to solve a specific problem can be extremely complicated\nand hard to design. This paper focuses on utilising Particle Swarm Optimisation\n(PSO) to automatically search for the optimal architecture of CNNs without any\nmanual work involved. In order to achieve the goal, three improvements are made\nbased on traditional PSO. First, a novel encoding strategy inspired by computer\nnetworks which empowers particle vectors to easily encode CNN layers is\nproposed; Second, in order to allow the proposed method to learn\nvariable-length CNN architectures, a Disabled layer is designed to hide some\ndimensions of the particle vector to achieve variable-length particles; Third,\nsince the learning process on large data is slow, partial datasets are randomly\npicked for the evaluation to dramatically speed it up. The proposed algorithm\nis examined and compared with 12 existing algorithms including the state-of-art\nmethods on three widely used image classification benchmark datasets. The\nexperimental results show that the proposed algorithm is a strong competitor to\nthe state-of-art algorithms in terms of classification error. This is the first\nwork using PSO for automatically evolving the architectures of CNNs.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 11:47:43 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Wang", "Bin", ""], ["Sun", "Yanan", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "1803.06622", "submitter": "Christopher Kim", "authors": "Christopher Kim and Carson Chow", "title": "Learning recurrent dynamics in spiking networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking activity of neurons engaged in learning and performing a task show\ncomplex spatiotemporal dynamics. While the output of recurrent network models\ncan learn to perform various tasks, the possible range of recurrent dynamics\nthat emerge after learning remains unknown. Here we show that modifying the\nrecurrent connectivity with a recursive least squares algorithm provides\nsufficient flexibility for synaptic and spiking rate dynamics of spiking\nnetworks to produce a wide range of spatiotemporal activity. We apply the\ntraining method to learn arbitrary firing patterns, stabilize irregular spiking\nactivity of a balanced network, and reproduce the heterogeneous spiking rate\npatterns of cortical neurons engaged in motor planning and movement. We\nidentify sufficient conditions for successful learning, characterize two types\nof learning errors, and assess the network capacity. Our findings show that\nsynaptically-coupled recurrent spiking networks possess a vast computational\ncapability that can support the diverse activity patterns in the brain.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 07:51:19 GMT"}, {"version": "v2", "created": "Sat, 18 Aug 2018 14:13:37 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Kim", "Christopher", ""], ["Chow", "Carson", ""]]}, {"id": "1803.06744", "submitter": "Purushotham Kamath", "authors": "Purushotham Kamath, Abhishek Singh, and Debo Dutta", "title": "Fast Neural Architecture Construction using EnvelopeNets", "comments": "A shorter version of this paper appeared in the Workshop on\n  MetaLearning 2018 (MetaLearning 2018 at NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast Neural Architecture Construction (NAC) is a method to construct deep\nnetwork architectures by pruning and expansion of a base network. In recent\nyears, several automated search methods for neural network architectures have\nbeen proposed using methods such as evolutionary algorithms and reinforcement\nlearning. These methods use a single scalar objective function (usually\naccuracy) that is evaluated after a full training and evaluation cycle. In\ncontrast NAC directly compares the utility of different filters using\nstatistics derived from filter featuremaps reach a state where the utility of\ndifferent filters within a network can be compared and hence can be used to\nconstruct networks. The training epochs needed for filters within a network to\nreach this state is much less than the training epochs needed for the accuracy\nof a network to stabilize. NAC exploits this finding to construct convolutional\nneural nets (CNNs) with close to state of the art accuracy, in < 1 GPU day,\nfaster than most of the current neural architecture search methods. The\nconstructed networks show close to state of the art performance on the image\nclassification problem on well known datasets (CIFAR-10, ImageNet) and\nconsistently show better performance than hand constructed and randomly\ngenerated networks of the same depth, operators and approximately the same\nnumber of parameters.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 21:28:03 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 18:48:06 GMT"}, {"version": "v3", "created": "Fri, 14 Dec 2018 00:34:40 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Kamath", "Purushotham", ""], ["Singh", "Abhishek", ""], ["Dutta", "Debo", ""]]}, {"id": "1803.06959", "submitter": "Ari Morcos", "authors": "Ari S. Morcos, David G.T. Barrett, Neil C. Rabinowitz, Matthew\n  Botvinick", "title": "On the importance of single directions for generalization", "comments": "ICLR 2018 conference paper; added additional methodological details", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their ability to memorize large datasets, deep neural networks often\nachieve good generalization performance. However, the differences between the\nlearned solutions of networks which generalize and those which do not remain\nunclear. Additionally, the tuning properties of single directions (defined as\nthe activation of a single unit or some linear combination of units in response\nto some input) have been highlighted, but their importance has not been\nevaluated. Here, we connect these lines of inquiry to demonstrate that a\nnetwork's reliance on single directions is a good predictor of its\ngeneralization performance, across networks trained on datasets with different\nfractions of corrupted labels, across ensembles of networks trained on datasets\nwith unmodified labels, across different hyperparameters, and over the course\nof training. While dropout only regularizes this quantity up to a point, batch\nnormalization implicitly discourages single direction reliance, in part by\ndecreasing the class selectivity of individual units. Finally, we find that\nclass selectivity is a poor predictor of task importance, suggesting not only\nthat networks which generalize well minimize their dependence on individual\nunits by reducing their selectivity, but also that individually selective units\nmay not be necessary for strong network performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 14:42:19 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 10:03:34 GMT"}, {"version": "v3", "created": "Mon, 21 May 2018 10:48:45 GMT"}, {"version": "v4", "created": "Tue, 22 May 2018 09:55:52 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Morcos", "Ari S.", ""], ["Barrett", "David G. T.", ""], ["Rabinowitz", "Neil C.", ""], ["Botvinick", "Matthew", ""]]}, {"id": "1803.07307", "submitter": "Hendrik Richter", "authors": "Hendrik Richter", "title": "Information content of coevolutionary game landscapes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.NE physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coevolutionary game dynamics is the result of players that may change their\nstrategies and their network of interaction. For such games, and based on\ninterpreting strategies as configurations, strategy-to-payoff maps can be\ndefined for every interaction network, which opens up to derive game\nlandscapes. This paper presents an analysis of these game landscapes by their\ninformation content. By this analysis, we particularly study the effect of a\nrescaled payoff matrix generalizing social dilemmas and differences between\nwell-mixed and structured populations.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 09:03:12 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Richter", "Hendrik", ""]]}, {"id": "1803.07423", "submitter": "Chengjia Wang", "authors": "Chengjia Wang, Keith A. Goatman, James Boardman, Erin Beveridge, David\n  Newby, and Scott Semple", "title": "A Distance Oriented Kalman Filter Particle Swarm Optimizer Applied to\n  Multi-Modality Image Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe improvements to the particle swarm optimizer (PSO)\nmade by inclusion of an unscented Kalman filter to guide particle motion. We\ndemonstrate the effectiveness of the unscented Kalman filter PSO by comparing\nit with the original PSO algorithm and its variants designed to improve\nperformance. The PSOs were tested firstly on a number of common synthetic\nbenchmarking functions, and secondly applied to a practical three-dimensional\nimage registration problem. The proposed methods displayed better performances\nfor 4 out of 8 benchmark functions, and reduced the target registration errors\nby at least 2mm when registering down-sampled benchmark brain images. Our\nmethods also demonstrated an ability to align images featuring motion related\nartefacts which all other methods failed to register. These new PSO methods\nprovide a novel, efficient mechanism to integrate prior knowledge into each\niteration of the optimization process, which can enhance the accuracy and speed\nof convergence in the application of medical image registration.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 13:40:36 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Wang", "Chengjia", ""], ["Goatman", "Keith A.", ""], ["Boardman", "James", ""], ["Beveridge", "Erin", ""], ["Newby", "David", ""], ["Semple", "Scott", ""]]}, {"id": "1803.07488", "submitter": "Alexander Sagel", "authors": "Alexander Sagel and Hao Shen", "title": "Dynamic Variational Autoencoders for Visual Process Modeling", "comments": null, "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053660", "report-no": null, "categories": "cs.NE cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the problem of modeling visual processes by leveraging deep\ngenerative architectures for learning linear, Gaussian representations from\nobserved sequences. We propose a joint learning framework, combining a vector\nautoregressive model and Variational Autoencoders. This results in an\narchitecture that allows Variational Autoencoders to simultaneously learn a\nnon-linear observation as well as a linear state model from sequences of\nframes. We validate our approach on artificial sequences and dynamic textures.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 15:38:40 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 08:08:45 GMT"}, {"version": "v3", "created": "Wed, 12 Feb 2020 14:19:04 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Sagel", "Alexander", ""], ["Shen", "Hao", ""]]}, {"id": "1803.07770", "submitter": "Christopher J. Cueva", "authors": "Christopher J. Cueva and Xue-Xin Wei", "title": "Emergence of grid-like representations by training recurrent neural\n  networks to perform spatial localization", "comments": null, "journal-ref": "International Conference on Learning Representations (ICLR) 2018", "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decades of research on the neural code underlying spatial navigation have\nrevealed a diverse set of neural response properties. The Entorhinal Cortex\n(EC) of the mammalian brain contains a rich set of spatial correlates,\nincluding grid cells which encode space using tessellating patterns. However,\nthe mechanisms and functional significance of these spatial representations\nremain largely mysterious. As a new way to understand these neural\nrepresentations, we trained recurrent neural networks (RNNs) to perform\nnavigation tasks in 2D arenas based on velocity inputs. Surprisingly, we find\nthat grid-like spatial response patterns emerge in trained networks, along with\nunits that exhibit other spatial correlates, including border cells and\nband-like cells. All these different functional types of neurons have been\nobserved experimentally. The order of the emergence of grid-like and border\ncells is also consistent with observations from developmental studies.\nTogether, our results suggest that grid cells, border cells and others as\nobserved in EC may be a natural solution for representing space efficiently\ngiven the predominant recurrent connections in the neural circuits.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 07:09:57 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Cueva", "Christopher J.", ""], ["Wei", "Xue-Xin", ""]]}, {"id": "1803.07870", "submitter": "Filippo Maria Bianchi", "authors": "Filippo Maria Bianchi, Simone Scardapane, Sigurd L{\\o}kse, Robert\n  Jenssen", "title": "Reservoir computing approaches for representation and classification of\n  multivariate time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification of multivariate time series (MTS) has been tackled with a\nlarge variety of methodologies and applied to a wide range of scenarios.\nReservoir Computing (RC) provides efficient tools to generate a vectorial,\nfixed-size representation of the MTS that can be further processed by standard\nclassifiers. Despite their unrivaled training speed, MTS classifiers based on a\nstandard RC architecture fail to achieve the same accuracy of fully trainable\nneural networks. In this paper we introduce the reservoir model space, an\nunsupervised approach based on RC to learn vectorial representations of MTS.\nEach MTS is encoded within the parameters of a linear model trained to predict\na low-dimensional embedding of the reservoir dynamics. Compared to other RC\nmethods, our model space yields better representations and attains comparable\ncomputational performance, thanks to an intermediate dimensionality reduction\nprocedure. As a second contribution we propose a modular RC framework for MTS\nclassification, with an associated open-source Python library. The framework\nprovides different modules to seamlessly implement advanced RC architectures.\nThe architectures are compared to other MTS classifiers, including deep\nlearning models and time series kernels. Results obtained on benchmark and\nreal-world MTS datasets show that RC classifiers are dramatically faster and,\nwhen implemented using our proposed representation, also achieve superior\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 11:54:57 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 10:23:40 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2020 20:02:21 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Bianchi", "Filippo Maria", ""], ["Scardapane", "Simone", ""], ["L\u00f8kse", "Sigurd", ""], ["Jenssen", "Robert", ""]]}, {"id": "1803.08165", "submitter": "Xavier Gir\\'o-i-Nieto", "authors": "Daniel Fojo, V\\'ictor Campos and Xavier Giro-i-Nieto", "title": "Comparing Fixed and Adaptive Computation Time for Recurrent Neural\n  Networks", "comments": "Accepted as workshop paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive Computation Time for Recurrent Neural Networks (ACT) is one of the\nmost promising architectures for variable computation. ACT adapts to the input\nsequence by being able to look at each sample more than once, and learn how\nmany times it should do it. In this paper, we compare ACT to Repeat-RNN, a\nnovel architecture based on repeating each sample a fixed number of times. We\nfound surprising results, where Repeat-RNN performs as good as ACT in the\nselected tasks. Source code in TensorFlow and PyTorch is publicly available at\nhttps://imatge-upc.github.io/danifojo-2018-repeatrnn/\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 22:59:53 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Fojo", "Daniel", ""], ["Campos", "V\u00edctor", ""], ["Giro-i-Nieto", "Xavier", ""]]}, {"id": "1803.08203", "submitter": "Kamil Nar", "authors": "Kamil Nar, Shankar Sastry", "title": "Residual Networks: Lyapunov Stability and Convex Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While training error of most deep neural networks degrades as the depth of\nthe network increases, residual networks appear to be an exception. We show\nthat the main reason for this is the Lyapunov stability of the gradient descent\nalgorithm: for an arbitrarily chosen step size, the equilibria of the gradient\ndescent are most likely to remain stable for the parametrization of residual\nnetworks. We then present an architecture with a pair of residual networks to\napproximate a large class of functions by decomposing them into a convex and a\nconcave part. Some parameters of this model are shown to change little during\ntraining, and this imperfect optimization prevents overfitting the data and\nleads to solutions with small Lipschitz constants, while providing clues about\nthe generalization of other deep networks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 02:14:08 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Nar", "Kamil", ""], ["Sastry", "Shankar", ""]]}, {"id": "1803.08240", "submitter": "Stephen Merity", "authors": "Stephen Merity, Nitish Shirish Keskar, Richard Socher", "title": "An Analysis of Neural Language Modeling at Multiple Scales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the leading approaches in language modeling introduce novel, complex\nand specialized architectures. We take existing state-of-the-art word level\nlanguage models based on LSTMs and QRNNs and extend them to both larger\nvocabularies as well as character-level granularity. When properly tuned, LSTMs\nand QRNNs achieve state-of-the-art results on character-level (Penn Treebank,\nenwik8) and word-level (WikiText-103) datasets, respectively. Results are\nobtained in only 12 hours (WikiText-103) to 2 days (enwik8) using a single\nmodern GPU.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 06:25:47 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Merity", "Stephen", ""], ["Keskar", "Nitish Shirish", ""], ["Socher", "Richard", ""]]}, {"id": "1803.08353", "submitter": "David Gomez-Cabrero", "authors": "D G\\'omez-Cabrero, D. N. Ranasinghe", "title": "Fine-tuning the Ant Colony System algorithm through Particle Swarm\n  Optimization", "comments": "2006 paper. Presented in conference. Technical report in \"Universitat\n  de Valencia\"", "journal-ref": null, "doi": null, "report-no": "tr07-05", "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ant Colony System (ACS) is a distributed (agent- based) algorithm which has\nbeen widely studied on the Symmetric Travelling Salesman Problem (TSP). The\noptimum parameters for this algorithm have to be found by trial and error. We\nuse a Particle Swarm Optimization algorithm (PSO) to optimize the ACS\nparameters working in a designed subset of TSP instances. First goal is to\nperform the hybrid PSO-ACS algorithm on a single instance to find the optimum\nparameters and optimum solutions for the instance. Second goal is to analyze\nthose sets of optimum parameters, in relation to instance characteristics.\nComputational results have shown good quality solutions for single instances\nthough with high computational times, and that there may be sets of parameters\nthat work optimally for a majority of instances.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 14:13:31 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["G\u00f3mez-Cabrero", "D", ""], ["Ranasinghe", "D. N.", ""]]}, {"id": "1803.08375", "submitter": "Abien Fred Agarap", "authors": "Abien Fred Agarap", "title": "Deep Learning using Rectified Linear Units (ReLU)", "comments": "7 pages, 11 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce the use of rectified linear units (ReLU) as the classification\nfunction in a deep neural network (DNN). Conventionally, ReLU is used as an\nactivation function in DNNs, with Softmax function as their classification\nfunction. However, there have been several studies on using a classification\nfunction other than Softmax, and this study is an addition to those. We\naccomplish this by taking the activation of the penultimate layer $h_{n - 1}$\nin a neural network, then multiply it by weight parameters $\\theta$ to get the\nraw scores $o_{i}$. Afterwards, we threshold the raw scores $o_{i}$ by $0$,\ni.e. $f(o) = \\max(0, o_{i})$, where $f(o)$ is the ReLU function. We provide\nclass predictions $\\hat{y}$ through argmax function, i.e. argmax $f(x)$.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 14:30:17 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 06:13:13 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Agarap", "Abien Fred", ""]]}, {"id": "1803.08554", "submitter": "Ramin M. Hasani", "authors": "Mathias Lechner, Ramin M. Hasani, Radu Grosu", "title": "Neuronal Circuit Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an effective way to create interpretable control agents, by\nre-purposing the function of a biological neural circuit model, to govern\nsimulated and real world reinforcement learning (RL) test-beds. We model the\ntap-withdrawal (TW) neural circuit of the nematode, C. elegans, a circuit\nresponsible for the worm's reflexive response to external mechanical touch\nstimulations, and learn its synaptic and neuronal parameters as a policy for\ncontrolling basic RL tasks. We also autonomously park a real rover robot on a\npre-defined trajectory, by deploying such neuronal circuit policies learned in\na simulated environment. For reconfiguration of the purpose of the TW neural\ncircuit, we adopt a search-based RL algorithm. We show that our neuronal\npolicies perform as good as deep neural network policies with the advantage of\nrealizing interpretable dynamics at the cell level.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 19:23:32 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Lechner", "Mathias", ""], ["Hasani", "Ramin M.", ""], ["Grosu", "Radu", ""]]}, {"id": "1803.08631", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang and Limeng Cui and Fisher B. Gouza", "title": "SEGEN: Sample-Ensemble Genetic Evolutional Network Model", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning, a rebranding of deep neural network research works, has\nachieved a remarkable success in recent years. With multiple hidden layers,\ndeep learning models aim at computing the hierarchical feature representations\nof the observational data. Meanwhile, due to its severe disadvantages in data\nconsumption, computational resources, parameter tuning costs and the lack of\nresult explainability, deep learning has also suffered from lots of criticism.\nIn this paper, we will introduce a new representation learning model, namely\n\"Sample-Ensemble Genetic Evolutionary Network\" (SEGEN), which can serve as an\nalternative approach to deep learning models. Instead of building one single\ndeep model, based on a set of sampled sub-instances, SEGEN adopts a\ngenetic-evolutionary learning strategy to build a group of unit models\ngenerations by generations. The unit models incorporated in SEGEN can be either\ntraditional machine learning models or the recent deep learning models with a\nmuch \"narrower\" and \"shallower\" architecture. The learning results of each\ninstance at the final generation will be effectively combined from each unit\nmodel via diffusive propagation and ensemble learning strategies. From the\ncomputational perspective, SEGEN requires far less data, fewer computational\nresources and parameter tuning efforts, but has sound theoretic\ninterpretability of the learning process and results. Extensive experiments\nhave been done on several different real-world benchmark datasets, and the\nexperimental results obtained by SEGEN have demonstrated its advantages over\nthe state-of-the-art representation learning models.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 01:43:37 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 04:39:53 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Zhang", "Jiawei", ""], ["Cui", "Limeng", ""], ["Gouza", "Fisher B.", ""]]}, {"id": "1803.08635", "submitter": "Samiran Ganguly", "authors": "Samiran Ganguly, Yunfei Gu, Mircea R. Stan, Avik W. Ghosh", "title": "Hardware based Spatio-Temporal Neural Processing Backend for Imaging\n  Sensors: Towards a Smart Camera", "comments": "11 pages, 5 figures. To be presented in SPIE DCS 2018: Image Sensing\n  Technologies: Materials, Devices, Systems, and Applications V", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we show how we can build a technology platform for cognitive\nimaging sensors using recent advances in recurrent neural network architectures\nand training methods inspired from biology. We demonstrate learning and\nprocessing tasks specific to imaging sensors, including enhancement of\nsensitivity and signal-to-noise ratio (SNR) purely through neural filtering\nbeyond the fundamental limits sensor materials, and inferencing and\nspatio-temporal pattern recognition capabilities of these networks with\napplications in object detection, motion tracking and prediction. We then show\ndesigns of unit hardware cells built using complementary metal-oxide\nsemiconductor (CMOS) and emerging materials technologies for ultra-compact and\nenergy-efficient embedded neural processors for smart cameras.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 01:57:49 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Ganguly", "Samiran", ""], ["Gu", "Yunfei", ""], ["Stan", "Mircea R.", ""], ["Ghosh", "Avik W.", ""]]}, {"id": "1803.08660", "submitter": "Michael Moeller", "authors": "Peter Ochs, Tim Meinhardt, Laura Leal-Taixe, Michael Moeller", "title": "Lifting Layers: Analysis and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The great advances of learning-based approaches in image processing and\ncomputer vision are largely based on deeply nested networks that compose linear\ntransfer functions with suitable non-linearities. Interestingly, the most\nfrequently used non-linearities in imaging applications (variants of the\nrectified linear unit) are uncommon in low dimensional approximation problems.\nIn this paper we propose a novel non-linear transfer function, called lifting,\nwhich is motivated from a related technique in convex optimization. A lifting\nlayer increases the dimensionality of the input, naturally yields a linear\nspline when combined with a fully connected layer, and therefore closes the gap\nbetween low and high dimensional approximation problems. Moreover, applying the\nlifting operation to the loss layer of the network allows us to handle\nnon-convex and flat (zero-gradient) cost functions. We analyze the proposed\nlifting theoretically, exemplify interesting properties in synthetic\nexperiments and demonstrate its effectiveness in deep learning approaches to\nimage classification and denoising.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 05:47:50 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Ochs", "Peter", ""], ["Meinhardt", "Tim", ""], ["Leal-Taixe", "Laura", ""], ["Moeller", "Michael", ""]]}, {"id": "1803.08833", "submitter": "Elena Pastorelli", "authors": "Elena Pastorelli, Pier Stanislao Paolucci, Francesco Simula, Andrea\n  Biagioni, Fabrizio Capuani, Paolo Cretaro, Giulia De Bonis, Francesca Lo\n  Cicero, Alessandro Lonardo, Michele Martinelli, Luca Pontisso, Piero Vicini,\n  Roberto Ammendola", "title": "Gaussian and exponential lateral connectivity on distributed spiking\n  neural network simulation", "comments": "9 pages, 9 figures, added reference to final peer reviewed version on\n  conference paper and DOI", "journal-ref": null, "doi": "10.1109/PDP2018.2018.00110", "report-no": null, "categories": "cs.DC cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We measured the impact of long-range exponentially decaying intra-areal\nlateral connectivity on the scaling and memory occupation of a distributed\nspiking neural network simulator compared to that of short-range Gaussian\ndecays. While previous studies adopted short-range connectivity, recent\nexperimental neurosciences studies are pointing out the role of longer-range\nintra-areal connectivity with implications on neural simulation platforms.\nTwo-dimensional grids of cortical columns composed by up to 11 M point-like\nspiking neurons with spike frequency adaption were connected by up to 30 G\nsynapses using short- and long-range connectivity models. The MPI processes\ncomposing the distributed simulator were run on up to 1024 hardware cores,\nhosted on a 64 nodes server platform. The hardware platform was a cluster of\nIBM NX360 M5 16-core compute nodes, each one containing two Intel Xeon Haswell\n8-core E5-2630 v3 processors, with a clock of 2.40 G Hz, interconnected through\nan InfiniBand network, equipped with 4x QDR switches.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 15:21:42 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 14:54:34 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Pastorelli", "Elena", ""], ["Paolucci", "Pier Stanislao", ""], ["Simula", "Francesco", ""], ["Biagioni", "Andrea", ""], ["Capuani", "Fabrizio", ""], ["Cretaro", "Paolo", ""], ["De Bonis", "Giulia", ""], ["Cicero", "Francesca Lo", ""], ["Lonardo", "Alessandro", ""], ["Martinelli", "Michele", ""], ["Pontisso", "Luca", ""], ["Vicini", "Piero", ""], ["Ammendola", "Roberto", ""]]}, {"id": "1803.08884", "submitter": "Joel Leibo", "authors": "Edward Hughes, Joel Z. Leibo, Matthew G. Phillips, Karl Tuyls, Edgar\n  A. Du\\'e\\~nez-Guzm\\'an, Antonio Garc\\'ia Casta\\~neda, Iain Dunning, Tina Zhu,\n  Kevin R. McKee, Raphael Koster, Heather Roff, Thore Graepel", "title": "Inequity aversion improves cooperation in intertemporal social dilemmas", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.GT cs.MA q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Groups of humans are often able to find ways to cooperate with one another in\ncomplex, temporally extended social dilemmas. Models based on behavioral\neconomics are only able to explain this phenomenon for unrealistic stateless\nmatrix games. Recently, multi-agent reinforcement learning has been applied to\ngeneralize social dilemma problems to temporally and spatially extended Markov\ngames. However, this has not yet generated an agent that learns to cooperate in\nsocial dilemmas as humans do. A key insight is that many, but not all, human\nindividuals have inequity averse social preferences. This promotes a particular\nresolution of the matrix game social dilemma wherein inequity-averse\nindividuals are personally pro-social and punish defectors. Here we extend this\nidea to Markov games and show that it promotes cooperation in several types of\nsequential social dilemma, via a profitable interaction with policy\nlearnability. In particular, we find that inequity aversion improves temporal\ncredit assignment for the important class of intertemporal social dilemmas.\nThese results help explain how large-scale cooperation may emerge and persist.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 17:05:38 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 18:50:44 GMT"}, {"version": "v3", "created": "Thu, 27 Sep 2018 13:03:57 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Hughes", "Edward", ""], ["Leibo", "Joel Z.", ""], ["Phillips", "Matthew G.", ""], ["Tuyls", "Karl", ""], ["Du\u00e9\u00f1ez-Guzm\u00e1n", "Edgar A.", ""], ["Casta\u00f1eda", "Antonio Garc\u00eda", ""], ["Dunning", "Iain", ""], ["Zhu", "Tina", ""], ["McKee", "Kevin R.", ""], ["Koster", "Raphael", ""], ["Roff", "Heather", ""], ["Graepel", "Thore", ""]]}, {"id": "1803.09074", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui", "title": "Multi-range Reasoning for Machine Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose MRU (Multi-Range Reasoning Units), a new fast compositional\nencoder for machine comprehension (MC). Our proposed MRU encoders are\ncharacterized by multi-ranged gating, executing a series of parameterized\ncontract-and-expand layers for learning gating vectors that benefit from long\nand short-term dependencies. The aims of our approach are as follows: (1)\nlearning representations that are concurrently aware of long and short-term\ncontext, (2) modeling relationships between intra-document blocks and (3) fast\nand efficient sequence encoding. We show that our proposed encoder demonstrates\npromising results both as a standalone encoder and as well as a complementary\nbuilding block. We conduct extensive experiments on three challenging MC\ndatasets, namely RACE, SearchQA and NarrativeQA, achieving highly competitive\nperformance on all. On the RACE benchmark, our model outperforms DFN (Dynamic\nFusion Networks) by 1.5%-6% without using any recurrent or convolution layers.\nSimilarly, we achieve competitive performance relative to AMANDA on the\nSearchQA benchmark and BiDAF on the NarrativeQA benchmark without using any\nLSTM/GRU layers. Finally, incorporating MRU encoders with standard BiLSTM\narchitectures further improves performance, achieving state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sat, 24 Mar 2018 08:10:04 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1803.09227", "submitter": "Johannes Lengler", "authors": "Johannes Lengler", "title": "A General Dichotomy of Evolutionary Algorithms on Monotone Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that the evolutionary algorithm $(1+1)$-EA with mutation rate\n$c/n$ optimises every monotone function efficiently if $c<1$, and needs\nexponential time on some monotone functions (HotTopic functions) if $c\\geq\n2.2$. We study the same question for a large variety of algorithms,\nparticularly for $(1+\\lambda)$-EA, $(\\mu+1)$-EA, $(\\mu+1)$-GA, their fast\ncounterparts like fast $(1+1)$-EA, and for $(1+(\\lambda,\\lambda))$-GA. We find\nthat all considered mutation-based algorithms show a similar dichotomy for\nHotTopic functions, or even for all monotone functions. For the\n$(1+(\\lambda,\\lambda))$-GA, this dichotomy is in the parameter $c\\gamma$, which\nis the expected number of bit flips in an individual after mutation and\ncrossover, neglecting selection. For the fast algorithms, the dichotomy is in\n$m_2/m_1$, where $m_1$ and $m_2$ are the first and second falling moment of the\nnumber of bit flips. Surprisingly, the range of efficient parameters is not\naffected by either population size $\\mu$ nor by the offspring population size\n$\\lambda$.\n  The picture changes completely if crossover is allowed. The genetic\nalgorithms $(\\mu+1)$-GA and fast $(\\mu+1)$-GA are efficient for arbitrary\nmutations strengths if $\\mu$ is large enough.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 10:33:25 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 06:57:37 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Lengler", "Johannes", ""]]}, {"id": "1803.09254", "submitter": "Bruno Messias Farias de Resende", "authors": "Bruno Messias, Bruno W. D. Morais", "title": "A theory of the phenomenology of multipopulation genetic algorithm with\n  an application to the Ising model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic algorithm (GA) is a stochastic metaheuristic process consisting on\nthe evolution of a population of candidate solutions for a given optimization\nproblem. By extension, multipopulation genetic algorithm (MPGA) aims for\nefficiency by evolving many populations, or islands, in parallel and performing\nmigrations between them periodically. The connectivity between islands\nconstrains the directions of migration and characterizes MPGA as a dynamic\nprocess over a network. As such, predicting the evolution of the quality of the\nsolutions is a difficult challenge, implying in the waste of computer resources\nand energy when the parameters are inadequate. By using models derived from\nstatistical mechanics, this work aims to estimate equations for the study of\ndynamics in relation to the connectivity in MPGA. To illustrate the importance\nof understanding MPGA, we show its application as an efficient alternative to\nthe thermalization phase of Metropolis-Hastings algorithm applied to the Ising\nmodel.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 13:52:33 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 17:23:46 GMT"}, {"version": "v3", "created": "Tue, 5 Jun 2018 18:58:11 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Messias", "Bruno", ""], ["Morais", "Bruno W. D.", ""]]}, {"id": "1803.09258", "submitter": "Richard Preen", "authors": "Richard J. Preen and Jim Smith", "title": "Evolutionary n-level Hypergraph Partitioning with Adaptive Coarsening", "comments": null, "journal-ref": "IEEE Transactions on Evolutionary Computation (2019),\n  23(6):962-971", "doi": "10.1109/TEVC.2019.2896951", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypergraph partitioning is an NP-hard problem that occurs in many computer\nscience applications where it is necessary to reduce large problems into a\nnumber of smaller, computationally tractable sub-problems. Current techniques\nuse a multilevel approach wherein an initial partitioning is performed after\ncompressing the hypergraph to a predetermined level. This level is typically\nchosen to produce very coarse hypergraphs in which heuristic algorithms are\nfast and effective. This article presents a novel memetic algorithm which\nremains effective on larger initial hypergraphs. This enables the exploitation\nof information that can be lost during coarsening and results in improved final\nsolution quality. We use this algorithm to present an empirical analysis of the\nspace of possible initial hypergraphs in terms of its searchability at\ndifferent levels of coarsening. We find that the best results arise at\ncoarsening levels unique to each hypergraph. Based on this, we introduce an\nadaptive scheme that stops coarsening when the rate of information loss in a\nhypergraph becomes non-linear and show that this produces further improvements.\nThe results show that we have identified a valuable role for evolutionary\nalgorithms within the current state-of-the-art hypergraph partitioning\nframework.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 14:24:11 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 15:12:32 GMT"}, {"version": "v3", "created": "Sun, 10 Feb 2019 12:13:04 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Preen", "Richard J.", ""], ["Smith", "Jim", ""]]}, {"id": "1803.09356", "submitter": "Bart Jacobs", "authors": "Bart Jacobs and David Sprunger", "title": "Neural Nets via Forward State Transformation and Backward Loss\n  Transformation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article studies (multilayer perceptron) neural networks with an emphasis\non the transformations involved --- both forward and backward --- in order to\ndevelop a semantical/logical perspective that is in line with standard program\nsemantics. The common two-pass neural network training algorithms make this\nviewpoint particularly fitting. In the forward direction, neural networks act\nas state transformers. In the reverse direction, however, neural networks\nchange losses of outputs to losses of inputs, thereby acting like a\n(real-valued) predicate transformer. In this way, backpropagation is functorial\nby construction, as shown earlier in recent other work. We illustrate this\nperspective by training a simple instance of a neural network.\n", "versions": [{"version": "v1", "created": "Sun, 25 Mar 2018 22:01:32 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Jacobs", "Bart", ""], ["Sprunger", "David", ""]]}, {"id": "1803.09574", "submitter": "Darjan Salaj", "authors": "Guillaume Bellec, Darjan Salaj, Anand Subramoney, Robert Legenstein,\n  Wolfgang Maass", "title": "Long short-term memory and learning-to-learn in networks of spiking\n  neurons", "comments": "First three authors contributed equally; Paper accepted at NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent networks of spiking neurons (RSNNs) underlie the astounding\ncomputing and learning capabilities of the brain. But computing and learning\ncapabilities of RSNN models have remained poor, at least in comparison with\nartificial neural networks (ANNs). We address two possible reasons for that.\nOne is that RSNNs in the brain are not randomly connected or designed according\nto simple rules, and they do not start learning as a tabula rasa network.\nRather, RSNNs in the brain were optimized for their tasks through evolution,\ndevelopment, and prior experience. Details of these optimization processes are\nlargely unknown. But their functional contribution can be approximated through\npowerful optimization methods, such as backpropagation through time (BPTT).\n  A second major mismatch between RSNNs in the brain and models is that the\nlatter only show a small fraction of the dynamics of neurons and synapses in\nthe brain. We include neurons in our RSNN model that reproduce one prominent\ndynamical process of biological neurons that takes place at the behaviourally\nrelevant time scale of seconds: neuronal adaptation. We denote these networks\nas LSNNs because of their Long short-term memory. The inclusion of adapting\nneurons drastically increases the computing and learning capability of RSNNs if\nthey are trained and configured by deep learning (BPTT combined with a rewiring\nalgorithm that optimizes the network architecture). In fact, the computational\nperformance of these RSNNs approaches for the first time that of LSTM networks.\nIn addition RSNNs with adapting neurons can acquire abstract knowledge from\nprior learning in a Learning-to-Learn (L2L) scheme, and transfer that knowledge\nin order to learn new but related tasks from very few examples. We demonstrate\nthis for supervised learning and reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 13:25:43 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 16:29:36 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2018 12:26:32 GMT"}, {"version": "v4", "created": "Tue, 25 Dec 2018 11:17:22 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Bellec", "Guillaume", ""], ["Salaj", "Darjan", ""], ["Subramoney", "Anand", ""], ["Legenstein", "Robert", ""], ["Maass", "Wolfgang", ""]]}, {"id": "1803.09587", "submitter": "Malte Ludewig", "authors": "Malte Ludewig, Dietmar Jannach", "title": "Evaluation of Session-based Recommendation Algorithms", "comments": null, "journal-ref": null, "doi": "10.1007/s11257-018-9209-6", "report-no": null, "categories": "cs.IR cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems help users find relevant items of interest, for example\non e-commerce or media streaming sites. Most academic research is concerned\nwith approaches that personalize the recommendations according to long-term\nuser profiles. In many real-world applications, however, such long-term\nprofiles often do not exist and recommendations therefore have to be made\nsolely based on the observed behavior of a user during an ongoing session.\nGiven the high practical relevance of the problem, an increased interest in\nthis problem can be observed in recent years, leading to a number of proposals\nfor session-based recommendation algorithms that typically aim to predict the\nuser's immediate next actions. In this work, we present the results of an\nin-depth performance comparison of a number of such algorithms, using a variety\nof datasets and evaluation measures. Our comparison includes the most recent\napproaches based on recurrent neural networks like GRU4REC, factorized Markov\nmodel approaches such as FISM or FOSSIL, as well as simpler methods based,\ne.g., on nearest neighbor schemes. Our experiments reveal that algorithms of\nthis latter class, despite their sometimes almost trivial nature, often perform\nequally well or significantly better than today's more complex approaches based\non deep neural networks. Our results therefore suggest that there is\nsubstantial room for improvement regarding the development of more\nsophisticated session-based recommendation algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 13:46:07 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 10:14:57 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Ludewig", "Malte", ""], ["Jannach", "Dietmar", ""]]}, {"id": "1803.09715", "submitter": "Edgar Covantes Osuna", "authors": "Edgar Covantes Osuna and Dirk Sudholt", "title": "On the Runtime Analysis of the Clearing Diversity-Preserving Mechanism", "comments": "To be published in Evolutionary Computation Journal", "journal-ref": "Evolutionary Computation 27 (2019) 403-433", "doi": "10.1162/evco_a_00225", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clearing is a niching method inspired by the principle of assigning the\navailable resources among a niche to a single individual. The clearing\nprocedure supplies these resources only to the best individual of each niche:\nthe winner. So far, its analysis has been focused on experimental approaches\nthat have shown that clearing is a powerful diversity-preserving mechanism.\nUsing rigorous runtime analysis to explain how and why it is a powerful method,\nwe prove that a mutation-based evolutionary algorithm with a large enough\npopulation size, and a phenotypic distance function always succeeds in\noptimising all functions of unitation for small niches in polynomial time,\nwhile a genotypic distance function requires exponential time. Finally, we\nprove that with phenotypic and genotypic distances clearing is able to find\nboth optima for Twomax and several general classes of bimodal functions in\npolynomial expected time. We use empirical analysis to highlight some of the\ncharacteristics that makes it a useful mechanism and to support the theoretical\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 17:10:15 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Osuna", "Edgar Covantes", ""], ["Sudholt", "Dirk", ""]]}, {"id": "1803.09760", "submitter": "Andrew Jaegle", "authors": "Andrew Jaegle, Oleh Rybkin, Konstantinos G. Derpanis, Kostas\n  Daniilidis", "title": "Predicting the Future with Transformational States", "comments": "24 pages, including supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An intelligent observer looks at the world and sees not only what is, but\nwhat is moving and what can be moved. In other words, the observer sees how the\npresent state of the world can transform in the future. We propose a model that\npredicts future images by learning to represent the present state and its\ntransformation given only a sequence of images. To do so, we introduce an\narchitecture with a latent state composed of two components designed to capture\n(i) the present image state and (ii) the transformation between present and\nfuture states, respectively. We couple this latent state with a recurrent\nneural network (RNN) core that predicts future frames by transforming past\nstates into future states by applying the accumulated state transformation with\na learned operator. We describe how this model can be integrated into an\nencoder-decoder convolutional neural network (CNN) architecture that uses\nweighted residual connections to integrate representations of the past with\nrepresentations of the future. Qualitatively, our approach generates image\nsequences that are stable and capture realistic motion over multiple predicted\nframes, without requiring adversarial training. Quantitatively, our method\nachieves prediction results comparable to state-of-the-art results on standard\nimage prediction benchmarks (Moving MNIST, KTH, and UCF101).\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 18:00:07 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Jaegle", "Andrew", ""], ["Rybkin", "Oleh", ""], ["Derpanis", "Konstantinos G.", ""], ["Daniilidis", "Kostas", ""]]}, {"id": "1803.09766", "submitter": "Edgar Covantes Osuna", "authors": "Edgar Covantes Osuna and Dirk Sudholt", "title": "Runtime Analysis of Probabilistic Crowding and Restricted Tournament\n  Selection for Bimodal Optimisation", "comments": "To be published in the proceedings of the Genetic and Evolutionary\n  Computation Conference, GECCO '08", "journal-ref": null, "doi": "10.1145/3205455.3205591", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real optimisation problems lead to multimodal domains and so require the\nidentification of multiple optima. Niching methods have been developed to\nmaintain the population diversity, to investigate many peaks in parallel and to\nreduce the effect of genetic drift. Using rigorous runtime analysis, we analyse\nfor the first time two well known niching methods: probabilistic crowding and\nrestricted tournament selection (RTS). We incorporate both methods into a\n$(\\mu+1)~EA$ on the bimodal function Twomax where the goal is to find two\noptima at opposite ends of the search space. In probabilistic crowding, the\noffspring compete with their parents and the survivor is chosen proportionally\nto its fitness. On Twomax probabilistic crowding fails to find any reasonable\nsolution quality even in exponential time. In RTS the offspring compete against\nthe closest individual amongst $w$ (window size) individuals. We prove that RTS\nfails if $w$ is too small, leading to exponential times with high probability.\nHowever, if w is chosen large enough, it finds both optima for Twomax in time\n$O(\\mu n \\log{n})$ with high probability. Our theoretical results are\naccompanied by experimental studies that match the theoretical results and also\nshed light on parameters not covered by the theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 18:00:29 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Osuna", "Edgar Covantes", ""], ["Sudholt", "Dirk", ""]]}, {"id": "1803.09807", "submitter": "Jesse Livezey", "authors": "Jesse A. Livezey, Kristofer E. Bouchard, Edward F. Chang", "title": "Deep learning as a tool for neural data analysis: speech classification\n  and cross-frequency coupling in human sensorimotor cortex", "comments": "23 pages, 9 figures", "journal-ref": null, "doi": "10.1371/journal.pcbi.1007091", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge in neuroscience is to understand what structure in\nthe world is represented in spatially distributed patterns of neural activity\nfrom multiple single-trial measurements. This is often accomplished by learning\na simple, linear transformations between neural features and features of the\nsensory stimuli or motor task. While successful in some early sensory\nprocessing areas, linear mappings are unlikely to be ideal tools for\nelucidating nonlinear, hierarchical representations of higher-order brain areas\nduring complex tasks, such as the production of speech by humans. Here, we\napply deep networks to predict produced speech syllables from cortical surface\nelectric potentials recorded from human sensorimotor cortex. We found that deep\nnetworks had higher decoding prediction accuracy compared to baseline models,\nand also exhibited greater improvements in accuracy with increasing dataset\nsize. We further demonstrate that deep network's confusions revealed\nhierarchical latent structure in the neural data, which recapitulated the\nunderlying articulatory nature of speech motor control. Finally, we used deep\nnetworks to compare task-relevant information in different neural frequency\nbands, and found that the high-gamma band contains the vast majority of\ninformation relevant for the speech prediction task, with little-to-no\nadditional contribution from lower-frequencies. Together, these results\ndemonstrate the utility of deep networks as a data analysis tool for\nneuroscience.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 19:26:44 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Livezey", "Jesse A.", ""], ["Bouchard", "Kristofer E.", ""], ["Chang", "Edward F.", ""]]}, {"id": "1803.09820", "submitter": "Leslie Smith", "authors": "Leslie N. Smith", "title": "A disciplined approach to neural network hyper-parameters: Part 1 --\n  learning rate, batch size, momentum, and weight decay", "comments": "Files to help replicate the results reported here are available on\n  Github", "journal-ref": null, "doi": null, "report-no": "US Naval Research Laboratory Technical Report 5510-026", "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning has produced dazzling successes for applications of\nimage, speech, and video processing in the past few years, most trainings are\nwith suboptimal hyper-parameters, requiring unnecessarily long training times.\nSetting the hyper-parameters remains a black art that requires years of\nexperience to acquire. This report proposes several efficient ways to set the\nhyper-parameters that significantly reduce training time and improves\nperformance. Specifically, this report shows how to examine the training\nvalidation/test loss function for subtle clues of underfitting and overfitting\nand suggests guidelines for moving toward the optimal balance point. Then it\ndiscusses how to increase/decrease the learning rate/momentum to speed up\ntraining. Our experiments show that it is crucial to balance every manner of\nregularization for each dataset and architecture. Weight decay is used as a\nsample regularizer to show how its optimal value is tightly coupled with the\nlearning rates and momentums. Files to help replicate the results reported here\nare available.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 20:05:59 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 17:43:51 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Smith", "Leslie N.", ""]]}, {"id": "1803.09877", "submitter": "Lingjiao Chen", "authors": "Lingjiao Chen and Hongyi Wang and Zachary Charles and Dimitris\n  Papailiopoulos", "title": "DRACO: Byzantine-resilient Distributed Training via Redundant Gradients", "comments": "Accepted by ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.IT cs.LG cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed model training is vulnerable to byzantine system failures and\nadversarial compute nodes, i.e., nodes that use malicious updates to corrupt\nthe global model stored at a parameter server (PS). To guarantee some form of\nrobustness, recent work suggests using variants of the geometric median as an\naggregation rule, in place of gradient averaging. Unfortunately, median-based\nrules can incur a prohibitive computational overhead in large-scale settings,\nand their convergence guarantees often require strong assumptions. In this\nwork, we present DRACO, a scalable framework for robust distributed training\nthat uses ideas from coding theory. In DRACO, each compute node evaluates\nredundant gradients that are used by the parameter server to eliminate the\neffects of adversarial updates. DRACO comes with problem-independent robustness\nguarantees, and the model that it trains is identical to the one trained in the\nadversary-free setup. We provide extensive experiments on real datasets and\ndistributed setups across a variety of large-scale models, where we show that\nDRACO is several times, to orders of magnitude faster than median-based\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 03:34:25 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 05:38:33 GMT"}, {"version": "v3", "created": "Fri, 27 Apr 2018 02:10:56 GMT"}, {"version": "v4", "created": "Fri, 22 Jun 2018 02:47:53 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Chen", "Lingjiao", ""], ["Wang", "Hongyi", ""], ["Charles", "Zachary", ""], ["Papailiopoulos", "Dimitris", ""]]}, {"id": "1803.10225", "submitter": "Mirco Ravanelli", "authors": "Mirco Ravanelli, Philemon Brakel, Maurizio Omologo, Yoshua Bengio", "title": "Light Gated Recurrent Units for Speech Recognition", "comments": "Copyright 2018 IEEE", "journal-ref": "IEEE Transactions on Emerging Topics in Computational\n  Intelligence, vol. 2, no. 2, pp. 92-102, April 2018", "doi": "10.1109/TETCI.2017.2762739", "report-no": null, "categories": "eess.AS cs.NE cs.SD eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A field that has directly benefited from the recent advances in deep learning\nis Automatic Speech Recognition (ASR). Despite the great achievements of the\npast decades, however, a natural and robust human-machine speech interaction\nstill appears to be out of reach, especially in challenging environments\ncharacterized by significant noise and reverberation. To improve robustness,\nmodern speech recognizers often employ acoustic models based on Recurrent\nNeural Networks (RNNs), that are naturally able to exploit large time contexts\nand long-term speech modulations. It is thus of great interest to continue the\nstudy of proper techniques for improving the effectiveness of RNNs in\nprocessing speech signals.\n  In this paper, we revise one of the most popular RNN models, namely Gated\nRecurrent Units (GRUs), and propose a simplified architecture that turned out\nto be very effective for ASR. The contribution of this work is two-fold: First,\nwe analyze the role played by the reset gate, showing that a significant\nredundancy with the update gate occurs. As a result, we propose to remove the\nformer from the GRU design, leading to a more efficient and compact single-gate\nmodel. Second, we propose to replace hyperbolic tangent with ReLU activations.\nThis variation couples well with batch normalization and could help the model\nlearn long-term dependencies without numerical issues.\n  Results show that the proposed architecture, called Light GRU (Li-GRU), not\nonly reduces the per-epoch training time by more than 30% over a standard GRU,\nbut also consistently improves the recognition accuracy across different tasks,\ninput features, noisy conditions, as well as across different ASR paradigms,\nranging from standard DNN-HMM speech recognizers to end-to-end CTC models.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 17:48:18 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Ravanelli", "Mirco", ""], ["Brakel", "Philemon", ""], ["Omologo", "Maurizio", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1803.10288", "submitter": "Aavaas Gajurel", "authors": "Aavaas Gajurel, Sushil J Louis, Daniel J Mendez, Siming Liu", "title": "Neuroevolution for RTS Micro", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper uses neuroevolution of augmenting topologies to evolve control\ntactics for groups of units in real-time strategy games. In such games, players\nbuild economies to generate armies composed of multiple types of units with\ndifferent attack and movement characteristics to combat each other. This paper\nevolves neural networks to control movement and attack commands, also called\nmicro, for a group of ranged units skirmishing with a group of melee units. Our\nresults show that neuroevolution of augmenting topologies can effectively\ngenerate neural networks capable of good micro for our ranged units against a\ngroup of hand-coded melee units. The evolved neural networks lead to kiting\nbehavior for the ranged units which is a common tactic used by professional\nplayers in ranged versus melee skirmishes in popular real-time strategy games\nlike Starcraft. The evolved neural networks also generalized well to other\nstarting positions and numbers of units. We believe these results indicate the\npotential of neuroevolution for generating effective micro in real-time\nstrategy games.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 19:48:21 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Gajurel", "Aavaas", ""], ["Louis", "Sushil J", ""], ["Mendez", "Daniel J", ""], ["Liu", "Siming", ""]]}, {"id": "1803.10314", "submitter": "Navin Adhikari", "authors": "Navin K Adhikari, Sushil J. Louis, Siming Liu, and Walker Spurgeon", "title": "Co-evolving Real-Time Strategy Game Micro", "comments": "Submitted to CIG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate competitive co-evolution of unit micromanagement in real-time\nstrategy games. Although good long-term macro-strategy and good short-term unit\nmicromanagement both impact real-time strategy games performance, this paper\nfocuses on generating quality micro. Better micro, for example, can help\nplayers win skirmishes and battles even when outnumbered. Prior work has shown\nthat we can evolve micro to beat a given opponent. We remove the need for a\ngood opponent to evolve against by using competitive co-evolution to evolve\nhigh-quality micro for both sides from scratch. We first co-evolve micro to\ncontrol a group of ranged units versus a group of melee units. We then move to\nco-evolve micro for a group of ranged and melee units versus a group of ranged\nand melee units. Results show that competitive co-evolution produces good\nquality micro and when combined with the well-known techniques of fitness\nsharing, shared sampling, and a hall of fame takes less time to produce better\nquality micro than simple co-evolution. We believe these results indicate the\nviability of co-evolutionary approaches for generating good unit\nmicro-management.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 20:44:44 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Adhikari", "Navin K", ""], ["Louis", "Sushil J.", ""], ["Liu", "Siming", ""], ["Spurgeon", "Walker", ""]]}, {"id": "1803.10316", "submitter": "Rahul Dubey", "authors": "Rahul Dubey, Joseph Ghantous, Sushil Louis, and Siming Liu", "title": "Evolutionary Multi-objective Optimization of Real-Time Strategy Micro", "comments": "Submitted to CIG 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate an evolutionary multi-objective approach to good micro for\nreal-time strategy games. Good micro helps a player win skirmishes and is one\nof the keys to developing better real-time strategy game play. In prior work,\nthe same multi-objective approach of maximizing damage done while minimizing\ndamage received was used to evolve micro for a group of ranged units versus a\ngroup of melee units. We extend this work to consider groups composed from two\ntypes of units. Specifically, this paper uses evolutionary multi-objective\noptimization to generate micro for one group composed from both ranged and\nmelee units versus another group of ranged and melee units. Our micro behavior\nrepresentation uses influence maps to represent enemy spatial information and\npotential fields generated from distance, health, and weapons cool down to\nguide unit movement. Experimental results indicate that our multi-objective\napproach leads to a Pareto front of diverse high-quality micro encapsulating\nmultiple possible tactics. This range of micro provided by the Pareto front\nenables a human or AI player to trade-off among short term tactics that better\nsuit the player's longer term strategy - for example, choosing to minimize\nfriendly unit damage at the cost of only lightly damaging the enemy versus\nmaximizing damage to the enemy units at the cost of increased damage to\nfriendly units. We believe that our results indicate the usefulness of\npotential fields as a representation, and of evolutionary multi-objective\noptimization as an approach, for generating good micro.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 20:50:30 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Dubey", "Rahul", ""], ["Ghantous", "Joseph", ""], ["Louis", "Sushil", ""], ["Liu", "Siming", ""]]}, {"id": "1803.10375", "submitter": "Chi-Ning Chou", "authors": "Chi-Ning Chou, Kai-Min Chung, Chi-Jen Lu", "title": "On the Algorithmic Power of Spiking Neural Networks", "comments": "To appear in ITCS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNN) are mathematical models in neuroscience to\ndescribe the dynamics among a set of neurons that interact with each other by\nfiring instantaneous signals, a.k.a., spikes. Interestingly, a recent advance\nin neuroscience [Barrett-Den\\`eve-Machens, NIPS 2013] showed that the neurons'\nfiring rate, i.e., the average number of spikes fired per unit of time, can be\ncharacterized by the optimal solution of a quadratic program defined by the\nparameters of the dynamics. This indicated that SNN potentially has the\ncomputational power to solve non-trivial quadratic programs. However, the\nresults were justified empirically without rigorous analysis.\n  We put this into the context of natural algorithms and aim to investigate the\nalgorithmic power of SNN. Especially, we emphasize on giving rigorous\nasymptotic analysis on the performance of SNN in solving optimization problems.\nTo enforce a theoretical study, we first identify a simplified SNN model that\nis tractable for analysis. Next, we confirm the empirical observation in the\nwork of Barrett et al. by giving an upper bound on the convergence rate of SNN\nin solving the quadratic program. Further, we observe that in the case where\nthere are infinitely many optimal solutions, SNN tends to converge to the one\nwith smaller l1 norm. We give an affirmative answer to our finding by showing\nthat SNN can solve the l1 minimization problem under some regular conditions.\n  Our main technical insight is a dual view of the SNN dynamics, under which\nSNN can be viewed as a new natural primal-dual algorithm for the l1\nminimization problem. We believe that the dual view is of independent interest\nand may potentially find interesting interpretation in neuroscience.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 01:31:59 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 20:15:01 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Chou", "Chi-Ning", ""], ["Chung", "Kai-Min", ""], ["Lu", "Chi-Jen", ""]]}, {"id": "1803.10397", "submitter": "Takeshi Inagaki", "authors": "Takeshi Inagaki", "title": "Supervising Unsupervised Learning with Evolutionary Algorithm in Deep\n  Neural Network", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method to control results of gradient descent unsupervised learning in a\ndeep neural network by using evolutionary algorithm is proposed. To process\ncrossover of unsupervisedly trained models, the algorithm evaluates pointwise\nfitness of individual nodes in neural network. Labeled training data is\nrandomly sampled and breeding process selects nodes by calculating degree of\ntheir consistency on different sets of sampled data. This method supervises\nunsupervised training by evolutionary process. We also introduce modified\nRestricted Boltzmann Machine which contains repulsive force among nodes in a\nneural network and it contributes to isolate network nodes each other to avoid\naccidental degeneration of nodes by evolutionary process. These new methods are\napplied to document classification problem and it results better accuracy than\na traditional fully supervised classifier implemented with linear regression\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 03:20:18 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Inagaki", "Takeshi", ""]]}, {"id": "1803.10459", "submitter": "Aditya Grover", "authors": "Aditya Grover, Aaron Zweig, Stefano Ermon", "title": "Graphite: Iterative Generative Modeling of Graphs", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are a fundamental abstraction for modeling relational data. However,\ngraphs are discrete and combinatorial in nature, and learning representations\nsuitable for machine learning tasks poses statistical and computational\nchallenges. In this work, we propose Graphite, an algorithmic framework for\nunsupervised learning of representations over nodes in large graphs using deep\nlatent variable generative models. Our model parameterizes variational\nautoencoders (VAE) with graph neural networks, and uses a novel iterative graph\nrefinement strategy inspired by low-rank approximations for decoding. On a wide\nvariety of synthetic and benchmark datasets, Graphite outperforms competing\napproaches for the tasks of density estimation, link prediction, and node\nclassification. Finally, we derive a theoretical connection between message\npassing in graph neural networks and mean-field variational inference.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 08:37:25 GMT"}, {"version": "v2", "created": "Thu, 29 Mar 2018 08:15:20 GMT"}, {"version": "v3", "created": "Tue, 19 Jun 2018 06:02:17 GMT"}, {"version": "v4", "created": "Wed, 15 May 2019 07:13:30 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Grover", "Aditya", ""], ["Zweig", "Aaron", ""], ["Ermon", "Stefano", ""]]}, {"id": "1803.10560", "submitter": "Alexander Shekhovtsov", "authors": "Alexander Shekhovtsov, Boris Flach", "title": "Normalization of Neural Networks using Analytic Variance Propagation", "comments": null, "journal-ref": "In Proceedings of Computer Vision Winter Workshop 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of estimating statistics of hidden units in a neural\nnetwork using a method of analytic moment propagation. These statistics are\nuseful for approximate whitening of the inputs in front of saturating\nnon-linearities such as a sigmoid function. This is important for\ninitialization of training and for reducing the accumulated scale and bias\ndependencies (compensating covariate shift), which presumably eases the\nlearning. In batch normalization, which is currently a very widely applied\ntechnique, sample estimates of statistics of hidden units over a batch are\nused. The proposed estimation uses an analytic propagation of mean and variance\nof the training set through the network. The result depends on the network\nstructure and its current weights but not on the specific batch input. The\nestimates are suitable for initialization and normalization, efficient to\ncompute and independent of the batch size. The experimental verification well\nsupports these claims. However, the method does not share the generalization\nproperties of BN, to which our experiments give some additional insight.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 12:37:27 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Shekhovtsov", "Alexander", ""], ["Flach", "Boris", ""]]}, {"id": "1803.10567", "submitter": "Tobias Hinz", "authors": "Tobias Hinz, Stefan Wermter", "title": "Image Generation and Translation with Disentangled Representations", "comments": "Accepted as a conference paper at the International Joint Conference\n  on Neural Networks (IJCNN) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models have made significant progress in the tasks of modeling\ncomplex data distributions such as natural images. The introduction of\nGenerative Adversarial Networks (GANs) and auto-encoders lead to the\npossibility of training on big data sets in an unsupervised manner. However,\nfor many generative models it is not possible to specify what kind of image\nshould be generated and it is not possible to translate existing images into\nnew images of similar domains. Furthermore, models that can perform\nimage-to-image translation often need distinct models for each domain, making\nit hard to scale these systems to multiple domain image-to-image translation.\nWe introduce a model that can do both, controllable image generation and\nimage-to-image translation between multiple domains. We split our image\nrepresentation into two parts encoding unstructured and structured information\nrespectively. The latter is designed in a disentangled manner, so that\ndifferent parts encode different image characteristics. We train an encoder to\nencode images into these representations and use a small amount of labeled data\nto specify what kind of information should be encoded in the disentangled part.\nA generator is trained to generate images from these representations using the\ncharacteristics provided by the disentangled part of the representation.\nThrough this we can control what kind of images the generator generates,\ntranslate images between different domains, and even learn unknown\ndata-generating factors while only using one single model.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 12:53:01 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Hinz", "Tobias", ""], ["Wermter", "Stefan", ""]]}, {"id": "1803.10590", "submitter": "Alexander Shekhovtsov", "authors": "Alexander Shekhovtsov and Boris Flach and Michal Busta", "title": "Feed-forward Uncertainty Propagation in Belief and Neural Networks", "comments": "error corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a feed-forward inference method applicable to belief and neural\nnetworks. In a belief network, the method estimates an approximate factorized\nposterior of all hidden units given the input. In neural networks the method\npropagates uncertainty of the input through all the layers. In neural networks\nwith injected noise, the method analytically takes into account uncertainties\nresulting from this noise. Such feed-forward analytic propagation is\ndifferentiable in parameters and can be trained end-to-end. Compared to\nstandard NN, which can be viewed as propagating only the means, we propagate\nthe mean and variance. The method can be useful in all scenarios that require\nknowledge of the neuron statistics, e.g. when dealing with uncertain inputs,\nconsidering sigmoid activations as probabilities of Bernoulli units, training\nthe models regularized by injected noise (dropout) or estimating activation\nstatistics over the dataset (as needed for normalization methods). In the\nexperiments we show the possible utility of the method in all these tasks as\nwell as its current limitations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 13:26:47 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 17:02:02 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Shekhovtsov", "Alexander", ""], ["Flach", "Boris", ""], ["Busta", "Michal", ""]]}, {"id": "1803.10615", "submitter": "Amir Gholami", "authors": "Amir Gholami and Kiseok Kwon and Bichen Wu and Zizheng Tai and Xiangyu\n  Yue and Peter Jin and Sicheng Zhao and Kurt Keutzer", "title": "SqueezeNext: Hardware-Aware Neural Network Design", "comments": "12 Pages", "journal-ref": "Design Automation Conference 2018 (and CVPR 2018 workshop)", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main barriers for deploying neural networks on embedded systems\nhas been large memory and power consumption of existing neural networks. In\nthis work, we introduce SqueezeNext, a new family of neural network\narchitectures whose design was guided by considering previous architectures\nsuch as SqueezeNet, as well as by simulation results on a neural network\naccelerator. This new network is able to match AlexNet's accuracy on the\nImageNet benchmark with $112\\times$ fewer parameters, and one of its deeper\nvariants is able to achieve VGG-19 accuracy with only 4.4 Million parameters,\n($31\\times$ smaller than VGG-19). SqueezeNext also achieves better top-5\nclassification accuracy with $1.3\\times$ fewer parameters as compared to\nMobileNet, but avoids using depthwise-separable convolutions that are\ninefficient on some mobile processor platforms. This wide range of accuracy\ngives the user the ability to make speed-accuracy tradeoffs, depending on the\navailable resources on the target hardware. Using hardware simulation results\nfor power and inference speed on an embedded system has guided us to design\nvariations of the baseline model that are $2.59\\times$/$8.26\\times$ faster and\n$2.25\\times$/$7.5\\times$ more energy efficient as compared to\nSqueezeNet/AlexNet without any accuracy degradation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 16:40:30 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 18:38:51 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Gholami", "Amir", ""], ["Kwon", "Kiseok", ""], ["Wu", "Bichen", ""], ["Tai", "Zizheng", ""], ["Yue", "Xiangyu", ""], ["Jin", "Peter", ""], ["Zhao", "Sicheng", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1803.10837", "submitter": "Nikolaos Passalis", "authors": "Nikolaos Passalis and Anastasios Tefas", "title": "Learning Deep Representations with Probabilistic Knowledge Transfer", "comments": "Accepted at ECCV2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge Transfer (KT) techniques tackle the problem of transferring the\nknowledge from a large and complex neural network into a smaller and faster\none. However, existing KT methods are tailored towards classification tasks and\nthey cannot be used efficiently for other representation learning tasks. In\nthis paper a novel knowledge transfer technique, that is capable of training a\nstudent model that maintains the same amount of mutual information between the\nlearned representation and a set of (possible unknown) labels as the teacher\nmodel, is proposed. Apart from outperforming existing KT techniques, the\nproposed method allows for overcoming several limitations of existing methods\nproviding new insight into KT as well as novel KT applications, ranging from\nknowledge transfer from handcrafted feature extractors to {cross-modal} KT from\nthe textual modality into the representation extracted from the visual modality\nof the data.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 20:14:08 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 19:03:32 GMT"}, {"version": "v3", "created": "Wed, 20 Mar 2019 07:45:15 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Passalis", "Nikolaos", ""], ["Tefas", "Anastasios", ""]]}, {"id": "1803.11389", "submitter": "Jinhwan Park", "authors": "Wonyong Sung, Jinhwan Park", "title": "Single Stream Parallelization of Recurrent Neural Networks for Low Power\n  and Fast Inference", "comments": "Submitted to International Conference on Embedded Computer Systems:\n  Architectures, MOdeling and Simulation (SAMOS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural network algorithms show high performance in many applications,\ntheir efficient inference on mobile and embedded systems are of great\ninterests. When a single stream recurrent neural network (RNN) is executed for\na personal user in embedded systems, it demands a large amount of DRAM accesses\nbecause the network size is usually much bigger than the cache size and the\nweights of an RNN are used only once at each time step. We overcome this\nproblem by parallelizing the algorithm and executing it multiple time steps at\na time. This approach also reduces the power consumption by lowering the number\nof DRAM accesses. QRNN (Quasi Recurrent Neural Networks) and SRU (Simple\nRecurrent Unit) based recurrent neural networks are used for implementation.\nThe experiments for SRU showed about 300% and 930% of speed-up when the numbers\nof multi time steps are 4 and 16, respectively, in an ARM CPU based system.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 09:15:07 GMT"}], "update_date": "2018-04-02", "authors_parsed": [["Sung", "Wonyong", ""], ["Park", "Jinhwan", ""]]}, {"id": "1803.11395", "submitter": "Guanbin Li", "authors": "Guanbin Li and Yizhou Yu", "title": "Contrast-Oriented Deep Neural Networks for Salient Object Detection", "comments": "Accept to TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks have become a key element in the recent\nbreakthrough of salient object detection. However, existing CNN-based methods\nare based on either patch-wise (region-wise) training and inference or fully\nconvolutional networks. Methods in the former category are generally\ntime-consuming due to severe storage and computational redundancies among\noverlapping patches. To overcome this deficiency, methods in the second\ncategory attempt to directly map a raw input image to a predicted dense\nsaliency map in a single network forward pass. Though being very efficient, it\nis arduous for these methods to detect salient objects of different scales or\nsalient regions with weak semantic information. In this paper, we develop\nhybrid contrast-oriented deep neural networks to overcome the aforementioned\nlimitations. Each of our deep networks is composed of two complementary\ncomponents, including a fully convolutional stream for dense prediction and a\nsegment-level spatial pooling stream for sparse saliency inference. We further\npropose an attentional module that learns weight maps for fusing the two\nsaliency predictions from these two streams. A tailored alternate scheme is\ndesigned to train these deep networks by fine-tuning pre-trained baseline\nmodels. Finally, a customized fully connected CRF model incorporating a salient\ncontour feature embedding can be optionally applied as a post-processing step\nto improve spatial coherence and contour positioning in the fused result from\nthese two streams. Extensive experiments on six benchmark datasets demonstrate\nthat our proposed model can significantly outperform the state of the art in\nterms of all popular evaluation metrics.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 09:51:04 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Li", "Guanbin", ""], ["Yu", "Yizhou", ""]]}, {"id": "1803.11410", "submitter": "Amnon Drory", "authors": "Amnon Drory, Oria Ratzon, Shai Avidan, Raja Giryes", "title": "The Resistance to Label Noise in K-NN and DNN Depends on its\n  Concentration", "comments": "None", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the classification performance of K-nearest neighbors (K-NN)\nand deep neural networks (DNNs) in the presence of label noise. We first show\nempirically that a DNN's prediction for a given test example depends on the\nlabels of the training examples in its local neighborhood. This motivates us to\nderive a realizable analytic expression that approximates the multi-class K-NN\nclassification error in the presence of label noise, which is of independent\nimportance. We then suggest that the expression for K-NN may serve as a\nfirst-order approximation for the DNN error. Finally, we demonstrate\nempirically the proximity of the developed expression to the observed\nperformance of K-NN and DNN classifiers. Our result may explain the already\nobserved surprising resistance of DNN to some types of label noise. It also\ncharacterizes an important factor of it showing that the more concentrated the\nnoise the greater is the degradation in performance.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 11:06:43 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 13:49:57 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2020 09:18:17 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Drory", "Amnon", ""], ["Ratzon", "Oria", ""], ["Avidan", "Shai", ""], ["Giryes", "Raja", ""]]}, {"id": "1803.11469", "submitter": "Amaury Depierre", "authors": "Amaury Depierre (imagine), Emmanuel Dellandr\\'ea (imagine), Liming\n  Chen (imagine)", "title": "Jacquard: A Large Scale Dataset for Robotic Grasp Detection", "comments": null, "journal-ref": "IEEE/RSJ International Conference on Intelligent Robots and\n  Systems, Oct 2018, Madrid, Spain", "doi": null, "report-no": null, "categories": "cs.RO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grasping skill is a major ability that a wide number of real-life\napplications require for robotisation. State-of-the-art robotic grasping\nmethods perform prediction of object grasp locations based on deep neural\nnetworks. However, such networks require huge amount of labeled data for\ntraining making this approach often impracticable in robotics. In this paper,\nwe propose a method to generate a large scale synthetic dataset with ground\ntruth, which we refer to as the Jacquard grasping dataset. Jacquard is built on\na subset of ShapeNet, a large CAD models dataset, and contains both RGB-D\nimages and annotations of successful grasping positions based on grasp attempts\nperformed in a simulated environment. We carried out experiments using an\noff-the-shelf CNN, with three different evaluation metrics, including real\ngrasping robot trials. The results show that Jacquard enables much better\ngeneralization skills than a human labeled dataset thanks to its diversity of\nobjects and grasping positions. For the purpose of reproducible research in\nrobotics, we are releasing along with the Jacquard dataset a web interface for\nresearchers to evaluate the successfulness of their grasping position\ndetections using our dataset.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 13:56:19 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 12:01:18 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Depierre", "Amaury", "", "imagine"], ["Dellandr\u00e9a", "Emmanuel", "", "imagine"], ["Chen", "Liming", "", "imagine"]]}]