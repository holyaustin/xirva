[{"id": "2012.00101", "submitter": "Abhinav Anand", "authors": "Abhinav Anand, Matthias Degroote, and Al\\'an Aspuru-Guzik", "title": "Natural Evolutionary Strategies for Variational Quantum Computation", "comments": null, "journal-ref": null, "doi": "10.1088/2632-2153/abf3ac", "report-no": null, "categories": "quant-ph cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural evolutionary strategies (NES) are a family of gradient-free black-box\noptimization algorithms. This study illustrates their use for the optimization\nof randomly-initialized parametrized quantum circuits (PQCs) in the region of\nvanishing gradients. We show that using the NES gradient estimator the\nexponential decrease in variance can be alleviated. We implement two specific\napproaches, the exponential and separable natural evolutionary strategies, for\nparameter optimization of PQCs and compare them against standard gradient\ndescent. We apply them to two different problems of ground state energy\nestimation using variational quantum eigensolver (VQE) and state preparation\nwith circuits of varying depth and length. We also introduce batch optimization\nfor circuits with larger depth to extend the use of evolutionary strategies to\na larger number of parameters. We achieve accuracy comparable to\nstate-of-the-art optimization techniques in all the above cases with a lower\nnumber of circuit evaluations. Our empirical results indicate that one can use\nNES as a hybrid tool in tandem with other gradient-based methods for\noptimization of deep quantum circuits in regions with vanishing gradients.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 21:23:38 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 17:15:50 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Anand", "Abhinav", ""], ["Degroote", "Matthias", ""], ["Aspuru-Guzik", "Al\u00e1n", ""]]}, {"id": "2012.00152", "submitter": "Pedro Domingos", "authors": "Pedro Domingos", "title": "Every Model Learned by Gradient Descent Is Approximately a Kernel\n  Machine", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning's successes are often attributed to its ability to\nautomatically discover new representations of the data, rather than relying on\nhandcrafted features like other learning methods. We show, however, that deep\nnetworks learned by the standard gradient descent algorithm are in fact\nmathematically approximately equivalent to kernel machines, a learning method\nthat simply memorizes the data and uses it directly for prediction via a\nsimilarity function (the kernel). This greatly enhances the interpretability of\ndeep network weights, by elucidating that they are effectively a superposition\nof the training examples. The network architecture incorporates knowledge of\nthe target function into the kernel. This improved understanding should lead to\nbetter learning algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 23:02:47 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Domingos", "Pedro", ""]]}, {"id": "2012.00176", "submitter": "Clement Nyirenda", "authors": "Dineshan Subramoney, Clement N. Nyirenda", "title": "A Comparative Evaluation of Population-based Optimization Algorithms for\n  Workflow Scheduling in Cloud-Fog Environments", "comments": "8 pages", "journal-ref": "2020 IEEE Symposium Series on Computational Intelligence (SSCI)\n  (SSCI 2020)", "doi": null, "report-no": null, "categories": "cs.NE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a comparative evaluation of four population-based\noptimization algorithms for workflow scheduling in cloud-fog environments.\nThese algorithms are as follows: Particle Swarm Optimization (PSO), Genetic\nAlgorithm (GA), Differential Evolution (DE) and GA-PSO. This work also provides\nthe motivational groundwork for the weighted sum objective function for the\nworkflow scheduling problem and develops this function based on three\nobjectives: makespan, cost and energy. The recently proposed FogWorkflowSim is\nused as the simulation environment with the aforementioned objectives serving\nperformance metrics. Results show that hybrid combination of the GA-PSO\nalgorithm exhibits slightly better than the standard algorithms. Future work\nwill include expansion of the workflows used by increasing the number of tasks\nas well as adding some more workflows. The addition of some more objectives to\nthe weighted objective function will also be pursued\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 23:58:05 GMT"}, {"version": "v2", "created": "Sat, 12 Dec 2020 17:39:21 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Subramoney", "Dineshan", ""], ["Nyirenda", "Clement N.", ""]]}, {"id": "2012.00194", "submitter": "Luca Saglietti", "authors": "Luca Saglietti and Lenka Zdeborov\\'a", "title": "Solvable Model for Inheriting the Regularization through Knowledge\n  Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years the empirical success of transfer learning with neural\nnetworks has stimulated an increasing interest in obtaining a theoretical\nunderstanding of its core properties. Knowledge distillation where a smaller\nneural network is trained using the outputs of a larger neural network is a\nparticularly interesting case of transfer learning. In the present work, we\nintroduce a statistical physics framework that allows an analytic\ncharacterization of the properties of knowledge distillation (KD) in shallow\nneural networks. Focusing the analysis on a solvable model that exhibits a\nnon-trivial generalization gap, we investigate the effectiveness of KD. We are\nable to show that, through KD, the regularization properties of the larger\nteacher model can be inherited by the smaller student and that the yielded\ngeneralization performance is closely linked to and limited by the optimality\nof the teacher. Finally, we analyze the double descent phenomenology that can\narise in the considered KD setting.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 01:01:34 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 16:55:14 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Saglietti", "Luca", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "2012.00596", "submitter": "Zhengang Li", "authors": "Zhengang Li, Geng Yuan, Wei Niu, Pu Zhao, Yanyu Li, Yuxuan Cai, Xuan\n  Shen, Zheng Zhan, Zhenglun Kong, Qing Jin, Zhiyu Chen, Sijia Liu, Kaiyuan\n  Yang, Bin Ren, Yanzhi Wang, Xue Lin", "title": "NPAS: A Compiler-aware Framework of Unified Network Pruning and\n  Architecture Search for Beyond Real-Time Mobile Acceleration", "comments": "Accepted as an oral paper in the Conference on Computer Vision and\n  Pattern Recognition (CVPR), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing demand to efficiently deploy DNNs on mobile edge devices,\nit becomes much more important to reduce unnecessary computation and increase\nthe execution speed. Prior methods towards this goal, including model\ncompression and network architecture search (NAS), are largely performed\nindependently and do not fully consider compiler-level optimizations which is a\nmust-do for mobile acceleration. In this work, we first propose (i) a general\ncategory of fine-grained structured pruning applicable to various DNN layers,\nand (ii) a comprehensive, compiler automatic code generation framework\nsupporting different DNNs and different pruning schemes, which bridge the gap\nof model compression and NAS. We further propose NPAS, a compiler-aware unified\nnetwork pruning, and architecture search. To deal with large search space, we\npropose a meta-modeling procedure based on reinforcement learning with fast\nevaluation and Bayesian optimization, ensuring the total number of training\nepochs comparable with representative NAS frameworks. Our framework achieves\n6.7ms, 5.9ms, 3.9ms ImageNet inference times with 78.2%, 75% (MobileNet-V3\nlevel), and 71% (MobileNet-V2 level) Top-1 accuracy respectively on an\noff-the-shelf mobile phone, consistently outperforming prior work.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 16:03:40 GMT"}, {"version": "v2", "created": "Sun, 25 Apr 2021 04:18:34 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 00:07:48 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Li", "Zhengang", ""], ["Yuan", "Geng", ""], ["Niu", "Wei", ""], ["Zhao", "Pu", ""], ["Li", "Yanyu", ""], ["Cai", "Yuxuan", ""], ["Shen", "Xuan", ""], ["Zhan", "Zheng", ""], ["Kong", "Zhenglun", ""], ["Jin", "Qing", ""], ["Chen", "Zhiyu", ""], ["Liu", "Sijia", ""], ["Yang", "Kaiyuan", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""], ["Lin", "Xue", ""]]}, {"id": "2012.00886", "submitter": "Hao Wang", "authors": "Hao Wang and Carlos Igncio Hern\\'andez Castellanos and Tome Eftimov", "title": "On Statistical Analysis of MOEAs with Multiple Performance Indicators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Assessing the empirical performance of Multi-Objective Evolutionary\nAlgorithms (MOEAs) is vital when we extensively test a set of MOEAs and aim to\ndetermine a proper ranking thereof. Multiple performance indicators, e.g., the\ngenerational distance and the hypervolume, are frequently applied when\nreporting the experimental data, where typically the data on each indicator is\nanalyzed independently from other indicators. Such a treatment brings\nconceptual difficulties in aggregating the result on all performance\nindicators, and it might fail to discover significant differences among\nalgorithms if the marginal distributions of the performance indicator overlap.\nTherefore, in this paper, we propose to conduct a multivariate\n$\\mathcal{E}$-test on the joint empirical distribution of performance\nindicators to detect the potential difference in the data, followed by a\npost-hoc procedure that utilizes the linear discriminative analysis to\ndetermine the superiority between algorithms. This performance analysis's\neffectiveness is supported by an experimentation conducted on four algorithms,\n16 problems, and 6 different numbers of objectives.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 23:12:10 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Wang", "Hao", ""], ["Castellanos", "Carlos Igncio Hern\u00e1ndez", ""], ["Eftimov", "Tome", ""]]}, {"id": "2012.01118", "submitter": "Marco A. Armenta", "authors": "Marco Armenta, Thierry Judge, Nathan Painchaud, Youssef Skandarani,\n  Carl Lemaire, Gabriel Gibeau Sanchez, Philippe Spino, Pierre-Marc Jodoin", "title": "Neural Teleportation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce neural teleportation, a simple operation one can\nuse to initialize the weights of a neural network and gain faster convergence.\nNeural teleportation is the consequence of applying isomorphisms of quiver\nrepresentations to neural networks. This process \"teleports\" a network to a new\nposition in the weight space while leaving its input-to-output function\nunchanged. The concept of neural teleportation generalizes to any neural\nnetwork architecture, activation function and task. We run several experiments\nthat validate our hypothesis: teleporting a network at initialization speeds-up\nconvergence. Finally, we discuss several mathematical and empirical findings\nconcerning teleportation.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 12:18:23 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 13:47:00 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Armenta", "Marco", ""], ["Judge", "Thierry", ""], ["Painchaud", "Nathan", ""], ["Skandarani", "Youssef", ""], ["Lemaire", "Carl", ""], ["Sanchez", "Gabriel Gibeau", ""], ["Spino", "Philippe", ""], ["Jodoin", "Pierre-Marc", ""]]}, {"id": "2012.01244", "submitter": "Anssi Kanervisto", "authors": "Anssi Kanervisto, Tomi Kinnunen, Ville Hautam\\\"aki", "title": "Policy Supervectors: General Characterization of Agents by their\n  Behaviour", "comments": "Code available at https://github.com/Miffyli/policy-supervectors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By studying the underlying policies of decision-making agents, we can learn\nabout their shortcomings and potentially improve them. Traditionally, this has\nbeen done either by examining the agent's implementation, its behaviour while\nit is being executed, its performance with a reward/fitness function or by\nvisualizing the density of states the agent visits. However, these methods fail\nto describe the policy's behaviour in complex, high-dimensional environments or\ndo not scale to thousands of policies, which is required when studying training\nalgorithms. We propose policy supervectors for characterizing agents by the\ndistribution of states they visit, adopting successful techniques from the area\nof speech technology. Policy supervectors can characterize policies regardless\nof their design philosophy (e.g. rule-based vs. neural networks) and scale to\nthousands of policies on a single workstation machine. We demonstrate method's\napplicability by studying the evolution of policies during reinforcement\nlearning, evolutionary training and imitation learning, providing insight on\ne.g. how the search space of evolutionary algorithms is also reflected in\nagent's behaviour, not just in the parameters.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 14:43:16 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Kanervisto", "Anssi", ""], ["Kinnunen", "Tomi", ""], ["Hautam\u00e4ki", "Ville", ""]]}, {"id": "2012.01409", "submitter": "Thomas Carroll", "authors": "Thomas L. Carroll", "title": "Do Reservoir Computers Work Best at the Edge of Chaos?", "comments": null, "journal-ref": null, "doi": "10.1063/5.0038163", "report-no": null, "categories": "cs.NE nlin.CD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It has been demonstrated that cellular automata had the highest computational\ncapacity at the edge of chaos, the parameter at which their behavior\ntransitioned from ordered to chaotic. This same concept has been applied to\nreservoir computers; a number of researchers have stated that the highest\ncomputational capacity for a reservoir computer is at the edge of chaos,\nalthough others have suggested that this rule is not universally true. Because\nmany reservoir computers do not show chaotic behavior but merely become\nunstable, it is felt that a more accurate term for this instability transition\nis the \"edge of stability\"Here I find two examples where the computational\ncapacity of a reservoir computer decreases as the edge of stability is\napproached; in one case, because generalized synchronization breaks down, and\nin the other case because the reservoir computer is a poor match to the problem\nbeing solved. The edge of stability as an optimal operating point for a\nreservoir computer is not in general true, although it may be true in some\ncases.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 18:57:52 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Carroll", "Thomas L.", ""]]}, {"id": "2012.01417", "submitter": "Gaurav Bhardwaj", "authors": "Gaurav Bhardwaj, Utkarsh A. Mishra, N. Sukavanam and R.\n  Balasubramanian", "title": "Cycloidal Trajectory Realization on Staircase based on Neural Network\n  Temporal Quantized Lagrange Dynamics (NNTQLD) with Ant Colony Optimization\n  for a 9-Link Bipedal Robot", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NE cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, a novel optimal technique for joint angles trajectory tracking\ncontrol with energy optimization for a biped robot with toe foot is proposed.\nFor the task of climbing stairs by a 9-link biped model, a cycloid trajectory\nfor swing phase is proposed in such a way that the cycloid variables depend on\nthe staircase dimensions. Zero Moment Point(ZMP) criteria is taken for\nsatisfying stability constraint. This paper mainly can be divided into 3 steps:\n1) Planning stable cycloid trajectory for initial step and subsequent step for\nclimbing upstairs and Inverse Kinematics using an unsupervised artificial\nneural network with knot shifting procedure for jerk minimization. 2) Modeling\nDynamics for Toe foot biped model using Lagrange Dynamics along with contact\nmodeling using spring-damper system followed by developing Neural Network\nTemporal Quantized Lagrange Dynamics which takes inverse kinematics output from\nneural network as its inputs. 3) Using Ant Colony Optimization to tune PD\n(Proportional Derivative) controller parameters and torso angle with the\nobjective to minimize joint space trajectory errors and total energy consumed.\nThree cases with variable staircase dimensions have been taken and a brief\ncomparison is done to verify the effectiveness of our proposed work Generated\npatterns have been simulated in MATLAB .\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 05:50:42 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 12:48:49 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 14:56:47 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Bhardwaj", "Gaurav", ""], ["Mishra", "Utkarsh A.", ""], ["Sukavanam", "N.", ""], ["Balasubramanian", "R.", ""]]}, {"id": "2012.01573", "submitter": "Brian Hutchinson", "authors": "Piper Wolters, Chris Careaga, Brian Hutchinson, Lauren Phillips", "title": "A Study of Few-Shot Audio Classification", "comments": "Presented at GHC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep learning have resulted in state-of-the-art performance for\nmany audio classification tasks but, unlike humans, these systems traditionally\nrequire large amounts of data to make accurate predictions. Not every person or\norganization has access to those resources, and the organizations that do, like\nour field at large, do not reflect the demographics of our country. Enabling\npeople to use machine learning without significant resource hurdles is\nimportant, because machine learning is an increasingly useful tool for solving\nproblems, and can solve a broader set of problems when put in the hands of a\nbroader set of people. Few-shot learning is a type of machine learning designed\nto enable the model to generalize to new classes with very few examples. In\nthis research, we address two audio classification tasks (speaker\nidentification and activity classification) with the Prototypical Network\nfew-shot learning algorithm, and assess performance of various encoder\narchitectures. Our encoders include recurrent neural networks, as well as one-\nand two-dimensional convolutional neural networks. We evaluate our model for\nspeaker identification on the VoxCeleb dataset and ICSI Meeting Corpus,\nobtaining 5-shot 5-way accuracies of 93.5% and 54.0%, respectively. We also\nevaluate for activity classification from audio using few-shot subsets of the\nKinetics~600 dataset and AudioSet, both drawn from Youtube videos, obtaining\n51.5% and 35.2% accuracy, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 22:19:16 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Wolters", "Piper", ""], ["Careaga", "Chris", ""], ["Hutchinson", "Brian", ""], ["Phillips", "Lauren", ""]]}, {"id": "2012.01698", "submitter": "Wei Kang", "authors": "Wei Kang and Qi Gong", "title": "Neural Network Approximations of Compositional Functions With\n  Applications to Dynamical Systems", "comments": "40 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA cs.NE math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As demonstrated in many areas of real-life applications, neural networks have\nthe capability of dealing with high dimensional data. In the fields of optimal\ncontrol and dynamical systems, the same capability was studied and verified in\nmany published results in recent years. Towards the goal of revealing the\nunderlying reason why neural networks are capable of solving some high\ndimensional problems, we develop an algebraic framework and an approximation\ntheory for compositional functions and their neural network approximations. The\ntheoretical foundation is developed in a way so that it supports the error\nanalysis for not only functions as input-output relations, but also numerical\nalgorithms. This capability is critical because it enables the analysis of\napproximation errors for problems for which analytic solutions are not\navailable, such as differential equations and optimal control. We identify a\nset of key features of compositional functions and the relationship between the\nfeatures and the complexity of neural networks. In addition to function\napproximations, we prove several formulae of error upper bounds for neural\nnetworks that approximate the solutions to differential equations,\noptimization, and optimal control.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 04:40:25 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Kang", "Wei", ""], ["Gong", "Qi", ""]]}, {"id": "2012.01748", "submitter": "Alexandre Variengien", "authors": "Alexandre Variengien and Xavier Hinaut", "title": "A journey in ESN and LSTM visualisations on a language task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Echo States Networks (ESN) and Long-Short Term Memory networks (LSTM) are two\npopular architectures of Recurrent Neural Networks (RNN) to solve machine\nlearning task involving sequential data. However, little have been done to\ncompare their performances and their internal mechanisms on a common task. In\nthis work, we trained ESNs and LSTMs on a Cross-Situationnal Learning (CSL)\ntask. This task aims at modelling how infants learn language: they create\nassociations between words and visual stimuli in order to extract meaning from\nwords and sentences. The results are of three kinds: performance comparison,\ninternal dynamics analyses and visualization of latent space. (1) We found that\nboth models were able to successfully learn the task: the LSTM reached the\nlowest error for the basic corpus, but the ESN was quicker to train.\nFurthermore, the ESN was able to outperform LSTMs on datasets more challenging\nwithout any further tuning needed. (2) We also conducted an analysis of the\ninternal units activations of LSTMs and ESNs. Despite the deep differences\nbetween both models (trained or fixed internal weights), we were able to\nuncover similar inner mechanisms: both put emphasis on the units encoding\naspects of the sentence structure. (3) Moreover, we present Recurrent States\nSpace Visualisations (RSSviz), a method to visualize the structure of latent\nstate space of RNNs, based on dimension reduction (using UMAP). This technique\nenables us to observe a fractal embedding of sequences in the LSTM. RSSviz is\nalso useful for the analysis of ESNs (i) to spot difficult examples and (ii) to\ngenerate animated plots showing the evolution of activations across learning\nstages. Finally, we explore qualitatively how the RSSviz could provide an\nintuitive visualisation to understand the influence of hyperparameters on the\nreservoir dynamics prior to ESN training.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 08:32:01 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 16:06:12 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Variengien", "Alexandre", ""], ["Hinaut", "Xavier", ""]]}, {"id": "2012.01830", "submitter": "Mojtaba Shakeri", "authors": "Mojtaba Shakeri, Erfan Miahi, Abhishek Gupta and Yew-Soon Ong", "title": "Scalable Transfer Evolutionary Optimization: Coping with Big Task\n  Instances", "comments": "12 pages, 5 figures, 2 tables, 2 algorithm pseudocodes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In today's digital world, we are confronted with an explosion of data and\nmodels produced and manipulated by numerous large-scale IoT/cloud-based\napplications. Under such settings, existing transfer evolutionary optimization\nframeworks grapple with satisfying two important quality attributes, namely\nscalability against a growing number of source tasks and online learning\nagility against sparsity of relevant sources to the target task of interest.\nSatisfying these attributes shall facilitate practical deployment of transfer\noptimization to big source instances as well as simultaneously curbing the\nthreat of negative transfer. While applications of existing algorithms are\nlimited to tens of source tasks, in this paper, we take a quantum leap forward\nin enabling two orders of magnitude scale-up in the number of tasks; i.e., we\nefficiently handle scenarios with up to thousands of source problem instances.\nWe devise a novel transfer evolutionary optimization framework comprising two\nco-evolving species for joint evolutions in the space of source knowledge and\nin the search space of solutions to the target problem. In particular,\nco-evolution enables the learned knowledge to be orchestrated on the fly,\nexpediting convergence in the target optimization task. We have conducted an\nextensive series of experiments across a set of practically motivated discrete\nand continuous optimization examples comprising a large number of source\nproblem instances, of which only a small fraction show source-target\nrelatedness. The experimental results strongly validate the efficacy of our\nproposed framework with two salient features of scalability and online learning\nagility.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 11:07:26 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Shakeri", "Mojtaba", ""], ["Miahi", "Erfan", ""], ["Gupta", "Abhishek", ""], ["Ong", "Yew-Soon", ""]]}, {"id": "2012.01867", "submitter": "Toni Schneidereit", "authors": "Toni Schneidereit and Michael Breu{\\ss}", "title": "Computational characteristics of feedforward neural networks for solving\n  a stiff differential equation", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feedforward neural networks offer a promising approach for solving\ndifferential equations. However, the reliability and accuracy of the\napproximation still represent delicate issues that are not fully resolved in\nthe current literature. Computational approaches are in general highly\ndependent on a variety of computational parameters as well as on the choice of\noptimisation methods, a point that has to be seen together with the structure\nof the cost function. The intention of this paper is to make a step towards\nresolving these open issues. To this end we study here the solution of a simple\nbut fundamental stiff ordinary differential equation modelling a damped system.\nWe consider two computational approaches for solving differential equations by\nneural forms. These are the classic but still actual method of trial solutions\ndefining the cost function, and a recent direct construction of the cost\nfunction related to the trial solution method. Let us note that the settings we\nstudy can easily be applied more generally, including solution of partial\ndifferential equations. By a very detailed computational study we show that it\nis possible to identify preferable choices to be made for parameters and\nmethods. We also illuminate some interesting effects that are observable in the\nneural network simulations. Overall we extend the current literature in the\nfield by showing what can be done in order to obtain reliable and accurate\nresults by the neural network approach. By doing this we illustrate the\nimportance of a careful choice of the computational setup.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 12:22:24 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Schneidereit", "Toni", ""], ["Breu\u00df", "Michael", ""]]}, {"id": "2012.02097", "submitter": "Benjamin Paassen", "authors": "Benjamin Paassen, Irena Koprinska, Kalina Yacef", "title": "Recursive Tree Grammar Autoencoders", "comments": "Submitted to IEEE TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning on tree data has been mostly focused on trees as input. Much\nless research has investigates trees as output, like in molecule optimization\nfor drug discovery or hint generation for intelligent tutoring systems. In this\nwork, we propose a novel autoencoder approach, called recursive tree grammar\nautoencoder (RTG-AE), which encodes trees via a bottom-up parser and decodes\ntrees via a tree grammar, both controlled by neural networks that minimize the\nvariational autoencoder loss. The resulting encoding and decoding functions can\nthen be employed in subsequent tasks, such as optimization and time series\nprediction. RTG-AE combines variational autoencoders, grammatical knowledge,\nand recursive processing. Our key message is that this combination improves\nperformance compared to only combining two of these three components. In\nparticular, we show experimentally that our proposed method improves the\nautoencoding error, training time, and optimization score on four benchmark\ndatasets compared to baselines from the literature.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 17:37:25 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 13:06:01 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Paassen", "Benjamin", ""], ["Koprinska", "Irena", ""], ["Yacef", "Kalina", ""]]}, {"id": "2012.02223", "submitter": "Trevor Londt", "authors": "Trevor Londt, Xiaoying Gao, Bing Xue, Peter Andreae", "title": "Evolving Character-level Convolutional Neural Networks for Text\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Character-level convolutional neural networks (char-CNN) require no knowledge\nof the semantic or syntactic structure of the language they classify. This\nproperty simplifies its implementation but reduces its classification accuracy.\nIncreasing the depth of char-CNN architectures does not result in breakthrough\naccuracy improvements. Research has not established which char-CNN\narchitectures are optimal for text classification tasks. Manually designing and\ntraining char-CNNs is an iterative and time-consuming process that requires\nexpert domain knowledge. Evolutionary deep learning (EDL) techniques, including\nsurrogate-based versions, have demonstrated success in automatically searching\nfor performant CNN architectures for image analysis tasks. Researchers have not\napplied EDL techniques to search the architecture space of char-CNNs for text\nclassification tasks. This article demonstrates the first work in evolving\nchar-CNN architectures using a novel EDL algorithm based on genetic\nprogramming, an indirect encoding and surrogate models, to search for\nperformant char-CNN architectures automatically. The algorithm is evaluated on\neight text classification datasets and benchmarked against five manually\ndesigned CNN architecture and one long short-term memory (LSTM) architecture.\nExperiment results indicate that the algorithm can evolve architectures that\noutperform the LSTM in terms of classification accuracy and five of the\nmanually designed CNN architectures in terms of classification accuracy and\nparameter count.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 19:27:29 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Londt", "Trevor", ""], ["Gao", "Xiaoying", ""], ["Xue", "Bing", ""], ["Andreae", "Peter", ""]]}, {"id": "2012.02260", "submitter": "Eric L. Manibardo", "authors": "Eric L. Manibardo, Ibai La\\~na and Javier Del Ser", "title": "Deep Learning for Road Traffic Forecasting: Does it Make a Difference?", "comments": "25 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning methods have been proven to be flexible to model complex\nphenomena. This has also been the case of Intelligent Transportation Systems\n(ITS), in which several areas such as vehicular perception and traffic analysis\nhave widely embraced Deep Learning as a core modeling technology. Particularly\nin short-term traffic forecasting, the capability of Deep Learning to deliver\ngood results has generated a prevalent inertia towards using Deep Learning\nmodels, without examining in depth their benefits and downsides. This paper\nfocuses on critically analyzing the state of the art in what refers to the use\nof Deep Learning for this particular ITS research area. To this end, we\nelaborate on the findings distilled from a review of publications from recent\nyears, based on two taxonomic criteria. A posterior critical analysis is held\nto formulate questions and trigger a necessary debate about the issues of Deep\nLearning for traffic forecasting. The study is completed with a benchmark of\ndiverse short-term traffic forecasting methods over traffic datasets of\ndifferent nature, aimed to cover a wide spectrum of possible scenarios. Our\nexperimentation reveals that Deep Learning could not be the best modeling\ntechnique for every case, which unveils some caveats unconsidered to date that\nshould be addressed by the community in prospective studies. These insights\nreveal new challenges and research opportunities in road traffic forecasting,\nwhich are enumerated and discussed thoroughly, with the intention of inspiring\nand guiding future research efforts in this field.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 15:56:11 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Manibardo", "Eric L.", ""], ["La\u00f1a", "Ibai", ""], ["Del Ser", "Javier", ""]]}, {"id": "2012.02327", "submitter": "Trevor Londt", "authors": "Trevor Londt, Xiaoying Gao, Peter Andreae", "title": "Evolving Character-Level DenseNet Architectures using Genetic\n  Programming", "comments": "Submitted to EvoStar 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DenseNet architectures have demonstrated impressive performance in image\nclassification tasks, but limited research has been conducted on using\ncharacter-level DenseNet (char-DenseNet) architectures for text classification\ntasks. It is not clear what DenseNet architectures are optimal for text\nclassification tasks. The iterative task of designing, training and testing of\nchar-DenseNets is an NP-Hard problem that requires expert domain knowledge.\nEvolutionary deep learning (EDL) has been used to automatically design CNN\narchitectures for the image classification domain, thereby mitigating the need\nfor expert domain knowledge. This study demonstrates the first work on using\nEDL to evolve char-DenseNet architectures for text classification tasks. A\nnovel genetic programming-based algorithm (GP-Dense) coupled with an\nindirect-encoding scheme, facilitates the evolution of performant char DenseNet\narchitectures. The algorithm is evaluated on two popular text datasets, and the\nbest-evolved models are benchmarked against four current state-of-the-art\ncharacter-level CNN and DenseNet models. Results indicate that the algorithm\nevolves performant models for both datasets that outperform two of the\nstate-of-the-art models in terms of model accuracy and three of the\nstate-of-the-art models in terms of parameter size.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 23:28:56 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Londt", "Trevor", ""], ["Gao", "Xiaoying", ""], ["Andreae", "Peter", ""]]}, {"id": "2012.02659", "submitter": "Shriraj Sawant", "authors": "Shriraj P. Sawant and Shruti Singh", "title": "Understanding Attention: In Minds and Machines", "comments": "Accepted at NeurIPS 2020 Workshop: ML Retrospectives, Surveys &\n  Meta-Analyses (ML-RSA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention is a complex and broad concept, studied across multiple disciplines\nspanning artificial intelligence, cognitive science, psychology, neuroscience,\nand related fields. Although many of the ideas regarding attention do not\nsignificantly overlap among these fields, there is a common theme of adaptive\ncontrol of limited resources. In this work, we review the concept and variants\nof attention in artificial neural networks (ANNs). We also discuss the origin\nof attention from the neuroscience point of view parallel to that of ANNs.\nInstead of having seemingly disconnected dialogues between varied disciplines,\nwe suggest grounding the ideas on common conceptual frameworks for a systematic\nanalysis of attention and towards possible unification of ideas in AI and\nNeuroscience.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 15:35:17 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Sawant", "Shriraj P.", ""], ["Singh", "Shruti", ""]]}, {"id": "2012.02909", "submitter": "Huan Wang", "authors": "Huan Wang, Suhas Lohit, Michael Jones, Yun Fu", "title": "Knowledge Distillation Thrives on Data Augmentation", "comments": "Code will be updated soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is a general deep neural network training\nframework that uses a teacher model to guide a student model. Many works have\nexplored the rationale for its success, however, its interplay with data\naugmentation (DA) has not been well recognized so far. In this paper, we are\nmotivated by an interesting observation in classification: KD loss can benefit\nfrom extended training iterations while the cross-entropy loss does not. We\nshow this disparity arises because of data augmentation: KD loss can tap into\nthe extra information from different input views brought by DA. By this\nexplanation, we propose to enhance KD via a stronger data augmentation scheme\n(e.g., mixup, CutMix). Furthermore, an even stronger new DA approach is\ndeveloped specifically for KD based on the idea of active learning. The\nfindings and merits of the proposed method are validated by extensive\nexperiments on CIFAR-100, Tiny ImageNet, and ImageNet datasets. We can achieve\nimproved performance simply by using the original KD loss combined with\nstronger augmentation schemes, compared to existing state-of-the-art methods,\nwhich employ more advanced distillation losses. In addition, when our\napproaches are combined with more advanced distillation losses, we can advance\nthe state-of-the-art performance even more. On top of the encouraging\nperformance, this paper also sheds some light on explaining the success of\nknowledge distillation. The discovered interplay between KD and DA may inspire\nmore advanced KD algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 00:32:04 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Wang", "Huan", ""], ["Lohit", "Suhas", ""], ["Jones", "Michael", ""], ["Fu", "Yun", ""]]}, {"id": "2012.02911", "submitter": "Huan Wang", "authors": "Huan Wang, Suhas Lohit, Michael Jones, Yun Fu", "title": "Multi-head Knowledge Distillation for Model Compression", "comments": "Copyright: 2020 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several methods of knowledge distillation have been developed for neural\nnetwork compression. While they all use the KL divergence loss to align the\nsoft outputs of the student model more closely with that of the teacher, the\nvarious methods differ in how the intermediate features of the student are\nencouraged to match those of the teacher. In this paper, we propose a\nsimple-to-implement method using auxiliary classifiers at intermediate layers\nfor matching features, which we refer to as multi-head knowledge distillation\n(MHKD). We add loss terms for training the student that measure the\ndissimilarity between student and teacher outputs of the auxiliary classifiers.\nAt the same time, the proposed method also provides a natural way to measure\ndifferences at the intermediate layers even though the dimensions of the\ninternal teacher and student features may be different. Through several\nexperiments in image classification on multiple datasets we show that the\nproposed method outperforms prior relevant approaches presented in the\nliterature.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 00:49:14 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Wang", "Huan", ""], ["Lohit", "Suhas", ""], ["Jones", "Michael", ""], ["Fu", "Yun", ""]]}, {"id": "2012.02974", "submitter": "Chenxi Sun", "authors": "Chenxi Sun and Moxian Song and Shenda Hong and Hongyan Li", "title": "A Review of Designs and Applications of Echo State Networks", "comments": "37 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrent Neural Networks (RNNs) have demonstrated their outstanding ability\nin sequence tasks and have achieved state-of-the-art in wide range of\napplications, such as industrial, medical, economic and linguistic. Echo State\nNetwork (ESN) is simple type of RNNs and has emerged in the last decade as an\nalternative to gradient descent training based RNNs. ESN, with a strong\ntheoretical ground, is practical, conceptually simple, easy to implement. It\navoids non-converging and computationally expensive in the gradient descent\nmethods. Since ESN was put forward in 2002, abundant existing works have\npromoted the progress of ESN, and the recently introduced Deep ESN model opened\nthe way to uniting the merits of deep learning and ESNs. Besides, the\ncombinations of ESNs with other machine learning models have also overperformed\nbaselines in some applications. However, the apparent simplicity of ESNs can\nsometimes be deceptive and successfully applying ESNs needs some experience.\nThus, in this paper, we categorize the ESN-based methods to basic ESNs,\nDeepESNs and combinations, then analyze them from the perspective of\ntheoretical studies, network designs and specific applications. Finally, we\ndiscuss the challenges and opportunities of ESNs by summarizing the open\nquestions and proposing possible future works.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 08:20:57 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Sun", "Chenxi", ""], ["Song", "Moxian", ""], ["Hong", "Shenda", ""], ["Li", "Hongyan", ""]]}, {"id": "2012.02976", "submitter": "Liu Yuezhang", "authors": "Liu Yuezhang, Bo Li, Qifeng Chen", "title": "Evaluating adversarial robustness in simulated cerebellum", "comments": "18 pages, 3 figures, NeurIPS 2020 Preregistration Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that artificial neural networks are vulnerable to\nadversarial examples, in which great efforts have been made to improve the\nrobustness. However, such examples are usually imperceptible to humans, and\nthus their effect on biological neural circuits is largely unknown. This paper\nwill investigate the adversarial robustness in a simulated cerebellum, a\nwell-studied supervised learning system in computational neuroscience.\nSpecifically, we propose to study three unique characteristics revealed in the\ncerebellum: (i) network width; (ii) long-term depression on the parallel\nfiber-Purkinje cell synapses; (iii) sparse connectivity in the granule layer,\nand hypothesize that they will be beneficial for improving robustness. To the\nbest of our knowledge, this is the first attempt to examine the adversarial\nrobustness in simulated cerebellum models.\n  The results are negative in the experimental phase -- no significant\nimprovements in robustness are discovered from the proposed three mechanisms.\nConsequently, the cerebellum is expected to be vulnerable to adversarial\nexamples as the deep neural networks under batch training. Neuroscientists are\nencouraged to fool the biological system in experiments with adversarial\nattacks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2020 08:26:41 GMT"}, {"version": "v2", "created": "Sun, 27 Jun 2021 15:28:00 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Yuezhang", "Liu", ""], ["Li", "Bo", ""], ["Chen", "Qifeng", ""]]}, {"id": "2012.03312", "submitter": "Peng Wang", "authors": "Peng Wang, Gang Xin, Yuwei Jiao", "title": "Quantum Dynamics of Optimization Problems", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, by establishing the Schr\\\"odinger equation of the\noptimization problem, the optimization problem is transformed into a\nconstrained state quantum problem with the objective function as the potential\nenergy. The mathematical relationship between the objective function and the\nwave function is established, and the quantum interpretation of the\noptimization problem is realized. Under the black box model, the Schr\\\"odinger\nequation of the optimization problem is used to establish the kinetic equation,\ni.e., the Fokker-Planck equation of the time evolution of the optimization\nalgorithm, and the basic iterative structure of the optimization algorithm is\ngiven according to the interpretation of the Fokker-Planck equation. The\nestablishment of the Fokker-Planck equation allows optimization algorithms to\nbe studied using dynamic methods and is expected to become an important\ntheoretical basis for algorithm dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 16:31:09 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Wang", "Peng", ""], ["Xin", "Gang", ""], ["Jiao", "Yuwei", ""]]}, {"id": "2012.03378", "submitter": "Rajesh Rao", "authors": "Rajesh P. N. Rao", "title": "Brain Co-Processors: Using AI to Restore and Augment Brain Function", "comments": "arXiv admin note: text overlap with arXiv:1811.11876", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE nlin.AO q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Brain-computer interfaces (BCIs) use decoding algorithms to control\nprosthetic devices based on brain signals for restoration of lost function.\nComputer-brain interfaces (CBIs), on the other hand, use encoding algorithms to\ntransform external sensory signals into neural stimulation patterns for\nrestoring sensation or providing sensory feedback for closed-loop prosthetic\ncontrol. In this article, we introduce brain co-processors, devices that\ncombine decoding and encoding in a unified framework using artificial\nintelligence (AI) to supplement or augment brain function. Brain co-processors\ncan be used for a range of applications, from inducing Hebbian plasticity for\nrehabilitation after brain injury to reanimating paralyzed limbs and enhancing\nmemory. A key challenge is simultaneous multi-channel neural decoding and\nencoding for optimization of external behavioral or task-related goals. We\ndescribe a new framework for developing brain co-processors based on artificial\nneural networks, deep learning and reinforcement learning. These \"neural\nco-processors\" allow joint optimization of cost functions with the nervous\nsystem to achieve desired behaviors. By coupling artificial neural networks\nwith their biological counterparts, neural co-processors offer a new way of\nrestoring and augmenting the brain, as well as a new scientific tool for brain\nresearch. We conclude by discussing the potential applications and ethical\nimplications of brain co-processors.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 21:06:28 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Rao", "Rajesh P. N.", ""]]}, {"id": "2012.03391", "submitter": "Edmondo Trentin", "authors": "Edmondo Trentin (DIISM, University of Siena, Italy)", "title": "Multivariate Density Estimation with Deep Neural Mixture Models", "comments": "Extended journal version of E. Trentin, \"Maximum-Likelihood\n  Estimation of Neural Mixture Densities: Model, Algorithm, and Preliminary\n  Experimental Evaluation\". In Proc. of ANNPR 2018: 178-189, Springer, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Albeit worryingly underrated in the recent literature on machine learning in\ngeneral (and, on deep learning in particular), multivariate density estimation\nis a fundamental task in many applications, at least implicitly, and still an\nopen issue. With a few exceptions, deep neural networks (DNNs) have seldom been\napplied to density estimation, mostly due to the unsupervised nature of the\nestimation task, and (especially) due to the need for constrained training\nalgorithms that ended up realizing proper probabilistic models that satisfy\nKolmogorov's axioms. Moreover, in spite of the well-known improvement in terms\nof modeling capabilities yielded by mixture models over plain single-density\nstatistical estimators, no proper mixtures of multivariate DNN-based component\ndensities have been investigated so far. The paper fills this gap by extending\nour previous work on Neural Mixture Densities (NMMs) to multivariate DNN\nmixtures. A maximum-likelihood (ML) algorithm for estimating Deep NMMs (DNMMs)\nis handed out, which satisfies numerically a combination of hard and soft\nconstraints aimed at ensuring satisfaction of Kolmogorov's axioms. The class of\nprobability density functions that can be modeled to any degree of precision\nvia DNMMs is formally defined. A procedure for the automatic selection of the\nDNMM architecture, as well as of the hyperparameters for its ML training\nalgorithm, is presented (exploiting the probabilistic nature of the DNMM).\nExperimental results on univariate and multivariate data are reported on,\ncorroborating the effectiveness of the approach and its superiority to the most\npopular statistical estimation techniques.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 23:03:48 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Trentin", "Edmondo", "", "DIISM, University of Siena, Italy"]]}, {"id": "2012.03405", "submitter": "Alexander Ororbia", "authors": "Alexander Ororbia and Daniel Kifer", "title": "The Neural Coding Framework for Learning Generative Models", "comments": "Major revisions/organization changes have been made, significant\n  edits made for clarity, appendix now added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural generative models can be used to learn complex probability\ndistributions from data, to sample from them, and to produce probability\ndensity estimates. We propose a novel neural generative model inspired by the\ntheory of predictive processing in the brain. According to predictive\nprocessing theory, the neurons in the brain form a hierarchy in which neurons\nin one level form expectations about sensory inputs from another level. These\nneurons update their local models based on differences between their\nexpectations and the observed signals. In a similar way, artificial neurons in\nour generative model predict what neighboring neurons will do, and adjust their\nparameters based on how well the predictions matched reality. This neural\ngenerative model performs very well in practice. On a variety of benchmark\ndatasets and metrics, it either remains competitive with or significantly\noutperforms other generative models with similar functionality (such as the\nvariational auto-encoder).\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 01:20:38 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 18:24:43 GMT"}, {"version": "v3", "created": "Fri, 25 Dec 2020 01:52:40 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Ororbia", "Alexander", ""], ["Kifer", "Daniel", ""]]}, {"id": "2012.03485", "submitter": "Souvik Das", "authors": "Souvik Das, Anirudh Shankar, Vaneet Aggarwal", "title": "A multi-agent evolutionary robotics framework to train spiking neural\n  networks", "comments": "9 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A novel multi-agent evolutionary robotics (ER) based framework, inspired by\ncompetitive evolutionary environments in nature, is demonstrated for training\nSpiking Neural Networks (SNN). The weights of a population of SNNs along with\nmorphological parameters of bots they control in the ER environment are treated\nas phenotypes. Rules of the framework select certain bots and their SNNs for\nreproduction and others for elimination based on their efficacy in capturing\nfood in a competitive environment. While the bots and their SNNs are given no\nexplicit reward to survive or reproduce via any loss function, these drives\nemerge implicitly as they evolve to hunt food and survive within these rules.\nTheir efficiency in capturing food as a function of generations exhibit the\nevolutionary signature of punctuated equilibria. Two evolutionary inheritance\nalgorithms on the phenotypes, Mutation and Crossover with Mutation, are\ndemonstrated. Performances of these algorithms are compared using ensembles of\n100 experiments for each algorithm. We find that Crossover with Mutation\npromotes 40% faster learning in the SNN than mere Mutation with a statistically\nsignificant margin.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 07:26:52 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Das", "Souvik", ""], ["Shankar", "Anirudh", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "2012.03510", "submitter": "Gi-Hwan Shin", "authors": "Gi-Hwan Shin, Young-Seok Kweon, Minji Lee", "title": "Predicting the Transition from Short-term to Long-term Memory based on\n  Deep Neural Network", "comments": "Submitted IEEE The 9th International Winter Conference on\n  Brain-Computer Interface", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory is an essential element in people's daily life based on experience. So\nfar, many studies have analyzed electroencephalogram (EEG) signals at encoding\nto predict later remembered items, but few studies have predicted long-term\nmemory only with EEG signals of successful short-term memory. Therefore, we aim\nto predict long-term memory using deep neural networks. In specific, the\nspectral power of the EEG signals of remembered items in short-term memory was\ncalculated and inputted to the multilayer perceptron (MLP) and convolutional\nneural network (CNN) classifiers to predict long-term memory. Seventeen\nparticipants performed visuo-spatial memory task consisting of picture and\nlocation memory in the order of encoding, immediate retrieval (short-term\nmemory), and delayed retrieval (long-term memory). We applied\nleave-one-subject-out cross-validation to evaluate the predictive models. As a\nresult, the picture memory showed the highest kappa-value of 0.19 on CNN, and\nlocation memory showed the highest kappa-value of 0.32 in MLP. These results\nshowed that long-term memory can be predicted with measured EEG signals during\nshort-term memory, which improves learning efficiency and helps people with\nmemory and cognitive impairments.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 08:00:35 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Shin", "Gi-Hwan", ""], ["Kweon", "Young-Seok", ""], ["Lee", "Minji", ""]]}, {"id": "2012.03774", "submitter": "Mohammad Nazmul Haque", "authors": "Pablo Moscato, Mohammad Nazmul Haque, Kevin Huang, Julia Sloan, Jon C.\n  de Oliveira", "title": "Learning to extrapolate using continued fractions: Predicting the\n  critical temperature of superconductor materials", "comments": "Submitted to IEEE Transactions on Artificial Intelligence (TAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.supr-con cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Artificial Intelligence we often seek to identify an unknown target\nfunction of many variables $y=f(\\mathbf{x})$ giving a limited set of instances\n$S=\\{(\\mathbf{x^{(i)}},y^{(i)})\\}$ with $\\mathbf{x^{(i)}} \\in D$ where $D$ is a\ndomain of interest. We refer to $S$ as the training set and the final quest is\nto identify the mathematical model that approximates this target function for\nnew $\\mathbf{x}$; with the set $T=\\{ \\mathbf{x^{(j)}} \\} \\subset D$ with $T\n\\neq S$ (i.e. thus testing the model generalisation). However, for some\napplications, the main interest is approximating well the unknown function on a\nlarger domain $D'$ that contains $D$. In cases involving the design of new\nstructures, for instance, we may be interested in maximizing $f$; thus, the\nmodel derived from $S$ alone should also generalize well in $D'$ for samples\nwith values of $y$ larger than the largest observed in $S$. In that sense, the\nAI system would provide important information that could guide the design\nprocess, e.g., using the learned model as a surrogate function to design new\nlab experiments.\n  We introduce a method for multivariate regression based on iterative fitting\nof a continued fraction by incorporating additive spline models. We compared it\nwith established methods such as AdaBoost, Kernel Ridge, Linear Regression,\nLasso Lars, Linear Support Vector Regression, Multi-Layer Perceptrons, Random\nForests, Stochastic Gradient Descent and XGBoost. We tested the performance on\nthe important problem of predicting the critical temperature of superconductors\nbased on physical-chemical characteristics.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 04:57:40 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Moscato", "Pablo", ""], ["Haque", "Mohammad Nazmul", ""], ["Huang", "Kevin", ""], ["Sloan", "Julia", ""], ["de Oliveira", "Jon C.", ""]]}, {"id": "2012.03793", "submitter": "Alexander Wong", "authors": "Andrew Hryniowski and Alexander Wong", "title": "Inter-layer Information Similarity Assessment of Deep Neural Networks\n  Via Topological Similarity and Persistence Analysis of Data Neighbour\n  Dynamics", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantitative analysis of information structure through a deep neural\nnetwork (DNN) can unveil new insights into the theoretical performance of DNN\narchitectures. Two very promising avenues of research towards quantitative\ninformation structure analysis are: 1) layer similarity (LS) strategies focused\non the inter-layer feature similarity, and 2) intrinsic dimensionality (ID)\nstrategies focused on layer-wise data dimensionality using pairwise\ninformation. Inspired by both LS and ID strategies for quantitative information\nstructure analysis, we introduce two novel complimentary methods for\ninter-layer information similarity assessment premised on the interesting idea\nof studying a data sample's neighbourhood dynamics as it traverses through a\nDNN. More specifically, we introduce the concept of Nearest Neighbour\nTopological Similarity (NNTS) for quantifying the information topology\nsimilarity between layers of a DNN. Furthermore, we introduce the concept of\nNearest Neighbour Topological Persistence (NNTP) for quantifying the\ninter-layer persistence of data neighbourhood relationships throughout a DNN.\nThe proposed strategies facilitate the efficient inter-layer information\nsimilarity assessment by leveraging only local topological information, and we\ndemonstrate their efficacy in this study by performing analysis on a deep\nconvolutional neural network architecture on image data to study the insights\nthat can be gained with respect to the theoretical performance of a DNN.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 15:34:58 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Hryniowski", "Andrew", ""], ["Wong", "Alexander", ""]]}, {"id": "2012.03837", "submitter": "Michael Laskin", "authors": "Michael Laskin, Luke Metz, Seth Nabarro, Mark Saroufim, Badreddine\n  Noune, Carlo Luschi, Jascha Sohl-Dickstein, Pieter Abbeel", "title": "Parallel Training of Deep Networks with Local Updates", "comments": "First two authors - Michael Laskin and Luke Metz - contributed\n  equally. Order was determined by a coin flip", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning models trained on large data sets have been widely successful\nin both vision and language domains. As state-of-the-art deep learning\narchitectures have continued to grow in parameter count so have the compute\nbudgets and times required to train them, increasing the need for\ncompute-efficient methods that parallelize training. Two common approaches to\nparallelize the training of deep networks have been data and model parallelism.\nWhile useful, data and model parallelism suffer from diminishing returns in\nterms of compute efficiency for large batch sizes. In this paper, we\ninvestigate how to continue scaling compute efficiently beyond the point of\ndiminishing returns for large batches through local parallelism, a framework\nwhich parallelizes training of individual layers in deep networks by replacing\nglobal backpropagation with truncated layer-wise backpropagation. Local\nparallelism enables fully asynchronous layer-wise parallelism with a low memory\nfootprint, and requires little communication overhead compared with model\nparallelism. We show results in both vision and language domains across a\ndiverse set of architectures, and find that local parallelism is particularly\neffective in the high-compute regime.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 16:38:45 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 14:50:45 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Laskin", "Michael", ""], ["Metz", "Luke", ""], ["Nabarro", "Seth", ""], ["Saroufim", "Mark", ""], ["Noune", "Badreddine", ""], ["Luschi", "Carlo", ""], ["Sohl-Dickstein", "Jascha", ""], ["Abbeel", "Pieter", ""]]}, {"id": "2012.04115", "submitter": "Guillermo Valle-P\\'erez", "authors": "Guillermo Valle-P\\'erez, Ard A. Louis", "title": "Generalization bounds for deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generalization in deep learning has been the topic of much recent theoretical\nand empirical research. Here we introduce desiderata for techniques that\npredict generalization errors for deep learning models in supervised learning.\nSuch predictions should 1) scale correctly with data complexity; 2) scale\ncorrectly with training set size; 3) capture differences between architectures;\n4) capture differences between optimization algorithms; 5) be quantitatively\nnot too far from the true error (in particular, be non-vacuous); 6) be\nefficiently computable; and 7) be rigorous. We focus on generalization error\nupper bounds, and introduce a categorisation of bounds depending on assumptions\non the algorithm and data. We review a wide range of existing approaches, from\nclassical VC dimension to recent PAC-Bayesian bounds, commenting on how well\nthey perform against the desiderata.\n  We next use a function-based picture to derive a marginal-likelihood\nPAC-Bayesian bound. This bound is, by one definition, optimal up to a\nmultiplicative constant in the asymptotic limit of large training sets, as long\nas the learning curve follows a power law, which is typically found in practice\nfor deep learning problems. Extensive empirical analysis demonstrates that our\nmarginal-likelihood PAC-Bayes bound fulfills desiderata 1-3 and 5. The results\nfor 6 and 7 are promising, but not yet fully conclusive, while only desideratum\n4 is currently beyond the scope of our bound. Finally, we comment on why this\nfunction-based bound performs significantly better than current parameter-based\nPAC-Bayes bounds.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 23:45:09 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2020 15:00:23 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Valle-P\u00e9rez", "Guillermo", ""], ["Louis", "Ard A.", ""]]}, {"id": "2012.04163", "submitter": "Suranga Seneviratne", "authors": "Sicong Wang, Naveen Karunanayake, Tham Nguyen, Suranga Seneviratne", "title": "Privacy-Preserving Spam Filtering using Functional Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional spam classification requires the end-user to reveal the content\nof its received email to the spam classifier which violates the privacy. Spam\nclassification over encrypted emails enables the classifier to classify spam\nemail without accessing the email, hence protects the privacy of email content.\nIn this paper, we construct a spam classification framework that enables the\nclassification of encrypted emails. Our classification model is based on a\nneural network with a quadratic network part and a multi-layer perception\nnetwork part. The quadratic network architecture is compatible with the\noperation of an existing quadratic functional encryption scheme that enables\nour classification to predict the label of encrypted emails without revealing\nthe associated plain-text email. The evaluation results on real-world spam\ndatasets indicate that our proposed spam classification model achieves an\naccuracy of over 96%.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 02:14:28 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Wang", "Sicong", ""], ["Karunanayake", "Naveen", ""], ["Nguyen", "Tham", ""], ["Seneviratne", "Suranga", ""]]}, {"id": "2012.04231", "submitter": "Ziqi Chen", "authors": "Ziqi Chen, Martin Renqiang Min, Srinivasan Parthasarathy, Xia Ning", "title": "Molecule Optimization via Fragment-based Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In drug discovery, molecule optimization is an important step in order to\nmodify drug candidates into better ones in terms of desired drug properties.\nWith the recent advance of Artificial Intelligence, this traditionally in vitro\nprocess has been increasingly facilitated by in silico approaches. We present\nan innovative in silico approach to computationally optimizing molecules and\nformulate the problem as to generate optimized molecular graphs via deep\ngenerative models. Our generative models follow the key idea of fragment-based\ndrug design, and optimize molecules by modifying their small fragments. Our\nmodels learn how to identify the to-be-optimized fragments and how to modify\nsuch fragments by learning from the difference of molecules that have good and\nbad properties. In optimizing a new molecule, our models apply the learned\nsignals to decode optimized fragments at the predicted location of the\nfragments. We also construct multiple such models into a pipeline such that\neach of the models in the pipeline is able to optimize one fragment, and thus\nthe entire pipeline is able to modify multiple fragments of molecule if needed.\nWe compare our models with other state-of-the-art methods on benchmark datasets\nand demonstrate that our methods significantly outperform others with more than\n80% property improvement under moderate molecular similarity constraints, and\nmore than 10% property improvement under high molecular similarity constraints.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 05:52:16 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2021 16:39:36 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Chen", "Ziqi", ""], ["Min", "Martin Renqiang", ""], ["Parthasarathy", "Srinivasan", ""], ["Ning", "Xia", ""]]}, {"id": "2012.04322", "submitter": "Konstantinos Chatzilygeroudis", "authors": "Konstantinos Chatzilygeroudis, Antoine Cully, Vassilis Vassiliades and\n  Jean-Baptiste Mouret", "title": "Quality-Diversity Optimization: a novel branch of stochastic\n  optimization", "comments": "13 pages, 4 figures, 3 algorithms, to be published in \"Black Box\n  Optimization, Machine Learning and No-Free Lunch Theorems\", P. Pardalos, V.\n  Rasskazova, M.N. Vrahatis, Ed., Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional optimization algorithms search for a single global optimum that\nmaximizes (or minimizes) the objective function. Multimodal optimization\nalgorithms search for the highest peaks in the search space that can be more\nthan one. Quality-Diversity algorithms are a recent addition to the\nevolutionary computation toolbox that do not only search for a single set of\nlocal optima, but instead try to illuminate the search space. In effect, they\nprovide a holistic view of how high-performing solutions are distributed\nthroughout a search space. The main differences with multimodal optimization\nalgorithms are that (1) Quality-Diversity typically works in the behavioral\nspace (or feature space), and not in the genotypic (or parameter) space, and\n(2) Quality-Diversity attempts to fill the whole behavior space, even if the\nniche is not a peak in the fitness landscape. In this chapter, we provide a\ngentle introduction to Quality-Diversity optimization, discuss the main\nrepresentative algorithms, and the main current topics under consideration in\nthe community. Throughout the chapter, we also discuss several successful\napplications of Quality-Diversity algorithms, including deep learning,\nrobotics, and reinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 09:52:50 GMT"}, {"version": "v2", "created": "Thu, 17 Dec 2020 00:50:04 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Chatzilygeroudis", "Konstantinos", ""], ["Cully", "Antoine", ""], ["Vassiliades", "Vassilis", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "2012.04353", "submitter": "Shashi Kant Gupta", "authors": "Shashi Kant Gupta", "title": "Reinforcement Based Learning on Classification Task Could Yield Better\n  Generalization and Adversarial Accuracy", "comments": "10 pages (5 main, 1 ref, 4 supplementary); Accepted at 2nd Workshop\n  on Shared Visual Representations in Human and Machine Intelligence (SVRHM),\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has become interestingly popular in computer vision, mostly\nattaining near or above human-level performance in various vision tasks. But\nrecent work has also demonstrated that these deep neural networks are very\nvulnerable to adversarial examples (adversarial examples - inputs to a model\nwhich are naturally similar to original data but fools the model in classifying\nit into a wrong class). Humans are very robust against such perturbations; one\npossible reason could be that humans do not learn to classify based on an error\nbetween \"target label\" and \"predicted label\" but possibly due to reinforcements\nthat they receive on their predictions. In this work, we proposed a novel\nmethod to train deep learning models on an image classification task. We used a\nreward-based optimization function, similar to the vanilla policy gradient\nmethod used in reinforcement learning, to train our model instead of\nconventional cross-entropy loss. An empirical evaluation on the cifar10 dataset\nshowed that our method learns a more robust classifier than the same model\narchitecture trained using cross-entropy loss function (on adversarial\ntraining). At the same time, our method shows a better generalization with the\ndifference in test accuracy and train accuracy $< 2\\%$ for most of the time\ncompared to the cross-entropy one, whose difference most of the time remains $>\n2\\%$.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 11:03:17 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Gupta", "Shashi Kant", ""]]}, {"id": "2012.04567", "submitter": "Razvan Marinescu", "authors": "Razvan V Marinescu, Daniel Moyer, Polina Golland", "title": "Bayesian Image Reconstruction using Deep Generative Models", "comments": "25 pages, 18 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning models are commonly trained end-to-end and in a supervised\nsetting, using paired (input, output) data. Examples include recent\nsuper-resolution methods that train on pairs of (low-resolution,\nhigh-resolution) images. However, these end-to-end approaches require\nre-training every time there is a distribution shift in the inputs (e.g., night\nimages vs daylight) or relevant latent variables (e.g., camera blur or hand\nmotion). In this work, we leverage state-of-the-art (SOTA) generative models\n(here StyleGAN2) for building powerful image priors, which enable application\nof Bayes' theorem for many downstream reconstruction tasks. Our method,\nBayesian Reconstruction through Generative Models (BRGM), uses a single\npre-trained generator model to solve different image restoration tasks, i.e.,\nsuper-resolution and in-painting, by combining it with different forward\ncorruption models. We keep the weights of the generator model fixed, and\nreconstruct the image by estimating the Bayesian maximum a-posteriori (MAP)\nestimate over the input latent vector that generated the reconstructed image.\nWe further use variational inference to approximate the posterior distribution\nover the latent vectors, from which we sample multiple solutions. We\ndemonstrate BRGM on three large and diverse datasets: (i) 60,000 images from\nthe Flick Faces High Quality dataset (ii) 240,000 chest X-rays from MIMIC III\nand (iii) a combined collection of 5 brain MRI datasets with 7,329 scans.\nAcross all three datasets and without any dataset-specific hyperparameter\ntuning, our simple approach yields performance competitive with current\ntask-specific state-of-the-art methods on super-resolution and in-painting,\nwhile being more generalisable and without requiring any training. Our source\ncode and pre-trained models are available online:\nhttps://razvanmarinescu.github.io/brgm/.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 17:11:26 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 21:48:44 GMT"}, {"version": "v3", "created": "Sun, 21 Feb 2021 21:44:29 GMT"}, {"version": "v4", "created": "Tue, 8 Jun 2021 13:44:01 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Marinescu", "Razvan V", ""], ["Moyer", "Daniel", ""], ["Golland", "Polina", ""]]}, {"id": "2012.04700", "submitter": "Yoonsuck Choe", "authors": "Khuong Nguyen and Yoonsuck Choe", "title": "Emergence of Different Modes of Tool Use in a Reaching and Dragging Task", "comments": "11 pages, 10 figures, 14 pdf-embedded animations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Tool use is an important milestone in the evolution of intelligence. In this\npaper, we investigate different modes of tool use that emerge in a reaching and\ndragging task. In this task, a jointed arm with a gripper must grab a tool (T,\nI, or L-shaped) and drag an object down to the target location (the bottom of\nthe arena). The simulated environment had real physics such as gravity and\nfriction. We trained a deep-reinforcement learning based controller (with raw\nvisual and proprioceptive input) with minimal reward shaping information to\ntackle this task. We observed the emergence of a wide range of unexpected\nbehaviors, not directly encoded in the motor primitives or reward functions.\nExamples include hitting the object to the target location, correcting error of\ninitial contact, throwing the tool toward the object, as well as normal\nexpected behavior such as wide sweep. Also, we further analyzed these behaviors\nbased on the type of tool and the initial position of the target object. Our\nresults show a rich repertoire of behaviors, beyond the basic built-in\nmechanisms of the deep reinforcement learning method we used.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 19:37:58 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Nguyen", "Khuong", ""], ["Choe", "Yoonsuck", ""]]}, {"id": "2012.04717", "submitter": "Edgar Galvan", "authors": "Edgar Galv\\'an and Fergal Stapleton", "title": "Promoting Semantics in Multi-objective Genetic Programming based on\n  Decomposition", "comments": "9 pages, 4 Tables, 1 Figure. arXiv admin note: substantial text\n  overlap with arXiv:2009.12401", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of semantics in Genetic Program (GP) deals with the behaviour of a\nprogram given a set of inputs and has been widely reported in helping to\npromote diversity in GP for a range of complex problems ultimately improving\nevolutionary search. The vast majority of these studies have focused their\nattention in single-objective GP, with just a few exceptions where Pareto-based\ndominance algorithms such as NSGA-II and SPEA2 have been used as frameworks to\ntest whether highly popular semantics-based methods, such as Semantic\nSimilarity-based Crossover (SSC), helps or hinders evolutionary search.\nSurprisingly it has been reported that the benefits exhibited by SSC in SOGP\nare not seen in Pareto-based dominance Multi-objective GP. In this work, we are\ninterested in studying if the same carries out in Multi-objective Evolutionary\nAlgorithms based on Decomposition (MOEA/D). By using the MNIST dataset, a\nwell-known dataset used in the machine learning community, we show how SSC in\nMOEA/D promotes semantic diversity yielding better results compared to when\nthis is not present in canonical MOEA/D.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 20:07:47 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Galv\u00e1n", "Edgar", ""], ["Stapleton", "Fergal", ""]]}, {"id": "2012.04926", "submitter": "Chonghyuk Song", "authors": "Chonghyuk Song, Eunseok Kim, Inwook Shim", "title": "Improving Gradient Flow with Unrolled Highway Expectation Maximization", "comments": "Accepted at AAAI 2021. Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating model-based machine learning methods into deep neural\narchitectures allows one to leverage both the expressive power of deep neural\nnets and the ability of model-based methods to incorporate domain-specific\nknowledge. In particular, many works have employed the expectation maximization\n(EM) algorithm in the form of an unrolled layer-wise structure that is jointly\ntrained with a backbone neural network. However, it is difficult to\ndiscriminatively train the backbone network by backpropagating through the EM\niterations as they are prone to the vanishing gradient problem. To address this\nissue, we propose Highway Expectation Maximization Networks (HEMNet), which is\ncomprised of unrolled iterations of the generalized EM (GEM) algorithm based on\nthe Newton-Rahpson method. HEMNet features scaled skip connections, or\nhighways, along the depths of the unrolled architecture, resulting in improved\ngradient flow during backpropagation while incurring negligible additional\ncomputation and memory costs compared to standard unrolled EM. Furthermore,\nHEMNet preserves the underlying EM procedure, thereby fully retaining the\nconvergence properties of the original EM algorithm. We achieve significant\nimprovement in performance on several semantic segmentation benchmarks and\nempirically show that HEMNet effectively alleviates gradient decay.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 09:11:45 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Song", "Chonghyuk", ""], ["Kim", "Eunseok", ""], ["Shim", "Inwook", ""]]}, {"id": "2012.04984", "submitter": "Eneko Osaba", "authors": "Eneko Osaba, Esther Villar-Rodriguez, Izaskun Oregi and Aitor\n  Moreno-Fernandez-de-Leceta", "title": "Hybrid Quantum Computing -- Tabu Search Algorithm for Partitioning\n  Problems: preliminary study on the Traveling Salesman Problem", "comments": "8 pages, 4 figures, paper accepted in IEEE Congress on Evolutionary\n  Computation 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum Computing is considered as the next frontier in computing, and it is\nattracting a lot of attention from the current scientific community. This kind\nof computation provides to researchers with a revolutionary paradigm for\naddressing complex optimization problems, offering a significant speed\nadvantage and an efficient search ability. Anyway, Quantum Computing is still\nin an incipient stage of development. For this reason, present architectures\nshow certain limitations, which have motivated the carrying out of this paper.\nIn this paper, we introduce a novel solving scheme coined as hybrid Quantum\nComputing - Tabu Search Algorithm. Main pillars of operation of the proposed\nmethod are a greater control over the access to quantum resources, and a\nconsiderable reduction of non-profitable accesses. To assess the quality of our\nmethod, we have used 7 different Traveling Salesman Problem instances as\nbenchmarking set. The obtained outcomes support the preliminary conclusion that\nour algorithm is an approach which offers promising results for solving\npartitioning problems while it drastically reduces the access to quantum\ncomputing resources. We also contribute to the field of Transfer Optimization\nby developing an evolutionary multiform multitasking algorithm as\ninitialization method.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 11:21:50 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 13:59:57 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Osaba", "Eneko", ""], ["Villar-Rodriguez", "Esther", ""], ["Oregi", "Izaskun", ""], ["Moreno-Fernandez-de-Leceta", "Aitor", ""]]}, {"id": "2012.05046", "submitter": "Hamed Javidi", "authors": "Hamed Javidi, Dan Simon, Ling Zhu, Yan Wang", "title": "A multi-objective optimization framework for on-line ridesharing systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DM cs.NE cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ultimate goal of ridesharing systems is to matchtravelers who do not have\na vehicle with those travelers whowant to share their vehicle. A good match can\nbe found amongthose who have similar itineraries and time schedules. In thisway\neach rider can be served without any delay and also eachdriver can earn as much\nas possible without having too muchdeviation from their original route. We\npropose an algorithmthat leverages biogeography-based optimization to solve a\nmulti-objective optimization problem for online ridesharing. It isnecessary to\nsolve the ridesharing problem as a multi-objectiveproblem since there are some\nimportant objectives that must beconsidered simultaneously. We test our\nalgorithm by evaluatingperformance on the Beijing ridesharing dataset. The\nsimulationresults indicate that BBO provides competitive performancerelative to\nstate-of-the-art ridesharing optimization algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2020 16:25:39 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Javidi", "Hamed", ""], ["Simon", "Dan", ""], ["Zhu", "Ling", ""], ["Wang", "Yan", ""]]}, {"id": "2012.05152", "submitter": "Mahdi Sadeghi", "authors": "Mahdi Sadeghi, Fabian Schrodt, Sebastian Otte, Martin V. Butz", "title": "Binding and Perspective Taking as Inference in a Generative Neural\n  Network Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to flexibly bind features into coherent wholes from different\nperspectives is a hallmark of cognition and intelligence. Importantly, the\nbinding problem is not only relevant for vision but also for general\nintelligence, sensorimotor integration, event processing, and language. Various\nartificial neural network models have tackled this problem with dynamic neural\nfields and related approaches. Here we focus on a generative encoder-decoder\narchitecture that adapts its perspective and binds features by means of\nretrospective inference. We first train a model to learn sufficiently accurate\ngenerative models of dynamic biological motion or other harmonic motion\npatterns, such as a pendulum. We then scramble the input to a certain extent,\npossibly vary the perspective onto it, and propagate the prediction error back\nonto a binding matrix, that is, hidden neural states that determine feature\nbinding. Moreover, we propagate the error further back onto perspective taking\nneurons, which rotate and translate the input features onto a known frame of\nreference. Evaluations show that the resulting gradient-based inference process\nsolves the perspective taking and binding problem for known biological motion\npatterns, essentially yielding a Gestalt perception mechanism. In addition,\nredundant feature properties and population encodings are shown to be highly\nuseful. While we evaluate the algorithm on biological motion patterns, the\nprincipled approach should be applicable to binding and Gestalt perception\nproblems in other domains.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 16:43:26 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Sadeghi", "Mahdi", ""], ["Schrodt", "Fabian", ""], ["Otte", "Sebastian", ""], ["Butz", "Martin V.", ""]]}, {"id": "2012.05208", "submitter": "Klaus Greff", "authors": "Klaus Greff, Sjoerd van Steenkiste, J\\\"urgen Schmidhuber", "title": "On the Binding Problem in Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Contemporary neural networks still fall short of human-level generalization,\nwhich extends far beyond our direct experiences. In this paper, we argue that\nthe underlying cause for this shortcoming is their inability to dynamically and\nflexibly bind information that is distributed throughout the network. This\nbinding problem affects their capacity to acquire a compositional understanding\nof the world in terms of symbol-like entities (like objects), which is crucial\nfor generalizing in predictable and systematic ways. To address this issue, we\npropose a unifying framework that revolves around forming meaningful entities\nfrom unstructured sensory inputs (segregation), maintaining this separation of\ninformation at a representational level (representation), and using these\nentities to construct new inferences, predictions, and behaviors (composition).\nOur analysis draws inspiration from a wealth of research in neuroscience and\ncognitive psychology, and surveys relevant mechanisms from the machine learning\nliterature, to help identify a combination of inductive biases that allow\nsymbolic information processing to emerge naturally in neural networks. We\nbelieve that a compositional approach to AI, in terms of grounded symbol-like\nrepresentations, is of fundamental importance for realizing human-level\ngeneralization, and we hope that this paper may contribute towards that goal as\na reference and inspiration.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 18:02:49 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Greff", "Klaus", ""], ["van Steenkiste", "Sjoerd", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "2012.05419", "submitter": "Harideep Nair", "authors": "Harideep Nair, Prabhu Vellaisamy, Santha Bhasuthkar, and John Paul\n  Shen", "title": "A Custom 7nm CMOS Standard Cell Library for Implementing TNN-based\n  Neuromorphic Processors", "comments": "This work is dated and will be superseded by a forthcoming work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A set of highly-optimized custom macro extensions is developed for a 7nm CMOS\ncell library for implementing Temporal Neural Networks (TNNs) that can mimic\nbrain-like sensory processing with extreme energy efficiency. A TNN prototype\n(13,750 neurons and 315,000 synapses) for MNIST requires only 1.56mm2 die area\nand consumes only 1.69mW.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 02:31:57 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 22:01:18 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Nair", "Harideep", ""], ["Vellaisamy", "Prabhu", ""], ["Bhasuthkar", "Santha", ""], ["Shen", "John Paul", ""]]}, {"id": "2012.05705", "submitter": "Young-Seok Kweon", "authors": "Young-Seok Kweon, Gi-Hwan Shin, Heon-Gyu Kwak, Minji Lee", "title": "Automatic Micro-sleep Detection under Car-driving Simulation Environment\n  using Night-sleep EEG", "comments": "Submitted IEEE The 9th International Winter Conference on\n  Brain-Computer Interface", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A micro-sleep is a short sleep that lasts from 1 to 30 secs. Its detection\nduring driving is crucial to prevent accidents that could claim a lot of\npeople's lives. Electroencephalogram (EEG) is suitable to detect micro-sleep\nbecause EEG was associated with consciousness and sleep. Deep learning showed\ngreat performance in recognizing brain states, but sufficient data should be\nneeded. However, collecting micro-sleep data during driving is inefficient and\nhas a high risk of obtaining poor data quality due to noisy driving situations.\nNight-sleep data at home is easier to collect than micro-sleep data during\ndriving. Therefore, we proposed a deep learning approach using night-sleep EEG\nto improve the performance of micro-sleep detection. We pre-trained the U-Net\nto classify the 5-class sleep stages using night-sleep EEG and used the sleep\nstages estimated by the U-Net to detect micro-sleep during driving. This\nimproved micro-sleep detection performance by about 30\\% compared to the\ntraditional approach. Our approach was based on the hypothesis that micro-sleep\ncorresponds to the early stage of non-rapid eye movement (NREM) sleep. We\nanalyzed EEG distribution during night-sleep and micro-sleep and found that\nmicro-sleep has a similar distribution to NREM sleep. Our results provide the\npossibility of similarity between micro-sleep and the early stage of NREM sleep\nand help prevent micro-sleep during driving.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 14:37:47 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Kweon", "Young-Seok", ""], ["Shin", "Gi-Hwan", ""], ["Kwak", "Heon-Gyu", ""], ["Lee", "Minji", ""]]}, {"id": "2012.05738", "submitter": "Nico Potyka", "authors": "Nico Potyka", "title": "Interpreting Neural Networks as Gradual Argumentation Frameworks\n  (Including Proof Appendix)", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that an interesting class of feed-forward neural networks can be\nunderstood as quantitative argumentation frameworks. This connection creates a\nbridge between research in Formal Argumentation and Machine Learning. We\ngeneralize the semantics of feed-forward neural networks to acyclic graphs and\nstudy the resulting computational and semantical properties in argumentation\ngraphs. As it turns out, the semantics gives stronger guarantees than existing\nsemantics that have been tailor-made for the argumentation setting. From a\nmachine-learning perspective, the connection does not seem immediately helpful.\nWhile it gives intuitive meaning to some feed-forward-neural networks, they\nremain difficult to understand due to their size and density. However, the\nconnection seems helpful for combining background knowledge in form of sparse\nargumentation networks with dense neural networks that have been trained for\ncomplementary purposes and for learning the parameters of quantitative\nargumentation frameworks in an end-to-end fashion from data.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 15:18:15 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Potyka", "Nico", ""]]}, {"id": "2012.05959", "submitter": "Syeda Nyma Ferdous", "authors": "Syeda Nyma Ferdous, Ali Dabouei, Jeremy Dawson, Nasser M Nasrabadi", "title": "Super-resolution Guided Pore Detection for Fingerprint Recognition", "comments": null, "journal-ref": "ICPR: International Conference on Pattern Recognition 2021", "doi": null, "report-no": "SR:NEW01", "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance of fingerprint recognition algorithms substantially rely on fine\nfeatures extracted from fingerprints. Apart from minutiae and ridge patterns,\npore features have proven to be usable for fingerprint recognition. Although\nfeatures from minutiae and ridge patterns are quite attainable from\nlow-resolution images, using pore features is practical only if the fingerprint\nimage is of high resolution which necessitates a model that enhances the image\nquality of the conventional 500 ppi legacy fingerprints preserving the fine\ndetails. To find a solution for recovering pore information from low-resolution\nfingerprints, we adopt a joint learning-based approach that combines both\nsuper-resolution and pore detection networks. Our modified single image\nSuper-Resolution Generative Adversarial Network (SRGAN) framework helps to\nreliably reconstruct high-resolution fingerprint samples from low-resolution\nones assisting the pore detection network to identify pores with a high\naccuracy. The network jointly learns a distinctive feature representation from\na real low-resolution fingerprint sample and successfully synthesizes a\nhigh-resolution sample from it. To add discriminative information and\nuniqueness for all the subjects, we have integrated features extracted from a\ndeep fingerprint verifier with the SRGAN quality discriminator. We also add\nridge reconstruction loss, utilizing ridge patterns to make the best use of\nextracted features. Our proposed method solves the recognition problem by\nimproving the quality of fingerprint images. High recognition accuracy of the\nsynthesized samples that is close to the accuracy achieved using the original\nhigh-resolution images validate the effectiveness of our proposed model.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 20:30:56 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Ferdous", "Syeda Nyma", ""], ["Dabouei", "Ali", ""], ["Dawson", "Jeremy", ""], ["Nasrabadi", "Nasser M", ""]]}, {"id": "2012.06027", "submitter": "Xiao Shen", "authors": "Kyle N. Edwards and Xiao Shen", "title": "Comparison of Update and Genetic Training Algorithms in a Memristor\n  Crossbar Perceptron", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memristor-based computer architectures are becoming more attractive as a\npossible choice of hardware for the implementation of neural networks. However,\nat present, memristor technologies are susceptible to a variety of failure\nmodes, a serious concern in any application where regular access to the\nhardware may not be expected or even possible. In this study, we investigate\nwhether certain training algorithms may be more resilient to particular\nhardware failure modes, and therefore more suitable for use in those\napplications. We implement two training algorithms -- a local update scheme and\na genetic algorithm -- in a simulated memristor crossbar, and compare their\nability to train for a simple image classification task as an increasing number\nof memristors fail to adjust their conductance. We demonstrate that there is a\nclear distinction between the two algorithms in several measures of the rate of\nfailure to train.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 23:48:58 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Edwards", "Kyle N.", ""], ["Shen", "Xiao", ""]]}, {"id": "2012.06138", "submitter": "Rei Sato", "authors": "Rei Sato, Jun Sakuma, Youhei Akimoto", "title": "AdvantageNAS: Efficient Neural Architecture Search with Credit\n  Assignment", "comments": "The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) is an approach for automatically designing a\nneural network architecture without human effort or expert knowledge. However,\nthe high computational cost of NAS limits its use in commercial applications.\nTwo recent NAS paradigms, namely one-shot and sparse propagation, which reduce\nthe time and space complexities, respectively, provide clues for solving this\nproblem. In this paper, we propose a novel search strategy for one-shot and\nsparse propagation NAS, namely AdvantageNAS, which further reduces the time\ncomplexity of NAS by reducing the number of search iterations. AdvantageNAS is\na gradient-based approach that improves the search efficiency by introducing\ncredit assignment in gradient estimation for architecture updates. Experiments\non the NAS-Bench-201 and PTB dataset show that AdvantageNAS discovers an\narchitecture with higher performance under a limited time budget compared to\nexisting sparse propagation NAS. To further reveal the reliabilities of\nAdvantageNAS, we investigate it theoretically and find that it monotonically\nimproves the expected loss and thus converges.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 05:45:03 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 03:02:38 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Sato", "Rei", ""], ["Sakuma", "Jun", ""], ["Akimoto", "Youhei", ""]]}, {"id": "2012.06365", "submitter": "Peter Drotar", "authors": "Peter Bugata and Peter Drotar", "title": "Feature Selection Based on Sparse Neural Network Layer with Normalizing\n  Constraints", "comments": "in IEEE Transactions on Cybernetics", "journal-ref": null, "doi": "10.1109/TCYB.2021.3087776", "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Feature selection is important step in machine learning since it has shown to\nimprove prediction accuracy while depressing the curse of dimensionality of\nhigh dimensional data. The neural networks have experienced tremendous success\nin solving many nonlinear learning problems. Here, we propose new\nneural-network based feature selection approach that introduces two constrains,\nthe satisfying of which leads to sparse FS layer. We have performed extensive\nexperiments on synthetic and real world data to evaluate performance of the\nproposed FS. In experiments we focus on the high dimension, low sample size\ndata since those represent the main challenge for feature selection. The\nresults confirm that proposed Feature Selection Based on Sparse Neural Network\nLayer with Normalizing Constraints (SNEL-FS) is able to select the important\nfeatures and yields superior performance compared to other conventional FS\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 14:14:33 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 09:00:38 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Bugata", "Peter", ""], ["Drotar", "Peter", ""]]}, {"id": "2012.06373", "submitter": "Julien Launay", "authors": "Julien Launay, Iacopo Poli, Kilian M\\\"uller, Gustave Pariente, Igor\n  Carron, Laurent Daudet, Florent Krzakala, Sylvain Gigan", "title": "Hardware Beyond Backpropagation: a Photonic Co-Processor for Direct\n  Feedback Alignment", "comments": "6 pages, 2 figures, 1 table. Oral at the Beyond Backpropagation\n  Workshop, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scaling hypothesis motivates the expansion of models past trillions of\nparameters as a path towards better performance. Recent significant\ndevelopments, such as GPT-3, have been driven by this conjecture. However, as\nmodels scale-up, training them efficiently with backpropagation becomes\ndifficult. Because model, pipeline, and data parallelism distribute parameters\nand gradients over compute nodes, communication is challenging to orchestrate:\nthis is a bottleneck to further scaling. In this work, we argue that\nalternative training methods can mitigate these issues, and can inform the\ndesign of extreme-scale training hardware. Indeed, using a synaptically\nasymmetric method with a parallelizable backward pass, such as Direct Feedback\nAlignement, communication needs are drastically reduced. We present a photonic\naccelerator for Direct Feedback Alignment, able to compute random projections\nwith trillions of parameters. We demonstrate our system on benchmark tasks,\nusing both fully-connected and graph convolutional networks. Our hardware is\nthe first architecture-agnostic photonic co-processor for training neural\nnetworks. This is a significant step towards building scalable hardware, able\nto go beyond backpropagation, and opening new avenues for deep learning.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 14:20:45 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Launay", "Julien", ""], ["Poli", "Iacopo", ""], ["M\u00fcller", "Kilian", ""], ["Pariente", "Gustave", ""], ["Carron", "Igor", ""], ["Daudet", "Laurent", ""], ["Krzakala", "Florent", ""], ["Gigan", "Sylvain", ""]]}, {"id": "2012.06400", "submitter": "Noor Awad", "authors": "Noor Awad, Neeratyoy Mallik, Frank Hutter", "title": "Differential Evolution for Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural architecture search (NAS) methods rely on a search strategy for\ndeciding which architectures to evaluate next and a performance estimation\nstrategy for assessing their performance (e.g., using full evaluations,\nmulti-fidelity evaluations, or the one-shot model). In this paper, we focus on\nthe search strategy. We introduce the simple yet powerful evolutionary\nalgorithm of differential evolution to the NAS community. Using the simplest\nperformance evaluation strategy of full evaluations, we comprehensively compare\nthis search strategy to regularized evolution and Bayesian optimization and\ndemonstrate that it yields improved and more robust results for 13 tabular NAS\nbenchmarks based on NAS-Bench-101, NAS-Bench-1Shot1, NAS-Bench-201 and NAS-HPO\nbench.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 14:58:43 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Awad", "Noor", ""], ["Mallik", "Neeratyoy", ""], ["Hutter", "Frank", ""]]}, {"id": "2012.06441", "submitter": "Hyun Ju Go", "authors": "Hyun Ju Go", "title": "Learnable and time-reversible cellular automata with holographic\n  principle", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE hep-th", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there are active studies to extend the concept of convolutional\nneural networks(CNNs) to non-Euclidean space. In particular, there have been a\nstudy on how to implement CNNs for data in non-Euclidean space that are\ninvariant under a certain transformation. During this process, the concept of\nsymmetry came in and convolution was described as a covariant form that the\nphysics theory should be satisfied with after considering gauge symmetry.\nHowever, just because the convoultion expressed in covariant form is obtained,\nit is not obvious to implement the algorithm corresponding to that expression.\nHere, the universal approximation theorem tells us that any function can be\napproximated to a feed-forward networks. Therefore, the already known\nmathematical expression of covariant CNNs can be implemented through\nfeed-forward neural networks. In this point of view, we demonstrate to learning\nprocess of cellular automata(CA) that could satisfy locality,time-reversibility\nand the certain holographic principle through conventional CNNs. With simple\nrules that satisfy the above three conditions and an arbitrary dataset that\nsatisfies those rules, CNNs architecture that can learn rules were proposed and\nit was confirmed that accurate inferences were made for simple examples.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 15:17:40 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 18:52:27 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Go", "Hyun Ju", ""]]}, {"id": "2012.06453", "submitter": "Subodip Biswas", "authors": "Subhodip Biswas, Adam D Cobb, Andreea Sistrunk, Naren Ramakrishnan,\n  Brian Jalaian", "title": "Better call Surrogates: A hybrid Evolutionary Algorithm for\n  Hyperparameter optimization", "comments": "Accepted at the black box optimization challenge at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a surrogate-assisted evolutionary algorithm (EA)\nfor hyperparameter optimization of machine learning (ML) models. The proposed\nSTEADE model initially estimates the objective function landscape using\nRadialBasis Function interpolation, and then transfers the knowledge to an EA\ntechnique called Differential Evolution that is used to evolve new solutions\nguided by a Bayesian optimization framework. We empirically evaluate our model\non the hyperparameter optimization problems as a part of the black box\noptimization challenge at NeurIPS 2020 and demonstrate the improvement brought\nabout by STEADE over the vanilla EA.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 16:19:59 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Biswas", "Subhodip", ""], ["Cobb", "Adam D", ""], ["Sistrunk", "Andreea", ""], ["Ramakrishnan", "Naren", ""], ["Jalaian", "Brian", ""]]}, {"id": "2012.06694", "submitter": "Shima Rahimi Moghaddam", "authors": "Shima Rahimi Moghaddam, Fanjun Bu, Christopher J. Honey", "title": "Learning Representations from Temporally Smooth Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Events in the real world are correlated across nearby points in time, and we\nmust learn from this temporally smooth data. However, when neural networks are\ntrained to categorize or reconstruct single items, the common practice is to\nrandomize the order of training items. What are the effects of temporally\nsmooth training data on the efficiency of learning? We first tested the effects\nof smoothness in training data on incremental learning in feedforward nets and\nfound that smoother data slowed learning. Moreover, sampling so as to minimize\ntemporal smoothness produced more efficient learning than sampling randomly. If\nsmoothness generally impairs incremental learning, then how can networks be\nmodified to benefit from smoothness in the training data? We hypothesized that\ntwo simple brain-inspired mechanisms, leaky memory in activation units and\nmemory-gating, could enable networks to rapidly extract useful representations\nfrom smooth data. Across all levels of data smoothness, these brain-inspired\narchitectures achieved more efficient category learning than feedforward\nnetworks. This advantage persisted, even when leaky memory networks with gating\nwere trained on smooth data and tested on randomly-ordered data. Finally, we\ninvestigated how these brain-inspired mechanisms altered the internal\nrepresentations learned by the networks. We found that networks with\nmulti-scale leaky memory and memory-gating could learn internal representations\nthat un-mixed data sources which vary on fast and slow timescales across\ntraining samples. Altogether, we identified simple mechanisms enabling neural\nnetworks to learn more quickly from temporally smooth data, and to generate\ninternal representations that separate timescales in the training signal.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 01:24:36 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Moghaddam", "Shima Rahimi", ""], ["Bu", "Fanjun", ""], ["Honey", "Christopher J.", ""]]}, {"id": "2012.06720", "submitter": "Huachuan Wang", "authors": "Huachuan Wang and James Ting-Ho Lo", "title": "Low-Order Model of Biological Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A biologically plausible low-order model (LOM) of biological neural networks\nis a recurrent hierarchical network of dendritic nodes/trees,\nspiking/nonspiking neurons, unsupervised/ supervised covariance/accumulative\nlearning mechanisms, feedback connections, and a scheme for maximal\ngeneralization. These component models are motivated and necessitated by making\nLOM learn and retrieve easily without differentiation, optimization, or\niteration, and cluster, detect and recognize multiple/hierarchical corrupted,\ndistorted, and occluded temporal and spatial patterns.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 04:22:09 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Wang", "Huachuan", ""], ["Lo", "James Ting-Ho", ""]]}, {"id": "2012.06800", "submitter": "Srinivas Anumasa", "authors": "Srinivas Anumasa, P.K. Srijith", "title": "Delay Differential Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural ordinary differential equations (NODEs) treat computation of\nintermediate feature vectors as trajectories of ordinary differential equation\nparameterized by a neural network. In this paper, we propose a novel model,\ndelay differential neural networks (DDNN), inspired by delay differential\nequations (DDEs). The proposed model considers the derivative of the hidden\nfeature vector as a function of the current feature vector and past feature\nvectors (history). The function is modelled as a neural network and\nconsequently, it leads to continuous depth alternatives to many recent ResNet\nvariants. We propose two different DDNN architectures, depending on the way\ncurrent and past feature vectors are considered. For training DDNNs, we provide\na memory-efficient adjoint method for computing gradients and back-propagate\nthrough the network. DDNN improves the data efficiency of NODE by further\nreducing the number of parameters without affecting the generalization\nperformance. Experiments conducted on synthetic and real-world image\nclassification datasets such as Cifar10 and Cifar100 show the effectiveness of\nthe proposed models.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 12:20:54 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Anumasa", "Srinivas", ""], ["Srijith", "P. K.", ""]]}, {"id": "2012.06908", "submitter": "Tianlong Chen", "authors": "Tianlong Chen, Jonathan Frankle, Shiyu Chang, Sijia Liu, Yang Zhang,\n  Michael Carbin, Zhangyang Wang", "title": "The Lottery Tickets Hypothesis for Supervised and Self-supervised\n  Pre-training in Computer Vision Models", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computer vision world has been re-gaining enthusiasm in various\npre-trained models, including both classical ImageNet supervised pre-training\nand recently emerged self-supervised pre-training such as simCLR and MoCo.\nPre-trained weights often boost a wide range of downstream tasks including\nclassification, detection, and segmentation. Latest studies suggest that\npre-training benefits from gigantic model capacity. We are hereby curious and\nask: after pre-training, does a pre-trained model indeed have to stay large for\nits downstream transferability?\n  In this paper, we examine supervised and self-supervised pre-trained models\nthrough the lens of the lottery ticket hypothesis (LTH). LTH identifies highly\nsparse matching subnetworks that can be trained in isolation from (nearly)\nscratch yet still reach the full models' performance. We extend the scope of\nLTH and question whether matching subnetworks still exist in pre-trained\ncomputer vision models, that enjoy the same downstream transfer performance.\nOur extensive experiments convey an overall positive message: from all\npre-trained weights obtained by ImageNet classification, simCLR, and MoCo, we\nare consistently able to locate such matching subnetworks at 59.04% to 96.48%\nsparsity that transfer universally to multiple downstream tasks, whose\nperformance see no degradation compared to using full pre-trained weights.\nFurther analyses reveal that subnetworks found from different pre-training tend\nto yield diverse mask structures and perturbation sensitivities. We conclude\nthat the core LTH observations remain generally relevant in the pre-training\nparadigm of computer vision, but more delicate discussions are needed in some\ncases. Codes and pre-trained models will be made available at:\nhttps://github.com/VITA-Group/CV_LTH_Pre-training.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 21:53:55 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 18:13:06 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Chen", "Tianlong", ""], ["Frankle", "Jonathan", ""], ["Chang", "Shiyu", ""], ["Liu", "Sijia", ""], ["Zhang", "Yang", ""], ["Carbin", "Michael", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2012.07225", "submitter": "Cuie Yang", "authors": "Cuie Yang, Jinliang Ding, Yaochu Jin, Tianyou Chai", "title": "Incremental Data-driven Optimization of Complex Systems in Nonstationary\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing work on data-driven optimization focuses on problems in static\nenvironments, but little attention has been paid to problems in dynamic\nenvironments. This paper proposes a data-driven optimization algorithm to deal\nwith the challenges presented by the dynamic environments. First, a data stream\nensemble learning method is adopted to train the surrogates so that each base\nlearner of the ensemble learns the time-varying objective function in the\nprevious environments. After that, a multi-task evolutionary algorithm is\nemployed to simultaneously optimize the problems in the past environments\nassisted by the ensemble surrogate. This way, the optimization tasks in the\nprevious environments can be used to accelerate the tracking of the optimum in\nthe current environment. Since the real fitness function is not available for\nverifying the surrogates in offline data-driven optimization, a support vector\ndomain description that was designed for outlier detection is introduced to\nselect a reliable solution. Empirical results on six dynamic optimization\nbenchmark problems demonstrate the effectiveness of the proposed algorithm\ncompared with four state-of-the-art data-driven optimization algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 02:55:42 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2020 13:35:04 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Yang", "Cuie", ""], ["Ding", "Jinliang", ""], ["Jin", "Yaochu", ""], ["Chai", "Tianyou", ""]]}, {"id": "2012.07231", "submitter": "Weijie Zheng", "authors": "Benjamin Doerr, Weijie Zheng", "title": "Theoretical Analyses of Multi-Objective Evolutionary Algorithms on\n  Multi-Modal Objectives", "comments": "To appear at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous theory work on multi-objective evolutionary algorithms considers\nmostly easy problems that are composed of unimodal objectives. This paper takes\na first step towards a deeper understanding of how evolutionary algorithms\nsolve multi-modal multi-objective problems. We propose the OneJumpZeroJump\nproblem, a bi-objective problem whose single objectives are isomorphic to the\nclassic jump functions benchmark. We prove that the simple evolutionary\nmulti-objective optimizer (SEMO) cannot compute the full Pareto front. In\ncontrast, for all problem sizes~$n$ and all jump sizes $k \\in [4..\\frac n2 -\n1]$, the global SEMO (GSEMO) covers the Pareto front in $\\Theta((n-2k)n^{k})$\niterations in expectation. To improve the performance, we combine the GSEMO\nwith two approaches, a heavy-tailed mutation operator and a stagnation\ndetection strategy, that showed advantages in single-objective multi-modal\nproblems. Runtime improvements of asymptotic order at least $k^{\\Omega(k)}$ are\nshown for both strategies. Our experiments verify the {substantial} runtime\ngains already for moderate problem sizes. Overall, these results show that the\nideas recently developed for single-objective evolutionary algorithms can be\neffectively employed also in multi-objective optimization.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 03:07:39 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 03:26:29 GMT"}, {"version": "v3", "created": "Mon, 19 Apr 2021 12:34:00 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Doerr", "Benjamin", ""], ["Zheng", "Weijie", ""]]}, {"id": "2012.07319", "submitter": "Ke Shang", "authors": "Hisao Ishibuchi and Lie Meng Pang and Ke Shang", "title": "Evolutionary Multi-Objective Optimization Algorithm Framework with Three\n  Solution Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is assumed in the evolutionary multi-objective optimization (EMO)\ncommunity that a final solution is selected by a decision maker from a\nnon-dominated solution set obtained by an EMO algorithm. The number of\nsolutions to be presented to the decision maker can be totally different. In\nsome cases, the decision maker may want to examine only a few representative\nsolutions from which a final solution is selected. In other cases, a large\nnumber of non-dominated solutions may be needed to visualize the Pareto front.\nIn this paper, we suggest the use of a general EMO framework with three\nsolution sets to handle various situations with respect to the required number\nof solutions. The three solution sets are the main population of an EMO\nalgorithm, an external archive to store promising solutions, and a final\nsolution set which is presented to the decision maker. The final solution set\nis selected from the archive. Thus the population size and the archive size can\nbe arbitrarily specified as long as the archive size is not smaller than the\nrequired number of solutions. The final population is not necessarily to be a\ngood solution set since it is not presented to the decision maker. Through\ncomputational experiments, we show the advantages of this framework over the\nstandard final population and final archive frameworks. We also discuss how to\nselect a final solution set and how to explain the reason for the selection,\nwhich is the first attempt towards an explainable EMO framework.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 08:04:07 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Ishibuchi", "Hisao", ""], ["Pang", "Lie Meng", ""], ["Shang", "Ke", ""]]}, {"id": "2012.07458", "submitter": "Sophie Gruenbacher", "authors": "Sophie Gruenbacher, Jacek Cyranka, Mathias Lechner, Md. Ariful Islam,\n  Scott A. Smolka and Radu Grosu", "title": "Lagrangian Reachtubes: The Next Generation", "comments": "12 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce LRT-NG, a set of techniques and an associated toolset that\ncomputes a reachtube (an over-approximation of the set of reachable states over\na given time horizon) of a nonlinear dynamical system. LRT-NG significantly\nadvances the state-of-the-art Langrangian Reachability and its associated tool\nLRT. From a theoretical perspective, LRT-NG is superior to LRT in three ways.\nFirst, it uses for the first time an analytically computed metric for the\npropagated ball which is proven to minimize the ball's volume. We emphasize\nthat the metric computation is the centerpiece of all bloating-based\ntechniques. Secondly, it computes the next reachset as the intersection of two\nballs: one based on the Cartesian metric and the other on the new metric. While\nthe two metrics were previously considered opposing approaches, their joint use\nconsiderably tightens the reachtubes. Thirdly, it avoids the \"wrapping effect\"\nassociated with the validated integration of the center of the reachset, by\noptimally absorbing the interval approximation in the radius of the next ball.\nFrom a tool-development perspective, LRT-NG is superior to LRT in two ways.\nFirst, it is a standalone tool that no longer relies on CAPD. This required the\nimplementation of the Lohner method and a Runge-Kutta time-propagation method.\nSecondly, it has an improved interface, allowing the input model and initial\nconditions to be provided as external input files. Our experiments on a\ncomprehensive set of benchmarks, including two Neural ODEs, demonstrates\nLRT-NG's superior performance compared to LRT, CAPD, and Flow*.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 12:09:50 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Gruenbacher", "Sophie", ""], ["Cyranka", "Jacek", ""], ["Lechner", "Mathias", ""], ["Islam", "Md. Ariful", ""], ["Smolka", "Scott A.", ""], ["Grosu", "Radu", ""]]}, {"id": "2012.07515", "submitter": "Uwe Aickelin", "authors": "J Liu, R Bai, Z Lu, P Ge, D Liu, Uwe Aickelin", "title": "Data-Driven Regular Expressions Evolution for Medical Text\n  Classification Using Genetic Programming", "comments": "2020 IEEE Congress on Evolutionary Computation (CEC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In medical fields, text classification is one of the most important tasks\nthat can significantly reduce human workload through structured information\ndigitization and intelligent decision support. Despite the popularity of\nlearning-based text classification techniques, it is hard for human to\nunderstand or manually fine-tune the classification results for better\nprecision and recall, due to the black box nature of learning. This study\nproposes a novel regular expression-based text classification method making use\nof genetic programming (GP) approaches to evolve regular expressions that can\nclassify a given medical text inquiry with satisfactory precision and recall\nwhile allow human to read the classifier and fine-tune accordingly if\nnecessary. Given a seed population of regular expressions (can be randomly\ninitialized or manually constructed by experts), our method evolves a\npopulation of regular expressions according to chosen fitness function, using a\nnovel regular expression syntax and a series of carefully chosen reproduction\noperators. Our method is evaluated with real-life medical text inquiries from\nan online healthcare provider and shows promising performance. More\nimportantly, our method generates classifiers that can be fully understood,\nchecked and updated by medical doctors, which are fundamentally crucial for\nmedical related practices.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 03:44:46 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Liu", "J", ""], ["Bai", "R", ""], ["Lu", "Z", ""], ["Ge", "P", ""], ["Liu", "D", ""], ["Aickelin", "Uwe", ""]]}, {"id": "2012.07564", "submitter": "Stamatis Mastromichalakis", "authors": "Stamatis Mastromichalakis", "title": "ALReLU: A different approach on Leaky ReLU activation function to\n  improve Neural Networks Performance", "comments": "10 pages,4 figures,1 table,2 Listings-Python code snippets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Despite the unresolved 'dying ReLU problem', the classical ReLU activation\nfunction (AF) has been extensively applied in Deep Neural Networks (DNN), in\nparticular Convolutional Neural Networks (CNN), for image classification. The\ncommon gradient issues of ReLU pose challenges in applications on academy and\nindustry sectors. Recent approaches for improvements are in a similar direction\nby just proposing variations of the AF, such as Leaky ReLU (LReLU), while\nmaintaining the solution within the same unresolved gradient problems. In this\npaper, the Absolute Leaky ReLU (ALReLU) AF, a variation of LReLU, is proposed,\nas an alternative method to resolve the common 'dying ReLU problem' on NN-based\nalgorithms for supervised learning. The experimental results demonstrate that\nby using the absolute values of LReLU's small negative gradient, has a\nsignificant improvement in comparison with LReLU and ReLU, on image\nclassification of diseases such as COVID-19, text and tabular data\nclassification tasks on five different datasets.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 06:46:42 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 07:33:06 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Mastromichalakis", "Stamatis", ""]]}, {"id": "2012.07664", "submitter": "Dominique Chu", "authors": "Dominique Chu and Huy Le Nguyen", "title": "Constraints on Hebbian and STDP learned weights of a spiking neuron", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyse mathematically the constraints on weights resulting from Hebbian\nand STDP learning rules applied to a spiking neuron with weight normalisation.\nIn the case of pure Hebbian learning, we find that the normalised weights equal\nthe promotion probabilities of weights up to correction terms that depend on\nthe learning rate and are usually small. A similar relation can be derived for\nSTDP algorithms, where the normalised weight values reflect a difference\nbetween the promotion and demotion probabilities of the weight. These relations\nare practically useful in that they allow checking for convergence of Hebbian\nand STDP algorithms. Another application is novelty detection. We demonstrate\nthis using the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 16:09:12 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Chu", "Dominique", ""], ["Nguyen", "Huy Le", ""]]}, {"id": "2012.08063", "submitter": "Zhang Peng", "authors": "Peng Zhang, Jinlong Li, Tengfei Li, Huanhuan Chen", "title": "A New Many-Objective Evolutionary Algorithm Based on Determinantal Point\n  Processes", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To handle different types of Many-Objective Optimization Problems (MaOPs),\nMany-Objective Evolutionary Algorithms (MaOEAs) need to simultaneously maintain\nconvergence and population diversity in the high-dimensional objective space.\nIn order to balance the relationship between diversity and convergence, we\nintroduce a Kernel Matrix and probability model called Determinantal Point\nProcesses (DPPs). Our Many-Objective Evolutionary Algorithm with Determinantal\nPoint Processes (MaOEADPPs) is presented and compared with several\nstate-of-the-art algorithms on various types of MaOPs \\textcolor{blue}{with\ndifferent numbers of objectives}. The experimental results demonstrate that\nMaOEADPPs is competitive.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 03:22:06 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Zhang", "Peng", ""], ["Li", "Jinlong", ""], ["Li", "Tengfei", ""], ["Chen", "Huanhuan", ""]]}, {"id": "2012.08180", "submitter": "Noor Awad", "authors": "Noor Awad, Gresa Shala, Difan Deng, Neeratyoy Mallik, Matthias Feurer,\n  Katharina Eggensperger, Andre' Biedenkapp, Diederick Vermetten, Hao Wang,\n  Carola Doerr, Marius Lindauer, Frank Hutter", "title": "Squirrel: A Switching Hyperparameter Optimizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this short note, we describe our submission to the NeurIPS 2020 BBO\nchallenge. Motivated by the fact that different optimizers work well on\ndifferent problems, our approach switches between different optimizers. Since\nthe team names on the competition's leaderboard were randomly generated\n\"alliteration nicknames\", consisting of an adjective and an animal with the\nsame initial letter, we called our approach the Switching Squirrel, or here,\nshort, Squirrel.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 09:57:08 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 06:56:03 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Awad", "Noor", ""], ["Shala", "Gresa", ""], ["Deng", "Difan", ""], ["Mallik", "Neeratyoy", ""], ["Feurer", "Matthias", ""], ["Eggensperger", "Katharina", ""], ["Biedenkapp", "Andre'", ""], ["Vermetten", "Diederick", ""], ["Wang", "Hao", ""], ["Doerr", "Carola", ""], ["Lindauer", "Marius", ""], ["Hutter", "Frank", ""]]}, {"id": "2012.08296", "submitter": "Karol Desnos", "authors": "Karol Desnos (UNIV-RENNES, INSA Rennes, IETR), Nicolas Sourbier (INSA\n  Rennes, UNIV-RENNES, IETR), Pierre-Yves Raumer (INSA Rennes, IETR), Olivier\n  Gesny, Maxime Pelcat (UNIV-RENNES, INSA Rennes, IETR)", "title": "Gegelati: Lightweight Artificial Intelligence through Generic and\n  Evolvable Tangled Program Graphs", "comments": null, "journal-ref": "Workshop on Design and Architectures for Signal and Image\n  Processing (DASIP), Jan 2021, Budapest, Hungary", "doi": "10.1145/3441110.3441575", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tangled Program Graph (TPG) is a reinforcement learning technique based on\ngenetic programming concepts. On state-of-the-art learning environments, TPGs\nhave been shown to offer comparable competence with Deep Neural Networks\n(DNNs), for a fraction of their computational and storage cost. This lightness\nof TPGs, both for training and inference, makes them an interesting model to\nimplement Artificial Intelligences (AIs) on embedded systems with limited\ncomputational and storage resources. In this paper, we introduce the Gegelati\nlibrary for TPGs. Besides introducing the general concepts and features of the\nlibrary, two main contributions are detailed in the paper: 1/ The\nparallelization of the deterministic training process of TPGs, for supporting\nheterogeneous Multiprocessor Systems-on-Chips (MPSoCs). 2/ The support for\ncustomizable instruction sets and data types within the genetically evolved\nprograms of the TPG model. The scalability of the parallel training process is\ndemonstrated through experiments on architectures ranging from a high-end\n24-core processor to a low-power heterogeneous MPSoC. The impact of\ncustomizable instructions on the outcome of a training process is demonstrated\non a state-of-the-art reinforcement learning environment. CCS Concepts:\n$\\bullet$ Computer systems organization $\\rightarrow$ Embedded systems;\n$\\bullet$ Computing methodologies $\\rightarrow$ Machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 14:02:59 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Desnos", "Karol", "", "UNIV-RENNES, INSA Rennes, IETR"], ["Sourbier", "Nicolas", "", "INSA\n  Rennes, UNIV-RENNES, IETR"], ["Raumer", "Pierre-Yves", "", "INSA Rennes, IETR"], ["Gesny", "Olivier", "", "UNIV-RENNES, INSA Rennes, IETR"], ["Pelcat", "Maxime", "", "UNIV-RENNES, INSA Rennes, IETR"]]}, {"id": "2012.08300", "submitter": "Hyeryung Jang", "authors": "Hyeryung Jang and Nicolas Skatchkovsky and Osvaldo Simeone", "title": "BiSNN: Training Spiking Neural Networks with Binary Weights via Bayesian\n  Learning", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Network (ANN)-based inference on battery-powered devices\ncan be made more energy-efficient by restricting the synaptic weights to be\nbinary, hence eliminating the need to perform multiplications. An alternative,\nemerging, approach relies on the use of Spiking Neural Networks (SNNs),\nbiologically inspired, dynamic, event-driven models that enhance energy\nefficiency via the use of binary, sparse, activations. In this paper, an SNN\nmodel is introduced that combines the benefits of temporally sparse binary\nactivations and of binary weights. Two learning rules are derived, the first\nbased on the combination of straight-through and surrogate gradient techniques,\nand the second based on a Bayesian paradigm. Experiments validate the\nperformance loss with respect to full-precision implementations, and\ndemonstrate the advantage of the Bayesian paradigm in terms of accuracy and\ncalibration.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 14:06:36 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Jang", "Hyeryung", ""], ["Skatchkovsky", "Nicolas", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "2012.08403", "submitter": "Volker Turau", "authors": "Marcus Venzke, Daniel Klisch, Philipp Kubik, Asad Ali, Jesper Dell\n  Missier and Volker Turau", "title": "Artificial Neural Networks for Sensor Data Classification on Small\n  Embedded Systems", "comments": "21 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the usage of machine learning for interpreting\nmeasured sensor values in sensor modules. In particular we analyze the\npotential of artificial neural networks (ANNs) on low-cost micro-controllers\nwith a few kilobytes of memory to semantically enrich data captured by sensors.\nThe focus is on classifying temporal data series with a high level of\nreliability. Design and implementation of ANNs are analyzed considering Feed\nForward Neural Networks (FFNNs) and Recurrent Neural Networks (RNNs). We\nvalidate the developed ANNs in a case study of optical hand gesture recognition\non an 8-bit micro-controller. The best reliability was found for an FFNN with\ntwo layers and 1493 parameters requiring an execution time of 36 ms. We propose\na workflow to develop ANNs for embedded devices.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 16:25:23 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Venzke", "Marcus", ""], ["Klisch", "Daniel", ""], ["Kubik", "Philipp", ""], ["Ali", "Asad", ""], ["Missier", "Jesper Dell", ""], ["Turau", "Volker", ""]]}, {"id": "2012.08676", "submitter": "Nemanja Rakicevic", "authors": "Nemanja Rakicevic, Antoine Cully and Petar Kormushev", "title": "Policy Manifold Search for Improving Diversity-based Neuroevolution", "comments": "Paper accepted as oral (8% acceptance rate) at Beyond\n  Backpropagation: Novel Ideas for Training Neural Architectures Workshop at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diversity-based approaches have recently gained popularity as an alternative\nparadigm to performance-based policy search. A popular approach from this\nfamily, Quality-Diversity (QD), maintains a collection of high-performing\npolicies separated in the diversity-metric space, defined based on policies'\nrollout behaviours. When policies are parameterised as neural networks, i.e.\nNeuroevolution, QD tends to not scale well with parameter space dimensionality.\nOur hypothesis is that there exists a low-dimensional manifold embedded in the\npolicy parameter space, containing a high density of diverse and feasible\npolicies. We propose a novel approach to diversity-based policy search via\nNeuroevolution, that leverages learned latent representations of the policy\nparameters which capture the local structure of the data. Our approach\niteratively collects policies according to the QD framework, in order to (i)\nbuild a collection of diverse policies, (ii) use it to learn a latent\nrepresentation of the policy parameters, (iii) perform policy search in the\nlearned latent space. We use the Jacobian of the inverse transformation\n(i.e.reconstruction function) to guide the search in the latent space. This\nensures that the generated samples remain in the high-density regions of the\noriginal space, after reconstruction. We evaluate our contributions on three\ncontinuous control tasks in simulated environments, and compare to\ndiversity-based baselines. The findings suggest that our approach yields a more\nefficient and robust policy search process.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 23:59:49 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Rakicevic", "Nemanja", ""], ["Cully", "Antoine", ""], ["Kormushev", "Petar", ""]]}, {"id": "2012.08738", "submitter": "Anh Viet Do", "authors": "Anh Viet Do, Frank Neumann", "title": "Pareto Optimization for Subset Selection with Dynamic Partition Matroid\n  Constraints", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we consider the subset selection problems with submodular or\nmonotone discrete objective functions under partition matroid constraints where\nthe thresholds are dynamic. We focus on POMC, a simple Pareto optimization\napproach that has been shown to be effective on such problems. Our analysis\ndeparts from singular constraint problems and extends to problems of multiple\nconstraints. We show that previous results of POMC's performance also hold for\nmultiple constraints. Our experimental investigations on random undirected\nmaxcut problems demonstrate POMC's competitiveness against the classical GREEDY\nalgorithm with restart strategy.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 04:27:45 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Do", "Anh Viet", ""], ["Neumann", "Frank", ""]]}, {"id": "2012.08761", "submitter": "Satoshi Sunada", "authors": "Genki Furuhata, Tomoaki Niiyama, and Satoshi Sunada", "title": "Physical deep learning based on optimal control of dynamical systems", "comments": "11 pages, 9 figures", "journal-ref": "Phys. Rev. Applied 15, 034092 (2021)", "doi": "10.1103/PhysRevApplied.15.034092", "report-no": null, "categories": "cs.NE cs.ET physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is the backbone of artificial intelligence technologies, and it\ncan be regarded as a kind of multilayer feedforward neural network. An essence\nof deep learning is information propagation through layers. This suggests that\nthere is a connection between deep neural networks and dynamical systems in the\nsense that information propagation is explicitly modeled by the time-evolution\nof dynamical systems. In this study, we perform pattern recognition based on\nthe optimal control of continuous-time dynamical systems, which is suitable for\nphysical hardware implementation. The learning is based on the adjoint method\nto optimally control dynamical systems, and the deep (virtual) network\nstructures based on the time evolution of the systems are used for processing\ninput information. As a key example, we apply the dynamics-based recognition\napproach to an optoelectronic delay system and demonstrate that the use of the\ndelay system allows for image recognition and nonlinear classifications using\nonly a few control signals. This is in contrast to conventional multilayer\nneural networks, which require a large number of weight parameters to be\ntrained. The proposed approach provides insight into the mechanisms of deep\nnetwork processing in the framework of an optimal control problem and presents\na pathway for realizing physical computing hardware.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 06:38:01 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 06:43:47 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Furuhata", "Genki", ""], ["Niiyama", "Tomoaki", ""], ["Sunada", "Satoshi", ""]]}, {"id": "2012.08858", "submitter": "Shuji Shinohara Shinohara", "authors": "Shuji Shinohara, Nobuhito Manome, Yoshihiro Nakajima, Yukio Pegio\n  Gunji, Toru Moriyama, Hiroshi Okamoto, Shunji Mitsuyoshi, Ung-il Chung", "title": "L\\'evy walks derived from a Bayesian decision-making model in\n  non-stationary environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  L\\'evy walks are found in the migratory behaviour patterns of various\norganisms, and the reason for this phenomenon has been much discussed. We use\nsimulations to demonstrate that learning causes the changes in confidence level\nduring decision-making in non-stationary environments, and results in\nL\\'evy-walk-like patterns. One inference algorithm involving confidence is\nBayesian inference. We propose an algorithm that introduces the effects of\nlearning and forgetting into Bayesian inference, and simulate an imitation game\nin which two decision-making agents incorporating the algorithm estimate each\nother's internal models from their opponent's observational data. For\nforgetting without learning, agent confidence levels remained low due to a lack\nof information on the counterpart and Brownian walks occurred for a wide range\nof forgetting rates. Conversely, when learning was introduced, high confidence\nlevels occasionally occurred even at high forgetting rates, and Brownian walks\nuniversally became L\\'evy walks through a mixture of high- and low-confidence\nstates.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 10:59:22 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Shinohara", "Shuji", ""], ["Manome", "Nobuhito", ""], ["Nakajima", "Yoshihiro", ""], ["Gunji", "Yukio Pegio", ""], ["Moriyama", "Toru", ""], ["Okamoto", "Hiroshi", ""], ["Mitsuyoshi", "Shunji", ""], ["Chung", "Ung-il", ""]]}, {"id": "2012.08859", "submitter": "Bert Moons", "authors": "Bert Moons, Parham Noorzad, Andrii Skliar, Giovanni Mariani, Dushyant\n  Mehta, Chris Lott, Tijmen Blankevoort", "title": "Distilling Optimal Neural Networks: Rapid Search in Diverse Spaces", "comments": "Main text 9 pages, Full text 21 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Today, state-of-the-art Neural Architecture Search (NAS) methods cannot scale\nto many hardware platforms or scenarios at a low training costs and/or can only\nhandle non-diverse, heavily constrained architectural search-spaces. To solve\nthese issues, we present DONNA (Distilling Optimal Neural Network\nArchitectures), a novel pipeline for rapid and diverse NAS, that scales to many\nuser scenarios. In DONNA, a search consists of three phases. First, an accuracy\npredictor is built using blockwise knowledge distillation. This predictor\nenables searching across diverse networks with varying macro-architectural\nparameters such as layer types and attention mechanisms as well as across\nmicro-architectural parameters such as block repeats and expansion rates.\nSecond, a rapid evolutionary search phase finds a set of Pareto-optimal\narchitectures for any scenario using the accuracy predictor and on-device\nmeasurements. Third, optimal models are quickly finetuned to\ntraining-from-scratch accuracy. With this approach, DONNA is up to 100x faster\nthan MNasNet in finding state-of-the-art architectures on-device. Classifying\nImageNet, DONNA architectures are 20% faster than EfficientNet-B0 and\nMobileNetV2 on a Nvidia V100 GPU and 10% faster with 0.5% higher accuracy than\nMobileNetV2-1.4x on a Samsung S20 smartphone. In addition to NAS, DONNA is used\nfor search-space extension and exploration, as well as hardware-aware model\ncompression.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 11:00:19 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 08:14:26 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Moons", "Bert", ""], ["Noorzad", "Parham", ""], ["Skliar", "Andrii", ""], ["Mariani", "Giovanni", ""], ["Mehta", "Dushyant", ""], ["Lott", "Chris", ""], ["Blankevoort", "Tijmen", ""]]}, {"id": "2012.08863", "submitter": "Sophie Gruenbacher", "authors": "Sophie Gruenbacher, Ramin Hasani, Mathias Lechner, Jacek Cyranka,\n  Scott A. Smolka, Radu Grosu", "title": "On The Verification of Neural ODEs with Stochastic Guarantees", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Neural ODEs, an emerging class of time-continuous neural\nnetworks, can be verified by solving a set of global-optimization problems. For\nthis purpose, we introduce Stochastic Lagrangian Reachability (SLR), an\nabstraction-based technique for constructing a tight Reachtube (an\nover-approximation of the set of reachable states over a given time-horizon),\nand provide stochastic guarantees in the form of confidence intervals for the\nReachtube bounds. SLR inherently avoids the infamous wrapping effect\n(accumulation of over-approximation errors) by performing local optimization\nsteps to expand safe regions instead of repeatedly forward-propagating them as\nis done by deterministic reachability methods. To enable fast local\noptimizations, we introduce a novel forward-mode adjoint sensitivity method to\ncompute gradients without the need for backpropagation. Finally, we establish\nasymptotic and non-asymptotic convergence rates for SLR.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 11:04:34 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Gruenbacher", "Sophie", ""], ["Hasani", "Ramin", ""], ["Lechner", "Mathias", ""], ["Cyranka", "Jacek", ""], ["Smolka", "Scott A.", ""], ["Grosu", "Radu", ""]]}, {"id": "2012.09229", "submitter": "Alexander Lalejini", "authors": "Alexander Lalejini, Matthew Andres Moreno, and Charles Ofria", "title": "Tag-based regulation of modules in genetic programming improves\n  context-dependent problem solving", "comments": "2020-12-23-revisions: correct typos; revise abstract, results &\n  discussion, and conclusion based on feedback; add unsuccessful runs to\n  performance figures 2021-07-03-revisions: update title; incorporate feedback;\n  add journal reference. Genet Program Evolvable Mach (2021)", "journal-ref": null, "doi": "10.1007/s10710-021-09406-8", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce and experimentally demonstrate the utility of tag-based genetic\nregulation, a new genetic programming (GP) technique that allows programs to\ndynamically adjust which code modules to express. Tags are evolvable labels\nthat provide a flexible mechanism for referencing code modules. Tag-based\ngenetic regulation extends existing tag-based naming schemes to allow programs\nto \"promote\" and \"repress\" code modules in order to alter expression patterns.\nThis extension allows evolution to structure a program as a gene regulatory\nnetwork where modules are regulated based on instruction executions. We\ndemonstrate the functionality of tag-based regulation on a range of program\nsynthesis problems. We find that tag-based regulation improves problem-solving\nperformance on context-dependent problems; that is, problems where programs\nmust adjust how they respond to current inputs based on prior inputs. Indeed,\nthe system could not evolve solutions to some context-dependent problems until\nregulation was added. Our implementation of tag-based genetic regulation is not\nuniversally beneficial, however. We identify scenarios where the correct\nresponse to a particular input never changes, rendering tag-based regulation an\nunneeded functionality that can sometimes impede adaptive evolution. Tag-based\ngenetic regulation broadens our repertoire of techniques for evolving more\ndynamic genetic programs and can easily be incorporated into existing\ntag-enabled GP systems.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 19:49:28 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 16:43:30 GMT"}, {"version": "v3", "created": "Sat, 10 Jul 2021 00:44:12 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Lalejini", "Alexander", ""], ["Moreno", "Matthew Andres", ""], ["Ofria", "Charles", ""]]}, {"id": "2012.09243", "submitter": "Huan Wang", "authors": "Huan Wang, Can Qin, Yulun Zhang, Yun Fu", "title": "Neural Pruning via Growing Regularization", "comments": "Accepted by ICLR 2021", "journal-ref": "International Conference on Learning Representations (ICLR) 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization has long been utilized to learn sparsity in deep neural\nnetwork pruning. However, its role is mainly explored in the small penalty\nstrength regime. In this work, we extend its application to a new scenario\nwhere the regularization grows large gradually to tackle two central problems\nof pruning: pruning schedule and weight importance scoring. (1) The former\ntopic is newly brought up in this work, which we find critical to the pruning\nperformance while receives little research attention. Specifically, we propose\nan L2 regularization variant with rising penalty factors and show it can bring\nsignificant accuracy gains compared with its one-shot counterpart, even when\nthe same weights are removed. (2) The growing penalty scheme also brings us an\napproach to exploit the Hessian information for more accurate pruning without\nknowing their specific values, thus not bothered by the common Hessian\napproximation problems. Empirically, the proposed algorithms are easy to\nimplement and scalable to large datasets and networks in both structured and\nunstructured pruning. Their effectiveness is demonstrated with modern deep\nneural networks on the CIFAR and ImageNet datasets, achieving competitive\nresults compared to many state-of-the-art algorithms. Our code and trained\nmodels are publicly available at\nhttps://github.com/mingsuntse/regularization-pruning.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 20:16:28 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 19:37:45 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Wang", "Huan", ""], ["Qin", "Can", ""], ["Zhang", "Yulun", ""], ["Fu", "Yun", ""]]}, {"id": "2012.09287", "submitter": "Mark Connor Mr", "authors": "Mark Connor and Michael O'Neill", "title": "Optimizing the Parameters of A Physical Exercise Dose-Response Model: An\n  Algorithmic Comparison", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The purpose of this research was to compare the robustness and performance of\na local and global optimization algorithm when given the task of fitting the\nparameters of a common non-linear dose-response model utilized in the field of\nexercise physiology. Traditionally the parameters of dose-response models have\nbeen fit using a non-linear least-squares procedure in combination with local\noptimization algorithms. However, these algorithms have demonstrated\nlimitations in their ability to converge on a globally optimal solution. This\nresearch purposes the use of an evolutionary computation based algorithm as an\nalternative method to fit a nonlinear dose-response model. The results of our\ncomparison over 1000 experimental runs demonstrate the superior performance of\nthe evolutionary computation based algorithm to consistently achieve a stronger\nmodel fit and holdout performance in comparison to the local search algorithm.\nThis initial research would suggest that global evolutionary computation based\noptimization algorithms may present a fast and robust alternative to local\nalgorithms when fitting the parameters of non-linear dose-response models.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 22:06:35 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Connor", "Mark", ""], ["O'Neill", "Michael", ""]]}, {"id": "2012.09318", "submitter": "Daniel Elton", "authors": "Daniel C. Elton", "title": "Applying Deutsch's concept of good explanations to artificial\n  intelligence and neuroscience -- an initial exploration", "comments": "Accepted for a talk at BICA 2020 and for publication in Cognitive\n  Systems Research", "journal-ref": null, "doi": "10.1016/j.cogsys.2020.12.002", "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial intelligence has made great strides since the deep learning\nrevolution, but AI systems still struggle to extrapolate outside of their\ntraining data and adapt to new situations. For inspiration we look to the\ndomain of science, where scientists have been able to develop theories which\nshow remarkable ability to extrapolate and sometimes predict the existence of\nphenomena which have never been observed before. According to David Deutsch,\nthis type of extrapolation, which he calls \"reach\", is due to scientific\ntheories being hard to vary. In this work we investigate Deutsch's hard-to-vary\nprinciple and how it relates to more formalized principles in deep learning\nsuch as the bias-variance trade-off and Occam's razor. We distinguish internal\nvariability, how much a model/theory can be varied internally while still\nyielding the same predictions, with external variability, which is how much a\nmodel must be varied to accurately predict new, out-of-distribution data. We\ndiscuss how to measure internal variability using the size of the Rashomon set\nand how to measure external variability using Kolmogorov complexity. We explore\nwhat role hard-to-vary explanations play in intelligence by looking at the\nhuman brain and distinguish two learning systems in the brain. The first system\noperates similar to deep learning and likely underlies most of perception and\nmotor control while the second is a more creative system capable of generating\nhard-to-vary explanations of the world. We argue that figuring out how\nreplicate this second system, which is capable of generating hard-to-vary\nexplanations, is a key challenge which needs to be solved in order to realize\nartificial general intelligence. We make contact with the framework of\nPopperian epistemology which rejects induction and asserts that knowledge\ngeneration is an evolutionary process which proceeds through conjecture and\nrefutation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2020 23:23:22 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2020 23:06:46 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Elton", "Daniel C.", ""]]}, {"id": "2012.09444", "submitter": "Ying Bi", "authors": "Ying Bi, Bing Xue, and Mengjie Zhang", "title": "Learning and Sharing: A Multitask Genetic Programming Approach to Image\n  Feature Learning", "comments": "Submitted to IEEE Transactions on Evolutionary Computation", "journal-ref": "IEEE Transactions on Evolutionary Computation, 2021", "doi": "10.1109/TEVC.2021.3097043", "report-no": "2012.09444", "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using evolutionary computation algorithms to solve multiple tasks with\nknowledge sharing is a promising approach. Image feature learning can be\nconsidered as a multitask problem because different tasks may have a similar\nfeature space. Genetic programming (GP) has been successfully applied to image\nfeature learning for classification. However, most of the existing GP methods\nsolve one task, independently, using sufficient training data. No multitask GP\nmethod has been developed for image feature learning. Therefore, this paper\ndevelops a multitask GP approach to image feature learning for classification\nwith limited training data. Owing to the flexible representation of GP, a new\nknowledge sharing mechanism based on a new individual representation is\ndeveloped to allow GP to automatically learn what to share across two tasks and\nto improve its learning performance. The shared knowledge is encoded as a\ncommon tree, which can represent the common/general features of two tasks. With\nthe new individual representation, each task is solved using the features\nextracted from a common tree and a task-specific tree representing\ntask-specific features. To learn the best common and task-specific trees, a new\nevolutionary process and new fitness functions are developed. The performance\nof the proposed approach is examined on six multitask problems of 12 image\nclassification datasets with limited training data and compared with three GP\nand 14 non-GP-based competitive methods. Experimental results show that the new\napproach outperforms these compared methods in almost all the comparisons.\nFurther analysis reveals that the new approach learns simple yet effective\ncommon trees with high effectiveness and transferability.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 08:34:22 GMT"}, {"version": "v2", "created": "Fri, 18 Dec 2020 20:51:55 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Bi", "Ying", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "2012.09542", "submitter": "Novanto Yudistira", "authors": "Novanto Yudistira, Muthu Subash Kavitha, Takio Kurita", "title": "Weakly-Supervised Action Localization and Action Recognition using\n  Global-Local Attention of 3D CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  3D Convolutional Neural Network (3D CNN) captures spatial and temporal\ninformation on 3D data such as video sequences. However, due to the convolution\nand pooling mechanism, the information loss seems unavoidable. To improve the\nvisual explanations and classification in 3D CNN, we propose two approaches; i)\naggregate layer-wise global to local (global-local) discrete gradients using\ntrained 3DResNext network, and ii) implement attention gating network to\nimprove the accuracy of the action recognition. The proposed approach intends\nto show the usefulness of every layer termed as global-local attention in 3D\nCNN via visual attribution, weakly-supervised action localization, and action\nrecognition. Firstly, the 3DResNext is trained and applied for action\nclassification using backpropagation concerning the maximum predicted class.\nThe gradients and activations of every layer are then up-sampled. Later,\naggregation is used to produce more nuanced attention, which points out the\nmost critical part of the predicted class's input videos. We use contour\nthresholding of final attention for final localization. We evaluate spatial and\ntemporal action localization in trimmed videos using fine-grained visual\nexplanation via 3DCam. Experimental results show that the proposed approach\nproduces informative visual explanations and discriminative attention.\nFurthermore, the action recognition via attention gating on each layer produces\nbetter classification results than the baseline model.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 12:29:16 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Yudistira", "Novanto", ""], ["Kavitha", "Muthu Subash", ""], ["Kurita", "Takio", ""]]}, {"id": "2012.09605", "submitter": "Guruprasad Raghavan", "authors": "Guruprasad Raghavan, Matt Thomson", "title": "Sparsifying networks by traversing Geodesics", "comments": "5 pages; Presented work at NeurIPS 2020 Workshop (DiffGeo4DL). arXiv\n  admin note: text overlap with arXiv:2005.11603", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.DG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The geometry of weight spaces and functional manifolds of neural networks\nplay an important role towards 'understanding' the intricacies of ML. In this\npaper, we attempt to solve certain open questions in ML, by viewing them\nthrough the lens of geometry, ultimately relating it to the discovery of points\nor paths of equivalent function in these spaces. We propose a mathematical\nframework to evaluate geodesics in the functional space, to find\nhigh-performance paths from a dense network to its sparser counterpart. Our\nresults are obtained on VGG-11 trained on CIFAR-10 and MLP's trained on MNIST.\nBroadly, we demonstrate that the framework is general, and can be applied to a\nwide variety of problems, ranging from sparsification to alleviating\ncatastrophic forgetting.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 21:39:19 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Raghavan", "Guruprasad", ""], ["Thomson", "Matt", ""]]}, {"id": "2012.09741", "submitter": "Hojjat Rakhshani", "authors": "Hojjat Rakhshani, Lhassane Idoumghar, Soheila Ghambari, Julien\n  Lepagnot, Mathieu Br\\'evilliers", "title": "On the performance of deep learning for numerical optimization: an\n  application to protein structure prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks have recently drawn considerable attention to build and\nevaluate artificial learning models for perceptual tasks. Here, we present a\nstudy on the performance of the deep learning models to deal with global\noptimization problems. The proposed approach adopts the idea of the neural\narchitecture search (NAS) to generate efficient neural networks for solving the\nproblem at hand. The space of network architectures is represented using a\ndirected acyclic graph and the goal is to find the best architecture to\noptimize the objective function for a new, previously unknown task. Different\nfrom proposing very large networks with GPU computational burden and long\ntraining time, we focus on searching for lightweight implementations to find\nthe best architecture. The performance of NAS is first analyzed through\nempirical experiments on CEC 2017 benchmark suite. Thereafter, it is applied to\na set of protein structure prediction (PSP) problems. The experiments reveal\nthat the generated learning models can achieve competitive results when\ncompared to hand-designed algorithms; given enough computational budget\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 17:01:30 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Rakhshani", "Hojjat", ""], ["Idoumghar", "Lhassane", ""], ["Ghambari", "Soheila", ""], ["Lepagnot", "Julien", ""], ["Br\u00e9villiers", "Mathieu", ""]]}, {"id": "2012.09810", "submitter": "Alexander Watson Mr", "authors": "Alexander Watson", "title": "Deep Learning Techniques for Super-Resolution in Video Games", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational cost of video game graphics is increasing and hardware for\nprocessing graphics is struggling to keep up. This means that computer\nscientists need to develop creative new ways to improve the performance of\ngraphical processing hardware. Deep learning techniques for video\nsuper-resolution can enable video games to have high quality graphics whilst\noffsetting much of the computational cost. These emerging technologies allow\nconsumers to have improved performance and enjoyment from video games and have\nthe potential to become standard within the game development industry.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 18:22:05 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Watson", "Alexander", ""]]}, {"id": "2012.09816", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu and Yuanzhi Li", "title": "Towards Understanding Ensemble, Knowledge Distillation and\n  Self-Distillation in Deep Learning", "comments": "v2 polishes writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formally study how ensemble of deep learning models can improve test\naccuracy, and how the superior performance of ensemble can be distilled into a\nsingle model using knowledge distillation. We consider the challenging case\nwhere the ensemble is simply an average of the outputs of a few independently\ntrained neural networks with the SAME architecture, trained using the SAME\nalgorithm on the SAME data set, and they only differ by the random seeds used\nin the initialization.\n  We empirically show that ensemble/knowledge distillation in deep learning\nworks very differently from traditional learning theory, especially differently\nfrom ensemble of random feature mappings or the neural-tangent-kernel feature\nmappings, and is potentially out of the scope of existing theorems. Thus, to\nproperly understand ensemble and knowledge distillation in deep learning, we\ndevelop a theory showing that when data has a structure we refer to as\n\"multi-view\", then ensemble of independently trained neural networks can\nprovably improve test accuracy, and such superior test accuracy can also be\nprovably distilled into a single model by training a single model to match the\noutput of the ensemble instead of the true label. Our result sheds light on how\nensemble works in deep learning in a way that is completely different from\ntraditional theorems, and how the \"dark knowledge\" is hidden in the outputs of\nthe ensemble -- that can be used in knowledge distillation -- comparing to the\ntrue data labels. In the end, we prove that self-distillation can also be\nviewed as implicitly combining ensemble and knowledge distillation to improve\ntest accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 18:34:45 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 23:21:21 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""]]}, {"id": "2012.09823", "submitter": "Magdalena Biesialska", "authors": "Magdalena Biesialska and Katarzyna Biesialska and Marta R.\n  Costa-juss\\`a", "title": "Continual Lifelong Learning in Natural Language Processing: A Survey", "comments": "COLING 2020", "journal-ref": "Proceedings of the 28th International Conference on Computational\n  Linguistics (COLING 2020), Barcelona, Spain (Online), pp. 6523--6541", "doi": "10.18653/v1/2020.coling-main.574", "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning (CL) aims to enable information systems to learn from a\ncontinuous data stream across time. However, it is difficult for existing deep\nlearning architectures to learn a new task without largely forgetting\npreviously acquired knowledge. Furthermore, CL is particularly challenging for\nlanguage learning, as natural language is ambiguous: it is discrete,\ncompositional, and its meaning is context-dependent. In this work, we look at\nthe problem of CL through the lens of various NLP tasks. Our survey discusses\nmajor challenges in CL and current methods applied in neural network models. We\nalso provide a critical review of the existing CL evaluation methods and\ndatasets in NLP. Finally, we present our outlook on future research directions.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 18:44:36 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Biesialska", "Magdalena", ""], ["Biesialska", "Katarzyna", ""], ["Costa-juss\u00e0", "Marta R.", ""]]}, {"id": "2012.10384", "submitter": "Thibaut Vidal", "authors": "Thibaut Vidal", "title": "Hybrid Genetic Search for the CVRP: Open-Source Implementation and SWAP*\n  Neighborhood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vehicle routing problem is one of the most studied combinatorial\noptimization topics, due to its practical importance and methodological\ninterest. Yet, despite extensive methodological progress, many recent studies\nare hampered by the limited access to simple and efficient open-source solution\nmethods. Given the sophistication of current algorithms, reimplementation is\nbecoming a difficult and time-consuming exercise that requires extensive care\nfor details to be truly successful. Against this background, we use the\nopportunity of this short paper to introduce a simple -- open-source --\nimplementation of the hybrid genetic search (HGS) specialized to the\ncapacitated vehicle routing problem (CVRP). This state-of-the-art algorithm\nuses the same general methodology as Vidal et al. (2012) but also includes\nadditional methodological improvements and lessons learned over the past decade\nof research. In particular, it includes an additional neighborhood called SWAP*\nwhich consists in exchanging two customers between different routes without an\ninsertion in place. As highlighted in our study, an efficient exploration of\nSWAP* moves significantly contributes to the performance of local searches.\nMoreover, as observed in experimental comparisons with other recent approaches\non the classical instances of Uchoa et al. (2017), HGS still stands as a\nleading metaheuristic regarding solution quality, convergence speed, and\nconceptual simplicity.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 21:37:49 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Vidal", "Thibaut", ""]]}, {"id": "2012.10388", "submitter": "Xuefei Ning", "authors": "Xuefei Ning, Changcheng Tang, Wenshuo Li, Songyi Yang, Tianchen Zhao,\n  Niansong Zhang, Tianyi Lu, Shuang Liang, Huazhong Yang, Yu Wang", "title": "aw_nas: A Modularized and Extensible NAS framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) has received extensive attention due to its\ncapability to discover neural network architectures in an automated manner.\naw_nas is an open-source Python framework implementing various NAS algorithms\nin a modularized manner. Currently, aw_nas can be used to reproduce the results\nof mainstream NAS algorithms of various types. Also, due to the modularized\ndesign, one can simply experiment with different NAS algorithms for various\napplications with awnas (e.g., classification, detection, text modeling, fault\ntolerance, adversarial robustness, hardware efficiency, and etc.). Codes and\ndocumentation are available at https://github.com/walkerning/aw_nas.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 13:01:19 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Ning", "Xuefei", ""], ["Tang", "Changcheng", ""], ["Li", "Wenshuo", ""], ["Yang", "Songyi", ""], ["Zhao", "Tianchen", ""], ["Zhang", "Niansong", ""], ["Lu", "Tianyi", ""], ["Liang", "Shuang", ""], ["Yang", "Huazhong", ""], ["Wang", "Yu", ""]]}, {"id": "2012.10390", "submitter": "Rufin VanRullen", "authors": "Rufin VanRullen and Ryota Kanai", "title": "Deep Learning and the Global Workspace Theory", "comments": "This version with improved text and figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning have allowed Artificial Intelligence (AI) to\nreach near human-level performance in many sensory, perceptual, linguistic or\ncognitive tasks. There is a growing need, however, for novel, brain-inspired\ncognitive architectures. The Global Workspace theory refers to a large-scale\nsystem integrating and distributing information among networks of specialized\nmodules to create higher-level forms of cognition and awareness. We argue that\nthe time is ripe to consider explicit implementations of this theory using deep\nlearning techniques. We propose a roadmap based on unsupervised neural\ntranslation between multiple latent spaces (neural networks trained for\ndistinct tasks, on distinct sensory inputs and/or modalities) to create a\nunique, amodal global latent workspace (GLW). Potential functional advantages\nof GLW are reviewed, along with neuroscientific implications.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 11:36:01 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 00:33:38 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["VanRullen", "Rufin", ""], ["Kanai", "Ryota", ""]]}, {"id": "2012.10613", "submitter": "Piotr Antonik", "authors": "Piotr Antonik, Marc Haelterman, Serge Massar", "title": "Online training for high-performance analogue readout layers in photonic\n  reservoir computers", "comments": "11 pages, 5 figures", "journal-ref": "Cognitive Computation (Volume: 9, Pages: 297-306, 11 March 2017)", "doi": "10.1007/s12559-017-9459-3", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduction. Reservoir Computing is a bio-inspired computing paradigm for\nprocessing time-dependent signals. The performance of its hardware\nimplementation is comparable to state-of-the-art digital algorithms on a series\nof benchmark tasks. The major bottleneck of these implementation is the readout\nlayer, based on slow offline post-processing. Few analogue solutions have been\nproposed, but all suffered from notice able decrease in performance due to\nadded complexity of the setup. Methods. Here we propose the use of online\ntraining to solve these issues. We study the applicability of this method using\nnumerical simulations of an experimentally feasible reservoir computer with an\nanalogue readout layer. We also consider a nonlinear output layer, which would\nbe very difficult to train with traditional methods. Results. We show\nnumerically that online learning allows to circumvent the added complexity of\nthe analogue layer and obtain the same level of performance as with a digital\nlayer. Conclusion. This work paves the way to high-performance fully-analogue\nreservoir computers through the use of online training of the output layers.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 07:12:26 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Antonik", "Piotr", ""], ["Haelterman", "Marc", ""], ["Massar", "Serge", ""]]}, {"id": "2012.10615", "submitter": "Piotr Antonik", "authors": "Piotr Antonik, Michiel Hermans, Marc Haelterman, Serge Massar", "title": "Random pattern and frequency generation using a photonic reservoir\n  computer with output feedback", "comments": "15 pages, 9 figures. arXiv admin note: substantial text overlap with\n  arXiv:1802.02026", "journal-ref": "Neural Processing Letters (Volume: 47, Pages: 1041-1054, 13 April\n  2017)", "doi": "10.1007/s11063-017-9628-0", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computing is a bio-inspired computing paradigm for processing time\ndependent signals. The performance of its analogue implementations matches\nother digital algorithms on a series of benchmark tasks. Their potential can be\nfurther increased by feeding the output signal back into the reservoir, which\nwould allow to apply the algorithm to time series generation. This requires, in\nprinciple, implementing a sufficiently fast readout layer for real-time output\ncomputation. Here we achieve this with a digital output layer driven by a FPGA\nchip. We demonstrate the first opto-electronic reservoir computer with output\nfeedback and test it on two examples of time series generation tasks: frequency\nand random pattern generation. We obtain very good results on the first task,\nsimilar to idealised numerical simulations. The performance on the second one,\nhowever, suffers from the experimental noise. We illustrate this point with a\ndetailed investigation of the consequences of noise on the performance of a\nphysical reservoir computer with output feedback. Our work thus opens new\npossible applications for analogue reservoir computing and brings new insights\non the impact of noise on the output feedback.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 07:26:32 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Antonik", "Piotr", ""], ["Hermans", "Michiel", ""], ["Haelterman", "Marc", ""], ["Massar", "Serge", ""]]}, {"id": "2012.10769", "submitter": "Maciej Sypetkowski", "authors": "Maciej Sypetkowski, Jakub Jasiulewicz, Zbigniew Wojna", "title": "Augmentation Inside the Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present augmentation inside the network, a method that\nsimulates data augmentation techniques for computer vision problems on\nintermediate features of a convolutional neural network. We perform these\ntransformations, changing the data flow through the network, and sharing common\ncomputations when it is possible. Our method allows us to obtain smoother\nspeed-accuracy trade-off adjustment and achieves better results than using\nstandard test-time augmentation (TTA) techniques. Additionally, our approach\ncan improve model performance even further when coupled with test-time\naugmentation. We validate our method on the ImageNet-2012 and CIFAR-100\ndatasets for image classification. We propose a modification that is 30% faster\nthan the flip test-time augmentation and achieves the same results for\nCIFAR-100.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 20:07:03 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Sypetkowski", "Maciej", ""], ["Jasiulewicz", "Jakub", ""], ["Wojna", "Zbigniew", ""]]}, {"id": "2012.11097", "submitter": "Yi Ding", "authors": "Yi Ding, Fuyuan Tan, Zhen Qin, Mingsheng Cao, Kim-Kwang Raymond Choo\n  and Zhiguang Qin", "title": "DeepKeyGen: A Deep Learning-based Stream Cipher Generator for Medical\n  Image Encryption and Decryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for medical image encryption is increasingly pronounced, for example\nto safeguard the privacy of the patients' medical imaging data. In this paper,\na novel deep learning-based key generation network (DeepKeyGen) is proposed as\na stream cipher generator to generate the private key, which can then be used\nfor encrypting and decrypting of medical images. In DeepKeyGen, the generative\nadversarial network (GAN) is adopted as the learning network to generate the\nprivate key. Furthermore, the transformation domain (that represents the\n\"style\" of the private key to be generated) is designed to guide the learning\nnetwork to realize the private key generation process. The goal of DeepKeyGen\nis to learn the mapping relationship of how to transfer the initial image to\nthe private key. We evaluate DeepKeyGen using three datasets, namely: the\nMontgomery County chest X-ray dataset, the Ultrasonic Brachial Plexus dataset,\nand the BraTS18 dataset. The evaluation findings and security analysis show\nthat the proposed key generation network can achieve a high-level security in\ngenerating the private key.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 03:21:59 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Ding", "Yi", ""], ["Tan", "Fuyuan", ""], ["Qin", "Zhen", ""], ["Cao", "Mingsheng", ""], ["Choo", "Kim-Kwang Raymond", ""], ["Qin", "Zhiguang", ""]]}, {"id": "2012.11153", "submitter": "Xavier Porte", "authors": "Xavier Porte, Anas Skalli, Nasibeh Haghighi, Stephan Reitzenstein,\n  James A. Lott, Daniel Brunner", "title": "A complete, parallel and autonomous photonic neural network in a\n  semiconductor multimode laser", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG physics.optics", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks are one of the disruptive computing concepts of our time.\nHowever, they fundamentally differ from classical, algorithmic computing in a\nnumber of fundamental aspects. These differences result in equally fundamental,\nsevere and relevant challenges for neural network computing using current\ncomputing substrates. Neural networks urge for parallelism across the entire\nprocessor and for a co-location of memory and arithmetic, i.e. beyond von\nNeumann architectures. Parallelism in particular made photonics a highly\npromising platform, yet until now scalable and integratable concepts are\nscarce. Here, we demonstrate for the first time how a fully parallel and fully\nimplemented photonic neural network can be realized using spatially distributed\nmodes of an efficient and fast semiconductor laser. Importantly, all neural\nnetwork connections are realized in hardware, and our processor produces\nresults without pre- or post-processing. 130+ nodes are implemented in a\nlarge-area vertical cavity surface emitting laser, input and output weights are\nrealized via the complex transmission matrix of a multimode fiber and a digital\nmicro-mirror array, respectively. We train the readout weights to perform 2-bit\nheader recognition, a 2-bit XOR and 2-bit digital analog conversion, and obtain\n< 0.9 10^-3 and 2.9 10^-2 error rates for digit recognition and XOR,\nrespectively. Finally, the digital analog conversion can be realized with a\nstandard deviation of only 5.4 10^-2. Our system is scalable to much larger\nsizes and to bandwidths in excess of 20 GHz.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 07:03:43 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Porte", "Xavier", ""], ["Skalli", "Anas", ""], ["Haghighi", "Nasibeh", ""], ["Reitzenstein", "Stephan", ""], ["Lott", "James A.", ""], ["Brunner", "Daniel", ""]]}, {"id": "2012.11444", "submitter": "David Mark Bossens", "authors": "David M. Bossens and Danesh Tarapore", "title": "Rapidly adapting robot swarms with Swarm Map-based Bayesian Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid performance recovery from unforeseen environmental perturbations\nremains a grand challenge in swarm robotics. To solve this challenge, we\ninvestigate a behaviour adaptation approach, where one searches an archive of\ncontrollers for potential recovery solutions. To apply behaviour adaptation in\nswarm robotic systems, we propose two algorithms: (i) Swarm Map-based\nOptimisation (SMBO), which selects and evaluates one controller at a time, for\na homogeneous swarm, in a centralised fashion; and (ii) Swarm Map-based\nOptimisation Decentralised (SMBO-Dec), which performs an asynchronous\nbatch-based Bayesian optimisation to simultaneously explore different\ncontrollers for groups of robots in the swarm. We set up foraging experiments\nwith a variety of disturbances: injected faults to proximity sensors, ground\nsensors, and the actuators of individual robots, with 100 unique combinations\nfor each type. We also investigate disturbances in the operating environment of\nthe swarm, where the swarm has to adapt to drastic changes in the number of\nresources available in the environment, and to one of the robots behaving\ndisruptively towards the rest of the swarm, with 30 unique conditions for each\nsuch perturbation. The viability of SMBO and SMBO-Dec is demonstrated,\ncomparing favourably to variants of random search and gradient descent, and\nvarious ablations, and improving performance up to 80% compared to the\nperformance at the time of fault injection within at most 30 evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 15:54:37 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Bossens", "David M.", ""], ["Tarapore", "Danesh", ""]]}, {"id": "2012.11557", "submitter": "Elizabeth Wanner Dr", "authors": "Claudio Lucio do Val Lopes, Fl\\'avio Vin\\'icius Cruzeiro Martins,\n  Elizabeth Fialho Wanner, Kalyanmoy Deb", "title": "Analyzing Dominance Move (MIP-DoM) Indicator for Multi- and\n  Many-objective Optimization", "comments": "15 Pages. Submitted for consideration for publication in the IEEE\n  Transactions on Evolutionary Computation", "journal-ref": "IEEE Transactions on Evolutionary Computation 2021", "doi": "10.1109/TEVC.2021.3096669", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dominance move (DoM) is a binary quality indicator that can be used in\nmulti-objective and many-objective optimization to compare two solution sets\nobtained from different algorithms. The DoM indicator can differentiate the\nsets for certain important features, such as convergence, spread, uniformity,\nand cardinality. DoM does not use any reference, and it has an intuitive and\nphysical meaning, similar to the $\\epsilon$-indicator, and calculates the\nminimum total move of members of one set so that all elements in another set\nare to be dominated or identical to at least one member of the first set.\nDespite the aforementioned properties, DoM is hard to calculate, particularly\nin higher dimensions. There is an efficient and exact method to calculate it in\na bi-objective case only. This work proposes a novel approach to calculate DoM\nusing a mixed integer programming (MIP) approach, which can handle sets with\nthree or more objectives and is shown to overcome the $\\epsilon$-indicator's\ninformation loss. Experiments, in the bi-objective space, are done to verify\nthe model's correctness. Furthermore, other experiments, using 3, 5, 10, 15,\n20, 25 and 30-objective problems are performed to show how the model behaves in\nhigher-dimensional cases. Algorithms, such as IBEA, MOEA/D, NSGA-III, NSGA-II,\nand SPEA2 are used to generate the solution sets (however any other algorithms\ncan also be used with the proposed MIP-DoM indicator). Further extensions are\ndiscussed to handle certain idiosyncrasies with some solution sets and also to\nimprove the quality indicator and its use for other situations.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 18:36:26 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 11:50:30 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 15:21:58 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Lopes", "Claudio Lucio do Val", ""], ["Martins", "Fl\u00e1vio Vin\u00edcius Cruzeiro", ""], ["Wanner", "Elizabeth Fialho", ""], ["Deb", "Kalyanmoy", ""]]}, {"id": "2012.11692", "submitter": "Jean-Baptiste Mouret", "authors": "Jean-Baptiste Mouret", "title": "Evolving the Behavior of Machines: From Micro to Macroevolution", "comments": null, "journal-ref": "iScience (2020): 101731", "doi": "10.1016/j.isci.2020.101731", "report-no": null, "categories": "cs.NE cs.RO nlin.AO q-bio.PE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Evolution gave rise to creatures that are arguably more sophisticated than\nthe greatest human-designed systems. This feat has inspired computer scientists\nsince the advent of computing and led to optimization tools that can evolve\ncomplex neural networks for machines -- an approach known as \"neuroevolution\".\nAfter a few successes in designing evolvable representations for\nhigh-dimensional artifacts, the field has been recently revitalized by going\nbeyond optimization: to many, the wonder of evolution is less in the perfect\noptimization of each species than in the creativity of such a simple iterative\nprocess, that is, in the diversity of species. This modern view of artificial\nevolution is moving the field away from microevolution, following a fitness\ngradient in a niche, to macroevolution, filling many niches with highly\ndifferent species. It already opened promising applications, like evolving gait\nrepertoires, video game levels for different tastes, and diverse designs for\naerodynamic bikes.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 21:35:15 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Mouret", "Jean-Baptiste", ""]]}, {"id": "2012.11832", "submitter": "Stephen Whitelam", "authors": "Stephen Whitelam, Isaac Tamblyn", "title": "Neuroevolutionary learning of particles and protocols for self-assembly", "comments": null, "journal-ref": "Phys. Rev. Lett. 127, 018003 (2021)", "doi": "10.1103/PhysRevLett.127.018003", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.soft cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Within simulations of molecules deposited on a surface we show that\nneuroevolutionary learning can design particles and time-dependent protocols to\npromote self-assembly, without input from physical concepts such as thermal\nequilibrium or mechanical stability and without prior knowledge of candidate or\ncompeting structures. The learning algorithm is capable of both directed and\nexploratory design: it can assemble a material with a user-defined property, or\nsearch for novelty in the space of specified order parameters. In the latter\nmode it explores the space of what can be made rather than the space of\nstructures that are low in energy but not necessarily kinetically accessible.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 05:03:19 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Whitelam", "Stephen", ""], ["Tamblyn", "Isaac", ""]]}, {"id": "2012.11905", "submitter": "Silvan Mertes", "authors": "Silvan Mertes, Tobias Huber, Katharina Weitz, Alexander Heimerl,\n  Elisabeth Andr\\'e", "title": "This is not the Texture you are looking for! Introducing Novel\n  Counterfactual Explanations for Non-Experts using Generative Adversarial\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.HC cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  With the ongoing rise of machine learning, the need for methods for\nexplaining decisions made by artificial intelligence systems is becoming a more\nand more important topic. Especially for image classification tasks, many\nstate-of-the-art tools to explain such classifiers rely on visual highlighting\nof important areas of the input data. Contrary, counterfactual explanation\nsystems try to enable a counterfactual reasoning by modifying the input image\nin a way such that the classifier would have made a different prediction. By\ndoing so, the users of counterfactual explanation systems are equipped with a\ncompletely different kind of explanatory information. However, methods for\ngenerating realistic counterfactual explanations for image classifiers are\nstill rare. In this work, we present a novel approach to generate such\ncounterfactual image explanations based on adversarial image-to-image\ntranslation techniques. Additionally, we conduct a user study to evaluate our\napproach in a use case which was inspired by a healthcare scenario. Our results\nshow that our approach leads to significantly better results regarding mental\nmodels, explanation satisfaction, trust, emotions, and self-efficacy than two\nstate-of-the art systems that work with saliency maps, namely LIME and LRP.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 10:08:05 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Mertes", "Silvan", ""], ["Huber", "Tobias", ""], ["Weitz", "Katharina", ""], ["Heimerl", "Alexander", ""], ["Andr\u00e9", "Elisabeth", ""]]}, {"id": "2012.12248", "submitter": "Adrian Korban", "authors": "Adrian Korban, Serap Sahinkaya, Deniz Ustun", "title": "A Novel Genetic Search Scheme Based on Nature -- Inspired Evolutionary\n  Algorithms for Self-Dual Codes", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a genetic algorithm, one of the evolutionary algorithms\noptimization methods, is used for the first time for the problem of finding\nextremal binary self-dual codes. We present a comparison of the computational\ntimes between a genetic algorithm and a linear search for different size search\nspaces and show that the genetic algorithm is capable of finding binary\nself-dual codes significantly faster than the linear search. Moreover, by\nemploying a known matrix construction together with the genetic algorithm, we\nare able to obtain new binary self-dual codes of lengths 68 and 72 in a\nsignificantly short time. In particular, we obtain 11 new extremal binary\nself-dual codes of length 68 and 17 new binary self-dual codes of length 72.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 18:46:22 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Korban", "Adrian", ""], ["Sahinkaya", "Serap", ""], ["Ustun", "Deniz", ""]]}, {"id": "2012.12294", "submitter": "Jakob Drefs", "authors": "Jakob Drefs, Enrico Guiraud, J\\\"org L\\\"ucke", "title": "Evolutionary Variational Optimization of Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We combine two popular optimization approaches to derive learning algorithms\nfor generative models: variational optimization and evolutionary algorithms.\nThe combination is realized for generative models with discrete latents by\nusing truncated posteriors as the family of variational distributions. The\nvariational parameters of truncated posteriors are sets of latent states. By\ninterpreting these states as genomes of individuals and by using the\nvariational lower bound to define a fitness, we can apply evolutionary\nalgorithms to realize the variational loop. The used variational distributions\nare very flexible and we show that evolutionary algorithms can effectively and\nefficiently optimize the variational bound. Furthermore, the variational loop\nis generally applicable (\"black box\") with no analytical derivations required.\nTo show general applicability, we apply the approach to three generative models\n(we use noisy-OR Bayes Nets, Binary Sparse Coding, and Spike-and-Slab Sparse\nCoding). To demonstrate effectiveness and efficiency of the novel variational\napproach, we use the standard competitive benchmarks of image denoising and\ninpainting. The benchmarks allow quantitative comparisons to a wide range of\nmethods including probabilistic approaches, deep deterministic and generative\nnetworks, and non-local image processing methods. In the category of\n\"zero-shot\" learning (when only the corrupted image is used for training), we\nobserved the evolutionary variational algorithm to significantly improve the\nstate-of-the-art in many benchmark settings. For one well-known inpainting\nbenchmark, we also observed state-of-the-art performance across all categories\nof algorithms although we only train on the corrupted image. In general, our\ninvestigations highlight the importance of research on optimization methods for\ngenerative models to achieve performance improvements.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 19:06:33 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 19:44:49 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Drefs", "Jakob", ""], ["Guiraud", "Enrico", ""], ["L\u00fccke", "J\u00f6rg", ""]]}, {"id": "2012.12540", "submitter": "Nilotpal Sinha", "authors": "Nilotpal Sinha, Kuan-Wen Chen", "title": "Evolving Neural Architecture Using One Shot Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural Architecture Search (NAS) is emerging as a new research direction\nwhich has the potential to replace the hand-crafted neural architectures\ndesigned for specific tasks. Previous evolution based architecture search\nrequires high computational resources resulting in high search time. In this\nwork, we propose a novel way of applying a simple genetic algorithm to the NAS\nproblem called EvNAS (Evolving Neural Architecture using One Shot Model) which\nreduces the search time significantly while still achieving better result than\nprevious evolution based methods. The architectures are represented by using\nthe architecture parameter of the one shot model which results in the weight\nsharing among the architectures for a given population of architectures and\nalso weight inheritance from one generation to the next generation of\narchitectures. We propose a decoding technique for the architecture parameter\nwhich is used to divert majority of the gradient information towards the given\narchitecture and is also used for improving the performance prediction of the\ngiven architecture from the one shot model during the search process.\nFurthermore, we use the accuracy of the partially trained architecture on the\nvalidation data as a prediction of its fitness in order to reduce the search\ntime. EvNAS searches for the architecture on the proxy dataset i.e. CIFAR-10\nfor 4.4 GPU day on a single GPU and achieves top-1 test error of 2.47% with\n3.63M parameters which is then transferred to CIFAR-100 and ImageNet achieving\ntop-1 error of 16.37% and top-5 error of 7.4% respectively. All of these\nresults show the potential of evolutionary methods in solving the architecture\nsearch problem.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 08:40:53 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Sinha", "Nilotpal", ""], ["Chen", "Kuan-Wen", ""]]}, {"id": "2012.12586", "submitter": "Oscar Guerrero-Rosado", "authors": "Oscar Guerrero-Rosado and Paul Verschure", "title": "Distributed Adaptive Control: An ideal Cognitive Architecture candidate\n  for managing a robotic recycling plant", "comments": "12 pages, 2 figures, Living Machines conference 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.NE cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past decade, society has experienced notable growth in a variety of\ntechnological areas. However, the Fourth Industrial Revolution has not been\nembraced yet. Industry 4.0 imposes several challenges which include the\nnecessity of new architectural models to tackle the uncertainty that open\nenvironments represent to cyber-physical systems (CPS). Waste Electrical and\nElectronic Equipment (WEEE) recycling plants stand for one of such open\nenvironments. Here, CPSs must work harmoniously in a changing environment,\ninteracting with similar and not so similar CPSs, and adaptively collaborating\nwith human workers. In this paper, we support the Distributed Adaptive Control\n(DAC) theory as a suitable Cognitive Architecture for managing a recycling\nplant. Specifically, a recursive implementation of DAC (between both\nsingle-agent and large-scale levels) is proposed to meet the expected demands\nof the European Project HR-Recycler. Additionally, with the aim of having a\nrealistic benchmark for future implementations of the recursive DAC, a\nmicro-recycling plant prototype is presented.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 10:33:22 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Guerrero-Rosado", "Oscar", ""], ["Verschure", "Paul", ""]]}, {"id": "2012.13134", "submitter": "Katsunari Shibata", "authors": "Katsunari Shibata, Takuya Ejima, Yuki Tokumaru, Toshitaka Matsuki", "title": "Sensitivity - Local Index to Control Chaoticity or Gradient Globally -", "comments": "26 pages, 20 figures", "journal-ref": "Neural Networks, vol.143, pp.436-451 (2021)", "doi": "10.1016/j.neunet.2021.06.015", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Here, we introduce a fully local index named \"sensitivity\" for each neuron to\ncontrol chaoticity or gradient globally in a neural network (NN). We also\npropose a learning method to adjust it named \"sensitivity adjustment learning\n(SAL)\". The index is the gradient magnitude of its output with respect to its\ninputs. By adjusting its time average to 1.0 in each neuron, information\ntransmission in the neuron changes to be moderate without shrinking or\nexpanding for both forward and backward computations. That results in moderate\ninformation transmission through a layer of neurons when the weights and inputs\nare random. Therefore, SAL can control the chaoticity of the network dynamics\nin a recurrent NN (RNN). It can also solve the vanishing gradient problem in\nerror backpropagation (BP) learning in a deep feedforward NN or an RNN. We\ndemonstrate that when applying SAL to an RNN with small and random initial\nweights, log-sensitivity, which is the logarithm of RMS (root mean square)\nsensitivity over all the neurons, is equivalent to the maximum Lyapunov\nexponent until it reaches 0.0. We also show that SAL works with BP or BPTT (BP\nthrough time) to avoid the vanishing gradient problem in a 300-layer NN or an\nRNN that learns a problem with a lag of 300 steps between the first input and\nthe output. Compared with manually fine-tuning the spectral radius of the\nweight matrix before learning, SAL's continuous nonlinear learning nature\nprevents loss of sensitivities during learning, resulting in a significant\nimprovement in learning performance.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 06:35:29 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 13:18:38 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Shibata", "Katsunari", ""], ["Ejima", "Takuya", ""], ["Tokumaru", "Yuki", ""], ["Matsuki", "Toshitaka", ""]]}, {"id": "2012.13320", "submitter": "Min Jiang", "authors": "Min Jiang, Guokun Chi, Geqiang Pan, Shihui Guo, and Kay Chen Tan", "title": "Evolutionary Gait Transfer of Multi-Legged Robots in Complex Terrains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robot gait optimization is the task of generating an optimal control\ntrajectory under various internal and external constraints. Given the high\ndimensions of control space, this problem is particularly challenging for\nmulti-legged robots walking in complex and unknown environments. Existing\nliteratures often regard the gait generation as an optimization problem and\nsolve the gait optimization from scratch for robots walking in a specific\nenvironment. However, such approaches do not consider the use of pre-acquired\nknowledge which can be useful in improving the quality and speed of motion\ngeneration in complex environments. To address the issue, this paper proposes a\ntransfer learning-based evolutionary framework for multi-objective gait\noptimization, named Tr-GO. The idea is to initialize a high-quality population\nby using the technique of transfer learning, so any kind of population-based\noptimization algorithms can be seamlessly integrated into this framework. The\nadvantage is that the generated gait can not only dynamically adapt to\ndifferent environments and tasks, but also simultaneously satisfy multiple\ndesign specifications (e.g., speed, stability). The experimental results show\nthe effectiveness of the proposed framework for the gait optimization problem\nbased on three multi-objective evolutionary algorithms: NSGA-II, RM-MEDA and\nMOPSO. When transferring the pre-acquired knowledge from the plain terrain to\nvarious inclined and rugged ones, the proposed Tr-GO framework accelerates the\nevolution process by a minimum of 3-4 times compared with non-transferred\nscenarios.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 16:41:36 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Jiang", "Min", ""], ["Chi", "Guokun", ""], ["Pan", "Geqiang", ""], ["Guo", "Shihui", ""], ["Tan", "Kay Chen", ""]]}, {"id": "2012.13349", "submitter": "Nicolas Sonnerat", "authors": "Vinod Nair, Sergey Bartunov, Felix Gimeno, Ingrid von Glehn, Pawel\n  Lichocki, Ivan Lobov, Brendan O'Donoghue, Nicolas Sonnerat, Christian\n  Tjandraatmadja, Pengming Wang, Ravichandra Addanki, Tharindi Hapuarachchi,\n  Thomas Keck, James Keeling, Pushmeet Kohli, Ira Ktena, Yujia Li, Oriol\n  Vinyals, Yori Zwols", "title": "Solving Mixed Integer Programs Using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.DM cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed Integer Programming (MIP) solvers rely on an array of sophisticated\nheuristics developed with decades of research to solve large-scale MIP\ninstances encountered in practice. Machine learning offers to automatically\nconstruct better heuristics from data by exploiting shared structure among\ninstances in the data. This paper applies learning to the two key sub-tasks of\na MIP solver, generating a high-quality joint variable assignment, and bounding\nthe gap in objective value between that assignment and an optimal one. Our\napproach constructs two corresponding neural network-based components, Neural\nDiving and Neural Branching, to use in a base MIP solver such as SCIP. Neural\nDiving learns a deep neural network to generate multiple partial assignments\nfor its integer variables, and the resulting smaller MIPs for un-assigned\nvariables are solved with SCIP to construct high quality joint assignments.\nNeural Branching learns a deep neural network to make variable selection\ndecisions in branch-and-bound to bound the objective value gap with a small\ntree. This is done by imitating a new variant of Full Strong Branching we\npropose that scales to large instances using GPUs. We evaluate our approach on\nsix diverse real-world datasets, including two Google production datasets and\nMIPLIB, by training separate neural networks on each. Most instances in all the\ndatasets combined have $10^3-10^6$ variables and constraints after presolve,\nwhich is significantly larger than previous learning approaches. Comparing\nsolvers with respect to primal-dual gap averaged over a held-out set of\ninstances, the learning-augmented SCIP is 2x to 10x better on all datasets\nexcept one on which it is $10^5$x better, at large time limits. To the best of\nour knowledge, ours is the first learning approach to demonstrate such large\nimprovements over SCIP on both large-scale real-world application datasets and\nMIPLIB.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 09:33:11 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 16:49:39 GMT"}, {"version": "v3", "created": "Thu, 29 Jul 2021 13:41:25 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Nair", "Vinod", ""], ["Bartunov", "Sergey", ""], ["Gimeno", "Felix", ""], ["von Glehn", "Ingrid", ""], ["Lichocki", "Pawel", ""], ["Lobov", "Ivan", ""], ["O'Donoghue", "Brendan", ""], ["Sonnerat", "Nicolas", ""], ["Tjandraatmadja", "Christian", ""], ["Wang", "Pengming", ""], ["Addanki", "Ravichandra", ""], ["Hapuarachchi", "Tharindi", ""], ["Keck", "Thomas", ""], ["Keeling", "James", ""], ["Kohli", "Pushmeet", ""], ["Ktena", "Ira", ""], ["Li", "Yujia", ""], ["Vinyals", "Oriol", ""], ["Zwols", "Yori", ""]]}, {"id": "2012.13352", "submitter": "Uwe Aickelin", "authors": "Hadi A. Khorshidi, Michael Kirley, Uwe Aickelin", "title": "Machine learning with incomplete datasets using multi-objective\n  optimization models", "comments": "2020 International Joint Conference on Neural Networks (IJCNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning techniques have been developed to learn from complete data.\nWhen missing values exist in a dataset, the incomplete data should be\npreprocessed separately by removing data points with missing values or\nimputation. In this paper, we propose an online approach to handle missing\nvalues while a classification model is learnt. To reach this goal, we develop a\nmulti-objective optimization model with two objective functions for imputation\nand model selection. We also propose three formulations for imputation\nobjective function. We use an evolutionary algorithm based on NSGA II to find\nthe optimal solutions as the Pareto solutions. We investigate the reliability\nand robustness of the proposed model using experiments by defining several\nscenarios in dealing with missing values and classification. We also describe\nhow the proposed model can contribute to medical informatics. We compare the\nperformance of three different formulations via experimental results. The\nproposed model results get validated by comparing with a comparable literature.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 03:44:33 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Khorshidi", "Hadi A.", ""], ["Kirley", "Michael", ""], ["Aickelin", "Uwe", ""]]}, {"id": "2012.13421", "submitter": "Laura Giordano", "authors": "Laura Giordano and Daniele Theseider Dupr\\'e", "title": "Weighted defeasible knowledge bases and a multipreference semantics for\n  a deep neural network model", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the relationships between a multipreferential\nsemantics for defeasible reasoning in knowledge representation and a deep\nneural network model. Weighted knowledge bases for description logics are\nconsidered under a \"concept-wise\" multipreference semantics. The semantics is\nfurther extended to fuzzy interpretations and exploited to provide a\npreferential interpretation of Multilayer Perceptrons.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 19:04:51 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 18:11:00 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Giordano", "Laura", ""], ["Dupr\u00e9", "Daniele Theseider", ""]]}, {"id": "2012.13475", "submitter": "Amy X. Lu", "authors": "Amy X. Lu, Alex X. Lu, Alan Moses", "title": "Evolution Is All You Need: Phylogenetic Augmentation for Contrastive\n  Learning", "comments": "Machine Learning in Computational Biology (MLCB) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised representation learning of biological sequence embeddings\nalleviates computational resource constraints on downstream tasks while\ncircumventing expensive experimental label acquisition. However, existing\nmethods mostly borrow directly from large language models designed for NLP,\nrather than with bioinformatics philosophies in mind. Recently, contrastive\nmutual information maximization methods have achieved state-of-the-art\nrepresentations for ImageNet. In this perspective piece, we discuss how viewing\nevolution as natural sequence augmentation and maximizing information across\nphylogenetic \"noisy channels\" is a biologically and theoretically desirable\nobjective for pretraining encoders. We first provide a review of current\ncontrastive learning literature, then provide an illustrative example where we\nshow that contrastive learning using evolutionary augmentation can be used as a\nrepresentation learning objective which maximizes the mutual information\nbetween biological sequences and their conserved function, and finally outline\nrationale for this approach.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 01:35:06 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Lu", "Amy X.", ""], ["Lu", "Alex X.", ""], ["Moses", "Alan", ""]]}, {"id": "2012.13567", "submitter": "Hafez Ghaemi", "authors": "Mahbod Nouri, Faraz Moradi, Hafez Ghaemi, Ali Motie Nasrabadi", "title": "Towards Real-World BCI: CCSPNet, A Compact Subject-Independent Motor\n  Imagery Framework", "comments": "15 pages, 6 figures, 6 tables, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE eess.SP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A conventional subject-dependent (SD) brain-computer interface (BCI) requires\na complete data-gathering, training, and calibration phase for each user before\nit can be used. In recent years, a number of subject-independent (SI) BCIs have\nbeen developed. However, there are many problems preventing them from being\nused in real-world BCI applications. A weaker performance compared to the\nsubject-dependent (SD) approach, and a relatively large model requiring high\ncomputational power are the most important ones. Therefore, a potential\nreal-world BCI would greatly benefit from a compact low-power\nsubject-independent BCI framework, ready to be used immediately after the user\nputs it on. To move towards this goal, we propose a novel subject-independent\nBCI framework named CCSPNet (Convolutional Common Spatial Pattern Network)\ntrained on the motor imagery (MI) paradigm of a large-scale\nelectroencephalography (EEG) signals database consisting of 21600 trials for 54\nsubjects performing two-class hand-movement MI tasks. The proposed framework\napplies a wavelet kernel convolutional neural network (WKCNN) and a temporal\nconvolutional neural network (TCNN) in order to represent and extract the\ndiverse spectral features of EEG signals. The outputs of the convolutional\nlayers go through a common spatial pattern (CSP) algorithm for spatial feature\nextraction. The number of CSP features is reduced by a dense neural network,\nand the final class label is determined by a linear discriminative analysis\n(LDA) classifier. The CCSPNet framework evaluation results show that it is\npossible to have a low-power compact BCI that achieves both SD and SI\nperformance comparable to complex and computationally expensive.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 12:00:47 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 11:07:29 GMT"}, {"version": "v3", "created": "Sat, 10 Apr 2021 19:10:36 GMT"}, {"version": "v4", "created": "Fri, 2 Jul 2021 08:12:12 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Nouri", "Mahbod", ""], ["Moradi", "Faraz", ""], ["Ghaemi", "Hafez", ""], ["Nasrabadi", "Ali Motie", ""]]}, {"id": "2012.13574", "submitter": "Margarita Rebolledo", "authors": "Margarita Rebolledo, Sowmya Chandrasekaran, and Thomas\n  Bartz-Beielstein", "title": "Technical Report: Flushing Strategies in Drinking Water Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Drinking water supply and distribution systems are critical infrastructure\nthat has to be well maintained for the safety of the public. One important tool\nin the maintenance of water distribution systems (WDS) is flushing. Flushing is\na process carried out in a periodic fashion to clean sediments and other\ncontaminants in the water pipes. Given the different topographies, water\ncomposition and supply demand between WDS no single flushing strategy is\nsuitable for all of them. In this report a non-exhaustive overview of\noptimization methods for flushing in WDS is given. Implementation of\noptimization methods for the flushing procedure and the flushing planing are\npresented. Suggestions are given as a possible option to optimise existing\nflushing planing frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 13:37:06 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Rebolledo", "Margarita", ""], ["Chandrasekaran", "Sowmya", ""], ["Bartz-Beielstein", "Thomas", ""]]}, {"id": "2012.13628", "submitter": "Ahmadreza Jeddi", "authors": "Ahmadreza Jeddi, Mohammad Javad Shafiee, Alexander Wong", "title": "A Simple Fine-tuning Is All You Need: Towards Robust Deep Learning Via\n  Adversarial Fine-tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Adversarial Training (AT) with Projected Gradient Descent (PGD) is an\neffective approach for improving the robustness of the deep neural networks.\nHowever, PGD AT has been shown to suffer from two main limitations: i) high\ncomputational cost, and ii) extreme overfitting during training that leads to\nreduction in model generalization. While the effect of factors such as model\ncapacity and scale of training data on adversarial robustness have been\nextensively studied, little attention has been paid to the effect of a very\nimportant parameter in every network optimization on adversarial robustness:\nthe learning rate. In particular, we hypothesize that effective learning rate\nscheduling during adversarial training can significantly reduce the overfitting\nissue, to a degree where one does not even need to adversarially train a model\nfrom scratch but can instead simply adversarially fine-tune a pre-trained\nmodel. Motivated by this hypothesis, we propose a simple yet very effective\nadversarial fine-tuning approach based on a $\\textit{slow start, fast decay}$\nlearning rate scheduling strategy which not only significantly decreases\ncomputational cost required, but also greatly improves the accuracy and\nrobustness of a deep neural network. Experimental results show that the\nproposed adversarial fine-tuning approach outperforms the state-of-the-art\nmethods on CIFAR-10, CIFAR-100 and ImageNet datasets in both test accuracy and\nthe robustness, while reducing the computational cost by 8-10$\\times$.\nFurthermore, a very important benefit of the proposed adversarial fine-tuning\napproach is that it enables the ability to improve the robustness of any\npre-trained deep neural network without needing to train the model from\nscratch, which to the best of the authors' knowledge has not been previously\ndemonstrated in research literature.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 20:50:15 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Jeddi", "Ahmadreza", ""], ["Shafiee", "Mohammad Javad", ""], ["Wong", "Alexander", ""]]}, {"id": "2012.14368", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu, Faeze Ebrahimian, Jerry Li, Dan Alistarh", "title": "Byzantine-Resilient Non-Convex Stochastic Gradient Descent", "comments": "V1.5 polishes writing and V2 rewrites the experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.DS cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study adversary-resilient stochastic distributed optimization, in which\n$m$ machines can independently compute stochastic gradients, and cooperate to\njointly optimize over their local objective functions. However, an\n$\\alpha$-fraction of the machines are $\\textit{Byzantine}$, in that they may\nbehave in arbitrary, adversarial ways. We consider a variant of this procedure\nin the challenging $\\textit{non-convex}$ case. Our main result is a new\nalgorithm SafeguardSGD which can provably escape saddle points and find\napproximate local minima of the non-convex objective. The algorithm is based on\na new concentration filtering technique, and its sample and time complexity\nbounds match the best known theoretical bounds in the stochastic, distributed\nsetting when no Byzantine machines are present.\n  Our algorithm is very practical: it improves upon the performance of all\nprior methods when training deep neural networks, it is relatively lightweight,\nand it is the first method to withstand two recently-proposed Byzantine\nattacks.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 17:19:32 GMT"}, {"version": "v2", "created": "Fri, 2 Apr 2021 17:25:48 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Ebrahimian", "Faeze", ""], ["Li", "Jerry", ""], ["Alistarh", "Dan", ""]]}, {"id": "2012.14601", "submitter": "Taylor Webb", "authors": "Taylor W. Webb, Ishan Sinha, Jonathan D. Cohen", "title": "Emergent Symbols through Binding in External Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key aspect of human intelligence is the ability to infer abstract rules\ndirectly from high-dimensional sensory data, and to do so given only a limited\namount of training experience. Deep neural network algorithms have proven to be\na powerful tool for learning directly from high-dimensional data, but currently\nlack this capacity for data-efficient induction of abstract rules, leading some\nto argue that symbol-processing mechanisms will be necessary to account for\nthis capacity. In this work, we take a step toward bridging this gap by\nintroducing the Emergent Symbol Binding Network (ESBN), a recurrent network\naugmented with an external memory that enables a form of variable-binding and\nindirection. This binding mechanism allows symbol-like representations to\nemerge through the learning process without the need to explicitly incorporate\nsymbol-processing machinery, enabling the ESBN to learn rules in a manner that\nis abstracted away from the particular entities to which those rules apply.\nAcross a series of tasks, we show that this architecture displays nearly\nperfect generalization of learned rules to novel entities given only a limited\nnumber of training examples, and outperforms a number of other competitive\nneural network architectures.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 04:28:32 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 01:13:38 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Webb", "Taylor W.", ""], ["Sinha", "Ishan", ""], ["Cohen", "Jonathan D.", ""]]}, {"id": "2012.14905", "submitter": "Louis Kirsch", "authors": "Louis Kirsch and J\\\"urgen Schmidhuber", "title": "Meta Learning Backpropagation And Improving It", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many concepts have been proposed for meta learning with neural networks\n(NNs), e.g., NNs that learn to control fast weights, hyper networks, learned\nlearning rules, and meta recurrent NNs. Our Variable Shared Meta Learning\n(VS-ML) unifies the above and demonstrates that simple weight-sharing and\nsparsity in an NN is sufficient to express powerful learning algorithms (LAs)\nin a reusable fashion. A simple implementation of VS-ML called VS-ML RNN allows\nfor implementing the backpropagation LA solely by running an RNN in\nforward-mode. It can even meta-learn new LAs that improve upon backpropagation\nand generalize to datasets outside of the meta training distribution without\nexplicit gradient calculation. Introspection reveals that our meta-learned LAs\nlearn qualitatively different from gradient descent through fast association.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 18:56:10 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 17:28:31 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Kirsch", "Louis", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "2012.15059", "submitter": "Rakshitha Godahewa", "authors": "Rakshitha Godahewa, Kasun Bandara, Geoffrey I. Webb, Slawek Smyl,\n  Christoph Bergmeir", "title": "Ensembles of Localised Models for Time Series Forecasting", "comments": "29 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With large quantities of data typically available nowadays, forecasting\nmodels that are trained across sets of time series, known as Global Forecasting\nModels (GFM), are regularly outperforming traditional univariate forecasting\nmodels that work on isolated series. As GFMs usually share the same set of\nparameters across all time series, they often have the problem of not being\nlocalised enough to a particular series, especially in situations where\ndatasets are heterogeneous. We study how ensembling techniques can be used with\ngeneric GFMs and univariate models to solve this issue. Our work systematises\nand compares relevant current approaches, namely clustering series and training\nseparate submodels per cluster, the so-called ensemble of specialists approach,\nand building heterogeneous ensembles of global and local models. We fill some\ngaps in the approaches and generalise them to different underlying GFM model\ntypes. We then propose a new methodology of clustered ensembles where we train\nmultiple GFMs on different clusters of series, obtained by changing the number\nof clusters and cluster seeds. Using Feed-forward Neural Networks, Recurrent\nNeural Networks, and Pooled Regression models as the underlying GFMs, in our\nevaluation on six publicly available datasets, the proposed models are able to\nachieve significantly higher accuracy than baseline GFM models and univariate\nforecasting methods.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2020 06:33:51 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Godahewa", "Rakshitha", ""], ["Bandara", "Kasun", ""], ["Webb", "Geoffrey I.", ""], ["Smyl", "Slawek", ""], ["Bergmeir", "Christoph", ""]]}]