[{"id": "1606.00094", "submitter": "Matthew Moskewicz", "authors": "Matthew Moskewicz and Forrest Iandola and Kurt Keutzer", "title": "Boda-RTC: Productive Generation of Portable, Efficient Code for\n  Convolutional Neural Networks on Mobile Computing Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of neural networks (NNs) spans academia, industry, and popular\nculture. In particular, convolutional neural networks (CNNs) have been applied\nto many image based machine learning tasks and have yielded strong results. The\navailability of hardware/software systems for efficient training and deployment\nof large and/or deep CNN models has been, and continues to be, an important\nconsideration for the field. Early systems for NN computation focused on\nleveraging existing dense linear algebra techniques and libraries. Current\napproaches use low-level machine specific programming and/or closed-source,\npurpose-built vendor libraries. In this work, we present an open source system\nthat, compared to existing approaches, achieves competitive computational speed\nwhile achieving higher portability. We achieve this by targeting the\nvendor-neutral OpenCL platform using a code-generation approach. We argue that\nour approach allows for both: (1) the rapid development of new computational\nkernels for existing hardware targets, and (2) the rapid tuning of existing\ncomputational kernels for new hardware targets. Results are presented for a\ncase study of targeting the Qualcomm Snapdragon 820 mobile computing platform\nfor CNN deployment.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 02:17:26 GMT"}, {"version": "v2", "created": "Tue, 13 Sep 2016 16:20:09 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Moskewicz", "Matthew", ""], ["Iandola", "Forrest", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1606.00157", "submitter": "Zhaofei Yu", "authors": "Zhaofei Yu, David Kappel, Robert Legenstein, Sen Song, Feng Chen,\n  Wolfgang Maass", "title": "CaMKII activation supports reward-based neural network optimization\n  through Hamiltonian sampling", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synaptic plasticity is implemented and controlled through over thousand\ndifferent types of molecules in the postsynaptic density and presynaptic\nboutons that assume a staggering array of different states through\nphosporylation and other mechanisms. One of the most prominent molecule in the\npostsynaptic density is CaMKII, that is described in molecular biology as a\n\"memory molecule\" that can integrate through auto-phosporylation Ca-influx\nsignals on a relatively large time scale of dozens of seconds. The functional\nimpact of this memory mechanism is largely unknown. We show that the\nexperimental data on the specific role of CaMKII activation in dopamine-gated\nspine consolidation suggest a general functional role in speeding up\nreward-guided search for network configurations that maximize reward\nexpectation. Our theoretical analysis shows that stochastic search could in\nprinciple even attain optimal network configurations by emulating one of the\nmost well-known nonlinear optimization methods, simulated annealing. But this\noptimization is usually impeded by slowness of stochastic search at a given\ntemperature. We propose that CaMKII contributes a momentum term that\nsubstantially speeds up this search. In particular, it allows the network to\novercome saddle points of the fitness function. The resulting improved\nstochastic policy search can be understood on a more abstract level as\nHamiltonian sampling, which is known to be one of the most efficient stochastic\nsearch methods.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 08:12:34 GMT"}, {"version": "v2", "created": "Thu, 29 Sep 2016 09:51:22 GMT"}, {"version": "v3", "created": "Tue, 15 May 2018 16:57:22 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Yu", "Zhaofei", ""], ["Kappel", "David", ""], ["Legenstein", "Robert", ""], ["Song", "Sen", ""], ["Chen", "Feng", ""], ["Maass", "Wolfgang", ""]]}, {"id": "1606.00540", "submitter": "Zhen Hu", "authors": "Zhen Hu, Zhuyin Xue, Tong Cui, Shiqiang Zong, Chenglong He", "title": "Multi-pretrained Deep Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretraining is widely used in deep neutral network and one of the most famous\npretraining models is Deep Belief Network (DBN). The optimization formulas are\ndifferent during the pretraining process for different pretraining models. In\nthis paper, we pretrained deep neutral network by different pretraining models\nand hence investigated the difference between DBN and Stacked Denoising\nAutoencoder (SDA) when used as pretraining model. The experimental results show\nthat DBN get a better initial model. However the model converges to a\nrelatively worse model after the finetuning process. Yet after pretrained by\nSDA for the second time the model converges to a better model if finetuned.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 05:39:54 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Hu", "Zhen", ""], ["Xue", "Zhuyin", ""], ["Cui", "Tong", ""], ["Zong", "Shiqiang", ""], ["He", "Chenglong", ""]]}, {"id": "1606.00575", "submitter": "Shizhao Sun", "authors": "Shizhao Sun, Wei Chen, Jiang Bian, Xiaoguang Liu, Tie-Yan Liu", "title": "Ensemble-Compression: A New Method for Parallel Training of Deep Neural\n  Networks", "comments": "ECML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallelization framework has become a necessity to speed up the training of\ndeep neural networks (DNN) recently. Such framework typically employs the Model\nAverage approach, denoted as MA-DNN, in which parallel workers conduct\nrespective training based on their own local data while the parameters of local\nmodels are periodically communicated and averaged to obtain a global model\nwhich serves as the new start of local models. However, since DNN is a highly\nnon-convex model, averaging parameters cannot ensure that such global model can\nperform better than those local models. To tackle this problem, we introduce a\nnew parallel training framework called Ensemble-Compression, denoted as EC-DNN.\nIn this framework, we propose to aggregate the local models by ensemble, i.e.,\naveraging the outputs of local models instead of the parameters. As most of\nprevalent loss functions are convex to the output of DNN, the performance of\nensemble-based global model is guaranteed to be at least as good as the average\nperformance of local models. However, a big challenge lies in the explosion of\nmodel size since each round of ensemble can give rise to multiple times size\nincrement. Thus, we carry out model compression after each ensemble,\nspecialized by a distillation based method in this paper, to reduce the size of\nthe global model to be the same as the local ones. Our experimental results\ndemonstrate the prominent advantage of EC-DNN over MA-DNN in terms of both\naccuracy and speedup.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 08:10:10 GMT"}, {"version": "v2", "created": "Tue, 18 Jul 2017 08:50:05 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Sun", "Shizhao", ""], ["Chen", "Wei", ""], ["Bian", "Jiang", ""], ["Liu", "Xiaoguang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1606.00601", "submitter": "Chun Liu", "authors": "Chun Liu, Andreas Kroll", "title": "On the performance of different mutation operators of a\n  subpopulation-based genetic algorithm for multi-robot task allocation\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of different mutation operators is usually evaluated in\nconjunc-tion with specific parameter settings of genetic algorithms and target\nproblems. Most studies focus on the classical genetic algorithm with different\nparameters or on solving unconstrained combinatorial optimization problems such\nas the traveling salesman problems. In this paper, a subpopulation-based\ngenetic al-gorithm that uses only mutation and selection is developed to solve\nmulti-robot task allocation problems. The target problems are constrained\ncombinatorial optimization problems, and are more complex if cooperative tasks\nare involved as these introduce additional spatial and temporal constraints.\nThe proposed genetic algorithm can obtain better solutions than classical\ngenetic algorithms with tournament selection and partially mapped crossover.\nThe performance of different mutation operators in solving problems\nwithout/with cooperative tasks is evaluated. The results imply that inversion\nmutation performs better than others when solving problems without cooperative\ntasks, and the swap-inversion combination performs better than others when\nsolving problems with cooperative tasks.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 09:57:52 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Liu", "Chun", ""], ["Kroll", "Andreas", ""]]}, {"id": "1606.00611", "submitter": "Boris Knyazev", "authors": "Boris Knyazev, Erhardt Barth, Thomas Martinetz", "title": "Recursive Autoconvolution for Unsupervised Learning of Convolutional\n  Neural Networks", "comments": "8 pages, accepted to International Joint Conference on Neural\n  Networks (IJCNN 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In visual recognition tasks, such as image classification, unsupervised\nlearning exploits cheap unlabeled data and can help to solve these tasks more\nefficiently. We show that the recursive autoconvolution operator, adopted from\nphysics, boosts existing unsupervised methods by learning more discriminative\nfilters. We take well established convolutional neural networks and train their\nfilters layer-wise. In addition, based on previous works we design a network\nwhich extracts more than 600k features per sample, but with the total number of\ntrainable parameters greatly reduced by introducing shared filters in higher\nlayers. We evaluate our networks on the MNIST, CIFAR-10, CIFAR-100 and STL-10\nimage classification benchmarks and report several state of the art results\namong other unsupervised methods.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 10:37:46 GMT"}, {"version": "v2", "created": "Sun, 26 Mar 2017 18:31:05 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Knyazev", "Boris", ""], ["Barth", "Erhardt", ""], ["Martinetz", "Thomas", ""]]}, {"id": "1606.00776", "submitter": "Iulian Vlad Serban", "authors": "Iulian Vlad Serban, Tim Klinger, Gerald Tesauro, Kartik Talamadupula,\n  Bowen Zhou, Yoshua Bengio, Aaron Courville", "title": "Multiresolution Recurrent Neural Networks: An Application to Dialogue\n  Response Generation", "comments": "21 pages, 2 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the multiresolution recurrent neural network, which extends the\nsequence-to-sequence framework to model natural language generation as two\nparallel discrete stochastic processes: a sequence of high-level coarse tokens,\nand a sequence of natural language tokens. There are many ways to estimate or\nlearn the high-level coarse tokens, but we argue that a simple extraction\nprocedure is sufficient to capture a wealth of high-level discourse semantics.\nSuch procedure allows training the multiresolution recurrent neural network by\nmaximizing the exact joint log-likelihood over both sequences. In contrast to\nthe standard log- likelihood objective w.r.t. natural language tokens (word\nperplexity), optimizing the joint log-likelihood biases the model towards\nmodeling high-level abstractions. We apply the proposed model to the task of\ndialogue response generation in two challenging domains: the Ubuntu technical\nsupport domain, and Twitter conversations. On Ubuntu, the model outperforms\ncompeting approaches by a substantial margin, achieving state-of-the-art\nresults according to both automatic evaluation metrics and a human evaluation\nstudy. On Twitter, the model appears to generate more relevant and on-topic\nresponses according to automatic evaluation metrics. Finally, our experiments\ndemonstrate that the proposed model is more adept at overcoming the sparsity of\nnatural language and is better able to capture long-term structure.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 17:37:31 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2016 02:01:16 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Serban", "Iulian Vlad", ""], ["Klinger", "Tim", ""], ["Tesauro", "Gerald", ""], ["Talamadupula", "Kartik", ""], ["Zhou", "Bowen", ""], ["Bengio", "Yoshua", ""], ["Courville", "Aaron", ""]]}, {"id": "1606.00802", "submitter": "Amirhossein Tavanaei", "authors": "Amirhossein Tavanaei and Anthony S Maida", "title": "A Spiking Network that Learns to Extract Spike Signatures from Speech\n  Signals", "comments": "Published in Neurocomputing Journal, Elsevier", "journal-ref": "Neurocomputing, 140:191-199, 2017", "doi": "10.1016/j.neucom.2017.01.088", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) with adaptive synapses reflect core properties\nof biological neural networks. Speech recognition, as an application involving\naudio coding and dynamic learning, provides a good test problem to study SNN\nfunctionality. We present a simple, novel, and efficient nonrecurrent SNN that\nlearns to convert a speech signal into a spike train signature. The signature\nis distinguishable from signatures for other speech signals representing\ndifferent words, thereby enabling digit recognition and discrimination in\ndevices that use only spiking neurons. The method uses a small, nonrecurrent\nSNN consisting of Izhikevich neurons equipped with spike timing dependent\nplasticity (STDP) and biologically realistic synapses. This approach introduces\nan efficient and fast network without error-feedback training, although it does\nrequire supervised training. The new simulation results produce discriminative\nspike train patterns for spoken digits in which highly correlated spike trains\nbelong to the same category and low correlated patterns belong to different\ncategories. The proposed SNN is evaluated using a spoken digit recognition task\nwhere a subset of the Aurora speech dataset is used. The experimental results\nshow that the network performs well in terms of accuracy rate and complexity.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 18:54:25 GMT"}, {"version": "v2", "created": "Tue, 11 Oct 2016 19:27:43 GMT"}, {"version": "v3", "created": "Sun, 12 Mar 2017 04:31:19 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Tavanaei", "Amirhossein", ""], ["Maida", "Anthony S", ""]]}, {"id": "1606.00825", "submitter": "Amirhossein Tavanaei", "authors": "Amirhossein Tavanaei and Anthony S Maida", "title": "Training a Hidden Markov Model with a Bayesian Spiking Neural Network", "comments": "Bayesian Spiking Neural Network, Revision submitted: April-27-2016", "journal-ref": "Journal of Signal Processing Systems, (2016), 1-10", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is of some interest to understand how statistically based mechanisms for\nsignal processing might be integrated with biologically motivated mechanisms\nsuch as neural networks. This paper explores a novel hybrid approach for\nclassifying segments of sequential data, such as individual spoken works. The\napproach combines a hidden Markov model (HMM) with a spiking neural network\n(SNN). The HMM, consisting of states and transitions, forms a fixed backbone\nwith nonadaptive transition probabilities. The SNN, however, implements a\nbiologically based Bayesian computation that derives from the spike\ntiming-dependent plasticity (STDP) learning rule. The emission (observation)\nprobabilities of the HMM are represented in the SNN and trained with the STDP\nrule. A separate SNN, each with the same architecture, is associated with each\nof the states of the HMM. Because of the STDP training, each SNN implements an\nexpectation maximization algorithm to learn the emission probabilities for one\nHMM state. The model was studied on synthesized spike-train data and also on\nspoken word data. Preliminary results suggest its performance compares\nfavorably with other biologically motivated approaches. Because of the model's\nuniqueness and initial promise, it warrants further study. It provides some new\nideas on how the brain might implement the equivalent of an HMM in a neural\ncircuit.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 19:48:22 GMT"}, {"version": "v2", "created": "Wed, 20 Jul 2016 22:42:41 GMT"}], "update_date": "2016-07-22", "authors_parsed": [["Tavanaei", "Amirhossein", ""], ["Maida", "Anthony S", ""]]}, {"id": "1606.00931", "submitter": "Jared Katzman", "authors": "Jared Katzman, Uri Shaham, Jonathan Bates, Alexander Cloninger,\n  Tingting Jiang, Yuval Kluger", "title": "DeepSurv: Personalized Treatment Recommender System Using A Cox\n  Proportional Hazards Deep Neural Network", "comments": "Presented at the International Conference of Machine Learning\n  Computational Biology Workshop 2016", "journal-ref": null, "doi": "10.1186/s12874-018-0482-1", "report-no": null, "categories": "stat.ML cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical practitioners use survival models to explore and understand the\nrelationships between patients' covariates (e.g. clinical and genetic features)\nand the effectiveness of various treatment options. Standard survival models\nlike the linear Cox proportional hazards model require extensive feature\nengineering or prior medical knowledge to model treatment interaction at an\nindividual level. While nonlinear survival methods, such as neural networks and\nsurvival forests, can inherently model these high-level interaction terms, they\nhave yet to be shown as effective treatment recommender systems. We introduce\nDeepSurv, a Cox proportional hazards deep neural network and state-of-the-art\nsurvival method for modeling interactions between a patient's covariates and\ntreatment effectiveness in order to provide personalized treatment\nrecommendations. We perform a number of experiments training DeepSurv on\nsimulated and real survival data. We demonstrate that DeepSurv performs as well\nas or better than other state-of-the-art survival models and validate that\nDeepSurv successfully models increasingly complex relationships between a\npatient's covariates and their risk of failure. We then show how DeepSurv\nmodels the relationship between a patient's features and effectiveness of\ndifferent treatment options to show how DeepSurv can be used to provide\nindividual treatment recommendations. Finally, we train DeepSurv on real\nclinical studies to demonstrate how it's personalized treatment recommendations\nwould increase the survival time of a set of patients. The predictive and\nmodeling capabilities of DeepSurv will enable medical researchers to use deep\nneural networks as a tool in their exploration, understanding, and prediction\nof the effects of a patient's characteristics on their risk of failure.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 23:01:49 GMT"}, {"version": "v2", "created": "Tue, 25 Oct 2016 01:17:22 GMT"}, {"version": "v3", "created": "Wed, 9 Aug 2017 02:58:51 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Katzman", "Jared", ""], ["Shaham", "Uri", ""], ["Bates", "Jonathan", ""], ["Cloninger", "Alexander", ""], ["Jiang", "Tingting", ""], ["Kluger", "Yuval", ""]]}, {"id": "1606.00972", "submitter": "Jianwen Xie", "authors": "Jianwen Xie, Song-Chun Zhu, Ying Nian Wu", "title": "Synthesizing Dynamic Patterns by Spatial-Temporal Generative ConvNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video sequences contain rich dynamic patterns, such as dynamic texture\npatterns that exhibit stationarity in the temporal domain, and action patterns\nthat are non-stationary in either spatial or temporal domain. We show that a\nspatial-temporal generative ConvNet can be used to model and synthesize dynamic\npatterns. The model defines a probability distribution on the video sequence,\nand the log probability is defined by a spatial-temporal ConvNet that consists\nof multiple layers of spatial-temporal filters to capture spatial-temporal\npatterns of different scales. The model can be learned from the training video\nsequences by an \"analysis by synthesis\" learning algorithm that iterates the\nfollowing two steps. Step 1 synthesizes video sequences from the currently\nlearned model. Step 2 then updates the model parameters based on the difference\nbetween the synthesized video sequences and the observed training sequences. We\nshow that the learning algorithm can synthesize realistic dynamic patterns.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 05:36:06 GMT"}, {"version": "v2", "created": "Mon, 29 May 2017 23:26:38 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Xie", "Jianwen", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1606.00979", "submitter": "Kang Liu", "authors": "Yuanzhe Zhang, Kang Liu, Shizhu He, Guoliang Ji, Zhanyi Liu, Hua Wu,\n  Jun Zhao", "title": "Question Answering over Knowledge Base with Neural Attention Combining\n  Global Knowledge Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of knowledge bases (KBs) on the web, how to take full\nadvantage of them becomes increasingly important. Knowledge base-based question\nanswering (KB-QA) is one of the most promising approaches to access the\nsubstantial knowledge. Meantime, as the neural network-based (NN-based) methods\ndevelop, NN-based KB-QA has already achieved impressive results. However,\nprevious work did not put emphasis on question representation, and the question\nis converted into a fixed vector regardless of its candidate answers. This\nsimple representation strategy is unable to express the proper information of\nthe question. Hence, we present a neural attention-based model to represent the\nquestions dynamically according to the different focuses of various candidate\nanswer aspects. In addition, we leverage the global knowledge inside the\nunderlying KB, aiming at integrating the rich KB information into the\nrepresentation of the answers. And it also alleviates the out of vocabulary\n(OOV) problem, which helps the attention model to represent the question more\nprecisely. The experimental results on WEBQUESTIONS demonstrate the\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 06:40:14 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Zhang", "Yuanzhe", ""], ["Liu", "Kang", ""], ["He", "Shizhu", ""], ["Ji", "Guoliang", ""], ["Liu", "Zhanyi", ""], ["Wu", "Hua", ""], ["Zhao", "Jun", ""]]}, {"id": "1606.01102", "submitter": "Amirhossein Tavanaei", "authors": "Amirhossein Tavanaei, Timothee Masquelier, Anthony S Maida", "title": "Acquisition of Visual Features Through Probabilistic\n  Spike-Timing-Dependent Plasticity", "comments": "IEEE-IJCNN 2016", "journal-ref": "2016 International Joint Conference on Neural Networks", "doi": "10.1109/IJCNN.2016.7727213", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The final version of this paper has been published in IEEEXplore available at\nhttp://ieeexplore.ieee.org/document/7727213. Please cite this paper as:\nAmirhossein Tavanaei, Timothee Masquelier, and Anthony Maida, Acquisition of\nvisual features through probabilistic spike-timing-dependent plasticity. IEEE\nInternational Joint Conference on Neural Networks. pp. 307-314, IJCNN 2016.\n  This paper explores modifications to a feedforward five-layer spiking\nconvolutional network (SCN) of the ventral visual stream [Masquelier, T.,\nThorpe, S., Unsupervised learning of visual features through spike timing\ndependent plasticity. PLoS Computational Biology, 3(2), 247-257]. The original\nmodel showed that a spike-timing-dependent plasticity (STDP) learning algorithm\nembedded in an appropriately selected SCN could perform unsupervised feature\ndiscovery. The discovered features where interpretable and could effectively be\nused to perform rapid binary decisions in a classifier. In order to study the\nrobustness of the previous results, the present research examines the effects\nof modifying some of the components of the original model. For improved\nbiological realism, we replace the original non-leaky integrate-and-fire\nneurons with Izhikevich-like neurons. We also replace the original STDP rule\nwith a novel rule that has a probabilistic interpretation. The probabilistic\nSTDP slightly but significantly improves the performance for both types of\nmodel neurons. Use of the Izhikevich-like neuron was not found to improve\nperformance although performance was still comparable to the IF neuron. This\nshows that the model is robust enough to handle more biologically realistic\nneurons. We also conclude that the underlying reasons for stable performance in\nthe model are preserved despite the overt changes to the explicit components of\nthe model.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 14:30:38 GMT"}, {"version": "v2", "created": "Wed, 9 Nov 2016 03:43:14 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Tavanaei", "Amirhossein", ""], ["Masquelier", "Timothee", ""], ["Maida", "Anthony S", ""]]}, {"id": "1606.01164", "submitter": "Dmitry Krotov", "authors": "Dmitry Krotov, John J Hopfield", "title": "Dense Associative Memory for Pattern Recognition", "comments": "Accepted for publication at NIPS 2016", "journal-ref": "Advances in Neural Information Processing Systems 29 (2016),\n  1172-1180", "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model of associative memory is studied, which stores and reliably retrieves\nmany more patterns than the number of neurons in the network. We propose a\nsimple duality between this dense associative memory and neural networks\ncommonly used in deep learning. On the associative memory side of this duality,\na family of models that smoothly interpolates between two limiting cases can be\nconstructed. One limit is referred to as the feature-matching mode of pattern\nrecognition, and the other one as the prototype regime. On the deep learning\nside of the duality, this family corresponds to feedforward neural networks\nwith one hidden layer and various activation functions, which transmit the\nactivities of the visible neurons to the hidden layer. This family of\nactivation functions includes logistics, rectified linear units, and rectified\npolynomials of higher degrees. The proposed duality makes it possible to apply\nenergy-based intuition from associative memory to analyze computational\nproperties of neural networks with unusual activation functions - the higher\nrectified polynomials which until now have not been used in deep learning. The\nutility of the dense memories is illustrated for two test cases: the logical\ngate XOR and the recognition of handwritten digits from the MNIST data set.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 16:17:01 GMT"}, {"version": "v2", "created": "Tue, 27 Sep 2016 16:05:36 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Krotov", "Dmitry", ""], ["Hopfield", "John J", ""]]}, {"id": "1606.01166", "submitter": "Jean-Charles Vialatte", "authors": "Jean-Charles Vialatte, Vincent Gripon, Gr\\'egoire Mercier", "title": "Generalizing the Convolution Operator to extend CNNs to Irregular\n  Domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have become the state-of-the-art in\nsupervised learning vision tasks. Their convolutional filters are of paramount\nimportance for they allow to learn patterns while disregarding their locations\nin input images. When facing highly irregular domains, generalized\nconvolutional operators based on an underlying graph structure have been\nproposed. However, these operators do not exactly match standard ones on grid\ngraphs, and introduce unwanted additional invariance (e.g. with regards to\nrotations). We propose a novel approach to generalize CNNs to irregular domains\nusing weight sharing and graph-based operators. Using experiments, we show that\nthese models resemble CNNs on regular domains and offer better performance than\nmultilayer perceptrons on distorded ones.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 16:18:22 GMT"}, {"version": "v2", "created": "Mon, 27 Jun 2016 09:41:55 GMT"}, {"version": "v3", "created": "Tue, 4 Jul 2017 11:46:46 GMT"}, {"version": "v4", "created": "Wed, 25 Oct 2017 12:28:26 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Vialatte", "Jean-Charles", ""], ["Gripon", "Vincent", ""], ["Mercier", "Gr\u00e9goire", ""]]}, {"id": "1606.01239", "submitter": "Reza Moazzezi", "authors": "Reza Moazzezi", "title": "Grid-like structure is optimal for path integration", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid cells in medial entorhinal cortex are believed to play a key role in\npath integration. However, the relation between path integration and the\ngrid-like arrangement of their firing field remains unclear. We provide\ntheoretical evidence that grid-like structure and path integration are closely\nrelated. In one dimension, the grid-like structure provides the optimal\nsolution for path integration assuming that the noise correlation structure is\nGaussian. In two dimensions, assuming that the noise is Gaussian, rectangular\ngrid-like structure is the optimal solution provided that 1- both noise\ncorrelation and receptive field structures of the neurons can be\nmultiplicatively decomposed into orthogonal components and 2- the eigenvalues\nof the decomposed correlation matrices decrease faster than the square of the\nfrequency of the corresponding eigenvectors. We will also address the decoding\nmechanism and show that the problem of decoding reduces to the problem of\nextracting task relevant information in the presence of task irrelevant\ninformation. Change-based Population Coding provides the optimal solution for\nthis problem.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 19:55:11 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Moazzezi", "Reza", ""]]}, {"id": "1606.01305", "submitter": "David Krueger", "authors": "David Krueger, Tegan Maharaj, J\\'anos Kram\\'ar, Mohammad Pezeshki,\n  Nicolas Ballas, Nan Rosemary Ke, Anirudh Goyal, Yoshua Bengio, Aaron\n  Courville, Chris Pal", "title": "Zoneout: Regularizing RNNs by Randomly Preserving Hidden Activations", "comments": "David Krueger and Tegan Maharaj contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose zoneout, a novel method for regularizing RNNs. At each timestep,\nzoneout stochastically forces some hidden units to maintain their previous\nvalues. Like dropout, zoneout uses random noise to train a pseudo-ensemble,\nimproving generalization. But by preserving instead of dropping hidden units,\ngradient information and state information are more readily propagated through\ntime, as in feedforward stochastic depth networks. We perform an empirical\ninvestigation of various RNN regularizers, and find that zoneout gives\nsignificant performance improvements across tasks. We achieve competitive\nresults with relatively simple models in character- and word-level language\nmodelling on the Penn Treebank and Text8 datasets, and combining with recurrent\nbatch normalization yields state-of-the-art results on permuted sequential\nMNIST.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 23:31:47 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2016 18:59:48 GMT"}, {"version": "v3", "created": "Wed, 18 Jan 2017 03:12:03 GMT"}, {"version": "v4", "created": "Fri, 22 Sep 2017 20:43:09 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Krueger", "David", ""], ["Maharaj", "Tegan", ""], ["Kram\u00e1r", "J\u00e1nos", ""], ["Pezeshki", "Mohammad", ""], ["Ballas", "Nicolas", ""], ["Ke", "Nan Rosemary", ""], ["Goyal", "Anirudh", ""], ["Bengio", "Yoshua", ""], ["Courville", "Aaron", ""], ["Pal", "Chris", ""]]}, {"id": "1606.01404", "submitter": "Tim Rockt\\\"aschel", "authors": "Vladyslav Kolesnyk, Tim Rockt\\\"aschel, Sebastian Riedel", "title": "Generating Natural Language Inference Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to reason with natural language is a fundamental prerequisite for\nmany NLP tasks such as information extraction, machine translation and question\nanswering. To quantify this ability, systems are commonly tested whether they\ncan recognize textual entailment, i.e., whether one sentence can be inferred\nfrom another one. However, in most NLP applications only single source\nsentences instead of sentence pairs are available. Hence, we propose a new task\nthat measures how well a model can generate an entailed sentence from a source\nsentence. We take entailment-pairs of the Stanford Natural Language Inference\ncorpus and train an LSTM with attention. On a manually annotated test set we\nfound that 82% of generated sentences are correct, an improvement of 10.3% over\nan LSTM baseline. A qualitative analysis shows that this model is not only\ncapable of shortening input sentences, but also inferring new statements via\nparaphrasing and phrase entailment. We then apply this model recursively to\ninput-output pairs, thereby generating natural language inference chains that\ncan be used to automatically construct an entailment graph from source\nsentences. Finally, by swapping source and target sentences we can also train a\nmodel that given an input sentence invents additional information to generate a\nnew sentence.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2016 18:34:51 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Kolesnyk", "Vladyslav", ""], ["Rockt\u00e4schel", "Tim", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1606.01467", "submitter": "Jie Fu", "authors": "Jie Fu", "title": "Deep Q-Networks for Accelerating the Training of Deep Neural Networks", "comments": "We choose to withdraw this paper. The DQN itself has too many\n  hyperparameters, which makes it almost impossible to be applied to reasonably\n  large datasets. In the later versions (from v4) with SGDR experiments, it\n  seems that the agent only performs random actions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a principled deep reinforcement learning (RL)\napproach that is able to accelerate the convergence rate of general deep neural\nnetworks (DNNs). With our approach, a deep RL agent (synonym for optimizer in\nthis work) is used to automatically learn policies about how to schedule\nlearning rates during the optimization of a DNN. The state features of the\nagent are learned from the weight statistics of the optimizee during training.\nThe reward function of this agent is designed to learn policies that minimize\nthe optimizee's training time given a certain performance goal. The actions of\nthe agent correspond to changing the learning rate for the optimizee during\ntraining. As far as we know, this is the first attempt to use deep RL to learn\nhow to optimize a large-sized DNN. We perform extensive experiments on a\nstandard benchmark dataset and demonstrate the effectiveness of the policies\nlearned by our approach.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jun 2016 06:42:56 GMT"}, {"version": "v10", "created": "Thu, 13 Jul 2017 08:49:36 GMT"}, {"version": "v2", "created": "Wed, 8 Jun 2016 17:02:49 GMT"}, {"version": "v3", "created": "Mon, 1 Aug 2016 14:17:18 GMT"}, {"version": "v4", "created": "Sun, 16 Oct 2016 04:20:25 GMT"}, {"version": "v5", "created": "Mon, 7 Nov 2016 05:27:02 GMT"}, {"version": "v6", "created": "Fri, 11 Nov 2016 06:22:25 GMT"}, {"version": "v7", "created": "Thu, 17 Nov 2016 06:16:24 GMT"}, {"version": "v8", "created": "Tue, 20 Jun 2017 10:28:34 GMT"}, {"version": "v9", "created": "Wed, 12 Jul 2017 12:29:29 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Fu", "Jie", ""]]}, {"id": "1606.01552", "submitter": "Qianli Liao", "authors": "Joel Z. Leibo, Qianli Liao, Winrich Freiwald, Fabio Anselmi, Tomaso\n  Poggio", "title": "View-tolerant face recognition and Hebbian learning imply\n  mirror-symmetric neural tuning to head orientation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primate brain contains a hierarchy of visual areas, dubbed the ventral\nstream, which rapidly computes object representations that are both specific\nfor object identity and relatively robust against identity-preserving\ntransformations like depth-rotations. Current computational models of object\nrecognition, including recent deep learning networks, generate these properties\nthrough a hierarchy of alternating selectivity-increasing filtering and\ntolerance-increasing pooling operations, similar to simple-complex cells\noperations. While simulations of these models recapitulate the ventral stream's\nprogression from early view-specific to late view-tolerant representations,\nthey fail to generate the most salient property of the intermediate\nrepresentation for faces found in the brain: mirror-symmetric tuning of the\nneural population to head orientation. Here we prove that a class of\nhierarchical architectures and a broad set of biologically plausible learning\nrules can provide approximate invariance at the top level of the network. While\nmost of the learning rules do not yield mirror-symmetry in the mid-level\nrepresentations, we characterize a specific biologically-plausible Hebb-type\nlearning rule that is guaranteed to generate mirror-symmetric tuning to faces\ntuning at intermediate levels of the architecture.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jun 2016 20:10:43 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Leibo", "Joel Z.", ""], ["Liao", "Qianli", ""], ["Freiwald", "Winrich", ""], ["Anselmi", "Fabio", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1606.01651", "submitter": "Yoshua Bengio", "authors": "Yoshua Bengio, Benjamin Scellier, Olexa Bilaniuk, Joao Sacramento and\n  Walter Senn", "title": "Feedforward Initialization for Fast Inference of Deep Generative\n  Networks is biologically plausible", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider deep multi-layered generative models such as Boltzmann machines\nor Hopfield nets in which computation (which implements inference) is both\nrecurrent and stochastic, but where the recurrence is not to model sequential\nstructure, only to perform computation. We find conditions under which a simple\nfeedforward computation is a very good initialization for inference, after the\ninput units are clamped to observed values. It means that after the feedforward\ninitialization, the recurrent network is very close to a fixed point of the\nnetwork dynamics, where the energy gradient is 0. The main condition is that\nconsecutive layers form a good auto-encoder, or more generally that different\ngroups of inputs into the unit (in particular, bottom-up inputs on one hand,\ntop-down inputs on the other hand) are consistent with each other, producing\nthe same contribution into the total weighted sum of inputs. In biological\nterms, this would correspond to having each dendritic branch correctly\npredicting the aggregate input from all the dendritic branches, i.e., the soma\npotential. This is consistent with the prediction that the synaptic weights\ninto dendritic branches such as those of the apical and basal dendrites of\npyramidal cells are trained to minimize the prediction error made by the\ndendritic branch when the target is the somatic activity. Whereas previous work\nhas shown how to achieve fast negative phase inference (when the model is\nunclamped) in a predictive recurrent model, this contribution helps to achieve\nfast positive phase inference (when the target output is clamped) in such\nrecurrent neural models.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 08:09:19 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2016 00:10:22 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Bengio", "Yoshua", ""], ["Scellier", "Benjamin", ""], ["Bilaniuk", "Olexa", ""], ["Sacramento", "Joao", ""], ["Senn", "Walter", ""]]}, {"id": "1606.01781", "submitter": "Alexis Conneau", "authors": "Alexis Conneau, Holger Schwenk, Lo\\\"ic Barrault, Yann Lecun", "title": "Very Deep Convolutional Networks for Text Classification", "comments": "10 pages, EACL 2017, camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant approach for many NLP tasks are recurrent neural networks, in\nparticular LSTMs, and convolutional neural networks. However, these\narchitectures are rather shallow in comparison to the deep convolutional\nnetworks which have pushed the state-of-the-art in computer vision. We present\na new architecture (VDCNN) for text processing which operates directly at the\ncharacter level and uses only small convolutions and pooling operations. We are\nable to show that the performance of this model increases with depth: using up\nto 29 convolutional layers, we report improvements over the state-of-the-art on\nseveral public text classification tasks. To the best of our knowledge, this is\nthe first time that very deep convolutional nets have been applied to text\nprocessing.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 15:14:50 GMT"}, {"version": "v2", "created": "Fri, 27 Jan 2017 12:49:11 GMT"}], "update_date": "2017-01-30", "authors_parsed": [["Conneau", "Alexis", ""], ["Schwenk", "Holger", ""], ["Barrault", "Lo\u00efc", ""], ["Lecun", "Yann", ""]]}, {"id": "1606.01865", "submitter": "Zhengping Che", "authors": "Zhengping Che, Sanjay Purushotham, Kyunghyun Cho, David Sontag, Yan\n  Liu", "title": "Recurrent Neural Networks for Multivariate Time Series with Missing\n  Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series data in practical applications, such as health care,\ngeoscience, and biology, are characterized by a variety of missing values. In\ntime series prediction and other related tasks, it has been noted that missing\nvalues and their missing patterns are often correlated with the target labels,\na.k.a., informative missingness. There is very limited work on exploiting the\nmissing patterns for effective imputation and improving prediction performance.\nIn this paper, we develop novel deep learning models, namely GRU-D, as one of\nthe early attempts. GRU-D is based on Gated Recurrent Unit (GRU), a\nstate-of-the-art recurrent neural network. It takes two representations of\nmissing patterns, i.e., masking and time interval, and effectively incorporates\nthem into a deep model architecture so that it not only captures the long-term\ntemporal dependencies in time series, but also utilizes the missing patterns to\nachieve better prediction results. Experiments of time series classification\ntasks on real-world clinical datasets (MIMIC-III, PhysioNet) and synthetic\ndatasets demonstrate that our models achieve state-of-the-art performance and\nprovides useful insights for better understanding and utilization of missing\nvalues in time series analysis.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 19:08:41 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 20:51:29 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Che", "Zhengping", ""], ["Purushotham", "Sanjay", ""], ["Cho", "Kyunghyun", ""], ["Sontag", "David", ""], ["Liu", "Yan", ""]]}, {"id": "1606.01981", "submitter": "Paul Merolla", "authors": "Paul Merolla, Rathinakumar Appuswamy, John Arthur, Steve K. Esser,\n  Dharmendra Modha", "title": "Deep neural networks are robust to weight binarization and other\n  non-linear distortions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results show that deep neural networks achieve excellent performance\neven when, during training, weights are quantized and projected to a binary\nrepresentation. Here, we show that this is just the tip of the iceberg: these\nsame networks, during testing, also exhibit a remarkable robustness to\ndistortions beyond quantization, including additive and multiplicative noise,\nand a class of non-linear projections where binarization is just a special\ncase. To quantify this robustness, we show that one such network achieves 11%\ntest error on CIFAR-10 even with 0.68 effective bits per weight. Furthermore,\nwe find that a common training heuristic--namely, projecting quantized weights\nduring backpropagation--can be altered (or even removed) and networks still\nachieve a base level of robustness during testing. Specifically, training with\nweight projections other than quantization also works, as does simply clipping\nthe weights, both of which have never been reported before. We confirm our\nresults for CIFAR-10 and ImageNet datasets. Finally, drawing from these ideas,\nwe propose a stochastic projection rule that leads to a new state of the art\nnetwork with 7.64% test error on CIFAR-10 using no data augmentation.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 00:28:42 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Merolla", "Paul", ""], ["Appuswamy", "Rathinakumar", ""], ["Arthur", "John", ""], ["Esser", "Steve K.", ""], ["Modha", "Dharmendra", ""]]}, {"id": "1606.02228", "submitter": "Dmytro Mishkin", "authors": "Dmytro Mishkin and Nikolay Sergievskiy and Jiri Matas", "title": "Systematic evaluation of CNN advances on the ImageNet", "comments": "Submitted to CVIU Special Issue on Deep Learning. Updated dataset\n  quality experiment", "journal-ref": null, "doi": "10.1016/j.cviu.2017.05.007", "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper systematically studies the impact of a range of recent advances in\nCNN architectures and learning methods on the object categorization (ILSVRC)\nproblem. The evalution tests the influence of the following choices of the\narchitecture: non-linearity (ReLU, ELU, maxout, compatibility with batch\nnormalization), pooling variants (stochastic, max, average, mixed), network\nwidth, classifier design (convolutional, fully-connected, SPP), image\npre-processing, and of learning parameters: learning rate, batch size,\ncleanliness of the data, etc.\n  The performance gains of the proposed modifications are first tested\nindividually and then in combination. The sum of individual gains is bigger\nthan the observed improvement when all modifications are introduced, but the\n\"deficit\" is small suggesting independence of their benefits. We show that the\nuse of 128x128 pixel images is sufficient to make qualitative conclusions about\noptimal network structure that hold for the full size Caffe and VGG nets. The\nresults are obtained an order of magnitude faster than with the standard 224\npixel images.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 17:38:06 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2016 13:48:39 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Mishkin", "Dmytro", ""], ["Sergievskiy", "Nikolay", ""], ["Matas", "Jiri", ""]]}, {"id": "1606.02245", "submitter": "Alessandro Sordoni", "authors": "Alessandro Sordoni and Philip Bachman and Adam Trischler and Yoshua\n  Bengio", "title": "Iterative Alternating Neural Attention for Machine Reading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel neural attention architecture to tackle machine\ncomprehension tasks, such as answering Cloze-style queries with respect to a\ndocument. Unlike previous models, we do not collapse the query into a single\nvector, instead we deploy an iterative alternating attention mechanism that\nallows a fine-grained exploration of both the query and the document. Our model\noutperforms state-of-the-art baselines in standard machine comprehension\nbenchmarks such as CNN news articles and the Children's Book Test (CBT)\ndataset.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 18:25:48 GMT"}, {"version": "v2", "created": "Wed, 8 Jun 2016 18:17:03 GMT"}, {"version": "v3", "created": "Fri, 10 Jun 2016 21:16:56 GMT"}, {"version": "v4", "created": "Wed, 9 Nov 2016 18:11:09 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Sordoni", "Alessandro", ""], ["Bachman", "Philip", ""], ["Trischler", "Adam", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1606.02396", "submitter": "Ardavan Saeedi", "authors": "Tejas D. Kulkarni, Ardavan Saeedi, Simanta Gautam, Samuel J. Gershman", "title": "Deep Successor Reinforcement Learning", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robust value functions given raw observations and rewards is now\npossible with model-free and model-based deep reinforcement learning\nalgorithms. There is a third alternative, called Successor Representations\n(SR), which decomposes the value function into two components -- a reward\npredictor and a successor map. The successor map represents the expected future\nstate occupancy from any given state and the reward predictor maps states to\nscalar rewards. The value function of a state can be computed as the inner\nproduct between the successor map and the reward weights. In this paper, we\npresent DSR, which generalizes SR within an end-to-end deep reinforcement\nlearning framework. DSR has several appealing properties including: increased\nsensitivity to distal reward changes due to factorization of reward and world\ndynamics, and the ability to extract bottleneck states (subgoals) given\nsuccessor maps trained under a random policy. We show the efficacy of our\napproach on two diverse environments given raw pixel observations -- simple\ngrid-world domains (MazeBase) and the Doom game engine.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 04:48:49 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Kulkarni", "Tejas D.", ""], ["Saeedi", "Ardavan", ""], ["Gautam", "Simanta", ""], ["Gershman", "Samuel J.", ""]]}, {"id": "1606.02407", "submitter": "Rathinakumar Appuswamy", "authors": "Rathinakumar Appuswamy, Tapan Nayak, John Arthur, Steven Esser, Paul\n  Merolla, Jeffrey Mckinstry, Timothy Melano, Myron Flickner, Dharmendra Modha", "title": "Structured Convolution Matrices for Energy-efficient Deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a relationship between network representation in energy-efficient\nneuromorphic architectures and block Toplitz convolutional matrices. Inspired\nby this connection, we develop deep convolutional networks using a family of\nstructured convolutional matrices and achieve state-of-the-art trade-off\nbetween energy efficiency and classification accuracy for well-known image\nrecognition tasks. We also put forward a novel method to train binary\nconvolutional networks by utilising an existing connection between\nnoisy-rectified linear units and binary activations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 05:31:43 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Appuswamy", "Rathinakumar", ""], ["Nayak", "Tapan", ""], ["Arthur", "John", ""], ["Esser", "Steven", ""], ["Merolla", "Paul", ""], ["Mckinstry", "Jeffrey", ""], ["Melano", "Timothy", ""], ["Flickner", "Myron", ""], ["Modha", "Dharmendra", ""]]}, {"id": "1606.02492", "submitter": "Shreyas Saxena", "authors": "Shreyas Saxena and Jakob Verbeek", "title": "Convolutional Neural Fabrics", "comments": "Corrected typos (In proceedings of NIPS16 )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of CNNs, selecting the optimal architecture for a given\ntask remains an open problem. Instead of aiming to select a single optimal\narchitecture, we propose a \"fabric\" that embeds an exponentially large number\nof architectures. The fabric consists of a 3D trellis that connects response\nmaps at different layers, scales, and channels with a sparse homogeneous local\nconnectivity pattern. The only hyper-parameters of a fabric are the number of\nchannels and layers. While individual architectures can be recovered as paths,\nthe fabric can in addition ensemble all embedded architectures together,\nsharing their weights where their paths overlap. Parameters can be learned\nusing standard methods based on back-propagation, at a cost that scales\nlinearly in the fabric size. We present benchmark results competitive with the\nstate of the art for image classification on MNIST and CIFAR10, and for\nsemantic segmentation on the Part Labels dataset.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 10:17:51 GMT"}, {"version": "v2", "created": "Thu, 9 Jun 2016 16:21:57 GMT"}, {"version": "v3", "created": "Fri, 28 Oct 2016 13:10:05 GMT"}, {"version": "v4", "created": "Mon, 30 Jan 2017 12:28:29 GMT"}], "update_date": "2017-01-31", "authors_parsed": [["Saxena", "Shreyas", ""], ["Verbeek", "Jakob", ""]]}, {"id": "1606.02555", "submitter": "Marco Dinarelli", "authors": "Marco Dinarelli and Isabelle Tellier", "title": "Improving Recurrent Neural Networks For Sequence Labelling", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study different types of Recurrent Neural Networks (RNN) for\nsequence labeling tasks. We propose two new variants of RNNs integrating\nimprovements for sequence labeling, and we compare them to the more traditional\nElman and Jordan RNNs. We compare all models, either traditional or new, on\nfour distinct tasks of sequence labeling: two on Spoken Language Understanding\n(ATIS and MEDIA); and two of POS tagging for the French Treebank (FTB) and the\nPenn Treebank (PTB) corpora. The results show that our new variants of RNNs are\nalways more effective than the others.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 13:47:18 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Dinarelli", "Marco", ""], ["Tellier", "Isabelle", ""]]}, {"id": "1606.02580", "submitter": "Chrisantha Fernando Dr", "authors": "Chrisantha Fernando, Dylan Banarse, Malcolm Reynolds, Frederic Besse,\n  David Pfau, Max Jaderberg, Marc Lanctot, Daan Wierstra", "title": "Convolution by Evolution: Differentiable Pattern Producing Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce a differentiable version of the Compositional\nPattern Producing Network, called the DPPN. Unlike a standard CPPN, the\ntopology of a DPPN is evolved but the weights are learned. A Lamarckian\nalgorithm, that combines evolution and learning, produces DPPNs to reconstruct\nan image. Our main result is that DPPNs can be evolved/trained to compress the\nweights of a denoising autoencoder from 157684 to roughly 200 parameters, while\nachieving a reconstruction accuracy comparable to a fully connected network\nwith more than two orders of magnitude more parameters. The regularization\nability of the DPPN allows it to rediscover (approximate) convolutional network\narchitectures embedded within a fully connected architecture. Such\nconvolutional architectures are the current state of the art for many computer\nvision applications, so it is satisfying that DPPNs are capable of discovering\nthis structure rather than having to build it in by design. DPPNs exhibit\nbetter generalization when tested on the Omniglot dataset after being trained\non MNIST, than directly encoded fully connected autoencoders. DPPNs are\ntherefore a new framework for integrating learning and evolution.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 14:37:39 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Fernando", "Chrisantha", ""], ["Banarse", "Dylan", ""], ["Reynolds", "Malcolm", ""], ["Besse", "Frederic", ""], ["Pfau", "David", ""], ["Jaderberg", "Max", ""], ["Lanctot", "Marc", ""], ["Wierstra", "Daan", ""]]}, {"id": "1606.02960", "submitter": "Sam Wiseman", "authors": "Sam Wiseman and Alexander M. Rush", "title": "Sequence-to-Sequence Learning as Beam-Search Optimization", "comments": "EMNLP 2016 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-Sequence (seq2seq) modeling has rapidly become an important\ngeneral-purpose NLP tool that has proven effective for many text-generation and\nsequence-labeling tasks. Seq2seq builds on deep neural language modeling and\ninherits its remarkable accuracy in estimating local, next-word distributions.\nIn this work, we introduce a model and beam-search training scheme, based on\nthe work of Daume III and Marcu (2005), that extends seq2seq to learn global\nsequence scores. This structured approach avoids classical biases associated\nwith local training and unifies the training loss with the test-time usage,\nwhile preserving the proven model architecture of seq2seq and its efficient\ntraining approach. We show that our system outperforms a highly-optimized\nattention-based seq2seq system and other baselines on three different sequence\nto sequence tasks: word ordering, parsing, and machine translation.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 13:29:34 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 03:45:30 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Wiseman", "Sam", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1606.03002", "submitter": "Dirk Weissenborn", "authors": "Dirk Weissenborn and Tim Rockt\\\"aschel", "title": "MuFuRU: The Multi-Function Recurrent Unit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks such as the GRU and LSTM found wide adoption in\nnatural language processing and achieve state-of-the-art results for many\ntasks. These models are characterized by a memory state that can be written to\nand read from by applying gated composition operations to the current input and\nthe previous state. However, they only cover a small subset of potentially\nuseful compositions. We propose Multi-Function Recurrent Units (MuFuRUs) that\nallow for arbitrary differentiable functions as composition operations.\nFurthermore, MuFuRUs allow for an input- and state-dependent choice of these\ncomposition operations that is learned. Our experiments demonstrate that the\nadditional functionality helps in different sequence modeling tasks, including\nthe evaluation of propositional logic formulae, language modeling and sentiment\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 15:41:17 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Weissenborn", "Dirk", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "1606.03144", "submitter": "Marek Rei", "authors": "Marek Rei and Ronan Cummins", "title": "Sentence Similarity Measures for Fine-Grained Estimation of Topical\n  Relevance in Learner Essays", "comments": "Accepted for publication at BEA-2016", "journal-ref": null, "doi": "10.18653/v1/W16-0533", "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the task of assessing sentence-level prompt relevance in\nlearner essays. Various systems using word overlap, neural embeddings and\nneural compositional models are evaluated on two datasets of learner writing.\nWe propose a new method for sentence-level similarity calculation, which learns\nto adjust the weights of pre-trained word embeddings for a specific task,\nachieving substantially higher accuracy compared to other relevant baselines.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 23:42:45 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Rei", "Marek", ""], ["Cummins", "Ronan", ""]]}, {"id": "1606.03207", "submitter": "Hwaran Lee", "authors": "Hwaran Lee, Geonmin Kim, Ho-Gyeong Kim, Sang-Hoon Oh, and Soo-Young\n  Lee", "title": "Deep CNNs along the Time Axis with Intermap Pooling for Robustness to\n  Spectral Variations", "comments": "Submitted to IEEE Signal Processing Letters", "journal-ref": null, "doi": "10.1109/LSP.2016.2589962", "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) with convolutional and pooling\noperations along the frequency axis have been proposed to attain invariance to\nfrequency shifts of features. However, this is inappropriate with regard to the\nfact that acoustic features vary in frequency. In this paper, we contend that\nconvolution along the time axis is more effective. We also propose the addition\nof an intermap pooling (IMP) layer to deep CNNs. In this layer, filters in each\ngroup extract common but spectrally variant features, then the layer pools the\nfeature maps of each group. As a result, the proposed IMP CNN can achieve\ninsensitivity to spectral variations characteristic of different speakers and\nutterances. The effectiveness of the IMP CNN architecture is demonstrated on\nseveral LVCSR tasks. Even without speaker adaptation techniques, the\narchitecture achieved a WER of 12.7% on the SWB part of the Hub5'2000\nevaluation test set, which is competitive with other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 06:44:21 GMT"}, {"version": "v2", "created": "Tue, 12 Jul 2016 07:23:53 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Lee", "Hwaran", ""], ["Kim", "Geonmin", ""], ["Kim", "Ho-Gyeong", ""], ["Oh", "Sang-Hoon", ""], ["Lee", "Soo-Young", ""]]}, {"id": "1606.03326", "submitter": "Zhi-Hua Zhou", "authors": "Chao Qian, Yang Yu, Zhi-Hua Zhou", "title": "A Lower Bound Analysis of Population-based Evolutionary Algorithms for\n  Pseudo-Boolean Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms (EAs) are population-based general-purpose\noptimization algorithms, and have been successfully applied in various\nreal-world optimization tasks. However, previous theoretical studies often\nemploy EAs with only a parent or offspring population and focus on specific\nproblems. Furthermore, they often only show upper bounds on the running time,\nwhile lower bounds are also necessary to get a complete understanding of an\nalgorithm. In this paper, we analyze the running time of the\n($\\mu$+$\\lambda$)-EA (a general population-based EA with mutation only) on the\nclass of pseudo-Boolean functions with a unique global optimum. By applying the\nrecently proposed switch analysis approach, we prove the lower bound $\\Omega(n\n\\ln n+ \\mu + \\lambda n\\ln\\ln n/ \\ln n)$ for the first time. Particularly on the\ntwo widely-studied problems, OneMax and LeadingOnes, the derived lower bound\ndiscloses that the ($\\mu$+$\\lambda$)-EA will be strictly slower than the\n(1+1)-EA when the population size $\\mu$ or $\\lambda$ is above a moderate order.\nOur results imply that the increase of population size, while usually desired\nin practice, bears the risk of increasing the lower bound of the running time\nand thus should be carefully considered.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 13:59:16 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Qian", "Chao", ""], ["Yu", "Yang", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1606.03352", "submitter": "Tsung-Hsien Wen", "authors": "Tsung-Hsien Wen, Milica Gasic, Nikola Mrksic, Lina M. Rojas-Barahona,\n  Pei-Hao Su, Stefan Ultes, David Vandyke, Steve Young", "title": "Conditional Generation and Snapshot Learning in Neural Dialogue Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently a variety of LSTM-based conditional language models (LM) have been\napplied across a range of language generation tasks. In this work we study\nvarious model architectures and different ways to represent and aggregate the\nsource information in an end-to-end neural dialogue system framework. A method\ncalled snapshot learning is also proposed to facilitate learning from\nsupervised sequential signals by applying a companion cross-entropy objective\nfunction to the conditioning vector. The experimental and analytical results\ndemonstrate firstly that competition occurs between the conditioning vector and\nthe LM, and the differing architectures provide different trade-offs between\nthe two. Secondly, the discriminative power and transparency of the\nconditioning vector is key to providing both model interpretability and better\nperformance. Thirdly, snapshot learning leads to consistent performance\nimprovements independent of which architecture is used.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 14:56:19 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Wen", "Tsung-Hsien", ""], ["Gasic", "Milica", ""], ["Mrksic", "Nikola", ""], ["Rojas-Barahona", "Lina M.", ""], ["Su", "Pei-Hao", ""], ["Ultes", "Stefan", ""], ["Vandyke", "David", ""], ["Young", "Steve", ""]]}, {"id": "1606.03401", "submitter": "Audrunas Gruslys", "authors": "Audr\\=unas Gruslys, Remi Munos, Ivo Danihelka, Marc Lanctot, Alex\n  Graves", "title": "Memory-Efficient Backpropagation Through Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to reduce memory consumption of the\nbackpropagation through time (BPTT) algorithm when training recurrent neural\nnetworks (RNNs). Our approach uses dynamic programming to balance a trade-off\nbetween caching of intermediate results and recomputation. The algorithm is\ncapable of tightly fitting within almost any user-set memory budget while\nfinding an optimal execution policy minimizing the computational cost.\nComputational devices have limited memory capacity and maximizing a\ncomputational performance given a fixed memory budget is a practical use-case.\nWe provide asymptotic computational upper bounds for various regimes. The\nalgorithm is particularly effective for long sequences. For sequences of length\n1000, our algorithm saves 95\\% of memory usage while using only one third more\ntime per iteration than the standard BPTT.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 17:20:39 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Gruslys", "Audr\u016bnas", ""], ["Munos", "Remi", ""], ["Danihelka", "Ivo", ""], ["Lanctot", "Marc", ""], ["Graves", "Alex", ""]]}, {"id": "1606.03475", "submitter": "Franck Dernoncourt", "authors": "Franck Dernoncourt, Ji Young Lee, Ozlem Uzuner, Peter Szolovits", "title": "De-identification of Patient Notes with Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Patient notes in electronic health records (EHRs) may contain\ncritical information for medical investigations. However, the vast majority of\nmedical investigators can only access de-identified notes, in order to protect\nthe confidentiality of patients. In the United States, the Health Insurance\nPortability and Accountability Act (HIPAA) defines 18 types of protected health\ninformation (PHI) that needs to be removed to de-identify patient notes. Manual\nde-identification is impractical given the size of EHR databases, the limited\nnumber of researchers with access to the non-de-identified notes, and the\nfrequent mistakes of human annotators. A reliable automated de-identification\nsystem would consequently be of high value.\n  Materials and Methods: We introduce the first de-identification system based\non artificial neural networks (ANNs), which requires no handcrafted features or\nrules, unlike existing systems. We compare the performance of the system with\nstate-of-the-art systems on two datasets: the i2b2 2014 de-identification\nchallenge dataset, which is the largest publicly available de-identification\ndataset, and the MIMIC de-identification dataset, which we assembled and is\ntwice as large as the i2b2 2014 dataset.\n  Results: Our ANN model outperforms the state-of-the-art systems. It yields an\nF1-score of 97.85 on the i2b2 2014 dataset, with a recall 97.38 and a precision\nof 97.32, and an F1-score of 99.23 on the MIMIC de-identification dataset, with\na recall 99.25 and a precision of 99.06.\n  Conclusion: Our findings support the use of ANNs for de-identification of\npatient notes, as they show better performance than previously published\nsystems while requiring no feature engineering.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 20:45:30 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Dernoncourt", "Franck", ""], ["Lee", "Ji Young", ""], ["Uzuner", "Ozlem", ""], ["Szolovits", "Peter", ""]]}, {"id": "1606.03490", "submitter": "Zachary Lipton", "authors": "Zachary C. Lipton", "title": "The Mythos of Model Interpretability", "comments": "presented at 2016 ICML Workshop on Human Interpretability in Machine\n  Learning (WHI 2016), New York, NY", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised machine learning models boast remarkable predictive capabilities.\nBut can you trust your model? Will it work in deployment? What else can it tell\nyou about the world? We want models to be not only good, but interpretable. And\nyet the task of interpretation appears underspecified. Papers provide diverse\nand sometimes non-overlapping motivations for interpretability, and offer\nmyriad notions of what attributes render models interpretable. Despite this\nambiguity, many papers proclaim interpretability axiomatically, absent further\nexplanation. In this paper, we seek to refine the discourse on\ninterpretability. First, we examine the motivations underlying interest in\ninterpretability, finding them to be diverse and occasionally discordant. Then,\nwe address model properties and techniques thought to confer interpretability,\nidentifying transparency to humans and post-hoc explanations as competing\nnotions. Throughout, we discuss the feasibility and desirability of different\nnotions, and question the oft-made assertions that linear models are\ninterpretable and that deep neural networks are not.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 21:28:47 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2016 21:21:04 GMT"}, {"version": "v3", "created": "Mon, 6 Mar 2017 08:51:10 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Lipton", "Zachary C.", ""]]}, {"id": "1606.03498", "submitter": "Ian Goodfellow", "authors": "Tim Salimans and Ian Goodfellow and Wojciech Zaremba and Vicki Cheung\n  and Alec Radford and Xi Chen", "title": "Improved Techniques for Training GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a variety of new architectural features and training procedures\nthat we apply to the generative adversarial networks (GANs) framework. We focus\non two applications of GANs: semi-supervised learning, and the generation of\nimages that humans find visually realistic. Unlike most work on generative\nmodels, our primary goal is not to train a model that assigns high likelihood\nto test data, nor do we require the model to be able to learn well without\nusing any labels. Using our new techniques, we achieve state-of-the-art results\nin semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated\nimages are of high quality as confirmed by a visual Turing test: our model\ngenerates MNIST samples that humans cannot distinguish from real data, and\nCIFAR-10 samples that yield a human error rate of 21.3%. We also present\nImageNet samples with unprecedented resolution and show that our methods enable\nthe model to learn recognizable features of ImageNet classes.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 22:53:35 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Salimans", "Tim", ""], ["Goodfellow", "Ian", ""], ["Zaremba", "Wojciech", ""], ["Cheung", "Vicki", ""], ["Radford", "Alec", ""], ["Chen", "Xi", ""]]}, {"id": "1606.03674", "submitter": "N. Michael Mayer", "authors": "Norbert Michael Mayer", "title": "Critical Echo State Networks that Anticipate Input using Morphable\n  Transfer Functions", "comments": "14th International Symposium on Neural Networks (ISNN), Sapporo,\n  Hakodate, Japan, June 21st - 26th 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper investigates a new type of truly critical echo state networks where\nindividual transfer functions for every neuron can be modified to anticipate\nthe expected next input. Deviations from expected input are only forgotten\nslowly in power law fashion. The paper outlines the theory, numerically\nanalyzes a one neuron model network and finally discusses technical and also\nbiological implications of this type of approach.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jun 2016 07:22:58 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 13:34:29 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Mayer", "Norbert Michael", ""]]}, {"id": "1606.03864", "submitter": "Dirk Weissenborn", "authors": "Dirk Weissenborn", "title": "Neural Associative Memory for Dual-Sequence Modeling", "comments": "To appear in RepL4NLP at ACL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many important NLP problems can be posed as dual-sequence or\nsequence-to-sequence modeling tasks. Recent advances in building end-to-end\nneural architectures have been highly successful in solving such tasks. In this\nwork we propose a new architecture for dual-sequence modeling that is based on\nassociative memory. We derive AM-RNNs, a recurrent associative memory (AM)\nwhich augments generic recurrent neural networks (RNN). This architecture is\nextended to the Dual AM-RNN which operates on two AMs at once. Our models\nachieve very competitive results on textual entailment. A qualitative analysis\ndemonstrates that long range dependencies between source and target-sequence\ncan be bridged effectively using Dual AM-RNNs. However, an initial experiment\non auto-encoding reveals that these benefits are not exploited by the system\nwhen learning to solve sequence-to-sequence tasks which indicates that\nadditional supervision or regularization is needed.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 09:08:04 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2016 07:59:18 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Weissenborn", "Dirk", ""]]}, {"id": "1606.04052", "submitter": "Julien Perez", "authors": "Julien Perez and Fei Liu", "title": "Dialog state tracking, a machine reading approach using Memory Network", "comments": "10 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an end-to-end dialog system, the aim of dialog state tracking is to\naccurately estimate a compact representation of the current dialog status from\na sequence of noisy observations produced by the speech recognition and the\nnatural language understanding modules. This paper introduces a novel method of\ndialog state tracking based on the general paradigm of machine reading and\nproposes to solve it using an End-to-End Memory Network, MemN2N, a\nmemory-enhanced neural network architecture. We evaluate the proposed approach\non the second Dialog State Tracking Challenge (DSTC-2) dataset. The corpus has\nbeen converted for the occasion in order to frame the hidden state variable\ninference as a question-answering task based on a sequence of utterances\nextracted from a dialog. We show that the proposed tracker gives encouraging\nresults. Then, we propose to extend the DSTC-2 dataset with specific reasoning\ncapabilities requirement like counting, list maintenance, yes-no question\nanswering and indefinite knowledge management. Finally, we present encouraging\nresults using our proposed MemN2N based tracking model.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 18:09:40 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2016 06:42:04 GMT"}, {"version": "v3", "created": "Wed, 29 Jun 2016 00:07:41 GMT"}, {"version": "v4", "created": "Thu, 13 Oct 2016 19:23:00 GMT"}, {"version": "v5", "created": "Thu, 2 Mar 2017 20:17:23 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Perez", "Julien", ""], ["Liu", "Fei", ""]]}, {"id": "1606.04055", "submitter": "Saeid Parvandeh", "authors": "Saeid Parvandeh, Parya Soltani, Mohammadreza Boroumand, Fahimeh\n  Boroumand", "title": "A modified single and multi-objective bacteria foraging optimization for\n  the solution of quadratic assignment problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-polynomial hard (NP-hard) problems are challenging because no\npolynomial-time algorithm has yet been discovered to solve them in polynomial\ntime. The Bacteria Foraging Optimization (BFO) algorithm is one of the\nmetaheuristics algorithms that is mostly used for NP-hard problems. BFO is\ninspired by the behavior of the bacteria foraging such as Escherichia coli\n(E-coli). The aim of BFO is to eliminate those bacteria that have weak foraging\nproperties and maintain those bacteria that have breakthrough foraging\nproperties toward the optimum. Despite the strength of this algorithm, most of\nthe problems reaching optimal solutions are time-demanding or impossible. In\nthis paper, we modified single objective BFO by adding a mutation operator and\nmulti-objective BFO (MOBFO) by adding mutation and crossover from genetic\nalgorithm operators to update the solutions in each generation, and local tabu\nsearch algorithm to reach the local optimum solution. Additionally, we used a\nfast nondominated sort algorithm in MOBFO to find the best-nondominated\nsolutions in each generation. We evaluated the performance of the proposed\nalgorithms through a number of single and multi-objective Quadratic Assignment\nProblem (QAP) instances. The experimental results show that our approaches\noutperform some previous optimization algorithms in both convergent and\ndivergent solutions.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 18:18:07 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 21:08:33 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Parvandeh", "Saeid", ""], ["Soltani", "Parya", ""], ["Boroumand", "Mohammadreza", ""], ["Boroumand", "Fahimeh", ""]]}, {"id": "1606.04130", "submitter": "Zachary Lipton", "authors": "Zachary C. Lipton, David C. Kale, Randall Wetzel", "title": "Modeling Missing Data in Clinical Time Series with RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate a simple strategy to cope with missing data in sequential\ninputs, addressing the task of multilabel classification of diagnoses given\nclinical time series. Collected from the pediatric intensive care unit (PICU)\nat Children's Hospital Los Angeles, our data consists of multivariate time\nseries of observations. The measurements are irregularly spaced, leading to\nmissingness patterns in temporally discretized sequences. While these artifacts\nare typically handled by imputation, we achieve superior predictive performance\nby treating the artifacts as features. Unlike linear models, recurrent neural\nnetworks can realize this improvement using only simple binary indicators of\nmissingness. For linear models, we show an alternative strategy to capture this\nsignal. Training models on missingness patterns only, we show that for some\ndiseases, what tests are run can be as predictive as the results themselves.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 20:34:35 GMT"}, {"version": "v2", "created": "Mon, 8 Aug 2016 09:04:23 GMT"}, {"version": "v3", "created": "Thu, 18 Aug 2016 08:51:35 GMT"}, {"version": "v4", "created": "Tue, 20 Sep 2016 01:10:14 GMT"}, {"version": "v5", "created": "Fri, 11 Nov 2016 12:46:53 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Lipton", "Zachary C.", ""], ["Kale", "David C.", ""], ["Wetzel", "Randall", ""]]}, {"id": "1606.04155", "submitter": "Tao Lei", "authors": "Tao Lei, Regina Barzilay and Tommi Jaakkola", "title": "Rationalizing Neural Predictions", "comments": "EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction without justification has limited applicability. As a remedy, we\nlearn to extract pieces of input text as justifications -- rationales -- that\nare tailored to be short and coherent, yet sufficient for making the same\nprediction. Our approach combines two modular components, generator and\nencoder, which are trained to operate well together. The generator specifies a\ndistribution over text fragments as candidate rationales and these are passed\nthrough the encoder for prediction. Rationales are never given during training.\nInstead, the model is regularized by desiderata for rationales. We evaluate the\napproach on multi-aspect sentiment analysis against manually annotated test\ncases. Our approach outperforms attention-based baseline by a significant\nmargin. We also successfully illustrate the method on the question retrieval\ntask.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 22:10:23 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2016 20:26:20 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Lei", "Tao", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1606.04189", "submitter": "Andrey Zhmoginov", "authors": "Andrey Zhmoginov and Mark Sandler", "title": "Inverting face embeddings with convolutional neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have dramatically advanced the state of the art for many\nareas of machine learning. Recently they have been shown to have a remarkable\nability to generate highly complex visual artifacts such as images and text\nrather than simply recognize them.\n  In this work we use neural networks to effectively invert low-dimensional\nface embeddings while producing realistically looking consistent images. Our\ncontribution is twofold, first we show that a gradient ascent style approaches\ncan be used to reproduce consistent images, with a help of a guiding image.\nSecond, we demonstrate that we can train a separate neural network to\neffectively solve the minimization problem in one pass, and generate images in\nreal-time. We then evaluate the loss imposed by using a neural network instead\nof the gradient descent by comparing the final values of the minimized loss\nfunction.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 01:35:12 GMT"}, {"version": "v2", "created": "Thu, 7 Jul 2016 18:52:57 GMT"}], "update_date": "2016-07-08", "authors_parsed": [["Zhmoginov", "Andrey", ""], ["Sandler", "Mark", ""]]}, {"id": "1606.04209", "submitter": "Xuan Yang", "authors": "Xuan Yang, Jing Pu, Blaine Burton Rister, Nikhil Bhagdikar, Stephen\n  Richardson, Shahar Kvatinsky, Jonathan Ragan-Kelley, Ardavan Pedram and Mark\n  Horowitz", "title": "A Systematic Approach to Blocking Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are the state of the art solution for\nmany computer vision problems, and many researchers have explored optimized\nimplementations. Most implementations heuristically block the computation to\ndeal with the large data sizes and high data reuse of CNNs. This paper explores\nhow to block CNN computations for memory locality by creating an analytical\nmodel for CNN-like loop nests. Using this model we automatically derive\noptimized blockings for common networks that improve the energy efficiency of\ncustom hardware implementations by up to an order of magnitude. Compared to\ntraditional CNN CPU implementations based on highly-tuned, hand-optimized BLAS\nlibraries,our x86 programs implementing the optimal blocking reduce the number\nof memory accesses by up to 90%.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 06:22:30 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Yang", "Xuan", ""], ["Pu", "Jing", ""], ["Rister", "Blaine Burton", ""], ["Bhagdikar", "Nikhil", ""], ["Richardson", "Stephen", ""], ["Kvatinsky", "Shahar", ""], ["Ragan-Kelley", "Jonathan", ""], ["Pedram", "Ardavan", ""], ["Horowitz", "Mark", ""]]}, {"id": "1606.04217", "submitter": "Ekaterina Vylomova", "authors": "Ekaterina Vylomova, Trevor Cohn, Xuanli He and Gholamreza Haffari", "title": "Word Representation Models for Morphologically Rich Languages in Neural\n  Machine Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with the complex word forms in morphologically rich languages is an\nopen problem in language processing, and is particularly important in\ntranslation. In contrast to most modern neural systems of translation, which\ndiscard the identity for rare words, in this paper we propose several\narchitectures for learning word representations from character and morpheme\nlevel word decompositions. We incorporate these representations in a novel\nmachine translation model which jointly learns word alignments and translations\nvia a hard attention mechanism. Evaluating on translating from several\nmorphologically rich languages into English, we show consistent improvements\nover strong baseline methods, of between 1 and 1.5 BLEU points.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 07:04:37 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Vylomova", "Ekaterina", ""], ["Cohn", "Trevor", ""], ["He", "Xuanli", ""], ["Haffari", "Gholamreza", ""]]}, {"id": "1606.04289", "submitter": "Dimitrios Alikaniotis", "authors": "Dimitrios Alikaniotis and Helen Yannakoudakis and Marek Rei", "title": "Automatic Text Scoring Using Neural Networks", "comments": "11 pages, 3 figures, 2 tables, ACL-2016", "journal-ref": null, "doi": "10.18653/v1/P16-1068", "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated Text Scoring (ATS) provides a cost-effective and consistent\nalternative to human marking. However, in order to achieve good performance,\nthe predictive features of the system need to be manually engineered by human\nexperts. We introduce a model that forms word representations by learning the\nextent to which specific words contribute to the text's score. Using Long-Short\nTerm Memory networks to represent the meaning of texts, we demonstrate that a\nfully automated framework is able to achieve excellent results over similar\napproaches. In an attempt to make our results more interpretable, and inspired\nby recent advances in visualizing neural networks, we introduce a novel method\nfor identifying the regions of the text that the model has found more\ndiscriminative.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 10:17:27 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2016 16:30:33 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Alikaniotis", "Dimitrios", ""], ["Yannakoudakis", "Helen", ""], ["Rei", "Marek", ""]]}, {"id": "1606.04306", "submitter": "Matteo Gardini", "authors": "Matteo Gardini", "title": "Viral Search algorithm", "comments": "12 pages, in Italian, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article, after a brief introduction on genetic algorithms and their\nfunctioning, presents a kind of genetic algorithm called Viral Search. We\npresent the key concepts, we formally derive the algorithm and we perform\nnumerical tests designed to illustrate the potential and limits.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 10:55:53 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Gardini", "Matteo", ""]]}, {"id": "1606.04393", "submitter": "Alexander Wong", "authors": "Mohammad Javad Shafiee, Akshaya Mishra, and Alexander Wong", "title": "Deep Learning with Darwin: Evolutionary Synthesis of Deep Neural\n  Networks", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking inspiration from biological evolution, we explore the idea of \"Can\ndeep neural networks evolve naturally over successive generations into highly\nefficient deep neural networks?\" by introducing the notion of synthesizing new\nhighly efficient, yet powerful deep neural networks over successive generations\nvia an evolutionary process from ancestor deep neural networks. The\narchitectural traits of ancestor deep neural networks are encoded using\nsynaptic probability models, which can be viewed as the `DNA' of these\nnetworks. New descendant networks with differing network architectures are\nsynthesized based on these synaptic probability models from the ancestor\nnetworks and computational environmental factor models, in a random manner to\nmimic heredity, natural selection, and random mutation. These offspring\nnetworks are then trained into fully functional networks, like one would train\na newborn, and have more efficient, more diverse network architectures than\ntheir ancestor networks, while achieving powerful modeling capabilities.\nExperimental results for the task of visual saliency demonstrated that the\nsynthesized `evolved' offspring networks can achieve state-of-the-art\nperformance while having network architectures that are significantly more\nefficient (with a staggering $\\sim$48-fold decrease in synapses by the fourth\ngeneration) compared to the original ancestor network.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 14:36:55 GMT"}, {"version": "v2", "created": "Tue, 12 Jul 2016 16:15:40 GMT"}, {"version": "v3", "created": "Mon, 6 Feb 2017 22:51:33 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Shafiee", "Mohammad Javad", ""], ["Mishra", "Akshaya", ""], ["Wong", "Alexander", ""]]}, {"id": "1606.04422", "submitter": "Artur Garcez", "authors": "Luciano Serafini and Artur d'Avila Garcez", "title": "Logic Tensor Networks: Deep Learning and Logical Reasoning from Data and\n  Knowledge", "comments": "12 pages, 2 figs, 1 table, 27 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Logic Tensor Networks: a uniform framework for integrating\nautomatic learning and reasoning. A logic formalism called Real Logic is\ndefined on a first-order language whereby formulas have truth-value in the\ninterval [0,1] and semantics defined concretely on the domain of real numbers.\nLogical constants are interpreted as feature vectors of real numbers. Real\nLogic promotes a well-founded integration of deductive reasoning on a\nknowledge-base and efficient data-driven relational machine learning. We show\nhow Real Logic can be implemented in deep Tensor Neural Networks with the use\nof Google's tensorflow primitives. The paper concludes with experiments\napplying Logic Tensor Networks on a simple but representative example of\nknowledge completion.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 15:25:28 GMT"}, {"version": "v2", "created": "Thu, 7 Jul 2016 12:28:57 GMT"}], "update_date": "2016-07-08", "authors_parsed": [["Serafini", "Luciano", ""], ["Garcez", "Artur d'Avila", ""]]}, {"id": "1606.04435", "submitter": "Kathrin Grosse", "authors": "Kathrin Grosse, Nicolas Papernot, Praveen Manoharan, Michael Backes,\n  Patrick McDaniel", "title": "Adversarial Perturbations Against Deep Neural Networks for Malware\n  Classification", "comments": "version update: correcting typos, incorporating external feedback", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks, like many other machine learning models, have recently\nbeen shown to lack robustness against adversarially crafted inputs. These\ninputs are derived from regular inputs by minor yet carefully selected\nperturbations that deceive machine learning models into desired\nmisclassifications. Existing work in this emerging field was largely specific\nto the domain of image classification, since the high-entropy of images can be\nconveniently manipulated without changing the images' overall visual\nappearance. Yet, it remains unclear how such attacks translate to more\nsecurity-sensitive applications such as malware detection - which may pose\nsignificant challenges in sample generation and arguably grave consequences for\nfailure.\n  In this paper, we show how to construct highly-effective adversarial sample\ncrafting attacks for neural networks used as malware classifiers. The\napplication domain of malware classification introduces additional constraints\nin the adversarial sample crafting problem when compared to the computer vision\ndomain: (i) continuous, differentiable input domains are replaced by discrete,\noften binary inputs; and (ii) the loose condition of leaving visual appearance\nunchanged is replaced by requiring equivalent functional behavior. We\ndemonstrate the feasibility of these attacks on many different instances of\nmalware classifiers that we trained using the DREBIN Android malware data set.\nWe furthermore evaluate to which extent potential defensive mechanisms against\nadversarial crafting can be leveraged to the setting of malware classification.\nWhile feature reduction did not prove to have a positive impact, distillation\nand re-training on adversarially crafted samples show promising results.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 16:01:52 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2016 08:14:12 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Grosse", "Kathrin", ""], ["Papernot", "Nicolas", ""], ["Manoharan", "Praveen", ""], ["Backes", "Michael", ""], ["McDaniel", "Patrick", ""]]}, {"id": "1606.04466", "submitter": "Frieder Stolzenburg", "authors": "Frieder Stolzenburg and Florian Ruh", "title": "Neural Networks and Continuous Time", "comments": "16 pages, 10 figures. This paper is an extended version of a\n  contribution presented at KI 2009 Workshop Complex Cognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fields of neural computation and artificial neural networks have\ndeveloped much in the last decades. Most of the works in these fields focus on\nimplementing and/or learning discrete functions or behavior. However,\ntechnical, physical, and also cognitive processes evolve continuously in time.\nThis cannot be described directly with standard architectures of artificial\nneural networks such as multi-layer feed-forward perceptrons. Therefore, in\nthis paper, we will argue that neural networks modeling continuous time are\nneeded explicitly for this purpose, because with them the synthesis and\nanalysis of continuous and possibly periodic processes in time are possible\n(e.g. for robot behavior) besides computing discrete classification functions\n(e.g. for logical reasoning). We will relate possible neural network\narchitectures with (hybrid) automata models that allow to express continuous\nprocesses.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 17:26:27 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Stolzenburg", "Frieder", ""], ["Ruh", "Florian", ""]]}, {"id": "1606.04474", "submitter": "Matthew W. Hoffman", "authors": "Marcin Andrychowicz and Misha Denil and Sergio Gomez and Matthew W.\n  Hoffman and David Pfau and Tom Schaul and Brendan Shillingford and Nando de\n  Freitas", "title": "Learning to learn by gradient descent by gradient descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The move from hand-designed features to learned features in machine learning\nhas been wildly successful. In spite of this, optimization algorithms are still\ndesigned by hand. In this paper we show how the design of an optimization\nalgorithm can be cast as a learning problem, allowing the algorithm to learn to\nexploit structure in the problems of interest in an automatic way. Our learned\nalgorithms, implemented by LSTMs, outperform generic, hand-designed competitors\non the tasks for which they are trained, and also generalize well to new tasks\nwith similar structure. We demonstrate this on a number of tasks, including\nsimple convex problems, training neural networks, and styling images with\nneural art.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 17:49:32 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2016 16:45:45 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Andrychowicz", "Marcin", ""], ["Denil", "Misha", ""], ["Gomez", "Sergio", ""], ["Hoffman", "Matthew W.", ""], ["Pfau", "David", ""], ["Schaul", "Tom", ""], ["Shillingford", "Brendan", ""], ["de Freitas", "Nando", ""]]}, {"id": "1606.04518", "submitter": "Haoqi Li", "authors": "Haoqi Li, Brian Baucom, Panayiotis Georgiou", "title": "Sparsely Connected and Disjointly Trained Deep Neural Networks for Low\n  Resource Behavioral Annotation: Acoustic Classification in Couples' Therapy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observational studies are based on accurate assessment of human state. A\nbehavior recognition system that models interlocutors' state in real-time can\nsignificantly aid the mental health domain. However, behavior recognition from\nspeech remains a challenging task since it is difficult to find generalizable\nand representative features because of noisy and high-dimensional data,\nespecially when data is limited and annotated coarsely and subjectively. Deep\nNeural Networks (DNN) have shown promise in a wide range of machine learning\ntasks, but for Behavioral Signal Processing (BSP) tasks their application has\nbeen constrained due to limited quantity of data. We propose a\nSparsely-Connected and Disjointly-Trained DNN (SD-DNN) framework to deal with\nlimited data. First, we break the acoustic feature set into subsets and train\nmultiple distinct classifiers. Then, the hidden layers of these classifiers\nbecome parts of a deeper network that integrates all feature streams. The\noverall system allows for full connectivity while limiting the number of\nparameters trained at any time and allows convergence possible with even\nlimited data. We present results on multiple behavior codes in the couples'\ntherapy domain and demonstrate the benefits in behavior classification\naccuracy. We also show the viability of this system towards live behavior\nannotations.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 19:32:34 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Li", "Haoqi", ""], ["Baucom", "Brian", ""], ["Georgiou", "Panayiotis", ""]]}, {"id": "1606.04582", "submitter": "Minjoon Seo", "authors": "Minjoon Seo, Sewon Min, Ali Farhadi, Hannaneh Hajishirzi", "title": "Query-Reduction Networks for Question Answering", "comments": "Published as a conference paper at ICLR 2017. Title of the paper has\n  changed from \"Query-Regression Networks for Machine Comprehension\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of question answering when reasoning over\nmultiple facts is required. We propose Query-Reduction Network (QRN), a variant\nof Recurrent Neural Network (RNN) that effectively handles both short-term\n(local) and long-term (global) sequential dependencies to reason over multiple\nfacts. QRN considers the context sentences as a sequence of state-changing\ntriggers, and reduces the original query to a more informed query as it\nobserves each trigger (context sentence) through time. Our experiments show\nthat QRN produces the state-of-the-art results in bAbI QA and dialog tasks, and\nin a real goal-oriented dialog dataset. In addition, QRN formulation allows\nparallelization on RNN's time axis, saving an order of magnitude in time\ncomplexity for training and inference.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 21:54:46 GMT"}, {"version": "v2", "created": "Wed, 6 Jul 2016 21:54:45 GMT"}, {"version": "v3", "created": "Wed, 16 Nov 2016 10:07:22 GMT"}, {"version": "v4", "created": "Fri, 9 Dec 2016 00:05:06 GMT"}, {"version": "v5", "created": "Tue, 7 Feb 2017 22:04:54 GMT"}, {"version": "v6", "created": "Fri, 24 Feb 2017 19:59:01 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Seo", "Minjoon", ""], ["Min", "Sewon", ""], ["Farhadi", "Ali", ""], ["Hajishirzi", "Hannaneh", ""]]}, {"id": "1606.04615", "submitter": "Ishan Durugkar", "authors": "Ishan P. Durugkar, Clemens Rosenbaum, Stefan Dernbach, Sridhar\n  Mahadevan", "title": "Deep Reinforcement Learning With Macro-Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has been shown to be a powerful framework for\nlearning policies from complex high-dimensional sensory inputs to actions in\ncomplex tasks, such as the Atari domain. In this paper, we explore output\nrepresentation modeling in the form of temporal abstraction to improve\nconvergence and reliability of deep reinforcement learning approaches. We\nconcentrate on macro-actions, and evaluate these on different Atari 2600 games,\nwhere we show that they yield significant improvements in learning speed.\nAdditionally, we show that they can even achieve better scores than DQN. We\noffer analysis and explanation for both convergence and final results,\nrevealing a problem deep RL approaches have with sparse reward signals.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 01:57:40 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Durugkar", "Ishan P.", ""], ["Rosenbaum", "Clemens", ""], ["Dernbach", "Stefan", ""], ["Mahadevan", "Sridhar", ""]]}, {"id": "1606.04750", "submitter": "Zhenzhou Wu", "authors": "Zhenzhou Wu, Sunil Sivadas, Yong Kiam Tan, Ma Bin, Rick Siow Mong Goh", "title": "Multi-Modal Hybrid Deep Neural Network for Speech Enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNN) have been successful in en- hancing noisy speech\nsignals. Enhancement is achieved by learning a nonlinear mapping function from\nthe features of the corrupted speech signal to that of the reference clean\nspeech signal. The quality of predicted features can be improved by providing\nadditional side channel information that is robust to noise, such as visual\ncues. In this paper we propose a novel deep learning model inspired by insights\nfrom human audio visual perception. In the proposed unified hybrid\narchitecture, features from a Convolution Neural Network (CNN) that processes\nthe visual cues and features from a fully connected DNN that processes the\naudio signal are integrated using a Bidirectional Long Short-Term Memory\n(BiLSTM) network. The parameters of the hybrid model are jointly learned using\nbackpropagation. We compare the quality of enhanced speech from the hybrid\nmodels with those from traditional DNN and BiLSTM models.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 13:14:05 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Wu", "Zhenzhou", ""], ["Sivadas", "Sunil", ""], ["Tan", "Yong Kiam", ""], ["Bin", "Ma", ""], ["Goh", "Rick Siow Mong", ""]]}, {"id": "1606.04801", "submitter": "Kun He Prof.", "authors": "Kun He and Yan Wang and John Hopcroft", "title": "A Powerful Generative Model Using Random Weights for the Deep Image\n  Representation", "comments": "10 pages, 10 figures, submited to NIPS 2016 conference. Computer\n  Vision and Pattern Recognition, Neurons and Cognition, Neural and\n  Evolutionary Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To what extent is the success of deep visualization due to the training?\nCould we do deep visualization using untrained, random weight networks? To\naddress this issue, we explore new and powerful generative models for three\npopular deep visualization tasks using untrained, random weight convolutional\nneural networks. First we invert representations in feature spaces and\nreconstruct images from white noise inputs. The reconstruction quality is\nstatistically higher than that of the same method applied on well trained\nnetworks with the same architecture. Next we synthesize textures using scaled\ncorrelations of representations in multiple layers and our results are almost\nindistinguishable with the original natural texture and the synthesized\ntextures based on the trained network. Third, by recasting the content of an\nimage in the style of various artworks, we create artistic images with high\nperceptual quality, highly competitive to the prior work of Gatys et al. on\npretrained networks. To our knowledge this is the first demonstration of image\nrepresentations using untrained deep neural networks. Our work provides a new\nand fascinating tool to study the representation of deep network architecture\nand sheds light on new understandings on deep visualization.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 14:56:42 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2016 06:53:55 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["He", "Kun", ""], ["Wang", "Yan", ""], ["Hopcroft", "John", ""]]}, {"id": "1606.04884", "submitter": "Hugh Perkins", "authors": "Hugh Perkins (ASAPP)", "title": "cltorch: a Hardware-Agnostic Backend for the Torch Deep Neural Network\n  Library, Based on OpenCL", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents cltorch, a hardware-agnostic backend for the Torch neural\nnetwork framework. cltorch enables training of deep neural networks on GPUs\nfrom diverse hardware vendors, including AMD, NVIDIA, and Intel. cltorch\ncontains sufficient implementation to run models such as AlexNet, VGG,\nOverfeat, and GoogleNet. It is written using the OpenCL language, a portable\ncompute language, governed by the Khronos Group. cltorch is the top-ranked\nhardware-agnostic machine learning framework on Chintala's convnet-benchmarks\npage.\n  This paper presents the technical challenges encountered whilst creating the\ncltorch backend for Torch, and looks in detail at the challenges related to\nobtaining a fast hardware-agnostic implementation.\n  The convolutional layers are identified as the key area of focus for\naccelerating hardware-agnostic frameworks. Possible approaches to accelerating\nthe convolutional implementation are identified including: implementation of\nthe convolutions using the implicitgemm or winograd algorithm, using a GEMM\nimplementation adapted to the geometries associated with the convolutional\nalgorithm, or using a pluggable hardware-specific convolutional implementation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 17:59:31 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Perkins", "Hugh", "", "ASAPP"]]}, {"id": "1606.05018", "submitter": "Stefan Hosein", "authors": "Stefan Hosein and Patrick Hosein", "title": "Improving Power Generation Efficiency using Deep Neural Networks", "comments": "presented at 2016 ICML Workshop on #Data4Good: Machine Learning in\n  Social Good Applications, New York, NY", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been significant research on power generation,\ndistribution and transmission efficiency especially in the case of renewable\nresources. The main objective is reduction of energy losses and this requires\nimprovements on data acquisition and analysis. In this paper we address these\nconcerns by using consumers' electrical smart meter readings to estimate\nnetwork loading and this information can then be used for better capacity\nplanning. We compare Deep Neural Network (DNN) methods with traditional methods\nfor load forecasting. Our results indicate that DNN methods outperform most\ntraditional methods. This comes at the cost of additional computational\ncomplexity but this can be addressed with the use of cloud resources. We also\nillustrate how these results can be used to better support dynamic pricing.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 00:53:56 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Hosein", "Stefan", ""], ["Hosein", "Patrick", ""]]}, {"id": "1606.05169", "submitter": "Hu Zhang", "authors": "Jianyong Sun, Hu Zhang, Aimin Zhou and Qingfu Zhang", "title": "Learning from Non-Stationary Stream Data in Multiobjective Evolutionary\n  Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms (EAs) have been well acknowledged as a promising\nparadigm for solving optimisation problems with multiple conflicting objectives\nin the sense that they are able to locate a set of diverse approximations of\nPareto optimal solutions in a single run. EAs drive the search for approximated\nsolutions through maintaining a diverse population of solutions and by\nrecombining promising solutions selected from the population. Combining machine\nlearning techniques has shown great potentials since the intrinsic structure of\nthe Pareto optimal solutions of an multiobjective optimisation problem can be\nlearned and used to guide for effective recombination. However, existing\nmultiobjective EAs (MOEAs) based on structure learning spend too much\ncomputational resources on learning. To address this problem, we propose to use\nan online learning scheme. Based on the fact that offsprings along evolution\nare streamy, dependent and non-stationary (which implies that the intrinsic\nstructure, if any, is temporal and scale-variant), an online agglomerative\nclustering algorithm is applied to adaptively discover the intrinsic structure\nof the Pareto optimal solution set; and to guide effective offspring\nrecombination. Experimental results have shown significant improvement over\nfive state-of-the-art MOEAs on a set of well-known benchmark problems with\ncomplicated Pareto sets and complex Pareto fronts.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jun 2016 12:58:43 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Sun", "Jianyong", ""], ["Zhang", "Hu", ""], ["Zhou", "Aimin", ""], ["Zhang", "Qingfu", ""]]}, {"id": "1606.05464", "submitter": "Isabelle Augenstein", "authors": "Isabelle Augenstein and Tim Rockt\\\"aschel and Andreas Vlachos and\n  Kalina Bontcheva", "title": "Stance Detection with Bidirectional Conditional Encoding", "comments": "10 pages", "journal-ref": "EMNLP 2016", "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stance detection is the task of classifying the attitude expressed in a text\ntowards a target such as Hillary Clinton to be \"positive\", negative\" or\n\"neutral\". Previous work has assumed that either the target is mentioned in the\ntext or that training data for every target is given. This paper considers the\nmore challenging version of this task, where targets are not always mentioned\nand no training data is available for the test targets. We experiment with\nconditional LSTM encoding, which builds a representation of the tweet that is\ndependent on the target, and demonstrate that it outperforms encoding the tweet\nand the target independently. Performance is improved further when the\nconditional model is augmented with bidirectional encoding. We evaluate our\napproach on the SemEval 2016 Task 6 Twitter Stance Detection corpus achieving\nperformance second best only to a system trained on semi-automatically labelled\ntweets for the test target. When such weak supervision is added, our approach\nachieves state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 09:39:47 GMT"}, {"version": "v2", "created": "Mon, 26 Sep 2016 20:49:16 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Augenstein", "Isabelle", ""], ["Rockt\u00e4schel", "Tim", ""], ["Vlachos", "Andreas", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "1606.05487", "submitter": "Renzo Andri", "authors": "Renzo Andri and Lukas Cavigelli and Davide Rossi and Luca Benini", "title": "YodaNN: An Architecture for Ultra-Low Power Binary-Weight CNN\n  Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have revolutionized the world of\ncomputer vision over the last few years, pushing image classification beyond\nhuman accuracy. The computational effort of today's CNNs requires power-hungry\nparallel processors or GP-GPUs. Recent developments in CNN accelerators for\nsystem-on-chip integration have reduced energy consumption significantly.\nUnfortunately, even these highly optimized devices are above the power envelope\nimposed by mobile and deeply embedded applications and face hard limitations\ncaused by CNN weight I/O and storage. This prevents the adoption of CNNs in\nfuture ultra-low power Internet of Things end-nodes for near-sensor analytics.\nRecent algorithmic and theoretical advancements enable competitive\nclassification accuracy even when limiting CNNs to binary (+1/-1) weights\nduring training. These new findings bring major optimization opportunities in\nthe arithmetic core by removing the need for expensive multiplications, as well\nas reducing I/O bandwidth and storage. In this work, we present an accelerator\noptimized for binary-weight CNNs that achieves 1510 GOp/s at 1.2 V on a core\narea of only 1.33 MGE (Million Gate Equivalent) or 0.19 mm$^2$ and with a power\ndissipation of 895 {\\mu}W in UMC 65 nm technology at 0.6 V. Our accelerator\nsignificantly outperforms the state-of-the-art in terms of energy and area\nefficiency achieving 61.2 TOp/s/W@0.6 V and 1135 GOp/s/MGE@1.2 V, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 11:48:29 GMT"}, {"version": "v2", "created": "Mon, 13 Feb 2017 11:00:58 GMT"}, {"version": "v3", "created": "Thu, 16 Feb 2017 10:54:26 GMT"}, {"version": "v4", "created": "Fri, 24 Feb 2017 08:46:12 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Andri", "Renzo", ""], ["Cavigelli", "Lukas", ""], ["Rossi", "Davide", ""], ["Benini", "Luca", ""]]}, {"id": "1606.05551", "submitter": "Per Kristian Lehre", "authors": "Duc-Cuong Dang and Per Kristian Lehre", "title": "Self-adaptation of Mutation Rates in Non-elitist Populations", "comments": "To appear in the Proceedings of the 14th International Conference on\n  Parallel Problem Solving from Nature (PPSN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The runtime of evolutionary algorithms (EAs) depends critically on their\nparameter settings, which are often problem-specific. Automated schemes for\nparameter tuning have been developed to alleviate the high costs of manual\nparameter tuning. Experimental results indicate that self-adaptation, where\nparameter settings are encoded in the genomes of individuals, can be effective\nin continuous optimisation. However, results in discrete optimisation have been\nless conclusive. Furthermore, a rigorous runtime analysis that explains how\nself-adaptation can lead to asymptotic speedups has been missing. This paper\nprovides the first such analysis for discrete, population-based EAs. We apply\nlevel-based analysis to show how a self-adaptive EA is capable of fine-tuning\nits mutation rate, leading to exponential speedups over EAs using fixed\nmutation rates.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 15:06:35 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Dang", "Duc-Cuong", ""], ["Lehre", "Per Kristian", ""]]}, {"id": "1606.05554", "submitter": "Noura Al Moubayed", "authors": "Noura Al Moubayed, Toby Breckon, Peter Matthews, and A. Stephen\n  McGough", "title": "SMS Spam Filtering using Probabilistic Topic Modelling and Stacked\n  Denoising Autoencoder", "comments": "Paper was accepted to the 25th International Conference on Artificial\n  Neural Networks (ICANN 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In This paper we present a novel approach to spam filtering and demonstrate\nits applicability with respect to SMS messages. Our approach requires minimum\nfeatures engineering and a small set of la- belled data samples. Features are\nextracted using topic modelling based on latent Dirichlet allocation, and then\na comprehensive data model is created using a Stacked Denoising Autoencoder\n(SDA). Topic modelling summarises the data providing ease of use and high\ninterpretability by visualising the topics using word clouds. Given that the\nSMS messages can be regarded as either spam (unwanted) or ham (wanted), the SDA\nis able to model the messages and accurately discriminate between the two\nclasses without the need for a pre-labelled training set. The results are\ncompared against the state-of-the-art spam detection algorithms with our\nproposed approach achieving over 97% accuracy which compares favourably to the\nbest reported algorithms presented in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 15:15:18 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Moubayed", "Noura Al", ""], ["Breckon", "Toby", ""], ["Matthews", "Peter", ""], ["McGough", "A. Stephen", ""]]}, {"id": "1606.05647", "submitter": "Chantal Nguyen", "authors": "Chantal Nguyen, Fangqiu Han, Kimberly J. Schlesinger, Izzeddin G\\\"ur,\n  Jean M. Carlson", "title": "Collective Decision Dynamics in Group Evacuation: Behavioral Experiment\n  and Machine Learning Models", "comments": "formerly part 1 of a 2-part series, now presented individually", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.NE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying factors that affect human decision making and quantifying their\ninfluence remain essential and challenging tasks for the design and\nimplementation of social and technological communication systems. We report\nresults of a behavioral experiment involving decision making in the face of an\nimpending natural disaster. In a controlled laboratory setting, we characterize\nindividual and group evacuation decision making influenced by several key\nfactors, including the likelihood of the disaster, available shelter capacity,\ngroup size, and group decision protocol. Our results show that success in\nindividual decision making is not a strong predictor of group performance. We\nuse an artificial neural network trained on the collective behavior of subjects\nto predict individual and group outcomes. Overall model accuracy increases with\nthe inclusion of a subject-specific performance parameter based on laboratory\ntrials that captures individual differences. In parallel, we demonstrate that\nthe social media activity of individual subjects, specifically their Facebook\nuse, can be used to generate an alternative individual personality profile that\nleads to comparable model accuracy. Quantitative characterization and\nprediction of collective decision making is crucial for the development of\neffective policies to guide the action of populations in the face of threat or\nuncertainty.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 20:00:00 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 18:52:12 GMT"}, {"version": "v3", "created": "Thu, 1 Dec 2016 02:42:15 GMT"}], "update_date": "2016-12-02", "authors_parsed": [["Nguyen", "Chantal", ""], ["Han", "Fangqiu", ""], ["Schlesinger", "Kimberly J.", ""], ["G\u00fcr", "Izzeddin", ""], ["Carlson", "Jean M.", ""]]}, {"id": "1606.05784", "submitter": "Anton Eremeev", "authors": "Anton Eremeev", "title": "Hitting times of local and global optima in genetic algorithms with very\n  high selection pressure", "comments": "Submitted to Yugoslav Journal of Operations Research. arXiv admin\n  note: text overlap with arXiv:1512.02047", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is devoted to upper bounds on the expected first hitting times of\nthe sets of local or global optima for non-elitist genetic algorithms with very\nhigh selection pressure. The results of this paper extend the range of\nsituations where the upper bounds on the expected runtime are known for genetic\nalgorithms and apply, in particular, to the Canonical Genetic Algorithm. The\nobtained bounds do not require the probability of fitness-decreasing mutation\nto be bounded by a constant less than one.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jun 2016 17:36:28 GMT"}, {"version": "v2", "created": "Thu, 30 Jun 2016 17:29:55 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["Eremeev", "Anton", ""]]}, {"id": "1606.05927", "submitter": "Andrew Connor", "authors": "Wilson S. Siringoringo, Andy M. Connor, Nick Clements and Nick\n  Alexander", "title": "Minimum cost polygon overlay with rectangular shape stock panels", "comments": null, "journal-ref": "International Journal of Construction Education & Research, 4(3),\n  1-24 (2008)", "doi": "10.1080/15578770802494516", "report-no": null, "categories": "cs.NE cs.CG cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimum Cost Polygon Overlay (MCPO) is a unique two-dimensional optimization\nproblem that involves the task of covering a polygon shaped area with a series\nof rectangular shaped panels. This has a number of applications in the\nconstruction industry. This work examines the MCPO problem in order to\nconstruct a model that captures essential parameters of the problem to be\nsolved automatically using numerical optimization algorithms. Three algorithms\nhave been implemented of the actual optimization task: the greedy search, the\nMonte Carlo (MC) method, and the Genetic Algorithm (GA). Results are presented\nto show the relative effectiveness of the algorithms. This is followed by\ncritical analysis of various findings of this research.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jun 2016 23:50:15 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Siringoringo", "Wilson S.", ""], ["Connor", "Andy M.", ""], ["Clements", "Nick", ""], ["Alexander", "Nick", ""]]}, {"id": "1606.05929", "submitter": "Hengyue Pan", "authors": "Hengyue Pan and Hui Jiang", "title": "Learning Convolutional Neural Networks using Hybrid Orthogonal\n  Projection and Estimation", "comments": "7 Pages, 5 figures, submitted to AAAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have yielded the excellent performance\nin a variety of computer vision tasks, where CNNs typically adopt a similar\nstructure consisting of convolution layers, pooling layers and fully connected\nlayers. In this paper, we propose to apply a novel method, namely Hybrid\nOrthogonal Projection and Estimation (HOPE), to CNNs in order to introduce\northogonality into the CNN structure. The HOPE model can be viewed as a hybrid\nmodel to combine feature extraction using orthogonal linear projection with\nmixture models. It is an effective model to extract useful information from the\noriginal high-dimension feature vectors and meanwhile filter out irrelevant\nnoises. In this work, we present three different ways to apply the HOPE models\nto CNNs, i.e., {\\em HOPE-Input}, {\\em single-HOPE-Block} and {\\em\nmulti-HOPE-Blocks}. For {\\em HOPE-Input} CNNs, a HOPE layer is directly used\nright after the input to de-correlate high-dimension input feature vectors.\nAlternatively, in {\\em single-HOPE-Block} and {\\em multi-HOPE-Blocks} CNNs, we\nconsider to use HOPE layers to replace one or more blocks in the CNNs, where\none block may include several convolutional layers and one pooling layer. The\nexperimental results on both Cifar-10 and Cifar-100 data sets have shown that\nthe orthogonal constraints imposed by the HOPE layers can significantly improve\nthe performance of CNNs in these image classification tasks (we have achieved\none of the best performance when image augmentation has not been applied, and\ntop 5 performance with image augmentation).\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 00:19:43 GMT"}, {"version": "v2", "created": "Wed, 29 Jun 2016 20:42:04 GMT"}, {"version": "v3", "created": "Thu, 8 Sep 2016 08:46:52 GMT"}, {"version": "v4", "created": "Sun, 11 Sep 2016 03:25:25 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Pan", "Hengyue", ""], ["Jiang", "Hui", ""]]}, {"id": "1606.05990", "submitter": "Petre Birtea", "authors": "Petre Birtea, Cosmin Cernazanu-Glavan, Alexandru Sisu", "title": "A New Training Method for Feedforward Neural Networks Based on Geometric\n  Contraction Property of Activation Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new training method for a feedforward neural network having the\nactivation functions with the geometric contraction property. The method\nconsists of constructing a new functional that is less nonlinear in comparison\nwith the classical functional by removing the nonlinearity of the activation\nfunction from the output layer. We validate this new method by a series of\nexperiments that show an improved learning speed and better classification\nerror.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 07:05:14 GMT"}, {"version": "v2", "created": "Sat, 11 Aug 2018 19:52:59 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Birtea", "Petre", ""], ["Cernazanu-Glavan", "Cosmin", ""], ["Sisu", "Alexandru", ""]]}, {"id": "1606.06041", "submitter": "Jialin Liu Ph.D", "authors": "Jialin Liu, Diego Pe\\'rez-Lie\\'bana, Simon M. Lucas", "title": "Bandit-Based Random Mutation Hill-Climbing", "comments": "7 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Random Mutation Hill-Climbing algorithm is a direct search technique\nmostly used in discrete domains. It repeats the process of randomly selecting a\nneighbour of a best-so-far solution and accepts the neighbour if it is better\nthan or equal to it. In this work, we propose to use a novel method to select\nthe neighbour solution using a set of independent multi- armed bandit-style\nselection units which results in a bandit-based Random Mutation Hill-Climbing\nalgorithm. The new algorithm significantly outperforms Random Mutation\nHill-Climbing in both OneMax (in noise-free and noisy cases) and Royal Road\nproblems (in the noise-free case). The algorithm shows particular promise for\ndiscrete optimisation problems where each fitness evaluation is expensive.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 09:53:29 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Liu", "Jialin", ""], ["Pe\u0155ez-Liebana", "Diego", ""], ["Lucas", "Simon M.", ""]]}, {"id": "1606.06047", "submitter": "Harmeet Singh", "authors": "Harmeet Singh", "title": "Contravening Esotery: Cryptanalysis of Knapsack Cipher using Genetic\n  Algorithms", "comments": "http://www.ijcaonline.org/archives/volume140/number6/24599-2016909333, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptanalysis of knapsack cipher is a fascinating problem which has eluded\nthe computing fraternity for decades. However, in most of the cases either the\ntime complexity of the proposed algorithm is colossal or an insufficient number\nof samples have been taken for verification. The present work proposes a\nGenetic Algorithm based technique for cryptanalysis of knapsack cipher. The\nexperiments conducted prove the validity of the technique. The results prove\nthat the technique is better than the existing techniques. An extensive review\nhas been carried out in order to find the gaps in the existing techniques. The\nwork paves the way of the application of computational intelligence techniques\nto the discipline of cryptanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 10:04:05 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Singh", "Harmeet", ""]]}, {"id": "1606.06137", "submitter": "Markus Koskela", "authors": "Petri Luukkonen, Markus Koskela, and Patrik Flor\\'een", "title": "LSTM-Based Predictions for Proactive Information Retrieval", "comments": "Neu-IR '16 SIGIR Workshop on Neural Information Retrieval, July 21,\n  2016, Pisa, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for proactive information retrieval targeted at\nretrieving relevant information during a writing task. In our method, the\ncurrent task and the needs of the user are estimated, and the potential next\nsteps are unobtrusively predicted based on the user's past actions. We focus on\nthe task of writing, in which the user is coalescing previously collected\ninformation into a text. Our proactive system automatically recommends the user\nrelevant background information. The proposed system incorporates text input\nprediction using a long short-term memory (LSTM) network. We present\nsimulations, which show that the system is able to reach higher precision\nvalues in an exploratory search setting compared to both a baseline and a\ncomparison system.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 14:26:33 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Luukkonen", "Petri", ""], ["Koskela", "Markus", ""], ["Flor\u00e9en", "Patrik", ""]]}, {"id": "1606.06160", "submitter": "Shuchang Zhou", "authors": "Shuchang Zhou, Yuxin Wu, Zekun Ni, Xinyu Zhou, He Wen, Yuheng Zou", "title": "DoReFa-Net: Training Low Bitwidth Convolutional Neural Networks with Low\n  Bitwidth Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose DoReFa-Net, a method to train convolutional neural networks that\nhave low bitwidth weights and activations using low bitwidth parameter\ngradients. In particular, during backward pass, parameter gradients are\nstochastically quantized to low bitwidth numbers before being propagated to\nconvolutional layers. As convolutions during forward/backward passes can now\noperate on low bitwidth weights and activations/gradients respectively,\nDoReFa-Net can use bit convolution kernels to accelerate both training and\ninference. Moreover, as bit convolutions can be efficiently implemented on CPU,\nFPGA, ASIC and GPU, DoReFa-Net opens the way to accelerate training of low\nbitwidth neural network on these hardware. Our experiments on SVHN and ImageNet\ndatasets prove that DoReFa-Net can achieve comparable prediction accuracy as\n32-bit counterparts. For example, a DoReFa-Net derived from AlexNet that has\n1-bit weights, 2-bit activations, can be trained from scratch using 6-bit\ngradients to get 46.1\\% top-1 accuracy on ImageNet validation set. The\nDoReFa-Net AlexNet model is released publicly.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 15:02:31 GMT"}, {"version": "v2", "created": "Sun, 17 Jul 2016 14:21:03 GMT"}, {"version": "v3", "created": "Fri, 2 Feb 2018 01:43:54 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Zhou", "Shuchang", ""], ["Wu", "Yuxin", ""], ["Ni", "Zekun", ""], ["Zhou", "Xinyu", ""], ["Wen", "He", ""], ["Zou", "Yuheng", ""]]}, {"id": "1606.06216", "submitter": "Thomas Miconi", "authors": "Thomas Miconi", "title": "Neural networks with differentiable structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While gradient descent has proven highly successful in learning connection\nweights for neural networks, the actual structure of these networks is usually\ndetermined by hand, or by other optimization algorithms. Here we describe a\nsimple method to make network structure differentiable, and therefore\naccessible to gradient descent. We test this method on recurrent neural\nnetworks applied to simple sequence prediction problems. Starting with initial\nnetworks containing only one node, the method automatically builds networks\nthat successfully solve the tasks. The number of nodes in the final network\ncorrelates with task difficulty. The method can dynamically increase network\nsize in response to an abrupt complexification in the task; however, reduction\nin network size in response to task simplification is not evident for\nreasonable meta-parameters. The method does not penalize network performance\nfor these test tasks: variable-size networks actually reach better performance\nthan fixed-size networks of higher, lower or identical size. We conclude by\ndiscussing how this method could be applied to more complex networks, such as\nfeedforward layered networks, or multiple-area networks of arbitrary shape.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 17:29:01 GMT"}, {"version": "v2", "created": "Thu, 7 Jul 2016 00:16:00 GMT"}, {"version": "v3", "created": "Sat, 6 Aug 2016 23:45:51 GMT"}], "update_date": "2016-08-09", "authors_parsed": [["Miconi", "Thomas", ""]]}, {"id": "1606.06443", "submitter": "Zhang Chong", "authors": "Chong Zhang, Jochen Triesch and Bertram E. Shi", "title": "An active efficient coding model of the optokinetic nystagmus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optokinetic nystagmus (OKN) is an involuntary eye movement responsible for\nstabilizing retinal images in the presence of relative motion between an\nobserver and the environment. Fully understanding the development of\noptokinetic nystagmus requires a neurally plausible computational model that\naccounts for the neural development and the behavior. To date, work in this\narea has been limited. We propose a neurally plausible framework for the joint\ndevelopment of disparity and motion tuning in the visual cortex, the\noptokinetic and vergence eye movements. This framework models the joint\nemergence of both perception and behavior, and accounts for the importance of\nthe development of normal vergence control and binocular vision in achieving\nnormal monocular OKN (mOKN) behaviors. Because the model includes behavior, we\ncan simulate the same perturbations as performed in past experiments, such as\nartificially induced strabismus. The proposed model agrees both qualitatively\nand quantitatively with a number of findings from the literature on both\nbinocular vision as well as the optokinetic reflex. Finally, our model also\nmakes quantitative predictions about the OKN behavior using the same methods\nused to characterize the OKN in the experimental literature.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 07:01:18 GMT"}, {"version": "v2", "created": "Sun, 2 Oct 2016 07:24:00 GMT"}, {"version": "v3", "created": "Tue, 11 Oct 2016 07:07:35 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Zhang", "Chong", ""], ["Triesch", "Jochen", ""], ["Shi", "Bertram E.", ""]]}, {"id": "1606.06724", "submitter": "Klaus Greff", "authors": "Klaus Greff, Antti Rasmus, Mathias Berglund, Tele Hotloo Hao, J\\\"urgen\n  Schmidhuber, Harri Valpola", "title": "Tagger: Deep Unsupervised Perceptual Grouping", "comments": "14 pages + 5 pages supplementary, accepted at NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for efficient perceptual inference that explicitly\nreasons about the segmentation of its inputs and features. Rather than being\ntrained for any specific segmentation, our framework learns the grouping\nprocess in an unsupervised manner or alongside any supervised task. By\nenriching the representations of a neural network, we enable it to group the\nrepresentations of different objects in an iterative manner. By allowing the\nsystem to amortize the iterative inference of the groupings, we achieve very\nfast convergence. In contrast to many other recently proposed methods for\naddressing multi-object scenes, our system does not assume the inputs to be\nimages and can therefore directly handle other modalities. For multi-digit\nclassification of very cluttered images that require texture segmentation, our\nmethod offers improved classification performance over convolutional networks\ndespite being fully connected. Furthermore, we observe that our system greatly\nimproves on the semi-supervised result of a baseline Ladder network on our\ndataset, indicating that segmentation can also improve sample efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 19:55:32 GMT"}, {"version": "v2", "created": "Mon, 28 Nov 2016 18:59:28 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Greff", "Klaus", ""], ["Rasmus", "Antti", ""], ["Berglund", "Mathias", ""], ["Hao", "Tele Hotloo", ""], ["Schmidhuber", "J\u00fcrgen", ""], ["Valpola", "Harri", ""]]}, {"id": "1606.06818", "submitter": "Markus Wagner", "authors": "Mohammad Reza Bonyadi, Zbigniew Michalewicz, Frank Neumann, Markus\n  Wagner", "title": "Evolutionary computation for multicomponent problems: opportunities and\n  future directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past 30 years many researchers in the field of evolutionary\ncomputation have put a lot of effort to introduce various approaches for\nsolving hard problems. Most of these problems have been inspired by major\nindustries so that solving them, by providing either optimal or near optimal\nsolution, was of major significance. Indeed, this was a very promising\ntrajectory as advances in these problem-solving approaches could result in\nadding values to major industries. In this paper we revisit this trajectory to\nfind out whether the attempts that started three decades ago are still aligned\nwith the same goal, as complexities of real-world problems increased\nsignificantly. We present some examples of modern real-world problems, discuss\nwhy they might be difficult to solve, and whether there is any mismatch between\nthese examples and the problems that are investigated in the evolutionary\ncomputation area.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 05:08:52 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Bonyadi", "Mohammad Reza", ""], ["Michalewicz", "Zbigniew", ""], ["Neumann", "Frank", ""], ["Wagner", "Markus", ""]]}, {"id": "1606.06871", "submitter": "Albert Zeyer", "authors": "Albert Zeyer, Patrick Doetsch, Paul Voigtlaender, Ralf Schl\\\"uter,\n  Hermann Ney", "title": "A Comprehensive Study of Deep Bidirectional LSTM RNNs for Acoustic\n  Modeling in Speech Recognition", "comments": "published on ICASSP 2017 conference, New Orleans, USA", "journal-ref": null, "doi": "10.1109/ICASSP.2017.7952599", "report-no": null, "categories": "cs.NE cs.CL cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comprehensive study of deep bidirectional long short-term memory\n(LSTM) recurrent neural network (RNN) based acoustic models for automatic\nspeech recognition (ASR). We study the effect of size and depth and train\nmodels of up to 8 layers. We investigate the training aspect and study\ndifferent variants of optimization methods, batching, truncated\nbackpropagation, different regularization techniques such as dropout and $L_2$\nregularization, and different gradient clipping variants.\n  The major part of the experimental analysis was performed on the Quaero\ncorpus. Additional experiments also were performed on the Switchboard corpus.\nOur best LSTM model has a relative improvement in word error rate of over 14\\%\ncompared to our best feed-forward neural network (FFNN) baseline on the Quaero\ntask. On this task, we get our best result with an 8 layer bidirectional LSTM\nand we show that a pretraining scheme with layer-wise construction helps for\ndeep LSTMs.\n  Finally we compare the training calculation time of many of the presented\nexperiments in relation with recognition performance.\n  All the experiments were done with RETURNN, the RWTH extensible training\nframework for universal recurrent neural networks in combination with RASR, the\nRWTH ASR toolkit.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 10:00:14 GMT"}, {"version": "v2", "created": "Wed, 29 Mar 2017 08:08:29 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Zeyer", "Albert", ""], ["Doetsch", "Patrick", ""], ["Voigtlaender", "Paul", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1606.06961", "submitter": "Pasquale Salza", "authors": "Pasquale Salza and Filomena Ferrucci", "title": "An Approach for Parallel Genetic Algorithms in the Cloud using Software\n  Containers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic Algorithms (GAs) are a powerful technique to address hard\noptimisation problems. However, scalability issues might prevent them from\nbeing applied to real-world problems. Exploiting parallel GAs in the cloud\nmight be an affordable approach to get time efficient solutions that benefit of\nthe appealing features of the cloud, such as scalability, reliability,\nfault-tolerance and cost-effectiveness. Nevertheless, distributed computation\nis very prone to cause considerable overhead for communication and making GAs\ndistributed in an on-demand fashion is not trivial. Aiming to keep under\ncontrol the communication overhead and support GAs developers in the\nconstruction and deployment of parallel GAs in the cloud, in this paper we\npropose an approach to distribute GAs using the global parallelisation model,\nexploiting software containers and their cloud orchestration. We also devised a\nconceptual workflow covering each cloud GAs distribution phase, from resources\nallocation to actual deployment and execution, in a DevOps fashion.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 14:32:34 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Salza", "Pasquale", ""], ["Ferrucci", "Filomena", ""]]}, {"id": "1606.07149", "submitter": "Ivo Bukovsky Ph.D.", "authors": "Ivo Bukovsky and Noriyasu Homma", "title": "An Approach to Stable Gradient Descent Adaptation of Higher-Order Neural\n  Units", "comments": "2016, 13 pages", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems,ISSN:\n  2162-237X,2016", "doi": "10.1109/TNNLS.2016.2572310", "report-no": null, "categories": "cs.NE cs.AI cs.CE cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stability evaluation of a weight-update system of higher-order neural units\n(HONUs) with polynomial aggregation of neural inputs (also known as classes of\npolynomial neural networks) for adaptation of both feedforward and recurrent\nHONUs by a gradient descent method is introduced. An essential core of the\napproach is based on spectral radius of a weight-update system, and it allows\nstability monitoring and its maintenance at every adaptation step individually.\nAssuring stability of the weight-update system (at every single adaptation\nstep) naturally results in adaptation stability of the whole neural\narchitecture that adapts to target data. As an aside, the used approach\nhighlights the fact that the weight optimization of HONU is a linear problem,\nso the proposed approach can be generally extended to any neural architecture\nthat is linear in its adaptable parameters.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 01:07:27 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Bukovsky", "Ivo", ""], ["Homma", "Noriyasu", ""]]}, {"id": "1606.07262", "submitter": "Ofer Shir", "authors": "Ofer M. Shir, Jonathan Roslund and Amir Yehudayoff", "title": "On the Theoretical Capacity of Evolution Strategies to Statistically\n  Learn the Landscape Hessian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the theoretical capacity to statistically learn local landscape\ninformation by Evolution Strategies (ESs). Specifically, we investigate the\ncovariance matrix when constructed by ESs operating with the selection operator\nalone. We model continuous generation of candidate solutions about quadratic\nbasins of attraction, with deterministic selection of the decision vectors that\nminimize the objective function values. Our goal is to rigorously show that\naccumulation of winning individuals carries the potential to reveal valuable\ninformation about the search landscape, e.g., as already practically utilized\nby derandomized ES variants. We first show that the statistically-constructed\ncovariance matrix over such winning decision vectors shares the same\neigenvectors with the Hessian matrix about the optimum. We then provide an\nanalytic approximation of this covariance matrix for a non-elitist multi-child\n$(1,\\lambda)$-strategy, which holds for a large population size $\\lambda$.\nFinally, we also numerically corroborate our results.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 10:38:49 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Shir", "Ofer M.", ""], ["Roslund", "Jonathan", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "1606.07285", "submitter": "Wojciech Samek", "authors": "Farhad Arbabzadah and Gr\\'egoire Montavon and Klaus-Robert M\\\"uller\n  and Wojciech Samek", "title": "Identifying individual facial expressions by deconstructing a neural\n  network", "comments": "12 pages, 7 figures, Paper accepted for GCPR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of explaining predictions of psychological\nattributes such as attractiveness, happiness, confidence and intelligence from\nface photographs using deep neural networks. Since psychological attribute\ndatasets typically suffer from small sample sizes, we apply transfer learning\nwith two base models to avoid overfitting. These models were trained on an age\nand gender prediction task, respectively. Using a novel explanation method we\nextract heatmaps that highlight the parts of the image most responsible for the\nprediction. We further observe that the explanation method provides important\ninsights into the nature of features of the base model, which allow one to\nassess the aptitude of the base model for a given transfer learning task.\nFinally, we observe that the multiclass model is more feature rich than its\nbinary counterpart. The experimental evaluation is performed on the 2222 images\nfrom the 10k US faces dataset containing psychological attribute labels as well\nas on a subset of KDEF images.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 12:24:45 GMT"}, {"version": "v2", "created": "Sun, 26 Jun 2016 00:41:35 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Arbabzadah", "Farhad", ""], ["Montavon", "Gr\u00e9goire", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1606.07287", "submitter": "Andrea Esuli", "authors": "Fabio Carrara, Andrea Esuli, Tiziano Fagni, Fabrizio Falchi, Alejandro\n  Moreo Fern\\'andez", "title": "Picture It In Your Mind: Generating High Level Visual Representations\n  From Textual Descriptions", "comments": "Neu-IR '16 SIGIR Workshop on Neural Information Retrieval, July 21,\n  2016, Pisa, Italy", "journal-ref": null, "doi": "10.1007/s10791-017-9318-6", "report-no": null, "categories": "cs.IR cs.CL cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we tackle the problem of image search when the query is a short\ntextual description of the image the user is looking for. We choose to\nimplement the actual search process as a similarity search in a visual feature\nspace, by learning to translate a textual query into a visual representation.\nSearching in the visual feature space has the advantage that any update to the\ntranslation model does not require to reprocess the, typically huge, image\ncollection on which the search is performed. We propose Text2Vis, a neural\nnetwork that generates a visual representation, in the visual feature space of\nthe fc6-fc7 layers of ImageNet, from a short descriptive text. Text2Vis\noptimizes two loss functions, using a stochastic loss-selection method. A\nvisual-focused loss is aimed at learning the actual text-to-visual feature\nmapping, while a text-focused loss is aimed at modeling the higher-level\nsemantic concepts expressed in language and countering the overfit on\nnon-relevant visual components of the visual loss. We report preliminary\nresults on the MS-COCO dataset.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 12:25:09 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Carrara", "Fabio", ""], ["Esuli", "Andrea", ""], ["Fagni", "Tiziano", ""], ["Falchi", "Fabrizio", ""], ["Fern\u00e1ndez", "Alejandro Moreo", ""]]}, {"id": "1606.07298", "submitter": "Wojciech Samek", "authors": "Leila Arras and Franziska Horn and Gr\\'egoire Montavon and\n  Klaus-Robert M\\\"uller and Wojciech Samek", "title": "Explaining Predictions of Non-Linear Classifiers in NLP", "comments": "7 pages, 3 figures, Paper accepted for 1st Workshop on Representation\n  Learning for NLP at ACL 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Layer-wise relevance propagation (LRP) is a recently proposed technique for\nexplaining predictions of complex non-linear classifiers in terms of input\nvariables. In this paper, we apply LRP for the first time to natural language\nprocessing (NLP). More precisely, we use it to explain the predictions of a\nconvolutional neural network (CNN) trained on a topic categorization task. Our\nanalysis highlights which words are relevant for a specific prediction of the\nCNN. We compare our technique to standard sensitivity analysis, both\nqualitatively and quantitatively, using a \"word deleting\" perturbation\nexperiment, a PCA analysis, and various visualizations. All experiments\nvalidate the suitability of LRP for explaining the CNN predictions, which is\nalso in line with results reported in recent image classification studies.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 12:53:31 GMT"}], "update_date": "2016-06-24", "authors_parsed": [["Arras", "Leila", ""], ["Horn", "Franziska", ""], ["Montavon", "Gr\u00e9goire", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1606.07461", "submitter": "Alexander M. Rush", "authors": "Hendrik Strobelt, Sebastian Gehrmann, Hanspeter Pfister, Alexander M.\n  Rush", "title": "LSTMVis: A Tool for Visual Analysis of Hidden State Dynamics in\n  Recurrent Neural Networks", "comments": "InfoVis 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks, and in particular long short-term memory (LSTM)\nnetworks, are a remarkably effective tool for sequence modeling that learn a\ndense black-box hidden representation of their sequential input. Researchers\ninterested in better understanding these models have studied the changes in\nhidden state representations over time and noticed some interpretable patterns\nbut also significant noise. In this work, we present LSTMVIS, a visual analysis\ntool for recurrent neural networks with a focus on understanding these hidden\nstate dynamics. The tool allows users to select a hypothesis input range to\nfocus on local state changes, to match these states changes to similar patterns\nin a large data set, and to align these results with structural annotations\nfrom their domain. We show several use cases of the tool for analyzing specific\nhidden state properties on dataset containing nesting, phrase structure, and\nchord progressions, and demonstrate how the tool can be used to isolate\npatterns for further statistical analysis. We characterize the domain, the\ndifferent stakeholders, and their goals and tasks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 20:20:39 GMT"}, {"version": "v2", "created": "Mon, 30 Oct 2017 15:11:54 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Strobelt", "Hendrik", ""], ["Gehrmann", "Sebastian", ""], ["Pfister", "Hanspeter", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1606.07496", "submitter": "Roberto Camacho Barranco", "authors": "Roberto Camacho Barranco (1), Laura M. Rodriguez (1), Rebecca Urbina\n  (1), and M. Shahriar Hossain (1) ((1) The University of Texas at El Paso)", "title": "Is a Picture Worth Ten Thousand Words in a Review Dataset?", "comments": "10 pages, 11 figures, \"for associated results, see\n  http://http://auto-captioning.herokuapp.com/\" \"submitted to DLRS 2016\n  workshop\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While textual reviews have become prominent in many recommendation-based\nsystems, automated frameworks to provide relevant visual cues against text\nreviews where pictures are not available is a new form of task confronted by\ndata mining and machine learning researchers. Suggestions of pictures that are\nrelevant to the content of a review could significantly benefit the users by\nincreasing the effectiveness of a review. We propose a deep learning-based\nframework to automatically: (1) tag the images available in a review dataset,\n(2) generate a caption for each image that does not have one, and (3) enhance\neach review by recommending relevant images that might not be uploaded by the\ncorresponding reviewer. We evaluate the proposed framework using the Yelp\nChallenge Dataset. While a subset of the images in this particular dataset are\ncorrectly captioned, the majority of the pictures do not have any associated\ntext. Moreover, there is no mapping between reviews and images. Each image has\na corresponding business-tag where the picture was taken, though. The overall\ndata setting and unavailability of crucial pieces required for a mapping make\nthe problem of recommending images for reviews a major challenge. Qualitative\nand quantitative evaluations indicate that our proposed framework provides high\nquality enhancements through automatic captioning, tagging, and recommendation\nfor mapping reviews and images.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 22:04:08 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Barranco", "Roberto Camacho", "", "The University of Texas at El Paso"], ["Rodriguez", "Laura M.", "", "The University of Texas at El Paso"], ["Urbina", "Rebecca", "", "The University of Texas at El Paso"], ["Hossain", "M. Shahriar", "", "The University of Texas at El Paso"]]}, {"id": "1606.07767", "submitter": "Dimitri Nowicki", "authors": "Artem Chernodub and Dimitri Nowicki", "title": "Sampling-based Gradient Regularization for Capturing Long-Term\n  Dependencies in Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vanishing (and exploding) gradients effect is a common problem for recurrent\nneural networks with nonlinear activation functions which use backpropagation\nmethod for calculation of derivatives. Deep feedforward neural networks with\nmany hidden layers also suffer from this effect. In this paper we propose a\nnovel universal technique that makes the norm of the gradient stay in the\nsuitable range. We construct a way to estimate a contribution of each training\nexample to the norm of the long-term components of the target function s\ngradient. Using this subroutine we can construct mini-batches for the\nstochastic gradient descent (SGD) training that leads to high performance and\naccuracy of the trained network even for very complex tasks. We provide a\nstraightforward mathematical estimation of minibatch s impact on for the\ngradient norm and prove its correctness theoretically. To check our framework\nexperimentally we use some special synthetic benchmarks for testing RNNs on\nability to capture long-term dependencies. Our network can detect links between\nevents in the (temporal) sequence at the range approx. 100 and longer.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jun 2016 17:31:02 GMT"}, {"version": "v2", "created": "Tue, 31 Jan 2017 21:30:29 GMT"}, {"version": "v3", "created": "Mon, 13 Feb 2017 21:25:26 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Chernodub", "Artem", ""], ["Nowicki", "Dimitri", ""]]}, {"id": "1606.07786", "submitter": "Jonathan Binas", "authors": "Jonathan Binas, Daniel Neil, Giacomo Indiveri, Shih-Chii Liu, Michael\n  Pfeiffer", "title": "Precise neural network computation with imprecise analog devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The operations used for neural network computation map favorably onto simple\nanalog circuits, which outshine their digital counterparts in terms of\ncompactness and efficiency. Nevertheless, such implementations have been\nlargely supplanted by digital designs, partly because of device mismatch\neffects due to material and fabrication imperfections. We propose a framework\nthat exploits the power of deep learning to compensate for this mismatch by\nincorporating the measured device variations as constraints in the neural\nnetwork training process. This eliminates the need for mismatch minimization\nstrategies and allows circuit complexity and power-consumption to be reduced to\na minimum. Our results, based on large-scale simulations as well as a prototype\nVLSI chip implementation indicate a processing efficiency comparable to current\nstate-of-art digital implementations. This method is suitable for future\ntechnology based on nanodevices with large variability, such as memristive\narrays.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 18:32:43 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 06:27:05 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Binas", "Jonathan", ""], ["Neil", "Daniel", ""], ["Indiveri", "Giacomo", ""], ["Liu", "Shih-Chii", ""], ["Pfeiffer", "Michael", ""]]}, {"id": "1606.07947", "submitter": "Yoon Kim", "authors": "Yoon Kim, Alexander M. Rush", "title": "Sequence-Level Knowledge Distillation", "comments": "EMNLP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) offers a novel alternative formulation of\ntranslation that is potentially simpler than statistical approaches. However to\nreach competitive performance, NMT models need to be exceedingly large. In this\npaper we consider applying knowledge distillation approaches (Bucila et al.,\n2006; Hinton et al., 2015) that have proven successful for reducing the size of\nneural models in other domains to the problem of NMT. We demonstrate that\nstandard knowledge distillation applied to word-level prediction can be\neffective for NMT, and also introduce two novel sequence-level versions of\nknowledge distillation that further improve performance, and somewhat\nsurprisingly, seem to eliminate the need for beam search (even when applied on\nthe original teacher model). Our best student model runs 10 times faster than\nits state-of-the-art teacher with little loss in performance. It is also\nsignificantly better than a baseline model trained without knowledge\ndistillation: by 4.2/1.7 BLEU with greedy decoding/beam search. Applying weight\npruning on top of knowledge distillation results in a student model that has 13\ntimes fewer parameters than the original teacher model, with a decrease of 0.4\nBLEU.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2016 18:16:39 GMT"}, {"version": "v2", "created": "Thu, 4 Aug 2016 17:24:18 GMT"}, {"version": "v3", "created": "Mon, 8 Aug 2016 15:02:54 GMT"}, {"version": "v4", "created": "Thu, 22 Sep 2016 01:17:12 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Kim", "Yoon", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1606.07953", "submitter": "Abhyuday Jagannatha", "authors": "Abhyuday Jagannatha, Hong Yu", "title": "Bidirectional Recurrent Neural Networks for Medical Event Detection in\n  Electronic Health Records", "comments": "In proceedings of NAACL HLT 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence labeling for extraction of medical events and their attributes from\nunstructured text in Electronic Health Record (EHR) notes is a key step towards\nsemantic understanding of EHRs. It has important applications in health\ninformatics including pharmacovigilance and drug surveillance. The state of the\nart supervised machine learning models in this domain are based on Conditional\nRandom Fields (CRFs) with features calculated from fixed context windows. In\nthis application, we explored various recurrent neural network frameworks and\nshow that they significantly outperformed the CRF models.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jun 2016 19:46:28 GMT"}, {"version": "v2", "created": "Tue, 12 Jul 2016 17:10:38 GMT"}], "update_date": "2016-07-13", "authors_parsed": [["Jagannatha", "Abhyuday", ""], ["Yu", "Hong", ""]]}, {"id": "1606.08061", "submitter": "Pascal Vincent", "authors": "Pascal Vincent, Alexandre de Br\\'ebisson, Xavier Bouthillier", "title": "Exact gradient updates in time independent of output size for the\n  spherical loss family", "comments": "Expanded journal version of our NIPS-2015 conference paper\n  arXiv:1412.7091 with full algorithm generalized to the spherical family", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important class of problems involves training deep neural networks with\nsparse prediction targets of very high dimension D. These occur naturally in\ne.g. neural language models or the learning of word-embeddings, often posed as\npredicting the probability of next words among a vocabulary of size D (e.g.\n200,000). Computing the equally large, but typically non-sparse D-dimensional\noutput vector from a last hidden layer of reasonable dimension d (e.g. 500)\nincurs a prohibitive O(Dd) computational cost for each example, as does\nupdating the $D \\times d$ output weight matrix and computing the gradient\nneeded for backpropagation to previous layers. While efficient handling of\nlarge sparse network inputs is trivial, the case of large sparse targets is\nnot, and has thus so far been sidestepped with approximate alternatives such as\nhierarchical softmax or sampling-based approximations during training. In this\nwork we develop an original algorithmic approach which, for a family of loss\nfunctions that includes squared error and spherical softmax, can compute the\nexact loss, gradient update for the output weights, and gradient for\nbackpropagation, all in $O(d^{2})$ per example instead of $O(Dd)$, remarkably\nwithout ever computing the D-dimensional output. The proposed algorithm yields\na speedup of up to $D/4d$ i.e. two orders of magnitude for typical sizes, for\nthat critical part of the computations that often dominates the training time\nin this kind of network architecture.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jun 2016 17:57:36 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Vincent", "Pascal", ""], ["de Br\u00e9bisson", "Alexandre", ""], ["Bouthillier", "Xavier", ""]]}, {"id": "1606.08165", "submitter": "Hesham Mostafa", "authors": "Hesham Mostafa", "title": "Supervised learning based on temporal coding in spiking neural networks", "comments": "Extended the discussion and introduction. Clarified the training\n  parameters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent training techniques are remarkably successful in training\nanalog-valued artificial neural networks (ANNs). Such training techniques,\nhowever, do not transfer easily to spiking networks due to the spike generation\nhard non-linearity and the discrete nature of spike communication. We show that\nin a feedforward spiking network that uses a temporal coding scheme where\ninformation is encoded in spike times instead of spike rates, the network\ninput-output relation is differentiable almost everywhere. Moreover, this\nrelation is piece-wise linear after a transformation of variables. Methods for\ntraining ANNs thus carry directly to the training of such spiking networks as\nwe show when training on the permutation invariant MNIST task. In contrast to\nrate-based spiking networks that are often used to approximate the behavior of\nANNs, the networks we present spike much more sparsely and their behavior can\nnot be directly approximated by conventional ANNs. Our results highlight a new\napproach for controlling the behavior of spiking networks with realistic\ntemporal dynamics, opening up the potential for using these networks to process\nspike patterns with complex temporal information.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 08:58:29 GMT"}, {"version": "v2", "created": "Wed, 16 Aug 2017 16:15:20 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Mostafa", "Hesham", ""]]}, {"id": "1606.08282", "submitter": "Hamid Dadkhahi", "authors": "Hamid Dadkhahi and Marco F. Duarte and Benjamin Marlin", "title": "Out-of-Sample Extension for Dimensionality Reduction of Noisy Time\n  Series", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2017.2735189", "report-no": null, "categories": "stat.ML cs.CG cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an out-of-sample extension framework for a global\nmanifold learning algorithm (Isomap) that uses temporal information in\nout-of-sample points in order to make the embedding more robust to noise and\nartifacts. Given a set of noise-free training data and its embedding, the\nproposed framework extends the embedding for a noisy time series. This is\nachieved by adding a spatio-temporal compactness term to the optimization\nobjective of the embedding. To the best of our knowledge, this is the first\nmethod for out-of-sample extension of manifold embeddings that leverages timing\ninformation available for the extension set. Experimental results demonstrate\nthat our out-of-sample extension algorithm renders a more robust and accurate\nembedding of sequentially ordered image data in the presence of various noise\nand artifacts when compared to other timing-aware embeddings. Additionally, we\nshow that an out-of-sample extension framework based on the proposed algorithm\noutperforms the state of the art in eye-gaze estimation.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 14:03:40 GMT"}, {"version": "v2", "created": "Thu, 19 Jan 2017 20:13:17 GMT"}, {"version": "v3", "created": "Sat, 29 Jul 2017 01:37:40 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Dadkhahi", "Hamid", ""], ["Duarte", "Marco F.", ""], ["Marlin", "Benjamin", ""]]}, {"id": "1606.08366", "submitter": "Christopher H Bennett", "authors": "Christopher H. Bennett, Selina La Barbera, Adrien F. Vincent, Fabien\n  Alibart, and Damien Querlioz", "title": "Exploiting the Short-term to Long-term Plasticity Transition in\n  Memristive Nanodevice Learning Architectures", "comments": "9 pages, 8 figures. To be presented July 2016 at the International\n  Joint Conference on Neural Networks (IJCNN), Vancouver, BC, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memristive nanodevices offer new frontiers for computing systems that unite\narithmetic and memory operations on-chip. Here, we explore the integration of\nelectrochemical metallization cell (ECM) nanodevices with tunable filamentary\nswitching in nanoscale learning systems. Such devices offer a natural\ntransition between short-term plasticity (STP) and long-term plasticity (LTP).\nIn this work, we show that this property can be exploited to efficiently solve\nnoisy classification tasks. A single crossbar learning scheme is first\nintroduced and evaluated. Perfect classification is possible only for simple\ninput patterns, within critical timing parameters, and when device variability\nis weak. To overcome these limitations, a dual-crossbar learning system partly\ninspired by the extreme learning machine (ELM) approach is then introduced.\nThis approach outperforms a conventional ELM-inspired system when the first\nlayer is imprinted before training and testing, and especially so when\nvariability in device timing evolution is considered: variability is therefore\ntransformed from an issue to a feature. In attempting to classify the MNIST\ndatabase under the same conditions, conventional ELM obtains 84%\nclassification, the imprinted, uniform device system obtains 88%\nclassification, and the imprinted, variable device system reaches 92%\nclassification. We discuss benefits and drawbacks of both systems in terms of\nenergy, complexity, area imprint, and speed. All these results highlight that\ntuning and exploiting intrinsic device timing parameters may be of central\ninterest to future bio-inspired approximate computing systems.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 17:10:30 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Bennett", "Christopher H.", ""], ["La Barbera", "Selina", ""], ["Vincent", "Adrien F.", ""], ["Alibart", "Fabien", ""], ["Querlioz", "Damien", ""]]}, {"id": "1606.08571", "submitter": "Yang Lu", "authors": "Tian Han, Yang Lu, Song-Chun Zhu, and Ying Nian Wu", "title": "Alternating Back-Propagation for Generator Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an alternating back-propagation algorithm for learning\nthe generator network model. The model is a non-linear generalization of factor\nanalysis. In this model, the mapping from the continuous latent factors to the\nobserved signal is parametrized by a convolutional neural network. The\nalternating back-propagation algorithm iterates the following two steps: (1)\nInferential back-propagation, which infers the latent factors by Langevin\ndynamics or gradient descent. (2) Learning back-propagation, which updates the\nparameters given the inferred latent factors by gradient descent. The gradient\ncomputations in both steps are powered by back-propagation, and they share most\nof their code in common. We show that the alternating back-propagation\nalgorithm can learn realistic generator models of natural images, video\nsequences, and sounds. Moreover, it can also be used to learn from incomplete\nor indirect training data.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 06:46:05 GMT"}, {"version": "v2", "created": "Sat, 2 Jul 2016 15:11:00 GMT"}, {"version": "v3", "created": "Thu, 15 Sep 2016 04:38:01 GMT"}, {"version": "v4", "created": "Tue, 6 Dec 2016 04:04:19 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Han", "Tian", ""], ["Lu", "Yang", ""], ["Zhu", "Song-Chun", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1606.09163", "submitter": "Akash Kumar Dhaka", "authors": "Akash Kumar Dhaka and Giampiero Salvi", "title": "Optimising The Input Window Alignment in CD-DNN Based Phoneme\n  Recognition for Low Latency Processing", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a systematic analysis on the performance of a phonetic recogniser\nwhen the window of input features is not symmetric with respect to the current\nframe. The recogniser is based on Context Dependent Deep Neural Networks\n(CD-DNNs) and Hidden Markov Models (HMMs). The objective is to reduce the\nlatency of the system by reducing the number of future feature frames required\nto estimate the current output. Our tests performed on the TIMIT database show\nthat the performance does not degrade when the input window is shifted up to 5\nframes in the past compared to common practice (no future frame). This\ncorresponds to improving the latency by 50 ms in our settings. Our tests also\nshow that the best results are not obtained with the symmetric window commonly\nemployed, but with an asymmetric window with eight past and two future context\nframes, although this observation should be confirmed on other data sets. The\nreduction in latency suggested by our results is critical for specific\napplications such as real-time lip synchronisation for tele-presence, but may\nalso be beneficial in general applications to improve the lag in human-machine\nspoken interaction.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 15:51:44 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Dhaka", "Akash Kumar", ""], ["Salvi", "Giampiero", ""]]}, {"id": "1606.09187", "submitter": "Wojciech Samek", "authors": "Jing Yu Koh and Wojciech Samek and Klaus-Robert M\\\"uller and Alexander\n  Binder", "title": "Object Boundary Detection and Classification with Image-level Labels", "comments": "12 pages, 2 figures, accepted for GCPR 2017 - 39th German Conference\n  on Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic boundary and edge detection aims at simultaneously detecting object\nedge pixels in images and assigning class labels to them. Systematic training\nof predictors for this task requires the labeling of edges in images which is a\nparticularly tedious task. We propose a novel strategy for solving this task,\nwhen pixel-level annotations are not available, performing it in an almost\nzero-shot manner by relying on conventional whole image neural net classifiers\nthat were trained using large bounding boxes. Our method performs the following\ntwo steps at test time. Firstly it predicts the class labels by applying the\ntrained whole image network to the test images. Secondly, it computes\npixel-wise scores from the obtained predictions by applying backprop gradients\nas well as recent visualization algorithms such as deconvolution and layer-wise\nrelevance propagation. We show that high pixel-wise scores are indicative for\nthe location of semantic boundaries, which suggests that the semantic boundary\nproblem can be approached without using edge labels during the training phase.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 17:08:58 GMT"}, {"version": "v2", "created": "Mon, 4 Jul 2016 17:13:43 GMT"}, {"version": "v3", "created": "Sun, 25 Jun 2017 12:50:55 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Koh", "Jing Yu", ""], ["Samek", "Wojciech", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Binder", "Alexander", ""]]}, {"id": "1606.09274", "submitter": "Abigail See", "authors": "Abigail See, Minh-Thang Luong, Christopher D. Manning", "title": "Compression of Neural Machine Translation Models via Pruning", "comments": "Accepted to CoNLL 2016. 9 pages plus references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT), like many other deep learning domains,\ntypically suffers from over-parameterization, resulting in large storage sizes.\nThis paper examines three simple magnitude-based pruning schemes to compress\nNMT models, namely class-blind, class-uniform, and class-distribution, which\ndiffer in terms of how pruning thresholds are computed for the different\nclasses of weights in the NMT architecture. We demonstrate the efficacy of\nweight pruning as a compression technique for a state-of-the-art NMT system. We\nshow that an NMT model with over 200 million parameters can be pruned by 40%\nwith very little performance loss as measured on the WMT'14 English-German\ntranslation task. This sheds light on the distribution of redundancy in the NMT\narchitecture. Our main result is that with retraining, we can recover and even\nsurpass the original performance with an 80%-pruned model.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 20:36:23 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["See", "Abigail", ""], ["Luong", "Minh-Thang", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1606.09470", "submitter": "Michael Bukatin", "authors": "Michael Bukatin and Steve Matthews and Andrey Radul", "title": "Programming Patterns in Dataflow Matrix Machines and Generalized\n  Recurrent Neural Nets", "comments": "13 pages (v2 - update references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dataflow matrix machines arise naturally in the context of synchronous\ndataflow programming with linear streams. They can be viewed as a rather\npowerful generalization of recurrent neural networks. Similarly to recurrent\nneural networks, large classes of dataflow matrix machines are described by\nmatrices of numbers, and therefore dataflow matrix machines can be synthesized\nby computing their matrices. At the same time, the evidence is fairly strong\nthat dataflow matrix machines have sufficient expressive power to be a\nconvenient general-purpose programming platform. Because of the network nature\nof this platform, programming patterns often correspond to patterns of\nconnectivity in the generalized recurrent neural networks understood as\nprograms. This paper explores a variety of such programming patterns.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 13:05:03 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 20:00:11 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Bukatin", "Michael", ""], ["Matthews", "Steve", ""], ["Radul", "Andrey", ""]]}]