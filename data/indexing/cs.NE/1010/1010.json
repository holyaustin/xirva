[{"id": "1010.0771", "submitter": "Imen Harbaoui Dridi", "authors": "Imen Harbaoui Dridi (ACS), Ryan Kammarti (ACS), Mekki Ksouri (ACS),\n  Pierre Borne (LAGIS)", "title": "Genetic Algorithm for Mulicriteria Optimization of a Multi-Pickup and\n  Delivery Problem with Time Windows", "comments": null, "journal-ref": "INCOM'09 IFAC, Russie, F\\'ed\\'eration De (2009)", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In This paper we present a genetic algorithm for mulicriteria optimization of\na multipickup and delivery problem with time windows (m-PDPTW). The m-PDPTW is\nan optimization vehicles routing problem which must meet requests for transport\nbetween suppliers and customers satisfying precedence, capacity and time\nconstraints. This paper purposes a brief literature review of the PDPTW,\npresent an approach based on genetic algorithms and Pareto dominance method to\ngive a set of satisfying solutions to the m-PDPTW minimizing total travel cost,\ntotal tardiness time and the vehicles number.\n", "versions": [{"version": "v1", "created": "Tue, 5 Oct 2010 06:01:24 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2013 07:35:40 GMT"}], "update_date": "2013-02-04", "authors_parsed": [["Dridi", "Imen Harbaoui", "", "ACS"], ["Kammarti", "Ryan", "", "ACS"], ["Ksouri", "Mekki", "", "ACS"], ["Borne", "Pierre", "", "LAGIS"]]}, {"id": "1010.0979", "submitter": "Imen Harbaoui Dridi", "authors": "Imen Harbaoui Dridi (LAGIS, ACS), Ryan Kammarti (ACS), Pierre Borne\n  (LAGIS), Mekki Ksouri (ACS)", "title": "Un Algorithme g\\'en\\'etique pour le probl\\`eme de ramassage et de\n  livraison avec fen\\^etres de temps \\`a plusieurs v\\'ehicules", "comments": null, "journal-ref": "CIFA, Roumanie (2008)", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The PDPTW is an optimization vehicles routing problem which must meet\nrequests for transport between suppliers and customers satisfying precedence,\ncapacity and time constraints. We present, in this paper, a genetic algorithm\nfor optimization of a multi pickup and delivery problem with time windows\n(m-PDPTW). We purposes a brief literature review of the PDPTW, present an\napproach based on genetic algorithms to give a satisfying solution to the\nm-PDPTW minimizing the total travel cost.\n", "versions": [{"version": "v1", "created": "Tue, 5 Oct 2010 18:54:43 GMT"}], "update_date": "2010-10-06", "authors_parsed": [["Dridi", "Imen Harbaoui", "", "LAGIS, ACS"], ["Kammarti", "Ryan", "", "ACS"], ["Borne", "Pierre", "", "LAGIS"], ["Ksouri", "Mekki", "", "ACS"]]}, {"id": "1010.0980", "submitter": "Imen Harbaoui Dridi", "authors": "Imen Harbaoui Dridi (LAGIS, ACS), Ryan Kammarti (ACS), Mekki Ksouri\n  (ACS), Pierre Borne (LAGIS)", "title": "Approche Multicrit\\`ere pour le Probl\\`eme de Ramassage et de Livraison\n  avec Fen\\^etres de Temps \\`a Plusieurs V\\'ehicules", "comments": null, "journal-ref": "LT IEEE 2009, Tunisie (2009)", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the transport goods problem occupies an important place in the\neconomic life of modern societies. The pickup and delivery problem with time\nwindows (PDPTW) is one of the problems which a large part of the research was\ninterested. In this paper, we present a a brief literature review of the VRP\nand the PDPTW, propose our multicriteria approach based on genetic algorithms\nwhich allows minimize the compromise between the vehicles number, the total\ntardiness time and the total travel cost. And this, by treating the case where\na customer can have multiple suppliers and one supplier can have multiple\ncustomers\n", "versions": [{"version": "v1", "created": "Tue, 5 Oct 2010 18:55:13 GMT"}], "update_date": "2010-10-06", "authors_parsed": [["Dridi", "Imen Harbaoui", "", "LAGIS, ACS"], ["Kammarti", "Ryan", "", "ACS"], ["Ksouri", "Mekki", "", "ACS"], ["Borne", "Pierre", "", "LAGIS"]]}, {"id": "1010.1429", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr, Thomas Jansen, Dirk Sudholt, Carola Winzen, Christine\n  Zarges", "title": "Optimizing Monotone Functions Can Be Difficult", "comments": "Preliminary version appeared at PPSN XI. Compared to version 1, a\n  small bug in the constants was fixed ($\\gamma$ is slightly larger now, thus\n  ensuring that $\\gamma$ is now strictly larger than $\\rho$ in Lemma 5)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extending previous analyses on function classes like linear functions, we\nanalyze how the simple (1+1) evolutionary algorithm optimizes pseudo-Boolean\nfunctions that are strictly monotone. Contrary to what one would expect, not\nall of these functions are easy to optimize. The choice of the constant $c$ in\nthe mutation probability $p(n) = c/n$ can make a decisive difference.\n  We show that if $c < 1$, then the (1+1) evolutionary algorithm finds the\noptimum of every such function in $\\Theta(n \\log n)$ iterations. For $c=1$, we\ncan still prove an upper bound of $O(n^{3/2})$. However, for $c > 33$, we\npresent a strictly monotone function such that the (1+1) evolutionary algorithm\nwith overwhelming probability does not find the optimum within $2^{\\Omega(n)}$\niterations. This is the first time that we observe that a constant factor\nchange of the mutation probability changes the run-time by more than constant\nfactors.\n", "versions": [{"version": "v1", "created": "Thu, 7 Oct 2010 13:21:28 GMT"}, {"version": "v2", "created": "Thu, 14 Oct 2010 16:17:43 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Doerr", "Benjamin", ""], ["Jansen", "Thomas", ""], ["Sudholt", "Dirk", ""], ["Winzen", "Carola", ""], ["Zarges", "Christine", ""]]}, {"id": "1010.1888", "submitter": "Ilknur Icke", "authors": "Ilknur Icke and Andrew Rosenberg", "title": "Multi-Objective Genetic Programming Projection Pursuit for Exploratory\n  Data Modeling", "comments": "Submitted to the New York Academy of Sciences, 5th Annual Machine\n  Learning Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For classification problems, feature extraction is a crucial process which\naims to find a suitable data representation that increases the performance of\nthe machine learning algorithm. According to the curse of dimensionality\ntheorem, the number of samples needed for a classification task increases\nexponentially as the number of dimensions (variables, features) increases. On\nthe other hand, it is costly to collect, store and process data. Moreover,\nirrelevant and redundant features might hinder classifier performance. In\nexploratory analysis settings, high dimensionality prevents the users from\nexploring the data visually. Feature extraction is a two-step process: feature\nconstruction and feature selection. Feature construction creates new features\nbased on the original features and feature selection is the process of\nselecting the best features as in filter, wrapper and embedded methods.\n  In this work, we focus on feature construction methods that aim to decrease\ndata dimensionality for visualization tasks. Various linear (such as principal\ncomponents analysis (PCA), multiple discriminants analysis (MDA), exploratory\nprojection pursuit) and non-linear (such as multidimensional scaling (MDS),\nmanifold learning, kernel PCA/LDA, evolutionary constructive induction)\ntechniques have been proposed for dimensionality reduction. Our algorithm is an\nadaptive feature extraction method which consists of evolutionary constructive\ninduction for feature construction and a hybrid filter/wrapper method for\nfeature selection.\n", "versions": [{"version": "v1", "created": "Sun, 10 Oct 2010 02:34:22 GMT"}], "update_date": "2010-10-12", "authors_parsed": [["Icke", "Ilknur", ""], ["Rosenberg", "Andrew", ""]]}, {"id": "1010.3325", "submitter": "Arun Dua Dr.", "authors": "Arun Dua", "title": "Wireless Sensor Network based Future of Telecom Applications", "comments": "8 pages,4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A system and method for enabling human beings to communicate by way of their\nmonitored brain activity. The brain activity of an individual is monitored and\ntransmitted to a remote location (e.g. by satellite). At the remote location,\nthe monitored brain activity is compared with pre-recorded normalized brain\nactivity curves, waveforms, or patterns to determine if a match or substantial\nmatch is found. If such a match is found, then the computer at the remote\nlocation determines that the individual was attempting to communicate the word,\nphrase, or thought corresponding to the matched stored normalized signal.\n", "versions": [{"version": "v1", "created": "Sat, 16 Oct 2010 06:16:08 GMT"}], "update_date": "2010-10-19", "authors_parsed": [["Dua", "Arun", ""]]}, {"id": "1010.4138", "submitter": "Gabor Szirtes", "authors": "Andr\\'as L\\H{o}rincz, Zsolt Palotai and G\\'abor Szirtes", "title": "Sparse and silent coding in neural circuits", "comments": "19 pages, 2 figures and 4 tables with pseudocodes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse coding algorithms are about finding a linear basis in which signals\ncan be represented by a small number of active (non-zero) coefficients. Such\ncoding has many applications in science and engineering and is believed to play\nan important role in neural information processing. However, due to the\ncomputational complexity of the task, only approximate solutions provide the\nrequired efficiency (in terms of time). As new results show, under particular\nconditions there exist efficient solutions by minimizing the magnitude of the\ncoefficients (`$l_1$-norm') instead of minimizing the size of the active subset\nof features (`$l_0$-norm'). Straightforward neural implementation of these\nsolutions is not likely, as they require \\emph{a priori} knowledge of the\nnumber of active features. Furthermore, these methods utilize iterative\nre-evaluation of the reconstruction error, which in turn implies that final\nsparse forms (featuring `population sparseness') can only be reached through\nthe formation of a series of non-sparse representations, which is in contrast\nwith the overall sparse functioning of the neural systems (`lifetime\nsparseness'). In this article we present a novel algorithm which integrates our\nprevious `$l_0$-norm' model on spike based probabilistic optimization for\nsparse coding with ideas coming from novel `$l_1$-norm' solutions.\n  The resulting algorithm allows neurally plausible implementation and does not\nrequire an exactly defined sparseness level thus it is suitable for\nrepresenting natural stimuli with a varying number of features. We also\ndemonstrate that the combined method significantly extends the domain where\noptimal solutions can be found by `$l_1$-norm' based algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 20 Oct 2010 09:29:03 GMT"}], "update_date": "2016-08-14", "authors_parsed": [["L\u0151rincz", "Andr\u00e1s", ""], ["Palotai", "Zsolt", ""], ["Szirtes", "G\u00e1bor", ""]]}, {"id": "1010.4517", "submitter": "Jake Bouvrie", "authors": "Jake Bouvrie, Jean-Jacques Slotine", "title": "Synchronization and Redundancy: Implications for Robustness of Neural\n  Learning and Decision Making", "comments": "Preprint, accepted for publication in Neural Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning and decision making in the brain are key processes critical to\nsurvival, and yet are processes implemented by non-ideal biological building\nblocks which can impose significant error. We explore quantitatively how the\nbrain might cope with this inherent source of error by taking advantage of two\nubiquitous mechanisms, redundancy and synchronization. In particular we\nconsider a neural process whose goal is to learn a decision function by\nimplementing a nonlinear gradient dynamics. The dynamics, however, are assumed\nto be corrupted by perturbations modeling the error which might be incurred due\nto limitations of the biology, intrinsic neuronal noise, and imperfect\nmeasurements. We show that error, and the associated uncertainty surrounding a\nlearned solution, can be controlled in large part by trading off\nsynchronization strength among multiple redundant neural systems against the\nnoise amplitude. The impact of the coupling between such redundant systems is\nquantified by the spectrum of the network Laplacian, and we discuss the role of\nnetwork topology in synchronization and in reducing the effect of noise. A\nrange of situations in which the mechanisms we model arise in brain science are\ndiscussed, and we draw attention to experimental evidence suggesting that\ncortical circuits capable of implementing the computations of interest here can\nbe found on several scales. Finally, simulations comparing theoretical bounds\nto the relevant empirical quantities show that the theoretical estimates we\nderive can be tight.\n", "versions": [{"version": "v1", "created": "Thu, 21 Oct 2010 16:34:43 GMT"}, {"version": "v2", "created": "Sat, 16 Apr 2011 17:01:04 GMT"}], "update_date": "2011-04-19", "authors_parsed": [["Bouvrie", "Jake", ""], ["Slotine", "Jean-Jacques", ""]]}, {"id": "1010.6178", "submitter": "Sander Bohte", "authors": "Sander M. Bohte and Jaldert O. Rombouts", "title": "Fractionally Predictive Spiking Neurons", "comments": "13 pages, 5 figures, in Advances in Neural Information Processing\n  2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent experimental work has suggested that the neural firing rate can be\ninterpreted as a fractional derivative, at least when signal variation induces\nneural adaptation. Here, we show that the actual neural spike-train itself can\nbe considered as the fractional derivative, provided that the neural signal is\napproximated by a sum of power-law kernels. A simple standard thresholding\nspiking neuron suffices to carry out such an approximation, given a suitable\nrefractory response. Empirically, we find that the online approximation of\nsignals with a sum of power-law kernels is beneficial for encoding signals with\nslowly varying components, like long-memory self-similar signals. For such\nsignals, the online power-law kernel approximation typically required less than\nhalf the number of spikes for similar SNR as compared to sums of similar but\nexponentially decaying kernels. As power-law kernels can be accurately\napproximated using sums or cascades of weighted exponentials, we demonstrate\nthat the corresponding decoding of spike-trains by a receiving neuron allows\nfor natural and transparent temporal signal filtering by tuning the weights of\nthe decoding kernel.\n", "versions": [{"version": "v1", "created": "Fri, 29 Oct 2010 10:48:25 GMT"}], "update_date": "2010-11-01", "authors_parsed": [["Bohte", "Sander M.", ""], ["Rombouts", "Jaldert O.", ""]]}]