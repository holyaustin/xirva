[{"id": "2007.00449", "submitter": "Shahryar Rahnamayan", "authors": "Mostapha Kalami Heris and Shahryar Rahnamayan", "title": "Multi-objective Optimal Control of Dynamic Integrated Model of Climate\n  and Economy: Evolution in Action", "comments": "8 pages, 6 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.NE cs.SY eess.SY q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the widely used models for studying economics of climate change is the\nDynamic Integrated model of Climate and Economy (DICE), which has been\ndeveloped by Professor William Nordhaus, one of the laureates of the 2018 Nobel\nMemorial Prize in Economic Sciences. Originally a single-objective optimal\ncontrol problem has been defined on DICE dynamics, which is aimed to maximize\nthe social welfare. In this paper, a bi-objective optimal control problem\ndefined on DICE model, objectives of which are maximizing social welfare and\nminimizing the temperature deviation of atmosphere. This multi-objective\noptimal control problem solved using Non-Dominated Sorting Genetic Algorithm II\n(NSGA-II) also it is compared to previous works on single-objective version of\nthe problem. The resulting Pareto front rediscovers the previous results and\ngeneralizes to a wide range of non-dominant solutions to minimize the global\ntemperature deviation while optimizing the economic welfare. The previously\nused single-objective approach is unable to create such a variety of\npossibilities, hence, its offered solution is limited in vision and reachable\nperformance. Beside this, resulting Pareto-optimal set reveals the fact that\ntemperature deviation cannot go below a certain lower limit, unless we have\nsignificant technology advancement or positive change in global conditions.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 20:41:34 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Heris", "Mostapha Kalami", ""], ["Rahnamayan", "Shahryar", ""]]}, {"id": "2007.00487", "submitter": "Timoth\\'ee Lesort", "authors": "Timoth\\'ee Lesort", "title": "Continual Learning: Tackling Catastrophic Forgetting in Deep Neural\n  Networks with Replay Processes", "comments": "Doctoral Thesis Manuscript, Institut Polytechnique de Paris (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans learn all their life long. They accumulate knowledge from a sequence\nof learning experiences and remember the essential concepts without forgetting\nwhat they have learned previously. Artificial neural networks struggle to learn\nsimilarly. They often rely on data rigorously preprocessed to learn solutions\nto specific problems such as classification or regression. In particular, they\nforget their past learning experiences if trained on new ones. Therefore,\nartificial neural networks are often inept to deal with real-life settings such\nas an autonomous-robot that has to learn on-line to adapt to new situations and\novercome new problems without forgetting its past learning-experiences.\nContinual learning (CL) is a branch of machine learning addressing this type of\nproblem. Continual algorithms are designed to accumulate and improve knowledge\nin a curriculum of learning-experiences without forgetting. In this thesis, we\npropose to explore continual algorithms with replay processes. Replay processes\ngather together rehearsal methods and generative replay methods. Generative\nReplay consists of regenerating past learning experiences with a generative\nmodel to remember them. Rehearsal consists of saving a core-set of samples from\npast learning experiences to rehearse them later. The replay processes make\npossible a compromise between optimizing the current learning objective and the\npast ones enabling learning without forgetting in sequences of tasks settings.\nWe show that they are very promising methods for continual learning. Notably,\nthey enable the re-evaluation of past data with new knowledge and the\nconfrontation of data from different learning-experiences. We demonstrate their\nability to learn continually through unsupervised learning, supervised learning\nand reinforcement learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 13:44:33 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 13:07:32 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 17:08:29 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Lesort", "Timoth\u00e9e", ""]]}, {"id": "2007.00501", "submitter": "Shengcai Liu", "authors": "Ke Tang, Shengcai Liu, Peng Yang, Xin Yao", "title": "Few-shots Parallel Algorithm Portfolio Construction via Co-evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization, i.e., the ability of solving problem instances that are not\navailable during the system design and development phase, is a critical goal\nfor intelligent systems. A typical way to achieve good generalization is to\nlearn a model from vast data. In the context of heuristic search, such a\nparadigm could be implemented as configuring the parameters of a parallel\nalgorithm portfolio (PAP) based on a set of training problem instances, which\nis often referred to as PAP construction. However, compared to traditional\nmachine learning, PAP construction often suffers from the lack of training\ninstances, and the obtained PAPs may fail to generalize well. This paper\nproposes a novel competitive co-evolution scheme, named Co-Evolution of\nParameterized Search (CEPS), as a remedy to this challenge. By co-evolving a\nconfiguration population and an instance population, CEPS is capable of\nobtaining generalizable PAPs with few training instances. The advantage of CEPS\nin improving generalization is analytically shown in this paper. Two concrete\nalgorithms, namely CEPS-TSP and CEPS-VRPSPDTW, are presented for the Traveling\nSalesman Problem (TSP) and the Vehicle Routing Problem with Simultaneous\nPickup-Delivery and Time Windows (VRPSPDTW), respectively. Experimental results\nshow that CEPS has led to better generalization, and even managed to find new\nbest-known solutions for some instances.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 14:02:19 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 07:12:38 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Tang", "Ke", ""], ["Liu", "Shengcai", ""], ["Yang", "Peng", ""], ["Yao", "Xin", ""]]}, {"id": "2007.00541", "submitter": "Ramses Sala", "authors": "Ramses Sala and Ralf M\\\"uller", "title": "Benchmarking for Metaheuristic Black-Box Optimization: Perspectives and\n  Open Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.PF math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on new optimization algorithms is often funded based on the\nmotivation that such algorithms might improve the capabilities to deal with\nreal-world and industrially relevant optimization challenges. Besides a huge\nvariety of different evolutionary and metaheuristic optimization algorithms,\nalso a large number of test problems and benchmark suites have been developed\nand used for comparative assessments of algorithms, in the context of global,\ncontinuous, and black-box optimization. For many of the commonly used synthetic\nbenchmark problems or artificial fitness landscapes, there are however, no\nmethods available, to relate the resulting algorithm performance assessments to\ntechnologically relevant real-world optimization problems, or vice versa. Also,\nfrom a theoretical perspective, many of the commonly used benchmark problems\nand approaches have little to no generalization value. Based on a mini-review\nof publications with critical comments, advice, and new approaches, this\ncommunication aims to give a constructive perspective on several open\nchallenges and prospective research directions related to systematic and\ngeneralizable benchmarking for black-box optimization.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 15:09:40 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Sala", "Ramses", ""], ["M\u00fcller", "Ralf", ""]]}, {"id": "2007.00864", "submitter": "Shail Dave", "authors": "Shail Dave, Riyadh Baghdadi, Tony Nowatzki, Sasikanth Avancha, Aviral\n  Shrivastava, Baoxin Li", "title": "Hardware Acceleration of Sparse and Irregular Tensor Computations of ML\n  Models: A Survey and Insights", "comments": "Accepted for publication in Proceedings of the IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.CV cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) models are widely used in many important domains. For\nefficiently processing these computational- and memory-intensive applications,\ntensors of these over-parameterized models are compressed by leveraging\nsparsity, size reduction, and quantization of tensors. Unstructured sparsity\nand tensors with varying dimensions yield irregular computation, communication,\nand memory access patterns; processing them on hardware accelerators in a\nconventional manner does not inherently leverage acceleration opportunities.\nThis paper provides a comprehensive survey on the efficient execution of sparse\nand irregular tensor computations of ML models on hardware accelerators. In\nparticular, it discusses enhancement modules in the architecture design and the\nsoftware support; categorizes different hardware designs and acceleration\ntechniques and analyzes them in terms of hardware and execution costs; analyzes\nachievable accelerations for recent DNNs; highlights further opportunities in\nterms of hardware/software/model co-design optimizations (inter/intra-module).\nThe takeaways from this paper include: understanding the key challenges in\naccelerating sparse, irregular-shaped, and quantized tensors; understanding\nenhancements in accelerator systems for supporting their efficient\ncomputations; analyzing trade-offs in opting for a specific design choice for\nencoding, storing, extracting, communicating, computing, and load-balancing the\nnon-zeros; understanding how structured sparsity can improve storage efficiency\nand balance computations; understanding how to compile and map models with\nsparse tensors on the accelerators; understanding recent design trends for\nefficient accelerations and further opportunities.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 04:08:40 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 17:41:44 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Dave", "Shail", ""], ["Baghdadi", "Riyadh", ""], ["Nowatzki", "Tony", ""], ["Avancha", "Sasikanth", ""], ["Shrivastava", "Aviral", ""], ["Li", "Baoxin", ""]]}, {"id": "2007.00886", "submitter": "Qinbing Fu", "authors": "Qinbing Fu and Shigang Yue", "title": "Modelling Drosophila Motion Vision Pathways for Decoding the Direction\n  of Translating Objects Against Cluttered Moving Backgrounds", "comments": "27 pages, 13 figures, been included in a future issue of the journal\n  of Biological Cybernetics", "journal-ref": null, "doi": "10.1007/s00422-020-00841-x", "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decoding the direction of translating objects in front of cluttered moving\nbackgrounds, accurately and efficiently, is still a challenging problem. In\nnature, lightweight and low-powered flying insects apply motion vision to\ndetect a moving target in highly variable environments during flight, which are\nexcellent paradigms to learn motion perception strategies. This paper\ninvestigates the fruit fly \\textit{Drosophila} motion vision pathways and\npresents computational modelling based on cutting-edge physiological\nresearches. The proposed visual system model features bio-plausible ON and OFF\npathways, wide-field horizontal-sensitive (HS) and vertical-sensitive (VS)\nsystems. The main contributions of this research are on two aspects: 1) the\nproposed model articulates the forming of both direction-selective (DS) and\ndirection-opponent (DO) responses, revealed as principal features of motion\nperception neural circuits, in a feed-forward manner; 2) it also shows robust\ndirection selectivity to translating objects in front of cluttered moving\nbackgrounds, via the modelling of spatiotemporal dynamics including combination\nof motion pre-filtering mechanisms and ensembles of local correlators inside\nboth the ON and OFF pathways, which works effectively to suppress irrelevant\nbackground motion or distractors, and to improve the dynamic response.\nAccordingly, the direction of translating objects is decoded as global\nresponses of both the HS and VS systems with positive or negative output\nindicating preferred-direction (PD) or null-direction (ND) translation. The\nexperiments have verified the effectiveness of the proposed neural system\nmodel, and demonstrated its responsive preference to faster-moving,\nhigher-contrast and larger-size targets embedded in cluttered moving\nbackgrounds.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 05:15:31 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Fu", "Qinbing", ""], ["Yue", "Shigang", ""]]}, {"id": "2007.00925", "submitter": "Elena Raponi", "authors": "Elena Raponi, Hao Wang, Mariusz Bujny, Simonetta Boria and Carola\n  Doerr", "title": "High Dimensional Bayesian Optimization Assisted by Principal Component\n  Analysis", "comments": "11 pages, 5 figures, conference paper accepted at PPSN2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimization (BO) is a surrogate-assisted global optimization\ntechnique that has been successfully applied in various fields, e.g., automated\nmachine learning and design optimization. Built upon a so-called\ninfill-criterion and Gaussian Process regression (GPR), the BO technique\nsuffers from a substantial computational complexity and hampered convergence\nrate as the dimension of the search spaces increases. Scaling up BO for\nhigh-dimensional optimization problems remains a challenging task. In this\npaper, we propose to tackle the scalability of BO by hybridizing it with a\nPrincipal Component Analysis (PCA), resulting in a novel PCA-assisted BO\n(PCA-BO) algorithm. Specifically, the PCA procedure learns a linear\ntransformation from all the evaluated points during the run and selects\ndimensions in the transformed space according to the variability of evaluated\npoints. We then construct the GPR model, and the infill-criterion in the space\nspanned by the selected dimensions. We assess the performance of our PCA-BO in\nterms of the empirical convergence rate and CPU time on multi-modal problems\nfrom the COCO benchmark framework. The experimental results show that PCA-BO\ncan effectively reduce the CPU time incurred on high-dimensional problems, and\nmaintains the convergence rate on problems with an adequate global structure.\nPCA-BO therefore provides a satisfactory trade-off between the convergence rate\nand computational efficiency opening new ways to benefit from the strength of\nBO approaches in high dimensional numerical optimization.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 07:03:27 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Raponi", "Elena", ""], ["Wang", "Hao", ""], ["Bujny", "Mariusz", ""], ["Boria", "Simonetta", ""], ["Doerr", "Carola", ""]]}, {"id": "2007.00970", "submitter": "Ettore Randazzo", "authors": "Ettore Randazzo, Eyvind Niklasson, Alexander Mordvintsev", "title": "MPLP: Learning a Message Passing Learning Protocol", "comments": "Code at\n  https://github.com/google-research/self-organising-systems/tree/master/mplp;\n  code base link fixed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel method for learning the weights of an artificial neural\nnetwork - a Message Passing Learning Protocol (MPLP). In MPLP, we abstract\nevery operations occurring in ANNs as independent agents. Each agent is\nresponsible for ingesting incoming multidimensional messages from other agents,\nupdating its internal state, and generating multidimensional messages to be\npassed on to neighbouring agents. We demonstrate the viability of MPLP as\nopposed to traditional gradient-based approaches on simple feed-forward neural\nnetworks, and present a framework capable of generalizing to non-traditional\nneural network architectures. MPLP is meta learned using end-to-end\ngradient-based meta-optimisation. We further discuss the observed properties of\nMPLP and hypothesize its applicability on various fields of deep learning.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 09:03:14 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 10:28:35 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Randazzo", "Ettore", ""], ["Niklasson", "Eyvind", ""], ["Mordvintsev", "Alexander", ""]]}, {"id": "2007.01001", "submitter": "A. K. Qin", "authors": "Ziqiang Li, Hong Pan, Yaping Zhu, A. K. Qin", "title": "PGD-UNet: A Position-Guided Deformable Network for Simultaneous\n  Segmentation of Organs and Tumors", "comments": "Accepted by the 2020 International Joint Conference on Neural\n  Networks (IJCNN 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precise segmentation of organs and tumors plays a crucial role in clinical\napplications. It is a challenging task due to the irregular shapes and various\nsizes of organs and tumors as well as the significant class imbalance between\nthe anatomy of interest (AOI) and the background region. In addition, in most\nsituation tumors and normal organs often overlap in medical images, but current\napproaches fail to delineate both tumors and organs accurately. To tackle such\nchallenges, we propose a position-guided deformable UNet, namely PGD-UNet,\nwhich exploits the spatial deformation capabilities of deformable convolution\nto deal with the geometric transformation of both organs and tumors. Position\ninformation is explicitly encoded into the network to enhance the capabilities\nof deformation. Meanwhile, we introduce a new pooling module to preserve\nposition information lost in conventional max-pooling operation. Besides, due\nto unclear boundaries between different structures as well as the subjectivity\nof annotations, labels are not necessarily accurate for medical image\nsegmentation tasks. It may cause the overfitting of the trained network due to\nlabel noise. To address this issue, we formulate a novel loss function to\nsuppress the influence of potential label noise on the training process. Our\nmethod was evaluated on two challenging segmentation tasks and achieved very\npromising segmentation accuracy in both tasks.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 10:23:57 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Li", "Ziqiang", ""], ["Pan", "Hong", ""], ["Zhu", "Yaping", ""], ["Qin", "A. K.", ""]]}, {"id": "2007.01016", "submitter": "A. K. Qin", "authors": "Boyu Zhang, A. K. Qin, Hong Pan, Timos Sellis", "title": "A Novel DNN Training Framework via Data Sampling and Multi-Task\n  Optimization", "comments": "Accepted by the 2020 International Joint Conference on Neural\n  Networks (IJCNN 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional DNN training paradigms typically rely on one training set and\none validation set, obtained by partitioning an annotated dataset used for\ntraining, namely gross training set, in a certain way. The training set is used\nfor training the model while the validation set is used to estimate the\ngeneralization performance of the trained model as the training proceeds to\navoid over-fitting. There exist two major issues in this paradigm. Firstly, the\nvalidation set may hardly guarantee an unbiased estimate of generalization\nperformance due to potential mismatching with test data. Secondly, training a\nDNN corresponds to solve a complex optimization problem, which is prone to\ngetting trapped into inferior local optima and thus leads to undesired training\nresults. To address these issues, we propose a novel DNN training framework. It\ngenerates multiple pairs of training and validation sets from the gross\ntraining set via random splitting, trains a DNN model of a pre-specified\nstructure on each pair while making the useful knowledge (e.g., promising\nnetwork parameters) obtained from one model training process to be transferred\nto other model training processes via multi-task optimization, and outputs the\nbest, among all trained models, which has the overall best performance across\nthe validation sets from all pairs. The knowledge transfer mechanism featured\nin this new framework can not only enhance training effectiveness by helping\nthe model training process to escape from local optima but also improve on\ngeneralization performance via implicit regularization imposed on one model\ntraining process from other model training processes. We implement the proposed\nframework, parallelize the implementation on a GPU cluster, and apply it to\ntrain several widely used DNN models. Experimental results demonstrate the\nsuperiority of the proposed framework over the conventional training paradigm.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 10:58:57 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Zhang", "Boyu", ""], ["Qin", "A. K.", ""], ["Pan", "Hong", ""], ["Sellis", "Timos", ""]]}, {"id": "2007.01062", "submitter": "Ella Gale", "authors": "Ella M. Gale and Nicholas Martin and Ryan Blything and Anh Nguyen and\n  Jeffrey S. Bowers", "title": "Are there any 'object detectors' in the hidden layers of CNNs trained to\n  identify objects or scenes?", "comments": "Published in Vision Research 2020, 19 pages, 8 figures", "journal-ref": "Vision Research, 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various methods of measuring unit selectivity have been developed with the\naim of better understanding how neural networks work. But the different\nmeasures provide divergent estimates of selectivity, and this has led to\ndifferent conclusions regarding the conditions in which selective object\nrepresentations are learned and the functional relevance of these\nrepresentations. In an attempt to better characterize object selectivity, we\nundertake a comparison of various selectivity measures on a large set of units\nin AlexNet, including localist selectivity, precision, class-conditional mean\nactivity selectivity (CCMAS), network dissection,the human interpretation of\nactivation maximization (AM) images, and standard signal-detection measures. We\nfind that the different measures provide different estimates of object\nselectivity, with precision and CCMAS measures providing misleadingly high\nestimates. Indeed, the most selective units had a poor hit-rate or a high\nfalse-alarm rate (or both) in object classification, making them poor object\ndetectors. We fail to find any units that are even remotely as selective as the\n'grandmother cell' units reported in recurrent neural networks. In order to\ngeneralize these results, we compared selectivity measures on units in VGG-16\nand GoogLeNet trained on the ImageNet or Places-365 datasets that have been\ndescribed as 'object detectors'. Again, we find poor hit-rates and high\nfalse-alarm rates for object classification. We conclude that signal-detection\nmeasures provide a better assessment of single-unit selectivity compared to\ncommon alternative approaches, and that deep convolutional networks of image\nclassification do not learn object detectors in their hidden layers.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 12:33:37 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Gale", "Ella M.", ""], ["Martin", "Nicholas", ""], ["Blything", "Ryan", ""], ["Nguyen", "Anh", ""], ["Bowers", "Jeffrey S.", ""]]}, {"id": "2007.01192", "submitter": "Abdul Mueed Hafiz Dr.", "authors": "Abdul Mueed Hafiz and Mahmoud Hassaballah", "title": "Digit Image Recognition Using an Ensemble of One-Versus-All Deep Network\n  Classifiers", "comments": "ICTCS 2020 Camera Ready Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multiclass deep network classifiers, the burden of classifying samples of\ndifferent classes is put on a single classifier. As the result the optimum\nclassification accuracy is not obtained. Also training times are large due to\nrunning the CNN training on single CPU/GPU. However it is known that using\nensembles of classifiers increases the performance. Also, the training times\ncan be reduced by running each member of the ensemble on a separate processor.\nEnsemble learning has been used in the past for traditional methods to a\nvarying extent and is a hot topic. With the advent of deep learning, ensemble\nlearning has been applied to the former as well. However, an area which is\nunexplored and has potential is One-Versus-All (OVA) deep ensemble learning. In\nthis paper we explore it and show that by using OVA ensembles of deep networks,\nimprovements in performance of deep networks can be obtained. As shown in this\npaper, the classification capability of deep networks can be further increased\nby using an ensemble of binary classification (OVA) deep networks. We implement\na novel technique for the case of digit image recognition and test and evaluate\nit on the same. In the proposed approach, a single OVA deep network classifier\nis dedicated to each category. Subsequently, OVA deep network ensembles have\nbeen investigated. Every network in an ensemble has been trained by an OVA\ntraining technique using the Stochastic Gradient Descent with Momentum\nAlgorithm (SGDMA). For classification of a test sample, the sample is presented\nto each network in the ensemble. After prediction score voting, the network\nwith the largest score is assumed to have classified the sample. The\nexperimentation has been done on the MNIST digit dataset, the USPS+ digit\ndataset, and MATLAB digit image dataset. Our proposed technique outperforms the\nbaseline on digit image recognition for all datasets.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 15:37:39 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2020 13:04:35 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Hafiz", "Abdul Mueed", ""], ["Hassaballah", "Mahmoud", ""]]}, {"id": "2007.01204", "submitter": "Jibin Wu", "authors": "Jibin Wu, Chenglin Xu, Daquan Zhou, Haizhou Li, Kay Chen Tan", "title": "Progressive Tandem Learning for Pattern Recognition with Deep Spiking\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) have shown clear advantages over traditional\nartificial neural networks (ANNs) for low latency and high computational\nefficiency, due to their event-driven nature and sparse communication. However,\nthe training of deep SNNs is not straightforward. In this paper, we propose a\nnovel ANN-to-SNN conversion and layer-wise learning framework for rapid and\nefficient pattern recognition, which is referred to as progressive tandem\nlearning of deep SNNs. By studying the equivalence between ANNs and SNNs in the\ndiscrete representation space, a primitive network conversion method is\nintroduced that takes full advantage of spike count to approximate the\nactivation value of analog neurons. To compensate for the approximation errors\narising from the primitive network conversion, we further introduce a\nlayer-wise learning method with an adaptive training scheduler to fine-tune the\nnetwork weights. The progressive tandem learning framework also allows hardware\nconstraints, such as limited weight precision and fan-in connections, to be\nprogressively imposed during training. The SNNs thus trained have demonstrated\nremarkable classification and regression capabilities on large-scale object\nrecognition, image reconstruction, and speech separation tasks, while requiring\nat least an order of magnitude reduced inference time and synaptic operations\nthan other state-of-the-art SNN implementations. It, therefore, opens up a\nmyriad of opportunities for pervasive mobile and embedded devices with a\nlimited power budget.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 15:38:44 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Wu", "Jibin", ""], ["Xu", "Chenglin", ""], ["Zhou", "Daquan", ""], ["Li", "Haizhou", ""], ["Tan", "Kay Chen", ""]]}, {"id": "2007.01356", "submitter": "Yifei Wang", "authors": "Yifei Wang, Dan Peng, Furui Liu, Zhenguo Li, Zhitang Chen, Jiansheng\n  Yang", "title": "Decoder-free Robustness Disentanglement without (Additional) Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial Training (AT) is proposed to alleviate the adversarial\nvulnerability of machine learning models by extracting only robust features\nfrom the input, which, however, inevitably leads to severe accuracy reduction\nas it discards the non-robust yet useful features. This motivates us to\npreserve both robust and non-robust features and separate them with\ndisentangled representation learning. Our proposed Adversarial Asymmetric\nTraining (AAT) algorithm can reliably disentangle robust and non-robust\nrepresentations without additional supervision on robustness. Empirical results\nshow our method does not only successfully preserve accuracy by combining two\nrepresentations, but also achieve much better disentanglement than previous\nwork.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 19:51:40 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Wang", "Yifei", ""], ["Peng", "Dan", ""], ["Liu", "Furui", ""], ["Li", "Zhenguo", ""], ["Chen", "Zhitang", ""], ["Yang", "Jiansheng", ""]]}, {"id": "2007.01388", "submitter": "Farshid Varno", "authors": "Farshid Varno and Lucas May Petry and Lisa Di Jorio and Stan Matwin", "title": "Learn Faster and Forget Slower via Fast and Stable Task Adaptation", "comments": "52 pages, 15 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Training Deep Neural Networks (DNNs) is still highly time-consuming and\ncompute-intensive. It has been shown that adapting a pretrained model may\nsignificantly accelerate this process. With a focus on classification, we show\nthat current fine-tuning techniques make the pretrained models catastrophically\nforget the transferred knowledge even before anything about the new task is\nlearned. Such rapid knowledge loss undermines the merits of transfer learning\nand may result in a much slower convergence rate compared to when the maximum\namount of knowledge is exploited. We investigate the source of this problem\nfrom different perspectives and to alleviate it, introduce Fast And Stable\nTask-adaptation (FAST), an easy to apply fine-tuning algorithm. The paper\nprovides a novel geometric perspective on how the loss landscape of source and\ntarget tasks are linked in different transfer learning strategies. We\nempirically show that compared to prevailing fine-tuning practices, FAST learns\nthe target task faster and forgets the source task slower.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 21:13:55 GMT"}, {"version": "v2", "created": "Sun, 29 Nov 2020 16:01:50 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Varno", "Farshid", ""], ["Petry", "Lucas May", ""], ["Di Jorio", "Lisa", ""], ["Matwin", "Stan", ""]]}, {"id": "2007.01419", "submitter": "Yimeng Min", "authors": "Yimeng Min", "title": "Persistent Neurons", "comments": "add some new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NN)-based learning algorithms are strongly affected by the\nchoices of initialization and data distribution. Different optimization\nstrategies have been proposed for improving the learning trajectory and finding\na better optima. However, designing improved optimization strategies is a\ndifficult task under the conventional landscape view. Here, we propose\npersistent neurons, a trajectory-based strategy that optimizes the learning\ntask using information from previous converged solutions. More precisely, we\nutilize the end of trajectories and let the parameters explore new landscapes\nby penalizing the model from converging to the previous solutions under the\nsame initialization. Persistent neurons can be regarded as a stochastic\ngradient method with informed bias where individual updates are corrupted by\ndeterministic error terms. Specifically, we show that persistent neurons, under\ncertain data distribution, is able to converge to more optimal solutions while\ninitializations under popular framework find bad local minima. We further\ndemonstrate that persistent neurons helps improve the model's performance under\nboth good and poor initializations. We evaluate the full and partial persistent\nmodel and show it can be used to boost the performance on a range of NN\nstructures, such as AlexNet and residual neural network (ResNet).\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 22:36:49 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 09:16:24 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Min", "Yimeng", ""]]}, {"id": "2007.01556", "submitter": "Bin Wang", "authors": "Bin Wang, Bing Xue, Mengjie Zhang", "title": "Surrogate-assisted Particle Swarm Optimisation for Evolving\n  Variable-length Transferable Blocks for Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks have demonstrated promising performance on\nimage classification tasks, but the manual design process becomes more and more\ncomplex due to the fast depth growth and the increasingly complex topologies of\nconvolutional neural networks. As a result, neural architecture search has\nemerged to automatically design convolutional neural networks that outperform\nhandcrafted counterparts. However, the computational cost is immense, e.g.\n22,400 GPU-days and 2,000 GPU-days for two outstanding neural architecture\nsearch works named NAS and NASNet, respectively, which motivates this work. A\nnew effective and efficient surrogate-assisted particle swarm optimisation\nalgorithm is proposed to automatically evolve convolutional neural networks.\nThis is achieved by proposing a novel surrogate model, a new method of creating\na surrogate dataset and a new encoding strategy to encode variable-length\nblocks of convolutional neural networks, all of which are integrated into a\nparticle swarm optimisation algorithm to form the proposed method. The proposed\nmethod shows its effectiveness by achieving competitive error rates of 3.49% on\nthe CIFAR-10 dataset, 18.49% on the CIFAR-100 dataset, and 1.82% on the SVHN\ndataset. The convolutional neural network blocks are efficiently learned by the\nproposed method from CIFAR-10 within 3 GPU-days due to the acceleration\nachieved by the surrogate model and the surrogate dataset to avoid the training\nof 80.1% of convolutional neural network blocks represented by the particles.\nWithout any further search, the evolved blocks from CIFAR-10 can be\nsuccessfully transferred to CIFAR-100 and SVHN, which exhibits the\ntransferability of the block learned by the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 08:48:21 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Wang", "Bin", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "2007.01575", "submitter": "S\\\"oren Dittmer", "authors": "S\\\"oren Dittmer, Carola-Bibiane Sch\\\"onlieb, Peter Maass", "title": "Ground Truth Free Denoising by Optimal Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE math.FA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a learned unsupervised denoising method for arbitrary types of\ndata, which we explore on images and one-dimensional signals. The training is\nsolely based on samples of noisy data and examples of noise, which --\ncritically -- do not need to come in pairs. We only need the assumption that\nthe noise is independent and additive (although we describe how this can be\nextended). The method rests on a Wasserstein Generative Adversarial Network\nsetting, which utilizes two critics and one generator.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 09:39:25 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Dittmer", "S\u00f6ren", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""], ["Maass", "Peter", ""]]}, {"id": "2007.01807", "submitter": "Hao Wang", "authors": "Hao Wang and Hao He and Dina Katabi", "title": "Continuously Indexed Domain Adaptation", "comments": "Accepted at ICML 2020. Talk:\n  https://www.youtube.com/watch?v=KtZPSCD-WhQ Code and Project Page:\n  https://github.com/hehaodele/CIDA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing domain adaptation focuses on transferring knowledge between domains\nwith categorical indices (e.g., between datasets A and B). However, many tasks\ninvolve continuously indexed domains. For example, in medical applications, one\noften needs to transfer disease analysis and prediction across patients of\ndifferent ages, where age acts as a continuous domain index. Such tasks are\nchallenging for prior domain adaptation methods since they ignore the\nunderlying relation among domains. In this paper, we propose the first method\nfor continuously indexed domain adaptation. Our approach combines traditional\nadversarial adaptation with a novel discriminator that models the\nencoding-conditioned domain index distribution. Our theoretical analysis\ndemonstrates the value of leveraging the domain index to generate invariant\nfeatures across a continuous range of domains. Our empirical results show that\nour approach outperforms the state-of-the-art domain adaption methods on both\nsynthetic and real-world medical datasets.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 16:53:50 GMT"}, {"version": "v2", "created": "Sun, 30 Aug 2020 02:31:43 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Wang", "Hao", ""], ["He", "Hao", ""], ["Katabi", "Dina", ""]]}, {"id": "2007.02047", "submitter": "Haiping Huang", "authors": "Zijian Jiang, Jianwen Zhou, and Haiping Huang", "title": "Relationship between manifold smoothness and adversarial vulnerability\n  in deep learning with local errors", "comments": "10 pages, 8 figures, to appear in Chin. Phys. B (2021)", "journal-ref": "Chin. Phys. B Vol. 30, No. 4 (2021) 048702", "doi": "10.1088/1674-1056/abd68e", "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks can achieve impressive performances, and even\noutperform humans in some specific tasks. Nevertheless, unlike biological\nbrains, the artificial neural networks suffer from tiny perturbations in\nsensory input, under various kinds of adversarial attacks. It is therefore\nnecessary to study the origin of the adversarial vulnerability. Here, we\nestablish a fundamental relationship between geometry of hidden representations\n(manifold perspective) and the generalization capability of the deep networks.\nFor this purpose, we choose a deep neural network trained by local errors, and\nthen analyze emergent properties of trained networks through the manifold\ndimensionality, manifold smoothness, and the generalization capability. To\nexplore effects of adversarial examples, we consider independent Gaussian noise\nattacks and fast-gradient-sign-method (FGSM) attacks. Our study reveals that a\nhigh generalization accuracy requires a relatively fast power-law decay of the\neigen-spectrum of hidden representations. Under Gaussian attacks, the\nrelationship between generalization accuracy and power-law exponent is\nmonotonic, while a non-monotonic behavior is observed for FGSM attacks. Our\nempirical study provides a route towards a final mechanistic interpretation of\nadversarial vulnerability under adversarial attacks.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 08:47:51 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 05:27:53 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Jiang", "Zijian", ""], ["Zhou", "Jianwen", ""], ["Huang", "Haiping", ""]]}, {"id": "2007.02050", "submitter": "Weiyu Chen", "authors": "Weiyu Chen, Hisao Ishibuhci, and Ke Shang", "title": "Lazy Greedy Hypervolume Subset Selection from Large Candidate Solution\n  Sets", "comments": "Accepted by CEC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subset selection is a popular topic in recent years and a number of subset\nselection methods have been proposed. Among those methods, hypervolume subset\nselection is widely used. Greedy hypervolume subset selection algorithms can\nachieve good approximations to the optimal subset. However, when the candidate\nset is large (e.g., an unbounded external archive with a large number of\nsolutions), the algorithm is very time-consuming. In this paper, we propose a\nnew lazy greedy algorithm exploiting the submodular property of the hypervolume\nindicator. The core idea is to avoid unnecessary hypervolume contribution\ncalculation when finding the solution with the largest contribution.\nExperimental results show that the proposed algorithm is hundreds of times\nfaster than the original greedy inclusion algorithm and several times faster\nthan the fastest known greedy inclusion algorithm on many test problems.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 09:19:45 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Chen", "Weiyu", ""], ["Ishibuhci", "Hisao", ""], ["Shang", "Ke", ""]]}, {"id": "2007.02209", "submitter": "Yiwen Guo", "authors": "Yiwen Guo and Long Chen and Yurong Chen and Changshui Zhang", "title": "On Connections between Regularizations for Improving DNN Robustness", "comments": "Accepted by TPAMI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes regularization terms proposed recently for improving the\nadversarial robustness of deep neural networks (DNNs), from a theoretical point\nof view. Specifically, we study possible connections between several effective\nmethods, including input-gradient regularization, Jacobian regularization,\ncurvature regularization, and a cross-Lipschitz functional. We investigate them\non DNNs with general rectified linear activations, which constitute one of the\nmost prevalent families of models for image classification and a host of other\nmachine learning applications. We shed light on essential ingredients of these\nregularizations and re-interpret their functionality. Through the lens of our\nstudy, more principled and efficient regularizations can possibly be invented\nin the near future.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 23:43:32 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Guo", "Yiwen", ""], ["Chen", "Long", ""], ["Chen", "Yurong", ""], ["Zhang", "Changshui", ""]]}, {"id": "2007.02210", "submitter": "Anup Das", "authors": "Shihao Song and Anup Das", "title": "A Case for Lifetime Reliability-Aware Neuromorphic Computing", "comments": "4 pages, 6 figures, accepted at MWCAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Neuromorphic computing with non-volatile memory (NVM) can significantly\nimprove performance and lower energy consumption of machine learning tasks\nimplemented using spike-based computations and bio-inspired learning\nalgorithms. High voltages required to operate certain NVMs such as phase-change\nmemory (PCM) can accelerate aging in a neuron's CMOS circuit, thereby reducing\nthe lifetime of neuromorphic hardware. In this work, we evaluate the long-term,\ni.e., lifetime reliability impact of executing state-of-the-art machine\nlearning tasks on a neuromorphic hardware, considering failure models such as\nnegative bias temperature instability (NBTI) and time-dependent dielectric\nbreakdown (TDDB). Based on such formulation, we show the\nreliability-performance trade-off obtained due to periodic relaxation of\nneuromorphic circuits, i.e., a stop-and-go style of neuromorphic computing.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 23:53:13 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Song", "Shihao", ""], ["Das", "Anup", ""]]}, {"id": "2007.02382", "submitter": "Michael Chang", "authors": "Michael Chang, Sidhant Kaushik, S. Matthew Weinberg, Thomas L.\n  Griffiths, Sergey Levine", "title": "Decentralized Reinforcement Learning: Global Decision-Making via Local\n  Economic Transactions", "comments": "18 pages, 13 figures, accepted to the International Conference on\n  Machine Learning (ICML) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper seeks to establish a framework for directing a society of simple,\nspecialized, self-interested agents to solve what traditionally are posed as\nmonolithic single-agent sequential decision problems. What makes it challenging\nto use a decentralized approach to collectively optimize a central objective is\nthe difficulty in characterizing the equilibrium strategy profile of\nnon-cooperative games. To overcome this challenge, we design a mechanism for\ndefining the learning environment of each agent for which we know that the\noptimal solution for the global objective coincides with a Nash equilibrium\nstrategy profile of the agents optimizing their own local objectives. The\nsociety functions as an economy of agents that learn the credit assignment\nprocess itself by buying and selling to each other the right to operate on the\nenvironment state. We derive a class of decentralized reinforcement learning\nalgorithms that are broadly applicable not only to standard reinforcement\nlearning but also for selecting options in semi-MDPs and dynamically composing\ncomputation graphs. Lastly, we demonstrate the potential advantages of a\nsociety's inherent modular structure for more efficient transfer learning.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2020 16:41:09 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 05:20:29 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Chang", "Michael", ""], ["Kaushik", "Sidhant", ""], ["Weinberg", "S. Matthew", ""], ["Griffiths", "Thomas L.", ""], ["Levine", "Sergey", ""]]}, {"id": "2007.02532", "submitter": "Theo Ladune", "authors": "Th\\'eo Ladune (IETR), Pierrick Philippe, Wassim Hamidouche (IETR), Lu\n  Zhang (IETR), Olivier D\\'eforges (IETR)", "title": "ModeNet: Mode Selection Network For Learned Video Coding", "comments": null, "journal-ref": "Machine Learning for Signal Processing (MLSP) 2020, Sep 2020,\n  Espoo, Finland", "doi": null, "report-no": null, "categories": "cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a mode selection network (ModeNet) is proposed to enhance deep\nlearning-based video compression. Inspired by traditional video coding, ModeNet\npurpose is to enable competition among several coding modes. The proposed\nModeNet learns and conveys a pixel-wise partitioning of the frame, used to\nassign each pixel to the most suited coding mode. ModeNet is trained alongside\nthe different coding modes to minimize a rate-distortion cost. It is a flexible\ncomponent which can be generalized to other systems to allow competition\nbetween different coding tools. Mod-eNet interest is studied on a P-frame\ncoding task, where it is used to design a method for coding a frame given its\nprediction. ModeNet-based systems achieve compelling performance when evaluated\nunder the Challenge on Learned Image Compression 2020 (CLIC20) P-frame coding\ntrack conditions.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 05:37:20 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 12:47:20 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Ladune", "Th\u00e9o", "", "IETR"], ["Philippe", "Pierrick", "", "IETR"], ["Hamidouche", "Wassim", "", "IETR"], ["Zhang", "Lu", "", "IETR"], ["D\u00e9forges", "Olivier", "", "IETR"]]}, {"id": "2007.02686", "submitter": "Elias Najarro", "authors": "Elias Najarro and Sebastian Risi", "title": "Meta-Learning through Hebbian Plasticity in Random Networks", "comments": "v4: Typo in equation in 3.1 corrected. v3: Bug that made diagonal\n  patterns appear has been fixed. Simulations have been re-run and plots\n  updated. v2: Figures 1, 7 and Table 1 updated, new results on 4.1 added,\n  typos corrected, references added", "journal-ref": "Advances in Neural Information Processing Systems (2020)", "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lifelong learning and adaptability are two defining aspects of biological\nagents. Modern reinforcement learning (RL) approaches have shown significant\nprogress in solving complex tasks, however once training is concluded, the\nfound solutions are typically static and incapable of adapting to new\ninformation or perturbations. While it is still not completely understood how\nbiological brains learn and adapt so efficiently from experience, it is\nbelieved that synaptic plasticity plays a prominent role in this process.\nInspired by this biological mechanism, we propose a search method that, instead\nof optimizing the weight parameters of neural networks directly, only searches\nfor synapse-specific Hebbian learning rules that allow the network to\ncontinuously self-organize its weights during the lifetime of the agent. We\ndemonstrate our approach on several reinforcement learning tasks with different\nsensory modalities and more than 450K trainable plasticity parameters. We find\nthat starting from completely random weights, the discovered Hebbian rules\nenable an agent to navigate a dynamical 2D-pixel environment; likewise they\nallow a simulated 3D quadrupedal robot to learn how to walk while adapting to\nmorphological damage not seen during training and in the absence of any\nexplicit reward or error signal in less than 100 timesteps. Code is available\nat https://github.com/enajx/HebbianMetaLearning.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 14:32:31 GMT"}, {"version": "v2", "created": "Sat, 26 Sep 2020 17:38:10 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 18:07:19 GMT"}, {"version": "v4", "created": "Thu, 25 Mar 2021 11:39:50 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Najarro", "Elias", ""], ["Risi", "Sebastian", ""]]}, {"id": "2007.02766", "submitter": "Samiran Ganguly", "authors": "Samiran Ganguly, Avik W. Ghosh", "title": "Building Reservoir Computing Hardware Using Low Energy-Barrier Magnetics", "comments": "To be presented at International Conference on Neuromorphic Systems\n  2020", "journal-ref": null, "doi": "10.1145/3407197.3407217", "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biologically inspired recurrent neural networks, such as reservoir computers\nare of interest in designing spatio-temporal data processors from a hardware\npoint of view due to the simple learning scheme and deep connections to Kalman\nfilters. In this work we discuss using in-depth simulation studies a way to\nconstruct hardware reservoir computers using an analog stochastic neuron cell\nbuilt from a low energy-barrier magnet based magnetic tunnel junction and a few\ntransistors. This allows us to implement a physical embodiment of the\nmathematical model of reservoir computers. Compact implementation of reservoir\ncomputers using such devices may enable building compact, energy-efficient\nsignal processors for standalone or in-situ machine cognition in edge devices.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 14:11:45 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Ganguly", "Samiran", ""], ["Ghosh", "Avik W.", ""]]}, {"id": "2007.03154", "submitter": "Yunjie Tian", "authors": "Yunjie Tian, Chang Liu, Lingxi Xie, Jianbin Jiao, Qixiang Ye", "title": "Discretization-Aware Architecture Search", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search cost of neural architecture search (NAS) has been largely reduced\nby weight-sharing methods. These methods optimize a super-network with all\npossible edges and operations, and determine the optimal sub-network by\ndiscretization, \\textit{i.e.}, pruning off weak candidates. The discretization\nprocess, performed on either operations or edges, incurs significant inaccuracy\nand thus the quality of the final architecture is not guaranteed. This paper\npresents discretization-aware architecture search (DA\\textsuperscript{2}S),\nwith the core idea being adding a loss term to push the super-network towards\nthe configuration of desired topology, so that the accuracy loss brought by\ndiscretization is largely alleviated. Experiments on standard image\nclassification benchmarks demonstrate the superiority of our approach, in\nparticular, under imbalanced target network configurations that were not\nstudied before.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 01:18:58 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Tian", "Yunjie", ""], ["Liu", "Chang", ""], ["Xie", "Lingxi", ""], ["Jiao", "Jianbin", ""], ["Ye", "Qixiang", ""]]}, {"id": "2007.03274", "submitter": "Zihan Pan", "authors": "Zihan Pan, Malu Zhang, Jibin Wu, Haizhou Li", "title": "Multi-Tones' Phase Coding (MTPC) of Interaural Time Difference by\n  Spiking Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the mammal's auditory localization pathway, in this paper we\npropose a pure spiking neural network (SNN) based computational model for\nprecise sound localization in the noisy real-world environment, and implement\nthis algorithm in a real-time robotic system with a microphone array. The key\nof this model relies on the MTPC scheme, which encodes the interaural time\ndifference (ITD) cues into spike patterns. This scheme naturally follows the\nfunctional structures of the human auditory localization system, rather than\nartificially computing of time difference of arrival. Besides, it highlights\nthe advantages of SNN, such as event-driven and power efficiency. The MTPC is\npipelined with two different SNN architectures, the convolutional SNN and\nrecurrent SNN, by which it shows the applicability to various SNNs. This\nproposal is evaluated by the microphone collected location-dependent acoustic\ndata, in a real-world environment with noise, obstruction, reflection, or other\naffects. The experiment results show a mean error azimuth of 1~3 degrees, which\nsurpasses the accuracy of the other biologically plausible neuromorphic\napproach for sound source localization.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 08:22:56 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Pan", "Zihan", ""], ["Zhang", "Malu", ""], ["Wu", "Jibin", ""], ["Li", "Haizhou", ""]]}, {"id": "2007.03286", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "An Entropy Equation for Energy", "comments": "Incorrectly edited on journal web site, read arXiv version", "journal-ref": "IOSR Journal of Engineering (IOSRJEN), Vol. 10, No. 7, pp. 16-19,\n  2020", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an entropy equation, but one that should be used for\nmeasuring energy and not information. In relation to the human brain therefore,\nboth of these quantities can be used to represent the stored information. The\nhuman brain makes use of energy efficiency to form its structures, which is\nlikely to be linked to the neuron wiring. This energy efficiency can also be\nused as the basis for a clustering algorithm, which is described in a different\npaper. This paper is more of a discussion about global properties, where the\nrules used for the clustering algorithm can also create the entropy equation E\n= (mean * variance). This states that work is done through the energy released\nby the 'change' in entropy. The equation is so simplistic and generic that it\ncan offer arguments for completely different domains, where the journey ends\nwith a discussion about global energy properties in physics and beyond. A\ncomparison with Einstein's relativity equation is made and also the audacious\nsuggestion that a black hole has zero-energy inside.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 09:01:00 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 07:22:57 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 09:33:58 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "2007.03326", "submitter": "Jannis Kurtz", "authors": "Bubacarr Bah, Jannis Kurtz", "title": "An Integer Programming Approach to Deep Neural Networks with Binary\n  Activation Functions", "comments": null, "journal-ref": "Workshop on Beyond first-order methods in ML systems at the 37th\n  International Conference on Machine Learning, Vienna, Austria, 2020", "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study deep neural networks with binary activation functions (BDNN), i.e.\nthe activation function only has two states. We show that the BDNN can be\nreformulated as a mixed-integer linear program which can be solved to global\noptimality by classical integer programming solvers. Additionally, a heuristic\nsolution algorithm is presented and we study the model under data uncertainty,\napplying a two-stage robust optimization approach. We implemented our methods\non random and real datasets and show that the heuristic version of the BDNN\noutperforms classical deep neural networks on the Breast Cancer Wisconsin\ndataset while performing worse on random data.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 10:28:20 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 09:10:02 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 15:33:05 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Bah", "Bubacarr", ""], ["Kurtz", "Jannis", ""]]}, {"id": "2007.03331", "submitter": "Lingxi Xie", "authors": "Kaifeng Bi, Lingxi Xie, Xin Chen, Longhui Wei, Qi Tian", "title": "GOLD-NAS: Gradual, One-Level, Differentiable", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a large literature of neural architecture search, but most\nexisting work made use of heuristic rules that largely constrained the search\nflexibility. In this paper, we first relax these manually designed constraints\nand enlarge the search space to contain more than $10^{160}$ candidates. In the\nnew space, most existing differentiable search methods can fail dramatically.\nWe then propose a novel algorithm named Gradual One-Level Differentiable Neural\nArchitecture Search (GOLD-NAS) which introduces a variable resource constraint\nto one-level optimization so that the weak operators are gradually pruned out\nfrom the super-network. In standard image classification benchmarks, GOLD-NAS\ncan find a series of Pareto-optimal architectures within a single search\nprocedure. Most of the discovered architectures were never studied before, yet\nthey achieve a nice tradeoff between recognition accuracy and model complexity.\nWe believe the new space and search algorithm can advance the search of\ndifferentiable NAS.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 10:37:49 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Bi", "Kaifeng", ""], ["Xie", "Lingxi", ""], ["Chen", "Xin", ""], ["Wei", "Longhui", ""], ["Tian", "Qi", ""]]}, {"id": "2007.03336", "submitter": "George Hall", "authors": "George T. Hall, Pietro Simone Oliveto, Dirk Sudholt", "title": "Fast Perturbative Algorithm Configurators", "comments": "To appear at PPSN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that the ParamRLS and ParamILS algorithm configurators\ncan tune some simple randomised search heuristics for standard benchmark\nfunctions in linear expected time in the size of the parameter space. In this\npaper we prove a linear lower bound on the expected time to optimise any\nparameter tuning problem for ParamRLS, ParamILS as well as for larger classes\nof algorithm configurators. We propose a harmonic mutation operator for\nperturbative algorithm configurators that provably tunes single-parameter\nalgorithms in polylogarithmic time for unimodal and approximately unimodal\n(i.e., non-smooth, rugged with an underlying gradient towards the optimum)\nparameter spaces. It is suitable as a general-purpose operator since even on\nworst-case (e.g., deceptive) landscapes it is only by at most a logarithmic\nfactor slower than the default ones used by ParamRLS and ParamILS. An\nexperimental analysis confirms the superiority of the approach in practice for\na number of configuration scenarios, including ones involving more than one\nparameter.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 10:48:32 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Hall", "George T.", ""], ["Oliveto", "Pietro Simone", ""], ["Sudholt", "Dirk", ""]]}, {"id": "2007.03347", "submitter": "Hussain Mohammed Kabir Dr", "authors": "H M Dipu Kabir, Moloud Abdar, Seyed Mohammad Jafar Jalali, Abbas\n  Khosravi, Amir F Atiya, Saeid Nahavandi, Dipti Srinivasan", "title": "SpinalNet: Deep Neural Network with Gradual Input", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Over the past few years, deep neural networks (DNNs) have garnered remarkable\nsuccess in a diverse range of real-world applications. However, DNNs consider a\nlarge number of inputs and consist of a large number of parameters, resulting\nin high computational demand. We study the human somatosensory system and\npropose the SpinalNet to achieve higher accuracy with less computational\nresources. In a typical neural network (NN) architecture, the hidden layers\nreceive inputs in the first layer and then transfer the intermediate outcomes\nto the next layer. In the proposed SpinalNet, the structure of hidden layers\nallocates to three sectors: 1) Input row, 2) Intermediate row, and 3) output\nrow. The intermediate row of the SpinalNet contains a few neurons. The role of\ninput segmentation is in enabling each hidden layer to receive a part of the\ninputs and outputs of the previous layer. Therefore, the number of incoming\nweights in a hidden layer is significantly lower than traditional DNNs. As all\nlayers of the SpinalNet directly contributes to the output row, the vanishing\ngradient problem does not exist. We also investigate the SpinalNet\nfully-connected layer to several well-known DNN models and perform traditional\nlearning and transfer learning. We observe significant error reductions with\nlower computational costs in most of the DNNs. We have also obtained the\nstate-of-the-art (SOTA) performance for QMNIST, Kuzushiji-MNIST, EMNIST\n(Letters, Digits, and Balanced), STL-10, Bird225, Fruits 360, and Caltech-101\ndatasets. The scripts of the proposed SpinalNet are available with the\nfollowing link: https://github.com/dipuk0506/SpinalNet\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 11:27:00 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 08:22:12 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Kabir", "H M Dipu", ""], ["Abdar", "Moloud", ""], ["Jalali", "Seyed Mohammad Jafar", ""], ["Khosravi", "Abbas", ""], ["Atiya", "Amir F", ""], ["Nahavandi", "Saeid", ""], ["Srinivasan", "Dipti", ""]]}, {"id": "2007.03488", "submitter": "Thomas Bartz-Beielstein", "authors": "Thomas Bartz-Beielstein, Carola Doerr, Daan van den Berg, Jakob\n  Bossek, Sowmya Chandrasekaran, Tome Eftimov, Andreas Fischbach, Pascal\n  Kerschke, William La Cava, Manuel Lopez-Ibanez, Katherine M. Malan, Jason H.\n  Moore, Boris Naujoks, Patryk Orzechowski, Vanessa Volz, Markus Wagner, Thomas\n  Weise", "title": "Benchmarking in Optimization: Best Practice and Open Issues", "comments": "Version 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.PF math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey compiles ideas and recommendations from more than a dozen\nresearchers with different backgrounds and from different institutes around the\nworld. Promoting best practice in benchmarking is its main goal. The article\ndiscusses eight essential topics in benchmarking: clearly stated goals,\nwell-specified problems, suitable algorithms, adequate performance measures,\nthoughtful analysis, effective and efficient designs, comprehensible\npresentations, and guaranteed reproducibility. The final goal is to provide\nwell-accepted guidelines (rules) that might be useful for authors and\nreviewers. As benchmarking in optimization is an active and evolving field of\nresearch this manuscript is meant to co-evolve over time by means of periodic\nupdates.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 14:20:26 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 22:36:27 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Bartz-Beielstein", "Thomas", ""], ["Doerr", "Carola", ""], ["Berg", "Daan van den", ""], ["Bossek", "Jakob", ""], ["Chandrasekaran", "Sowmya", ""], ["Eftimov", "Tome", ""], ["Fischbach", "Andreas", ""], ["Kerschke", "Pascal", ""], ["La Cava", "William", ""], ["Lopez-Ibanez", "Manuel", ""], ["Malan", "Katherine M.", ""], ["Moore", "Jason H.", ""], ["Naujoks", "Boris", ""], ["Orzechowski", "Patryk", ""], ["Volz", "Vanessa", ""], ["Wagner", "Markus", ""], ["Weise", "Thomas", ""]]}, {"id": "2007.03502", "submitter": "Anh Tran", "authors": "Anh Tran, Mike Eldred, Scott McCann, Yan Wang", "title": "srMO-BO-3GP: A sequential regularized multi-objective constrained\n  Bayesian optimization for design applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is an efficient and flexible global optimization\nframework that is applicable to a very wide range of engineering applications.\nTo leverage the capability of the classical BO, many extensions, including\nmulti-objective, multi-fidelity, parallelization, latent-variable model, have\nbeen proposed to improve the limitation of the classical BO framework. In this\nwork, we propose a novel multi-objective (MO) extension, called srMO-BO-3GP, to\nsolve the MO optimization problems in a sequential setting. Three different\nGaussian processes (GPs) are stacked together, where each of the GP is assigned\nwith a different task: the first GP is used to approximate the single-objective\nfunction, the second GP is used to learn the unknown constraints, and the third\nGP is used to learn the uncertain Pareto frontier. At each iteration, a MO\naugmented Tchebycheff function converting MO to single-objective is adopted and\nextended with a regularized ridge term, where the regularization is introduced\nto smoothen the single-objective function. Finally, we couple the third GP\nalong with the classical BO framework to promote the richness and diversity of\nthe Pareto frontier by the exploitation and exploration acquisition function.\nThe proposed framework is demonstrated using several numerical benchmark\nfunctions, as well as a thermomechanical finite element model for flip-chip\npackage design optimization.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 14:40:00 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 02:14:48 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Tran", "Anh", ""], ["Eldred", "Mike", ""], ["McCann", "Scott", ""], ["Wang", "Yan", ""]]}, {"id": "2007.03547", "submitter": "Haowen Fang", "authors": "Haowen Fang, Amar Shrestha, Qinru Qiu", "title": "Multivariate Time Series Classification Using Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing demand to process streams of temporal data in\nenergy-limited scenarios such as embedded devices, driven by the advancement\nand expansion of Internet of Things (IoT) and Cyber-Physical Systems (CPS).\nSpiking neural network has drawn attention as it enables low power consumption\nby encoding and processing information as sparse spike events, which can be\nexploited for event-driven computation. Recent works also show SNNs' capability\nto process spatial temporal information. Such advantages can be exploited by\npower-limited devices to process real-time sensor data. However, most existing\nSNN training algorithms focus on vision tasks and temporal credit assignment is\nnot addressed. Furthermore, widely adopted rate encoding ignores temporal\ninformation, hence it's not suitable for representing time series. In this\nwork, we present an encoding scheme to convert time series into sparse spatial\ntemporal spike patterns. A training algorithm to classify spatial temporal\npatterns is also proposed. Proposed approach is evaluated on multiple time\nseries datasets in the UCR repository and achieved performance comparable to\ndeep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 15:24:01 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Fang", "Haowen", ""], ["Shrestha", "Amar", ""], ["Qiu", "Qinru", ""]]}, {"id": "2007.03555", "submitter": "Andrei Ivanov", "authors": "Andrei Ivanov, Ilya Agapov", "title": "Physics-Based Deep Neural Networks for Beam Dynamics in Charged Particle\n  Accelerators", "comments": null, "journal-ref": "Phys. Rev. Accel. Beams 23, 074601 (2020)", "doi": "10.1103/PhysRevAccelBeams.23.074601", "report-no": null, "categories": "cs.NE physics.acc-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach for constructing neural networks which\nmodel charged particle beam dynamics. In our approach, the Taylor maps arising\nin the representation of dynamics are mapped onto the weights of a polynomial\nneural network. The resulting network approximates the dynamical system with\nperfect accuracy prior to training and provides a possibility to tune the\nnetwork weights on additional experimental data. We propose a symplectic\nregularization approach for such polynomial neural networks that always\nrestricts the trained model to Hamiltonian systems and significantly improves\nthe training procedure. The proposed networks can be used for beam dynamics\nsimulations or for fine-tuning of beam optics models with experimental data.\nThe structure of the network allows for the modeling of large accelerators with\na large number of magnets. We demonstrate our approach on the examples of the\nexisting PETRA III and the planned PETRA IV storage rings at DESY.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 15:33:11 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Ivanov", "Andrei", ""], ["Agapov", "Ilya", ""]]}, {"id": "2007.03629", "submitter": "Yujia Li", "authors": "Yujia Li, Felix Gimeno, Pushmeet Kohli, Oriol Vinyals", "title": "Strong Generalization and Efficiency in Neural Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning efficient algorithms that strongly\ngeneralize in the framework of neural program induction. By carefully designing\nthe input / output interfaces of the neural model and through imitation, we are\nable to learn models that produce correct results for arbitrary input sizes,\nachieving strong generalization. Moreover, by using reinforcement learning, we\noptimize for program efficiency metrics, and discover new algorithms that\nsurpass the teacher used in imitation. With this, our approach can learn to\noutperform custom-written solutions for a variety of problems, as we tested it\non sorting, searching in ordered lists and the NP-complete 0/1 knapsack\nproblem, which sets a notable milestone in the field of Neural Program\nInduction. As highlights, our learned model can perform sorting perfectly on\nany input data size we tested on, with $O(n log n)$ complexity, whilst\noutperforming hand-coded algorithms, including quick sort, in number of\noperations even for list sizes far beyond those seen during training.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 17:03:02 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 09:19:58 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Li", "Yujia", ""], ["Gimeno", "Felix", ""], ["Kohli", "Pushmeet", ""], ["Vinyals", "Oriol", ""]]}, {"id": "2007.03748", "submitter": "Edward Frady", "authors": "E. Paxon Frady, Spencer Kent, Bruno A. Olshausen, Friedrich T. Sommer", "title": "Resonator networks for factoring distributed representations of data\n  structures", "comments": "20 pages, 5 figures, to appear in Neural Computation 2020 with\n  companion paper: arXiv:1906.11684", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to encode and manipulate data structures with distributed neural\nrepresentations could qualitatively enhance the capabilities of traditional\nneural networks by supporting rule-based symbolic reasoning, a central property\nof cognition. Here we show how this may be accomplished within the framework of\nVector Symbolic Architectures (VSA) (Plate, 1991; Gayler, 1998; Kanerva, 1996),\nwhereby data structures are encoded by combining high-dimensional vectors with\noperations that together form an algebra on the space of distributed\nrepresentations. In particular, we propose an efficient solution to a hard\ncombinatorial search problem that arises when decoding elements of a VSA data\nstructure: the factorization of products of multiple code vectors. Our proposed\nalgorithm, called a resonator network, is a new type of recurrent neural\nnetwork that interleaves VSA multiplication operations and pattern completion.\nWe show in two examples -- parsing of a tree-like data structure and parsing of\na visual scene -- how the factorization problem arises and how the resonator\nnetwork can solve it. More broadly, resonator networks open the possibility to\napply VSAs to myriad artificial intelligence problems in real-world domains. A\ncompanion paper (Kent et al., 2020) presents a rigorous analysis and evaluation\nof the performance of resonator networks, showing it out-performs alternative\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 19:24:27 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Frady", "E. Paxon", ""], ["Kent", "Spencer", ""], ["Olshausen", "Bruno A.", ""], ["Sommer", "Friedrich T.", ""]]}, {"id": "2007.03787", "submitter": "Anya Vostinar", "authors": "Anya E. Vostinar, Barbara Z. Johnson, and Kevin Connors", "title": "Artificial Life in Game Mods for Intuitive Evolution Education", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The understanding and acceptance of evolution by natural selection has become\na difficult issue in many parts of the world, particularly the United States of\nAmerica. The use of games to improve intuition about evolution via natural\nselection is promising but can be challenging. We propose the use of\nmodifications to commercial games using artificial life techniques to 'stealth\nteach' about evolution via natural selection, provide a proof-of-concept mod of\nthe game Stardew Valley, and report on its initial reception.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 21:04:10 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Vostinar", "Anya E.", ""], ["Johnson", "Barbara Z.", ""], ["Connors", "Kevin", ""]]}, {"id": "2007.03948", "submitter": "Neil Yorke-Smith", "authors": "Kaan Yilmaz and Neil Yorke-Smith", "title": "Learning Efficient Search Approximation in Mixed Integer Branch and\n  Bound", "comments": null, "journal-ref": "AI, volume 2, number 2, pages 150-178, 2021", "doi": "10.3390/ai2020010", "report-no": null, "categories": "cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In line with the growing trend of using machine learning to improve solving\nof combinatorial optimisation problems, one promising idea is to improve node\nselection within a mixed integer programming branch-and-bound tree by using a\nlearned policy. In contrast to previous work using imitation learning, our\npolicy is focused on learning which of a node's children to select. We present\nan offline method to learn such a policy in two settings: one that is\napproximate by committing to pruning of nodes; one that is exact and backtracks\nfrom a leaf to use a different strategy. We apply the policy within the popular\nopen-source solver SCIP. Empirical results on four MIP datasets indicate that\nour node selection policy leads to solutions more quickly than the\nstate-of-the-art in the literature, but not as quickly as the state-of-practice\nSCIP node selector. While we do not beat the highly-optimised SCIP baseline in\nterms of solving time on exact solutions, our approximation-based policies have\na consistently better optimality gap than all baselines if the accuracy of the\npredictive model adds value to prediction. Further, the results also indicate\nthat, when a time limit is applied, our approximation method finds better\nsolutions than all baselines in the majority of problems tested.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 08:12:44 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Yilmaz", "Kaan", ""], ["Yorke-Smith", "Neil", ""]]}, {"id": "2007.03953", "submitter": "Carola Doerr", "authors": "Hao Wang, Diederick Vermetten, Furong Ye, Carola Doerr, Thomas B\\\"ack", "title": "IOHanalyzer: Performance Analysis for Iterative Optimization Heuristic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benchmarking and performance analysis play an important role in understanding\nthe behaviour of iterative optimization heuristics (IOHs) such as local search\nalgorithms, genetic and evolutionary algorithms, Bayesian optimization\nalgorithms, etc. This task, however, involves manual setup, execution, and\nanalysis of the experiment on an individual basis, which is laborious and can\nbe mitigated by a generic and well-designed platform. For this purpose, we\npropose IOHanalyzer, a new user-friendly tool for the analysis, comparison, and\nvisualization of performance data of IOHs.\n  Implemented in R and C++, IOHanalyzer is fully open source. It is available\non CRAN and GitHub. IOHanalyzer provides detailed statistics about fixed-target\nrunning times and about fixed-budget performance of the benchmarked algorithms\non real-valued, single-objective optimization tasks. Performance aggregation\nover several benchmark problems is possible, for example in the form of\nempirical cumulative distribution functions. Key advantages of IOHanalyzer over\nother performance analysis packages are its highly interactive design, which\nallows users to specify the performance measures, ranges, and granularity that\nare most useful for their experiments, and the possibility to analyze not only\nperformance traces, but also the evolution of dynamic state parameters.\n  IOHanalyzer can directly process performance data from the main benchmarking\nplatforms, including the COCO platform, Nevergrad, and our own IOHexperimenter.\nAn R programming interface is provided for users preferring to have a finer\ncontrol over the implemented functionalities.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 08:20:19 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 22:53:15 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2020 13:52:37 GMT"}], "update_date": "2020-11-02", "authors_parsed": [["Wang", "Hao", ""], ["Vermetten", "Diederick", ""], ["Ye", "Furong", ""], ["Doerr", "Carola", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2007.04039", "submitter": "Saeed Reza Kheradpisheh", "authors": "Saeed Reza Kheradpisheh, Maryam Mirsadeghi, Timoth\\'ee Masquelier", "title": "BS4NN: Binarized Spiking Neural Networks with Temporal Coding and\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We recently proposed the S4NN algorithm, essentially an adaptation of\nbackpropagation to multilayer spiking neural networks that use simple non-leaky\nintegrate-and-fire neurons and a form of temporal coding known as\ntime-to-first-spike coding. With this coding scheme, neurons fire at most once\nper stimulus, but the firing order carries information. Here, we introduce\nBS4NN, a modification of S4NN in which the synaptic weights are constrained to\nbe binary (+1 or -1), in order to decrease memory and computation footprints.\nThis was done using two sets of weights: firstly, real-valued weights, updated\nby gradient descent, and used in the backward pass of backpropagation, and\nsecondly, their signs, used in the forward pass. Similar strategies have been\nused to train (non-spiking) binarized neural networks. The main difference is\nthat BS4NN operates in the time domain: spikes are propagated sequentially, and\ndifferent neurons may reach their threshold at different times, which increases\ncomputational power. We validated BS4NN on two popular benchmarks, MNIST and\nFashion MNIST, and obtained state-of-the-art accuracies for this sort of\nnetworks (97.0% and 87.3% respectively) with a negligible accuracy drop with\nrespect to real-valued weights (0.4% and 0.7%, respectively). We also\ndemonstrated that BS4NN outperforms a simple BNN with the same architectures on\nthose two datasets (by 0.2% and 0.9% respectively), presumably because it\nleverages the temporal dimension.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 11:31:32 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Kheradpisheh", "Saeed Reza", ""], ["Mirsadeghi", "Maryam", ""], ["Masquelier", "Timoth\u00e9e", ""]]}, {"id": "2007.04082", "submitter": "Lakshay Chauhan", "authors": "Lakshay Chauhan, John Alberg, Zachary C. Lipton", "title": "Uncertainty-Aware Lookahead Factor Models for Quantitative Investing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On a periodic basis, publicly traded companies report fundamentals, financial\ndata including revenue, earnings, debt, among others. Quantitative finance\nresearch has identified several factors, functions of the reported data that\nhistorically correlate with stock market performance. In this paper, we first\nshow through simulation that if we could select stocks via factors calculated\non future fundamentals (via oracle), that our portfolios would far outperform\nstandard factor models. Motivated by this insight, we train deep nets to\nforecast future fundamentals from a trailing 5-year history. We propose\nlookahead factor models which plug these predicted future fundamentals into\ntraditional factors. Finally, we incorporate uncertainty estimates from both\nneural heteroscedastic regression and a dropout-based heuristic, improving\nperformance by adjusting our portfolios to avert risk. In retrospective\nanalysis, we leverage an industry-grade portfolio simulator (backtester) to\nshow simultaneous improvement in annualized return and Sharpe ratio.\nSpecifically, the simulated annualized return for the uncertainty-aware model\nis 17.7% (vs 14.0% for a standard factor model) and the Sharpe ratio is 0.84\n(vs 0.52).\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 00:18:40 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 16:52:16 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Chauhan", "Lakshay", ""], ["Alberg", "John", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2007.04223", "submitter": "Nuno Louren\\c{c}o", "authors": "Pedro Carvalho, Nuno Louren\\c{c}o, Filipe Assun\\c{c}\\~ao, Penousal\n  Machado", "title": "AutoLR: An Evolutionary Approach to Learning Rate Policies", "comments": null, "journal-ref": null, "doi": "10.1145/3377930.3390158", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of a proper learning rate is paramount for good Artificial Neural\nNetwork training and performance. In the past, one had to rely on experience\nand trial-and-error to find an adequate learning rate. Presently, a plethora of\nstate of the art automatic methods exist that make the search for a good\nlearning rate easier. While these techniques are effective and have yielded\ngood results over the years, they are general solutions. This means the\noptimization of learning rate for specific network topologies remains largely\nunexplored. This work presents AutoLR, a framework that evolves Learning Rate\nSchedulers for a specific Neural Network Architecture using Structured\nGrammatical Evolution. The system was used to evolve learning rate policies\nthat were compared with a commonly used baseline value for learning rate.\nResults show that training performed using certain evolved policies is more\nefficient than the established baseline and suggest that this approach is a\nviable means of improving a neural network's performance.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 16:03:44 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Carvalho", "Pedro", ""], ["Louren\u00e7o", "Nuno", ""], ["Assun\u00e7\u00e3o", "Filipe", ""], ["Machado", "Penousal", ""]]}, {"id": "2007.04542", "submitter": "Jia Zhao", "authors": "Colby L. Wight and Jia Zhao", "title": "Solving Allen-Cahn and Cahn-Hilliard Equations using the Adaptive\n  Physics Informed Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase field models, in particular, the Allen-Cahn type and Cahn-Hilliard type\nequations, have been widely used to investigate interfacial dynamic problems.\nDesigning accurate, efficient, and stable numerical algorithms for solving the\nphase field models has been an active field for decades. In this paper, we\nfocus on using the deep neural network to design an automatic numerical solver\nfor the Allen-Cahn and Cahn-Hilliard equations by proposing an improved physics\ninformed neural network (PINN). Though the PINN has been embraced to\ninvestigate many differential equation problems, we find a direct application\nof the PINN in solving phase-field equations won't provide accurate solutions\nin many cases. Thus, we propose various techniques that add to the\napproximation power of the PINN. As a major contribution of this paper, we\npropose to embrace the adaptive idea in both space and time and introduce\nvarious sampling strategies, such that we are able to improve the efficiency\nand accuracy of the PINN on solving phase field equations. In addition, the\nimproved PINN has no restriction on the explicit form of the PDEs, making it\napplicable to a wider class of PDE problems, and shedding light on numerical\napproximations of other PDEs in general.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 03:49:59 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Wight", "Colby L.", ""], ["Zhao", "Jia", ""]]}, {"id": "2007.04681", "submitter": "Lorenzo Federici Mr.", "authors": "Lorenzo Federici, Boris Benedikter, Alessandro Zavoli", "title": "EOS: a Parallel, Self-Adaptive, Multi-Population Evolutionary Algorithm\n  for Constrained Global Optimization", "comments": "2020 IEEE Congress on Evolutionary Computation (IEEE World Congress\n  on Computational Intelligence), Glasgow, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the main characteristics of the evolutionary optimization\ncode named EOS, Evolutionary Optimization at Sapienza, and its successful\napplication to challenging, real-world space trajectory optimization problems.\nEOS is a global optimization algorithm for constrained and unconstrained\nproblems of real-valued variables. It implements a number of improvements to\nthe well-known Differential Evolution (DE) algorithm, namely, a self-adaptation\nof the control parameters, an epidemic mechanism, a clustering technique, an\n$\\varepsilon$-constrained method to deal with nonlinear constraints, and a\nsynchronous island-model to handle multiple populations in parallel. The\nresults reported prove that EOSis capable of achieving increased performance\ncompared to state-of-the-art single-population self-adaptive DE algorithms when\napplied to high-dimensional or highly-constrained space trajectory optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 10:19:22 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 10:27:23 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Federici", "Lorenzo", ""], ["Benedikter", "Boris", ""], ["Zavoli", "Alessandro", ""]]}, {"id": "2007.04725", "submitter": "Ahmed Hallawa Mr.", "authors": "Ahmed Hallawa, Thorsten Born, Anke Schmeink, Guido Dartmann, Arne\n  Peine, Lukas Martin, Giovanni Iacca, A. E. Eiben, Gerd Ascheid", "title": "EVO-RL: Evolutionary-Driven Reinforcement Learning", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a novel approach for reinforcement learning driven\nby evolutionary computation. Our algorithm, dubbed as Evolutionary-Driven\nReinforcement Learning (evo-RL), embeds the reinforcement learning algorithm in\nan evolutionary cycle, where we distinctly differentiate between purely\nevolvable (instinctive) behaviour versus purely learnable behaviour.\nFurthermore, we propose that this distinction is decided by the evolutionary\nprocess, thus allowing evo-RL to be adaptive to different environments. In\naddition, evo-RL facilitates learning on environments with rewardless states,\nwhich makes it more suited for real-world problems with incomplete information.\nTo show that evo-RL leads to state-of-the-art performance, we present the\nperformance of different state-of-the-art reinforcement learning algorithms\nwhen operating within evo-RL and compare it with the case when these same\nalgorithms are executed independently. Results show that reinforcement learning\nalgorithms embedded within our evo-RL approach significantly outperform the\nstand-alone versions of the same RL algorithms on OpenAI Gym control problems\nwith rewardless states constrained by the same computational budget.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 11:52:19 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 16:14:58 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Hallawa", "Ahmed", ""], ["Born", "Thorsten", ""], ["Schmeink", "Anke", ""], ["Dartmann", "Guido", ""], ["Peine", "Arne", ""], ["Martin", "Lukas", ""], ["Iacca", "Giovanni", ""], ["Eiben", "A. E.", ""], ["Ascheid", "Gerd", ""]]}, {"id": "2007.04756", "submitter": "Manas Gupta", "authors": "Manas Gupta, Siddharth Aravindan, Aleksandra Kalisz, Vijay\n  Chandrasekhar, Lin Jie", "title": "Learning to Prune Deep Neural Networks via Reinforcement Learning", "comments": "Accepted at the ICML 2020 Workshop on Automated Machine Learning\n  (AutoML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes PuRL - a deep reinforcement learning (RL) based algorithm\nfor pruning neural networks. Unlike current RL based model compression\napproaches where feedback is given only at the end of each episode to the\nagent, PuRL provides rewards at every pruning step. This enables PuRL to\nachieve sparsity and accuracy comparable to current state-of-the-art methods,\nwhile having a much shorter training cycle. PuRL achieves more than 80%\nsparsity on the ResNet-50 model while retaining a Top-1 accuracy of 75.37% on\nthe ImageNet dataset. Through our experiments we show that PuRL is also able to\nsparsify already efficient architectures like MobileNet-V2. In addition to\nperformance characterisation experiments, we also provide a discussion and\nanalysis of the various RL design choices that went into the tuning of the\nMarkov Decision Process underlying PuRL. Lastly, we point out that PuRL is\nsimple to use and can be easily adapted for various architectures.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 13:06:07 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Gupta", "Manas", ""], ["Aravindan", "Siddharth", ""], ["Kalisz", "Aleksandra", ""], ["Chandrasekhar", "Vijay", ""], ["Jie", "Lin", ""]]}, {"id": "2007.04769", "submitter": "Han Zhang", "authors": "Han Zhang, Jialin Liu, and Xin Yao", "title": "A Hybrid Evolutionary Algorithm for Reliable Facility Location Problem", "comments": "Accepted at PPSN2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reliable facility location problem (RFLP) is an important research topic\nof operational research and plays a vital role in the decision-making and\nmanagement of modern supply chain and logistics. Through solving RFLP, the\ndecision-maker can obtain reliable location decisions under the risk of\nfacilities' disruptions or failures. In this paper, we propose a novel model\nfor the RFLP. Instead of assuming allocating a fixed number of facilities to\neach customer as in the existing works, we set the number of allocated\nfacilities as an independent variable in our proposed model, which makes our\nmodel closer to the scenarios in real life but more difficult to be solved by\ntraditional methods. To handle it, we propose EAMLS, a hybrid evolutionary\nalgorithm, which combines a memorable local search (MLS) method and an\nevolutionary algorithm (EA). Additionally, a novel metric called l3-value is\nproposed to assist the analysis of the algorithm's convergence speed and exam\nthe process of evolution. The experimental results show the effectiveness and\nsuperior performance of our EAMLS, compared to a CPLEX solver and a Genetic\nAlgorithm (GA), on large-scale problems.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2020 11:31:55 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Zhang", "Han", ""], ["Liu", "Jialin", ""], ["Yao", "Xin", ""]]}, {"id": "2007.04779", "submitter": "Ali Lotfi Rezaabad", "authors": "Ali Lotfi Rezaabad and Sriram Vishwanath", "title": "Long Short-Term Memory Spiking Networks and Their Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in event-based neuromorphic systems have resulted in\nsignificant interest in the use and development of spiking neural networks\n(SNNs). However, the non-differentiable nature of spiking neurons makes SNNs\nincompatible with conventional backpropagation techniques. In spite of the\nsignificant progress made in training conventional deep neural networks (DNNs),\ntraining methods for SNNs still remain relatively poorly understood. In this\npaper, we present a novel framework for training recurrent SNNs. Analogous to\nthe benefits presented by recurrent neural networks (RNNs) in learning time\nseries models within DNNs, we develop SNNs based on long short-term memory\n(LSTM) networks. We show that LSTM spiking networks learn the timing of the\nspikes and temporal dependencies. We also develop a methodology for error\nbackpropagation within LSTM-based SNNs. The developed architecture and method\nfor backpropagation within LSTM-based SNNs enable them to learn long-term\ndependencies with comparable results to conventional LSTMs.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 13:22:27 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Rezaabad", "Ali Lotfi", ""], ["Vishwanath", "Sriram", ""]]}, {"id": "2007.04796", "submitter": "Mehrdad Shafiei Dizaji", "authors": "Mehrdad Shafiei Dizaji", "title": "Training of Deep Learning Neuro-Skin Neural Network", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this brief paper, a learning algorithm is developed for Deep Learning\nNeuro-Skin Neural Network to improve their learning properties. Neuroskin is a\nnew type of neural network presented recently by the authors. It is comprised\nof a cellular membrane which has a neuron attached to each cell. The neuron is\nthe cells nucleus. A neuroskin is modelled using finite elements. Each element\nof the finite element represents a cell. Each cells neuron has dendritic fibers\nwhich connects it to the nodes of the cell. On the other hand, its axon is\nconnected to the nodes of a number of different neurons. The neuroskin is\ntrained to contract upon receiving an input. The learning takes place during\nupdating iterations using sensitivity analysis. It is shown that while the\nneuroskin can not present the desirable response, it improves gradually to the\ndesired level.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 18:51:45 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Dizaji", "Mehrdad Shafiei", ""]]}, {"id": "2007.04853", "submitter": "Victor Popescu", "authors": "Victor-Bogdan Popescu and Krishna Kanhaiya and Iulian N\\u{a}stac and\n  Eugen Czeizler and Ion Petre", "title": "Identifying efficient controls of complex interaction networks using\n  genetic algorithms", "comments": "The submission contains 34 pages, 9 figures and 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.NE cs.SY eess.SY q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control theory has seen recently impactful applications in network science,\nespecially in connections with applications in network medicine. A key topic of\nresearch is that of finding minimal external interventions that offer control\nover the dynamics of a given network, a problem known as network\ncontrollability. We propose in this article a new solution for this problem\nbased on genetic algorithms. We tailor our solution for applications in\ncomputational drug repurposing, seeking to maximise its use of FDA-approved\ndrug targets in a given disease-specific protein-protein interaction network.\nWe show how our algorithm identifies a number of potentially efficient drugs\nfor breast, ovarian, and pancreatic cancer. We demonstrate our algorithm on\nseveral benchmark networks from cancer medicine, social networks, electronic\ncircuits, and several random networks with their edges distributed according to\nthe Erd\\H{o}s-R\\'{e}nyi, the small-world, and the scale-free properties.\nOverall, we show that our new algorithm is more efficient in identifying\nrelevant drug targets in a disease network, advancing the computational\nsolutions needed for new therapeutic and drug repurposing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 14:56:54 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Popescu", "Victor-Bogdan", ""], ["Kanhaiya", "Krishna", ""], ["N\u0103stac", "Iulian", ""], ["Czeizler", "Eugen", ""], ["Petre", "Ion", ""]]}, {"id": "2007.04882", "submitter": "Jonas Hasbach", "authors": "Jonas D. Hasbach, Maren Bennewitz", "title": "A Neuro-inspired Theory of Joint Human-Swarm Interaction", "comments": "ICRA Workshop on Human-Swarm Interaction 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.MA cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-swarm interaction (HSI) is an active research challenge in the realms\nof swarm robotics and human-factors engineering. Here we apply a cognitive\nsystems engineering perspective and introduce a neuro-inspired joint systems\ntheory of HSI. The mindset defines predictions for adaptive, robust and\nscalable HSI dynamics and therefore has the potential to inform human-swarm\nloop design.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 15:34:22 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Hasbach", "Jonas D.", ""], ["Bennewitz", "Maren", ""]]}, {"id": "2007.04897", "submitter": "Sungsoo Ahn", "authors": "Sungsoo Ahn, Junsu Kim, Hankook Lee, Jinwoo Shin", "title": "Guiding Deep Molecular Optimization with Genetic Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  De novo molecular design attempts to search over the chemical space for\nmolecules with the desired property. Recently, deep learning has gained\nconsiderable attention as a promising approach to solve the problem. In this\npaper, we propose genetic expert-guided learning (GEGL), a simple yet novel\nframework for training a deep neural network (DNN) to generate highly-rewarding\nmolecules. Our main idea is to design a \"genetic expert improvement\" procedure,\nwhich generates high-quality targets for imitation learning of the DNN.\nExtensive experiments show that GEGL significantly improves over\nstate-of-the-art methods. For example, GEGL manages to solve the penalized\noctanol-water partition coefficient optimization with a score of 31.40, while\nthe best-known score in the literature is 27.22. Besides, for the GuacaMol\nbenchmark with 20 tasks, our method achieves the highest score for 19 tasks, in\ncomparison with state-of-the-art methods, and newly obtains the perfect score\nfor three tasks.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 05:01:26 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 11:23:07 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 10:49:47 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Ahn", "Sungsoo", ""], ["Kim", "Junsu", ""], ["Lee", "Hankook", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2007.04965", "submitter": "Colin White", "authors": "Colin White, Willie Neiswanger, Sam Nolen, Yash Savani", "title": "A Study on Encodings for Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) has been extensively studied in the past few\nyears. A popular approach is to represent each neural architecture in the\nsearch space as a directed acyclic graph (DAG), and then search over all DAGs\nby encoding the adjacency matrix and list of operations as a set of\nhyperparameters. Recent work has demonstrated that even small changes to the\nway each architecture is encoded can have a significant effect on the\nperformance of NAS algorithms.\n  In this work, we present the first formal study on the effect of architecture\nencodings for NAS, including a theoretical grounding and an empirical study.\nFirst we formally define architecture encodings and give a theoretical\ncharacterization on the scalability of the encodings we study Then we identify\nthe main encoding-dependent subroutines which NAS algorithms employ, running\nexperiments to show which encodings work best with each subroutine for many\npopular algorithms. The experiments act as an ablation study for prior work,\ndisentangling the algorithmic and encoding-based contributions, as well as a\nguideline for future work. Our results demonstrate that NAS encodings are an\nimportant design decision which can have a significant impact on overall\nperformance. Our code is available at\nhttps://github.com/naszilla/nas-encodings.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 17:52:11 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 23:04:02 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["White", "Colin", ""], ["Neiswanger", "Willie", ""], ["Nolen", "Sam", ""], ["Savani", "Yash", ""]]}, {"id": "2007.05112", "submitter": "William Podlaski", "authors": "William F. Podlaski, Christian K. Machens", "title": "Biological credit assignment through dynamic inversion of feedforward\n  networks", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning depends on changes in synaptic connections deep inside the brain. In\nmultilayer networks, these changes are triggered by error signals fed back from\nthe output, generally through a stepwise inversion of the feedforward\nprocessing steps. The gold standard for this process -- backpropagation --\nworks well in artificial neural networks, but is biologically implausible.\nSeveral recent proposals have emerged to address this problem, but many of\nthese biologically-plausible schemes are based on learning an independent set\nof feedback connections. This complicates the assignment of errors to each\nsynapse by making it dependent upon a second learning problem, and by fitting\ninversions rather than guaranteeing them. Here, we show that feedforward\nnetwork transformations can be effectively inverted through dynamics. We derive\nthis dynamic inversion from the perspective of feedback control, where the\nforward transformation is reused and dynamically interacts with fixed or random\nfeedback to propagate error signals during the backward pass. Importantly, this\nscheme does not rely upon a second learning problem for feedback because\naccurate inversion is guaranteed through the network dynamics. We map these\ndynamics onto generic feedforward networks, and show that the resulting\nalgorithm performs well on several supervised and unsupervised datasets.\nFinally, we discuss potential links between dynamic inversion and second-order\noptimization. Overall, our work introduces an alternative perspective on credit\nassignment in the brain, and proposes a special role for temporal dynamics and\nfeedback control during learning.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 00:03:01 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 00:31:24 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Podlaski", "William F.", ""], ["Machens", "Christian K.", ""]]}, {"id": "2007.05123", "submitter": "Tuan Anh Bui", "authors": "Anh Bui, Trung Le, He Zhao, Paul Montague, Olivier deVel, Tamas\n  Abraham, Dinh Phung", "title": "Improving Adversarial Robustness by Enforcing Local and Global\n  Compactness", "comments": "Proceeding of the European Conference on Computer Vision (ECCV) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fact that deep neural networks are susceptible to crafted perturbations\nseverely impacts the use of deep learning in certain domains of application.\nAmong many developed defense models against such attacks, adversarial training\nemerges as the most successful method that consistently resists a wide range of\nattacks. In this work, based on an observation from a previous study that the\nrepresentations of a clean data example and its adversarial examples become\nmore divergent in higher layers of a deep neural net, we propose the Adversary\nDivergence Reduction Network which enforces local/global compactness and the\nclustering assumption over an intermediate layer of a deep neural network. We\nconduct comprehensive experiments to understand the isolating behavior of each\ncomponent (i.e., local/global compactness and the clustering assumption) and\ncompare our proposed model with state-of-the-art adversarial training methods.\nThe experimental results demonstrate that augmenting adversarial training with\nour proposed components can further improve the robustness of the network,\nleading to higher unperturbed and adversarial predictive performances.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 00:43:06 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Bui", "Anh", ""], ["Le", "Trung", ""], ["Zhao", "He", ""], ["Montague", "Paul", ""], ["deVel", "Olivier", ""], ["Abraham", "Tamas", ""], ["Phung", "Dinh", ""]]}, {"id": "2007.05125", "submitter": "Rustam Rustam", "authors": "Rustam and Agus Yodi Gunawan and Made Tri Ari Penia Kresnowati", "title": "Artificial Neural Network Approach for the Identification of Clove Buds\n  Origin Based on Metabolites Composition", "comments": "10 pages, 6 figures, submitted to Acta Polytechnica as scientific\n  journal published by the Czech Technical University in Prague", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper examines the use of artificial neural network approach in\nidentifying the origin of clove buds based on metabolites composition.\nGenerally, large data sets are critical for accurate identification. Machine\nlearning with large data sets lead to precise identification based on origins.\nHowever, clove buds uses small data sets due to lack of metabolites composition\nand their high cost of extraction. The results show that backpropagation and\nresilient propagation with one and two hidden layers identifies clove buds\norigin accurately. The backpropagation with one hidden layer offers 99.91% and\n99.47% for training and testing data sets, respectively. The resilient\npropagation with two hidden layers offers 99.96% and 97.89% accuracy for\ntraining and testing data sets, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 00:55:12 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Rustam", "", ""], ["Gunawan", "Agus Yodi", ""], ["Kresnowati", "Made Tri Ari Penia", ""]]}, {"id": "2007.05352", "submitter": "Antoine Cully", "authors": "Antoine Cully", "title": "Multi-Emitter MAP-Elites: Improving quality, diversity and convergence\n  speed with heterogeneous sets of emitters", "comments": null, "journal-ref": "In Proceedings of the Genetic and Evolutionary Computation\n  Conference (pp. 84-92) 2021", "doi": "10.1145/3449639.3459326", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Quality-Diversity (QD) optimisation is a new family of learning algorithms\nthat aims at generating collections of diverse and high-performing solutions.\nAmong those algorithms, the recently introduced Covariance Matrix Adaptation\nMAP-Elites (CMA-ME) algorithm proposes the concept of emitters, which uses a\npredefined heuristic to drive the algorithm's exploration. This algorithm was\nshown to outperform MAP-Elites, a popular QD algorithm that has demonstrated\npromising results in numerous applications. In this paper, we introduce\nMulti-Emitter MAP-Elites (ME-MAP-Elites), an algorithm that directly extends\nCMA-ME and improves its quality, diversity and data efficiency. It leverages\nthe diversity of a heterogeneous set of emitters, in which each emitter type\nimproves the optimisation process in different ways. A bandit algorithm\ndynamically finds the best selection of emitters depending on the current\nsituation. We evaluate the performance of ME-MAP-Elites on six tasks, ranging\nfrom standard optimisation problems (in 100 dimensions) to complex locomotion\ntasks in robotics. Our comparisons against CMA-ME and MAP-Elites show that\nME-MAP-Elites is faster at providing collections of solutions that are\nsignificantly more diverse and higher performing. Moreover, in cases where no\nfruitful synergy can be found between the different emitters, ME-MAP-Elites is\nequivalent to the best of the compared algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 12:45:02 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 09:33:24 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Cully", "Antoine", ""]]}, {"id": "2007.05606", "submitter": "Philippe Reiter", "authors": "Philippe Reiter, Geet Rose Jose, Spyridon Bizmpikis, Ionela-Ancu\\c{t}a\n  C\\^irjil\\u{a}", "title": "Neuromorphic Processing and Sensing: Evolutionary Progression of AI to\n  Spiking", "comments": "15 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing rise in machine learning and deep learning applications is\nrequiring ever more computational resources to successfully meet the growing\ndemands of an always-connected, automated world. Neuromorphic technologies\nbased on Spiking Neural Network algorithms hold the promise to implement\nadvanced artificial intelligence using a fraction of the computations and power\nrequirements by modeling the functioning, and spiking, of the human brain. With\nthe proliferation of tools and platforms aiding data scientists and machine\nlearning engineers to develop the latest innovations in artificial and deep\nneural networks, a transition to a new paradigm will require building from the\ncurrent well-established foundations. This paper explains the theoretical\nworkings of neuromorphic technologies based on spikes, and overviews the\nstate-of-art in hardware processors, software platforms and neuromorphic\nsensing devices. A progression path is paved for current machine learning\nspecialists to update their skillset, as well as classification or predictive\nmodels from the current generation of deep neural networks to SNNs. This can be\nachieved by leveraging existing, specialized hardware in the form of SpiNNaker\nand the Nengo migration toolkit. First-hand, experimental results of converting\na VGG-16 neural network to an SNN are shared. A forward gaze into industrial,\nmedical and commercial applications that can readily benefit from SNNs wraps up\nthis investigation into the neuromorphic computing future.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 20:54:42 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Reiter", "Philippe", ""], ["Jose", "Geet Rose", ""], ["Bizmpikis", "Spyridon", ""], ["C\u00eerjil\u0103", "Ionela-Ancu\u0163a", ""]]}, {"id": "2007.05781", "submitter": "Romit Beed Mr", "authors": "Romit S Beed, Sunita Sarkar, Arindam Roy, Suvranil D Biswas and Suhana\n  Biswas", "title": "A Hybrid Multi-Objective Carpool Route Optimization Technique using\n  Genetic Algorithm and A* Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Carpooling has gained considerable importance in developed as well as in\ndeveloping countries as an effective solution for controlling vehicular\npollution, both sound and air. As carpooling decreases the number of vehicles\nused by commuters, it results in multiple benefits like mitigation of traffic\nand congestion on the roads, reduced demand for parking facilities, lesser\nenergy or fuel consumption and most importantly, reduction in carbon emission,\nthus improving the quality of life in cities. This work presents a hybrid GA-A*\nalgorithm to obtain optimal routes for the carpooling problem in the domain of\nmulti-objective optimization having multiple conflicting objectives. Though\nGenetic algorithm provides optimal solutions, A* algorithm because of its\nefficiency in providing the shortest route between any two points based on\nheuristics, enhances the optimal routes obtained using Genetic algorithm. The\nrefined routes, obtained using the GA-A* algorithm, are further subjected to\ndominance test to obtain non-dominating solutions based on Pareto-Optimality.\nThe routes obtained maximize the profit of the service provider by minimizing\nthe travel and detour distance as well as pick-up/drop costs while maximizing\nthe utilization of the car. The proposed algorithm has been implemented over\nthe Salt Lake area of Kolkata. Route distance and detour distance for the\noptimal routes obtained using the proposed algorithm are consistently lesser\nfor the same number of passengers when compared with the corresponding data\nobtained using the existing algorithm. Various statistical analyses like\nboxplots have also confirmed that the proposed algorithm regularly performed\nbetter than the existing algorithm using only Genetic Algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 14:13:20 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Beed", "Romit S", ""], ["Sarkar", "Sunita", ""], ["Roy", "Arindam", ""], ["Biswas", "Suvranil D", ""], ["Biswas", "Suhana", ""]]}, {"id": "2007.05785", "submitter": "Wei Fang", "authors": "Wei Fang, Zhaofei Yu, Yanqi Chen, Timothee Masquelier, Tiejun Huang,\n  Yonghong Tian", "title": "Incorporating Learnable Membrane Time Constant to Enhance Learning of\n  Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) have attracted enormous research interest due\nto temporal information processing capability, low power consumption, and high\nbiological plausibility. However, the formulation of efficient and\nhigh-performance learning algorithms for SNNs is still challenging. Most\nexisting learning methods learn the synaptic-related parameters only, and\nrequire manual tuning of the membrane-related parameters that determine the\ndynamics of single spiking neurons. These parameters are typically chosen to be\nthe same for all neurons, which limits the diversity of neurons and thus the\nexpressiveness of the resulting SNNs. In this paper, we take inspiration from\nthe observation that membrane-related parameters are different across brain\nregions, and propose a training algorithm that is capable to learn not only the\nsynaptic weights but also the membrane time constants of SNN. We show that\nincorporating learnable membrane time constants can make the network less\nsensitive to initial values and can speed up learning. In addition, we\nreevaluate the pooling methods in SNNs and find that max-pooling is able to\nincrease the fitting capacity of SNNs in temporal tasks, as well as reduce the\ncomputation cost. We evaluate the proposed method for image classification\ntasks on both traditional static MNIST, Fashion-MNIST, CIFAR-10 datasets, and\nneuromorphic N-MNIST, CIFAR10-DVS, DVS128 Gesture datasets. The experiment\nresults show that the proposed method outperforms the state-of-the-art accuracy\non nearly all datasets, using fewer time-steps.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 14:35:42 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 16:08:36 GMT"}, {"version": "v3", "created": "Tue, 24 Nov 2020 12:47:40 GMT"}, {"version": "v4", "created": "Fri, 27 Nov 2020 05:23:29 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Fang", "Wei", ""], ["Yu", "Zhaofei", ""], ["Chen", "Yanqi", ""], ["Masquelier", "Timothee", ""], ["Huang", "Tiejun", ""], ["Tian", "Yonghong", ""]]}, {"id": "2007.06176", "submitter": "Angel Yanguas-Gil", "authors": "Angel Yanguas-Gil", "title": "Coarse scale representation of spiking neural networks: backpropagation\n  through spikes and application to neuromorphic hardware", "comments": "Paper accepted in ICONS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore recurrent representations of leaky integrate and fire\nneurons operating at a timescale equal to their absolute refractory period. Our\ncoarse time scale approximation is obtained using a probability distribution\nfunction for spike arrivals that is homogeneously distributed over this time\ninterval. This leads to a discrete representation that exhibits the same\ndynamics as the continuous model, enabling efficient large scale simulations\nand backpropagation through the recurrent implementation. We use this approach\nto explore the training of deep spiking neural networks including\nconvolutional, all-to-all connectivity, and maxpool layers directly in Pytorch.\nWe found that the recurrent model leads to high classification accuracy using\njust 4-long spike trains during training. We also observed a good transfer back\nto continuous implementations of leaky integrate and fire neurons. Finally, we\napplied this approach to some of the standard control problems as a first step\nto explore reinforcement learning using neuromorphic chips.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 04:02:35 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Yanguas-Gil", "Angel", ""]]}, {"id": "2007.06192", "submitter": "Blaine Rister", "authors": "Blaine Rister and Daniel L. Rubin", "title": "Probabilistic bounds on neuron death in deep rectifier networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuron death is a complex phenomenon with implications for model\ntrainability: the deeper the network, the lower the probability of finding a\nvalid initialization. In this work, we derive both upper and lower bounds on\nthe probability that a ReLU network is initialized to a trainable point, as a\nfunction of model hyperparameters. We show that it is possible to increase the\ndepth of a network indefinitely, so long as the width increases as well.\nFurthermore, our bounds are asymptotically tight under reasonable assumptions:\nfirst, the upper bound coincides with the true probability for a single-layer\nnetwork with the largest possible input set. Second, the true probability\nconverges to our lower bound as the input set shrinks to a single point, or as\nthe network complexity grows under an assumption about the output variance. We\nconfirm these results by numerical simulation, showing rapid convergence to the\nlower bound with increasing network depth. Then, motivated by the theory, we\npropose a practical sign flipping scheme which guarantees that the ratio of\nliving data points in a $k$-layer network is at least $2^{-k}$. Finally, we\nshow how these issues are mitigated by network design features currently seen\nin practice, such as batch normalization, residual connections, dense networks\nand skip connections. This suggests that neuron death may provide insight into\nthe efficacy of various model architectures.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 05:15:04 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 20:54:09 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Rister", "Blaine", ""], ["Rubin", "Daniel L.", ""]]}, {"id": "2007.06251", "submitter": "Victor Costa", "authors": "Victor Costa, Nuno Louren\\c{c}o, Jo\\~ao Correia, Penousal Machado", "title": "Exploring the Evolution of GANs through Quality Diversity", "comments": "Published in GECCO 2020", "journal-ref": null, "doi": "10.1145/3377930.3389824", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) achieved relevant advances in the\nfield of generative algorithms, presenting high-quality results mainly in the\ncontext of images. However, GANs are hard to train, and several aspects of the\nmodel should be previously designed by hand to ensure training success. In this\ncontext, evolutionary algorithms such as COEGAN were proposed to solve the\nchallenges in GAN training. Nevertheless, the lack of diversity and premature\noptimization can be found in some of these solutions. We propose in this paper\nthe application of a quality-diversity algorithm in the evolution of GANs. The\nsolution is based on the Novelty Search with Local Competition (NSLC)\nalgorithm, adapting the concepts used in COEGAN to this new proposal. We\ncompare our proposal with the original COEGAN model and with an alternative\nversion using a global competition approach. The experimental results evidenced\nthat our proposal increases the diversity of the discovered solutions and\nleverage the performance of the models found by the algorithm. Furthermore, the\nglobal competition approach was able to consistently find better models for\nGANs.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 08:54:52 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Costa", "Victor", ""], ["Louren\u00e7o", "Nuno", ""], ["Correia", "Jo\u00e3o", ""], ["Machado", "Penousal", ""]]}, {"id": "2007.06281", "submitter": "Simone Scardapane", "authors": "Simone Scardapane, Indro Spinelli, Paolo Di Lorenzo", "title": "Distributed Training of Graph Convolutional Networks", "comments": "Published on IEEE Transactions on Signal and Information Processing\n  over Networks", "journal-ref": null, "doi": "10.1109/TSIPN.2020.3046237", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this work is to develop a fully-distributed algorithmic framework\nfor training graph convolutional networks (GCNs). The proposed method is able\nto exploit the meaningful relational structure of the input data, which are\ncollected by a set of agents that communicate over a sparse network topology.\nAfter formulating the centralized GCN training problem, we first show how to\nmake inference in a distributed scenario where the underlying data graph is\nsplit among different agents. Then, we propose a distributed gradient descent\nprocedure to solve the GCN training problem. The resulting model distributes\ncomputation along three lines: during inference, during back-propagation, and\nduring optimization. Convergence to stationary solutions of the GCN training\nproblem is also established under mild conditions. Finally, we propose an\noptimization criterion to design the communication topology between agents in\norder to match with the graph describing data relationships. A wide set of\nnumerical results validate our proposal. To the best of our knowledge, this is\nthe first work combining graph convolutional neural networks with distributed\noptimization.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 10:04:20 GMT"}, {"version": "v2", "created": "Thu, 7 Jan 2021 10:00:24 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Scardapane", "Simone", ""], ["Spinelli", "Indro", ""], ["Di Lorenzo", "Paolo", ""]]}, {"id": "2007.06286", "submitter": "Gustav Sourek", "authors": "Gustav Sourek, Filip Zelezny, Ondrej Kuzelka", "title": "Beyond Graph Neural Networks with Lifted Relational Neural Networks", "comments": "Submitted to MLJ's Special Track on Learning and Reasoning (May 15th\n  2020 cut-off) http://lr2020.iit.demokritos.gr/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate a declarative differentiable programming framework based on\nthe language of Lifted Relational Neural Networks, where small parameterized\nlogic programs are used to encode relational learning scenarios. When presented\nwith relational data, such as various forms of graphs, the program interpreter\ndynamically unfolds differentiable computational graphs to be used for the\nprogram parameter optimization by standard means. Following from the used\ndeclarative Datalog abstraction, this results into compact and elegant learning\nprograms, in contrast with the existing procedural approaches operating\ndirectly on the computational graph level. We illustrate how this idea can be\nused for an efficient encoding of a diverse range of existing advanced neural\narchitectures, with a particular focus on Graph Neural Networks (GNNs).\nAdditionally, we show how the contemporary GNN models can be easily extended\ntowards higher relational expressiveness. In the experiments, we demonstrate\ncorrectness and computation efficiency through comparison against specialized\nGNN deep learning frameworks, while shedding some light on the learning\nperformance of existing GNN models.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 10:10:58 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Sourek", "Gustav", ""], ["Zelezny", "Filip", ""], ["Kuzelka", "Ondrej", ""]]}, {"id": "2007.06407", "submitter": "Marko Angjelichinoski", "authors": "Marko Angjelichinoski, Bijan Pesaran and Vahid Tarokh", "title": "Deep Cross-Subject Mapping of Neural Activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective. In this paper, we consider the problem of cross-subject decoding,\nwhere neural activity data collected from the prefrontal cortex of a given\nsubject (destination) is used to decode motor intentions from the neural\nactivity of a different subject (source). Approach. We cast the problem of\nneural activity mapping in a probabilistic framework where we adopt deep\ngenerative modelling. Our proposed algorithm uses deep conditional variational\nautoencoder to infer the representation of the neural activity of the source\nsubject into an adequate feature space of the destination subject where neural\ndecoding takes place. Results. We verify our approach on an experimental data\nset in which two macaque monkeys perform memory-guided visual saccades to one\nof eight target locations. The results show a peak cross-subject decoding\nimprovement of $8\\%$ over subject-specific decoding. Conclusion. We demonstrate\nthat a neural decoder trained on neural activity signals of one subject can be\nused to robustly decode the motor intentions of a different subject with high\nreliability. This is achieved in spite of the non-stationary nature of neural\nactivity signals and the subject-specific variations of the recording\nconditions. Significance. The findings reported in this paper are an important\nstep towards the development of cross-subject brain-computer that generalize\nwell across a population.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 14:35:02 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 18:05:37 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Angjelichinoski", "Marko", ""], ["Pesaran", "Bijan", ""], ["Tarokh", "Vahid", ""]]}, {"id": "2007.06463", "submitter": "Uday Chakraborty", "authors": "Uday K. Chakraborty", "title": "Semi-steady-state Jaya Algorithm", "comments": null, "journal-ref": "Applied Sciences 10(15), 5388, 2020", "doi": "10.3390/app10155388", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Jaya algorithm is arguably one of the fastest-emerging metaheuristics\namongst the newest members of the evolutionary computation family. The present\npaper proposes a new, improved Jaya algorithm by modifying the update\nstrategies of the best and the worst members in the population. Simulation\nresults on a twelve-function benchmark test-suite as well as a real-world\nproblem of practical importance show that the proposed strategy produces\nresults that are better and faster in the majority of cases. Statistical tests\nof significance are used to validate the performance improvement.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 15:54:36 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Chakraborty", "Uday K.", ""]]}, {"id": "2007.06477", "submitter": "Pasquale Minervini", "authors": "Pasquale Minervini, Sebastian Riedel, Pontus Stenetorp, Edward\n  Grefenstette, Tim Rockt\\\"aschel", "title": "Learning Reasoning Strategies in End-to-End Differentiable Proving", "comments": "Proceedings of the 37th International Conference on Machine Learning\n  (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.NE cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attempts to render deep learning models interpretable, data-efficient, and\nrobust have seen some success through hybridisation with rule-based systems,\nfor example, in Neural Theorem Provers (NTPs). These neuro-symbolic models can\ninduce interpretable rules and learn representations from data via\nback-propagation, while providing logical explanations for their predictions.\nHowever, they are restricted by their computational complexity, as they need to\nconsider all possible proof paths for explaining a goal, thus rendering them\nunfit for large-scale applications. We present Conditional Theorem Provers\n(CTPs), an extension to NTPs that learns an optimal rule selection strategy via\ngradient-based optimisation. We show that CTPs are scalable and yield\nstate-of-the-art results on the CLUTRR dataset, which tests systematic\ngeneralisation of neural models by learning to reason over smaller graphs and\nevaluating on larger ones. Finally, CTPs show better link prediction results on\nstandard benchmarks in comparison with other neural-symbolic models, while\nbeing explainable. All source code and datasets are available online, at\nhttps://github.com/uclnlp/ctp.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 16:22:14 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2020 08:40:14 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 16:17:34 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Minervini", "Pasquale", ""], ["Riedel", "Sebastian", ""], ["Stenetorp", "Pontus", ""], ["Grefenstette", "Edward", ""], ["Rockt\u00e4schel", "Tim", ""]]}, {"id": "2007.06630", "submitter": "Javier Gonzalez-Trejo", "authors": "Javier Antonio Gonzalez-Trejo, Diego Alberto Mercado-Ravell", "title": "Dense Crowds Detection and Counting with a Lightweight Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of crowd counting, most of the works have focused on improving\nthe accuracy without regard to the performance leading to algorithms that are\nnot suitable for embedded applications. In this paper, we propose a lightweight\nconvolutional neural network architecture to perform crowd detection and\ncounting using fewer computer resources without a significant loss on count\naccuracy. The architecture was trained using the Bayes loss function to further\nimprove its accuracy and then pruned to further reduce the computational\nresources used. The proposed architecture was tested over the USF-QNRF\nachieving a competitive Mean Average Error of 154.07 and a superior Mean Square\nError of 241.77 while maintaining a competitive number of parameters of 0.067\nMillion. The obtained results suggest that the Bayes loss can be used with\nother architectures to further improve them and also the last convolutional\nlayer provides no significant information and even encourage over-fitting at\ntraining.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 19:02:25 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Gonzalez-Trejo", "Javier Antonio", ""], ["Mercado-Ravell", "Diego Alberto", ""]]}, {"id": "2007.07207", "submitter": "Ben Hamida Mrabet Sana", "authors": "Sana Ben Hamida and Wafa Abdelmalek and Fathi Abid", "title": "Applying Dynamic Training-Subset Selection Methods Using Genetic\n  Programming for Forecasting Implied Volatility", "comments": "20 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:2006.16407", "journal-ref": "Wiley Computational Intelligence December 2014", "doi": null, "report-no": null, "categories": "q-fin.GN cs.CE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volatility is a key variable in option pricing, trading and hedging\nstrategies. The purpose of this paper is to improve the accuracy of forecasting\nimplied volatility using an extension of genetic programming (GP) by means of\ndynamic training-subset selection methods. These methods manipulate the\ntraining data in order to improve the out of sample patterns fitting. When\napplied with the static subset selection method using a single training data\nsample, GP could generate forecasting models which are not adapted to some out\nof sample fitness cases. In order to improve the predictive accuracy of\ngenerated GP patterns, dynamic subset selection methods are introduced to the\nGP algorithm allowing a regular change of the training sample during evolution.\nFour dynamic training-subset selection methods are proposed based on random,\nsequential or adaptive subset selection. The latest approach uses an adaptive\nsubset weight measuring the sample difficulty according to the fitness cases\nerrors. Using real data from SP500 index options, these techniques are compared\nto the static subset selection method. Based on MSE total and percentage of non\nfitted observations, results show that the dynamic approach improves the\nforecasting performance of the generated GP models, specially those obtained\nfrom the adaptive random training subset selection method applied to the whole\nset of training samples.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 21:28:30 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Hamida", "Sana Ben", ""], ["Abdelmalek", "Wafa", ""], ["Abid", "Fathi", ""]]}, {"id": "2007.07346", "submitter": "Alex Spaeth", "authors": "Alex Spaeth, Maryam Tebyani, David Haussler, Mircea Teodorescu", "title": "Spiking neural state machine for gait frequency entrainment in a\n  flexible modular robot", "comments": "22 pages, 11 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0240267", "report-no": null, "categories": "cs.NE cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a modular architecture for neuromorphic closed-loop control based\non bistable relaxation oscillator modules consisting of three spiking neurons\neach. Like its biological prototypes, this basic component is robust to\nparameter variation but can be modulated by external inputs. By combining these\nmodules, we can construct a neural state machine capable of generating the\ncyclic or repetitive behaviors necessary for legged locomotion. A concrete case\nstudy for the approach is provided by a modular robot constructed from flexible\nplastic volumetric pixels, in which we produce a forward crawling gait\nentrained to the natural frequency of the robot by a minimal system of twelve\nneurons organized into four modules.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 20:47:31 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 17:59:50 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Spaeth", "Alex", ""], ["Tebyani", "Maryam", ""], ["Haussler", "David", ""], ["Teodorescu", "Mircea", ""]]}, {"id": "2007.07967", "submitter": "Dario Malchiodi", "authors": "Giosu\\`e Cataldo Marin\\`o, Gregorio Ghidoli, Marco Frasca and Dario\n  Malchiodi", "title": "Compression strategies and space-conscious representations for deep\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning have made available large, powerful\nconvolutional neural networks (CNN) with state-of-the-art performance in\nseveral real-world applications. Unfortunately, these large-sized models have\nmillions of parameters, thus they are not deployable on resource-limited\nplatforms (e.g. where RAM is limited). Compression of CNNs thereby becomes a\ncritical problem to achieve memory-efficient and possibly computationally\nfaster model representations. In this paper, we investigate the impact of lossy\ncompression of CNNs by weight pruning and quantization, and lossless weight\nmatrix representations based on source coding. We tested several combinations\nof these techniques on four benchmark datasets for classification and\nregression problems, achieving compression rates up to $165$ times, while\npreserving or improving the model performance.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 19:41:19 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Marin\u00f2", "Giosu\u00e8 Cataldo", ""], ["Ghidoli", "Gregorio", ""], ["Frasca", "Marco", ""], ["Malchiodi", "Dario", ""]]}, {"id": "2007.08035", "submitter": "Akshay Jain", "authors": "Hamidreza Taghvaee, Akshay Jain, Xavier Timoneda, Christos Liaskos,\n  Sergi Abadal, Eduard Alarc\\'on and Albert Cabellos-Aparicio", "title": "Radiation pattern prediction for Metasurfaces: A Neural Network based\n  approach", "comments": "Submitted to IEEE OJ-COMS", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.ET cs.NE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the current standardization for the 5G networks nears completion, work\ntowards understanding the potential technologies for the 6G wireless networks\nis already underway. One of these potential technologies for the 6G networks\nare Reconfigurable Intelligent Surfaces (RISs). They offer unprecedented\ndegrees of freedom towards engineering the wireless channel, i.e., the ability\nto modify the characteristics of the channel whenever and however required.\nNevertheless, such properties demand that the response of the associated\nmetasurface (MSF) is well understood under all possible operational conditions.\nWhile an understanding of the radiation pattern characteristics can be obtained\nthrough either analytical models or full wave simulations, they suffer from\ninaccuracy under certain conditions and extremely high computational\ncomplexity, respectively. Hence, in this paper we propose a novel neural\nnetworks based approach that enables a fast and accurate characterization of\nthe MSF response. We analyze multiple scenarios and demonstrate the\ncapabilities and utility of the proposed methodology. Concretely, we show that\nthis method is able to learn and predict the parameters governing the reflected\nwave radiation pattern with an accuracy of a full wave simulation (98.8%-99.8%)\nand the time and computational complexity of an analytical model. The\naforementioned result and methodology will be of specific importance for the\ndesign, fault tolerance and maintenance of the thousands of RISs that will be\ndeployed in the 6G network environment.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 23:33:43 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Taghvaee", "Hamidreza", ""], ["Jain", "Akshay", ""], ["Timoneda", "Xavier", ""], ["Liaskos", "Christos", ""], ["Abadal", "Sergi", ""], ["Alarc\u00f3n", "Eduard", ""], ["Cabellos-Aparicio", "Albert", ""]]}, {"id": "2007.08277", "submitter": "Martin Krejca", "authors": "Benjamin Doerr and Martin S. Krejca", "title": "The Univariate Marginal Distribution Algorithm Copes Well With Deception\n  and Epistasis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In their recent work, Lehre and Nguyen (FOGA 2019) show that the univariate\nmarginal distribution algorithm (UMDA) needs time exponential in the parent\npopulations size to optimize the DeceptiveLeadingBlocks (DLB) problem. They\nconclude from this result that univariate EDAs have difficulties with deception\nand epistasis.\n  In this work, we show that this negative finding is caused by an unfortunate\nchoice of the parameters of the UMDA. When the population sizes are chosen\nlarge enough to prevent genetic drift, then the UMDA optimizes the DLB problem\nwith high probability with at most $\\lambda(\\frac{n}{2} + 2 e \\ln n)$ fitness\nevaluations. Since an offspring population size $\\lambda$ of order $n \\log n$\ncan prevent genetic drift, the UMDA can solve the DLB problem with $O(n^2 \\log\nn)$ fitness evaluations. In contrast, for classic evolutionary algorithms no\nbetter run time guarantee than $O(n^3)$ is known (which we prove to be tight\nfor the ${(1+1)}$ EA), so our result rather suggests that the UMDA can cope\nwell with deception and epistatis.\n  From a broader perspective, our result shows that the UMDA can cope better\nwith local optima than evolutionary algorithms; such a result was previously\nknown only for the compact genetic algorithm. Together with the lower bound of\nLehre and Nguyen, our result for the first time rigorously proves that running\nEDAs in the regime with genetic drift can lead to drastic performance losses.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 12:07:09 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 09:19:31 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Doerr", "Benjamin", ""], ["Krejca", "Martin S.", ""]]}, {"id": "2007.08311", "submitter": "Ciprian Oprisa", "authors": "Dan Domnita and Ciprian Oprisa", "title": "A Genetic Algorithm for Obtaining Memory Constrained Near-Perfect\n  Hashing", "comments": null, "journal-ref": null, "doi": "10.1109/AQTR.2018.8402794", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of fast items retrieval from a fixed collection is often\nencountered in most computer science areas, from operating system components to\ndatabases and user interfaces. We present an approach based on hash tables that\nfocuses on both minimizing the number of comparisons performed during the\nsearch and minimizing the total collection size. The standard open-addressing\ndouble-hashing approach is improved with a non-linear transformation that can\nbe parametrized in order to ensure a uniform distribution of the data in the\nhash table. The optimal parameter is determined using a genetic algorithm. The\npaper results show that near-perfect hashing is faster than binary search, yet\nuses less memory than perfect hashing, being a good choice for\nmemory-constrained applications where search time is also critical.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 12:57:15 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Domnita", "Dan", ""], ["Oprisa", "Ciprian", ""]]}, {"id": "2007.08497", "submitter": "Aaron Dharna", "authors": "Aaron Dharna, Julian Togelius, L. B. Soros", "title": "Co-generation of game levels and game-playing agents", "comments": "7 pages, 5 figures, AIIDE 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open-endedness, primarily studied in the context of artificial life, is the\nability of systems to generate potentially unbounded ontologies of increasing\nnovelty and complexity. Engineering generative systems displaying at least some\ndegree of this ability is a goal with clear applications to procedural content\ngeneration in games. The Paired Open-Ended Trailblazer (POET) algorithm,\nheretofore explored only in a biped walking domain, is a coevolutionary system\nthat simultaneously generates environments and agents that can solve them. This\npaper introduces a POET-Inspired Neuroevolutionary System for KreativitY\n(PINSKY) in games, which co-generates levels for multiple video games and\nagents that play them. This system leverages the General Video Game Artificial\nIntelligence (GVGAI) framework to enable co-generation of levels and agents for\nthe 2D Atari-style games Zelda and Solar Fox. Results demonstrate the ability\nof PINSKY to generate curricula of game levels, opening up a promising new\navenue for research at the intersection of procedural content generation and\nartificial life. At the same time, results in these challenging game domains\nhighlight the limitations of the current algorithm and opportunities for\nimprovement.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 17:48:05 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 15:23:04 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Dharna", "Aaron", ""], ["Togelius", "Julian", ""], ["Soros", "L. B.", ""]]}, {"id": "2007.08656", "submitter": "Sondre Engebr{\\aa}ten Msc", "authors": "Sondre A. Engebraaten, Jonas Moen, Oleg A. Yakimenko, Kyrre Glette", "title": "A Framework for Automatic Behavior Generation in Multi-Function Swarms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-function swarms are swarms that solve multiple tasks at once. For\nexample, a quadcopter swarm could be tasked with exploring an area of interest\nwhile simultaneously functioning as ad-hoc relays. With this type of\nmulti-function comes the challenge of handling potentially conflicting\nrequirements simultaneously. Using the Quality-Diversity algorithm MAP-elites\nin combination with a suitable controller structure, a framework for automatic\nbehavior generation in multi-function swarms is proposed. The framework is\ntested on a scenario with three simultaneous tasks: exploration, communication\nnetwork creation and geolocation of RF emitters. A repertoire is evolved,\nconsisting of a wide range of controllers, or behavior primitives, with\ndifferent characteristics and trade-offs in the different tasks. This\nrepertoire would enable the swarm to transition between behavior trade-offs\nonline, according to the situational requirements. Furthermore, the effect of\nnoise on the behavior characteristics in MAP-elites is investigated. A moderate\nnumber of re-evaluations is found to increase the robustness while keeping the\ncomputational requirements relatively low. A few selected controllers are\nexamined, and the dynamics of transitioning between these controllers are\nexplored. Finally, the study develops a methodology for analyzing the makeup of\nthe resulting controllers. This is done through a parameter variation study\nwhere the importance of individual inputs to the swarm controllers is assessed\nand analyzed.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 20:50:52 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Engebraaten", "Sondre A.", ""], ["Moen", "Jonas", ""], ["Yakimenko", "Oleg A.", ""], ["Glette", "Kyrre", ""]]}, {"id": "2007.08663", "submitter": "Christopher Morris", "authors": "Christopher Morris, Nils M. Kriege, Franka Bause, Kristian Kersting,\n  Petra Mutzel, Marion Neumann", "title": "TUDataset: A collection of benchmark datasets for learning with graphs", "comments": "ICML 2020 workshop \"Graph Representation Learning and Beyond\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been an increasing interest in (supervised) learning with\ngraph data, especially using graph neural networks. However, the development of\nmeaningful benchmark datasets and standardized evaluation procedures is\nlagging, consequently hindering advancements in this area. To address this, we\nintroduce the TUDataset for graph classification and regression. The collection\nconsists of over 120 datasets of varying sizes from a wide range of\napplications. We provide Python-based data loaders, kernel and graph neural\nnetwork baseline implementations, and evaluation tools. Here, we give an\noverview of the datasets, standardized evaluation procedures, and provide\nbaseline experiments. All datasets are available at www.graphlearning.io. The\nexperiments are fully reproducible from the code available at\nwww.github.com/chrsmrrs/tudataset.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 21:46:33 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Morris", "Christopher", ""], ["Kriege", "Nils M.", ""], ["Bause", "Franka", ""], ["Kersting", "Kristian", ""], ["Mutzel", "Petra", ""], ["Neumann", "Marion", ""]]}, {"id": "2007.08855", "submitter": "Wenjie Chen", "authors": "Wenjie Chen, Fengtong Du, Ye Wang, Lihong Cao", "title": "A Biologically Plausible Audio-Visual Integration Model for Continual\n  Learning", "comments": "Accepted by 2021 International Joint Conference on Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of catastrophic forgetting has a history of more than 30 years\nand has not been completely solved yet. Since the human brain has natural\nability to perform continual lifelong learning, learning from the brain may\nprovide solutions to this problem. In this paper, we propose a novel\nbiologically plausible audio-visual integration model (AVIM) based on the\nassumption that the integration of audio and visual perceptual information in\nthe medial temporal lobe during learning is crucial to form concepts and make\ncontinual learning possible. Specifically, we use multi-compartment\nHodgkin-Huxley neurons to build the model and adopt the calcium-based synaptic\ntagging and capture as the model's learning rule. Furthermore, we define a new\ncontinual learning paradigm to simulate the possible continual learning process\nin the human brain. We then test our model under this new paradigm. Our\nexperimental results show that the proposed AVIM can achieve state-of-the-art\ncontinual learning performance compared with other advanced methods such as\nOWM, iCaRL and GEM. Moreover, it can generate stable representations of objects\nduring learning. These results support our assumption that concept formation is\nessential for continuous lifelong learning and suggest the proposed AVIM is a\npossible concept formation mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 09:30:41 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 09:21:16 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Chen", "Wenjie", ""], ["Du", "Fengtong", ""], ["Wang", "Ye", ""], ["Cao", "Lihong", ""]]}, {"id": "2007.08860", "submitter": "Rachmad Vidya Wicaksana Putra", "authors": "Rachmad Vidya Wicaksana Putra, Muhammad Shafique", "title": "FSpiNN: An Optimization Framework for Memory- and Energy-Efficient\n  Spiking Neural Networks", "comments": "To appear at the IEEE Transactions on Computer-Aided Design of\n  Integrated Circuits and Systems (IEEE-TCAD), as part of the ESWEEK-TCAD\n  Special Issue, September 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) are gaining interest due to their event-driven\nprocessing which potentially consumes low power/energy computations in hardware\nplatforms, while offering unsupervised learning capability due to the\nspike-timing-dependent plasticity (STDP) rule. However, state-of-the-art SNNs\nrequire a large memory footprint to achieve high accuracy, thereby making them\ndifficult to be deployed on embedded systems, for instance on battery-powered\nmobile devices and IoT Edge nodes. Towards this, we propose FSpiNN, an\noptimization framework for obtaining memory- and energy-efficient SNNs for\ntraining and inference processing, with unsupervised learning capability while\nmaintaining accuracy. It is achieved by (1) reducing the computational\nrequirements of neuronal and STDP operations, (2) improving the accuracy of\nSTDP-based learning, (3) compressing the SNN through a fixed-point\nquantization, and (4) incorporating the memory and energy requirements in the\noptimization process. FSpiNN reduces the computational requirements by reducing\nthe number of neuronal operations, the STDP-based synaptic weight updates, and\nthe STDP complexity. To improve the accuracy of learning, FSpiNN employs\ntimestep-based synaptic weight updates, and adaptively determines the STDP\npotentiation factor and the effective inhibition strength. The experimental\nresults show that, as compared to the state-of-the-art work, FSpiNN achieves\n7.5x memory saving, and improves the energy-efficiency by 3.5x on average for\ntraining and by 1.8x on average for inference, across MNIST and Fashion MNIST\ndatasets, with no accuracy loss for a network with 4900 excitatory neurons,\nthereby enabling energy-efficient SNNs for edge devices/embedded systems.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 09:40:26 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Putra", "Rachmad Vidya Wicaksana", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2007.09087", "submitter": "Weiwen Jiang", "authors": "Weiwen Jiang, Lei Yang, Sakyasingha Dasgupta, Jingtong Hu, Yiyu Shi", "title": "Standing on the Shoulders of Giants: Hardware and Neural Architecture\n  Co-Search with Hot Start", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware and neural architecture co-search that automatically generates\nArtificial Intelligence (AI) solutions from a given dataset is promising to\npromote AI democratization; however, the amount of time that is required by\ncurrent co-search frameworks is in the order of hundreds of GPU hours for one\ntarget hardware. This inhibits the use of such frameworks on commodity\nhardware. The root cause of the low efficiency in existing co-search frameworks\nis the fact that they start from a \"cold\" state (i.e., search from scratch). In\nthis paper, we propose a novel framework, namely HotNAS, that starts from a\n\"hot\" state based on a set of existing pre-trained models (a.k.a. model zoo) to\navoid lengthy training time. As such, the search time can be reduced from 200\nGPU hours to less than 3 GPU hours. In HotNAS, in addition to hardware design\nspace and neural architecture search space, we further integrate a compression\nspace to conduct model compressing during the co-search, which creates new\nopportunities to reduce latency but also brings challenges. One of the key\nchallenges is that all of the above search spaces are coupled with each other,\ne.g., compression may not work without hardware design support. To tackle this\nissue, HotNAS builds a chain of tools to design hardware to support\ncompression, based on which a global optimizer is developed to automatically\nco-search all the involved search spaces. Experiments on ImageNet dataset and\nXilinx FPGA show that, within the timing constraint of 5ms, neural\narchitectures generated by HotNAS can achieve up to 5.79% Top-1 and 3.97% Top-5\naccuracy gain, compared with the existing ones.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 16:09:06 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Jiang", "Weiwen", ""], ["Yang", "Lei", ""], ["Dasgupta", "Sakyasingha", ""], ["Hu", "Jingtong", ""], ["Shi", "Yiyu", ""]]}, {"id": "2007.09163", "submitter": "C.-H. Huck Yang", "authors": "Hao-Hsiang Yang, Chao-Han Huck Yang, Yu-Chiang Frank Wang", "title": "Wavelet Channel Attention Module with a Fusion Network for Single Image\n  Deraining", "comments": "Accepted to IEEE ICIP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Single image deraining is a crucial problem because rain severely degenerates\nthe visibility of images and affects the performance of computer vision tasks\nlike outdoor surveillance systems and intelligent vehicles. In this paper, we\npropose the new convolutional neural network (CNN) called the wavelet channel\nattention module with a fusion network. Wavelet transform and the inverse\nwavelet transform are substituted for down-sampling and up-sampling so feature\nmaps from the wavelet transform and convolutions contain different frequencies\nand scales. Furthermore, feature maps are integrated by channel attention. Our\nproposed network learns confidence maps of four sub-band images derived from\nthe wavelet transform of the original images. Finally, the clear image can be\nwell restored via the wavelet reconstruction and fusion of the low-frequency\npart and high-frequency parts. Several experimental results on synthetic and\nreal images present that the proposed algorithm outperforms state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 18:06:13 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Yang", "Hao-Hsiang", ""], ["Yang", "Chao-Han Huck", ""], ["Wang", "Yu-Chiang Frank", ""]]}, {"id": "2007.09200", "submitter": "Yujia Huang", "authors": "Yujia Huang, James Gornet, Sihui Dai, Zhiding Yu, Tan Nguyen, Doris Y.\n  Tsao, Anima Anandkumar", "title": "Neural Networks with Recurrent Generative Feedback", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are vulnerable to input perturbations such as additive noise\nand adversarial attacks. In contrast, human perception is much more robust to\nsuch perturbations. The Bayesian brain hypothesis states that human brains use\nan internal generative model to update the posterior beliefs of the sensory\ninput. This mechanism can be interpreted as a form of self-consistency between\nthe maximum a posteriori (MAP) estimation of an internal generative model and\nthe external environment. Inspired by such hypothesis, we enforce\nself-consistency in neural networks by incorporating generative recurrent\nfeedback. We instantiate this design on convolutional neural networks (CNNs).\nThe proposed framework, termed Convolutional Neural Networks with Feedback\n(CNN-F), introduces a generative feedback with latent variables to existing CNN\narchitectures, where consistent predictions are made through alternating MAP\ninference under a Bayesian framework. In the experiments, CNN-F shows\nconsiderably improved adversarial robustness over conventional feedforward CNNs\non standard benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 19:32:48 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 08:29:39 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Huang", "Yujia", ""], ["Gornet", "James", ""], ["Dai", "Sihui", ""], ["Yu", "Zhiding", ""], ["Nguyen", "Tan", ""], ["Tsao", "Doris Y.", ""], ["Anandkumar", "Anima", ""]]}, {"id": "2007.09345", "submitter": "Abraham Martin del Campo", "authors": "Ruth Davidson and Abraham Martin del Campo", "title": "Combinatorial and computational investigations of Neighbor-Joining bias", "comments": "18 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.CG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Neighbor-Joining algorithm is a popular distance-based phylogenetic\nmethod that computes a tree metric from a dissimilarity map arising from\nbiological data. Realizing dissimilarity maps as points in Euclidean space, the\nalgorithm partitions the input space into polyhedral regions indexed by the\ncombinatorial type of the trees returned. A full combinatorial description of\nthese regions has not been found yet; different sequences of Neighbor-Joining\nagglomeration events can produce the same combinatorial tree, therefore\nassociating multiple geometric regions to the same algorithmic output. We\nresolve this confusion by defining agglomeration orders on trees, leading to a\nbijection between distinct regions of the output space and weighted Motzkin\npaths. As a result, we give a formula for the number of polyhedral regions\ndepending only on the number of taxa. We conclude with a computational\ncomparison between these polyhedral regions, to unveil biases introduced in any\nimplementation of the algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 06:48:45 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 22:46:09 GMT"}, {"version": "v3", "created": "Wed, 16 Sep 2020 20:54:55 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Davidson", "Ruth", ""], ["del Campo", "Abraham Martin", ""]]}, {"id": "2007.09426", "submitter": "Ralf M\\\"oller", "authors": "Ralf M\\\"oller", "title": "Improved Convergence Speed of Fully Symmetric Learning Rules for\n  Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully symmetric learning rules for principal component analysis can be\nderived from a novel objective function suggested in our previous work. We\nobserved that these learning rules suffer from slow convergence for covariance\nmatrices where some principal eigenvalues are close to each other. Here we\ndescribe a modified objective function with an additional term which mitigates\nthis convergence problem. We show that the learning rule derived from the\nmodified objective function inherits all fixed points from the original\nlearning rule (but may introduce additional ones). Also the stability of the\ninherited fixed points remains unchanged. Only the steepness of the objective\nfunction is increased in some directions. Simulations confirm that the\nconvergence speed can be noticeably improved, depending on the weight factor of\nthe additional term.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 13:41:35 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["M\u00f6ller", "Ralf", ""]]}, {"id": "2007.09835", "submitter": "Mengshu Sun", "authors": "Wei Niu, Mengshu Sun, Zhengang Li, Jou-An Chen, Jiexiong Guan, Xipeng\n  Shen, Yanzhi Wang, Sijia Liu, Xue Lin, Bin Ren", "title": "RT3D: Achieving Real-Time Execution of 3D Convolutional Neural Networks\n  on Mobile Devices", "comments": "To appear in Proceedings of the 35th AAAI Conference on Artificial\n  Intelligence (AAAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile devices are becoming an important carrier for deep learning tasks, as\nthey are being equipped with powerful, high-end mobile CPUs and GPUs. However,\nit is still a challenging task to execute 3D Convolutional Neural Networks\n(CNNs) targeting for real-time performance, besides high inference accuracy.\nThe reason is more complex model structure and higher model dimensionality\noverwhelm the available computation/storage resources on mobile devices. A\nnatural way may be turning to deep learning weight pruning techniques. However,\nthe direct generalization of existing 2D CNN weight pruning methods to 3D CNNs\nis not ideal for fully exploiting mobile parallelism while achieving high\ninference accuracy.\n  This paper proposes RT3D, a model compression and mobile acceleration\nframework for 3D CNNs, seamlessly integrating neural network weight pruning and\ncompiler code generation techniques. We propose and investigate two structured\nsparsity schemes i.e., the vanilla structured sparsity and kernel group\nstructured (KGS) sparsity that are mobile acceleration friendly. The vanilla\nsparsity removes whole kernel groups, while KGS sparsity is a more fine-grained\nstructured sparsity that enjoys higher flexibility while exploiting full\non-device parallelism. We propose a reweighted regularization pruning algorithm\nto achieve the proposed sparsity schemes. The inference time speedup due to\nsparsity is approaching the pruning rate of the whole model FLOPs (floating\npoint operations). RT3D demonstrates up to 29.1$\\times$ speedup in end-to-end\ninference time comparing with current mobile frameworks supporting 3D CNNs,\nwith moderate 1%-1.5% accuracy loss. The end-to-end inference time for 16 video\nframes could be within 150 ms, when executing representative C3D and R(2+1)D\nmodels on a cellphone. For the first time, real-time execution of 3D CNNs is\nachieved on off-the-shelf mobiles.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 02:05:32 GMT"}, {"version": "v2", "created": "Sun, 3 Jan 2021 18:03:16 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Niu", "Wei", ""], ["Sun", "Mengshu", ""], ["Li", "Zhengang", ""], ["Chen", "Jou-An", ""], ["Guan", "Jiexiong", ""], ["Shen", "Xipeng", ""], ["Wang", "Yanzhi", ""], ["Liu", "Sijia", ""], ["Lin", "Xue", ""], ["Ren", "Bin", ""]]}, {"id": "2007.09963", "submitter": "Petar Jokic", "authors": "Petar Jokic, Stephane Emery, Luca Benini", "title": "Improving Memory Utilization in Convolutional Neural Network\n  Accelerators", "comments": null, "journal-ref": null, "doi": "10.1109/LES.2020.3009924", "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the accuracy of convolutional neural networks has achieved vast\nimprovements by introducing larger and deeper network architectures, also the\nmemory footprint for storing their parameters and activations has increased.\nThis trend especially challenges power- and resource-limited accelerator\ndesigns, which are often restricted to store all network data in on-chip memory\nto avoid interfacing energy-hungry external memories. Maximizing the network\nsize that fits on a given accelerator thus requires to maximize its memory\nutilization. While the traditionally used ping-pong buffering technique is\nmapping subsequent activation layers to disjunctive memory regions, we propose\na mapping method that allows these regions to overlap and thus utilize the\nmemory more efficiently. This work presents the mathematical model to compute\nthe maximum activations memory overlap and thus the lower bound of on-chip\nmemory needed to perform layer-by-layer processing of convolutional neural\nnetworks on memory-limited accelerators. Our experiments with various\nreal-world object detector networks show that the proposed mapping technique\ncan decrease the activations memory by up to 32.9%, reducing the overall memory\nfor the entire network by up to 23.9% compared to traditional ping-pong\nbuffering. For higher resolution de-noising networks, we achieve activation\nmemory savings of 48.8%. Additionally, we implement a face detector network on\nan FPGA-based camera to validate these memory savings on a complete end-to-end\nsystem.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 09:34:36 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 15:45:49 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Jokic", "Petar", ""], ["Emery", "Stephane", ""], ["Benini", "Luca", ""]]}, {"id": "2007.10022", "submitter": "Anthony Berthelier", "authors": "Anthony Berthelier, Yongzhe Yan, Thierry Chateau, Christophe Blanc,\n  Stefan Duffner, Christophe Garcia", "title": "Learning Sparse Filters in Deep Convolutional Neural Networks with a\n  l1/l2 Pseudo-Norm", "comments": "8 pages, 7 figures, under review for ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks (DNNs) have proven to be efficient for numerous\ntasks, they come at a high memory and computation cost, thus making them\nimpractical on resource-limited devices. However, these networks are known to\ncontain a large number of parameters. Recent research has shown that their\nstructure can be more compact without compromising their performance. In this\npaper, we present a sparsity-inducing regularization term based on the ratio\nl1/l2 pseudo-norm defined on the filter coefficients. By defining this\npseudo-norm appropriately for the different filter kernels, and removing\nirrelevant filters, the number of kernels in each layer can be drastically\nreduced leading to very compact Deep Convolutional Neural Networks (DCNN)\nstructures. Unlike numerous existing methods, our approach does not require an\niterative retraining process and, using this regularization term, directly\nproduces a sparse model during the training process. Furthermore, our approach\nis also much easier and simpler to implement than existing methods.\nExperimental results on MNIST and CIFAR-10 show that our approach significantly\nreduces the number of filters of classical models such as LeNet and VGG while\nreaching the same or even better accuracy than the baseline models. Moreover,\nthe trade-off between the sparsity and the accuracy is compared to other loss\nregularization terms based on the l1 or l2 norm as well as the SSL, NISP and\nGAL methods and shows that our approach is outperforming them.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 11:56:12 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Berthelier", "Anthony", ""], ["Yan", "Yongzhe", ""], ["Chateau", "Thierry", ""], ["Blanc", "Christophe", ""], ["Duffner", "Stefan", ""], ["Garcia", "Christophe", ""]]}, {"id": "2007.10143", "submitter": "Rumen Dangovski", "authors": "Evan Vogelbaum and Rumen Dangovski and Li Jing and Marin\n  Solja\\v{c}i\\'c", "title": "Contextualizing Enhances Gradient Based Meta Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta learning methods have found success when applied to few shot\nclassification problems, in which they quickly adapt to a small number of\nlabeled examples. Prototypical representations, each representing a particular\nclass, have been of particular importance in this setting, as they provide a\ncompact form to convey information learned from the labeled examples. However,\nthese prototypes are just one method of representing this information, and they\nare narrow in their scope and ability to classify unseen examples. We propose\nthe implementation of contextualizers, which are generalizable prototypes that\nadapt to given examples and play a larger role in classification for\ngradient-based models. We demonstrate how to equip meta learning methods with\ncontextualizers and show that their use can significantly boost performance on\na range of few shot learning datasets. We also present figures of merit\ndemonstrating the potential benefits of contextualizers, along with analysis of\nhow models make use of them. Our approach is particularly apt for low-data\nenvironments where it is difficult to update parameters without overfitting.\nOur implementation and instructions to reproduce the experiments are available\nat https://github.com/naveace/proto-context.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 04:01:56 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Vogelbaum", "Evan", ""], ["Dangovski", "Rumen", ""], ["Jing", "Li", ""], ["Solja\u010di\u0107", "Marin", ""]]}, {"id": "2007.10227", "submitter": "Travis DeWolf", "authors": "Travis DeWolf and Pawel Jaworski and Chris Eliasmith", "title": "Nengo and low-power AI hardware for robust, embedded neurorobotics", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we demonstrate how the Nengo neural modeling and simulation\nlibraries enable users to quickly develop robotic perception and action neural\nnetworks for simulation on neuromorphic hardware using familiar tools, such as\nKeras and Python. We identify four primary challenges in building robust,\nembedded neurorobotic systems: 1) developing infrastructure for interfacing\nwith the environment and sensors; 2) processing task specific sensory signals;\n3) generating robust, explainable control signals; and 4) compiling neural\nnetworks to run on target hardware. Nengo helps to address these challenges by:\n1) providing the NengoInterfaces library, which defines a simple but powerful\nAPI for users to interact with simulations and hardware; 2) providing the\nNengoDL library, which lets users use the Keras and TensorFlow API to develop\nNengo models; 3) implementing the Neural Engineering Framework, which provides\nwhite-box methods for implementing known functions and circuits; and 4)\nproviding multiple backend libraries, such as NengoLoihi, that enable users to\ncompile the same model to different hardware. We present two examples using\nNengo to develop neural networks that run on CPUs, GPUs, and Intel's\nneuromorphic chip, Loihi, to demonstrate this workflow. The first example is an\nend-to-end spiking neural network that controls a rover simulated in Mujoco.\nThe network integrates a deep convolutional network that processes visual input\nfrom mounted cameras to track a target, and a control system implementing\nsteering and drive functions to guide the rover to the target. The second\nexample augments a force-based operational space controller with neural\nadaptive control to improve performance during a reaching task using a\nreal-world Kinova Jaco2 robotic arm. Code and details are provided with the\nintent of enabling other researchers to build their own neurorobotic systems.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 16:17:27 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 19:38:40 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["DeWolf", "Travis", ""], ["Jaworski", "Pawel", ""], ["Eliasmith", "Chris", ""]]}, {"id": "2007.10396", "submitter": "Vishnu Naresh Boddeti", "authors": "Zhichao Lu and Kalyanmoy Deb and Erik Goodman and Wolfgang Banzhaf and\n  Vishnu Naresh Boddeti", "title": "NSGANetV2: Evolutionary Multi-Objective Surrogate-Assisted Neural\n  Architecture Search", "comments": "Accepted for oral presentation at ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an efficient NAS algorithm for generating\ntask-specific models that are competitive under multiple competing objectives.\nIt comprises of two surrogates, one at the architecture level to improve sample\nefficiency and one at the weights level, through a supernet, to improve\ngradient descent training efficiency. On standard benchmark datasets (C10,\nC100, ImageNet), the resulting models, dubbed NSGANetV2, either match or\noutperform models from existing approaches with the search being orders of\nmagnitude more sample efficient. Furthermore, we demonstrate the effectiveness\nand versatility of the proposed method on six diverse non-standard datasets,\ne.g. STL-10, Flowers102, Oxford Pets, FGVC Aircrafts etc. In all cases,\nNSGANetV2s improve the state-of-the-art (under mobile setting), suggesting that\nNAS can be a viable alternative to conventional transfer learning approaches in\nhandling diverse scenarios such as small-scale or fine-grained datasets. Code\nis available at https://github.com/mikelzc1990/nsganetv2\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 18:30:11 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Lu", "Zhichao", ""], ["Deb", "Kalyanmoy", ""], ["Goodman", "Erik", ""], ["Banzhaf", "Wolfgang", ""], ["Boddeti", "Vishnu Naresh", ""]]}, {"id": "2007.10497", "submitter": "Shayan Hassantabar", "authors": "Shayan Hassantabar, Novati Stefano, Vishweshwar Ghanakota, Alessandra\n  Ferrari, Gregory N. Nicola, Raffaele Bruno, Ignazio R. Marino, Kenza\n  Hamidouche, and Niraj K. Jha", "title": "CovidDeep: SARS-CoV-2/COVID-19 Test Based on Wearable Medical Sensors\n  and Efficient Neural Networks", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The novel coronavirus (SARS-CoV-2) has led to a pandemic. The current testing\nregime based on Reverse Transcription-Polymerase Chain Reaction for SARS-CoV-2\nhas been unable to keep up with testing demands, and also suffers from a\nrelatively low positive detection rate in the early stages of the resultant\nCOVID-19 disease. Hence, there is a need for an alternative approach for\nrepeated large-scale testing of SARS-CoV-2/COVID-19. We propose a framework\ncalled CovidDeep that combines efficient DNNs with commercially available WMSs\nfor pervasive testing of the virus. We collected data from 87 individuals,\nspanning three cohorts including healthy, asymptomatic, and symptomatic\npatients. We trained DNNs on various subsets of the features automatically\nextracted from six WMS and questionnaire categories to perform ablation studies\nto determine which subsets are most efficacious in terms of test accuracy for a\nthree-way classification. The highest test accuracy obtained was 98.1%. We also\naugmented the real training dataset with a synthetic training dataset drawn\nfrom the same probability distribution to impose a prior on DNN weights and\nleveraged a grow-and-prune synthesis paradigm to learn both DNN architecture\nand weights. This boosted the accuracy of the various DNNs further and\nsimultaneously reduced their size and floating-point operations.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 21:47:28 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 14:23:38 GMT"}, {"version": "v3", "created": "Wed, 28 Oct 2020 23:12:41 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Hassantabar", "Shayan", ""], ["Stefano", "Novati", ""], ["Ghanakota", "Vishweshwar", ""], ["Ferrari", "Alessandra", ""], ["Nicola", "Gregory N.", ""], ["Bruno", "Raffaele", ""], ["Marino", "Ignazio R.", ""], ["Hamidouche", "Kenza", ""], ["Jha", "Niraj K.", ""]]}, {"id": "2007.10637", "submitter": "Taewon Park", "authors": "Taewon Park, Inchul Choi, Minho Lee", "title": "Distributed Associative Memory Network with Memory Refreshing Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent progress in memory augmented neural network (MANN) research,\nassociative memory networks with a single external memory still show limited\nperformance on complex relational reasoning tasks. Especially the content-based\naddressable memory networks often fail to encode input data into rich enough\nrepresentation for relational reasoning and this limits the relation modeling\nperformance of MANN for long temporal sequence data. To address these problems,\nhere we introduce a novel Distributed Associative Memory architecture (DAM)\nwith Memory Refreshing Loss (MRL) which enhances the relation reasoning\nperformance of MANN. Inspired by how the human brain works, our framework\nencodes data with distributed representation across multiple memory blocks and\nrepeatedly refreshes the contents for enhanced memorization similar to the\nrehearsal process of the brain. For this procedure, we replace a single\nexternal memory with a set of multiple smaller associative memory blocks and\nupdate these sub-memory blocks simultaneously and independently for the\ndistributed representation of input data. Moreover, we propose MRL which\nassists a task's target objective while learning relational information\nexisting in data. MRL enables MANN to reinforce an association between input\ndata and task objective by reproducing stochastically sampled input data from\nstored memory contents. With this procedure, MANN further enriches the stored\nrepresentations with relational information. In experiments, we apply our\napproaches to Differential Neural Computer (DNC), which is one of the\nrepresentative content-based addressing memory models and achieves the\nstate-of-the-art performance on both memorization and relational reasoning\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 07:34:33 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 08:21:09 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Park", "Taewon", ""], ["Choi", "Inchul", ""], ["Lee", "Minho", ""]]}, {"id": "2007.10784", "submitter": "Rumen Dangovski", "authors": "Allan Costa and Rumen Dangovski and Owen Dugan and Samuel Kim and\n  Pawan Goyal and Marin Solja\\v{c}i\\'c and Joseph Jacobson", "title": "Fast Neural Models for Symbolic Regression at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning owes much of its success to the astonishing expressiveness of\nneural networks. However, this comes at the cost of complex, black-boxed models\nthat extrapolate poorly beyond the domain of the training dataset, conflicting\nwith goals of finding analytic expressions to describe science, engineering and\nreal world data. Under the hypothesis that the hierarchical modularity of such\nlaws can be captured by training a neural network, we introduce OccamNet, a\nneural network model that finds interpretable, compact, and sparse solutions\nfor fitting data, \\`{a} la Occam's razor. Our model defines a probability\ndistribution over a non-differentiable function space. We introduce a two-step\noptimization method that samples functions and updates the weights with\nbackpropagation based on cross-entropy matching in an evolutionary strategy: we\ntrain by biasing the probability mass toward better fitting solutions. OccamNet\nis able to fit a variety of symbolic laws including simple analytic functions,\nrecursive programs, implicit functions, simple image classification, and can\noutperform noticeably state-of-the-art symbolic regression methods on real\nworld regression datasets. Our method requires minimal memory footprint, does\nnot require AI accelerators for efficient training, fits complicated functions\nin minutes of training on a single CPU, and demonstrates significant\nperformance gains when scaled on a GPU. Our implementation, demonstrations and\ninstructions for reproducing the experiments are available at\nhttps://github.com/druidowm/OccamNet_Public.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 21:14:45 GMT"}, {"version": "v2", "created": "Sat, 10 Jul 2021 17:50:27 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Costa", "Allan", ""], ["Dangovski", "Rumen", ""], ["Dugan", "Owen", ""], ["Kim", "Samuel", ""], ["Goyal", "Pawan", ""], ["Solja\u010di\u0107", "Marin", ""], ["Jacobson", "Joseph", ""]]}, {"id": "2007.10928", "submitter": "David Wolpert", "authors": "David H. Wolpert", "title": "What is important about the No Free Lunch theorems?", "comments": "15 pages, 11 of main text, to be published in \"Black Box\n  Optimization, Machine Learning and No-Free Lunch Theorems\", P. Pardalos, V.\n  Rasskazova, M.N. Vrahatis, Ed., Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The No Free Lunch theorems prove that under a uniform distribution over\ninduction problems (search problems or learning problems), all induction\nalgorithms perform equally. As I discuss in this chapter, the importance of the\ntheorems arises by using them to analyze scenarios involving {non-uniform}\ndistributions, and to compare different algorithms, without any assumption\nabout the distribution over problems at all. In particular, the theorems prove\nthat {anti}-cross-validation (choosing among a set of candidate algorithms\nbased on which has {worst} out-of-sample behavior) performs as well as\ncross-validation, unless one makes an assumption -- which has never been\nformalized -- about how the distribution over induction problems, on the one\nhand, is related to the set of algorithms one is choosing among using\n(anti-)cross validation, on the other. In addition, they establish strong\ncaveats concerning the significance of the many results in the literature which\nestablish the strength of a particular algorithm without assuming a particular\ndistribution. They also motivate a ``dictionary'' between supervised learning\nand improve blackbox optimization, which allows one to ``translate'' techniques\nfrom supervised learning into the domain of blackbox optimization, thereby\nstrengthening blackbox optimization algorithms. In addition to these topics, I\nalso briefly discuss their implications for philosophy of science.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 16:42:36 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Wolpert", "David H.", ""]]}, {"id": "2007.11845", "submitter": "Hamit Basgol", "authors": "Hamit Basgol, Inci Ayhan, Emre Ugur", "title": "Time Perception: A Review on Psychological, Computational and Robotic\n  Models", "comments": "15 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals exploit time to survive in the world. Temporal information is\nrequired for higher-level cognitive abilities such as planning, decision\nmaking, communication, and effective cooperation. Since time is an inseparable\npart of cognition, there is a growing interest in the artificial intelligence\napproach to subjective time, which has a possibility of advancing the field.\nThe current survey study aims to provide researchers with an interdisciplinary\nperspective on time perception. Firstly, we introduce a brief background from\nthe psychology and neuroscience literature, covering the characteristics and\nmodels of time perception and related abilities. Secondly, we summarize the\nemergent computational and robotic models of time perception. A general\noverview to the literature reveals that a substantial amount of timing models\nare based on a dedicated time processing like the emergence of a clock-like\nmechanism from the neural network dynamics and reveal a relationship between\nthe embodiment and time perception. We also notice that most models of timing\nare developed for either sensory timing (i.e. ability to assess an interval) or\nmotor timing (i.e. ability to reproduce an interval). The number of timing\nmodels capable of retrospective timing, which is the ability to track time\nwithout paying attention, is insufficient. In this light, we discuss the\npossible research directions to promote interdisciplinary collaboration in the\nfield of time perception.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 08:16:47 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 23:30:12 GMT"}, {"version": "v3", "created": "Fri, 25 Dec 2020 08:23:33 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Basgol", "Hamit", ""], ["Ayhan", "Inci", ""], ["Ugur", "Emre", ""]]}, {"id": "2007.11893", "submitter": "Maurizio Ferrari Dacrema", "authors": "Maurizio Ferrari Dacrema, Federico Parroni, Paolo Cremonesi, Dietmar\n  Jannach", "title": "Critically Examining the Claimed Value of Convolutions over User-Item\n  Embedding Maps for Recommender Systems", "comments": "Source code available here:\n  https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation", "journal-ref": "The 29th ACM International Conference on Information and Knowledge\n  Management (CIKM '20), October 19--23, 2020, Virtual Event, Ireland", "doi": "10.1145/3340531.3411901", "report-no": null, "categories": "cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, algorithm research in the area of recommender systems has\nshifted from matrix factorization techniques and their latent factor models to\nneural approaches. However, given the proven power of latent factor models,\nsome newer neural approaches incorporate them within more complex network\narchitectures. One specific idea, recently put forward by several researchers,\nis to consider potential correlations between the latent factors, i.e.,\nembeddings, by applying convolutions over the user-item interaction map.\nHowever, contrary to what is claimed in these articles, such interaction maps\ndo not share the properties of images where Convolutional Neural Networks\n(CNNs) are particularly useful. In this work, we show through analytical\nconsiderations and empirical evaluations that the claimed gains reported in the\nliterature cannot be attributed to the ability of CNNs to model embedding\ncorrelations, as argued in the original papers. Moreover, additional\nperformance evaluations show that all of the examined recent CNN-based models\nare outperformed by existing non-neural machine learning techniques or\ntraditional nearest-neighbor approaches. On a more general level, our work\npoints to major methodological issues in recommender systems research.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 10:03:47 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 18:53:28 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Dacrema", "Maurizio Ferrari", ""], ["Parroni", "Federico", ""], ["Cremonesi", "Paolo", ""], ["Jannach", "Dietmar", ""]]}, {"id": "2007.11894", "submitter": "Hyeryung Jang", "authors": "Hyeryung Jang and Osvaldo Simeone", "title": "Multi-Sample Online Learning for Probabilistic Spiking Neural Networks", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) capture some of the efficiency of biological\nbrains for inference and learning via the dynamic, online, event-driven\nprocessing of binary time series. Most existing learning algorithms for SNNs\nare based on deterministic neuronal models, such as leaky integrate-and-fire,\nand rely on heuristic approximations of backpropagation through time that\nenforce constraints such as locality. In contrast, probabilistic SNN models can\nbe trained directly via principled online, local, update rules that have proven\nto be particularly effective for resource-constrained systems. This paper\ninvestigates another advantage of probabilistic SNNs, namely their capacity to\ngenerate independent outputs when queried over the same input. It is shown that\nthe multiple generated output samples can be used during inference to robustify\ndecisions and to quantify uncertainty -- a feature that deterministic SNN\nmodels cannot provide. Furthermore, they can be leveraged for training in order\nto obtain more accurate statistical estimates of the log-loss training\ncriterion, as well as of its gradient. Specifically, this paper introduces an\nonline learning rule based on generalized expectation-maximization (GEM) that\nfollows a three-factor form with global learning signals and is referred to as\nGEM-SNN. Experimental results on structured output memorization and\nclassification on a standard neuromorphic data set demonstrate significant\nimprovements in terms of log-likelihood, accuracy, and calibration when\nincreasing the number of samples used for inference and training.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 10:03:58 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 11:44:25 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Jang", "Hyeryung", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "2007.12063", "submitter": "Olga Krestinskaya", "authors": "Olga Krestinskaya, Bhaskar Choubey, Alex Pappachen James", "title": "AM-DCGAN: Analog Memristive Hardware Accelerator for Deep Convolutional\n  Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Network (GAN) is a well known computationally complex\nalgorithm requiring signficiant computational resources in software\nimplementations including large amount of data to be trained. This makes its\nimplementation in edge devices with conventional microprocessor hardware a slow\nand difficult task. In this paper, we propose to accelerate the computationally\nintensive GAN using memristive neural networks in analog domain. We present a\nfully analog hardware design of Deep Convolutional GAN (DCGAN) based on\nCMOS-memristive convolutional and deconvolutional networks simulated using\n180nm CMOS technology.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2020 15:37:29 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Krestinskaya", "Olga", ""], ["Choubey", "Bhaskar", ""], ["James", "Alex Pappachen", ""]]}, {"id": "2007.12076", "submitter": "Aditya Srivastava", "authors": "Aditya Srivastava, V. Harsha Vardhan", "title": "HCMS at SemEval-2020 Task 9: A Neural Approach to Sentiment Analysis for\n  Code-Mixed Texts", "comments": "6 pages, 2 figures, 4 tables, math equations, to be published in the\n  proceedings of the 14th International Workshop on Semantic Evaluation\n  (SemEval) 2020, Association for Computational Linguistics (ACL). Code for the\n  paper is available at https://github.com/IamAdiSri/hcms-semeval20 . Data and\n  task description is available at\n  https://competitions.codalab.org/competitions/20654", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problems involving code-mixed language are often plagued by a lack of\nresources and an absence of materials to perform sophisticated transfer\nlearning with. In this paper we describe our submission to the Sentimix\nHindi-English task involving sentiment classification of code-mixed texts, and\nwith an F1 score of 67.1%, we demonstrate that simple convolution and attention\nmay well produce reasonable results.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 15:39:53 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Srivastava", "Aditya", ""], ["Vardhan", "V. Harsha", ""]]}, {"id": "2007.12141", "submitter": "Juan-Pablo Ortega", "authors": "Lyudmila Grigoryeva and Juan-Pablo Ortega", "title": "Dimension reduction in recurrent networks by canonicalization", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recurrent neural network machine learning paradigms can be formulated\nusing state-space representations. The classical notion of canonical\nstate-space realization is adapted in this paper to accommodate semi-infinite\ninputs so that it can be used as a dimension reduction tool in the recurrent\nnetworks setup. The so called input forgetting property is identified as the\nkey hypothesis that guarantees the existence and uniqueness (up to system\nisomorphisms) of canonical realizations for causal and time-invariant\ninput/output systems with semi-infinite inputs. A second result uses the notion\nof optimal reduction borrowed from the theory of symmetric Hamiltonian systems\nto construct canonical realizations out of input forgetting but not necessarily\ncanonical ones. These two procedures are implemented and studied in detail in\nthe framework of linear fading memory input/output systems.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 17:12:37 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Grigoryeva", "Lyudmila", ""], ["Ortega", "Juan-Pablo", ""]]}, {"id": "2007.12159", "submitter": "Eitan Frachtenberg", "authors": "Hrishee Shastri, Eitan Frachtenberg", "title": "Revisiting Locality in Binary-Integer Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Mutation and recombination operators play a key role in determining the speed\nand quality of Genetic and Evolutionary Algorithms (GEAs). Prior work has\nanalyzed the effects of these operators on genotypic variation, often using\nlocality metrics that measure the sensitivity and stability of\ngenotype-phenotype representations to these operators.\n  In this paper, we focus on an important subset of representations, namely\nnonredundant bitstring-to-integer representations, and analyze them through the\nlens of Rothlauf's widely used locality metrics. We first define locality\nmetrics equivalent to Rothlauf's that are tailored to our domain: the\n\\textit{point locality} for single-bit mutation and \\textit{general locality}\nfor recombination. With these definitions, we derive tight bounds and a closed\nform expected value for point locality. For general locality we show that it is\nasymptotically equivalent across all representations and operators. We also\nrecreate three established GEA experiments to understand the predictive power\nof point locality on GEA performance, focusing on two popular and often\njuxtaposed representations: standard binary and binary reflected Gray.\n  We show that standard binary has provably no worse locality than any Gray\nencoding, including binary reflected Gray. We discuss this result in the\ncontext of previous studies that found binary reflected Gray to outperform\nstandard binary, and we argue that locality cannot be the explanation for\nstrong performance. Finally, we provide empirical evidence that weak point\nlocality representations can be beneficial to performance in the exploration\nphase of the GEA, while strong point locality representations are more\nbeneficial in the exploitation phase.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 17:46:18 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2020 23:43:58 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Shastri", "Hrishee", ""], ["Frachtenberg", "Eitan", ""]]}, {"id": "2007.12213", "submitter": "Marco A. Armenta", "authors": "Marco Antonio Armenta and Pierre-Marc Jodoin", "title": "The Representation Theory of Neural Networks", "comments": "52 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.RT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we show that neural networks can be represented via the\nmathematical theory of quiver representations. More specifically, we prove that\na neural network is a quiver representation with activation functions, a\nmathematical object that we represent using a network quiver. Also, we show\nthat network quivers gently adapt to common neural network concepts such as\nfully-connected layers, convolution operations, residual connections, batch\nnormalization, pooling operations and even randomly wired neural networks. We\nshow that this mathematical representation is by no means an approximation of\nwhat neural networks are as it exactly matches reality. This interpretation is\nalgebraic and can be studied with algebraic methods. We also provide a quiver\nrepresentation model to understand how a neural network creates representations\nfrom the data. We show that a neural network saves the data as quiver\nrepresentations, and maps it to a geometrical space called the moduli space,\nwhich is given in terms of the underlying oriented graph of the network, i.e.,\nits quiver. This results as a consequence of our defined objects and of\nunderstanding how the neural network computes a prediction in a combinatorial\nand algebraic way. Overall, representing neural networks through the quiver\nrepresentation theory leads to 9 consequences and 4 inquiries for future\nresearch that we believe are of great interest to better understand what neural\nnetworks are and how they work.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 19:02:14 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 19:20:35 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Armenta", "Marco Antonio", ""], ["Jodoin", "Pierre-Marc", ""]]}, {"id": "2007.12223", "submitter": "Tianlong Chen", "authors": "Tianlong Chen, Jonathan Frankle, Shiyu Chang, Sijia Liu, Yang Zhang,\n  Zhangyang Wang, Michael Carbin", "title": "The Lottery Ticket Hypothesis for Pre-trained BERT Networks", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural language processing (NLP), enormous pre-trained models like BERT\nhave become the standard starting point for training on a range of downstream\ntasks, and similar trends are emerging in other areas of deep learning. In\nparallel, work on the lottery ticket hypothesis has shown that models for NLP\nand computer vision contain smaller matching subnetworks capable of training in\nisolation to full accuracy and transferring to other tasks. In this work, we\ncombine these observations to assess whether such trainable, transferrable\nsubnetworks exist in pre-trained BERT models. For a range of downstream tasks,\nwe indeed find matching subnetworks at 40% to 90% sparsity. We find these\nsubnetworks at (pre-trained) initialization, a deviation from prior NLP\nresearch where they emerge only after some amount of training. Subnetworks\nfound on the masked language modeling task (the same task used to pre-train the\nmodel) transfer universally; those found on other tasks transfer in a limited\nfashion if at all. As large-scale pre-training becomes an increasingly central\nparadigm in deep learning, our results demonstrate that the main lottery ticket\nobservations remain relevant in this context. Codes available at\nhttps://github.com/VITA-Group/BERT-Tickets.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 19:35:39 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2020 20:10:29 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Chen", "Tianlong", ""], ["Frankle", "Jonathan", ""], ["Chang", "Shiyu", ""], ["Liu", "Sijia", ""], ["Zhang", "Yang", ""], ["Wang", "Zhangyang", ""], ["Carbin", "Michael", ""]]}, {"id": "2007.12332", "submitter": "Shahryar Rahnamayan", "authors": "Kyle Robert Harrison, Azam Asilian Bidgoli, Shahryar Rahnamayan,\n  Kalyanmoy Deb", "title": "Image-Based Benchmarking and Visualization for Large-Scale Global\n  Optimization", "comments": "Preprint submitted to Applied Intelligence. 43 pages, 30 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of optimization, visualization techniques can be useful for\nunderstanding the behaviour of optimization algorithms and can even provide a\nmeans to facilitate human interaction with an optimizer. Towards this goal, an\nimage-based visualization framework, without dimension reduction, that\nvisualizes the solutions to large-scale global optimization problems as images\nis proposed. In the proposed framework, the pixels visualize decision variables\nwhile the entire image represents the overall solution quality. This framework\naffords a number of benefits over existing visualization techniques including\nenhanced scalability (in terms of the number of decision variables),\nfacilitation of standard image processing techniques, providing nearly infinite\nbenchmark cases, and explicit alignment with human perception. Furthermore,\nimage-based visualization can be used to visualize the optimization process in\nreal-time, thereby allowing the user to ascertain characteristics of the search\nprocess as it is progressing. To the best of the authors' knowledge, this is\nthe first realization of a dimension-preserving, scalable visualization\nframework that embeds the inherent relationship between decision space and\nobjective space. The proposed framework is utilized with 10 different mapping\nschemes on an image-reconstruction problem that encompass continuous, discrete,\nbinary, combinatorial, constrained, dynamic, and multi-objective optimization.\nThe proposed framework is then demonstrated on arbitrary benchmark problems\nwith known optima. Experimental results elucidate the flexibility and\ndemonstrate how valuable information about the search process can be gathered\nvia the proposed visualization framework.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 03:39:23 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Harrison", "Kyle Robert", ""], ["Bidgoli", "Azam Asilian", ""], ["Rahnamayan", "Shahryar", ""], ["Deb", "Kalyanmoy", ""]]}, {"id": "2007.12371", "submitter": "Hans-Christian Ruiz Euler Dr.", "authors": "Hans-Christian Ruiz-Euler, Unai Alegre-Ibarra, Bram van de Ven, Hajo\n  Broersma, Peter A. Bobbert, Wilfred G. van der Wiel", "title": "Dopant Network Processing Units: Towards Efficient Neural-network\n  Emulators with High-capacity Nanoelectronic Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.ET cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapidly growing computational demands of deep neural networks require\nnovel hardware designs. Recently, tunable nanoelectronic devices were developed\nbased on hopping electrons through a network of dopant atoms in silicon. These\n\"Dopant Network Processing Units\" (DNPUs) are highly energy-efficient and have\npotentially very high throughput. By adapting the control voltages applied to\nits terminals, a single DNPU can solve a variety of linearly non-separable\nclassification problems. However, using a single device has limitations due to\nthe implicit single-node architecture. This paper presents a promising novel\napproach to neural information processing by introducing DNPUs as high-capacity\nneurons and moving from a single to a multi-neuron framework. By implementing\nand testing a small multi-DNPU classifier in hardware, we show that\nfeed-forward DNPU networks improve the performance of a single DNPU from 77% to\n94% test accuracy on a binary classification task with concentric classes on a\nplane. Furthermore, motivated by the integration of DNPUs with memristor\narrays, we study the potential of using DNPUs in combination with linear\nlayers. We show by simulation that a single-layer MNIST classifier with only 10\nDNPUs achieves over 96% test accuracy. Our results pave the road towards\nhardware neural-network emulators that offer atomic-scale information\nprocessing with low latency and energy consumption.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 06:35:44 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Ruiz-Euler", "Hans-Christian", ""], ["Alegre-Ibarra", "Unai", ""], ["van de Ven", "Bram", ""], ["Broersma", "Hajo", ""], ["Bobbert", "Peter A.", ""], ["van der Wiel", "Wilfred G.", ""]]}, {"id": "2007.12499", "submitter": "Aditya Shrivastava", "authors": "Aditya Shrivastava", "title": "Adma: A Flexible Loss Function for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Highly increased interest in Artificial Neural Networks (ANNs) have resulted\nin impressively wide-ranging improvements in its structure. In this work, we\ncome up with the idea that instead of static plugins that the currently\navailable loss functions are, they should by default be flexible in nature. A\nflexible loss function can be a more insightful navigator for neural networks\nleading to higher convergence rates and therefore reaching the optimum accuracy\nmore quickly. The insights to help decide the degree of flexibility can be\nderived from the complexity of ANNs, the data distribution, selection of\nhyper-parameters and so on. In the wake of this, we introduce a novel flexible\nloss function for neural networks. The function is shown to characterize a\nrange of fundamentally unique properties from which, much of the properties of\nother loss functions are only a subset and varying the flexibility parameter in\nthe function allows it to emulate the loss curves and the learning behavior of\nprevalent static loss functions. The extensive experimentation performed with\nthe loss function demonstrates that it is able to give state-of-the-art\nperformance on selected data sets. Thus, in all the idea of flexibility itself\nand the proposed function built upon it carry the potential to open to a new\ninteresting chapter in deep learning research.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 02:41:09 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Shrivastava", "Aditya", ""]]}, {"id": "2007.12515", "submitter": "Liangming Chen", "authors": "Liangming Chen, Long Jin, Xiujuan Du, Shuai Li, and Mei Liu", "title": "Deforming the Loss Surface", "comments": "This paper is not perfect yet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep learning, it is usually assumed that the shape of the loss surface is\nfixed. Differently, a novel concept of deformation operator is first proposed\nin this paper to deform the loss surface, thereby improving the optimization.\nDeformation function, as a type of deformation operator, can improve the\ngeneralization performance. Moreover, various deformation functions are\ndesigned, and their contributions to the loss surface are further provided.\nThen, the original stochastic gradient descent optimizer is theoretically\nproved to be a flat minima filter that owns the talent to filter out the sharp\nminima. Furthermore, the flatter minima could be obtained by exploiting the\nproposed deformation functions, which is verified on CIFAR-100, with\nvisualizations of loss landscapes near the critical points obtained by both the\noriginal optimizer and optimizer enhanced by deformation functions. The\nexperimental results show that deformation functions do find flatter regions.\nMoreover, on ImageNet, CIFAR-10, and CIFAR-100, popular convolutional neural\nnetworks enhanced by deformation functions are compared with the corresponding\noriginal models, where significant improvements are observed on all of the\ninvolved models equipped with deformation functions. For example, the top-1\ntest accuracy of ResNet-20 on CIFAR-100 increases by 1.46%, with insignificant\nadditional computational overhead.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 13:17:46 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 02:15:37 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Chen", "Liangming", ""], ["Jin", "Long", ""], ["Du", "Xiujuan", ""], ["Li", "Shuai", ""], ["Liu", "Mei", ""]]}, {"id": "2007.12562", "submitter": "Carola Figueroa Flores", "authors": "Carola Figueroa-Flores, Bogdan Raducanu, David Berga, and Joost van de\n  Weijer", "title": "Hallucinating Saliency Maps for Fine-Grained Image Classification for\n  Limited Data Domains", "comments": "Accepted to VISIGRAPP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most of the saliency methods are evaluated on their ability to generate\nsaliency maps, and not on their functionality in a complete vision pipeline,\nlike for instance, image classification. In the current paper, we propose an\napproach which does not require explicit saliency maps to improve image\nclassification, but they are learned implicitely, during the training of an\nend-to-end image classification task. We show that our approach obtains similar\nresults as the case when the saliency maps are provided explicitely. Combining\nRGB data with saliency maps represents a significant advantage for object\nrecognition, especially for the case when training data is limited. We validate\nour method on several datasets for fine-grained classification tasks (Flowers,\nBirds and Cars). In addition, we show that our saliency estimation method,\nwhich is trained without any saliency groundtruth data, obtains competitive\nresults on real image saliency benchmark (Toronto), and outperforms deep\nsaliency models with synthetic images (SID4VAM).\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 15:08:55 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 11:09:47 GMT"}, {"version": "v3", "created": "Wed, 3 Feb 2021 10:29:57 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Figueroa-Flores", "Carola", ""], ["Raducanu", "Bogdan", ""], ["Berga", "David", ""], ["van de Weijer", "Joost", ""]]}, {"id": "2007.12723", "submitter": "Thomas Bohnstingl", "authors": "Thomas Bohnstingl, Stanis{\\l}aw Wo\\'zniak, Wolfgang Maass, Angeliki\n  Pantazi and Evangelos Eleftheriou", "title": "Online Spatio-Temporal Learning in Deep Neural Networks", "comments": "Main manuscript: 9 pages, 3 figures, 1 table, Supplementary notes: 13\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological neural networks are equipped with an inherent capability to\ncontinuously adapt through online learning. This aspect remains in stark\ncontrast to learning with error backpropagation through time (BPTT) applied to\nrecurrent neural networks (RNNs), or recently to biologically-inspired spiking\nneural networks (SNNs). BPTT involves offline computation of the gradients due\nto the requirement to unroll the network through time. Online learning has\nrecently regained the attention of the research community, focusing either on\napproaches that approximate BPTT or on biologically-plausible schemes applied\nto SNNs. Here we present an alternative perspective that is based on a clear\nseparation of spatial and temporal gradient components. Combined with insights\nfrom biology, we derive from first principles a novel online learning algorithm\nfor deep SNNs, called online spatio-temporal learning (OSTL). For shallow\nnetworks, OSTL is gradient-equivalent to BPTT enabling for the first time\nonline training of SNNs with BPTT-equivalent gradients. In addition, the\nproposed formulation unveils a class of SNN architectures trainable online at\nlow time complexity. Moreover, we extend OSTL to a generic form, applicable to\na wide range of network architectures, including networks comprising long\nshort-term memory (LSTM) and gated recurrent units (GRU). We demonstrate the\noperation of our algorithm on various tasks from language modelling to speech\nrecognition and obtain results on par with the BPTT baselines. The proposed\nalgorithm provides a framework for developing succinct and efficient online\ntraining approaches for SNNs and in general deep RNNs.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 18:10:18 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 12:54:20 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Bohnstingl", "Thomas", ""], ["Wo\u017aniak", "Stanis\u0142aw", ""], ["Maass", "Wolfgang", ""], ["Pantazi", "Angeliki", ""], ["Eleftheriou", "Evangelos", ""]]}, {"id": "2007.12813", "submitter": "Aydogan Ozcan", "authors": "Onur Kulce, Deniz Mengu, Yair Rivenson, Aydogan Ozcan", "title": "All-Optical Information Processing Capacity of Diffractive Surfaces", "comments": "31 Pages, 6 Figures, 1 Table", "journal-ref": "Light: Science & Applications (2021)", "doi": "10.1038/s41377-020-00439-9", "report-no": null, "categories": "eess.IV cs.CV cs.NE physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precise engineering of materials and surfaces has been at the heart of some\nof the recent advances in optics and photonics. These advances around the\nengineering of materials with new functionalities have also opened up exciting\navenues for designing trainable surfaces that can perform computation and\nmachine learning tasks through light-matter interaction and diffraction. Here,\nwe analyze the information processing capacity of coherent optical networks\nformed by diffractive surfaces that are trained to perform an all-optical\ncomputational task between a given input and output field-of-view. We show that\nthe dimensionality of the all-optical solution space covering the\ncomplex-valued transformations between the input and output fields-of-view is\nlinearly proportional to the number of diffractive surfaces within the optical\nnetwork, up to a limit that is dictated by the extent of the input and output\nfields-of-view. Deeper diffractive networks that are composed of larger numbers\nof trainable surfaces can cover a higher dimensional subspace of the\ncomplex-valued linear transformations between a larger input field-of-view and\na larger output field-of-view, and exhibit depth advantages in terms of their\nstatistical inference, learning and generalization capabilities for different\nimage classification tasks, when compared with a single trainable diffractive\nsurface. These analyses and conclusions are broadly applicable to various forms\nof diffractive surfaces, including e.g., plasmonic and/or dielectric-based\nmetasurfaces and flat optics that can be used to form all-optical processors.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 00:40:46 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 03:49:56 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Kulce", "Onur", ""], ["Mengu", "Deniz", ""], ["Rivenson", "Yair", ""], ["Ozcan", "Aydogan", ""]]}, {"id": "2007.13024", "submitter": "C.-H. Huck Yang", "authors": "Jun Qi, Hu Hu, Yannan Wang, Chao-Han Huck Yang, Sabato Marco\n  Siniscalchi, Chin-Hui Lee", "title": "Exploring Deep Hybrid Tensor-to-Vector Network Architectures for\n  Regression Based Speech Enhancement", "comments": "Accepted to InterSpeech 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates different trade-offs between the number of model\nparameters and enhanced speech qualities by employing several deep\ntensor-to-vector regression models for speech enhancement. We find that a\nhybrid architecture, namely CNN-TT, is capable of maintaining a good quality\nperformance with a reduced model parameter size. CNN-TT is composed of several\nconvolutional layers at the bottom for feature extraction to improve speech\nquality and a tensor-train (TT) output layer on the top to reduce model\nparameters. We first derive a new upper bound on the generalization power of\nthe convolutional neural network (CNN) based vector-to-vector regression\nmodels. Then, we provide experimental evidence on the Edinburgh noisy speech\ncorpus to demonstrate that, in single-channel speech enhancement, CNN\noutperforms DNN at the expense of a small increment of model sizes. Besides,\nCNN-TT slightly outperforms the CNN counterpart by utilizing only 32\\% of the\nCNN model parameters. Besides, further performance improvement can be attained\nif the number of CNN-TT parameters is increased to 44\\% of the CNN model size.\nFinally, our experiments of multi-channel speech enhancement on a simulated\nnoisy WSJ0 corpus demonstrate that our proposed hybrid CNN-TT architecture\nachieves better results than both DNN and CNN models in terms of\nbetter-enhanced speech qualities and smaller parameter sizes.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 22:21:05 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 00:07:39 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Qi", "Jun", ""], ["Hu", "Hu", ""], ["Wang", "Yannan", ""], ["Yang", "Chao-Han Huck", ""], ["Siniscalchi", "Sabato Marco", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2007.13044", "submitter": "Xavier-Lewis Palmer", "authors": "Akwarandu Ugo Nwachuku, Xavier Lewis-Palmer, Darlington Ahiale Akogo", "title": "A Preliminary Exploration into an Alternative CellLineNet: An\n  Evolutionary Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV eess.IV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Within this paper, the exploration of an evolutionary approach to an\nalternative CellLineNet: a convolutional neural network adept at the\nclassification of epithelial breast cancer cell lines, is presented. This\nevolutionary algorithm introduces control variables that guide the search of\narchitectures in the search space of inverted residual blocks, bottleneck\nblocks, residual blocks and a basic 2x2 convolutional block. The promise of\nEvoCELL is predicting what combination or arrangement of the feature extracting\nblocks that produce the best model architecture for a given task. Therein, the\nperformance of how the fittest model evolved after each generation is shown.\nThe final evolved model CellLineNet V2 classifies 5 types of epithelial breast\ncell lines consisting of two human cancer lines, 2 normal immortalized lines,\nand 1 immortalized mouse line (MDA-MB-468, MCF7, 10A, 12A and HC11). The\nMulticlass Cell Line Classification Convolutional Neural Network extends our\nearlier work on a Binary Breast Cancer Cell Line Classification model. This\npaper presents an on-going exploratory approach to neural network architecture\ndesign and is presented for further study.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 02:36:56 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Nwachuku", "Akwarandu Ugo", ""], ["Lewis-Palmer", "Xavier", ""], ["Akogo", "Darlington Ahiale", ""]]}, {"id": "2007.13101", "submitter": "Renlong Jie", "authors": "Renlong Jie, Junbin Gao, Andrey Vasnev, Min-ngoc Tran", "title": "Regularized Flexible Activation Function Combinations for Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activation in deep neural networks is fundamental to achieving non-linear\nmappings. Traditional studies mainly focus on finding fixed activations for a\nparticular set of learning tasks or model architectures. The research on\nflexible activation is quite limited in both designing philosophy and\napplication scenarios. In this study, three principles of choosing flexible\nactivation components are proposed and a general combined form of flexible\nactivation functions is implemented. Based on this, a novel family of flexible\nactivation functions that can replace sigmoid or tanh in LSTM cells are\nimplemented, as well as a new family by combining ReLU and ELUs. Also, two new\nregularisation terms based on assumptions as prior knowledge are introduced. It\nhas been shown that LSTM models with proposed flexible activations P-Sig-Ramp\nprovide significant improvements in time series forecasting, while the proposed\nP-E2-ReLU achieves better and more stable performance on lossy image\ncompression tasks with convolutional auto-encoders. In addition, the proposed\nregularization terms improve the convergence, performance and stability of the\nmodels with flexible activation functions.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2020 11:32:52 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 13:45:49 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Jie", "Renlong", ""], ["Gao", "Junbin", ""], ["Vasnev", "Andrey", ""], ["Tran", "Min-ngoc", ""]]}, {"id": "2007.13296", "submitter": "Andrew Stephan", "authors": "Andrew Stephan, Brian Gardner, Steven J. Koester, Andre Gruning", "title": "Supervised Learning in Temporally-Coded Spiking Neural Networks with\n  Approximate Backpropagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a new supervised learning method for\ntemporally-encoded multilayer spiking networks to perform classification. The\nmethod employs a reinforcement signal that mimics backpropagation but is far\nless computationally intensive. The weight update calculation at each layer\nrequires only local data apart from this signal. We also employ a rule capable\nof producing specific output spike trains; by setting the target spike time\nequal to the actual spike time with a slight negative offset for key high-value\nneurons the actual spike time becomes as early as possible. In simulated MNIST\nhandwritten digit classification, two-layer networks trained with this rule\nmatched the performance of a comparable backpropagation based non-spiking\nnetwork.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 03:39:49 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Stephan", "Andrew", ""], ["Gardner", "Brian", ""], ["Koester", "Steven J.", ""], ["Gruning", "Andre", ""]]}, {"id": "2007.13352", "submitter": "Lie Meng Pang", "authors": "Lie Meng Pang, Hisao Ishibuchi and Ke Shang", "title": "Algorithm Configurations of MOEA/D with an Unbounded External Archive", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the evolutionary multi-objective optimization (EMO) community, it is\nusually assumed that the final population is presented to the decision maker as\nthe result of the execution of an EMO algorithm. Recently, an unbounded\nexternal archive was used to evaluate the performance of EMO algorithms in some\nstudies where a pre-specified number of solutions are selected from all the\nexamined non-dominated solutions. In this framework, which is referred to as\nthe solution selection framework, the final population does not have to be a\ngood solution set. Thus, the solution selection framework offers higher\nflexibility to the design of EMO algorithms than the final population\nframework. In this paper, we examine the design of MOEA/D under these two\nframeworks. First, we show that the performance of MOEA/D is improved by\nlinearly changing the reference point specification during its execution\nthrough computational experiments with various combinations of initial and\nfinal specifications. Robust and high performance of the solution selection\nframework is observed. Then, we examine the use of a genetic algorithm-based\noffline hyper-heuristic method to find the best configuration of MOEA/D in each\nframework. Finally, we further discuss solution selection after the execution\nof an EMO algorithm in the solution selection framework.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 08:14:37 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Pang", "Lie Meng", ""], ["Ishibuchi", "Hisao", ""], ["Shang", "Ke", ""]]}, {"id": "2007.13476", "submitter": "Ahmed Mohamadeen", "authors": "Mona Nasr, Omar Farouk, Ahmed Mohamedeen, Ali Elrafie, Marwan Bedeir\n  and Ali Khaled", "title": "Benchmarking Meta-heuristic Optimization", "comments": "International Journal of Advanced Networking and Applications - IJANA", "journal-ref": null, "doi": "10.35444/IJANA.2020.11063", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving an optimization task in any domain is a very challenging problem,\nespecially when dealing with nonlinear problems and non-convex functions. Many\nmeta-heuristic algorithms are very efficient when solving nonlinear functions.\nA meta-heuristic algorithm is a problem-independent technique that can be\napplied to a broad range of problems. In this experiment, some of the\nevolutionary algorithms will be tested, evaluated, and compared with each\nother. We will go through the Genetic Algorithm\\, Differential Evolution,\nParticle Swarm Optimization Algorithm, Grey Wolf Optimizer, and Simulated\nAnnealing. They will be evaluated against the performance from many points of\nview like how the algorithm performs throughout generations and how the\nalgorithm's result is close to the optimal result. Other points of evaluation\nare discussed in depth in later sections.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 12:25:31 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Nasr", "Mona", ""], ["Farouk", "Omar", ""], ["Mohamedeen", "Ahmed", ""], ["Elrafie", "Ali", ""], ["Bedeir", "Marwan", ""], ["Khaled", "Ali", ""]]}, {"id": "2007.13489", "submitter": "Saavan Patel", "authors": "Saavan Patel, Philip Canoza, Sayeef Salahuddin", "title": "Logically Synthesized, Hardware-Accelerated, Restricted Boltzmann\n  Machines for Combinatorial Optimization and Integer Factorization", "comments": "14 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Restricted Boltzmann Machine (RBM) is a stochastic neural network capable\nof solving a variety of difficult tasks such as NP-Hard combinatorial\noptimization problems and integer factorization. The RBM architecture is also\nvery compact; requiring very few weights and biases. This, along with its\nsimple, parallelizable sampling algorithm for finding the ground state of such\nproblems, makes the RBM amenable to hardware acceleration. However, training of\nthe RBM on these problems can pose a significant challenge, as the training\nalgorithm tends to fail for large problem sizes and efficient mappings can be\nhard to find. Here, we propose a method of combining RBMs together that avoids\nthe need to train large problems in their full form. We also propose methods\nfor making the RBM more hardware amenable, allowing the algorithm to be\nefficiently mapped to an FPGA-based accelerator. Using this accelerator, we are\nable to show hardware accelerated factorization of 16 bit numbers with high\naccuracy with a speed improvement of 10000x and a power improvement of 32x.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 17:44:17 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 17:06:58 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Patel", "Saavan", ""], ["Canoza", "Philip", ""], ["Salahuddin", "Sayeef", ""]]}, {"id": "2007.13492", "submitter": "Daniel Buades Marcos", "authors": "Daniel Buades Marcos, Soumaya Yacout, Said Berriah", "title": "Self-Supervised Encoder for Fault Prediction in Electrochemical Cells", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting faults before they occur helps to avoid potential safety hazards.\nFurthermore, planning the required maintenance actions in advance reduces\noperation costs. In this article, the focus is on electrochemical cells. In\norder to predict a cell's fault, the typical approach is to estimate the\nexpected voltage that a healthy cell would present and compare it with the\ncell's measured voltage in real-time. This approach is possible because, when a\nfault is about to happen, the cell's measured voltage differs from the one\nexpected for the same operating conditions. However, estimating the expected\nvoltage is challenging, as the voltage of a healthy cell is also affected by\nits degradation -- an unknown parameter. Expert-defined parametric models are\ncurrently used for this estimation task. Instead, we propose the use of a\nneural network model based on an encoder-decoder architecture. The network\nreceives the operating conditions as input. The encoder's task is to find a\nfaithful representation of the cell's degradation and to pass it to the\ndecoder, which in turn predicts the expected cell's voltage. As no labeled\ndegradation data is given to the network, we consider our approach to be a\nself-supervised encoder. Results show that we were able to predict the voltage\nof multiple cells while diminishing the prediction error that was obtained by\nthe parametric models by 53%. This improvement enabled our network to predict a\nfault 31 hours before it happened, a 64% increase in reaction time compared to\nthe parametric model. Moreover, the output of the encoder can be plotted,\nadding interpretability to the neural network model.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2020 21:21:36 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Marcos", "Daniel Buades", ""], ["Yacout", "Soumaya", ""], ["Berriah", "Said", ""]]}, {"id": "2007.13690", "submitter": "Karush Suri", "authors": "Karush Suri, Xiao Qi Shi, Konstantinos N. Plataniotis, Yuri A.\n  Lawryshyn", "title": "Maximum Mutation Reinforcement Learning for Scalable Control", "comments": "10+3 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in Reinforcement Learning (RL) have demonstrated data efficiency and\noptimal control over large state spaces at the cost of scalable performance.\nGenetic methods, on the other hand, provide scalability but depict\nhyperparameter sensitivity towards evolutionary operations. However, a\ncombination of the two methods has recently demonstrated success in scaling RL\nagents to high-dimensional action spaces. Parallel to recent developments, we\npresent the Evolution-based Soft Actor-Critic (ESAC), a scalable RL algorithm.\nWe abstract exploration from exploitation by combining Evolution Strategies\n(ES) with Soft Actor-Critic (SAC). Through this lens, we enable dominant skill\ntransfer between offsprings by making use of soft winner selections and genetic\ncrossovers in hindsight and simultaneously improve hyperparameter sensitivity\nin evolutions using the novel Automatic Mutation Tuning (AMT). AMT gradually\nreplaces the entropy framework of SAC allowing the population to succeed at the\ntask while acting as randomly as possible, without making use of\nbackpropagation updates. In a study of challenging locomotion tasks consisting\nof high-dimensional action spaces and sparse rewards, ESAC demonstrates\nimproved performance and sample efficiency in comparison to the Maximum Entropy\nframework. Additionally, ESAC presents efficacious use of hardware resources\nand algorithm overhead. A complete implementation of ESAC can be found at\nkarush17.github.io/esac-web/.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 16:29:19 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 01:51:07 GMT"}, {"version": "v3", "created": "Sat, 24 Oct 2020 18:08:24 GMT"}, {"version": "v4", "created": "Sun, 8 Nov 2020 02:57:01 GMT"}, {"version": "v5", "created": "Tue, 17 Nov 2020 22:21:26 GMT"}, {"version": "v6", "created": "Sat, 21 Nov 2020 23:02:54 GMT"}, {"version": "v7", "created": "Sat, 16 Jan 2021 23:51:53 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Suri", "Karush", ""], ["Shi", "Xiao Qi", ""], ["Plataniotis", "Konstantinos N.", ""], ["Lawryshyn", "Yuri A.", ""]]}, {"id": "2007.13926", "submitter": "Yujun Zheng", "authors": "Yu-Jun Zheng, Si-Lan Yu, Jun-Chao Yang, Tie-Er Gan, Qin Song, Jun Yang\n  and Mumtaz Karatas", "title": "Intelligent Optimization of Diversified Community Prevention of COVID-19\n  using Traditional Chinese Medicine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional Chinese medicine (TCM) has played an important role in the\nprevention and control of the novel coronavirus pneumonia (COVID-19), and\ncommunity prevention has become the most essential part in reducing the spread\nrisk and protecting populations. However, most communities use a uniform TCM\nprevention program for all residents, which violates the \"treatment based on\nsyndrome differentiation\" principle of TCM and limits the effectiveness of\nprevention. In this paper, we propose an intelligent optimization method to\ndevelop diversified TCM prevention programs for community residents. First, we\nuse a fuzzy clustering method to divide the population based on both modern\nmedicine and TCM health characteristics; we then use an interactive\noptimization method, in which TCM experts develop different TCM prevention\nprograms for different clusters, and a heuristic algorithm is used to optimize\nthe programs under the resource constraints. We demonstrate the computational\nefficiency of the proposed method and report its successful application to\nTCM-based prevention of COVID-19 in 12 communities in Zhejiang province, China,\nduring the peak of the pandemic.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 00:55:01 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Zheng", "Yu-Jun", ""], ["Yu", "Si-Lan", ""], ["Yang", "Jun-Chao", ""], ["Gan", "Tie-Er", ""], ["Song", "Qin", ""], ["Yang", "Jun", ""], ["Karatas", "Mumtaz", ""]]}, {"id": "2007.13941", "submitter": "Hamid Soleimani", "authors": "Hamid Soleimani and Emmanuel. M. Drakakis", "title": "A Generalized Strong-Inversion CMOS Circuitry for Neuromorphic\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It has always been a challenge in the neuromorphic field to systematically\ntranslate biological models into analog electronic circuitry. In this paper, a\ngeneralized circuit design platform is introduced where biological models can\nbe conveniently implemented using CMOS circuitry operating in strong-inversion.\nThe application of the method is demonstrated by synthesizing a relatively\ncomplex two-dimensional (2-D) nonlinear neuron model. The validity of our\napproach is verified by nominal simulated results with realistic process\nparameters from the commercially available AMS 0.35 um technology. The circuit\nsimulation results exhibit regular spiking responses in good agreement with\ntheir mathematical counterpart.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 01:47:39 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Soleimani", "Hamid", ""], ["Drakakis", "Emmanuel. M.", ""]]}, {"id": "2007.14055", "submitter": "Yujun Zheng", "authors": "Chen-Xin Wu, Min-Hui Liao, Mumtaz Karatas, Sheng-Yong Chen and Yu-Jun\n  Zheng", "title": "Real-Time Neural Network Scheduling of Emergency Medical Mask Production\n  during COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the outbreak of the novel coronavirus pneumonia (COVID-19), there is a\nhuge demand for medical masks. A mask manufacturer often receives a large\namount of orders that are beyond its capability. Therefore, it is of critical\nimportance for the manufacturer to schedule mask production tasks as\nefficiently as possible. However, existing scheduling methods typically require\na considerable amount of computational resources and, therefore, cannot\neffectively cope with the surge of orders. In this paper, we propose an\nend-to-end neural network for scheduling real-time production tasks. The neural\nnetwork takes a sequence of production tasks as inputs to predict a\ndistribution over different schedules, employs reinforcement learning to\noptimize network parameters using the negative total tardiness as the reward\nsignal, and finally produces a high-quality solution to the scheduling problem.\nWe applied the proposed approach to schedule emergency production tasks for a\nmedical mask manufacturer during the peak of COVID-19 in China. Computational\nresults show that the neural network scheduler can solve problem instances with\nhundreds of tasks within seconds. The objective function value (i.e., the total\nweighted tardiness) produced by the neural network scheduler is significantly\nbetter than those of existing constructive heuristics, and is very close to\nthose of the state-of-the-art metaheuristics whose computational time is\nunaffordable in practice.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 08:18:15 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Wu", "Chen-Xin", ""], ["Liao", "Min-Hui", ""], ["Karatas", "Mumtaz", ""], ["Chen", "Sheng-Yong", ""], ["Zheng", "Yu-Jun", ""]]}, {"id": "2007.14236", "submitter": "Bruno Golosio", "authors": "Bruno Golosio, Gianmarco Tiddia, Chiara De Luca, Elena Pastorelli,\n  Francesco Simula, Pier Stanislao Paolucci", "title": "Fast simulations of highly-connected spiking cortical models using GPUs", "comments": null, "journal-ref": "Front. Comput. Neurosci. 15:627620 2021", "doi": "10.3389/fncom.2021.627620", "report-no": null, "categories": "q-bio.NC cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade there has been a growing interest in the development of\nparallel hardware systems for simulating large-scale networks of spiking\nneurons. Compared to other highly-parallel systems, GPU-accelerated solutions\nhave the advantage of a relatively low cost and a great versatility, thanks\nalso to the possibility of using the CUDA-C/C++ programming languages.\nNeuronGPU is a GPU library for large-scale simulations of spiking neural\nnetwork models, written in the C++ and CUDA-C++ programming languages, based on\na novel spike-delivery algorithm. This library includes simple LIF\n(leaky-integrate-and-fire) neuron models as well as several multisynapse AdEx\n(adaptive-exponential-integrate-and-fire) neuron models with current or\nconductance based synapses, user definable models and different devices. The\nnumerical solution of the differential equations of the dynamics of the AdEx\nmodels is performed through a parallel implementation, written in CUDA-C++, of\nthe fifth-order Runge-Kutta method with adaptive step-size control. In this\nwork we evaluate the performance of this library on the simulation of a\ncortical microcircuit model, based on LIF neurons and current-based synapses,\nand on a balanced network of excitatory and inhibitory neurons, using AdEx\nneurons and conductance-based synapses. On these models, we will show that the\nproposed library achieves state-of-the-art performance in terms of simulation\ntime per second of biological activity. In particular, using a single NVIDIA\nGeForce RTX 2080 Ti GPU board, the full-scale cortical-microcircuit model,\nwhich includes about 77,000 neurons and $3 \\cdot 10^8$ connections, can be\nsimulated at a speed very close to real time, while the simulation time of a\nbalanced network of 1,000,000 AdEx neurons with 1,000 connections per neuron\nwas about 70 s per second of biological activity.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 13:58:50 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 15:43:02 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 17:13:33 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Golosio", "Bruno", ""], ["Tiddia", "Gianmarco", ""], ["De Luca", "Chiara", ""], ["Pastorelli", "Elena", ""], ["Simula", "Francesco", ""], ["Paolucci", "Pier Stanislao", ""]]}, {"id": "2007.14745", "submitter": "Andreas Selmar Hauptmann", "authors": "Andreas Hauptmann and Jonas Adler", "title": "On the unreasonable effectiveness of CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods using convolutional neural networks (CNN) have been\nsuccessfully applied to virtually all imaging problems, and particularly in\nimage reconstruction tasks with ill-posed and complicated imaging models. In an\nattempt to put upper bounds on the capability of baseline CNNs for solving\nimage-to-image problems we applied a widely used standard off-the-shelf network\narchitecture (U-Net) to the \"inverse problem\" of XOR decryption from noisy data\nand show acceptable results.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 11:16:20 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Hauptmann", "Andreas", ""], ["Adler", "Jonas", ""]]}, {"id": "2007.14885", "submitter": "Siavash Tabrizian", "authors": "Zohreh Raziei, Reza Tavakkoli-Moghaddam, Siavash Tabrizian", "title": "Performance Analysis of Meta-heuristic Algorithms for a Quadratic\n  Assignment Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A quadratic assignment problem (QAP) is a combinatorial optimization problem\nthat belongs to the class of NP-hard ones. So, it is difficult to solve in the\npolynomial time even for small instances. Research on the QAP has thus focused\non obtaining a method to overcome this problem. Heuristics and meta-heuristics\nalgorithm are prevalent solution methods for this problem. This paper is one of\ncomparative studies to apply different metaheuristic algorithms for solving the\nQAP. One of the most popular approaches for categorizing meta-heuristic\nalgorithms is based on a search strategy, including (1) local search\nimprovement meta-heuristics and (2) global search-based meta-heuristics. The\nmatter that distinguishes this paper from the other is the comparative\nperformance of local and global search (both EA and SI), in which\nmeta-heuristics that consist of genetic algorithm (GA), particle swarm\noptimization (PSO), hybrid GA-PSO, grey wolf optimization (GWO), harmony search\nalgorithm (HAS) and simulated annealing (SA). Also, one improvement heuristic\nalgorithm (ie, 2-Opt) is used to compare with others. The PSO, GWO and 2-Opt\nalgorithms are improved to achieve the better comparison toward the other\nalgorithms for evaluation. In order to analysis the comparative advantage of\nthese algorithms, eight different factors are presented. By taking into account\nall these factors, the test is implemented in six test problems of the QAP\nLibrary (QAPLIB) from different sizes. Another contribution of this paper is to\nmeasure a strong convergence condition for each algorithm in a new way.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 15:02:07 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Raziei", "Zohreh", ""], ["Tavakkoli-Moghaddam", "Reza", ""], ["Tabrizian", "Siavash", ""]]}, {"id": "2007.15101", "submitter": "Emily Toomey", "authors": "Emily Toomey, Ken Segall, Matteo Castellani, Marco Colangelo, Nancy\n  Lynch, and Karl K. Berggren", "title": "A superconducting nanowire spiking element for neural networks", "comments": "5 main figures; 7 supplemental figures", "journal-ref": null, "doi": "10.1021/acs.nanolett.0c03057", "report-no": null, "categories": "q-bio.NC cond-mat.supr-con cs.ET cs.NE physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the limits of traditional von Neumann computing come into view, the\nbrain's ability to communicate vast quantities of information using low-power\nspikes has become an increasing source of inspiration for alternative\narchitectures. Key to the success of these largescale neural networks is a\npower-efficient spiking element that is scalable and easily interfaced with\ntraditional control electronics. In this work, we present a spiking element\nfabricated from superconducting nanowires that has pulse energies on the order\nof ~10 aJ. We demonstrate that the device reproduces essential characteristics\nof biological neurons, such as a refractory period and a firing threshold.\nThrough simulations using experimentally measured device parameters, we show\nhow nanowire-based networks may be used for inference in image recognition, and\nthat the probabilistic nature of nanowire switching may be exploited for\nmodeling biological processes and for applications that rely on stochasticity.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 20:48:36 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Toomey", "Emily", ""], ["Segall", "Ken", ""], ["Castellani", "Matteo", ""], ["Colangelo", "Marco", ""], ["Lynch", "Nancy", ""], ["Berggren", "Karl K.", ""]]}, {"id": "2007.15206", "submitter": "Rui Li", "authors": "Rui Li, Jianbo Yang, Xianguo Tuo and Rui Shi", "title": "Research on Fitness Function of Two Evolution Algorithms Used for\n  Neutron Spectrum Unfolding", "comments": "12 pages,5 figures", "journal-ref": null, "doi": "10.1007/s40042-020-00005-x", "report-no": null, "categories": "cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When evolution algorithms are used to unfold the neutron energy spectrum,\nfitness function design is an important fundamental work for evaluating the\nquality of the solution, but it has not attracted much attention. In this work,\nwe investigated the performance of eight fitness functions attached to the\ngenetic algorithm (GA) and the differential evolution algorithm (DEA) used for\nunfolding four neutron spectra selected from the IAEA 403 report. Experiments\nshow that the fitness functions with a maximum in the GA can limit the ability\nof the population to percept the fitness change, but the ability can be made up\nin the DEA. The fitness function with a feature penalty term helps to improve\nthe performance of solutions, and the fitness function using the standard\ndeviation and the Chi-squared result shows the balance between the algorithm\nand the spectra. The results also show that the DEA has good potential for\nneutron energy spectrum unfolding. The purposes of this work are to provide\nevidence for structuring and modifying the fitness functions and to suggest\nsome genetic operations that should receive attention when using the fitness\nfunction to unfold neutron spectra.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 03:27:09 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 01:17:56 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Li", "Rui", ""], ["Yang", "Jianbo", ""], ["Tuo", "Xianguo", ""], ["Shi", "Rui", ""]]}, {"id": "2007.15298", "submitter": "Marcus Hutter", "authors": "Marcus Hutter", "title": "On Representing (Anti)Symmetric Functions", "comments": "22 pages, 1 table", "journal-ref": null, "doi": null, "report-no": "DM rh/P1543", "categories": "cs.NE quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permutation-invariant, -equivariant, and -covariant functions and\nanti-symmetric functions are important in quantum physics, computer vision, and\nother disciplines. Applications often require most or all of the following\nproperties: (a) a large class of such functions can be approximated, e.g. all\ncontinuous function, (b) only the (anti)symmetric functions can be represented,\n(c) a fast algorithm for computing the approximation, (d) the representation\nitself is continuous or differentiable, (e) the architecture is suitable for\nlearning the function from data. (Anti)symmetric neural networks have recently\nbeen developed and applied with great success. A few theoretical approximation\nresults have been proven, but many questions are still open, especially for\nparticles in more than one dimension and the anti-symmetric case, which this\nwork focusses on. More concretely, we derive natural polynomial approximations\nin the symmetric case, and approximations based on a single generalized Slater\ndeterminant in the anti-symmetric case. Unlike some previous super-exponential\nand discontinuous approximations, these seem a more promising basis for future\ntighter bounds. We provide a complete and explicit universality proof of the\nEquivariant MultiLayer Perceptron, which implies universality of symmetric MLPs\nand the FermiNet.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 08:23:33 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Hutter", "Marcus", ""]]}, {"id": "2007.15554", "submitter": "Prasannavenkatesan Theerthagiri", "authors": "Prasannavenkatesan Theerthagiri", "title": "Forecasting Hyponatremia in hospitalized patients Using Multilayer\n  Perceptron and Multivariate Linear Regression Techniques", "comments": "19 pages, 5 figure", "journal-ref": "Concurrency and Computation: Practice and Experience, 2021", "doi": "10.1002/cpe.6248", "report-no": null, "categories": "q-bio.QM cs.LG cs.NE stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The percentage of patients hospitalized due to hyponatremia is getting\nhigher. Hyponatremia is the deficiency of sodium electrolyte in the human\nserum. This deficiency might indulge adverse effects and also associated with\nlonger hospital stay or mortality, if it wasnt actively treated and managed.\nThis work predicts the futuristic sodium levels of patients based on their\nhistory of health problems using multilayer perceptron and multivariate linear\nregression algorithm. This work analyses the patients age, information about\nother disease such as diabetes, pneumonia, liver-disease, malignancy,\npulmonary, sepsis, SIADH, and sodium level of the patient during admission to\nthe hospital. The results of the proposed MLP algorithm is compared with MLR\nalgorithm based results. The MLP prediction results generates 23-72 of higher\nprediction results than MLR algorithm. Thus, proposed MLR algorithm has\nproduced 57.1 of reduced mean squared error rate than the MLR results on\npredicting future sodium ranges of patients. Further, proposed MLR algorithm\nproduces 27-50 of higher prediction precision rate.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 12:47:24 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 04:16:06 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Theerthagiri", "Prasannavenkatesan", ""]]}, {"id": "2007.15579", "submitter": "Mahboobeh Parsapoor", "authors": "Mahboobeh Parsapoor", "title": "Brain Emotional Learning-based Prediction Model For the Prediction of\n  Geomagnetic Storms", "comments": "10 pages, 10 Figures, 6 Tables, submitted to WCCI 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study suggests a new data-driven model for the prediction of geomagnetic\nstorm. The model which is an instance of Brain Emotional Learning Inspired\nModels (BELIMs), is known as the Brain Emotional Learning-based Prediction\nModel (BELPM). BELPM consists of four main subsystems; the connection between\nthese subsystems has been mimicked by the corresponding regions of the\nemotional system. The functions of these subsystems are explained using\nadaptive networks. The learning algorithm of BELPM is defined using the\nsteepest descent (SD) and the least square estimator (LSE). BELPM is employed\nto predict geomagnetic storms using two geomagnetic indices, Auroral Electrojet\n(AE) Index and Disturbance Time (Dst) Index. To evaluate the performance of\nBELPM, the obtained results have been compared with ANFIS, WKNN and other\ninstances of BELIMs. The results verify that BELPM has the capability to\nachieve a reasonable accuracy for both the short-term and the long-term\ngeomagnetic storms prediction.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 20:28:18 GMT"}, {"version": "v2", "created": "Sat, 1 Aug 2020 13:37:17 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Parsapoor", "Mahboobeh", ""]]}, {"id": "2007.15884", "submitter": "Johannes Schmidt-Hieber", "authors": "Johannes Schmidt-Hieber", "title": "The Kolmogorov-Arnold representation theorem revisited", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a longstanding debate whether the Kolmogorov-Arnold representation\ntheorem can explain the use of more than one hidden layer in neural networks.\nThe Kolmogorov-Arnold representation decomposes a multivariate function into an\ninterior and an outer function and therefore has indeed a similar structure as\na neural network with two hidden layers. But there are distinctive differences.\nOne of the main obstacles is that the outer function depends on the represented\nfunction and can be wildly varying even if the represented function is smooth.\nWe derive modifications of the Kolmogorov-Arnold representation that transfer\nsmoothness properties of the represented function to the outer function and can\nbe well approximated by ReLU networks. It appears that instead of two hidden\nlayers, a more natural interpretation of the Kolmogorov-Arnold representation\nis that of a deep neural network where most of the layers are required to\napproximate the interior function.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 07:41:09 GMT"}, {"version": "v2", "created": "Sat, 2 Jan 2021 16:42:55 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Schmidt-Hieber", "Johannes", ""]]}, {"id": "2007.15987", "submitter": "W B Langdon", "authors": "William B. Langdon, Westley Weimer, Justyna Petke, Erik Fredericks,\n  Seongmin Lee, Emily Winter, Michail Basios, Myra B. Cohen, Aymeric Blot,\n  Markus Wagner, Bobby R. Bruce, Shin Yoo, Simos Gerasimou, Oliver Krauss, Yu\n  Huang and Michael Gerten", "title": "Genetic Improvement @ ICSE 2020", "comments": "7 pages, 2 figures. Write up of GI @ ICSE 2020 workshop. Submitted to\n  ACM SIGSOFT Software Engineering Notes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following Prof. Mark Harman of Facebook's keynote and formal presentations\n(which are recorded in the proceedings) there was a wide ranging discussion at\nthe eighth international Genetic Improvement workshop, GI-2020 @ ICSE (held as\npart of the 42nd ACM/IEEE International Conference on Software Engineering on\nFriday 3rd July 2020). Topics included industry take up, human factors,\nexplainabiloity (explainability, justifyability, exploitability) and GI\nbenchmarks. We also contrast various recent online approaches (e.g. SBST 2020)\nto holding virtual computer science conferences and workshops via the WWW on\nthe Internet without face-2-face interaction. Finally we speculate on how the\nCoronavirus Covid-19 Pandemic will affect research next year and into the\nfuture.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 11:51:38 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Langdon", "William B.", ""], ["Weimer", "Westley", ""], ["Petke", "Justyna", ""], ["Fredericks", "Erik", ""], ["Lee", "Seongmin", ""], ["Winter", "Emily", ""], ["Basios", "Michail", ""], ["Cohen", "Myra B.", ""], ["Blot", "Aymeric", ""], ["Wagner", "Markus", ""], ["Bruce", "Bobby R.", ""], ["Yoo", "Shin", ""], ["Gerasimou", "Simos", ""], ["Krauss", "Oliver", ""], ["Huang", "Yu", ""], ["Gerten", "Michael", ""]]}, {"id": "2007.16149", "submitter": "Vasco Lopes Ferrinho", "authors": "Vasco Lopes and Lu\\'is A. Alexandre", "title": "HMCNAS: Neural Architecture Search using Hidden Markov Chains and\n  Bayesian Optimization", "comments": "9 pages, 1 figure, 2 tables, neural architecture search, macro-search", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search has achieved state-of-the-art performance in a\nvariety of tasks, out-performing human-designed networks. However, many\nassumptions, that require human definition, related with the problems being\nsolved or the models generated are still needed: final model architectures,\nnumber of layers to be sampled, forced operations, small search spaces, which\nultimately contributes to having models with higher performances at the cost of\ninducing bias into the system. In this paper, we propose HMCNAS, which is\ncomposed of two novel components: i) a method that leverages information about\nhuman-designed models to autonomously generate a complex search space, and ii)\nan Evolutionary Algorithm with Bayesian Optimization that is capable of\ngenerating competitive CNNs from scratch, without relying on human-defined\nparameters or small search spaces. The experimental results show that the\nproposed approach results in competitive architectures obtained in a very short\ntime. HMCNAS provides a step towards generalizing NAS, by providing a way to\ncreate competitive models, without requiring any human knowledge about the\nspecific task.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 16:04:08 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Lopes", "Vasco", ""], ["Alexandre", "Lu\u00eds A.", ""]]}, {"id": "2007.16189", "submitter": "Emin Orhan", "authors": "A. Emin Orhan, Vaibhav V. Gupta, Brenden M. Lake", "title": "Self-supervised learning through the eyes of a child", "comments": "Published as a conference paper at NeurIPS 2020; v3 adds a reference,\n  fixes a typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within months of birth, children develop meaningful expectations about the\nworld around them. How much of this early knowledge can be explained through\ngeneric learning mechanisms applied to sensory data, and how much of it\nrequires more substantive innate inductive biases? Addressing this fundamental\nquestion in its full generality is currently infeasible, but we can hope to\nmake real progress in more narrowly defined domains, such as the development of\nhigh-level visual categories, thanks to improvements in data collecting\ntechnology and recent progress in deep learning. In this paper, our goal is\nprecisely to achieve such progress by utilizing modern self-supervised deep\nlearning methods and a recent longitudinal, egocentric video dataset recorded\nfrom the perspective of three young children (Sullivan et al., 2020). Our\nresults demonstrate the emergence of powerful, high-level visual\nrepresentations from developmentally realistic natural videos using generic\nself-supervised learning objectives.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 17:33:45 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 18:25:27 GMT"}, {"version": "v3", "created": "Tue, 15 Dec 2020 18:24:16 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Orhan", "A. Emin", ""], ["Gupta", "Vaibhav V.", ""], ["Lake", "Brenden M.", ""]]}]