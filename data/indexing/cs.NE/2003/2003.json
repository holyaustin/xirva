[{"id": "2003.00063", "submitter": "Gustavo Assun\\c{c}\\~ao", "authors": "Gustavo Assun\\c{c}\\~ao, Nuno Gon\\c{c}alves, Paulo Menezes", "title": "Bio-Inspired Modality Fusion for Active Speaker Detection", "comments": null, "journal-ref": "Appl. Sci. 2021, 11(8), 3397", "doi": "10.3390/app11083397", "report-no": null, "categories": "cs.CV cs.LG cs.NE cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human beings have developed fantastic abilities to integrate information from\nvarious sensory sources exploring their inherent complementarity. Perceptual\ncapabilities are therefore heightened, enabling, for instance, the well-known\n\"cocktail party\" and McGurk effects, i.e., speech disambiguation from a panoply\nof sound signals. This fusion ability is also key in refining the perception of\nsound source location, as in distinguishing whose voice is being heard in a\ngroup conversation. Furthermore, neuroscience has successfully identified the\nsuperior colliculus region in the brain as the one responsible for this\nmodality fusion, with a handful of biological models having been proposed to\napproach its underlying neurophysiological process. Deriving inspiration from\none of these models, this paper presents a methodology for effectively fusing\ncorrelated auditory and visual information for active speaker detection. Such\nan ability can have a wide range of applications, from teleconferencing systems\nto social robotics. The detection approach initially routes auditory and visual\ninformation through two specialized neural network structures. The resulting\nembeddings are fused via a novel layer based on the superior colliculus, whose\ntopological structure emulates spatial neuron cross-mapping of unimodal\nperceptual fields. The validation process employed two publicly available\ndatasets, with achieved results confirming and greatly surpassing initial\nexpectations.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 20:56:24 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 11:05:06 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Assun\u00e7\u00e3o", "Gustavo", ""], ["Gon\u00e7alves", "Nuno", ""], ["Menezes", "Paulo", ""]]}, {"id": "2003.00152", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle, David J. Schwab, and Ari S. Morcos", "title": "Training BatchNorm and Only BatchNorm: On the Expressive Power of Random\n  Features in CNNs", "comments": "Published in ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide variety of deep learning techniques from style transfer to multitask\nlearning rely on training affine transformations of features. Most prominent\namong these is the popular feature normalization technique BatchNorm, which\nnormalizes activations and then subsequently applies a learned affine\ntransform. In this paper, we aim to understand the role and expressive power of\naffine parameters used to transform features in this way. To isolate the\ncontribution of these parameters from that of the learned features they\ntransform, we investigate the performance achieved when training only these\nparameters in BatchNorm and freezing all weights at their random\ninitializations. Doing so leads to surprisingly high performance considering\nthe significant limitations that this style of training imposes. For example,\nsufficiently deep ResNets reach 82% (CIFAR-10) and 32% (ImageNet, top-5)\naccuracy in this configuration, far higher than when training an equivalent\nnumber of randomly chosen parameters elsewhere in the network. BatchNorm\nachieves this performance in part by naturally learning to disable around a\nthird of the random features. Not only do these results highlight the\nexpressive power of affine parameters in deep learning, but - in a broader\nsense - they characterize the expressive power of neural networks constructed\nsimply by shifting and rescaling random features.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 01:57:37 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 14:52:52 GMT"}, {"version": "v3", "created": "Sun, 21 Mar 2021 21:48:35 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Frankle", "Jonathan", ""], ["Schwab", "David J.", ""], ["Morcos", "Ari S.", ""]]}, {"id": "2003.00203", "submitter": "Michael Gimelfarb Mr.", "authors": "Michael Gimelfarb, Scott Sanner, Chi-Guhn Lee", "title": "Contextual Policy Transfer in Reinforcement Learning Domains via Deep\n  Mixtures-of-Experts", "comments": "- updated experiment for Lander domain (fixed a bug in the UCB\n  baseline) - minor editing and formatting, fixing typos - new template - 15\n  pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, agents that consider the context, or current\nstate, when selecting source policies for transfer have been shown to\noutperform context-free approaches. However, none of the existing approaches\ntransfer knowledge contextually from model-based learners to a model-free\nlearner. This could be useful, for instance, when source policies are\nintentionally learned on diverse simulations with plentiful data but\ntransferred to a real-world setting with limited data. In this paper, we assume\nknowledge of estimated source task dynamics and policies, and common sub-goals\nbut different dynamics. We introduce a novel deep mixture-of-experts\nformulation for learning state-dependent beliefs over source task dynamics that\nmatch the target dynamics using state trajectories collected from the target\ntask. The mixture model is easy to interpret, demonstrates robustness to\nestimation errors in dynamics, and is compatible with most learning algorithms.\nWe then show how this model can be incorporated into standard policy reuse\nframeworks, and demonstrate its effectiveness on benchmarks from OpenAI-Gym.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 07:58:36 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 08:11:44 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Gimelfarb", "Michael", ""], ["Sanner", "Scott", ""], ["Lee", "Chi-Guhn", ""]]}, {"id": "2003.00348", "submitter": "Iztok Fister", "authors": "Iztok Fister Jr., Iztok Fister", "title": "Information cartography in association rule mining", "comments": "Accepted for publication in IEEE Transactions on Emerging Topics in\n  Computational Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Association Rule Mining is a machine learning method for discovering the\ninteresting relations between the attributes in a huge transaction database.\nTypically, algorithms for Association Rule Mining generate a huge number of\nassociation rules, from which it is hard to extract structured knowledge and\npresent this automatically in a form that would be suitable for the user.\nRecently, an information cartography has been proposed for creating structured\nsummaries of information and visualizing with methodology called \"metro maps\".\nThis was applied to several problem domains, where pattern mining was\nnecessary. The aim of this study is to develop a method for automatic creation\nof metro maps of information obtained by Association Rule Mining and, thus,\nspread its applicability to the other machine learning methods. Although the\nproposed method consists of multiple steps, its core presents metro map\nconstruction that is defined in the study as an optimization problem, which is\nsolved using an evolutionary algorithm. Finally, this was applied to four\nwell-known UCI Machine Learning datasets and one sport dataset. Visualizing the\nresulted metro maps not only justifies that this is a suitable tool for\npresenting structured knowledge hidden in data, but also that they can tell\nstories to users.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 21:57:54 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 11:04:06 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Fister", "Iztok", "Jr."], ["Fister", "Iztok", ""]]}, {"id": "2003.00370", "submitter": "Masashi Okada Dr", "authors": "Masashi Okada and Norio Kosaka and Tadahiro Taniguchi", "title": "PlaNet of the Bayesians: Reconsidering and Improving Deep Planning\n  Network by Incorporating Bayesian Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, we propose an extension of the Deep Planning Network\n(PlaNet), also referred to as PlaNet of the Bayesians (PlaNet-Bayes). There has\nbeen a growing demand in model predictive control (MPC) in partially observable\nenvironments in which complete information is unavailable because of, for\nexample, lack of expensive sensors. PlaNet is a promising solution to realize\nsuch latent MPC, as it is used to train state-space models via model-based\nreinforcement learning (MBRL) and to conduct planning in the latent space.\nHowever, recent state-of-the-art strategies mentioned in MBRR literature, such\nas involving uncertainty into training and planning, have not been considered,\nsignificantly suppressing the training performance. The proposed extension is\nto make PlaNet uncertainty-aware on the basis of Bayesian inference, in which\nboth model and action uncertainty are incorporated. Uncertainty in latent\nmodels is represented using a neural network ensemble to approximately infer\nmodel posteriors. The ensemble of optimal action candidates is also employed to\ncapture multimodal uncertainty in the optimality. The concept of the action\nensemble relies on a general variational inference MPC (VI-MPC) framework and\nits instance, probabilistic action ensemble with trajectory sampling (PaETS).\nIn this paper, we extend VI-MPC and PaETS, which have been originally\nintroduced in previous literature, to address partially observable cases. We\nexperimentally compare the performances on continuous control tasks, and\nconclude that our method can consistently improve the asymptotic performance\ncompared with PlaNet.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2020 00:46:36 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Okada", "Masashi", ""], ["Kosaka", "Norio", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "2003.00688", "submitter": "David Krueger", "authors": "David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang,\n  Jonathan Binas, Dinghuai Zhang, Remi Le Priol, Aaron Courville", "title": "Out-of-Distribution Generalization via Risk Extrapolation (REx)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional shift is one of the major obstacles when transferring machine\nlearning prediction systems from the lab to the real world. To tackle this\nproblem, we assume that variation across training domains is representative of\nthe variation we might encounter at test time, but also that shifts at test\ntime may be more extreme in magnitude. In particular, we show that reducing\ndifferences in risk across training domains can reduce a model's sensitivity to\na wide range of extreme distributional shifts, including the challenging\nsetting where the input contains both causal and anti-causal elements. We\nmotivate this approach, Risk Extrapolation (REx), as a form of robust\noptimization over a perturbation set of extrapolated domains (MM-REx), and\npropose a penalty on the variance of training risks (V-REx) as a simpler\nvariant. We prove that variants of REx can recover the causal mechanisms of the\ntargets, while also providing some robustness to changes in the input\ndistribution (\"covariate shift\"). By appropriately trading-off robustness to\ncausally induced distributional shifts and covariate shift, REx is able to\noutperform alternative methods such as Invariant Risk Minimization in\nsituations where these types of shift co-occur.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 06:29:50 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 04:15:23 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 22:57:37 GMT"}, {"version": "v4", "created": "Thu, 10 Dec 2020 21:46:28 GMT"}, {"version": "v5", "created": "Thu, 25 Feb 2021 17:53:07 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Krueger", "David", ""], ["Caballero", "Ethan", ""], ["Jacobsen", "Joern-Henrik", ""], ["Zhang", "Amy", ""], ["Binas", "Jonathan", ""], ["Zhang", "Dinghuai", ""], ["Priol", "Remi Le", ""], ["Courville", "Aaron", ""]]}, {"id": "2003.00863", "submitter": "Haotian Zhang", "authors": "Haotian Zhang, Jianyong Sun and Zongben Xu", "title": "Adaptive Structural Hyper-Parameter Configuration by Q-Learning", "comments": null, "journal-ref": "2020 IEEE Congress on Evolutionary Computation (CEC)", "doi": "10.1109/CEC48606.2020.9185665", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuning hyper-parameters for evolutionary algorithms is an important issue in\ncomputational intelligence. Performance of an evolutionary algorithm depends\nnot only on its operation strategy design, but also on its hyper-parameters.\nHyper-parameters can be categorized in two dimensions as structural/numerical\nand time-invariant/time-variant. Particularly, structural hyper-parameters in\nexisting studies are usually tuned in advance for time-invariant parameters, or\nwith hand-crafted scheduling for time-invariant parameters. In this paper, we\nmake the first attempt to model the tuning of structural hyper-parameters as a\nreinforcement learning problem, and present to tune the structural\nhyper-parameter which controls computational resource allocation in the CEC\n2018 winner algorithm by Q-learning. Experimental results show favorably\nagainst the winner algorithm on the CEC 2018 test functions.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 13:10:13 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Zhang", "Haotian", ""], ["Sun", "Jianyong", ""], ["Xu", "Zongben", ""]]}, {"id": "2003.01033", "submitter": "Niceto R. Luque", "authors": "Ignacio Abadia, Francisco Naveros, Jesus A. Garrido, Eduardo Ros,\n  Niceto R. Luque", "title": "On robot compliance. A cerebellar control approach", "comments": null, "journal-ref": null, "doi": "10.1109/TCYB.2019.2945498", "report-no": null, "categories": "cs.RO cs.NE cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work presented here is a novel biological approach for the compliant\ncontrol of a robotic arm in real time (RT). We integrate a spiking cerebellar\nnetwork at the core of a feedback control loop performing torque-driven\ncontrol. The spiking cerebellar controller provides torque commands allowing\nfor accurate and coordinated arm movements. To compute these output motor\ncommands, the spiking cerebellar controller receives the robot's sensorial\nsignals, the robot's goal behavior, and an instructive signal. These input\nsignals are translated into a set of evolving spiking patterns representing\nunivocally a specific system state at every point of time.\nSpike-timing-dependent plasticity (STDP) is then supported, allowing for\nbuilding adaptive control. The spiking cerebellar controller continuously\nadapts the torque commands provided to the robot from experience as STDP is\ndeployed. Adaptive torque commands, in turn, help the spiking cerebellar\ncontroller to cope with built-in elastic elements within the robot's actuators\nmimicking human muscles (inherently elastic). We propose a natural integration\nof a bio inspired control scheme, based on the cerebellum, with a compliant\nrobot. We prove that our compliant approach outperforms the accuracy of the\ndefault factory-installed position control in a set of tasks used for\naddressing cerebellar motor behavior: controlling six degrees of freedom (DoF)\nin smooth movements, fast ballistic movements, and unstructured scenario\ncompliant movements.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 17:06:19 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 07:19:55 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Abadia", "Ignacio", ""], ["Naveros", "Francisco", ""], ["Garrido", "Jesus A.", ""], ["Ros", "Eduardo", ""], ["Luque", "Niceto R.", ""]]}, {"id": "2003.01157", "submitter": "Konstantinos Michmizos", "authors": "Guangzhi Tang, Neelesh Kumar, Konstantinos P. Michmizos", "title": "Reinforcement co-Learning of Deep and Spiking Neural Networks for\n  Energy-Efficient Mapless Navigation with Neuromorphic Hardware", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy-efficient mapless navigation is crucial for mobile robots as they\nexplore unknown environments with limited on-board resources. Although the\nrecent deep reinforcement learning (DRL) approaches have been successfully\napplied to navigation, their high energy consumption limits their use in\nseveral robotic applications. Here, we propose a neuromorphic approach that\ncombines the energy-efficiency of spiking neural networks with the optimality\nof DRL and benchmark it in learning control policies for mapless navigation.\nOur hybrid framework, spiking deep deterministic policy gradient (SDDPG),\nconsists of a spiking actor network (SAN) and a deep critic network, where the\ntwo networks were trained jointly using gradient descent. The co-learning\nenabled synergistic information exchange between the two networks, allowing\nthem to overcome each other's limitations through a shared representation\nlearning. To evaluate our approach, we deployed the trained SAN on Intel's\nLoihi neuromorphic processor. When validated on simulated and real-world\ncomplex environments, our method on Loihi consumed 75 times less energy per\ninference as compared to DDPG on Jetson TX2, and also exhibited a higher rate\nof successful navigation to the goal, which ranged from 1% to 4.2% and depended\non the forward-propagation timestep size. These results reinforce our ongoing\nefforts to design brain-inspired algorithms for controlling autonomous robots\nwith neuromorphic hardware.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 19:39:16 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2020 22:25:13 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Tang", "Guangzhi", ""], ["Kumar", "Neelesh", ""], ["Michmizos", "Konstantinos P.", ""]]}, {"id": "2003.01184", "submitter": "Kyongmin Yeo", "authors": "Kyongmin Yeo, Dylan E. C. Grullon, Fan-Keng Sun, Duane S. Boning,\n  Jayant R. Kalagnanam", "title": "Variational inference formulation for a model-free simulation of a\n  dynamical system with unknown parameters by a recurrent neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a recurrent neural network for a \"model-free\" simulation of a\ndynamical system with unknown parameters without prior knowledge. The deep\nlearning model aims to jointly learn the nonlinear time marching operator and\nthe effects of the unknown parameters from a time series dataset. We assume\nthat the time series data set consists of an ensemble of trajectories for a\nrange of the parameters. The learning task is formulated as a statistical\ninference problem by considering the unknown parameters as random variables. A\nlatent variable is introduced to model the effects of the unknown parameters,\nand a variational inference method is employed to simultaneously train\nprobabilistic models for the time marching operator and an approximate\nposterior distribution for the latent variable. Unlike the classical\nvariational inference, where a factorized distribution is used to approximate\nthe posterior, we employ a feedforward neural network supplemented by an\nencoder recurrent neural network to develop a more flexible probabilistic\nmodel. The approximate posterior distribution makes an inference on a\ntrajectory to identify the effects of the unknown parameters. The time marching\noperator is approximated by a recurrent neural network, which takes a latent\nstate sampled from the approximate posterior distribution as one of the input\nvariables, to compute the time evolution of the probability distribution\nconditioned on the latent variable. In the numerical experiments, it is shown\nthat the proposed variational inference model makes a more accurate simulation\ncompared to the standard recurrent neural networks. It is found that the\nproposed deep learning model is capable of correctly identifying the dimensions\nof the random parameters and learning a representation of complex time series\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 20:57:02 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 17:20:51 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Yeo", "Kyongmin", ""], ["Grullon", "Dylan E. C.", ""], ["Sun", "Fan-Keng", ""], ["Boning", "Duane S.", ""], ["Kalagnanam", "Jayant R.", ""]]}, {"id": "2003.01239", "submitter": "Xingyou Song", "authors": "Xingyou Song, Yuxiang Yang, Krzysztof Choromanski, Ken Caluwaerts,\n  Wenbo Gao, Chelsea Finn, Jie Tan", "title": "Rapidly Adaptable Legged Robots via Evolutionary Meta-Learning", "comments": "Published as a conference paper at International Conference on\n  Intelligent Robots and Systems (IROS) 2020. See http://youtu.be/_QPMCDdFC3E\n  for associated video file,\n  http://github.com/google-research/google-research/tree/master/es_maml for\n  associated code, and\n  https://ai.googleblog.com/2020/04/exploring-evolutionary-meta-learning-in.html\n  for the corresponding Google AI Blog post", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning adaptable policies is crucial for robots to operate autonomously in\nour complex and quickly changing world. In this work, we present a new\nmeta-learning method that allows robots to quickly adapt to changes in\ndynamics. In contrast to gradient-based meta-learning algorithms that rely on\nsecond-order gradient estimation, we introduce a more noise-tolerant Batch\nHill-Climbing adaptation operator and combine it with meta-learning based on\nevolutionary strategies. Our method significantly improves adaptation to\nchanges in dynamics in high noise settings, which are common in robotics\napplications. We validate our approach on a quadruped robot that learns to walk\nwhile subject to changes in dynamics. We observe that our method significantly\noutperforms prior gradient-based approaches, enabling the robot to adapt its\npolicy to changes based on less than 3 minutes of real data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 22:56:27 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2020 19:06:32 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2020 00:22:35 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Song", "Xingyou", ""], ["Yang", "Yuxiang", ""], ["Choromanski", "Krzysztof", ""], ["Caluwaerts", "Ken", ""], ["Gao", "Wenbo", ""], ["Finn", "Chelsea", ""], ["Tan", "Jie", ""]]}, {"id": "2003.01250", "submitter": "Jason Allred", "authors": "Jason M. Allred, Steven J. Spencer, Gopalakrishnan Srinivasan, Kaushik\n  Roy", "title": "Explicitly Trained Spiking Sparsity in Spiking Neural Networks with\n  Backpropagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) are being explored for their potential energy\nefficiency resulting from sparse, event-driven computations. Many recent works\nhave demonstrated effective backpropagation for deep Spiking Neural Networks\n(SNNs) by approximating gradients over discontinuous neuron spikes or firing\nevents. A beneficial side-effect of these surrogate gradient spiking\nbackpropagation algorithms is that the spikes, which trigger additional\ncomputations, may now themselves be directly considered in the gradient\ncalculations. We propose an explicit inclusion of spike counts in the loss\nfunction, along with a traditional error loss, causing the backpropagation\nlearning algorithms to optimize weight parameters for both accuracy and spiking\nsparsity. As supported by existing theory of over-parameterized neural\nnetworks, there are many solution states with effectively equivalent accuracy.\nAs such, appropriate weighting of the two loss goals during training in this\nmulti-objective optimization process can yield an improvement in spiking\nsparsity without a significant loss of accuracy. We additionally explore a\nsimulated annealing-inspired loss weighting technique to increase the weighting\nfor sparsity as training time increases. Our preliminary results on the\nCifar-10 dataset show up to 70.1% reduction in spiking activity with\niso-accuracy compared to an equivalent SNN trained only for accuracy and up to\n73.3% reduction in spiking activity if allowed a trade-off of 1% reduction in\nclassification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 23:39:18 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Allred", "Jason M.", ""], ["Spencer", "Steven J.", ""], ["Srinivasan", "Gopalakrishnan", ""], ["Roy", "Kaushik", ""]]}, {"id": "2003.01262", "submitter": "Matthew Leavitt", "authors": "Matthew L. Leavitt and Ari Morcos", "title": "Selectivity considered harmful: evaluating the causal impact of class\n  selectivity in DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The properties of individual neurons are often analyzed in order to\nunderstand the biological and artificial neural networks in which they're\nembedded. Class selectivity-typically defined as how different a neuron's\nresponses are across different classes of stimuli or data samples-is commonly\nused for this purpose. However, it remains an open question whether it is\nnecessary and/or sufficient for deep neural networks (DNNs) to learn class\nselectivity in individual units. We investigated the causal impact of class\nselectivity on network function by directly regularizing for or against class\nselectivity. Using this regularizer to reduce class selectivity across units in\nconvolutional neural networks increased test accuracy by over 2% for ResNet18\ntrained on Tiny ImageNet. For ResNet20 trained on CIFAR10 we could reduce class\nselectivity by a factor of 2.5 with no impact on test accuracy, and reduce it\nnearly to zero with only a small ($\\sim$2%) drop in test accuracy. In contrast,\nregularizing to increase class selectivity significantly decreased test\naccuracy across all models and datasets. These results indicate that class\nselectivity in individual units is neither sufficient nor strictly necessary,\nand can even impair DNN performance. They also encourage caution when focusing\non the properties of single units as representative of the mechanisms by which\nDNNs function.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 00:22:37 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 00:20:47 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 17:31:24 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Leavitt", "Matthew L.", ""], ["Morcos", "Ari", ""]]}, {"id": "2003.01335", "submitter": "Xu Zhang", "authors": "XuZhang, ChenjunZhou, BoGu", "title": "ADWPNAS: Architecture-Driven Weight Prediction for Neural Architecture\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to discover and evaluate the true strength of models quickly and\naccurately is one of the key challenges in Neural Architecture Search (NAS). To\ncope with this problem, we propose an Architecture-Driven Weight Prediction\n(ADWP) approach for neural architecture search (NAS). In our approach, we first\ndesign an architecture-intensive search space and then train a HyperNetwork by\ninputting stochastic encoding architecture parameters. In the trained\nHyperNetwork, weights of convolution kernels can be well predicted for neural\narchitectures in the search space. Consequently, the target architectures can\nbe evaluated efficiently without any finetuning, thus enabling us to search\nfortheoptimalarchitectureinthespaceofgeneralnetworks (macro-search). Through\nreal experiments, we evaluate the performance of the models discovered by the\nproposed AD-WPNAS and results show that one search procedure can be completed\nin 4.0 GPU hours on CIFAR-10. Moreover, the discovered model obtains a test\nerror of 2.41% with only 1.52M parameters which is superior to the best\nexisting models.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 05:06:20 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["XuZhang", "", ""], ["ChenjunZhou", "", ""], ["BoGu", "", ""]]}, {"id": "2003.01409", "submitter": "Niceto R. Luque", "authors": "Francisco Naveros, Niceto R. Luque, Eduardo Ros, Angelo Arleo", "title": "VOR Adaptation on a Humanoid iCub Robot Using a Spiking Cerebellar Model", "comments": null, "journal-ref": null, "doi": "10.1109/TCYB.2019.2899246", "report-no": null, "categories": "q-bio.NC cs.NE cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We embed a spiking cerebellar model within an adaptive real-time (RT) control\nloop that is able to operate a real robotic body (iCub) when performing\ndifferent vestibulo-ocular reflex (VOR) tasks. The spiking neural network\ncomputation, including event- and time-driven neural dynamics, neural activity,\nand spike-timing dependent plasticity (STDP) mechanisms, leads to a\nnondeterministic computation time caused by the neural activity volleys\nencountered during cerebellar simulation. This nondeterministic computation\ntime motivates the integration of an RT supervisor module that is able to\nensure a well-orchestrated neural computation time and robot operation.\nActually, our neurorobotic experimental setup (VOR) benefits from the\nbiological sensory motor delay between the cerebellum and the body to buffer\nthe computational overloads as well as providing flexibility in adjusting the\nneural computation time and RT operation. The RT supervisor module provides for\nincremental countermeasures that dynamically slow down or speed up the\ncerebellar simulation by either halting the simulation or disabling certain\nneural computation features (i.e., STDP mechanisms, spike propagation, and\nneural updates) to cope with the RT constraints imposed by the real robot\noperation. This neurorobotic experimental setup is applied to different\nhorizontal and vertical VOR adaptive tasks that are widely used by the\nneuroscientific community to address cerebellar functioning. We aim to\nelucidate the manner in which the combination of the cerebellar neural\nsubstrate and the distributed plasticity shapes the cerebellar neural activity\nto mediate motor adaptation. This paper underlies the need for a two-stage\nlearning process to facilitate VOR acquisition.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 09:48:15 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 07:26:00 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Naveros", "Francisco", ""], ["Luque", "Niceto R.", ""], ["Ros", "Eduardo", ""], ["Arleo", "Angelo", ""]]}, {"id": "2003.01412", "submitter": "Ziling Wu", "authors": "Ziling Wu, Ping Liu, Zheng Hu, Bocheng Li and Jun Wang", "title": "CRATOS: Cognition of Reliable Algorithm for Time-series Optimal Solution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection of time series plays an important role in reliability\nsystems engineering. However, in practical application, there is no precisely\ndefined boundary between normal and anomalous behaviors in different\napplication scenarios. Therefore, different anomaly detection algorithms and\nprocesses ought to be adopted for time series in different situation. Although\nsuch strategy improve the accuracy of anomaly detection, it takes a lot of time\nfor practitioners to configure various algorithms to millions of series, which\ngreatly increases the development and maintenance cost of anomaly detection\nprocesses. In this paper, we propose CRATOS which is a self-adapt algorithms\nthat extract features from time series, and then cluster series with similar\nfeatures into one group. For each group we utilize evolutionary algorithm to\nsearch the best anomaly detection methods and processes. Our methods can\nsignificantly reduce the cost of development and maintenance of anomaly\ndetection. According to experiments, our clustering methods achieves the\nstate-of-art results. The accuracy of the anomaly detection algorithms in this\npaper is 85.1%.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 09:49:30 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 03:17:59 GMT"}, {"version": "v3", "created": "Thu, 15 Oct 2020 13:12:23 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Wu", "Ziling", ""], ["Liu", "Ping", ""], ["Hu", "Zheng", ""], ["Li", "Bocheng", ""], ["Wang", "Jun", ""]]}, {"id": "2003.01431", "submitter": "Jacques Kaiser", "authors": "Jacques Kaiser, Michael Hoff, Andreas Konle, J. Camilo Vasquez Tieck,\n  David Kappel, Daniel Reichard, Anand Subramoney, Robert Legenstein, Arne\n  Roennau, Wolfgang Maass, Rudiger Dillmann", "title": "Embodied Synaptic Plasticity with Online Reinforcement learning", "comments": "18 pages, 5 figures, published in frontiers in neurorobotics", "journal-ref": "Frontiers in neurorobotics, volume 13, p81, 2019", "doi": "10.3389/fnbot.2019.00081", "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The endeavor to understand the brain involves multiple collaborating research\nfields. Classically, synaptic plasticity rules derived by theoretical\nneuroscientists are evaluated in isolation on pattern classification tasks.\nThis contrasts with the biological brain which purpose is to control a body in\nclosed-loop. This paper contributes to bringing the fields of computational\nneuroscience and robotics closer together by integrating open-source software\ncomponents from these two fields. The resulting framework allows to evaluate\nthe validity of biologically-plausibe plasticity models in closed-loop robotics\nenvironments. We demonstrate this framework to evaluate Synaptic Plasticity\nwith Online REinforcement learning (SPORE), a reward-learning rule based on\nsynaptic sampling, on two visuomotor tasks: reaching and lane following. We\nshow that SPORE is capable of learning to perform policies within the course of\nsimulated hours for both tasks. Provisional parameter explorations indicate\nthat the learning rate and the temperature driving the stochastic processes\nthat govern synaptic learning dynamics need to be regulated for performance\nimprovements to be retained. We conclude by discussing the recent deep\nreinforcement learning techniques which would be beneficial to increase the\nfunctionality of SPORE on visuomotor tasks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 10:29:02 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Kaiser", "Jacques", ""], ["Hoff", "Michael", ""], ["Konle", "Andreas", ""], ["Tieck", "J. Camilo Vasquez", ""], ["Kappel", "David", ""], ["Reichard", "Daniel", ""], ["Subramoney", "Anand", ""], ["Legenstein", "Robert", ""], ["Roennau", "Arne", ""], ["Maass", "Wolfgang", ""], ["Dillmann", "Rudiger", ""]]}, {"id": "2003.01445", "submitter": "Niceto R. Luque", "authors": "Francisco Naveros, Jesus A. Garrido, Angelo Arleo, Eduardo Ros, Niceto\n  R. Luque", "title": "Exploring vestibulo-ocular adaptation in a closed-loop neuro-robotic\n  experiment using STDP. A simulation study", "comments": null, "journal-ref": null, "doi": "10.1109/IROS.2018.8594019", "report-no": null, "categories": "q-bio.NC cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying and understanding the computational primitives of our neural system\nrequires for a diverse and complementary set of techniques. In this work, we\nuse the Neuro-robotic Platform (NRP)to evaluate the vestibulo ocular cerebellar\nadaptatIon (Vestibulo-ocular reflex, VOR)mediated by two STDP mechanisms\nlocated at the cerebellar molecular layer and the vestibular nuclei\nrespectively. This simulation study adopts an experimental setup (rotatory\nVOR)widely used by neuroscientists to better understand the contribution of\ncertain specific cerebellar properties (i.e. distributed STDP, neural\nproperties, coding cerebellar topology, etc.)to r-VOR adaptation. The work\nproposes and describes an embodiment solution for which we endow a simulated\nhumanoid robot (iCub)with a spiking cerebellar model by means of the NRP, and\nwe face the humanoid to an r-VOR task. The results validate the adaptive\ncapabilities of the spiking cerebellar model (with STDP)in a perception-action\nclosed-loop (r- VOR)causing the simulated iCub robot to mimic a human behavior.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 10:55:42 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Naveros", "Francisco", ""], ["Garrido", "Jesus A.", ""], ["Arleo", "Angelo", ""], ["Ros", "Eduardo", ""], ["Luque", "Niceto R.", ""]]}, {"id": "2003.01513", "submitter": "Javier Sagastuy-Brena", "authors": "Daniel Kunin, Aran Nayebi, Javier Sagastuy-Brena, Surya Ganguli,\n  Jonathan M. Bloom, Daniel L. K. Yamins", "title": "Two Routes to Scalable Credit Assignment without Weight Symmetry", "comments": "ICML 2020 Camera Ready Version, 19 pages including supplementary\n  information, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural plausibility of backpropagation has long been disputed, primarily\nfor its use of non-local weight transport $-$ the biologically dubious\nrequirement that one neuron instantaneously measure the synaptic weights of\nanother. Until recently, attempts to create local learning rules that avoid\nweight transport have typically failed in the large-scale learning scenarios\nwhere backpropagation shines, e.g. ImageNet categorization with deep\nconvolutional networks. Here, we investigate a recently proposed local learning\nrule that yields competitive performance with backpropagation and find that it\nis highly sensitive to metaparameter choices, requiring laborious tuning that\ndoes not transfer across network architecture. Our analysis indicates the\nunderlying mathematical reason for this instability, allowing us to identify a\nmore robust local learning rule that better transfers without metaparameter\ntuning. Nonetheless, we find a performance and stability gap between this local\nrule and backpropagation that widens with increasing model depth. We then\ninvestigate several non-local learning rules that relax the need for\ninstantaneous weight transport into a more biologically-plausible \"weight\nestimation\" process, showing that these rules match state-of-the-art\nperformance on deep networks and operate effectively in the presence of noisy\nupdates. Taken together, our results suggest two routes towards the discovery\nof neural implementations for credit assignment without weight symmetry:\nfurther improvement of local rules so that they perform consistently across\narchitectures and the identification of biological implementations for\nnon-local learning mechanisms.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:39:16 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 03:55:29 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Kunin", "Daniel", ""], ["Nayebi", "Aran", ""], ["Sagastuy-Brena", "Javier", ""], ["Ganguli", "Surya", ""], ["Bloom", "Jonathan M.", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "2003.01517", "submitter": "Aneta Neumann", "authors": "Aneta Neumann, Bradley Alexander, Frank Neumann", "title": "Evolutionary Image Transition and Painting Using Random Walks", "comments": "Accepted for the Evolutionary Computation Journal (MIT Press). arXiv\n  admin note: text overlap with arXiv:1604.06187", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a study demonstrating how random walk algorithms can be used for\nevolutionary image transition. We design different mutation operators based on\nuniform and biased random walks and study how their combination with a baseline\nmutation operator can lead to interesting image transition processes in terms\nof visual effects and artistic features. Using feature-based analysis we\ninvestigate the evolutionary image transition behaviour with respect to\ndifferent features and evaluate the images constructed during the image\ntransition process. Afterwards, we investigate how modifications of our biased\nrandom walk approaches can be used for evolutionary image painting. We\nintroduce an evolutionary image painting approach whose underlying biased\nrandom walk can be controlled by a parameter influencing the bias of the random\nwalk and thereby creating different artistic painting effects.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 10:28:24 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Neumann", "Aneta", ""], ["Alexander", "Bradley", ""], ["Neumann", "Frank", ""]]}, {"id": "2003.01588", "submitter": "Niceto R. Luque", "authors": "Richard R Carrillo, Francisco Naveros, Eduardo Ros, Niceto R Luque", "title": "A Metric for Evaluating Neural Input Representation in Supervised\n  Learning Networks", "comments": null, "journal-ref": null, "doi": "10.3389/fnins.2018.00913", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning has long been attributed to several feed-forward neural\ncircuits within the brain, with attention being paid to the cerebellar granular\nlayer. The focus of this study is to evaluate the input activity representation\nof these feed-forward neural networks. The activity of cerebellar granule cells\nis conveyed by parallel fibers and translated into Purkinje cell activity; the\nsole output of the cerebellar cortex. The learning process at this\nparallel-fiber-to-Purkinje-cell connection makes each Purkinje cell sensitive\nto a set of specific cerebellar states, determined by the granule-cell activity\nduring a certain time window. A Purkinje cell becomes sensitive to each neural\ninput state and, consequently, the network operates as a function able to\ngenerate a desired output for each provided input by means of supervised\nlearning. However, not all sets of Purkinje cell responses can be assigned to\nany set of input states due to the network's own limitations (inherent to the\nnetwork neurobiological substrate), that is, not all input-output mapping can\nbe learned. A limiting factor is the representation of the input states through\ngranule-cell activity. The quality of this representation will determine the\ncapacity of the network to learn a varied set of outputs. In this study we\npresent an algorithm for evaluating quantitatively the level of\ncompatibility/interference amongst a set of given cerebellar states according\nto their representation (granule-cell activation patterns) without the need for\nactually conducting simulations and network training. The algorithm input\nconsists of a real-number matrix that codifies the activity level of every\nconsidered granule-cell in each state. The capability of this representation to\ngenerate a varied set of outputs is evaluated geometrically, thus resulting in\na real number that assesses the goodness of the representation\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 15:21:25 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Carrillo", "Richard R", ""], ["Naveros", "Francisco", ""], ["Ros", "Eduardo", ""], ["Luque", "Niceto R", ""]]}, {"id": "2003.01811", "submitter": "Bing Han", "authors": "Bing Han, Gopalakrishnan Srinivasan, and Kaushik Roy", "title": "RMP-SNN: Residual Membrane Potential Neuron for Enabling Deeper\n  High-Accuracy and Low-Latency Spiking Neural Network", "comments": "to be published in CVPR'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) have recently attracted significant research\ninterest as the third generation of artificial neural networks that can enable\nlow-power event-driven data analytics. The best performing SNNs for image\nrecognition tasks are obtained by converting a trained Analog Neural Network\n(ANN), consisting of Rectified Linear Units (ReLU), to SNN composed of\nintegrate-and-fire neurons with \"proper\" firing thresholds. The converted SNNs\ntypically incur loss in accuracy compared to that provided by the original ANN\nand require sizable number of inference time-steps to achieve the best\naccuracy. We find that performance degradation in the converted SNN stems from\nusing \"hard reset\" spiking neuron that is driven to fixed reset potential once\nits membrane potential exceeds the firing threshold, leading to information\nloss during SNN inference. We propose ANN-SNN conversion using \"soft reset\"\nspiking neuron model, referred to as Residual Membrane Potential (RMP) spiking\nneuron, which retains the \"residual\" membrane potential above threshold at the\nfiring instants. We demonstrate near loss-less ANN-SNN conversion using RMP\nneurons for VGG-16, ResNet-20, and ResNet-34 SNNs on challenging datasets\nincluding CIFAR-10 (93.63% top-1), CIFAR-100 (70.93% top-1), and ImageNet\n(73.09% top-1 accuracy). Our results also show that RMP-SNN surpasses the best\ninference accuracy provided by the converted SNN with \"hard reset\" spiking\nneurons using 2-8 times fewer inference time-steps across network architectures\nand datasets.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 18:19:12 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 17:27:05 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Han", "Bing", ""], ["Srinivasan", "Gopalakrishnan", ""], ["Roy", "Kaushik", ""]]}, {"id": "2003.01825", "submitter": "C\\'edric Colas", "authors": "C\\'edric Colas, Joost Huizinga, Vashisht Madhavan, Jeff Clune", "title": "Scaling MAP-Elites to Deep Neuroevolution", "comments": "Accepted to GECCO 2020", "journal-ref": null, "doi": "10.1145/3377930.3390217", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality-Diversity (QD) algorithms, and MAP-Elites (ME) in particular, have\nproven very useful for a broad range of applications including enabling real\nrobots to recover quickly from joint damage, solving strongly deceptive maze\ntasks or evolving robot morphologies to discover new gaits. However, present\nimplementations of MAP-Elites and other QD algorithms seem to be limited to\nlow-dimensional controllers with far fewer parameters than modern deep neural\nnetwork models. In this paper, we propose to leverage the efficiency of\nEvolution Strategies (ES) to scale MAP-Elites to high-dimensional controllers\nparameterized by large neural networks. We design and evaluate a new hybrid\nalgorithm called MAP-Elites with Evolution Strategies (ME-ES) for post-damage\nrecovery in a difficult high-dimensional control task where traditional ME\nfails. Additionally, we show that ME-ES performs efficient exploration, on par\nwith state-of-the-art exploration algorithms in high-dimensional control tasks\nwith strongly deceptive rewards.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 23:02:37 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 08:53:53 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 15:59:15 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Colas", "C\u00e9dric", ""], ["Huizinga", "Joost", ""], ["Madhavan", "Vashisht", ""], ["Clune", "Jeff", ""]]}, {"id": "2003.01897", "submitter": "Preetum Nakkiran", "authors": "Preetum Nakkiran, Prayaag Venkat, Sham Kakade, Tengyu Ma", "title": "Optimal Regularization Can Mitigate Double Descent", "comments": "v2: Accepted to ICLR 2021. Minor edits to Intro and Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent empirical and theoretical studies have shown that many learning\nalgorithms -- from linear regression to neural networks -- can have test\nperformance that is non-monotonic in quantities such the sample size and model\nsize. This striking phenomenon, often referred to as \"double descent\", has\nraised questions of if we need to re-think our current understanding of\ngeneralization. In this work, we study whether the double-descent phenomenon\ncan be avoided by using optimal regularization. Theoretically, we prove that\nfor certain linear regression models with isotropic data distribution,\noptimally-tuned $\\ell_2$ regularization achieves monotonic test performance as\nwe grow either the sample size or the model size. We also demonstrate\nempirically that optimally-tuned $\\ell_2$ regularization can mitigate double\ndescent for more general models, including neural networks. Our results suggest\nthat it may also be informative to study the test risk scalings of various\nalgorithms in the context of appropriately tuned regularization.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 05:19:09 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 04:45:47 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Nakkiran", "Preetum", ""], ["Venkat", "Prayaag", ""], ["Kakade", "Sham", ""], ["Ma", "Tengyu", ""]]}, {"id": "2003.02038", "submitter": "Haotian Zhang", "authors": "Haotian Zhang, Jianyong Sun and Zongben Xu", "title": "On Hyper-parameter Tuning for Stochastic Optimization Algorithms", "comments": "Our explanation of reinforcement learning for adjustment algorithm is\n  far fetched in Section ?B", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the first-ever algorithmic framework for tuning\nhyper-parameters of stochastic optimization algorithm based on reinforcement\nlearning. Hyper-parameters impose significant influences on the performance of\nstochastic optimization algorithms, such as evolutionary algorithms (EAs) and\nmeta-heuristics. Yet, it is very time-consuming to determine optimal\nhyper-parameters due to the stochastic nature of these algorithms. We propose\nto model the tuning procedure as a Markov decision process, and resort the\npolicy gradient algorithm to tune the hyper-parameters. Experiments on tuning\nstochastic algorithms with different kinds of hyper-parameters (continuous and\ndiscrete) for different optimization problems (continuous and discrete) show\nthat the proposed hyper-parameter tuning algorithms do not require much less\nrunning times of the stochastic algorithms than bayesian optimization method.\nThe proposed framework can be used as a standard tool for hyper-parameter\ntuning in stochastic algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 12:29:12 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 16:32:23 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Zhang", "Haotian", ""], ["Sun", "Jianyong", ""], ["Xu", "Zongben", ""]]}, {"id": "2003.02341", "submitter": "David Mark Bossens", "authors": "David M. Bossens and Danesh Tarapore", "title": "QED: using Quality-Environment-Diversity to evolve resilient robot\n  swarms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In swarm robotics, any of the robots in a swarm may be affected by different\nfaults, resulting in significant performance declines. To allow fault recovery\nfrom randomly injected faults to different robots in a swarm, a model-free\napproach may be preferable due to the accumulation of faults in models and the\ndifficulty to predict the behaviour of neighbouring robots. One model-free\napproach to fault recovery involves two phases: during simulation, a\nquality-diversity algorithm evolves a behaviourally diverse archive of\ncontrollers; during the target application, a search for the best controller is\ninitiated after fault injection. In quality-diversity algorithms, the choice of\nthe behavioural descriptor is a key design choice that determines the quality\nof the evolved archives, and therefore the fault recovery performance. Although\nthe environment is an important determinant of behaviour, the impact of\nenvironmental diversity is often ignored in the choice of a suitable\nbehavioural descriptor. This study compares different behavioural descriptors,\nincluding two generic descriptors that work on a wide range of tasks, one\nhand-coded descriptor which fits the domain of interest, and one novel type of\ndescriptor based on environmental diversity, which we call\nQuality-Environment-Diversity (QED). Results demonstrate that the\nabove-mentioned model-free approach to fault recovery is feasible in the\ncontext of swarm robotics, reducing the fault impact by a factor 2-3. Further,\nthe environmental diversity obtained with QED yields a unique behavioural\ndiversity profile that allows it to recover from high-impact faults.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 21:36:07 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Bossens", "David M.", ""], ["Tarapore", "Danesh", ""]]}, {"id": "2003.02357", "submitter": "Christopher H Bennett", "authors": "Christopher H. Bennett, T. Patrick Xiao, Can Cui, Naimul Hassan,\n  Otitoaleke G. Akinola, Jean Anne C. Incorvia, Alvaro Velasquez, Joseph S.\n  Friedman, and Matthew J. Marinella", "title": "Plasticity-Enhanced Domain-Wall MTJ Neural Networks for Energy-Efficient\n  Online Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning implements backpropagation via abundant training samples. We\ndemonstrate a multi-stage learning system realized by a promising non-volatile\nmemory device, the domain-wall magnetic tunnel junction (DW-MTJ). The system\nconsists of unsupervised (clustering) as well as supervised sub-systems, and\ngeneralizes quickly (with few samples). We demonstrate interactions between\nphysical properties of this device and optimal implementation of\nneuroscience-inspired plasticity learning rules, and highlight performance on a\nsuite of tasks. Our energy analysis confirms the value of the approach, as the\nlearning budget stays below 20 $\\mu J$ even for large tasks used typically in\nmachine learning.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 22:45:59 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Bennett", "Christopher H.", ""], ["Xiao", "T. Patrick", ""], ["Cui", "Can", ""], ["Hassan", "Naimul", ""], ["Akinola", "Otitoaleke G.", ""], ["Incorvia", "Jean Anne C.", ""], ["Velasquez", "Alvaro", ""], ["Friedman", "Joseph S.", ""], ["Marinella", "Matthew J.", ""]]}, {"id": "2003.02436", "submitter": "Noam Shazeer", "authors": "Noam Shazeer, Zhenzhong Lan, Youlong Cheng, Nan Ding, Le Hou", "title": "Talking-Heads Attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce \"talking-heads attention\" - a variation on multi-head attention\nwhich includes linearprojections across the attention-heads dimension,\nimmediately before and after the softmax operation.While inserting only a small\nnumber of additional parameters and a moderate amount of additionalcomputation,\ntalking-heads attention leads to better perplexities on masked language\nmodeling tasks, aswell as better quality when transfer-learning to language\ncomprehension and question answering tasks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 05:17:17 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Shazeer", "Noam", ""], ["Lan", "Zhenzhong", ""], ["Cheng", "Youlong", ""], ["Ding", "Nan", ""], ["Hou", "Le", ""]]}, {"id": "2003.02491", "submitter": "Jiri Matyas", "authors": "Milan Ceska, Jiri Matyas, Vojtech Mrazek, Lukas Sekanina, Zdenek\n  Vasicek, Tomas Vojnar", "title": "Adaptive Verifiability-Driven Strategy for Evolutionary Approximation of\n  Arithmetic Circuits", "comments": null, "journal-ref": "Applied Soft Computing, Volume 95, October 2020, 106466", "doi": "10.1016/j.asoc.2020.106466", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach for designing complex approximate arithmetic\ncircuits that trade correctness for power consumption and play important role\nin many energy-aware applications. Our approach integrates in a unique way\nformal methods providing formal guarantees on the approximation error into an\nevolutionary circuit optimisation algorithm. The key idea is to employ a novel\nadaptive search strategy that drives the evolution towards promptly verifiable\napproximate circuits. As demonstrated in an extensive experimental evaluation\nincluding several structurally different arithmetic circuits and target\nprecisions, the search strategy provides superior scalability and versatility\nwith respect to various approximation scenarios. Our approach significantly\nimproves capabilities of the existing methods and paves a way towards an\nautomated design process of provably-correct circuit approximations.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 09:11:45 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Ceska", "Milan", ""], ["Matyas", "Jiri", ""], ["Mrazek", "Vojtech", ""], ["Sekanina", "Lukas", ""], ["Vasicek", "Zdenek", ""], ["Vojnar", "Tomas", ""]]}, {"id": "2003.02642", "submitter": "Jack Kendall", "authors": "Jack D. Kendall, Ross D. Pantone, and Juan C. Nino", "title": "Deep Learning in Memristive Nanowire Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analog crossbar architectures for accelerating neural network training and\ninference have made tremendous progress over the past several years. These\narchitectures are ideal for dense layers with fewer than roughly a thousand\nneurons. However, for large sparse layers, crossbar architectures are highly\ninefficient. A new hardware architecture, dubbed the MN3 (Memristive Nanowire\nNeural Network), was recently described as an efficient architecture for\nsimulating very wide, sparse neural network layers, on the order of millions of\nneurons per layer. The MN3 utilizes a high-density memristive nanowire mesh to\nefficiently connect large numbers of silicon neurons with modifiable weights.\nHere, in order to explore the MN3's ability to function as a deep neural\nnetwork, we describe one algorithm for training deep MN3 models and benchmark\nsimulations of the architecture on two deep learning tasks. We utilize a simple\npiecewise linear memristor model, since we seek to demonstrate that training\nis, in principle, possible for randomized nanowire architectures. In future\nwork, we intend on utilizing more realistic memristor models, and we will adapt\nthe presented algorithm appropriately. We show that the MN3 is capable of\nperforming composition, gradient propagation, and weight updates, which\ntogether allow it to function as a deep neural network. We show that a\nsimulated multilayer perceptron (MLP), built from MN3 networks, can obtain a\n1.61% error rate on the popular MNIST dataset, comparable to equivalently sized\nsoftware-based network. This work represents, to the authors' knowledge, the\nfirst randomized nanowire architecture capable of reproducing the\nbackpropagation algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 20:11:33 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Kendall", "Jack D.", ""], ["Pantone", "Ross D.", ""], ["Nino", "Juan C.", ""]]}, {"id": "2003.02790", "submitter": "Mathias Gehrig", "authors": "Mathias Gehrig, Sumit Bam Shrestha, Daniel Mouritzen and Davide\n  Scaramuzza", "title": "Event-Based Angular Velocity Regression with Spiking Networks", "comments": null, "journal-ref": "IEEE International Conference on Robotics and Automation (ICRA),\n  Paris, 2020", "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) are bio-inspired networks that process\ninformation conveyed as temporal spikes rather than numeric values. A spiking\nneuron of an SNN only produces a spike whenever a significant number of spikes\noccur within a short period of time. Due to their spike-based computational\nmodel, SNNs can process output from event-based, asynchronous sensors without\nany pre-processing at extremely lower power unlike standard artificial neural\nnetworks. This is possible due to specialized neuromorphic hardware that\nimplements the highly-parallelizable concept of SNNs in silicon. Yet, SNNs have\nnot enjoyed the same rise of popularity as artificial neural networks. This not\nonly stems from the fact that their input format is rather unconventional but\nalso due to the challenges in training spiking networks. Despite their temporal\nnature and recent algorithmic advances, they have been mostly evaluated on\nclassification problems. We propose, for the first time, a temporal regression\nproblem of numerical values given events from an event camera. We specifically\ninvestigate the prediction of the 3-DOF angular velocity of a rotating event\ncamera with an SNN. The difficulty of this problem arises from the prediction\nof angular velocities continuously in time directly from irregular,\nasynchronous event-based input. Directly utilising the output of event cameras\nwithout any pre-processing ensures that we inherit all the benefits that they\nprovide over conventional cameras. That is high-temporal resolution,\nhigh-dynamic range and no motion blur. To assess the performance of SNNs on\nthis task, we introduce a synthetic event camera dataset generated from\nreal-world panoramic images and show that we can successfully train an SNN to\nperform angular velocity regression.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 17:37:16 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Gehrig", "Mathias", ""], ["Shrestha", "Sumit Bam", ""], ["Mouritzen", "Daniel", ""], ["Scaramuzza", "Davide", ""]]}, {"id": "2003.02902", "submitter": "Jakub Fil", "authors": "Jakub Fil and Dominique Chu", "title": "Minimal spiking neuron for solving multi-label classification tasks", "comments": null, "journal-ref": "Neural Computation 2020", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Multi-Spike Tempotron (MST) is a powerful single spiking neuron model\nthat can solve complex supervised classification tasks. While powerful, it is\nalso internally complex, computationally expensive to evaluate, and not\nsuitable for neuromorphic hardware. Here we aim to understand whether it is\npossible to simplify the MST model, while retaining its ability to learn and to\nprocess information. To this end, we introduce a family of Generalised Neuron\nModels (GNM) which are a special case of the Spike Response Model and much\nsimpler and cheaper to simulate than the MST. We find that over a wide range of\nparameters the GNM can learn at least as well as the MST. We identify the\ntemporal autocorrelation of the membrane potential as the single most important\ningredient of the GNM which enables it to classify multiple spatio-temporal\npatterns. We also interpret the GNM as a chemical system, thus conceptually\nbridging computation by neural networks with molecular information processing.\nWe conclude the paper by proposing alternative training approaches for the GNM\nincluding error trace learning and error backpropagation.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 20:18:08 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Fil", "Jakub", ""], ["Chu", "Dominique", ""]]}, {"id": "2003.02944", "submitter": "Haowen Fang", "authors": "Haowen Fang, Amar Shrestha, Ziyi Zhao, Qinru Qiu", "title": "Exploiting Neuron and Synapse Filter Dynamics in Spatial Temporal\n  Learning of Deep Spiking Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recent discovered spatial-temporal information processing capability of\nbio-inspired Spiking neural networks (SNN) has enabled some interesting models\nand applications. However designing large-scale and high-performance model is\nyet a challenge due to the lack of robust training algorithms. A bio-plausible\nSNN model with spatial-temporal property is a complex dynamic system. Each\nsynapse and neuron behave as filters capable of preserving temporal\ninformation. As such neuron dynamics and filter effects are ignored in existing\ntraining algorithms, the SNN downgrades into a memoryless system and loses the\nability of temporal signal processing. Furthermore, spike timing plays an\nimportant role in information representation, but conventional rate-based spike\ncoding models only consider spike trains statistically, and discard information\ncarried by its temporal structures. To address the above issues, and exploit\nthe temporal dynamics of SNNs, we formulate SNN as a network of infinite\nimpulse response (IIR) filters with neuron nonlinearity. We proposed a training\nalgorithm that is capable to learn spatial-temporal patterns by searching for\nthe optimal synapse filter kernels and weights. The proposed model and training\nalgorithm are applied to construct associative memories and classifiers for\nsynthetic and public datasets including MNIST, NMNIST, DVS 128 etc.; and their\naccuracy outperforms state-of-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2020 01:27:39 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2020 03:39:24 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Fang", "Haowen", ""], ["Shrestha", "Amar", ""], ["Zhao", "Ziyi", ""], ["Qiu", "Qinru", ""]]}, {"id": "2003.03118", "submitter": "Jesse Hagenaars", "authors": "J. J. Hagenaars, F. Paredes-Vall\\'es, S. M. Boht\\'e, G. C. H. E. de\n  Croon", "title": "Evolved Neuromorphic Control for High Speed Divergence-based Landings of\n  MAVs", "comments": "8 pages, 6 figures, camera-ready version to appear in IEEE Robotics\n  and Automation Letters", "journal-ref": "IEEE Robotics and Automation Letters, vol. 5, no. 4, pp.\n  6239-6246, Oct. 2020", "doi": "10.1109/LRA.2020.3012129", "report-no": null, "categories": "cs.RO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flying insects are capable of vision-based navigation in cluttered\nenvironments, reliably avoiding obstacles through fast and agile maneuvers,\nwhile being very efficient in the processing of visual stimuli. Meanwhile,\nautonomous micro air vehicles still lag far behind their biological\ncounterparts, displaying inferior performance at a much higher energy\nconsumption. In light of this, we want to mimic flying insects in terms of\ntheir processing capabilities, and consequently show the efficiency of this\napproach in the real world. This letter does so through evolving spiking neural\nnetworks for controlling landings of micro air vehicles using optical flow\ndivergence from a downward-looking camera. We demonstrate that the resulting\nneuromorphic controllers transfer robustly from a highly abstracted simulation\nto the real world, performing fast and safe landings while keeping network\nspike rate minimal. Furthermore, we provide insight into the resources required\nfor successfully solving the problem of divergence-based landing, showing that\nhigh-resolution control can be learned with only a single spiking neuron. To\nthe best of our knowledge, this work is the first to integrate spiking neural\nnetworks in the control loop of a real-world flying robot. Videos of the\nexperiments can be found at https://bit.ly/neuro-controller .\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 10:19:02 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 07:55:36 GMT"}, {"version": "v3", "created": "Thu, 23 Jul 2020 17:13:23 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Hagenaars", "J. J.", ""], ["Paredes-Vall\u00e9s", "F.", ""], ["Boht\u00e9", "S. M.", ""], ["de Croon", "G. C. H. E.", ""]]}, {"id": "2003.03124", "submitter": "Karol Gregor", "authors": "Karol Gregor", "title": "Finding online neural update rules by learning to remember", "comments": "11 Pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate learning of the online local update rules for neural\nactivations (bodies) and weights (synapses) from scratch. We represent the\nstates of each weight and activation by small vectors, and parameterize their\nupdates using (meta-) neural networks. Different neuron types are represented\nby different embedding vectors which allows the same two functions to be used\nfor all neurons. Instead of training directly for the objective using evolution\nor long term back-propagation, as is commonly done in similar systems, we\nmotivate and study a different objective: That of remembering past snippets of\nexperience. We explain how this objective relates to standard back-propagation\ntraining and other forms of learning. We train for this objective using short\nterm back-propagation and analyze the performance as a function of both the\ndifferent network types and the difficulty of the problem. We find that this\nanalysis gives interesting insights onto what constitutes a learning rule. We\nalso discuss how such system could form a natural substrate for addressing\ntopics such as episodic memories, meta-learning and auxiliary objectives.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 10:31:30 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Gregor", "Karol", ""]]}, {"id": "2003.03229", "submitter": "Radu Tudor Ionescu", "authors": "Mariana-Iuliana Georgescu, Radu Tudor Ionescu, Nicolae-Catalin Ristea,\n  Nicu Sebe", "title": "Non-linear Neurons with Human-like Apical Dendrite Activations", "comments": "Submitted for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to classify linearly non-separable data, neurons are typically\norganized into multi-layer neural networks that are equipped with at least one\nhidden layer. Inspired by some recent discoveries in neuroscience, we propose a\nnew neuron model along with a novel activation function enabling learning of\nnon-linear decision boundaries using a single neuron. We show that a standard\nneuron followed by the novel apical dendrite activation (ADA) can learn the XOR\nlogical function with 100% accuracy. Furthermore, we conduct experiments on\nthree benchmark data sets from computer vision and natural language processing,\ni.e. Fashion-MNIST, UTKFace and MOROCO, showing that the ADA and the leaky ADA\nfunctions provide superior results to Rectified Liner Units (ReLU) and leaky\nReLU, for various neural network architectures, e.g. 1-hidden layer or 2-hidden\nlayers multi-layer perceptrons (MLPs) and convolutional neural networks (CNNs)\nsuch as LeNet, VGG, ResNet and Character-level CNN. We also obtain further\nimprovements when we change the standard model of the neuron with our pyramidal\nneuron with apical dendrite activations (PyNADA).\n", "versions": [{"version": "v1", "created": "Sun, 2 Feb 2020 21:09:39 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2020 06:51:38 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Georgescu", "Mariana-Iuliana", ""], ["Ionescu", "Radu Tudor", ""], ["Ristea", "Nicolae-Catalin", ""], ["Sebe", "Nicu", ""]]}, {"id": "2003.03268", "submitter": "Alberto Alvarez", "authors": "Alberto Alvarez and Jose Font", "title": "Learning the Designer's Preferences to Drive Evolution", "comments": "16 pages, Accepted and to appear in proceedings of the 23rd European\n  Conference on the Applications of Evolutionary and bio-inspired Computation,\n  EvoApplications 2020", "journal-ref": null, "doi": "10.1007/978-3-030-43722-0_28", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Designer Preference Model, a data-driven solution\nthat pursues to learn from user generated data in a Quality-Diversity\nMixed-Initiative Co-Creativity (QD MI-CC) tool, with the aims of modelling the\nuser's design style to better assess the tool's procedurally generated content\nwith respect to that user's preferences. Through this approach, we aim for\nincreasing the user's agency over the generated content in a way that neither\nstalls the user-tool reciprocal stimuli loop nor fatigues the user with\nperiodical suggestion handpicking. We describe the details of this novel\nsolution, as well as its implementation in the MI-CC tool the Evolutionary\nDungeon Designer. We present and discuss our findings out of the initial tests\ncarried out, spotting the open challenges for this combined line of research\nthat integrates MI-CC with Procedural Content Generation through Machine\nLearning.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 15:10:09 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Alvarez", "Alberto", ""], ["Font", "Jose", ""]]}, {"id": "2003.03377", "submitter": "Alberto Alvarez", "authors": "Alberto Alvarez, Steve Dahlskog, Jose Font and Julian Togelius", "title": "Interactive Constrained MAP-Elites: Analysis and Evaluation of the\n  Expressiveness of the Feature Dimensions", "comments": "10 pages, 7 figures, Accepted by IEEE Transactions on Games for\n  publication. arXiv admin note: substantial text overlap with arXiv:1906.05175", "journal-ref": "IEEE Transactions on Games, pp. 1-10, 2020", "doi": "10.1109/TG.2020.3046133", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Interactive Constrained MAP-Elites, a quality-diversity\nsolution for game content generation, implemented as a new feature of the\nEvolutionary Dungeon Designer: a mixed-initiative co-creativity tool for\ndesigning dungeons. The feature uses the MAP-Elites algorithm, an illumination\nalgorithm that segregates the population among several cells depending on their\nscores with respect to different behavioral dimensions. Users can flexibly and\ndynamically alternate between these dimensions anytime, thus guiding the\nevolutionary process in an intuitive way, and then incorporate suggestions\nproduced by the algorithm in their room designs. At the same time, any\nmodifications performed by the human user will feed back into MAP-Elites,\nclosing a circular workflow of constant mutual inspiration. This paper presents\nthe algorithm followed by an in-depth analysis of its behaviour, with the aims\nof evaluating the expressive range of all possible dimension combinations in\nseveral scenarios, as well as discussing their influence in the fitness\nlandscape and in the overall performance of the mixed-initiative procedural\ncontent generation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 15:03:21 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 10:43:34 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Alvarez", "Alberto", ""], ["Dahlskog", "Steve", ""], ["Font", "Jose", ""], ["Togelius", "Julian", ""]]}, {"id": "2003.03384", "submitter": "Esteban Real", "authors": "Esteban Real, Chen Liang, David R. So, and Quoc V. Le", "title": "AutoML-Zero: Evolving Machine Learning Algorithms From Scratch", "comments": "Accepted for publication at the 37th International Conference on\n  Machine Learning (ICML 2020). Near camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning research has advanced in multiple aspects, including model\nstructures and learning methods. The effort to automate such research, known as\nAutoML, has also made significant progress. However, this progress has largely\nfocused on the architecture of neural networks, where it has relied on\nsophisticated expert-designed layers as building blocks---or similarly\nrestrictive search spaces. Our goal is to show that AutoML can go further: it\nis possible today to automatically discover complete machine learning\nalgorithms just using basic mathematical operations as building blocks. We\ndemonstrate this by introducing a novel framework that significantly reduces\nhuman bias through a generic search space. Despite the vastness of this space,\nevolutionary search can still discover two-layer neural networks trained by\nbackpropagation. These simple neural networks can then be surpassed by evolving\ndirectly on tasks of interest, e.g. CIFAR-10 variants, where modern techniques\nemerge in the top algorithms, such as bilinear interactions, normalized\ngradients, and weight averaging. Moreover, evolution adapts algorithms to\ndifferent task types: e.g., dropout-like techniques appear when little data is\navailable. We believe these preliminary successes in discovering machine\nlearning algorithms from scratch indicate a promising new direction for the\nfield.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 19:00:04 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 04:32:44 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Real", "Esteban", ""], ["Liang", "Chen", ""], ["So", "David R.", ""], ["Le", "Quoc V.", ""]]}, {"id": "2003.03482", "submitter": "Li Songlin", "authors": "Li Songlin, Deng Yangdong, Wang Zhihua", "title": "Grid Cells Are Ubiquitous in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid cells are believed to play an important role in both spatial and\nnon-spatial cognition tasks. A recent study observed the emergence of grid\ncells in an LSTM for path integration. The connection between biological and\nartificial neural networks underlying the seemingly similarity, as well as the\napplication domain of grid cells in deep neural networks (DNNs), expect further\nexploration. This work demonstrated that grid cells could be replicated in\neither pure vision based or vision guided path integration DNNs for navigation\nunder a proper setting of training parameters. We also show that grid-like\nbehaviors arise in feedforward DNNs for non-spatial tasks. Our findings support\nthat the grid coding is an effective representation for both biological and\nartificial networks.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 01:40:56 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 09:38:15 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Songlin", "Li", ""], ["Yangdong", "Deng", ""], ["Zhihua", "Wang", ""]]}, {"id": "2003.03533", "submitter": "Damien Querlioz", "authors": "Axel Laborieux, Maxence Ernoult, Tifenn Hirtzlin and Damien Querlioz", "title": "Synaptic Metaplasticity in Binarized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks have surpassed human performance in multiple\nsituations, they are prone to catastrophic forgetting: upon training a new\ntask, they rapidly forget previously learned ones. Neuroscience studies, based\non idealized tasks, suggest that in the brain, synapses overcome this issue by\nadjusting their plasticity depending on their past history. However, such\n\"metaplastic\" behaviours do not transfer directly to mitigate catastrophic\nforgetting in deep neural networks. In this work, we interpret the hidden\nweights used by binarized neural networks, a low-precision version of deep\nneural networks, as metaplastic variables, and modify their training technique\nto alleviate forgetting. Building on this idea, we propose and demonstrate\nexperimentally, in situations of multitask and stream learning, a training\ntechnique that reduces catastrophic forgetting without needing previously\npresented data, nor formal boundaries between datasets and with performance\napproaching more mainstream techniques with task boundaries. We support our\napproach with a theoretical analysis on a tractable task. This work bridges\ncomputational neuroscience and deep learning, and presents significant assets\nfor future embedded and neuromorphic systems, especially when using novel\nnanodevices featuring physics analogous to metaplasticity.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 08:09:34 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 14:56:46 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Laborieux", "Axel", ""], ["Ernoult", "Maxence", ""], ["Hirtzlin", "Tifenn", ""], ["Querlioz", "Damien", ""]]}, {"id": "2003.03676", "submitter": "Seyed Jalaleddin Mousavirad", "authors": "Shahryar Rahnamayan and Seyed Jalaleddin Mousavirad", "title": "Towards Solving Large-scale Expensive Optimization Problems Efficiently\n  Using Coordinate Descent Algorithm", "comments": "Accepted in IEEE International Conference On Systems, Man, and\n  Cybernetics, 2020, Toronto, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world problems are categorized as large-scale problems, and\nmetaheuristic algorithms as an alternative method to solve large-scale problem;\nthey need the evaluation of many candidate solutions to tackle them prior to\ntheir convergence, which is not affordable for practical applications since the\nmost of them are computationally expensive. In other words, these problems are\nnot only large-scale but also computationally expensive, that makes them very\ndifficult to solve. There is no efficient surrogate model to support\nlarge-scale expensive global optimization (LSEGO) problems. As a result, the\nalgorithms should address LSEGO problems using a limited computational budget\nto be applicable in real-world applications. Coordinate Descent (CD) algorithm\nis an optimization strategy based on the decomposition of a n-dimensional\nproblem into n one-dimensional problem. To the best our knowledge, there is no\nsignificant study to assess benchmark functions with various dimensions and\nlandscape properties to investigate CD algorithm. In this paper, we propose a\nmodified Coordinate Descent algorithm (MCD) to tackle LSEGO problems with a\nlimited computational budget. Our proposed algorithm benefits from two leading\nsteps, namely, finding the region of interest and then shrinkage of the search\nspace by folding it into the half with exponential speed. One of the main\nadvantages of the proposed algorithm is being free of any control parameters,\nwhich makes it far from the intricacies of the tuning process. The proposed\nalgorithm is compared with cooperative co-evolution with delta grouping on 20\nbenchmark functions with dimension 1000. Also, we conducted some experiments on\nCEC-2017, D=10, 30, 50, and 100, to investigate the behavior of MCD algorithm\nin lower dimensions. The results show that MCD is beneficial not only in\nlarge-scale problems, but also in low-scale optimization problems.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 22:48:38 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 12:49:34 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 11:52:50 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Rahnamayan", "Shahryar", ""], ["Mousavirad", "Seyed Jalaleddin", ""]]}, {"id": "2003.03695", "submitter": "Hammad Ayyubi", "authors": "Hammad A. Ayyubi, Yi Yao and Ajay Divakaran", "title": "Progressive Growing of Neural ODEs", "comments": null, "journal-ref": "ICLR Workshop on Neural Networks and Differential Equations, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Ordinary Differential Equations (NODEs) have proven to be a powerful\nmodeling tool for approximating (interpolation) and forecasting (extrapolation)\nirregularly sampled time series data. However, their performance degrades\nsubstantially when applied to real-world data, especially long-term data with\ncomplex behaviors (e.g., long-term trend across years, mid-term seasonality\nacross months, and short-term local variation across days). To address the\nmodeling of such complex data with different behaviors at different frequencies\n(time spans), we propose a novel progressive learning paradigm of NODEs for\nlong-term time series forecasting. Specifically, following the principle of\ncurriculum learning, we gradually increase the complexity of data and network\ncapacity as training progresses. Our experiments with both synthetic data and\nreal traffic data (PeMS Bay Area traffic data) show that our training\nmethodology consistently improves the performance of vanilla NODEs by over 64%.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 01:15:01 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Ayyubi", "Hammad A.", ""], ["Yao", "Yi", ""], ["Divakaran", "Ajay", ""]]}, {"id": "2003.03776", "submitter": "Xin-She Yang", "authors": "Xin-She Yang", "title": "Nature-Inspired Optimization Algorithms: Challenges and Open Problems", "comments": "15 pages", "journal-ref": "Journal of Computational Science, Article 101104, (2020)", "doi": "10.1016/j.jocs.2020.101104", "report-no": null, "categories": "cs.NE cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many problems in science and engineering can be formulated as optimization\nproblems, subject to complex nonlinear constraints. The solutions of highly\nnonlinear problems usually require sophisticated optimization algorithms, and\ntraditional algorithms may struggle to deal with such problems. A current trend\nis to use nature-inspired algorithms due to their flexibility and\neffectiveness. However, there are some key issues concerning nature-inspired\ncomputation and swarm intelligence. This paper provides an in-depth review of\nsome recent nature-inspired algorithms with the emphasis on their search\nmechanisms and mathematical foundations. Some challenging issues are identified\nand five open problems are highlighted, concerning the analysis of algorithmic\nconvergence and stability, parameter tuning, mathematical framework, role of\nbenchmarking and scalability. These problems are discussed with the directions\nfor future research.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 13:00:04 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Yang", "Xin-She", ""]]}, {"id": "2003.03789", "submitter": "Xin-She Yang", "authors": "Qian Li, San-Yang Liu, Xin-She Yang", "title": "Influence of Initialization on the Performance of Metaheuristic\n  Optimizers", "comments": "39 pages, 10 figures, 20 tables", "journal-ref": "Applied Soft Computing, vol. 91, (2020), article 106193", "doi": "10.1016/j.asoc.2020.106193", "report-no": null, "categories": "cs.NE cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  All metaheuristic optimization algorithms require some initialization, and\nthe initialization for such optimizers is usually carried out randomly.\nHowever, initialization can have some significant influence on the performance\nof such algorithms. This paper presents a systematic comparison of 22 different\ninitialization methods on the convergence and accuracy of five optimizers:\ndifferential evolution (DE), particle swarm optimization (PSO), cuckoo search\n(CS), artificial bee colony (ABC) algorithm and genetic algorithm (GA). We have\nused 19 different test functions with different properties and modalities to\ncompare the possible effects of initialization, population sizes and the\nnumbers of iterations. Rigorous statistical ranking tests indicate that 43.37\\%\nof the functions using the DE algorithm show significant differences for\ndifferent initialization methods, while 73.68\\% of the functions using both PSO\nand CS algorithms are significantly affected by different initialization\nmethods. The simulations show that DE is less sensitive to initialization,\nwhile both PSO and CS are more sensitive to initialization. In addition, under\nthe condition of the same maximum number of function evaluations (FEs), the\npopulation size can also have a strong effect. Particle swarm optimization\nusually requires a larger population, while the cuckoo search needs only a\nsmall population size. Differential evolution depends more heavily on the\nnumber of iterations, a relatively small population with more iterations can\nlead to better results. Furthermore, ABC is more sensitive to initialization,\nwhile such initialization has little effect on GA. Some probability\ndistributions such as the beta distribution, exponential distribution and\nRayleigh distribution can usually lead to better performance. The implications\nof this study and further research topics are also discussed in detail.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 14:58:04 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Li", "Qian", ""], ["Liu", "San-Yang", ""], ["Yang", "Xin-She", ""]]}, {"id": "2003.03792", "submitter": "Divyam Aggarwal", "authors": "Divyam Aggarwal, Dhish Kumar Saxena, Thomas Back, Michael Emmerich", "title": "Real-World Airline Crew Pairing Optimization: Customized Genetic\n  Algorithm versus Column Generation Method", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Airline crew cost is the second-largest operating cost component and its\nmarginal improvement may translate to millions of dollars annually. Further,\nit's highly constrained-combinatorial nature brings-in high impact research and\ncommercial value. The airline crew pairing optimization problem (CPOP) is aimed\nat generating a set of crew pairings, covering all flights from its timetable,\nwith minimum cost, while satisfying multiple legality constraints laid by\nfederations, etc. Depending upon CPOP's scale, several Genetic Algorithm and\nColumn Generation based approaches have been proposed in the literature.\nHowever, these approaches have been validated either on small-scale flight\ndatasets (a handful of pairings) or for smaller airlines (operating-in\nlow-demand regions) such as Turkish Airlines, etc. Their search-efficiency gets\nimpaired drastically when scaled to the networks of bigger airlines. The\ncontributions of this paper relate to the proposition of a customized genetic\nalgorithm, with improved initialization and genetic operators, developed by\nexploiting the domain-knowledge; and its comparison with a column generation\nbased large-scale optimizer (developed by authors). To demonstrate the utility\nof the above-cited contributions, a real-world test-case (839 flights),\nprovided by GE Aviation, is used which has been extracted from the networks of\nlarger airlines (operating up to 33000 monthly flights in the US).\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 15:04:57 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Aggarwal", "Divyam", ""], ["Saxena", "Dhish Kumar", ""], ["Back", "Thomas", ""], ["Emmerich", "Michael", ""]]}, {"id": "2003.04138", "submitter": "Dimitris Kamilis", "authors": "Dimitris Kamilis, Mario Blatter, Nick Polydorides", "title": "Learned Spectral Computed Tomography", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral Photon-Counting Computed Tomography (SPCCT) is a promising\ntechnology that has shown a number of advantages over conventional X-ray\nComputed Tomography (CT) in the form of material separation, artefact removal\nand enhanced image quality. However, due to the increased complexity and\nnon-linearity of the SPCCT governing equations, model-based reconstruction\nalgorithms typically require handcrafted regularisation terms and meticulous\ntuning of hyperparameters making them impractical to calibrate in variable\nconditions. Additionally, they typically incur high computational costs and in\ncases of limited-angle data, their imaging capability deteriorates\nsignificantly. Recently, Deep Learning has proven to provide state-of-the-art\nreconstruction performance in medical imaging applications while circumventing\nmost of these challenges. Inspired by these advances, we propose a Deep\nLearning imaging method for SPCCT that exploits the expressive power of Neural\nNetworks while also incorporating model knowledge. The method takes the form of\na two-step learned primal-dual algorithm that is trained using case-specific\ndata. The proposed approach is characterised by fast reconstruction capability\nand high imaging performance, even in limited-data cases, while avoiding the\nhand-tuning that is required by other optimisation approaches. We demonstrate\nthe performance of the method in terms of reconstructed images and quality\nmetrics via numerical examples inspired by the application of cardiovascular\nimaging.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 13:39:12 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Kamilis", "Dimitris", ""], ["Blatter", "Mario", ""], ["Polydorides", "Nick", ""]]}, {"id": "2003.04273", "submitter": "Saket Dingliwal", "authors": "Saket Dingliwal, Divyansh Pareek, Jatin Arora", "title": "Finding Input Characterizations for Output Properties in ReLU Neural\n  Networks", "comments": "5 page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have emerged as a powerful mechanism and are\nbeing increasingly deployed in real-world safety-critical domains. Despite the\nwidespread success, their complex architecture makes proving any formal\nguarantees about them difficult. Identifying how logical notions of high-level\ncorrectness relate to the complex low-level network architecture is a\nsignificant challenge. In this project, we extend the ideas presented in and\nintroduce a way to bridge the gap between the architecture and the high-level\nspecifications. Our key insight is that instead of directly proving the safety\nproperties that are required, we first prove properties that relate closely to\nthe structure of the neural net and use them to reason about the safety\nproperties. We build theoretical foundations for our approach, and empirically\nevaluate the performance through various experiments, achieving promising\nresults than the existing approach by identifying a larger region of input\nspace that guarantees a certain property on the output.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 17:29:39 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Dingliwal", "Saket", ""], ["Pareek", "Divyansh", ""], ["Arora", "Jatin", ""]]}, {"id": "2003.04285", "submitter": "Behzad Ghazanfari", "authors": "Behzad Ghazanfari, Fatemeh Afghah", "title": "Deep Inverse Feature Learning: A Representation Learning of Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel perspective about error in machine learning and\nproposes inverse feature learning (IFL) as a representation learning approach\nthat learns a set of high-level features based on the representation of error\nfor classification or clustering purposes. The proposed perspective about error\nrepresentation is fundamentally different from current learning methods, where\nin classification approaches they interpret the error as a function of the\ndifferences between the true labels and the predicted ones or in clustering\napproaches, in which the clustering objective functions such as compactness are\nused. Inverse feature learning method operates based on a deep clustering\napproach to obtain a qualitative form of the representation of error as\nfeatures. The performance of the proposed IFL method is evaluated by applying\nthe learned features along with the original features, or just using the\nlearned features in different classification and clustering techniques for\nseveral data sets. The experimental results show that the proposed method leads\nto promising results in classification and especially in clustering. In\nclassification, the proposed features along with the primary features improve\nthe results of most of the classification methods on several popular data sets.\nIn clustering, the performance of different clustering methods is considerably\nimproved on different data sets. There are interesting results that show some\nfew features of the representation of error capture highly informative aspects\nof primary features. We hope this paper helps to utilize the error\nrepresentation learning in different feature learning domains.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 17:45:44 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Ghazanfari", "Behzad", ""], ["Afghah", "Fatemeh", ""]]}, {"id": "2003.04286", "submitter": "Charles Jin", "authors": "Charles Jin, Martin Rinard", "title": "Manifold Regularization for Locally Stable Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply concepts from manifold regularization to develop new regularization\ntechniques for training locally stable deep neural networks. Our regularizers\nare based on a sparsification of the graph Laplacian which holds with high\nprobability when the data is sparse in high dimensions, as is common in deep\nlearning. Empirically, our networks exhibit stability in a diverse set of\nperturbation models, including $\\ell_2$, $\\ell_\\infty$, and Wasserstein-based\nperturbations; in particular, we achieve 40% adversarial accuracy on CIFAR-10\nagainst an adaptive PGD attack using $\\ell_\\infty$ perturbations of size\n$\\epsilon = 8/255$, and state-of-the-art verified accuracy of 21% in the same\nperturbation model. Furthermore, our techniques are efficient, incurring\noverhead on par with two additional parallel forward passes through the\nnetwork.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 17:45:44 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2020 22:53:45 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Jin", "Charles", ""], ["Rinard", "Martin", ""]]}, {"id": "2003.04389", "submitter": "Adam Gaier", "authors": "Adam Gaier, Alexander Asteroth, Jean-Baptiste Mouret", "title": "Discovering Representations for Black-box Optimization", "comments": "Presented at GECCO 2020 -- v2 (Previous title 'Automating\n  Representation Discovery with MAP-Elites')", "journal-ref": null, "doi": "10.1145/3377930.3390221", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The encoding of solutions in black-box optimization is a delicate,\nhandcrafted balance between expressiveness and domain knowledge -- between\nexploring a wide variety of solutions, and ensuring that those solutions are\nuseful. Our main insight is that this process can be automated by generating a\ndataset of high-performing solutions with a quality diversity algorithm (here,\nMAP-Elites), then learning a representation with a generative model (here, a\nVariational Autoencoder) from that dataset. Our second insight is that this\nrepresentation can be used to scale quality diversity optimization to higher\ndimensions -- but only if we carefully mix solutions generated with the learned\nrepresentation and those generated with traditional variation operators. We\ndemonstrate these capabilities by learning an low-dimensional encoding for the\ninverse kinematics of a thousand joint planar arm. The results show that\nlearned representations make it possible to solve high-dimensional problems\nwith orders of magnitude fewer evaluations than the standard MAP-Elites, and\nthat, once solved, the produced encoding can be used for rapid optimization of\nnovel, but similar, tasks. The presented techniques not only scale up quality\ndiversity algorithms to high dimensions, but show that black-box optimization\nencodings can be automatically learned, rather than hand designed.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 20:06:20 GMT"}, {"version": "v2", "created": "Sun, 5 Jul 2020 13:28:03 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Gaier", "Adam", ""], ["Asteroth", "Alexander", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "2003.04407", "submitter": "Jean-Baptiste Mouret", "authors": "Jean-Baptiste Mouret, Glenn Maguire", "title": "Quality Diversity for Multi-task Optimization", "comments": null, "journal-ref": "Proc. of GECCO 2020", "doi": "10.1145/3377930.3390203", "report-no": null, "categories": "cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality Diversity (QD) algorithms are a recent family of optimization\nalgorithms that search for a large set of diverse but high-performing\nsolutions. In some specific situations, they can solve multiple tasks at once.\nFor instance, they can find the joint positions required for a robotic arm to\nreach a set of points, which can also be solved by running a classic optimizer\nfor each target point. However, they cannot solve multiple tasks when the\nfitness needs to be evaluated independently for each task (e.g., optimizing\npolicies to grasp many different objects). In this paper, we propose an\nextension of the MAP-Elites algorithm, called Multi-task MAP-Elites, that\nsolves multiple tasks when the fitness function depends on the task. We\nevaluate it on a simulated parameterized planar arm (10-dimensional search\nspace; 5000 tasks) and on a simulated 6-legged robot with legs of different\nlengths (36-dimensional search space; 2000 tasks). The results show that in\nboth cases our algorithm outperforms the optimization of each task separately\nwith the CMA-ES algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 20:48:07 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 09:53:07 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Mouret", "Jean-Baptiste", ""], ["Maguire", "Glenn", ""]]}, {"id": "2003.04603", "submitter": "Zhenshan Bing", "authors": "Zhenshan Bing, Claus Meschede, Guang Chen, Alois Knoll, Kai Huang", "title": "Indirect and Direct Training of Spiking Neural Networks for End-to-End\n  Control of a Lane-Keeping Vehicle", "comments": null, "journal-ref": "Neural Networks, 2020", "doi": "10.1016/j.neunet.2019.05.019", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building spiking neural networks (SNNs) based on biological synaptic\nplasticities holds a promising potential for accomplishing fast and\nenergy-efficient computing, which is beneficial to mobile robotic applications.\nHowever, the implementations of SNNs in robotic fields are limited due to the\nlack of practical training methods. In this paper, we therefore introduce both\nindirect and direct end-to-end training methods of SNNs for a lane-keeping\nvehicle. First, we adopt a policy learned using the \\textcolor{black}{Deep\nQ-Learning} (DQN) algorithm and then subsequently transfer it to an SNN using\nsupervised learning. Second, we adopt the reward-modulated\nspike-timing-dependent plasticity (R-STDP) for training SNNs directly, since it\ncombines the advantages of both reinforcement learning and the well-known\nspike-timing-dependent plasticity (STDP). We examine the proposed approaches in\nthree scenarios in which a robot is controlled to keep within lane markings by\nusing an event-based neuromorphic vision sensor. We further demonstrate the\nadvantages of the R-STDP approach in terms of the lateral localization accuracy\nand training time steps by comparing them with other three algorithms presented\nin this paper.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 09:35:46 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Bing", "Zhenshan", ""], ["Meschede", "Claus", ""], ["Chen", "Guang", ""], ["Knoll", "Alois", ""], ["Huang", "Kai", ""]]}, {"id": "2003.04713", "submitter": "Xin-She Yang", "authors": "Qian Li, San-Yang Liu, Xin-She Yang", "title": "Neighborhood Information-based Probabilistic Algorithm for Network\n  Disintegration", "comments": "25 pages, 13 figures, 2 tables", "journal-ref": "Expert Systems with Applications, Volume 139, (2020), Article\n  112853", "doi": "10.1016/j.eswa.2019.112853", "report-no": null, "categories": "cs.SI cs.AI cs.NE math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many real-world applications can be modelled as complex networks, and such\nnetworks include the Internet, epidemic disease networks, transport networks,\npower grids, protein-folding structures and others. Network integrity and\nrobustness are important to ensure that crucial networks are protected and\nundesired harmful networks can be dismantled. Network structure and integrity\ncan be controlled by a set of key nodes, and to find the optimal combination of\nnodes in a network to ensure network structure and integrity can be an\nNP-complete problem. Despite extensive studies, existing methods have many\nlimitations and there are still many unresolved problems. This paper presents a\nprobabilistic approach based on neighborhood information and node importance,\nnamely, neighborhood information-based probabilistic algorithm (NIPA). We also\ndefine a new centrality-based importance measure (IM), which combines the\ncontribution ratios of the neighbor nodes of each target node and two-hop node\ninformation. Our proposed NIPA has been tested for different network benchmarks\nand compared with three other methods: optimal attack strategy (OAS), high\nbetweenness first (HBF) and high degree first (HDF). Experiments suggest that\nthe proposed NIPA is most effective among all four methods. In general, NIPA\ncan identify the most crucial node combination with higher effectiveness, and\nthe set of optimal key nodes found by our proposed NIPA is much smaller than\nthat by heuristic centrality prediction. In addition, many previously neglected\nweakly connected nodes are identified, which become a crucial part of the newly\nidentified optimal nodes. Thus, revised strategies for protection are\nrecommended to ensure the safeguard of network integrity. Further key issues\nand future research topics are also discussed.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 15:09:25 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Li", "Qian", ""], ["Liu", "San-Yang", ""], ["Yang", "Xin-She", ""]]}, {"id": "2003.04881", "submitter": "Daniel Filan", "authors": "Daniel Filan, Shlomi Hod, Cody Wild, Andrew Critch, Stuart Russell", "title": "Pruned Neural Networks are Surprisingly Modular", "comments": "25 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learned weights of a neural network are often considered devoid of\nscrutable internal structure. To discern structure in these weights, we\nintroduce a measurable notion of modularity for multi-layer perceptrons (MLPs),\nand investigate the modular structure of MLPs trained on datasets of small\nimages. Our notion of modularity comes from the graph clustering literature: a\n\"module\" is a set of neurons with strong internal connectivity but weak\nexternal connectivity. We find that training and weight pruning produces MLPs\nthat are more modular than randomly initialized ones, and often significantly\nmore modular than random MLPs with the same (sparse) distribution of weights.\nInterestingly, they are much more modular when trained with dropout. We also\npresent exploratory analyses of the importance of different modules for\nperformance and how modules depend on each other. Understanding the modular\nstructure of neural networks, when such structure exists, will hopefully render\ntheir inner workings more interpretable to engineers. Note that this paper has\nbeen superceded by \"Clusterability in Neural Networks\", arxiv:2103.03386!\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 17:51:33 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 16:57:35 GMT"}, {"version": "v3", "created": "Mon, 22 Jun 2020 22:18:17 GMT"}, {"version": "v4", "created": "Tue, 11 Aug 2020 21:50:05 GMT"}, {"version": "v5", "created": "Mon, 8 Mar 2021 21:17:49 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Filan", "Daniel", ""], ["Hod", "Shlomi", ""], ["Wild", "Cody", ""], ["Critch", "Andrew", ""], ["Russell", "Stuart", ""]]}, {"id": "2003.05271", "submitter": "Talgat Daulbaev", "authors": "Talgat Daulbaev and Alexandr Katrutsa and Larisa Markeeva and Julia\n  Gusak and Andrzej Cichocki and Ivan Oseledets", "title": "Interpolation Technique to Speed Up Gradients Propagation in Neural ODEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple interpolation-based method for the efficient\napproximation of gradients in neural ODE models. We compare it with the reverse\ndynamic method (known in the literature as \"adjoint method\") to train neural\nODEs on classification, density estimation, and inference approximation tasks.\nWe also propose a theoretical justification of our approach using logarithmic\nnorm formalism. As a result, our method allows faster model training than the\nreverse dynamic method that was confirmed and validated by extensive numerical\nexperiments for several standard benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 13:15:57 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2020 21:44:17 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Daulbaev", "Talgat", ""], ["Katrutsa", "Alexandr", ""], ["Markeeva", "Larisa", ""], ["Gusak", "Julia", ""], ["Cichocki", "Andrzej", ""], ["Oseledets", "Ivan", ""]]}, {"id": "2003.05385", "submitter": "Ehsan Kharazmi", "authors": "Ehsan Kharazmi, Zhongqiang Zhang, George Em Karniadakis", "title": "hp-VPINNs: Variational Physics-Informed Neural Networks With Domain\n  Decomposition", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2020.113547", "report-no": null, "categories": "cs.NE cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate a general framework for hp-variational physics-informed neural\nnetworks (hp-VPINNs) based on the nonlinear approximation of shallow and deep\nneural networks and hp-refinement via domain decomposition and projection onto\nspace of high-order polynomials. The trial space is the space of neural\nnetwork, which is defined globally over the whole computational domain, while\nthe test space contains the piecewise polynomials. Specifically in this study,\nthe hp-refinement corresponds to a global approximation with local learning\nalgorithm that can efficiently localize the network parameter optimization. We\ndemonstrate the advantages of hp-VPINNs in accuracy and training cost for\nseveral numerical examples of function approximation and solving differential\nequations.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 16:06:34 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Kharazmi", "Ehsan", ""], ["Zhang", "Zhongqiang", ""], ["Karniadakis", "George Em", ""]]}, {"id": "2003.05988", "submitter": "Hui Wang", "authors": "Hui Wang, Michael Emmerich, Mike Preuss, Aske Plaat", "title": "Analysis of Hyper-Parameters for Small Games: Iterations or Epochs in\n  Self-Play?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The landmark achievements of AlphaGo Zero have created great research\ninterest into self-play in reinforcement learning. In self-play, Monte Carlo\nTree Search is used to train a deep neural network, that is then used in tree\nsearches. Training itself is governed by many hyperparameters.There has been\nsurprisingly little research on design choices for hyper-parameter values and\nloss-functions, presumably because of the prohibitive computational cost to\nexplore the parameter space. In this paper, we investigate 12 hyper-parameters\nin an AlphaZero-like self-play algorithm and evaluate how these parameters\ncontribute to training. We use small games, to achieve meaningful exploration\nwith moderate computational effort. The experimental results show that training\nis highly sensitive to hyper-parameter choices. Through multi-objective\nanalysis we identify 4 important hyper-parameters to further assess. To start,\nwe find surprising results where too much training can sometimes lead to lower\nperformance. Our main result is that the number of self-play iterations\nsubsumes MCTS-search simulations, game-episodes, and training epochs. The\nintuition is that these three increase together as self-play iterations\nincrease, and that increasing them individually is sub-optimal. A consequence\nof our experiments is a direct recommendation for setting hyper-parameter\nvalues in self-play: the overarching outer-loop of self-play iterations should\nbe maximized, in favor of the three inner-loop hyper-parameters, which should\nbe set at lower values. A secondary result of our experiments concerns the\nchoice of optimization goals, for which we also provide recommendations.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 19:28:48 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Wang", "Hui", ""], ["Emmerich", "Michael", ""], ["Preuss", "Mike", ""], ["Plaat", "Aske", ""]]}, {"id": "2003.06212", "submitter": "I-Chen Wu", "authors": "Ti-Rong Wu, Ting-Han Wei, I-Chen Wu", "title": "Accelerating and Improving AlphaZero Using Population Based Training", "comments": "accepted by AAAI2020 as oral presentation. In this version,\n  supplementary materials are added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AlphaZero has been very successful in many games. Unfortunately, it still\nconsumes a huge amount of computing resources, the majority of which is spent\nin self-play. Hyperparameter tuning exacerbates the training cost since each\nhyperparameter configuration requires its own time to train one run, during\nwhich it will generate its own self-play records. As a result, multiple runs\nare usually needed for different hyperparameter configurations. This paper\nproposes using population based training (PBT) to help tune hyperparameters\ndynamically and improve strength during training time. Another significant\nadvantage is that this method requires a single run only, while incurring a\nsmall additional time cost, since the time for generating self-play records\nremains unchanged though the time for optimization is increased following the\nAlphaZero training algorithm. In our experiments for 9x9 Go, the PBT method is\nable to achieve a higher win rate for 9x9 Go than the baselines, each with its\nown hyperparameter configuration and trained individually. For 19x19 Go, with\nPBT, we are able to obtain improvements in playing strength. Specifically, the\nPBT agent can obtain up to 74% win rate against ELF OpenGo, an open-source\nstate-of-the-art AlphaZero program using a neural network of a comparable\ncapacity. This is compared to a saturated non-PBT agent, which achieves a win\nrate of 47% against ELF OpenGo under the same circumstances.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 11:56:14 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Wu", "Ti-Rong", ""], ["Wei", "Ting-Han", ""], ["Wu", "I-Chen", ""]]}, {"id": "2003.06310", "submitter": "Pai-Yu Tan", "authors": "Pai-Yu Tan, Po-Yao Chuang, Yen-Ting Lin, Cheng-Wen Wu, and Juin-Ming\n  Lu", "title": "A Power-Efficient Binary-Weight Spiking Neural Network Architecture for\n  Real-Time Object Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AR cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network hardware is considered an essential part of future edge\ndevices. In this paper, we propose a binary-weight spiking neural network\n(BW-SNN) hardware architecture for low-power real-time object classification on\nedge platforms. This design stores a full neural network on-chip, and hence\nrequires no off-chip bandwidth. The proposed systolic array maximizes data\nreuse for a typical convolutional layer. A 5-layer convolutional BW-SNN\nhardware is implemented in 90nm CMOS. Compared with state-of-the-art designs,\nthe area cost and energy per classification are reduced by 7$\\times$ and\n23$\\times$, respectively, while also achieving a higher accuracy on the MNIST\nbenchmark. This is also a pioneering SNN hardware architecture that supports\nadvanced CNN architectures.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 11:25:00 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Tan", "Pai-Yu", ""], ["Chuang", "Po-Yao", ""], ["Lin", "Yen-Ting", ""], ["Wu", "Cheng-Wen", ""], ["Lu", "Juin-Ming", ""]]}, {"id": "2003.06513", "submitter": "Yifan Gong", "authors": "Yifan Gong, Zheng Zhan, Zhengang Li, Wei Niu, Xiaolong Ma, Wenhao\n  Wang, Bin Ren, Caiwen Ding, Xue Lin, Xiaolin Xu, and Yanzhi Wang", "title": "A Privacy-Preserving-Oriented DNN Pruning and Mobile Acceleration\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight pruning of deep neural networks (DNNs) has been proposed to satisfy\nthe limited storage and computing capability of mobile edge devices. However,\nprevious pruning methods mainly focus on reducing the model size and/or\nimproving performance without considering the privacy of user data. To mitigate\nthis concern, we propose a privacy-preserving-oriented pruning and mobile\nacceleration framework that does not require the private training dataset. At\nthe algorithm level of the proposed framework, a systematic weight pruning\ntechnique based on the alternating direction method of multipliers (ADMM) is\ndesigned to iteratively solve the pattern-based pruning problem for each layer\nwith randomly generated synthetic data. In addition, corresponding\noptimizations at the compiler level are leveraged for inference accelerations\non devices. With the proposed framework, users could avoid the time-consuming\npruning process for non-experts and directly benefit from compressed models.\nExperimental results show that the proposed framework outperforms three\nstate-of-art end-to-end DNN frameworks, i.e., TensorFlow-Lite, TVM, and MNN,\nwith speedup up to 4.2X, 2.5X, and 2.0X, respectively, with almost no accuracy\nloss, while preserving data privacy.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 23:52:03 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 00:45:39 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Gong", "Yifan", ""], ["Zhan", "Zheng", ""], ["Li", "Zhengang", ""], ["Niu", "Wei", ""], ["Ma", "Xiaolong", ""], ["Wang", "Wenhao", ""], ["Ren", "Bin", ""], ["Ding", "Caiwen", ""], ["Lin", "Xue", ""], ["Xu", "Xiaolin", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2003.06617", "submitter": "Ivars Dzalbs Mr", "authors": "Ivars Dzalbs, Tatiana Kalganova, Ian Dear", "title": "Imperialist Competitive Algorithm with Independence and Constrained\n  Assimilation for Solving 0-1 Multidimensional Knapsack Problem", "comments": "PPSN2020 Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multidimensional knapsack problem is a well-known constrained\noptimization problem with many real-world engineering applications. In order to\nsolve this NP-hard problem, a new modified Imperialist Competitive Algorithm\nwith Constrained Assimilation (ICAwICA) is presented. The proposed algorithm\nintroduces the concept of colony independence, a free will to choose between\nclassical ICA assimilation to empires imperialist or any other imperialist in\nthe population. Furthermore, a constrained assimilation process has been\nimplemented that combines classical ICA assimilation and revolution operators,\nwhile maintaining population diversity. This work investigates the performance\nof the proposed algorithm across 101 Multidimensional Knapsack Problem (MKP)\nbenchmark instances. Experimental results show that the algorithm is able to\nobtain an optimal solution in all small instances and presents very competitive\nresults for large MKP instances.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 12:19:31 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Dzalbs", "Ivars", ""], ["Kalganova", "Tatiana", ""], ["Dear", "Ian", ""]]}, {"id": "2003.06696", "submitter": "Chankyu Lee", "authors": "Chankyu Lee, Adarsh Kumar Kosta, Alex Zihao Zhu, Kenneth Chaney,\n  Kostas Daniilidis, and Kaushik Roy", "title": "Spike-FlowNet: Event-based Optical Flow Estimation with Energy-Efficient\n  Hybrid Neural Networks", "comments": "European Conference on Computer Vision (ECCV) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event-based cameras display great potential for a variety of tasks such as\nhigh-speed motion detection and navigation in low-light environments where\nconventional frame-based cameras suffer critically. This is attributed to their\nhigh temporal resolution, high dynamic range, and low-power consumption.\nHowever, conventional computer vision methods as well as deep Analog Neural\nNetworks (ANNs) are not suited to work well with the asynchronous and discrete\nnature of event camera outputs. Spiking Neural Networks (SNNs) serve as ideal\nparadigms to handle event camera outputs, but deep SNNs suffer in terms of\nperformance due to the spike vanishing phenomenon. To overcome these issues, we\npresent Spike-FlowNet, a deep hybrid neural network architecture integrating\nSNNs and ANNs for efficiently estimating optical flow from sparse event camera\noutputs without sacrificing the performance. The network is end-to-end trained\nwith self-supervised learning on Multi-Vehicle Stereo Event Camera (MVSEC)\ndataset. Spike-FlowNet outperforms its corresponding ANN-based method in terms\nof the optical flow prediction capability while providing significant\ncomputational efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 14 Mar 2020 20:37:21 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 14:58:19 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 18:34:20 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Lee", "Chankyu", ""], ["Kosta", "Adarsh Kumar", ""], ["Zhu", "Alex Zihao", ""], ["Chaney", "Kenneth", ""], ["Daniilidis", "Kostas", ""], ["Roy", "Kaushik", ""]]}, {"id": "2003.06731", "submitter": "Sudarshan Ramenahalli", "authors": "Sudarshan Ramenahalli", "title": "A model of figure ground organization incorporating local and global\n  cues", "comments": "46 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Figure Ground Organization (FGO) -- inferring spatial depth ordering of\nobjects in a visual scene -- involves determining which side of an occlusion\nboundary is figure (closer to the observer) and which is ground (further away\nfrom the observer). A combination of global cues, like convexity, and local\ncues, like T-junctions are involved in this process. We present a biologically\nmotivated, feed forward computational model of FGO incorporating convexity,\nsurroundedness, parallelism as global cues and Spectral Anisotropy (SA),\nT-junctions as local cues. While SA is computed in a biologically plausible\nmanner, the inclusion of T-Junctions is biologically motivated. The model\nconsists of three independent feature channels, Color, Intensity and\nOrientation, but SA and T-Junctions are introduced only in the Orientation\nchannel as these properties are specific to that feature of objects. We study\nthe effect of adding each local cue independently and both of them\nsimultaneously to the model with no local cues. We evaluate model performance\nbased on figure-ground classification accuracy (FGCA) at every border location\nusing the BSDS 300 figure-ground dataset. Each local cue, when added alone,\ngives statistically significant improvement in the FGCA of the model suggesting\nits usefulness as an independent FGO cue. The model with both local cues\nachieves higher FGCA than the models with individual cues, indicating SA and\nT-Junctions are not mutually contradictory. Compared to the model with no local\ncues, the feed-forward model with both local cues achieves $\\geq 8.78$%\nimprovement in terms of FGCA.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 01:18:40 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Ramenahalli", "Sudarshan", ""]]}, {"id": "2003.06737", "submitter": "Claus Aranha", "authors": "Yifan He, Claus Aranha", "title": "Solving Portfolio Optimization Problems Using MOEA/D and Levy Flight", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Portfolio optimization is a financial task which requires the allocation of\ncapital on a set of financial assets to achieve a better trade-off between\nreturn and risk. To solve this problem, recent studies applied multi-objective\nevolutionary algorithms (MOEAs) for its natural bi-objective structure. This\npaper presents a method injecting a distribution-based mutation method named\nL\\'evy Flight into a decomposition based MOEA named MOEA/D. The proposed\nalgorithm is compared with three MOEA/D-like algorithms, NSGA-II, and other\ndistribution-based mutation methods on five portfolio optimization benchmarks\nsized from 31 to 225 in OR library without constraints, assessing with six\nmetrics. Numerical results and statistical test indicate that this method can\noutperform comparison methods in most cases. We analyze how Levy Flight\ncontributes to this improvement by promoting global search early in the\noptimization. We explain this improvement by considering the interaction\nbetween mutation method and the property of the problem.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 02:14:53 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["He", "Yifan", ""], ["Aranha", "Claus", ""]]}, {"id": "2003.06834", "submitter": "Yunfei Meng", "authors": "Yunfei Meng, Zhiqiu Huang, Senzhang Wang, Guohua Shen, Changbo Ke", "title": "SOM-based DDoS Defense Mechanism using SDN for the Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To effectively tackle the security threats towards the Internet of things, we\npropose a SOM-based DDoS defense mechanism using software-defined networking\n(SDN) in this paper. The main idea of the mechanism is to deploy a SDN-based\ngateway to protect the device services in the Internet of things. The gateway\nprovides DDoS defense mechanism based on SOM neural network. By means of\nSOM-based DDoS defense mechanism, the gateway can effectively identify the\nmalicious sensing devices in the IoT, and automatically block those malicious\ndevices after detecting them, so that it can effectively enforce the security\nand robustness of the system when it is under DDoS attacks. In order to\nvalidate the feasibility and effectiveness of the mechanism, we leverage POX\ncontroller and Mininet emulator to implement an experimental system, and\nfurther implement the aforementioned security enforcement mechanisms with\nPython. The final experimental results illustrate that the mechanism is truly\neffective under the different test scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 14:13:17 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 02:41:59 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Meng", "Yunfei", ""], ["Huang", "Zhiqiu", ""], ["Wang", "Senzhang", ""], ["Shen", "Guohua", ""], ["Ke", "Changbo", ""]]}, {"id": "2003.07013", "submitter": "Zhongwei Wan", "authors": "Zhenyu Liang, Yunfan Li, Zhongwei Wan", "title": "Large Scale Many-Objective Optimization Driven by Distributional\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of distribution algorithms (EDA) as one of the EAs is a stochastic\noptimization problem which establishes a probability model to describe the\ndistribution of solutions and randomly samples the probability model to create\noffspring and optimize model and population. Reference Vector Guided\nEvolutionary (RVEA) based on the EDA framework, having a better performance to\nsolve MaOPs. Besides, using the generative adversarial networks to generate\noffspring solutions is also a state-of-art thought in EAs instead of crossover\nand mutation. In this paper, we will propose a novel algorithm based on RVEA[1]\nframework and using Distributional Adversarial Networks (DAN) [2]to generate\nnew offspring. DAN uses a new distributional framework for adversarial training\nof neural networks and operates on genuine samples rather than a single point\nbecause the framework also leads to more stable training and extraordinarily\nbetter mode coverage compared to single-point-sample methods. Thereby, DAN can\nquickly generate offspring with high convergence regarding the same\ndistribution of data. In addition, we also use Large-Scale Multi-Objective\nOptimization Based on A Competitive Swarm Optimizer (LMOCSO)[3] to adopts a new\ntwo-stage strategy to update the position in order to significantly increase\nthe search efficiency to find optimal solutions in huge decision space. The\npropose new algorithm will be tested on 9 benchmark problems in Large scale\nmulti-objective problems (LSMOP). To measure the performance, we will compare\nour proposal algorithm with some state-of-art EAs e.g., RM-MEDA[4], MO-CMA[10]\nand NSGA-II.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 04:14:15 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Liang", "Zhenyu", ""], ["Li", "Yunfan", ""], ["Wan", "Zhongwei", ""]]}, {"id": "2003.07202", "submitter": "Chiou-Jye Huang", "authors": "Hsu-Yung Cheng, Ping-Huan Kuo, Yamin Shen, Chiou-Jye Huang", "title": "Deep Convolutional Neural Network Model for Short-Term Electricity Price\n  Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the modern power market, electricity trading is an extremely competitive\nindustry. More accurate price forecast is crucial to help electricity producers\nand traders make better decisions. In this paper, a novel method of\nconvolutional neural network (CNN) is proposed to rapidly provide hourly\nforecasting in the energy market. To improve prediction accuracy, we divide the\nannual electricity price data into four categories by seasons and conduct\ntraining and forecasting for each category respectively. By comparing the\nproposed method with other existing methods, we find that the proposed model\nhas achieved outstanding results, the mean absolute percentage error (MAPE) and\nroot mean square error (RMSE) for each category are about 5.5% and 3,\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 06:06:18 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Cheng", "Hsu-Yung", ""], ["Kuo", "Ping-Huan", ""], ["Shen", "Yamin", ""], ["Huang", "Chiou-Jye", ""]]}, {"id": "2003.07258", "submitter": "Wojciech Samek", "authors": "Leila Arras, Ahmed Osman, Wojciech Samek", "title": "Ground Truth Evaluation of Neural Network Explanations with CLEVR-XAI", "comments": "37 pages, 9 tables, 2 figures (plus appendix 14 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of deep learning in today's applications entailed an increasing need\nin explaining the model's decisions beyond prediction performances in order to\nfoster trust and accountability. Recently, the field of explainable AI (XAI)\nhas developed methods that provide such explanations for already trained neural\nnetworks. In computer vision tasks such explanations, termed heatmaps,\nvisualize the contributions of individual pixels to the prediction. So far XAI\nmethods along with their heatmaps were mainly validated qualitatively via\nhuman-based assessment, or evaluated through auxiliary proxy tasks such as\npixel perturbation, weak object localization or randomization tests. Due to the\nlack of an objective and commonly accepted quality measure for heatmaps, it was\ndebatable which XAI method performs best and whether explanations can be\ntrusted at all. In the present work, we tackle the problem by proposing a\nground truth based evaluation framework for XAI methods based on the CLEVR\nvisual question answering task. Our framework provides a (1) selective, (2)\ncontrolled and (3) realistic testbed for the evaluation of neural network\nexplanations. We compare ten different explanation methods, resulting in new\ninsights about the quality and properties of XAI methods, sometimes\ncontradicting with conclusions from previous comparative studies. The CLEVR-XAI\ndataset and the benchmarking code can be found at\nhttps://github.com/ahmedmagdiosman/clevr-xai.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 14:43:33 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 16:18:05 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Arras", "Leila", ""], ["Osman", "Ahmed", ""], ["Samek", "Wojciech", ""]]}, {"id": "2003.07292", "submitter": "Jamieson Warner", "authors": "J. Warner, A. Devaraj, and R. Miikkulainen", "title": "Using context to make gas classifiers robust to sensor drift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ins-det cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interaction of a gas particle with a metal-oxide based gas sensor changes\nthe sensor irreversibly. The compounded changes, referred to as sensor drift,\nare unstable, but adaptive algorithms can sustain the accuracy of odor sensor\nsystems. This paper shows how such a system can be defined without additional\ndata acquisition by transfering knowledge from one time window to a subsequent\none after drift has occurred. A context-based neural network model is used to\nform a latent representation of sensor state, thus making it possible to\ngeneralize across a sequence of states. When tested on samples from unseen\nsubsequent time windows, the approach performed better than drift-naive and\nensemble methods on a gas sensor array drift dataset. By reducing the effect\nthat sensor drift has on classification accuracy, context-based models may be\nused to extend the effective lifetime of gas identification systems in\npractical settings.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 15:53:11 GMT"}, {"version": "v2", "created": "Fri, 22 May 2020 19:09:26 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Warner", "J.", ""], ["Devaraj", "A.", ""], ["Miikkulainen", "R.", ""]]}, {"id": "2003.07417", "submitter": "Sina Ghiassian", "authors": "Sina Ghiassian, Banafsheh Rafiee, Yat Long Lo, Adam White", "title": "Improving Performance in Reinforcement Learning by Breaking\n  Generalization in Neural Networks", "comments": "10 pages; Accepted to AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning systems require good representations to work well. For\ndecades practical success in reinforcement learning was limited to small\ndomains. Deep reinforcement learning systems, on the other hand, are scalable,\nnot dependent on domain specific prior knowledge and have been successfully\nused to play Atari, in 3D navigation from pixels, and to control high degree of\nfreedom robots. Unfortunately, the performance of deep reinforcement learning\nsystems is sensitive to hyper-parameter settings and architecture choices. Even\nwell tuned systems exhibit significant instability both within a trial and\nacross experiment replications. In practice, significant expertise and trial\nand error are usually required to achieve good performance. One potential\nsource of the problem is known as catastrophic interference: when later\ntraining decreases performance by overriding previous learning. Interestingly,\nthe powerful generalization that makes Neural Networks (NN) so effective in\nbatch supervised learning might explain the challenges when applying them in\nreinforcement learning tasks. In this paper, we explore how online NN training\nand interference interact in reinforcement learning. We find that simply\nre-mapping the input observations to a high-dimensional space improves learning\nspeed and parameter sensitivity. We also show this preprocessing reduces\ninterference in prediction tasks. More practically, we provide a simple\napproach to NN training that is easy to implement, and requires little\nadditional computation. We demonstrate that our approach improves performance\nin both prediction and control with an extensive batch of experiments in\nclassic control domains.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 19:21:08 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Ghiassian", "Sina", ""], ["Rafiee", "Banafsheh", ""], ["Lo", "Yat Long", ""], ["White", "Adam", ""]]}, {"id": "2003.07442", "submitter": "Al-Akhir Nayan", "authors": "Al-Akhir Nayan, Joyeta Saha, Ahamad Nokib Mozumder, Khan Raqib Mahmud,\n  Abul Kalam Al Azad", "title": "Real Time Multi-Class Object Detection and Recognition Using Vision\n  Augmentation Algorithm", "comments": null, "journal-ref": "International Journal of Advanced Science and Technology, Vol. 29,\n  No. 5, (2020), pp. 14070 - 14083", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The aim of this research is to detect small objects with low resolution and\nnoise. The existing real time object detection algorithm is based on the deep\nneural network of convolution need to perform multilevel convolution and\npooling operations on the entire image to extract a deep semantic\ncharacteristic of the image. The detection models perform better for large\nobjects. The features of existing models do not fully represent the essential\nfeatures of small objects after repeated convolution operations. We have\nintroduced a novel real time detection algorithm which employs upsampling and\nskip connection to extract multiscale features at different convolution levels\nin a learning task resulting a remarkable performance in detecting small\nobjects. The detection precision of the model is shown to be higher and faster\nthan that of the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 01:08:24 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 00:42:06 GMT"}, {"version": "v3", "created": "Mon, 18 May 2020 06:32:23 GMT"}, {"version": "v4", "created": "Wed, 11 Nov 2020 18:22:22 GMT"}], "update_date": "2020-11-13", "authors_parsed": [["Nayan", "Al-Akhir", ""], ["Saha", "Joyeta", ""], ["Mozumder", "Ahamad Nokib", ""], ["Mahmud", "Khan Raqib", ""], ["Azad", "Abul Kalam Al", ""]]}, {"id": "2003.07477", "submitter": "Elie Aljalbout", "authors": "Elie Aljalbout and Florian Walter and Florian R\\\"ohrbein and Alois\n  Knoll", "title": "Task-Independent Spiking Central Pattern Generator: A Learning-Based\n  Approach", "comments": "Neural Processing Letters", "journal-ref": null, "doi": "10.1007/s11063-020-10224-9", "report-no": null, "categories": "cs.NE cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Legged locomotion is a challenging task in the field of robotics but a rather\nsimple one in nature. This motivates the use of biological methodologies as\nsolutions to this problem. Central pattern generators are neural networks that\nare thought to be responsible for locomotion in humans and some animal species.\nAs for robotics, many attempts were made to reproduce such systems and use them\nfor a similar goal. One interesting design model is based on spiking neural\nnetworks. This model is the main focus of this work, as its contribution is not\nlimited to engineering but also applicable to neuroscience. This paper\nintroduces a new general framework for building central pattern generators that\nare task-independent, biologically plausible, and rely on learning methods. The\nabilities and properties of the presented approach are not only evaluated in\nsimulation but also in a robotic experiment. The results are very promising as\nthe used robot was able to perform stable walking at different speeds and to\nchange speed within the same gait cycle.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 00:01:38 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Aljalbout", "Elie", ""], ["Walter", "Florian", ""], ["R\u00f6hrbein", "Florian", ""], ["Knoll", "Alois", ""]]}, {"id": "2003.07573", "submitter": "Tal Grinshpoun", "authors": "Haya Brama and Tal Grinshpoun", "title": "Heat and Blur: An Effective and Fast Defense Against Adversarial\n  Examples", "comments": "Submitted to IJCAI 2020 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing incorporation of artificial neural networks (NNs) into many\nfields, and especially into life-critical systems, is restrained by their\nvulnerability to adversarial examples (AEs). Some existing defense methods can\nincrease NNs' robustness, but they often require special architecture or\ntraining procedures and are irrelevant to already trained models. In this\npaper, we propose a simple defense that combines feature visualization with\ninput modification, and can, therefore, be applicable to various pre-trained\nnetworks. By reviewing several interpretability methods, we gain new insights\nregarding the influence of AEs on NNs' computation. Based on that, we\nhypothesize that information about the \"true\" object is preserved within the\nNN's activity, even when the input is adversarial, and present a feature\nvisualization version that can extract that information in the form of\nrelevance heatmaps. We then use these heatmaps as a basis for our defense, in\nwhich the adversarial effects are corrupted by massive blurring. We also\nprovide a new evaluation metric that can capture the effects of both attacks\nand defenses more thoroughly and descriptively, and demonstrate the\neffectiveness of the defense and the utility of the suggested evaluation\nmeasurement with VGG19 results on the ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 08:11:18 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Brama", "Haya", ""], ["Grinshpoun", "Tal", ""]]}, {"id": "2003.07584", "submitter": "Yihao Luo", "authors": "Yihao Luo, Min Xu, Caihong Yuan, Xiang Cao, Liangqi Zhang, Yan Xu,\n  Tianjiang Wang and Qi Feng", "title": "SiamSNN: Siamese Spiking Neural Networks for Energy-Efficient Object\n  Tracking", "comments": "Accepted by ICANN2021, 12 pages, 5figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently spiking neural networks (SNNs), the third-generation of neural\nnetworks has shown remarkable capabilities of energy-efficient computing, which\nis a promising alternative for deep neural networks (DNNs) with high energy\nconsumption. SNNs have reached competitive results compared to DNNs in\nrelatively simple tasks and small datasets such as image classification and\nMNIST/CIFAR, while few studies on more challenging vision tasks on complex\ndatasets. In this paper, we focus on extending deep SNNs to object tracking, a\nmore advanced vision task with embedded applications and energy-saving\nrequirements, and present a spike-based Siamese network called SiamSNN.\nSpecifically, we propose an optimized hybrid similarity estimation method to\nexploit temporal information in the SNNs, and introduce a novel two-status\ncoding scheme to optimize the temporal distribution of output spike trains for\nfurther improvements. SiamSNN is the first deep SNN tracker that achieves short\nlatency and low precision loss on the visual object tracking benchmarks\nOTB2013/2015, VOT2016/2018, and GOT-10k. Moreover, SiamSNN achieves notably low\nenergy consumption and real-time on Neuromorphic chip TrueNorth.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 08:49:51 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2020 11:41:09 GMT"}, {"version": "v3", "created": "Sat, 19 Jun 2021 05:25:33 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Luo", "Yihao", ""], ["Xu", "Min", ""], ["Yuan", "Caihong", ""], ["Cao", "Xiang", ""], ["Zhang", "Liangqi", ""], ["Xu", "Yan", ""], ["Wang", "Tianjiang", ""], ["Feng", "Qi", ""]]}, {"id": "2003.07629", "submitter": "Daniel Schl\\\"or", "authors": "Daniel Schl\\\"or, Markus Ring, Andreas Hotho", "title": "iNALU: Improved Neural Arithmetic Logic Unit", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have to capture mathematical relationships in order to learn\nvarious tasks. They approximate these relations implicitly and therefore often\ndo not generalize well. The recently proposed Neural Arithmetic Logic Unit\n(NALU) is a novel neural architecture which is able to explicitly represent the\nmathematical relationships by the units of the network to learn operations such\nas summation, subtraction or multiplication. Although NALUs have been shown to\nperform well on various downstream tasks, an in-depth analysis reveals\npractical shortcomings by design, such as the inability to multiply or divide\nnegative input values or training stability issues for deeper networks. We\naddress these issues and propose an improved model architecture. We evaluate\nour model empirically in various settings from learning basic arithmetic\noperations to more complex functions. Our experiments indicate that our model\nsolves stability issues and outperforms the original NALU model in means of\narithmetic precision and convergence.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 10:37:22 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Schl\u00f6r", "Daniel", ""], ["Ring", "Markus", ""], ["Hotho", "Andreas", ""]]}, {"id": "2003.07631", "submitter": "Wojciech Samek", "authors": "Wojciech Samek, Gr\\'egoire Montavon, Sebastian Lapuschkin, Christopher\n  J. Anders, Klaus-Robert M\\\"uller", "title": "Explaining Deep Neural Networks and Beyond: A Review of Methods and\n  Applications", "comments": "30 pages, 20 figures", "journal-ref": null, "doi": "10.1109/JPROC.2021.3060483", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the broader and highly successful usage of machine learning in industry\nand the sciences, there has been a growing demand for Explainable AI.\nInterpretability and explanation methods for gaining a better understanding\nabout the problem solving abilities and strategies of nonlinear Machine\nLearning, in particular, deep neural networks, are therefore receiving\nincreased attention. In this work we aim to (1) provide a timely overview of\nthis active emerging field, with a focus on 'post-hoc' explanations, and\nexplain its theoretical foundations, (2) put interpretability algorithms to a\ntest both from a theory and comparative evaluation perspective using extensive\nsimulations, (3) outline best practice aspects i.e. how to best include\ninterpretation methods into the standard usage of machine learning and (4)\ndemonstrate successful usage of explainable AI in a representative selection of\napplication scenarios. Finally, we discuss challenges and possible future\ndirections of this exciting foundational field of machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 10:45:51 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 12:39:41 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Samek", "Wojciech", ""], ["Montavon", "Gr\u00e9goire", ""], ["Lapuschkin", "Sebastian", ""], ["Anders", "Christopher J.", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "2003.07636", "submitter": "Francesco Leofante", "authors": "Dario Guidotti and Francesco Leofante and Luca Pulina and Armando\n  Tacchella", "title": "Verification of Neural Networks: Enhancing Scalability through Pruning", "comments": "Accepted at ECAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification of deep neural networks has witnessed a recent surge of\ninterest, fueled by success stories in diverse domains and by abreast concerns\nabout safety and security in envisaged applications. Complexity and sheer size\nof such networks are challenging for automated formal verification techniques\nwhich, on the other hand, could ease the adoption of deep networks in safety-\nand security-critical contexts.\n  In this paper we focus on enabling state-of-the-art verification tools to\ndeal with neural networks of some practical interest. We propose a new training\npipeline based on network pruning with the goal of striking a balance between\nmaintaining accuracy and robustness while making the resulting networks\namenable to formal analysis. The results of our experiments with a portfolio of\npruning algorithms and verification tools show that our approach is successful\nfor the kind of networks we consider and for some combinations of pruning and\nverification techniques, thus bringing deep neural networks closer to the reach\nof formally-grounded methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 10:54:08 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Guidotti", "Dario", ""], ["Leofante", "Francesco", ""], ["Pulina", "Luca", ""], ["Tacchella", "Armando", ""]]}, {"id": "2003.07794", "submitter": "Sen Tian", "authors": "Xuanyu Shu, Jin Zhang, Sen Tian, Sheng chen and Lingyu Chen", "title": "Research on a New Convolutional Neural Network Model Combined with\n  Random Edges Adding", "comments": "I am very sorry to request the withdrawal of the manuscript for the\n  following reasons: 1.Uploading this manuscript violates school-related\n  requirements. 2.And at the same time, when the tutor and other authors knew\n  about it, they did not agree and requested to withdraw the manuscript. I hope\n  you can understand and agree to my request", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is always a hot and difficult point to improve the accuracy of\nconvolutional neural network model and speed up its convergence. Based on the\nidea of small world network, a random edge adding algorithm is proposed to\nimprove the performance of convolutional neural network model. This algorithm\ntakes the convolutional neural network model as a benchmark, and randomizes\nbackwards and cross-layer connections with probability p to form a new\nconvolutional neural network model. The proposed idea can optimize the cross\nlayer connectivity by changing the topological structure of convolutional\nneural network, and provide a new idea for the improvement of the model. The\nsimulation results based on Fashion-MINST and cifar10 data set show that the\nmodel recognition accuracy and training convergence speed are greatly improved\nby random edge adding reconstructed models with aprobability p = 0.1.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 16:17:55 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 07:58:22 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Shu", "Xuanyu", ""], ["Zhang", "Jin", ""], ["Tian", "Sen", ""], ["chen", "Sheng", ""], ["Chen", "Lingyu", ""]]}, {"id": "2003.07916", "submitter": "Germ\\'an Kruszewski", "authors": "Germ\\'an Kruszewski, Tomas Mikolov", "title": "Combinatory Chemistry: Towards a Simple Model of Emergent Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.NE q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An explanatory model for the emergence of evolvable units must display\nemerging structures that (1) preserve themselves in time (2) self-reproduce and\n(3) tolerate a certain amount of variation when reproducing. To tackle this\nchallenge, here we introduce Combinatory Chemistry, an Algorithmic Artificial\nChemistry based on a minimalistic computational paradigm named Combinatory\nLogic. The dynamics of this system comprise very few rules, it is initialised\nwith an elementary tabula rasa state, and features conservation laws\nreplicating natural resource constraints. Our experiments show that a single\nrun of this dynamical system with no external intervention discovers a wide\nrange of emergent patterns. All these structures rely on acquiring basic\nconstituents from the environment and decomposing them in a process that is\nremarkably similar to biological metabolisms. These patterns include\nautopoietic structures that maintain their organisation, recursive ones that\ngrow in linear chains or binary-branching trees, and most notably, patterns\nable to reproduce themselves, duplicating their number at each generation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 19:55:58 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 10:09:57 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["Kruszewski", "Germ\u00e1n", ""], ["Mikolov", "Tomas", ""]]}, {"id": "2003.08154", "submitter": "Sven Banisch", "authors": "Sven Banisch and Felix Gaisbauer and Eckehard Olbrich", "title": "How social feedback processing in the brain shapes collective opinion\n  processes in the era of social media", "comments": "Odycceus Research (www.odycceus.eu)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.MA cs.NE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What are the mechanisms by which groups with certain opinions gain public\nvoice and force others holding a different view into silence? And how does\nsocial media play into this? Drawing on recent neuro-scientific insights into\nthe processing of social feedback, we develop a theoretical model that allows\nto address these questions. The model captures phenomena described by spiral of\nsilence theory of public opinion, provides a mechanism-based foundation for it,\nand allows in this way more general insight into how different group structures\nrelate to different regimes of collective opinion expression. Even strong\nmajorities can be forced into silence if a minority acts as a cohesive whole.\nThe proposed framework of social feedback theory (SFT) highlights the need for\nsociological theorising to understand the societal-level implications of\nfindings in social and cognitive neuroscience.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 11:06:34 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Banisch", "Sven", ""], ["Gaisbauer", "Felix", ""], ["Olbrich", "Eckehard", ""]]}, {"id": "2003.08165", "submitter": "David Ha", "authors": "Yujin Tang, Duong Nguyen, David Ha", "title": "Neuroevolution of Self-Interpretable Agents", "comments": "To appear at the Genetic and Evolutionary Computation Conference\n  (GECCO 2020) as a full paper", "journal-ref": null, "doi": "10.1145/3377930.3389847", "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Inattentional blindness is the psychological phenomenon that causes one to\nmiss things in plain sight. It is a consequence of the selective attention in\nperception that lets us remain focused on important parts of our world without\ndistraction from irrelevant details. Motivated by selective attention, we study\nthe properties of artificial agents that perceive the world through the lens of\na self-attention bottleneck. By constraining access to only a small fraction of\nthe visual input, we show that their policies are directly interpretable in\npixel space. We find neuroevolution ideal for training self-attention\narchitectures for vision-based reinforcement learning (RL) tasks, allowing us\nto incorporate modules that can include discrete, non-differentiable operations\nwhich are useful for our agent. We argue that self-attention has similar\nproperties as indirect encoding, in the sense that large implicit weight\nmatrices are generated from a small number of key-query parameters, thus\nenabling our agent to solve challenging vision based tasks with at least 1000x\nfewer parameters than existing methods. Since our agent attends to only task\ncritical visual hints, they are able to generalize to environments where task\nirrelevant elements are modified while conventional methods fail. Videos of our\nresults and source code available at https://attentionagent.github.io/\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 11:40:35 GMT"}, {"version": "v2", "created": "Thu, 2 Apr 2020 09:00:39 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Tang", "Yujin", ""], ["Nguyen", "Duong", ""], ["Ha", "David", ""]]}, {"id": "2003.08196", "submitter": "\\.Ilke Ercan", "authors": "Se\\c{c}kin Bar{\\i}\\c{s}{\\i}k and \\.Ilke Ercan", "title": "Thermodynamic Cost of Edge Detection in Artificial Neural\n  Network(ANN)-Based Processors", "comments": "International Journal of Parallel, Emergent and Distributed Systems,\n  October 2020", "journal-ref": null, "doi": "10.1080/17445760.2020.1836639", "report-no": null, "categories": "eess.IV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Architecture-based heat dissipation analyses allow us to reveal fundamental\nsources of inefficiency in a given processor and thereby provide us with\nroad-maps to design less dissipative computing schemes independent of\ntechnology-base used to implement them. In this work, we study\narchitectural-level contributions to energy dissipation in an Artificial Neural\nNetwork (ANN)-based processor that is trained to perform edge-detection task.\nWe compare the training and information processing cost of ANN to that of\nconventional architectures and algorithms using 64-pixel binary image. Our\nresults reveal the inherent efficiency advantages of an ANN network trained for\nspecific tasks over general-purpose processors based on von Neumann\narchitecture. We also compare the proposed performance improvements to that of\nCellular Array Processors (CAPs) and illustrate the reduction in dissipation\nfor special purpose processors. Lastly, we calculate the change in dissipation\nas a result of input data structure and show the effect of randomness on\nenergetic cost of information processing. The results we obtained provide a\nbasis for comparison for task-based fundamental energy efficiency analyses for\na range of processors and therefore contribute to the study of\narchitecture-level descriptions of processors and thermodynamic cost\ncalculations based on physics of computation.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 13:02:10 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 10:15:49 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Bar\u0131\u015f\u0131k", "Se\u00e7kin", ""], ["Ercan", "\u0130lke", ""]]}, {"id": "2003.08295", "submitter": "Zhongwei Wan", "authors": "Zhenyu Liang, Yunfan Li, Zhongwei Wan", "title": "Many-Objective Estimation of Distribution Optimization Algorithm Based\n  on WGAN-GP", "comments": "arXiv admin note: substantial text overlap with arXiv:2003.07013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of distribution algorithms (EDA) are stochastic optimization\nalgorithms. EDA establishes a probability model to describe the distribution of\nsolution from the perspective of population macroscopically by statistical\nlearning method, and then randomly samples the probability model to generate a\nnew population. EDA can better solve multi-objective optimal problems (MOPs).\nHowever, the performance of EDA decreases in solving many-objective optimal\nproblems (MaOPs), which contains more than three objectives. Reference Vector\nGuided Evolutionary Algorithm (RVEA), based on the EDA framework, can better\nsolve MaOPs. In our paper, we use the framework of RVEA. However, we generate\nthe new population by Wasserstein Generative Adversarial Networks-Gradient\nPenalty (WGAN-GP) instead of using crossover and mutation. WGAN-GP have\nadvantages of fast convergence, good stability and high sample quality. WGAN-GP\nlearn the mapping relationship from standard normal distribution to given data\nset distribution based on a given data set subject to the same distribution. It\ncan quickly generate populations with high diversity and good convergence. To\nmeasure the performance, RM-MEDA, MOPSO and NSGA-II are selected to perform\ncomparison experiments over DTLZ and LSMOP test suites with 3-, 5-, 8-, 10- and\n15-objective.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 03:14:59 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Liang", "Zhenyu", ""], ["Li", "Yunfan", ""], ["Wan", "Zhongwei", ""]]}, {"id": "2003.08536", "submitter": "Rui Wang", "authors": "Rui Wang, Joel Lehman, Aditya Rawal, Jiale Zhi, Yulun Li, Jeff Clune,\n  Kenneth O. Stanley", "title": "Enhanced POET: Open-Ended Reinforcement Learning through Unbounded\n  Invention of Learning Challenges and their Solutions", "comments": "23 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating open-ended algorithms, which generate their own never-ending stream\nof novel and appropriately challenging learning opportunities, could help to\nautomate and accelerate progress in machine learning. A recent step in this\ndirection is the Paired Open-Ended Trailblazer (POET), an algorithm that\ngenerates and solves its own challenges, and allows solutions to goal-switch\nbetween challenges to avoid local optima. However, the original POET was unable\nto demonstrate its full creative potential because of limitations of the\nalgorithm itself and because of external issues including a limited problem\nspace and lack of a universal progress measure. Importantly, both limitations\npose impediments not only for POET, but for the pursuit of open-endedness in\ngeneral. Here we introduce and empirically validate two new innovations to the\noriginal algorithm, as well as two external innovations designed to help\nelucidate its full potential. Together, these four advances enable the most\nopen-ended algorithmic demonstration to date. The algorithmic innovations are\n(1) a domain-general measure of how meaningfully novel new challenges are,\nenabling the system to potentially create and solve interesting challenges\nendlessly, and (2) an efficient heuristic for determining when agents should\ngoal-switch from one problem to another (helping open-ended search better\nscale). Outside the algorithm itself, to enable a more definitive demonstration\nof open-endedness, we introduce (3) a novel, more flexible way to encode\nenvironmental challenges, and (4) a generic measure of the extent to which a\nsystem continues to exhibit open-ended innovation. Enhanced POET produces a\ndiverse range of sophisticated behaviors that solve a wide range of\nenvironmental challenges, many of which cannot be solved through other means.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 01:35:56 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 07:18:27 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Wang", "Rui", ""], ["Lehman", "Joel", ""], ["Rawal", "Aditya", ""], ["Zhi", "Jiale", ""], ["Li", "Yulun", ""], ["Clune", "Jeff", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "2003.08561", "submitter": "Sung Whan Yoon", "authors": "Sung Whan Yoon, Do-Yeon Kim, Jun Seo, Jaekyun Moon", "title": "XtarNet: Learning to Extract Task-Adaptive Representation for\n  Incremental Few-Shot Learning", "comments": "In Proceedings of the 37th International Conference on Machine\n  Learning (ICML) 2020, Vienna, Austria, PMLR 119; *Equal contribution", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning (ICML) 2020, Vienna, Austria, PMLR 119", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning novel concepts while preserving prior knowledge is a long-standing\nchallenge in machine learning. The challenge gets greater when a novel task is\ngiven with only a few labeled examples, a problem known as incremental few-shot\nlearning. We propose XtarNet, which learns to extract task-adaptive\nrepresentation (TAR) for facilitating incremental few-shot learning. The method\nutilizes a backbone network pretrained on a set of base categories while also\nemploying additional modules that are meta-trained across episodes. Given a new\ntask, the novel feature extracted from the meta-trained modules is mixed with\nthe base feature obtained from the pretrained model. The process of combining\ntwo different features provides TAR and is also controlled by meta-trained\nmodules. The TAR contains effective information for classifying both novel and\nbase categories. The base and novel classifiers quickly adapt to a given task\nby utilizing the TAR. Experiments on standard image datasets indicate that\nXtarNet achieves state-of-the-art incremental few-shot learning performance.\nThe concept of TAR can also be used in conjunction with existing incremental\nfew-shot learning methods; extensive simulation results in fact show that\napplying TAR enhances the known methods significantly.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 04:02:44 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 07:08:02 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Yoon", "Sung Whan", ""], ["Kim", "Do-Yeon", ""], ["Seo", "Jun", ""], ["Moon", "Jaekyun", ""]]}, {"id": "2003.08646", "submitter": "Guangli Li", "authors": "Guangli Li, Lei Liu, Xueying Wang, Xiu Ma, Xiaobing Feng", "title": "LANCE: Efficient Low-Precision Quantized Winograd Convolution for Neural\n  Networks Based on Graphics Processing Units", "comments": "Accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerating deep convolutional neural networks has become an active topic\nand sparked an interest in academia and industry. In this paper, we propose an\nefficient low-precision quantized Winograd convolution algorithm, called LANCE,\nwhich combines the advantages of fast convolution and quantization techniques.\nBy embedding linear quantization operations into the Winograd-domain, the fast\nconvolution can be performed efficiently under low-precision computation on\ngraphics processing units. We test neural network models with LANCE on\nrepresentative image classification datasets, including SVHN, CIFAR, and\nImageNet. The experimental results show that our 8-bit quantized Winograd\nconvolution improves the performance by up to 2.40x over the full-precision\nconvolution with trivial accuracy loss.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 09:46:50 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 03:03:26 GMT"}, {"version": "v3", "created": "Tue, 28 Jul 2020 13:15:20 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Li", "Guangli", ""], ["Liu", "Lei", ""], ["Wang", "Xueying", ""], ["Ma", "Xiu", ""], ["Feng", "Xiaobing", ""]]}, {"id": "2003.08766", "submitter": "Javier Gonzalez-Trejo", "authors": "Javier Gonzalez-Trejo, Diego Mercado-Ravell", "title": "Dense Crowds Detection and Surveillance with Drones using Density Maps", "comments": "2020 International Conference on Unmanned Aircraft Systems (ICUAS),\n  Athens, Greece, 2020", "journal-ref": null, "doi": "10.1109/ICUAS48674.2020.9213886", "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting and Counting people in a human crowd from a moving drone present\nchallenging problems that arisefrom the constant changing in the image\nperspective andcamera angle. In this paper, we test two different\nstate-of-the-art approaches, density map generation with VGG19 trainedwith the\nBayes loss function and detect-then-count with FasterRCNN with ResNet50-FPN as\nbackbone, in order to comparetheir precision for counting and detecting people\nin differentreal scenarios taken from a drone flight. We show empiricallythat\nboth proposed methodologies perform especially well fordetecting and counting\npeople in sparse crowds when thedrone is near the ground. Nevertheless, VGG19\nprovides betterprecision on both tasks while also being lighter than\nFasterRCNN. Furthermore, VGG19 outperforms Faster RCNN whendealing with dense\ncrowds, proving to be more robust toscale variations and strong occlusions,\nbeing more suitable forsurveillance applications using drones\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 02:05:47 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Gonzalez-Trejo", "Javier", ""], ["Mercado-Ravell", "Diego", ""]]}, {"id": "2003.09114", "submitter": "German I. Parisi", "authors": "German I. Parisi and Vincenzo Lomonaco", "title": "Online Continual Learning on Sequences", "comments": "L. Oneto et al. (eds.), Recent Trends in Learning From Data, Studies\n  in Computational Intelligence 896", "journal-ref": null, "doi": "10.1007/978-3-030-43883-8_8", "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online continual learning (OCL) refers to the ability of a system to learn\nover time from a continuous stream of data without having to revisit previously\nencountered training samples. Learning continually in a single data pass is\ncrucial for agents and robots operating in changing environments and required\nto acquire, fine-tune, and transfer increasingly complex representations from\nnon-i.i.d. input distributions. Machine learning models that address OCL must\nalleviate \\textit{catastrophic forgetting} in which hidden representations are\ndisrupted or completely overwritten when learning from streams of novel input.\nIn this chapter, we summarize and discuss recent deep learning models that\naddress OCL on sequential input through the use (and combination) of synaptic\nregularization, structural plasticity, and experience replay. Different\nimplementations of replay have been proposed that alleviate catastrophic\nforgetting in connectionists architectures via the re-occurrence of (latent\nrepresentations of) input sequences and that functionally resemble mechanisms\nof hippocampal replay in the mammalian brain. Empirical evidence shows that\narchitectures endowed with experience replay typically outperform architectures\nwithout in (online) incremental learning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 05:49:31 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Parisi", "German I.", ""], ["Lomonaco", "Vincenzo", ""]]}, {"id": "2003.09158", "submitter": "Ravi Vadlamani", "authors": "Shaik Tanveer Ul Huq and Vadlamani Ravi", "title": "Evolutionary Multi-Objective Optimization Framework for Mining\n  Association Rules", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, two multi-objective optimization frameworks in two variants\n(i.e., NSGA-III-ARM-V1, NSGA-III-ARM-V2; and MOEAD-ARM-V1, MOEAD-ARM-V2) are\nproposed to find association rules from transactional datasets. The first\nframework uses Non-dominated sorting genetic algorithm III (NSGA-III) and the\nsecond uses Decomposition based multi-objective evolutionary algorithm (MOEA/D)\nto find the association rules which are diverse, non-redundant and\nnon-dominated (having high objective function values). In both these\nframeworks, there is no need to specify minimum support and minimum confidence.\nIn the first variant, support, confidence, and lift are considered as objective\nfunctions while in second, confidence, lift, and interestingness are considered\nas objective functions. These frameworks are tested on seven different kinds of\ndatasets including two real-life bank datasets. Our study suggests that\nNSGA-III-ARM framework works better than MOEAD-ARM framework in both the\nvariants across majority of the datasets.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 09:27:53 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Huq", "Shaik Tanveer Ul", ""], ["Ravi", "Vadlamani", ""]]}, {"id": "2003.09415", "submitter": "Leslie Smith", "authors": "Leslie S. Smith", "title": "Comments on Sejnowski's \"The unreasonable effectiveness of deep learning\n  in artificial intelligence\" [arXiv:2002.04806]", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Terry Sejnowski's 2020 paper [arXiv:2002.04806] is entitled \"The unreasonable\neffectiveness of deep learning in artificial intelligence\". However, the paper\ndoesn't attempt to answer the implied question of why Deep Convolutional Neural\nNetworks (DCNNs) can approximate so many of the mappings that they have been\ntrained to model. While there are detailed mathematical analyses, this short\npaper attempts to look at the issue differently, considering the way that these\nnetworks are used, the subset of these functions that can be achieved by\ntraining (starting from some location in the original function space), as well\nas the functions to which these networks will actually be applied.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 17:54:08 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 13:45:34 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Smith", "Leslie S.", ""]]}, {"id": "2003.09543", "submitter": "Seyed Mohssen Ghafari", "authors": "Seyed Mohssen Ghafari", "title": "Towards Time-Aware Context-Aware Deep Trust Prediction in Online Social\n  Networks", "comments": "158 pages, 20 figures, and 19 tables. This is my PhD thesis in\n  Macquarie University, Sydney, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust can be defined as a measure to determine which source of information is\nreliable and with whom we should share or from whom we should accept\ninformation. There are several applications for trust in Online Social Networks\n(OSNs), including social spammer detection, fake news detection, retweet\nbehaviour detection and recommender systems. Trust prediction is the process of\npredicting a new trust relation between two users who are not currently\nconnected. In applications of trust, trust relations among users need to be\npredicted. This process faces many challenges, such as the sparsity of\nuser-specified trust relations, the context-awareness of trust and changes in\ntrust values over time. In this dissertation, we analyse the state-of-the-art\nin pair-wise trust prediction models in OSNs. We discuss three main challenges\nin this domain and present novel trust prediction approaches to address them.\nWe first focus on proposing a low-rank representation of users that\nincorporates users' personality traits as additional information. Then, we\npropose a set of context-aware trust prediction models. Finally, by considering\nthe time-dependency of trust relations, we propose a dynamic deep trust\nprediction approach. We design and implement five pair-wise trust prediction\napproaches and evaluate them with real-world datasets collected from OSNs. The\nexperimental results demonstrate the effectiveness of our approaches compared\nto other state-of-the-art pair-wise trust prediction models.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 01:00:02 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Ghafari", "Seyed Mohssen", ""]]}, {"id": "2003.09594", "submitter": "Mehdi Neshat", "authors": "Mehdi Neshat, Bradley Alexander, Nataliia Y. Sergiienko, Markus Wagner", "title": "Optimisation of Large Wave Farms using a Multi-strategy Evolutionary\n  Framework", "comments": null, "journal-ref": "GECCO 20 (2020) 1150-1158", "doi": "10.1145/3377930.3390235", "report-no": null, "categories": "cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wave energy is a fast-developing and promising renewable energy resource. The\nprimary goal of this research is to maximise the total harnessed power of a\nlarge wave farm consisting of fully-submerged three-tether wave energy\nconverters (WECs). Energy maximisation for large farms is a challenging search\nproblem due to the costly calculations of the hydrodynamic interactions between\nWECs in a large wave farm and the high dimensionality of the search space. To\naddress this problem, we propose a new hybrid multi-strategy evolutionary\nframework combining smart initialisation, binary population-based evolutionary\nalgorithm, discrete local search and continuous global optimisation. For\nassessing the performance of the proposed hybrid method, we compare it with a\nwide variety of state-of-the-art optimisation approaches, including six\ncontinuous evolutionary algorithms, four discrete search techniques and three\nhybrid optimisation methods. The results show that the proposed method performs\nconsiderably better in terms of convergence speed and farm output.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 07:07:50 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Neshat", "Mehdi", ""], ["Alexander", "Bradley", ""], ["Sergiienko", "Nataliia Y.", ""], ["Wagner", "Markus", ""]]}, {"id": "2003.09696", "submitter": "Anup Das", "authors": "Adarsha Balaji, Prathyusha Adiraju, Hirak J. Kashyap, Anup Das,\n  Jeffrey L. Krichmar, Nikil D. Dutt, Francky Catthoor", "title": "PyCARL: A PyNN Interface for Hardware-Software Co-Simulation of Spiking\n  Neural Network", "comments": "10 pages, 25 figures. Accepted for publication at International Joint\n  Conference on Neural Networks (IJCNN) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present PyCARL, a PyNN-based common Python programming interface for\nhardware-software co-simulation of spiking neural network (SNN). Through\nPyCARL, we make the following two key contributions. First, we provide an\ninterface of PyNN to CARLsim, a computationally-efficient, GPU-accelerated and\nbiophysically-detailed SNN simulator. PyCARL facilitates joint development of\nmachine learning models and code sharing between CARLsim and PyNN users,\npromoting an integrated and larger neuromorphic community. Second, we integrate\ncycle-accurate models of state-of-the-art neuromorphic hardware such as\nTrueNorth, Loihi, and DynapSE in PyCARL, to accurately model hardware latencies\nthat delay spikes between communicating neurons and degrade performance. PyCARL\nallows users to analyze and optimize the performance difference between\nsoftware-only simulation and hardware-software co-simulation of their machine\nlearning models. We show that system designers can also use PyCARL to perform\ndesign-space exploration early in the product development stage, facilitating\nfaster time-to-deployment of neuromorphic products. We evaluate the memory\nusage and simulation time of PyCARL using functionality tests, synthetic SNNs,\nand realistic applications. Our results demonstrate that for large SNNs, PyCARL\ndoes not lead to any significant overhead compared to CARLsim. We also use\nPyCARL to analyze these SNNs for a state-of-the-art neuromorphic hardware and\ndemonstrate a significant performance deviation from software-only simulations.\nPyCARL allows to evaluate and minimize such differences early during model\ndevelopment.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 16:37:03 GMT"}, {"version": "v2", "created": "Tue, 12 May 2020 13:31:08 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Balaji", "Adarsha", ""], ["Adiraju", "Prathyusha", ""], ["Kashyap", "Hirak J.", ""], ["Das", "Anup", ""], ["Krichmar", "Jeffrey L.", ""], ["Dutt", "Nikil D.", ""], ["Catthoor", "Francky", ""]]}, {"id": "2003.09847", "submitter": "Khanh N. Dang", "authors": "Khanh N. Dang, Abderazek Ben Abdallah", "title": "An Efficient Software-Hardware Design Framework for Spiking Neural\n  Network Systems", "comments": null, "journal-ref": "2019 International Conference on Internet of Things, Embedded\n  Systems and Communications (IINTEC)", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Network (SNN) is the third generation of Neural Network (NN)\nmimicking the natural behavior of the brain. By processing based on binary\ninput/output, SNNs offer lower complexity, higher density and lower power\nconsumption. This work presents an efficient software-hardware design framework\nfor developing SNN systems in hardware. In addition, a design of low-cost\nneurosynaptic core is presented based on packet-switching communication\napproach. The evaluation results show that the ANN to SNN conversion method\nwith the size 784:1200:1200:10 performs 99% accuracy for MNIST while the\nunsupervised STDP archives 89% with the size 784:400 with recurrent\nconnections. The design of 256-neurons and 65k synapses is also implemented in\nASIC 45nm technology with an area cost of 0.205 $m m^2$.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 09:52:15 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Dang", "Khanh N.", ""], ["Abdallah", "Abderazek Ben", ""]]}, {"id": "2003.09855", "submitter": "Xinyu Liu", "authors": "Xinyu Liu, Xiaoguang Di", "title": "TanhExp: A Smooth Activation Function with High Convergence Speed for\n  Lightweight Neural Networks", "comments": "This paper is a preprint of a paper accepted by IET Computer Vision\n  and is subject to Institution of Engineering and Technology Copyright. When\n  the final version is published, the copy of record will be available at the\n  IET Digital Library", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lightweight or mobile neural networks used for real-time computer vision\ntasks contain fewer parameters than normal networks, which lead to a\nconstrained performance. In this work, we proposed a novel activation function\nnamed Tanh Exponential Activation Function (TanhExp) which can improve the\nperformance for these networks on image classification task significantly. The\ndefinition of TanhExp is f(x) = xtanh(e^x). We demonstrate the simplicity,\nefficiency, and robustness of TanhExp on various datasets and network models\nand TanhExp outperforms its counterparts in both convergence speed and\naccuracy. Its behaviour also remains stable even with noise added and dataset\naltered. We show that without increasing the size of the network, the capacity\nof lightweight neural networks can be enhanced by TanhExp with only a few\ntraining epochs and no extra parameters added.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 10:40:31 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 13:43:34 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Liu", "Xinyu", ""], ["Di", "Xiaoguang", ""]]}, {"id": "2003.09887", "submitter": "Thomas Hubregtsen", "authors": "Thomas Hubregtsen, Josef Pichlmeier, Patrick Stecher, Koen Bertels", "title": "Evaluation of Parameterized Quantum Circuits: on the relation between\n  classification accuracy, expressibility and entangling capability", "comments": "Pre-Print", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An active area of investigation in the search for quantum advantage is\nQuantum Machine Learning. Quantum Machine Learning, and Parameterized Quantum\nCircuits in a hybrid quantum-classical setup in particular, could bring\nadvancements in accuracy by utilizing the high dimensionality of the Hilbert\nspace as feature space. But is the ability of a quantum circuit to uniformly\naddress the Hilbert space a good indicator of classification accuracy? In our\nwork, we use methods and quantifications from prior art to perform a numerical\nstudy in order to evaluate the level of correlation. We find a strong\ncorrelation between the ability of the circuit to uniformly address the Hilbert\nspace and the achieved classification accuracy for circuits that entail a\nsingle embedding layer followed by 1 or 2 circuit designs. This is based on our\nstudy encompassing 19 circuits in both 1 and 2 layer configuration, evaluated\non 9 datasets of increasing difficulty. Future work will evaluate if this holds\nfor different circuit designs.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 13:31:31 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 11:51:04 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Hubregtsen", "Thomas", ""], ["Pichlmeier", "Josef", ""], ["Stecher", "Patrick", ""], ["Bertels", "Koen", ""]]}, {"id": "2003.09917", "submitter": "Weiyu Chen", "authors": "Weiyu Chen, Hisao Ishibuchi, Ke Shang", "title": "Effects of Discretization of Decision and Objective Spaces on the\n  Performance of Evolutionary Multiobjective Optimization Algorithms", "comments": "2019 IEEE Symposium Series on Computational Intelligence (SSCI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, the discretization of decision and objective spaces has been\ndiscussed in the literature. In some studies, it is shown that the decision\nspace discretization improves the performance of evolutionary multi-objective\noptimization (EMO) algorithms on continuous multi-objective test problems. In\nother studies, it is shown that the objective space discretization improves the\nperformance on combinatorial multi-objective problems. However, the effect of\nthe simultaneous discretization of both spaces has not been examined in the\nliterature. In this paper, we examine the effects of the decision space\ndiscretization, objective space discretization and simultaneous discretization\non the performance of NSGA-II through computational experiments on the DTLZ and\nWFG problems. Using various settings about the number of decision variables and\nthe number of objectives, our experiments are performed on four types of\nproblems: standard problems, large-scale problems, many-objective problems, and\nlarge-scale many-objective problems. We show that the decision space\ndiscretization has a positive effect for large-scale problems and the objective\nspace discretization has a positive effect for many-objective problems. We also\nshow the discretization of both spaces is useful for large-scale many-objective\nproblems.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 15:07:45 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Chen", "Weiyu", ""], ["Ishibuchi", "Hisao", ""], ["Shang", "Ke", ""]]}, {"id": "2003.10026", "submitter": "Yan Fang", "authors": "Ashwin Sanjay Lele, Yan Fang, Justin Ting, Arijit Raychowdhury", "title": "Learning to Walk: Spike Based Reinforcement Learning for Hexapod Robot\n  Central Pattern Generation", "comments": "5 pages, 7 figures, to be published in proceeding of IEEE AICAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to walk -- i.e., learning locomotion under performance and energy\nconstraints continues to be a challenge in legged robotics. Methods such as\nstochastic gradient, deep reinforcement learning (RL) have been explored for\nbipeds, quadrupeds and hexapods. These techniques are computationally intensive\nand often prohibitive for edge applications. These methods rely on complex\nsensors and pre-processing of data, which further increases energy and latency.\nRecent advances in spiking neural networks (SNNs) promise a significant\nreduction in computing owing to the sparse firing of neuros and has been shown\nto integrate reinforcement learning mechanisms with biologically observed spike\ntime dependent plasticity (STDP). However, training a legged robot to walk by\nlearning the synchronization patterns of central pattern generators (CPG) in an\nSNN framework has not been shown. This can marry the efficiency of SNNs with\nsynchronized locomotion of CPG based systems providing breakthrough end-to-end\nlearning in mobile robotics. In this paper, we propose a reinforcement based\nstochastic weight update technique for training a spiking CPG. The whole system\nis implemented on a lightweight raspberry pi platform with integrated sensors,\nthus opening up exciting new possibilities.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 23:45:32 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Lele", "Ashwin Sanjay", ""], ["Fang", "Yan", ""], ["Ting", "Justin", ""], ["Raychowdhury", "Arijit", ""]]}, {"id": "2003.10306", "submitter": "Thomas Uriot Tu", "authors": "Thomas Uriot and Dario Izzo", "title": "Safe Crossover of Neural Networks Through Neuron Alignment", "comments": null, "journal-ref": null, "doi": "10.1145/3377930.3390197", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main and largely unexplored challenges in evolving the weights of\nneural networks using genetic algorithms is to find a sensible crossover\noperation between parent networks. Indeed, naive crossover leads to\nfunctionally damaged offspring that do not retain information from the parents.\nThis is because neural networks are invariant to permutations of neurons,\ngiving rise to multiple ways of representing the same solution. This is often\nreferred to as the competing conventions problem. In this paper, we propose a\ntwo-step safe crossover(SC) operator. First, the neurons of the parents are\nfunctionally aligned by computing how well they correlate, and only then are\nthe parents recombined. We compare two ways of measuring relationships between\nneurons: Pairwise Correlation (PwC) and Canonical Correlation Analysis (CCA).\nWe test our safe crossover operators (SC-PwC and SC-CCA) on MNIST and CIFAR-10\nby performing arithmetic crossover on the weights of feed-forward neural\nnetwork pairs. We show that it effectively transmits information from parents\nto offspring and significantly improves upon naive crossover. Our method is\ncomputationally fast,can serve as a way to explore the fitness landscape more\nefficiently and makes safe crossover a potentially promising operator in future\nneuroevolution research and applications.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 14:50:00 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 23:00:20 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 07:58:22 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Uriot", "Thomas", ""], ["Izzo", "Dario", ""]]}, {"id": "2003.10396", "submitter": "Christopher H Bennett", "authors": "Christopher H. Bennett, Ryan Dellana, T. Patrick Xiao, Ben Feinberg,\n  Sapan Agarwal, Suma Cardwell, Matthew J. Marinella, William Severa, Brad\n  Aimone", "title": "Evaluating complexity and resilience trade-offs in emerging memory\n  inference machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic-style inference only works well if limited hardware resources\nare maximized properly, e.g. accuracy continues to scale with parameters and\ncomplexity in the face of potential disturbance. In this work, we use realistic\ncrossbar simulations to highlight that compact implementations of deep neural\nnetworks are unexpectedly susceptible to collapse from multiple system\ndisturbances. Our work proposes a middle path towards high performance and\nstrong resilience utilizing the Mosaics framework, and specifically by re-using\nsynaptic connections in a recurrent neural network implementation that\npossesses a natural form of noise-immunity.\n", "versions": [{"version": "v1", "created": "Tue, 25 Feb 2020 21:40:08 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Bennett", "Christopher H.", ""], ["Dellana", "Ryan", ""], ["Xiao", "T. Patrick", ""], ["Feinberg", "Ben", ""], ["Agarwal", "Sapan", ""], ["Cardwell", "Suma", ""], ["Marinella", "Matthew J.", ""], ["Severa", "William", ""], ["Aimone", "Brad", ""]]}, {"id": "2003.10397", "submitter": "Charles Frye", "authors": "Charles G. Frye, James Simon, Neha S. Wadia, Andrew Ligeralde, Michael\n  R. DeWeese, Kristofer E. Bouchard", "title": "Critical Point-Finding Methods Reveal Gradient-Flat Regions of Deep\n  Network Losses", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the fact that the loss functions of deep neural networks are highly\nnon-convex, gradient-based optimization algorithms converge to approximately\nthe same performance from many random initial points. One thread of work has\nfocused on explaining this phenomenon by characterizing the local curvature\nnear critical points of the loss function, where the gradients are near zero,\nand demonstrating that neural network losses enjoy a no-bad-local-minima\nproperty and an abundance of saddle points. We report here that the methods\nused to find these putative critical points suffer from a bad local minima\nproblem of their own: they often converge to or pass through regions where the\ngradient norm has a stationary point. We call these gradient-flat regions,\nsince they arise when the gradient is approximately in the kernel of the\nHessian, such that the loss is locally approximately linear, or flat, in the\ndirection of the gradient. We describe how the presence of these regions\nnecessitates care in both interpreting past results that claimed to find\ncritical points of neural network losses and in designing second-order methods\nfor optimizing neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 17:16:19 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Frye", "Charles G.", ""], ["Simon", "James", ""], ["Wadia", "Neha S.", ""], ["Ligeralde", "Andrew", ""], ["DeWeese", "Michael R.", ""], ["Bouchard", "Kristofer E.", ""]]}, {"id": "2003.10399", "submitter": "Saima Sharmin", "authors": "Saima Sharmin, Nitin Rathi, Priyadarshini Panda and Kaushik Roy", "title": "Inherent Adversarial Robustness of Deep Spiking Neural Networks: Effects\n  of Discrete Input Encoding and Non-Linear Activations", "comments": "Accepted in 16th European Conference on Computer Vision (ECCV 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent quest for trustworthy neural networks, we present Spiking\nNeural Network (SNN) as a potential candidate for inherent robustness against\nadversarial attacks. In this work, we demonstrate that adversarial accuracy of\nSNNs under gradient-based attacks is higher than their non-spiking counterparts\nfor CIFAR datasets on deep VGG and ResNet architectures, particularly in\nblackbox attack scenario. We attribute this robustness to two fundamental\ncharacteristics of SNNs and analyze their effects. First, we exhibit that input\ndiscretization introduced by the Poisson encoder improves adversarial\nrobustness with reduced number of timesteps. Second, we quantify the amount of\nadversarial accuracy with increased leak rate in Leaky-Integrate-Fire (LIF)\nneurons. Our results suggest that SNNs trained with LIF neurons and smaller\nnumber of timesteps are more robust than the ones with IF (Integrate-Fire)\nneurons and larger number of timesteps. Also we overcome the bottleneck of\ncreating gradient-based adversarial inputs in temporal domain by proposing a\ntechnique for crafting attacks from SNN\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 17:20:24 GMT"}, {"version": "v2", "created": "Thu, 23 Jul 2020 21:05:40 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Sharmin", "Saima", ""], ["Rathi", "Nitin", ""], ["Panda", "Priyadarshini", ""], ["Roy", "Kaushik", ""]]}, {"id": "2003.10423", "submitter": "Xiaolong Wang", "authors": "Qian Long, Zihan Zhou, Abhibav Gupta, Fei Fang, Yi Wu, Xiaolong Wang", "title": "Evolutionary Population Curriculum for Scaling Multi-Agent Reinforcement\n  Learning", "comments": "The project page is https://sites.google.com/view/epciclr2020 .The\n  source code is released at https://github.com/qian18long/epciclr2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent games, the complexity of the environment can grow\nexponentially as the number of agents increases, so it is particularly\nchallenging to learn good policies when the agent population is large. In this\npaper, we introduce Evolutionary Population Curriculum (EPC), a curriculum\nlearning paradigm that scales up Multi-Agent Reinforcement Learning (MARL) by\nprogressively increasing the population of training agents in a stage-wise\nmanner. Furthermore, EPC uses an evolutionary approach to fix an objective\nmisalignment issue throughout the curriculum: agents successfully trained in an\nearly stage with a small population are not necessarily the best candidates for\nadapting to later stages with scaled populations. Concretely, EPC maintains\nmultiple sets of agents in each stage, performs mix-and-match and fine-tuning\nover these sets and promotes the sets of agents with the best adaptability to\nthe next stage. We implement EPC on a popular MARL algorithm, MADDPG, and\nempirically show that our approach consistently outperforms baselines by a\nlarge margin as the number of agents grows exponentially.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 17:49:39 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Long", "Qian", ""], ["Zhou", "Zihan", ""], ["Gupta", "Abhibav", ""], ["Fang", "Fei", ""], ["Wu", "Yi", ""], ["Wang", "Xiaolong", ""]]}, {"id": "2003.10523", "submitter": "Eren Can K{\\i}z{\\i}lda\\u{g}", "authors": "Matt Emschwiller, David Gamarnik, Eren C. K{\\i}z{\\i}lda\\u{g}, Ilias\n  Zadik", "title": "Neural Networks and Polynomial Regression. Demystifying the\n  Overparametrization Phenomena", "comments": "59 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of neural network models, overparametrization refers to the\nphenomena whereby these models appear to generalize well on the unseen data,\neven though the number of parameters significantly exceeds the sample sizes,\nand the model perfectly fits the in-training data. A conventional explanation\nof this phenomena is based on self-regularization properties of algorithms used\nto train the data. In this paper we prove a series of results which provide a\nsomewhat diverging explanation. Adopting a teacher/student model where the\nteacher network is used to generate the predictions and student network is\ntrained on the observed labeled data, and then tested on out-of-sample data, we\nshow that any student network interpolating the data generated by a teacher\nnetwork generalizes well, provided that the sample size is at least an explicit\nquantity controlled by data dimension and approximation guarantee alone,\nregardless of the number of internal nodes of either teacher or student\nnetwork.\n  Our claim is based on approximating both teacher and student networks by\npolynomial (tensor) regression models with degree depending on the desired\naccuracy and network depth only. Such a parametrization notably does not depend\non the number of internal nodes. Thus a message implied by our results is that\nparametrizing wide neural networks by the number of hidden nodes is misleading,\nand a more fitting measure of parametrization complexity is the number of\nregression coefficients associated with tensorized data. In particular, this\nsomewhat reconciles the generalization ability of neural networks with more\nclassical statistical notions of data complexity and generalization bounds. Our\nempirical results on MNIST and Fashion-MNIST datasets indeed confirm that\ntensorized regression achieves a good out-of-sample performance, even when the\ndegree of the tensor is at most two.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 20:09:31 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Emschwiller", "Matt", ""], ["Gamarnik", "David", ""], ["K\u0131z\u0131lda\u011f", "Eren C.", ""], ["Zadik", "Ilias", ""]]}, {"id": "2003.10585", "submitter": "Pietro Verzelli", "authors": "Pietro Verzelli and Cesare Alippi and Lorenzo Livi and Peter Tino", "title": "Input-to-State Representation in linear reservoirs dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computing is a popular approach to design recurrent neural\nnetworks, due to its training simplicity and approximation performance. The\nrecurrent part of these networks is not trained (e.g., via gradient descent),\nmaking them appealing for analytical studies by a large community of\nresearchers with backgrounds spanning from dynamical systems to neuroscience.\nHowever, even in the simple linear case, the working principle of these\nnetworks is not fully understood and their design is usually driven by\nheuristics. A novel analysis of the dynamics of such networks is proposed,\nwhich allows the investigator to express the state evolution using the\ncontrollability matrix. Such a matrix encodes salient characteristics of the\nnetwork dynamics; in particular, its rank represents an input-indepedent\nmeasure of the memory capacity of the network. Using the proposed approach, it\nis possible to compare different reservoir architectures and explain why a\ncyclic topology achieves favourable results as verified by practitioners.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 00:14:25 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 23:22:16 GMT"}, {"version": "v3", "created": "Fri, 12 Feb 2021 14:29:49 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Verzelli", "Pietro", ""], ["Alippi", "Cesare", ""], ["Livi", "Lorenzo", ""], ["Tino", "Peter", ""]]}, {"id": "2003.10596", "submitter": "Apurva Gandhi", "authors": "Apurva Gandhi and Shomik Jain", "title": "Adversarial Perturbations Fool Deepfake Detectors", "comments": "To appear in the proceedings of the International Joint Conference on\n  Neural Networks (IJCNN 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work uses adversarial perturbations to enhance deepfake images and fool\ncommon deepfake detectors. We created adversarial perturbations using the Fast\nGradient Sign Method and the Carlini and Wagner L2 norm attack in both blackbox\nand whitebox settings. Detectors achieved over 95% accuracy on unperturbed\ndeepfakes, but less than 27% accuracy on perturbed deepfakes. We also explore\ntwo improvements to deepfake detectors: (i) Lipschitz regularization, and (ii)\nDeep Image Prior (DIP). Lipschitz regularization constrains the gradient of the\ndetector with respect to the input in order to increase robustness to input\nperturbations. The DIP defense removes perturbations using generative\nconvolutional neural networks in an unsupervised manner. Regularization\nimproved the detection of perturbed deepfakes on average, including a 10%\naccuracy boost in the blackbox case. The DIP defense achieved 95% accuracy on\nperturbed deepfakes that fooled the original detector, while retaining 98%\naccuracy in other cases on a 100 image subsample.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 00:54:02 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 05:41:32 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Gandhi", "Apurva", ""], ["Jain", "Shomik", ""]]}, {"id": "2003.10768", "submitter": "Javier Del Ser Dr.", "authors": "Eneko Osaba, Aritz D. Martinez, Jesus L. Lobo, Javier Del Ser and\n  Francisco Herrera", "title": "Multifactorial Cellular Genetic Algorithm (MFCGA): Algorithmic Design,\n  Performance Comparison and Genetic Transferability Analysis", "comments": "Accepted for its presentation at WCCI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitasking optimization is an incipient research area which is lately\ngaining a notable research momentum. Unlike traditional optimization paradigm\nthat focuses on solving a single task at a time, multitasking addresses how\nmultiple optimization problems can be tackled simultaneously by performing a\nsingle search process. The main objective to achieve this goal efficiently is\nto exploit synergies between the problems (tasks) to be optimized, helping each\nother via knowledge transfer (thereby being referred to as Transfer\nOptimization). Furthermore, the equally recent concept of Evolutionary\nMultitasking (EM) refers to multitasking environments adopting concepts from\nEvolutionary Computation as their inspiration for the simultaneous solving of\nthe problems under consideration. As such, EM approaches such as the\nMultifactorial Evolutionary Algorithm (MFEA) has shown a remarkable success\nwhen dealing with multiple discrete, continuous, single-, and/or\nmulti-objective optimization problems. In this work we propose a novel\nalgorithmic scheme for Multifactorial Optimization scenarios - the\nMultifactorial Cellular Genetic Algorithm (MFCGA) - that hinges on concepts\nfrom Cellular Automata to implement mechanisms for exchanging knowledge among\nproblems. We conduct an extensive performance analysis of the proposed MFCGA\nand compare it to the canonical MFEA under the same algorithmic conditions and\nover 15 different multitasking setups (encompassing different reference\ninstances of the discrete Traveling Salesman Problem). A further contribution\nof this analysis beyond performance benchmarking is a quantitative examination\nof the genetic transferability among the problem instances, eliciting an\nempirical demonstration of the synergies emerged between the different\noptimization tasks along the MFCGA search process.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 11:03:55 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Osaba", "Eneko", ""], ["Martinez", "Aritz D.", ""], ["Lobo", "Jesus L.", ""], ["Del Ser", "Javier", ""], ["Herrera", "Francisco", ""]]}, {"id": "2003.10847", "submitter": "Viktor Varkarakis", "authors": "Viktor Varkarakis, Shabab Bazrafkan, Peter Corcoran", "title": "Re-Training StyleGAN -- A First Step Towards Building Large, Scalable\n  Synthetic Facial Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  StyleGAN is a state-of-art generative adversarial network architecture that\ngenerates random 2D high-quality synthetic facial data samples. In this paper,\nwe recap the StyleGAN architecture and training methodology and present our\nexperiences of retraining it on a number of alternative public datasets.\nPractical issues and challenges arising from the retraining process are\ndiscussed. Tests and validation results are presented and a comparative\nanalysis of several different re-trained StyleGAN weightings is provided 1. The\nrole of this tool in building large, scalable datasets of synthetic facial data\nis also discussed.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 13:47:07 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Varkarakis", "Viktor", ""], ["Bazrafkan", "Shabab", ""], ["Corcoran", "Peter", ""]]}, {"id": "2003.10948", "submitter": "Joseph Friedman", "authors": "Peng Zhou, Nathan R. McDonald, Alexander J. Edwards, Lisa Loomis,\n  Clare D. Thiem, Joseph S. Friedman", "title": "Reservoir Computing with Planar Nanomagnet Arrays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computing is an emerging methodology for neuromorphic computing\nthat is especially well-suited for hardware implementations in size, weight,\nand power (SWaP) constrained environments. This work proposes a novel hardware\nimplementation of a reservoir computer using a planar nanomagnet array. A small\nnanomagnet reservoir is demonstrated via micromagnetic simulations to be able\nto identify simple waveforms with 100% accuracy. Planar nanomagnet reservoirs\nare a promising new solution to the growing need for dedicated neuromorphic\nhardware.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 16:25:31 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Zhou", "Peng", ""], ["McDonald", "Nathan R.", ""], ["Edwards", "Alexander J.", ""], ["Loomis", "Lisa", ""], ["Thiem", "Clare D.", ""], ["Friedman", "Joseph S.", ""]]}, {"id": "2003.11120", "submitter": "Joseph Friedman", "authors": "Alvaro Velasquez, Christopher H. Bennett, Naimul Hassan, Wesley H.\n  Brigner, Otitoaleke G. Akinola, Jean Anne C. Incorvia, Matthew J. Marinella,\n  Joseph S. Friedman", "title": "Unsupervised Competitive Hardware Learning Rule for Spintronic\n  Clustering Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hardware learning rule for unsupervised clustering within a\nnovel spintronic computing architecture. The proposed approach leverages the\nthree-terminal structure of domain-wall magnetic tunnel junction devices to\nestablish a feedback loop that serves to train such devices when they are used\nas synapses in a neuromorphic computing architecture.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 21:25:53 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Velasquez", "Alvaro", ""], ["Bennett", "Christopher H.", ""], ["Hassan", "Naimul", ""], ["Brigner", "Wesley H.", ""], ["Akinola", "Otitoaleke G.", ""], ["Incorvia", "Jean Anne C.", ""], ["Marinella", "Matthew J.", ""], ["Friedman", "Joseph S.", ""]]}, {"id": "2003.11236", "submitter": "Shan You", "authors": "Shan You, Tao Huang, Mingmin Yang, Fei Wang, Chen Qian, Changshui\n  Zhang", "title": "GreedyNAS: Towards Fast One-Shot NAS with Greedy Supernet", "comments": "To appear in CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a supernet matters for one-shot neural architecture search (NAS)\nmethods since it serves as a basic performance estimator for different\narchitectures (paths). Current methods mainly hold the assumption that a\nsupernet should give a reasonable ranking over all paths. They thus treat all\npaths equally, and spare much effort to train paths. However, it is harsh for a\nsingle supernet to evaluate accurately on such a huge-scale search space (e.g.,\n$7^{21}$). In this paper, instead of covering all paths, we ease the burden of\nsupernet by encouraging it to focus more on evaluation of those\npotentially-good ones, which are identified using a surrogate portion of\nvalidation data. Concretely, during training, we propose a multi-path sampling\nstrategy with rejection, and greedily filter the weak paths. The training\nefficiency is thus boosted since the training space has been greedily shrunk\nfrom all paths to those potentially-good ones. Moreover, we further adopt an\nexploration and exploitation policy by introducing an empirical candidate path\npool. Our proposed method GreedyNAS is easy-to-follow, and experimental results\non ImageNet dataset indicate that it can achieve better Top-1 accuracy under\nsame search space and FLOPs or latency level, but with only $\\sim$60\\% of\nsupernet training cost. By searching on a larger space, our GreedyNAS can also\nobtain new state-of-the-art architectures.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 06:54:10 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["You", "Shan", ""], ["Huang", "Tao", ""], ["Yang", "Mingmin", ""], ["Wang", "Fei", ""], ["Qian", "Chen", ""], ["Zhang", "Changshui", ""]]}, {"id": "2003.11256", "submitter": "Vinay Joshi", "authors": "Vinay Joshi, Geethan Karunaratne, Manuel Le Gallo, Irem Boybat,\n  Christophe Piveteau, Abu Sebastian, Bipin Rajendran and Evangelos Eleftheriou", "title": "ESSOP: Efficient and Scalable Stochastic Outer Product Architecture for\n  Deep Learning", "comments": "5 pages. 5 figures. Accepted at ISCAS 2020 for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have surpassed human-level accuracy in a variety\nof cognitive tasks but at the cost of significant memory/time requirements in\nDNN training. This limits their deployment in energy and memory limited\napplications that require real-time learning. Matrix-vector multiplications\n(MVM) and vector-vector outer product (VVOP) are the two most expensive\noperations associated with the training of DNNs. Strategies to improve the\nefficiency of MVM computation in hardware have been demonstrated with minimal\nimpact on training accuracy. However, the VVOP computation remains a relatively\nless explored bottleneck even with the aforementioned strategies. Stochastic\ncomputing (SC) has been proposed to improve the efficiency of VVOP computation\nbut on relatively shallow networks with bounded activation functions and\nfloating-point (FP) scaling of activation gradients. In this paper, we propose\nESSOP, an efficient and scalable stochastic outer product architecture based on\nthe SC paradigm. We introduce efficient techniques to generalize SC for weight\nupdate computation in DNNs with the unbounded activation functions (e.g.,\nReLU), required by many state-of-the-art networks. Our architecture reduces the\ncomputational cost by re-using random numbers and replacing certain FP\nmultiplication operations by bit shift scaling. We show that the ResNet-32\nnetwork with 33 convolution layers and a fully-connected layer can be trained\nwith ESSOP on the CIFAR-10 dataset to achieve baseline comparable accuracy.\nHardware design of ESSOP at 14nm technology node shows that, compared to a\nhighly pipelined FP16 multiplier design, ESSOP is 82.2% and 93.7% better in\nenergy and area efficiency respectively for outer product computation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 07:54:42 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Joshi", "Vinay", ""], ["Karunaratne", "Geethan", ""], ["Gallo", "Manuel Le", ""], ["Boybat", "Irem", ""], ["Piveteau", "Christophe", ""], ["Sebastian", "Abu", ""], ["Rajendran", "Bipin", ""], ["Eleftheriou", "Evangelos", ""]]}, {"id": "2003.11323", "submitter": "Javier Del Ser Dr.", "authors": "Alejandro Barredo-Arrieta and Javier Del Ser", "title": "Plausible Counterfactuals: Auditing Deep Learning Classifiers with\n  Realistic Adversarial Examples", "comments": "7 pages, 5 figures. Accepted for its presentation at WCCI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has witnessed the proliferation of Deep Learning models in\nmany applications, achieving unrivaled levels of predictive performance.\nUnfortunately, the black-box nature of Deep Learning models has posed\nunanswered questions about what they learn from data. Certain application\nscenarios have highlighted the importance of assessing the bounds under which\nDeep Learning models operate, a problem addressed by using assorted approaches\naimed at audiences from different domains. However, as the focus of the\napplication is placed more on non-expert users, it results mandatory to provide\nthe means for him/her to trust the model, just like a human gets familiar with\na system or process: by understanding the hypothetical circumstances under\nwhich it fails. This is indeed the angular stone for this research work: to\nundertake an adversarial analysis of a Deep Learning model. The proposed\nframework constructs counterfactual examples by ensuring their plausibility,\ne.g. there is a reasonable probability that a human could generate them without\nresorting to a computer program. Therefore, this work must be regarded as\nvaluable auditing exercise of the usable bounds a certain model is constrained\nwithin, thereby allowing for a much greater understanding of the capabilities\nand pitfalls of a model used in a real application. To this end, a Generative\nAdversarial Network (GAN) and multi-objective heuristics are used to furnish a\nplausible attack to the audited model, efficiently trading between the\nconfusion of this model, the intensity and plausibility of the generated\ncounterfactual. Its utility is showcased within a human face classification\ntask, unveiling the enormous potential of the proposed framework.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 11:08:56 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Barredo-Arrieta", "Alejandro", ""], ["Del Ser", "Javier", ""]]}, {"id": "2003.11455", "submitter": "Andreas Gr\\\"ubl", "authors": "Andreas Gr\\\"ubl, Sebastian Billaudelle, Benjamin Cramer, Vitali\n  Karasenko, Johannes Schemmel", "title": "Verification and Design Methods for the BrainScaleS Neuromorphic\n  Hardware System", "comments": "15 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents verification and implementation methods that have been\ndeveloped for the design of the BrainScaleS-2 65nm ASICs. The 2nd generation\nBrainScaleS chips are mixed-signal devices with tight coupling between\nfull-custom analog neuromorphic circuits and two general purpose\nmicroprocessors (PPU) with SIMD extension for on-chip learning and plasticity.\nSimulation methods for automated analysis and pre-tapeout calibration of the\nhighly parameterizable analog neuron and synapse circuits and for\nhardware-software co-development of the digital logic and software stack are\npresented. Accelerated operation of neuromorphic circuits and highly-parallel\ndigital data buses between the full-custom neuromorphic part and the PPU\nrequire custom methodologies to close the digital signal timing at the\ninterfaces. Novel extensions to the standard digital physical implementation\ndesign flow are highlighted. We present early results from the first full-size\nBrainScaleS-2 ASIC containing 512 neurons and 130K synapses, demonstrating the\nsuccessful application of these methods. An application example illustrates the\nfull functionality of the BrainScaleS-2 hybrid plasticity architecture.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 15:48:54 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Gr\u00fcbl", "Andreas", ""], ["Billaudelle", "Sebastian", ""], ["Cramer", "Benjamin", ""], ["Karasenko", "Vitali", ""], ["Schemmel", "Johannes", ""]]}, {"id": "2003.11456", "submitter": "Ralf M\\\"oller", "authors": "Ralf M\\\"oller", "title": "Derivation of Coupled PCA and SVD Learning Rules from a Newton\n  Zero-Finding Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In coupled learning rules for PCA (principal component analysis) and SVD\n(singular value decomposition), the update of the estimates of eigenvectors or\nsingular vectors is influenced by the estimates of eigenvalues or singular\nvalues, respectively. This coupled update mitigates the speed-stability problem\nsince the update equations converge from all directions with approximately the\nsame speed. A method to derive coupled learning rules from information criteria\nby Newton optimization is known. However, these information criteria have to be\ndesigned, offer no explanatory value, and can only impose Euclidean constraints\non the vector estimates. Here we describe an alternative approach where coupled\nPCA and SVD learning rules can systematically be derived from a Newton\nzero-finding framework. The derivation starts from an objective function,\ncombines the equations for its extrema with arbitrary constraints on the vector\nestimates, and solves the resulting vector zero-point equation using Newton's\nzero-finding method. To demonstrate the framework, we derive PCA and SVD\nlearning rules with constant Euclidean length or constant sum of the vector\nestimates.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 15:49:55 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["M\u00f6ller", "Ralf", ""]]}, {"id": "2003.11613", "submitter": "Haoyu Zhang", "authors": "Haoyu Zhang, Yaochu Jin, Ran Cheng, and Kuangrong Hao", "title": "Sampled Training and Node Inheritance for Fast Evolutionary Neural\n  Architecture Search", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of a deep neural network is heavily dependent on its\narchitecture and various neural architecture search strategies have been\ndeveloped for automated network architecture design. Recently, evolutionary\nneural architecture search (ENAS) has received increasing attention due to the\nattractive global optimization capability of evolutionary algorithms. However,\nENAS suffers from extremely high computation costs because a large number of\nperformance evaluations is usually required in evolutionary optimization and\ntraining deep neural networks is itself computationally very intensive. To\naddress this issue, this paper proposes a new evolutionary framework for fast\nENAS based on directed acyclic graph, in which parents are randomly sampled and\ntrained on each mini-batch of training data. In addition, a node inheritance\nstrategy is adopted to generate offspring individuals and their fitness is\ndirectly evaluated without training. To enhance the feature processing\ncapability of the evolved neural networks, we also encode a channel attention\nmechanism in the search space. We evaluate the proposed algorithm on the widely\nused datasets, in comparison with 26 state-of-the-art peer algorithms. Our\nexperimental results show the proposed algorithm is not only computationally\nmuch more efficiently, but also highly competitive in learning performance.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 12:33:01 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Zhang", "Haoyu", ""], ["Jin", "Yaochu", ""], ["Cheng", "Ran", ""], ["Hao", "Kuangrong", ""]]}, {"id": "2003.11623", "submitter": "Michail-Antisthenis Tsompanas", "authors": "Michail-Antisthenis Tsompanas, Larry Bull, Andrew Adamatzky, Igor\n  Balaz", "title": "Utilizing Differential Evolution into optimizing targeted cancer\n  treatments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Working towards the development of an evolvable cancer treatment simulator,\nthe investigation of Differential Evolution was considered, motivated by the\nhigh efficiency of variations of this technique in real-valued problems. A\nbasic DE algorithm, namely \"DE/rand/1\" was used to optimize the simulated\ndesign of a targeted drug delivery system for tumor treatment on PhysiCell\nsimulator. The suggested approach proved to be more efficient than a standard\ngenetic algorithm, which was not able to escape local minima after a predefined\nnumber of generations. The key attribute of DE that enables it to outperform\nstandard EAs, is the fact that it keeps the diversity of the population high,\nthroughout all the generations. This work will be incorporated with ongoing\nresearch in a more wide applicability platform that will design, develop and\nevaluate targeted drug delivery systems aiming cancer tumours.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 10:20:43 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Tsompanas", "Michail-Antisthenis", ""], ["Bull", "Larry", ""], ["Adamatzky", "Andrew", ""], ["Balaz", "Igor", ""]]}, {"id": "2003.11624", "submitter": "Michail-Antisthenis Tsompanas", "authors": "Michail-Antisthenis Tsompanas, Larry Bull, Andrew Adamatzky, Igor\n  Balaz", "title": "Novelty search employed into the development of cancer treatment\n  simulations", "comments": null, "journal-ref": null, "doi": "10.1016/j.imu.2020.100347", "report-no": null, "categories": "cs.NE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional optimization methodologies may be hindered when the automated\nsearch is stuck into local optima because of a deceptive objective function\nlandscape. Consequently, open ended search methodologies, such as novelty\nsearch, have been proposed to tackle this issue. Overlooking the objective,\nwhile putting pressure into discovering novel solutions may lead to better\nsolutions in practical problems. Novelty search was employed here to optimize\nthe simulated design of a targeted drug delivery system for tumor treatment\nunder the PhysiCell simulator. A hybrid objective equation was used containing\nboth the actual objective of an effective tumour treatment and the novelty\nmeasure of the possible solutions. Different weights of the two components of\nthe hybrid equation were investigated to unveil the significance of each one.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 10:40:04 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Tsompanas", "Michail-Antisthenis", ""], ["Bull", "Larry", ""], ["Adamatzky", "Andrew", ""], ["Balaz", "Igor", ""]]}, {"id": "2003.11628", "submitter": "Eneko Osaba", "authors": "Eneko Osaba, Javier Del Ser, Xin-She Yang, Andres Iglesias and Akemi\n  Galvez", "title": "COEBA: A Coevolutionary Bat Algorithm for Discrete Evolutionary\n  Multitasking", "comments": "13 pages, 0 figures, paper submitted and accepted in the 11th\n  workshop Computational Optimization, Modelling and Simulation (COMS 2020),\n  part of the International Conference on Computational Science (ICCS 2020)", "journal-ref": null, "doi": "10.1007/978-3-030-50426-7_19", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitasking optimization is an emerging research field which has attracted\nlot of attention in the scientific community. The main purpose of this paradigm\nis how to solve multiple optimization problems or tasks simultaneously by\nconducting a single search process. The main catalyst for reaching this\nobjective is to exploit possible synergies and complementarities among the\ntasks to be optimized, helping each other by virtue of the transfer of\nknowledge among them (thereby being referred to as Transfer Optimization). In\nthis context, Evolutionary Multitasking addresses Transfer Optimization\nproblems by resorting to concepts from Evolutionary Computation for\nsimultaneous solving the tasks at hand. This work contributes to this trend by\nproposing a novel algorithmic scheme for dealing with multitasking\nenvironments. The proposed approach, coined as Coevolutionary Bat Algorithm,\nfinds its inspiration in concepts from both co-evolutionary strategies and the\nmetaheuristic Bat Algorithm. We compare the performance of our proposed method\nwith that of its Multifactorial Evolutionary Algorithm counterpart over 15\ndifferent multitasking setups, composed by eight reference instances of the\ndiscrete Traveling Salesman Problem. The experimentation and results stemming\ntherefrom support the main hypothesis of this study: the proposed\nCoevolutionary Bat Algorithm is a promising meta-heuristic for solving\nEvolutionary Multitasking scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 13:37:43 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Osaba", "Eneko", ""], ["Del Ser", "Javier", ""], ["Yang", "Xin-She", ""], ["Iglesias", "Andres", ""], ["Galvez", "Akemi", ""]]}, {"id": "2003.11632", "submitter": "Andrea Gayon Lombardo Miss", "authors": "Andrea Gayon-Lombardo, Lukas Mosser, Nigel P. Brandon, Samuel J.\n  Cooper", "title": "Pores for thought: The use of generative adversarial networks for the\n  stochastic reconstruction of 3D multi-phase electrode microstructures with\n  periodic boundaries", "comments": "37 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generation of multiphase porous electrode microstructures is a critical\nstep in the optimisation of electrochemical energy storage devices. This work\nimplements a deep convolutional generative adversarial network (DC-GAN) for\ngenerating realistic n-phase microstructural data. The same network\narchitecture is successfully applied to two very different three-phase\nmicrostructures: A lithium-ion battery cathode and a solid oxide fuel cell\nanode. A comparison between the real and synthetic data is performed in terms\nof the morphological properties (volume fraction, specific surface area,\ntriple-phase boundary) and transport properties (relative diffusivity), as well\nas the two-point correlation function. The results show excellent agreement\nbetween for datasets and they are also visually indistinguishable. By modifying\nthe input to the generator, we show that it is possible to generate\nmicrostructure with periodic boundaries in all three directions. This has the\npotential to significantly reduce the simulated volume required to be\nconsidered representative and therefore massively reduce the computational cost\nof the electrochemical simulations necessary to predict the performance of a\nparticular microstructure during optimisation.\n", "versions": [{"version": "v1", "created": "Mon, 17 Feb 2020 17:38:27 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 21:37:20 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Gayon-Lombardo", "Andrea", ""], ["Mosser", "Lukas", ""], ["Brandon", "Nigel P.", ""], ["Cooper", "Samuel J.", ""]]}, {"id": "2003.11637", "submitter": "Pravin Game", "authors": "Pravin S Game, Dr. Vinod Vaze, Dr. Emmanuel M", "title": "Bio-inspired Optimization: metaheuristic algorithms for optimization", "comments": null, "journal-ref": "pp. 1-9, (17-18 January 2020)", "doi": null, "report-no": "ISBN- 978-819-20113-4-9", "categories": "cs.NE cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In today's day and time solving real-world complex problems has become\nfundamentally vital and critical task. Many of these are combinatorial\nproblems, where optimal solutions are sought rather than exact solutions.\nTraditional optimization methods are found to be effective for small scale\nproblems. However, for real-world large scale problems, traditional methods\neither do not scale up or fail to obtain optimal solutions or they end-up\ngiving solutions after a long running time. Even earlier artificial\nintelligence based techniques used to solve these problems could not give\nacceptable results. However, last two decades have seen many new methods in AI\nbased on the characteristics and behaviors of the living organisms in the\nnature which are categorized as bio-inspired or nature inspired optimization\nalgorithms. These methods, are also termed meta-heuristic optimization methods,\nhave been proved theoretically and implemented using simulation as well used to\ncreate many useful applications. They have been used extensively to solve many\nindustrial and engineering complex problems due to being easy to understand,\nflexible, simple to adapt to the problem at hand and most importantly their\nability to come out of local optima traps. This local optima avoidance property\nhelps in finding global optimal solutions. This paper is aimed at understanding\nhow nature has inspired many optimization algorithms, basic categorization of\nthem, major bio-inspired optimization algorithms invented in recent time with\ntheir applications.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2020 13:26:34 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Game", "Pravin S", ""], ["Vaze", "Dr. Vinod", ""], ["M", "Dr. Emmanuel", ""]]}, {"id": "2003.11638", "submitter": "Fatima Tuz Zohora", "authors": "Fatima Tuz Zohora, Abdullah M. Zyarah, Nicholas Soures and Dhireesha\n  Kudithipudi", "title": "Metaplasticity in Multistate Memristor Synaptic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that metaplastic synapses can retain information\nlonger than simple binary synapses and are beneficial for continual learning.\nIn this paper, we explore the multistate metaplastic synapse characteristics in\nthe context of high retention and reception of information. Inherent behavior\nof a memristor emulating the multistate synapse is employed to capture the\nmetaplastic behavior. An integrated neural network study for learning and\nmemory retention is performed by integrating the synapse in a $5\\times3$\ncrossbar at the circuit level and $128\\times128$ network at the architectural\nlevel. An on-device training circuitry ensures the dynamic learning in the\nnetwork. In the $128\\times128$ network, it is observed that the number of input\npatterns the multistate synapse can classify is $\\simeq$ 2.1x that of a simple\nbinary synapse model, at a mean accuracy of $\\geq$ 75% .\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2020 04:55:33 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Zohora", "Fatima Tuz", ""], ["Zyarah", "Abdullah M.", ""], ["Soures", "Nicholas", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "2003.11639", "submitter": "Clemens Jonathan Simon Schaefer", "authors": "Clemens JS Schaefer, Patrick Faley, Emre O Neftci, Siddharth Joshi", "title": "Memory Organization for Energy-Efficient Learning and Inference in\n  Digital Neuromorphic Accelerators", "comments": "submitted to ISCAS2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The energy efficiency of neuromorphic hardware is greatly affected by the\nenergy of storing, accessing, and updating synaptic parameters. Various methods\nof memory organisation targeting energy-efficient digital accelerators have\nbeen investigated in the past, however, they do not completely encapsulate the\nenergy costs at a system level. To address this shortcoming and to account for\nvarious overheads, we synthesize the controller and memory for different\nencoding schemes and extract the energy costs from these synthesized blocks.\nAdditionally, we introduce functional encoding for structured connectivity such\nas the connectivity in convolutional layers. Functional encoding offers a 58%\nreduction in the energy to implement a backward pass and weight update in such\nlayers compared to existing index-based solutions. We show that for a 2 layer\nspiking neural network trained to retain a spatio-temporal pattern, bitmap\n(PB-BMP) based organization can encode the sparser networks more efficiently.\nThis form of encoding delivers a 1.37x improvement in energy efficiency coming\nat the cost of a 4% degradation in network retention accuracy as measured by\nthe van Rossum distance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 19:19:09 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Schaefer", "Clemens JS", ""], ["Faley", "Patrick", ""], ["Neftci", "Emre O", ""], ["Joshi", "Siddharth", ""]]}, {"id": "2003.11640", "submitter": "Xavier Hinaut", "authors": "Anthony Strock (Mnemosyne, LaBRI, IMN), Nicolas Rougier (Mnemosyne,\n  LaBRI, IMN), Xavier Hinaut (Mnemosyne, LaBRI, IMN)", "title": "Transfer between long-term and short-term memory using Conceptors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG nlin.AO q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a recurrent neural network model of working memory combining\nshort-term and long-term components. e short-term component is modelled using a\ngated reservoir model that is trained to hold a value from an input stream when\na gate signal is on. e long-term component is modelled using conceptors in\norder to store inner temporal patterns (that corresponds to values). We combine\nthese two components to obtain a model where information can go from long-term\nmemory to short-term memory and vice-versa and we show how standard operations\non conceptors allow to combine long-term memories and describe their effect on\nshort-term memory.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 09:13:58 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Strock", "Anthony", "", "Mnemosyne, LaBRI, IMN"], ["Rougier", "Nicolas", "", "Mnemosyne,\n  LaBRI, IMN"], ["Hinaut", "Xavier", "", "Mnemosyne, LaBRI, IMN"]]}, {"id": "2003.11641", "submitter": "Rafet Durgut", "authors": "Rafet Durgut", "title": "Improved Binary Artificial Bee Colony Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Artificial Bee Colony (ABC) algorithm is an evolutionary optimization\nalgorithm based on swarm intelligence and inspired by the honey bees' food\nsearch behavior. Since the ABC algorithm has been developed to achieve optimal\nsolutions by searching in the continuous search space, modification is required\nto apply this method to binary optimization problems. In this paper, we improve\nthe ABC algorithm to solve binary optimization problems and call it the\nimproved binary Artificial Bee Colony (ibinABC). The proposed method consists\nof an update mechanism based on fitness values and processing different number\nof decision variables. Thus, we aim to prevent the ABC algorithm from getting\nstuck in a local minimum by increasing its exploration ability. We compare the\nibinABC algorithm with three variants of the ABC and other meta-heuristic\nalgorithms in the literature. For comparison, we use the wellknown OR-Library\ndataset containing 15 problem instances prepared for the uncapacitated facility\nlocation problem. Computational results show that the proposed method is\nsuperior to other methods in terms of convergence speed and robustness. The\nsource code of the algorithm will be available on GitHub after reviewing\nprocess\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 17:22:52 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 17:27:22 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Durgut", "Rafet", ""]]}, {"id": "2003.11642", "submitter": "Jordan Ott", "authors": "Jordan Ott", "title": "Giving Up Control: Neurons as Reinforcement Learning Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence has historically relied on planning, heuristics, and\nhandcrafted approaches designed by experts. All the while claiming to pursue\nthe creation of Intelligence. This approach fails to acknowledge that\nintelligence emerges from the dynamics within a complex system. Neurons in the\nbrain are governed by local rules, where no single neuron, or group of neurons,\ncoordinates or controls the others. This local structure gives rise to the\nappropriate dynamics in which intelligence can emerge. Populations of neurons\nmust compete with their neighbors for resources, inhibition, and activity\nrepresentation. At the same time, they must cooperate, so the population and\norganism can perform high-level functions. To this end, we introduce modeling\nneurons as reinforcement learning agents. Where each neuron may be viewed as an\nindependent actor, trying to maximize its own self-interest. By framing\nlearning in this way, we open the door to an entirely new approach to building\nintelligent systems.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 04:47:40 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Ott", "Jordan", ""]]}, {"id": "2003.11660", "submitter": "Eli Shlizerman", "authors": "Yang Zheng, Eli Shlizerman", "title": "R-FORCE: Robust Learning for Random Recurrent Neural Networks", "comments": "Github Repository: https://github.com/shlizee/R-FORCE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Recurrent Neural Networks (RRNN) are the simplest recurrent networks\nto model and extract features from sequential data. The simplicity however\ncomes with a price; RRNN are known to be susceptible to diminishing/exploding\ngradient problem when trained with gradient-descent based optimization. To\nenhance robustness of RRNN, alternative training approaches have been proposed.\nSpecifically, FORCE learning approach proposed a recursive least squares\nalternative to train RRNN and was shown to be applicable even for the\nchallenging task of target-learning, where the network is tasked with\ngenerating dynamic patterns with no guiding input. While FORCE training\nindicates that solving target-learning is possible, it appears to be effective\nonly in a specific regime of network dynamics (edge-of-chaos). We thereby\ninvestigate whether initialization of RRNN connectivity according to a tailored\ndistribution can guarantee robust FORCE learning. We are able to generate such\ndistribution by inference of four generating principles constraining the\nspectrum of the network Jacobian to remain in stability region. This\ninitialization along with FORCE learning provides a robust training method,\ni.e., Robust-FORCE (R-FORCE). We validate R-FORCE performance on various target\nfunctions for a wide range of network configurations and compare with\nalternative methods. Our experiments indicate that R-FORCE facilitates\nsignificantly more stable and accurate target-learning for a wide class of\nRRNN. Such stability becomes critical in modeling multi-dimensional sequences\nas we demonstrate on modeling time-series of human body joints during physical\nmovements.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 22:08:03 GMT"}], "update_date": "2020-03-28", "authors_parsed": [["Zheng", "Yang", ""], ["Shlizerman", "Eli", ""]]}, {"id": "2003.11708", "submitter": "Ali Anaissi", "authors": "Seid Miad Zandavi, Vera Chung, Ali Anaissi", "title": "Multi-User Remote lab: Timetable Scheduling Using Simplex Nondominated\n  Sorting Genetic Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scheduling of multi-user remote laboratories is modeled as a multimodal\nfunction for the proposed optimization algorithm. The hybrid optimization\nalgorithm, hybridization of the Nelder-Mead Simplex algorithm and Non-dominated\nSorting Genetic Algorithm (NSGA), is proposed to optimize the timetable problem\nfor the remote laboratories to coordinate shared access. The proposed algorithm\nutilizes the Simplex algorithm in terms of exploration, and NSGA for sorting\nlocal optimum points with consideration of potential areas. The proposed\nalgorithm is applied to difficult nonlinear continuous multimodal functions,\nand its performance is compared with hybrid Simplex Particle Swarm\nOptimization, Simplex Genetic Algorithm, and other heuristic algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 02:31:50 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Zandavi", "Seid Miad", ""], ["Chung", "Vera", ""], ["Anaissi", "Ali", ""]]}, {"id": "2003.11741", "submitter": "Seongsik Park", "authors": "Seongsik Park, Seijoon Kim, Byunggook Na, Sungroh Yoon", "title": "T2FSNN: Deep Spiking Neural Networks with Time-to-first-spike Coding", "comments": "Accepted to DAC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) have gained considerable interest due to their\nenergy-efficient characteristics, yet lack of a scalable training algorithm has\nrestricted their applicability in practical machine learning problems. The deep\nneural network-to-SNN conversion approach has been widely studied to broaden\nthe applicability of SNNs. Most previous studies, however, have not fully\nutilized spatio-temporal aspects of SNNs, which has led to inefficiency in\nterms of number of spikes and inference latency. In this paper, we present\nT2FSNN, which introduces the concept of time-to-first-spike coding into deep\nSNNs using the kernel-based dynamic threshold and dendrite to overcome the\naforementioned drawback. In addition, we propose gradient-based optimization\nand early firing methods to further increase the efficiency of the T2FSNN.\nAccording to our results, the proposed methods can reduce inference latency and\nnumber of spikes to 22% and less than 1%, compared to those of burst coding,\nwhich is the state-of-the-art result on the CIFAR-100.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 04:39:12 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Park", "Seongsik", ""], ["Kim", "Seijoon", ""], ["Na", "Byunggook", ""], ["Yoon", "Sungroh", ""]]}, {"id": "2003.11837", "submitter": "Malu Zhang", "authors": "Malu Zhang, Jiadong Wang, Burin Amornpaisannon, Zhixuan Zhang, VPK\n  Miriyala, Ammar Belatreche, Hong Qu, Jibin Wu, Yansong Chua, Trevor E.\n  Carlson and Haizhou Li", "title": "Rectified Linear Postsynaptic Potential Function for Backpropagation in\n  Deep Spiking Neural Networks", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyrightmay be transferred without notice, after which this version may no\n  longer beaccessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) use spatio-temporal spike patterns to\nrepresent and transmit information, which is not only biologically realistic\nbut also suitable for ultra-low-power event-driven neuromorphic implementation.\nMotivated by the success of deep learning, the study of Deep Spiking Neural\nNetworks (DeepSNNs) provides promising directions for artificial intelligence\napplications. However, training of DeepSNNs is not straightforward because the\nwell-studied error back-propagation (BP) algorithm is not directly applicable.\nIn this paper, we first establish an understanding as to why error\nback-propagation does not work well in DeepSNNs. To address this problem, we\npropose a simple yet efficient Rectified Linear Postsynaptic Potential function\n(ReL-PSP) for spiking neurons and propose a Spike-Timing-Dependent\nBack-Propagation (STDBP) learning algorithm for DeepSNNs. In STDBP algorithm,\nthe timing of individual spikes is used to convey information (temporal\ncoding), and learning (back-propagation) is performed based on spike timing in\nan event-driven manner. Our experimental results show that the proposed\nlearning algorithm achieves state-of-the-art classification accuracy in single\nspike time based learning algorithms of DeepSNNs. Furthermore, by utilizing the\ntrained model parameters obtained from the proposed STDBP learning algorithm,\nwe demonstrate the ultra-low-power inference operations on a recently proposed\nneuromorphic inference accelerator. Experimental results show that the\nneuromorphic hardware consumes 0.751~mW of the total power consumption and\nachieves a low latency of 47.71~ms to classify an image from the MNIST dataset.\nOverall, this work investigates the contribution of spike timing dynamics to\ninformation encoding, synaptic plasticity and decision making, providing a new\nperspective to design of future DeepSNNs and neuromorphic hardware systems.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 11:13:07 GMT"}, {"version": "v2", "created": "Wed, 4 Nov 2020 04:07:23 GMT"}], "update_date": "2020-11-05", "authors_parsed": [["Zhang", "Malu", ""], ["Wang", "Jiadong", ""], ["Amornpaisannon", "Burin", ""], ["Zhang", "Zhixuan", ""], ["Miriyala", "VPK", ""], ["Belatreche", "Ammar", ""], ["Qu", "Hong", ""], ["Wu", "Jibin", ""], ["Chua", "Yansong", ""], ["Carlson", "Trevor E.", ""], ["Li", "Haizhou", ""]]}, {"id": "2003.11842", "submitter": "Frank Glavin", "authors": "James Houston, Frank G. Glavin, Michael G. Madden", "title": "Robust Classification of High-Dimensional Spectroscopy Data Using Deep\n  Learning and Data Synthesis", "comments": "Journal of Chemical Information and Modeling", "journal-ref": null, "doi": "10.1021/acs.jcim.9b01037", "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new approach to classification of high dimensional\nspectroscopy data and demonstrates that it outperforms other current\nstate-of-the art approaches. The specific task we consider is identifying\nwhether samples contain chlorinated solvents or not, based on their Raman\nspectra. We also examine robustness to classification of outlier samples that\nare not represented in the training set (negative outliers). A novel\napplication of a locally-connected neural network (NN) for the binary\nclassification of spectroscopy data is proposed and demonstrated to yield\nimproved accuracy over traditionally popular algorithms. Additionally, we\npresent the ability to further increase the accuracy of the locally-connected\nNN algorithm through the use of synthetic training spectra and we investigate\nthe use of autoencoder based one-class classifiers and outlier detectors.\nFinally, a two-step classification process is presented as an alternative to\nthe binary and one-class classification paradigms. This process combines the\nlocally-connected NN classifier, the use of synthetic training data, and an\nautoencoder based outlier detector to produce a model which is shown to both\nproduce high classification accuracy, and be robust to the presence of negative\noutliers.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 11:33:52 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Houston", "James", ""], ["Glavin", "Frank G.", ""], ["Madden", "Michael G.", ""]]}, {"id": "2003.11894", "submitter": "Tarik A. Rashid", "authors": "Hardi M. Mohammed, Tarik A. Rashid", "title": "A Novel Hybrid GWO with WOA for Global Numerical Optimization and\n  Solving Pressure Vessel Design", "comments": "28 pages", "journal-ref": "Neural Computing and Applications, 2020", "doi": "10.1007/s00521-020-04823-9", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A recent metaheuristic algorithm, such as Whale Optimization Algorithm (WOA),\nwas proposed. The idea of proposing this algorithm belongs to the hunting\nbehavior of the humpback whale. However, WOA suffers from poor performance in\nthe exploitation phase and stagnates in the local best solution. Grey Wolf\nOptimization (GWO) is a very competitive algorithm comparing to other common\nmetaheuristic algorithms as it has a super performance in the exploitation\nphase while it is tested on unimodal benchmark functions. Therefore, the aim of\nthis paper is to hybridize GWO with WOA to overcome the problems. GWO can\nperform well in exploiting optimal solutions. In this paper, a hybridized WOA\nwith GWO which is called WOAGWO is presented. The proposed hybridized model\nconsists of two steps. Firstly, the hunting mechanism of GWO is embedded into\nthe WOA exploitation phase with a new condition which is related to GWO.\nSecondly, a new technique is added to the exploration phase to improve the\nsolution after each iteration. Experimentations are tested on three different\nstandard test functions which are called benchmark functions: 23 common\nfunctions, 25 CEC2005 functions and 10 CEC2019 functions. The proposed WOAGWO\nis also evaluated against original WOA, GWO and three other commonly used\nalgorithms. Results show that WOAGWO outperforms other algorithms depending on\nthe Wilcoxon rank-sum test. Finally, WOAGWO is likewise applied to solve an\nengineering problem such as pressure vessel design. Then the results prove that\nWOAGWO achieves optimum solution which is better than WOA and Fitness Dependent\nOptimizer (FDO).\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 21:15:16 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Mohammed", "Hardi M.", ""], ["Rashid", "Tarik A.", ""]]}, {"id": "2003.11902", "submitter": "Rafa{\\l} Skinderowicz", "authors": "Rafa{\\l} Skinderowicz", "title": "Implementing a GPU-based parallel MAX-MIN Ant System", "comments": null, "journal-ref": "Future Generation Computer Systems, Volume 106, 2020, Pages\n  277-295, ISSN 0167-739X", "doi": "10.1016/j.future.2020.01.011", "report-no": null, "categories": "cs.NE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MAX-MIN Ant System (MMAS) is one of the best-known Ant Colony\nOptimization (ACO) algorithms proven to be efficient at finding satisfactory\nsolutions to many difficult combinatorial optimization problems. The slow-down\nin Moore's law, and the availability of graphics processing units (GPUs)\ncapable of conducting general-purpose computations at high speed, has sparked\nconsiderable research efforts into the development of GPU-based ACO\nimplementations. In this paper, we discuss a range of novel ideas for improving\nthe GPU-based parallel MMAS implementation, allowing it to better utilize the\ncomputing power offered by two subsequent Nvidia GPU architectures.\nSpecifically, based on the weighted reservoir sampling algorithm we propose a\nnovel parallel implementation of the node selection procedure, which is at the\nheart of the MMAS and other ACO algorithms. We also present a memory-efficient\nimplementation of another key-component -- the tabu list structure -- which is\nused in the ACO's solution construction stage. The proposed implementations,\ncombined with the existing approaches, lead to a total of six MMAS variants,\nwhich are evaluated on a set of Traveling Salesman Problem (TSP) instances\nranging from 198 to 3,795 cities. The results show that our MMAS implementation\nis competitive with state-of-the-art GPU-based and multi-core CPU-based\nparallel ACO implementations: in fact, the times obtained for the Nvidia V100\nVolta GPU were up to 7.18x and 21.79x smaller, respectively. The fastest of the\nproposed MMAS variants is able to generate over 1 million candidate solutions\nper second when solving a 1,002-city instance. Moreover, we show that, combined\nwith the 2-opt local search heuristic, the proposed parallel MMAS finds\nhigh-quality solutions for the TSP instances with up to 18,512 nodes.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 14:18:34 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Skinderowicz", "Rafa\u0142", ""]]}, {"id": "2003.11996", "submitter": "Johannes Schemmel", "authors": "Johannes Schemmel, Sebastian Billaudelle, Phillip Dauer, Johannes Weis", "title": "Accelerated Analog Neuromorphic Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the concepts behind the BrainScales (BSS) accelerated\nanalog neuromorphic computing architecture. It describes the second-generation\nBrainScales-2 (BSS-2) version and its most recent in-silico realization, the\nHICANN-X Application Specific Integrated Circuit (ASIC), as it has been\ndeveloped as part of the neuromorphic computing activities within the European\nHuman Brain Project (HBP). While the first generation is implemented in an\n180nm process, the second generation uses 65nm technology. This allows the\nintegration of a digital plasticity processing unit, a highly-parallel micro\nprocessor specially built for the computational needs of learning in an\naccelerated analog neuromorphic systems. The presented architecture is based\nupon a continuous-time, analog, physical model implementation of neurons and\nsynapses, resembling an analog neuromorphic accelerator attached to build-in\ndigital compute cores. While the analog part emulates the spike-based dynamics\nof the neural network in continuous-time, the latter simulates biological\nprocesses happening on a slower time-scale, like structural and parameter\nchanges. Compared to biological time-scales, the emulation is highly\naccelerated, i.e. all time-constants are several orders of magnitude smaller\nthan in biology. Programmable ion channel emulation and inter-compartmental\nconductances allow the modeling of nonlinear dendrites, back-propagating\naction-potentials as well as NMDA and Calcium plateau potentials. To extend the\nusability of the analog accelerator, it also supports vector-matrix\nmultiplication. Thereby, BSS-2 supports inference of deep convolutional\nnetworks as well as local-learning with complex ensembles of spiking neurons\nwithin the same substrate.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 16:00:55 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Schemmel", "Johannes", ""], ["Billaudelle", "Sebastian", ""], ["Dauer", "Phillip", ""], ["Weis", "Johannes", ""]]}, {"id": "2003.12319", "submitter": "Xavier Porte", "authors": "Louis Andreoli, Xavier Porte, St\\'ephane Chr\\'etien, Maxime Jacquot,\n  Laurent Larger and Daniel Brunner", "title": "Boolean learning under noise-perturbations in hardware neural networks", "comments": "8 pages, 5 figures", "journal-ref": "Nanophotonics (published online ahead of print), 20200171 (2020)", "doi": "10.1515/nanoph-2020-0171", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A high efficiency hardware integration of neural networks benefits from\nrealizing nonlinearity, network connectivity and learning fully in a physical\nsubstrate. Multiple systems have recently implemented some or all of these\noperations, yet the focus was placed on addressing technological challenges.\nFundamental questions regarding learning in hardware neural networks remain\nlargely unexplored. Noise in particular is unavoidable in such architectures,\nand here we investigate its interaction with a learning algorithm using an\nopto-electronic recurrent neural network. We find that noise strongly modifies\nthe system's path during convergence, and surprisingly fully decorrelates the\nfinal readout weight matrices. This highlights the importance of understanding\narchitecture, noise and learning algorithm as interacting players, and\ntherefore identifies the need for mathematical tools for noisy, analogue system\noptimization.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 10:36:03 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 09:41:21 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Andreoli", "Louis", ""], ["Porte", "Xavier", ""], ["Chr\u00e9tien", "St\u00e9phane", ""], ["Jacquot", "Maxime", ""], ["Larger", "Laurent", ""], ["Brunner", "Daniel", ""]]}, {"id": "2003.12331", "submitter": "Raluca Gaina", "authors": "Raluca D. Gaina, Sam Devlin, Simon M. Lucas, Diego Perez-Liebana", "title": "Rolling Horizon Evolutionary Algorithms for General Video Game Playing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Game-playing Evolutionary Algorithms, specifically Rolling Horizon\nEvolutionary Algorithms, have recently managed to beat the state of the art in\nwin rate across many video games. However, the best results in a game are\nhighly dependent on the specific configuration of modifications and hybrids\nintroduced over several papers, each adding additional parameters to the core\nalgorithm. Further, the best previously published parameters have been found\nfrom only a few human-picked combinations, as the possibility space has grown\nbeyond exhaustive search. This paper presents the state of the art in Rolling\nHorizon Evolutionary Algorithms, combining all modifications described in\nliterature, as well as new ones, for a large resultant hybrid. We then use a\nparameter optimiser, the N-Tuple Bandit Evolutionary Algorithm, to find the\nbest combination of parameters in 20 games from the General Video Game AI\nFramework. Further, we analyse the algorithm's parameters and some interesting\ncombinations revealed through the optimisation process. Lastly, we find new\nstate of the art solutions on several games by automatically exploring the\nlarge parameter space of RHEA.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 11:19:10 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2020 14:03:28 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Gaina", "Raluca D.", ""], ["Devlin", "Sam", ""], ["Lucas", "Simon M.", ""], ["Perez-Liebana", "Diego", ""]]}, {"id": "2003.12365", "submitter": "Sharif Abuadbba Dr", "authors": "Sharif Abuadbba, Kyuyeon Kim, Minki Kim, Chandra Thapa, Seyit A.\n  Camtepe, Yansong Gao, Hyoungshick Kim, Surya Nepal", "title": "Can We Use Split Learning on 1D CNN Models for Privacy Preserving\n  Training?", "comments": "13 pages, Accepted at ACM ASIACCS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new collaborative learning, called split learning, was recently introduced,\naiming to protect user data privacy without revealing raw input data to a\nserver. It collaboratively runs a deep neural network model where the model is\nsplit into two parts, one for the client and the other for the server.\nTherefore, the server has no direct access to raw data processed at the client.\nUntil now, the split learning is believed to be a promising approach to protect\nthe client's raw data; for example, the client's data was protected in\nhealthcare image applications using 2D convolutional neural network (CNN)\nmodels. However, it is still unclear whether the split learning can be applied\nto other deep learning models, in particular, 1D CNN.\n  In this paper, we examine whether split learning can be used to perform\nprivacy-preserving training for 1D CNN models. To answer this, we first design\nand implement an 1D CNN model under split learning and validate its efficacy in\ndetecting heart abnormalities using medical ECG data. We observed that the 1D\nCNN model under split learning can achieve the same accuracy of 98.9\\% like the\noriginal (non-split) model. However, our evaluation demonstrates that split\nlearning may fail to protect the raw data privacy on 1D CNN models. To address\nthe observed privacy leakage in split learning, we adopt two privacy leakage\nmitigation techniques: 1) adding more hidden layers to the client side and 2)\napplying differential privacy. Although those mitigation techniques are helpful\nin reducing privacy leakage, they have a significant impact on model accuracy.\nHence, based on those results, we conclude that split learning alone would not\nbe sufficient to maintain the confidentiality of raw sequential data in 1D CNN\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 06:06:14 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Abuadbba", "Sharif", ""], ["Kim", "Kyuyeon", ""], ["Kim", "Minki", ""], ["Thapa", "Chandra", ""], ["Camtepe", "Seyit A.", ""], ["Gao", "Yansong", ""], ["Kim", "Hyoungshick", ""], ["Nepal", "Surya", ""]]}, {"id": "2003.12415", "submitter": "Naresh Balaji Ravichandran", "authors": "Naresh Balaji Ravichandran, Anders Lansner, Pawel Herman", "title": "Learning representations in Bayesian Confidence Propagation neural\n  networks", "comments": null, "journal-ref": "2020 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN48605.2020.9207061", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Unsupervised learning of hierarchical representations has been one of the\nmost vibrant research directions in deep learning during recent years. In this\nwork we study biologically inspired unsupervised strategies in neural networks\nbased on local Hebbian learning. We propose new mechanisms to extend the\nBayesian Confidence Propagating Neural Network (BCPNN) architecture, and\ndemonstrate their capability for unsupervised learning of salient hidden\nrepresentations when tested on the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 13:47:16 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Ravichandran", "Naresh Balaji", ""], ["Lansner", "Anders", ""], ["Herman", "Pawel", ""]]}, {"id": "2003.12449", "submitter": "Lucian Petrica", "authors": "Mairin Kroes, Lucian Petrica, Sorin Cotofana, Michaela Blott", "title": "Evolutionary Bin Packing for Memory-Efficient Dataflow Inference\n  Acceleration on FPGA", "comments": "To appear in GECCO 2020 Proceedings", "journal-ref": null, "doi": "10.1145/3377930.3389808", "report-no": null, "categories": "cs.DC cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN) dataflow inference accelerators\nimplemented in Field Programmable Gate Arrays (FPGAs) have demonstrated\nincreased energy efficiency and lower latency compared to CNN execution on CPUs\nor GPUs. However, the complex shapes of CNN parameter memories do not typically\nmap well to FPGA on-chip memories (OCM), which results in poor OCM utilization\nand ultimately limits the size and types of CNNs which can be effectively\naccelerated on FPGAs. In this work, we present a design methodology that\nimproves the mapping efficiency of CNN parameters to FPGA OCM. We frame the\nmapping as a bin packing problem and determine that traditional bin packing\nalgorithms are not well suited to solve the problem within FPGA- and\nCNN-specific constraints. We hybridize genetic algorithms and simulated\nannealing with traditional bin packing heuristics to create flexible mappers\ncapable of grouping parameter memories such that each group optimally fits FPGA\non-chip memories. We evaluate these algorithms on a variety of FPGA inference\naccelerators. Our hybrid mappers converge to optimal solutions in a matter of\nseconds for all CNN use-cases, achieve an increase of up to 65% in OCM\nutilization efficiency for deep CNNs, and are up to 200$\\times$ faster than\ncurrent state-of-the-art simulated annealing approaches.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 09:55:08 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Kroes", "Mairin", ""], ["Petrica", "Lucian", ""], ["Cotofana", "Sorin", ""], ["Blott", "Michaela", ""]]}, {"id": "2003.12508", "submitter": "Romit Beed Mr", "authors": "Romit S Beed, Sunita Sarkar and Arindam Roy", "title": "Bayesian Hierarchical Multi-Objective Optimization for Vehicle Parking\n  Route Discovery", "comments": "10 pages, 2 Figures, 3 Tables, journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering an optimal route to the most feasible parking lot has been a\nmatter of concern for any driver which aggravates further during peak hours of\nthe day and at congested places leading to considerable wastage of time and\nfuel. This paper proposes a Bayesian hierarchical technique for obtaining the\nmost optimal route to a parking lot. The route selection is based on\nconflicting objectives and hence the problem belongs to the domain of\nmulti-objective optimization. A probabilistic data driven method has been used\nto overcome the inherent problem of weight selection in the popular weighted\nsum technique. The weights of these conflicting objectives have been refined\nusing a Bayesian hierarchical model based on Multinomial and Dirichlet prior.\nGenetic algorithm has been used to obtain optimal solutions. Simulated data has\nbeen used to obtain routes which are in close agreement with real life\nsituations.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 16:15:53 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Beed", "Romit S", ""], ["Sarkar", "Sunita", ""], ["Roy", "Arindam", ""]]}, {"id": "2003.12848", "submitter": "Anil Yaman", "authors": "Anil Yaman, Giovanni Iacca", "title": "Distributed Embodied Evolution over Networks", "comments": null, "journal-ref": "Applied Soft Computing (2020) 106993", "doi": "10.1016/j.asoc.2020.106993", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several network problems the optimum behavior of the agents (i.e., the\nnodes of the network) is not known before deployment. Furthermore, the agents\nmight be required to adapt, i.e. change their behavior based on the environment\nconditions. In these scenarios, offline optimization is usually costly and\ninefficient, while online methods might be more suitable. In this work, we use\na distributed Embodied Evolution approach to optimize spatially distributed,\nlocally interacting agents by allowing them to exchange their behavior\nparameters and learn from each other to adapt to a certain task within a given\nenvironment. Our results on several test scenarios show that the local exchange\nof information, performed by means of crossover of behavior parameters with\nneighbors, allows the network to conduct the optimization process more\nefficiently than the cases where local interactions are not allowed, even when\nthere are large differences on the optimal behavior parameters within each\nagent's neighborhood.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 17:34:48 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 17:47:17 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 15:45:05 GMT"}, {"version": "v4", "created": "Mon, 21 Dec 2020 01:58:50 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Yaman", "Anil", ""], ["Iacca", "Giovanni", ""]]}, {"id": "2003.12857", "submitter": "Chen Wei", "authors": "Chen Wei, Chuang Niu, Yiping Tang, Yue Wang, Haihong Hu, Jimin Liang", "title": "NPENAS: Neural Predictor Guided Evolution for Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) is a promising method for automatically\ndesign neural architectures. NAS adopts a search strategy to explore the\npredefined search space to find outstanding performance architecture with the\nminimum searching costs. Bayesian optimization and evolutionary algorithms are\ntwo commonly used search strategies, but they suffer from computationally\nexpensive, challenge to implement or inefficient exploration ability. In this\npaper, we propose a neural predictor guided evolutionary algorithm to enhance\nthe exploration ability of EA for NAS (NPENAS) and design two kinds of neural\npredictors. The first predictor is defined from Bayesian optimization and we\npropose a graph-based uncertainty estimation network as a surrogate model that\nis easy to implement and computationally efficient. The second predictor is a\ngraph-based neural network that directly outputs the performance prediction of\nthe input neural architecture. The NPENAS using the two neural predictors are\ndenoted as NPENAS-BO and NPENAS-NP respectively. In addition, we introduce a\nnew random architecture sampling method to overcome the drawbacks of the\nexisting sampling method. Extensive experiments demonstrate the superiority of\nNPENAS. Quantitative results on three NAS search spaces indicate that both\nNPENAS-BO and NPENAS-NP outperform most existing NAS algorithms, with NPENAS-BO\nachieving state-of-the-art performance on NASBench-201 and NPENAS-NP on\nNASBench-101 and DARTS, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 17:56:31 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 16:32:49 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 06:22:06 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Wei", "Chen", ""], ["Niu", "Chuang", ""], ["Tang", "Yiping", ""], ["Wang", "Yue", ""], ["Hu", "Haihong", ""], ["Liang", "Jimin", ""]]}, {"id": "2003.13006", "submitter": "Tobi Delbruck", "authors": "Tobi Delbruck, Shih-Chii Liu", "title": "Data-Driven Neuromorphic DRAM-based CNN and RNN Accelerators", "comments": "To appear in 2019 IEEE Sig. Proc. Soc. Asilomar Conference on\n  Signals, Systems, and Computers Session MP6b: Neuromorphic Computing\n  (Invited)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The energy consumed by running large deep neural networks (DNNs) on hardware\naccelerators is dominated by the need for lots of fast memory to store both\nstates and weights. This large required memory is currently only economically\nviable through DRAM. Although DRAM is high-throughput and low-cost memory\n(costing 20X less than SRAM), its long random access latency is bad for the\nunpredictable access patterns in spiking neural networks (SNNs). In addition,\naccessing data from DRAM costs orders of magnitude more energy than doing\narithmetic with that data. SNNs are energy-efficient if local memory is\navailable and few spikes are generated. This paper reports on our developments\nover the last 5 years of convolutional and recurrent deep neural network\nhardware accelerators that exploit either spatial or temporal sparsity similar\nto SNNs but achieve SOA throughput, power efficiency and latency even with the\nuse of DRAM for the required storage of the weights and states of large DNNs.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 11:45:53 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Delbruck", "Tobi", ""], ["Liu", "Shih-Chii", ""]]}, {"id": "2003.13135", "submitter": "Jonathan Young", "authors": "Jonathan D. Young, Bryan Andrews, Gregory F. Cooper, Xinghua Lu", "title": "Learning Latent Causal Structures with a Redundant Input Neural Network", "comments": "Proceedings of the 2020 KDD Workshop on Causal Discovery, in\n  Proceedings of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.MN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most causal discovery algorithms find causal structure among a set of\nobserved variables. Learning the causal structure among latent variables\nremains an important open problem, particularly when using high-dimensional\ndata. In this paper, we address a problem for which it is known that inputs\ncause outputs, and these causal relationships are encoded by a causal network\namong a set of an unknown number of latent variables. We developed a deep\nlearning model, which we call a redundant input neural network (RINN), with a\nmodified architecture and a regularized objective function to find causal\nrelationships between input, hidden, and output variables. More specifically,\nour model allows input variables to directly interact with all latent variables\nin a neural network to influence what information the latent variables should\nencode in order to generate the output variables accurately. In this setting,\nthe direct connections between input and latent variables makes the latent\nvariables partially interpretable; furthermore, the connectivity among the\nlatent variables in the neural network serves to model their potential causal\nrelationships to each other and to the output variables. A series of simulation\nexperiments provide support that the RINN method can successfully recover\nlatent causal structure between input and output variables.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 20:52:35 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 17:01:50 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2020 16:31:51 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Young", "Jonathan D.", ""], ["Andrews", "Bryan", ""], ["Cooper", "Gregory F.", ""], ["Lu", "Xinghua", ""]]}, {"id": "2003.13254", "submitter": "T{\\o}nnes F. Nygaard", "authors": "T{\\o}nnes F. Nygaard, Charles P. Martin, David Howard, Jim Torresen\n  and Kyrre Glette", "title": "Environmental Adaptation of Robot Morphology and Control through\n  Real-world Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots operating in the real world will experience a range of different\nenvironments and tasks. It is essential for the robot to have the ability to\nadapt to its surroundings to work efficiently in changing conditions.\nEvolutionary robotics aims to solve this by optimizing both the control and\nbody (morphology) of a robot, allowing adaptation to internal, as well as\nexternal factors. Most work in this field has been done in physics simulators,\nwhich are relatively simple and not able to replicate the richness of\ninteractions found in the real world. Solutions that rely on the complex\ninterplay between control, body, and environment are therefore rarely found. In\nthis paper, we rely solely on real-world evaluations and apply evolutionary\nsearch to yield combinations of morphology and control for our mechanically\nself-reconfiguring quadruped robot. We evolve solutions on two distinct\nphysical surfaces and analyze the results in terms of both control and\nmorphology. We then transition to two previously unseen surfaces to demonstrate\nthe generality of our method. We find that the evolutionary search finds\nhigh-performing and diverse morphology-controller configurations by adapting\nboth control and body to the different properties of the physical environments.\nWe additionally find that morphology and control vary with statistical\nsignificance between the environments. Moreover, we observe that our method\nallows for morphology and control parameters to transfer to previously-unseen\nterrains, demonstrating the generality of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 07:57:19 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 11:09:57 GMT"}], "update_date": "2020-10-21", "authors_parsed": [["Nygaard", "T\u00f8nnes F.", ""], ["Martin", "Charles P.", ""], ["Howard", "David", ""], ["Torresen", "Jim", ""], ["Glette", "Kyrre", ""]]}, {"id": "2003.13256", "submitter": "Tobias Glasmachers", "authors": "Tobias Glasmachers, Oswin Krause", "title": "The Hessian Estimation Evolution Strategy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel black box optimization algorithm called Hessian Estimation\nEvolution Strategy. The algorithm updates the covariance matrix of its sampling\ndistribution by directly estimating the curvature of the objective function.\nThis algorithm design is targeted at twice continuously differentiable\nproblems. For this, we extend the cumulative step-size adaptation algorithm of\nthe CMA-ES to mirrored sampling. We demonstrate that our approach to covariance\nmatrix adaptation is efficient by evaluation it on the BBOB/COCO testbed. We\nalso show that the algorithm is surprisingly robust when its core assumption of\na twice continuously differentiable objective function is violated. The\napproach yields a new evolution strategy with competitive performance, and at\nthe same time it also offers an interesting alternative to the usual covariance\nmatrix update mechanism.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 08:01:16 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 07:30:53 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Glasmachers", "Tobias", ""], ["Krause", "Oswin", ""]]}, {"id": "2003.13345", "submitter": "Tomislav Duricic", "authors": "Tomislav Duricic, Hussain Hussain, Emanuel Lacic, Dominik Kowald,\n  Denis Helic, Elisabeth Lex", "title": "Empirical Comparison of Graph Embeddings for Trust-Based Collaborative\n  Filtering", "comments": "10 pages, Accepted as a full paper on the 25th International\n  Symposium on Methodologies for Intelligent Systems (ISMIS'20)", "journal-ref": "Lecture Notes in Computer Science, vol 12117. Springer, Cham. 2020", "doi": "10.1007/978-3-030-59491-6_17", "report-no": null, "categories": "cs.SI cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the utility of graph embeddings to generate latent\nuser representations for trust-based collaborative filtering. In a cold-start\nsetting, on three publicly available datasets, we evaluate approaches from four\nmethod families: (i) factorization-based, (ii) random walk-based, (iii) deep\nlearning-based, and (iv) the Large-scale Information Network Embedding (LINE)\napproach. We find that across the four families, random-walk-based approaches\nconsistently achieve the best accuracy. Besides, they result in highly novel\nand diverse recommendations. Furthermore, our results show that the use of\ngraph embeddings in trust-based collaborative filtering significantly improves\nuser coverage.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 11:22:44 GMT"}, {"version": "v2", "created": "Mon, 1 Feb 2021 15:30:58 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Duricic", "Tomislav", ""], ["Hussain", "Hussain", ""], ["Lacic", "Emanuel", ""], ["Kowald", "Dominik", ""], ["Helic", "Denis", ""], ["Lex", "Elisabeth", ""]]}, {"id": "2003.13365", "submitter": "Alberto Vergani Dr", "authors": "Alberto Arturo Vergani and Christian Robert Huyck", "title": "Critical Limits in a Bump Attractor Network of Spiking Neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE nlin.PS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A bump attractor network is a model that implements a competitive neuronal\nprocess emerging from a spike pattern related to an input source. Since the\nbump network could behave in many ways, this paper explores some critical\nlimits of the parameter space using various positive and negative weights and\nan increasing size of the input spike sources The neuromorphic simulation of\nthe bumpattractor network shows that it exhibits a stationary, a splitting and\na divergent spike pattern, in relation to different sets of weights and input\nwindows. The balance between the values of positive and negative weights is\nimportant in determining the splitting or diverging behaviour of the spike\ntrain pattern and in defining the minimal firing conditions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 11:54:33 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Vergani", "Alberto Arturo", ""], ["Huyck", "Christian Robert", ""]]}, {"id": "2003.13425", "submitter": "Jianjun Hu", "authors": "Yong Zhao, Kunpeng Yuan, Yinqiao Liu, Steph-Yves Louis, Ming Hu, and\n  Jianjun Hu", "title": "Predicting Elastic Properties of Materials from Electronic Charge\n  Density Using 3D Deep Convolutional Neural Networks", "comments": "15 pages; 5 figures", "journal-ref": "The Journal of Physical Chemistry C 2020", "doi": "10.1021/acs.jpcc.0c02348", "report-no": null, "categories": "cond-mat.mtrl-sci cs.CE cs.LG cs.NE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Materials representation plays a key role in machine learning based\nprediction of materials properties and new materials discovery. Currently both\ngraph and 3D voxel representation methods are based on the heterogeneous\nelements of the crystal structures. Here, we propose to use electronic charge\ndensity (ECD) as a generic unified 3D descriptor for materials property\nprediction with the advantage of possessing close relation with the physical\nand chemical properties of materials. We developed an ECD based 3D\nconvolutional neural networks (CNNs) for predicting elastic properties of\nmaterials, in which CNNs can learn effective hierarchical features with\nmultiple convolving and pooling operations. Extensive benchmark experiments\nover 2,170 Fm-3m face-centered-cubic (FCC) materials show that our ECD based\nCNNs can achieve good performance for elasticity prediction. Especially, our\nCNN models based on the fusion of elemental Magpie features and ECD descriptors\nachieved the best 5-fold cross-validation performance. More importantly, we\nshowed that our ECD based CNN models can achieve significantly better\nextrapolation performance when evaluated over non-redundant datasets where\nthere are few neighbor training samples around test samples. As additional\nvalidation, we evaluated the predictive performance of our models on 329\nmaterials of space group Fm-3m by comparing to DFT calculated values, which\nshows better prediction power of our model for bulk modulus than shear modulus.\nDue to the unified representation power of ECD, it is expected that our ECD\nbased CNN approach can also be applied to predict other physical and chemical\nproperties of crystalline materials.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2020 06:21:36 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 23:58:19 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Zhao", "Yong", ""], ["Yuan", "Kunpeng", ""], ["Liu", "Yinqiao", ""], ["Louis", "Steph-Yves", ""], ["Hu", "Ming", ""], ["Hu", "Jianjun", ""]]}, {"id": "2003.13508", "submitter": "Chao Zhang", "authors": "Takumi Nakane, Xuequan Lu, Chao Zhang", "title": "SHX: Search History Driven Crossover for Real-Coded Genetic Algorithm", "comments": "GECCO2020 poster", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In evolutionary algorithms, genetic operators iteratively generate new\noffspring which constitute a potentially valuable set of search history. To\nboost the performance of crossover in real-coded genetic algorithm (RCGA), in\nthis paper we propose to exploit the search history cached so far in an online\nstyle during the iteration. Specifically, survivor individuals over past few\ngenerations are collected and stored in the archive to form the search history.\nWe introduce a simple yet effective crossover model driven by the search\nhistory (abbreviated as SHX). In particular, the search history is clustered\nand each cluster is assigned a score for SHX. In essence, the proposed SHX is a\ndata-driven method which exploits the search history to perform offspring\nselection after the offspring generation. Since no additional fitness\nevaluations are needed, SHX is favorable for the tasks with limited budget or\nexpensive fitness evaluations. We experimentally verify the effectiveness of\nSHX over 4 benchmark functions. Quantitative results show that our SHX can\nsignificantly enhance the performance of RCGA, in terms of accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 14:32:15 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Nakane", "Takumi", ""], ["Lu", "Xuequan", ""], ["Zhang", "Chao", ""]]}, {"id": "2003.13532", "submitter": "Jamal Toutouh", "authors": "Jamal Toutouh, Erik Hemberg, and Una-May O'Reilly", "title": "Re-purposing Heterogeneous Generative Ensembles with Evolutionary\n  Computation", "comments": "Accepted as a full paper for the Genetic and Evolutionary Computation\n  Conference - GECCO'20", "journal-ref": null, "doi": "10.1145/3377930.3390229", "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are popular tools for generative\nmodeling. The dynamics of their adversarial learning give rise to convergence\npathologies during training such as mode and discriminator collapse. In machine\nlearning, ensembles of predictors demonstrate better results than a single\npredictor for many tasks. In this study, we apply two evolutionary algorithms\n(EAs) to create ensembles to re-purpose generative models, i.e., given a set of\nheterogeneous generators that were optimized for one objective (e.g., minimize\nFrechet Inception Distance), create ensembles of them for optimizing a\ndifferent objective (e.g., maximize the diversity of the generated samples).\nThe first method is restricted by the exact size of the ensemble and the second\nmethod only restricts the upper bound of the ensemble size. Experimental\nanalysis on the MNIST image benchmark demonstrates that both EA ensembles\ncreation methods can re-purpose the models, without reducing their original\nfunctionality. The EA-based demonstrate significantly better performance\ncompared to other heuristic-based methods. When comparing both evolutionary,\nthe one with only an upper size bound on the ensemble size is the best.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 15:04:40 GMT"}, {"version": "v2", "created": "Mon, 3 Aug 2020 17:48:34 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Toutouh", "Jamal", ""], ["Hemberg", "Erik", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "2003.13720", "submitter": "Marko Vasic", "authors": "Marko Vasic and Cameron Chalk and Sarfraz Khurshid and David\n  Soloveichik", "title": "Deep Molecular Programming: A Natural Implementation of Binary-Weight\n  ReLU Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding computation in molecular contexts incompatible with traditional\nelectronics is expected to have wide ranging impact in synthetic biology,\nmedicine, nanofabrication and other fields. A key remaining challenge lies in\ndeveloping programming paradigms for molecular computation that are\nwell-aligned with the underlying chemical hardware and do not attempt to\nshoehorn ill-fitting electronics paradigms. We discover a surprisingly tight\nconnection between a popular class of neural networks (binary-weight ReLU aka\nBinaryConnect) and a class of coupled chemical reactions that are absolutely\nrobust to reaction rates. The robustness of rate-independent chemical\ncomputation makes it a promising target for bioengineering implementation. We\nshow how a BinaryConnect neural network trained in silico using well-founded\ndeep learning optimization techniques, can be compiled to an equivalent\nchemical reaction network, providing a novel molecular programming paradigm. We\nillustrate such translation on the paradigmatic IRIS and MNIST datasets. Toward\nintended applications of chemical computation, we further use our method to\ngenerate a chemical reaction network that can discriminate between different\nvirus types based on gene expression levels. Our work sets the stage for rich\nknowledge transfer between neural network and molecular programming\ncommunities.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 18:12:11 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 03:07:17 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 15:38:06 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Vasic", "Marko", ""], ["Chalk", "Cameron", ""], ["Khurshid", "Sarfraz", ""], ["Soloveichik", "David", ""]]}, {"id": "2003.13749", "submitter": "Eric M\\\"uller", "authors": "Eric M\\\"uller, Sebastian Schmitt, Christian Mauch, Sebastian\n  Billaudelle, Andreas Gr\\\"ubl, Maurice G\\\"uttler, Dan Husmann, Joscha\n  Ilmberger, Sebastian Jeltsch, Jakob Kaiser, Johann Kl\\\"ahn, Mitja Kleider,\n  Christoph Koke, Jos\\'e Montes, Paul M\\\"uller, Johannes Partzsch, Felix\n  Passenberg, Hartmut Schmidt, Bernhard Vogginger, Jonas Weidner, Christian\n  Mayr, Johannes Schemmel", "title": "The Operating System of the Neuromorphic BrainScaleS-1 System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BrainScaleS-1 is a wafer-scale mixed-signal accelerated neuromorphic system\ntargeted for research in the fields of computational neuroscience and\nbeyond-von-Neumann computing. The BrainScaleS Operating System (BrainScaleS OS)\nis a software stack giving users the possibility to emulate networks described\nin the high-level network description language PyNN with minimal knowledge of\nthe system. At the same time, expert usage is facilitated by allowing to hook\ninto the system at any depth of the stack. We present operation and development\nmethodologies implemented for the BrainScaleS-1 neuromorphic architecture and\nwalk through the individual components of BrainScaleS OS constituting the\nsoftware stack for BrainScaleS-1 platform operation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 18:58:51 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["M\u00fcller", "Eric", ""], ["Schmitt", "Sebastian", ""], ["Mauch", "Christian", ""], ["Billaudelle", "Sebastian", ""], ["Gr\u00fcbl", "Andreas", ""], ["G\u00fcttler", "Maurice", ""], ["Husmann", "Dan", ""], ["Ilmberger", "Joscha", ""], ["Jeltsch", "Sebastian", ""], ["Kaiser", "Jakob", ""], ["Kl\u00e4hn", "Johann", ""], ["Kleider", "Mitja", ""], ["Koke", "Christoph", ""], ["Montes", "Jos\u00e9", ""], ["M\u00fcller", "Paul", ""], ["Partzsch", "Johannes", ""], ["Passenberg", "Felix", ""], ["Schmidt", "Hartmut", ""], ["Vogginger", "Bernhard", ""], ["Weidner", "Jonas", ""], ["Mayr", "Christian", ""], ["Schemmel", "Johannes", ""]]}, {"id": "2003.13750", "submitter": "Eric M\\\"uller", "authors": "Eric M\\\"uller, Christian Mauch, Philipp Spilger, Oliver Julien\n  Breitwieser, Johann Kl\\\"ahn, David St\\\"ockel, Timo Wunderlich, Johannes\n  Schemmel", "title": "Extending BrainScaleS OS for BrainScaleS-2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BrainScaleS-2 is a mixed-signal accelerated neuromorphic system targeted for\nresearch in the fields of computational neuroscience and beyond-von-Neumann\ncomputing. To augment its flexibility, the analog neural network core is\naccompanied by an embedded SIMD microprocessor. The BrainScaleS Operating\nSystem (BrainScaleS OS) is a software stack designed for the user-friendly\noperation of the BrainScaleS architectures. We present and walk through the\nsoftware-architectural enhancements that were introduced for the BrainScaleS-2\narchitecture. Finally, using a second-version BrainScaleS-2 prototype we\ndemonstrate its application in an example experiment based on spike-based\nexpectation maximization.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 18:58:55 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["M\u00fcller", "Eric", ""], ["Mauch", "Christian", ""], ["Spilger", "Philipp", ""], ["Breitwieser", "Oliver Julien", ""], ["Kl\u00e4hn", "Johann", ""], ["St\u00f6ckel", "David", ""], ["Wunderlich", "Timo", ""], ["Schemmel", "Johannes", ""]]}, {"id": "2003.13826", "submitter": "Carola Doerr", "authors": "Jakob Bossek, Carola Doerr, Pascal Kerschke", "title": "Initial Design Strategies and their Effects on Sequential Model-Based\n  Optimization", "comments": "To appear in Proc. of ACM Genetic and Evolutionary Computation\n  Conference (GECCO'20)", "journal-ref": null, "doi": "10.1145/3377930.3390155", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential model-based optimization (SMBO) approaches are algorithms for\nsolving problems that require computationally or otherwise expensive function\nevaluations. The key design principle of SMBO is a substitution of the true\nobjective function by a surrogate, which is used to propose the point(s) to be\nevaluated next.\n  SMBO algorithms are intrinsically modular, leaving the user with many\nimportant design choices. Significant research efforts go into understanding\nwhich settings perform best for which type of problems. Most works, however,\nfocus on the choice of the model, the acquisition function, and the strategy\nused to optimize the latter. The choice of the initial sampling strategy,\nhowever, receives much less attention. Not surprisingly, quite diverging\nrecommendations can be found in the literature.\n  We analyze in this work how the size and the distribution of the initial\nsample influences the overall quality of the efficient global\noptimization~(EGO) algorithm, a well-known SMBO approach. While, overall, small\ninitial budgets using Halton sampling seem preferable, we also observe that the\nperformance landscape is rather unstructured. We furthermore identify several\nsituations in which EGO performs unfavorably against random sampling. Both\nobservations indicate that an adaptive SMBO design could be beneficial, making\nSMBO an interesting test-bed for automated algorithm design.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 21:25:41 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Bossek", "Jakob", ""], ["Doerr", "Carola", ""], ["Kerschke", "Pascal", ""]]}, {"id": "2003.13850", "submitter": "KongFatt Wong-Lin", "authors": "Ifeatu Ezenwe, Alok Joshi and KongFatt Wong-Lin", "title": "Genetic Algorithmic Parameter Optimisation of a Recurrent Spiking Neural\n  Network Model", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are complex algorithms that loosely model the behaviour of\nthe human brain. They play a significant role in computational neuroscience and\nartificial intelligence. The next generation of neural network models is based\non the spike timing activity of neurons: spiking neural networks (SNNs).\nHowever, model parameters in SNNs are difficult to search and optimise.\nPrevious studies using genetic algorithm (GA) optimisation of SNNs were focused\nmainly on simple, feedforward, or oscillatory networks, but not much work has\nbeen done on optimising cortex-like recurrent SNNs. In this work, we\ninvestigated the use of GAs to search for optimal parameters in recurrent SNNs\nto reach targeted neuronal population firing rates, e.g. as in experimental\nobservations. We considered a cortical column based SNN comprising 1000\nIzhikevich spiking neurons for computational efficiency and biologically\nrealism. The model parameters explored were the neuronal biased input currents.\nFirst, we found for this particular SNN, the optimal parameter values for\ntargeted population averaged firing activities, and the convergence of\nalgorithm by ~100 generations. We then showed that the GA optimal population\nsize was within ~16-20 while the crossover rate that returned the best fitness\nvalue was ~0.95. Overall, we have successfully demonstrated the feasibility of\nimplementing GA to optimise model parameters in a recurrent cortical based SNN.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 22:44:04 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 23:43:06 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Ezenwe", "Ifeatu", ""], ["Joshi", "Alok", ""], ["Wong-Lin", "KongFatt", ""]]}, {"id": "2003.13880", "submitter": "Vishnu Naresh Boddeti", "authors": "Zhichao Lu and Kalyanmoy Deb and Vishnu Naresh Boddeti", "title": "MUXConv: Information Multiplexing in Convolutional Neural Networks", "comments": "CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have witnessed remarkable improvements in\ncomputational efficiency in recent years. A key driving force has been the idea\nof trading-off model expressivity and efficiency through a combination of\n$1\\times 1$ and depth-wise separable convolutions in lieu of a standard\nconvolutional layer. The price of the efficiency, however, is the sub-optimal\nflow of information across space and channels in the network. To overcome this\nlimitation, we present MUXConv, a layer that is designed to increase the flow\nof information by progressively multiplexing channel and spatial information in\nthe network, while mitigating computational complexity. Furthermore, to\ndemonstrate the effectiveness of MUXConv, we integrate it within an efficient\nmulti-objective evolutionary algorithm to search for the optimal model\nhyper-parameters while simultaneously optimizing accuracy, compactness, and\ncomputational efficiency. On ImageNet, the resulting models, dubbed MUXNets,\nmatch the performance (75.3% top-1 accuracy) and multiply-add operations (218M)\nof MobileNetV3 while being 1.6$\\times$ more compact, and outperform other\nmobile models in all the three criteria. MUXNet also performs well under\ntransfer learning and when adapted to object detection. On the ChestX-Ray 14\nbenchmark, its accuracy is comparable to the state-of-the-art while being\n$3.3\\times$ more compact and $14\\times$ more efficient. Similarly, detection on\nPASCAL VOC 2007 is 1.2% more accurate, 28% faster and 6% more compact compared\nto MobileNetV2. Code is available from\nhttps://github.com/human-analysis/MUXConv\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 00:09:47 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 17:27:20 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Lu", "Zhichao", ""], ["Deb", "Kalyanmoy", ""], ["Boddeti", "Vishnu Naresh", ""]]}, {"id": "2003.13904", "submitter": "Fatemeh Ganji", "authors": "Rabin Yu Acharya, Sreeja Chowdhury, Fatemeh Ganji, and Domenic Forte", "title": "Attack of the Genes: Finding Keys and Parameters of Locked Analog ICs\n  Using Genetic Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware intellectual property (IP) theft is a major issue in today's\nglobalized supply chain. To address it, numerous logic locking and obfuscation\ntechniques have been proposed. While locking initially focused on digital\nintegrated circuits (ICs), there have been recent attempts to extend it to\nanalog ICs, which are easier to reverse engineer and to copy than digital ICs.\nIn this paper, we use algorithms based on evolutionary strategies to\ninvestigate the security of analog obfuscation/locking techniques. We present a\ngenetic algorithm (GA) approach which is capable of completely breaking a\nlocked analog circuit by finding either its obfuscation key or its obfuscated\nparameters. We implement both the GA attack as well as a more naive\nsatisfiability modulo theory (SMT)-based attack on common analog benchmark\ncircuits obfuscated by combinational locking and parameter biasing. We find\nthat GA attack can unlock all the circuits using only the locked netlist and an\nunlocked chip in minutes. On the other hand, while the SMT attack converges\nfaster, it requires circuit specification to execute and it also returns\nmultiple keys that need to be brute-forced by a post-processing step. We also\ndiscuss how the GA attack can generalize to other recent analog locking\ntechniques not tested in the paper\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 01:38:00 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Acharya", "Rabin Yu", ""], ["Chowdhury", "Sreeja", ""], ["Ganji", "Fatemeh", ""], ["Forte", "Domenic", ""]]}]