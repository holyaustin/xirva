[{"id": "2107.00223", "submitter": "Kei Uchizawa Dr.", "authors": "Kei Uchizawa and Haruki Abe", "title": "Circuit Complexity of Visual Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study computational hardness of feature and conjunction search through the\nlens of circuit complexity. Let $x = (x_1, ... , x_n)$ (resp., $y = (y_1, ... ,\ny_n)$) be Boolean variables each of which takes the value one if and only if a\nneuron at place $i$ detects a feature (resp., another feature). We then simply\nformulate the feature and conjunction search as Boolean functions ${\\rm\nFTR}_n(x) = \\bigvee_{i=1}^n x_i$ and ${\\rm CONJ}_n(x, y) = \\bigvee_{i=1}^n x_i\n\\wedge y_i$, respectively. We employ a threshold circuit or a discretized\ncircuit (such as a sigmoid circuit or a ReLU circuit with discretization) as\nour models of neural networks, and consider the following four computational\nresources: [i] the number of neurons (size), [ii] the number of levels (depth),\n[iii] the number of active neurons outputting non-zero values (energy), and\n[iv] synaptic weight resolution (weight).\n  We first prove that any threshold circuit $C$ of size $s$, depth $d$, energy\n$e$ and weight $w$ satisfies $\\log rk(M_C) \\le ed (\\log s + \\log w + \\log n)$,\nwhere $rk(M_C)$ is the rank of the communication matrix $M_C$ of a\n$2n$-variable Boolean function that $C$ computes. Since ${\\rm CONJ}_n$ has rank\n$2^n$, we have $n \\le ed (\\log s + \\log w + \\log n)$. Thus, an exponential\nlower bound on the size of even sublinear-depth threshold circuits exists if\nthe energy and weight are sufficiently small. Since ${\\rm FTR}_n$ is computable\nindependently of $n$, our result suggests that computational capacity for the\nfeature and conjunction search are different. We also show that the inequality\nis tight up to a constant factor if $ed = o(n/ \\log n)$. We next show that a\nsimilar inequality holds for any discretized circuit. Thus, if we regard the\nnumber of gates outputting non-zero values as a measure for sparse activity,\nour results suggest that larger depth helps neural networks to acquire sparse\nactivity.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 05:37:53 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Uchizawa", "Kei", ""], ["Abe", "Haruki", ""]]}, {"id": "2107.00385", "submitter": "Viera Maslej-Kre\\v{s}\\v{n}\\'akov\\'a", "authors": "Viera Maslej-Kre\\v{s}\\v{n}\\'akov\\'a, Khadija El Bouchefry, Peter Butka", "title": "Morphological classification of compact and extended radio galaxies\n  using convolutional neural networks and data augmentation techniques", "comments": "12 pages, 7 figures, 9 tables, published in Monthly Notices of the\n  Royal Astronomical Society", "journal-ref": "Mon Not Roy Astron Soc 505 (2021) 1464-1475", "doi": "10.1093/mnras/stab1400", "report-no": null, "categories": "astro-ph.GA astro-ph.IM cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Machine learning techniques have been increasingly used in astronomical\napplications and have proven to successfully classify objects in image data\nwith high accuracy. The current work uses archival data from the Faint Images\nof the Radio Sky at Twenty Centimeters (FIRST) to classify radio galaxies into\nfour classes: Fanaroff-Riley Class I (FRI), Fanaroff-Riley Class II (FRII),\nBent-Tailed (BENT), and Compact (COMPT). The model presented in this work is\nbased on Convolutional Neural Networks (CNNs). The proposed architecture\ncomprises three parallel blocks of convolutional layers combined and processed\nfor final classification by two feed-forward layers. Our model classified\nselected classes of radio galaxy sources on an independent testing subset with\nan average of 96\\% for precision, recall, and F1 score. The best selected\naugmentation techniques were rotations, horizontal or vertical flips, and\nincrease of brightness. Shifts, zoom and decrease of brightness worsened the\nperformance of the model. The current results show that model developed in this\nwork is able to identify different morphological classes of radio galaxies with\na high efficiency and performance\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 11:53:18 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Maslej-Kre\u0161\u0148\u00e1kov\u00e1", "Viera", ""], ["Bouchefry", "Khadija El", ""], ["Butka", "Peter", ""]]}, {"id": "2107.00397", "submitter": "Leon Victor", "authors": "L\\'eon Victor (LIRIS, INSA Lyon), Alexandre Meyer (LIRIS, UCBL),\n  Sa\\\"ida Bouakaz (LIRIS, UCBL)", "title": "Learning-based pose edition for efficient and interactive design", "comments": null, "journal-ref": "Computer Animation and Virtual Worlds, Wiley, 2021", "doi": "10.1002/cav.2013", "report-no": null, "categories": "cs.GR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authoring an appealing animation for a virtual character is a challenging\ntask. In computer-aided keyframe animation artists define the key poses of a\ncharacter by manipulating its underlying skeletons. To look plausible, a\ncharacter pose must respect many ill-defined constraints, and so the resulting\nrealism greatly depends on the animator's skill and knowledge. Animation\nsoftware provide tools to help in this matter, relying on various algorithms to\nautomatically enforce some of these constraints. The increasing availability of\nmotion capture data has raised interest in data-driven approaches to pose\ndesign, with the potential of shifting more of the task of assessing realism\nfrom the artist to the computer, and to provide easier access to nonexperts. In\nthis article, we propose such a method, relying on neural networks to\nautomatically learn the constraints from the data. We describe an efficient\ntool for pose design, allowing na{\\\"i}ve users to intuitively manipulate a pose\nto create character animations.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 12:15:02 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Victor", "L\u00e9on", "", "LIRIS, INSA Lyon"], ["Meyer", "Alexandre", "", "LIRIS, UCBL"], ["Bouakaz", "Sa\u00efda", "", "LIRIS, UCBL"]]}, {"id": "2107.00401", "submitter": "Alberto Marchisio", "authors": "Alberto Viale and Alberto Marchisio and Maurizio Martina and Guido\n  Masera and Muhammad Shafique", "title": "CarSNN: An Efficient Spiking Neural Network for Event-Based Autonomous\n  Cars on the Loihi Neuromorphic Research Processor", "comments": "Accepted for publication at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous Driving (AD) related features provide new forms of mobility that\nare also beneficial for other kind of intelligent and autonomous systems like\nrobots, smart transportation, and smart industries. For these applications, the\ndecisions need to be made fast and in real-time. Moreover, in the quest for\nelectric mobility, this task must follow low power policy, without affecting\nmuch the autonomy of the mean of transport or the robot. These two challenges\ncan be tackled using the emerging Spiking Neural Networks (SNNs). When deployed\non a specialized neuromorphic hardware, SNNs can achieve high performance with\nlow latency and low power consumption. In this paper, we use an SNN connected\nto an event-based camera for facing one of the key problems for AD, i.e., the\nclassification between cars and other objects. To consume less power than\ntraditional frame-based cameras, we use a Dynamic Vision Sensor (DVS). The\nexperiments are made following an offline supervised learning rule, followed by\nmapping the learnt SNN model on the Intel Loihi Neuromorphic Research Chip. Our\nbest experiment achieves an accuracy on offline implementation of 86%, that\ndrops to 83% when it is ported onto the Loihi Chip. The Neuromorphic Hardware\nimplementation has maximum 0.72 ms of latency for every sample, and consumes\nonly 310 mW. To the best of our knowledge, this work is the first\nimplementation of an event-based car classifier on a Neuromorphic Chip.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 12:20:48 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Viale", "Alberto", ""], ["Marchisio", "Alberto", ""], ["Martina", "Maurizio", ""], ["Masera", "Guido", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2107.01280", "submitter": "Humberto De las Casas", "authors": "Humberto De las Casas and Santino Bianco and Hanz Richter", "title": "Targeted Muscle Effort Distribution with Exercise Robots: Trajectory and\n  Resistance Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The objective of this work is to relate muscle effort distributions to the\ntrajectory and resistance settings of a robotic exercise and rehabilitation\nmachine. Muscular effort distribution, representing the participation of each\nmuscle in the training activity, was measured with electromyography sensors\n(EMG) and defined as the individual activation divided by the total muscle\ngroup activation. A four degrees-of-freedom robot and its impedance control\nsystem are used to create advanced exercise protocols whereby the user is asked\nto follow a path against the machine's neutral path and resistance. In this\nwork, the robot establishes a zero-effort circular path, and the subject is\nasked to follow an elliptical trajectory. The control system produces a\nuser-defined stiffness between the deviations from the neutral path and the\ntorque applied by the subject. The trajectory and resistance settings used in\nthe experiments were the orientation of the ellipse and a stiffness parameter.\nMultiple combinations of these parameters were used to measure their effects on\nthe muscle effort distribution. An artificial neural network (ANN) used part of\nthe data for training the model. Then, the accuracy of the model was evaluated\nusing the rest of the data. The results show how the precision of the model is\nlost over time. These outcomes show the complexity of the muscle dynamics for\nlong-term estimations suggesting the existence of time-varying dynamics\npossibly associated with fatigue.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 21:07:35 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Casas", "Humberto De las", ""], ["Bianco", "Santino", ""], ["Richter", "Hanz", ""]]}, {"id": "2107.01318", "submitter": "Daniel Mario Lima", "authors": "Marcelo Toledo, Daniel Lima, Jos\\'e Krieger, Marco Gutierrez", "title": "A study of CNN capacity applied to Left Venticle Segmentation in Cardiac\n  MRI", "comments": "Submitted to IJBRA", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  CNN (Convolutional Neural Network) models have been successfully used for\nsegmentation of the left ventricle (LV) in cardiac MRI (Magnetic Resonance\nImaging), providing clinical measurements.In practice, two questions arise with\ndeployment of CNNs: 1) when is it better to use a shallow model instead of a\ndeeper one? 2) how the size of a dataset might change the network performance?\nWe propose a framework to answer them, by experimenting with deep and shallow\nversions of three U-Net families, trained from scratch in six subsets varying\nfrom 100 to 10,000 images, different network sizes, learning rates and\nregularization values. 1620 models were evaluated using 5-foldcross-validation\nby loss and DICE. The results indicate that: sample size affects performance\nmore than architecture or hyper-parameters; in small samples the performance is\nmore sensitive to hyper-parameters than architecture; the performance\ndifference between shallow and deeper networks is not the same across families.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 00:56:21 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Toledo", "Marcelo", ""], ["Lima", "Daniel", ""], ["Krieger", "Jos\u00e9", ""], ["Gutierrez", "Marco", ""]]}, {"id": "2107.01400", "submitter": "Yaniv Shulman", "authors": "Yaniv Shulman", "title": "Exact Backpropagation in Binary Weighted Networks with Group Weight\n  Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantization based model compression serves as high performing and fast\napproach for inference that yields models which are highly compressed when\ncompared to their full-precision floating point counterparts. The most extreme\nquantization is a 1-bit representation of parameters such that they have only\ntwo possible values, typically -1(0) or +1, enabling efficient implementation\nof the ubiquitous dot product using only additions. The main contribution of\nthis work is the introduction of a method to smooth the combinatorial problem\nof determining a binary vector of weights to minimize the expected loss for a\ngiven objective by means of empirical risk minimization with backpropagation.\nThis is achieved by approximating a multivariate binary state over the weights\nutilizing a deterministic and differentiable transformation of real-valued,\ncontinuous parameters. The proposed method adds little overhead in training,\ncan be readily applied without any substantial modifications to the original\narchitecture, does not introduce additional saturating nonlinearities or\nauxiliary losses, and does not prohibit applying other methods for binarizing\nthe activations. Contrary to common assertions made in the literature, it is\ndemonstrated that binary weighted networks can train well with the same\nstandard optimization techniques and similar hyperparameter settings as their\nfull-precision counterparts, specifically momentum SGD with large learning\nrates and $L_2$ regularization. To conclude experiments demonstrate the method\nperforms remarkably well across a number of inductive image classification\ntasks with various architectures compared to their full-precision counterparts.\nThe source code is publicly available at\nhttps://bitbucket.org/YanivShu/binary_weighted_networks_public.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 10:29:34 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 03:22:29 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Shulman", "Yaniv", ""]]}, {"id": "2107.01410", "submitter": "Amirhossein Nouranizadeh", "authors": "Amirhossein Nouranizadeh, Mohammadjavad Matinkia, Mohammad Rahmati,\n  Reza Safabakhsh", "title": "Maximum Entropy Weighted Independent Set Pooling for Graph Neural\n  Networks", "comments": "21 pages, 12 figures, under review in 35th Conference on Neural\n  Information Processing Systems (NeurIPS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel pooling layer for graph neural networks\nbased on maximizing the mutual information between the pooled graph and the\ninput graph. Since the maximum mutual information is difficult to compute, we\nemploy the Shannon capacity of a graph as an inductive bias to our pooling\nmethod. More precisely, we show that the input graph to the pooling layer can\nbe viewed as a representation of a noisy communication channel. For such a\nchannel, sending the symbols belonging to an independent set of the graph\nyields a reliable and error-free transmission of information. We show that\nreaching the maximum mutual information is equivalent to finding a maximum\nweight independent set of the graph where the weights convey entropy contents.\nThrough this communication theoretic standpoint, we provide a distinct\nperspective for posing the problem of graph pooling as maximizing the\ninformation transmission rate across a noisy communication channel, implemented\nby a graph neural network. We evaluate our method, referred to as Maximum\nEntropy Weighted Independent Set Pooling (MEWISPool), on graph classification\ntasks and the combinatorial optimization problem of the maximum independent\nset. Empirical results demonstrate that our method achieves the\nstate-of-the-art and competitive results on graph classification tasks and the\nmaximum independent set problem in several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 11:19:28 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Nouranizadeh", "Amirhossein", ""], ["Matinkia", "Mohammadjavad", ""], ["Rahmati", "Mohammad", ""], ["Safabakhsh", "Reza", ""]]}, {"id": "2107.01702", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek", "title": "Data-Driven Learning of Feedforward Neural Networks with Different\n  Activation Functions", "comments": "20th International Conference on Artificial Intelligence and Soft\n  Computing ICAISC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work contributes to the development of a new data-driven method (D-DM)\nof feedforward neural networks (FNNs) learning. This method was proposed\nrecently as a way of improving randomized learning of FNNs by adjusting the\nnetwork parameters to the target function fluctuations. The method employs\nlogistic sigmoid activation functions for hidden nodes. In this study, we\nintroduce other activation functions, such as bipolar sigmoid, sine function,\nsaturating linear functions, reLU, and softplus. We derive formulas for their\nparameters, i.e. weights and biases. In the simulation study, we evaluate the\nperformance of FNN data-driven learning with different activation functions.\nThe results indicate that the sigmoid activation functions perform much better\nthan others in the approximation of complex, fluctuated target functions.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 18:20:27 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 07:33:13 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "2107.01705", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek", "title": "Randomized Neural Networks for Forecasting Time Series with Multiple\n  Seasonality", "comments": "International Work Conference on Artificial Neural Networks IWANN\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work contributes to the development of neural forecasting models with\nnovel randomization-based learning methods. These methods improve the fitting\nabilities of the neural model, in comparison to the standard method, by\ngenerating network parameters in accordance with the data and target function\nfeatures. A pattern-based representation of time series makes the proposed\napproach useful for forecasting time series with multiple seasonality. In the\nsimulation study, we evaluate the performance of the proposed models and find\nthat they can compete in terms of forecasting accuracy with fully-trained\nnetworks. Extremely fast and easy training, simple architecture, ease of\nimplementation, high accuracy as well as dealing with nonstationarity and\nmultiple seasonality in time series make the proposed model very attractive for\na wide range of complex time series forecasting problems.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 18:39:27 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "2107.01711", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek", "title": "Autoencoder based Randomized Learning of Feedforward Neural Networks for\n  Regression", "comments": "International Joint Conference on Neural Networks IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Feedforward neural networks are widely used as universal predictive models to\nfit data distribution. Common gradient-based learning, however, suffers from\nmany drawbacks making the training process ineffective and time-consuming.\nAlternative randomized learning does not use gradients but selects hidden node\nparameters randomly. This makes the training process extremely fast. However,\nthe problem in randomized learning is how to determine the random parameters. A\nrecently proposed method uses autoencoders for unsupervised parameter learning.\nThis method showed superior performance on classification tasks. In this work,\nwe apply this method to regression problems, and, finding that it has some\ndrawbacks, we show how to improve it. We propose a learning method of\nautoencoders that controls the produced random weights. We also propose how to\ndetermine the biases of hidden nodes. We empirically compare autoencoder based\nlearning with other randomized learning methods proposed recently for\nregression and find that despite the proposed improvement of the autoencoder\nbased learning, it does not outperform its competitors in fitting accuracy.\nMoreover, the method is much more complex than its competitors.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 19:07:39 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "2107.01729", "submitter": "Thomas Miconi", "authors": "Thomas Miconi", "title": "Multi-layer Hebbian networks with modern deep learning frameworks", "comments": "All code available at\n  https://github.com/ThomasMiconi/HebbianCNNPyTorch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning networks generally use non-biological learning methods. By\ncontrast, networks based on more biologically plausible learning, such as\nHebbian learning, show comparatively poor performance and difficulties of\nimplementation. Here we show that hierarchical, convolutional Hebbian learning\ncan be implemented almost trivially with modern deep learning frameworks, by\nusing specific losses whose gradients produce exactly the desired Hebbian\nupdates. We provide expressions whose gradients exactly implement a plain\nHebbian rule (dw ~= xy), Grossberg's instar rule (dw ~= y(x-w)), and Oja's rule\n(dw ~= y(x-yw)). As an application, we build Hebbian convolutional multi-layer\nnetworks for object recognition. We observe that higher layers of such networks\ntend to learn large, simple features (Gabor-like filters and blobs), explaining\nthe previously reported decrease in decoding performance over successive\nlayers. To combat this tendency, we introduce interventions (denser activations\nwith sparse plasticity, pruning of connections between layers) which result in\nsparser learned features, massively increase performance, and allow information\nto increase over successive layers. We hypothesize that more advanced\ntechniques (dynamic stimuli, trace learning, feedback connections, etc.),\ntogether with the massive computational boost offered by modern deep learning\nframeworks, could greatly improve the performance and biological relevance of\nmulti-layer Hebbian networks.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 20:50:49 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Miconi", "Thomas", ""]]}, {"id": "2107.01807", "submitter": "Rachmad Vidya Wicaksana Putra", "authors": "Rachmad Vidya Wicaksana Putra, Muhammad Shafique", "title": "Q-SpiNN: A Framework for Quantizing Spiking Neural Networks", "comments": "Accepted for publication at the 2021 International Joint Conference\n  on Neural Networks (IJCNN), July 2021, Virtual Event", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A prominent technique for reducing the memory footprint of Spiking Neural\nNetworks (SNNs) without decreasing the accuracy significantly is quantization.\nHowever, the state-of-the-art only focus on employing the weight quantization\ndirectly from a specific quantization scheme, i.e., either the post-training\nquantization (PTQ) or the in-training quantization (ITQ), and do not consider\n(1) quantizing other SNN parameters (e.g., neuron membrane potential), (2)\nexploring different combinations of quantization approaches (i.e., quantization\nschemes, precision levels, and rounding schemes), and (3) selecting the SNN\nmodel with a good memory-accuracy trade-off at the end. Therefore, the memory\nsaving offered by these state-of-the-art to meet the targeted accuracy is\nlimited, thereby hindering processing SNNs on the resource-constrained systems\n(e.g., the IoT-Edge devices). Towards this, we propose Q-SpiNN, a novel\nquantization framework for memory-efficient SNNs. The key mechanisms of the\nQ-SpiNN are: (1) employing quantization for different SNN parameters based on\ntheir significance to the accuracy, (2) exploring different combinations of\nquantization schemes, precision levels, and rounding schemes to find efficient\nSNN model candidates, and (3) developing an algorithm that quantifies the\nbenefit of the memory-accuracy trade-off obtained by the candidates, and\nselects the Pareto-optimal one. The experimental results show that, for the\nunsupervised network, the Q-SpiNN reduces the memory footprint by ca. 4x, while\nmaintaining the accuracy within 1% from the baseline on the MNIST dataset. For\nthe supervised network, the Q-SpiNN reduces the memory by ca. 2x, while keeping\nthe accuracy within 2% from the baseline on the DVS-Gesture dataset.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 06:01:15 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Putra", "Rachmad Vidya Wicaksana", ""], ["Shafique", "Muhammad", ""]]}, {"id": "2107.02080", "submitter": "Teresa Ludermir", "authors": "Danielle Silva and Teresa Ludermir", "title": "Uso de GSO cooperativos com decaimentos de pesos para otimizacao de\n  redes neurais", "comments": "9 pages, in Portuguese, 2 Figures, 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training of Artificial Neural Networks is a complex task of great importance\nin supervised learning problems. Evolutionary Algorithms are widely used as\nglobal optimization techniques and these approaches have been used for\nArtificial Neural Networks to perform various tasks. An optimization algorithm,\ncalled Group Search Optimizer (GSO), was proposed and inspired by the search\nbehaviour of animals. In this article we present two new hybrid approaches:\nCGSO-Hk-WD and CGSO-Sk-WD. Cooperative GSOs are based on the divide-and-conquer\nparadigm, employing cooperative behaviour between GSO groups to improve the\nperformance of the standard GSO. We also apply the weight decay strategy (WD,\nacronym for Weight Decay) to increase the generalizability of the networks. The\nresults show that cooperative GSOs are able to achieve better performance than\ntraditional GSO for classification problems in benchmark datasets such as\nCancer, Diabetes, Ecoli and Glass datasets.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 15:19:13 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Silva", "Danielle", ""], ["Ludermir", "Teresa", ""]]}, {"id": "2107.02202", "submitter": "Raz Saremi", "authors": "Razieh Saremi, Hardik Yagnik, Julian Togelius, Ye Yang, and Guenther\n  Ruhe", "title": "An Evolutionary Algorithm for Task Scheduling in Crowdsourced Software\n  Development", "comments": "16 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of software tasks and the uncertainty of crowd developer\nbehaviors make it challenging to plan crowdsourced software development (CSD)\nprojects. In a competitive crowdsourcing marketplace, competition for shared\nworker resources from multiple simultaneously open tasks adds another layer of\nuncertainty to the potential outcomes of software crowdsourcing. These factors\nlead to the need for supporting CSD managers with automated scheduling to\nimprove the visibility and predictability of crowdsourcing processes and\noutcomes. To that end, this paper proposes an evolutionary algorithm-based task\nscheduling method for crowdsourced software development. The proposed\nevolutionary scheduling method uses a multiobjective genetic algorithm to\nrecommend an optimal task start date. The method uses three fitness functions,\nbased on project duration, task similarity, and task failure prediction,\nrespectively. The task failure fitness function uses a neural network to\npredict the probability of task failure with respect to a specific task start\ndate. The proposed method then recommends the best tasks start dates for the\nproject as a whole and each individual task so as to achieve the lowest project\nfailure ratio. Experimental results on 4 projects demonstrate that the proposed\nmethod has the potential to reduce project duration by a factor of 33-78%.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 18:07:26 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Saremi", "Razieh", ""], ["Yagnik", "Hardik", ""], ["Togelius", "Julian", ""], ["Yang", "Ye", ""], ["Ruhe", "Guenther", ""]]}, {"id": "2107.02238", "submitter": "Xuan Hu", "authors": "Pranav O. Mathews and Christian B. Duffee and Abel Thayil and Ty E.\n  Stovall and Christopher H. Bennett and Felipe Garcia-Sanchez and Matthew J.\n  Marinella and Jean Anne C. Incorvia and Naimul Hassan and Xuan Hu and Joseph\n  S. Friedman", "title": "High-Speed CMOS-Free Purely Spintronic Asynchronous Recurrent Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neuromorphic computing systems overcome the limitations of traditional von\nNeumann computing architectures. These computing systems can be further\nimproved upon by using emerging technologies that are more efficient than CMOS\nfor neural computation. Recent research has demonstrated memristors and\nspintronic devices in various neural network designs boost efficiency and\nspeed. This paper presents a biologically inspired fully spintronic neuron used\nin a fully spintronic Hopfield RNN. The network is used to solve tasks, and the\nresults are compared against those of current Hopfield neuromorphic\narchitectures which use emerging technologies.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 19:23:33 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Mathews", "Pranav O.", ""], ["Duffee", "Christian B.", ""], ["Thayil", "Abel", ""], ["Stovall", "Ty E.", ""], ["Bennett", "Christopher H.", ""], ["Garcia-Sanchez", "Felipe", ""], ["Marinella", "Matthew J.", ""], ["Incorvia", "Jean Anne C.", ""], ["Hassan", "Naimul", ""], ["Hu", "Xuan", ""], ["Friedman", "Joseph S.", ""]]}, {"id": "2107.02248", "submitter": "Roberto Cahuantzi", "authors": "Roberto Cahuantzi, Xinye Chen, Stefan G\\\"uttel", "title": "A comparison of LSTM and GRU networks for learning symbolic sequences", "comments": "12 pages, 8 figures, submitted to the International Conference on\n  Neural Information Processing 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore relations between the hyper-parameters of a recurrent neural\nnetwork (RNN) and the complexity of string sequences it is able to memorize. We\ncompare long short-term memory (LSTM) networks and gated recurrent units\n(GRUs). We find that an increase of RNN depth does not necessarily result in\nbetter memorization capability when the training time is constrained. Our\nresults also indicate that the learning rate and the number of units per layer\nare among the most important hyper-parameters to be tuned. Generally, GRUs\noutperform LSTM networks on low complexity sequences while on high complexity\nsequences LSTMs perform better.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 19:49:14 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Cahuantzi", "Roberto", ""], ["Chen", "Xinye", ""], ["G\u00fcttel", "Stefan", ""]]}, {"id": "2107.02744", "submitter": "Ayushe Gangal", "authors": "Ayushe Gangal, Peeyush Kumar, Sunita Kumari and Aditya Kumar", "title": "Neural Computing", "comments": "Book chapter, 25 pages, 16 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This chapter aims to provide next-level understanding of the problems of the\nworld and the solutions available to those problems, which lie very well within\nthe domain of neural computing, and at the same time are intelligent in their\napproach, to invoke a sense of innovation among the educationalists,\nresearchers, academic professionals, students and people concerned, by\nhighlighting the work done by major researchers and innovators in this field\nand thus, encouraging the readers to develop newer and more advanced techniques\nfor the same. By means of this chapter, the societal problems are discussed and\nvarious solutions are also given by means of the theories presented and\nresearches done so far. Different types of neural networks discovered so far\nand applications of some of those neural networks are focused on, apart from\ntheir theoretical understanding, the working and core concepts involved in the\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 17:21:03 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Gangal", "Ayushe", ""], ["Kumar", "Peeyush", ""], ["Kumari", "Sunita", ""], ["Kumar", "Aditya", ""]]}, {"id": "2107.02840", "submitter": "Ren Wang", "authors": "Ren Wang, Tianqi Chen, Stephen Lindsly, Cooper Stansbury, Alnawaz\n  Rehemtulla, Indika Rajapakse, Alfred Hero", "title": "RAILS: A Robust Adversarial Immune-inspired Learning System", "comments": "arXiv admin note: text overlap with arXiv:2012.10485", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial attacks against deep neural networks (DNNs) are continuously\nevolving, requiring increasingly powerful defense strategies. We develop a\nnovel adversarial defense framework inspired by the adaptive immune system: the\nRobust Adversarial Immune-inspired Learning System (RAILS). Initializing a\npopulation of exemplars that is balanced across classes, RAILS starts from a\nuniform label distribution that encourages diversity and debiases a potentially\ncorrupted initial condition. RAILS implements an evolutionary optimization\nprocess to adjust the label distribution and achieve specificity towards ground\ntruth. RAILS displays a tradeoff between robustness (diversity) and accuracy\n(specificity), providing a new immune-inspired perspective on adversarial\nlearning. We empirically validate the benefits of RAILS through several\nadversarial image classification experiments on MNIST, SVHN, and CIFAR-10\ndatasets. For the PGD attack, RAILS is found to improve the robustness over\nexisting methods by >= 5.62%, 12.5% and 10.32%, respectively, without\nappreciable loss of standard accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 17:57:45 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wang", "Ren", ""], ["Chen", "Tianqi", ""], ["Lindsly", "Stephen", ""], ["Stansbury", "Cooper", ""], ["Rehemtulla", "Alnawaz", ""], ["Rajapakse", "Indika", ""], ["Hero", "Alfred", ""]]}, {"id": "2107.02842", "submitter": "Ren Wang", "authors": "Ren Wang, Tianqi Chen, Stephen Lindsly, Cooper Stansbury, Indika\n  Rajapakse, Alfred Hero", "title": "Immuno-mimetic Deep Neural Networks (Immuno-Net)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomimetics has played a key role in the evolution of artificial neural\nnetworks. Thus far, in silico metaphors have been dominated by concepts from\nneuroscience and cognitive psychology. In this paper we introduce a different\ntype of biomimetic model, one that borrows concepts from the immune system, for\ndesigning robust deep neural networks. This immuno-mimetic model leads to a new\ncomputational biology framework for robustification of deep neural networks\nagainst adversarial attacks. Within this Immuno-Net framework we define a\nrobust adaptive immune-inspired learning system (Immuno-Net RAILS) that\nemulates, in silico, the adaptive biological mechanisms of B-cells that are\nused to defend a mammalian host against pathogenic attacks. When applied to\nimage classification tasks on benchmark datasets, we demonstrate that\nImmuno-net RAILS results in improvement of as much as 12.5% in adversarial\naccuracy of a baseline method, the DkNN-robustified CNN, without appreciable\nloss of accuracy on clean data.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 16:45:23 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wang", "Ren", ""], ["Chen", "Tianqi", ""], ["Lindsly", "Stephen", ""], ["Stansbury", "Cooper", ""], ["Rajapakse", "Indika", ""], ["Hero", "Alfred", ""]]}, {"id": "2107.02976", "submitter": "Jon McCormack", "authors": "Jon McCormack and Camilo Cruz Gambardella", "title": "Growing and Evolving 3D Prints", "comments": "Preprint of paper submitted to IEEE Transactions on Evolutionary\n  Computing", "journal-ref": "IEEE Transactions on Evolutionary Computation, 2021", "doi": "10.1109/TEVC.2021.3095156", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Design - especially of physical objects - can be understood as creative acts\nsolving practical problems. In this paper we describe a biologically-inspired\ndevelopmental model as the basis of a generative form-finding system. Using\nlocal interactions between cells in a two-dimensional environment, then\ncapturing the state of the system at every time step, complex three-dimensional\n(3D) forms can be generated by the system. Unlike previous systems, our method\nis capable of directly producing 3D printable objects, eliminating intermediate\ntransformations and manual manipulation often necessary to ensure the 3D form\nis printable. We devise fitness measures for optimising 3D printability and\naesthetic complexity and use a Covariance Matrix Adaptation Evolutionary\nStrategies algorithm (CMA-ES) to find 3D forms that are both aesthetically\ninteresting and physically printable using fused deposition modelling printing\ntechniques. We investigate the system's capabilities by evolving and 3D\nprinting objects at different levels of structural consistency, and assess the\nquality of the fitness measures presented to explore the design space of our\ngenerative system. We find that by evolving first for aesthetic complexity,\nthen evolving for structural consistency until the form is 'just printable',\ngives the best results.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 01:51:29 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["McCormack", "Jon", ""], ["Gambardella", "Camilo Cruz", ""]]}, {"id": "2107.03146", "submitter": "Alexander Hvatov", "authors": "Alexander Hvatov, Mikhail Maslyaev, Iana S. Polonskaya, Mikhail\n  Sarafanov, Mark Merezhnikov, Nikolay O. Nikitin", "title": "Model-agnostic multi-objective approach for the evolutionary discovery\n  of mathematical models", "comments": "OL2A conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern data science, it is often not enough to obtain only a data-driven\nmodel with a good prediction quality. On the contrary, it is more interesting\nto understand the properties of the model, which parts could be replaced to\nobtain better results. Such questions are unified under machine learning\ninterpretability questions, which could be considered one of the area's raising\ntopics. In the paper, we use multi-objective evolutionary optimization for\ncomposite data-driven model learning to obtain the algorithm's desired\nproperties. It means that whereas one of the apparent objectives is precision,\nthe other could be chosen as the complexity of the model, robustness, and many\nothers. The method application is shown on examples of multi-objective learning\nof composite models, differential equations, and closed-form algebraic\nexpressions are unified and form approach for model-agnostic learning of the\ninterpretable models.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 11:17:09 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 08:16:48 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Hvatov", "Alexander", ""], ["Maslyaev", "Mikhail", ""], ["Polonskaya", "Iana S.", ""], ["Sarafanov", "Mikhail", ""], ["Merezhnikov", "Mark", ""], ["Nikitin", "Nikolay O.", ""]]}, {"id": "2107.03992", "submitter": "Arjun Rao", "authors": "Philipp Plank, Arjun Rao, Andreas Wild, Wolfgang Maass", "title": "A Long Short-Term Memory for AI Applications in Spike-based Neuromorphic\n  Hardware", "comments": "Philipp Plank and Arjun Rao have contributed equally to this work as\n  first authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of intensive efforts it has remained an open problem to what extent\ncurrent Artificial Intelligence (AI) methods that employ Deep Neural Networks\n(DNNs) can be implemented more energy-efficiently on spike-based neuromorphic\nhardware. This holds in particular for AI methods that solve sequence\nprocessing tasks, a primary application target for spike-based neuromorphic\nhardware. One difficulty is that DNNs for such tasks typically employ Long\nShort-Term Memory (LSTM) units. Yet an efficient emulation of these units in\nspike-based hardware has been missing. We present a biologically inspired\nsolution that solves this problem. This solution enables us to implement a\nmajor class of DNNs for sequence processing tasks such as time series\nclassification and question answering with substantial energy savings on\nneuromorphic hardware. In fact, the Relational Network for reasoning about\nrelations between objects that we use for question answering is the first\nexample of a large DNN that carries out a sequence processing task with\nsubstantial energy-saving on neuromorphic hardware.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 17:37:02 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Plank", "Philipp", ""], ["Rao", "Arjun", ""], ["Wild", "Andreas", ""], ["Maass", "Wolfgang", ""]]}, {"id": "2107.04092", "submitter": "Dennis Bautembach", "authors": "Dennis Bautembach, Iason Oikonomidis, Antonis Argyros", "title": "Even Faster SNN Simulation with Lazy+Event-driven Plasticity and Shared\n  Atomics", "comments": "Submitted to IEEE-HPEC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two novel optimizations that accelerate clock-based spiking neural\nnetwork (SNN) simulators. The first one targets spike timing dependent\nplasticity (STDP). It combines lazy- with event-driven plasticity and\nefficiently facilitates the computation of pre- and post-synaptic spikes using\nbitfields and integer intrinsics. It offers higher bandwidth than event-driven\nplasticity alone and achieves a 1.5x-2x speedup over our closest competitor.\nThe second optimization targets spike delivery. We partition our graph\nrepresentation in a way that bounds the number of neurons that need be updated\nat any given time which allows us to perform said update in shared memory\ninstead of global memory. This is 2x-2.5x faster than our closest competitor.\nBoth optimizations represent the final evolutionary stages of years of\niteration on STDP and spike delivery inside \"Spice\" (/spaIk/), our state of the\nart SNN simulator. The proposed optimizations are not exclusive to our graph\nrepresentation or pipeline but are applicable to a multitude of simulator\ndesigns. We evaluate our performance on three well-established models and\ncompare ourselves against three other state of the art simulators.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 20:13:54 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Bautembach", "Dennis", ""], ["Oikonomidis", "Iason", ""], ["Argyros", "Antonis", ""]]}, {"id": "2107.04702", "submitter": "Teresa Ludermir", "authors": "Anderson P. da Silva, Teresa B. Ludermir, Leandro M. Almeida", "title": "Um Metodo para Busca Automatica de Redes Neurais Artificiais", "comments": "13 pages, in Portuguese, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a method that automatically searches Artificial Neural\nNetworks using Cellular Genetic Algorithms. The main difference of this method\nfor a common genetic algorithm is the use of a cellular automaton capable of\nproviding the location for individuals, reducing the possibility of local\nminima in search space. This method employs an evolutionary search for\nsimultaneous choices of initial weights, transfer functions, architectures and\nlearning rules. Experimental results have shown that the developed method can\nfind compact, efficient networks with a satisfactory generalization power and\nwith shorter training times when compared to other methods found in the\nliterature.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 22:25:08 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["da Silva", "Anderson P.", ""], ["Ludermir", "Teresa B.", ""], ["Almeida", "Leandro M.", ""]]}, {"id": "2107.04964", "submitter": "Tae Jong Choi", "authors": "Tae Jong Choi and Julian Togelius", "title": "Self-Referential Quality Diversity Through Differential Map-Elites", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential MAP-Elites is a novel algorithm that combines the illumination\ncapacity of CVT-MAP-Elites with the continuous-space optimization capacity of\nDifferential Evolution. The algorithm is motivated by observations that\nillumination algorithms, and quality-diversity algorithms in general, offer\nqualitatively new capabilities and applications for evolutionary computation\nyet are in their original versions relatively unsophisticated optimizers. The\nbasic Differential MAP-Elites algorithm, introduced for the first time here, is\nrelatively simple in that it simply combines the operators from Differential\nEvolution with the map structure of CVT-MAP-Elites. Experiments based on 25\nnumerical optimization problems suggest that Differential MAP-Elites clearly\noutperforms CVT-MAP-Elites, finding better-quality and more diverse solutions.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 04:31:10 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Choi", "Tae Jong", ""], ["Togelius", "Julian", ""]]}, {"id": "2107.05124", "submitter": "Gabriel De Souza Pereira Moreira", "authors": "Gabriel de Souza P. Moreira and Sara Rabhi and Ronay Ak and Md Yasin\n  Kabir and Even Oldridge", "title": "Transformers with multi-modal features and post-fusion context for\n  e-commerce session-based recommendation", "comments": "In Proceedings of SIGIR eCom'21 - SIGIR eCommerce Workshop Data\n  Challenge 2021. https://sigir-ecom.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Session-based recommendation is an important task for e-commerce services,\nwhere a large number of users browse anonymously or may have very distinct\ninterests for different sessions. In this paper we present one of the winning\nsolutions for the Recommendation task of the SIGIR 2021 Workshop on E-commerce\nData Challenge. Our solution was inspired by NLP techniques and consists of an\nensemble of two Transformer architectures - Transformer-XL and XLNet - trained\nwith autoregressive and autoencoding approaches. To leverage most of the rich\ndataset made available for the competition, we describe how we prepared\nmulti-model features by combining tabular events with textual and image\nvectors. We also present a model prediction analysis to better understand the\neffectiveness of our architectures for the session-based recommendation.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 20:02:59 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Moreira", "Gabriel de Souza P.", ""], ["Rabhi", "Sara", ""], ["Ak", "Ronay", ""], ["Kabir", "Md Yasin", ""], ["Oldridge", "Even", ""]]}, {"id": "2107.05709", "submitter": "Guillermo Barrios Morales", "authors": "Guillermo B. Morales and Miguel A. Mu\\~noz", "title": "Optimal input representation in neural systems at the edge of chaos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Shedding light onto how biological systems represent, process and store\ninformation in noisy environments is a key and challenging goal. A stimulating,\nthough controversial, hypothesis poses that operating in dynamical regimes near\nthe edge of a phase transition, i.e. at criticality or the \"edge of chaos\", can\nprovide information-processing living systems with important operational\nadvantages, creating, e.g., an optimal trade-off between robustness and\nflexibility. Here, we elaborate on a recent theoretical result, which\nestablishes that the spectrum of covariance matrices of neural networks\nrepresenting complex inputs in a robust way needs to decay as a power-law of\nthe rank, with an exponent close to unity, a result that has been indeed\nexperimentally verified in neurons of the mouse visual cortex. Aimed at\nunderstanding and mimicking these results, we construct an artificial neural\nnetwork and train it to classify images. Remarkably, we find that the best\nperformance in such a task is obtained when the network operates near the\ncritical point, at which the eigenspectrum of the covariance matrix follows the\nvery same statistics as actual neurons do. Thus, we conclude that operating\nnear criticality can also have -- besides the usually alleged virtues -- the\nadvantage of allowing for flexible, robust and efficient input representations.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 19:55:03 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Morales", "Guillermo B.", ""], ["Mu\u00f1oz", "Miguel A.", ""]]}, {"id": "2107.05747", "submitter": "Timoleon Moraitis", "authors": "Timoleon Moraitis, Dmitry Toichkin, Yansong Chua, Qinghai Guo", "title": "SoftHebb: Bayesian inference in unsupervised Hebbian soft\n  winner-take-all networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art artificial neural networks (ANNs) require labelled data or\nfeedback between layers, are often biologically implausible, and are vulnerable\nto adversarial attacks that humans are not susceptible to. On the other hand,\nHebbian learning in winner-take-all (WTA) networks, is unsupervised,\nfeed-forward, and biologically plausible. However, an objective optimization\ntheory for WTA networks has been missing, except under very limiting\nassumptions. Here we derive formally such a theory, based on biologically\nplausible but generic ANN elements. Through Hebbian learning, network\nparameters maintain a Bayesian generative model of the data. There is no\nsupervisory loss function, but the network does minimize cross-entropy between\nits activations and the input distribution. The key is a \"soft\" WTA where there\nis no absolute \"hard\" winner neuron, and a specific type of Hebbian-like\nplasticity of weights and biases. We confirm our theory in practice, where, in\nhandwritten digit (MNIST) recognition, our Hebbian algorithm, SoftHebb,\nminimizes cross-entropy without having access to it, and outperforms the more\nfrequently used, hard-WTA-based method. Strikingly, it even outperforms\nsupervised end-to-end backpropagation, under certain conditions. Specifically,\nin a two-layered network, SoftHebb outperforms backpropagation when the\ntraining dataset is only presented once, when the testing data is noisy, and\nunder gradient-based adversarial attacks. Adversarial attacks that confuse\nSoftHebb are also confusing to the human eye. Finally, the model can generate\ninterpolations of objects from its input distribution.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 21:34:45 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Moraitis", "Timoleon", ""], ["Toichkin", "Dmitry", ""], ["Chua", "Yansong", ""], ["Guo", "Qinghai", ""]]}, {"id": "2107.05777", "submitter": "Bryce Primavera", "authors": "Bryce A. Primavera and Jeffrey M. Shainline", "title": "An active dendritic tree can mitigate fan-in limitations in\n  superconducting neurons", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Superconducting electronic circuits have much to offer with regard to\nneuromorphic hardware. Superconducting quantum interference devices (SQUIDs)\ncan serve as an active element to perform the thresholding operation of a\nneuron's soma. However, a SQUID has a response function that is periodic in the\napplied signal. We show theoretically that if one restricts the total input to\na SQUID to maintain a monotonically increasing response, a large fraction of\nsynapses must be active to drive a neuron to threshold. We then demonstrate\nthat an active dendritic tree (also based on SQUIDs) can significantly reduce\nthe fraction of synapses that must be active to drive the neuron to threshold.\nIn this context, the inclusion of a dendritic tree provides the dual benefits\nof enhancing the computational abilities of each neuron and allowing the neuron\nto spike with sparse input activity.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 23:33:39 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Primavera", "Bryce A.", ""], ["Shainline", "Jeffrey M.", ""]]}, {"id": "2107.05989", "submitter": "Marwan Dhuheir", "authors": "Marwan Dhuheir, Abdullatif Albaseer, Emna Baccour, Aiman Erbad,\n  Mohamed Abdallah, and Mounir Hamdi", "title": "Emotion Recognition for Healthcare Surveillance Systems Using Neural\n  Networks: A Survey", "comments": "conference paper accepted and presented at 17th Int. Wireless\n  Communications & Mobile Computing Conference - IWCMC 2021, Harbin, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing the patient's emotions using deep learning techniques has\nattracted significant attention recently due to technological advancements.\nAutomatically identifying the emotions can help build smart healthcare centers\nthat can detect depression and stress among the patients in order to start the\nmedication early. Using advanced technology to identify emotions is one of the\nmost exciting topics as it defines the relationships between humans and\nmachines. Machines learned how to predict emotions by adopting various methods.\nIn this survey, we present recent research in the field of using neural\nnetworks to recognize emotions. We focus on studying emotions' recognition from\nspeech, facial expressions, and audio-visual input and show the different\ntechniques of deploying these algorithms in the real world. These three emotion\nrecognition techniques can be used as a surveillance system in healthcare\ncenters to monitor patients. We conclude the survey with a presentation of the\nchallenges and the related future work to provide an insight into the\napplications of using emotion recognition.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 11:17:00 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Dhuheir", "Marwan", ""], ["Albaseer", "Abdullatif", ""], ["Baccour", "Emna", ""], ["Erbad", "Aiman", ""], ["Abdallah", "Mohamed", ""], ["Hamdi", "Mounir", ""]]}, {"id": "2107.06131", "submitter": "Michaela Beneder", "authors": "Gabriel Kronberger, Lukas Kammerer, Michael Kommenda", "title": "Identification of Dynamical Systems using Symbolic Regression", "comments": "The final authenticated publication is available online at\n  https://doi.org/10.1007/978-3-030-45093-9", "journal-ref": "In Computer Aided Systems Theory - EUROCAST 2019, Series Volume\n  12013, pp. 370-377. Springer. (2020)", "doi": "10.1007/978-3-030-45093-9", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for the identification of models for dynamical systems\nfrom observational data. The method is based on the concept of symbolic\nregression and uses genetic programming to evolve a system of ordinary\ndifferential equations (ODE). The novelty is that we add a step of\ngradient-based optimization of the ODE parameters. For this we calculate the\nsensitivities of the solution to the initial value problem (IVP) using\nautomatic differentiation. The proposed approach is tested on a set of 19\nproblem instances taken from the literature which includes datasets from\nsimulated systems as well as datasets captured from mechanical systems. We find\nthat gradient-based optimization of parameters improves predictive accuracy of\nthe models. The best results are obtained when we first fit the individual\nequations to the numeric differences and then subsequently fine-tune the\nidentified parameter values by fitting the IVP solution to the observed\nvariable values.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 11:41:10 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Kronberger", "Gabriel", ""], ["Kammerer", "Lukas", ""], ["Kommenda", "Michael", ""]]}, {"id": "2107.06446", "submitter": "Dmitry Krotov", "authors": "Dmitry Krotov", "title": "Hierarchical Associative Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense Associative Memories or Modern Hopfield Networks have many appealing\nproperties of associative memory. They can do pattern completion, store a large\nnumber of memories, and can be described using a recurrent neural network with\na degree of biological plausibility and rich feedback between the neurons. At\nthe same time, up until now all the models of this class have had only one\nhidden layer, and have only been formulated with densely connected network\narchitectures, two aspects that hinder their machine learning applications.\nThis paper tackles this gap and describes a fully recurrent model of\nassociative memory with an arbitrary large number of layers, some of which can\nbe locally connected (convolutional), and a corresponding energy function that\ndecreases on the dynamical trajectory of the neurons' activations. The memories\nof the full network are dynamically \"assembled\" using primitives encoded in the\nsynaptic weights of the lower layers, with the \"assembling rules\" encoded in\nthe synaptic weights of the higher layers. In addition to the bottom-up\npropagation of information, typical of commonly used feedforward neural\nnetworks, the model described has rich top-down feedback from higher layers\nthat help the lower-layer neurons to decide on their response to the input\nstimuli.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 01:38:40 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Krotov", "Dmitry", ""]]}, {"id": "2107.06475", "submitter": "Patryk Orzechowski", "authors": "Patryk Orzechowski and Jason H. Moore", "title": "Generative and reproducible benchmarks for comprehensive evaluation of\n  machine learning classifiers", "comments": "12 pages, 3 figures with subfigures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the strengths and weaknesses of machine learning (ML)\nalgorithms is crucial for determine their scope of application. Here, we\nintroduce the DIverse and GENerative ML Benchmark (DIGEN) - a collection of\nsynthetic datasets for comprehensive, reproducible, and interpretable\nbenchmarking of machine learning algorithms for classification of binary\noutcomes. The DIGEN resource consists of 40 mathematical functions which map\ncontinuous features to discrete endpoints for creating synthetic datasets.\nThese 40 functions were discovered using a heuristic algorithm designed to\nmaximize the diversity of performance among multiple popular machine learning\nalgorithms thus providing a useful test suite for evaluating and comparing new\nmethods. Access to the generative functions facilitates understanding of why a\nmethod performs poorly compared to other algorithms thus providing ideas for\nimprovement. The resource with extensive documentation and analyses is\nopen-source and available on GitHub.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 03:58:02 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Orzechowski", "Patryk", ""], ["Moore", "Jason H.", ""]]}, {"id": "2107.06608", "submitter": "Nadav Cohen", "authors": "Omer Elkabetz and Nadav Cohen", "title": "Continuous vs. Discrete Optimization of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing analyses of optimization in deep learning are either continuous,\nfocusing on (variants of) gradient flow, or discrete, directly treating\n(variants of) gradient descent. Gradient flow is amenable to theoretical\nanalysis, but is stylized and disregards computational efficiency. The extent\nto which it represents gradient descent is an open question in deep learning\ntheory. The current paper studies this question. Viewing gradient descent as an\napproximate numerical solution to the initial value problem of gradient flow,\nwe find that the degree of approximation depends on the curvature along the\nlatter's trajectory. We then show that over deep neural networks with\nhomogeneous activations, gradient flow trajectories enjoy favorable curvature,\nsuggesting they are well approximated by gradient descent. This finding allows\nus to translate an analysis of gradient flow over deep linear neural networks\ninto a guarantee that gradient descent efficiently converges to global minimum\nalmost surely under random initialization. Experiments suggest that over simple\ndeep neural networks, gradient descent with conventional step size is indeed\nclose to the continuous limit. We hypothesize that the theory of gradient flows\nwill be central to unraveling mysteries behind deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 10:59:57 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Elkabetz", "Omer", ""], ["Cohen", "Nadav", ""]]}, {"id": "2107.06676", "submitter": "Steven W. D. Chien", "authors": "Martin Svedin, Artur Podobas, Steven W. D. Chien, Stefano Markidis", "title": "Higgs Boson Classification: Brain-inspired BCPNN Learning with\n  StreamBrain", "comments": "Submitted to The 2nd Workshop on Artificial Intelligence and Machine\n  Learning for Scientific Applications (AI4S 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most promising approaches for data analysis and exploration of\nlarge data sets is Machine Learning techniques that are inspired by brain\nmodels. Such methods use alternative learning rules potentially more\nefficiently than established learning rules. In this work, we focus on the\npotential of brain-inspired ML for exploiting High-Performance Computing (HPC)\nresources to solve ML problems: we discuss the BCPNN and an HPC implementation,\ncalled StreamBrain, its computational cost, suitability to HPC systems. As an\nexample, we use StreamBrain to analyze the Higgs Boson dataset from High Energy\nPhysics and discriminate between background and signal classes in collisions of\nhigh-energy particle colliders. Overall, we reach up to 69.15% accuracy and\n76.4% Area Under the Curve (AUC) performance.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 13:08:19 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Svedin", "Martin", ""], ["Podobas", "Artur", ""], ["Chien", "Steven W. D.", ""], ["Markidis", "Stefano", ""]]}, {"id": "2107.06686", "submitter": "Djordje Grbic", "authors": "Djordje Grbic and Sebastian Risi", "title": "Safer Reinforcement Learning through Transferable Instinct Networks", "comments": "The paper was accepted in the ALIFE 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Random exploration is one of the main mechanisms through which reinforcement\nlearning (RL) finds well-performing policies. However, it can lead to\nundesirable or catastrophic outcomes when learning online in safety-critical\nenvironments. In fact, safe learning is one of the major obstacles towards\nreal-world agents that can learn during deployment. One way of ensuring that\nagents respect hard limitations is to explicitly configure boundaries in which\nthey can operate. While this might work in some cases, we do not always have\nclear a-priori information which states and actions can lead dangerously close\nto hazardous states. Here, we present an approach where an additional policy\ncan override the main policy and offer a safer alternative action. In our\ninstinct-regulated RL (IR^2L) approach, an \"instinctual\" network is trained to\nrecognize undesirable situations, while guarding the learning policy against\nentering them. The instinct network is pre-trained on a single task where it is\nsafe to make mistakes, and transferred to environments in which learning a new\ntask safely is critical. We demonstrate IR^2L in the OpenAI Safety gym domain,\nin which it receives a significantly lower number of safety violations during\ntraining than a baseline RL approach while reaching similar task performance.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 13:22:04 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Grbic", "Djordje", ""], ["Risi", "Sebastian", ""]]}, {"id": "2107.06721", "submitter": "Mat\\v{e}j Hejda", "authors": "Mat\\v{e}j Hejda, Juan Arturo Alanis, Ignacio Ortega-Piwonka, Jo\\~ao\n  Louren\\c{c}o, Jos\\'e Figueiredo, Julien Javaloyes, Bruno Romeira and Antonio\n  Hurtado", "title": "Resonant tunnelling diode nano-optoelectronic spiking nodes for\n  neuromorphic information processing", "comments": "Changed manuscript title to lower-case", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.app-ph cs.ET cs.NE physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce an optoelectronic spiking artificial neuron\ncapable of operating at ultrafast rates ($\\approx$ 100 ps/optical spike) and\nwith low energy consumption ($<$ pJ/spike). The proposed system combines an\nexcitable resonant tunnelling diode (RTD) element exhibiting negative\ndifferential conductance, coupled to a nanoscale light source (forming a master\nnode) or a photodetector (forming a receiver node). We study numerically the\nspiking dynamical responses and information propagation functionality of an\ninterconnected master-receiver RTD node system. Using the key functionality of\npulse thresholding and integration, we utilize a single node to classify\nsequential pulse patterns and perform convolutional functionality for image\nfeature (edge) recognition. We also demonstrate an optically-interconnected\nspiking neural network model for processing of spatiotemporal data at over 10\nGbps with high inference accuracy. Finally, we demonstrate an off-chip\nsupervised learning approach utilizing spike-timing dependent plasticity for\nthe RTD-enabled photonic spiking neural network. These results demonstrate the\npotential and viability of RTD spiking nodes for low footprint, low energy,\nhigh-speed optoelectronic realization of neuromorphic hardware.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 14:11:04 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 08:29:59 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Hejda", "Mat\u011bj", ""], ["Alanis", "Juan Arturo", ""], ["Ortega-Piwonka", "Ignacio", ""], ["Louren\u00e7o", "Jo\u00e3o", ""], ["Figueiredo", "Jos\u00e9", ""], ["Javaloyes", "Julien", ""], ["Romeira", "Bruno", ""], ["Hurtado", "Antonio", ""]]}, {"id": "2107.06861", "submitter": "Yukun Yang", "authors": "Yukun Yang, Wenrui Zhang, Peng Li", "title": "Backpropagated Neighborhood Aggregation for Accurate Training of Spiking\n  Neural Networks", "comments": null, "journal-ref": "Proceedings of the 38 th International Conference on Machine\n  Learning, PMLR 139, 2021", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  While backpropagation (BP) has been applied to spiking neural networks (SNNs)\nachieving encouraging results, a key challenge involved is to backpropagate a\ncontinuous-valued loss over layers of spiking neurons exhibiting discontinuous\nall-or-none firing activities. Existing methods deal with this difficulty by\nintroducing compromises that come with their own limitations, leading to\npotential performance degradation. We propose a novel BP-like method, called\nneighborhood aggregation (NA), which computes accurate error gradients guiding\nweight updates that may lead to discontinuous modifications of firing\nactivities. NA achieves this goal by aggregating finite differences of the loss\nover multiple perturbed membrane potential waveforms in the neighborhood of the\npresent membrane potential of each neuron while utilizing a new membrane\npotential distance function. Our experiments show that the proposed NA\nalgorithm delivers the state-of-the-art performance for SNN training on several\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 16:42:48 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Yang", "Yukun", ""], ["Zhang", "Wenrui", ""], ["Li", "Peng", ""]]}, {"id": "2107.06862", "submitter": "Eyvind Niklasson", "authors": "Alexander Mordvintsev, Ettore Randazzo, Eyvind Niklasson", "title": "Differentiable Programming of Reaction-Diffusion Patterns", "comments": "ALIFE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reaction-Diffusion (RD) systems provide a computational framework that\ngoverns many pattern formation processes in nature. Current RD system design\npractices boil down to trial-and-error parameter search. We propose a\ndifferentiable optimization method for learning the RD system parameters to\nperform example-based texture synthesis on a 2D plane. We do this by\nrepresenting the RD system as a variant of Neural Cellular Automata and using\ntask-specific differentiable loss functions. RD systems generated by our method\nexhibit robust, non-trivial 'life-like' behavior.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jun 2021 17:38:34 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Mordvintsev", "Alexander", ""], ["Randazzo", "Ettore", ""], ["Niklasson", "Eyvind", ""]]}, {"id": "2107.06865", "submitter": "Xu Mingkun", "authors": "Mingkun Xu, Yujie Wu, Lei Deng, Faqiang Liu, Guoqi Li, Jing Pei", "title": "Exploiting Spiking Dynamics with Spatial-temporal Feature Normalization\n  in Graph Learning", "comments": "Accepted by IJCAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological spiking neurons with intrinsic dynamics underlie the powerful\nrepresentation and learning capabilities of the brain for processing multimodal\ninformation in complex environments. Despite recent tremendous progress in\nspiking neural networks (SNNs) for handling Euclidean-space tasks, it still\nremains challenging to exploit SNNs in processing non-Euclidean-space data\nrepresented by graph data, mainly due to the lack of effective modeling\nframework and useful training techniques. Here we present a general spike-based\nmodeling framework that enables the direct training of SNNs for graph learning.\nThrough spatial-temporal unfolding for spiking data flows of node features, we\nincorporate graph convolution filters into spiking dynamics and formalize a\nsynergistic learning paradigm. Considering the unique features of spike\nrepresentation and spiking dynamics, we propose a spatial-temporal feature\nnormalization (STFN) technique suitable for SNN to accelerate convergence. We\ninstantiate our methods into two spiking graph models, including graph\nconvolution SNNs and graph attention SNNs, and validate their performance on\nthree node-classification benchmarks, including Cora, Citeseer, and Pubmed. Our\nmodel can achieve comparable performance with the state-of-the-art graph neural\nnetwork (GNN) models with much lower computation costs, demonstrating great\nbenefits for the execution on neuromorphic hardware and prompting neuromorphic\napplications in graphical scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 11:20:16 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Xu", "Mingkun", ""], ["Wu", "Yujie", ""], ["Deng", "Lei", ""], ["Liu", "Faqiang", ""], ["Li", "Guoqi", ""], ["Pei", "Jing", ""]]}, {"id": "2107.06869", "submitter": "Kyeongbo Kong", "authors": "Jae-hun Shim, Kyeongbo Kong, and Suk-Ju Kang", "title": "Core-set Sampling for Efficient Neural Architecture Search", "comments": "8 pages, 2 figures, spotlight presented at the ICML 2021 Workshop on\n  Subset Selection in ML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS), an important branch of automatic machine\nlearning, has become an effective approach to automate the design of deep\nlearning models. However, the major issue in NAS is how to reduce the large\nsearch time imposed by the heavy computational burden. While most recent\napproaches focus on pruning redundant sets or developing new search\nmethodologies, this paper attempts to formulate the problem based on the data\ncuration manner. Our key strategy is to search the architecture using\nsummarized data distribution, i.e., core-set. Typically, many NAS algorithms\nseparate searching and training stages, and the proposed core-set methodology\nis only used in search stage, thus their performance degradation can be\nminimized. In our experiments, we were able to save overall computational time\nfrom 30.8 hours to 3.5 hours, 8.8x reduction, on a single RTX 3090 GPU without\nsacrificing accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 06:19:18 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Shim", "Jae-hun", ""], ["Kong", "Kyeongbo", ""], ["Kang", "Suk-Ju", ""]]}, {"id": "2107.06870", "submitter": "Jiongzhi Zheng", "authors": "Jiongzhi Zheng and Menglei Chen and Jialun Zhong and Kun He", "title": "Reinforced Hybrid Genetic Algorithm for the Traveling Salesman Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a powerful Reinforced Hybrid Genetic Algorithm (RHGA) for the\nfamous NP-hard Traveling Salesman Problem (TSP). RHGA combines reinforcement\nlearning technique with the well-known Edge Assembly Crossover genetic\nalgorithm (EAX-GA) and the Lin-Kernighan-Helsgaun (LKH) local search heuristic.\nWith the help of the proposed hybrid mechanism, the genetic evolution of EAX-GA\nand the local search of LKH can boost each other's performance. And the\nreinforcement learning technique based on Q-learning further promotes the\nhybrid genetic algorithm. Experimental results on 138 well-known and widely\nused TSP benchmarks, with the number of cities ranging from 1,000 to 85,900,\ndemonstrate the excellent performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jul 2021 07:36:12 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Zheng", "Jiongzhi", ""], ["Chen", "Menglei", ""], ["Zhong", "Jialun", ""], ["He", "Kun", ""]]}, {"id": "2107.06872", "submitter": "Jeff Mitchell", "authors": "Jeff Mitchell and Jeffrey S. Bowers", "title": "Generalisation in Neural Networks Does not Require Feature Overlap", "comments": "19 pages, 3 Figures. Submitted to Cognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  That shared features between train and test data are required for\ngeneralisation in artificial neural networks has been a common assumption of\nboth proponents and critics of these models. Here, we show that convolutional\narchitectures avoid this limitation by applying them to two well known\nchallenges, based on learning the identity function and learning rules\ngoverning sequences of words. In each case, successful performance on the test\nset requires generalising to features that were not present in the training\ndata, which is typically not feasible for standard connectionist models.\nHowever, our experiments demonstrate that neural networks can succeed on such\nproblems when they incorporate the weight sharing employed by convolutional\narchitectures. In the image processing domain, such architectures are intended\nto reflect the symmetry under spatial translations of the natural world that\nsuch images depict. We discuss the role of symmetry in the two tasks and its\nconnection to generalisation.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 09:23:49 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Mitchell", "Jeff", ""], ["Bowers", "Jeffrey S.", ""]]}, {"id": "2107.06996", "submitter": "Xiaorui Liu", "authors": "Xiaorui Liu, Wei Jin, Yao Ma, Yaxin Li, Hua Liu, Yiqi Wang, Ming Yan,\n  Jiliang Tang", "title": "Elastic Graph Neural Networks", "comments": "ICML 2021 (International Conference on Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many existing graph neural networks (GNNs) have been proven to perform\n$\\ell_2$-based graph smoothing that enforces smoothness globally, in this work\nwe aim to further enhance the local smoothness adaptivity of GNNs via\n$\\ell_1$-based graph smoothing. As a result, we introduce a family of GNNs\n(Elastic GNNs) based on $\\ell_1$ and $\\ell_2$-based graph smoothing. In\nparticular, we propose a novel and general message passing scheme into GNNs.\nThis message passing algorithm is not only friendly to back-propagation\ntraining but also achieves the desired smoothing properties with a theoretical\nconvergence guarantee. Experiments on semi-supervised learning tasks\ndemonstrate that the proposed Elastic GNNs obtain better adaptivity on\nbenchmark datasets and are significantly robust to graph adversarial attacks.\nThe implementation of Elastic GNNs is available at\n\\url{https://github.com/lxiaorui/ElasticGNN}.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 01:36:01 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Liu", "Xiaorui", ""], ["Jin", "Wei", ""], ["Ma", "Yao", ""], ["Li", "Yaxin", ""], ["Liu", "Hua", ""], ["Wang", "Yiqi", ""], ["Yan", "Ming", ""], ["Tang", "Jiliang", ""]]}, {"id": "2107.07062", "submitter": "Ji-Seon Bang", "authors": "Ji-Seon Bang and Seong-Whan Lee", "title": "Motor Imagery Classification based on CNN-GRU Network with\n  Spatio-Temporal Feature Representation", "comments": "Submitted to IAPR 6th Asian Conference on Pattern Recognition (ACPR\n  2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, various deep neural networks have been applied to classify\nelectroencephalogram (EEG) signal. EEG is a brain signal that can be acquired\nin a non-invasive way and has a high temporal resolution. It can be used to\ndecode the intention of users. As the EEG signal has a high dimension of\nfeature space, appropriate feature extraction methods are needed to improve\nclassification performance. In this study, we obtained spatio-temporal feature\nrepresentation and classified them with the combined convolutional neural\nnetworks (CNN)-gated recurrent unit (GRU) model. To this end, we obtained\ncovariance matrices in each different temporal band and then concatenated them\non the temporal axis to obtain a final spatio-temporal feature representation.\nIn the classification model, CNN is responsible for spatial feature extraction\nand GRU is responsible for temporal feature extraction. Classification\nperformance was improved by distinguishing spatial data processing and temporal\ndata processing. The average accuracy of the proposed model was 77.70% for the\nBCI competition IV_2a data set. The proposed method outperformed all other\nmethods compared as a baseline method.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 01:05:38 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Bang", "Ji-Seon", ""], ["Lee", "Seong-Whan", ""]]}, {"id": "2107.07116", "submitter": "Feng Shi", "authors": "Feng Shi, Chonghan Lee, Mohammad Khairul Bashar, Nikhil Shukla,\n  Song-Chun Zhu and Vijaykrishnan Narayanan", "title": "Transformer-based Machine Learning for Fast SAT Solvers and Logic\n  Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CNF-based SAT and MaxSAT solvers are central to logic synthesis and\nverification systems. The increasing popularity of these constraint problems in\nelectronic design automation encourages studies on different SAT problems and\ntheir properties for further computational efficiency. There has been both\ntheoretical and practical success of modern Conflict-driven clause learning SAT\nsolvers, which allows solving very large industrial instances in a relatively\nshort amount of time. Recently, machine learning approaches provide a new\ndimension to solving this challenging problem. Neural symbolic models could\nserve as generic solvers that can be specialized for specific domains based on\ndata without any changes to the structure of the model. In this work, we\npropose a one-shot model derived from the Transformer architecture to solve the\nMaxSAT problem, which is the optimization version of SAT where the goal is to\nsatisfy the maximum number of clauses. Our model has a scale-free structure\nwhich could process varying size of instances. We use meta-path and\nself-attention mechanism to capture interactions among homogeneous nodes. We\nadopt cross-attention mechanisms on the bipartite graph to capture interactions\namong heterogeneous nodes. We further apply an iterative algorithm to our model\nto satisfy additional clauses, enabling a solution approaching that of an\nexact-SAT problem. The attention mechanisms leverage the parallelism for\nspeedup. Our evaluation indicates improved speedup compared to heuristic\napproaches and improved completion rate compared to machine learning\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 04:47:35 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Shi", "Feng", ""], ["Lee", "Chonghan", ""], ["Bashar", "Mohammad Khairul", ""], ["Shukla", "Nikhil", ""], ["Zhu", "Song-Chun", ""], ["Narayanan", "Vijaykrishnan", ""]]}, {"id": "2107.07121", "submitter": "Claudia Gomez-Santillan PhD", "authors": "Gilberto Rivera, Carlos A. Coello Coello, Laura Cruz-Reyes, Eduardo R.\n  Fernandez, Claudia Gomez-Santillan, and Nelson Rangel-Valdez", "title": "Preference Incorporation into Many-Objective Optimization: An\n  Outranking-based Ant Colony Algorithm", "comments": "23 pages, 2 figures, 4 tables. submitted to Swarm and Evolutionary\n  Computation Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we enriched Ant Colony Optimization (ACO) with interval\noutranking to develop a novel multiobjective ACO optimizer to approach problems\nwith many objective functions. This proposal is suitable if the preferences of\nthe Decision Maker (DM) can be modeled through outranking relations. The\nintroduced algorithm (named Interval Outranking-based ACO, IO-ACO) is the first\nant-colony optimizer that embeds an outranking model to bear vagueness and\nill-definition of DM preferences. This capacity is the most differentiating\nfeature of IO-ACO because this issue is highly relevant in practice. IO-ACO\nbiases the search towards the Region of Interest (RoI), the privileged zone of\nthe Pareto frontier containing the solutions that better match the DM\npreferences. Two widely studied benchmarks were utilized to measure the\nefficiency of IO-ACO, i.e., the DTLZ and WFG test suites. Accordingly, IO-ACO\nwas compared with two competitive many-objective optimizers: The\nIndicator-based Many-Objective ACO and the Multiobjective Evolutionary\nAlgorithm Based on Decomposition. The numerical results show that IO-ACO\napproximates the Region of Interest (RoI) better than the leading\nmetaheuristics based on approximating the Pareto frontier alone.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 05:01:21 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Rivera", "Gilberto", ""], ["Coello", "Carlos A. Coello", ""], ["Cruz-Reyes", "Laura", ""], ["Fernandez", "Eduardo R.", ""], ["Gomez-Santillan", "Claudia", ""], ["Rangel-Valdez", "Nelson", ""]]}, {"id": "2107.07266", "submitter": "Nilotpal Sinha", "authors": "Nilotpal Sinha, Kuan-Wen Chen", "title": "Neural Architecture Search using Covariance Matrix Adaptation Evolution\n  Strategy", "comments": "Under review (Submitted to IEEE Transactions on Evolutionary\n  Computation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Evolution-based neural architecture search requires high computational\nresources, resulting in long search time. In this work, we propose a framework\nof applying the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) to the\nneural architecture search problem called CMANAS, which achieves better results\nthan previous evolution-based methods while reducing the search time\nsignificantly. The architectures are modelled using a normal distribution,\nwhich is updated using CMA-ES based on the fitness of the sampled population.\nWe used the accuracy of a trained one shot model (OSM) on the validation data\nas a prediction of the fitness of an individual architecture to reduce the\nsearch time. We also used an architecture-fitness table (AF table) for keeping\nrecord of the already evaluated architecture, thus further reducing the search\ntime. CMANAS finished the architecture search on CIFAR-10 with the top-1 test\naccuracy of 97.44% in 0.45 GPU day and on CIFAR-100 with the top-1 test\naccuracy of 83.24% for 0.6 GPU day on a single GPU. The top architectures from\nthe searches on CIFAR-10 and CIFAR-100 were then transferred to ImageNet,\nachieving the top-5 accuracy of 92.6% and 92.1%, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 11:41:23 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Sinha", "Nilotpal", ""], ["Chen", "Kuan-Wen", ""]]}, {"id": "2107.07341", "submitter": "Rutwik Shah", "authors": "Rutwik Shah, Bruno Astuto, Tyler Gleason, Will Fletcher, Justin\n  Banaga, Kevin Sweetwood, Allen Ye, Rina Patel, Kevin McGill, Thomas Link,\n  Jason Crane, Valentina Pedoia, Sharmila Majumdar", "title": "Leveraging wisdom of the crowds to improve consensus among radiologists\n  by real time, blinded collaborations on a digital swarm platform", "comments": "24 pages, 2 tables, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.DC cs.LG cs.NE cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Radiologists today play a key role in making diagnostic decisions and\nlabeling images for training A.I. algorithms. Low inter-reader reliability\n(IRR) can be seen between experts when interpreting challenging cases. While\nteams-based decisions are known to outperform individual decisions,\ninter-personal biases often creep up in group interactions which limit\nnon-dominant participants from expressing true opinions. To overcome the dual\nproblems of low consensus and inter-personal bias, we explored a solution\nmodeled on biological swarms of bees. Two separate cohorts; three radiologists\nand five radiology residents collaborated on a digital swarm platform in real\ntime and in a blinded fashion, grading meniscal lesions on knee MR exams. These\nconsensus votes were benchmarked against clinical (arthroscopy) and\nradiological (senior-most radiologist) observations. The IRR of the consensus\nvotes was compared to the IRR of the majority and most confident votes of the\ntwo cohorts.The radiologist cohort saw an improvement of 23% in IRR of swarm\nvotes over majority vote. Similar improvement of 23% in IRR in 3-resident swarm\nvotes over majority vote, was observed. The 5-resident swarm had an even higher\nimprovement of 32% in IRR over majority vote. Swarm consensus votes also\nimproved specificity by up to 50%. The swarm consensus votes outperformed\nindividual and majority vote decisions in both the radiologists and resident\ncohorts. The 5-resident swarm had higher IRR than 3-resident swarm indicating\npositive effect of increased swarm size. The attending and resident swarms also\noutperformed predictions from a state-of-the-art A.I. algorithm. Utilizing a\ndigital swarm platform improved agreement and allows participants to express\njudgement free intent, resulting in superior clinical performance and robust\nA.I. training labels.\n", "versions": [{"version": "v1", "created": "Sat, 26 Jun 2021 06:52:06 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Shah", "Rutwik", ""], ["Astuto", "Bruno", ""], ["Gleason", "Tyler", ""], ["Fletcher", "Will", ""], ["Banaga", "Justin", ""], ["Sweetwood", "Kevin", ""], ["Ye", "Allen", ""], ["Patel", "Rina", ""], ["McGill", "Kevin", ""], ["Link", "Thomas", ""], ["Crane", "Jason", ""], ["Pedoia", "Valentina", ""], ["Majumdar", "Sharmila", ""]]}, {"id": "2107.07343", "submitter": "Lennart Schneider", "authors": "Lennart Schneider, Florian Pfisterer, Martin Binder and Bernd Bischl", "title": "Mutation is all you need", "comments": "Accepted for the 8th ICML Workshop on Automated Machine Learning\n  (2021). 10 pages, 1 table, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) promises to make deep learning accessible to\nnon-experts by automating architecture engineering of deep neural networks.\nBANANAS is one state-of-the-art NAS method that is embedded within the Bayesian\noptimization framework. Recent experimental findings have demonstrated the\nstrong performance of BANANAS on the NAS-Bench-101 benchmark being determined\nby its path encoding and not its choice of surrogate model. We present\nexperimental results suggesting that the performance of BANANAS on the\nNAS-Bench-301 benchmark is determined by its acquisition function optimizer,\nwhich minimally mutates the incumbent.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 15:15:36 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Schneider", "Lennart", ""], ["Pfisterer", "Florian", ""], ["Binder", "Martin", ""], ["Bischl", "Bernd", ""]]}, {"id": "2107.07382", "submitter": "Md Ali Azam", "authors": "Md Ali Azam, Abir Hossen, Md Hafizur Rahman", "title": "Hybrid Ant Swarm-Based Data Clustering", "comments": "Conference", "journal-ref": "2021 IEEE World AI IoT Congress (AIIoT)", "doi": "10.1109/AIIoT52608.2021.9454238", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biologically inspired computing techniques are very effective and useful in\nmany areas of research including data clustering. Ant clustering algorithm is a\nnature-inspired clustering technique which is extensively studied for over two\ndecades. In this study, we extend the ant clustering algorithm (ACA) to a\nhybrid ant clustering algorithm (hACA). Specifically, we include a genetic\nalgorithm in standard ACA to extend the hybrid algorithm for better\nperformance. We also introduced novel pick up and drop off rules to speed up\nthe clustering performance. We study the performance of the hACA algorithm and\ncompare with standard ACA as a benchmark.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 16:43:11 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Azam", "Md Ali", ""], ["Hossen", "Abir", ""], ["Rahman", "Md Hafizur", ""]]}, {"id": "2107.07506", "submitter": "Kenneth Derek", "authors": "Kenneth Derek, Phillip Isola", "title": "Adaptable Agent Populations via a Generative Model of Policies", "comments": "Website at https://kennyderek.github.io/adap/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the natural world, life has found innumerable ways to survive and often\nthrive. Between and even within species, each individual is in some manner\nunique, and this diversity lends adaptability and robustness to life. In this\nwork, we aim to learn a space of diverse and high-reward policies on any given\nenvironment. To this end, we introduce a generative model of policies, which\nmaps a low-dimensional latent space to an agent policy space. Our method\nenables learning an entire population of agent policies, without requiring the\nuse of separate policy parameters. Just as real world populations can adapt and\nevolve via natural selection, our method is able to adapt to changes in our\nenvironment solely by selecting for policies in latent space. We test our\ngenerative model's capabilities in a variety of environments, including an\nopen-ended grid-world and a two-player soccer environment. Code,\nvisualizations, and additional experiments can be found at\nhttps://kennyderek.github.io/adap/.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:58:18 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Derek", "Kenneth", ""], ["Isola", "Phillip", ""]]}, {"id": "2107.07878", "submitter": "Igor Muniz MSc.", "authors": "I. Muniz, F. H. F. Camargo and A. Marques", "title": "Ranking labs-of-origin for genetically engineered DNA using Metric\n  Learning", "comments": "4 pages, 2 figures, 1 algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the constant advancements of genetic engineering, a common concern is to\nbe able to identify the lab-of-origin of genetically engineered DNA sequences.\nFor that reason, AltLabs has hosted the genetic Engineering Attribution\nChallenge to gather many teams to propose new tools to solve this problem. Here\nwe show our proposed method to rank the most likely labs-of-origin and generate\nembeddings for DNA sequences and labs. These embeddings can also perform\nvarious other tasks, like clustering both DNA sequences and labs and using them\nas features for Machine Learning models applied to solve other problems. This\nwork demonstrates that our method outperforms the classic training method for\nthis task while generating other helpful information.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 13:06:47 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Muniz", "I.", ""], ["Camargo", "F. H. F.", ""], ["Marques", "A.", ""]]}, {"id": "2107.07961", "submitter": "Yongxin Zhang", "authors": "Yongxin Zhang, Jiahai Wang, Zizhen Zhang, Yalan Zhou", "title": "MODRL/D-EL: Multiobjective Deep Reinforcement Learning with Evolutionary\n  Learning for Multiobjective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-based heuristics for solving combinatorial optimization problems has\nrecently attracted much academic attention. While most of the existing works\nonly consider the single objective problem with simple constraints, many\nreal-world problems have the multiobjective perspective and contain a rich set\nof constraints. This paper proposes a multiobjective deep reinforcement\nlearning with evolutionary learning algorithm for a typical complex problem\ncalled the multiobjective vehicle routing problem with time windows (MO-VRPTW).\nIn the proposed algorithm, the decomposition strategy is applied to generate\nsubproblems for a set of attention models. The comprehensive context\ninformation is introduced to further enhance the attention models. The\nevolutionary learning is also employed to fine-tune the parameters of the\nmodels. The experimental results on MO-VRPTW instances demonstrate the\nsuperiority of the proposed algorithm over other learning-based and\niterative-based approaches.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 15:22:20 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Zhang", "Yongxin", ""], ["Wang", "Jiahai", ""], ["Zhang", "Zizhen", ""], ["Zhou", "Yalan", ""]]}, {"id": "2107.07968", "submitter": "Joris De Jong", "authors": "J.P. de Jong", "title": "Controlling Recurrent Neural Networks by Diagonal Conceptors", "comments": "58 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The human brain is capable of learning, memorizing, and regenerating a\npanoply of temporal patterns. A neuro-dynamical mechanism called conceptors\noffers a method for controlling the dynamics of a recurrent neural network by\nwhich a variety of temporal patterns can be learned and recalled. However,\nconceptors are matrices whose size scales quadratically with the number of\nneurons in the recurrent neural network, hence they quickly become impractical.\nIn the work reported in this thesis, a variation of conceptors is introduced,\ncalled diagonal conceptors, which are diagonal matrices, thus reducing the\ncomputational cost drastically. It will be shown that diagonal conceptors\nachieve the same accuracy as conceptors, but are slightly more unstable. This\ninstability can be improved, but requires further research. Nevertheless,\ndiagonal conceptors show to be a promising practical alternative to the\nstandard full matrix conceptors.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 15:33:20 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["de Jong", "J. P.", ""]]}, {"id": "2107.08035", "submitter": "Charles Jekel", "authors": "Charles F. Jekel, Raphael T. Haftka", "title": "Testing Surrogate-Based Optimization with the Fortified Branin-Hoo\n  Extended to Four Dimensions", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": "LLNL-JRNL-824509", "categories": "math.OC cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Some popular functions used to test global optimization algorithms have\nmultiple local optima, all with the same value, making them all global optima.\nIt is easy to make them more challenging by fortifying them via adding a\nlocalized bump at the location of one of the optima. In previous work the\nauthors illustrated this for the Branin-Hoo function and the popular\ndifferential evolution algorithm, showing that the fortified Branin-Hoo\nrequired an order of magnitude more function evaluations. This paper examines\nthe effect of fortifying the Branin-Hoo function on surrogate-based\noptimization, which usually proceeds by adaptive sampling. Two algorithms are\nconsidered. The EGO algorithm, which is based on a Gaussian process (GP) and an\nalgorithm based on radial basis functions (RBF). EGO is found to be more frugal\nin terms of the number of required function evaluations required to identify\nthe correct basin, but it is expensive to run on a desktop, limiting the number\nof times the runs could be repeated to establish sound statistics on the number\nof required function evaluations. The RBF algorithm was cheaper to run,\nproviding more sound statistics on performance. A four-dimensional version of\nthe Branin-Hoo function was introduced in order to assess the effect of\ndimensionality. It was found that the difference between the ordinary function\nand the fortified one was much more pronounced for the four-dimensional\nfunction compared to the two dimensional one.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 17:56:32 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Jekel", "Charles F.", ""], ["Haftka", "Raphael T.", ""]]}, {"id": "2107.08326", "submitter": "Teresa Ludermir", "authors": "Anderson da Silva, Teresa Ludermir", "title": "Otimizacao de Redes Neurais atraves de Algoritmos Geneticos Celulares", "comments": "35 pages, in Portuguese, 4 figures, 7 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This works proposes a methodology to searching for automatically Artificial\nNeural Networks (ANN) by using Cellular Genetic Algorithm (CGA). The goal of\nthis methodology is to find compact networks whit good performance for\nclassification problems. The main reason for developing this work is centered\nat the difficulties of configuring compact ANNs with good performance rating.\nThe use of CGAs aims at seeking the components of the RNA in the same way that\na common Genetic Algorithm (GA), but it has the differential of incorporating a\nCellular Automaton (CA) to give location for the GA individuals. The location\nimposed by the CA aims to control the spread of solutions in the populations to\nmaintain the genetic diversity for longer time. This genetic diversity is\nimportant for obtain good results with the GAs.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 00:10:15 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["da Silva", "Anderson", ""], ["Ludermir", "Teresa", ""]]}, {"id": "2107.08399", "submitter": "Andrei Velichko", "authors": "Andrei Velichko and Hanif Heidari", "title": "A method for estimating the entropy of time series using artificial\n  neural network", "comments": "18 pages, 18 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NE math.IT nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the predictability and complexity of time series is an essential\ntool in designing and controlling the nonlinear system. There exist different\nentropy measures in the literature to analyze the predictability and complexity\nof time series. However, these measures have some drawbacks especially in short\ntime series. To overcome the difficulties, this paper proposes a new method for\nestimating the entropy of a time series using the LogNNet 784:25:10 neural\nnetwork model. The LogNNet reservoir matrix consists of 19625 elements which is\nfilled with the time series elements. After that, the network is trained on\nMNIST-10 dataset and the classification accuracy is calculated. The accuracy is\nconsidered as the entropy measure and denoted by NNetEn. A more complex\ntransformation of the input information by the time series in the reservoir\nleads to higher NNetEn values. Many practical time series data have less than\n19625 elements. Some duplicating or stretching methods are investigated to\novercome this difficulty and the most successful method is identified for\npractical applications. The epochs number in the training process of LogNNet is\nconsidered as the input parameter. A new time series characteristic called time\nseries learning inertia is introduced to investigate the effect of epochs\nnumber in the efficiency of neural network. To show the robustness and\nefficiency of the proposed method, it is applied on some chaotic, periodic,\nrandom, binary and constant time series. The NNetEn is compared with some\nexisting entropy measures. The results show that the proposed method is more\nrobust and accurate than existing methods.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 09:31:14 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Velichko", "Andrei", ""], ["Heidari", "Hanif", ""]]}, {"id": "2107.08454", "submitter": "Annibale Panichella", "authors": "Mitchell Olsthoorn and Annibale Panichella", "title": "Multi-objective Test Case Selection Through Linkage Learning-based\n  Crossover", "comments": null, "journal-ref": "13th Symposium on Search-Based Software Engineering (SSBSE) 2021", "doi": null, "report-no": null, "categories": "cs.SE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Test Case Selection (TCS) aims to select a subset of the test suite to run\nfor regression testing. The selection is typically based on past coverage and\nexecution cost data. Researchers have successfully used multi-objective\nevolutionary algorithms (MOEAs), such as NSGA-II and its variants, to solve\nthis problem. These MOEAs use traditional crossover operators to create new\ncandidate solutions through genetic recombination. Recent studies in numerical\noptimization have shown that better recombinations can be made using machine\nlearning, in particular link-age learning. Inspired by these recent advances in\nthis field, we propose a new variant of NSGA-II, called L2-NSGA, that uses\nlinkage learning to optimize test case selection. In particular, we use an\nunsupervised clustering algorithm to infer promising patterns among the\nsolutions (subset of test suites). Then, these patterns are used in the next\niterations of L2-NSGA to create solutions that preserve these inferred\npatterns. Our results show that our customizations make NSGA-II more effective\nfor test case selection. The test suite sub-sets generated by L2-NSGA are less\nexpensive and detect more faults than those generated by MOEAs used in the\nliterature for regression testing.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 14:11:49 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 10:11:47 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Olsthoorn", "Mitchell", ""], ["Panichella", "Annibale", ""]]}, {"id": "2107.08467", "submitter": "Ramin Hasani", "authors": "Sophie Gruenbacher, Mathias Lechner, Ramin Hasani, Daniela Rus, Thomas\n  A. Henzinger, Scott Smolka, Radu Grosu", "title": "GoTube: Scalable Stochastic Verification of Continuous-Depth Models", "comments": "17 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.DS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce a new stochastic verification algorithm that formally quantifies\nthe behavioral robustness of any time-continuous process formulated as a\ncontinuous-depth model. The algorithm solves a set of global optimization (Go)\nproblems over a given time horizon to construct a tight enclosure (Tube) of the\nset of all process executions starting from a ball of initial states. We call\nour algorithm GoTube. Through its construction, GoTube ensures that the\nbounding tube is conservative up to a desired probability. GoTube is\nimplemented in JAX and optimized to scale to complex continuous-depth models.\nCompared to advanced reachability analysis tools for time-continuous neural\nnetworks, GoTube provably does not accumulate over-approximation errors between\ntime steps and avoids the infamous wrapping effect inherent in symbolic\ntechniques. We show that GoTube substantially outperforms state-of-the-art\nverification tools in terms of the size of the initial ball, speed,\ntime-horizon, task completion, and scalability, on a large set of experiments.\nGoTube is stable and sets the state-of-the-art for its ability to scale up to\ntime horizons well beyond what has been possible before.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 14:59:31 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Gruenbacher", "Sophie", ""], ["Lechner", "Mathias", ""], ["Hasani", "Ramin", ""], ["Rus", "Daniela", ""], ["Henzinger", "Thomas A.", ""], ["Smolka", "Scott", ""], ["Grosu", "Radu", ""]]}, {"id": "2107.08484", "submitter": "George Kyriakides", "authors": "Aristeidis Chrostoforidis, George Kyriakides, Konstantinos Margaritis", "title": "A Novel Evolutionary Algorithm for Hierarchical Neural Architecture\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, we propose a novel evolutionary algorithm for neural\narchitecture search, applicable to global search spaces. The algorithm's\narchitectural representation organizes the topology in multiple hierarchical\nmodules, while the design process exploits this representation, in order to\nexplore the search space. We also employ a curation system, which promotes the\nutilization of well performing sub-structures to subsequent generations. We\napply our method to Fashion-MNIST and NAS-Bench101, achieving accuracies of\n$93.2\\%$ and $94.8\\%$ respectively in a relatively small number of generations.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 16:19:53 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chrostoforidis", "Aristeidis", ""], ["Kyriakides", "George", ""], ["Margaritis", "Konstantinos", ""]]}, {"id": "2107.08564", "submitter": "Ali Momeni", "authors": "Ali Momeni and Romain Fleury", "title": "Wave-based extreme deep learning based on non-linear time-Floquet\n  entanglement", "comments": "23 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG cs.NE physics.app-ph physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wave-based analog signal processing holds the promise of extremely fast,\non-the-fly, power-efficient data processing, occurring as a wave propagates\nthrough an artificially engineered medium. Yet, due to the fundamentally weak\nnon-linearities of traditional wave materials, such analog processors have been\nso far largely confined to simple linear projections such as image edge\ndetection or matrix multiplications. Complex neuromorphic computing tasks,\nwhich inherently require strong non-linearities, have so far remained\nout-of-reach of wave-based solutions, with a few attempts that implemented\nnon-linearities on the digital front, or used weak and inflexible non-linear\nsensors, restraining the learning performance. Here, we tackle this issue by\ndemonstrating the relevance of Time-Floquet physics to induce a strong\nnon-linear entanglement between signal inputs at different frequencies,\nenabling a power-efficient and versatile wave platform for analog extreme deep\nlearning involving a single, uniformly modulated dielectric layer and a\nscattering medium. We prove the efficiency of the method for extreme learning\nmachines and reservoir computing to solve a range of challenging learning\ntasks, from forecasting chaotic time series to the simultaneous classification\nof distinct datasets. Our results open the way for wave-based machine learning\nwith high energy efficiency, speed, and scalability.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 00:18:09 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Momeni", "Ali", ""], ["Fleury", "Romain", ""]]}, {"id": "2107.08908", "submitter": "Tarik A. Rashid", "authors": "Aram Ahmed, Tarik A. Rashid and Soran Saeed", "title": "Dynamic Cat Swarm Optimization Algorithm for Backboard Wiring Problem", "comments": "22 pages", "journal-ref": "Neural Computing and Applications, 2021", "doi": "10.1007/s00521-021-06041-3", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper presents a powerful swarm intelligence meta-heuristic optimization\nalgorithm called Dynamic Cat Swarm Optimization. The formulation is through\nmodifying the existing Cat Swarm Optimization. The original Cat Swarm\nOptimization suffers from the shortcoming of 'premature convergence', which is\nthe possibility of entrapment in local optima which usually happens due to the\noff-balance between exploration and exploitation phases. Therefore, the\nproposed algorithm suggests a new method to provide a proper balance between\nthese phases by modifying the selection scheme and the seeking mode of the\nalgorithm. To evaluate the performance of the proposed algorithm, 23 classical\ntest functions, 10 modern test functions (CEC 2019) and a real world scenario\nare used. In addition, the Dimension-wise diversity metric is used to measure\nthe percentage of the exploration and exploitation phases. The optimization\nresults show the effectiveness of the proposed algorithm, which ranks first\ncompared to several well-known algorithms available in the literature.\nFurthermore, statistical methods and graphs are also used to further confirm\nthe outperformance of the algorithm. Finally, the conclusion as well as future\ndirections to further improve the algorithm are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 19:41:27 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Ahmed", "Aram", ""], ["Rashid", "Tarik A.", ""], ["Saeed", "Soran", ""]]}, {"id": "2107.08944", "submitter": "Tarik A. Rashid", "authors": "Sabat Abdulhameed and Tarik A. Rashid", "title": "Child Drawing Development Optimization Algorithm based on Child's\n  Cognitive Development", "comments": "21 pages", "journal-ref": "Arabian Journal for Science and Engineering, 2021", "doi": "10.1007/s13369-021-05928-6", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper proposes a novel metaheuristic Child Drawing Development\nOptimization (CDDO) algorithm inspired by the child's learning behaviour and\ncognitive development using the golden ratio to optimize the beauty behind\ntheir art. The golden ratio was first introduced by the famous mathematician\nFibonacci. The ratio of two consecutive numbers in the Fibonacci sequence is\nsimilar, and it is called the golden ratio, which is prevalent in nature, art,\narchitecture, and design. CDDO uses golden ratio and mimics cognitive learning\nand child's drawing development stages starting from the scribbling stage to\nthe advanced pattern-based stage. Hand pressure width, length and golden ratio\nof the child's drawing are tuned to attain better results. This helps children\nwith evolving, improving their intelligence and collectively achieving shared\ngoals. CDDO shows superior performance in finding the global optimum solution\nfor the optimization problems tested by 19 benchmark functions. Its results are\nevaluated against more than one state of art algorithms such as PSO, DE, WOA,\nGSA, and FEP. The performance of the CDDO is assessed, and the test result\nshows that CDDO is relatively competitive through scoring 2.8 ranks. This\ndisplays that the CDDO is outstandingly robust in exploring a new solution.\nAlso, it reveals the competency of the algorithm to evade local minima as it\ncovers promising regions extensively within the design space and exploits the\nbest solution.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 08:51:01 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Abdulhameed", "Sabat", ""], ["Rashid", "Tarik A.", ""]]}, {"id": "2107.09309", "submitter": "Mohanad Odema", "authors": "Mohanad Odema, Nafiul Rashid, Berken Utku Demirel, Mohammad Abdullah\n  Al Faruque", "title": "LENS: Layer Distribution Enabled Neural Architecture Search in\n  Edge-Cloud Hierarchies", "comments": "To appear at the 58th IEEE/ACM Design Automation Conference (DAC),\n  December 2021, San Francisco, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge-Cloud hierarchical systems employing intelligence through Deep Neural\nNetworks (DNNs) endure the dilemma of workload distribution within them.\nPrevious solutions proposed to distribute workloads at runtime according to the\nstate of the surroundings, like the wireless conditions. However, such\nconditions are usually overlooked at design time. This paper addresses this\nissue for DNN architectural design by presenting a novel methodology, LENS,\nwhich administers multi-objective Neural Architecture Search (NAS) for\ntwo-tiered systems, where the performance objectives are refashioned to\nconsider the wireless communication parameters. From our experimental search\nspace, we demonstrate that LENS improves upon the traditional solution's Pareto\nset by 76.47% and 75% with respect to the energy and latency metrics,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 07:53:02 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Odema", "Mohanad", ""], ["Rashid", "Nafiul", ""], ["Demirel", "Berken Utku", ""], ["Faruque", "Mohammad Abdullah Al", ""]]}, {"id": "2107.09458", "submitter": "Christian Haider", "authors": "Christian Haider, Fabricio Olivetti de Fran\\c{c}a, Bogdan Burlacu,\n  Gabriel Kronberger", "title": "Using Shape Constraints for Improving Symbolic Regression Models", "comments": "33 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe and analyze algorithms for shape-constrained symbolic regression,\nwhich allows the inclusion of prior knowledge about the shape of the regression\nfunction. This is relevant in many areas of engineering -- in particular\nwhenever a data-driven model obtained from measurements must have certain\nproperties (e.g. positivity, monotonicity or convexity/concavity). We implement\nshape constraints using a soft-penalty approach which uses multi-objective\nalgorithms to minimize constraint violations and training error. We use the\nnon-dominated sorting genetic algorithm (NSGA-II) as well as the\nmulti-objective evolutionary algorithm based on decomposition (MOEA/D). We use\na set of models from physics textbooks to test the algorithms and compare\nagainst earlier results with single-objective algorithms. The results show that\nall algorithms are able to find models which conform to all shape constraints.\nUsing shape constraints helps to improve extrapolation behavior of the models.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 12:53:28 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Haider", "Christian", ""], ["de Fran\u00e7a", "Fabricio Olivetti", ""], ["Burlacu", "Bogdan", ""], ["Kronberger", "Gabriel", ""]]}, {"id": "2107.09484", "submitter": "Gabriel Kronberger", "authors": "Gabriel Kronberger, Michael Kommenda, Andreas Promberger, Falk Nickel", "title": "Predicting Friction System Performance with Symbolic Regression and\n  Genetic Programming with Factor Variables", "comments": "Genetic and Evolutionary Computation Conference (GECCO), July\n  15th-19th, 2018", "journal-ref": "In Proceedings of the Genetic and Evolutionary Computation\n  Conference, pp. 1278-1285. ACM. (July 2018)", "doi": "10.1145/3205455.3205522", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Friction systems are mechanical systems wherein friction is used for force\ntransmission (e.g. mechanical braking systems or automatic gearboxes). For\nfinding optimal and safe design parameters, engineers have to predict friction\nsystem performance. This is especially difficult in real-world applications,\nbecause it is affected by many parameters. We have used symbolic regression and\ngenetic programming for finding accurate and trustworthy prediction models for\nthis task. However, it is not straight-forward how nominal variables can be\nincluded. In particular, a one-hot-encoding is unsatisfactory because genetic\nprogramming tends to remove such indicator variables. We have therefore used\nso-called factor variables for representing nominal variables in symbolic\nregression models. Our results show that GP is able to produce symbolic\nregression models for predicting friction performance with predictive accuracy\nthat is comparable to artificial neural networks. The symbolic regression\nmodels with factor variables are less complex than models using a one-hot\nencoding.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 16:10:27 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Kronberger", "Gabriel", ""], ["Kommenda", "Michael", ""], ["Promberger", "Andreas", ""], ["Nickel", "Falk", ""]]}, {"id": "2107.09507", "submitter": "Jian Cui", "authors": "Jian Cui, Yisi Liu, Zirui Lan, Olga Sourina, Wolfgang M\\\"uller-Wittig", "title": "EEG-based Cross-Subject Driver Drowsiness Recognition with Interpretable\n  CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the context of electroencephalogram (EEG)-based driver drowsiness\nrecognition, it is still a challenging task to design a calibration-free\nsystem, since there exists a significant variability of EEG signals among\ndifferent subjects and recording sessions. As deep learning has received much\nresearch attention in recent years, many efforts have been made to use deep\nlearning methods for EEG signal recognition. However, existing works mostly\ntreat deep learning models as blackbox classifiers, while what have been\nlearned by the models and to which extent they are affected by the noise from\nEEG data are still underexplored. In this paper, we develop a novel\nconvolutional neural network that can explain its decision by highlighting the\nlocal areas of the input sample that contain important information for the\nclassification. The network has a compact structure for ease of interpretation\nand takes advantage of separable convolutions to process the EEG signals in a\nspatial-temporal sequence. Results show that the model achieves an average\naccuracy of 78.35% on 11 subjects for leave-one-out cross-subject drowsiness\nrecognition, which is higher than the conventional baseline methods of\n53.4%-72.68% and state-of-art deep learning methods of 63.90%-65.61%.\nVisualization results show that the model has learned to recognize biologically\nexplainable features from EEG signals, e.g., Alpha spindles, as strong\nindicators of drowsiness across different subjects. In addition, we also\nexplore reasons behind some wrongly classified samples and how the model is\naffected by artifacts and noise in the data. Our work illustrates a promising\ndirection on using interpretable deep learning models to discover meaning\npatterns related to different mental states from complex EEG signals.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 14:47:20 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Cui", "Jian", ""], ["Liu", "Yisi", ""], ["Lan", "Zirui", ""], ["Sourina", "Olga", ""], ["M\u00fcller-Wittig", "Wolfgang", ""]]}, {"id": "2107.09558", "submitter": "Hieu Tran", "authors": "Hieu Tran, Son Nguyen, I-Ling Yen, Farokh Bastani", "title": "Into Summarization Techniques for IoT Data Discovery Routing", "comments": "10 pages, 8 figures", "journal-ref": "IEEE International Conference on Cloud Computing 2021 (IEEE CLOUD\n  2021)", "doi": null, "report-no": null, "categories": "cs.NI cs.DB cs.DC cs.IR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider the IoT data discovery problem in very large and\ngrowing scale networks. Specifically, we investigate in depth the routing table\nsummarization techniques to support effective and space-efficient IoT data\ndiscovery routing. Novel summarization algorithms, including alphabetical\nbased, hash based, and meaning based summarization and their corresponding\ncoding schemes are proposed. The issue of potentially misleading routing due to\nsummarization is also investigated. Subsequently, we analyze the strategy of\nwhen to summarize in order to balance the tradeoff between the routing table\ncompression rate and the chance of causing misleading routing. For experimental\nstudy, we have collected 100K IoT data streams from various IoT databases as\nthe input dataset. Experimental results show that our summarization solution\ncan reduce the routing table size by 20 to 30 folds with 2-5% increase in\nlatency when compared with similar peer-to-peer discovery routing algorithms\nwithout summarization. Also, our approach outperforms DHT based approaches by 2\nto 6 folds in terms of latency and traffic.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 15:22:16 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 14:52:47 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Tran", "Hieu", ""], ["Nguyen", "Son", ""], ["Yen", "I-Ling", ""], ["Bastani", "Farokh", ""]]}, {"id": "2107.09669", "submitter": "Tim Taylor", "authors": "Tim Taylor", "title": "Evolutionary Innovation Viewed as Novel Physical Phenomena and\n  Hierarchical Systems Building", "comments": "Presented at the Fourth Workshop on Open-Ended Evolution (OEE4) at\n  the 2021 Conference on Artificial Life (ALIFE 2021), Prague/Online, July 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous work I proposed a framework for thinking about open-ended\nevolution. The framework characterised the basic processes required for\nDarwinian evolution as: (1) the generation of a phenotype from a genetic\ndescription; (2) the evaluation of that phenotype; and (3) the reproduction\nwith variation of successful genotype-phenotypes. My treatment emphasized the\npotential influence of the biotic and abiotic environment, and of the laws of\nphysics/chemistry, on each of these processes. I demonstrated the conditions\nunder which these processes can allow for ongoing exploration of a space of\npossible phenotypes (which I labelled exploratory open-endedness). However,\nthese processes by themselves cannot expand the space of possible phenotypes\nand therefore cannot account for the more interesting and unexpected kinds of\nevolutionary innovation (such as those I labelled expansive and\ntransformational open-endedness). In the previous work I looked at ways in\nwhich expansive and transformational innovations could arise. I proposed\ntransdomain bridges and non-additive compositional systems as two mechanisms by\nwhich these kinds of innovations could arise. In the current paper I wish to\ngeneralise and expand upon these two concepts. I do this by adopting the\nParameter Space-Organisation Space-Action Space (POA) perspective, as suggested\nat in my previous work, and proposing that all evolutionary innovations can be\nviewed as either capturing some novel physical phenomena that had previously\nbeen unused, or as the creation of new persistent systems within the\nenvironment.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 15:48:31 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Taylor", "Tim", ""]]}, {"id": "2107.09718", "submitter": "Carolina Gil Marcelino", "authors": "C.G. Marcelino, G.M.C. Leite, C.A.D.M Delgado, L.B. de Oliveira, E.F.\n  Wanner, S. Jim\\'enez-Fern\\'andez, S. Salcedo-Sanz", "title": "An Efficient Multi-objective Evolutionary Approach for Solving the\n  Operation of Multi-Reservoir System Scheduling in Hydro-Power Plants", "comments": "Accepted Manuscript version (after peer review, and editor-author\n  communications). https://doi.org/10.1016/j.eswa.2021.115638", "journal-ref": "Expert Systems With Applications (2021)", "doi": "10.1016/2021.j.eswa.2021.115638", "report-no": null, "categories": "cs.NE cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper tackles the short-term hydro-power unit commitment problem in a\nmulti-reservoir system - a cascade-based operation scenario. For this, we\npropose a new mathematical modelling in which the goal is to maximize the total\nenergy production of the hydro-power plant in a sub-daily operation, and,\nsimultaneously, to maximize the total water content (volume) of reservoirs. For\nsolving the problem, we discuss the Multi-objective Evolutionary Swarm\nHybridization (MESH) algorithm, a recently proposed multi-objective swarm\nintelligence-based optimization method which has obtained very competitive\nresults when compared to existing evolutionary algorithms in specific\napplications. The MESH approach has been applied to find the optimal water\ndischarge and the power produced at the maximum reservoir volume for all\npossible combinations of turbines in a hydro-power plant. The performance of\nMESH has been compared with that of well-known evolutionary approaches such as\nNSGA-II, NSGA-III, SPEA2, and MOEA/D in a realistic problem considering data\nfrom a hydro-power energy system with two cascaded hydro-power plants in\nBrazil. Results indicate that MESH showed a superior performance than\nalternative multi-objective approaches in terms of efficiency and accuracy,\nproviding a profit of \\$412,500 per month in a projection analysis carried out.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 18:39:09 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 16:24:51 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Marcelino", "C. G.", ""], ["Leite", "G. M. C.", ""], ["Delgado", "C. A. D. M", ""], ["de Oliveira", "L. B.", ""], ["Wanner", "E. F.", ""], ["Jim\u00e9nez-Fern\u00e1ndez", "S.", ""], ["Salcedo-Sanz", "S.", ""]]}, {"id": "2107.09760", "submitter": "Jose Hernandez", "authors": "Jose Guadalupe Hernandez, Alexander Lalejini, Charles Ofria", "title": "An Exploration of Exploration: Measuring the ability of lexicase\n  selection to find obscure pathways to optimality", "comments": "Changes to the axis labels and added funding sources to\n  acknowledgments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parent selection algorithms (selection schemes) steer populations through a\nproblem's search space, often trading off between exploitation and exploration.\nUnderstanding how selection schemes affect exploitation and exploration within\na search space is crucial to tackling increasingly challenging problems. Here,\nwe introduce an \"exploration diagnostic\" that diagnoses a selection scheme's\ncapacity for search space exploration. We use our exploration diagnostic to\ninvestigate the exploratory capacity of lexicase selection and several of its\nvariants: epsilon lexicase, down-sampled lexicase, cohort lexicase, and\nnovelty-lexicase. We verify that lexicase selection out-explores tournament\nselection, and we show that lexicase selection's exploratory capacity can be\nsensitive to the ratio between population size and the number of test cases\nused for evaluating candidate solutions. Additionally, we find that relaxing\nlexicase's elitism with epsilon lexicase can further improve exploration. Both\ndown-sampling and cohort lexicase -- two techniques for applying random\nsubsampling to test cases -- degrade lexicase's exploratory capacity; however,\nwe find that cohort partitioning better preserves lexicase's exploratory\ncapacity than down-sampling. Finally, we find evidence that novelty-lexicase's\naddition of novelty test cases can degrade lexicase's capacity for exploration.\nOverall, our findings provide hypotheses for further exploration and actionable\ninsights and recommendations for using lexicase selection. Additionally, this\nwork demonstrates the value of selection scheme diagnostics as a complement to\nmore conventional benchmarking approaches to selection scheme analysis.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 20:43:06 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 21:52:40 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Hernandez", "Jose Guadalupe", ""], ["Lalejini", "Alexander", ""], ["Ofria", "Charles", ""]]}, {"id": "2107.09869", "submitter": "Zeeshan Ahmad", "authors": "Zeeshan Ahmad, Anika Tabassum, Ling Guan, Naimul Khan", "title": "ECG Heartbeat Classification Using Multimodal Fusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electrocardiogram (ECG) is an authoritative source to diagnose and counter\ncritical cardiovascular syndromes such as arrhythmia and myocardial infarction\n(MI). Current machine learning techniques either depend on manually extracted\nfeatures or large and complex deep learning networks which merely utilize the\n1D ECG signal directly. Since intelligent multimodal fusion can perform at the\nstateof-the-art level with an efficient deep network, therefore, in this paper,\nwe propose two computationally efficient multimodal fusion frameworks for ECG\nheart beat classification called Multimodal Image Fusion (MIF) and Multimodal\nFeature Fusion (MFF). At the input of these frameworks, we convert the raw ECG\ndata into three different images using Gramian Angular Field (GAF), Recurrence\nPlot (RP) and Markov Transition Field (MTF). In MIF, we first perform image\nfusion by combining three imaging modalities to create a single image modality\nwhich serves as input to the Convolutional Neural Network (CNN). In MFF, we\nextracted features from penultimate layer of CNNs and fused them to get unique\nand interdependent information necessary for better performance of classifier.\nThese informational features are finally used to train a Support Vector Machine\n(SVM) classifier for ECG heart-beat classification. We demonstrate the\nsuperiority of the proposed fusion models by performing experiments on\nPhysioNets MIT-BIH dataset for five distinct conditions of arrhythmias which\nare consistent with the AAMI EC57 protocols and on PTB diagnostics dataset for\nMyocardial Infarction (MI) classification. We achieved classification accuracy\nof 99.7% and 99.2% on arrhythmia and MI classification, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 03:48:35 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Ahmad", "Zeeshan", ""], ["Tabassum", "Anika", ""], ["Guan", "Ling", ""], ["Khan", "Naimul", ""]]}, {"id": "2107.10030", "submitter": "Jeremie Dona", "authors": "J\\'er\\'emie Dona (MLIA), Patrick Gallinari (MLIA)", "title": "Differentiable Feature Selection, a Reparameterization Approach", "comments": null, "journal-ref": "European Conference (ECML-PKDD), In press", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of feature selection for reconstruction which consists\nin choosing a small subset of features from which whole data instances can be\nreconstructed. This is of particular importance in several contexts involving\nfor example costly physical measurements, sensor placement or information\ncompression. To break the intrinsic combinatorial nature of this problem, we\nformulate the task as optimizing a binary mask distribution enabling an\naccurate reconstruction. We then face two main challenges. One concerns\ndifferentiability issues due to the binary distribution. The second one\ncorresponds to the elimination of redundant information by selecting variables\nin a correlated fashion which requires modeling the covariance of the binary\ndistribution. We address both issues by introducing a relaxation of the problem\nvia a novel reparameterization of the logitNormal distribution. We demonstrate\nthat the proposed method provides an effective exploration scheme and leads to\nefficient feature selection for reconstruction through evaluation on several\nhigh dimensional image benchmarks. We show that the method leverages the\nintrinsic geometry of the data, facilitating reconstruction.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 11:52:34 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Dona", "J\u00e9r\u00e9mie", "", "MLIA"], ["Gallinari", "Patrick", "", "MLIA"]]}, {"id": "2107.10034", "submitter": "Jan Jakubuv", "authors": "Karel Chvalovsk\\'y, Jan Jakub\\r{u}v, Miroslav Ol\\v{s}\\'ak, Josef Urban", "title": "Learning Theorem Proving Components", "comments": "Accepted to TABLEAUX'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.LG cs.NE cs.SC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Saturation-style automated theorem provers (ATPs) based on the given clause\nprocedure are today the strongest general reasoners for classical first-order\nlogic. The clause selection heuristics in such systems are, however, often\nevaluating clauses in isolation, ignoring other clauses. This has changed\nrecently by equipping the E/ENIGMA system with a graph neural network (GNN)\nthat chooses the next given clause based on its evaluation in the context of\npreviously selected clauses. In this work, we describe several algorithms and\nexperiments with ENIGMA, advancing the idea of contextual evaluation based on\nlearning important components of the graph of clauses.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 12:00:05 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Chvalovsk\u00fd", "Karel", ""], ["Jakub\u016fv", "Jan", ""], ["Ol\u0161\u00e1k", "Miroslav", ""], ["Urban", "Josef", ""]]}, {"id": "2107.10295", "submitter": "Tirtharaj Dash", "authors": "Tirtharaj Dash, Sharad Chitlangia, Aditya Ahuja, Ashwin Srinivasan", "title": "How to Tell Deep Neural Networks What We Know", "comments": "12 pages (full version); substantial overlap with arXiv:2103.00180", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a short survey of ways in which existing scientific knowledge are\nincluded when constructing models with neural networks. The inclusion of\ndomain-knowledge is of special interest not just to constructing scientific\nassistants, but also, many other areas that involve understanding data using\nhuman-machine collaboration. In many such instances, machine-based model\nconstruction may benefit significantly from being provided with human-knowledge\nof the domain encoded in a sufficiently precise form. This paper examines the\ninclusion of domain-knowledge by means of changes to: the input, the\nloss-function, and the architecture of deep networks. The categorisation is for\nease of exposition: in practice we expect a combination of such changes will be\nemployed. In each category, we describe techniques that have been shown to\nyield significant changes in network performance.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 18:18:02 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Dash", "Tirtharaj", ""], ["Chitlangia", "Sharad", ""], ["Ahuja", "Aditya", ""], ["Srinivasan", "Ashwin", ""]]}, {"id": "2107.10325", "submitter": "Jos\\'e Enrique Alvarez Iglesias MSc.", "authors": "Jos\\'e Enrique Alvarez Iglesias and Mayrim Vega-Hern\\'andez and\n  Eduardo Mart\\'inez-Montes", "title": "A Multi-objective Evolutionary Algorithm for EEG Inverse Problem", "comments": "11 pages, 4 figures, 18 references", "journal-ref": null, "doi": "10.13140/RG.2.2.18311.93604", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we proposed a multi-objective approach for the EEG Inverse\nProblem. This formulation does not need unknown parameters that involve\nempirical procedures. Due to the combinatorial characteristics of the problem,\nthis alternative included evolutionary strategies to resolve it. The result is\na Multi-objective Evolutionary Algorithm based on Anatomical Restrictions\n(MOEAAR) to estimate distributed solutions. The comparative tests were between\nthis approach and 3 classic methods of regularization: LASSO, Ridge-L and\nENET-L. In the experimental phase, regression models were selected to obtain\nsparse and distributed solutions. The analysis involved simulated data with\ndifferent signal-to-noise ratio (SNR). The indicators for quality control were\nLocalization Error, Spatial Resolution and Visibility. The MOEAAR evidenced\nbetter stability than the classic methods in the reconstruction and\nlocalization of the maximum activation. The norm L0 was used to estimate sparse\nsolutions with the evolutionary approach and its results were relevant.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 19:37:27 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Iglesias", "Jos\u00e9 Enrique Alvarez", ""], ["Vega-Hern\u00e1ndez", "Mayrim", ""], ["Mart\u00ednez-Montes", "Eduardo", ""]]}, {"id": "2107.10342", "submitter": "Mikhail Burtsev", "authors": "Mikhail Burtsev and Anna Rumshisky", "title": "Multi-Stream Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transformer-based encoder-decoder models produce a fused token-wise\nrepresentation after every encoder layer. We investigate the effects of\nallowing the encoder to preserve and explore alternative hypotheses, combined\nat the end of the encoding process. To that end, we design and examine a\n$\\textit{Multi-stream Transformer}$ architecture and find that splitting the\nTransformer encoder into multiple encoder streams and allowing the model to\nmerge multiple representational hypotheses improves performance, with further\nimprovement obtained by adding a skip connection between the first and the\nfinal encoder layer.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 20:16:57 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Burtsev", "Mikhail", ""], ["Rumshisky", "Anna", ""]]}, {"id": "2107.10429", "submitter": "Roberto Perera", "authors": "Libo Sun, James Browning, Roberto Perera", "title": "Shedding some light on Light Up with Artificial Intelligence", "comments": "14 pages, 16 figures, for associated codes, see\n  \\<https://github.com/rperera12/AKARI-LightUp-GameSolver-with-DeepNeuralNetworks-and-HillClimb-or-SimulatedAnnealing>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Light-Up puzzle, also known as the AKARI puzzle, has never been solved\nusing modern artificial intelligence (AI) methods. Currently, the most widely\nused computational technique to autonomously develop solutions involve\nevolution theory algorithms. This project is an effort to apply new AI\ntechniques for solving the Light-up puzzle faster and more computationally\nefficient. The algorithms explored for producing optimal solutions include hill\nclimbing, simulated annealing, feed-forward neural network (FNN), and\nconvolutional neural network (CNN). Two algorithms were developed for hill\nclimbing and simulated annealing using 2 actions (add and remove light bulb)\nversus 3 actions(add, remove, or move light-bulb to a different cell). Both\nhill climbing and simulated annealing algorithms showed a higher accuracy for\nthe case of 3 actions. The simulated annealing showed to significantly\noutperform hill climbing, FNN, CNN, and an evolutionary theory algorithm\nachieving 100% accuracy in 30 unique board configurations. Lastly, while FNN\nand CNN algorithms showed low accuracies, computational times were\nsignificantly faster compared to the remaining algorithms. The GitHub\nrepository for this project can be found at\nhttps://github.com/rperera12/AKARI-LightUp-GameSolver-with-DeepNeuralNetworks-and-HillClimb-or-SimulatedAnnealing.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 03:03:57 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Sun", "Libo", ""], ["Browning", "James", ""], ["Perera", "Roberto", ""]]}, {"id": "2107.10640", "submitter": "Bogdan Burlacu", "authors": "Bogdan Burlacu, Lukas Kammerer, Michael Affenzeller, Gabriel\n  Kronberger", "title": "Hash-Based Tree Similarity and Simplification in Genetic Programming for\n  Symbolic Regression", "comments": "International Conference on Computer Aided Systems Theory, EUROCAST\n  2019", "journal-ref": "In: Moreno-D\\'iaz R. et al. Computer Aided Systems Theory. Lecture\n  Notes in Computer Science, Vol. 12013. Springer, 2020, pp 361-369", "doi": "10.1007/2F978-3-030-45093-9_44", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce in this paper a runtime-efficient tree hashing algorithm for the\nidentification of isomorphic subtrees, with two important applications in\ngenetic programming for symbolic regression: fast, online calculation of\npopulation diversity and algebraic simplification of symbolic expression trees.\nBased on this hashing approach, we propose a simple diversity-preservation\nmechanism with promising results on a collection of symbolic regression\nbenchmark problems.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 13:22:06 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Burlacu", "Bogdan", ""], ["Kammerer", "Lukas", ""], ["Affenzeller", "Michael", ""], ["Kronberger", "Gabriel", ""]]}, {"id": "2107.10647", "submitter": "Joaquin Cordero", "authors": "Joaqu\\'in Cordero, Alfredo Bolt and Mauricio Valle", "title": "An\\'alisis de Canasta de mercado en supermercados mediante mapas\n  auto-organizados", "comments": "18 pages, in Spanish, 7 Figures, 5 tables, Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Introduction: An important chain of supermarkets in the western zone of the\ncapital of Chile, needs to obtain key information to make decisions, this\ninformation is available in the databases but needs to be processed due to the\ncomplexity and quantity of information which becomes difficult to visualiz,.\nMethod: For this purpose, an algorithm was developed using artificial neural\nnetworks applying Kohonen's SOM method. To carry it out, certain key procedures\nmust be followed to develop it, such as data mining that will be responsible\nfor filtering and then use only the relevant data for market basket analysis.\nAfter filtering the information, the data must be prepared. After data\npreparation, we prepared the Python programming environment to adapt it to the\nsample data, then proceed to train the SOM with its parameters set after test\nresults. Result: the result of the SOM obtains the relationship between the\nproducts that were most purchased by positioning them topologically close, to\nform promotions, packs and bundles for the retail manager to take into\nconsideration, because these relationships were obtained as a result of the SOM\ntraining with the real transactions of the clients. Conclusion: Based on this,\nrecommendations on frequent shopping baskets have been made to the supermarket\nchain that provided the data used in the research\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 16:52:14 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Cordero", "Joaqu\u00edn", ""], ["Bolt", "Alfredo", ""], ["Valle", "Mauricio", ""]]}, {"id": "2107.11019", "submitter": "Danial Yazdani", "authors": "Mohammad Nabi Omidvar, Danial Yazdani, Juergen Branke, Xiaodong Li,\n  Shengxiang Yang, Xin Yao", "title": "Generating Large-scale Dynamic Optimization Problem Instances Using the\n  Generalized Moving Peaks Benchmark", "comments": "arXiv admin note: text overlap with arXiv:2106.06174", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This document describes the generalized moving peaks benchmark (GMPB) and how\nit can be used to generate problem instances for continuous large-scale dynamic\noptimization problems. It presents a set of 15 benchmark problems, the relevant\nsource code, and a performance indicator, designed for comparative studies and\ncompetitions in large-scale dynamic optimization. Although its primary purpose\nis to provide a coherent basis for running competitions, its generality allows\nthe interested reader to use this document as a guide to design customized\nproblem instances to investigate issues beyond the scope of the presented\nbenchmark suite. To this end, we explain the modular structure of the GMPB and\nhow its constituents can be assembled to form problem instances with a variety\nof controllable characteristics ranging from unimodal to highly multimodal,\nsymmetric to highly asymmetric, smooth to highly irregular, and various degrees\nof variable interaction and ill-conditioning.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 03:57:50 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Omidvar", "Mohammad Nabi", ""], ["Yazdani", "Danial", ""], ["Branke", "Juergen", ""], ["Li", "Xiaodong", ""], ["Yang", "Shengxiang", ""], ["Yao", "Xin", ""]]}, {"id": "2107.11201", "submitter": "Sebastien Verel", "authors": "Mathieu Muniglia, S\\'ebastien Verel (LISIC), Jean-Charles Le Pallec,\n  Jean-Michel Do", "title": "A Fitness Landscape View on the Tuning of an Asynchronous Master-Worker\n  EA for Nuclear Reactor Design", "comments": null, "journal-ref": "International Conference on Artificial Evolution (Evolution\n  Artificielle), Oct 2017, Paris, France. pp.30-46", "doi": "10.1007/978-3-319-78133-4_3", "report-no": null, "categories": "eess.SY cs.AI cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of the introduction of intermittent renewable energies, we\npropose to optimize the main variables of the control rods of a nuclear power\nplant to improve its capability to load-follow. The design problem is a\nblack-box combinatorial optimization problem with expensive evaluation based on\na multi-physics simulator. Therefore, we use a parallel asynchronous\nmaster-worker Evolutionary Algorithm scaling up to thousand computing units.\nOne main issue is the tuning of the algorithm parameters. A fitness landscape\nanalysis is conducted on this expensive real-world problem to show that it\nwould be possible to tune the mutation parameters according to the low-cost\nestimation of the fitness landscape features.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 14:35:25 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Muniglia", "Mathieu", "", "LISIC"], ["Verel", "S\u00e9bastien", "", "LISIC"], ["Pallec", "Jean-Charles Le", ""], ["Do", "Jean-Michel", ""]]}, {"id": "2107.11300", "submitter": "Wilfried Jakob", "authors": "Wilfried Jakob", "title": "Applying Evolutionary Algorithms Successfully: A Guide Gained from\n  Real-world Applications", "comments": null, "journal-ref": null, "doi": "10.5445/IR/1000135763", "report-no": "170", "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Metaheuristics (MHs) in general and Evolutionary Algorithms (EAs) in\nparticular are well known tools for successful optimization of difficult\nproblems. But when is their application meaningful and how does one approach\nsuch a project as a novice? How do you avoid beginner's mistakes or use the\ndesign possibilities of a metaheuristic search as efficiently as possible? This\npaper tries to give answers to these questions based on 30 years of research\nand application of the Evolutionary Algorithm GLEAM and its memetic extension\nHyGLEAM. Most of the experience gathered and discussed here can also be applied\nto the use of other metaheuristics such as ant algorithms or particle swarm\noptimization. This paper addresses users with basic knowledge of MHs in general\nand EAs in particular who want to apply them in an optimization project. For\nthis purpose, a number of questions that arise in the course of such a project\nare addressed. At the end, some non-technical project management issues are\ndiscussed, whose importance for project success is often underestimated.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 15:22:19 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Jakob", "Wilfried", ""]]}, {"id": "2107.11445", "submitter": "Klas Leino", "authors": "Klas Leino, Aymeric Fromherz, Ravi Mangal, Matt Fredrikson, Bryan\n  Parno, Corina P\\u{a}s\\u{a}reanu", "title": "Self-Repairing Neural Networks: Provable Safety for Deep Networks via\n  Dynamic Repair", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are increasingly being deployed in contexts where safety is a\ncritical concern. In this work, we propose a way to construct neural network\nclassifiers that dynamically repair violations of non-relational safety\nconstraints called safe ordering properties. Safe ordering properties relate\nrequirements on the ordering of a network's output indices to conditions on\ntheir input, and are sufficient to express most useful notions of\nnon-relational safety for classifiers. Our approach is based on a novel\nself-repairing layer, which provably yields safe outputs regardless of the\ncharacteristics of its input. We compose this layer with an existing network to\nconstruct a self-repairing network (SR-Net), and show that in addition to\nproviding safe outputs, the SR-Net is guaranteed to preserve the accuracy of\nthe original network. Notably, our approach is independent of the size and\narchitecture of the network being repaired, depending only on the specified\nproperty and the dimension of the network's output; thus it is scalable to\nlarge state-of-the-art networks. We show that our approach can be implemented\nusing vectorized computations that execute efficiently on a GPU, introducing\nrun-time overhead of less than one millisecond on current hardware -- even on\nlarge, widely-used networks containing hundreds of thousands of neurons and\nmillions of parameters.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 20:08:52 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Leino", "Klas", ""], ["Fromherz", "Aymeric", ""], ["Mangal", "Ravi", ""], ["Fredrikson", "Matt", ""], ["Parno", "Bryan", ""], ["P\u0103s\u0103reanu", "Corina", ""]]}, {"id": "2107.11746", "submitter": "Ling Liang", "authors": "Ling Liang, Zheng Qu, Zhaodong Chen, Fengbin Tu, Yujie Wu, Lei Deng,\n  Guoqi Li, Peng Li, Yuan Xie", "title": "H2Learn: High-Efficiency Learning Accelerator for High-Accuracy Spiking\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although spiking neural networks (SNNs) take benefits from the bio-plausible\nneural modeling, the low accuracy under the common local synaptic plasticity\nlearning rules limits their application in many practical tasks. Recently, an\nemerging SNN supervised learning algorithm inspired by backpropagation through\ntime (BPTT) from the domain of artificial neural networks (ANNs) has\nsuccessfully boosted the accuracy of SNNs and helped improve the practicability\nof SNNs. However, current general-purpose processors suffer from low efficiency\nwhen performing BPTT for SNNs due to the ANN-tailored optimization. On the\nother hand, current neuromorphic chips cannot support BPTT because they mainly\nadopt local synaptic plasticity rules for simplified implementation.\n  In this work, we propose H2Learn, a novel architecture that can achieve high\nefficiency for BPTT-based SNN learning which ensures high accuracy of SNNs. At\nthe beginning, we characterized the behaviors of BPTT-based SNN learning.\nBenefited from the binary spike-based computation in the forward pass and the\nweight update, we first design lookup table (LUT) based processing elements in\nForward Engine and Weight Update Engine to make accumulations implicit and to\nfuse the computations of multiple input points. Second, benefited from the rich\nsparsity in the backward pass, we design a dual-sparsity-aware Backward Engine\nwhich exploits both input and output sparsity. Finally, we apply a pipeline\noptimization between different engines to build an end-to-end solution for the\nBPTT-based SNN learning. Compared with the modern NVIDIA V100 GPU, H2Learn\nachieves 7.38x area saving, 5.74-10.20x speedup, and 5.25-7.12x energy saving\non several benchmark datasets.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 07:37:17 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Liang", "Ling", ""], ["Qu", "Zheng", ""], ["Chen", "Zhaodong", ""], ["Tu", "Fengbin", ""], ["Wu", "Yujie", ""], ["Deng", "Lei", ""], ["Li", "Guoqi", ""], ["Li", "Peng", ""], ["Xie", "Yuan", ""]]}, {"id": "2107.11844", "submitter": "Jagdish Chand Bansal Ph.D.", "authors": "Susheel Kumar Joshi, Jagdish Chand Bansal", "title": "A binary variant of gravitational search algorithm and its application\n  to windfarm layout optimization problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the binary search space, GSA framework encounters the shortcomings of\nstagnation, diversity loss, premature convergence and high time complexity. To\naddress these issues, a novel binary variant of GSA called `A novel\nneighbourhood archives embedded gravitational constant in GSA for binary search\nspace (BNAGGSA)' is proposed in this paper. In BNAGGSA, the novel\nfitness-distance based social interaction strategy produces a self-adaptive\nstep size mechanism through which the agent moves towards the optimal direction\nwith the optimal step size, as per its current search requirement. The\nperformance of the proposed algorithm is compared with the two binary variants\nof GSA over 23 well-known benchmark test problems. The experimental results and\nstatistical analyses prove the supremacy of BNAGGSA over the compared\nalgorithms. Furthermore, to check the applicability of the proposed algorithm\nin solving real-world applications, a windfarm layout optimization problem is\nconsidered. Two case studies with two different wind data sets of two different\nwind sites is considered for experiments.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 16:56:19 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Joshi", "Susheel Kumar", ""], ["Bansal", "Jagdish Chand", ""]]}, {"id": "2107.11979", "submitter": "Gourav Datta", "authors": "Gourav Datta, Souvik Kundu, Akhilesh R. Jaiswal, Peter A. Beerel", "title": "HYPER-SNN: Towards Energy-efficient Quantized Deep Spiking Neural\n  Networks for Hyperspectral Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hyper spectral images (HSI) provide rich spectral and spatial information\nacross a series of contiguous spectral bands. However, the accurate processing\nof the spectral and spatial correlation between the bands requires the use of\nenergy-expensive 3-D Convolutional Neural Networks (CNNs). To address this\nchallenge, we propose the use of Spiking Neural Networks (SNNs) that are\ngenerated from iso-architecture CNNs and trained with quantization-aware\ngradient descent to optimize their weights, membrane leak, and firing\nthresholds. During both training and inference, the analog pixel values of a\nHSI are directly applied to the input layer of the SNN without the need to\nconvert to a spike-train. The reduced latency of our training technique\ncombined with high activation sparsity yields significant improvements in\ncomputational efficiency. We evaluate our proposal using three HSI datasets on\na 3-D and a 3-D/2-D hybrid convolutional architecture. We achieve overall\naccuracy, average accuracy, and kappa coefficient of 98.68%, 98.34%, and 98.20%\nrespectively with 5 time steps (inference latency) and 6-bit weight\nquantization on the Indian Pines dataset. In particular, our models achieved\naccuracies similar to state-of-the-art (SOTA) with 560.6 and 44.8 times less\ncompute energy on average over three HSI datasets than an iso-architecture\nfull-precision and 6-bit quantized CNN, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 06:17:10 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 06:17:55 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Datta", "Gourav", ""], ["Kundu", "Souvik", ""], ["Jaiswal", "Akhilesh R.", ""], ["Beerel", "Peter A.", ""]]}, {"id": "2107.12053", "submitter": "Tomohiro Harada", "authors": "Tomohiro Harada", "title": "A Frequency-based Parent Selection for Reducing the Effect of Evaluation\n  Time Bias in Asynchronous Parallel Multi-objective Evolutionary Algorithms", "comments": "18 pages, submitted to Neural Computing and Applications and under\n  review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a new parent selection method for reducing the effect of\nevaluation time bias in asynchronous parallel evolutionary algorithms (APEAs).\nAPEAs have the advantage of increasing computational efficiency even when the\nevaluation times of solutions differ. However, APEAs have a problem that their\nsearch direction is biased toward the search region with a short evaluation\ntime. The proposed parent selection method considers the search frequency of\nsolutions to reduce such an adverse influence of APEAs while maintaining their\ncomputational efficiency. We conduct experiments on toy problems that reproduce\nthe evaluation time bias on multi-objective optimization problems to\ninvestigate the effectiveness of the proposed method. The experiments use\nNSGA-III, a well-known multi-objective evolutionary algorithm. In the\nexperiments, we compare the proposed method with the synchronous and\nasynchronous methods. The experimental results reveal that the proposed method\ncan reduce the effect of the evaluation time bias while reducing the computing\ntime of the parallel NSGA-III.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:20:55 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Harada", "Tomohiro", ""]]}, {"id": "2107.12165", "submitter": "Ricardo Cardona Rivera", "authors": "Ricardo Cardona-Rivera, Francesco Lo Iudice, Antonio Grotta, Marco\n  Coraggio, Mario di Bernardo", "title": "Utilizing synchronization to partition power networks into microgrids", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of partitioning a power grid into a set of microgrids, or\nislands, is of interest for both the design of future smart grids, and as a\nlast resort to restore power dispatchment in sections of a grid affected by an\nextreme failure. In the literature this problem is usually solved by turning it\ninto a combinatorial optimization problem, often solved through generic\nheruristic methods such as Genetic Algorithms or Tabu Search. In this paper, we\ntake a different route and obtain the grid partition by exploiting the\nsynchronization dynamics of a cyberlayer of Kuramoto oscillators, each\nparameterized as a rough approximation of the dynamics of the grid's node it\ncorresponds to. We present first a centralised algorithm and then a\ndecentralised strategy. In the former, nodes are aggregated based on their\ninternode synchronization times while in the latter they exploit\nsynchronization of the oscillators in the cyber layer to selforganise into\nislands. Our preliminary results show that the heuristic synchronization based\nalgorithms do converge towards partitions that are comparable to those obtained\nvia other more cumbersome and computationally expensive optimization-based\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 12:32:11 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Cardona-Rivera", "Ricardo", ""], ["Iudice", "Francesco Lo", ""], ["Grotta", "Antonio", ""], ["Coraggio", "Marco", ""], ["di Bernardo", "Mario", ""]]}, {"id": "2107.12243", "submitter": "Licheng Zong", "authors": "Junkang Wei, Siyuan Chen, Licheng Zong, Xin Gao, Yu Li", "title": "Protein-RNA interaction prediction with deep learning: Structure matters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Protein-RNA interactions are of vital importance to a variety of cellular\nactivities. Both experimental and computational techniques have been developed\nto study the interactions. Due to the limitation of the previous database,\nespecially the lack of protein structure data, most of the existing\ncomputational methods rely heavily on the sequence data, with only a small\nportion of the methods utilizing the structural information. Recently,\nAlphaFold has revolutionized the entire protein and biology field. Foreseeably,\nthe protein-RNA interaction prediction will also be promoted significantly in\nthe upcoming years. In this work, we give a thorough review of this field,\nsurveying both the binding site and binding preference prediction problems and\ncovering the commonly used datasets, features, and models. We also point out\nthe potential challenges and opportunities in this field. This survey\nsummarizes the development of the RBP-RNA interaction field in the past and\nforesees its future development in the post-AlphaFold era.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 14:43:36 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Wei", "Junkang", ""], ["Chen", "Siyuan", ""], ["Zong", "Licheng", ""], ["Gao", "Xin", ""], ["Li", "Yu", ""]]}, {"id": "2107.12374", "submitter": "Gourav Datta", "authors": "Gourav Datta, Souvik Kundu, Peter A. Beerel", "title": "Training Energy-Efficient Deep Spiking Neural Networks with Single-Spike\n  Hybrid Input Encoding", "comments": "arXiv admin note: text overlap with arXiv:2107.11979", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spiking Neural Networks (SNNs) have emerged as an attractive alternative to\ntraditional deep learning frameworks, since they provide higher computational\nefficiency in event driven neuromorphic hardware. However, the state-of-the-art\n(SOTA) SNNs suffer from high inference latency, resulting from inefficient\ninput encoding and training techniques. The most widely used input coding\nschemes, such as Poisson based rate-coding, do not leverage the temporal\nlearning capabilities of SNNs. This paper presents a training framework for\nlow-latency energy-efficient SNNs that uses a hybrid encoding scheme at the\ninput layer in which the analog pixel values of an image are directly applied\nduring the first timestep and a novel variant of spike temporal coding is used\nduring subsequent timesteps. In particular, neurons in every hidden layer are\nrestricted to fire at most once per image which increases activation sparsity.\nTo train these hybrid-encoded SNNs, we propose a variant of the gradient\ndescent based spike timing dependent back propagation (STDB) mechanism using a\nnovel cross entropy loss function based on both the output neurons' spike time\nand membrane potential. The resulting SNNs have reduced latency and high\nactivation sparsity, yielding significant improvements in computational\nefficiency. In particular, we evaluate our proposed training scheme on image\nclassification tasks from CIFAR-10 and CIFAR-100 datasets on several VGG\narchitectures. We achieve top-1 accuracy of $66.46$\\% with $5$ timesteps on the\nCIFAR-100 dataset with ${\\sim}125\\times$ less compute energy than an equivalent\nstandard ANN. Additionally, our proposed SNN performs $5$-$300\\times$ faster\ninference compared to other state-of-the-art rate or temporally coded SNN\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 06:16:40 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Datta", "Gourav", ""], ["Kundu", "Souvik", ""], ["Beerel", "Peter A.", ""]]}, {"id": "2107.12445", "submitter": "Souvik Kundu", "authors": "Souvik Kundu, Gourav Datta, Massoud Pedram, Peter A. Beerel", "title": "Towards Low-Latency Energy-Efficient Deep SNNs via Attention-Guided\n  Compression", "comments": "10 Pages, 8 Figures, 5 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep spiking neural networks (SNNs) have emerged as a potential alternative\nto traditional deep learning frameworks, due to their promise to provide\nincreased compute efficiency on event-driven neuromorphic hardware. However, to\nperform well on complex vision applications, most SNN training frameworks yield\nlarge inference latency which translates to increased spike activity and\nreduced energy efficiency. Hence,minimizing average spike activity while\npreserving accuracy indeep SNNs remains a significant challenge and\nopportunity.This paper presents a non-iterative SNN training technique\nthatachieves ultra-high compression with reduced spiking activitywhile\nmaintaining high inference accuracy. In particular, our framework first uses\nthe attention-maps of an un compressed meta-model to yield compressed ANNs.\nThis step can be tuned to support both irregular and structured channel pruning\nto leverage computational benefits over a broad range of platforms. The\nframework then performs sparse-learning-based supervised SNN training using\ndirect inputs. During the training, it jointly optimizes the SNN weight,\nthreshold, and leak parameters to drastically minimize the number of time steps\nrequired while retaining compression. To evaluate the merits of our approach,\nwe performed experiments with variants of VGG and ResNet, on both CIFAR-10 and\nCIFAR-100, and VGG16 on Tiny-ImageNet.The SNN models generated through the\nproposed technique yield SOTA compression ratios of up to 33.4x with no\nsignificant drops in accuracy compared to baseline unpruned counterparts.\nCompared to existing SNN pruning methods, we achieve up to 8.3x higher\ncompression with improved accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 18:23:36 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kundu", "Souvik", ""], ["Datta", "Gourav", ""], ["Pedram", "Massoud", ""], ["Beerel", "Peter A.", ""]]}, {"id": "2107.12521", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Ali Ghodsi, Fakhri Karray, Mark Crowley", "title": "Restricted Boltzmann Machine and Deep Belief Network: Tutorial and\n  Survey", "comments": "To appear as a part of an upcoming textbook on dimensionality\n  reduction and manifold learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a tutorial and survey paper on Boltzmann Machine (BM), Restricted\nBoltzmann Machine (RBM), and Deep Belief Network (DBN). We start with the\nrequired background on probabilistic graphical models, Markov random field,\nGibbs sampling, statistical physics, Ising model, and the Hopfield network.\nThen, we introduce the structures of BM and RBM. The conditional distributions\nof visible and hidden variables, Gibbs sampling in RBM for generating\nvariables, training BM and RBM by maximum likelihood estimation, and\ncontrastive divergence are explained. Then, we discuss different possible\ndiscrete and continuous distributions for the variables. We introduce\nconditional RBM and how it is trained. Finally, we explain deep belief network\nas a stack of RBM models. This paper on Boltzmann machines can be useful in\nvarious fields including data science, statistics, neural computation, and\nstatistical physics.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 23:59:12 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Ghodsi", "Ali", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "2107.12677", "submitter": "\\'Angel Gonz\\'alez-Prieto Dr.", "authors": "Jes\\'us Bobadilla, Fernando Ortega, Abraham Guti\\'errez, \\'Angel\n  Gonz\\'alez-Prieto", "title": "Deep Variational Models for Collaborative Filtering-based Recommender\n  Systems", "comments": "14 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning provides accurate collaborative filtering models to improve\nrecommender system results. Deep matrix factorization and their related\ncollaborative neural networks are the state-of-art in the field; nevertheless,\nboth models lack the necessary stochasticity to create the robust, continuous,\nand structured latent spaces that variational autoencoders exhibit. On the\nother hand, data augmentation through variational autoencoder does not provide\naccurate results in the collaborative filtering field due to the high sparsity\nof recommender systems. Our proposed models apply the variational concept to\ninject stochasticity in the latent space of the deep architecture, introducing\nthe variational technique in the neural collaborative filtering field. This\nmethod does not depend on the particular model used to generate the latent\nrepresentation. In this way, this approach can be applied as a plugin to any\ncurrent and future specific models. The proposed models have been tested using\nfour representative open datasets, three different quality measures, and\nstate-of-art baselines. The results show the superiority of the proposed\napproach in scenarios where the variational enrichment exceeds the injected\nnoise effect. Additionally, a framework is provided to enable the\nreproducibility of the conducted experiments.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 08:59:39 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Bobadilla", "Jes\u00fas", ""], ["Ortega", "Fernando", ""], ["Guti\u00e9rrez", "Abraham", ""], ["Gonz\u00e1lez-Prieto", "\u00c1ngel", ""]]}, {"id": "2107.12917", "submitter": "Julian Stier", "authors": "Julian Stier, Harshil Darji, Michael Granitzer", "title": "Experiments on Properties of Hidden Structures of Sparse Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity in the structure of Neural Networks can lead to less energy\nconsumption, less memory usage, faster computation times on convenient\nhardware, and automated machine learning. If sparsity gives rise to certain\nkinds of structure, it can explain automatically obtained features during\nlearning.\n  We provide insights into experiments in which we show how sparsity can be\nachieved through prior initialization, pruning, and during learning, and answer\nquestions on the relationship between the structure of Neural Networks and\ntheir performance. This includes the first work of inducing priors from network\ntheory into Recurrent Neural Networks and an architectural performance\nprediction during a Neural Architecture Search. Within our experiments, we show\nhow magnitude class blinded pruning achieves 97.5% on MNIST with 80%\ncompression and re-training, which is 0.5 points more than without compression,\nthat magnitude class uniform pruning is significantly inferior to it and how a\ngenetic search enhanced with performance prediction achieves 82.4% on CIFAR10.\nFurther, performance prediction for Recurrent Networks learning the Reber\ngrammar shows an $R^2$ of up to 0.81 given only structural information.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 16:18:13 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Stier", "Julian", ""], ["Darji", "Harshil", ""], ["Granitzer", "Michael", ""]]}, {"id": "2107.12979", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge, Anil Seth, Christopher L Buckley", "title": "Predictive Coding: a Theoretical and Experimental Review", "comments": "27/07/21 initial upload", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive coding offers a potentially unifying account of cortical function\n-- postulating that the core function of the brain is to minimize prediction\nerrors with respect to a generative model of the world. The theory is closely\nrelated to the Bayesian brain framework and, over the last two decades, has\ngained substantial influence in the fields of theoretical and cognitive\nneuroscience. A large body of research has arisen based on both empirically\ntesting improved and extended theoretical and mathematical models of predictive\ncoding, as well as in evaluating their potential biological plausibility for\nimplementation in the brain and the concrete neurophysiological and\npsychological predictions made by the theory. Despite this enduring popularity,\nhowever, no comprehensive review of predictive coding theory, and especially of\nrecent developments in this field, exists. Here, we provide a comprehensive\nreview both of the core mathematical structure and logic of predictive coding,\nthus complementing recent tutorials in the literature. We also review a wide\nrange of classic and recent work within the framework, ranging from the\nneurobiologically realistic microcircuits that could implement predictive\ncoding, to the close relationship between predictive coding and the widely-used\nbackpropagation of error algorithm, as well as surveying the close\nrelationships between predictive coding and modern machine learning techniques.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:44:21 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Millidge", "Beren", ""], ["Seth", "Anil", ""], ["Buckley", "Christopher L", ""]]}, {"id": "2107.13057", "submitter": "James Aimone", "authors": "J. Darby Smith, Aaron J. Hill, Leah E. Reeder, Brian C. Franke,\n  Richard B. Lehoucq, Ojas Parekh, William Severa, James B. Aimone", "title": "Neuromorphic scaling advantages for energy-efficient random walk\n  computation", "comments": "Paper, figures, supplement", "journal-ref": null, "doi": null, "report-no": "SAND2021-9085 O", "categories": "cs.NE cs.DC cs.NA math.NA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing stands to be radically improved by neuromorphic computing (NMC)\napproaches inspired by the brain's incredible efficiency and capabilities. Most\nNMC research, which aims to replicate the brain's computational structure and\narchitecture in man-made hardware, has focused on artificial intelligence;\nhowever, less explored is whether this brain-inspired hardware can provide\nvalue beyond cognitive tasks. We demonstrate that high-degree parallelism and\nconfigurability of spiking neuromorphic architectures makes them well-suited to\nimplement random walks via discrete time Markov chains. Such random walks are\nuseful in Monte Carlo methods, which represent a fundamental computational tool\nfor solving a wide range of numerical computing tasks. Additionally, we show\nhow the mathematical basis for a probabilistic solution involving a class of\nstochastic differential equations can leverage those simulations to provide\nsolutions for a range of broadly applicable computational tasks. Despite being\nin an early development stage, we find that NMC platforms, at a sufficient\nscale, can drastically reduce the energy demands of high-performance computing\n(HPC) platforms.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 19:44:33 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Smith", "J. Darby", ""], ["Hill", "Aaron J.", ""], ["Reeder", "Leah E.", ""], ["Franke", "Brian C.", ""], ["Lehoucq", "Richard B.", ""], ["Parekh", "Ojas", ""], ["Severa", "William", ""], ["Aimone", "James B.", ""]]}, {"id": "2107.13106", "submitter": "Marko {\\DJ}urasevi\\'c", "authors": "Marko {\\DJ}urasevi\\'c, Domagoj Jakobovi\\'c", "title": "Heuristic and Metaheuristic Methods for the Unrelated Machines\n  Scheduling Problem: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Today scheduling problems have an immense effect on various areas of human\nlives, be it from their application in manufacturing and production industry,\ntransportation, or workforce allocation. The unrelated parallel machines\nscheduling problem (UPMSP), which is only one of the many different problem\ntypes that exist, found its application in many areas like production\nindustries or distributed computing. Due to the complexity of the problem,\nheuristic and metaheuristic methods are gaining more attention for solving it.\nAlthough this problem variant did not receive much attention as other models,\nrecent years saw the increase of research dealing with this problem. During\nthat time, many different problem variants, solution methods, or other\ninteresting research directions were considered. However, no study has until\nnow tried to systematise the research in which heuristic methods are applied\nfor the UPMSP. The goal of this study is to provide an extensive literature\nreview on the application of heuristic and metaheuristic methods for solving\nthe UPMSP. The research was systematised and classified into several categories\nto enable an easy overview of the different problem and solution variants.\nAdditionally, current trends and possible future research directions are also\nshortly outlined.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 23:42:44 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["\u0110urasevi\u0107", "Marko", ""], ["Jakobovi\u0107", "Domagoj", ""]]}, {"id": "2107.13153", "submitter": "Yuqiao Liu", "authors": "Yuqiao Liu, Yehui Tang, Yanan Sun", "title": "Homogeneous Architecture Augmentation for Neural Predictor", "comments": "This paper has been accepted by ICCV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) can automatically design well-performed\narchitectures of Deep Neural Networks (DNNs) for the tasks at hand. However,\none bottleneck of NAS is the prohibitively computational cost largely due to\nthe expensive performance evaluation. The neural predictors can directly\nestimate the performance without any training of the DNNs to be evaluated, thus\nhave drawn increasing attention from researchers. Despite their popularity,\nthey also suffer a severe limitation: the shortage of annotated DNN\narchitectures for effectively training the neural predictors. In this paper, we\nproposed Homogeneous Architecture Augmentation for Neural Predictor (HAAP) of\nDNN architectures to address the issue aforementioned. Specifically, a\nhomogeneous architecture augmentation algorithm is proposed in HAAP to generate\nsufficient training data taking the use of homogeneous representation.\nFurthermore, the one-hot encoding strategy is introduced into HAAP to make the\nrepresentation of DNN architectures more effective. The experiments have been\nconducted on both NAS-Benchmark-101 and NAS-Bench-201 dataset. The experimental\nresults demonstrate that the proposed HAAP algorithm outperforms the state of\nthe arts compared, yet with much less training data. In addition, the ablation\nstudies on both benchmark datasets have also shown the universality of the\nhomogeneous architecture augmentation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 03:46:33 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Liu", "Yuqiao", ""], ["Tang", "Yehui", ""], ["Sun", "Yanan", ""]]}, {"id": "2107.13313", "submitter": "Marko {\\DJ}urasevi\\'c", "authors": "Mrko {\\DJ}urasevi\\'c, Mateja {\\DJ}umi\\'c", "title": "Automated Design of Heuristics for the Container Relocation Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The container relocation problem is a challenging combinatorial optimisation\nproblem tasked with finding a sequence of container relocations required to\nretrieve all containers by a given order. Due to the complexity of this\nproblem, heuristic methods are often applied to obtain acceptable solutions in\na small amount of time. These include relocation rules (RRs) that determine the\nrelocation moves that need to be performed to efficiently retrieve the next\ncontainer based on certain yard properties. Such rules are often designed\nmanually by domain experts, which is a time-consuming and challenging task.\nThis paper investigates the application of genetic programming (GP) to design\neffective RRs automatically. The experimental results show that GP evolved RRs\noutperform several existing manually designed RRs. Additional analyses of the\nproposed approach demonstrate that the evolved rules generalise well across a\nwide range of unseen problems and that their performance can be further\nenhanced. Therefore, the proposed method presents a viable alternative to\nexisting manually designed RRs and opens a new research direction in the area\nof container relocation problems.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 12:20:02 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["\u0110urasevi\u0107", "Mrko", ""], ["\u0110umi\u0107", "Mateja", ""]]}, {"id": "2107.13473", "submitter": "Nicolas Valenchon", "authors": "Nicolas Valenchon, Yann Bouteiller, Hugo R. Jourde, Emily B.J. Coffey\n  and Giovanni Beltrame", "title": "The Portiloop: a deep learning-based open science tool for closed-loop\n  brain stimulation", "comments": "12 pages, 13 Figures, journal paper. Open source code at\n  https://github.com/mistlab/portiloop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electroencephalography (EEG) is a method of measuring the brain's electrical\nactivity, using non-invasive scalp electrodes. In this article, we propose the\nPortiloop, a deep learning-based portable and low-cost device enabling the\nneuroscience community to capture EEG, process it in real time, detect patterns\nof interest, and respond with precisely-timed stimulation. The core of the\nPortiloop is a System on Chip composed of an Analog to Digital Converter (ADC)\nand a Field-Programmable Gate Array (FPGA). After being converted to digital by\nthe ADC, the EEG signal is processed in the FPGA. The FPGA contains an ad-hoc\nArtificial Neural Network (ANN) with convolutional and recurrent units,\ndirectly implemented in hardware. The output of the ANN is then used to trigger\nthe user-defined feedback. We use the Portiloop to develop a real-time sleep\nspindle stimulating application, as a case study. Sleep spindles are a specific\ntype of transient oscillation ($\\sim$2.5 s, 12-16 Hz) that are observed in EEG\nrecordings, and are related to memory consolidation during sleep. We tested the\nPortiloop's capacity to detect and stimulate sleep spindles in real time using\nan existing database of EEG sleep recordings. With 71% for both precision and\nrecall as compared with expert labels, the system is able to stimulate spindles\nwithin $\\sim$300 ms of their onset, enabling experimental manipulation of early\nthe entire spindle. The Portiloop can be extended to detect and stimulate other\nneural events in EEG. It is fully available to the research community as an\nopen science project.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:29:58 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Valenchon", "Nicolas", ""], ["Bouteiller", "Yann", ""], ["Jourde", "Hugo R.", ""], ["Coffey", "Emily B. J.", ""], ["Beltrame", "Giovanni", ""]]}, {"id": "2107.13616", "submitter": "Brian Hutchinson", "authors": "Piper Wolters, Chris Daw, Brian Hutchinson, Lauren Phillips", "title": "Proposal-based Few-shot Sound Event Detection for Speech and\n  Environmental Sounds with Perceivers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many important applications for detecting and localizing specific\nsound events within long, untrimmed documents including keyword spotting,\nmedical observation, and bioacoustic monitoring for conservation. Deep learning\ntechniques often set the state-of-the-art for these tasks. However, for some\ntypes of events, there is insufficient labeled data to train deep learning\nmodels. In this paper, we propose novel approaches to few-shot sound event\ndetection utilizing region proposals and the Perceiver architecture, which is\ncapable of accurately localizing sound events with very few examples of each\nclass of interest. Motivated by a lack of suitable benchmark datasets for\nfew-shot audio event detection, we generate and evaluate on two novel episodic\nrare sound event datasets: one using clips of celebrity speech as the sound\nevent, and the other using environmental sounds. Our highest performing\nproposed few-shot approaches achieve 0.575 and 0.672 F1-score, respectively,\nwith 5-shot 5-way tasks on these two datasets. These represent absolute\nimprovements of 0.200 and 0.234 over strong proposal-free few-shot sound event\ndetection baselines.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 19:46:55 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Wolters", "Piper", ""], ["Daw", "Chris", ""], ["Hutchinson", "Brian", ""], ["Phillips", "Lauren", ""]]}, {"id": "2107.13617", "submitter": "Carlos Lordelo", "authors": "Carlos Lordelo, Emmanouil Benetos, Simon Dixon and Sven Ahlb\\\"ack", "title": "Pitch-Informed Instrument Assignment Using a Deep Convolutional Network\n  with Multiple Kernel Shapes", "comments": "4 figures, 4 tables and 7 pages. Accepted for publication at ISMIR\n  Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG cs.NE eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a deep convolutional neural network for performing\nnote-level instrument assignment. Given a polyphonic multi-instrumental music\nsignal along with its ground truth or predicted notes, the objective is to\nassign an instrumental source for each note. This problem is addressed as a\npitch-informed classification task where each note is analysed individually. We\nalso propose to utilise several kernel shapes in the convolutional layers in\norder to facilitate learning of efficient timbre-discriminative feature maps.\nExperiments on the MusicNet dataset using 7 instrument classes show that our\napproach is able to achieve an average F-score of 0.904 when the original\nmulti-pitch annotations are used as the pitch information for the system, and\nthat it also excels if the note information is provided using third-party\nmulti-pitch estimation algorithms. We also include ablation studies\ninvestigating the effects of the use of multiple kernel shapes and comparing\ndifferent input representations for the audio and the note-related information.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 19:48:09 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Lordelo", "Carlos", ""], ["Benetos", "Emmanouil", ""], ["Dixon", "Simon", ""], ["Ahlb\u00e4ck", "Sven", ""]]}, {"id": "2107.13864", "submitter": "Xin-Long Luo", "authors": "Xin-long Luo and Hang Xiao", "title": "Quasi-genetic algorithms and continuation Newton methods with deflation\n  techniques for global optimization problems", "comments": "arXiv admin note: substantial text overlap with arXiv:2103.05829", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The global minimum point of an optimization problem is of interest in\nengineering fields and it is difficult to be found, especially for a nonconvex\noptimization problem. In this article, we consider a quasi-genetic algorithm\nand the continuation Newton method for this problem. Firstly, we use the\ncontinuation Newton method with the deflation technique to find critical points\nof the objective function as many as possible. Then, we use those critical\npoints as the initial evolutionary seeds of the quasi-genetic algorithm. After\nevolving into several generations such as twenty generations, we obtain a\nsuboptimal point of the optimization problem. Finally, we use this suboptimal\npoint as the initial point of the continuation Newton method to obtain the\ncritical point of the original objective function, and output the minimizer\nbetween this final critical point and the suboptimal point of the quasi-genetic\nalgorithm as the global minimum point of the original optimization problem.\nNumerical results show that the proposed method is quite reliable to find the\nglobal optimal point of the unconstrained optimization problem, compared to the\nmulti-start method (the built-in subroutine GlobalSearch.m of the MATLAB R2020a\nenvironment).\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 09:53:49 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Luo", "Xin-long", ""], ["Xiao", "Hang", ""]]}]