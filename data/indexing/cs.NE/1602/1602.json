[{"id": "1602.00172", "submitter": "Patrick O. Glauner", "authors": "Patrick O. Glauner", "title": "Deep Learning For Smile Recognition", "comments": "Proceedings of the 12th Conference on Uncertainty Modelling in\n  Knowledge Engineering and Decision Making (FLINS 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent successes of deep learning in computer vision, we propose\na novel application of deep convolutional neural networks to facial expression\nrecognition, in particular smile recognition. A smile recognition test accuracy\nof 99.45% is achieved for the Denver Intensity of Spontaneous Facial Action\n(DISFA) database, significantly outperforming existing approaches based on\nhand-crafted features with accuracies ranging from 65.55% to 79.67%. The\nnovelty of this approach includes a comprehensive model selection of the\narchitecture parameters, allowing to find an appropriate architecture for each\nexpression such as smile. This is feasible because all experiments were run on\na Tesla K40c GPU, allowing a speedup of factor 10 over traditional computations\non a CPU.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2016 23:59:04 GMT"}, {"version": "v2", "created": "Tue, 25 Jul 2017 04:46:01 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Glauner", "Patrick O.", ""]]}, {"id": "1602.00709", "submitter": "Adenilton Jos\\'e da Silva", "authors": "Adenilton J. da Silva, Teresa B. Ludermir, Wilson R. de Oliveira", "title": "Quantum perceptron over a field and neural network architecture\n  selection in a quantum computer", "comments": null, "journal-ref": "Neural Networks, Volume 76, April 2016, Pages 55-64", "doi": "10.1016/j.neunet.2016.01.002", "report-no": null, "categories": "quant-ph cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a quantum neural network named quantum perceptron\nover a field (QPF). Quantum computers are not yet a reality and the models and\nalgorithms proposed in this work cannot be simulated in actual (or classical)\ncomputers. QPF is a direct generalization of a classical perceptron and solves\nsome drawbacks found in previous models of quantum perceptrons. We also present\na learning algorithm named Superposition based Architecture Learning algorithm\n(SAL) that optimizes the neural network weights and architectures. SAL searches\nfor the best architecture in a finite set of neural network architectures with\nlinear time over the number of patterns in the training set. SAL is the first\nlearning algorithm to determine neural network architectures in polynomial\ntime. This speedup is obtained by the use of quantum parallelism and a\nnon-linear quantum operator.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2016 13:53:42 GMT"}], "update_date": "2016-03-08", "authors_parsed": [["da Silva", "Adenilton J.", ""], ["Ludermir", "Teresa B.", ""], ["de Oliveira", "Wilson R.", ""]]}, {"id": "1602.00991", "submitter": "Peter Ondruska", "authors": "Peter Ondruska and Ingmar Posner", "title": "Deep Tracking: Seeing Beyond Seeing Using Recurrent Neural Networks", "comments": "Published in The Thirtieth AAAI Conference on Artificial Intelligence\n  (AAAI-16), Video: https://youtu.be/cdeWCpfUGWc, Code:\n  http://mrg.robots.ox.ac.uk/mrg_people/peter-ondruska/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents to the best of our knowledge the first end-to-end object\ntracking approach which directly maps from raw sensor input to object tracks in\nsensor space without requiring any feature engineering or system identification\nin the form of plant or sensor models. Specifically, our system accepts a\nstream of raw sensor data at one end and, in real-time, produces an estimate of\nthe entire environment state at the output including even occluded objects. We\nachieve this by framing the problem as a deep learning task and exploit\nsequence models in the form of recurrent neural networks to learn a mapping\nfrom sensor measurements to object tracks. In particular, we propose a learning\nmethod based on a form of input dropout which allows learning in an\nunsupervised manner, only based on raw, occluded sensor data without access to\nground-truth annotations. We demonstrate our approach using a synthetic dataset\ndesigned to mimic the task of tracking objects in 2D laser data -- as commonly\nencountered in robotics applications -- and show that it learns to track many\ndynamic objects despite occlusions and the presence of sensor noise.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 16:10:16 GMT"}, {"version": "v2", "created": "Tue, 8 Mar 2016 22:09:05 GMT"}], "update_date": "2016-03-10", "authors_parsed": [["Ondruska", "Peter", ""], ["Posner", "Ingmar", ""]]}, {"id": "1602.01164", "submitter": "Conrado Miranda", "authors": "Conrado S. Miranda and Fernando J. Von Zuben", "title": "Single-Solution Hypervolume Maximization and its use for Improving\n  Generalization of Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the hypervolume maximization with a single solution as\nan alternative to the mean loss minimization. The relationship between the two\nproblems is proved through bounds on the cost function when an optimal solution\nto one of the problems is evaluated on the other, with a hyperparameter to\ncontrol the similarity between the two problems. This same hyperparameter\nallows higher weight to be placed on samples with higher loss when computing\nthe hypervolume's gradient, whose normalized version can range from the mean\nloss to the max loss. An experiment on MNIST with a neural network is used to\nvalidate the theory developed, showing that the hypervolume maximization can\nbehave similarly to the mean loss minimization and can also provide better\nperformance, resulting on a 20% reduction of the classification error on the\ntest set.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 01:32:01 GMT"}], "update_date": "2016-02-04", "authors_parsed": [["Miranda", "Conrado S.", ""], ["Von Zuben", "Fernando J.", ""]]}, {"id": "1602.01168", "submitter": "Zhuolin Jiang", "authors": "Zhuolin Jiang, Yaming Wang, Larry Davis, Walt Andrews, Viktor Rozgic", "title": "Learning Discriminative Features via Label Consistent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.MM cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Neural Networks (CNN) enforces supervised information only\nat the output layer, and hidden layers are trained by back propagating the\nprediction error from the output layer without explicit supervision. We propose\na supervised feature learning approach, Label Consistent Neural Network, which\nenforces direct supervision in late hidden layers. We associate each neuron in\na hidden layer with a particular class label and encourage it to be activated\nfor input signals from the same class. More specifically, we introduce a label\nconsistency regularization called \"discriminative representation error\" loss\nfor late hidden layers and combine it with classification error loss to build\nour overall objective function. This label consistency constraint alleviates\nthe common problem of gradient vanishing and tends to faster convergence; it\nalso makes the features derived from late hidden layers discriminative enough\nfor classification even using a simple $k$-NN classifier, since input signals\nfrom the same class will have very similar representations. Experimental\nresults demonstrate that our approach achieves state-of-the-art performances on\nseveral public benchmarks for action and object category recognition.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 02:41:33 GMT"}, {"version": "v2", "created": "Sun, 5 Jun 2016 02:45:35 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Jiang", "Zhuolin", ""], ["Wang", "Yaming", ""], ["Davis", "Larry", ""], ["Andrews", "Walt", ""], ["Rozgic", "Viktor", ""]]}, {"id": "1602.01321", "submitter": "Luke Godfrey", "authors": "Luke B. Godfrey, Michael S. Gashler", "title": "A continuum among logarithmic, linear, and exponential functions, and\n  its potential to improve generalization in neural networks", "comments": "6 pages, 8 figures, conference, In Proceedings of Knowledge Discovery\n  and Information Retrieval (KDIR) 2015, Lisbon, Portugal, December 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the soft exponential activation function for artificial neural\nnetworks that continuously interpolates between logarithmic, linear, and\nexponential functions. This activation function is simple, differentiable, and\nparameterized so that it can be trained as the rest of the network is trained.\nWe hypothesize that soft exponential has the potential to improve neural\nnetwork learning, as it can exactly calculate many natural operations that\ntypical neural networks can only approximate, including addition,\nmultiplication, inner product, distance, polynomials, and sinusoids.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 14:46:35 GMT"}], "update_date": "2016-02-04", "authors_parsed": [["Godfrey", "Luke B.", ""], ["Gashler", "Michael S.", ""]]}, {"id": "1602.01510", "submitter": "Priyadarshini Panda", "authors": "Priyadarshini Panda and Kaushik Roy", "title": "Unsupervised Regenerative Learning of Hierarchical Features in Spiking\n  Deep Networks for Object Recognition", "comments": "8 pages, 9 figures, <Under review in IJCNN 2016>", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a spike-based unsupervised regenerative learning scheme to train\nSpiking Deep Networks (SpikeCNN) for object recognition problems using\nbiologically realistic leaky integrate-and-fire neurons. The training\nmethodology is based on the Auto-Encoder learning model wherein the\nhierarchical network is trained layer wise using the encoder-decoder principle.\nRegenerative learning uses spike-timing information and inherent latencies to\nupdate the weights and learn representative levels for each convolutional layer\nin an unsupervised manner. The features learnt from the final layer in the\nhierarchy are then fed to an output layer. The output layer is trained with\nsupervision by showing a fraction of the labeled training dataset and performs\nthe overall classification of the input. Our proposed methodology yields\n0.92%/29.84% classification error on MNIST/CIFAR10 datasets which is comparable\nwith state-of-the-art results. The proposed methodology also introduces\nsparsity in the hierarchical feature representations on account of event-based\ncoding resulting in computationally efficient learning.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 23:51:22 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Panda", "Priyadarshini", ""], ["Roy", "Kaushik", ""]]}, {"id": "1602.01616", "submitter": "Jinhwan Park", "authors": "Jinhwan Park and Wonyong Sung", "title": "FPGA Based Implementation of Deep Neural Networks Using On-chip Memory\n  Only", "comments": "Published in ICASSP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) demand a very large amount of computation and\nweight storage, and thus efficient implementation using special purpose\nhardware is highly desired. In this work, we have developed an FPGA based\nfixed-point DNN system using only on-chip memory not to access external DRAM.\nThe execution time and energy consumption of the developed system is compared\nwith a GPU based implementation. Since the capacity of memory in FPGA is\nlimited, only 3-bit weights are used for this implementation, and training\nbased fixed-point weight optimization is employed. The implementation using\nXilinx XC7Z045 is tested for the MNIST handwritten digit recognition benchmark\nand a phoneme recognition task on TIMIT corpus. The obtained speed is about one\nquarter of a GPU based implementation and much better than that of a PC based\none. The power consumption is less than 5 Watt at the full speed operation\nresulting in much higher efficiency compared to GPU based systems.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 10:16:13 GMT"}, {"version": "v2", "created": "Mon, 29 Aug 2016 06:24:25 GMT"}], "update_date": "2016-08-30", "authors_parsed": [["Park", "Jinhwan", ""], ["Sung", "Wonyong", ""]]}, {"id": "1602.01729", "submitter": "Paul Honeine", "authors": "Fei Zhu, Abderrahim Halimi, Paul Honeine, Badong Chen, Nanning Zheng", "title": "Correntropy Maximization via ADMM - Application to Robust Hyperspectral\n  Unmixing", "comments": "23 pages", "journal-ref": null, "doi": "10.1109/TGRS.2017.2696262", "report-no": null, "categories": "stat.ML cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In hyperspectral images, some spectral bands suffer from low signal-to-noise\nratio due to noisy acquisition and atmospheric effects, thus requiring robust\ntechniques for the unmixing problem. This paper presents a robust supervised\nspectral unmixing approach for hyperspectral images. The robustness is achieved\nby writing the unmixing problem as the maximization of the correntropy\ncriterion subject to the most commonly used constraints. Two unmixing problems\nare derived: the first problem considers the fully-constrained unmixing, with\nboth the non-negativity and sum-to-one constraints, while the second one deals\nwith the non-negativity and the sparsity-promoting of the abundances. The\ncorresponding optimization problems are solved efficiently using an alternating\ndirection method of multipliers (ADMM) approach. Experiments on synthetic and\nreal hyperspectral images validate the performance of the proposed algorithms\nfor different scenarios, demonstrating that the correntropy-based unmixing is\nrobust to outlier bands.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 16:21:09 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Zhu", "Fei", ""], ["Halimi", "Abderrahim", ""], ["Honeine", "Paul", ""], ["Chen", "Badong", ""], ["Zheng", "Nanning", ""]]}, {"id": "1602.02009", "submitter": "Sergei Dytckov", "authors": "Sergei Dytckov and Masoud Daneshtalab", "title": "Computing with hardware neurons: spiking or classical? Perspectives of\n  applied Spiking Neural Networks from the hardware side", "comments": "Withdrawn by the author as the paper is rejected from the target\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While classical neural networks take a position of a leading method in the\nmachine learning community, spiking neuromorphic systems bring attention and\nlarge projects in neuroscience. Spiking neural networks were shown to be able\nto substitute networks of classical neurons in applied tasks. This work\nexplores recent hardware designs focusing on perspective applications (like\nconvolutional neural networks) for both neuron types from the energy efficiency\nside to analyse whether there is a possibility for spiking neuromorphic\nhardware to grow up for a wider use. Our comparison shows that spiking hardware\nis at least on the same level of energy efficiency or even higher than\nnon-spiking on a level of basic operations. However, on a system level, spiking\nsystems are outmatched and consume much more energy due to inefficient data\nrepresentation with a long series of spikes. If spike-driven applications,\nminimizing an amount of spikes, are developed, spiking neural systems may reach\nthe energy efficiency level of classical neural systems. However, in the near\nfuture, both type of neuromorphic systems may benefit from emerging memory\ntechnologies, minimizing the energy consumption of computation and memory for\nboth neuron types. That would make infrastructure and data transfer energy\ndominant on the system level. We expect that spiking neurons have some\nbenefits, which would allow achieving better energy results. Still the problem\nof an amount of spikes will still be the major bottleneck for spiking hardware\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 13:06:44 GMT"}, {"version": "v2", "created": "Wed, 6 Apr 2016 15:39:02 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Dytckov", "Sergei", ""], ["Daneshtalab", "Masoud", ""]]}, {"id": "1602.02218", "submitter": "David Balduzzi", "authors": "David Balduzzi, Muhammad Ghifary", "title": "Strongly-Typed Recurrent Neural Networks", "comments": "10 pages, final version, ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are increasing popular models for sequential\nlearning. Unfortunately, although the most effective RNN architectures are\nperhaps excessively complicated, extensive searches have not found simpler\nalternatives. This paper imports ideas from physics and functional programming\ninto RNN design to provide guiding principles. From physics, we introduce type\nconstraints, analogous to the constraints that forbids adding meters to\nseconds. From functional programming, we require that strongly-typed\narchitectures factorize into stateless learnware and state-dependent firmware,\nreducing the impact of side-effects. The features learned by strongly-typed\nnets have a simple semantic interpretation via dynamic average-pooling on\none-dimensional convolutions. We also show that strongly-typed gradients are\nbetter behaved than in classical architectures, and characterize the\nrepresentational power of strongly-typed nets. Finally, experiments show that,\ndespite being more constrained, strongly-typed architectures achieve lower\ntraining and comparable generalization error to classical architectures.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2016 05:34:03 GMT"}, {"version": "v2", "created": "Tue, 24 May 2016 21:35:23 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Balduzzi", "David", ""], ["Ghifary", "Muhammad", ""]]}, {"id": "1602.02237", "submitter": "Adham Atyabi", "authors": "Adham Atyabi, Martin Luerssena, Sean P. Fitzgibbon, Trent Lewis, David\n  M.W. Powersa", "title": "Reducing training requirements through evolutionary based dimension\n  reduction and subject transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Training Brain Computer Interface (BCI) systems to understand the intention\nof a subject through Electroencephalogram (EEG) data currently requires\nmultiple training sessions with a subject in order to develop the necessary\nexpertise to distinguish signals for different tasks. Conventionally the task\nof training the subject is done by introducing a training and calibration stage\nduring which some feedback is presented to the subject. This training session\ncan take several hours which is not appropriate for on-line EEG-based BCI\nsystems. An alternative approach is to use previous recording sessions of the\nsame person or some other subjects that performed the same tasks (subject\ntransfer) for training the classifiers. The main aim of this study is to\ngenerate a methodology that allows the use of data from other subjects while\nreducing the dimensions of the data. The study investigates several\npossibilities for reducing the necessary training and calibration period in\nsubjects and the classifiers and addresses the impact of i) evolutionary\nsubject transfer and ii) adapting previously trained methods (retraining) using\nother subjects data. Our results suggest reduction to 40% of target subject\ndata is sufficient for training the classifier. Our results also indicate the\nsuperiority of the approaches that incorporated evolutionary subject transfer\nand highlights the feasibility of adapting a system trained on other subjects.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2016 11:12:44 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Atyabi", "Adham", ""], ["Luerssena", "Martin", ""], ["Fitzgibbon", "Sean P.", ""], ["Lewis", "Trent", ""], ["Powersa", "David M. W.", ""]]}, {"id": "1602.02383", "submitter": "William Whitney", "authors": "William Whitney", "title": "Disentangled Representations in Neural Models", "comments": "MIT Master's of Engineering thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning is the foundation for the recent success of neural\nnetwork models. However, the distributed representations generated by neural\nnetworks are far from ideal. Due to their highly entangled nature, they are di\ncult to reuse and interpret, and they do a poor job of capturing the sparsity\nwhich is present in real- world transformations. In this paper, I describe\nmethods for learning disentangled representations in the two domains of\ngraphics and computation. These methods allow neural methods to learn\nrepresentations which are easy to interpret and reuse, yet they incur little or\nno penalty to performance. In the Graphics section, I demonstrate the ability\nof these methods to infer the generating parameters of images and rerender\nthose images under novel conditions. In the Computation section, I describe a\nmodel which is able to factorize a multitask learning problem into subtasks and\nwhich experiences no catastrophic forgetting. Together these techniques provide\nthe tools to design a wide range of models that learn disentangled\nrepresentations and better model the factors of variation in the real world.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2016 15:32:30 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Whitney", "William", ""]]}, {"id": "1602.02505", "submitter": "Itay Hubara", "authors": "Itay Hubara, Daniel Soudry, Ran El Yaniv", "title": "Binarized Neural Networks", "comments": "This is an obsolete version, up to date version is available here:\n  arXiv:1602.02830", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method to train Binarized Neural Networks (BNNs) - neural\nnetworks with binary weights and activations at run-time and when computing the\nparameters' gradient at train-time. We conduct two sets of experiments, each\nbased on a different framework, namely Torch7 and Theano, where we train BNNs\non MNIST, CIFAR-10 and SVHN, and achieve nearly state-of-the-art results.\nDuring the forward pass, BNNs drastically reduce memory size and accesses, and\nreplace most arithmetic operations with bit-wise operations, which might lead\nto a great increase in power-efficiency. Last but not least, we wrote a binary\nmatrix multiplication GPU kernel with which it is possible to run our MNIST BNN\n7 times faster than with an unoptimized GPU kernel, without suffering any loss\nin classification accuracy. The code for training and running our BNNs is\navailable.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 09:37:46 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2016 07:40:57 GMT"}, {"version": "v3", "created": "Thu, 10 Mar 2016 12:37:44 GMT"}], "update_date": "2016-03-11", "authors_parsed": [["Hubara", "Itay", ""], ["Soudry", "Daniel", ""], ["Yaniv", "Ran El", ""]]}, {"id": "1602.02644", "submitter": "Alexey Dosovitskiy", "authors": "Alexey Dosovitskiy and Thomas Brox", "title": "Generating Images with Perceptual Similarity Metrics based on Deep\n  Networks", "comments": "minor corrections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image-generating machine learning models are typically trained with loss\nfunctions based on distance in the image space. This often leads to\nover-smoothed results. We propose a class of loss functions, which we call deep\nperceptual similarity metrics (DeePSiM), that mitigate this problem. Instead of\ncomputing distances in the image space, we compute distances between image\nfeatures extracted by deep neural networks. This metric better reflects\nperceptually similarity of images and thus leads to better results. We show\nthree applications: autoencoder training, a modification of a variational\nautoencoder, and inversion of deep convolutional networks. In all cases, the\ngenerated images look sharp and resemble natural images.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 16:50:28 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2016 09:36:36 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Dosovitskiy", "Alexey", ""], ["Brox", "Thomas", ""]]}, {"id": "1602.02656", "submitter": "Marvin Coto Mr.", "authors": "Marvin Coto-Jim\\'enez, John Goddard-Close", "title": "LSTM Deep Neural Networks Postfiltering for Improving the Quality of\n  Synthetic Voices", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in speech synthesis have produced systems capable of\noutcome intelligible speech, but now researchers strive to create models that\nmore accurately mimic human voices. One such development is the incorporation\nof multiple linguistic styles in various languages and accents.\n  HMM-based Speech Synthesis is of great interest to many researchers, due to\nits ability to produce sophisticated features with small footprint. Despite\nsuch progress, its quality has not yet reached the level of the predominant\nunit-selection approaches that choose and concatenate recordings of real\nspeech. Recent efforts have been made in the direction of improving these\nsystems.\n  In this paper we present the application of Long-Short Term Memory Deep\nNeural Networks as a Postfiltering step of HMM-based speech synthesis, in order\nto obtain closer spectral characteristics to those of natural speech. The\nresults show how HMM-voices could be improved using this approach.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 17:25:22 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Coto-Jim\u00e9nez", "Marvin", ""], ["Goddard-Close", "John", ""]]}, {"id": "1602.02658", "submitter": "Tom Zahavy", "authors": "Tom Zahavy, Nir Ben Zrihem, Shie Mannor", "title": "Graying the black box: Understanding DQNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there is a growing interest in using deep representations for\nreinforcement learning. In this paper, we present a methodology and tools to\nanalyze Deep Q-networks (DQNs) in a non-blind matter. Moreover, we propose a\nnew model, the Semi Aggregated Markov Decision Process (SAMDP), and an\nalgorithm that learns it automatically. The SAMDP model allows us to identify\nspatio-temporal abstractions directly from features and may be used as a\nsub-goal detector in future work. Using our tools we reveal that the features\nlearned by DQNs aggregate the state space in a hierarchical fashion, explaining\nits success. Moreover, we are able to understand and describe the policies\nlearned by DQNs for three different Atari2600 games and suggest ways to\ninterpret, debug and optimize deep neural networks in reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 17:27:31 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2016 16:13:00 GMT"}, {"version": "v3", "created": "Wed, 17 Feb 2016 19:15:55 GMT"}, {"version": "v4", "created": "Mon, 24 Apr 2017 09:57:21 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Zahavy", "Tom", ""], ["Zrihem", "Nir Ben", ""], ["Mannor", "Shie", ""]]}, {"id": "1602.02660", "submitter": "Sander Dieleman", "authors": "Sander Dieleman, Jeffrey De Fauw, Koray Kavukcuoglu", "title": "Exploiting Cyclic Symmetry in Convolutional Neural Networks", "comments": "10 pages, 6 figures, accepted for publication at ICML 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many classes of images exhibit rotational symmetry. Convolutional neural\nnetworks are sometimes trained using data augmentation to exploit this, but\nthey are still required to learn the rotation equivariance properties from the\ndata. Encoding these properties into the network architecture, as we are\nalready used to doing for translation equivariance by using convolutional\nlayers, could result in a more efficient use of the parameter budget by\nrelieving the model from learning them. We introduce four operations which can\nbe inserted into neural network models as layers, and which can be combined to\nmake these models partially equivariant to rotations. They also enable\nparameter sharing across different orientations. We evaluate the effect of\nthese architectural modifications on three datasets which exhibit rotational\nsymmetry and demonstrate improved performance with smaller models.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 17:37:16 GMT"}, {"version": "v2", "created": "Thu, 26 May 2016 11:47:18 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Dieleman", "Sander", ""], ["De Fauw", "Jeffrey", ""], ["Kavukcuoglu", "Koray", ""]]}, {"id": "1602.02685", "submitter": "Cristobal Esteban", "authors": "Crist\\'obal Esteban, Oliver Staeck, Yinchong Yang and Volker Tresp", "title": "Predicting Clinical Events by Combining Static and Dynamic Information\n  Using Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In clinical data sets we often find static information (e.g. patient gender,\nblood type, etc.) combined with sequences of data that are recorded during\nmultiple hospital visits (e.g. medications prescribed, tests performed, etc.).\nRecurrent Neural Networks (RNNs) have proven to be very successful for\nmodelling sequences of data in many areas of Machine Learning. In this work we\npresent an approach based on RNNs, specifically designed for the clinical\ndomain, that combines static and dynamic information in order to predict future\nevents. We work with a database collected in the Charit\\'{e} Hospital in Berlin\nthat contains complete information concerning patients that underwent a kidney\ntransplantation. After the transplantation three main endpoints can occur:\nrejection of the kidney, loss of the kidney and death of the patient. Our goal\nis to predict, based on information recorded in the Electronic Health Record of\neach patient, whether any of those endpoints will occur within the next six or\ntwelve months after each visit to the clinic. We compared different types of\nRNNs that we developed for this work, with a model based on a Feedforward\nNeural Network and a Logistic Regression model. We found that the RNN that we\ndeveloped based on Gated Recurrent Units provides the best performance for this\ntask. We also used the same models for a second task, i.e., next event\nprediction, and found that here the model based on a Feedforward Neural Network\noutperformed the other models. Our hypothesis is that long-term dependencies\nare not as relevant in this task.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 18:30:58 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 11:52:19 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Esteban", "Crist\u00f3bal", ""], ["Staeck", "Oliver", ""], ["Yang", "Yinchong", ""], ["Tresp", "Volker", ""]]}, {"id": "1602.02823", "submitter": "Mark Tygert", "authors": "Mark Tygert", "title": "Poor starting points in machine learning", "comments": "11 pages, 3 figures, 1 table; this initial version is literally\n  identical to that circulated among a restricted audience over a month ago", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Poor (even random) starting points for learning/training/optimization are\ncommon in machine learning. In many settings, the method of Robbins and Monro\n(online stochastic gradient descent) is known to be optimal for good starting\npoints, but may not be optimal for poor starting points -- indeed, for poor\nstarting points Nesterov acceleration can help during the initial iterations,\neven though Nesterov methods not designed for stochastic approximation could\nhurt during later iterations. The common practice of training with nontrivial\nminibatches enhances the advantage of Nesterov acceleration.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 00:14:03 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Tygert", "Mark", ""]]}, {"id": "1602.02862", "submitter": "Shayan Poursoltan Mr", "authors": "Shayan Poursoltan, Frank Neumann", "title": "A Feature-Based Prediction Model of Algorithm Selection for Constrained\n  Continuous Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With this paper, we contribute to the growing research area of feature-based\nanalysis of bio-inspired computing. In this research area, problem instances\nare classified according to different features of the underlying problem in\nterms of their difficulty of being solved by a particular algorithm. We\ninvestigate the impact of different sets of evolved instances for building\nprediction models in the area of algorithm selection. Building on the work of\nPoursoltan and Neumann [11,10], we consider how evolved instances can be used\nto predict the best performing algorithm for constrained continuous\noptimisation from a set of bio-inspired computing methods, namely high\nperforming variants of differential evolution, particle swarm optimization, and\nevolution strategies. Our experimental results show that instances evolved with\na multi-objective approach in combination with random instances of the\nunderlying problem allow to build a model that accurately predicts the best\nperforming algorithm for a wide range of problem instances.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 05:15:24 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Poursoltan", "Shayan", ""], ["Neumann", "Frank", ""]]}, {"id": "1602.02865", "submitter": "Babak Saleh", "authors": "Babak Saleh and Ahmed Elgammal and Jacob Feldman", "title": "The Role of Typicality in Object Classification: Improving The\n  Generalization Capacity of Convolutional Neural Networks", "comments": "In Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep artificial neural networks have made remarkable progress in different\ntasks in the field of computer vision. However, the empirical analysis of these\nmodels and investigation of their failure cases has received attention\nrecently. In this work, we show that deep learning models cannot generalize to\natypical images that are substantially different from training images. This is\nin contrast to the superior generalization ability of the visual system in the\nhuman brain. We focus on Convolutional Neural Networks (CNN) as the\nstate-of-the-art models in object recognition and classification; investigate\nthis problem in more detail, and hypothesize that training CNN models suffer\nfrom unstructured loss minimization. We propose computational models to improve\nthe generalization capacity of CNNs by considering how typical a training image\nlooks like. By conducting an extensive set of experiments we show that\ninvolving a typicality measure can improve the classification results on a new\nset of images by a large margin. More importantly, this significant improvement\nis achieved without fine-tuning the CNN model on the target image set.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 05:30:33 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Saleh", "Babak", ""], ["Elgammal", "Ahmed", ""], ["Feldman", "Jacob", ""]]}, {"id": "1602.02867", "submitter": "Aviv Tamar", "authors": "Aviv Tamar, Yi Wu, Garrett Thomas, Sergey Levine, Pieter Abbeel", "title": "Value Iteration Networks", "comments": "Fixed missing table values", "journal-ref": "Advances in Neural Information Processing Systems 29 pages\n  2154--2162, 2016", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the value iteration network (VIN): a fully differentiable neural\nnetwork with a `planning module' embedded within. VINs can learn to plan, and\nare suitable for predicting outcomes that involve planning-based reasoning,\nsuch as policies for reinforcement learning. Key to our approach is a novel\ndifferentiable approximation of the value-iteration algorithm, which can be\nrepresented as a convolutional neural network, and trained end-to-end using\nstandard backpropagation. We evaluate VIN based policies on discrete and\ncontinuous path-planning domains, and on a natural-language based search task.\nWe show that by learning an explicit planning computation, VIN policies\ngeneralize better to new, unseen domains.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 05:44:36 GMT"}, {"version": "v2", "created": "Sun, 29 May 2016 18:33:04 GMT"}, {"version": "v3", "created": "Sun, 5 Feb 2017 20:06:14 GMT"}, {"version": "v4", "created": "Mon, 20 Mar 2017 21:41:51 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Tamar", "Aviv", ""], ["Wu", "Yi", ""], ["Thomas", "Garrett", ""], ["Levine", "Sergey", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1602.03032", "submitter": "Ivo Danihelka", "authors": "Ivo Danihelka, Greg Wayne, Benigno Uria, Nal Kalchbrenner, Alex Graves", "title": "Associative Long Short-Term Memory", "comments": "ICML-2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a new method to augment recurrent neural networks with extra\nmemory without increasing the number of network parameters. The system has an\nassociative memory based on complex-valued vectors and is closely related to\nHolographic Reduced Representations and Long Short-Term Memory networks.\nHolographic Reduced Representations have limited capacity: as they store more\ninformation, each retrieval becomes noisier due to interference. Our system in\ncontrast creates redundant copies of stored information, which enables\nretrieval with reduced noise. Experiments demonstrate faster learning on\nmultiple memorization tasks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 15:26:26 GMT"}, {"version": "v2", "created": "Thu, 19 May 2016 14:18:19 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Danihelka", "Ivo", ""], ["Wayne", "Greg", ""], ["Uria", "Benigno", ""], ["Kalchbrenner", "Nal", ""], ["Graves", "Alex", ""]]}, {"id": "1602.03616", "submitter": "Anh Nguyen", "authors": "Anh Nguyen, Jason Yosinski, Jeff Clune", "title": "Multifaceted Feature Visualization: Uncovering the Different Types of\n  Features Learned By Each Neuron in Deep Neural Networks", "comments": "23 pages (including SI), 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We can better understand deep neural networks by identifying which features\neach of their neurons have learned to detect. To do so, researchers have\ncreated Deep Visualization techniques including activation maximization, which\nsynthetically generates inputs (e.g. images) that maximally activate each\nneuron. A limitation of current techniques is that they assume each neuron\ndetects only one type of feature, but we know that neurons can be multifaceted,\nin that they fire in response to many different types of features: for example,\na grocery store class neuron must activate either for rows of produce or for a\nstorefront. Previous activation maximization techniques constructed images\nwithout regard for the multiple different facets of a neuron, creating\ninappropriate mixes of colors, parts of objects, scales, orientations, etc.\nHere, we introduce an algorithm that explicitly uncovers the multiple facets of\neach neuron by producing a synthetic visualization of each of the types of\nimages that activate a neuron. We also introduce regularization methods that\nproduce state-of-the-art results in terms of the interpretability of images\nobtained by activation maximization. By separately synthesizing each type of\nimage a neuron fires in response to, the visualizations have more appropriate\ncolors and coherent global structure. Multifaceted feature visualization thus\nprovides a clearer and more comprehensive description of the role of each\nneuron.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 05:10:42 GMT"}, {"version": "v2", "created": "Sat, 7 May 2016 06:30:51 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Nguyen", "Anh", ""], ["Yosinski", "Jason", ""], ["Clune", "Jeff", ""]]}, {"id": "1602.03686", "submitter": "Edward Choi", "authors": "Edward Choi, Andy Schuetz, Walter F. Stewart, Jimeng Sun", "title": "Medical Concept Representation Learning from Electronic Health Records\n  and its Application on Heart Failure Prediction", "comments": "45 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: To transform heterogeneous clinical data from electronic health\nrecords into clinically meaningful constructed features using data driven\nmethod that rely, in part, on temporal relations among data. Materials and\nMethods: The clinically meaningful representations of medical concepts and\npatients are the key for health analytic applications. Most of existing\napproaches directly construct features mapped to raw data (e.g., ICD or CPT\ncodes), or utilize some ontology mapping such as SNOMED codes. However, none of\nthe existing approaches leverage EHR data directly for learning such concept\nrepresentation. We propose a new way to represent heterogeneous medical\nconcepts (e.g., diagnoses, medications and procedures) based on co-occurrence\npatterns in longitudinal electronic health records. The intuition behind the\nmethod is to map medical concepts that are co-occuring closely in time to\nsimilar concept vectors so that their distance will be small. We also derive a\nsimple method to construct patient vectors from the related medical concept\nvectors. Results: For qualitative evaluation, we study similar medical concepts\nacross diagnosis, medication and procedure. In quantitative evaluation, our\nproposed representation significantly improves the predictive modeling\nperformance for onset of heart failure (HF), where classification methods (e.g.\nlogistic regression, neural network, support vector machine and K-nearest\nneighbors) achieve up to 23% improvement in area under the ROC curve (AUC)\nusing this proposed representation. Conclusion: We proposed an effective method\nfor patient and medical concept representation learning. The resulting\nrepresentation can map relevant concepts together and also improves predictive\nmodeling performance.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 12:03:42 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 22:28:50 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Choi", "Edward", ""], ["Schuetz", "Andy", ""], ["Stewart", "Walter F.", ""], ["Sun", "Jimeng", ""]]}, {"id": "1602.04186", "submitter": "Marco Alberto Javarone", "authors": "Marco Alberto Javarone", "title": "An Evolutionary Strategy based on Partial Imitation for Solving\n  Optimization Problems", "comments": "18 pages, 6 figures", "journal-ref": "Physica A: Statistical Mechanics and its Applications, volume 463\n  (2016), pp. 262-269", "doi": "10.1016/j.physa.2016.07.053", "report-no": null, "categories": "cond-mat.dis-nn cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce an evolutionary strategy to solve combinatorial\noptimization tasks, i.e. problems characterized by a discrete search space. In\nparticular, we focus on the Traveling Salesman Problem (TSP), i.e. a famous\nproblem whose search space grows exponentially, increasing the number of\ncities, up to becoming NP-hard. The solutions of the TSP can be codified by\narrays of cities, and can be evaluated by fitness, computed according to a cost\nfunction (e.g. the length of a path). Our method is based on the evolution of\nan agent population by means of an imitative mechanism, we define `partial\nimitation'. In particular, agents receive a random solution and then,\ninteracting among themselves, may imitate the solutions of agents with a higher\nfitness. Since the imitation mechanism is only partial, agents copy only one\nentry (randomly chosen) of another array (i.e. solution). In doing so, the\npopulation converges towards a shared solution, behaving like a spin system\nundergoing a cooling process, i.e. driven towards an ordered phase. We\nhighlight that the adopted `partial imitation' mechanism allows the population\nto generate solutions over time, before reaching the final equilibrium. Results\nof numerical simulations show that our method is able to find, in a finite\ntime, both optimal and suboptimal solutions, depending on the size of the\nconsidered search space.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 19:55:56 GMT"}, {"version": "v2", "created": "Thu, 4 Aug 2016 08:06:43 GMT"}], "update_date": "2016-08-05", "authors_parsed": [["Javarone", "Marco Alberto", ""]]}, {"id": "1602.04278", "submitter": "Taehwan Kim", "authors": "Taehwan Kim, Weiran Wang, Hao Tang, Karen Livescu", "title": "Signer-independent Fingerspelling Recognition with Deep Neural Network\n  Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of recognition of fingerspelled letter sequences in\nAmerican Sign Language in a signer-independent setting. Fingerspelled sequences\nare both challenging and important to recognize, as they are used for many\ncontent words such as proper nouns and technical terms. Previous work has shown\nthat it is possible to achieve almost 90% accuracies on fingerspelling\nrecognition in a signer-dependent setting. However, the more realistic\nsigner-independent setting presents challenges due to significant variations\namong signers, coupled with the dearth of available training data. We\ninvestigate this problem with approaches inspired by automatic speech\nrecognition. We start with the best-performing approaches from prior work,\nbased on tandem models and segmental conditional random fields (SCRFs), with\nfeatures based on deep neural network (DNN) classifiers of letters and\nphonological features. Using DNN adaptation, we find that it is possible to\nbridge a large part of the gap between signer-dependent and signer-independent\nperformance. Using only about 115 transcribed words for adaptation from the\ntarget signer, we obtain letter accuracies of up to 82.7% with frame-level\nadaptation labels and 69.7% with only word labels.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2016 03:30:34 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Kim", "Taehwan", ""], ["Wang", "Weiran", ""], ["Tang", "Hao", ""], ["Livescu", "Karen", ""]]}, {"id": "1602.04335", "submitter": "Hojjat Salehinejad", "authors": "Hojjat Salehinejad", "title": "Learning Over Long Time Lags", "comments": "This is a draft article, in preparation to submit for peer-review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advantage of recurrent neural networks (RNNs) in learning dependencies\nbetween time-series data has distinguished RNNs from other deep learning\nmodels. Recently, many advances are proposed in this emerging field. However,\nthere is a lack of comprehensive review on memory models in RNNs in the\nliterature. This paper provides a fundamental review on RNNs and long short\nterm memory (LSTM) model. Then, provides a surveys of recent advances in\ndifferent memory enhancements and learning techniques for capturing long term\ndependencies in RNNs.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2016 14:09:41 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Salehinejad", "Hojjat", ""]]}, {"id": "1602.04484", "submitter": "Phil Long", "authors": "David P. Helmbold and Philip M. Long", "title": "Surprising properties of dropout in deep networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze dropout in deep networks with rectified linear units and the\nquadratic loss. Our results expose surprising differences between the behavior\nof dropout and more traditional regularizers like weight decay. For example, on\nsome simple data sets dropout training produces negative weights even though\nthe output is the sum of the inputs. This provides a counterpoint to the\nsuggestion that dropout discourages co-adaptation of weights. We also show that\nthe dropout penalty can grow exponentially in the depth of the network while\nthe weight-decay penalty remains essentially linear, and that dropout is\ninsensitive to various re-scalings of the input features, outputs, and network\nweights. This last insensitivity implies that there are no isolated local\nminima of the dropout training criterion. Our work uncovers new properties of\ndropout, extends our understanding of why dropout succeeds, and lays the\nfoundation for further progress.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2016 18:20:29 GMT"}, {"version": "v2", "created": "Sat, 5 Mar 2016 23:00:10 GMT"}, {"version": "v3", "created": "Fri, 27 May 2016 23:24:17 GMT"}, {"version": "v4", "created": "Thu, 3 Nov 2016 16:39:19 GMT"}, {"version": "v5", "created": "Wed, 19 Apr 2017 21:15:15 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Helmbold", "David P.", ""], ["Long", "Philip M.", ""]]}, {"id": "1602.04485", "submitter": "Matus Telgarsky", "authors": "Matus Telgarsky", "title": "Benefits of depth in neural networks", "comments": "To appear, COLT 2016. For a simplified version, see\n  http://arxiv.org/abs/1509.08101", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For any positive integer $k$, there exist neural networks with $\\Theta(k^3)$\nlayers, $\\Theta(1)$ nodes per layer, and $\\Theta(1)$ distinct parameters which\ncan not be approximated by networks with $\\mathcal{O}(k)$ layers unless they\nare exponentially large --- they must possess $\\Omega(2^k)$ nodes. This result\nis proved here for a class of nodes termed \"semi-algebraic gates\" which\nincludes the common choices of ReLU, maximum, indicator, and piecewise\npolynomial functions, therefore establishing benefits of depth against not just\nstandard networks with ReLU gates, but also convolutional networks with ReLU\nand maximization gates, sum-product networks, and boosted decision trees (in\nthis last case with a stronger separation: $\\Omega(2^{k^3})$ total tree nodes\nare required).\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2016 18:36:59 GMT"}, {"version": "v2", "created": "Fri, 27 May 2016 22:11:26 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Telgarsky", "Matus", ""]]}, {"id": "1602.04723", "submitter": "David Jacobs", "authors": "Ronen Basri and David Jacobs", "title": "Efficient Representation of Low-Dimensional Manifolds using Deep\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the ability of deep neural networks to represent data that lies\nnear a low-dimensional manifold in a high-dimensional space. We show that deep\nnetworks can efficiently extract the intrinsic, low-dimensional coordinates of\nsuch data. We first show that the first two layers of a deep network can\nexactly embed points lying on a monotonic chain, a special type of piecewise\nlinear manifold, mapping them to a low-dimensional Euclidean space. Remarkably,\nthe network can do this using an almost optimal number of parameters. We also\nshow that this network projects nearby points onto the manifold and then embeds\nthem with little error. We then extend these results to more general manifolds.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 16:16:56 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Basri", "Ronen", ""], ["Jacobs", "David", ""]]}, {"id": "1602.04742", "submitter": "Oleg Sinyavskiy", "authors": "Oleg Y. Sinyavskiy", "title": "Training of spiking neural networks based on information theoretic costs", "comments": "A doctoral thesis, 111 pages, 55 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural network is a type of artificial neural network in which\nneurons communicate between each other with spikes. Spikes are identical\nBoolean events characterized by the time of their arrival. A spiking neuron has\ninternal dynamics and responds to the history of inputs as opposed to the\ncurrent inputs only. Because of such properties a spiking neural network has\nrich intrinsic capabilities to process spatiotemporal data. However, because\nthe spikes are discontinuous 'yes or no' events, it is not trivial to apply\ntraditional training procedures such as gradient descend to the spiking\nneurons. In this thesis we propose to use stochastic spiking neuron models in\nwhich probability of a spiking output is a continuous function of parameters.\nWe formulate several learning tasks as minimization of certain\ninformation-theoretic cost functions that use spiking output probability\ndistributions. We develop a generalized description of the stochastic spiking\nneuron and a new spiking neuron model that allows to flexibly process rich\nspatiotemporal data. We formulate and derive learning rules for the following\ntasks:\n  - a supervised learning task of detecting a spatiotemporal pattern as a\nminimization of the negative log-likelihood (the surprisal) of the neuron's\noutput\n  - an unsupervised learning task of increasing the stability of neurons output\nas a minimization of the entropy\n  - a reinforcement learning task of controlling an agent as a modulated\noptimization of filtered surprisal of the neuron's output.\n  We test the derived learning rules in several experiments such as\nspatiotemporal pattern detection, spatiotemporal data storing and recall with\nautoassociative memory, combination of supervised and unsupervised learning to\nspeed up the learning process, adaptive control of simple virtual agents in\nchanging environments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 17:21:00 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Sinyavskiy", "Oleg Y.", ""]]}, {"id": "1602.04933", "submitter": "Patrick Kenekayoro Mr", "authors": "Patrick Kenekayoro and Godswill Zipamone", "title": "Greedy Ants Colony Optimization Strategy for Solving the Curriculum\n  Based University Course Timetabling Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Timetabling is a problem faced in all higher education institutions. The\nInternational Timetabling Competition (ITC) has published a dataset that can be\nused to test the quality of methods used to solve this problem. A number of\nmeta-heuristic approaches have obtained good results when tested on the ITC\ndataset, however few have used the ant colony optimization technique,\nparticularly on the ITC 2007 curriculum based university course timetabling\nproblem. This study describes an ant system that solves the curriculum based\nuniversity course timetabling problem and the quality of the algorithm is\ntested on the ITC 2007 dataset. The ant system was able to find feasible\nsolutions in all instances of the dataset and close to optimal solutions in\nsome instances. The ant system performs better than some published approaches,\nhowever results obtained are not as good as those obtained by the best\npublished approaches. This study may be used as a benchmark for ant based\nalgorithms that solve the curriculum based university course timetabling\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 08:02:49 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Kenekayoro", "Patrick", ""], ["Zipamone", "Godswill", ""]]}, {"id": "1602.05925", "submitter": "Scott Purdy", "authors": "Scott Purdy", "title": "Encoding Data for HTM Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hierarchical Temporal Memory (HTM) is a biologically inspired machine\nintelligence technology that mimics the architecture and processes of the\nneocortex. In this white paper we describe how to encode data as Sparse\nDistributed Representations (SDRs) for use in HTM systems. We explain several\nexisting encoders, which are available through the open source project called\nNuPIC, and we discuss requirements for creating encoders for new types of data.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 19:56:39 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Purdy", "Scott", ""]]}, {"id": "1602.05996", "submitter": "Ojash Neopane", "authors": "Ojash Neopane, Srinjoy Das, Ery Arias-Castro, Kenneth Kreutz-Delgado", "title": "A Nonparametric Framework for Quantifying Generative Inference on\n  Neuromorphic Systems", "comments": "Accepted for lecture presentation at ISCAS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann Machines and Deep Belief Networks have been successfully\nused in probabilistic generative model applications such as image occlusion\nremoval, pattern completion and motion synthesis. Generative inference in such\nalgorithms can be performed very efficiently on hardware using a Markov Chain\nMonte Carlo procedure called Gibbs sampling, where stochastic samples are drawn\nfrom noisy integrate and fire neurons implemented on neuromorphic substrates.\nCurrently, no satisfactory metrics exist for evaluating the generative\nperformance of such algorithms implemented on high-dimensional data for\nneuromorphic platforms. This paper demonstrates the application of\nnonparametric goodness-of-fit testing to both quantify the generative\nperformance as well as provide decision-directed criteria for choosing the\nparameters of the neuromorphic Gibbs sampler and optimizing usage of hardware\nresources used during sampling.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 22:47:08 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Neopane", "Ojash", ""], ["Das", "Srinjoy", ""], ["Arias-Castro", "Ery", ""], ["Kreutz-Delgado", "Kenneth", ""]]}, {"id": "1602.06057", "submitter": "Raghavendra Singh", "authors": "Raghavendra Singh", "title": "Uniresolution representations of white-matter data from CoCoMac", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracing data as collated by CoCoMac, a seminal neuroinformatics database, is\nat multiple resolutions -- white matter tracts were studied for areas and their\nsubdivisions by different reports. Network theoretic analysis of this\nmulti-resolution data often assumes that the data at various resolutions is\nequivalent, which may not be correct. In this paper we propose three methods to\nresolve the multi-resolution issue such that the resultant networks have\nconnectivity data at only one resolution. The different resultant networks are\ncompared in terms of their network analysis metrics and degree distributions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2016 07:09:33 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Singh", "Raghavendra", ""]]}, {"id": "1602.06662", "submitter": "Mikael Henaff", "authors": "Mikael Henaff, Arthur Szlam, Yann LeCun", "title": "Recurrent Orthogonal Networks and Long-Memory Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although RNNs have been shown to be powerful tools for processing sequential\ndata, finding architectures or optimization strategies that allow them to model\nvery long term dependencies is still an active area of research. In this work,\nwe carefully analyze two synthetic datasets originally outlined in (Hochreiter\nand Schmidhuber, 1997) which are used to evaluate the ability of RNNs to store\ninformation over many time steps. We explicitly construct RNN solutions to\nthese problems, and using these constructions, illuminate both the problems\nthemselves and the way in which RNNs store different types of information in\ntheir hidden states. These constructions furthermore explain the success of\nrecent methods that specify unitary initializations or constraints on the\ntransition matrices.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 06:51:25 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 17:45:08 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Henaff", "Mikael", ""], ["Szlam", "Arthur", ""], ["LeCun", "Yann", ""]]}, {"id": "1602.06727", "submitter": "Zhizheng Wu", "authors": "Zhizheng Wu, Simon King", "title": "Improving Trajectory Modelling for DNN-based Speech Synthesis by using\n  Stacked Bottleneck Features and Minimum Generation Error Training", "comments": "submitted to IEEE/ACM Transactions on Audio, Speech and Language\n  Processing 2016 (AQ)", "journal-ref": null, "doi": "10.1109/TASLP.2016.2551865", "report-no": null, "categories": "cs.SD cs.CL cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose two novel techniques --- stacking bottleneck features and minimum\ngeneration error training criterion --- to improve the performance of deep\nneural network (DNN)-based speech synthesis. The techniques address the related\nissues of frame-by-frame independence and ignorance of the relationship between\nstatic and dynamic features, within current typical DNN-based synthesis\nframeworks. Stacking bottleneck features, which are an acoustically--informed\nlinguistic representation, provides an efficient way to include more detailed\nlinguistic context at the input. The minimum generation error training\ncriterion minimises overall output trajectory error across an utterance, rather\nthan minimising the error per frame independently, and thus takes into account\nthe interaction between static and dynamic features. The two techniques can be\neasily combined to further improve performance. We present both objective and\nsubjective results that demonstrate the effectiveness of the proposed\ntechniques. The subjective results show that combining the two techniques leads\nto significantly more natural synthetic speech than from conventional DNN or\nlong short-term memory (LSTM) recurrent neural network (RNN) systems.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 11:11:04 GMT"}, {"version": "v2", "created": "Mon, 4 Apr 2016 11:18:07 GMT"}, {"version": "v3", "created": "Tue, 5 Apr 2016 11:31:02 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Wu", "Zhizheng", ""], ["King", "Simon", ""]]}, {"id": "1602.06929", "submitter": "Praneeth Netrapalli", "authors": "Prateek Jain and Chi Jin and Sham M. Kakade and Praneeth Netrapalli\n  and Aaron Sidford", "title": "Streaming PCA: Matching Matrix Bernstein and Near-Optimal Finite Sample\n  Guarantees for Oja's Algorithm", "comments": "Updated title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides improved guarantees for streaming principle component\nanalysis (PCA). Given $A_1, \\ldots, A_n\\in \\mathbb{R}^{d\\times d}$ sampled\nindependently from distributions satisfying $\\mathbb{E}[A_i] = \\Sigma$ for\n$\\Sigma \\succeq \\mathbf{0}$, this work provides an $O(d)$-space linear-time\nsingle-pass streaming algorithm for estimating the top eigenvector of $\\Sigma$.\nThe algorithm nearly matches (and in certain cases improves upon) the accuracy\nobtained by the standard batch method that computes top eigenvector of the\nempirical covariance $\\frac{1}{n} \\sum_{i \\in [n]} A_i$ as analyzed by the\nmatrix Bernstein inequality. Moreover, to achieve constant accuracy, our\nalgorithm improves upon the best previous known sample complexities of\nstreaming algorithms by either a multiplicative factor of $O(d)$ or\n$1/\\mathrm{gap}$ where $\\mathrm{gap}$ is the relative distance between the top\ntwo eigenvalues of $\\Sigma$.\n  These results are achieved through a novel analysis of the classic Oja's\nalgorithm, one of the oldest and most popular algorithms for streaming PCA. In\nparticular, this work shows that simply picking a random initial point $w_0$\nand applying the update rule $w_{i + 1} = w_i + \\eta_i A_i w_i$ suffices to\naccurately estimate the top eigenvector, with a suitable choice of $\\eta_i$. We\nbelieve our result sheds light on how to efficiently perform streaming PCA both\nin theory and in practice and we hope that our analysis may serve as the basis\nfor analyzing many variants and extensions of streaming PCA.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 20:30:37 GMT"}, {"version": "v2", "created": "Mon, 28 Mar 2016 17:45:51 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Jain", "Prateek", ""], ["Jin", "Chi", ""], ["Kakade", "Sham M.", ""], ["Netrapalli", "Praneeth", ""], ["Sidford", "Aaron", ""]]}, {"id": "1602.07031", "submitter": "Mohammad Abu Alsheikh", "authors": "Mohammad Abu Alsheikh, Dusit Niyato, Shaowei Lin, Hwee-Pink Tan, and\n  Zhu Han", "title": "Mobile Big Data Analytics Using Deep Learning and Apache Spark", "comments": null, "journal-ref": "IEEE Network, vol. 30, no. 3, pp. 22-29, June 2016", "doi": "10.1109/MNET.2016.7474340", "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of mobile devices, such as smartphones and Internet of\nThings (IoT) gadgets, results in the recent mobile big data (MBD) era.\nCollecting MBD is unprofitable unless suitable analytics and learning methods\nare utilized for extracting meaningful information and hidden patterns from\ndata. This article presents an overview and brief tutorial of deep learning in\nMBD analytics and discusses a scalable learning framework over Apache Spark.\nSpecifically, a distributed deep learning is executed as an iterative MapReduce\ncomputing on many Spark workers. Each Spark worker learns a partial deep model\non a partition of the overall MBD, and a master deep model is then built by\naveraging the parameters of all partial models. This Spark-based framework\nspeeds up the learning of deep models consisting of many hidden layers and\nmillions of parameters. We use a context-aware activity recognition application\nwith a real-world dataset containing millions of samples to validate our\nframework and assess its speedup effectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 04:32:02 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Alsheikh", "Mohammad Abu", ""], ["Niyato", "Dusit", ""], ["Lin", "Shaowei", ""], ["Tan", "Hwee-Pink", ""], ["Han", "Zhu", ""]]}, {"id": "1602.07373", "submitter": "Song Wang", "authors": "Song Wang, Dongchun Ren, Li Chen, Wei Fan, Jun Sun, Satoshi Naoi", "title": "On Study of the Binarized Deep Neural Network for Image Classification", "comments": "9 pages, 6 figures. Rejected conference (CVPR 2015) submission.\n  Submission date: November, 2014. This work is patented in China (NO.\n  201410647710.3)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the deep neural network (derived from the artificial neural\nnetwork) has attracted many researchers' attention by its outstanding\nperformance. However, since this network requires high-performance GPUs and\nlarge storage, it is very hard to use it on individual devices. In order to\nimprove the deep neural network, many trials have been made by refining the\nnetwork structure or training strategy. Unlike those trials, in this paper, we\nfocused on the basic propagation function of the artificial neural network and\nproposed the binarized deep neural network. This network is a pure binary\nsystem, in which all the values and calculations are binarized. As a result,\nour network can save a lot of computational resource and storage. Therefore, it\nis possible to use it on various devices. Moreover, the experimental results\nproved the feasibility of the proposed network.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 02:39:47 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Wang", "Song", ""], ["Ren", "Dongchun", ""], ["Chen", "Li", ""], ["Fan", "Wei", ""], ["Sun", "Jun", ""], ["Naoi", "Satoshi", ""]]}, {"id": "1602.07383", "submitter": "Weiguang Ding", "authors": "Weiguang Ding, Graham Taylor", "title": "Automatic Moth Detection from Trap Images for Pest Management", "comments": "Preprints accepted by Computers and electronics in agriculture", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring the number of insect pests is a crucial component in\npheromone-based pest management systems. In this paper, we propose an automatic\ndetection pipeline based on deep learning for identifying and counting pests in\nimages taken inside field traps. Applied to a commercial codling moth dataset,\nour method shows promising performance both qualitatively and quantitatively.\nCompared to previous attempts at pest detection, our approach uses no\npest-specific engineering which enables it to adapt to other species and\nenvironments with minimal human effort. It is amenable to implementation on\nparallel hardware and therefore capable of deployment in settings where\nreal-time performance is required.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 03:35:42 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Ding", "Weiguang", ""], ["Taylor", "Graham", ""]]}, {"id": "1602.07393", "submitter": "Zhenhao Ge", "authors": "Zhenhao Ge and Yufang Sun", "title": "Domain Specific Author Attribution Based on Feedforward Neural Network\n  Language Models", "comments": "International Conference on Pattern Recognition Application and\n  Methods (ICPRAM) 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authorship attribution refers to the task of automatically determining the\nauthor based on a given sample of text. It is a problem with a long history and\nhas a wide range of application. Building author profiles using language models\nis one of the most successful methods to automate this task. New language\nmodeling methods based on neural networks alleviate the curse of dimensionality\nand usually outperform conventional N-gram methods. However, there have not\nbeen much research applying them to authorship attribution. In this paper, we\npresent a novel setup of a Neural Network Language Model (NNLM) and apply it to\na database of text samples from different authors. We investigate how the NNLM\nperforms on a task with moderate author set size and relatively limited\ntraining and test data, and how the topics of the text samples affect the\naccuracy. NNLM achieves nearly 2.5% reduction in perplexity, a measurement of\nfitness of a trained language model to the test data. Given 5 random test\nsentences, it also increases the author classification accuracy by 3.43% on\naverage, compared with the N-gram methods using SRILM tools. An open source\nimplementation of our methodology is freely available at\nhttps://github.com/zge/authorship-attribution/.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 04:32:34 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Ge", "Zhenhao", ""], ["Sun", "Yufang", ""]]}, {"id": "1602.07455", "submitter": "Ying-ping Chen", "authors": "Li-An Yang, Jui-Pin Liu, Chao-Hong Chen, Ying-ping Chen", "title": "Automatically Proving Mathematical Theorems with Evolutionary Algorithms\n  and Proof Assistants", "comments": "Accepted by 2016 IEEE Congress on Evolutionary Computation (CEC\n  2016), part of 2016 IEEE World Congress on Computational Intelligence (IEEE\n  WCCI 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical theorems are human knowledge able to be accumulated in the form\nof symbolic representation, and proving theorems has been considered\nintelligent behavior. Based on the BHK interpretation and the Curry-Howard\nisomorphism, proof assistants, software capable of interacting with human for\nconstructing formal proofs, have been developed in the past several decades.\nSince proofs can be considered and expressed as programs, proof assistants\nsimplify and verify a proof by computationally evaluating the program\ncorresponding to the proof. Thanks to the transformation from logic to\ncomputation, it is now possible to generate or search for formal proofs\ndirectly in the realm of computation. Evolutionary algorithms, known to be\nflexible and versatile, have been successfully applied to handle a variety of\nscientific and engineering problems in numerous disciplines for also several\ndecades. Examining the feasibility of establishing the link between\nevolutionary algorithms, as the program generator, and proof assistants, as the\nproof verifier, in order to automatically find formal proofs to a given logic\nsentence is the primary goal of this study. In the article, we describe in\ndetail our first, ad-hoc attempt to fully automatically prove theorems as well\nas the preliminary results. Ten simple theorems from various branches of\nmathematics were proven, and most of these theorems cannot be proven by using\nthe tactic auto alone in Coq, the adopted proof assistant. The implication and\npotential influence of this study are discussed, and the developed source code\nwith the obtained experimental results are released as open source.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 10:19:15 GMT"}, {"version": "v2", "created": "Fri, 15 Apr 2016 09:01:33 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Yang", "Li-An", ""], ["Liu", "Jui-Pin", ""], ["Chen", "Chao-Hong", ""], ["Chen", "Ying-ping", ""]]}, {"id": "1602.07714", "submitter": "Hado van Hasselt", "authors": "Hado van Hasselt and Arthur Guez and Matteo Hessel and Volodymyr Mnih\n  and David Silver", "title": "Learning values across many orders of magnitude", "comments": "Paper accepted for publication at NIPS 2016. This version includes\n  the appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most learning algorithms are not invariant to the scale of the function that\nis being approximated. We propose to adaptively normalize the targets used in\nlearning. This is useful in value-based reinforcement learning, where the\nmagnitude of appropriate value approximations can change over time when we\nupdate the policy of behavior. Our main motivation is prior work on learning to\nplay Atari games, where the rewards were all clipped to a predetermined range.\nThis clipping facilitates learning across many different games with a single\nlearning algorithm, but a clipped reward function can result in qualitatively\ndifferent behavior. Using the adaptive normalization we can remove this\ndomain-specific heuristic without diminishing overall performance.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 21:14:52 GMT"}, {"version": "v2", "created": "Tue, 16 Aug 2016 05:27:17 GMT"}], "update_date": "2016-08-17", "authors_parsed": [["van Hasselt", "Hado", ""], ["Guez", "Arthur", ""], ["Hessel", "Matteo", ""], ["Mnih", "Volodymyr", ""], ["Silver", "David", ""]]}, {"id": "1602.07776", "submitter": "Adhiguna Kuncoro", "authors": "Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, Noah A. Smith", "title": "Recurrent Neural Network Grammars", "comments": "Proceedings of NAACL 2016 (contains corrigendum)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce recurrent neural network grammars, probabilistic models of\nsentences with explicit phrase structure. We explain efficient inference\nprocedures that allow application to both parsing and language modeling.\nExperiments show that they provide better parsing in English than any single\npreviously published supervised generative model and better language modeling\nthan state-of-the-art sequential RNNs in English and Chinese.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 02:42:58 GMT"}, {"version": "v2", "created": "Fri, 1 Apr 2016 23:28:08 GMT"}, {"version": "v3", "created": "Thu, 6 Oct 2016 14:22:02 GMT"}, {"version": "v4", "created": "Wed, 12 Oct 2016 04:47:45 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Dyer", "Chris", ""], ["Kuncoro", "Adhiguna", ""], ["Ballesteros", "Miguel", ""], ["Smith", "Noah A.", ""]]}, {"id": "1602.07868", "submitter": "Tim Salimans", "authors": "Tim Salimans and Diederik P. Kingma", "title": "Weight Normalization: A Simple Reparameterization to Accelerate Training\n  of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present weight normalization: a reparameterization of the weight vectors\nin a neural network that decouples the length of those weight vectors from\ntheir direction. By reparameterizing the weights in this way we improve the\nconditioning of the optimization problem and we speed up convergence of\nstochastic gradient descent. Our reparameterization is inspired by batch\nnormalization but does not introduce any dependencies between the examples in a\nminibatch. This means that our method can also be applied successfully to\nrecurrent models such as LSTMs and to noise-sensitive applications such as deep\nreinforcement learning or generative models, for which batch normalization is\nless well suited. Although our method is much simpler, it still provides much\nof the speed-up of full batch normalization. In addition, the computational\noverhead of our method is lower, permitting more optimization steps to be taken\nin the same amount of time. We demonstrate the usefulness of our method on\napplications in supervised image recognition, generative modelling, and deep\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 10:13:45 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2016 08:53:23 GMT"}, {"version": "v3", "created": "Sat, 4 Jun 2016 01:21:52 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Salimans", "Tim", ""], ["Kingma", "Diederik P.", ""]]}, {"id": "1602.07884", "submitter": "Surafel Tilahun", "authors": "Surafel Luleseged Tilahun and Jean Medard T Ngnotchouye", "title": "Firefly Algorithm for optimization problems with non-continuous\n  variables: A Review and Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Firefly algorithm is a swarm based metaheuristic algorithm inspired by the\nflashing behavior of fireflies. It is an effective and an easy to implement\nalgorithm. It has been tested on different problems from different disciplines\nand found to be effective. Even though the algorithm is proposed for\noptimization problems with continuous variables, it has been modified and used\nfor problems with non-continuous variables, including binary and integer valued\nproblems. In this paper a detailed review of this modifications of firefly\nalgorithm for problems with non-continuous variables will be discussed. The\nstrength and weakness of the modifications along with possible future works\nwill be presented.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 11:04:09 GMT"}], "update_date": "2016-02-26", "authors_parsed": [["Tilahun", "Surafel Luleseged", ""], ["Ngnotchouye", "Jean Medard T", ""]]}, {"id": "1602.08007", "submitter": "Yann Ollivier", "authors": "Ga\\'etan Marceau-Caron, Yann Ollivier", "title": "Practical Riemannian Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first experimental results on non-synthetic datasets for the\nquasi-diagonal Riemannian gradient descents for neural networks introduced in\n[Ollivier, 2015]. These include the MNIST, SVHN, and FACE datasets as well as a\npreviously unpublished electroencephalogram dataset. The quasi-diagonal\nRiemannian algorithms consistently beat simple stochastic gradient gradient\ndescents by a varying margin. The computational overhead with respect to simple\nbackpropagation is around a factor $2$. Perhaps more interestingly, these\nmethods also reach their final performance quickly, thus requiring fewer\ntraining epochs and a smaller total computation time.\n  We also present an implementation guide to these Riemannian gradient descents\nfor neural networks, showing how the quasi-diagonal versions can be implemented\nwith minimal effort on top of existing routines which compute gradients.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 17:37:28 GMT"}], "update_date": "2016-02-26", "authors_parsed": [["Marceau-Caron", "Ga\u00e9tan", ""], ["Ollivier", "Yann", ""]]}, {"id": "1602.08124", "submitter": "Minsoo Rhu", "authors": "Minsoo Rhu, Natalia Gimelshein, Jason Clemons, Arslan Zulfiqar,\n  Stephen W. Keckler", "title": "vDNN: Virtualized Deep Neural Networks for Scalable, Memory-Efficient\n  Neural Network Design", "comments": "Published as a conference paper at the 49th IEEE/ACM International\n  Symposium on Microarchitecture (MICRO-49), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most widely used machine learning frameworks require users to carefully\ntune their memory usage so that the deep neural network (DNN) fits into the\nDRAM capacity of a GPU. This restriction hampers a researcher's flexibility to\nstudy different machine learning algorithms, forcing them to either use a less\ndesirable network architecture or parallelize the processing across multiple\nGPUs. We propose a runtime memory manager that virtualizes the memory usage of\nDNNs such that both GPU and CPU memory can simultaneously be utilized for\ntraining larger DNNs. Our virtualized DNN (vDNN) reduces the average GPU memory\nusage of AlexNet by up to 89%, OverFeat by 91%, and GoogLeNet by 95%, a\nsignificant reduction in memory requirements of DNNs. Similar experiments on\nVGG-16, one of the deepest and memory hungry DNNs to date, demonstrate the\nmemory-efficiency of our proposal. vDNN enables VGG-16 with batch size 256\n(requiring 28 GB of memory) to be trained on a single NVIDIA Titan X GPU card\ncontaining 12 GB of memory, with 18% performance loss compared to a\nhypothetical, oracular GPU with enough memory to hold the entire DNN.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 21:31:55 GMT"}, {"version": "v2", "created": "Tue, 1 Mar 2016 03:52:59 GMT"}, {"version": "v3", "created": "Thu, 28 Jul 2016 23:19:03 GMT"}], "update_date": "2016-08-01", "authors_parsed": [["Rhu", "Minsoo", ""], ["Gimelshein", "Natalia", ""], ["Clemons", "Jason", ""], ["Zulfiqar", "Arslan", ""], ["Keckler", "Stephen W.", ""]]}, {"id": "1602.08159", "submitter": "Keisuke Fujii", "authors": "Keisuke Fujii and Kohei Nakajima", "title": "Harnessing disordered quantum dynamics for machine learning", "comments": "19 pages, 13 figures", "journal-ref": "Phys. Rev. Applied 8, 024030 (2017)", "doi": "10.1103/PhysRevApplied.8.024030", "report-no": null, "categories": "quant-ph cs.AI cs.LG cs.NE nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computer has an amazing potential of fast information processing.\nHowever, realisation of a digital quantum computer is still a challenging\nproblem requiring highly accurate controls and key application strategies. Here\nwe propose a novel platform, quantum reservoir computing, to solve these issues\nsuccessfully by exploiting natural quantum dynamics, which is ubiquitous in\nlaboratories nowadays, for machine learning. In this framework, nonlinear\ndynamics including classical chaos can be universally emulated in quantum\nsystems. A number of numerical experiments show that quantum systems consisting\nof at most seven qubits possess computational capabilities comparable to\nconventional recurrent neural networks of 500 nodes. This discovery opens up a\nnew paradigm for information processing with artificial intelligence powered by\nquantum physics.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 00:57:59 GMT"}, {"version": "v2", "created": "Wed, 9 Nov 2016 16:05:22 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Fujii", "Keisuke", ""], ["Nakajima", "Kohei", ""]]}, {"id": "1602.08194", "submitter": "Ryan Spring", "authors": "Ryan Spring, Anshumali Shrivastava", "title": "Scalable and Sustainable Deep Learning via Randomized Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current deep learning architectures are growing larger in order to learn from\ncomplex datasets. These architectures require giant matrix multiplication\noperations to train millions of parameters. Conversely, there is another\ngrowing trend to bring deep learning to low-power, embedded devices. The matrix\noperations, associated with both training and testing of deep networks, are\nvery expensive from a computational and energy standpoint. We present a novel\nhashing based technique to drastically reduce the amount of computation needed\nto train and test deep networks. Our approach combines recent ideas from\nadaptive dropouts and randomized hashing for maximum inner product search to\nselect the nodes with the highest activation efficiently. Our new algorithm for\ndeep learning reduces the overall computational cost of forward and\nback-propagation by operating on significantly fewer (sparse) nodes. As a\nconsequence, our algorithm uses only 5% of the total multiplications, while\nkeeping on average within 1% of the accuracy of the original model. A unique\nproperty of the proposed hashing based back-propagation is that the updates are\nalways sparse. Due to the sparse gradient updates, our algorithm is ideally\nsuited for asynchronous and parallel training leading to near linear speedup\nwith increasing number of cores. We demonstrate the scalability and\nsustainability (energy efficiency) of our proposed algorithm via rigorous\nexperimental evaluations on several real datasets.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 05:07:23 GMT"}, {"version": "v2", "created": "Mon, 5 Dec 2016 04:52:36 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Spring", "Ryan", ""], ["Shrivastava", "Anshumali", ""]]}, {"id": "1602.08210", "submitter": "Yuhuai(Tony) Wu", "authors": "Saizheng Zhang, Yuhuai Wu, Tong Che, Zhouhan Lin, Roland Memisevic,\n  Ruslan Salakhutdinov, Yoshua Bengio", "title": "Architectural Complexity Measures of Recurrent Neural Networks", "comments": "17 pages, 8 figures; To appear in NIPS2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we systematically analyze the connecting architectures of\nrecurrent neural networks (RNNs). Our main contribution is twofold: first, we\npresent a rigorous graph-theoretic framework describing the connecting\narchitectures of RNNs in general. Second, we propose three architecture\ncomplexity measures of RNNs: (a) the recurrent depth, which captures the RNN's\nover-time nonlinear complexity, (b) the feedforward depth, which captures the\nlocal input-output nonlinearity (similar to the \"depth\" in feedforward neural\nnetworks (FNNs)), and (c) the recurrent skip coefficient which captures how\nrapidly the information propagates over time. We rigorously prove each\nmeasure's existence and computability. Our experimental results show that RNNs\nmight benefit from larger recurrent depth and feedforward depth. We further\ndemonstrate that increasing recurrent skip coefficient offers performance\nboosts on long term dependency problems.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 06:16:27 GMT"}, {"version": "v2", "created": "Mon, 29 Feb 2016 17:18:21 GMT"}, {"version": "v3", "created": "Sat, 12 Nov 2016 19:38:43 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Zhang", "Saizheng", ""], ["Wu", "Yuhuai", ""], ["Che", "Tong", ""], ["Lin", "Zhouhan", ""], ["Memisevic", "Roland", ""], ["Salakhutdinov", "Ruslan", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1602.08313", "submitter": "Esra'a Alkafaween", "authors": "Ahmad B. A. Hassanat, Esra'a Alkafaween, Nedal A. Al-Nawaiseh,\n  Mohammad A. Abbadi, Mouhammd Alkasassbeh, Mahmoud B. Alhasanat", "title": "Enhancing Genetic Algorithms using Multi Mutations", "comments": "17 pages, 11 figures, 1 table, 41 references", "journal-ref": "International Journal of Computer Science and Information Security\n  14, no. 7 (2016): 785", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mutation is one of the most important stages of the genetic algorithm because\nof its impact on the exploration of global optima, and to overcome premature\nconvergence. There are many types of mutation, and the problem lies in\nselection of the appropriate type, where the decision becomes more difficult\nand needs more trial and error. This paper investigates the use of more than\none mutation operator to enhance the performance of genetic algorithms. Novel\nmutation operators are proposed, in addition to two selection strategies for\nthe mutation operators, one of which is based on selecting the best mutation\noperator and the other randomly selects any operator. Several experiments on\nsome Travelling Salesman Problems (TSP) were conducted to evaluate the proposed\nmethods, and these were compared to the well-known exchange mutation and\nrearrangement mutation. The results show the importance of some of the proposed\nmethods, in addition to the significant enhancement of the genetic algorithm's\nperformance, particularly when using more than one mutation operator.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 13:26:24 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 20:22:59 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Hassanat", "Ahmad B. A.", ""], ["Alkafaween", "Esra'a", ""], ["Al-Nawaiseh", "Nedal A.", ""], ["Abbadi", "Mohammad A.", ""], ["Alkasassbeh", "Mouhammd", ""], ["Alhasanat", "Mahmoud B.", ""]]}, {"id": "1602.08323", "submitter": "Peter O'Connor", "authors": "Peter O'Connor, Max Welling", "title": "Deep Spiking Networks", "comments": "8 pages main paper + 1 page reference + 7 pages Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an algorithm to do backpropagation on a spiking network. Our\nnetwork is \"spiking\" in the sense that our neurons accumulate their activation\ninto a potential over time, and only send out a signal (a \"spike\") when this\npotential crosses a threshold and the neuron is reset. Neurons only update\ntheir states when receiving signals from other neurons. Total computation of\nthe network thus scales with the number of spikes caused by an input rather\nthan network size. We show that the spiking Multi-Layer Perceptron behaves\nidentically, during both prediction and training, to a conventional deep\nnetwork of rectified-linear units, in the limiting case where we run the\nspiking network for a long time. We apply this architecture to a conventional\nclassification problem (MNIST) and achieve performance very close to that of a\nconventional Multi-Layer Perceptron with the same architecture. Our network is\na natural architecture for learning based on streaming event-based data, and is\na stepping stone towards using spiking neural networks to learn efficiently on\nstreaming data.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 13:54:47 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 12:38:17 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["O'Connor", "Peter", ""], ["Welling", "Max", ""]]}, {"id": "1602.08332", "submitter": "Felix Leibfried", "authors": "Felix Leibfried and Daniel Alexander Braun", "title": "Bounded Rational Decision-Making in Feedforward Neural Networks", "comments": "Proceedings of the 32nd Conference on Uncertainty in Artificial\n  Intelligence (UAI), New York City, NY, USA, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bounded rational decision-makers transform sensory input into motor output\nunder limited computational resources. Mathematically, such decision-makers can\nbe modeled as information-theoretic channels with limited transmission rate.\nHere, we apply this formalism for the first time to multilayer feedforward\nneural networks. We derive synaptic weight update rules for two scenarios,\nwhere either each neuron is considered as a bounded rational decision-maker or\nthe network as a whole. In the update rules, bounded rationality translates\ninto information-theoretically motivated types of regularization in weight\nspace. In experiments on the MNIST benchmark classification task for\nhandwritten digits, we show that such information-theoretic regularization\nsuccessfully prevents overfitting across different architectures and attains\nresults that are competitive with other recent techniques like dropout,\ndropconnect and Bayes by backprop, for both ordinary and convolutional neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 14:15:03 GMT"}, {"version": "v2", "created": "Mon, 23 May 2016 15:51:07 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Leibfried", "Felix", ""], ["Braun", "Daniel Alexander", ""]]}, {"id": "1602.08357", "submitter": "Samantha Petti", "authors": "Christos Papadimitrou, Samantha Petti, Santosh Vempala", "title": "Cortical Computation via Iterative Constructions", "comments": "40 pages, COLT 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Boolean functions of an arbitrary number of input variables that can\nbe realized by simple iterative constructions based on constant-size\nprimitives. This restricted type of construction needs little global\ncoordination or control and thus is a candidate for neurally feasible\ncomputation. Valiant's construction of a majority function can be realized in\nthis manner and, as we show, can be generalized to any uniform threshold\nfunction. We study the rate of convergence, finding that while linear\nconvergence to the correct function can be achieved for any threshold using a\nfixed set of primitives, for quadratic convergence, the size of the primitives\nmust grow as the threshold approaches 0 or 1. We also study finite realizations\nof this process and the learnability of the functions realized. We show that\nthe constructions realized are accurate outside a small interval near the\ntarget threshold, where the size of the construction grows as the inverse\nsquare of the interval width. This phenomenon, that errors are higher closer to\nthresholds (and thresholds closer to the boundary are harder to represent), is\na well-known cognitive finding.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 15:01:08 GMT"}, {"version": "v2", "created": "Wed, 15 Jun 2016 03:16:18 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Papadimitrou", "Christos", ""], ["Petti", "Samantha", ""], ["Vempala", "Santosh", ""]]}, {"id": "1602.08486", "submitter": "Garrison Cottrell", "authors": "Honghao Shan, Matthew H. Tong, Garrison W. Cottrell", "title": "A Single Model Explains both Visual and Auditory Precortical Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precortical neural systems encode information collected by the senses, but\nthe driving principles of the encoding used have remained a subject of debate.\nWe present a model of retinal coding that is based on three constraints:\ninformation preservation, minimization of the neural wiring, and response\nequalization. The resulting novel version of sparse principal components\nanalysis successfully captures a number of known characteristics of the retinal\ncoding system, such as center-surround receptive fields, color opponency\nchannels, and spatiotemporal responses that correspond to magnocellular and\nparvocellular pathways. Furthermore, when trained on auditory data, the same\nmodel learns receptive fields well fit by gammatone filters, commonly used to\nmodel precortical auditory coding. This suggests that efficient coding may be a\nunifying principle of precortical encoding across modalities.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 10:17:53 GMT"}, {"version": "v2", "created": "Thu, 7 Apr 2016 19:19:11 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Shan", "Honghao", ""], ["Tong", "Matthew H.", ""], ["Cottrell", "Garrison W.", ""]]}, {"id": "1602.08556", "submitter": "Syed Shakib Sarwar", "authors": "Gopalakrishnan Srinivasan, Parami Wijesinghe, Syed Shakib Sarwar,\n  Akhilesh Jaiswal, and Kaushik Roy", "title": "Significance Driven Hybrid 8T-6T SRAM for Energy-Efficient Synaptic\n  Storage in Artificial Neural Networks", "comments": "Accepted in Design, Automation and Test in Europe 2016 conference\n  (DATE-2016)", "journal-ref": "In Design, Automation & Test in Europe Conference & Exhibition\n  (DATE), 2016, pp. 151-156", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multilayered artificial neural networks (ANN) have found widespread utility\nin classification and recognition applications. The scale and complexity of\nsuch networks together with the inadequacies of general purpose computing\nplatforms have led to a significant interest in the development of efficient\nhardware implementations. In this work, we focus on designing energy efficient\non-chip storage for the synaptic weights. In order to minimize the power\nconsumption of typical digital CMOS implementations of such large-scale\nnetworks, the digital neurons could be operated reliably at scaled voltages by\nreducing the clock frequency. On the contrary, the on-chip synaptic storage\ndesigned using a conventional 6T SRAM is susceptible to bitcell failures at\nreduced voltages. However, the intrinsic error resiliency of NNs to small\nsynaptic weight perturbations enables us to scale the operating voltage of the\n6TSRAM. Our analysis on a widely used digit recognition dataset indicates that\nthe voltage can be scaled by 200mV from the nominal operating voltage (950mV)\nfor practically no loss (less than 0.5%) in accuracy (22nm predictive\ntechnology). Scaling beyond that causes substantial performance degradation\nowing to increased probability of failures in the MSBs of the synaptic weights.\nWe, therefore propose a significance driven hybrid 8T-6T SRAM, wherein the\nsensitive MSBs are stored in 8T bitcells that are robust at scaled voltages due\nto decoupled read and write paths. In an effort to further minimize the area\npenalty, we present a synaptic-sensitivity driven hybrid memory architecture\nconsisting of multiple 8T-6T SRAM banks. Our circuit to system-level simulation\nframework shows that the proposed synaptic-sensitivity driven architecture\nprovides a 30.91% reduction in the memory access power with a 10.41% area\noverhead, for less than 1% loss in the classification accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2016 05:36:42 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Srinivasan", "Gopalakrishnan", ""], ["Wijesinghe", "Parami", ""], ["Sarwar", "Syed Shakib", ""], ["Jaiswal", "Akhilesh", ""], ["Roy", "Kaushik", ""]]}, {"id": "1602.08557", "submitter": "Syed Shakib Sarwar", "authors": "Syed Shakib Sarwar, Swagath Venkataramani, Anand Raghunathan, and\n  Kaushik Roy", "title": "Multiplier-less Artificial Neurons Exploiting Error Resiliency for\n  Energy-Efficient Neural Computing", "comments": "Accepted in Design, Automation and Test in Europe 2016 conference\n  (DATE-2016)", "journal-ref": "In Design, Automation & Test in Europe Conference & Exhibition\n  (DATE), 2016, pp. 145-150", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale artificial neural networks have shown significant promise in\naddressing a wide range of classification and recognition applications.\nHowever, their large computational requirements stretch the capabilities of\ncomputing platforms. The fundamental components of these neural networks are\nthe neurons and its synapses. The core of a digital hardware neuron consists of\nmultiplier, accumulator and activation function. Multipliers consume most of\nthe processing energy in the digital neurons, and thereby in the hardware\nimplementations of artificial neural networks. We propose an approximate\nmultiplier that utilizes the notion of computation sharing and exploits error\nresilience of neural network applications to achieve improved energy\nconsumption. We also propose Multiplier-less Artificial Neuron (MAN) for even\nlarger improvement in energy consumption and adapt the training process to\nensure minimal degradation in accuracy. We evaluated the proposed design on 5\nrecognition applications. The results show, 35% and 60% reduction in energy\nconsumption, for neuron sizes of 8 bits and 12 bits, respectively, with a\nmaximum of ~2.83% loss in network accuracy, compared to a conventional neuron\nimplementation. We also achieve 37% and 62% reduction in area for a neuron size\nof 8 bits and 12 bits, respectively, under iso-speed conditions.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2016 05:37:44 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Sarwar", "Syed Shakib", ""], ["Venkataramani", "Swagath", ""], ["Raghunathan", "Anand", ""], ["Roy", "Kaushik", ""]]}, {"id": "1602.08571", "submitter": "Haoxi Zhang", "authors": "Haoxi Zhang, Cesar Sanin, Edward Szczerbicki", "title": "Towards Neural Knowledge DNA", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the Neural Knowledge DNA, a framework that tailors\nthe ideas underlying the success of neural networks to the scope of knowledge\nrepresentation. Knowledge representation is a fundamental field that dedicate\nto representing information about the world in a form that computer systems can\nutilize to solve complex tasks. The proposed Neural Knowledge DNA is designed\nto support discovering, storing, reusing, improving, and sharing knowledge\namong machines and organisation. It is constructed in a similar fashion of how\nDNA formed: built up by four essential elements. As the DNA produces\nphenotypes, the Neural Knowledge DNA carries information and knowledge via its\nfour essential elements, namely, Networks, Experiences, States, and Actions.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2016 08:45:35 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Zhang", "Haoxi", ""], ["Sanin", "Cesar", ""], ["Szczerbicki", "Edward", ""]]}, {"id": "1602.08671", "submitter": "Greg Yang", "authors": "Greg Yang", "title": "Lie Access Neural Turing Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the recent trend in explicit neural memory structures, we present a\nnew design of an external memory, wherein memories are stored in an Euclidean\nkey space $\\mathbb R^n$. An LSTM controller performs read and write via\nspecialized read and write heads. It can move a head by either providing a new\naddress in the key space (aka random access) or moving from its previous\nposition via a Lie group action (aka Lie access). In this way, the \"L\" and \"R\"\ninstructions of a traditional Turing Machine are generalized to arbitrary\nelements of a fixed Lie group action. For this reason, we name this new model\nthe Lie Access Neural Turing Machine, or LANTM.\n  We tested two different configurations of LANTM against an LSTM baseline in\nseveral basic experiments. We found the right configuration of LANTM to\noutperform the baseline in all of our experiments. In particular, we trained\nLANTM on addition of $k$-digit numbers for $2 \\le k \\le 16$, but it was able to\ngeneralize almost perfectly to $17 \\le k \\le 32$, all with the number of\nparameters 2 orders of magnitude below the LSTM baseline.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2016 04:55:19 GMT"}, {"version": "v2", "created": "Tue, 23 Aug 2016 01:23:46 GMT"}, {"version": "v3", "created": "Tue, 6 Sep 2016 14:42:56 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Yang", "Greg", ""]]}, {"id": "1602.08802", "submitter": "Randal Olson", "authors": "Randal S. Olson, Arend Hintze, Fred C. Dyer, Jason H. Moore, Christoph\n  Adami", "title": "Exploring the coevolution of predator and prey morphology and behavior", "comments": "8 pages, 8 figures, submitted to Artificial Life 2016 conference", "journal-ref": "Proceedings Artificial Life 15 (C. Gershenson, T. Froese, J.M.\n  Sisqueiros, W. Aguilar, E.J. Izquierdo, H. Sayama, eds.) MIT Press\n  (Cambridge, MA, 2016), pp. 250-258", "doi": "10.7551/978-0-262-33936-0-ch045", "report-no": null, "categories": "q-bio.PE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common idiom in biology education states, \"Eyes in the front, the animal\nhunts. Eyes on the side, the animal hides.\" In this paper, we explore one\npossible explanation for why predators tend to have forward-facing, high-acuity\nvisual systems. We do so using an agent-based computational model of evolution,\nwhere predators and prey interact and adapt their behavior and morphology to\none another over successive generations of evolution. In this model, we observe\na coevolutionary cycle between prey swarming behavior and the predator's visual\nsystem, where the predator and prey continually adapt their visual system and\nbehavior, respectively, over evolutionary time in reaction to one another due\nto the well-known \"predator confusion effect.\" Furthermore, we provide evidence\nthat the predator visual system is what drives this coevolutionary cycle, and\nsuggest that the cycle could be closed if the predator evolves a hybrid visual\nsystem capable of narrow, high-acuity vision for tracking prey as well as\nbroad, coarse vision for prey discovery. Thus, the conflicting demands imposed\non a predator's visual system by the predator confusion effect could have led\nto the evolution of complex eyes in many predators.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 02:48:19 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Olson", "Randal S.", ""], ["Hintze", "Arend", ""], ["Dyer", "Fred C.", ""], ["Moore", "Jason H.", ""], ["Adami", "Christoph", ""]]}, {"id": "1602.09046", "submitter": "Nitzan Guberman", "authors": "Nitzan Guberman", "title": "On Complex Valued Convolutional Neural Networks", "comments": "M.Sc. thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are the cutting edge model for\nsupervised machine learning in computer vision. In recent years CNNs have\noutperformed traditional approaches in many computer vision tasks such as\nobject detection, image classification and face recognition. CNNs are\nvulnerable to overfitting, and a lot of research focuses on finding\nregularization methods to overcome it. One approach is designing task specific\nmodels based on prior knowledge.\n  Several works have shown that properties of natural images can be easily\ncaptured using complex numbers. Motivated by these works, we present a\nvariation of the CNN model with complex valued input and weights. We construct\nthe complex model as a generalization of the real model. Lack of order over the\ncomplex field raises several difficulties both in the definition and in the\ntraining of the network. We address these issues and suggest possible\nsolutions.\n  The resulting model is shown to be a restricted form of a real valued CNN\nwith twice the parameters. It is sensitive to phase structure, and we suggest\nit serves as a regularized model for problems where such structure is\nimportant. This suggestion is verified empirically by comparing the performance\nof a complex and a real network in the problem of cell detection. The two\nnetworks achieve comparable results, and although the complex model is hard to\ntrain, it is significantly less vulnerable to overfitting. We also demonstrate\nthat the complex network detects meaningful phase structure in the data.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 17:13:47 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Guberman", "Nitzan", ""]]}]