[{"id": "0911.0485", "submitter": "Rdv Ijcsis", "authors": "Tich Phuoc Tran, Longbing Cao, Dat Tran, Cuong Duc Nguyen", "title": "Novel Intrusion Detection using Probabilistic Neural Network and\n  Adaptive Boosting", "comments": "9 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 6, No. 1, pp. 083-091, October 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article applies Machine Learning techniques to solve Intrusion Detection\nproblems within computer networks. Due to complex and dynamic nature of\ncomputer networks and hacking techniques, detecting malicious activities\nremains a challenging task for security experts, that is, currently available\ndefense systems suffer from low detection capability and high number of false\nalarms. To overcome such performance limitations, we propose a novel Machine\nLearning algorithm, namely Boosted Subspace Probabilistic Neural Network\n(BSPNN), which integrates an adaptive boosting technique and a semi parametric\nneural network to obtain good tradeoff between accuracy and generality. As the\nresult, learning bias and generalization variance can be significantly\nminimized. Substantial experiments on KDD 99 intrusion benchmark indicate that\nour model outperforms other state of the art learning algorithms, with\nsignificantly improved detection accuracy, minimal false alarms and relatively\nsmall computational complexity.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2009 04:07:19 GMT"}], "update_date": "2009-11-04", "authors_parsed": [["Tran", "Tich Phuoc", ""], ["Cao", "Longbing", ""], ["Tran", "Dat", ""], ["Nguyen", "Cuong Duc", ""]]}, {"id": "0911.0787", "submitter": "Rdv Ijcsis", "authors": "Shailendra Singh, Sanjay Silakari", "title": "Generalized Discriminant Analysis algorithm for feature reduction in\n  Cyber Attack Detection System", "comments": "8 pages IEEE format, International Journal of Computer Science and\n  Information Security, IJCSIS 2009, ISSN 1947 5500, Impact Factor 0.423,\n  http://sites.google.com/site/ijcsis/", "journal-ref": "International Journal of Computer Science and Information\n  Security, IJCSIS, Vol. 6, No. 1, pp. 173-180, October 2009, USA", "doi": null, "report-no": "ISSN 1947 5500", "categories": "cs.CR cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This Generalized Discriminant Analysis (GDA) has provided an extremely\npowerful approach to extracting non linear features. The network traffic data\nprovided for the design of intrusion detection system always are large with\nineffective information, thus we need to remove the worthless information from\nthe original high dimensional database. To improve the generalization ability,\nwe usually generate a small set of features from the original input variables\nby feature extraction. The conventional Linear Discriminant Analysis (LDA)\nfeature reduction technique has its limitations. It is not suitable for non\nlinear dataset. Thus we propose an efficient algorithm based on the Generalized\nDiscriminant Analysis (GDA) feature reduction technique which is novel approach\nused in the area of cyber attack detection. This not only reduces the number of\nthe input features but also increases the classification accuracy and reduces\nthe training and testing time of the classifiers by selecting most\ndiscriminating features. We use Artificial Neural Network (ANN) and C4.5\nclassifiers to compare the performance of the proposed technique. The result\nindicates the superiority of algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2009 11:29:57 GMT"}], "update_date": "2009-11-05", "authors_parsed": [["Singh", "Shailendra", ""], ["Silakari", "Sanjay", ""]]}, {"id": "0911.2324", "submitter": "EPTCS", "authors": "Martin F\\\"urer", "title": "Deterministic Autopoietic Automata", "comments": null, "journal-ref": "EPTCS 9, 2009, pp. 49-53", "doi": "10.4204/EPTCS.9.6", "report-no": null, "categories": "cs.NE cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies two issues related to the paper on Computing by\nSelf-reproduction: Autopoietic Automata by Jiri Wiedermann. It is shown that\nall results presented there extend to deterministic computations. In\nparticular, nondeterminism is not needed for a lineage to generate all\nautopoietic automata.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2009 08:48:38 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["F\u00fcrer", "Martin", ""]]}, {"id": "0911.2390", "submitter": "EPTCS", "authors": "Stefan Leijnen, Liane Gabora", "title": "How Creative Should Creators Be To Optimize the Evolution of Ideas? A\n  Computational Model", "comments": null, "journal-ref": "EPTCS 9, 2009, pp. 108-119", "doi": "10.4204/EPTCS.9.12", "report-no": null, "categories": "cs.AI cs.NE physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are both benefits and drawbacks to creativity. In a social group it is\nnot necessary for all members to be creative to benefit from creativity; some\nmerely imitate or enjoy the fruits of others' creative efforts. What proportion\nshould be creative? This paper contains a very preliminary investigation of\nthis question carried out using a computer model of cultural evolution referred\nto as EVOC (for EVOlution of Culture). EVOC is composed of neural network based\nagents that evolve fitter ideas for actions by (1) inventing new ideas through\nmodification of existing ones, and (2) imitating neighbors' ideas. The ideal\nproportion with respect to fitness of ideas occurs when thirty to forty percent\nof the individuals is creative. When creators are inventing 50% of iterations\nor less, mean fitness of actions in the society is a positive function of the\nratio of creators to imitators; otherwise mean fitness of actions starts to\ndrop when the ratio of creators to imitators exceeds approximately 30%. For all\nlevels or creativity, the diversity of ideas in a population is positively\ncorrelated with the ratio of creative agents.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2009 13:44:59 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Leijnen", "Stefan", ""], ["Gabora", "Liane", ""]]}, {"id": "0911.2829", "submitter": "EPTCS", "authors": "S. Barry Cooper, Vincent Danos", "title": "Proceedings Fifth Workshop on Developments in Computational\n  Models--Computational Models From Nature", "comments": null, "journal-ref": "EPTCS 9, 2009", "doi": "10.4204/EPTCS.9", "report-no": null, "categories": "cs.CE cs.AI cs.CC cs.FL cs.LO cs.NE cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The special theme of DCM 2009, co-located with ICALP 2009, concerned\nComputational Models From Nature, with a particular emphasis on computational\nmodels derived from physics and biology. The intention was to bring together\ndifferent approaches - in a community with a strong foundational background as\nproffered by the ICALP attendees - to create inspirational cross-boundary\nexchanges, and to lead to innovative further research. Specifically DCM 2009\nsought contributions in quantum computation and information, probabilistic\nmodels, chemical, biological and bio-inspired ones, including spatial models,\ngrowth models and models of self-assembly. Contributions putting to the test\nlogical or algorithmic aspects of computing (e.g., continuous computing with\ndynamical systems, or solid state computing models) were also very much\nwelcomed.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2009 03:35:32 GMT"}], "update_date": "2009-11-17", "authors_parsed": [["Cooper", "S. Barry", ""], ["Danos", "Vincent", ""]]}, {"id": "0911.2865", "submitter": "Nallusamy R", "authors": "R. Nallusamy and K. Duraiswamy", "title": "Neural Networks for Dynamic Shortest Path Routing Problems - A Survey", "comments": "This article has been withdrawn by the authors. Misplaced equation 1", "journal-ref": "CiiT International Journal of Artificial Intelligent Systems and\n  Machine Learning, Vol. 1, No. 2, pp. 31-34, May 2009", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews the overview of the dynamic shortest path routing problem\nand the various neural networks to solve it. Different shortest path\noptimization problems can be solved by using various neural networks\nalgorithms. The routing in packet switched multi-hop networks can be described\nas a classical combinatorial optimization problem i.e. a shortest path routing\nproblem in graphs. The survey shows that the neural networks are the best\ncandidates for the optimization of dynamic shortest path routing problems due\nto their fastness in computation comparing to other softcomputing and\nmetaheuristics algorithms\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2009 13:04:26 GMT"}, {"version": "v2", "created": "Sun, 30 May 2010 09:02:08 GMT"}], "update_date": "2010-06-01", "authors_parsed": [["Nallusamy", "R.", ""], ["Duraiswamy", "K.", ""]]}, {"id": "0911.3209", "submitter": "Chao-Yang Pang", "authors": "Chao-Yang Pang, Hui Liu, Xia Li, Yun-Fei Wang, Ben-Qiong Hu", "title": "Apply Ant Colony Algorithm to Search All Extreme Points of Function", "comments": "23 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To find all extreme points of multimodal functions is called extremum\nproblem, which is a well known difficult issue in optimization fields. Applying\nant colony optimization (ACO) to solve this problem is rarely reported. The\nmethod of applying ACO to solve extremum problem is explored in this paper.\nExperiment shows that the solution error of the method presented in this paper\nis less than 10^-8. keywords: Extremum Problem; Ant Colony Optimization (ACO)\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2009 03:34:19 GMT"}], "update_date": "2009-11-18", "authors_parsed": [["Pang", "Chao-Yang", ""], ["Liu", "Hui", ""], ["Li", "Xia", ""], ["Wang", "Yun-Fei", ""], ["Hu", "Ben-Qiong", ""]]}, {"id": "0911.3298", "submitter": "Alejandro Chinea Manrique De Lara", "authors": "Alejandro Chinea", "title": "Understanding the Principles of Recursive Neural networks: A Generative\n  Approach to Tackle Model Complexity", "comments": "11 pages, 4 figures, Recurrent Networks session ICANN 2009", "journal-ref": "Alippi, C., Polycarpou, M. Panayiotou, C., Ellinas, G. (Eds.)\n  ICANN 2009, LNCS, vol. 5768 pp. 952-963, Springer, Heidelberg (2009)", "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursive Neural Networks are non-linear adaptive models that are able to\nlearn deep structured information. However, these models have not yet been\nbroadly accepted. This fact is mainly due to its inherent complexity. In\nparticular, not only for being extremely complex information processing models,\nbut also because of a computational expensive learning phase. The most popular\ntraining method for these models is back-propagation through the structure.\nThis algorithm has been revealed not to be the most appropriate for structured\nprocessing due to problems of convergence, while more sophisticated training\nmethods enhance the speed of convergence at the expense of increasing\nsignificantly the computational cost. In this paper, we firstly perform an\nanalysis of the underlying principles behind these models aimed at\nunderstanding their computational power. Secondly, we propose an approximate\nsecond order stochastic learning algorithm. The proposed algorithm dynamically\nadapts the learning rate throughout the training phase of the network without\nincurring excessively expensive computational effort. The algorithm operates in\nboth on-line and batch modes. Furthermore, the resulting learning scheme is\nrobust against the vanishing gradients problem. The advantages of the proposed\nalgorithm are demonstrated with a real-world application example.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2009 13:17:05 GMT"}], "update_date": "2009-11-18", "authors_parsed": [["Chinea", "Alejandro", ""]]}, {"id": "0911.3717", "submitter": "Vir Dhar", "authors": "V.K.Dhar, A.K.Tickoo, S.K.Kaul, R.Koul, B.P.Dubey", "title": "Artificial Neural Network-based error compensation procedure for\n  low-cost encoders", "comments": "16 pages, 4 figures. Accepted for Publication in Measurement Science\n  and Technology (MST)", "journal-ref": null, "doi": "10.1088/0957-0233/21/1/015112", "report-no": null, "categories": "cs.NE astro-ph.IM physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Artificial Neural Network-based error compensation method is proposed for\nimproving the accuracy of resolver-based 16-bit encoders by compensating for\ntheir respective systematic error profiles. The error compensation procedure,\nfor a particular encoder, involves obtaining its error profile by calibrating\nit on a precision rotary table, training the neural network by using a part of\nthis data and then determining the corrected encoder angle by subtracting the\nANN-predicted error from the measured value of the encoder angle. Since it is\nnot guaranteed that all the resolvers will have exactly similar error profiles\nbecause of the inherent differences in their construction on a micro scale, the\nANN has been trained on one error profile at a time and the corresponding\nweight file is then used only for compensating the systematic error of this\nparticular encoder. The systematic nature of the error profile for each of the\nencoders has also been validated by repeated calibration of the encoders over a\nperiod of time and it was found that the error profiles of a particular encoder\nrecorded at different epochs show near reproducible behavior. The ANN-based\nerror compensation procedure has been implemented for 4 encoders by training\nthe ANN with their respective error profiles and the results indicate that the\naccuracy of encoders can be improved by nearly an order of magnitude from\nquoted values of ~6 arc-min to ~0.65 arc-min when their corresponding\nANN-generated weight files are used for determining the corrected encoder\nangle.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2009 07:51:03 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Dhar", "V. K.", ""], ["Tickoo", "A. K.", ""], ["Kaul", "S. K.", ""], ["Koul", "R.", ""], ["Dubey", "B. P.", ""]]}, {"id": "0911.3753", "submitter": "Ronald Hochreiter", "authors": "Ronald Hochreiter, David Wozabal", "title": "Evolutionary estimation of a Coupled Markov Chain credit risk model", "comments": null, "journal-ref": "Studies in Computational Intelligence 293: 31-44. 2010", "doi": "10.1007/978-3-642-13950-5_3", "report-no": null, "categories": "cs.NE cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exists a range of different models for estimating and simulating credit\nrisk transitions to optimally manage credit risk portfolios and products. In\nthis chapter we present a Coupled Markov Chain approach to model rating\ntransitions and thereby default probabilities of companies. As the likelihood\nof the model turns out to be a non-convex function of the parameters to be\nestimated, we apply heuristics to find the ML estimators. To this extent, we\noutline the model and its likelihood function, and present both a Particle\nSwarm Optimization algorithm, as well as an Evolutionary Optimization algorithm\nto maximize the likelihood function. Numerical results are shown which suggest\na further application of evolutionary optimization techniques for credit risk\nmanagement.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2009 10:43:16 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Hochreiter", "Ronald", ""], ["Wozabal", "David", ""]]}, {"id": "0911.4385", "submitter": "Mauricio Cerda", "authors": "Mauricio Cerda (INRIA Lorraine - LORIA), Lucas Terissi, Bernard Girau\n  (INRIA Lorraine - LORIA)", "title": "Bio-inspired speed detection and discrimination", "comments": null, "journal-ref": "4th International Conference on Bio-Inspired Models of Network,\n  Information, and Computing Systems, Avignon : France (2009)", "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of computer vision, a crucial task is the detection of motion\n(also called optical flow extraction). This operation allows analysis such as\n3D reconstruction, feature tracking, time-to-collision and novelty detection\namong others. Most of the optical flow extraction techniques work within a\nfinite range of speeds. Usually, the range of detection is extended towards\nhigher speeds by combining some multiscale information in a serial\narchitecture. This serial multi-scale approach suffers from the problem of\nerror propagation related to the number of scales used in the algorithm. On the\nother hand, biological experiments show that human motion perception seems to\nfollow a parallel multiscale scheme. In this work we present a bio-inspired\nparallel architecture to perform detection of motion, providing a wide range of\noperation and avoiding error propagation associated with the serial\narchitecture. To test our algorithm, we perform relative error comparisons\nbetween both classical and proposed techniques, showing that the parallel\narchitecture is able to achieve motion detection with results similar to the\nserial approach.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2009 12:23:39 GMT"}], "update_date": "2009-11-24", "authors_parsed": [["Cerda", "Mauricio", "", "INRIA Lorraine - LORIA"], ["Terissi", "Lucas", "", "INRIA Lorraine - LORIA"], ["Girau", "Bernard", "", "INRIA Lorraine - LORIA"]]}, {"id": "0911.4414", "submitter": "Arijit  Laha Ph.D.", "authors": "Nikhil R. Pal, Arijit Laha and J. Das", "title": "Designing fuzzy rule based classifier using self-organizing feature map\n  for analysis of multispectral satellite images", "comments": "23 pages, 7 figures", "journal-ref": "International Journal of Remote Sensing, Volume 26, No 10, Pages\n  2219-2240, May 2005", "doi": "10.1080/01431160500033419", "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel scheme for designing fuzzy rule based classifier. An SOFM\nbased method is used for generating a set of prototypes which is used to\ngenerate a set of fuzzy rules. Each rule represents a region in the feature\nspace that we call the context of the rule. The rules are tuned with respect to\ntheir context. We justified that the reasoning scheme may be different in\ndifferent context leading to context sensitive inferencing. To realize context\nsensitive inferencing we used a softmin operator with a tunable parameter. The\nproposed scheme is tested on several multispectral satellite image data sets\nand the performance is found to be much better than the results reported in the\nliterature.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2009 14:26:00 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Pal", "Nikhil R.", ""], ["Laha", "Arijit", ""], ["Das", "J.", ""]]}, {"id": "0911.4416", "submitter": "Arijit  Laha Ph.D.", "authors": "Arijit Laha, Nikhil R. Pal, and J. Das", "title": "Land cover classification using fuzzy rules and aggregation of\n  contextual information through evidence theory", "comments": "14 pages, 2 figures", "journal-ref": "IEEE Transactions on Geoscience and Remote Sensing, Vol. 44, No.\n  6, pp. 1633-1642, June 2006", "doi": "10.1109/TGRS.2006.864391", "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Land cover classification using multispectral satellite image is a very\nchallenging task with numerous practical applications. We propose a multi-stage\nclassifier that involves fuzzy rule extraction from the training data and then\ngeneration of a possibilistic label vector for each pixel using the fuzzy rule\nbase. To exploit the spatial correlation of land cover types we propose four\ndifferent information aggregation methods which use the possibilistic class\nlabel of a pixel and those of its eight spatial neighbors for making the final\nclassification decision. Three of the aggregation methods use Dempster-Shafer\ntheory of evidence while the remaining one is modeled after the fuzzy k-NN\nrule. The proposed methods are tested with two benchmark seven channel\nsatellite images and the results are found to be quite satisfactory. They are\nalso compared with a Markov random field (MRF) model-based contextual\nclassification method and found to perform consistently better.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2009 14:33:27 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Laha", "Arijit", ""], ["Pal", "Nikhil R.", ""], ["Das", "J.", ""]]}, {"id": "0911.4986", "submitter": "EPTCS", "authors": "Michael J. Dinneen (University of Auckland), Yun-Bum Kim (University\n  of Auckland), Radu Nicolescu (University of Auckland)", "title": "New Solutions to the Firing Squad Synchronization Problems for Neural\n  and Hyperdag P Systems", "comments": null, "journal-ref": "EPTCS 11, 2009, pp. 107-122", "doi": "10.4204/EPTCS.11.7", "report-no": null, "categories": "cs.CE cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two uniform solutions to an open question: the Firing Squad\nSynchronization Problem (FSSP), for hyperdag and symmetric neural P systems,\nwith anonymous cells. Our solutions take e_c+5 and 6e_c+7 steps, respectively,\nwhere e_c is the eccentricity of the commander cell of the dag or digraph\nunderlying these P systems. The first and fast solution is based on a novel\nproposal, which dynamically extends P systems with mobile channels. The second\nsolution is substantially longer, but is solely based on classical rules and\nstatic channels. In contrast to the previous solutions, which work for\ntree-based P systems, our solutions synchronize to any subset of the underlying\ndigraph; and do not require membrane polarizations or conditional rules, but\nrequire states, as typically used in hyperdag and neural P systems.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2009 00:26:39 GMT"}], "update_date": "2009-11-30", "authors_parsed": [["Dinneen", "Michael J.", "", "University of Auckland"], ["Kim", "Yun-Bum", "", "University\n  of Auckland"], ["Nicolescu", "Radu", "", "University of Auckland"]]}, {"id": "0911.5242", "submitter": "Coryn Bailer-Jones", "authors": "C.A.L. Bailer-Jones (Max Planck Institute for Astronomy, Heidelberg)", "title": "The ILIUM forward modelling algorithm for multivariate parameter\n  estimation and its application to derive stellar parameters from Gaia\n  spectrophotometry", "comments": "MNRAS, in press. This revision corrects a few minor errors and typos.\n  A better formatted version for A4 paper is available at\n  http://www.mpia.de/home/calj/ilium.pdf", "journal-ref": null, "doi": "10.1111/j.1365-2966.2009.16125.x", "report-no": null, "categories": "astro-ph.IM astro-ph.GA astro-ph.SR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I introduce an algorithm for estimating parameters from multidimensional data\nbased on forward modelling. In contrast to many machine learning approaches it\navoids fitting an inverse model and the problems associated with this. The\nalgorithm makes explicit use of the sensitivities of the data to the\nparameters, with the goal of better treating parameters which only have a weak\nimpact on the data. The forward modelling approach provides uncertainty (full\ncovariance) estimates in the predicted parameters as well as a goodness-of-fit\nfor observations. I demonstrate the algorithm, ILIUM, with the estimation of\nstellar astrophysical parameters (APs) from simulations of the low resolution\nspectrophotometry to be obtained by Gaia. The AP accuracy is competitive with\nthat obtained by a support vector machine. For example, for zero extinction\nstars covering a wide range of metallicity, surface gravity and temperature,\nILIUM can estimate Teff to an accuracy of 0.3% at G=15 and to 4% for (lower\nsignal-to-noise ratio) spectra at G=20. [Fe/H] and logg can be estimated to\naccuracies of 0.1-0.4dex for stars with G<=18.5. If extinction varies a priori\nover a wide range (Av=0-10mag), then Teff and Av can be estimated quite\naccurately (3-4% and 0.1-0.2mag respectively at G=15), but there is a strong\nand ubiquitous degeneracy in these parameters which limits our ability to\nestimate either accurately at faint magnitudes. Using the forward model we can\nmap these degeneracies (in advance), and thus provide a complete probability\ndistribution over solutions. (Abridged)\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2009 11:28:04 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2010 07:18:42 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Bailer-Jones", "C. A. L.", "", "Max Planck Institute for Astronomy, Heidelberg"]]}, {"id": "0911.5372", "submitter": "Srinivas Turaga", "authors": "Srinivas C. Turaga, Kevin L. Briggman, Moritz Helmstaedter, Winfried\n  Denk, H. Sebastian Seung", "title": "Maximin affinity learning of image segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Images can be segmented by first using a classifier to predict an affinity\ngraph that reflects the degree to which image pixels must be grouped together\nand then partitioning the graph to yield a segmentation. Machine learning has\nbeen applied to the affinity classifier to produce affinity graphs that are\ngood in the sense of minimizing edge misclassification rates. However, this\nerror measure is only indirectly related to the quality of segmentations\nproduced by ultimately partitioning the affinity graph. We present the first\nmachine learning algorithm for training a classifier to produce affinity graphs\nthat are good in the sense of producing segmentations that directly minimize\nthe Rand index, a well known segmentation performance measure. The Rand index\nmeasures segmentation performance by quantifying the classification of the\nconnectivity of image pixel pairs after segmentation. By using the simple graph\npartitioning algorithm of finding the connected components of the thresholded\naffinity graph, we are able to train an affinity classifier to directly\nminimize the Rand index of segmentations resulting from the graph partitioning.\nOur learning algorithm corresponds to the learning of maximin affinities\nbetween image pixel pairs, which are predictive of the pixel-pair connectivity.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2009 04:58:38 GMT"}], "update_date": "2009-12-01", "authors_parsed": [["Turaga", "Srinivas C.", ""], ["Briggman", "Kevin L.", ""], ["Helmstaedter", "Moritz", ""], ["Denk", "Winfried", ""], ["Seung", "H. Sebastian", ""]]}]