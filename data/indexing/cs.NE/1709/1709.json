[{"id": "1709.00268", "submitter": "Santiago Hern\\'andez Orozco", "authors": "Santiago Hern\\'andez-Orozco, Narsis A. Kiani and Hector Zenil", "title": "Algorithmically probable mutations reproduce aspects of evolution such\n  as convergence rate, genetic memory, and modularity", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.IT math.IT q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural selection explains how life has evolved over millions of years from\nmore primitive forms. The speed at which this happens, however, has sometimes\ndefied formal explanations when based on random (uniformly distributed)\nmutations. Here we investigate the application of a simplicity bias based on a\nnatural but algorithmic distribution of mutations (no recombination) in various\nexamples, particularly binary matrices in order to compare evolutionary\nconvergence rates. Results both on synthetic and on small biological examples\nindicate an accelerated rate when mutations are not statistical uniform but\n\\textit{algorithmic uniform}. We show that algorithmic distributions can evolve\nmodularity and genetic memory by preservation of structures when they first\noccur sometimes leading to an accelerated production of diversity but also\npopulation extinctions, possibly explaining naturally occurring phenomena such\nas diversity explosions (e.g. the Cambrian) and massive extinctions (e.g. the\nEnd Triassic) whose causes are currently a cause for debate. The natural\napproach introduced here appears to be a better approximation to biological\nevolution than models based exclusively upon random uniform mutations, and it\nalso approaches a formal version of open-ended evolution based on previous\nformal results. These results validate some suggestions in the direction that\ncomputation may be an equally important driver of evolution. We also show that\ninducing the method on problems of optimization, such as genetic algorithms,\nhas the potential to accelerate convergence of artificial evolutionary\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 12:12:02 GMT"}, {"version": "v2", "created": "Tue, 5 Sep 2017 11:27:40 GMT"}, {"version": "v3", "created": "Wed, 6 Sep 2017 00:51:01 GMT"}, {"version": "v4", "created": "Thu, 14 Sep 2017 19:18:19 GMT"}, {"version": "v5", "created": "Fri, 1 Dec 2017 00:06:20 GMT"}, {"version": "v6", "created": "Thu, 1 Feb 2018 22:23:08 GMT"}, {"version": "v7", "created": "Sat, 10 Mar 2018 19:36:29 GMT"}, {"version": "v8", "created": "Wed, 20 Jun 2018 20:23:47 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Hern\u00e1ndez-Orozco", "Santiago", ""], ["Kiani", "Narsis A.", ""], ["Zenil", "Hector", ""]]}, {"id": "1709.00410", "submitter": "Hendrik Richter", "authors": "Hendrik Richter", "title": "Visual art inspired by the collective feeding behavior of sand-bubbler\n  crabs", "comments": null, "journal-ref": "Computational Intelligence in Music, Sound, Art and Design,\n  EvoMUSART 2018, (Eds.: Liapis, A., Romero Cardalda, J.J., Ekart, A.),\n  Springer-Verlag, pp. 1-17, 2018", "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sand--bubblers are crabs of the genera Dotilla and Scopimera which are known\nto produce remarkable patterns and structures at tropical beaches. From these\npattern-making abilities, we may draw inspiration for digital visual art. A\nsimple mathematical model is proposed and an algorithm is designed that may\ncreate such sand-bubbler patterns artificially. In addition, design parameters\nto modify the patterns are identified and analyzed by computational aesthetic\nmeasures. Finally, an extension of the algorithm is discussed that may enable\ncontrolling and guiding generative evolution of the art-making process.\n", "versions": [{"version": "v1", "created": "Fri, 1 Sep 2017 09:01:39 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 11:57:56 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Richter", "Hendrik", ""]]}, {"id": "1709.00539", "submitter": "Chandrasekaran Anirudh Bhardwaj", "authors": "Chandrasekaran Anirudh Bhardwaj, Megha Mishra and Sweetlin Hemalatha", "title": "An Automated Compatibility Prediction Engine using DISC Theory Based\n  Classification and Neural Networks", "comments": "Presented in 6th International Conference on Research Trends in\n  Engineering, Applied Science and Management (ICRTESM-2017).Published in\n  International Journal of Engineering, Technology, Science and Research", "journal-ref": "International Journal of Engineering, Technology, Science and\n  Research Volume 4 Issue 8 2017", "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally psychometric tests were used for profiling incoming workers.\nThese methods use DISC profiling method to classify people into distinct\npersonality types, which are further used to predict if a person may be a\npossible fit to the organizational culture. This concept is taken further by\nintroducing a novel technique to predict if a particular pair of an incoming\nworker and the manager being assigned are compatible at a psychological scale.\nThis is done using multilayer perceptron neural network which can be adaptively\ntrained to showcase the true nature of the compatibility index. The proposed\nprototype model is used to quantify the relevant attributes, use them to train\nthe prediction engine, and to define the data pipeline required for it.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 06:38:12 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Bhardwaj", "Chandrasekaran Anirudh", ""], ["Mishra", "Megha", ""], ["Hemalatha", "Sweetlin", ""]]}, {"id": "1709.00575", "submitter": "Marek Rei", "authors": "Marek Rei, Luana Bulat, Douwe Kiela, Ekaterina Shutova", "title": "Grasping the Finer Point: A Supervised Similarity Network for Metaphor\n  Detection", "comments": "EMNLP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquity of metaphor in our everyday communication makes it an important\nproblem for natural language understanding. Yet, the majority of metaphor\nprocessing systems to date rely on hand-engineered features and there is still\nno consensus in the field as to which features are optimal for this task. In\nthis paper, we present the first deep learning architecture designed to capture\nmetaphorical composition. Our results demonstrate that it outperforms the\nexisting approaches in the metaphor identification task.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 13:13:06 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Rei", "Marek", ""], ["Bulat", "Luana", ""], ["Kiela", "Douwe", ""], ["Shutova", "Ekaterina", ""]]}, {"id": "1709.00583", "submitter": "Chaofei Hong", "authors": "Chaofei Hong", "title": "Training Spiking Neural Networks for Cognitive Tasks: A Versatile\n  Framework Compatible to Various Temporal Codes", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version will be\n  superseded", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional modeling approaches have found limitations in matching the\nincreasingly detailed neural network structures and dynamics recorded in\nexperiments to the diverse brain functionalities. On another approach, studies\nhave demonstrated to train spiking neural networks for simple functions using\nsupervised learning. Here, we introduce a modified SpikeProp learning\nalgorithm, which achieved better learning stability in different activity\nstates. In addition, we show biological realistic features such as lateral\nconnections and sparse activities can be included in the network. We\ndemonstrate the versatility of this framework by implementing three well-known\ntemporal codes for different types of cognitive tasks, which are MNIST digits\nrecognition, spatial coordinate transformation, and motor sequence generation.\nMoreover, we find several characteristic features have evolved alongside the\ntask training, such as selective activity, excitatory-inhibitory balance, and\nweak pair-wise correlation. The coincidence between the self-evolved and\nexperimentally observed features indicates their importance on the brain\nfunctionality. Our results suggest a unified setting in which diverse cognitive\ncomputations and mechanisms can be studied.\n", "versions": [{"version": "v1", "created": "Sat, 2 Sep 2017 13:59:39 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Hong", "Chaofei", ""]]}, {"id": "1709.00848", "submitter": "Denis Kleyko", "authors": "V.I. Gritsenko, D.A. Rachkovskij, A.A. Frolov, R. Gayler, D. Kleyko,\n  E. Osipov", "title": "Neural Distributed Autoassociative Memories: A Survey", "comments": "31 pages", "journal-ref": "Cybernetics and Computer Engineering, 2017. 2(188), 5-35", "doi": "10.15407/kvt188.02.005", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduction. Neural network models of autoassociative, distributed memory\nallow storage and retrieval of many items (vectors) where the number of stored\nitems can exceed the vector dimension (the number of neurons in the network).\nThis opens the possibility of a sublinear time search (in the number of stored\nitems) for approximate nearest neighbors among vectors of high dimension. The\npurpose of this paper is to review models of autoassociative, distributed\nmemory that can be naturally implemented by neural networks (mainly with local\nlearning rules and iterative dynamics based on information locally available to\nneurons). Scope. The survey is focused mainly on the networks of Hopfield,\nWillshaw and Potts, that have connections between pairs of neurons and operate\non sparse binary vectors. We discuss not only autoassociative memory, but also\nthe generalization properties of these networks. We also consider neural\nnetworks with higher-order connections and networks with a bipartite graph\nstructure for non-binary data with linear constraints. Conclusions. In\nconclusion we discuss the relations to similarity search, advantages and\ndrawbacks of these techniques, and topics for further research. An interesting\nand still not completely resolved question is whether neural autoassociative\nmemories can search for approximate nearest neighbors faster than other index\nstructures for similarity search, in particular for the case of very high\ndimensional vectors.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 07:54:53 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Gritsenko", "V. I.", ""], ["Rachkovskij", "D. A.", ""], ["Frolov", "A. A.", ""], ["Gayler", "R.", ""], ["Kleyko", "D.", ""], ["Osipov", "E.", ""]]}, {"id": "1709.00890", "submitter": "Pietro Oliveto", "authors": "Per Kristian Lehre and Pietro S. Oliveto", "title": "Theoretical Analysis of Stochastic Search Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theoretical analyses of stochastic search algorithms, albeit few, have always\nexisted since these algorithms became popular. Starting in the nineties a\nsystematic approach to analyse the performance of stochastic search heuristics\nhas been put in place. This quickly increasing basis of results allows,\nnowadays, the analysis of sophisticated algorithms such as population-based\nevolutionary algorithms, ant colony optimisation and artificial immune systems.\nResults are available concerning problems from various domains including\nclassical combinatorial and continuous optimisation, single and multi-objective\noptimisation, and noisy and dynamic optimisation. This chapter introduces the\nmathematical techniques that are most commonly used in the runtime analysis of\nstochastic search heuristics. Careful attention is given to the very popular\nartificial fitness levels and drift analyses techniques for which several\nvariants are presented. To aid the reader's comprehension of the presented\nmathematical methods, these are applied to the analysis of simple evolutionary\nalgorithms for artificial example functions. The chapter is concluded by\nproviding references to more complex applications and further extensions of the\ntechniques for the obtainment of advanced results.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 10:30:04 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Lehre", "Per Kristian", ""], ["Oliveto", "Pietro S.", ""]]}, {"id": "1709.01134", "submitter": "Asit Mishra", "authors": "Asit Mishra, Eriko Nurvitadhi, Jeffrey J Cook and Debbie Marr", "title": "WRPN: Wide Reduced-Precision Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For computer vision applications, prior works have shown the efficacy of\nreducing numeric precision of model parameters (network weights) in deep neural\nnetworks. Activation maps, however, occupy a large memory footprint during both\nthe training and inference step when using mini-batches of inputs. One way to\nreduce this large memory footprint is to reduce the precision of activations.\nHowever, past works have shown that reducing the precision of activations hurts\nmodel accuracy. We study schemes to train networks from scratch using\nreduced-precision activations without hurting accuracy. We reduce the precision\nof activation maps (along with model parameters) and increase the number of\nfilter maps in a layer, and find that this scheme matches or surpasses the\naccuracy of the baseline full-precision network. As a result, one can\nsignificantly improve the execution efficiency (e.g. reduce dynamic memory\nfootprint, memory bandwidth and computational energy) and speed up the training\nand inference process with appropriate hardware support. We call our scheme\nWRPN - wide reduced-precision networks. We report results and show that WRPN\nscheme is better than previously reported accuracies on ILSVRC-12 dataset while\nbeing computationally less expensive compared to previously reported\nreduced-precision networks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Sep 2017 19:56:48 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Mishra", "Asit", ""], ["Nurvitadhi", "Eriko", ""], ["Cook", "Jeffrey J", ""], ["Marr", "Debbie", ""]]}, {"id": "1709.01215", "submitter": "Chunyuan Li", "authors": "Chunyuan Li, Hao Liu, Changyou Chen, Yunchen Pu, Liqun Chen, Ricardo\n  Henao, Lawrence Carin", "title": "ALICE: Towards Understanding Adversarial Learning for Joint Distribution\n  Matching", "comments": "NIPS 2017 (22 pages); short version (9 pages):\n  http://people.duke.edu/~cl319/doc/papers/nips_2017_alice.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the non-identifiability issues associated with bidirectional\nadversarial training for joint distribution matching. Within a framework of\nconditional entropy, we propose both adversarial and non-adversarial approaches\nto learn desirable matched joint distributions for unsupervised and supervised\ntasks. We unify a broad family of adversarial models as joint distribution\nmatching problems. Our approach stabilizes learning of unsupervised\nbidirectional adversarial learning methods. Further, we introduce an extension\nfor semi-supervised learning tasks. Theoretical results are validated in\nsynthetic data and real-world applications.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 02:18:06 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 03:58:52 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Li", "Chunyuan", ""], ["Liu", "Hao", ""], ["Chen", "Changyou", ""], ["Pu", "Yunchen", ""], ["Chen", "Liqun", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1709.01427", "submitter": "Alice Schoenauer Sebag", "authors": "Alice Schoenauer-Sebag, Marc Schoenauer and Mich\\`ele Sebag", "title": "Stochastic Gradient Descent: Going As Fast As Possible But Not Faster", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When applied to training deep neural networks, stochastic gradient descent\n(SGD) often incurs steady progression phases, interrupted by catastrophic\nepisodes in which loss and gradient norm explode. A possible mitigation of such\nevents is to slow down the learning process. This paper presents a novel\napproach to control the SGD learning rate, that uses two statistical tests. The\nfirst one, aimed at fast learning, compares the momentum of the normalized\ngradient vectors to that of random unit vectors and accordingly gracefully\nincreases or decreases the learning rate. The second one is a change point\ndetection test, aimed at the detection of catastrophic learning episodes; upon\nits triggering the learning rate is instantly halved. Both abilities of\nspeeding up and slowing down the learning rate allows the proposed approach,\ncalled SALeRA, to learn as fast as possible but not faster. Experiments on\nstandard benchmarks show that SALeRA performs well in practice, and compares\nfavorably to the state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 14:50:55 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Schoenauer-Sebag", "Alice", ""], ["Schoenauer", "Marc", ""], ["Sebag", "Mich\u00e8le", ""]]}, {"id": "1709.01574", "submitter": "Devinder Kumar", "authors": "Devinder Kumar, Graham W Taylor, Alexander Wong", "title": "Opening the Black Box of Financial AI with CLEAR-Trade: A CLass-Enhanced\n  Attentive Response Approach for Explaining and Visualizing Deep\n  Learning-Driven Stock Market Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been shown to outperform traditional machine learning\nalgorithms across a wide range of problem domains. However, current deep\nlearning algorithms have been criticized as uninterpretable \"black-boxes\" which\ncannot explain their decision making processes. This is a major shortcoming\nthat prevents the widespread application of deep learning to domains with\nregulatory processes such as finance. As such, industries such as finance have\nto rely on traditional models like decision trees that are much more\ninterpretable but less effective than deep learning for complex problems. In\nthis paper, we propose CLEAR-Trade, a novel financial AI visualization\nframework for deep learning-driven stock market prediction that mitigates the\ninterpretability issue of deep learning methods. In particular, CLEAR-Trade\nprovides a effective way to visualize and explain decisions made by deep stock\nmarket prediction models. We show the efficacy of CLEAR-Trade in enhancing the\ninterpretability of stock market prediction by conducting experiments based on\nS&P 500 stock index prediction. The results demonstrate that CLEAR-Trade can\nprovide significant insight into the decision-making process of deep\nlearning-driven financial models, particularly for regulatory processes, thus\nimproving their potential uptake in the financial industry.\n", "versions": [{"version": "v1", "created": "Tue, 5 Sep 2017 19:56:36 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Kumar", "Devinder", ""], ["Taylor", "Graham W", ""], ["Wong", "Alexander", ""]]}, {"id": "1709.01672", "submitter": "Rahul  Singh", "authors": "Rahul Singh, P.R. Kumar, and Eytan Modiano", "title": "Throughput Optimal Decentralized Scheduling of Multi-Hop Networks with\n  End-to-End Deadline Constraints: II Wireless Networks with Interference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a multihop wireless network serving multiple flows in which wireless\nlink interference constraints are described by a link interference graph. For\nsuch a network, we design routing-scheduling policies that maximize the\nend-to-end timely throughput of the network. Timely throughput of a flow $f$ is\ndefined as the average rate at which packets of flow $f$ reach their\ndestination node $d_f$ within their deadline.\n  Our policy has several surprising characteristics. Firstly, we show that the\noptimal routing-scheduling decision for an individual packet that is present at\na wireless node $i\\in V$ is solely a function of its location, and \"age\". Thus,\na wireless node $i$ does not require the knowledge of the \"global\" network\nstate in order to maximize the timely throughput. We notice that in comparison,\nunder the backpressure routing policy, a node $i$ requires only the knowledge\nof its neighbours queue lengths in order to guarantee maximal stability, and\nhence is decentralized. The key difference arises due to the fact that in our\nset-up the packets loose their utility once their \"age\" has crossed their\ndeadline, thus making the task of optimizing timely throughput much more\nchallenging than that of ensuring network stability. Of course, due to this key\ndifference, the decision process involved in maximizing the timely throughput\nis also much more complex than that involved in ensuring network-wide queue\nstabilization. In view of this, our results are somewhat surprising.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 04:56:43 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 03:58:18 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Singh", "Rahul", ""], ["Kumar", "P. R.", ""], ["Modiano", "Eytan", ""]]}, {"id": "1709.01686", "submitter": "Surat Teerapittayanon", "authors": "Surat Teerapittayanon, Bradley McDanel, H.T. Kung", "title": "BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are state of the art methods for many learning tasks due\nto their ability to extract increasingly better features at each network layer.\nHowever, the improved performance of additional layers in a deep network comes\nat the cost of added latency and energy usage in feedforward inference. As\nnetworks continue to get deeper and larger, these costs become more prohibitive\nfor real-time and energy-sensitive applications. To address this issue, we\npresent BranchyNet, a novel deep network architecture that is augmented with\nadditional side branch classifiers. The architecture allows prediction results\nfor a large portion of test samples to exit the network early via these\nbranches when samples can already be inferred with high confidence. BranchyNet\nexploits the observation that features learned at an early layer of a network\nmay often be sufficient for the classification of many data points. For more\ndifficult samples, which are expected less frequently, BranchyNet will use\nfurther or all network layers to provide the best likelihood of correct\nprediction. We study the BranchyNet architecture using several well-known\nnetworks (LeNet, AlexNet, ResNet) and datasets (MNIST, CIFAR10) and show that\nit can both improve accuracy and significantly reduce the inference time of the\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 06:30:51 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Teerapittayanon", "Surat", ""], ["McDanel", "Bradley", ""], ["Kung", "H. T.", ""]]}, {"id": "1709.02043", "submitter": "Alexander Wong", "authors": "Audrey Chung, Mohammad Javad Shafiee, Paul Fieguth, and Alexander Wong", "title": "The Mating Rituals of Deep Neural Networks: Learning Compact Feature\n  Representations through Sexual Evolutionary Synthesis", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary deep intelligence was recently proposed as a method for\nachieving highly efficient deep neural network architectures over successive\ngenerations. Drawing inspiration from nature, we propose the incorporation of\nsexual evolutionary synthesis. Rather than the current asexual synthesis of\nnetworks, we aim to produce more compact feature representations by\nsynthesizing more diverse and generalizable offspring networks in subsequent\ngenerations via the combination of two parent networks. Experimental results\nwere obtained using the MNIST and CIFAR-10 datasets, and showed improved\narchitectural efficiency and comparable testing accuracy relative to the\nbaseline asexual evolutionary neural networks. In particular, the network\nsynthesized via sexual evolutionary synthesis for MNIST had approximately\ndouble the architectural efficiency (cluster efficiency of 34.29X and synaptic\nefficiency of 258.37X) in comparison to the network synthesized via asexual\nevolutionary synthesis, with both networks achieving a testing accuracy of\n~97%.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 01:43:19 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Chung", "Audrey", ""], ["Shafiee", "Mohammad Javad", ""], ["Fieguth", "Paul", ""], ["Wong", "Alexander", ""]]}, {"id": "1709.02268", "submitter": "Giuseppe Jurman", "authors": "Diego Fioravanti, Ylenia Giarratano, Valerio Maggio, Claudio\n  Agostinelli, Marco Chierici, Giuseppe Jurman and Cesare Furlanello", "title": "Phylogenetic Convolutional Neural Networks in Metagenomics", "comments": "Presented at BMTL 2017, Naples", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG cs.NE q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Convolutional Neural Networks can be effectively used only when\ndata are endowed with an intrinsic concept of neighbourhood in the input space,\nas is the case of pixels in images. We introduce here Ph-CNN, a novel deep\nlearning architecture for the classification of metagenomics data based on the\nConvolutional Neural Networks, with the patristic distance defined on the\nphylogenetic tree being used as the proximity measure. The patristic distance\nbetween variables is used together with a sparsified version of\nMultiDimensional Scaling to embed the phylogenetic tree in a Euclidean space.\nResults: Ph-CNN is tested with a domain adaptation approach on synthetic data\nand on a metagenomics collection of gut microbiota of 38 healthy subjects and\n222 Inflammatory Bowel Disease patients, divided in 6 subclasses.\nClassification performance is promising when compared to classical algorithms\nlike Support Vector Machines and Random Forest and a baseline fully connected\nneural network, e.g. the Multi-Layer Perceptron. Conclusion: Ph-CNN represents\na novel deep learning approach for the classification of metagenomics data.\nOperatively, the algorithm has been implemented as a custom Keras layer taking\ncare of passing to the following convolutional layer not only the data but also\nthe ranked list of neighbourhood of each sample, thus mimicking the case of\nimage data, transparently to the user. Keywords: Metagenomics; Deep learning;\nConvolutional Neural Networks; Phylogenetic trees\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 12:59:14 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Fioravanti", "Diego", ""], ["Giarratano", "Ylenia", ""], ["Maggio", "Valerio", ""], ["Agostinelli", "Claudio", ""], ["Chierici", "Marco", ""], ["Jurman", "Giuseppe", ""], ["Furlanello", "Cesare", ""]]}, {"id": "1709.02349", "submitter": "Iulian Vlad Serban", "authors": "Iulian V. Serban, Chinnadhurai Sankar, Mathieu Germain, Saizheng\n  Zhang, Zhouhan Lin, Sandeep Subramanian, Taesup Kim, Michael Pieper, Sarath\n  Chandar, Nan Rosemary Ke, Sai Rajeshwar, Alexandre de Brebisson, Jose M. R.\n  Sotelo, Dendi Suhubdy, Vincent Michalski, Alexandre Nguyen, Joelle Pineau,\n  Yoshua Bengio", "title": "A Deep Reinforcement Learning Chatbot", "comments": "40 pages, 9 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MILABOT: a deep reinforcement learning chatbot developed by the\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\ncompetition. MILABOT is capable of conversing with humans on popular small talk\ntopics through both speech and text. The system consists of an ensemble of\nnatural language generation and retrieval models, including template-based\nmodels, bag-of-words models, sequence-to-sequence neural network and latent\nvariable neural network models. By applying reinforcement learning to\ncrowdsourced data and real-world user interactions, the system has been trained\nto select an appropriate response from the models in its ensemble. The system\nhas been evaluated through A/B testing with real-world users, where it\nperformed significantly better than many competing systems. Due to its machine\nlearning architecture, the system is likely to improve with additional data.\n", "versions": [{"version": "v1", "created": "Thu, 7 Sep 2017 16:51:09 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 21:02:57 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Serban", "Iulian V.", ""], ["Sankar", "Chinnadhurai", ""], ["Germain", "Mathieu", ""], ["Zhang", "Saizheng", ""], ["Lin", "Zhouhan", ""], ["Subramanian", "Sandeep", ""], ["Kim", "Taesup", ""], ["Pieper", "Michael", ""], ["Chandar", "Sarath", ""], ["Ke", "Nan Rosemary", ""], ["Rajeshwar", "Sai", ""], ["de Brebisson", "Alexandre", ""], ["Sotelo", "Jose M. R.", ""], ["Suhubdy", "Dendi", ""], ["Michalski", "Vincent", ""], ["Nguyen", "Alexandre", ""], ["Pineau", "Joelle", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1709.02679", "submitter": "Miqing Li", "authors": "Miqing Li, Xin Yao", "title": "What Weights Work for You? Adapting Weights for Any Pareto Front Shape\n  in Decomposition-based Evolutionary Multi-Objective Optimisation", "comments": "22 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of solution sets generated by decomposition-based evolutionary\nmultiobjective optimisation (EMO) algorithms depends heavily on the consistency\nbetween a given problem's Pareto front shape and the specified weights'\ndistribution. A set of weights distributed uniformly in a simplex often lead to\na set of well-distributed solutions on a Pareto front with a simplex-like\nshape, but may fail on other Pareto front shapes. It is an open problem on how\nto specify a set of appropriate weights without the information of the\nproblem's Pareto front beforehand. In this paper, we propose an approach to\nadapt the weights during the evolutionary process (called AdaW). AdaW\nprogressively seeks a suitable distribution of weights for the given problem by\nelaborating five parts in the weight adaptation --- weight generation, weight\naddition, weight deletion, archive maintenance, and weight update frequency.\nExperimental results have shown the effectiveness of the proposed approach.\nAdaW works well for Pareto fronts with very different shapes: 1) the\nsimplex-like, 2) the inverted simplex-like, 3) the highly nonlinear, 4) the\ndisconnect, 5) the degenerated, 6) the badly-scaled, and 7) the\nhigh-dimensional.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 12:56:59 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Li", "Miqing", ""], ["Yao", "Xin", ""]]}, {"id": "1709.02699", "submitter": "Aditya Shukla", "authors": "Aditya Shukla and Udayan Ganguly", "title": "An On-chip Trainable and Clock-less Spiking Neural Network with 1R\n  Memristive Synapses", "comments": null, "journal-ref": null, "doi": "10.1109/TBCAS.2018.2831618", "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) are being explored in an attempt to mimic\nbrain's capability to learn and recognize at low power. Crossbar architecture\nwith highly scalable Resistive RAM or RRAM array serving as synaptic weights\nand neuronal drivers in the periphery is an attractive option for SNN.\nRecognition (akin to reading the synaptic weight) requires small amplitude bias\napplied across the RRAM to minimize conductance change. Learning (akin to\nwriting or updating the synaptic weight) requires large amplitude bias pulses\nto produce a conductance change. The contradictory bias amplitude requirement\nto perform reading and writing simultaneously and asynchronously, akin to\nbiology, is a major challenge. Solutions suggested in the literature rely on\ntime-division-multiplexing of read and write operations based on clocks, or\napproximations ignoring the reading when coincidental with writing. In this\nwork, we overcome this challenge and present a clock-less approach wherein\nreading and writing are performed in different frequency domains. This enables\nlearning and recognition simultaneously on an SNN. We validate our scheme in\nSPICE circuit simulator by translating a two-layered feed-forward Iris\nclassifying SNN to demonstrate software-equivalent performance. The system\nperformance is not adversely affected by a voltage dependence of conductance in\nrealistic RRAMs, despite departing from linearity. Overall, our approach\nenables direct implementation of biological SNN algorithms in hardware.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 13:38:44 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 13:20:29 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Shukla", "Aditya", ""], ["Ganguly", "Udayan", ""]]}, {"id": "1709.02755", "submitter": "Tao Lei", "authors": "Tao Lei, Yu Zhang, Sida I. Wang, Hui Dai and Yoav Artzi", "title": "Simple Recurrent Units for Highly Parallelizable Recurrence", "comments": "EMNLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common recurrent neural architectures scale poorly due to the intrinsic\ndifficulty in parallelizing their state computations. In this work, we propose\nthe Simple Recurrent Unit (SRU), a light recurrent unit that balances model\ncapacity and scalability. SRU is designed to provide expressive recurrence,\nenable highly parallelized implementation, and comes with careful\ninitialization to facilitate training of deep models. We demonstrate the\neffectiveness of SRU on multiple NLP tasks. SRU achieves 5--9x speed-up over\ncuDNN-optimized LSTM on classification and question answering datasets, and\ndelivers stronger results than LSTM and convolutional models. We also obtain an\naverage of 0.7 BLEU improvement over the Transformer model on translation by\nincorporating SRU into the architecture.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 16:02:30 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 20:13:56 GMT"}, {"version": "v3", "created": "Sun, 5 Nov 2017 12:44:43 GMT"}, {"version": "v4", "created": "Tue, 26 Dec 2017 03:58:02 GMT"}, {"version": "v5", "created": "Fri, 7 Sep 2018 17:17:02 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Lei", "Tao", ""], ["Zhang", "Yu", ""], ["Wang", "Sida I.", ""], ["Dai", "Hui", ""], ["Artzi", "Yoav", ""]]}, {"id": "1709.02797", "submitter": "Matti Herranen", "authors": "Heikki Arponen, Matti Herranen, Harri Valpola", "title": "On the exact relationship between the denoising function and the data\n  distribution", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove an exact relationship between the optimal denoising function and the\ndata distribution in the case of additive Gaussian noise, showing that\ndenoising implicitly models the structure of data allowing it to be exploited\nin the unsupervised learning of representations. This result generalizes a\nknown relationship [2], which is valid only in the limit of small corruption\nnoise.\n", "versions": [{"version": "v1", "created": "Wed, 6 Sep 2017 07:26:59 GMT"}], "update_date": "2017-09-11", "authors_parsed": [["Arponen", "Heikki", ""], ["Herranen", "Matti", ""], ["Valpola", "Harri", ""]]}, {"id": "1709.02877", "submitter": "Vincent Cicirello", "authors": "Vincent A. Cicirello", "title": "Variable Annealing Length and Parallelism in Simulated Annealing", "comments": "Tenth International Symposium on Combinatorial Search, pages 2-10.\n  June 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose: (a) a restart schedule for an adaptive simulated\nannealer, and (b) parallel simulated annealing, with an adaptive and\nparameter-free annealing schedule. The foundation of our approach is the\nModified Lam annealing schedule, which adaptively controls the temperature\nparameter to track a theoretically ideal rate of acceptance of neighboring\nstates. A sequential implementation of Modified Lam simulated annealing is\nalmost parameter-free. However, it requires prior knowledge of the annealing\nlength. We eliminate this parameter using restarts, with an exponentially\nincreasing schedule of annealing lengths. We then extend this restart schedule\nto parallel implementation, executing several Modified Lam simulated annealers\nin parallel, with varying initial annealing lengths, and our proposed parallel\nannealing length schedule. To validate our approach, we conduct experiments on\nan NP-Hard scheduling problem with sequence-dependent setup constraints. We\ncompare our approach to fixed length restarts, both sequentially and in\nparallel. Our results show that our approach can achieve substantial\nperformance gains, throughout the course of the run, demonstrating our approach\nto be an effective anytime algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 23:05:55 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Cicirello", "Vincent A.", ""]]}, {"id": "1709.03082", "submitter": "Abien Fred Agarap", "authors": "Abien Fred Agarap", "title": "A Neural Network Architecture Combining Gated Recurrent Unit (GRU) and\n  Support Vector Machine (SVM) for Intrusion Detection in Network Traffic Data", "comments": "5 pages, 4 figures, 5 tables, accepted paper at the International\n  Conference on Machine Learning and Computing (ICMLC) 2018", "journal-ref": null, "doi": "10.1145/3195106.3195117", "report-no": null, "categories": "cs.NE cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Gated Recurrent Unit (GRU) is a recently-developed variation of the long\nshort-term memory (LSTM) unit, both of which are types of recurrent neural\nnetwork (RNN). Through empirical evidence, both models have been proven to be\neffective in a wide variety of machine learning tasks such as natural language\nprocessing (Wen et al., 2015), speech recognition (Chorowski et al., 2015), and\ntext classification (Yang et al., 2016). Conventionally, like most neural\nnetworks, both of the aforementioned RNN variants employ the Softmax function\nas its final output layer for its prediction, and the cross-entropy function\nfor computing its loss. In this paper, we present an amendment to this norm by\nintroducing linear support vector machine (SVM) as the replacement for Softmax\nin the final output layer of a GRU model. Furthermore, the cross-entropy\nfunction shall be replaced with a margin-based function. While there have been\nsimilar studies (Alalshekmubarak & Smith, 2013; Tang, 2013), this proposal is\nprimarily intended for binary classification on intrusion detection using the\n2013 network traffic data from the honeypot systems of Kyoto University.\nResults show that the GRU-SVM model performs relatively higher than the\nconventional GRU-Softmax model. The proposed model reached a training accuracy\nof ~81.54% and a testing accuracy of ~84.15%, while the latter was able to\nreach a training accuracy of ~63.07% and a testing accuracy of ~70.75%. In\naddition, the juxtaposition of these two final output layers indicate that the\nSVM would outperform Softmax in prediction time - a theoretical implication\nwhich was supported by the actual training and testing time in the study.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 10:43:09 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 06:17:37 GMT"}, {"version": "v3", "created": "Thu, 5 Oct 2017 10:40:13 GMT"}, {"version": "v4", "created": "Sat, 7 Oct 2017 07:01:11 GMT"}, {"version": "v5", "created": "Wed, 25 Oct 2017 02:15:07 GMT"}, {"version": "v6", "created": "Thu, 28 Dec 2017 18:55:35 GMT"}, {"version": "v7", "created": "Sat, 10 Mar 2018 05:50:54 GMT"}, {"version": "v8", "created": "Thu, 7 Feb 2019 06:38:08 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Agarap", "Abien Fred", ""]]}, {"id": "1709.03187", "submitter": "Darren Chitty", "authors": "Darren M. Chitty", "title": "Applying ACO To Large Scale TSP Instances", "comments": null, "journal-ref": "UK Workshop on Computational Intelligence, pp. 104-118. Springer,\n  Cham, 2017", "doi": "10.1007/978-3-319-66939-7_9", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ant Colony Optimisation (ACO) is a well known metaheuristic that has proven\nsuccessful at solving Travelling Salesman Problems (TSP). However, ACO suffers\nfrom two issues; the first is that the technique has significant memory\nrequirements for storing pheromone levels on edges between cities and second,\nthe iterative probabilistic nature of choosing which city to visit next at\nevery step is computationally expensive. This restricts ACO from solving larger\nTSP instances. This paper will present a methodology for deploying ACO on\nlarger TSP instances by removing the high memory requirements, exploiting\nparallel CPU hardware and introducing a significant efficiency saving measure.\nThe approach results in greater accuracy and speed. This enables the proposed\nACO approach to tackle TSP instances of up to 200K cities within reasonable\ntimescales using a single CPU. Speedups of as much as 1200 fold are achieved by\nthe technique.\n", "versions": [{"version": "v1", "created": "Sun, 10 Sep 2017 22:21:36 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Chitty", "Darren M.", ""]]}, {"id": "1709.03247", "submitter": "Oliver Kramer", "authors": "Oliver Kramer", "title": "Evolution of Convolutional Highway Networks", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional highways are deep networks based on multiple stacked\nconvolutional layers for feature preprocessing. We introduce an evolutionary\nalgorithm (EA) for optimization of the structure and hyperparameters of\nconvolutional highways and demonstrate the potential of this optimization\nsetting on the well-known MNIST data set. The (1+1)-EA employs Rechenberg's\nmutation rate control and a niching mechanism to overcome local optima adapts\nthe optimization approach. An experimental study shows that the EA is capable\nof improving the state-of-the-art network contribution and of evolving highway\nnetworks from scratch.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 05:37:53 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Kramer", "Oliver", ""]]}, {"id": "1709.03450", "submitter": "Mario Amrehn", "authors": "Mario Amrehn, Sven Gaube, Mathias Unberath, Frank Schebesch, Tim Horz,\n  Maddalena Strumia, Stefan Steidl, Markus Kowarschik, Andreas Maier", "title": "UI-Net: Interactive Artificial Neural Networks for Iterative Image\n  Segmentation Based on a User Model", "comments": "This work is submitted to the 2017 Eurographics Workshop on Visual\n  Computing for Biology and Medicine", "journal-ref": "Eurographics Workshop on Visual Computing for Biology and Medicine\n  (2017) 143-147", "doi": "10.2312/vcbm.20171248", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For complex segmentation tasks, fully automatic systems are inherently\nlimited in their achievable accuracy for extracting relevant objects.\nEspecially in cases where only few data sets need to be processed for a highly\naccurate result, semi-automatic segmentation techniques exhibit a clear benefit\nfor the user. One area of application is medical image processing during an\nintervention for a single patient. We propose a learning-based cooperative\nsegmentation approach which includes the computing entity as well as the user\ninto the task. Our system builds upon a state-of-the-art fully convolutional\nartificial neural network (FCN) as well as an active user model for training.\nDuring the segmentation process, a user of the trained system can iteratively\nadd additional hints in form of pictorial scribbles as seed points into the FCN\nsystem to achieve an interactive and precise segmentation result. The\nsegmentation quality of interactive FCNs is evaluated. Iterative FCN approaches\ncan yield superior results compared to networks without the user input channel\ncomponent, due to a consistent improvement in segmentation quality after each\ninteraction.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 15:50:24 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Amrehn", "Mario", ""], ["Gaube", "Sven", ""], ["Unberath", "Mathias", ""], ["Schebesch", "Frank", ""], ["Horz", "Tim", ""], ["Strumia", "Maddalena", ""], ["Steidl", "Stefan", ""], ["Kowarschik", "Markus", ""], ["Maier", "Andreas", ""]]}, {"id": "1709.03485", "submitter": "Eli Gibson", "authors": "Eli Gibson, Wenqi Li, Carole Sudre, Lucas Fidon, Dzhoshkun I. Shakir,\n  Guotai Wang, Zach Eaton-Rosen, Robert Gray, Tom Doel, Yipeng Hu, Tom Whyntie,\n  Parashkev Nachev, Marc Modat, Dean C. Barratt, S\\'ebastien Ourselin, M. Jorge\n  Cardoso and Tom Vercauteren", "title": "NiftyNet: a deep-learning platform for medical imaging", "comments": "Wenqi Li and Eli Gibson contributed equally to this work. M. Jorge\n  Cardoso and Tom Vercauteren contributed equally to this work. 26 pages, 6\n  figures; Update includes additional applications, updated author list and\n  formatting for journal submission", "journal-ref": null, "doi": "10.1016/j.cmpb.2018.01.025", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical image analysis and computer-assisted intervention problems are\nincreasingly being addressed with deep-learning-based solutions. Established\ndeep-learning platforms are flexible but do not provide specific functionality\nfor medical image analysis and adapting them for this application requires\nsubstantial implementation effort. Thus, there has been substantial duplication\nof effort and incompatible infrastructure developed across many research\ngroups. This work presents the open-source NiftyNet platform for deep learning\nin medical imaging. The ambition of NiftyNet is to accelerate and simplify the\ndevelopment of these solutions, and to provide a common mechanism for\ndisseminating research outputs for the community to use, adapt and build upon.\n  NiftyNet provides a modular deep-learning pipeline for a range of medical\nimaging applications including segmentation, regression, image generation and\nrepresentation learning applications. Components of the NiftyNet pipeline\nincluding data loading, data augmentation, network architectures, loss\nfunctions and evaluation metrics are tailored to, and take advantage of, the\nidiosyncracies of medical image analysis and computer-assisted intervention.\nNiftyNet is built on TensorFlow and supports TensorBoard visualization of 2D\nand 3D images and computational graphs by default.\n  We present 3 illustrative medical image analysis applications built using\nNiftyNet: (1) segmentation of multiple abdominal organs from computed\ntomography; (2) image regression to predict computed tomography attenuation\nmaps from brain magnetic resonance images; and (3) generation of simulated\nultrasound images for specified anatomical poses.\n  NiftyNet enables researchers to rapidly develop and distribute deep learning\nsolutions for segmentation, regression, image generation and representation\nlearning applications, or extend the platform to new applications.\n", "versions": [{"version": "v1", "created": "Mon, 11 Sep 2017 17:42:10 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 13:46:31 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Gibson", "Eli", ""], ["Li", "Wenqi", ""], ["Sudre", "Carole", ""], ["Fidon", "Lucas", ""], ["Shakir", "Dzhoshkun I.", ""], ["Wang", "Guotai", ""], ["Eaton-Rosen", "Zach", ""], ["Gray", "Robert", ""], ["Doel", "Tom", ""], ["Hu", "Yipeng", ""], ["Whyntie", "Tom", ""], ["Nachev", "Parashkev", ""], ["Modat", "Marc", ""], ["Barratt", "Dean C.", ""], ["Ourselin", "S\u00e9bastien", ""], ["Cardoso", "M. Jorge", ""], ["Vercauteren", "Tom", ""]]}, {"id": "1709.03793", "submitter": "Shubham Dokania", "authors": "Shubham Dokania, Sunyam Bagga, Rohit Sharma", "title": "Opportunistic Self Organizing Migrating Algorithm for Real-Time Dynamic\n  Traveling Salesman Problem", "comments": "6 pages, published in CISS 2017", "journal-ref": null, "doi": "10.1109/CISS.2017.7926065", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Self Organizing Migrating Algorithm (SOMA) is a meta-heuristic algorithm\nbased on the self-organizing behavior of individuals in a simulated social\nenvironment. SOMA performs iterative computations on a population of potential\nsolutions in the given search space to obtain an optimal solution. In this\npaper, an Opportunistic Self Organizing Migrating Algorithm (OSOMA) has been\nproposed that introduces a novel strategy to generate perturbations\neffectively. This strategy allows the individual to span across more possible\nsolutions and thus, is able to produce better solutions. A comprehensive\nanalysis of OSOMA on multi-dimensional unconstrained benchmark test functions\nis performed. OSOMA is then applied to solve real-time Dynamic Traveling\nSalesman Problem (DTSP). The problem of real-time DTSP has been stipulated and\nsimulated using real-time data from Google Maps with a varying cost-metric\nbetween any two cities. Although DTSP is a very common and intuitive model in\nthe real world, its presence in literature is still very limited. OSOMA\nperforms exceptionally well on the problems mentioned above. To substantiate\nthis claim, the performance of OSOMA is compared with SOMA, Differential\nEvolution and Particle Swarm Optimization.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 11:47:07 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Dokania", "Shubham", ""], ["Bagga", "Sunyam", ""], ["Sharma", "Rohit", ""]]}, {"id": "1709.03849", "submitter": "Christopher H Bennett", "authors": "Christopher H. Bennett, Damien Querlioz, and Jacques-Olivier Klein", "title": "Spatio-temporal Learning with Arrays of Analog Nanosynapses", "comments": "6 pages, 3 figures. Presented at 2017 IEEE/ACM Symposium on Nanoscale\n  architectures (NANOARCH)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging nanodevices such as resistive memories are being considered for\nhardware realizations of a variety of artificial neural networks (ANNs),\nincluding highly promising online variants of the learning approaches known as\nreservoir computing (RC) and the extreme learning machine (ELM). We propose an\nRC/ELM inspired learning system built with nanosynapses that performs both\non-chip projection and regression operations. To address time-dynamic tasks,\nthe hidden neurons of our system perform spatio-temporal integration and can be\nfurther enhanced with variable sampling or multiple activation windows. We\ndetail the system and show its use in conjunction with a highly analog\nnanosynapse device on a standard task with intrinsic timing dynamics- the TI-46\nbattery of spoken digits. The system achieves nearly perfect (99%) accuracy at\nsufficient hidden layer size, which compares favorably with software results.\nIn addition, the model is extended to a larger dataset, the MNIST database of\nhandwritten digits. By translating the database into the time domain and using\nvariable integration windows, up to 95% classification accuracy is achieved. In\naddition to an intrinsically low-power programming style, the proposed\narchitecture learns very quickly and can easily be converted into a spiking\nsystem with negligible loss in performance- all features that confer\nsignificant energy efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 14:04:06 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Bennett", "Christopher H.", ""], ["Querlioz", "Damien", ""], ["Klein", "Jacques-Olivier", ""]]}, {"id": "1709.03946", "submitter": "Nikhita Vedula", "authors": "Nikhita Vedula, Wei Sun, Hyunhwan Lee, Harsh Gupta, Mitsunori Ogihara,\n  Joseph Johnson, Gang Ren, Srinivasan Parthasarathy", "title": "Multimodal Content Analysis for Effective Advertisements on YouTube", "comments": "11 pages, 5 figures, ICDM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid advances in e-commerce and Web 2.0 technologies have greatly\nincreased the impact of commercial advertisements on the general public. As a\nkey enabling technology, a multitude of recommender systems exists which\nanalyzes user features and browsing patterns to recommend appealing\nadvertisements to users. In this work, we seek to study the characteristics or\nattributes that characterize an effective advertisement and recommend a useful\nset of features to aid the designing and production processes of commercial\nadvertisements. We analyze the temporal patterns from multimedia content of\nadvertisement videos including auditory, visual and textual components, and\nstudy their individual roles and synergies in the success of an advertisement.\nThe objective of this work is then to measure the effectiveness of an\nadvertisement, and to recommend a useful set of features to advertisement\ndesigners to make it more successful and approachable to users. Our proposed\nframework employs the signal processing technique of cross modality feature\nlearning where data streams from different components are employed to train\nseparate neural network models and are then fused together to learn a shared\nrepresentation. Subsequently, a neural network model trained on this joint\nfeature embedding representation is utilized as a classifier to predict\nadvertisement effectiveness. We validate our approach using subjective ratings\nfrom a dedicated user study, the sentiment strength of online viewer comments,\nand a viewer opinion metric of the ratio of the Likes and Views received by\neach advertisement from an online platform.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 16:47:21 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Vedula", "Nikhita", ""], ["Sun", "Wei", ""], ["Lee", "Hyunhwan", ""], ["Gupta", "Harsh", ""], ["Ogihara", "Mitsunori", ""], ["Johnson", "Joseph", ""], ["Ren", "Gang", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "1709.04054", "submitter": "Lars Eidnes", "authors": "Lars Eidnes, Arild N{\\o}kland", "title": "Shifting Mean Activation Towards Zero with Bipolar Activation Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple extension to the ReLU-family of activation functions that\nallows them to shift the mean activation across a layer towards zero. Combined\nwith proper weight initialization, this alleviates the need for normalization\nlayers. We explore the training of deep vanilla recurrent neural networks\n(RNNs) with up to 144 layers, and show that bipolar activation functions help\nlearning in this setting. On the Penn Treebank and Text8 language modeling\ntasks we obtain competitive results, improving on the best reported results for\nnon-gated networks. In experiments with convolutional neural networks without\nbatch normalization, we find that bipolar activations produce a faster drop in\ntraining error, and results in a lower test error on the CIFAR-10\nclassification task.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 20:44:15 GMT"}, {"version": "v2", "created": "Mon, 18 Dec 2017 20:18:47 GMT"}, {"version": "v3", "created": "Thu, 15 Mar 2018 01:59:24 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Eidnes", "Lars", ""], ["N\u00f8kland", "Arild", ""]]}, {"id": "1709.04057", "submitter": "Eric Martin", "authors": "Eric Martin, Chris Cundy", "title": "Parallelizing Linear Recurrent Neural Nets Over Sequence Length", "comments": "9 pages. Published as a conference paper at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are widely used to model sequential data but\ntheir non-linear dependencies between sequence elements prevent parallelizing\ntraining over sequence length. We show the training of RNNs with only linear\nsequential dependencies can be parallelized over the sequence length using the\nparallel scan algorithm, leading to rapid training on long sequences even with\nsmall minibatch size. We develop a parallel linear recurrence CUDA kernel and\nshow that it can be applied to immediately speed up training and inference of\nseveral state of the art RNN architectures by up to 9x. We abstract recent work\non linear RNNs into a new framework of linear surrogate RNNs and develop a\nlinear surrogate model for the long short-term memory unit, the GILR-LSTM, that\nutilizes parallel linear recurrence. We extend sequence learning to new\nextremely long sequence regimes that were previously out of reach by\nsuccessfully training a GILR-LSTM on a synthetic sequence classification task\nwith a one million timestep dependency.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 20:52:22 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 05:38:25 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Martin", "Eric", ""], ["Cundy", "Chris", ""]]}, {"id": "1709.04317", "submitter": "Mohammad Tarek Al Muallim M.Sc.", "authors": "Mohammad Tarek Al Muallim", "title": "Pattern Recognition using Artificial Immune System", "comments": "MSc Thesis, 126 pages, in Arabic", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, the uses of Artificial Immune Systems (AIS) in Machine\nlearning is studded. the thesis focus on some of immune inspired algorithms\nsuch as clonal selection algorithm and artificial immune network. The effect of\nchanging the algorithm parameter on its performance is studded. Then a new\nimmune inspired algorithm for unsupervised classification is proposed. The new\nalgorithm is based on clonal selection principle and named Unsupervised Clonal\nSelection Classification (UCSC). The new proposed algorithm is almost parameter\nfree. The algorithm parameters are data driven and it adjusts itself to make\nthe classification as fast as possible. The performance of UCSC is evaluated.\nThe experiments show that the proposed UCSC algorithm has a good performance\nand more reliable.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 07:09:47 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Muallim", "Mohammad Tarek Al", ""]]}, {"id": "1709.04318", "submitter": "Varun Ojha", "authors": "Varun Kumar Ojha, Serena Schiano, Chuan-Yu Wu, V\\'aclav Sn\\'a\\v{s}el,\n  Ajith Abraham", "title": "Predictive modeling of die filling of the pharmaceutical granules using\n  the flexible neural tree", "comments": null, "journal-ref": "Neural Computing and Application, 2016", "doi": "10.1007/s00521-016-2545-8", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a computational intelligence (CI) technique named flexible\nneural tree (FNT) was developed to predict die filling performance of\npharmaceutical granules and to identify significant die filling process\nvariables. FNT resembles feedforward neural network, which creates a tree-like\nstructure by using genetic programming. To improve accuracy, FNT parameters\nwere optimized by using differential evolution algorithm. The performance of\nthe FNT-based CI model was evaluated and compared with other CI techniques:\nmultilayer perceptron, Gaussian process regression, and reduced error pruning\ntree. The accuracy of the CI model was evaluated experimentally using die\nfilling as a case study. The die filling experiments were performed using a\nmodel shoe system and three different grades of microcrystalline cellulose\n(MCC) powders (MCC PH 101, MCC PH 102, and MCC DG). The feed powders were\nroll-compacted and milled into granules. The granules were then sieved into\nsamples of various size classes. The mass of granules deposited into the die at\ndifferent shoe speeds was measured. From these experiments, a dataset\nconsisting true density, mean diameter (d50), granule size, and shoe speed as\nthe inputs and the deposited mass as the output was generated. Cross-validation\n(CV) methods such as 10FCV and 5x2FCV were applied to develop and to validate\nthe predictive models. It was found that the FNT-based CI model (for both CV\nmethods) performed much better than other CI models. Additionally, it was\nobserved that process variables such as the granule size and the shoe speed had\na higher impact on the predictability than that of the powder property such as\nd50. Furthermore, validation of model prediction with experimental data showed\nthat the die filling behavior of coarse granules could be better predicted than\nthat of fine granules.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 08:50:24 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Ojha", "Varun Kumar", ""], ["Schiano", "Serena", ""], ["Wu", "Chuan-Yu", ""], ["Sn\u00e1\u0161el", "V\u00e1clav", ""], ["Abraham", "Ajith", ""]]}, {"id": "1709.04319", "submitter": "Gang Cao", "authors": "Gang Cao, Edmund M-K Lai, Fakhrul Alam", "title": "Enhanced Particle Swarm Optimization Algorithms for Multiple-Input\n  Multiple-Output System Modelling using Convolved Gaussian Process Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolved Gaussian Process (CGP) is able to capture the correlations not only\nbetween inputs and outputs but also among the outputs. This allows a superior\nperformance of using CGP than standard Gaussian Process (GP) in the modelling\nof Multiple-Input Multiple-Output (MIMO) systems when observations are missing\nfor some of outputs. Similar to standard GP, a key issue of CGP is the learning\nof hyperparameters from a set of input-output observations. It typically\nperformed by maximizing the Log-Likelihood (LL) function which leads to an\nunconstrained nonlinear and non-convex optimization problem. Algorithms such as\nConjugate Gradient (CG) or Broyden-Fletcher-Goldfarb-Shanno (BFGS) are commonly\nused but they often get stuck in local optima, especially for CGP where there\nare more hyperparameters. In addition, the LL value is not a reliable indicator\nfor judging the quality intermediate models in the optimization process. In\nthis paper, we propose to use enhanced Particle Swarm Optimization (PSO)\nalgorithms to solve this problem by minimizing the model output error instead.\nThis optimization criterion enables the quality of intermediate solutions to be\ndirectly observable during the optimization process. Two enhancements to the\nstandard PSO algorithm which make use of gradient information and the multi-\nstart technique are proposed. Simulation results on the modelling of both\nlinear and nonlinear systems demonstrate the effectiveness of minimizing the\nmodel output error to learn hyperparameters and the performance of using\nenhanced algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 22:39:07 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Cao", "Gang", ""], ["Lai", "Edmund M-K", ""], ["Alam", "Fakhrul", ""]]}, {"id": "1709.04320", "submitter": "Xu Gong", "authors": "Xu Gong, David Plets, Emmeric Tanghe, Toon De Pessemier, Luc Martens,\n  Wout Joseph", "title": "An efficient genetic algorithm for large-scale transmit power control of\n  dense industrial wireless networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The industrial wireless local area network (IWLAN) is increasingly dense, not\nonly due to the penetration of wireless applications into factories and\nwarehouses, but also because of the rising need of redundancy for robust\nwireless coverage. Instead of powering on all the nodes with the maximal\ntransmit power, it becomes an unavoidable challenge to control the transmit\npower of all wireless nodes on a large scale, in order to reduce interference\nand adapt coverage to the latest shadowing effects in the environment.\nTherefore, this paper proposes an efficient genetic algorithm (GA) to solve\nthis transmit power control (TPC) problem for dense IWLANs, named GATPC.\nEffective population initialization, crossover and mutation, parallel computing\nas well as dedicated speedup measures are introduced to tailor GATPC for the\nlarge-scale optimization that is intrinsically involved in this problem. In\ncontrast to most coverage-related optimization algorithms which cannot deal\nwith the prevalent shadowing effects in harsh industrial indoor environments,\nan empirical one-slope path loss model considering three-dimensional obstacle\nshadowing effects is used in GATPC, in order to enable accurate yet simple\ncoverage prediction. Experimental validation and numerical experiments in real\nindustrial cases show the promising performance of GATPC in terms of\nscalability to a hyper-large scale, up to 37-times speedup in resolution\nruntime, and solution quality to achieve adaptive coverage and to minimize\ninterference.\n", "versions": [{"version": "v1", "created": "Sat, 12 Aug 2017 18:15:08 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Gong", "Xu", ""], ["Plets", "David", ""], ["Tanghe", "Emmeric", ""], ["De Pessemier", "Toon", ""], ["Martens", "Luc", ""], ["Joseph", "Wout", ""]]}, {"id": "1709.04321", "submitter": "Xu Gong", "authors": "Xu Gong, David Plets, Emmeric Tanghe, Toon De Pessemier, Luc Martens,\n  Wout Joseph", "title": "An efficient genetic algorithm for large-scale planning of robust\n  industrial wireless networks", "comments": null, "journal-ref": "Expert Systems with Applications 2017", "doi": "10.1016/j.eswa.2017.12.011", "report-no": null, "categories": "cs.NE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An industrial indoor environment is harsh for wireless communications\ncompared to an office environment, because the prevalent metal easily causes\nshadowing effects and affects the availability of an industrial wireless local\narea network (IWLAN). On the one hand, it is costly, time-consuming, and\nineffective to perform trial-and-error manual deployment of wireless nodes. On\nthe other hand, the existing wireless planning tools only focus on office\nenvironments such that it is hard to plan IWLANs due to the larger problem size\nand the deployed IWLANs are vulnerable to prevalent shadowing effects in harsh\nindustrial indoor environments. To fill this gap, this paper proposes an\noverdimensioning model and a genetic algorithm based over-dimensioning (GAOD)\nalgorithm for deploying large-scale robust IWLANs. As a progress beyond the\nstate-of-the-art wireless planning, two full coverage layers are created. The\nsecond coverage layer serves as redundancy in case of shadowing. Meanwhile, the\ndeployment cost is reduced by minimizing the number of access points (APs); the\nhard constraint of minimal inter-AP spatial paration avoids multiple APs\ncovering the same area to be simultaneously shadowed by the same obstacle. The\ncomputation time and occupied memory are dedicatedly considered in the design\nof GAOD for large-scale optimization. A greedy heuristic based\nover-dimensioning (GHOD) algorithm and a random OD algorithm are taken as\nbenchmarks. In two vehicle manufacturers with a small and large indoor\nenvironment, GAOD outperformed GHOD with up to 20% less APs, while GHOD\noutputted up to 25% less APs than a random OD algorithm. Furthermore, the\neffectiveness of this model and GAOD was experimentally validated with a real\ndeployment system.\n", "versions": [{"version": "v1", "created": "Sat, 12 Aug 2017 18:20:25 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Gong", "Xu", ""], ["Plets", "David", ""], ["Tanghe", "Emmeric", ""], ["De Pessemier", "Toon", ""], ["Martens", "Luc", ""], ["Joseph", "Wout", ""]]}, {"id": "1709.04322", "submitter": "Ankit Mondal", "authors": "Ankit Mondal and Ankur Srivastava", "title": "Power Optimizations in MTJ-based Neural Networks through Stochastic\n  Computing", "comments": "Accepted in the 2017 IEEE/ACM International Conference on Low Power\n  Electronics and Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks (ANNs) have found widespread applications in tasks\nsuch as pattern recognition and image classification. However, hardware\nimplementations of ANNs using conventional binary arithmetic units are\ncomputationally expensive, energy-intensive and have large area overheads.\nStochastic Computing (SC) is an emerging paradigm which replaces these\nconventional units with simple logic circuits and is particularly suitable for\nfault-tolerant applications. Spintronic devices, such as Magnetic Tunnel\nJunctions (MTJs), are capable of replacing CMOS in memory and logic circuits.\nIn this work, we propose an energy-efficient use of MTJs, which exhibit\nprobabilistic switching behavior, as Stochastic Number Generators (SNGs), which\nforms the basis of our NN implementation in the SC domain. Further, error\nresilient target applications of NNs allow us to introduce Approximate\nComputing, a framework wherein accuracy of computations is traded-off for\nsubstantial reductions in power consumption. We propose approximating the\nsynaptic weights in our MTJ-based NN implementation, in ways brought about by\nproperties of our MTJ-SNG, to achieve energy-efficiency. We design an algorithm\nthat can perform such approximations within a given error tolerance in a\nsingle-layer NN in an optimal way owing to the convexity of the problem\nformulation. We then use this algorithm and develop a heuristic approach for\napproximating multi-layer NNs. To give a perspective of the effectiveness of\nour approach, a 43% reduction in power consumption was obtained with less than\n1% accuracy loss on a standard classification problem, with 26% being brought\nabout by the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 19:56:23 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Mondal", "Ankit", ""], ["Srivastava", "Ankur", ""]]}, {"id": "1709.04482", "submitter": "Yonatan Belinkov", "authors": "Yonatan Belinkov, James Glass", "title": "Analyzing Hidden Representations in End-to-End Automatic Speech\n  Recognition Systems", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural models have become ubiquitous in automatic speech recognition systems.\nWhile neural networks are typically used as acoustic models in more complex\nsystems, recent studies have explored end-to-end speech recognition systems\nbased on neural networks, which can be trained to directly predict text from\ninput acoustic features. Although such systems are conceptually elegant and\nsimpler than traditional systems, it is less obvious how to interpret the\ntrained models. In this work, we analyze the speech representations learned by\na deep end-to-end model that is based on convolutional and recurrent layers,\nand trained with a connectionist temporal classification (CTC) loss. We use a\npre-trained model to generate frame-level features which are given to a\nclassifier that is trained on frame classification into phones. We evaluate\nrepresentations from different layers of the deep model and compare their\nquality for predicting phone labels. Our experiments shed light on important\naspects of the end-to-end model such as layer depth, model complexity, and\nother design choices.\n", "versions": [{"version": "v1", "created": "Wed, 13 Sep 2017 18:02:53 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Belinkov", "Yonatan", ""], ["Glass", "James", ""]]}, {"id": "1709.05027", "submitter": "Wei Wen", "authors": "Wei Wen, Yuxiong He, Samyam Rajbhandari, Minjia Zhang, Wenhan Wang,\n  Fang Liu, Bin Hu, Yiran Chen, Hai Li", "title": "Learning Intrinsic Sparse Structures within Long Short-Term Memory", "comments": "Published in ICLR 2018 ( the Sixth International Conference on\n  Learning Representations)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression is significant for the wide adoption of Recurrent Neural\nNetworks (RNNs) in both user devices possessing limited resources and business\nclusters requiring quick responses to large-scale service requests. This work\naims to learn structurally-sparse Long Short-Term Memory (LSTM) by reducing the\nsizes of basic structures within LSTM units, including input updates, gates,\nhidden states, cell states and outputs. Independently reducing the sizes of\nbasic structures can result in inconsistent dimensions among them, and\nconsequently, end up with invalid LSTM units. To overcome the problem, we\npropose Intrinsic Sparse Structures (ISS) in LSTMs. Removing a component of ISS\nwill simultaneously decrease the sizes of all basic structures by one and\nthereby always maintain the dimension consistency. By learning ISS within LSTM\nunits, the obtained LSTMs remain regular while having much smaller basic\nstructures. Based on group Lasso regularization, our method achieves 10.59x\nspeedup without losing any perplexity of a language modeling of Penn TreeBank\ndataset. It is also successfully evaluated through a compact model with only\n2.69M weights for machine Question Answering of SQuAD dataset. Our approach is\nsuccessfully extended to non- LSTM RNNs, like Recurrent Highway Networks\n(RHNs). Our source code is publicly available at\nhttps://github.com/wenwei202/iss-rnns\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 01:10:23 GMT"}, {"version": "v2", "created": "Fri, 13 Oct 2017 17:23:05 GMT"}, {"version": "v3", "created": "Sat, 28 Oct 2017 15:49:22 GMT"}, {"version": "v4", "created": "Sun, 24 Dec 2017 19:24:23 GMT"}, {"version": "v5", "created": "Fri, 5 Jan 2018 16:23:10 GMT"}, {"version": "v6", "created": "Tue, 30 Jan 2018 04:42:43 GMT"}, {"version": "v7", "created": "Sun, 11 Feb 2018 16:36:32 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Wen", "Wei", ""], ["He", "Yuxiong", ""], ["Rajbhandari", "Samyam", ""], ["Zhang", "Minjia", ""], ["Wang", "Wenhan", ""], ["Liu", "Fang", ""], ["Hu", "Bin", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "1709.05306", "submitter": "Tianchan Guan", "authors": "Tianchan Guan, Xiaoyang Zeng, Mingoo Seok", "title": "Recursive Binary Neural Network Learning Model with 2.28b/Weight Storage\n  Requirement", "comments": "10 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a storage-efficient learning model titled Recursive\nBinary Neural Networks for sensing devices having a limited amount of on-chip\ndata storage such as < 100's kilo-Bytes. The main idea of the proposed model is\nto recursively recycle data storage of synaptic weights (parameters) during\ntraining. This enables a device with a given storage constraint to train and\ninstantiate a neural network classifier with a larger number of weights on a\nchip and with a less number of off-chip storage accesses. This enables higher\nclassification accuracy, shorter training time, less energy dissipation, and\nless on-chip storage requirement. We verified the training model with deep\nneural network classifiers and the permutation-invariant MNIST benchmark. Our\nmodel uses only 2.28 bits/weight while for the same data storage constraint\nachieving ~1% lower classification error as compared to the conventional\nbinary-weight learning model which yet has to use 8 to 16 bit storage per\nweight. To achieve the similar classification error, the conventional binary\nmodel requires ~4x more data storage for weights than the proposed model.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 16:57:11 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Guan", "Tianchan", ""], ["Zeng", "Xiaoyang", ""], ["Seok", "Mingoo", ""]]}, {"id": "1709.05340", "submitter": "Saarthak Sarup", "authors": "Saarthak Sarup and Mingoo Seok", "title": "Dynamic Capacity Estimation in Hopfield Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the memory capacity of neural networks remains a challenging\nproblem in implementing artificial intelligence systems. In this paper, we\naddress the notion of capacity with respect to Hopfield networks and propose a\ndynamic approach to monitoring a network's capacity. We define our\nunderstanding of capacity as the maximum number of stored patterns which can be\nretrieved when probed by the stored patterns. Prior work in this area has\npresented static expressions dependent on neuron count $N$, forcing network\ndesigners to assume worst-case input characteristics for bias and correlation\nwhen setting the capacity of the network. Instead, our model operates\nsimultaneously with the learning Hopfield network and concludes on a capacity\nestimate based on the patterns which were stored. By continuously updating the\ncrosstalk associated with the stored patterns, our model guards the network\nfrom overwriting its memory traces and exceeding its capacity. We simulate our\nmodel using artificially generated random patterns, which can be set to a\ndesired bias and correlation, and observe capacity estimates between 93% and\n97% accurate. As a result, our model doubles the memory efficiency of Hopfield\nnetworks in comparison to the static and worst-case capacity estimate while\nminimizing the risk of lost patterns.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 01:48:20 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Sarup", "Saarthak", ""], ["Seok", "Mingoo", ""]]}, {"id": "1709.05394", "submitter": "William La Cava", "authors": "William La Cava, Thomas Helmuth, Lee Spector, Jason H. Moore", "title": "A probabilistic and multi-objective analysis of lexicase selection and\n  epsilon-lexicase selection", "comments": "30 pages, 8 figures. To appear in Evolutionary Computation Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexicase selection is a parent selection method that considers training cases\nindividually, rather than in aggregate, when performing parent selection.\nWhereas previous work has demonstrated the ability of lexicase selection to\nsolve difficult problems in program synthesis and symbolic regression, the\ncentral goal of this paper is to develop the theoretical underpinnings that\nexplain its performance. To this end, we derive an analytical formula that\ngives the expected probabilities of selection under lexicase selection, given a\npopulation and its behavior. In addition, we expand upon the relation of\nlexicase selection to many-objective optimization methods to describe the\nbehavior of lexicase selection, which is to select individuals on the\nboundaries of Pareto fronts in high-dimensional space. We show analytically why\nlexicase selection performs more poorly for certain sizes of population and\ntraining cases, and show why it has been shown to perform more poorly in\ncontinuous error spaces. To address this last concern, we propose new variants\nof epsilon-lexicase selection, a method that modifies the pass condition in\nlexicase selection to allow near-elite individuals to pass cases, thereby\nimproving selection performance with continuous errors. We show that\nepsilon-lexicase outperforms several diversity-maintenance strategies on a\nnumber of real-world and synthetic regression problems.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 20:38:38 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 21:45:50 GMT"}, {"version": "v3", "created": "Sun, 29 Apr 2018 23:46:48 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["La Cava", "William", ""], ["Helmuth", "Thomas", ""], ["Spector", "Lee", ""], ["Moore", "Jason H.", ""]]}, {"id": "1709.05538", "submitter": "Wentao Zhu", "authors": "Wentao Zhu, Chaochun Liu, Wei Fan, Xiaohui Xie", "title": "DeepLung: 3D Deep Convolutional Nets for Automated Pulmonary Nodule\n  Detection and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, we present a fully automated lung CT cancer diagnosis system,\nDeepLung. DeepLung contains two parts, nodule detection and classification.\nConsidering the 3D nature of lung CT data, two 3D networks are designed for the\nnodule detection and classification respectively. Specifically, a 3D Faster\nR-CNN is designed for nodule detection with a U-net-like encoder-decoder\nstructure to effectively learn nodule features. For nodule classification,\ngradient boosting machine (GBM) with 3D dual path network (DPN) features is\nproposed. The nodule classification subnetwork is validated on a public dataset\nfrom LIDC-IDRI, on which it achieves better performance than state-of-the-art\napproaches, and surpasses the average performance of four experienced doctors.\nFor the DeepLung system, candidate nodules are detected first by the nodule\ndetection subnetwork, and nodule diagnosis is conducted by the classification\nsubnetwork. Extensive experimental results demonstrate the DeepLung is\ncomparable to the experienced doctors both for the nodule-level and\npatient-level diagnosis on the LIDC-IDRI dataset.\n", "versions": [{"version": "v1", "created": "Sat, 16 Sep 2017 16:18:22 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Zhu", "Wentao", ""], ["Liu", "Chaochun", ""], ["Fan", "Wei", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1709.05703", "submitter": "Justin Gottschlich", "authors": "Kory Becker and Justin Gottschlich", "title": "AI Programmer: Autonomously Creating Software Programs Using Genetic\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the first-of-its-kind machine learning (ML) system,\ncalled AI Programmer, that can automatically generate full software programs\nrequiring only minimal human guidance. At its core, AI Programmer uses genetic\nalgorithms (GA) coupled with a tightly constrained programming language that\nminimizes the overhead of its ML search space. Part of AI Programmer's novelty\nstems from (i) its unique system design, including an embedded, hand-crafted\ninterpreter for efficiency and security and (ii) its augmentation of GAs to\ninclude instruction-gene randomization bindings and programming\nlanguage-specific genome construction and elimination techniques. We provide a\ndetailed examination of AI Programmer's system design, several examples\ndetailing how the system works, and experimental data demonstrating its\nsoftware generation capabilities and performance using only mainstream CPUs.\n", "versions": [{"version": "v1", "created": "Sun, 17 Sep 2017 18:17:55 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Becker", "Kory", ""], ["Gottschlich", "Justin", ""]]}, {"id": "1709.05804", "submitter": "Bingzhen Wei", "authors": "Bingzhen Wei, Xu Sun, Xuancheng Ren, Jingjing Xu", "title": "Minimal Effort Back Propagation for Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As traditional neural network consumes a significant amount of computing\nresources during back propagation, \\citet{Sun2017mePropSB} propose a simple yet\neffective technique to alleviate this problem. In this technique, only a small\nsubset of the full gradients are computed to update the model parameters. In\nthis paper we extend this technique into the Convolutional Neural Network(CNN)\nto reduce calculation in back propagation, and the surprising results verify\nits validity in CNN: only 5\\% of the gradients are passed back but the model\nstill achieves the same effect as the traditional CNN, or even better. We also\nshow that the top-$k$ selection of gradients leads to a sparse calculation in\nback propagation, which may bring significant computational benefits for high\ncomputational complexity of convolution operation in CNN.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 08:07:40 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Wei", "Bingzhen", ""], ["Sun", "Xu", ""], ["Ren", "Xuancheng", ""], ["Xu", "Jingjing", ""]]}, {"id": "1709.05870", "submitter": "Jiaxin Shi", "authors": "Jiaxin Shi, Jianfei Chen, Jun Zhu, Shengyang Sun, Yucen Luo, Yihong\n  Gu, Yuhao Zhou", "title": "ZhuSuan: A Library for Bayesian Deep Learning", "comments": "The GitHub page is at https://github.com/thu-ml/zhusuan", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce ZhuSuan, a python probabilistic programming\nlibrary for Bayesian deep learning, which conjoins the complimentary advantages\nof Bayesian methods and deep learning. ZhuSuan is built upon Tensorflow. Unlike\nexisting deep learning libraries, which are mainly designed for deterministic\nneural networks and supervised tasks, ZhuSuan is featured for its deep root\ninto Bayesian inference, thus supporting various kinds of probabilistic models,\nincluding both the traditional hierarchical Bayesian models and recent deep\ngenerative models. We use running examples to illustrate the probabilistic\nprogramming on ZhuSuan, including Bayesian logistic regression, variational\nauto-encoders, deep sigmoid belief networks and Bayesian recurrent neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 11:30:08 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Shi", "Jiaxin", ""], ["Chen", "Jianfei", ""], ["Zhu", "Jun", ""], ["Sun", "Shengyang", ""], ["Luo", "Yucen", ""], ["Gu", "Yihong", ""], ["Zhou", "Yuhao", ""]]}, {"id": "1709.05915", "submitter": "Wenji Li", "authors": "Zhun Fan, Wenji Li, Xinye Cai, Hui Li, Caimin Wei, Qingfu Zhang,\n  Kalyanmoy Deb, and Erik D. Goodman", "title": "Push and Pull Search for Solving Constrained Multi-objective\n  Optimization Problems", "comments": "13 pages, 10 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a push and pull search (PPS) framework for solving\nconstrained multi-objective optimization problems (CMOPs). To be more specific,\nthe proposed PPS divides the search process into two different stages,\nincluding the push and pull search stages. In the push stage, a multi-objective\nevolutionary algorithm (MOEA) is adopted to explore the search space without\nconsidering any constraints, which can help to get across infeasible regions\nvery fast and approach the unconstrained Pareto front. Furthermore, the\nlandscape of CMOPs with constraints can be probed and estimated in the push\nstage, which can be utilized to conduct the parameters setting for\nconstraint-handling approaches applied in the pull stage. Then, a constrained\nmulti-objective evolutionary algorithm (CMOEA) equipped with an improved\nepsilon constraint-handling is applied to pull the infeasible individuals\nachieved in the push stage to the feasible and non-dominated regions. Compared\nwith other CMOEAs, the proposed PPS method can more efficiently get across\ninfeasible regions and converge to the feasible and non-dominated regions by\napplying push and pull search strategies at different stages. To evaluate the\nperformance regarding convergence and diversity, a set of benchmark CMOPs is\nused to test the proposed PPS and compare with other five CMOEAs, including\nMOEA/D-CDP, MOEA/D-SR, C-MOEA/D, MOEA/D-Epsilon and MOEA/D-IEpsilon. The\ncomprehensive experimental results demonstrate that the proposed PPS achieves\nsignificantly better or competitive performance than the other five CMOEAs on\nmost of the benchmark set.\n", "versions": [{"version": "v1", "created": "Fri, 15 Sep 2017 13:18:55 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Fan", "Zhun", ""], ["Li", "Wenji", ""], ["Cai", "Xinye", ""], ["Li", "Hui", ""], ["Wei", "Caimin", ""], ["Zhang", "Qingfu", ""], ["Deb", "Kalyanmoy", ""], ["Goodman", "Erik D.", ""]]}, {"id": "1709.05943", "submitter": "Alexander Wong", "authors": "Mohammad Javad Shafiee, Brendan Chywl, Francis Li, and Alexander Wong", "title": "Fast YOLO: A Fast You Only Look Once System for Real-time Embedded\n  Object Detection in Video", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object detection is considered one of the most challenging problems in this\nfield of computer vision, as it involves the combination of object\nclassification and object localization within a scene. Recently, deep neural\nnetworks (DNNs) have been demonstrated to achieve superior object detection\nperformance compared to other approaches, with YOLOv2 (an improved You Only\nLook Once model) being one of the state-of-the-art in DNN-based object\ndetection methods in terms of both speed and accuracy. Although YOLOv2 can\nachieve real-time performance on a powerful GPU, it still remains very\nchallenging for leveraging this approach for real-time object detection in\nvideo on embedded computing devices with limited computational power and\nlimited memory. In this paper, we propose a new framework called Fast YOLO, a\nfast You Only Look Once framework which accelerates YOLOv2 to be able to\nperform object detection in video on embedded devices in a real-time manner.\nFirst, we leverage the evolutionary deep intelligence framework to evolve the\nYOLOv2 network architecture and produce an optimized architecture (referred to\nas O-YOLOv2 here) that has 2.8X fewer parameters with just a ~2% IOU drop. To\nfurther reduce power consumption on embedded devices while maintaining\nperformance, a motion-adaptive inference method is introduced into the proposed\nFast YOLO framework to reduce the frequency of deep inference with O-YOLOv2\nbased on temporal motion characteristics. Experimental results show that the\nproposed Fast YOLO framework can reduce the number of deep inferences by an\naverage of 38.13%, and an average speedup of ~3.3X for objection detection in\nvideo compared to the original YOLOv2, leading Fast YOLO to run an average of\n~18FPS on a Nvidia Jetson TX1 embedded system.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 13:57:16 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Shafiee", "Mohammad Javad", ""], ["Chywl", "Brendan", ""], ["Li", "Francis", ""], ["Wong", "Alexander", ""]]}, {"id": "1709.05956", "submitter": "Nastaran Mohammadian Rad", "authors": "Nastaran Mohammadian Rad, Seyed Mostafa Kia, Calogero Zarbo, Twan van\n  Laarhoven, Giuseppe Jurman, Paola Venuti, Elena Marchiori, Cesare Furlanello", "title": "Deep Learning for Automatic Stereotypical Motor Movement Detection using\n  Wearable Sensors in Autism Spectrum Disorders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autism Spectrum Disorders are associated with atypical movements, of which\nstereotypical motor movements (SMMs) interfere with learning and social\ninteraction. The automatic SMM detection using inertial measurement units (IMU)\nremains complex due to the strong intra and inter-subject variability,\nespecially when handcrafted features are extracted from the signal. We propose\na new application of the deep learning to facilitate automatic SMM detection\nusing multi-axis IMUs. We use a convolutional neural network (CNN) to learn a\ndiscriminative feature space from raw data. We show how the CNN can be used for\nparameter transfer learning to enhance the detection rate on longitudinal data.\nWe also combine the long short-term memory (LSTM) with CNN to model the\ntemporal patterns in a sequence of multi-axis signals. Further, we employ\nensemble learning to combine multiple LSTM learners into a more robust SMM\ndetector. Our results show that: 1) feature learning outperforms handcrafted\nfeatures; 2) parameter transfer learning is beneficial in longitudinal\nsettings; 3) using LSTM to learn the temporal dynamic of signals enhances the\ndetection rate especially for skewed training data; 4) an ensemble of LSTMs\nprovides more accurate and stable detectors. These findings provide a\nsignificant step toward accurate SMM detection in real-time scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 14 Sep 2017 20:41:45 GMT"}], "update_date": "2017-09-19", "authors_parsed": [["Rad", "Nastaran Mohammadian", ""], ["Kia", "Seyed Mostafa", ""], ["Zarbo", "Calogero", ""], ["van Laarhoven", "Twan", ""], ["Jurman", "Giuseppe", ""], ["Venuti", "Paola", ""], ["Marchiori", "Elena", ""], ["Furlanello", "Cesare", ""]]}, {"id": "1709.05963", "submitter": "Christian Beck", "authors": "Christian Beck, Weinan E, and Arnulf Jentzen", "title": "Machine learning approximation algorithms for high-dimensional fully\n  nonlinear partial differential equations and second-order backward stochastic\n  differential equations", "comments": "56 pages, 12 figures", "journal-ref": "J. Nonlinear Sci. 29, 1563-1619 (2019)", "doi": "10.1007/s00332-018-9525-3", "report-no": null, "categories": "math.NA cs.LG cs.NE math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional partial differential equations (PDE) appear in a number of\nmodels from the financial industry, such as in derivative pricing models,\ncredit valuation adjustment (CVA) models, or portfolio optimization models. The\nPDEs in such applications are high-dimensional as the dimension corresponds to\nthe number of financial assets in a portfolio. Moreover, such PDEs are often\nfully nonlinear due to the need to incorporate certain nonlinear phenomena in\nthe model such as default risks, transaction costs, volatility uncertainty\n(Knightian uncertainty), or trading constraints in the model. Such\nhigh-dimensional fully nonlinear PDEs are exceedingly difficult to solve as the\ncomputational effort for standard approximation methods grows exponentially\nwith the dimension. In this work we propose a new method for solving\nhigh-dimensional fully nonlinear second-order PDEs. Our method can in\nparticular be used to sample from high-dimensional nonlinear expectations. The\nmethod is based on (i) a connection between fully nonlinear second-order PDEs\nand second-order backward stochastic differential equations (2BSDEs), (ii) a\nmerged formulation of the PDE and the 2BSDE problem, (iii) a temporal forward\ndiscretization of the 2BSDE and a spatial approximation via deep neural nets,\nand (iv) a stochastic gradient descent-type optimization procedure. Numerical\nresults obtained using ${\\rm T{\\small ENSOR}F{\\small LOW}}$ in ${\\rm P{\\small\nYTHON}}$ illustrate the efficiency and the accuracy of the method in the cases\nof a $100$-dimensional Black-Scholes-Barenblatt equation, a $100$-dimensional\nHamilton-Jacobi-Bellman equation, and a nonlinear expectation of a $ 100\n$-dimensional $ G $-Brownian motion.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 14:16:06 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Beck", "Christian", ""], ["E", "Weinan", ""], ["Jentzen", "Arnulf", ""]]}, {"id": "1709.06114", "submitter": "Xin Xie", "authors": "Juncai Xu, Zhenzhong Shen, Qingwen Ren, Xin Xie, and Zhengyu Yang", "title": "Geometric Semantic Genetic Programming Algorithm and Slump Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on the performance of recycled concrete as building material in the\ncurrent world is an important subject. Given the complex composition of\nrecycled concrete, conventional methods for forecasting slump scarcely obtain\nsatisfactory results. Based on theory of nonlinear prediction method, we\npropose a recycled concrete slump prediction model based on geometric semantic\ngenetic programming (GSGP) and combined it with recycled concrete features.\nTests show that the model can accurately predict the recycled concrete slump by\nusing the established prediction model to calculate the recycled concrete slump\nwith different mixing ratios in practical projects and by comparing the\npredicted values with the experimental values. By comparing the model with\nseveral other nonlinear prediction models, we can conclude that GSGP has higher\naccuracy and reliability than conventional methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 Sep 2017 18:18:32 GMT"}, {"version": "v2", "created": "Thu, 7 Dec 2017 04:55:04 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Xu", "Juncai", ""], ["Shen", "Zhenzhong", ""], ["Ren", "Qingwen", ""], ["Xie", "Xin", ""], ["Yang", "Zhengyu", ""]]}, {"id": "1709.06165", "submitter": "Yi Shang", "authors": "Chao Fang, Yi Shang, and Dong Xu", "title": "MUFold-SS: Protein Secondary Structure Prediction Using Deep\n  Inception-Inside-Inception Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Protein secondary structure prediction can provide important\ninformation for protein 3D structure prediction and protein functions. Deep\nlearning, which has been successfully applied to various research fields such\nas image classification and voice recognition, provides a new opportunity to\nsignificantly improve the secondary structure prediction accuracy. Although\nseveral deep-learning methods have been developed for secondary structure\nprediction, there is room for improvement. MUFold-SS was developed to address\nthese issues. Results: Here, a very deep neural network, the deep\ninception-inside-inception networks (Deep3I), is proposed for protein secondary\nstructure prediction and a software tool was implemented using this network.\nThis network takes two inputs: a protein sequence and a profile generated by\nPSI-BLAST. The output is the predicted eight states (Q8) or three states (Q3)\nof secondary structures. The proposed Deep3I not only achieves the\nstate-of-the-art performance but also runs faster than other tools. Deep3I\nachieves Q3 82.8% and Q8 71.1% accuracies on the CB513 benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 12 Sep 2017 20:59:27 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Fang", "Chao", ""], ["Shang", "Yi", ""], ["Xu", "Dong", ""]]}, {"id": "1709.06206", "submitter": "Jae-Sun Seo", "authors": "Shihui Yin, Shreyas K. Venkataramanaiah, Gregory K. Chen, Ram\n  Krishnamurthy, Yu Cao, Chaitali Chakrabarti, Jae-sun Seo", "title": "Algorithm and Hardware Design of Discrete-Time Spiking Neural Networks\n  Based on Back Propagation with Binary Activations", "comments": "2017 IEEE Biomedical Circuits and Systems (BioCAS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new back propagation based training algorithm for discrete-time\nspiking neural networks (SNN). Inspired by recent deep learning algorithms on\nbinarized neural networks, binary activation with a straight-through gradient\nestimator is used to model the leaky integrate-fire spiking neuron, overcoming\nthe difficulty in training SNNs using back propagation. Two SNN training\nalgorithms are proposed: (1) SNN with discontinuous integration, which is\nsuitable for rate-coded input spikes, and (2) SNN with continuous integration,\nwhich is more general and can handle input spikes with temporal information.\nNeuromorphic hardware designed in 40nm CMOS exploits the spike sparsity and\ndemonstrates high classification accuracy (>98% on MNIST) and low energy\n(48.4-773 nJ/image).\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 00:05:55 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Yin", "Shihui", ""], ["Venkataramanaiah", "Shreyas K.", ""], ["Chen", "Gregory K.", ""], ["Krishnamurthy", "Ram", ""], ["Cao", "Yu", ""], ["Chakrabarti", "Chaitali", ""], ["Seo", "Jae-sun", ""]]}, {"id": "1709.06620", "submitter": "Qiyang Li", "authors": "Qiyang Li, Xintong Du, Yizhou Huang, Quinlan Sykora, and Angela P.\n  Schoellig", "title": "Learning of Coordination Policies for Robotic Swarms", "comments": "8 pages, 11 figures, submitted to 2018 IEEE International Conference\n  on Robotics and Automation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by biological swarms, robotic swarms are envisioned to solve\nreal-world problems that are difficult for individual agents. Biological swarms\ncan achieve collective intelligence based on local interactions and simple\nrules; however, designing effective distributed policies for large-scale\nrobotic swarms to achieve a global objective can be challenging. Although it is\noften possible to design an optimal centralized strategy for smaller numbers of\nagents, those methods can fail as the number of agents increases. Motivated by\nthe growing success of machine learning, we develop a deep learning approach\nthat learns distributed coordination policies from centralized policies. In\ncontrast to traditional distributed control approaches, which are usually based\non human-designed policies for relatively simple tasks, this learning-based\napproach can be adapted to more difficult tasks. We demonstrate the efficacy of\nour proposed approach on two different tasks, the well-known rendezvous problem\nand a more difficult particle assignment problem. For the latter, no known\ndistributed policy exists. From extensive simulations, it is shown that the\nperformance of the learned coordination policies is comparable to the\ncentralized policies, surpassing state-of-the-art distributed policies.\nThereby, our proposed approach provides a promising alternative for real-world\ncoordination problems that would be otherwise computationally expensive to\nsolve or intangible to explore.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 19:26:20 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Li", "Qiyang", ""], ["Du", "Xintong", ""], ["Huang", "Yizhou", ""], ["Sykora", "Quinlan", ""], ["Schoellig", "Angela P.", ""]]}, {"id": "1709.06671", "submitter": "Danushka Bollegala", "authors": "Danushka Bollegala, Kohei Hayashi and Ken-ichi Kawarabayashi", "title": "Think Globally, Embed Locally --- Locally Linear Meta-embedding of Words", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed word embeddings have shown superior performances in numerous\nNatural Language Processing (NLP) tasks. However, their performances vary\nsignificantly across different tasks, implying that the word embeddings learnt\nby those methods capture complementary aspects of lexical semantics. Therefore,\nwe believe that it is important to combine the existing word embeddings to\nproduce more accurate and complete \\emph{meta-embeddings} of words. For this\npurpose, we propose an unsupervised locally linear meta-embedding learning\nmethod that takes pre-trained word embeddings as the input, and produces more\naccurate meta embeddings. Unlike previously proposed meta-embedding learning\nmethods that learn a global projection over all words in a vocabulary, our\nproposed method is sensitive to the differences in local neighbourhoods of the\nindividual source word embeddings. Moreover, we show that vector concatenation,\na previously proposed highly competitive baseline approach for integrating word\nembeddings, can be derived as a special case of the proposed method.\nExperimental results on semantic similarity, word analogy, relation\nclassification, and short-text classification tasks show that our\nmeta-embeddings to significantly outperform prior methods in several benchmark\ndatasets, establishing a new state of the art for meta-embeddings.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 22:58:02 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Bollegala", "Danushka", ""], ["Hayashi", "Kohei", ""], ["Kawarabayashi", "Ken-ichi", ""]]}, {"id": "1709.06673", "submitter": "Danushka Bollegala", "authors": "Huda Hakami and Danushka Bollegala and Hayashi Kohei", "title": "Why PairDiff works? -- A Mathematical Analysis of Bilinear Relational\n  Compositional Operators for Analogy Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing the semantic relations that exist between two given words (or\nentities) is an important first step in a wide-range of NLP applications such\nas analogical reasoning, knowledge base completion and relational information\nretrieval. A simple, yet surprisingly accurate method for representing a\nrelation between two words is to compute the vector offset (\\PairDiff) between\ntheir corresponding word embeddings. Despite the empirical success, it remains\nunclear as to whether \\PairDiff is the best operator for obtaining a relational\nrepresentation from word embeddings. We conduct a theoretical analysis of\ngeneralised bilinear operators that can be used to measure the $\\ell_{2}$\nrelational distance between two word-pairs. We show that, if the word\nembeddings are standardised and uncorrelated, such an operator will be\nindependent of bilinear terms, and can be simplified to a linear form, where\n\\PairDiff is a special case. For numerous word embedding types, we empirically\nverify the uncorrelation assumption, demonstrating the general applicability of\nour theoretical result. Moreover, we experimentally discover \\PairDiff from the\nbilinear relation composition operator on several benchmark analogy datasets.\n", "versions": [{"version": "v1", "created": "Tue, 19 Sep 2017 23:09:15 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 15:41:23 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Hakami", "Huda", ""], ["Bollegala", "Danushka", ""], ["Kohei", "Hayashi", ""]]}, {"id": "1709.06909", "submitter": "Hojjat Salehinejad", "authors": "Hojjat Salehinejad, Shahryar Rahnamayan, Hamid R. Tizhoosh", "title": "Opposition based Ensemble Micro Differential Evolution", "comments": "This paper is accepted for presentation at IEEE Symposium Series on\n  Computational Intelligence (IEEE SSCI 2017), Hawaii, USA, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential evolution (DE) algorithm with a small population size is called\nMicro-DE (MDE). A small population size decreases the computational complexity\nbut also reduces the exploration ability of DE by limiting the population\ndiversity. In this paper, we propose the idea of combining ensemble mutation\nscheme selection and opposition-based learning concepts to enhance the\ndiversity of population in MDE at mutation and selection stages. The proposed\nalgorithm enhances the diversity of population by generating a random mutation\nscale factor per individual and per dimension, randomly assigning a mutation\nscheme to each individual in each generation, and diversifying individuals\nselection using opposition-based learning. This approach is easy to implement\nand does not require the setting of mutation scheme selection and mutation\nscale factor. Experimental results are conducted for a variety of objective\nfunctions with low and high dimensionality on the CEC Black- Box Optimization\nBenchmarking 2015 (CEC-BBOB 2015). The results show superior performance of the\nproposed algorithm compared to the other micro-DE algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 8 Sep 2017 02:21:37 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 00:22:45 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Salehinejad", "Hojjat", ""], ["Rahnamayan", "Shahryar", ""], ["Tizhoosh", "Hamid R.", ""]]}, {"id": "1709.06917", "submitter": "Konstantinos Chatzilygeroudis", "authors": "Konstantinos Chatzilygeroudis and Jean-Baptiste Mouret", "title": "Using Parameterized Black-Box Priors to Scale Up Model-Based Policy\n  Search for Robotics", "comments": "Accepted at ICRA 2018; 8 pages, 4 figures, 2 algorithms, 1 table;\n  Video at https://youtu.be/HFkZkhGGzTo ; Spotlight ICRA presentation at\n  https://youtu.be/_MZYDhfWeLc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most data-efficient algorithms for reinforcement learning in robotics are\nmodel-based policy search algorithms, which alternate between learning a\ndynamical model of the robot and optimizing a policy to maximize the expected\nreturn given the model and its uncertainties. Among the few proposed\napproaches, the recently introduced Black-DROPS algorithm exploits a black-box\noptimization algorithm to achieve both high data-efficiency and good\ncomputation times when several cores are used; nevertheless, like all\nmodel-based policy search approaches, Black-DROPS does not scale to high\ndimensional state/action spaces. In this paper, we introduce a new model\nlearning procedure in Black-DROPS that leverages parameterized black-box priors\nto (1) scale up to high-dimensional systems, and (2) be robust to large\ninaccuracies of the prior information. We demonstrate the effectiveness of our\napproach with the \"pendubot\" swing-up task in simulation and with a physical\nhexapod robot (48D state space, 18D action space) that has to walk forward as\nfast as possible. The results show that our new algorithm is more\ndata-efficient than previous model-based policy search algorithms (with and\nwithout priors) and that it can allow a physical 6-legged robot to learn new\ngaits in only 16 to 30 seconds of interaction time.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 15:03:47 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 16:39:40 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Chatzilygeroudis", "Konstantinos", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1709.06919", "submitter": "Konstantinos Chatzilygeroudis", "authors": "R\\'emi Pautrat, Konstantinos Chatzilygeroudis and Jean-Baptiste Mouret", "title": "Bayesian Optimization with Automatic Prior Selection for Data-Efficient\n  Direct Policy Search", "comments": "Accepted at ICRA 2018; 8 pages, 4 figures, 1 algorithm; Video at\n  https://youtu.be/xo8mUIZTvNE ; Spotlight ICRA presentation\n  https://youtu.be/iiVaV-U6Kqo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most interesting features of Bayesian optimization for direct\npolicy search is that it can leverage priors (e.g., from simulation or from\nprevious tasks) to accelerate learning on a robot. In this paper, we are\ninterested in situations for which several priors exist but we do not know in\nadvance which one fits best the current situation. We tackle this problem by\nintroducing a novel acquisition function, called Most Likely Expected\nImprovement (MLEI), that combines the likelihood of the priors and the expected\nimprovement. We evaluate this new acquisition function on a transfer learning\ntask for a 5-DOF planar arm and on a possibly damaged, 6-legged robot that has\nto learn to walk on flat ground and on stairs, with priors corresponding to\ndifferent stairs and different kinds of damages. Our results show that MLEI\neffectively identifies and exploits the priors, even when there is no obvious\nmatch between the current situations and the priors.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 15:04:50 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2018 16:45:49 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Pautrat", "R\u00e9mi", ""], ["Chatzilygeroudis", "Konstantinos", ""], ["Mouret", "Jean-Baptiste", ""]]}, {"id": "1709.06950", "submitter": "Damian Berger", "authors": "Damian L. Berger, Lucilla de Arcangelis, and Hans J. Herrmann", "title": "Spatial features of synaptic adaptation affecting learning performance", "comments": null, "journal-ref": "Scientific Reports 7, 11016 (2017)", "doi": "10.1038/s41598-017-11424-5", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have proposed that the diffusion of messenger molecules, such\nas monoamines, can mediate the plastic adaptation of synapses in supervised\nlearning of neural networks. Based on these findings we developed a model for\nneural learning, where the signal for plastic adaptation is assumed to\npropagate through the extracellular space. We investigate the conditions\nallowing learning of Boolean rules in a neural network. Even fully excitatory\nnetworks show very good learning performances. Moreover, the investigation of\nthe plastic adaptation features optimizing the performance suggests that\nlearning is very sensitive to the extent of the plastic adaptation and the\nspatial range of synaptic connections.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 16:18:17 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Berger", "Damian L.", ""], ["de Arcangelis", "Lucilla", ""], ["Herrmann", "Hans J.", ""]]}, {"id": "1709.06990", "submitter": "Emmanuel Dufourq Mr", "authors": "Emmanuel Dufourq and Bruce A. Bassett", "title": "Text Compression for Sentiment Analysis via Evolutionary Algorithms", "comments": "8 pages, 2 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Can textual data be compressed intelligently without losing accuracy in\nevaluating sentiment? In this study, we propose a novel evolutionary\ncompression algorithm, PARSEC (PARts-of-Speech for sEntiment Compression),\nwhich makes use of Parts-of-Speech tags to compress text in a way that\nsacrifices minimal classification accuracy when used in conjunction with\nsentiment analysis algorithms. An analysis of PARSEC with eight commercial and\nnon-commercial sentiment analysis algorithms on twelve English sentiment data\nsets reveals that accurate compression is possible with (0%, 1.3%, 3.3%) loss\nin sentiment classification accuracy for (20%, 50%, 75%) data compression with\nPARSEC using LingPipe, the most accurate of the sentiment algorithms. Other\nsentiment analysis algorithms are more severely affected by compression. We\nconclude that significant compression of text data is possible for sentiment\nanalysis depending on the accuracy demands of the specific application and the\nspecific sentiment analysis algorithm used.\n", "versions": [{"version": "v1", "created": "Wed, 20 Sep 2017 17:57:16 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Dufourq", "Emmanuel", ""], ["Bassett", "Bruce A.", ""]]}, {"id": "1709.07409", "submitter": "Lucas Lamata", "authors": "L. Lamata, U. Alvarez-Rodriguez, J. D. Mart\\'in-Guerrero, M. Sanz, E.\n  Solano", "title": "Quantum autoencoders via quantum adders with genetic algorithms", "comments": null, "journal-ref": "Quantum Sci. Technol. 4 (2019) 014007", "doi": "10.1088/2058-9565/aae22b", "report-no": null, "categories": "quant-ph cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantum autoencoder is a recent paradigm in the field of quantum machine\nlearning, which may enable an enhanced use of resources in quantum\ntechnologies. To this end, quantum neural networks with less nodes in the inner\nthan in the outer layers were considered. Here, we propose a useful connection\nbetween approximate quantum adders and quantum autoencoders. Specifically, this\nlink allows us to employ optimized approximate quantum adders, obtained with\ngenetic algorithms, for the implementation of quantum autoencoders for a\nvariety of initial states. Furthermore, we can also directly optimize the\nquantum autoencoders via genetic algorithms. Our approach opens a different\npath for the design of quantum autoencoders in controllable quantum platforms.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 16:52:00 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 09:25:40 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Lamata", "L.", ""], ["Alvarez-Rodriguez", "U.", ""], ["Mart\u00edn-Guerrero", "J. D.", ""], ["Sanz", "M.", ""], ["Solano", "E.", ""]]}, {"id": "1709.07432", "submitter": "Benjamin Krause", "authors": "Ben Krause, Emmanuel Kahembwe, Iain Murray, Steve Renals", "title": "Dynamic Evaluation of Neural Sequence Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present methodology for using dynamic evaluation to improve neural\nsequence models. Models are adapted to recent history via a gradient descent\nbased mechanism, causing them to assign higher probabilities to re-occurring\nsequential patterns. Dynamic evaluation outperforms existing adaptation\napproaches in our comparisons. Dynamic evaluation improves the state-of-the-art\nword-level perplexities on the Penn Treebank and WikiText-2 datasets to 51.1\nand 44.3 respectively, and the state-of-the-art character-level cross-entropies\non the text8 and Hutter Prize datasets to 1.19 bits/char and 1.08 bits/char\nrespectively.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 17:50:04 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 22:31:34 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Krause", "Ben", ""], ["Kahembwe", "Emmanuel", ""], ["Murray", "Iain", ""], ["Renals", "Steve", ""]]}, {"id": "1709.07536", "submitter": "Mejbah Alam", "authors": "Mejbah Alam, Justin Gottschlich, Nesime Tatbul, Javier Turek, Timothy\n  Mattson, Abdullah Muzahid", "title": "A Zero-Positive Learning Approach for Diagnosing Software Performance\n  Regressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of machine programming (MP), the automation of the development of\nsoftware, is making notable research advances. This is, in part, due to the\nemergence of a wide range of novel techniques in machine learning. In this\npaper, we apply MP to the automation of software performance regression\ntesting. A performance regression is a software performance degradation caused\nby a code change. We present AutoPerf - a novel approach to automate regression\ntesting that utilizes three core techniques: (i) zero-positive learning, (ii)\nautoencoders, and (iii) hardware telemetry. We demonstrate AutoPerf's\ngenerality and efficacy against 3 types of performance regressions across 10\nreal performance bugs in 7 benchmark and open-source programs. On average,\nAutoPerf exhibits 4% profiling overhead and accurately diagnoses more\nperformance bugs than prior state-of-the-art approaches. Thus far, AutoPerf has\nproduced no false negatives.\n", "versions": [{"version": "v1", "created": "Thu, 21 Sep 2017 22:39:39 GMT"}, {"version": "v2", "created": "Sun, 19 Nov 2017 18:53:21 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 21:07:46 GMT"}, {"version": "v4", "created": "Fri, 31 May 2019 23:38:38 GMT"}, {"version": "v5", "created": "Fri, 1 Nov 2019 06:17:41 GMT"}, {"version": "v6", "created": "Wed, 1 Jan 2020 19:10:01 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Alam", "Mejbah", ""], ["Gottschlich", "Justin", ""], ["Tatbul", "Nesime", ""], ["Turek", "Javier", ""], ["Mattson", "Timothy", ""], ["Muzahid", "Abdullah", ""]]}, {"id": "1709.07626", "submitter": "Jagmohan Chauhan", "authors": "Jagmohan Chauhan, Suranga Seneviratne, Yining Hu, Archan Misra, Aruna\n  Seneviratne, Youngki Lee", "title": "BreathRNNet: Breathing Based Authentication on Resource-Constrained IoT\n  Devices using RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) have shown promising results in audio and\nspeech processing applications due to their strong capabilities in modelling\nsequential data. In many applications, RNNs tend to outperform conventional\nmodels based on GMM/UBMs and i-vectors. Increasing popularity of IoT devices\nmakes a strong case for implementing RNN based inferences for applications such\nas acoustics based authentication, voice commands, and edge analytics for smart\nhomes. Nonetheless, the feasibility and performance of RNN based inferences on\nresources-constrained IoT devices remain largely unexplored. In this paper, we\ninvestigate the feasibility of using RNNs for an end-to-end authentication\nsystem based on breathing acoustics. We evaluate the performance of RNN models\non three types of devices; smartphone, smartwatch, and Raspberry Pi and show\nthat unlike CNN models, RNN models can be easily ported onto\nresource-constrained devices without a significant loss in accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 08:06:38 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Chauhan", "Jagmohan", ""], ["Seneviratne", "Suranga", ""], ["Hu", "Yining", ""], ["Misra", "Archan", ""], ["Seneviratne", "Aruna", ""], ["Lee", "Youngki", ""]]}, {"id": "1709.07808", "submitter": "Mikel Sanz", "authors": "M. Sanz, L. Lamata, E. Solano", "title": "Quantum Memristors in Quantum Photonics", "comments": null, "journal-ref": "APL Photonics 3, 080801 (2018)", "doi": "10.1063/1.5036596", "report-no": null, "categories": "quant-ph cond-mat.mes-hall cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to build quantum memristors in quantum photonic\nplatforms. We firstly design an effective beam splitter, which is tunable in\nreal-time, by means of a Mach-Zehnder-type array with two equal 50:50 beam\nsplitters and a tunable retarder, which allows us to control its reflectivity.\nThen, we show that this tunable beam splitter, when equipped with weak\nmeasurements and classical feedback, behaves as a quantum memristor. Indeed, in\norder to prove its quantumness, we show how to codify quantum information in\nthe coherent beams. Moreover, we estimate the memory capability of the quantum\nmemristor. Finally, we show the feasibility of the proposed setup in integrated\nquantum photonics.\n", "versions": [{"version": "v1", "created": "Fri, 22 Sep 2017 15:24:31 GMT"}, {"version": "v2", "created": "Fri, 14 Dec 2018 15:35:33 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Sanz", "M.", ""], ["Lamata", "L.", ""], ["Solano", "E.", ""]]}, {"id": "1709.08166", "submitter": "Luziwei Leng", "authors": "Luziwei Leng, Roman Martel, Oliver Breitwieser, Ilja Bytschok, Walter\n  Senn, Johannes Schemmel, Karlheinz Meier and Mihai A. Petrovici", "title": "Spiking neurons with short-term synaptic plasticity form superior\n  generative networks", "comments": "corrected typo in abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking networks that perform probabilistic inference have been proposed both\nas models of cortical computation and as candidates for solving problems in\nmachine learning. However, the evidence for spike-based computation being in\nany way superior to non-spiking alternatives remains scarce. We propose that\nshort-term plasticity can provide spiking networks with distinct computational\nadvantages compared to their classical counterparts. In this work, we use\nnetworks of leaky integrate-and-fire neurons that are trained to perform both\ndiscriminative and generative tasks in their forward and backward information\nprocessing paths, respectively. During training, the energy landscape\nassociated with their dynamics becomes highly diverse, with deep attractor\nbasins separated by high barriers. Classical algorithms solve this problem by\nemploying various tempering techniques, which are both computationally\ndemanding and require global state updates. We demonstrate how similar results\ncan be achieved in spiking networks endowed with local short-term synaptic\nplasticity. Additionally, we discuss how these networks can even outperform\ntempering-based approaches when the training data is imbalanced. We thereby\nshow how biologically inspired, local, spike-triggered synaptic dynamics based\nsimply on a limited pool of synaptic resources can allow spiking networks to\noutperform their non-spiking relatives.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 09:15:39 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 03:23:56 GMT"}, {"version": "v3", "created": "Tue, 10 Oct 2017 20:45:49 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Leng", "Luziwei", ""], ["Martel", "Roman", ""], ["Breitwieser", "Oliver", ""], ["Bytschok", "Ilja", ""], ["Senn", "Walter", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""], ["Petrovici", "Mihai A.", ""]]}, {"id": "1709.08248", "submitter": "Alexander Wong", "authors": "Mohammad Javad Shafiee and Alexander Wong", "title": "Discovery Radiomics via Deep Multi-Column Radiomic Sequencers for Skin\n  Cancer Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While skin cancer is the most diagnosed form of cancer in men and women, with\nmore cases diagnosed each year than all other cancers combined, sufficiently\nearly diagnosis results in very good prognosis and as such makes early\ndetection crucial. While radiomics have shown considerable promise as a\npowerful diagnostic tool for significantly improving oncological diagnostic\naccuracy and efficiency, current radiomics-driven methods have largely rely on\npre-defined, hand-crafted quantitative features, which can greatly limit the\nability to fully characterize unique cancer phenotype that distinguish it from\nhealthy tissue. Recently, the notion of discovery radiomics was introduced,\nwhere a large amount of custom, quantitative radiomic features are directly\ndiscovered from the wealth of readily available medical imaging data. In this\nstudy, we present a novel discovery radiomics framework for skin cancer\ndetection, where we leverage novel deep multi-column radiomic sequencers for\nhigh-throughput discovery and extraction of a large amount of custom radiomic\nfeatures tailored for characterizing unique skin cancer tissue phenotype. The\ndiscovered radiomic sequencer was tested against 9,152 biopsy-proven clinical\nimages comprising of different skin cancers such as melanoma and basal cell\ncarcinoma, and demonstrated sensitivity and specificity of 91% and 75%,\nrespectively, thus achieving dermatologist-level performance and \\break hence\ncan be a powerful tool for assisting general practitioners and dermatologists\nalike in improving the efficiency, consistency, and accuracy of skin cancer\ndiagnosis.\n", "versions": [{"version": "v1", "created": "Sun, 24 Sep 2017 19:53:20 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Shafiee", "Mohammad Javad", ""], ["Wong", "Alexander", ""]]}, {"id": "1709.08367", "submitter": "Vincent Gripon", "authors": "Eliott Coyac, Vincent Gripon, Charlotte Langlais, and Claude Berrou", "title": "Robust Associative Memories Naturally Occuring From Recurrent Hebbian\n  Networks Under Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain is a noisy system subject to energy constraints. These facts are\nrarely taken into account when modelling artificial neural networks. In this\npaper, we are interested in demonstrating that those factors can actually lead\nto the appearance of robust associative memories. We first propose a simplified\nmodel of noise in the brain, taking into account synaptic noise and\ninterference from neurons external to the network. When coarsely quantized, we\nshow that this noise can be reduced to insertions and erasures. We take a\nneural network with recurrent modifiable connections, and subject it to noisy\nexternal inputs. We introduce an energy usage limitation principle in the\nnetwork as well as consolidated Hebbian learning, resulting in an incremental\nprocessing of inputs. We show that the connections naturally formed correspond\nto state-of-the-art binary sparse associative memories.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 08:29:39 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Coyac", "Eliott", ""], ["Gripon", "Vincent", ""], ["Langlais", "Charlotte", ""], ["Berrou", "Claude", ""]]}, {"id": "1709.08385", "submitter": "Xavier Bellekens", "authors": "Gregory D. Hill and Xavier J. A. Bellekens", "title": "Deep Learning Based Cryptographic Primitive Classification", "comments": "9 Pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Cryptovirological augmentations present an immediate, incomparable threat.\nOver the last decade, the substantial proliferation of crypto-ransomware has\nhad widespread consequences for consumers and organisations alike. Established\npreventive measures perform well, however, the problem has not ceased. Reverse\nengineering potentially malicious software is a cumbersome task due to platform\neccentricities and obfuscated transmutation mechanisms, hence requiring\nsmarter, more efficient detection strategies. The following manuscript presents\na novel approach for the classification of cryptographic primitives in compiled\nbinary executables using deep learning. The model blueprint, a DCNN, is\nfittingly configured to learn from variable-length control flow diagnostics\noutput from a dynamic trace. To rival the size and variability of contemporary\ndata compendiums, hence feeding the model cognition, a methodology for the\nprocedural generation of synthetic cryptographic binaries is defined, utilising\ncore primitives from OpenSSL with multivariate obfuscation, to draw a vastly\nscalable distribution. The library, CryptoKnight, rendered an algorithmic pool\nof AES, RC4, Blowfish, MD5 and RSA to synthesis combinable variants which are\nautomatically fed in its core model. Converging at 91% accuracy, CryptoKnight\nis successfully able to classify the sample algorithms with minimal loss.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 09:07:30 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Hill", "Gregory D.", ""], ["Bellekens", "Xavier J. A.", ""]]}, {"id": "1709.08524", "submitter": "Alexander Shekhovtsov", "authors": "Boris Flach, Alexander Shekhovtsov, Ondrej Fikar", "title": "Generative learning for deep networks", "comments": "submitted to AAAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning, taking into account full distribution of the data, referred to as\ngenerative, is not feasible with deep neural networks (DNNs) because they model\nonly the conditional distribution of the outputs given the inputs. Current\nsolutions are either based on joint probability models facing difficult\nestimation problems or learn two separate networks, mapping inputs to outputs\n(recognition) and vice-versa (generation). We propose an intermediate approach.\nFirst, we show that forward computation in DNNs with logistic sigmoid\nactivations corresponds to a simplified approximate Bayesian inference in a\ndirected probabilistic multi-layer model. This connection allows to interpret\nDNN as a probabilistic model of the output and all hidden units given the\ninput. Second, we propose that in order for the recognition and generation\nnetworks to be more consistent with the joint model of the data, weights of the\nrecognition and generator network should be related by transposition. We\ndemonstrate in a tentative experiment that such a coupled pair can be learned\ngeneratively, modelling the full distribution of the data, and has enough\ncapacity to perform well in both recognition and generation.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 14:43:53 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Flach", "Boris", ""], ["Shekhovtsov", "Alexander", ""], ["Fikar", "Ondrej", ""]]}, {"id": "1709.08563", "submitter": "Christian Schulz", "authors": "Orlando Moreira, Merten Popp, Christian Schulz", "title": "Evolutionary Acyclic Graph Partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed graphs are widely used to model data flow and execution dependencies\nin streaming applications. This enables the utilization of graph partitioning\nalgorithms for the problem of parallelizing computation for multiprocessor\narchitectures. However due to resource restrictions, an acyclicity constraint\non the partition is necessary when mapping streaming applications to an\nembedded multiprocessor. Here, we contribute a multi-level algorithm for the\nacyclic graph partitioning problem. Based on this, we engineer an evolutionary\nalgorithm to further reduce communication cost, as well as to improve load\nbalancing and the scheduling makespan on embedded multiprocessor architectures.\n", "versions": [{"version": "v1", "created": "Mon, 25 Sep 2017 15:54:25 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Moreira", "Orlando", ""], ["Popp", "Merten", ""], ["Schulz", "Christian", ""]]}, {"id": "1709.08853", "submitter": "Xianggen Liu", "authors": "Zhengdong Lu and Xianggen Liu and Haotian Cui and Yukun Yan and Daqi\n  Zheng", "title": "Object-oriented Neural Programming (OONP) for Document Understanding", "comments": "accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Object-oriented Neural Programming (OONP), a framework for\nsemantically parsing documents in specific domains. Basically, OONP reads a\ndocument and parses it into a predesigned object-oriented data structure\n(referred to as ontology in this paper) that reflects the domain-specific\nsemantics of the document. An OONP parser models semantic parsing as a decision\nprocess: a neural net-based Reader sequentially goes through the document, and\nduring the process it builds and updates an intermediate ontology to summarize\nits partial understanding of the text it covers. OONP supports a rich family of\noperations (both symbolic and differentiable) for composing the ontology, and a\nbig variety of forms (both symbolic and differentiable) for representing the\nstate and the document. An OONP parser can be trained with supervision of\ndifferent forms and strength, including supervised learning (SL) ,\nreinforcement learning (RL) and hybrid of the two. Our experiments on both\nsynthetic and real-world document parsing tasks have shown that OONP can learn\nto handle fairly complicated ontology with training data of modest sizes.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 06:17:35 GMT"}, {"version": "v2", "created": "Thu, 28 Sep 2017 06:56:18 GMT"}, {"version": "v3", "created": "Tue, 3 Oct 2017 15:07:54 GMT"}, {"version": "v4", "created": "Sun, 8 Oct 2017 07:36:03 GMT"}, {"version": "v5", "created": "Thu, 19 Jul 2018 11:21:07 GMT"}, {"version": "v6", "created": "Wed, 25 Jul 2018 08:56:09 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Lu", "Zhengdong", ""], ["Liu", "Xianggen", ""], ["Cui", "Haotian", ""], ["Yan", "Yukun", ""], ["Zheng", "Daqi", ""]]}, {"id": "1709.08878", "submitter": "Kelvin Guu", "authors": "Kelvin Guu, Tatsunori B. Hashimoto, Yonatan Oren, Percy Liang", "title": "Generating Sentences by Editing Prototypes", "comments": "14 pages, Transactions of the Association for Computational\n  Linguistics (TACL), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new generative model of sentences that first samples a prototype\nsentence from the training corpus and then edits it into a new sentence.\nCompared to traditional models that generate from scratch either left-to-right\nor by first sampling a latent sentence vector, our prototype-then-edit model\nimproves perplexity on language modeling and generates higher quality outputs\naccording to human evaluation. Furthermore, the model gives rise to a latent\nedit vector that captures interpretable semantics such as sentence similarity\nand sentence-level analogies.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 08:11:33 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 04:57:15 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Guu", "Kelvin", ""], ["Hashimoto", "Tatsunori B.", ""], ["Oren", "Yonatan", ""], ["Liang", "Percy", ""]]}, {"id": "1709.08992", "submitter": "Nicolas Bredeche", "authors": "Nicolas Bredeche, Evert Haasdijk, Abraham Prieto", "title": "Embodied Evolution in Collective Robotics: A Review", "comments": "23 pages, 1 figure, 1 table", "journal-ref": "(2018) Embodied Evolution in Collective Robotics: A Review. Front.\n  Robot. AI 5:12", "doi": "10.3389/frobt.2018.00012", "report-no": null, "categories": "cs.NE cs.AI cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an overview of evolutionary robotics techniques applied\nto on-line distributed evolution for robot collectives -- namely, embodied\nevolution. It provides a definition of embodied evolution as well as a thorough\ndescription of the underlying concepts and mechanisms. The paper also presents\na comprehensive summary of research published in the field since its inception\n(1999-2017), providing various perspectives to identify the major trends. In\nparticular, we identify a shift from considering embodied evolution as a\nparallel search method within small robot collectives (fewer than 10 robots) to\nembodied evolution as an on-line distributed learning method for designing\ncollective behaviours in swarm-like collectives. The paper concludes with a\ndiscussion of applications and open questions, providing a milestone for past\nand an inspiration for future research.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 13:08:27 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 14:56:37 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Bredeche", "Nicolas", ""], ["Haasdijk", "Evert", ""], ["Prieto", "Abraham", ""]]}, {"id": "1709.09161", "submitter": "Emmanuel Dufourq Mr", "authors": "Emmanuel Dufourq, Bruce A. Bassett", "title": "EDEN: Evolutionary Deep Networks for Efficient Machine Learning", "comments": "7 pages, 3 figures, 3 tables and see video\n  https://vimeo.com/234510097", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep neural networks continue to show improved performance with increasing\ndepth, an encouraging trend that implies an explosion in the possible\npermutations of network architectures and hyperparameters for which there is\nlittle intuitive guidance. To address this increasing complexity, we propose\nEvolutionary DEep Networks (EDEN), a computationally efficient\nneuro-evolutionary algorithm which interfaces to any deep neural network\nplatform, such as TensorFlow. We show that EDEN evolves simple yet successful\narchitectures built from embedding, 1D and 2D convolutional, max pooling and\nfully connected layers along with their hyperparameters. Evaluation of EDEN\nacross seven image and sentiment classification datasets shows that it reliably\nfinds good networks -- and in three cases achieves state-of-the-art results --\neven on a single GPU, in just 6-24 hours. Our study provides a first attempt at\napplying neuro-evolution to the creation of 1D convolutional networks for\nsentiment analysis including the optimisation of the embedding layer.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 17:56:31 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Dufourq", "Emmanuel", ""], ["Bassett", "Bruce A.", ""]]}, {"id": "1709.09227", "submitter": "Adam Nyberg", "authors": "Adam Nyberg", "title": "Optimizing PID parameters with machine learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the Evolutionary programming (EP) method for optimizing\nPID parameters. PID is the most common type of regulator within control theory,\npartly because it's relatively simple and yields stable results for most\napplications. The p, i and d parameters vary for each application; therefore,\nchoosing the right parameters is crucial for obtaining good results but also\nsomewhat difficult. EP is a derivative-free optimization algorithm which makes\nit suitable for PID optimization. The experiments in this paper demonstrate the\npower of EP to solve the problem of optimizing PID parameters without getting\nstuck in local minimums.\n", "versions": [{"version": "v1", "created": "Tue, 26 Sep 2017 19:20:31 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Nyberg", "Adam", ""]]}, {"id": "1709.09749", "submitter": "Bin Bi", "authors": "Bin Bi and Hao Ma", "title": "KeyVec: Key-semantics Preserving Document Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies have demonstrated the empirical success of word embeddings\nin various applications. In this paper, we investigate the problem of learning\ndistributed representations for text documents which many machine learning\nalgorithms take as input for a number of NLP tasks.\n  We propose a neural network model, KeyVec, which learns document\nrepresentations with the goal of preserving key semantics of the input text. It\nenables the learned low-dimensional vectors to retain the topics and important\ninformation from the documents that will flow to downstream tasks. Our\nempirical evaluations show the superior quality of KeyVec representations in\ntwo different document understanding tasks.\n", "versions": [{"version": "v1", "created": "Wed, 27 Sep 2017 22:05:59 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Bi", "Bin", ""], ["Ma", "Hao", ""]]}, {"id": "1709.09840", "submitter": "Yinyan Zhang", "authors": "Yinyan Zhang, Pei Zhang, and Shuai Li", "title": "PSA: A novel optimization algorithm based on survival rules of porcellio\n  scaber", "comments": "4 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bio-inspired algorithms such as neural network algorithms and genetic\nalgorithms have received a significant amount of attention in both academic and\nengineering societies. In this paper, based on the observation of two major\nsurvival rules of a species of woodlice, i.e., porcellio scaber, we present an\nalgorithm called the porcellio scaber algorithm (PSA) for solving general\nunconstrained optimization problems, including differentiable and\nnon-differential ones as well as the case with local optima. Numerical results\nbased on benchmark problems are presented to validate the efficacy of PSA.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 08:02:16 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 04:39:44 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Zhang", "Yinyan", ""], ["Zhang", "Pei", ""], ["Li", "Shuai", ""]]}, {"id": "1709.09902", "submitter": "Dat Thanh Tran", "authors": "Dat Thanh Tran, Alexandros Iosifidis, Moncef Gabbouj", "title": "Improving Efficiency in Convolutional Neural Network with Multilinear\n  Filters", "comments": "10 pages, 3 figures", "journal-ref": "Neural Networks vol. 105, pp. 328-339, 2018", "doi": "10.1016/j.neunet.2018.05.017", "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The excellent performance of deep neural networks has enabled us to solve\nseveral automatization problems, opening an era of autonomous devices. However,\ncurrent deep net architectures are heavy with millions of parameters and\nrequire billions of floating point operations. Several works have been\ndeveloped to compress a pre-trained deep network to reduce memory footprint\nand, possibly, computation. Instead of compressing a pre-trained network, in\nthis work, we propose a generic neural network layer structure employing\nmultilinear projection as the primary feature extractor. The proposed\narchitecture requires several times less memory as compared to the traditional\nConvolutional Neural Networks (CNN), while inherits the similar design\nprinciples of a CNN. In addition, the proposed architecture is equipped with\ntwo computation schemes that enable computation reduction or scalability.\nExperimental results show the effectiveness of our compact projection that\noutperforms traditional CNN, while requiring far fewer parameters.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 11:55:13 GMT"}, {"version": "v2", "created": "Mon, 9 Oct 2017 12:45:30 GMT"}, {"version": "v3", "created": "Mon, 23 Oct 2017 15:42:11 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Tran", "Dat Thanh", ""], ["Iosifidis", "Alexandros", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1709.10089", "submitter": "Ashvin Nair", "authors": "Ashvin Nair, Bob McGrew, Marcin Andrychowicz, Wojciech Zaremba, Pieter\n  Abbeel", "title": "Overcoming Exploration in Reinforcement Learning with Demonstrations", "comments": "8 pages, ICRA 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration in environments with sparse rewards has been a persistent problem\nin reinforcement learning (RL). Many tasks are natural to specify with a sparse\nreward, and manually shaping a reward function can result in suboptimal\nperformance. However, finding a non-zero reward is exponentially more difficult\nwith increasing task horizon or action dimensionality. This puts many\nreal-world tasks out of practical reach of RL methods. In this work, we use\ndemonstrations to overcome the exploration problem and successfully learn to\nperform long-horizon, multi-step robotics tasks with continuous control such as\nstacking blocks with a robot arm. Our method, which builds on top of Deep\nDeterministic Policy Gradients and Hindsight Experience Replay, provides an\norder of magnitude of speedup over RL on simulated robotics tasks. It is simple\nto implement and makes only the additional assumption that we can collect a\nsmall set of demonstrations. Furthermore, our method is able to solve tasks not\nsolvable by either RL or behavior cloning alone, and often ends up\noutperforming the demonstrator policy.\n", "versions": [{"version": "v1", "created": "Thu, 28 Sep 2017 17:51:48 GMT"}, {"version": "v2", "created": "Sun, 25 Feb 2018 07:48:19 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Nair", "Ashvin", ""], ["McGrew", "Bob", ""], ["Andrychowicz", "Marcin", ""], ["Zaremba", "Wojciech", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1709.10204", "submitter": "Bin Bi", "authors": "Bin Bi and Hao Ma", "title": "A Neural Comprehensive Ranker (NCR) for Open-Domain Question Answering", "comments": "A paper with a similar method has been published earlier at\n  arXiv:1706.04815 The authors believe there is no need for a separate\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel neural machine reading model for open-domain\nquestion answering at scale. Existing machine comprehension models typically\nassume that a short piece of relevant text containing answers is already\nidentified and given to the models, from which the models are designed to\nextract answers. This assumption, however, is not realistic for building a\nlarge-scale open-domain question answering system which requires both deep text\nunderstanding and identifying relevant text from corpus simultaneously.\n  In this paper, we introduce Neural Comprehensive Ranker (NCR) that integrates\nboth passage ranking and answer extraction in one single framework. A Q&A\nsystem based on this framework allows users to issue an open-domain question\nwithout needing to provide a piece of text that must contain the answer.\nExperiments show that the unified NCR model is able to outperform the\nstates-of-the-art in both retrieval of relevant text and answer extraction.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 00:27:48 GMT"}, {"version": "v2", "created": "Thu, 5 Oct 2017 17:56:02 GMT"}], "update_date": "2017-10-06", "authors_parsed": [["Bi", "Bin", ""], ["Ma", "Hao", ""]]}, {"id": "1709.10205", "submitter": "Georgios Detorakis", "authors": "Georgios Detorakis, Sadique Sheik, Charles Augustine, Somnath Paul,\n  Bruno U. Pedroni, Nikil Dutt, Jeffrey Krichmar, Gert Cauwenberghs, Emre\n  Neftci", "title": "Neural and Synaptic Array Transceiver: A Brain-Inspired Computing\n  Framework for Embedded Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded, continual learning for autonomous and adaptive behavior is a key\napplication of neuromorphic hardware. However, neuromorphic implementations of\nembedded learning at large scales that are both flexible and efficient have\nbeen hindered by a lack of a suitable algorithmic framework. As a result, the\nmost neuromorphic hardware is trained off-line on large clusters of dedicated\nprocessors or GPUs and transferred post hoc to the device. We address this by\nintroducing the neural and synaptic array transceiver (NSAT), a neuromorphic\ncomputational framework facilitating flexible and efficient embedded learning\nby matching algorithmic requirements and neural and synaptic dynamics. NSAT\nsupports event-driven supervised, unsupervised and reinforcement learning\nalgorithms including deep learning. We demonstrate the NSAT in a wide range of\ntasks, including the simulation of Mihalas-Niebur neuron, dynamic neural\nfields, event-driven random back-propagation for event-based deep learning,\nevent-based contrastive divergence for unsupervised learning, and voltage-based\nlearning rules for sequence learning. We anticipate that this contribution will\nestablish the foundation for a new generation of devices enabling adaptive\nmobile systems, wearable devices, and robots with data-driven autonomy.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 00:30:32 GMT"}, {"version": "v2", "created": "Fri, 6 Oct 2017 22:51:48 GMT"}, {"version": "v3", "created": "Wed, 8 Aug 2018 18:30:13 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Detorakis", "Georgios", ""], ["Sheik", "Sadique", ""], ["Augustine", "Charles", ""], ["Paul", "Somnath", ""], ["Pedroni", "Bruno U.", ""], ["Dutt", "Nikil", ""], ["Krichmar", "Jeffrey", ""], ["Cauwenberghs", "Gert", ""], ["Neftci", "Emre", ""]]}, {"id": "1709.10211", "submitter": "Samiran Ganguly", "authors": "Samiran Ganguly, Kerem Y. Camsari, Avik W. Ghosh", "title": "Reservoir Computing using Stochastic p-Bits", "comments": "4 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cond-mat.mes-hall cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general hardware framework for building networks that directly\nimplement Reservoir Computing, a popular software method for implementing and\ntraining Recurrent Neural Networks and are particularly suited for temporal\ninferencing and pattern recognition. We provide a specific example of a\ncandidate hardware unit based on a combination of soft-magnets, spin-orbit\nmaterials and CMOS transistors that can implement these networks. Efficient non\nvon-Neumann hardware implementation of reservoir computers can open up a\npathway for integration of temporal Neural Networks in a wide variety of\nemerging systems such as Internet of Things (IoTs), industrial controls, bio-\nand photo-sensors, and self-driving automotives.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 01:30:50 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Ganguly", "Samiran", ""], ["Camsari", "Kerem Y.", ""], ["Ghosh", "Avik W.", ""]]}, {"id": "1709.10377", "submitter": "Naoki Hamada", "authors": "Naoki Hamada", "title": "Simple Problems: The Simplicial Gluing Structure of Pareto Sets and\n  Pareto Fronts", "comments": "10 pages, accepted at GECCO'17 as a poster paper (2 pages)", "journal-ref": null, "doi": "10.1145/3067695.3076069", "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quite a few studies on real-world applications of multi-objective\noptimization reported that their Pareto sets and Pareto fronts form a\ntopological simplex. Such a class of problems was recently named the simple\nproblems, and their Pareto set and Pareto front were observed to have a gluing\nstructure similar to the faces of a simplex. This paper gives a theoretical\njustification for that observation by proving the gluing structure of the\nPareto sets/fronts of subproblems of a simple problem. The simplicity of\nstandard benchmark problems is studied.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 09:59:57 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Hamada", "Naoki", ""]]}, {"id": "1709.10443", "submitter": "Luk\\'a\\v{s} Bajer", "authors": "Jakub Repicky, Lukas Bajer, Zbynek Pitra, Martin Holena", "title": "Adaptive Generation-Based Evolution Control for Gaussian Process\n  Surrogate Models", "comments": "Updated version. The original article appeared in Proceedings of the\n  17th ITAT Conference Martin, September 22--26, 2017, published by CreateSpace\n  Independent Publ. Platform and online by CEUR Workshop Proceedings. Abstract:\n  Added credits to the s*ACM-ES algorithm. Section 1: Added references and\n  clarified the motivation. Section 3: Added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interest in accelerating black-box optimizers has resulted in several\nsurrogate model-assisted version of the Covariance Matrix Adaptation Evolution\nStrategy, a state-of-the-art continuous black-box optimizer. The version called\nSurrogate CMA-ES uses Gaussian processes or random forests surrogate models\nwith a generation-based evolution control. This paper presents an adaptive\nimprovement for S-CMA-ES based on a general procedure introduced with the\ns*ACM-ES algorithm, in which the number of generations using the surrogate\nmodel before retraining is adjusted depending on the performance of the last\ninstance of the surrogate. Three algorithms that differ in the measure of the\nsurrogate model's performance are evaluated on the COCO/BBOB framework. The\nresults show a minor improvement on S-CMA-ES with constant model lifelengths,\nespecially when larger lifelengths are considered.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 15:05:53 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Repicky", "Jakub", ""], ["Bajer", "Lukas", ""], ["Pitra", "Zbynek", ""], ["Holena", "Martin", ""]]}, {"id": "1709.10459", "submitter": "Fred Bertsch", "authors": "Andrew Kyle Lampinen, David So, Douglas Eck, and Fred Bertsch", "title": "Improving image generative models with human interactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GANs provide a framework for training generative models which mimic a data\ndistribution. However, in many cases we wish to train these generative models\nto optimize some auxiliary objective function within the data it generates,\nsuch as making more aesthetically pleasing images. In some cases, these\nobjective functions are difficult to evaluate, e.g. they may require human\ninteraction. Here, we develop a system for efficiently improving a GAN to\ntarget an objective involving human interaction, specifically generating images\nthat increase rates of positive user interactions. To improve the generative\nmodel, we build a model of human behavior in the targeted domain from a\nrelatively small set of interactions, and then use this behavioral model as an\nauxiliary loss function to improve the generative model. We show that this\nsystem is successful at improving positive interaction rates, at least on\nsimulated data, and characterize some of the factors that affect its\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 29 Sep 2017 15:38:42 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Lampinen", "Andrew Kyle", ""], ["So", "David", ""], ["Eck", "Douglas", ""], ["Bertsch", "Fred", ""]]}]