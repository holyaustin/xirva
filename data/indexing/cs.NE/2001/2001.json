[{"id": "2001.00053", "submitter": "Kamyar Givaki", "authors": "Kamyar Givaki, Behzad Salami, Reza Hojabr, S. M. Reza Tayaranian,\n  Ahmad Khonsari, Dara Rahmati, Saeid Gorgin, Adrian Cristal, Osman S. Unsal", "title": "On the Resilience of Deep Learning for Reduced-voltage FPGAs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) are inherently computation-intensive and also\npower-hungry. Hardware accelerators such as Field Programmable Gate Arrays\n(FPGAs) are a promising solution that can satisfy these requirements for both\nembedded and High-Performance Computing (HPC) systems. In FPGAs, as well as\nCPUs and GPUs, aggressive voltage scaling below the nominal level is an\neffective technique for power dissipation minimization. Unfortunately, bit-flip\nfaults start to appear as the voltage is scaled down closer to the transistor\nthreshold due to timing issues, thus creating a resilience issue.\n  This paper experimentally evaluates the resilience of the training phase of\nDNNs in the presence of voltage underscaling related faults of FPGAs,\nespecially in on-chip memories. Toward this goal, we have experimentally\nevaluated the resilience of LeNet-5 and also a specially designed network for\nCIFAR-10 dataset with different activation functions of Rectified Linear Unit\n(Relu) and Hyperbolic Tangent (Tanh). We have found that modern FPGAs are\nrobust enough in extremely low-voltage levels and that low-voltage related\nfaults can be automatically masked within the training iterations, so there is\nno need for costly software- or hardware-oriented fault mitigation techniques\nlike ECC. Approximately 10% more training iterations are needed to fill the gap\nin the accuracy. This observation is the result of the relatively low rate of\nundervolting faults, i.e., <0.1\\%, measured on real FPGA fabrics. We have also\nincreased the fault rate significantly for the LeNet-5 network by randomly\ngenerated fault injection campaigns and observed that the training accuracy\nstarts to degrade. When the fault rate increases, the network with Tanh\nactivation function outperforms the one with Relu in terms of accuracy, e.g.,\nwhen the fault rate is 30% the accuracy difference is 4.92%.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 15:08:22 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Givaki", "Kamyar", ""], ["Salami", "Behzad", ""], ["Hojabr", "Reza", ""], ["Tayaranian", "S. M. Reza", ""], ["Khonsari", "Ahmad", ""], ["Rahmati", "Dara", ""], ["Gorgin", "Saeid", ""], ["Cristal", "Adrian", ""], ["Unsal", "Osman S.", ""]]}, {"id": "2001.00624", "submitter": "Mohammad Nazmul Haque", "authors": "Pablo Moscato and Haoyuan Sun and Mohammad Nazmul Haque", "title": "Analytic Continued Fractions for Regression: A Memetic Algorithm\n  Approach", "comments": "Submitted to Expert Systems with Applications", "journal-ref": "Expert Systems with Applications 179 (2021): 115018", "doi": "10.1016/j.eswa.2021.115018", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach for regression problems that employs analytic\ncontinued fractions as a novel representation. Comparative computational\nresults using a memetic algorithm are reported in this work. Our experiments\nincluded fifteen other different machine learning approaches including five\ngenetic programming methods for symbolic regression and ten machine learning\nmethods. The comparison on training and test generalization was performed using\n94 datasets of the Penn State Machine Learning Benchmark. The statistical tests\nshowed that the generalization results using analytic continued fractions\nprovides a powerful and interesting new alternative in the quest for compact\nand interpretable mathematical models for artificial intelligence.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 00:09:01 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Moscato", "Pablo", ""], ["Sun", "Haoyuan", ""], ["Haque", "Mohammad Nazmul", ""]]}, {"id": "2001.00689", "submitter": "Soochan Lee", "authors": "Soochan Lee, Junsoo Ha, Dongsu Zhang, Gunhee Kim", "title": "A Neural Dirichlet Process Mixture Model for Task-Free Continual\n  Learning", "comments": "Accepted as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growing interest in continual learning, most of its contemporary\nworks have been studied in a rather restricted setting where tasks are clearly\ndistinguishable, and task boundaries are known during training. However, if our\ngoal is to develop an algorithm that learns as humans do, this setting is far\nfrom realistic, and it is essential to develop a methodology that works in a\ntask-free manner. Meanwhile, among several branches of continual learning,\nexpansion-based methods have the advantage of eliminating catastrophic\nforgetting by allocating new resources to learn new data. In this work, we\npropose an expansion-based approach for task-free continual learning. Our\nmodel, named Continual Neural Dirichlet Process Mixture (CN-DPM), consists of a\nset of neural network experts that are in charge of a subset of the data.\nCN-DPM expands the number of experts in a principled way under the Bayesian\nnonparametric framework. With extensive experiments, we show that our model\nsuccessfully performs task-free continual learning for both discriminative and\ngenerative tasks such as image classification and image generation.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 02:07:31 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 23:32:01 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Lee", "Soochan", ""], ["Ha", "Junsoo", ""], ["Zhang", "Dongsu", ""], ["Kim", "Gunhee", ""]]}, {"id": "2001.00810", "submitter": "Zhengping Liang", "authors": "Zhengping Liang, Weiqi Liang, Xiuju Xu, Ling Liu and Zexuan Zhu", "title": "A Two stage Adaptive Knowledge Transfer Evolutionary Multi-tasking Based\n  on Population Distribution for Multi/Many-Objective Optimization", "comments": "14 pages, 8 figures, 7 tables, 61 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-tasking optimization can usually achieve better performance than\ntraditional single-tasking optimization through knowledge transfer between\ntasks. However, current multi-tasking optimization algorithms have some\ndeficiencies. For high similarity problems, the knowledge that can accelerate\nthe convergence rate of tasks has not been fully taken advantages of. For low\nsimilarity problems, the probability of generating negative transfer is high,\nwhich may result in optimization performance degradation. In addition, some\nknowledge transfer methods proposed previously do not fully consider how to\ndeal with the situation in which the population falls into local optimum. To\nsolve these issues, a two-stage adaptive knowledge transfer evolutionary\nmulti-tasking optimization algorithm based on population distribution, labeled\nas EMT-PD, is proposed. EMT-PD can accelerate and improve the convergence\nperformance of tasks based on the knowledge extracted from the probability\nmodel that reflects the search trend of the whole population. At the first\ntransfer stage, an adaptive weight is used to adjust the step size of\nindividual's search, which can reduce the impact of negative transfer. At the\nsecond stage of knowledge transfer, the individual's search range is further\nadjusted dynamically, which can improve the diversity of population and be\nbeneficial for jumping out of local optimum. Experimental results on\nmulti-tasking multi-objective optimization test suites show that EMT-PD is\nsuperior to other six state-of-the-art evolutionary multi/single-tasking\nalgorithms. To further investigate the effectiveness of EMT-PD on\nmany-objective optimization problems, a multi-tasking many-objective test suite\nis also designed in this paper. The experimental results on the new test suite\nalso demonstrate the competitiveness of EMT-PD.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 13:05:32 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 06:55:27 GMT"}, {"version": "v3", "created": "Fri, 26 Jun 2020 08:56:26 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Liang", "Zhengping", ""], ["Liang", "Weiqi", ""], ["Xu", "Xiuju", ""], ["Liu", "Ling", ""], ["Zhu", "Zexuan", ""]]}, {"id": "2001.01121", "submitter": "Takashi Shinozaki", "authors": "Takashi Shinozaki", "title": "Biologically-Motivated Deep Learning Method using Hierarchical\n  Competitive Learning", "comments": "Appeared at NIPS 2019 Workshop: Shared Visual Representations in\n  Human and Machine Intelligence (SVRHM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a novel biologically-motivated learning method for deep\nconvolutional neural networks (CNNs). The combination of CNNs and back\npropagation (BP) learning is the most powerful method in recent machine\nlearning regimes. However, it requires large labeled data for training, and\nthis requirement can occasionally become a barrier for real world applications.\nTo address this problem and utilize unlabeled data, I propose to introduce\nunsupervised competitive learning which only requires forward propagating\nsignals as a pre-training method for CNNs. The method was evaluated by image\ndiscrimination tasks using MNIST, CIFAR-10, and ImageNet datasets, and it\nachieved a state-of-the-art performance as a biologically-motivated method in\nthe ImageNet experiment. The results suggested that the method enables\nhigher-level learning representations solely from forward propagating signals\nwithout a backward error signal for the learning of convolutional layers. The\nproposed method could be useful for a variety of poorly labeled data, for\nexample, time series or medical data.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2020 20:07:36 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Shinozaki", "Takashi", ""]]}, {"id": "2001.01233", "submitter": "Wenwei Zhang", "authors": "Dongzhan Zhou, Xinchi Zhou, Wenwei Zhang, Chen Change Loy, Shuai Yi,\n  Xuesen Zhang, Wanli Ouyang", "title": "EcoNAS: Finding Proxies for Economical Neural Architecture Search", "comments": "CVPR2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) achieves significant progress in many\ncomputer vision tasks. While many methods have been proposed to improve the\nefficiency of NAS, the search progress is still laborious because training and\nevaluating plausible architectures over large search space is time-consuming.\nAssessing network candidates under a proxy (i.e., computationally reduced\nsetting) thus becomes inevitable. In this paper, we observe that most existing\nproxies exhibit different behaviors in maintaining the rank consistency among\nnetwork candidates. In particular, some proxies can be more reliable -- the\nrank of candidates does not differ much comparing their reduced setting\nperformance and final performance. In this paper, we systematically investigate\nsome widely adopted reduction factors and report our observations. Inspired by\nthese observations, we present a reliable proxy and further formulate a\nhierarchical proxy strategy. The strategy spends more computations on candidate\nnetworks that are potentially more accurate, while discards unpromising ones in\nearly stage with a fast proxy. This leads to an economical evolutionary-based\nNAS (EcoNAS), which achieves an impressive 400x search time reduction in\ncomparison to the evolutionary-based state of the art (8 vs. 3150 GPU days).\nSome new proxies led by our observations can also be applied to accelerate\nother NAS methods while still able to discover good candidate networks with\nperformance matching those found by previous proxy strategies.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 13:29:02 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2020 02:42:45 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Zhou", "Dongzhan", ""], ["Zhou", "Xinchi", ""], ["Zhang", "Wenwei", ""], ["Loy", "Chen Change", ""], ["Yi", "Shuai", ""], ["Zhang", "Xuesen", ""], ["Ouyang", "Wanli", ""]]}, {"id": "2001.01331", "submitter": "Andrew Lensen", "authors": "Andrew Lensen, Mengjie Zhang, Bing Xue", "title": "Multi-Objective Genetic Programming for Manifold Learning: Balancing\n  Quality and Dimensionality", "comments": "31 pages, pre-print accepted by Genetic Programming and Evolvable\n  Machines journal", "journal-ref": null, "doi": "10.1007/s10710-020-09375-4", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold learning techniques have become increasingly valuable as data\ncontinues to grow in size. By discovering a lower-dimensional representation\n(embedding) of the structure of a dataset, manifold learning algorithms can\nsubstantially reduce the dimensionality of a dataset while preserving as much\ninformation as possible. However, state-of-the-art manifold learning algorithms\nare opaque in how they perform this transformation. Understanding the way in\nwhich the embedding relates to the original high-dimensional space is critical\nin exploratory data analysis. We previously proposed a Genetic Programming\nmethod that performed manifold learning by evolving mappings that are\ntransparent and interpretable. This method required the dimensionality of the\nembedding to be known a priori, which makes it hard to use when little is known\nabout a dataset. In this paper, we substantially extend our previous work, by\nintroducing a multi-objective approach that automatically balances the\ncompeting objectives of manifold quality and dimensionality. Our proposed\napproach is competitive with a range of baseline and state-of-the-art manifold\nlearning methods, while also providing a range (front) of solutions that give\ndifferent trade-offs between quality and dimensionality. Furthermore, the\nlearned models are shown to often be simple and efficient, utilising only a\nsmall number of features in an interpretable manner.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jan 2020 23:24:33 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Lensen", "Andrew", ""], ["Zhang", "Mengjie", ""], ["Xue", "Bing", ""]]}, {"id": "2001.01382", "submitter": "Andrei Velichko", "authors": "Andrei Velichko, Maksim Belyaev, Vadim Putrolaynen, Valentin Perminov,\n  and Alexander Pergament", "title": "Thermal coupling and effect of subharmonic synchronization in a system\n  of two VO2 based oscillators", "comments": "24 pages, 10 figures", "journal-ref": "Solid. State. Electron. 2018, 141, 40-49", "doi": "10.1016/j.sse.2017.12.003", "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a prototype of an oscillatory neural network (ONN) based on\nvanadium dioxide switching devices. The model system under study represents two\noscillators based on thermally coupled VO2 switches. Numerical simulation shows\nthat the effective action radius RTC of coupling depends both on the total\nenergy released during switching and on the average power. It is experimentally\nand numerically proved that the temperature change dT commences almost\nsynchronously with the released power peak and T-coupling reveals itself up to\na frequency of about 10 kHz. For the studied switching structure configuration,\nthe RTC value varies over a wide range from 4 to 45 mkm, depending on the\nexternal circuit capacitance C and resistance Ri, but the variation of Ri is\nmore promising from the practical viewpoint. In the case of a \"weak\" coupling,\nsynchronization is accompanied by attraction effect and decrease of the main\nspectra harmonics width. In the case of a \"strong\" coupling, the number of\neffects increases, synchronization can occur on subharmonics resulting in\nmultilevel stable synchronization of two oscillators. An advanced algorithm for\nsynchronization efficiency and subharmonic ratio calculation is proposed. It is\nshown that of the two oscillators the leading one is that with a higher main\nfrequency, and, in addition, the frequency stabilization effect is observed.\nAlso, in the case of a strong thermal coupling, the limit of the supply current\nparameters, for which the oscillations exist, expands by ~ 10 %. The obtained\nresults have a universal character and open up a new kind of coupling in ONNs,\nnamely, T-coupling, which allows for easy transition from 2D to 3D integration.\nThe effect of subharmonic synchronization hold promise for application in\nclassification and pattern recognition.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 03:26:53 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Velichko", "Andrei", ""], ["Belyaev", "Maksim", ""], ["Putrolaynen", "Vadim", ""], ["Perminov", "Valentin", ""], ["Pergament", "Alexander", ""]]}, {"id": "2001.01416", "submitter": "Thomas Weise", "authors": "Thomas Weise and Zhize Wu and Xinlu Li and Yan Chen", "title": "Frequency Fitness Assignment: Making Optimization Algorithms Invariant\n  under Bijective Transformations of the Objective Function Value", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under Frequency Fitness Assignment (FFA), the fitness corresponding to an\nobjective value is its encounter frequency in fitness assignment steps and is\nsubject to minimization. FFA renders optimization processes invariant under\nbijective transformations of the objective function value. On TwoMax, Jump, and\nTrap functions of dimension s, the classical (1+1)-EA with standard mutation at\nrate 1/s can have expected runtimes exponential in s. In our experiments, a\n(1+1)-FEA, the same algorithm but using FFA, exhibits mean runtimes that seem\nto scale as $s^2\\ln{s}$. Since Jump and Trap are bijective transformations of\nOneMax, it behaves identical on all three. On OneMax, LeadingOnes, and Plateau\nproblems, it seems to be slower than the (1+1)-EA by a factor linear in s. The\n(1+1)-FEA performs much better than the (1+1)-EA on W-Model and MaxSat\ninstances. We further verify the bijection invariance by applying the Md5\nchecksum computation as transformation to some of the above problems and yield\nthe same behaviors. Finally, we show that FFA can improve the performance of a\nmemetic algorithm for job shop scheduling.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 06:16:18 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 06:05:17 GMT"}, {"version": "v3", "created": "Wed, 17 Jun 2020 23:45:23 GMT"}, {"version": "v4", "created": "Thu, 1 Oct 2020 10:05:30 GMT"}, {"version": "v5", "created": "Thu, 15 Oct 2020 22:45:11 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Weise", "Thomas", ""], ["Wu", "Zhize", ""], ["Li", "Xinlu", ""], ["Chen", "Yan", ""]]}, {"id": "2001.01559", "submitter": "Mehrdad Shafiei Dizaji", "authors": "Mojtaba Farrokh, Mehrdad Shafiei Dizaji, Farzad Shafiei Dizaji,\n  Nazanin Moradinasab", "title": "Universal Hysteresis Identification Using Extended Preisach Neural\n  Network", "comments": "17 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hysteresis phenomena have been observed in different branches of physics and\nengineering sciences. Therefore, several models have been proposed for\nhysteresis simulation in different fields; however, almost neither of them can\nbe utilized universally. In this paper by inspiring of Preisach Neural Network\nwhich was inspired by the Preisach model that basically stemmed from Madelungs\nrules and using the learning capability of the neural networks, an adaptive\nuniversal model for hysteresis is introduced and called Extended Preisach\nNeural Network Model. It is comprised of input, output and, two hidden layers.\nThe input and output layers contain linear neurons while the first hidden layer\nincorporates neurons called Deteriorating Stop neurons, which their activation\nfunction follows Deteriorating Stop operator. Deteriorating Stop operators can\ngenerate non-congruent hysteresis loops. The second hidden layer includes\nSigmoidal neurons. Adding the second hidden layer, helps the neural network\nlearn non-Masing and asymmetric hysteresis loops very smoothly. At the input\nlayer, besides input data the rate at which input data changes, is included as\nwell in order to give the model the capability of learning rate-dependent\nhysteresis loops. Hence, the proposed approach has the capability of the\nsimulation of both rate-independent and rate-dependent hysteresis with either\ncongruent or non-congruent loops as well as symmetric and asymmetric loops. A\nnew hybridized algorithm has been adopted for training the model which is based\non a combination of the Genetic Algorithm and the optimization method of\nsub-gradient with space dilatation. The generality of the proposed model has\nbeen evaluated by applying it to various hysteresis from different areas of\nengineering with different characteristics. The results show that the model is\nsuccessful in the identification of the considered hystereses.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 18:10:48 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Farrokh", "Mojtaba", ""], ["Dizaji", "Mehrdad Shafiei", ""], ["Dizaji", "Farzad Shafiei", ""], ["Moradinasab", "Nazanin", ""]]}, {"id": "2001.01587", "submitter": "Ling Liang", "authors": "Ling Liang, Xing Hu, Lei Deng, Yujie Wu, Guoqi Li, Yufei Ding, Peng\n  Li, Yuan Xie", "title": "Exploring Adversarial Attack in Spiking Neural Networks with\n  Spike-Compatible Gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CR cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, backpropagation through time inspired learning algorithms are\nwidely introduced into SNNs to improve the performance, which brings the\npossibility to attack the models accurately given Spatio-temporal gradient\nmaps. We propose two approaches to address the challenges of gradient input\nincompatibility and gradient vanishing. Specifically, we design a gradient to\nspike converter to convert continuous gradients to ternary ones compatible with\nspike inputs. Then, we design a gradient trigger to construct ternary gradients\nthat can randomly flip the spike inputs with a controllable turnover rate, when\nmeeting all zero gradients. Putting these methods together, we build an\nadversarial attack methodology for SNNs trained by supervised algorithms.\nMoreover, we analyze the influence of the training loss function and the firing\nthreshold of the penultimate layer, which indicates a \"trap\" region under the\ncross-entropy loss that can be escaped by threshold tuning. Extensive\nexperiments are conducted to validate the effectiveness of our solution.\nBesides the quantitative analysis of the influence factors, we evidence that\nSNNs are more robust against adversarial attack than ANNs. This work can help\nreveal what happens in SNN attack and might stimulate more research on the\nsecurity of SNN models and neuromorphic devices.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 18:14:44 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 22:56:29 GMT"}], "update_date": "2020-10-02", "authors_parsed": [["Liang", "Ling", ""], ["Hu", "Xing", ""], ["Deng", "Lei", ""], ["Wu", "Yujie", ""], ["Li", "Guoqi", ""], ["Ding", "Yufei", ""], ["Li", "Peng", ""], ["Xie", "Yuan", ""]]}, {"id": "2001.01622", "submitter": "Tom Kocmi", "authors": "Tom Kocmi", "title": "Exploring Benefits of Transfer Learning in Neural Machine Translation", "comments": "Defended PhD thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation is known to require large numbers of parallel\ntraining sentences, which generally prevent it from excelling on low-resource\nlanguage pairs. This thesis explores the use of cross-lingual transfer learning\non neural networks as a way of solving the problem with the lack of resources.\nWe propose several transfer learning approaches to reuse a model pretrained on\na high-resource language pair. We pay particular attention to the simplicity of\nthe techniques. We study two scenarios: (a) when we reuse the high-resource\nmodel without any prior modifications to its training process and (b) when we\ncan prepare the first-stage high-resource model for transfer learning in\nadvance. For the former scenario, we present a proof-of-concept method by\nreusing a model trained by other researchers. In the latter scenario, we\npresent a method which reaches even larger improvements in translation\nperformance. Apart from proposed techniques, we focus on an in-depth analysis\nof transfer learning techniques and try to shed some light on transfer learning\nimprovements. We show how our techniques address specific problems of\nlow-resource languages and are suitable even in high-resource transfer\nlearning. We evaluate the potential drawbacks and behavior by studying transfer\nlearning in various situations, for example, under artificially damaged\ntraining corpora, or with fixed various model parts.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 15:11:59 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Kocmi", "Tom", ""]]}, {"id": "2001.01647", "submitter": "Jiwoong Im", "authors": "Daniel Jiwoong Im, Rutuja Patil, Kristin Branson", "title": "Are skip connections necessary for biologically plausible learning\n  rules?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation is the workhorse of deep learning, however, several other\nbiologically-motivated learning rules have been introduced, such as random\nfeedback alignment and difference target propagation. None of these methods\nhave produced a competitive performance against backpropagation. In this paper,\nwe show that biologically-motivated learning rules with skip connections\nbetween intermediate layers can perform as well as backpropagation on the MNIST\ndataset and are robust to various sets of hyper-parameters.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 22:21:16 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Im", "Daniel Jiwoong", ""], ["Patil", "Rutuja", ""], ["Branson", "Kristin", ""]]}, {"id": "2001.01680", "submitter": "Mingyuan Meng", "authors": "Mingyuan Meng, Xingyu Yang, Lei Bi, Jinman Kim, Shanlin Xiao, and\n  Zhiyi Yu", "title": "High-parallelism Inception-like Spiking Neural Networks for Unsupervised\n  Feature Learning", "comments": "Published at Neurocomputing", "journal-ref": "Neurocomputing 441(2021), pp. 92-104", "doi": "10.1016/j.neucom.2021.02.027", "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Spiking Neural Networks (SNNs) are brain-inspired, event-driven machine\nlearning algorithms that have been widely recognized in producing\nultra-high-energy-efficient hardware. Among existing SNNs, unsupervised SNNs\nbased on synaptic plasticity, especially Spike-Timing-Dependent Plasticity\n(STDP), are considered to have great potential in imitating the learning\nprocess of the biological brain. Nevertheless, the existing STDP-based SNNs\nhave limitations in constrained learning capability and/or slow learning speed.\nMost STDP-based SNNs adopted a slow-learning Fully-Connected (FC) architecture\nand used a sub-optimal vote-based scheme for spike decoding. In this paper, we\novercome these limitations with: 1) a design of high-parallelism network\narchitecture, inspired by the Inception module in Artificial Neural Networks\n(ANNs); 2) use of a Vote-for-All (VFA) decoding layer as a replacement to the\nstandard vote-based spike decoding scheme, to reduce the information loss in\nspike decoding and, 3) a proposed adaptive repolarization (resetting) mechanism\nthat accelerates SNNs' learning by enhancing spiking activities. Our\nexperimental results on two established benchmark datasets (MNIST/EMNIST) show\nthat our network architecture resulted in superior performance compared to the\nwidely used FC architecture and a more advanced Locally-Connected (LC)\narchitecture, and that our SNN achieved competitive results with\nstate-of-the-art unsupervised SNNs (95.64%/80.11% accuracy on the MNIST/EMNISE\ndataset) while having superior learning efficiency and robustness against\nhardware damage. Our SNN achieved great classification accuracy with only\nhundreds of training iterations, and random destruction of large numbers of\nsynapses or neurons only led to negligible performance degradation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 17:19:17 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 17:53:25 GMT"}, {"version": "v3", "created": "Sun, 12 Apr 2020 14:25:23 GMT"}, {"version": "v4", "created": "Thu, 4 Jun 2020 16:05:09 GMT"}, {"version": "v5", "created": "Tue, 9 Mar 2021 04:00:23 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Meng", "Mingyuan", ""], ["Yang", "Xingyu", ""], ["Bi", "Lei", ""], ["Kim", "Jinman", ""], ["Xiao", "Shanlin", ""], ["Yu", "Zhiyi", ""]]}, {"id": "2001.01681", "submitter": "Michael Y.-S. Fang", "authors": "Michael Y.-S. Fang, Sasikanth Manipatruni, Casimir Wierzynski, Amir\n  Khosrowshahi, and Michael R. DeWeese", "title": "Design of optical neural networks with component imprecisions", "comments": null, "journal-ref": "Optics express 27.10 (2019): 14009-14029", "doi": "10.1364/OE.27.014009", "report-no": null, "categories": "cs.NE cs.ET physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the benefit of designing scalable, fault resistant optical neural\nnetworks (ONNs), we investigate the effects architectural designs have on the\nONNs' robustness to imprecise components. We train two ONNs -- one with a more\ntunable design (GridNet) and one with better fault tolerance (FFTNet) -- to\nclassify handwritten digits. When simulated without any imperfections, GridNet\nyields a better accuracy (~98%) than FFTNet (~95%). However, under a small\namount of error in their photonic components, the more fault tolerant FFTNet\novertakes GridNet. We further provide thorough quantitative and qualitative\nanalyses of ONNs' sensitivity to varying levels and types of imprecisions. Our\nresults offer guidelines for the principled design of fault-tolerant ONNs as\nwell as a foundation for further research.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 20:15:35 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Fang", "Michael Y. -S.", ""], ["Manipatruni", "Sasikanth", ""], ["Wierzynski", "Casimir", ""], ["Khosrowshahi", "Amir", ""], ["DeWeese", "Michael R.", ""]]}, {"id": "2001.01682", "submitter": "Wolfgang Maass Prof.", "authors": "Christoph St\\\"ockl and Wolfgang Maass", "title": "Recognizing Images with at most one Spike per Neuron", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to port the performance of trained artificial neural networks (ANNs)\nto spiking neural networks (SNNs), which can be implemented in neuromorphic\nhardware with a drastically reduced energy consumption, an efficient ANN to SNN\nconversion is needed. Previous conversion schemes focused on the representation\nof the analog output of a rectified linear (ReLU) gate in the ANN by the firing\nrate of a spiking neuron. But this is not possible for other commonly used ANN\ngates, and it reduces the throughput even for ReLU gates. We introduce a new\nconversion method where a gate in the ANN, which can basically be of any type,\nis emulated by a small circuit of spiking neurons, with At Most One Spike\n(AMOS) per neuron. We show that this AMOS conversion improves the accuracy of\nSNNs for ImageNet from 74.60% to 80.97%, thereby bringing it within reach of\nthe best available ANN accuracy (85.0%). The Top5 accuracy of SNNs is raised to\n95.82%, getting even closer to the best Top5 performance of 97.2% for ANNs. In\naddition, AMOS conversion improves latency and throughput of spike-based image\nclassification by several orders of magnitude. Hence these results suggest that\nSNNs provide a viable direction for developing highly energy efficient hardware\nfor AI that combines high performance with versatility of applications.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 16:28:11 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 10:08:27 GMT"}, {"version": "v3", "created": "Tue, 21 Jan 2020 10:54:26 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["St\u00f6ckl", "Christoph", ""], ["Maass", "Wolfgang", ""]]}, {"id": "2001.01683", "submitter": "Sebastian Risi", "authors": "Sebastian Risi and Kenneth O. Stanley", "title": "Deep Innovation Protection: Confronting the Credit Assignment Problem in\n  Training Heterogeneous Neural Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning approaches have shown impressive results in a\nvariety of different domains, however, more complex heterogeneous architectures\nsuch as world models require the different neural components to be trained\nseparately instead of end-to-end. While a simple genetic algorithm recently\nshowed end-to-end training is possible, it failed to solve a more complex 3D\ntask. This paper presents a method called Deep Innovation Protection (DIP) that\naddresses the credit assignment problem in training complex heterogenous neural\nnetwork models end-to-end for such environments. The main idea behind the\napproach is to employ multiobjective optimization to temporally reduce the\nselection pressure on specific components in multi-component network, allowing\nother components to adapt. We investigate the emergent representations of these\nevolved networks, which learn to predict properties important for the survival\nof the agent, without the need for a specific forward-prediction loss.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 18:35:06 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 11:20:36 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Risi", "Sebastian", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "2001.01684", "submitter": "John Raisbeck", "authors": "John C. Raisbeck (1), Matthew Allen (1), Ralph Weissleder (1),\n  Hyungsoon Im (1), Hakho Lee (1) ((1) Massachusetts General Hospital)", "title": "Evolution Strategies Converges to Finite Differences", "comments": "6 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the debut of Evolution Strategies (ES) as a tool for Reinforcement\nLearning by Salimans et al. 2017, there has been interest in determining the\nexact relationship between the Evolution Strategies gradient and the gradient\nof a similar class of algorithms, Finite Differences (FD).(Zhang et al. 2017,\nLehman et al. 2018) Several investigations into the subject have been\nperformed, investigating the formal motivational differences(Lehman et al.\n2018) between ES and FD, as well as the differences in a standard benchmark\nproblem in Machine Learning, the MNIST classification problem(Zhang et al.\n2017). This paper proves that while the gradients are different, they converge\nas the dimension of the vector under optimization increases.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 19:24:05 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Raisbeck", "John C.", "", "Massachusetts General Hospital"], ["Allen", "Matthew", "", "Massachusetts General Hospital"], ["Weissleder", "Ralph", "", "Massachusetts General Hospital"], ["Im", "Hyungsoon", "", "Massachusetts General Hospital"], ["Lee", "Hakho", "", "Massachusetts General Hospital"]]}, {"id": "2001.01685", "submitter": "Yaodong He", "authors": "Yaodong He and Shiu Yin Yuen", "title": "Black Box Algorithm Selection by Convolutional Neural Network", "comments": "9 pages, 4 figures, 5 tables, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although a large number of optimization algorithms have been proposed for\nblack box optimization problems, the no free lunch theorems inform us that no\nalgorithm can beat others on all types of problems. Different types of\noptimization problems need different optimization algorithms. To deal with this\nissue, researchers propose algorithm selection to suggest the best optimization\nalgorithm from the algorithm set for a given unknown optimization problem.\nUsually, algorithm selection is treated as a classification or regression task.\nDeep learning, which has been shown to perform well on various classification\nand regression tasks, is applied to the algorithm selection problem in this\npaper. Our deep learning architecture is based on convolutional neural network\nand follows the main architecture of visual geometry group. This architecture\nhas been applied to many different types of 2-D data. Moreover, we also propose\na novel method to extract landscape information from the optimization problems\nand save the information as 2-D images. In the experimental section, we conduct\nthree experiments to investigate the classification and optimization capability\nof our approach on the BBOB functions. The results indicate that our new\napproach can effectively solve the algorithm selection problem.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 12:58:57 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["He", "Yaodong", ""], ["Yuen", "Shiu Yin", ""]]}, {"id": "2001.01686", "submitter": "Omolbanin Yazdanbakhsh", "authors": "Omolbanin Yazdanbakhsh and Scott Dick", "title": "A Deep Neuro-Fuzzy Network for Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of neural network and fuzzy systems into neuro-fuzzy systems\nintegrates fuzzy reasoning rules into the connectionist networks. However, the\nexisting neuro-fuzzy systems are developed under shallow structures having\nlower generalization capacity. We propose the first end-to-end deep neuro-fuzzy\nnetwork and investigate its application for image classification. Two new\noperations are developed based on definitions of Takagi-Sugeno-Kang (TSK) fuzzy\nmodel namely fuzzy inference operation and fuzzy pooling operations; stacks of\nthese operations comprise the layers in this network. We evaluate the network\non MNIST, CIFAR-10 and CIFAR-100 datasets, finding that the network has a\nreasonable accuracy in these benchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 03:28:05 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Yazdanbakhsh", "Omolbanin", ""], ["Dick", "Scott", ""]]}, {"id": "2001.01687", "submitter": "Rafi Qumsieh", "authors": "Rafi Qumsieh", "title": "A Supervised Modified Hebbian Learning Method On Feed-forward Neural\n  Networks", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a new supervised learning algorithm that is based\non the Hebbian learning algorithm in an attempt to offer a substitute for back\npropagation along with the gradient descent for a more biologically plausible\nmethod. The best performance for the algorithm was achieved when it was run on\na feed-forward neural network with the MNIST handwritten digits data set\nreaching an accuracy of 70.4% on the test data set and 71.48% on the validation\ndata set.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 03:12:50 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Qumsieh", "Rafi", ""]]}, {"id": "2001.01795", "submitter": "Zhong Meng", "authors": "Zhong Meng, Yashesh Gaur, Jinyu Li, Yifan Gong", "title": "Character-Aware Attention-Based End-to-End Speech Recognition", "comments": "7 pages, 3 figures, ASRU 2019", "journal-ref": "2019 IEEE Automatic Speech Recognition and Understanding Workshop\n  (ASRU), Sentosa, Singapore", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting words and subword units (WSUs) as the output has shown to be\neffective for the attention-based encoder-decoder (AED) model in end-to-end\nspeech recognition. However, as one input to the decoder recurrent neural\nnetwork (RNN), each WSU embedding is learned independently through context and\nacoustic information in a purely data-driven fashion. Little effort has been\nmade to explicitly model the morphological relationships among WSUs. In this\nwork, we propose a novel character-aware (CA) AED model in which each WSU\nembedding is computed by summarizing the embeddings of its constituent\ncharacters using a CA-RNN. This WSU-independent CA-RNN is jointly trained with\nthe encoder, the decoder and the attention network of a conventional AED to\npredict WSUs. With CA-AED, the embeddings of morphologically similar WSUs are\nnaturally and directly correlated through the CA-RNN in addition to the\nsemantic and acoustic relations modeled by a traditional AED. Moreover, CA-AED\nsignificantly reduces the model parameters in a traditional AED by replacing\nthe large pool of WSU embeddings with a much smaller set of character\nembeddings. On a 3400 hours Microsoft Cortana dataset, CA-AED achieves up to\n11.9% relative WER improvement over a strong AED baseline with 27.1% fewer\nmodel parameters.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 22:19:17 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Meng", "Zhong", ""], ["Gaur", "Yashesh", ""], ["Li", "Jinyu", ""], ["Gong", "Yifan", ""]]}, {"id": "2001.01798", "submitter": "Zhong Meng", "authors": "Zhong Meng, Jinyu Li, Yashesh Gaur, Yifan Gong", "title": "Domain Adaptation via Teacher-Student Learning for End-to-End Speech\n  Recognition", "comments": "8 pages, 2 figures, ASRU 2019", "journal-ref": "2019 IEEE Automatic Speech Recognition and Understanding Workshop\n  (ASRU), Sentosa, Singapore", "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teacher-student (T/S) has shown to be effective for domain adaptation of deep\nneural network acoustic models in hybrid speech recognition systems. In this\nwork, we extend the T/S learning to large-scale unsupervised domain adaptation\nof an attention-based end-to-end (E2E) model through two levels of knowledge\ntransfer: teacher's token posteriors as soft labels and one-best predictions as\ndecoder guidance. To further improve T/S learning with the help of ground-truth\nlabels, we propose adaptive T/S (AT/S) learning. Instead of conditionally\nchoosing from either the teacher's soft token posteriors or the one-hot\nground-truth label, in AT/S, the student always learns from both the teacher\nand the ground truth with a pair of adaptive weights assigned to the soft and\none-hot labels quantifying the confidence on each of the knowledge sources. The\nconfidence scores are dynamically estimated at each decoder step as a function\nof the soft and one-hot labels. With 3400 hours parallel close-talk and\nfar-field Microsoft Cortana data for domain adaptation, T/S and AT/S achieve\n6.3% and 10.3% relative word error rate improvement over a strong E2E model\ntrained with the same amount of far-field data.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 22:30:33 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Meng", "Zhong", ""], ["Li", "Jinyu", ""], ["Gaur", "Yashesh", ""], ["Gong", "Yifan", ""]]}, {"id": "2001.01829", "submitter": "Xiaofeng Zhu", "authors": "Xiaofeng Zhu, Feng Liu, Goce Trajcevski, Dingding Wang", "title": "Frosting Weights for Better Continual Training", "comments": null, "journal-ref": "ICMLA 2019", "doi": "10.1109/ICMLA.2019.00094", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a neural network model can be a lifelong learning process and is a\ncomputationally intensive one. A severe adverse effect that may occur in deep\nneural network models is that they can suffer from catastrophic forgetting\nduring retraining on new data. To avoid such disruptions in the continuous\nlearning, one appealing property is the additive nature of ensemble models. In\nthis paper, we propose two generic ensemble approaches, gradient boosting and\nmeta-learning, to solve the catastrophic forgetting problem in tuning\npre-trained neural network models.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 00:53:46 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Zhu", "Xiaofeng", ""], ["Liu", "Feng", ""], ["Trajcevski", "Goce", ""], ["Wang", "Dingding", ""]]}, {"id": "2001.01854", "submitter": "Andrei Velichko", "authors": "Andrei Velichko, Maksim Belyaev, Vadim Putrolaynen, Alexander\n  Pergament, and Valentin Perminov", "title": "Switching dynamics of single and coupled VO2-based oscillators as\n  elements of neural networks", "comments": "33 pages, 23 figures", "journal-ref": "International Journal of Modern Physics B, Vol. 31, No. 02,\n  1650261 (2017)", "doi": "10.1142/S0217979216502611", "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, we report on the switching dynamics of both single and\ncoupled VO2-based oscillators, with resistive and capacitive coupling, and\nexplore the capability of their application in oscillatory neural networks.\nBased on these results, we further select an adequate SPICE model to describe\nthe modes of operation of coupled oscillator circuits. Physical mechanisms\ninfluencing the time of forward and reverse electrical switching, that\ndetermine the applicability limits of the proposed model, are identified. For\nthe resistive coupling, it is shown that synchronization takes place at a\ncertain value of the coupling resistance, though it is unstable and a\nsynchronization failure occurs periodically. For the capacitive coupling, two\nsynchronization modes, with weak and strong coupling, are found. The transition\nbetween these modes is accompanied by chaotic oscillations. A decrease in the\nwidth of the spectrum harmonics in the weak-coupling mode, and its increase in\nthe strong-coupling one, is detected. The dependences of frequencies and phase\ndifferences of the coupled oscillatory circuits on the coupling capacitance are\nfound. Examples of operation of coupled VO2 oscillators as a central pattern\ngenerator are demonstrated.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 02:16:04 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Velichko", "Andrei", ""], ["Belyaev", "Maksim", ""], ["Putrolaynen", "Vadim", ""], ["Pergament", "Alexander", ""], ["Perminov", "Valentin", ""]]}, {"id": "2001.02037", "submitter": "Patrik Christen", "authors": "Patrik Christen and Olivier Del Fabbro", "title": "Cybernetical Concepts for Cellular Automaton and Artificial Neural\n  Network Modelling and Implementation", "comments": "12 pages, 1 figure", "journal-ref": "2019 IEEE International Conference on Systems, Man and Cybernetics\n  (SMC), 4124-4130, 2019", "doi": "10.1109/SMC.2019.8913839", "report-no": null, "categories": "cs.OH cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As a discipline cybernetics has a long and rich history. In its first\ngeneration it not only had a worldwide span, in the area of computer modelling,\nfor example, its proponents such as John von Neumann, Stanislaw Ulam, Warren\nMcCulloch and Walter Pitts, also came up with models and methods such as\ncellular automata and artificial neural networks, which are still the\nfoundation of most modern modelling approaches. At the same time, cybernetics\nalso got the attention of philosophers, such as the Frenchman Gilbert Simondon,\nwho made use of cybernetical concepts in order to establish a metaphysics and a\nnatural philosophy of individuation, giving cybernetics thereby a philosophical\ninterpretation, which he baptised allagmatic. In this paper, we emphasise this\nallagmatic theory by showing how Simondon's philosophical concepts can be used\nto formulate a generic computer model or metamodel for complex systems\nmodelling and its implementation in program code, according to generic\nprogramming. We also present how the developed allagmatic metamodel is capable\nof building simple cellular automata and artificial neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 24 Nov 2019 21:02:34 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 20:59:31 GMT"}, {"version": "v3", "created": "Mon, 31 Aug 2020 21:41:04 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Christen", "Patrik", ""], ["Del Fabbro", "Olivier", ""]]}, {"id": "2001.02292", "submitter": "Tarik A. Rashid", "authors": "Chnoor M. Rahman and Tarik A. Rashid", "title": "Dragonfly Algorithm and its Applications in Applied Science -- Survey", "comments": "24 pages. Computational Intelligence and Neuroscience, Hindawi, 23\n  November 2019", "journal-ref": null, "doi": null, "report-no": "Article ID: 9293617", "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most recently developed heuristic optimization algorithms is\ndragonfly by Mirjalili. Dragonfly algorithm has shown its ability to optimizing\ndifferent real world problems. It has three variants. In this work, an overview\nof the algorithm and its variants is presented. Moreover, the hybridization\nversions of the algorithm are discussed. Furthermore, the results of the\napplications that utilized dragonfly algorithm in applied science are offered\nin the following area: Machine Learning, Image Processing, Wireless, and\nNetworking. It is then compared with some other metaheuristic algorithms. In\naddition, the algorithm is tested on the CEC-C06 2019 benchmark functions. The\nresults prove that the algorithm has great exploration ability and its\nconvergence rate is better than other algorithms in the literature, such as PSO\nand GA. In general, in this survey the strong and weak points of the algorithm\nare discussed. Furthermore, some future works that will help in improving the\nalgorithm's weak points are recommended. This study is conducted with the hope\nof offering beneficial information about dragonfly algorithm to the researchers\nwho want to study the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 19:50:35 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Rahman", "Chnoor M.", ""], ["Rashid", "Tarik A.", ""]]}, {"id": "2001.02786", "submitter": "Zhucheng Tu", "authors": "Hadi Pouransari, Zhucheng Tu, Oncel Tuzel", "title": "Least squares binary quantization of neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantizing weights and activations of deep neural networks results in\nsignificant improvement in inference efficiency at the cost of lower accuracy.\nA source of the accuracy gap between full precision and quantized models is the\nquantization error. In this work, we focus on the binary quantization, in which\nvalues are mapped to -1 and 1. We provide a unified framework to analyze\ndifferent scaling strategies. Inspired by the pareto-optimality of 2-bits\nversus 1-bit quantization, we introduce a novel 2-bits quantization with\nprovably least squares error. Our quantization algorithms can be implemented\nefficiently on the hardware using bitwise operations. We present proofs to show\nthat our proposed methods are optimal, and also provide empirical error\nanalysis. We conduct experiments on the ImageNet dataset and show a reduced\naccuracy gap when using the proposed least squares quantization algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 00:01:14 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 00:33:48 GMT"}, {"version": "v3", "created": "Sat, 13 Jun 2020 07:23:03 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Pouransari", "Hadi", ""], ["Tu", "Zhucheng", ""], ["Tuzel", "Oncel", ""]]}, {"id": "2001.02920", "submitter": "Patrick Murer", "authors": "Patrick Murer and Hans-Andrea Loeliger", "title": "Online Memorization of Random Firing Sequences by a Recurrent Neural\n  Network", "comments": "8 pages, 3 figures; submitted to ISIT 2020; with additional proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the capability of a recurrent neural network model to\nmemorize random dynamical firing patterns by a simple local learning rule. Two\nmodes of learning/memorization are considered: The first mode is strictly\nonline, with a single pass through the data, while the second mode uses\nmultiple passes through the data. In both modes, the learning is strictly local\n(quasi-Hebbian): At any given time step, only the weights between the neurons\nfiring (or supposed to be firing) at the previous time step and those firing\n(or supposed to be firing) at the present time step are modified. The main\nresult of the paper is an upper bound on the probability that the single-pass\nmemorization is not perfect. It follows that the memorization capacity in this\nmode asymptotically scales like that of the classical Hopfield model (which, in\ncontrast, memorizes static patterns). However, multiple-rounds memorization is\nshown to achieve a higher capacity (with a nonvanishing number of bits per\nconnection/synapse). These mathematical findings may be helpful for\nunderstanding the functions of short-term memory and long-term memory in\nneuroscience.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 11:02:53 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Murer", "Patrick", ""], ["Loeliger", "Hans-Andrea", ""]]}, {"id": "2001.02957", "submitter": "Frederik Rehbach", "authors": "Frederik Rehbach and Martin Zaefferer and Boris Naujoks and Thomas\n  Bartz-Beielstein", "title": "Expected Improvement versus Predicted Value in Surrogate-Based\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surrogate-based optimization relies on so-called infill criteria (acquisition\nfunctions) to decide which point to evaluate next. When Kriging is used as the\nsurrogate model of choice (also called Bayesian optimization), one of the most\nfrequently chosen criteria is expected improvement. We argue that the\npopularity of expected improvement largely relies on its theoretical properties\nrather than empirically validated performance. Few results from the literature\nshow evidence, that under certain conditions, expected improvement may perform\nworse than something as simple as the predicted value of the surrogate model.\nWe benchmark both infill criteria in an extensive empirical study on the `BBOB'\nfunction set. This investigation includes a detailed study of the impact of\nproblem dimensionality on algorithm performance. The results support the\nhypothesis that exploration loses importance with increasing problem\ndimensionality. A statistical analysis reveals that the purely exploitative\nsearch with the predicted value criterion performs better on most problems of\nfive or higher dimensions. Possible reasons for these results are discussed. In\naddition, we give an in-depth guide for choosing the infill criteria based on\nprior knowledge about the problem at hand, its dimensionality, and the\navailable budget.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 13:09:44 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 08:38:39 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Rehbach", "Frederik", ""], ["Zaefferer", "Martin", ""], ["Naujoks", "Boris", ""], ["Bartz-Beielstein", "Thomas", ""]]}, {"id": "2001.02976", "submitter": "Jing Su", "authors": "Andrew Anderson, Jing Su, Rozenn Dahyot and David Gregg", "title": "Performance-Oriented Neural Architecture Search", "comments": "The 2019 International Conference on High Performance Computing &\n  Simulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware-Software Co-Design is a highly successful strategy for improving\nperformance of domain-specific computing systems. We argue for the application\nof the same methodology to deep learning; specifically, we propose to extend\nneural architecture search with information about the hardware to ensure that\nthe model designs produced are highly efficient in addition to the typical\ncriteria around accuracy. Using the task of keyword spotting in audio on edge\ncomputing devices, we demonstrate that our approach results in neural\narchitecture that is not only highly accurate, but also efficiently mapped to\nthe computing platform which will perform the inference. Using our modified\nneural architecture search, we demonstrate $0.88\\%$ increase in TOP-1 accuracy\nwith $1.85\\times$ reduction in latency for keyword spotting in audio on an\nembedded SoC, and $1.59\\times$ on a high-end GPU.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 13:47:39 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Anderson", "Andrew", ""], ["Su", "Jing", ""], ["Dahyot", "Rozenn", ""], ["Gregg", "David", ""]]}, {"id": "2001.03237", "submitter": "Mahesh Patil", "authors": "Mahesh B. Patil, Ramakrishna U., Mohan S. C", "title": "Multi-Objective Optimisation of Damper Placement for Improved Seismic\n  Response in Dynamically Similar Adjacent Buildings", "comments": "11 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective optimisation of damper placement in dynamically symmetric\nadjacent buildings is considered with identical viscoelastic dampers used for\nvibration control. First, exhaustive search is used to describe the solution\nspace in terms of various quantities of interest such as maximum top floor\ndisplacement, maximum floor acceleration, base shear, and interstorey drift.\nWith the help of examples, it is pointed out that the Pareto fronts in these\nproblems contain a very small number of solutions. The effectiveness of two\ncommonly used multi-objective evolutionary algorithms, viz., NSGA-II and MOPSO,\nis evaluated for a specific example.\n", "versions": [{"version": "v1", "created": "Sun, 29 Dec 2019 19:19:57 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Patil", "Mahesh B.", ""], ["U.", "Ramakrishna", ""], ["C", "Mohan S.", ""]]}, {"id": "2001.03255", "submitter": "Stefan Horoi", "authors": "Stefan Horoi, Guillaume Lajoie and Guy Wolf", "title": "Internal representation dynamics and geometry in recurrent neural\n  networks", "comments": "Presented as a poster at MAIS 2019: the Montreal AI Symposium,\n  Montreal, Quebec, Canada, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficiency of recurrent neural networks (RNNs) in dealing with sequential\ndata has long been established. However, unlike deep, and convolution networks\nwhere we can attribute the recognition of a certain feature to every layer, it\nis unclear what \"sub-task\" a single recurrent step or layer accomplishes. Our\nwork seeks to shed light onto how a vanilla RNN implements a simple\nclassification task by analysing the dynamics of the network and the geometric\nproperties of its hidden states. We find that early internal representations\nare evocative of the real labels of the data but this information is not\ndirectly accessible to the output layer. Furthermore the network's dynamics and\nthe sequence length are both critical to correct classifications even when\nthere is no additional task relevant information provided.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 23:19:21 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 14:23:02 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Horoi", "Stefan", ""], ["Lajoie", "Guillaume", ""], ["Wolf", "Guy", ""]]}, {"id": "2001.03554", "submitter": "Mathilde Caron", "authors": "Mathilde Caron, Ari Morcos, Piotr Bojanowski, Julien Mairal and Armand\n  Joulin", "title": "Pruning Convolutional Neural Networks with Self-Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks trained without supervision come close to\nmatching performance with supervised pre-training, but sometimes at the cost of\nan even higher number of parameters. Extracting subnetworks from these large\nunsupervised convnets with preserved performance is of particular interest to\nmake them less computationally intensive. Typical pruning methods operate\nduring training on a task while trying to maintain the performance of the\npruned network on the same task. However, in self-supervised feature learning,\nthe training objective is agnostic on the representation transferability to\ndownstream tasks. Thus, preserving performance for this objective does not\nensure that the pruned subnetwork remains effective for solving downstream\ntasks. In this work, we investigate the use of standard pruning methods,\ndeveloped primarily for supervised learning, for networks trained without\nlabels (i.e. on self-supervised tasks). We show that pruned masks obtained with\nor without labels reach comparable performance when re-trained on labels,\nsuggesting that pruning operates similarly for self-supervised and supervised\nlearning. Interestingly, we also find that pruning preserves the transfer\nperformance of self-supervised subnetwork representations.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 16:44:41 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Caron", "Mathilde", ""], ["Morcos", "Ari", ""], ["Bojanowski", "Piotr", ""], ["Mairal", "Julien", ""], ["Joulin", "Armand", ""]]}, {"id": "2001.03657", "submitter": "Elizabeth Wanner Dr", "authors": "Claudio Lucio do Val Lopes, Fl\\'avio Vin\\'icius Cruzeiro Martins, and\n  Elizabeth Fialho Wanner", "title": "Dominance Move calculation using a MIP approach for comparison of multi\n  and many-objective optimization solution sets", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dominance move (DoM) is a binary quality indicator that can be used in\nmultiobjective optimization. It can compare solution sets while representing\nsome important features such as convergence, spread, uniformity, and\ncardinality. DoM has an intuitive concept and considers the minimum move of one\nset needed to weakly Pareto dominate the other set. Despite the aforementioned\nproperties, DoM is hard to calculate. The original formulation presents an\nefficient and exact method to calculate it in a biobjective case only. This\nwork presents a new approach to calculate and extend DoM to deal with three or\nmore objectives. The idea is to use a mixed integer programming (MIP) approach\nto calculate DoM. Some initial experiments, in the biobjective space, were done\nto verify the model correctness. Furthermore, other experiments, using three,\nfive, and ten objective functions were done to show how the model behaves in\nhigher dimensional cases. Algorithms such as IBEA, MOEAD, NSGAIII, NSGAII, and\nSPEA2 were used to generate the solution sets, however any other algorithms\ncould be used with DoM indicator. The results have confirmed the effectiveness\nof the MIP DoM in problems with more than three objective functions. Final\nnotes, considerations, and future research are discussed to exploit some\nsolution sets particularities and improve the model and its use for other\nsituations.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 20:28:31 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Lopes", "Claudio Lucio do Val", ""], ["Martins", "Fl\u00e1vio Vin\u00edcius Cruzeiro", ""], ["Wanner", "Elizabeth Fialho", ""]]}, {"id": "2001.04027", "submitter": "Luca Magri", "authors": "Francisco Huhn, Luca Magri", "title": "Learning ergodic averages in chaotic systems", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a physics-informed machine learning method to predict the time\naverage of a chaotic attractor. The method is based on the hybrid echo state\nnetwork (hESN). We assume that the system is ergodic, so the time average is\nequal to the ergodic average. Compared to conventional echo state networks\n(ESN) (purely data-driven), the hESN uses additional information from an\nincomplete, or imperfect, physical model. We evaluate the performance of the\nhESN and compare it to that of an ESN. This approach is demonstrated on a\nchaotic time-delayed thermoacoustic system, where the inclusion of a physical\nmodel significantly improves the accuracy of the prediction, reducing the\nrelative error from 48% to 7%. This improvement is obtained at the low extra\ncost of solving two ordinary differential equations. This framework shows the\npotential of using machine learning techniques combined with prior physical\nknowledge to improve the prediction of time-averaged quantities in chaotic\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 18:12:39 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 11:50:08 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Huhn", "Francisco", ""], ["Magri", "Luca", ""]]}, {"id": "2001.04059", "submitter": "Xuan Liu", "authors": "Xuan Liu, Renato Gasoto, Cagdas Onal, Jie Fu", "title": "Learning to Locomote with Deep Neural-Network and CPG-based Control in a\n  Soft Snake Robot", "comments": "8 pages, 10 figures, 2 tables, submitted to IROS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NE math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a new locomotion control method for soft robot\nsnakes. Inspired by biological snakes, our control architecture is composed of\ntwo key modules: A deep reinforcement learning (RL) module for achieving\nadaptive goal-tracking behaviors with changing goals, and a central pattern\ngenerator (CPG) system with Matsuoka oscillators for generating stable and\ndiverse locomotion patterns. The two modules are interconnected into a\nclosed-loop system: The RL module, analogizing the locomotion region located in\nthe midbrain of vertebrate animals, regulates the input to the CPG system given\nstate feedback from the robot. The output of the CPG system is then translated\ninto pressure inputs to pneumatic actuators of the soft snake robot. Based on\nthe fact that the oscillation frequency and wave amplitude of the Matsuoka\noscillator can be independently controlled under different time scales, we\nfurther adapt the option-critic framework to improve the learning performance\nmeasured by optimality and data efficiency. The performance of the proposed\ncontroller is experimentally validated with both simulated and real soft snake\nrobots.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 04:32:27 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 20:45:19 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Liu", "Xuan", ""], ["Gasoto", "Renato", ""], ["Onal", "Cagdas", ""], ["Fu", "Jie", ""]]}, {"id": "2001.04276", "submitter": "Amir Mosavi Prof", "authors": "Shahab Shamshirband, Meisam Babanezhad, Amir Mosavi, Narjes Nabipour,\n  Eva Hajnal, Laszlo Nadai, Kwok-Wing Chau", "title": "Prediction of flow characteristics in the bubble column reactor by the\n  artificial pheromone-based communication of biological ants", "comments": "24 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to perceive the behavior presented by the multiphase chemical\nreactors, the ant colony optimization algorithm was combined with computational\nfluid dynamics (CFD) data. This intelligent algorithm creates a probabilistic\ntechnique for computing flow and it can predict various levels of\nthree-dimensional bubble column reactor (BCR). This artificial ant algorithm is\nmimicking real ant behavior. This method can anticipate the flow\ncharacteristics in the reactor using almost 30 % of the whole data in the\ndomain. Following discovering the suitable parameters, the method is used for\npredicting the points not being simulated with CFD, which represent mesh\nrefinement of Ant colony method. In addition, it is possible to anticipate the\nbubble-column reactors in the absence of numerical results or training of exact\nvalues of evaluated data. The major benefits include reduced computational\ncosts and time savings. The results show a great agreement between ant colony\nprediction and CFD outputs in different sections of the BCR. The combination of\nant colony system and neural network framework can provide the smart structure\nto estimate biological and nature physics base phenomena. The ant colony\noptimization algorithm (ACO) framework based on ant behavior can solve all\nlocal mathematical answers throughout 3D bubble column reactor. The integration\nof all local answers can provide the overall solution in the reactor for\ndifferent characteristics. This new overview of modelling can illustrate new\nsight into biological behavior in nature.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 19:36:45 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Shamshirband", "Shahab", ""], ["Babanezhad", "Meisam", ""], ["Mosavi", "Amir", ""], ["Nabipour", "Narjes", ""], ["Hajnal", "Eva", ""], ["Nadai", "Laszlo", ""], ["Chau", "Kwok-Wing", ""]]}, {"id": "2001.04413", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu and Yuanzhi Li", "title": "Backward Feature Correction: How Deep Learning Performs Deep Learning", "comments": "V2 adds more experiments, V3 polishes writing and improves\n  experiments, V4 makes minor fixes to the figures, V5 polishes writing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How does a 110-layer ResNet learn a high-complexity classifier using\nrelatively few training examples and short training time? We present a theory\ntowards explaining this in terms of Hierarchical Learning. We refer\nhierarchical learning as the learner learns to represent a complicated target\nfunction by decomposing it into a sequence of simpler functions to reduce\nsample and time complexity. We formally analyze how multi-layer neural networks\ncan perform such hierarchical learning efficiently and automatically by\napplying SGD.\n  On the conceptual side, we present, to the best of our knowledge, the FIRST\ntheory result indicating how deep neural networks can still be sample and time\nefficient using SGD on certain hierarchical learning tasks, when NO KNOWN\nexisting algorithm is efficient. We establish a new principle called \"backward\nfeature correction\", where training higher-level layers in the network can\nimprove the features of lower-level ones. We believe this is the key to\nunderstand the deep learning process in multi-layer neural networks.\n  On the technical side, we show for regression and even binary classification,\nfor every input dimension $d>0$, there is a concept class of degree $\\omega(1)$\npolynomials so that, using $\\omega(1)$-layer neural networks as learners, SGD\ncan learn any function from this class in $\\mathsf{poly}(d)$ time and sample\ncomplexity to any $\\frac{1}{\\mathsf{poly}(d)}$ error, through learning to\nrepresent it as a composition of $\\omega(1)$ layers of quadratic functions. In\ncontrast, we do not know any other simple algorithm (including layer-wise\ntraining or applying kernel method sequentially) that can learn this concept\nclass in $\\mathsf{poly}(d)$ time even to any $d^{-0.01}$ error. As a side\nresult, we prove $d^{\\omega(1)}$ lower bounds for several non-hierarchical\nlearners, including any kernel methods, neural tangent or neural compositional\nkernels.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 17:28:29 GMT"}, {"version": "v2", "created": "Mon, 1 Jun 2020 17:47:15 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2020 03:28:52 GMT"}, {"version": "v4", "created": "Thu, 10 Sep 2020 17:48:37 GMT"}, {"version": "v5", "created": "Sat, 13 Mar 2021 12:05:09 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""]]}, {"id": "2001.04505", "submitter": "W B Langdon", "authors": "William B. Langdon", "title": "Fast Generation of Big Random Binary Trees", "comments": "C++ code:\n  http://www.cs.ucl.ac.uk/staff/W.Langdon/ftp/gp-code/rand_tree.cc_r1.43", "journal-ref": null, "doi": null, "report-no": "RN/20/01 (Revision 1.1)", "categories": "cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  random_tree() is a linear time and space C++ implementation able to create\ntrees of up to a billion nodes for genetic programming and genetic improvement\nexperiments. A 3.60GHz CPU can generate more than 18 million random nodes for\nGP program trees per second.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 19:20:14 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Langdon", "William B.", ""]]}, {"id": "2001.05016", "submitter": "Andreas Madsen", "authors": "Andreas Madsen, Alexander Rosenberg Johansen", "title": "Neural Arithmetic Units", "comments": "International Conference on Learning Representations, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks can approximate complex functions, but they struggle to\nperform exact arithmetic operations over real numbers. The lack of inductive\nbias for arithmetic operations leaves neural networks without the underlying\nlogic necessary to extrapolate on tasks such as addition, subtraction, and\nmultiplication. We present two new neural network components: the Neural\nAddition Unit (NAU), which can learn exact addition and subtraction; and the\nNeural Multiplication Unit (NMU) that can multiply subsets of a vector. The NMU\nis, to our knowledge, the first arithmetic neural network component that can\nlearn to multiply elements from a vector, when the hidden size is large. The\ntwo new components draw inspiration from a theoretical analysis of recently\nproposed arithmetic components. We find that careful initialization,\nrestricting parameter space, and regularizing for sparsity is important when\noptimizing the NAU and NMU. Our proposed units NAU and NMU, compared with\nprevious neural units, converge more consistently, have fewer parameters, learn\nfaster, can converge for larger hidden sizes, obtain sparse and meaningful\nweights, and can extrapolate to negative and small values.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 19:35:04 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Madsen", "Andreas", ""], ["Johansen", "Alexander Rosenberg", ""]]}, {"id": "2001.05065", "submitter": "Jacob Schrum", "authors": "Jake Gutierrez and Jacob Schrum", "title": "Generative Adversarial Network Rooms in Generative Graph Grammar\n  Dungeons for The Legend of Zelda", "comments": "Congress on Evolutionary Computation 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have demonstrated their ability to\nlearn patterns in data and produce new exemplars similar to, but different\nfrom, their training set in several domains, including video games. However,\nGANs have a fixed output size, so creating levels of arbitrary size for a\ndungeon crawling game is difficult. GANs also have trouble encoding semantic\nrequirements that make levels interesting and playable. This paper combines a\nGAN approach to generating individual rooms with a graph grammar approach to\ncombining rooms into a dungeon. The GAN captures design principles of\nindividual rooms, but the graph grammar organizes rooms into a global layout\nwith a sequence of obstacles determined by a designer. Room data from The\nLegend of Zelda is used to train the GAN. This approach is validated by a user\nstudy, showing that GAN dungeons are as enjoyable to play as a level from the\noriginal game, and levels generated with a graph grammar alone. However, GAN\ndungeons have rooms considered more complex, and plain graph grammar's dungeons\nare considered least complex and challenging. Only the GAN approach creates an\nextensive supply of both layouts and rooms, where rooms span across the\nspectrum of those seen in the training set to new creations merging design\nprinciples from multiple rooms.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 22:22:11 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2020 19:07:28 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Gutierrez", "Jake", ""], ["Schrum", "Jacob", ""]]}, {"id": "2001.05120", "submitter": "Andrew M. Sutton", "authors": "Frank Neumann and Andrew M. Sutton", "title": "Parameterized Complexity Analysis of Randomized Search Heuristics", "comments": "This is a preliminary version of a chapter in the book \"Theory of\n  Evolutionary Computation: Recent Developments in Discrete Optimization\",\n  edited by Benjamin Doerr and Frank Neumann, published by Springer", "journal-ref": null, "doi": "10.1007/978-3-030-29414-4_4", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter compiles a number of results that apply the theory of\nparameterized algorithmics to the running-time analysis of randomized search\nheuristics such as evolutionary algorithms. The parameterized approach\narticulates the running time of algorithms solving combinatorial problems in\nfiner detail than traditional approaches from classical complexity theory. We\noutline the main results and proof techniques for a collection of randomized\nsearch heuristics tasked to solve NP-hard combinatorial optimization problems\nsuch as finding a minimum vertex cover in a graph, finding a maximum leaf\nspanning tree in a graph, and the traveling salesperson problem.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 03:43:56 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Neumann", "Frank", ""], ["Sutton", "Andrew M.", ""]]}, {"id": "2001.05140", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang, Haopeng Zhang, Congying Xia, Li Sun", "title": "Graph-Bert: Only Attention is Needed for Learning Graph Representations", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant graph neural networks (GNNs) over-rely on the graph links,\nseveral serious performance problems with which have been witnessed already,\ne.g., suspended animation problem and over-smoothing problem. What's more, the\ninherently inter-connected nature precludes parallelization within the graph,\nwhich becomes critical for large-sized graph, as memory constraints limit\nbatching across the nodes. In this paper, we will introduce a new graph neural\nnetwork, namely GRAPH-BERT (Graph based BERT), solely based on the attention\nmechanism without any graph convolution or aggregation operators. Instead of\nfeeding GRAPH-BERT with the complete large input graph, we propose to train\nGRAPH-BERT with sampled linkless subgraphs within their local contexts.\nGRAPH-BERT can be learned effectively in a standalone mode. Meanwhile, a\npre-trained GRAPH-BERT can also be transferred to other application tasks\ndirectly or with necessary fine-tuning if any supervised label information or\ncertain application oriented objective is available. We have tested the\neffectiveness of GRAPH-BERT on several graph benchmark datasets. Based the\npre-trained GRAPH-BERT with the node attribute reconstruction and structure\nrecovery tasks, we further fine-tune GRAPH-BERT on node classification and\ngraph clustering tasks specifically. The experimental results have demonstrated\nthat GRAPH-BERT can out-perform the existing GNNs in both the learning\neffectiveness and efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 05:56:59 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 15:16:10 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Zhang", "Jiawei", ""], ["Zhang", "Haopeng", ""], ["Xia", "Congying", ""], ["Sun", "Li", ""]]}, {"id": "2001.05205", "submitter": "Gilad Yehudai", "authors": "Gilad Yehudai and Ohad Shamir", "title": "Learning a Single Neuron with Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fundamental problem of learning a single neuron $x\n\\mapsto\\sigma(w^\\top x)$ using standard gradient methods. As opposed to\nprevious works, which considered specific (and not always realistic) input\ndistributions and activation functions $\\sigma(\\cdot)$, we ask whether a more\ngeneral result is attainable, under milder assumptions. On the one hand, we\nshow that some assumptions on the distribution and the activation function are\nnecessary. On the other hand, we prove positive guarantees under mild\nassumptions, which go beyond those studied in the literature so far. We also\npoint out and study the challenges in further strengthening and generalizing\nour results.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 10:02:45 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 10:46:34 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Yehudai", "Gilad", ""], ["Shamir", "Ohad", ""]]}, {"id": "2001.05227", "submitter": "Stephen Nuagah Jeswinde", "authors": "James D. Gadze, Kwame A. Agyekum, Stephen J. Nuagah and E.A. Affum", "title": "Improved propagation models for lte path loss prediction in urban &\n  suburban Ghana", "comments": "19 Pages, 15 figures", "journal-ref": "International Journal of Wireless & Mobile Networks (IJWMN) Vol.\n  11, No. 6, December 2019", "doi": "10.5121/ijwmn.2019.11603", "report-no": null, "categories": "eess.SP cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To maximize the benefits of LTE cellular networks, careful and proper\nplanning is needed. This requires the use of accurate propagation models to\nquantify the path loss required for base station deployment. Deployed LTE\nnetworks in Ghana can barely meet the desired 100Mbps throughput leading to\ncustomer dissatisfaction. Network operators rely on transmission planning tools\ndesigned for generalized environments that come with already embedded\npropagation models suited to other environments. A challenge therefore to\nGhanaian transmission Network planners will be choosing an accurate and precise\npropagation model that best suits the Ghanaian environment. Given this,\nextensive LTE path loss measurements at 800MHz and 2600MHz were taken in\nselected urban and suburban environments in Ghana and compared with 6 commonly\nused propagation models. Improved versions of the Ericson, SUI, and ECC-33\ndeveloped in this study predict more precisely the path loss in Ghanaian\nenvironments compared with commonly used propagation models.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 10:56:00 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Gadze", "James D.", ""], ["Agyekum", "Kwame A.", ""], ["Nuagah", "Stephen J.", ""], ["Affum", "E. A.", ""]]}, {"id": "2001.05320", "submitter": "Dhruv Khandelwal", "authors": "Dhruv Khandelwal, Maarten Schoukens and Roland T\\'oth", "title": "A Tree Adjoining Grammar Representation for Models Of Stochastic\n  Dynamical Systems", "comments": "Accepted as brief paper by Automatica", "journal-ref": null, "doi": "10.1016/J.AUTOMATICA.2020.109099", "report-no": null, "categories": "eess.SY cs.CL cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model structure and complexity selection remains a challenging problem in\nsystem identification, especially for parametric non-linear models. Many\nEvolutionary Algorithm (EA) based methods have been proposed in the literature\nfor estimating model structure and complexity. In most cases, the proposed\nmethods are devised for estimating structure and complexity within a specified\nmodel class and hence these methods do not extend to other model structures\nwithout significant changes. In this paper, we propose a Tree Adjoining Grammar\n(TAG) for stochastic parametric models. TAGs can be used to generate models in\nan EA framework while imposing desirable structural constraints and\nincorporating prior knowledge. In this paper, we propose a TAG that can\nsystematically generate models ranging from FIRs to polynomial NARMAX models.\nFurthermore, we demonstrate that TAGs can be easily extended to more general\nmodel classes, such as the non-linear Box-Jenkins model class, enabling the\nrealization of flexible and automatic model structure and complexity selection\nvia EA.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 13:35:19 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 13:24:49 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Khandelwal", "Dhruv", ""], ["Schoukens", "Maarten", ""], ["T\u00f3th", "Roland", ""]]}, {"id": "2001.05348", "submitter": "Yusuke Sakemi Ph.D.", "authors": "Yusuke Sakemi, Kai Morino, Takashi Morie, Kazuyuki Aihara", "title": "A Supervised Learning Algorithm for Multilayer Spiking Neural Networks\n  Based on Temporal Coding Toward Energy-Efficient VLSI Processor Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) are brain-inspired mathematical models with\nthe ability to process information in the form of spikes. SNNs are expected to\nprovide not only new machine-learning algorithms, but also energy-efficient\ncomputational models when implemented in VLSI circuits. In this paper, we\npropose a novel supervised learning algorithm for SNNs based on temporal\ncoding. A spiking neuron in this algorithm is designed to facilitate analog\nVLSI implementations with analog resistive memory, by which ultra-high energy\nefficiency can be achieved. We also propose several techniques to improve the\nperformance on a recognition task, and show that the classification accuracy of\nthe proposed algorithm is as high as that of the state-of-the-art temporal\ncoding SNN algorithms on the MNIST dataset. Finally, we discuss the robustness\nof the proposed SNNs against variations that arise from the device\nmanufacturing process and are unavoidable in analog VLSI implementation. We\nalso propose a technique to suppress the effects of variations in the\nmanufacturing process on the recognition performance.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 03:37:08 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Sakemi", "Yusuke", ""], ["Morino", "Kai", ""], ["Morie", "Takashi", ""], ["Aihara", "Kazuyuki", ""]]}, {"id": "2001.05381", "submitter": "Erdem Kose", "authors": "Erdem Kose", "title": "Analysis of Genetic Algorithm on Bearings-Only Target Motion Analysis", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Target motion analysis using only bearing angles is an important study for\ntracking targets in water. Several methods including Kalman-like filters and\nevolutionary strategies are used to get a good predictor. Kalman-like filters\ncouldn't get the expected results thus evolutionary strategies have been using\nin this area for a long time. Target Motion Analysis with Genetic Algorithm is\nthe most successful method for Bearings-Only Target Motion Analysis and we\ninvestigated it. We found that Covariance Matrix Adaptation Evolutionary\nStrategies does the similar work with Target Motion Analysis with Genetic\nAlgorithm and tried it; but it has statistical feedback mechanism and converges\nfaster than other methods. In this study, we compared and criticize the\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 15:40:01 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Kose", "Erdem", ""]]}, {"id": "2001.05670", "submitter": "Tatsuki Serizawa", "authors": "T. Serizawa, H. Fujita", "title": "Optimization of Convolutional Neural Network Using the Linearly\n  Decreasing Weight Particle Swarm Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network (CNN) is one of the most frequently used deep\nlearning techniques. Various forms of models have been proposed and improved\nfor learning at CNN. When learning with CNN, it is necessary to determine the\noptimal hyperparameters. However, the number of hyperparameters is so large\nthat it is difficult to do it manually, so much research has been done on\nautomation. A method that uses metaheuristic algorithms is attracting attention\nin research on hyperparameter optimization. Metaheuristic algorithms are\nnaturally inspired and include evolution strategies, genetic algorithms,\nantcolony optimization and particle swarm optimization. In particular, particle\nswarm optimization converges faster than genetic algorithms, and various models\nhave been proposed. In this paper, we propose CNN hyperparameter optimization\nwith linearly decreasing weight particle swarm optimization (LDWPSO). In the\nexperiment, the MNIST data set and CIFAR-10 data set, which are often used as\nbenchmark data sets, are used. By optimizing CNN hyperparameters with LDWPSO,\nlearning the MNIST and CIFAR-10 datasets, we compare the accuracy with a\nstandard CNN based on LeNet-5. As a result, when using the MNIST dataset, the\nbaseline CNN is 94.02% at the 5th epoch, compared to 98.95% for LDWPSO CNN,\nwhich improves accuracy. When using the CIFAR-10 dataset, the Baseline CNN is\n28.07% at the 10th epoch, compared to 69.37% for the LDWPSO CNN, which greatly\nimproves accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 06:27:50 GMT"}, {"version": "v2", "created": "Thu, 17 Sep 2020 11:49:42 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Serizawa", "T.", ""], ["Fujita", "H.", ""]]}, {"id": "2001.05844", "submitter": "Satoshi Ono", "authors": "Takahiro Suzuki, Shingo Takeshita, Satoshi Ono", "title": "Adversarial Example Generation using Evolutionary Multi-objective\n  Optimization", "comments": null, "journal-ref": "2019 IEEE Congress on Evolutionary Computation (CEC), Wellington,\n  New Zealand, 2019, pp. 2136-2144", "doi": "10.1109/CEC.2019.8790123", "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Evolutionary Multi-objective Optimization (EMO)-based\nAdversarial Example (AE) design method that performs under black-box setting.\nPrevious gradient-based methods produce AEs by changing all pixels of a target\nimage, while previous EC-based method changes small number of pixels to produce\nAEs. Thanks to EMO's property of population based-search, the proposed method\nproduces various types of AEs involving ones locating between AEs generated by\nthe previous two approaches, which helps to know the characteristics of a\ntarget model or to know unknown attack patterns. Experimental results showed\nthe potential of the proposed method, e.g., it can generate robust AEs and,\nwith the aid of DCT-based perturbation pattern generation, AEs for high\nresolution images.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 07:34:09 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Suzuki", "Takahiro", ""], ["Takeshita", "Shingo", ""], ["Ono", "Satoshi", ""]]}, {"id": "2001.05853", "submitter": "Mark Rowan", "authors": "Nataliya Le Vine, Claus Horn, Matthew Zeigenfuse, Mark Rowan", "title": "Identifying Table Structure in Documents using Conditional Generative\n  Adversarial Networks", "comments": "arXiv admin note: substantial text overlap with arXiv:1904.01947", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many industries, as well as in academic research, information is primarily\ntransmitted in the form of unstructured documents (this article, for example).\nHierarchically-related data is rendered as tables, and extracting information\nfrom tables in such documents presents a significant challenge. Many existing\nmethods take a bottom-up approach, first integrating lines into cells, then\ncells into rows or columns, and finally inferring a structure from the\nresulting 2-D layout. But such approaches neglect the available prior\ninformation relating to table structure, namely that the table is merely an\narbitrary representation of a latent logical structure. We propose a top-down\napproach, first using a conditional generative adversarial network to map a\ntable image into a standardised `skeleton' table form denoting approximate row\nand column borders without table content, then deriving latent table structure\nusing xy-cut projection and Genetic Algorithm optimisation. The approach is\neasily adaptable to different table configurations and requires small data set\nsizes for training.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 20:42:40 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Vine", "Nataliya Le", ""], ["Horn", "Claus", ""], ["Zeigenfuse", "Matthew", ""], ["Rowan", "Mark", ""]]}, {"id": "2001.05992", "submitter": "Wei Hu", "authors": "Wei Hu, Lechao Xiao, Jeffrey Pennington", "title": "Provable Benefit of Orthogonal Initialization in Optimizing Deep Linear\n  Networks", "comments": "International Conference on Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The selection of initial parameter values for gradient-based optimization of\ndeep neural networks is one of the most impactful hyperparameter choices in\ndeep learning systems, affecting both convergence times and model performance.\nYet despite significant empirical and theoretical analysis, relatively little\nhas been proved about the concrete effects of different initialization schemes.\nIn this work, we analyze the effect of initialization in deep linear networks,\nand provide for the first time a rigorous proof that drawing the initial\nweights from the orthogonal group speeds up convergence relative to the\nstandard Gaussian initialization with iid weights. We show that for deep\nnetworks, the width needed for efficient convergence to a global minimum with\northogonal initializations is independent of the depth, whereas the width\nneeded for efficient convergence with Gaussian initializations scales linearly\nin the depth. Our results demonstrate how the benefits of a good initialization\ncan persist throughout learning, suggesting an explanation for the recent\nempirical successes found by initializing very deep non-linear networks\naccording to the principle of dynamical isometry.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 18:48:34 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Hu", "Wei", ""], ["Xiao", "Lechao", ""], ["Pennington", "Jeffrey", ""]]}, {"id": "2001.06517", "submitter": "Iztok Fister", "authors": "Iztok Fister Jr., Suash Deb, Iztok Fister", "title": "Population-based metaheuristics for Association Rule Text Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the majority of data on the Internet is held in an unstructured\nformat, like websites and e-mails. The importance of analyzing these data has\nbeen growing day by day. Similar to data mining on structured data, text mining\nmethods for handling unstructured data have also received increasing attention\nfrom the research community. The paper deals with the problem of Association\nRule Text Mining. To solve the problem, the PSO-ARTM method was proposed, that\nconsists of three steps: Text preprocessing, Association Rule Text Mining using\npopulation-based metaheuristics, and text postprocessing. The method was\napplied to a transaction database obtained from professional triathlon\nathletes' blogs and news posted on their websites. The obtained results reveal\nthat the proposed method is suitable for Association Rule Text Mining and,\ntherefore, offers a promising way for further development.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 20:21:03 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Fister", "Iztok", "Jr."], ["Deb", "Suash", ""], ["Fister", "Iztok", ""]]}, {"id": "2001.06585", "submitter": "Zhengping Liang", "authors": "Zhengping Liang, Jian Zhang, Liang Feng, Zexuan Zhu", "title": "Multi-factorial Optimization for Large-scale Virtual Machine Placement\n  in Cloud Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The placement scheme of virtual machines (VMs) to physical servers (PSs) is\ncrucial to lowering operational cost for cloud providers. Evolutionary\nalgorithms (EAs) have been performed promising-solving on virtual machine\nplacement (VMP) problems in the past. However, as growing demand for cloud\nservices, the existing EAs fail to implement in large-scale virtual machine\nplacement (LVMP) problem due to the high time complexity and poor scalability.\nRecently, the multi-factorial optimization (MFO) technology has surfaced as a\nnew search paradigm in evolutionary computing. It offers the ability to evolve\nmultiple optimization tasks simultaneously during the evolutionary process.\nThis paper aims to apply the MFO technology to the LVMP problem in\nheterogeneous environment. Firstly, we formulate a deployment cost based VMP\nproblem in the form of the MFO problem. Then, a multi-factorial evolutionary\nalgorithm (MFEA) embedded with greedy-based allocation operator is developed to\naddress the established MFO problem. After that, a re-migration and merge\noperator is designed to offer the integrated solution of the LVMP problem from\nthe solutions of MFO problem. To assess the effectiveness of our proposed\nmethod, the simulation experiments are carried on large-scale and extra\nlarge-scale VMs test data sets. The results show that compared with various\nheuristic methods, our method could shorten optimization time significantly and\noffer a competitive placement solution for the LVMP problem in heterogeneous\nenvironment.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 02:59:18 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 07:03:53 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Liang", "Zhengping", ""], ["Zhang", "Jian", ""], ["Feng", "Liang", ""], ["Zhu", "Zexuan", ""]]}, {"id": "2001.06938", "submitter": "Roman Vershynin", "authors": "Roman Vershynin", "title": "Memory capacity of neural networks with threshold and ReLU activations", "comments": "26 pages. Minor inaccuracies corrected, discussion of prior work\n  expanded", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NE math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overwhelming theoretical and empirical evidence shows that mildly\noverparametrized neural networks -- those with more connections than the size\nof the training data -- are often able to memorize the training data with\n$100\\%$ accuracy. This was rigorously proved for networks with sigmoid\nactivation functions and, very recently, for ReLU activations. Addressing a\n1988 open question of Baum, we prove that this phenomenon holds for general\nmultilayered perceptrons, i.e. neural networks with threshold activation\nfunctions, or with any mix of threshold and ReLU activations. Our construction\nis probabilistic and exploits sparsity.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 01:54:21 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 18:38:18 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Vershynin", "Roman", ""]]}, {"id": "2001.06980", "submitter": "Yuri Lavinas Mr", "authors": "Yuri Lavinas, Claus Aranha, Marcelo Ladeira and Felipe Campelo", "title": "MOEA/D with Random Partial Update Strategy", "comments": null, "journal-ref": null, "doi": "10.1109/CEC48606.2020.9185527", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent studies on resource allocation suggest that some subproblems are more\nimportant than others in the context of the MOEA/D, and that focusing on the\nmost relevant ones can consistently improve the performance of that algorithm.\nThese studies share the common characteristic of updating only a fraction of\nthe population at any given iteration of the algorithm. In this work we\ninvestigate a new, simpler partial update strategy, in which a random subset of\nsolutions is selected at every iteration. The performance of the MOEA/D using\nthis new resource allocation approach is compared experimentally against that\nof the standard MOEA/D-DE and the MOEA/D with relative improvement-based\nresource allocation. The results indicate that using the MOEA/D with this new\npartial update strategy results in improved HV and IGD values, and a much\nhigher proportion of non-dominated solutions, particularly as the number of\nupdated solutions at every iteration is reduced.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 05:13:52 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Lavinas", "Yuri", ""], ["Aranha", "Claus", ""], ["Ladeira", "Marcelo", ""], ["Campelo", "Felipe", ""]]}, {"id": "2001.07002", "submitter": "Faizal Hafiz", "authors": "Renoh Johnson Chalakkal, Faizal Hafiz, Waleed Abdulla, and Akshya\n  Swain", "title": "An Efficient Framework for Automated Screening of Clinically Significant\n  Macular Edema", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study proposes a new approach to automated screening of\nClinically Significant Macular Edema (CSME) and addresses two major challenges\nassociated with such screenings, i.e., exudate segmentation and imbalanced\ndatasets. The proposed approach replaces the conventional exudate segmentation\nbased feature extraction by combining a pre-trained deep neural network with\nmeta-heuristic feature selection. A feature space over-sampling technique is\nbeing used to overcome the effects of skewed datasets and the screening is\naccomplished by a k-NN based classifier. The role of each data-processing step\n(e.g., class balancing, feature selection) and the effects of limiting the\nregion-of-interest to fovea on the classification performance are critically\nanalyzed. Finally, the selection and implication of operating point on Receiver\nOperating Characteristic curve are discussed. The results of this study\nconvincingly demonstrate that by following these fundamental practices of\nmachine learning, a basic k-NN based classifier could effectively accomplish\nthe CSME screening.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 07:34:13 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Chalakkal", "Renoh Johnson", ""], ["Hafiz", "Faizal", ""], ["Abdulla", "Waleed", ""], ["Swain", "Akshya", ""]]}, {"id": "2001.07092", "submitter": "Grace Lindsay", "authors": "Grace W. Lindsay", "title": "Convolutional Neural Networks as a Model of the Visual System: Past,\n  Present, and Future", "comments": "Review Article to be published in Journal of Cognitive Neuroscience,\n  18 pages, 5 figures plus 8 pages of references", "journal-ref": null, "doi": "10.1162/jocn_a_01544", "report-no": null, "categories": "q-bio.NC cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Convolutional neural networks (CNNs) were inspired by early findings in the\nstudy of biological vision. They have since become successful tools in computer\nvision and state-of-the-art models of both neural activity and behavior on\nvisual tasks. This review highlights what, in the context of CNNs, it means to\nbe a good model in computational neuroscience and the various ways models can\nprovide insight. Specifically, it covers the origins of CNNs and the methods by\nwhich we validate them as models of biological vision. It then goes on to\nelaborate on what we can learn about biological vision by understanding and\nexperimenting on CNNs and discusses emerging opportunities for the use of CNNS\nin vision research beyond basic object recognition.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 13:04:37 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 11:37:16 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Lindsay", "Grace W.", ""]]}, {"id": "2001.07305", "submitter": "Haibin Chang", "authors": "Hao Xu, Haibin Chang, Dongxiao Zhang", "title": "DLGA-PDE: Discovery of PDEs with incomplete candidate library via\n  combination of deep learning and genetic algorithm", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.109584", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven methods have recently been developed to discover underlying\npartial differential equations (PDEs) of physical problems. However, for these\nmethods, a complete candidate library of potential terms in a PDE are usually\nrequired. To overcome this limitation, we propose a novel framework combining\ndeep learning and genetic algorithm, called DLGA-PDE, for discovering PDEs. In\nthe proposed framework, a deep neural network that is trained with available\ndata of a physical problem is utilized to generate meta-data and calculate\nderivatives, and the genetic algorithm is then employed to discover the\nunderlying PDE. Owing to the merits of the genetic algorithm, such as mutation\nand crossover, DLGA-PDE can work with an incomplete candidate library. The\nproposed DLGA-PDE is tested for discovery of the Korteweg-de Vries (KdV)\nequation, the Burgers equation, the wave equation, and the Chaffee-Infante\nequation, respectively, for proof-of-concept. Satisfactory results are obtained\nwithout the need for a complete candidate library, even in the presence of\nnoisy and limited data.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 01:28:58 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Xu", "Hao", ""], ["Chang", "Haibin", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "2001.07553", "submitter": "Nuno M. Rodrigues", "authors": "Nuno M. Rodrigues, Jo\\~ao E. Batista, Sara Silva", "title": "Ensemble Genetic Programming", "comments": "eurogp 2020 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble learning is a powerful paradigm that has been usedin the top\nstate-of-the-art machine learning methods like Random Forestsand XGBoost.\nInspired by the success of such methods, we have devel-oped a new Genetic\nProgramming method called Ensemble GP. The evo-lutionary cycle of Ensemble GP\nfollows the same steps as other GeneticProgramming systems, but with\ndifferences in the population structure,fitness evaluation and genetic\noperators. We have tested this method oneight binary classification problems,\nachieving results significantly betterthan standard GP, with much smaller\nmodels. Although other methodslike M3GP and XGBoost were the best overall,\nEnsemble GP was able toachieve exceptionally good generalization results on a\nparticularly hardproblem where none of the other methods was able to succeed.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 14:10:37 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Rodrigues", "Nuno M.", ""], ["Batista", "Jo\u00e3o E.", ""], ["Silva", "Sara", ""]]}, {"id": "2001.07620", "submitter": "Fernando Gama", "authors": "Elvin Isufi, Fernando Gama, Alejandro Ribeiro", "title": "EdgeNets:Edge Varying Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the outstanding performance of neural networks in the structured\nEuclidean domain, recent years have seen a surge of interest in developing\nneural networks for graphs and data supported on graphs. The graph is leveraged\nat each layer of the neural network as a parameterization to capture detail at\nthe node level with a reduced number of parameters and computational\ncomplexity. Following this rationale, this paper puts forth a general framework\nthat unifies state-of-the-art graph neural networks (GNNs) through the concept\nof EdgeNet. An EdgeNet is a GNN architecture that allows different nodes to use\ndifferent parameters to weigh the information of different neighbors. By\nextrapolating this strategy to more iterations between neighboring nodes, the\nEdgeNet learns edge- and neighbor-dependent weights to capture local detail.\nThis is a general linear and local operation that a node can perform and\nencompasses under one formulation all existing graph convolutional neural\nnetworks (GCNNs) as well as graph attention networks (GATs). In writing\ndifferent GNN architectures with a common language, EdgeNets highlight specific\narchitecture advantages and limitations, while providing guidelines to improve\ntheir capacity without compromising their local implementation. An interesting\nconclusion is the unification of GCNNs and GATs -- approaches that have been so\nfar perceived as separate. In particular, we show that GATs are GCNNs on a\ngraph that is learned from the features. This particularization opens the doors\nto develop alternative attention mechanisms for improving discriminatory power.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 15:51:17 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 13:28:10 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 14:02:26 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Isufi", "Elvin", ""], ["Gama", "Fernando", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "2001.07710", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Wei Niu, Tianyun Zhang, Sijia Liu, Sheng Lin, Hongjia Li,\n  Xiang Chen, Jian Tang, Kaisheng Ma, Bin Ren, Yanzhi Wang", "title": "An Image Enhancing Pattern-based Sparsity for Real-time Inference on\n  Mobile Devices", "comments": "Paper accepted in the 16th European Conference on Computer Vision\n  (ECCV 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight pruning has been widely acknowledged as a straightforward and\neffective method to eliminate redundancy in Deep Neural Networks (DNN), thereby\nachieving acceleration on various platforms. However, most of the pruning\ntechniques are essentially trade-offs between model accuracy and regularity\nwhich lead to impaired inference accuracy and limited on-device acceleration\nperformance. To solve the problem, we introduce a new sparsity dimension,\nnamely pattern-based sparsity that comprises pattern and connectivity sparsity,\nand becoming both highly accurate and hardware friendly. With carefully\ndesigned patterns, the proposed pruning unprecedentedly and consistently\nachieves accuracy enhancement and better feature extraction ability on\ndifferent DNN structures and datasets, and our pattern-aware pruning framework\nalso achieves pattern library extraction, pattern selection, pattern and\nconnectivity pruning and weight training simultaneously. Our approach on the\nnew pattern-based sparsity naturally fits into compiler optimization for highly\nefficient DNN execution on mobile platforms. To the best of our knowledge, it\nis the first time that mobile devices achieve real-time inference for the\nlarge-scale DNN models thanks to the unique spatial property of pattern-based\nsparsity and the help of the code generation capability of compilers.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 16:17:36 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 02:55:08 GMT"}, {"version": "v3", "created": "Sun, 5 Jul 2020 01:22:19 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Ma", "Xiaolong", ""], ["Niu", "Wei", ""], ["Zhang", "Tianyun", ""], ["Liu", "Sijia", ""], ["Lin", "Sheng", ""], ["Li", "Hongjia", ""], ["Chen", "Xiang", ""], ["Tang", "Jian", ""], ["Ma", "Kaisheng", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2001.07804", "submitter": "Gongjin Lan", "authors": "Gongjin Lan, Matteo De Carlo, Fuda van Diggelen, Jakub M. Tomczak,\n  Diederik M. Roijers, and A.E. Eiben", "title": "Learning Directed Locomotion in Modular Robots with Evolvable\n  Morphologies", "comments": "30 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the well-studied problem of gait learning in modular robots in\ntwo dimensions. Firstly, we address locomotion in a given target direction that\ngoes beyond learning a typical undirected gait. Secondly, rather than studying\none fixed robot morphology we consider a test suite of different modular\nrobots. This study is based on our interest in evolutionary robot systems where\nboth morphologies and controllers evolve. In such a system, newborn robots have\nto learn to control their own body that is a random combination of the bodies\nof the parents. We apply and compare two learning algorithms, Bayesian\noptimization and HyperNEAT. The results of the experiments in simulation show\nthat both methods successfully learn good controllers, but Bayesian\noptimization is more effective and efficient. We validate the best learned\ncontrollers by constructing three robots from the test suite in the real world\nand observe their fitness and actual trajectories. The obtained results\nindicate a reality gap that depends on the controllers and the shape of the\nrobots, but overall the trajectories are adequate and follow the target\ndirections successfully.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 23:01:00 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Lan", "Gongjin", ""], ["De Carlo", "Matteo", ""], ["van Diggelen", "Fuda", ""], ["Tomczak", "Jakub M.", ""], ["Roijers", "Diederik M.", ""], ["Eiben", "A. E.", ""]]}, {"id": "2001.07922", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Get Rid of Suspended Animation Problem: Deep Diffusive Neural Network on\n  Graph Semi-Supervised Classification", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing graph neural networks may suffer from the \"suspended animation\nproblem\" when the model architecture goes deep. Meanwhile, for some graph\nlearning scenarios, e.g., nodes with text/image attributes or graphs with\nlong-distance node correlations, deep graph neural networks will be necessary\nfor effective graph representation learning. In this paper, we propose a new\ngraph neural network, namely DIFNET (Graph Diffusive Neural Network), for graph\nrepresentation learning and node classification. DIFNET utilizes both neural\ngates and graph residual learning for node hidden state modeling, and includes\nan attention mechanism for node neighborhood information diffusion. Extensive\nexperiments will be done in this paper to compare DIFNET against several\nstate-of-the-art graph neural network models. The experimental results can\nillustrate both the learning performance advantages and effectiveness of\nDIFNET, especially in addressing the \"suspended animation problem\".\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 09:19:12 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "2001.08063", "submitter": "Frank Schindler", "authors": "Frank Schindler, Adam S. Jermyn", "title": "Algorithms for Tensor Network Contraction Ordering", "comments": "10 pages, 10 figures", "journal-ref": "Mach. Learn.: Sci. Technol. 1 035001 (2020)", "doi": "10.1088/2632-2153/ab94c5", "report-no": null, "categories": "cs.NE cs.NA math.NA physics.comp-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contracting tensor networks is often computationally demanding. Well-designed\ncontraction sequences can dramatically reduce the contraction cost. We explore\nthe performance of simulated annealing and genetic algorithms, two common\ndiscrete optimization techniques, to this ordering problem. We benchmark their\nperformance as well as that of the commonly-used greedy search on physically\nrelevant tensor networks. Where computationally feasible, we also compare them\nwith the optimal contraction sequence obtained by an exhaustive search. We find\nthat the algorithms we consider consistently outperform a greedy search given\nequal computational resources, with an advantage that scales with tensor\nnetwork size. We compare the obtained contraction sequences and identify signs\nof highly non-local optimization, with the more sophisticated algorithms\nsacrificing run-time early in the contraction for better overall performance.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 19:00:07 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Schindler", "Frank", ""], ["Jermyn", "Adam S.", ""]]}, {"id": "2001.08102", "submitter": "Ivars Dzabls Mr", "authors": "Ivars Dzalbs, Tatiana Kalganova", "title": "Accelerating supply chains with Ant Colony Optimization across range of\n  hardware solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ant Colony algorithm has been applied to various optimization problems,\nhowever most of the previous work on scaling and parallelism focuses on\nTravelling Salesman Problems (TSPs). Although, useful for benchmarks and new\nidea comparison, the algorithmic dynamics does not always transfer to complex\nreal-life problems, where additional meta-data is required during solution\nconstruction. This paper looks at real-life outbound supply chain problem using\nAnt Colony Optimization (ACO) and its scaling dynamics with two parallel ACO\narchitectures - Independent Ant Colonies (IAC) and Parallel Ants (PA). Results\nshowed that PA was able to reach a higher solution quality in fewer iterations\nas the number of parallel instances increased. Furthermore, speed performance\nwas measured across three different hardware solutions - 16 core CPU, 68 core\nXeon Phi and up to 4 Geforce GPUs. State of the art, ACO vectorization\ntechniques such as SS-Roulette were implemented using C++ and CUDA. Although\nexcellent for TSP, it was concluded that for the given supply chain problem\nGPUs are not suitable due to meta-data access footprint required. Furthermore,\ncompared to their sequential counterpart, vectorized CPU AVX2 implementation\nachieved 25.4x speedup on CPU while Xeon Phi with its AVX512 instruction set\nreached 148x on PA with Vectorized (PAwV). PAwV is therefore able to scale at\nleast up to 1024 parallel instances on the supply chain network problem solved.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 16:09:06 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Dzalbs", "Ivars", ""], ["Kalganova", "Tatiana", ""]]}, {"id": "2001.08189", "submitter": "Rafael Fricks", "authors": "Rafael B. Fricks, Justin Solomon, Ehsan Samei", "title": "Automatic phantom test pattern classification through transfer learning\n  with deep neural networks", "comments": null, "journal-ref": null, "doi": "10.1117/12.2549366", "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV physics.med-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Imaging phantoms are test patterns used to measure image quality in computer\ntomography (CT) systems. A new phantom platform (Mercury Phantom, Gammex)\nprovides test patterns for estimating the task transfer function (TTF) or noise\npower spectrum (NPF) and simulates different patient sizes. Determining which\nimage slices are suitable for analysis currently requires manual annotation of\nthese patterns by an expert, as subtle defects may make an image unsuitable for\nmeasurement. We propose a method of automatically classifying these test\npatterns in a series of phantom images using deep learning techniques. By\nadapting a convolutional neural network based on the VGG19 architecture with\nweights trained on ImageNet, we use transfer learning to produce a classifier\nfor this domain. The classifier is trained and evaluated with over 3,500\nphantom images acquired at a university medical center. Input channels for\ncolor images are successfully adapted to convey contextual information for\nphantom images. A series of ablation studies are employed to verify design\naspects of the classifier and evaluate its performance under varying training\nconditions. Our solution makes extensive use of image augmentation to produce a\nclassifier that accurately classifies typical phantom images with 98% accuracy,\nwhile maintaining as much as 86% accuracy when the phantom is improperly\nimaged.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 18:17:41 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Fricks", "Rafael B.", ""], ["Solomon", "Justin", ""], ["Samei", "Ehsan", ""]]}, {"id": "2001.08269", "submitter": "Karol Antczak", "authors": "Karol Antczak", "title": "Representation Learning for Medical Data", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a representation learning framework for medical diagnosis domain.\nIt is based on heterogeneous network-based model of diagnostic data as well as\nmodified metapath2vec algorithm for learning latent node representation. We\ncompare the proposed algorithm with other representation learning methods in\ntwo practical case studies: symptom/disease classification and disease\nprediction. We observe a significant performance boost in these task resulting\nfrom learning representations of domain data in a form of heterogeneous\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 20:34:11 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Antczak", "Karol", ""]]}, {"id": "2001.08290", "submitter": "Haoran Miao", "authors": "Haoran Miao, Gaofeng Cheng, Changfeng Gao, Pengyuan Zhang and Yonghong\n  Yan", "title": "Transformer-based Online CTC/attention End-to-End Speech Recognition\n  Architecture", "comments": "Accepted by ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.NE cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Transformer has gained success in automatic speech recognition\n(ASR) field. However, it is challenging to deploy a Transformer-based\nend-to-end (E2E) model for online speech recognition. In this paper, we propose\nthe Transformer-based online CTC/attention E2E ASR architecture, which contains\nthe chunk self-attention encoder (chunk-SAE) and the monotonic truncated\nattention (MTA) based self-attention decoder (SAD). Firstly, the chunk-SAE\nsplits the speech into isolated chunks. To reduce the computational cost and\nimprove the performance, we propose the state reuse chunk-SAE. Sencondly, the\nMTA based SAD truncates the speech features monotonically and performs\nattention on the truncated features. To support the online recognition, we\nintegrate the state reuse chunk-SAE and the MTA based SAD into online\nCTC/attention architecture. We evaluate the proposed online models on the HKUST\nMandarin ASR benchmark and achieve a 23.66% character error rate (CER) with a\n320 ms latency. Our online model yields as little as 0.19% absolute CER\ndegradation compared with the offline baseline, and achieves significant\nimprovement over our prior work on Long Short-Term Memory (LSTM) based online\nE2E models.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2020 14:36:19 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 08:05:47 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Miao", "Haoran", ""], ["Cheng", "Gaofeng", ""], ["Gao", "Changfeng", ""], ["Zhang", "Pengyuan", ""], ["Yan", "Yonghong", ""]]}, {"id": "2001.08357", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Zhengang Li, Yifan Gong, Tianyun Zhang, Wei Niu, Zheng\n  Zhan, Pu Zhao, Jian Tang, Xue Lin, Bin Ren, Yanzhi Wang", "title": "BLK-REW: A Unified Block-based DNN Pruning Framework using Reweighted\n  Regularization Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerating DNN execution on various resource-limited computing platforms\nhas been a long-standing problem. Prior works utilize l1-based group lasso or\ndynamic regularization such as ADMM to perform structured pruning on DNN models\nto leverage the parallel computing architectures. However, both of the pruning\ndimensions and pruning methods lack universality, which leads to degraded\nperformance and limited applicability. To solve the problem, we propose a new\nblock-based pruning framework that comprises a general and flexible structured\npruning dimension as well as a powerful and efficient reweighted regularization\nmethod. Our framework is universal, which can be applied to both CNNs and RNNs,\nimplying complete support for the two major kinds of computation-intensive\nlayers (i.e., CONV and FC layers). To complete all aspects of the\npruning-for-acceleration task, we also integrate compiler-based code\noptimization into our framework that can perform DNN inference in a real-time\nmanner. To the best of our knowledge, it is the first time that the weight\npruning framework achieves universal coverage for both CNNs and RNNs with\nreal-time mobile acceleration and no accuracy compromise.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 03:30:56 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 03:00:10 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Ma", "Xiaolong", ""], ["Li", "Zhengang", ""], ["Gong", "Yifan", ""], ["Zhang", "Tianyun", ""], ["Niu", "Wei", ""], ["Zhan", "Zheng", ""], ["Zhao", "Pu", ""], ["Tang", "Jian", ""], ["Lin", "Xue", ""], ["Ren", "Bin", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2001.08439", "submitter": "Johan Kwisthout", "authors": "Johan Kwisthout, Nils Donselaar", "title": "On the computational power and complexity of Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The last decade has seen the rise of neuromorphic architectures based on\nartificial spiking neural networks, such as the SpiNNaker, TrueNorth, and Loihi\nsystems. The massive parallelism and co-locating of computation and memory in\nthese architectures potentially allows for an energy usage that is orders of\nmagnitude lower compared to traditional Von Neumann architectures. However, to\ndate a comparison with more traditional computational architectures\n(particularly with respect to energy usage) is hampered by the lack of a formal\nmachine model and a computational complexity theory for neuromorphic\ncomputation. In this paper we take the first steps towards such a theory. We\nintroduce spiking neural networks as a machine model where---in contrast to the\nfamiliar Turing machine---information and the manipulation thereof are\nco-located in the machine. We introduce canonical problems, define hierarchies\nof complexity classes and provide some first completeness results.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 10:40:16 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Kwisthout", "Johan", ""], ["Donselaar", "Nils", ""]]}, {"id": "2001.08517", "submitter": "Karol Ch\\k{e}ci\\'nski", "authors": "Karol Ch\\k{e}ci\\'nski, Pawe{\\l} Wawrzy\\'nski", "title": "DCT-Conv: Coding filters in convolutional networks with Discrete Cosine\n  Transform", "comments": "6 pages, 2 figures, submitted for IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks are based on a huge number of trained weights.\nConsequently, they are often data-greedy, sensitive to overtraining, and learn\nslowly. We follow the line of research in which filters of convolutional neural\nlayers are determined on the basis of a smaller number of trained parameters.\nIn this paper, the trained parameters define a frequency spectrum which is\ntransformed into convolutional filters with Inverse Discrete Cosine Transform\n(IDCT, the same is applied in decompression from JPEG). We analyze how\nswitching off selected components of the spectra, thereby reducing the number\nof trained weights of the network, affects its performance. Our experiments\nshow that coding the filters with trained DCT parameters leads to improvement\nover traditional convolution. Also, the performance of the networks modified\nthis way decreases very slowly with the increasing extent of switching off\nthese parameters. In some experiments, a good performance is observed when even\n99.9% of these parameters are switched off.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 13:58:17 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 13:54:04 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 15:47:59 GMT"}, {"version": "v4", "created": "Tue, 7 Apr 2020 10:59:07 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Ch\u0119ci\u0144ski", "Karol", ""], ["Wawrzy\u0144ski", "Pawe\u0142", ""]]}, {"id": "2001.08552", "submitter": "Arkadiy Dushatskiy", "authors": "Arkadiy Dushatskiy, Adri\\\"enne M. Mendrik, Peter A. N. Bosman, Tanja\n  Alderliesten", "title": "Observer variation-aware medical image segmentation by combining deep\n  learning and surrogate-assisted genetic algorithms", "comments": "11 pages, 5 figures, SPIE Medical Imaging Conference - 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been great progress in automatic segmentation of medical\nimages with deep learning algorithms. In most works observer variation is\nacknowledged to be a problem as it makes training data heterogeneous but so far\nno attempts have been made to explicitly capture this variation. Here, we\npropose an approach capable of mimicking different styles of segmentation,\nwhich potentially can improve quality and clinical acceptance of automatic\nsegmentation methods. In this work, instead of training one neural network on\nall available data, we train several neural networks on subgroups of data\nbelonging to different segmentation variations separately. Because a priori it\nmay be unclear what styles of segmentation exist in the data and because\ndifferent styles do not necessarily map one-on-one to different observers, the\nsubgroups should be automatically determined. We achieve this by searching for\nthe best data partition with a genetic algorithm. Therefore, each network can\nlearn a specific style of segmentation from grouped training data. We provide\nproof of principle results for open-sourced prostate segmentation MRI data with\nsimulated observer variations. Our approach provides an improvement of up to\n23% (depending on simulated variations) in terms of Dice and surface Dice\ncoefficients compared to one network trained on all data.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 14:51:40 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Dushatskiy", "Arkadiy", ""], ["Mendrik", "Adri\u00ebnne M.", ""], ["Bosman", "Peter A. N.", ""], ["Alderliesten", "Tanja", ""]]}, {"id": "2001.08617", "submitter": "Eric Medvet", "authors": "Eric Medvet, Alberto Bartoli, Andrea De Lorenzo, Stefano Seriani", "title": "Design, Validation, and Case Studies of 2D-VSR-Sim, an\n  Optimization-friendly Simulator of 2-D Voxel-based Soft Robots", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Voxel-based soft robots (VSRs) are aggregations of soft blocks whose design\nis amenable to optimization. We here present a software, 2D-VSR-Sim, for\nfacilitating research concerning the optimization of VSRs body and brain. The\nsoftware, written in Java, provides consistent interfaces for all the VSRs\naspects suitable for optimization and considers by design the presence of\nsensing, i.e., the possibility of exploiting the feedback from the environment\nfor controlling the VSR. We experimentally characterize, from a mechanical\npoint of view, the VSRs that can be simulated with 2D-VSR-Sim and we discuss\nthe computational burden of the simulation. Finally, we show how 2D-VSR-Sim can\nbe used to repeat the experiments of significant previous studies and, in\nperspective, to provide experimental answers to a variety of research\nquestions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 15:54:58 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 12:42:23 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Medvet", "Eric", ""], ["Bartoli", "Alberto", ""], ["De Lorenzo", "Andrea", ""], ["Seriani", "Stefano", ""]]}, {"id": "2001.08768", "submitter": "Sorour Mohajerani", "authors": "Sorour Mohajerani and Parvaneh Saeedi", "title": "Cloud and Cloud Shadow Segmentation for Remote Sensing Imagery via\n  Filtered Jaccard Loss Function and Parametric Augmentation", "comments": "12 pages. This version is a bit different from the one published in\n  IEEE JSTARS", "journal-ref": "IEEE Journal of Selected Topics in Applied Earth Observations and\n  Remote Sensing (JSTARS), 2021", "doi": "10.1109/JSTARS.2021.3070786", "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud and cloud shadow segmentation are fundamental processes in optical\nremote sensing image analysis. Current methods for cloud/shadow identification\nin geospatial imagery are not as accurate as they should, especially in the\npresence of snow and haze. This paper presents a deep learning-based framework\nfor the detection of cloud/shadow in Landsat 8 images. Our method benefits from\na convolutional neural network, Cloud-Net+ (a modification of our previously\nproposed Cloud-Net \\cite{myigarss}) that is trained with a novel loss function\n(Filtered Jaccard Loss). The proposed loss function is more sensitive to the\nabsence of foreground objects in an image and penalizes/rewards the predicted\nmask more accurately than other common loss functions. In addition, a sunlight\ndirection-aware data augmentation technique is developed for the task of cloud\nshadow detection to extend the generalization ability of the proposed model by\nexpanding existing training sets. The combination of Cloud-Net+, Filtered\nJaccard Loss function, and the proposed augmentation algorithm delivers\nsuperior results on four public cloud/shadow detection datasets. Our\nexperiments on Pascal VOC dataset exemplifies the applicability and quality of\nour proposed network and loss function in other computer vision applications.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 19:13:00 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 22:01:36 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Mohajerani", "Sorour", ""], ["Saeedi", "Parvaneh", ""]]}, {"id": "2001.08839", "submitter": "Xiaolong Ma", "authors": "Zhengang Li, Yifan Gong, Xiaolong Ma, Sijia Liu, Mengshu Sun, Zheng\n  Zhan, Zhenglun Kong, Geng Yuan, Yanzhi Wang", "title": "SS-Auto: A Single-Shot, Automatic Structured Weight Pruning Framework of\n  DNNs with Ultra-High Efficiency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured weight pruning is a representative model compression technique of\nDNNs for hardware efficiency and inference accelerations. Previous works in\nthis area leave great space for improvement since sparse structures with\ncombinations of different structured pruning schemes are not exploited fully\nand efficiently. To mitigate the limitations, we propose SS-Auto, a\nsingle-shot, automatic structured pruning framework that can achieve row\npruning and column pruning simultaneously. We adopt soft constraint-based\nformulation to alleviate the strong non-convexity of l0-norm constraints used\nin state-of-the-art ADMM-based methods for faster convergence and fewer\nhyperparameters. Instead of solving the problem directly, a Primal-Proximal\nsolution is proposed to avoid the pitfall of penalizing all weights equally,\nthereby enhancing the accuracy. Extensive experiments on CIFAR-10 and CIFAR-100\ndatasets demonstrate that the proposed framework can achieve ultra-high pruning\nrates while maintaining accuracy. Furthermore, significant inference speedup\nhas been observed from the proposed framework through actual measurements on\nthe smartphone.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 22:45:02 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Li", "Zhengang", ""], ["Gong", "Yifan", ""], ["Ma", "Xiaolong", ""], ["Liu", "Sijia", ""], ["Sun", "Mengshu", ""], ["Zhan", "Zheng", ""], ["Kong", "Zhenglun", ""], ["Yuan", "Geng", ""], ["Wang", "Yanzhi", ""]]}, {"id": "2001.08842", "submitter": "Benjamin Evans", "authors": "Benjamin Patrick Evans, Bing Xue, Mengjie Zhang", "title": "Improving generalisation of AutoML systems with dynamic fitness\n  evaluations", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": "10.1145/3377930.3389805", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem machine learning developers are faced with is overfitting,\nthat is, fitting a pipeline too closely to the training data that the\nperformance degrades for unseen data. Automated machine learning aims to free\n(or at least ease) the developer from the burden of pipeline creation, but this\noverfitting problem can persist. In fact, this can become more of a problem as\nwe look to iteratively optimise the performance of an internal cross-validation\n(most often \\textit{k}-fold). While this internal cross-validation hopes to\nreduce this overfitting, we show we can still risk overfitting to the\nparticular folds used. In this work, we aim to remedy this problem by\nintroducing dynamic fitness evaluations which approximate repeated\n\\textit{k}-fold cross-validation, at little extra cost over single\n\\textit{k}-fold, and far lower cost than typical repeated \\textit{k}-fold. The\nresults show that when time equated, the proposed fitness function results in\nsignificant improvement over the current state-of-the-art baseline method which\nuses an internal single \\textit{k}-fold. Furthermore, the proposed extension is\nvery simple to implement on top of existing evolutionary computation methods,\nand can provide essentially a free boost in generalisation/testing performance.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 22:54:54 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Evans", "Benjamin Patrick", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "2001.08903", "submitter": "Feng Shi", "authors": "Feng Shi, Frank Neumann, Jianxin Wang", "title": "Runtime Performances of Randomized Search Heuristics for the Dynamic\n  Weighted Vertex Cover Problem", "comments": "27 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized search heuristics such as evolutionary algorithms are frequently\napplied to dynamic combinatorial optimization problems. Within this paper, we\npresent a dynamic model of the classic Weighted Vertex Cover problem and\nanalyze the runtime performances of the well-studied algorithms Randomized\nLocal Search and (1+1) EA adapted to it, to contribute to the theoretical\nunderstanding of evolutionary computing for problems with dynamic changes. In\nour investigations, we use an edge-based representation based on the dual form\nof the Linear Programming formulation for the problem and study the expected\nruntime that the adapted algorithms require to maintain a 2-approximate\nsolution when the given weighted graph is modified by an edge-editing or\nweight-editing operation. Considering the weights on the vertices may be\nexponentially large with respect to the size of the graph, the step size\nadaption strategy is incorporated, with or without the 1/5-th rule that is\nemployed to control the increasing/decreasing rate of the step size. Our\nresults show that three of the four algorithms presented in the paper can\nrecompute 2-approximate solutions for the studied dynamic changes in polynomial\nexpected runtime, but the (1+1) EA with 1/5-th Rule requires pseudo-polynomial\nexpected runtime.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 07:10:15 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Shi", "Feng", ""], ["Neumann", "Frank", ""], ["Wang", "Jianxin", ""]]}, {"id": "2001.08928", "submitter": "Hamid Reza Boveiri", "authors": "Hamid Reza Boveiri and Raouf Khayami", "title": "On the Performance of Metaheuristics: A Different Perspective", "comments": "Version 0.1: 16 Pages, 5 Figures, and 7 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, we are immersed in tens of newly-proposed evolutionary and\nswam-intelligence metaheuristics, which makes it very difficult to choose a\nproper one to be applied on a specific optimization problem at hand. On the\nother hand, most of these metaheuristics are nothing but slightly modified\nvariants of the basic metaheuristics. For example, Differential Evolution (DE)\nor Shuffled Frog Leaping (SFL) are just Genetic Algorithms (GA) with a\nspecialized operator or an extra local search, respectively. Therefore, what\ncomes to the mind is whether the behavior of such newly-proposed metaheuristics\ncan be investigated on the basis of studying the specifications and\ncharacteristics of their ancestors. In this paper, a comprehensive evaluation\nstudy on some basic metaheuristics i.e. Genetic Algorithm (GA), Particle Swarm\nOptimization (PSO), Artificial Bee Colony (ABC), Teaching-Learning-Based\nOptimization (TLBO), and Cuckoo Optimization algorithm (COA) is conducted,\nwhich give us a deeper insight into the performance of them so that we will be\nable to better estimate the performance and applicability of all other\nvariations originated from them. A large number of experiments have been\nconducted on 20 different combinatorial optimization benchmark functions with\ndifferent characteristics, and the results reveal to us some fundamental\nconclusions besides the following ranking order among these metaheuristics,\n{ABC, PSO, TLBO, GA, COA} i.e. ABC and COA are the best and the worst methods\nfrom the performance point of view, respectively. In addition, from the\nconvergence perspective, PSO and ABC have significant better convergence for\nunimodal and multimodal functions, respectively, while GA and COA have\npremature convergence to local optima in many cases needing alternative\nmutation mechanisms to enhance diversification and global search.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 09:34:10 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Boveiri", "Hamid Reza", ""], ["Khayami", "Raouf", ""]]}, {"id": "2001.08966", "submitter": "Mehdi Neshat", "authors": "Nataliia Y. Sergiienko, Mehdi Neshat, Leandro S.P. da Silva, Bradley\n  Alexander and Markus Wagner", "title": "Design optimisation of a multi-mode wave energy converter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wave energy converter (WEC) similar to the CETO system developed by\nCarnegie Clean Energy is considered for design optimisation. This WEC is able\nto absorb power from heave, surge and pitch motion modes, making the\noptimisation problem nontrivial. The WEC dynamics is simulated using the\nspectral-domain model taking into account hydrodynamic forces, viscous drag,\nand power take-off forces. The design parameters for optimisation include the\nbuoy radius, buoy height, tether inclination angles, and control variables\n(damping and stiffness). The WEC design is optimised for the wave climate at\nAlbany test site in Western Australia considering unidirectional irregular\nwaves. Two objective functions are considered: (i) maximisation of the annual\naverage power output, and (ii) minimisation of the levelised cost of energy\n(LCoE) for a given sea site. The LCoE calculation is approximated as a ratio of\nthe produced energy to the significant mass of the system that includes the\nmass of the buoy and anchor system. Six different heuristic optimisation\nmethods are applied in order to evaluate and compare the performance of the\nbest known evolutionary algorithms, a swarm intelligence technique and a\nnumerical optimisation approach. The results demonstrate that if we are\ninterested in maximising energy production without taking into account the cost\nof manufacturing such a system, the buoy should be built as large as possible\n(20 m radius and 30 m height). However, if we want the system that produces\ncheap energy, then the radius of the buoy should be approximately 11-14~m while\nthe height should be as low as possible. These results coincide with the\noverall design that Carnegie Clean Energy has selected for its CETO 6\nmulti-moored unit. However, it should be noted that this study is not informed\nby them, so this can be seen as an independent validation of the design\nchoices.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 12:46:36 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Sergiienko", "Nataliia Y.", ""], ["Neshat", "Mehdi", ""], ["da Silva", "Leandro S. P.", ""], ["Alexander", "Bradley", ""], ["Wagner", "Markus", ""]]}, {"id": "2001.09040", "submitter": "Se Un Park", "authors": "Se Un Park", "title": "Estimation for Compositional Data using Measurements from Nonlinear\n  Systems using Artificial Neural Networks", "comments": "43 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Our objective is to estimate the unknown compositional input from its output\nresponse through an unknown system after estimating the inverse of the original\nsystem with a training set. The proposed methods using artificial neural\nnetworks (ANNs) can compete with the optimal bounds for linear systems, where\nconvex optimization theory applies, and demonstrate promising results for\nnonlinear system inversions. We performed extensive experiments by designing\nnumerous different types of nonlinear systems.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 14:50:13 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Park", "Se Un", ""]]}, {"id": "2001.09203", "submitter": "Erez Yahalomi", "authors": "Erez Yahalomi", "title": "Modular network for high accuracy object detection", "comments": "Revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel modular object detection convolutional neural network that\nsignificantly improves the accuracy of object detection. The network consists\nof two stages in a hierarchical structure. The first stage is a network that\ndetects general classes. The second stage consists of separate networks to\nrefine the classification and localization of each of the general classes\nobjects. Compared to a state of the art object detection networks the\nclassification error in the modular network is improved by approximately 3-5\ntimes, from 12% to 2.5 %-4.5%. This network is easy to implement and has a 0.94\nmAP. The network architecture can be a platform to improve the accuracy of\nwidespread state of the art object detection networks and other kinds of deep\nlearning networks. We show that a deep learning network initialized by transfer\nlearning becomes more accurate as the number of classes it later trained to\ndetect becomes smaller.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 21:38:22 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 15:50:45 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 19:03:31 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Yahalomi", "Erez", ""]]}, {"id": "2001.09209", "submitter": "Mahdi Bohlouli", "authors": "Rasoul Kiani, Amin Keshavarzi, and Mahdi Bohlouli", "title": "Detection of Thin Boundaries between Different Types of Anomalies in\n  Outlier Detection using Enhanced Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection has received special attention in various fields, mainly\nfor those dealing with machine learning and artificial intelligence. As strong\noutliers, anomalies are divided into the point, contextual and collective\noutliers. The most important challenges in outlier detection include the thin\nboundary between the remote points and natural area, the tendency of new data\nand noise to mimic the real data, unlabelled datasets and different definitions\nfor outliers in different applications. Considering the stated challenges, we\ndefined new types of anomalies called Collective Normal Anomaly and Collective\nPoint Anomaly in order to improve a much better detection of the thin boundary\nbetween different types of anomalies. Basic domain-independent methods are\nintroduced to detect these defined anomalies in both unsupervised and\nsupervised datasets. The Multi-Layer Perceptron Neural Network is enhanced\nusing the Genetic Algorithm to detect newly defined anomalies with higher\nprecision so as to ensure a test error less than that calculated for the\nconventional Multi-Layer Perceptron Neural Network. Experimental results on\nbenchmark datasets indicated reduced error of anomaly detection process in\ncomparison to baselines.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 21:52:02 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kiani", "Rasoul", ""], ["Keshavarzi", "Amin", ""], ["Bohlouli", "Mahdi", ""]]}, {"id": "2001.09220", "submitter": "Wei Wang", "authors": "Wei Wang, Shibo Zhou, Jingxi Li, Xiaohua Li, Junsong Yuan, Zhanpeng\n  Jin", "title": "Temporal Pulses Driven Spiking Neural Network for Fast Object\n  Recognition in Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate real-time object recognition from sensory data has long been a\ncrucial and challenging task for autonomous driving. Even though deep neural\nnetworks (DNNs) have been successfully applied in this area, most existing\nmethods still heavily rely on the pre-processing of the pulse signals derived\nfrom LiDAR sensors, and therefore introduce additional computational overhead\nand considerable latency. In this paper, we propose an approach to address the\nobject recognition problem directly with raw temporal pulses utilizing the\nspiking neural network (SNN). Being evaluated on various datasets (including\nSim LiDAR, KITTI and DVS-barrel) derived from LiDAR and dynamic vision sensor\n(DVS), our proposed method has shown comparable performance as the\nstate-of-the-art methods, while achieving remarkable time efficiency. It\nhighlights the SNN's great potentials in autonomous driving and related\napplications. To the best of our knowledge, this is the first attempt to use\nSNN to directly perform object recognition on raw temporal pulses.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2020 22:58:55 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Wang", "Wei", ""], ["Zhou", "Shibo", ""], ["Li", "Jingxi", ""], ["Li", "Xiaohua", ""], ["Yuan", "Junsong", ""], ["Jin", "Zhanpeng", ""]]}, {"id": "2001.09396", "submitter": "Parthe Pandit", "authors": "Parthe Pandit, Mojtaba Sahraee-Ardakan, Sundeep Rangan, Philip\n  Schniter, Alyson K. Fletcher", "title": "Inference in Multi-Layer Networks with Matrix-Valued Unknowns", "comments": "3 figures, 6 pages (two-column) + Appendix. arXiv admin note: text\n  overlap with arXiv:1911.03409", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT cs.NE eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inferring the input and hidden variables of a\nstochastic multi-layer neural network from an observation of the output. The\nhidden variables in each layer are represented as matrices. This problem\napplies to signal recovery via deep generative prior models, multi-task and\nmixed regression and learning certain classes of two-layer neural networks. A\nunified approximation algorithm for both MAP and MMSE inference is proposed by\nextending a recently-developed Multi-Layer Vector Approximate Message Passing\n(ML-VAMP) algorithm to handle matrix-valued unknowns. It is shown that the\nperformance of the proposed Multi-Layer Matrix VAMP (ML-Mat-VAMP) algorithm can\nbe exactly predicted in a certain random large-system limit, where the\ndimensions $N\\times d$ of the unknown quantities grow as $N\\rightarrow\\infty$\nwith $d$ fixed. In the two-layer neural-network learning problem, this scaling\ncorresponds to the case where the number of input features and training samples\ngrow to infinity but the number of hidden nodes stays fixed. The analysis\nenables a precise prediction of the parameter and test error of the learning.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 04:00:24 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Pandit", "Parthe", ""], ["Sahraee-Ardakan", "Mojtaba", ""], ["Rangan", "Sundeep", ""], ["Schniter", "Philip", ""], ["Fletcher", "Alyson K.", ""]]}, {"id": "2001.09545", "submitter": "Chiranjib Sur", "authors": "Chiranjib Sur", "title": "aiTPR: Attribute Interaction-Tensor Product Representation for Image\n  Caption", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Region visual features enhance the generative capability of the machines\nbased on features, however they lack proper interaction attentional perceptions\nand thus ends up with biased or uncorrelated sentences or pieces of\nmisinformation. In this work, we propose Attribute Interaction-Tensor Product\nRepresentation (aiTPR) which is a convenient way of gathering more information\nthrough orthogonal combination and learning the interactions as physical\nentities (tensors) and improving the captions. Compared to previous works,\nwhere features are added up to undefined feature spaces, TPR helps in\nmaintaining sanity in combinations and orthogonality helps in defining familiar\nspaces. We have introduced a new concept layer that defines the objects and\nalso their interactions that can play a crucial role in determination of\ndifferent descriptions. The interaction portions have contributed heavily for\nbetter caption quality and has out-performed different previous works on this\ndomain and MSCOCO dataset. We introduced, for the first time, the notion of\ncombining regional image features and abstracted interaction likelihood\nembedding for image captioning.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 00:19:41 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Sur", "Chiranjib", ""]]}, {"id": "2001.09578", "submitter": "Andrew Lensen", "authors": "Andrew Lensen, Bing Xue, Mengjie Zhang", "title": "Genetic Programming for Evolving a Front of Interpretable Models for\n  Data Visualisation", "comments": "Accepted by IEEE Transactions on Cybernetics, 2020", "journal-ref": null, "doi": "10.1109/TCYB.2020.2970198", "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data visualisation is a key tool in data mining for understanding big\ndatasets. Many visualisation methods have been proposed, including the\nwell-regarded state-of-the-art method t-Distributed Stochastic Neighbour\nEmbedding. However, the most powerful visualisation methods have a significant\nlimitation: the manner in which they create their visualisation from the\noriginal features of the dataset is completely opaque. Many domains require an\nunderstanding of the data in terms of the original features; there is hence a\nneed for powerful visualisation methods which use understandable models. In\nthis work, we propose a genetic programming approach named GPtSNE for evolving\ninterpretable mappings from a dataset to highquality visualisations. A\nmulti-objective approach is designed that produces a variety of visualisations\nin a single run which give different trade-offs between visual quality and\nmodel complexity. Testing against baseline methods on a variety of datasets\nshows the clear potential of GP-tSNE to allow deeper insight into data than\nthat provided by existing visualisation methods. We further highlight the\nbenefits of a multi-objective approach through an in-depth analysis of a\ncandidate front, which shows how multiple models can\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 04:03:19 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Lensen", "Andrew", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "2001.09641", "submitter": "Atsushi Masumori", "authors": "Atsushi Masumori, Lana Sinapayen, Norihiro Maruyama, Takeshi Mita,\n  Douglas Bakkum, Urs Frey, Hirokazu Takahashi, and Takashi Ikegami", "title": "Neural Autopoiesis: Organizing Self-Boundary by Stimulus Avoidance in\n  Biological and Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Living organisms must actively maintain themselves in order to continue\nexisting. Autopoiesis is a key concept in the study of living organisms, where\nthe boundaries of the organism is not static by dynamically regulated by the\nsystem itself. To study the autonomous regulation of self-boundary, we focus on\nneural homeodynamic responses to environmental changes using both biological\nand artificial neural networks. Previous studies showed that embodied cultured\nneural networks and spiking neural networks with spike-timing dependent\nplasticity (STDP) learn an action as they avoid stimulation from outside. In\nthis paper, as a result of our experiments using embodied cultured neurons, we\nfind that there is also a second property allowing the network to avoid\nstimulation: if the agent cannot learn an action to avoid the external stimuli,\nit tends to decrease the stimulus-evoked spikes, as if to ignore the\nuncontrollable-input. We also show such a behavior is reproduced by spiking\nneural networks with asymmetric STDP. We consider that these properties are\nregarded as autonomous regulation of self and non-self for the network, in\nwhich a controllable-neuron is regarded as self, and an uncontrollable-neuron\nis regarded as non-self. Finally, we introduce neural autopoiesis by proposing\nthe principle of stimulus avoidance.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 09:27:50 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Masumori", "Atsushi", ""], ["Sinapayen", "Lana", ""], ["Maruyama", "Norihiro", ""], ["Mita", "Takeshi", ""], ["Bakkum", "Douglas", ""], ["Frey", "Urs", ""], ["Takahashi", "Hirokazu", ""], ["Ikegami", "Takashi", ""]]}, {"id": "2001.09725", "submitter": "Nitin Chandrachoodan", "authors": "Abinand Nallathambi and Nitin Chandrachoodan", "title": "Probabilistic spike propagation for FPGA implementation of spiking\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation of spiking neural networks requires fetching a large number of\nsynaptic weights to update postsynaptic neurons. This limits parallelism and\nbecomes a bottleneck for hardware.\n  We present an approach for spike propagation based on a probabilistic\ninterpretation of weights, thus reducing memory accesses and updates. We study\nthe effects of introducing randomness into the spike processing, and show on\nbenchmark networks that this can be done with minimal impact on the recognition\naccuracy.\n  We present an architecture and the trade-offs in accuracy on fully connected\nand convolutional networks for the MNIST and CIFAR10 datasets on the Xilinx\nZynq platform.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 06:55:57 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Nallathambi", "Abinand", ""], ["Chandrachoodan", "Nitin", ""]]}, {"id": "2001.09841", "submitter": "Amir Mosavi Prof", "authors": "Javad Hassannataj Joloudari, Edris Hassannataj Joloudari, Hamid\n  Saadatfar, Mohammad GhasemiGol, Seyyed Mohammad Razavi, Amir Mosavi, Narjes\n  Nabipour, Shahaboddin Shamshirband, and Laszlo Nadai", "title": "Coronary Artery Disease Diagnosis; Ranking the Significant Features\n  Using Random Trees Model", "comments": "25 pages, 9 figures", "journal-ref": "International Journal of Environmental Research and Public Health,\n  2020", "doi": "10.3390/ijerph17030731", "report-no": null, "categories": "physics.med-ph cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Heart disease is one of the most common diseases in middle-aged citizens.\nAmong the vast number of heart diseases, the coronary artery disease (CAD) is\nconsidered as a common cardiovascular disease with a high death rate. The most\npopular tool for diagnosing CAD is the use of medical imaging, e.g.,\nangiography. However, angiography is known for being costly and also associated\nwith a number of side effects. Hence, the purpose of this study is to increase\nthe accuracy of coronary heart disease diagnosis through selecting significant\npredictive features in order of their ranking. In this study, we propose an\nintegrated method using machine learning. The machine learning methods of\nrandom trees (RTs), decision tree of C5.0, support vector machine (SVM),\ndecision tree of Chi-squared automatic interaction detection (CHAID) are used\nin this study. The proposed method shows promising results and the study\nconfirms that RTs model outperforms other models.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 20:01:09 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Joloudari", "Javad Hassannataj", ""], ["Joloudari", "Edris Hassannataj", ""], ["Saadatfar", "Hamid", ""], ["GhasemiGol", "Mohammad", ""], ["Razavi", "Seyyed Mohammad", ""], ["Mosavi", "Amir", ""], ["Nabipour", "Narjes", ""], ["Shamshirband", "Shahaboddin", ""], ["Nadai", "Laszlo", ""]]}, {"id": "2001.09923", "submitter": "Najla AL-Saati Dr.", "authors": "Najla Akram Al-Saati", "title": "Applying Gene Expression Programming for Solving One-Dimensional\n  Bin-Packing Problems", "comments": "20 page", "journal-ref": "Rafidain Journal of Computer sciences and Mathematics , Vol. 10,\n  No. 4, 2013", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims to study and explore the use of Gene Expression Programming\n(GEP) in solving the on-line Bin-Packing problem. The main idea is to show how\nGEP can automatically find acceptable heuristic rules to solve the problem\nefficiently and economically. One dimensional Bin-Packing problem is considered\nin the course of this work with the constraint of minimizing the number of bins\nfilled with the given pieces. Experimental Data includes instances of benchmark\ntest data taken from Falkenauer (1996) for One-dimensional Bin-Packing\nProblems. Results show that GEP can be used as a very powerful and flexible\ntool for finding interesting compact rules suited for the problem. The impact\nof functions is also investigated to show how they can affect and influence the\nsuccess of rates when they appear in rules. High success rates are gained with\nsmaller population size and fewer generations compared to previous work\nperformed using Genetic Programming.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 15:07:45 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Al-Saati", "Najla Akram", ""]]}, {"id": "2001.09977", "submitter": "Daniel de Freitas Adiwardana", "authors": "Daniel Adiwardana, Minh-Thang Luong, David R. So, Jamie Hall, Noah\n  Fiedel, Romal Thoppilan, Zi Yang, Apoorv Kulshreshtha, Gaurav Nemade, Yifeng\n  Lu, Quoc V. Le", "title": "Towards a Human-like Open-Domain Chatbot", "comments": "38 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Meena, a multi-turn open-domain chatbot trained end-to-end on data\nmined and filtered from public domain social media conversations. This 2.6B\nparameter neural network is simply trained to minimize perplexity of the next\ntoken. We also propose a human evaluation metric called Sensibleness and\nSpecificity Average (SSA), which captures key elements of a human-like\nmulti-turn conversation. Our experiments show strong correlation between\nperplexity and SSA. The fact that the best perplexity end-to-end trained Meena\nscores high on SSA (72% on multi-turn evaluation) suggests that a human-level\nSSA of 86% is potentially within reach if we can better optimize perplexity.\nAdditionally, the full version of Meena (with a filtering mechanism and tuned\ndecoding) scores 79% SSA, 23% higher in absolute SSA than the existing chatbots\nwe evaluated.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 18:53:15 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 18:58:14 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 07:36:47 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Adiwardana", "Daniel", ""], ["Luong", "Minh-Thang", ""], ["So", "David R.", ""], ["Hall", "Jamie", ""], ["Fiedel", "Noah", ""], ["Thoppilan", "Romal", ""], ["Yang", "Zi", ""], ["Kulshreshtha", "Apoorv", ""], ["Nemade", "Gaurav", ""], ["Lu", "Yifeng", ""], ["Le", "Quoc V.", ""]]}, {"id": "2001.10159", "submitter": "Junwen Luo", "authors": "Junwen Luo and Jiaoyan Chen", "title": "An Internal Clock Based Space-time Neural Network for Motion Speed\n  Recognition", "comments": "To appear in Neuro-inspired Computational Elements Workshop (NICE\n  20). March 26-28,2020 Heidelberg, Germany, 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we present a novel internal clock based space-time neural\nnetwork for motion speed recognition. The developed system has a spike train\nencoder, a Spiking Neural Network (SNN) with internal clocking behaviors, a\npattern transformation block and a Network Dynamic Dependent Plasticity (NDDP)\nlearning block. The core principle is that the developed SNN will automatically\ntune its network pattern frequency (internal clock frequency) to recognize\nhuman motions in a speed domain. We employed both cartoons and real-world\nvideos as training benchmarks, results demonstrate that our system can not only\nrecognize motions with considerable speed differences (e.g. run, walk, jump,\nwonder(think) and standstill), but also motions with subtle speed gaps such as\nrun and fast walk. The inference accuracy can be up to 83.3% (cartoon videos)\nand 75% (real-world videos). Meanwhile, the system only requires six video\ndatasets in the learning stage and with up to 42 training trials. Hardware\nperformance estimation indicates that the training time is 0.84-4.35s and power\nconsumption is 33.26-201mW (based on an ARM Cortex M4 processor). Therefore,\nour system takes unique learning advantages of the requirement of the small\ndataset, quick learning and low power performance, which shows great potentials\nfor edge or scalable AI-based applications.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 04:07:33 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Luo", "Junwen", ""], ["Chen", "Jiaoyan", ""]]}, {"id": "2001.10178", "submitter": "Benjamin Evans", "authors": "Benjamin Patrick Evans, Bing Xue, Mengjie Zhang", "title": "An Adaptive and Near Parameter-free Evolutionary Computation Approach\n  Towards True Automation in AutoML", "comments": "18 pages (single column), 2 figures", "journal-ref": null, "doi": "10.1109/CEC48606.2020.9185770", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common claim of evolutionary computation methods is that they can achieve\ngood results without the need for human intervention. However, one criticism of\nthis is that there are still hyperparameters which must be tuned in order to\nachieve good performance. In this work, we propose a near \"parameter-free\"\ngenetic programming approach, which adapts the hyperparameter values throughout\nevolution without ever needing to be specified manually. We apply this to the\narea of automated machine learning (by extending TPOT), to produce pipelines\nwhich can effectively be claimed to be free from human input, and show that the\nresults are competitive with existing state-of-the-art which use hand-selected\nhyperparameter values. Pipelines begin with a randomly chosen estimator and\nevolve to competitive pipelines automatically. This work moves towards a truly\nautomatic approach to AutoML.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 05:44:53 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Evans", "Benjamin Patrick", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "2001.10422", "submitter": "Arber Zela", "authors": "Arber Zela, Julien Siems, Frank Hutter", "title": "NAS-Bench-1Shot1: Benchmarking and Dissecting One-shot Neural\n  Architecture Search", "comments": "In: International Conference on Learning Representations (ICLR 2020);\n  19 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-shot neural architecture search (NAS) has played a crucial role in making\nNAS methods computationally feasible in practice. Nevertheless, there is still\na lack of understanding on how these weight-sharing algorithms exactly work due\nto the many factors controlling the dynamics of the process. In order to allow\na scientific study of these components, we introduce a general framework for\none-shot NAS that can be instantiated to many recently-introduced variants and\nintroduce a general benchmarking framework that draws on the recent large-scale\ntabular benchmark NAS-Bench-101 for cheap anytime evaluations of one-shot NAS\nmethods. To showcase the framework, we compare several state-of-the-art\none-shot NAS methods, examine how sensitive they are to their hyperparameters\nand how they can be improved by tuning their hyperparameters, and compare their\nperformance to that of blackbox optimizers for NAS-Bench-101.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:50:22 GMT"}, {"version": "v2", "created": "Sun, 12 Apr 2020 22:48:28 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Zela", "Arber", ""], ["Siems", "Julien", ""], ["Hutter", "Frank", ""]]}, {"id": "2001.10468", "submitter": "Firas Kassawat", "authors": "Firas Kassawat, Debanjan Chaudhuri, Jens Lehmann", "title": "Incorporating Joint Embeddings into Goal-Oriented Dialogues with\n  Multi-Task Learning", "comments": "The Semantic Web - 16th International Conference, ESWC 2019,\n  Portoro\\v{z}, Slovenia, June 2-6, 2019, Proceedings, page 225-239", "journal-ref": null, "doi": "10.1007/978-3-030-21348-0_15", "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention-based encoder-decoder neural network models have recently shown\npromising results in goal-oriented dialogue systems. However, these models\nstruggle to reason over and incorporate state-full knowledge while preserving\ntheir end-to-end text generation functionality. Since such models can greatly\nbenefit from user intent and knowledge graph integration, in this paper we\npropose an RNN-based end-to-end encoder-decoder architecture which is trained\nwith joint embeddings of the knowledge graph and the corpus as input. The model\nprovides an additional integration of user intent along with text generation,\ntrained with a multi-task learning paradigm along with an additional\nregularization technique to penalize generating the wrong entity as output. The\nmodel further incorporates a Knowledge Graph entity lookup during inference to\nguarantee the generated output is state-full based on the local knowledge graph\nprovided. We finally evaluated the model using the BLEU score, empirical\nevaluation depicts that our proposed architecture can aid in the betterment of\ntask-oriented dialogue system`s performance.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 17:15:02 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kassawat", "Firas", ""], ["Chaudhuri", "Debanjan", ""], ["Lehmann", "Jens", ""]]}, {"id": "2001.10529", "submitter": "C.-H. Huck Yang", "authors": "Jun Qi, Chao-Han Huck Yang, Javier Tejedor", "title": "Submodular Rank Aggregation on Score-based Permutations for Distributed\n  Automatic Speech Recognition", "comments": "Accepted to ICASSP 2020. Please download the pdf to view Figure 1.\n  arXiv admin note: substantial text overlap with arXiv:1707.01166", "journal-ref": "IEEE ICASSP 2020", "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed automatic speech recognition (ASR) requires to aggregate outputs\nof distributed deep neural network (DNN)-based models. This work studies the\nuse of submodular functions to design a rank aggregation on score-based\npermutations, which can be used for distributed ASR systems in both supervised\nand unsupervised modes. Specifically, we compose an aggregation rank function\nbased on the Lovasz Bregman divergence for setting up linear structured convex\nand nested structured concave functions. The algorithm is based on stochastic\ngradient descent (SGD) and can obtain well-trained aggregation models. Our\nexperiments on the distributed ASR system show that the submodular rank\naggregation can obtain higher speech recognition accuracy than traditional\naggregation methods like Adaboost. Code is available\nonline~\\footnote{https://github.com/uwjunqi/Subrank}.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 19:46:41 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Qi", "Jun", ""], ["Yang", "Chao-Han Huck", ""], ["Tejedor", "Javier", ""]]}, {"id": "2001.10605", "submitter": "Yang Chu", "authors": "Yang Chu, Wayne Luk, Dan Goodman", "title": "Learning Absolute Sound Source Localisation With Limited Supervisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE eess.AS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate auditory space map can be learned from auditory experience, for\nexample during development or in response to altered auditory cues such as a\nmodified pinna. We studied neural network models that learn to localise a\nsingle sound source in the horizontal plane using binaural cues based on\nlimited supervisions. These supervisions can be unreliable or sparse in real\nlife. First, a simple model that has unreliable estimation of the sound source\nlocation is built, in order to simulate the unreliable auditory orienting\nresponse of newborns. It is used as a Teacher that acts as a source of\nunreliable supervisions. Then we show that it is possible to learn a continuous\nauditory space map based only on noisy left or right feedbacks from the\nTeacher. Furthermore, reinforcement rewards from the environment are used as a\nsource of sparse supervision. By combining the unreliable innate response and\nthe sparse reinforcement rewards, an accurate auditory space map, which is hard\nto be achieved by either one of these two kind of supervisions, can eventually\nbe learned. Our results show that the auditory space mapping can be calibrated\neven without explicit supervision. Moreover, this study implies a possibly more\ngeneral neural mechanism where multiple sub-modules can be coordinated to\nfacilitate each other's learning process under limited supervisions.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 21:59:01 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Chu", "Yang", ""], ["Luk", "Wayne", ""], ["Goodman", "Dan", ""]]}, {"id": "2001.10696", "submitter": "Mingyuan Meng", "authors": "Mingyuan Meng, Xingyu Yang, Shanlin Xiao, Zhiyi Yu", "title": "Spiking Inception Module for Multi-layer Unsupervised Spiking Neural\n  Networks", "comments": "Published at the 2020 International Joint Conference on Neural\n  Networks (IJCNN); Extended from arXiv:2001.01680", "journal-ref": "2020 International Joint Conference on Neural Networks (IJCNN),\n  Glasgow, United Kingdom, 2020, pp. 1-8", "doi": "10.1109/IJCNN48605.2020.9207161", "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Spiking Neural Network (SNN), as a brain-inspired approach, is attracting\nattention due to its potential to produce ultra-high-energy-efficient hardware.\nCompetitive learning based on Spike-Timing-Dependent Plasticity (STDP) is a\npopular method to train an unsupervised SNN. However, previous unsupervised\nSNNs trained through this method are limited to a shallow network with only one\nlearnable layer and cannot achieve satisfactory results when compared with\nmulti-layer SNNs. In this paper, we eased this limitation by: 1)We proposed a\nSpiking Inception (Sp-Inception) module, inspired by the Inception module in\nthe Artificial Neural Network (ANN) literature. This module is trained through\nSTDP-based competitive learning and outperforms the baseline modules on\nlearning capability, learning efficiency, and robustness. 2)We proposed a\nPooling-Reshape-Activate (PRA) layer to make the Sp-Inception module stackable.\n3)We stacked multiple Sp-Inception modules to construct multi-layer SNNs. Our\nalgorithm outperforms the baseline algorithms on the hand-written digit\nclassification task, and reaches state-of-the-art results on the MNIST dataset\namong the existing unsupervised SNNs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 05:40:29 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 14:27:10 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 16:04:17 GMT"}, {"version": "v4", "created": "Fri, 5 Jun 2020 13:37:10 GMT"}, {"version": "v5", "created": "Mon, 28 Sep 2020 20:59:08 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Meng", "Mingyuan", ""], ["Yang", "Xingyu", ""], ["Xiao", "Shanlin", ""], ["Yu", "Zhiyi", ""]]}, {"id": "2001.10726", "submitter": "Andr\\'es Camero", "authors": "Andr\\'es Camero, Hao Wang, Enrique Alba, Thomas B\\\"ack", "title": "Bayesian Neural Architecture Search using A Training-Free Performance\n  Metric", "comments": null, "journal-ref": "Applied Soft Computing, p.107356 (2021)", "doi": "10.1016/j.asoc.2021.107356", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are a powerful approach for time series\nprediction. However, their performance is strongly affected by their\narchitecture and hyperparameter settings. The architecture optimization of RNNs\nis a time-consuming task, where the search space is typically a mixture of\nreal, integer and categorical values. To allow for shrinking and expanding the\nsize of the network, the representation of architectures often has a variable\nlength. In this paper, we propose to tackle the architecture optimization\nproblem with a variant of the Bayesian Optimization (BO) algorithm. To reduce\nthe evaluation time of candidate architectures the Mean Absolute Error Random\nSampling (MRS), a training-free method to estimate the network performance, is\nadopted as the objective function for BO. Also, we propose three fixed-length\nencoding schemes to cope with the variable-length architecture representation.\nThe result is a new perspective on accurate and efficient design of RNNs, that\nwe validate on three problems. Our findings show that 1) the BO algorithm can\nexplore different network architectures using the proposed encoding schemes and\nsuccessfully designs well-performing architectures, and 2) the optimization\ntime is significantly reduced by using MRS, without compromising the\nperformance as compared to the architectures obtained from the actual training\nprocedure.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 08:42:58 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 07:48:42 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Camero", "Andr\u00e9s", ""], ["Wang", "Hao", ""], ["Alba", "Enrique", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2001.10932", "submitter": "Yu Chen", "authors": "Yu Chen and Jun He", "title": "Exploitation and Exploration Analysis of Elitist Evolutionary\n  Algorithms: A Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Known as two cornerstones of problem solving by search, exploitation and\nexploration are extensively discussed for implementation and application of\nevolutionary algorithms (EAs). However, only a few researches focus on\nevaluation and theoretical estimation of exploitation and exploration.\nConsidering that exploitation and exploration are two issues regarding global\nsearch and local search, this paper proposes to evaluate them via the success\nprobability and the one-step improvement rate computed in different domains of\nintegration. Then, case studies are performed by analyzing performances of\n(1+1) random univariate search and (1+1) evolutionary programming on the sphere\nfunction and the cheating problem. By rigorous theoretical analysis, we\ndemonstrate that both exploitation and exploration of the investigated elitist\nEAs degenerate exponentially with the problem dimension $n$. Meanwhile, it is\nalso shown that maximization of exploitation and exploration can be achieved by\nsetting an appropriate value for the standard deviation $\\sigma$ of Gaussian\nmutation, which is positively related to the distance from the present solution\nto the center of the promising region.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 16:21:39 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Chen", "Yu", ""], ["He", "Jun", ""]]}, {"id": "2001.11272", "submitter": "Nuno M. Rodrigues", "authors": "Nuno M. Rodrigues, Sara Silva, Leonardo Vanneschi", "title": "A Study of Fitness Landscapes for Neuroevolution", "comments": "IEE CEC submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fitness landscapes are a useful concept to study the dynamics of\nmeta-heuristics. In the last two decades, they have been applied with success\nto estimate the optimization power of several types of evolutionary algorithms,\nincluding genetic algorithms and genetic programming. However, so far they have\nnever been used to study the performance of machine learning algorithms on\nunseen data, and they have never been applied to neuroevolution. This paper\naims at filling both these gaps, applying for the first time fitness landscapes\nto neuroevolution and using them to infer useful information about the\npredictive ability of the method. More specifically, we use a grammar-based\napproach to generate convolutional neural networks, and we study the dynamics\nof three different mutations to evolve them. To characterize fitness\nlandscapes, we study autocorrelation and entropic measure of ruggedness. The\nresults show that these measures are appropriate for estimating both the\noptimization power and the generalization ability of the considered\nneuroevolution configurations.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:53:55 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Rodrigues", "Nuno M.", ""], ["Silva", "Sara", ""], ["Vanneschi", "Leonardo", ""]]}, {"id": "2001.11296", "submitter": "Joseph Colonel", "authors": "Joseph T Colonel, Sam Keene", "title": "Conditioning Autoencoder Latent Spaces for Real-Time Timbre\n  Interpolation and Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare standard autoencoder topologies' performances for timbre\ngeneration. We demonstrate how different activation functions used in the\nautoencoder's bottleneck distributes a training corpus's embedding. We show\nthat the choice of sigmoid activation in the bottleneck produces a more bounded\nand uniformly distributed embedding than a leaky rectified linear unit\nactivation. We propose a one-hot encoded chroma feature vector for use in both\ninput augmentation and latent space conditioning. We measure the performance of\nthese networks, and characterize the latent embeddings that arise from the use\nof this chroma conditioning vector. An open source, real-time timbre synthesis\nalgorithm in Python is outlined and shared.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 13:06:26 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Colonel", "Joseph T", ""], ["Keene", "Sam", ""]]}, {"id": "2001.11396", "submitter": "Matthew Willetts", "authors": "Miguel Morin, Matthew Willetts", "title": "Non-Determinism in TensorFlow ResNets", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the stochasticity in training ResNets for image classification\non GPUs in TensorFlow is dominated by the non-determinism from GPUs, rather\nthan by the initialisation of the weights and biases of the network or by the\nsequence of minibatches given. The standard deviation of test set accuracy is\n0.02 with fixed seeds, compared to 0.027 with different seeds---nearly 74\\% of\nthe standard deviation of a ResNet model is non-deterministic. For test set\nloss the ratio of standard deviations is more than 80\\%. These results call for\nmore robust evaluation strategies of deep learning models, as a significant\namount of the variation in results across runs can arise simply from GPU\nrandomness.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 15:29:13 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Morin", "Miguel", ""], ["Willetts", "Matthew", ""]]}, {"id": "2001.11473", "submitter": "Gonzalo Rios", "authors": "Gonzalo Rios", "title": "Transport Gaussian Processes for Regression", "comments": "19 pages, 2 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process (GP) priors are non-parametric generative models with\nappealing modelling properties for Bayesian inference: they can model\nnon-linear relationships through noisy observations, have closed-form\nexpressions for training and inference, and are governed by interpretable\nhyperparameters. However, GP models rely on Gaussianity, an assumption that\ndoes not hold in several real-world scenarios, e.g., when observations are\nbounded or have extreme-value dependencies, a natural phenomenon in physics,\nfinance and social sciences. Although beyond-Gaussian stochastic processes have\ncaught the attention of the GP community, a principled definition and rigorous\ntreatment is still lacking. In this regard, we propose a methodology to\nconstruct stochastic processes, which include GPs, warped GPs, Student-t\nprocesses and several others under a single unified approach. We also provide\nformulas and algorithms for training and inference of the proposed models in\nthe regression problem. Our approach is inspired by layers-based models, where\neach proposed layer changes a specific property over the generated stochastic\nprocess. That, in turn, allows us to push-forward a standard Gaussian white\nnoise prior towards other more expressive stochastic processes, for which\nmarginals and copulas need not be Gaussian, while retaining the appealing\nproperties of GPs. We validate the proposed model through experiments with\nreal-world data.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 17:44:21 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Rios", "Gonzalo", ""]]}, {"id": "2001.11535", "submitter": "Valerio Terragni", "authors": "Stefano Ruberto and Valerio Terragni and Jason H. Moore", "title": "SGP-DT: Semantic Genetic Programming Based on Dynamic Targets", "comments": "16 pages, European Conference on Genetic Programming (EuroGP 20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic GP is a promising approach that introduces semantic awareness during\ngenetic evolution. This paper presents a new Semantic GP approach based on\nDynamic Target (SGP-DT) that divides the search problem into multiple GP runs.\nThe evolution in each run is guided by a new (dynamic) target based on the\nresidual errors. To obtain the final solution, SGP-DT combines the solutions of\neach run using linear scaling. SGP-DT presents a new methodology to produce the\noffspring that does not rely on the classic crossover. The synergy between such\na methodology and linear scaling yields to final solutions with low\napproximation error and computational cost. We evaluate SGP-DT on eight\nwell-known data sets and compare with {\\epsilon}-lexicase, a state-of-the-art\nevolutionary technique. SGP-DT achieves small RMSE values, on average 23.19%\nsmaller than the one of {\\epsilon}-lexicase.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 19:33:58 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Ruberto", "Stefano", ""], ["Terragni", "Valerio", ""], ["Moore", "Jason H.", ""]]}, {"id": "2001.11565", "submitter": "Ke Li Kl", "authors": "Joseph Billingsley, Ke Li, Wang Miao, Geyong Min, Nektarios Georgalas", "title": "Routing-Led Placement of VNFs in Arbitrary Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever increasing demand for computing resources has led to the creation of\nhyperscale datacentres with tens of thousands of servers. As demand continues\nto rise, new technologies must be incorporated to ensure high quality services\ncan be provided without the damaging environmental impact of high energy\nconsumption. Virtualisation technology such as network function virtualisation\n(NFV) allows for the creation of services by connecting component parts known\nas virtual network functions (VNFs). VNFs cam be used to maximally utilise\navailable datacentre resources by optimising the placement and routes of VNFs,\nto maintain a high quality of service whilst minimising energy costs. Current\nresearch on this problem has focussed on placing VNFs and considered routing as\na secondary concern. In this work we argue that the opposite approach, a\nrouting-led approach is preferable. We propose a novel routing-led algorithm\nand analyse each of the component parts over a range of different topologies on\nproblems with up to 16000 variables and compare its performance against a\ntraditional placement based algorithm. Empirical results show that our\nrouting-led algorithm can produce significantly better, faster solutions to\nlarge problem instances on a range of datacentre topologies.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 21:06:15 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Billingsley", "Joseph", ""], ["Li", "Ke", ""], ["Miao", "Wang", ""], ["Min", "Geyong", ""], ["Georgalas", "Nektarios", ""]]}, {"id": "2001.11588", "submitter": "Maryam Hasani-Shoreh", "authors": "Maryam Hasani-Shoreh, Renato Hermoza Aragon\\'es, Frank Neumann", "title": "Neural Networks in Evolutionary Dynamic Constrained Optimization:\n  Computational Cost and Benefits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NN) have been recently applied together with evolutionary\nalgorithms (EAs) to solve dynamic optimization problems. The applied NN\nestimates the position of the next optimum based on the previous time best\nsolutions. After detecting a change, the predicted solution can be employed to\nmove the EA's population to a promising region of the solution space in order\nto accelerate convergence and improve accuracy in tracking the optimum. While\nprevious works show improvement of the results, they neglect the overhead\ncreated by NN. In this work, we reflect the time spent on training NN in the\noptimization time and compare the results with a baseline EA. We explore if by\nconsidering the generated overhead, NN is still able to improve the results,\nand under which condition is able to do so.\n  The main difficulties to train the NN are: 1) to get enough samples to\ngeneralize predictions for new data, and 2) to obtain reliable samples. As NN\nneeds to collect data at each time step, if the time horizon is short, we will\nnot be able to collect enough samples to train the NN. To alleviate this, we\npropose to consider more individuals on each change to speed up sample\ncollection in shorter time steps. In environments with a high frequency of\nchanges, the solutions produced by EA are likely to be far from the real\noptimum. Using unreliable train data for the NN will, in consequence, produce\nunreliable predictions. Also, as the time spent for NN stays fixed regardless\nof the frequency, a higher frequency of change will mean a higher produced\noverhead by the NN in proportion to the EA. In general, after considering the\ngenerated overhead, we conclude that NN is not suitable in environments with a\nhigh frequency of changes and/or short time horizons. However, it can be\npromising for the low frequency of changes, and especially for the environments\nthat changes have a pattern.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 12:17:53 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Hasani-Shoreh", "Maryam", ""], ["Aragon\u00e9s", "Renato Hermoza", ""], ["Neumann", "Frank", ""]]}, {"id": "2001.11590", "submitter": "Thanh Pham Dinh", "authors": "Pham Dinh Thanh, Huynh Thi Thanh Binh, Bui Thu Lam", "title": "New mechanism of combination crossover operators in genetic algorithm\n  for solving the traveling salesman problem", "comments": "The final publication is available at link.springer.com", "journal-ref": null, "doi": "10.1007/978-3-319-11680-8_29", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traveling salesman problem (TSP) is a well-known in computing field. There\nare many researches to improve the genetic algorithm for solving TSP. In this\npaper, we propose two new crossover operators and new mechanism of combination\ncrossover operators in genetic algorithm for solving TSP. We experimented on\nTSP instances from TSP-Lib and compared the results of proposed algorithm with\ngenetic algorithm (GA), which used MSCX. Experimental results show that, our\nproposed algorithm is better than the GA using MSCX on the min, mean cost\nvalues.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 13:20:44 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Thanh", "Pham Dinh", ""], ["Binh", "Huynh Thi Thanh", ""], ["Lam", "Bui Thu", ""]]}, {"id": "2001.11591", "submitter": "Ivan Reinaldo Meneghini", "authors": "Ivan Reinaldo Meneghini, Marcos Antonio Alves, Ant\\'onio Gaspar-Cunha,\n  Frederico Gadelha Guimar\\~aes", "title": "Scalable and Customizable Benchmark Problems for Many-Objective\n  Optimization", "comments": "24 pages, 23 figures, to be published in Applied Soft computing", "journal-ref": "Applied Soft Computing, Volume 90, 2020, 106139", "doi": "10.1016/j.asoc.2020.106139", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Solving many-objective problems (MaOPs) is still a significant challenge in\nthe multi-objective optimization (MOO) field. One way to measure algorithm\nperformance is through the use of benchmark functions (also called test\nfunctions or test suites), which are artificial problems with a well-defined\nmathematical formulation, known solutions and a variety of features and\ndifficulties. In this paper we propose a parameterized generator of scalable\nand customizable benchmark problems for MaOPs. It is able to generate problems\nthat reproduce features present in other benchmarks and also problems with some\nnew features. We propose here the concept of generative benchmarking, in which\none can generate an infinite number of MOO problems, by varying parameters that\ncontrol specific features that the problem should have: scalability in the\nnumber of variables and objectives, bias, deceptiveness, multimodality, robust\nand non-robust solutions, shape of the Pareto front, and constraints. The\nproposed Generalized Position-Distance (GPD) tunable benchmark generator uses\nthe position-distance paradigm, a basic approach to building test functions,\nused in other benchmarks such as Deb, Thiele, Laumanns and Zitzler (DTLZ),\nWalking Fish Group (WFG) and others. It includes scalable problems in any\nnumber of variables and objectives and it presents Pareto fronts with different\ncharacteristics. The resulting functions are easy to understand and visualize,\neasy to implement, fast to compute and their Pareto optimal solutions are\nknown.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 12:39:51 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 12:49:59 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Meneghini", "Ivan Reinaldo", ""], ["Alves", "Marcos Antonio", ""], ["Gaspar-Cunha", "Ant\u00f3nio", ""], ["Guimar\u00e3es", "Frederico Gadelha", ""]]}, {"id": "2001.11679", "submitter": "Peter Csermely", "authors": "P\\'eter Csermely, Nina Kunsic, P\\'eter Mendik, M\\'ark Kerest\\'ely,\n  Teod\\'ora Farag\\'o, D\\'aniel V. Veres, and P\\'eter Tompa", "title": "Learning of signaling networks: molecular mechanisms", "comments": "cover story of the 2020 April issue of Trends in Biochemical Sciences", "journal-ref": "Trends in Biochemical Sciences (2020) 45, 284-294", "doi": "10.1016/j.tibs.2019.12.005", "report-no": null, "categories": "q-bio.MN cs.NE nlin.AO physics.bio-ph q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular processes of neuronal learning have been well-described. However,\nlearning mechanisms of non-neuronal cells have not been fully understood at the\nmolecular level. Here, we discuss molecular mechanisms of cellular learning,\nincluding conformational memory of intrinsically disordered proteins and\nprions, signaling cascades, protein translocation, RNAs (microRNA and lncRNA),\nand chromatin memory. We hypothesize that these processes constitute the\nlearning of signaling networks and correspond to a generalized Hebbian learning\nprocess of single, non-neuronal cells, and discuss how cellular learning may\nopen novel directions in drug design and inspire new artificial intelligence\nmethods.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 07:15:43 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 09:18:48 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Csermely", "P\u00e9ter", ""], ["Kunsic", "Nina", ""], ["Mendik", "P\u00e9ter", ""], ["Kerest\u00e9ly", "M\u00e1rk", ""], ["Farag\u00f3", "Teod\u00f3ra", ""], ["Veres", "D\u00e1niel V.", ""], ["Tompa", "P\u00e9ter", ""]]}, {"id": "2001.11771", "submitter": "Antonio Carta", "authors": "Antonio Carta, Alessandro Sperduti, Davide Bacciu", "title": "Encoding-based Memory Modules for Recurrent Neural Networks", "comments": "preprint submitted at Elsevier Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to solve sequential tasks with recurrent models requires the ability\nto memorize long sequences and to extract task-relevant features from them. In\nthis paper, we study the memorization subtask from the point of view of the\ndesign and training of recurrent neural networks. We propose a new model, the\nLinear Memory Network, which features an encoding-based memorization component\nbuilt with a linear autoencoder for sequences. We extend the memorization\ncomponent with a modular memory that encodes the hidden state sequence at\ndifferent sampling frequencies. Additionally, we provide a specialized training\nalgorithm that initializes the memory to efficiently encode the hidden\nactivations of the network. The experimental results on synthetic and\nreal-world datasets show that specializing the training algorithm to train the\nmemorization component always improves the final performance whenever the\nmemorization of long sequences is necessary to solve the problem.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 11:14:27 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Carta", "Antonio", ""], ["Sperduti", "Alessandro", ""], ["Bacciu", "Davide", ""]]}, {"id": "2001.11786", "submitter": "Shuaiqiang Liu", "authors": "Shuaiqiang Liu, \\'Alvaro Leitao, Anastasia Borovykh, Cornelis W.\n  Oosterlee", "title": "On Calibration Neural Networks for extracting implied information from\n  American options", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting implied information, like volatility and/or dividend, from\nobserved option prices is a challenging task when dealing with American\noptions, because of the computational costs needed to solve the corresponding\nmathematical problem many thousands of times. We will employ a data-driven\nmachine learning approach to estimate the Black-Scholes implied volatility and\nthe dividend yield for American options in a fast and robust way. To determine\nthe implied volatility, the inverse function is approximated by an artificial\nneural network on the computational domain of interest, which decouples the\noffline (training) and online (prediction) phases and thus eliminates the need\nfor an iterative process. For the implied dividend yield, we formulate the\ninverse problem as a calibration problem and determine simultaneously the\nimplied volatility and dividend yield. For this, a generic and robust\ncalibration framework, the Calibration Neural Network (CaNN), is introduced to\nestimate multiple parameters. It is shown that machine learning can be used as\nan efficient numerical technique to extract implied information from American\noptions.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 12:10:24 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Liu", "Shuaiqiang", ""], ["Leitao", "\u00c1lvaro", ""], ["Borovykh", "Anastasia", ""], ["Oosterlee", "Cornelis W.", ""]]}, {"id": "2001.11820", "submitter": "Tarik A. Rashid", "authors": "Danial A. Muhammed, Soran AM. Saeed, Tarik A. Rashid", "title": "Improved Fitness-Dependent Optimizer Algorithm", "comments": "17 pages", "journal-ref": "IEEE Access, 2020", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The fitness-dependent optimizer (FDO) algorithm was recently introduced in\n2019. An improved FDO (IFDO) algorithm is presented in this work, and this\nalgorithm contributes considerably to refining the ability of the original FDO\nto address complicated optimization problems. To improve the FDO, the IFDO\ncalculates the alignment and cohesion and then uses these behaviors with the\npace at which the FDO updates its position. Moreover, in determining the\nweights, the FDO uses the weight factor (wf), which is zero in most cases and\none in only a few cases. Conversely, the IFDO performs wf randomization in the\n[0-1] range and then minimizes the range when a better fitness weight value is\nachieved. In this work, the IFDO algorithm and its method of converging on the\noptimal solution are demonstrated. Additionally, 19 classical standard test\nfunction groups are utilized to test the IFDO, and then the FDO and three other\nwell-known algorithms, namely, the particle swarm algorithm (PSO), dragonfly\nalgorithm (DA), and genetic algorithm (GA), are selected to evaluate the IFDO\nresults. Furthermore, the CECC06 2019 Competition, which is the set of IEEE\nCongress of Evolutionary Computation benchmark test functions, is utilized to\ntest the IFDO, and then, the FDO and three recent algorithms, namely, the salp\nswarm algorithm (SSA), DA and whale optimization algorithm (WOA), are chosen to\ngauge the IFDO results. The results show that IFDO is practical in some cases,\nand its results are improved in most cases. Finally, to prove the\npracticability of the IFDO, it is used in real-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 21:50:11 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Muhammed", "Danial A.", ""], ["Saeed", "Soran AM.", ""], ["Rashid", "Tarik A.", ""]]}, {"id": "2001.11821", "submitter": "Jean-Philippe Fauvelle", "authors": "Alexandre Dey, Marc Velay, Jean-Philippe Fauvelle, Sylvain Navers", "title": "Adversarial vs behavioural-based defensive AI with joint, continual and\n  active learning: automated evaluation of robustness to deception, poisoning\n  and concept drift", "comments": "in French. European Cyber Week - CESAR/IAD Conference - Artificial\n  Intelligence and Defence, French Ministry of Defence, Nov 2019, Rennes,\n  France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in Artificial Intelligence (AI) have brought new\ncapabilities to behavioural analysis (UEBA) for cyber-security consisting in\nthe detection of hostile action based on the unusual nature of events observed\non the Information System.In our previous work (presented at C\\&ESAR 2018 and\nFIC 2019), we have associated deep neural networks auto-encoders for anomaly\ndetection and graph-based events correlation to address major limitations in\nUEBA systems. This resulted in reduced false positive and false negative rates,\nimproved alert explainability, while maintaining real-time performances and\nscalability. However, we did not address the natural evolution of behaviours\nthrough time, also known as concept drift. To maintain effective detection\ncapabilities, an anomaly-based detection system must be continually trained,\nwhich opens a door to an adversary that can conduct the so-called\n\"frog-boiling\" attack by progressively distilling unnoticed attack traces\ninside the behavioural models until the complete attack is considered normal.\nIn this paper, we present a solution to effectively mitigate this attack by\nimproving the detection process and efficiently leveraging human expertise. We\nalso present preliminary work on adversarial AI conducting deception attack,\nwhich, in term, will be used to help assess and improve the defense system.\nThese defensive and offensive AI implement joint, continual and active\nlearning, in a step that is necessary in assessing, validating and certifying\nAI-based defensive solutions.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 13:54:36 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Dey", "Alexandre", ""], ["Velay", "Marc", ""], ["Fauvelle", "Jean-Philippe", ""], ["Navers", "Sylvain", ""]]}, {"id": "2001.11822", "submitter": "Tarik A. Rashid", "authors": "Aram M. Ahmed, Tarik A. Rashid, Soran Ab. M. Saeed", "title": "Cat Swarm Optimization Algorithm -- A Survey and Performance Evaluation", "comments": "31 pages", "journal-ref": "Hindawi, Computational Intelligence and Neuroscience, Article ID\n  4854895, 2020", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper presents an in-depth survey and performance evaluation of the Cat\nSwarm Optimization (CSO) Algorithm. CSO is a robust and powerful metaheuristic\nswarm-based optimization approach that has received very positive feedback\nsince its emergence. It has been tackling many optimization problems and many\nvariants of it have been introduced. However, the literature lacks a detailed\nsurvey or a performance evaluation in this regard. Therefore, this paper is an\nattempt to review all these works, including its developments and applications,\nand group them accordingly. In addition, CSO is tested on 23 classical\nbenchmark functions and 10 modern benchmark functions (CEC 2019). The results\nare then compared against three novel and powerful optimization algorithms,\nnamely Dragonfly algorithm (DA), Butterfly optimization algorithm (BOA) and\nFitness Dependent Optimizer (FDO). These algorithms are then ranked according\nto Friedman test and the results show that CSO ranks first on the whole.\nFinally, statistical approaches are employed to further confirm the\noutperformance of CSO algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 18:18:05 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Ahmed", "Aram M.", ""], ["Rashid", "Tarik A.", ""], ["Saeed", "Soran Ab. M.", ""]]}, {"id": "2001.11846", "submitter": "Marcos Eduardo Valle", "authors": "Marcos Eduardo Valle and Rodolfo Anibal Lobo", "title": "Quaternion-Valued Recurrent Projection Neural Networks on Unit\n  Quaternions", "comments": "arXiv admin note: substantial text overlap with arXiv:1909.09227", "journal-ref": null, "doi": "10.1016/j.tcs.2020.08.033", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypercomplex-valued neural networks, including quaternion-valued neural\nnetworks, can treat multi-dimensional data as a single entity. In this paper,\nwe present the quaternion-valued recurrent projection neural networks (QRPNNs).\nBriefly, QRPNNs are obtained by combining the non-local projection learning\nwith the quaternion-valued recurrent correlation neural network (QRCNNs). We\nshow that QRPNNs overcome the cross-talk problem of QRCNNs. Thus, they are\nappropriate to implement associative memories. Furthermore, computational\nexperiments reveal that QRPNNs exhibit greater storage capacity and noise\ntolerance than their corresponding QRCNNs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 11:25:45 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Valle", "Marcos Eduardo", ""], ["Lobo", "Rodolfo Anibal", ""]]}, {"id": "2001.11847", "submitter": "Sara Mandelli", "authors": "Sara Mandelli, Davide Cozzolino, Paolo Bestagini, Luisa Verdoliva,\n  Stefano Tubaro", "title": "CNN-based fast source device identification", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2020.3008855", "report-no": null, "categories": "cs.NE cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Source identification is an important topic in image forensics, since it\nallows to trace back the origin of an image. This represents a precious\ninformation to claim intellectual property but also to reveal the authors of\nillicit materials. In this paper we address the problem of device\nidentification based on sensor noise and propose a fast and accurate solution\nusing convolutional neural networks (CNNs). Specifically, we propose a\n2-channel-based CNN that learns a way of comparing camera fingerprint and image\nnoise at patch level. The proposed solution turns out to be much faster than\nthe conventional approach and to ensure an increased accuracy. This makes the\napproach particularly suitable in scenarios where large databases of images are\nanalyzed, like over social networks. In this vein, since images uploaded on\nsocial media usually undergo at least two compression stages, we include\ninvestigations on double JPEG compressed images, always reporting higher\naccuracy than standard approaches.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 14:01:45 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 16:01:01 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 13:57:26 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Mandelli", "Sara", ""], ["Cozzolino", "Davide", ""], ["Bestagini", "Paolo", ""], ["Verdoliva", "Luisa", ""], ["Tubaro", "Stefano", ""]]}, {"id": "2001.11853", "submitter": "Felipe Carvalho", "authors": "Felipe Silva Carvalho, Jo\\~ao Pedro Braga", "title": "The G\\^ateaux-Hopfield Neural Network method", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present work a new set of differential equations for the Hopfield\nNeural Network (HNN) method were established by means of the Linear Extended\nGateaux Derivative (LEGD). This new approach will be referred to as\nG\\^ateaux-Hopfiel Neural Network (GHNN). A first order Fredholm integral\nproblem was used to test this new method and it was found to converge 22 times\nfaster to the exact solutions for {\\alpha} > 1 if compared with the HNN integer\norder differential equations. Also a limit to the learning time is observed by\nanalysing the results for different values of {\\alpha}. The robustness and\nadvantages of this new method will be pointed out.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 19:31:49 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Carvalho", "Felipe Silva", ""], ["Braga", "Jo\u00e3o Pedro", ""]]}, {"id": "2001.11946", "submitter": "Jennifer Sleeman", "authors": "Jennifer Sleeman, John Dorband, Milton Halem", "title": "A Hybrid Quantum enabled RBM Advantage: Convolutional Autoencoders For\n  Quantum Image Compression and Generative Learning", "comments": "18 figures, 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how the D-Wave quantum computer could be used for machine\nlearning problems is of growing interest. Our work evaluates the feasibility of\nusing the D-Wave as a sampler for machine learning. We describe a hybrid system\nthat combines a classical deep neural network autoencoder with a quantum\nannealing Restricted Boltzmann Machine (RBM) using the D-Wave. We evaluate our\nhybrid autoencoder algorithm using two datasets, the MNIST dataset and MNIST\nFashion dataset. We evaluate the quality of this method by using a downstream\nclassification method where the training is based on quantum RBM-generated\nsamples. Our method overcomes two key limitations in the current 2000-qubit\nD-Wave processor, namely the limited number of qubits available to accommodate\ntypical problem sizes for fully connected quantum objective functions and\nsamples that are binary pixel representations. As a consequence of these\nlimitations we are able to show how we achieved nearly a 22-fold compression\nfactor of grayscale 28 x 28 sized images to binary 6 x 6 sized images with a\nlossy recovery of the original 28 x 28 grayscale images. We further show how\ngenerating samples from the D-Wave after training the RBM, resulted in 28 x 28\nimages that were variations of the original input data distribution, as opposed\nto recreating the training samples. We formulated an MNIST classification\nproblem using a deep convolutional neural network that used samples from a\nquantum RBM to train the MNIST classifier and compared the results with an\nMNIST classifier trained with the original MNIST training data set, as well as\nan MNIST classifier trained using classical RBM samples. Our hybrid autoencoder\napproach indicates advantage for RBM results relative to the use of a current\nRBM classical computer implementation for image-based machine learning and even\nmore promising results for the next generation D-Wave quantum system.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 16:44:24 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Sleeman", "Jennifer", ""], ["Dorband", "John", ""], ["Halem", "Milton", ""]]}]