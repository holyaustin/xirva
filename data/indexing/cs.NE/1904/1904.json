[{"id": "1904.00687", "submitter": "Gilad Yehudai", "authors": "Gilad Yehudai and Ohad Shamir", "title": "On the Power and Limitations of Random Features for Understanding Neural\n  Networks", "comments": "Comparison to previous version: Fixed a bug in the proof of Theorem\n  4.1. Changed the polynomial dependency of ||w^*|| in Theorem 4.1 from d^2 to\n  d^3 and of |b^*| from O(d^3) to O(d^4)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a spate of papers have provided positive theoretical results for\ntraining over-parameterized neural networks (where the network size is larger\nthan what is needed to achieve low error). The key insight is that with\nsufficient over-parameterization, gradient-based methods will implicitly leave\nsome components of the network relatively unchanged, so the optimization\ndynamics will behave as if those components are essentially fixed at their\ninitial random values. In fact, fixing these explicitly leads to the well-known\napproach of learning with random features. In other words, these techniques\nimply that we can successfully learn with neural networks, whenever we can\nsuccessfully learn with random features. In this paper, we first review these\ntechniques, providing a simple and self-contained analysis for one-hidden-layer\nnetworks. We then argue that despite the impressive positive results, random\nfeature approaches are also inherently limited in what they can explain. In\nparticular, we rigorously show that random features cannot be used to learn\neven a single ReLU neuron with standard Gaussian inputs, unless the network\nsize (or magnitude of the weights) is exponentially large. Since a single\nneuron is learnable with gradient-based methods, we conclude that we are still\nfar from a satisfying general explanation for the empirical success of neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 10:21:24 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 16:40:26 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2020 08:13:41 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Yehudai", "Gilad", ""], ["Shamir", "Ohad", ""]]}, {"id": "1904.00758", "submitter": "Lex Fridman", "authors": "Li Ding, Jack Terwilliger, Rini Sherony, Bryan Reimer, Lex Fridman", "title": "Value of Temporal Dynamics Information in Driving Scene Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic scene segmentation has primarily been addressed by forming\nrepresentations of single images both with supervised and unsupervised methods.\nThe problem of semantic segmentation in dynamic scenes has begun to recently\nreceive attention with video object segmentation approaches. What is not known\nis how much extra information the temporal dynamics of the visual scene carries\nthat is complimentary to the information available in the individual frames of\nthe video. There is evidence that the human visual system can effectively\nperceive the scene from temporal dynamics information of the scene's changing\nvisual characteristics without relying on the visual characteristics of\nindividual snapshots themselves. Our work takes steps to explore whether\nmachine perception can exhibit similar properties by combining appearance-based\nrepresentations and temporal dynamics representations in a joint-learning\nproblem that reveals the contribution of each toward successful dynamic scene\nsegmentation. Additionally, we provide the MIT Driving Scene Segmentation\ndataset, which is a large-scale full driving scene segmentation dataset,\ndensely annotated for every pixel and every one of 5,000 video frames. This\ndataset is intended to help further the exploration of the value of temporal\ndynamics information for semantic segmentation in video.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 03:56:30 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Ding", "Li", ""], ["Terwilliger", "Jack", ""], ["Sherony", "Rini", ""], ["Reimer", "Bryan", ""], ["Fridman", "Lex", ""]]}, {"id": "1904.01070", "submitter": "Peyman Hosseinzadeh Kassani", "authors": "Peyman Hosseinzadeh Kassani, Alexej Gossmann, and Yu-Ping Wang", "title": "Multimodal Sparse Classifier for Adolescent Brain Age Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of healthy brain development helps to better understand the brain\ntransformation and brain connectivity patterns which happen during childhood to\nadulthood. This study presents a sparse machine learning solution across\nwhole-brain functional connectivity (FC) measures of three sets of data,\nderived from resting state functional magnetic resonance imaging (rs-fMRI) and\ntask fMRI data, including a working memory n-back task (nb-fMRI) and an emotion\nidentification task (em-fMRI). These multi-modal image data are collected on a\nsample of adolescents from the Philadelphia Neurodevelopmental Cohort (PNC) for\nthe prediction of brain ages. Due to extremely large variable-to-instance ratio\nof PNC data, a high dimensional matrix with several irrelevant and highly\ncorrelated features is generated and hence a pattern learning approach is\nnecessary to extract significant features. We propose a sparse learner based on\nthe residual errors along the estimation of an inverse problem for the extreme\nlearning machine (ELM) neural network. The purpose of the approach is to\novercome the overlearning problem through pruning of several redundant features\nand their corresponding output weights. The proposed multimodal sparse ELM\nclassifier based on residual errors (RES-ELM) is highly competitive in terms of\nthe classification accuracy compared to its counterparts such as conventional\nELM, and sparse Bayesian learning ELM.\n", "versions": [{"version": "v1", "created": "Mon, 1 Apr 2019 19:13:07 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Kassani", "Peyman Hosseinzadeh", ""], ["Gossmann", "Alexej", ""], ["Wang", "Yu-Ping", ""]]}, {"id": "1904.01336", "submitter": "Benjamin Jones", "authors": "Benjamin D.M. Jones, George O. O'Brien, David R. White, Earl T.\n  Campbell, John A. Clark", "title": "Optimising Trotter-Suzuki Decompositions for Quantum Simulation Using\n  Evolutionary Strategies", "comments": "A version of this paper is to appear in GECCO'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most promising applications of near-term quantum computing is the\nsimulation of quantum systems, a classically intractable task. Quantum\nsimulation requires computationally expensive matrix exponentiation;\nTrotter-Suzuki decomposition of this exponentiation enables efficient\nsimulation to a desired accuracy on a quantum computer. We apply the Covariance\nMatrix Adaptation Evolutionary Strategy (CMA-ES) algorithm to optimise the\nTrotter-Suzuki decompositions of a canonical quantum system, the Heisenberg\nChain; we reduce simulation error by around 60%. We introduce this problem to\nthe computational search community, show that an evolutionary optimisation\napproach is robust across runs and problem instances, and find that\noptimisation results generalise to the simulation of larger systems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 11:14:37 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2019 13:26:53 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2019 11:14:09 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Jones", "Benjamin D. M.", ""], ["O'Brien", "George O.", ""], ["White", "David R.", ""], ["Campbell", "Earl T.", ""], ["Clark", "John A.", ""]]}, {"id": "1904.01390", "submitter": "Shiv Ram Dubey", "authors": "Sai Prasanna Teja Reddy, Surya Teja Karri, Shiv Ram Dubey, Snehasis\n  Mukherjee", "title": "Spontaneous Facial Micro-Expression Recognition using 3D Spatiotemporal\n  Convolutional Neural Networks", "comments": "Accepted in 2019 International Joint Conference on Neural Networks\n  (IJCNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial expression recognition in videos is an active area of research in\ncomputer vision. However, fake facial expressions are difficult to be\nrecognized even by humans. On the other hand, facial micro-expressions\ngenerally represent the actual emotion of a person, as it is a spontaneous\nreaction expressed through human face. Despite of a few attempts made for\nrecognizing micro-expressions, still the problem is far from being a solved\nproblem, which is depicted by the poor rate of accuracy shown by the\nstate-of-the-art methods. A few CNN based approaches are found in the\nliterature to recognize micro-facial expressions from still images. Whereas, a\nspontaneous micro-expression video contains multiple frames that have to be\nprocessed together to encode both spatial and temporal information. This paper\nproposes two 3D-CNN methods: MicroExpSTCNN and MicroExpFuseNet, for spontaneous\nfacial micro-expression recognition by exploiting the spatiotemporal\ninformation in CNN framework. The MicroExpSTCNN considers the full spatial\ninformation, whereas the MicroExpFuseNet is based on the 3D-CNN feature fusion\nof the eyes and mouth regions. The experiments are performed over CAS(ME)^2 and\nSMIC micro-expression databases. The proposed MicroExpSTCNN model outperforms\nthe state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 13:45:49 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Reddy", "Sai Prasanna Teja", ""], ["Karri", "Surya Teja", ""], ["Dubey", "Shiv Ram", ""], ["Mukherjee", "Snehasis", ""]]}, {"id": "1904.01705", "submitter": "Michael Klachko", "authors": "Michael Klachko, Mohammad Reza Mahmoodi, and Dmitri B. Strukov", "title": "Improving Noise Tolerance of Mixed-Signal Neural Networks", "comments": "Accepted for publication in IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed-signal hardware accelerators for deep learning achieve orders of\nmagnitude better power efficiency than their digital counterparts. In the\nultra-low power consumption regime, limited signal precision inherent to analog\ncomputation becomes a challenge. We perform a case study of a 6-layer\nconvolutional neural network running on a mixed-signal accelerator and evaluate\nits sensitivity to hardware specific noise. We apply various methods to improve\nnoise robustness of the network and demonstrate an effective way to optimize\nuseful signal ranges through adaptive signal clipping. The resulting model is\nrobust enough to achieve 80.2% classification accuracy on CIFAR-10 dataset with\njust 1.4 mW power budget, while 6 mW budget allows us to achieve 87.1%\naccuracy, which is within 1% of the software baseline. For comparison, the\nunoptimized version of the same model achieves only 67.7% accuracy at 1.4 mW\nand 78.6% at 6 mW.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 23:24:18 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Klachko", "Michael", ""], ["Mahmoodi", "Mohammad Reza", ""], ["Strukov", "Dmitri B.", ""]]}, {"id": "1904.01709", "submitter": "Anil Yaman", "authors": "Anil Yaman, Giovanni Iacca, Decebal Constantin Mocanu, Matt Coler,\n  George Fletcher, Mykola Pechenizkiy", "title": "Evolving Plasticity for Autonomous Learning under Changing Environmental\n  Conditions", "comments": "Evolutionary Computation Journal", "journal-ref": "Evolutionary Computation 1 25, 2020", "doi": "10.1162/evco_a_00286", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental aspect of learning in biological neural networks is the\nplasticity property which allows them to modify their configurations during\ntheir lifetime. Hebbian learning is a biologically plausible mechanism for\nmodeling the plasticity property in artificial neural networks (ANNs), based on\nthe local interactions of neurons. However, the emergence of a coherent global\nlearning behavior from local Hebbian plasticity rules is not very well\nunderstood. The goal of this work is to discover interpretable local Hebbian\nlearning rules that can provide autonomous global learning. To achieve this, we\nuse a discrete representation to encode the learning rules in a finite search\nspace. These rules are then used to perform synaptic changes, based on the\nlocal interactions of the neurons. We employ genetic algorithms to optimize\nthese rules to allow learning on two separate tasks (a foraging and a\nprey-predator scenario) in online lifetime learning settings. The resulting\nevolved rules converged into a set of well-defined interpretable types, that\nare thoroughly discussed. Notably, the performance of these rules, while\nadapting the ANNs during the learning tasks, is comparable to that of offline\nlearning methods such as hill climbing.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 23:45:14 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 17:36:09 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 17:00:17 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Yaman", "Anil", ""], ["Iacca", "Giovanni", ""], ["Mocanu", "Decebal Constantin", ""], ["Coler", "Matt", ""], ["Fletcher", "George", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1904.01736", "submitter": "Nathalia Moraes do Nascimento", "authors": "Nathalia Nascimento, Carlos Lucena, Paulo Alencar and Carlos Juliano\n  Viana", "title": "Testing Self-Organizing Multiagent Systems", "comments": "9 pages, double column", "journal-ref": null, "doi": "10.1109/ACCESS.2020.3036668", "report-no": null, "categories": "cs.MA cs.NE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiagent Systems (MASs) involve different characteristics, such as\nautonomy, asynchronous and social features, which make these systems more\ndifficult to understand. Thus, there is a lack of procedures guaranteeing that\nmultiagent systems would behave as desired. Further complicating the situation\nis the fact that current agent-based approaches may also involve\nnon-deterministic characteristics, such as learning, self-adaptation and\nself-organization (SASO). Nonetheless, there is a gap in the literature\nregarding the testing of systems with these features. This paper presents a\npublish-subscribe-based approach to develop test applications that facilitate\nthe process of failure diagnosis in a self-organizing MAS. These tests are able\nto detect failures at the global behavior of the system or at the local\nproperties of its parts. To illustrate the use of this approach, we developed a\nself-organizing MAS system based on the context of the Internet of Things\n(IoT), which simulates a set of smart street lights, and we performed\nfunctional ad-hoc tests. The street lights need to interact with each other in\norder to achieve the global goals of reducing the energy consumption and\nmaintaining the maximum visual comfort in illuminated areas. To achieve these\nglobal behaviors, the street lights develop local behaviors automatically\nthrough a self-organizing process based on machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 01:33:49 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Nascimento", "Nathalia", ""], ["Lucena", "Carlos", ""], ["Alencar", "Paulo", ""], ["Viana", "Carlos Juliano", ""]]}, {"id": "1904.01908", "submitter": "Pierre Falez", "authors": "Pierre Falez, Pierre Tirilly, Ioan Marius Bilasco, Philippe Devienne,\n  Pierre Boulet", "title": "Multi-layered Spiking Neural Network with Target Timestamp Threshold\n  Adaptation and STDP", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) are good candidates to produce\nultra-energy-efficient hardware. However, the performance of these models is\ncurrently behind traditional methods. Introducing multi-layered SNNs is a\npromising way to reduce this gap. We propose in this paper a new threshold\nadaptation system which uses a timestamp objective at which neurons should\nfire. We show that our method leads to state-of-the-art classification rates on\nthe MNIST dataset (98.60%) and the Faces/Motorbikes dataset (99.46%) with an\nunsupervised SNN followed by a linear SVM. We also investigate the sparsity\nlevel of the network by testing different inhibition policies and STDP rules.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 10:47:34 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Falez", "Pierre", ""], ["Tirilly", "Pierre", ""], ["Bilasco", "Ioan Marius", ""], ["Devienne", "Philippe", ""], ["Boulet", "Pierre", ""]]}, {"id": "1904.01947", "submitter": "Mark Rowan", "authors": "Nataliya Le Vine, Matthew Zeigenfuse, Mark Rowan", "title": "Extracting Tables from Documents using Conditional Generative\n  Adversarial Networks and Genetic Algorithms", "comments": "8 pages, 5 figures. Published at IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting information from tables in documents presents a significant\nchallenge in many industries and in academic research. Existing methods which\ntake a bottom-up approach of integrating lines into cells and rows or columns\nneglect the available prior information relating to table structure. Our\nproposed method takes a top-down approach, first using a generative adversarial\nnetwork to map a table image into a standardised `skeleton' table form denoting\nthe approximate row and column borders without table content, then fitting\nrenderings of candidate latent table structures to the skeleton structure using\na distance measure optimised by a genetic algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 12:12:03 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Vine", "Nataliya Le", ""], ["Zeigenfuse", "Matthew", ""], ["Rowan", "Mark", ""]]}, {"id": "1904.02050", "submitter": "Marco Virgolin", "authors": "Marco Virgolin, Tanja Alderliesten, Cees Witteveen, Peter A.N. Bosman", "title": "Improving Model-based Genetic Programming for Symbolic Regression of\n  Small Expressions", "comments": "fix NMSE definition (it is 100xMSE/var instead of MSE/var)", "journal-ref": null, "doi": "10.1162/evco_a_00278", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Gene-pool Optimal Mixing Evolutionary Algorithm (GOMEA) is a model-based\nEA framework that has been shown to perform well in several domains, including\nGenetic Programming (GP). Differently from traditional EAs where variation acts\nblindly, GOMEA learns a model of interdependencies within the genotype, i.e.,\nthe linkage, to estimate what patterns to propagate. In this article, we study\nthe role of Linkage Learning (LL) performed by GOMEA in Symbolic Regression\n(SR). We show that the non-uniformity in the distribution of the genotype in GP\npopulations negatively biases LL, and propose a method to correct for this. We\nalso propose approaches to improve LL when ephemeral random constants are used.\nFurthermore, we adapt a scheme of interleaving runs to alleviate the burden of\ntuning the population size, a crucial parameter for LL, to SR. We run\nexperiments on 10 real-world datasets, enforcing a strict limitation on\nsolution size, to enable interpretability. We find that the new LL method\noutperforms the standard one, and that GOMEA outperforms both traditional and\nsemantic GP. We also find that the small solutions evolved by GOMEA are\ncompetitive with tuned decision trees, making GOMEA a promising new approach to\nSR.\n", "versions": [{"version": "v1", "created": "Wed, 3 Apr 2019 15:16:07 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 09:24:29 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2019 10:25:00 GMT"}, {"version": "v4", "created": "Fri, 5 Mar 2021 16:24:49 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Virgolin", "Marco", ""], ["Alderliesten", "Tanja", ""], ["Witteveen", "Cees", ""], ["Bosman", "Peter A. N.", ""]]}, {"id": "1904.02338", "submitter": "Maruan Al-Shedivat", "authors": "Maruan Al-Shedivat and Ankur P. Parikh", "title": "Consistency by Agreement in Zero-shot Neural Machine Translation", "comments": "NAACL 2019 (14 pages, 5 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalization and reliability of multilingual translation often highly\ndepend on the amount of available parallel data for each language pair of\ninterest. In this paper, we focus on zero-shot generalization---a challenging\nsetup that tests models on translation directions they have not been optimized\nfor at training time. To solve the problem, we (i) reformulate multilingual\ntranslation as probabilistic inference, (ii) define the notion of zero-shot\nconsistency and show why standard training often results in models unsuitable\nfor zero-shot tasks, and (iii) introduce a consistent agreement-based training\nmethod that encourages the model to produce equivalent translations of parallel\nsentences in auxiliary languages. We test our multilingual NMT models on\nmultiple public zero-shot translation benchmarks (IWSLT17, UN corpus, Europarl)\nand show that agreement-based learning often results in 2-3 BLEU zero-shot\nimprovement over strong baselines without any loss in performance on supervised\ntranslation directions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 03:49:05 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 04:00:03 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Al-Shedivat", "Maruan", ""], ["Parikh", "Ankur P.", ""]]}, {"id": "1904.02345", "submitter": "Ayman Elgharabawy", "authors": "Ayman Elgharabawy", "title": "Preference Neural Network", "comments": "The current content is inappropriate and requires to be\n  comprehensively reviewed again", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a preference neural network (PNN) to address the problem\nof indifference preferences orders with new activation function. PNN also\nsolves the Multi-label ranking problem, where labels may have indifference\npreference orders or subgroups are equally ranked. PNN follows a multi-layer\nfeedforward architecture with fully connected neurons. Each neuron contains a\nnovel smooth stairstep activation function based on the number of preference\norders. PNN inputs represent data features and output neurons represent label\nindexes. The proposed PNN is evaluated using new preference mining dataset that\ncontains repeated label values which have not experimented before. PNN\noutperforms five previously proposed methods for strict label ranking in terms\nof accurate results with high computational efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 04:47:02 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 03:13:53 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Elgharabawy", "Ayman", ""]]}, {"id": "1904.02397", "submitter": "Yinyan Zhang", "authors": "Yinyan Zhang, Shuai Li, and Bin Xu", "title": "Convergence analysis of beetle antennae search algorithm and its\n  applications", "comments": "no", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The beetle antennae search algorithm was recently proposed and investigated\nfor solving global optimization problems. Although the performance of the\nalgorithm and its variants were shown to be better than some existing\nmeta-heuristic algorithms, there is still a lack of convergence analysis. In\nthis paper, we provide theoretical analysis on the convergence of the beetle\nantennae search algorithm. We test the performance of the BAS algorithm via\nsome representative benchmark functions. Meanwhile, some applications of the\nBAS algorithm are also presented.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 07:52:56 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Zhang", "Yinyan", ""], ["Li", "Shuai", ""], ["Xu", "Bin", ""]]}, {"id": "1904.02435", "submitter": "Kai Olav Ellefsen", "authors": "Kai Olav Ellefsen and Jim Torresen", "title": "Self-Adapting Goals Allow Transfer of Predictive Models to New Tasks", "comments": "Accepted for publication in the proceedings of the 2019 Symposium of\n  the Norwegian AI Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long-standing challenge in Reinforcement Learning is enabling agents to\nlearn a model of their environment which can be transferred to solve other\nproblems in a world with the same underlying rules. One reason this is\ndifficult is the challenge of learning accurate models of an environment. If\nsuch a model is inaccurate, the agent's plans and actions will likely be\nsub-optimal, and likely lead to the wrong outcomes. Recent progress in\nmodel-based reinforcement learning has improved the ability for agents to learn\nand use predictive models. In this paper, we extend a recent deep learning\narchitecture which learns a predictive model of the environment that aims to\npredict only the value of a few key measurements, which are be indicative of an\nagent's performance. Predicting only a few measurements rather than the entire\nfuture state of an environment makes it more feasible to learn a valuable\npredictive model. We extend this predictive model with a small, evolving neural\nnetwork that suggests the best goals to pursue in the current state. We\ndemonstrate that this allows the predictive model to transfer to new scenarios\nwhere goals are different, and that the adaptive goals can even adjust agent\nbehavior on-line, changing its strategy to fit the current context.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 09:52:18 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 11:36:20 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Ellefsen", "Kai Olav", ""], ["Torresen", "Jim", ""]]}, {"id": "1904.02478", "submitter": "Jacopo Castellini", "authors": "Jacopo Castellini", "title": "Learning Numeracy: Binary Arithmetic with Neural Turing Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main problems encountered so far with recurrent neural networks is\nthat they struggle to retain long-time information dependencies in their\nrecurrent connections. Neural Turing Machines (NTMs) attempt to mitigate this\nissue by providing the neural network with an external portion of memory, in\nwhich information can be stored and manipulated later on. The whole mechanism\nis differentiable end-to-end, allowing the network to learn how to utilise this\nlong-term memory via stochastic gradient descent. This allows NTMs to infer\nsimple algorithms directly from data sequences. Nonetheless, the model can be\nhard to train due to a large number of parameters and interacting components\nand little related work is present. In this work we use NTMs to learn and\ngeneralise two arithmetical tasks: binary addition and multiplication. These\ntasks are two fundamental algorithmic examples in computer science, and are a\nlot more challenging than the previously explored ones, with which we aim to\nshed some light on the real capabilities on this neural model.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 11:00:11 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 12:10:29 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Castellini", "Jacopo", ""]]}, {"id": "1904.02807", "submitter": "Jeffrey Shainline", "authors": "Jeffrey M. Shainline", "title": "Fluxonic Processing of Photonic Synapse Events", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of the information processing performed by a neuron occurs in the\ndendritic tree. For neural systems using light for communication, it is\nadvantageous to convert signals to the electronic domain at synaptic terminals\nso dendritic computation can be performed with electrical circuits. Here we\npresent circuits based on Josephson junctions and mutual inductors that act as\ndendrites, processing signals from synapses receiving single-photon\ncommunication events with superconducting detectors. We show simulations of\ncircuits performing basic temporal filtering, logical operations, and nonlinear\ntransfer functions. We further show how the synaptic signal from a\nsingle-photon can fan out locally in the electronic domain to enable the\ndendrites of the receiving neuron to process a photonic synapse event or pulse\ntrain in multiple different ways simultaneously. Such a technique makes\nefficient use of photons, energy, space, and information.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 22:09:59 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Shainline", "Jeffrey M.", ""]]}, {"id": "1904.02830", "submitter": "Konstantinos Krommydas", "authors": "Ruchira Sasanka, Konstantinos Krommydas", "title": "An Evolutionary Framework for Automatic and Guided Discovery of\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Automatic Algorithm Discoverer (AAD), an evolutionary\nframework for synthesizing programs of high complexity. To guide evolution,\nprior evolutionary algorithms have depended on fitness (objective) functions,\nwhich are challenging to design. To make evolutionary progress, instead, AAD\nemploys Problem Guided Evolution (PGE), which requires introduction of a group\nof problems together. With PGE, solutions discovered for simpler problems are\nused to solve more complex problems in the same group. PGE also enables several\nnew evolutionary strategies, and naturally yields to High-Performance Computing\n(HPC) techniques.\n  We find that PGE and related evolutionary strategies enable AAD to discover\nalgorithms of similar or higher complexity relative to the state-of-the-art.\nSpecifically, AAD produces Python code for 29 array/vector problems ranging\nfrom min, max, reverse, to more challenging problems like sorting and\nmatrix-vector multiplication. Additionally, we find that AAD shows adaptability\nto constrained environments/inputs and demonstrates outside-of-the-box problem\nsolving abilities.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 00:03:23 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Sasanka", "Ruchira", ""], ["Krommydas", "Konstantinos", ""]]}, {"id": "1904.03137", "submitter": "Oleksiy Ostapenko", "authors": "Oleksiy Ostapenko, Mihai Puscas, Tassilo Klein, Patrick J\\\"ahnichen,\n  Moin Nabi", "title": "Learning to Remember: A Synaptic Plasticity Driven Framework for\n  Continual Learning", "comments": "CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models trained in the context of continual learning (CL) should be able to\nlearn from a stream of data over an undefined period of time. The main\nchallenges herein are: 1) maintaining old knowledge while simultaneously\nbenefiting from it when learning new tasks, and 2) guaranteeing model\nscalability with a growing amount of data to learn from. In order to tackle\nthese challenges, we introduce Dynamic Generative Memory (DGM) - a synaptic\nplasticity driven framework for continual learning. DGM relies on conditional\ngenerative adversarial networks with learnable connection plasticity realized\nwith neural masking. Specifically, we evaluate two variants of neural masking:\napplied to (i) layer activations and (ii) to connection weights directly.\nFurthermore, we propose a dynamic network expansion mechanism that ensures\nsufficient model capacity to accommodate for continually incoming tasks. The\namount of added capacity is determined dynamically from the learned binary\nmask. We evaluate DGM in the continual class-incremental setup on visual\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 16:02:15 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 07:23:22 GMT"}, {"version": "v3", "created": "Wed, 12 Jun 2019 16:28:09 GMT"}, {"version": "v4", "created": "Mon, 2 Dec 2019 14:46:07 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Ostapenko", "Oleksiy", ""], ["Puscas", "Mihai", ""], ["Klein", "Tassilo", ""], ["J\u00e4hnichen", "Patrick", ""], ["Nabi", "Moin", ""]]}, {"id": "1904.03152", "submitter": "Dhruv Khandelwal", "authors": "Dhruv Khandelwal, Maarten Schoukens, Roland T\\'oth", "title": "Data-driven Modelling of Dynamical Systems Using Tree Adjoining Grammar\n  and Genetic Programming", "comments": "Paper accepted at IEEE CEC 2019", "journal-ref": null, "doi": "10.1109/CEC.2019.8790250", "report-no": null, "categories": "cs.SY cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art methods for data-driven modelling of non-linear dynamical\nsystems typically involve interactions with an expert user. In order to\npartially automate the process of modelling physical systems from data, many\nEA-based approaches have been proposed for model-structure selection, with\nspecial focus on non-linear systems. Recently, an approach for data-driven\nmodelling of non-linear dynamical systems using Genetic Programming (GP) was\nproposed. The novelty of the method was the modelling of noise and the use of\nTree Adjoining Grammar to shape the search-space explored by GP. In this paper,\nwe report results achieved by the proposed method on three case studies. Each\nof the case studies considered here is based on real physical systems. The case\nstudies pose a variety of challenges. In particular, these challenges range\nover varying amounts of prior knowledge of the true system, amount of data\navailable, the complexity of the dynamics of the system, and the nature of\nnon-linearities in the system. Based on the results achieved for the case\nstudies, we critically analyse the performance of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 16:42:44 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Khandelwal", "Dhruv", ""], ["Schoukens", "Maarten", ""], ["T\u00f3th", "Roland", ""]]}, {"id": "1904.03178", "submitter": "Joseph Early", "authors": "Joseph Early", "title": "Reducing catastrophic forgetting when evolving neural networks", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key stepping stone in the development of an artificial general intelligence\n(a machine that can perform any task), is the production of agents that can\nperform multiple tasks at once instead of just one. Unfortunately, canonical\nmethods are very prone to catastrophic forgetting (CF) - the act of overwriting\nprevious knowledge about a task when learning a new task. Recent efforts have\ndeveloped techniques for overcoming CF in learning systems, but no attempt has\nbeen made to apply these new techniques to evolutionary systems. This research\npresents a novel technique, weight protection, for reducing CF in evolutionary\nsystems by adapting a method from learning systems. It is used in conjunction\nwith other evolutionary approaches for overcoming CF and is shown to be\neffective at alleviating CF when applied to a suite of reinforcement learning\ntasks. It is speculated that this work could indicate the potential for a wider\napplication of existing learning-based approaches to evolutionary systems and\nthat evolutionary techniques may be competitive with or better than learning\nsystems when it comes to reducing CF.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 17:57:29 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Early", "Joseph", ""]]}, {"id": "1904.03368", "submitter": "Fengyang Sun", "authors": "Aftab Anjum, Fengyang Sun, Lin Wang, and Jeff Orchard", "title": "A Novel Neural Network-Based Symbolic Regression Method: Neuro-Encoded\n  Expression Programming", "comments": "14 pages, 4 figures, 2 tables, has been published on ICANN 2019, 28th\n  International Conference on Artificial Neural Networks, pp. 373-386, 2019", "journal-ref": null, "doi": "10.1007/978-3-030-30484-3_31", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Neuro-encoded expression programming(NEEP) that aims to offer a novel\ncontinuous representation of combinatorial encoding for genetic programming\nmethods is proposed in this paper. Genetic programming with linear\nrepresentation uses nature-inspired operators (e.g., crossover, mutation) to\ntune expressions and finally search out the best explicit function to simulate\ndata. The encoding mechanism is essential for genetic programmings to find a\ndesirable solution efficiently. However, the linear representation methods\nmanipulate the expression tree in discrete solution space, where a small change\nof the input can cause a large change of the output. The unsmooth landscapes\ndestroy the local information and make difficulty in searching. The\nneuro-encoded expression programming constructs the gene string with recurrent\nneural network (RNN) and the weights of the network are optimized by powerful\ncontinuous evolutionary algorithms. The neural network mappings smoothen the\nsharp fitness landscape and provide rich neighborhood information to find the\nbest expression. The experiments indicate that the novel approach improves\ntraining efficiency and reduces test errors on several well-known symbolic\nregression problems.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 05:49:19 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 08:25:48 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Anjum", "Aftab", ""], ["Sun", "Fengyang", ""], ["Wang", "Lin", ""], ["Orchard", "Jeff", ""]]}, {"id": "1904.03491", "submitter": "Rahul-Vigneswaran K", "authors": "Rahul-Vigneswaran K, Prabaharan Poornachandran and Soman KP", "title": "A Compendium on Network and Host based Intrusion Detection Systems", "comments": "8 pages, Accepted for ICDSMLA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The techniques of deep learning have become the state of the art methodology\nfor executing complicated tasks from various domains of computer vision,\nnatural language processing, and several other areas. Due to its rapid\ndevelopment and promising benchmarks in those fields, researchers started\nexperimenting with this technique to perform in the area of, especially in\nintrusion detection related tasks. Deep learning is a subset and a natural\nextension of classical Machine learning and an evolved model of neural\nnetworks. This paper contemplates and discusses all the methodologies related\nto the leading edge Deep learning and Neural network models purposing to the\narena of Intrusion Detection Systems.\n", "versions": [{"version": "v1", "created": "Sat, 6 Apr 2019 16:45:42 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["K", "Rahul-Vigneswaran", ""], ["Poornachandran", "Prabaharan", ""], ["KP", "Soman", ""]]}, {"id": "1904.03603", "submitter": "Mohamed Osama Ahmed", "authors": "Ramy Hussein, Mohamed Osama Ahmed, Rabab Ward, Z. Jane Wang, Levin\n  Kuhlmann, and Yi Guo", "title": "Human Intracranial EEG Quantitative Analysis and Automatic Feature\n  Learning for Epileptic Seizure Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: The aim of this study is to develop an efficient and reliable\nepileptic seizure prediction system using intracranial EEG (iEEG) data,\nespecially for people with drug-resistant epilepsy. The prediction procedure\nshould yield accurate results in a fast enough fashion to alert patients of\nimpending seizures. Methods: We quantitatively analyze the human iEEG data to\nobtain insights into how the human brain behaves before and between epileptic\nseizures. We then introduce an efficient pre-processing method for reducing the\ndata size and converting the time-series iEEG data into an image-like format\nthat can be used as inputs to convolutional neural networks (CNNs). Further, we\npropose a seizure prediction algorithm that uses cooperative multi-scale CNNs\nfor automatic feature learning of iEEG data. Results: 1) iEEG channels contain\ncomplementary information and excluding individual channels is not advisable to\nretain the spatial information needed for accurate prediction of epileptic\nseizures. 2) The traditional PCA is not a reliable method for iEEG data\nreduction in seizure prediction. 3) Hand-crafted iEEG features may not be\nsuitable for reliable seizure prediction performance as the iEEG data varies\nbetween patients and over time for the same patient. 4) Seizure prediction\nresults show that our algorithm outperforms existing methods by achieving an\naverage sensitivity of 87.85% and AUC score of 0.84. Conclusion: Understanding\nhow the human brain behaves before seizure attacks and far from them\nfacilitates better designs of epileptic seizure predictors. Significance:\nAccurate seizure prediction algorithms can warn patients about the next seizure\nattack so they could avoid dangerous activities. Medications could then be\nadministered to abort the impending seizure and minimize the risk of injury.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 08:20:42 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Hussein", "Ramy", ""], ["Ahmed", "Mohamed Osama", ""], ["Ward", "Rabab", ""], ["Wang", "Z. Jane", ""], ["Kuhlmann", "Levin", ""], ["Guo", "Yi", ""]]}, {"id": "1904.03673", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Jiaoyang Huang, Leslie Pack Kaelbling", "title": "Every Local Minimum Value is the Global Minimum Value of Induced Model\n  in Non-convex Machine Learning", "comments": "Neural computation, MIT press", "journal-ref": "Neural computation, volume 31, pages 2293-2323, MIT press, 2019", "doi": "10.1162/neco_a_01234", "report-no": null, "categories": "stat.ML cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For nonconvex optimization in machine learning, this article proves that\nevery local minimum achieves the globally optimal value of the perturbable\ngradient basis model at any differentiable point. As a result, nonconvex\nmachine learning is theoretically as supported as convex machine learning with\na handcrafted basis in terms of the loss at differentiable local minima, except\nin the case when a preference is given to the handcrafted basis over the\nperturbable gradient basis. The proofs of these results are derived under mild\nassumptions. Accordingly, the proven results are directly applicable to many\nmachine learning models, including practical deep neural networks, without any\nmodification of practical methods. Furthermore, as special cases of our general\nresults, this article improves or complements several state-of-the-art\ntheoretical results on deep neural networks, deep residual networks, and\noverparameterized deep neural networks with a unified proof technique and novel\ngeometric insights. A special case of our results also contributes to the\ntheoretical foundation of representation learning.\n", "versions": [{"version": "v1", "created": "Sun, 7 Apr 2019 15:43:59 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 06:00:53 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 23:04:15 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Huang", "Jiaoyang", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "1904.03814", "submitter": "Sungjoo Ha", "authors": "Seungwoo Choi, Seokjun Seo, Beomjun Shin, Hyeongmin Byun, Martin\n  Kersner, Beomsu Kim, Dongyoung Kim, Sungjoo Ha", "title": "Temporal Convolution for Real-time Keyword Spotting on Mobile Devices", "comments": "In INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.NE eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword spotting (KWS) plays a critical role in enabling speech-based user\ninteractions on smart devices. Recent developments in the field of deep\nlearning have led to wide adoption of convolutional neural networks (CNNs) in\nKWS systems due to their exceptional accuracy and robustness. The main\nchallenge faced by KWS systems is the trade-off between high accuracy and low\nlatency. Unfortunately, there has been little quantitative analysis of the\nactual latency of KWS models on mobile devices. This is especially concerning\nsince conventional convolution-based KWS approaches are known to require a\nlarge number of operations to attain an adequate level of performance. In this\npaper, we propose a temporal convolution for real-time KWS on mobile devices.\nUnlike most of the 2D convolution-based KWS approaches that require a deep\narchitecture to fully capture both low- and high-frequency domains, we exploit\ntemporal convolutions with a compact ResNet architecture. In Google Speech\nCommand Dataset, we achieve more than \\textbf{385x} speedup on Google Pixel 1\nand surpass the accuracy compared to the state-of-the-art model. In addition,\nwe release the implementation of the proposed and the baseline models including\nan end-to-end pipeline for training models and evaluating them on mobile\ndevices.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 03:21:11 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 06:16:42 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Choi", "Seungwoo", ""], ["Seo", "Seokjun", ""], ["Shin", "Beomjun", ""], ["Byun", "Hyeongmin", ""], ["Kersner", "Martin", ""], ["Kim", "Beomsu", ""], ["Kim", "Dongyoung", ""], ["Ha", "Sungjoo", ""]]}, {"id": "1904.03816", "submitter": "Sungjoo Ha", "authors": "Seokjun Seo, Seungwoo Choi, Martin Kersner, Beomjun Shin, Hyungsuk\n  Yoon, Hyeongmin Byun, Sungjoo Ha", "title": "Towards Real-Time Automatic Portrait Matting on Mobile Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of automatic portrait matting on mobile devices. The\nproposed model is aimed at attaining real-time inference on mobile devices with\nminimal degradation of model performance. Our model MMNet, based on\nmulti-branch dilated convolution with linear bottleneck blocks, outperforms the\nstate-of-the-art model and is orders of magnitude faster. The model can be\naccelerated four times to attain 30 FPS on Xiaomi Mi 5 device with moderate\nincrease in the gradient error. Under the same conditions, our model has an\norder of magnitude less number of parameters and is faster than Mobile\nDeepLabv3 while maintaining comparable performance. The accompanied\nimplementation can be found at \\url{https://github.com/hyperconnect/MMNet}.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 03:21:25 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Seo", "Seokjun", ""], ["Choi", "Seungwoo", ""], ["Kersner", "Martin", ""], ["Shin", "Beomjun", ""], ["Yoon", "Hyungsuk", ""], ["Byun", "Hyeongmin", ""], ["Ha", "Sungjoo", ""]]}, {"id": "1904.03819", "submitter": "Zhiheng Huang", "authors": "Zhiheng Huang and Bing Xiang", "title": "WeNet: Weighted Networks for Recurrent Network Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been increasing demand for automatic architecture\nsearch in deep learning. Numerous approaches have been proposed and led to\nstate-of-the-art results in various applications, including image\nclassification and language modeling. In this paper, we propose a novel way of\narchitecture search by means of weighted networks (WeNet), which consist of a\nnumber of networks, with each assigned a weight. These weights are updated with\nback-propagation to reflect the importance of different networks. Such weighted\nnetworks bear similarity to mixture of experts. We conduct experiments on Penn\nTreebank and WikiText-2. We show that the proposed WeNet can find recurrent\narchitectures which result in state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 03:35:07 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Huang", "Zhiheng", ""], ["Xiang", "Bing", ""]]}, {"id": "1904.04036", "submitter": "Jia Liu", "authors": "Jia Liu, Maoguo Gong, Haibo He", "title": "Nucleus Neural Network: A Data-driven Self-organized Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Artificial neural networks which are inspired from the learning mechanism of\nbrain have achieved great successes in many problems, especially those with\ndeep layers. In this paper, we propose a nucleus neural network (NNN) and\ncorresponding connecting architecture learning method. In a nucleus, there are\nno regular layers, i.e., a neuron may connect to all the neurons in the\nnucleus. This type of architecture gets rid of layer limitation and may lead to\nmore powerful learning capability. It is crucial to determine the connections\nbetween them given numerous neurons. Based on the principle that more relevant\ninput and output neuron pair deserves higher connecting density, we propose an\nefficient architecture learning model for the nucleus. Moreover, we improve the\nlearning method for connecting weights and biases given the optimized\narchitecture. We find that this novel architecture is robust to irrelevant\ncomponents in test data. So we reconstruct a new dataset based on the MNIST\ndataset where the types of digital backgrounds in training and test sets are\ndifferent. Experiments demonstrate that the proposed learner achieves\nsignificant improvement over traditional learners on the reconstructed data\nset.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 13:03:50 GMT"}, {"version": "v2", "created": "Tue, 14 May 2019 14:06:05 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Liu", "Jia", ""], ["Gong", "Maoguo", ""], ["He", "Haibo", ""]]}, {"id": "1904.04156", "submitter": "Saugat Bhattacharyya", "authors": "Monalisa Pal, Sanghamitra Bandyopadhyay and Saugat Bhattacharyya", "title": "A Many Objective Optimization Approach for Transfer Learning in EEG\n  Classification", "comments": "Pre-submission work", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In Brain-Computer Interfacing (BCI), due to inter-subject non-stationarities\nof electroencephalogram (EEG), classifiers are trained and tested using EEG\nfrom the same subject. When physical disabilities bottleneck the natural\nmodality of performing a task, acquisition of ample training data is difficult\nwhich practically obstructs classifier training. Previous works have tackled\nthis problem by generalizing the feature space amongst multiple subjects\nincluding the test subject. This work aims at knowledge transfer to classify\nEEG of the target subject using a classifier trained with the EEG of another\nunit source subject. A many-objective optimization framework is proposed where\noptimal weights are obtained for projecting features in another dimension such\nthat single source-trained target EEG classification performance is maximized\nwith the modified features. To validate the approach, motor imagery tasks from\nthe BCI Competition III Dataset IVa are classified using power spectral density\nbased features and linear support vector machine. Several performance metrics,\nimprovement in accuracy, sensitivity to the dimension of the projected space,\nassess the efficacy of the proposed approach. Addressing single-source training\npromotes independent living of differently-abled individuals by reducing\nassistance from others. The proposed approach eliminates the requirement of EEG\nfrom multiple source subjects and is applicable to any existing feature\nextractors and classifiers. Source code is available at\nhttp://worksupplements.droppages.com/tlbci.html.\n", "versions": [{"version": "v1", "created": "Thu, 4 Apr 2019 13:28:24 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Pal", "Monalisa", ""], ["Bandyopadhyay", "Sanghamitra", ""], ["Bhattacharyya", "Saugat", ""]]}, {"id": "1904.04203", "submitter": "Marcos Oliveira", "authors": "Lydia Taw, Nishant Gurrapadi, Mariana Macedo, Marcos Oliveira, Diego\n  Pinheiro, Carmelo Bastos-Filho, Ronaldo Menezes", "title": "Characterizing the Social Interactions in the Artificial Bee Colony\n  Algorithm", "comments": "9 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational swarm intelligence consists of multiple artificial simple\nagents exchanging information while exploring a search space. Despite a rich\nliterature in the field, with works improving old approaches and proposing new\nones, the mechanism by which complex behavior emerges in these systems is still\nnot well understood. This literature gap hinders the researchers' ability to\ndeal with known problems in swarms intelligence such as premature convergence,\nand the balance of coordination and diversity among agents. Recent advances in\nthe literature, however, have proposed to study these systems via the network\nthat emerges from the social interactions within the swarm (i.e., the\ninteraction network). In our work, we propose a definition of the interaction\nnetwork for the Artificial Bee Colony (ABC) algorithm. With our approach, we\ncaptured striking idiosyncrasies of the algorithm. We uncovered the different\npatterns of social interactions that emerge from each type of bee, revealing\nthe importance of the bees variations throughout the iterations of the\nalgorithm. We found that ABC exhibits a dynamic information flow through the\nuse of different bees but lacks continuous coordination between the agents.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 17:21:14 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Taw", "Lydia", ""], ["Gurrapadi", "Nishant", ""], ["Macedo", "Mariana", ""], ["Oliveira", "Marcos", ""], ["Pinheiro", "Diego", ""], ["Bastos-Filho", "Carmelo", ""], ["Menezes", "Ronaldo", ""]]}, {"id": "1904.04377", "submitter": "Tarik A. Rashid", "authors": "Tarik A. Rashid and Hawraz A. Ahmad", "title": "Lecturer Performance System Using Neural Network with Particle Swarm\n  Optimization", "comments": "20 pages", "journal-ref": "Computer Applications in Engineering Education. Wiley publication,\n  2016", "doi": "10.1002/cae.21737", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The field of analyzing performance is very important and sensitive in\nparticular when it is related to the performance of lecturers in academic\ninstitutions. Locating the weak points of lecturers through a system that\nprovides an early warning to notify or reward the lecturers with warned or\npunished notices will help them to improve their weaknesses, leads to a better\nquality in the institutions. The current system has major issues in the higher\neducation at Salahaddin University-Erbil (SUE) in Kurdistan-Iraq. These issues\nare: first, the assessment of lecturers' activities is conducted traditionally\nvia the Quality Assurance Teams at different departments and colleges at the\nuniversity, second, the outcomes in some cases of lecturers' performance\nprovoke a low level of acceptance among lectures, as these cases are reflected\nand viewed by some academic communities as unfair cases, and finally, the\ncurrent system is not accurate and vigorous. In this paper, Particle Swarm\nOptimization Neural Network is used to assess performance of lecturers in more\nfruitful way and also to enhance the accuracy of recognition system. Different\nreal and novel data sets are collected from SUE. The prepared datasets\npreprocessed and important features are then fed as input source to the\ntraining and testing phases. Particle Swarm Optimization is used to find the\nbest weights and biases in the training phase of the neural network. The best\naccuracy rate obtained in the test phase is 98.28 %.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 21:58:05 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Rashid", "Tarik A.", ""], ["Ahmad", "Hawraz A.", ""]]}, {"id": "1904.04579", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "A Concept-Value Network as a Brain Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper suggests a statistical framework for describing the relations\nbetween the physical and conceptual entities of a brain-like model. In\nparticular, features and concept instances are put into context. This may help\nwith understanding or implementing a similar model. The paper suggests that\nfeatures are in fact the wiring. With this idea, the actual length of the\nconnection is important, because it is related to firing rates and neuron\nsynchronization. The paper then suggests that concepts are neuron groups that\nlink features and concept instances are the signals from those groups.\nTherefore, features become the static framework of the interconnected neural\nsystem and concepts are combinations of these, as determined by the external\nstimulus and the neural synaptic strengths. Along with this statistical model,\nit is possible to propose a simplified design for a neuron, based on an action\npotential and variable output signal. A strong comparison with Hebbian theory\nis then proposed, with some test results to support the theory.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 10:30:23 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 10:15:52 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "1904.04608", "submitter": "Carola Doerr", "authors": "Nguyen Dang and Carola Doerr", "title": "Hyper-Parameter Tuning for the (1+(\\lambda,\\lambda)) GA", "comments": "To appear at ACM Genetic and Evolutionary Computation Conference\n  (GECCO'19). This version has some additional plots and data", "journal-ref": null, "doi": "10.1145/3321707.3321725", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that the $(1+(\\lambda,\\lambda))$~Genetic Algorithm (GA) with\nself-adjusting parameter choices achieves a linear expected optimization time\non OneMax if its hyper-parameters are suitably chosen. However, it is not very\nwell understood how the hyper-parameter settings influences the overall\nperformance of the $(1+(\\lambda,\\lambda))$~GA. Analyzing such multi-dimensional\ndependencies precisely is at the edge of what running time analysis can offer.\nTo make a step forward on this question, we present an in-depth empirical study\nof the self-adjusting $(1+(\\lambda,\\lambda))$~GA and its hyper-parameters. We\nshow, among many other results, that a 15\\% reduction of the average running\ntime is possible by a slightly different setup, which allows non-identical\noffspring population sizes of mutation and crossover phase, and more\nflexibility in the choice of mutation rate and crossover bias --a\ngeneralization which may be of independent interest. We also show indication\nthat the parametrization of mutation rate and crossover bias derived by\ntheoretical means for the static variant of the $(1+(\\lambda,\\lambda))$~GA\nextends to the non-static case.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 11:47:33 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Dang", "Nguyen", ""], ["Doerr", "Carola", ""]]}, {"id": "1904.04734", "submitter": "Maximilian Alber", "authors": "Maximilian Alber", "title": "Software and application patterns for explanation methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks successfully pervaded many applications domains and are\nincreasingly used in critical decision processes. Understanding their workings\nis desirable or even required to further foster their potential as well as to\naccess sensitive domains like medical applications or autonomous driving. One\nkey to this broader usage of explaining frameworks is the accessibility and\nunderstanding of respective software. In this work we introduce software and\napplication patterns for explanation techniques that aim to explain individual\npredictions of neural networks. We discuss how to code well-known algorithms\nefficiently within deep learning software frameworks and describe how to embed\nalgorithms in downstream implementations. Building on this we show how\nexplanation methods can be used in applications to understand predictions for\nmiss-classified samples, to compare algorithms or networks, and to examine the\nfocus of networks. Furthermore, we review available open-source packages and\ndiscuss challenges posed by complex and evolving neural network structures to\nexplanation algorithm development and implementations.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 15:34:40 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Alber", "Maximilian", ""]]}, {"id": "1904.04754", "submitter": "Enrique Fernandez-Blanco", "authors": "Enrique Fernandez-Blanco, Daniel Rivero, Marcos Gestal, Carlos\n  Fernandez-Lozano, Norberto Ezquerra, Cristian R. Munteanu, Julian Dorado", "title": "A Hybrid Evolutionary System for Automated Artificial Neural Networks\n  Generation and Simplification in Biomedical Applications", "comments": "48 pages, 9 figures, 17 tables", "journal-ref": "Current Bioinformatics, Volume 10, Number 5, 2015, pp. 672-691(20)", "doi": "10.2174/1574893610666151008012923", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data mining and data classification over biomedical data are two of the most\nimportant research fields in computer science. Among the great diversity of\ntechniques that can be used for this purpose, Artifical Neural Networks (ANNs)\nis one of the most suited. One of the main problems in the development of this\ntechnique is the slow performance of the full process. Traditionally, in this\ndevelopment process, human experts are needed to experiment with different\narchitectural procedures until they find the one that presents the correct\nresults for solving a specific problem. However, many studies have emerged in\nwhich different ANN developmental techniques, more or less automated, are\ndescribed. In this paper, the authors have focused on developing a new\ntechnique to perform this process over biomedical data. The new technique is\ndescribed in which two Evolutionary Computation (EC) techniques are mixed to\nautomatically develop ANNs. These techniques are Genetic Algorithms and Genetic\nProgramming. The work goes further, and the system described here allows to\nobtain simplified networks with a low number of neurons to resolve the\nproblems. The system is compared with the already existent system which also\nuses EC over a set of well-known problems. The conclusions reached from these\ncomparisons indicate that this new system produces very good results, which in\nthe worst case are at least comparable to existing techniques and in many cases\nare substantially better.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 16:07:48 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Fernandez-Blanco", "Enrique", ""], ["Rivero", "Daniel", ""], ["Gestal", "Marcos", ""], ["Fernandez-Lozano", "Carlos", ""], ["Ezquerra", "Norberto", ""], ["Munteanu", "Cristian R.", ""], ["Dorado", "Julian", ""]]}, {"id": "1904.04805", "submitter": "Jacques Kaiser", "authors": "Jacques Kaiser, Alexander Friedrich, J. Camilo Vasquez Tieck, Daniel\n  Reichard, Arne Roennau, Emre Neftci, R\\\"udiger Dillmann", "title": "Embodied Neuromorphic Vision with Event-Driven Random Backpropagation", "comments": "v2: title update, better plots and wordings. 8 pages, 9 figures, 1\n  table, video: https://neurorobotics-files.net/index.php/s/sBQzWFrBPoH9Dx7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spike-based communication between biological neurons is sparse and\nunreliable. This enables the brain to process visual information from the eyes\nefficiently. Taking inspiration from biology, artificial spiking neural\nnetworks coupled with silicon retinas attempt to model these computations.\nRecent findings in machine learning allowed the derivation of a family of\npowerful synaptic plasticity rules approximating backpropagation for spiking\nnetworks. Are these rules capable of processing real-world visual sensory data?\nIn this paper, we evaluate the performance of Event-Driven Random\nBack-Propagation (eRBP) at learning representations from event streams provided\nby a Dynamic Vision Sensor (DVS). First, we show that eRBP matches\nstate-of-the-art performance on the DvsGesture dataset with the addition of a\nsimple covert attention mechanism. By remapping visual receptive fields\nrelatively to the center of the motion, this attention mechanism provides\ntranslation invariance at low computational cost compared to convolutions.\nSecond, we successfully integrate eRBP in a real robotic setup, where a robotic\narm grasps objects according to detected visual affordances. In this setup,\nvisual information is actively sensed by a DVS mounted on a robotic head\nperforming microsaccadic eye movements. We show that our method classifies\naffordances within 100ms after microsaccade onset, which is comparable to human\nperformance reported in behavioral study. Our results suggest that advances in\nneuromorphic technology and plasticity rules enable the development of\nautonomous robots operating at high speed and low energy consumption.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 17:35:24 GMT"}, {"version": "v2", "created": "Mon, 6 May 2019 12:56:48 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Kaiser", "Jacques", ""], ["Friedrich", "Alexander", ""], ["Tieck", "J. Camilo Vasquez", ""], ["Reichard", "Daniel", ""], ["Roennau", "Arne", ""], ["Neftci", "Emre", ""], ["Dillmann", "R\u00fcdiger", ""]]}, {"id": "1904.04867", "submitter": "Maxim Buzdalov", "authors": "Nina Bulanova, Maxim Buzdalov", "title": "Black-Box Complexity of the Binary Value Function", "comments": "24 pages, one figure. An extended two-page abstract of this work will\n  appear in proceedings of the Genetic and Evolutionary Computation Conference,\n  GECCO'19", "journal-ref": null, "doi": "10.1145/3319619.3322070", "report-no": null, "categories": "cs.NE cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The binary value function, or BinVal, has appeared in several studies in\ntheory of evolutionary computation as one of the extreme examples of linear\npseudo-Boolean functions. Its unbiased black-box complexity was previously\nshown to be at most $\\lceil \\log_2 n \\rceil + 2$, where $n$ is the problem\nsize. We augment it with an upper bound of $\\log_2 n + 2.42141558 - o(1)$,\nwhich is more precise for many values of $n$. We also present a lower bound of\n$\\log_2 n + 1.1186406 - o(1)$. Additionally, we prove that BinVal is an easiest\nfunction among all unimodal pseudo-Boolean functions at least for unbiased\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 18:54:36 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Bulanova", "Nina", ""], ["Buzdalov", "Maxim", ""]]}, {"id": "1904.05009", "submitter": "Charles Martin", "authors": "Charles P Martin and Jim Torresen", "title": "An Interactive Musical Prediction System with Mixture Density Recurrent\n  Neural Networks", "comments": "Accepted for presentation at the International Conference on New\n  Interfaces for Musical Expression (NIME), June 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.HC cs.NE eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is about creating digital musical instruments where a predictive\nneural network model is integrated into the interactive system. Rather than\npredicting symbolic music (e.g., MIDI notes), we suggest that predicting future\ncontrol data from the user and precise temporal information can lead to new and\ninteresting interactive possibilities. We propose that a mixture density\nrecurrent neural network (MDRNN) is an appropriate model for this task. The\npredictions can be used to fill-in control data when the user stops performing,\nor as a kind of filter on the user's own input. We present an interactive MDRNN\nprediction server that allows rapid prototyping of new NIMEs featuring\npredictive musical interaction by recording datasets, training MDRNN models,\nand experimenting with interaction modes. We illustrate our system with several\nexample NIMEs applying this idea. Our evaluation shows that real-time\npredictive interaction is viable even on single-board computers and that small\nmodels are appropriate for small datasets.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 05:50:15 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Martin", "Charles P", ""], ["Torresen", "Jim", ""]]}, {"id": "1904.05027", "submitter": "Enrique Fernandez-Blanco", "authors": "Daniel Rivero, Enrique Fernandez-Blanco, Julian Dorado, Alejandro\n  Pazos", "title": "Classification of Two-channel Signals by Means of Genetic Programming", "comments": "Conference paper, doble-column, 7 pages, 1 figure, 3 tables", "journal-ref": "Proceedings of Annual Conference on Genetic and Evolutionary\n  Computation 2015 (GECCO'15), pp. 1319-1325", "doi": "10.1145/2739482.2768507", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, signal classification is a process in which previous knowledge\nof the signals is needed. Human experts decide which features are extracted\nfrom the signals, and used as inputs to the classification system. This\nrequirement can make significant unknown information of the signal be missed by\nthe experts and not be included in the features. This paper proposes a new\nmethod that automatically analyses the signals and extracts the features\nwithout any human participation. Therefore, there is no need for previous\nknowledge about the signals to be classified. The proposed method is based on\nGenetic Programming and, in order to test this method, it has been applied to a\nwell-known EEG database related to epilepsy, a disease suffered by millions of\npeople. As the results section shows, high accuracies in classification are\nobtained\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 07:18:49 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Rivero", "Daniel", ""], ["Fernandez-Blanco", "Enrique", ""], ["Dorado", "Julian", ""], ["Pazos", "Alejandro", ""]]}, {"id": "1904.05061", "submitter": "Soroor Malekmohamadi", "authors": "Soroor Malekmohammadi Faradonbeh, Faramarz Safi-Esfahani", "title": "A review on Neural Turing Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major objectives of Artificial Intelligence is to design learning\nalgorithms that are executed on a general purposes computational machines such\nas human brain. Neural Turing Machine (NTM) is a step towards realizing such a\ncomputational machine. The attempt is made here to run a systematic review on\nNeural Turing Machine. First, the mind-map and taxonomy of machine learning,\nneural networks, and Turing machine are introduced. Next, NTM is inspected in\nterms of concepts, structure, variety of versions, implemented tasks,\ncomparisons, etc. Finally, the paper discusses on issues and ends up with\nseveral future works.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 08:36:46 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2020 10:15:53 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Faradonbeh", "Soroor Malekmohammadi", ""], ["Safi-Esfahani", "Faramarz", ""]]}, {"id": "1904.05098", "submitter": "Marco Frasca", "authors": "Marco Frasca, Giuliano Grossi, Giorgio Valentini", "title": "Multitask Hopfield Networks", "comments": "16 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask algorithms typically use task similarity information as a bias to\nspeed up and improve the performance of learning processes. Tasks are learned\njointly, sharing information across them, in order to construct models more\naccurate than those learned separately over single tasks. In this contribution,\nwe present the first multitask model, to our knowledge, based on Hopfield\nNetworks (HNs), named HoMTask. We show that by appropriately building a unique\nHN embedding all tasks, a more robust and effective classification model can be\nlearned. HoMTask is a transductive semi-supervised parametric HN, that\nminimizes an energy function extended to all nodes and to all tasks under\nstudy. We provide theoretical evidence that the optimal parameters\nautomatically estimated by HoMTask make coherent the model itself with the\nprior knowledge (connection weights and node labels). The convergence\nproperties of HNs are preserved, and the fixed point reached by the network\ndynamics gives rise to the prediction of unlabeled nodes. The proposed model\nimproves the classification abilities of singletask HNs on a preliminary\nbenchmark comparison, and achieves competitive performance with\nstate-of-the-art semi-supervised graph-based algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 10:25:19 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Frasca", "Marco", ""], ["Grossi", "Giuliano", ""], ["Valentini", "Giorgio", ""]]}, {"id": "1904.05158", "submitter": "Kyongmin Yeo", "authors": "Kyongmin Yeo", "title": "Short note on the behavior of recurrent neural network for noisy\n  dynamical system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG physics.comp-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavior of recurrent neural network for the data-driven simulation of\nnoisy dynamical systems is studied by training a set of Long Short-Term Memory\nNetworks (LSTM) on the Mackey-Glass time series with a wide range of noise\nlevel. It is found that, as the training noise becomes larger, LSTM learns to\ndepend more on its autonomous dynamics than the noisy input data. As a result,\nLSTM trained on noisy data becomes less susceptible to the perturbation in the\ndata, but has a longer relaxation timescale. On the other hand, when trained on\nnoiseless data, LSTM becomes extremely sensitive to a small perturbation, but\nis able to adjusts to the changes in the input data.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 21:17:32 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Yeo", "Kyongmin", ""]]}, {"id": "1904.05226", "submitter": "Tarik A. Rashid", "authors": "Jaza M. Abdullah and Tarik A. Rashid (IEEE Member)", "title": "Fitness Dependent Optimizer: Inspired by the Bee Swarming Reproductive\n  Process", "comments": "14 pages, Accepted in IEEE Access", "journal-ref": "IEEE Access, 2019", "doi": "10.1109/ACCESS.2019.2907012", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, a novel swarm intelligent algorithm is proposed, known as the\nfitness dependent optimizer (FDO). The bee swarming reproductive process and\ntheir collective decision-making have inspired this algorithm; it has no\nalgorithmic connection with the honey bee algorithm or the artificial bee\ncolony algorithm. It is worth mentioning that FDO is considered a particle\nswarm optimization (PSO)-based algorithm that updates the search agent position\nby adding velocity (pace). However, FDO calculates velocity differently; it\nuses the problem fitness function value to produce weights, and these weights\nguide the search agents during both the exploration and exploitation phases.\nThroughout the paper, the FDO algorithm is presented, and the motivation behind\nthe idea is explained. Moreover, FDO is tested on a group of 19 classical\nbenchmark test functions, and the results are compared with three well-known\nalgorithms: PSO, the genetic algorithm (GA), and the dragonfly algorithm (DA),\nadditionally, FDO is tested on IEEE Congress of Evolutionary Computation\nBenchmark Test Functions (CEC-C06, 2019 Competition) [1]. The results are\ncompared with three modern algorithms: (DA), the whale optimization algorithm\n(WOA), and the salp swarm algorithm (SSA). The FDO results show better\nperformance in most cases and comparative results in other cases. Furthermore,\nthe results are statistically tested with the Wilcoxon rank-sum test to show\nthe significance of the results. Likewise, FDO stability in both the\nexploration and exploitation phases is verified and performance-proofed using\ndifferent standard measurements. Finally, FDO is applied to real-world\napplications as evidence of its feasibility.\n", "versions": [{"version": "v1", "created": "Wed, 10 Apr 2019 14:51:58 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Abdullah", "Jaza M.", "", "IEEE Member"], ["Rashid", "Tarik A.", "", "IEEE Member"]]}, {"id": "1904.05606", "submitter": "Pavel Kral", "authors": "Ji\\v{r}\\'i Mart\\'inek, Pavel Kr\\'al, Ladislav Lenc, Christophe\n  Cerisara", "title": "Multi-lingual Dialogue Act Recognition with Deep Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with multi-lingual dialogue act (DA) recognition. The\nproposed approaches are based on deep neural networks and use word2vec\nembeddings for word representation. Two multi-lingual models are proposed for\nthis task. The first approach uses one general model trained on the embeddings\nfrom all available languages. The second method trains the model on a single\npivot language and a linear transformation method is used to project other\nlanguages onto the pivot language. The popular convolutional neural network and\nLSTM architectures with different set-ups are used as classifiers. To the best\nof our knowledge this is the first attempt at multi-lingual DA recognition\nusing neural networks. The multi-lingual models are validated experimentally on\ntwo languages from the Verbmobil corpus.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 09:55:41 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Mart\u00ednek", "Ji\u0159\u00ed", ""], ["Kr\u00e1l", "Pavel", ""], ["Lenc", "Ladislav", ""], ["Cerisara", "Christophe", ""]]}, {"id": "1904.05682", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr (\\'Ecole Polytechnique, CNRS, LIX) and Timo K\\\"otzing\n  (Hasso Plattner Institute)", "title": "Multiplicative Up-Drift", "comments": "Significantly extended version of: Benjamin Doerr and Timo K\\\"otzing.\n  Multiplicative up-drift. In Genetic and Evolutionary Computation Conference,\n  GECCO 2019, pages 1470-1478. ACM, 2019", "journal-ref": null, "doi": "10.1145/3321707.3321819", "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drift analysis aims at translating the expected progress of an evolutionary\nalgorithm (or more generally, a random process) into a probabilistic guarantee\non its run time (hitting time). So far, drift arguments have been successfully\nemployed in the rigorous analysis of evolutionary algorithms, however, only for\nthe situation that the progress is constant or becomes weaker when approaching\nthe target.\n  Motivated by questions like how fast fit individuals take over a population,\nwe analyze random processes exhibiting a $(1+\\delta)$-multiplicative growth in\nexpectation. We prove a drift theorem translating this expected progress into a\nhitting time. This drift theorem gives a simple and insightful proof of the\nlevel-based theorem first proposed by Lehre (2011). Our version of this theorem\nhas, for the first time, the best-possible near-linear dependence on $1/\\delta$\n(the previous results had an at least near-quadratic dependence), and it only\nrequires a population size near-linear in $\\delta$ (this was super-quadratic in\nprevious results). These improvements immediately lead to stronger run time\nguarantees for a number of applications.\n  We also discuss the case of large $\\delta$ and show stronger results for this\nsetting.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 13:24:14 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 21:35:02 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2019 20:37:05 GMT"}, {"version": "v4", "created": "Wed, 15 Jul 2020 14:43:02 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Doerr", "Benjamin", "", "\u00c9cole Polytechnique, CNRS, LIX"], ["K\u00f6tzing", "Timo", "", "Hasso Plattner Institute"]]}, {"id": "1904.05760", "submitter": "Tinkle Chugh", "authors": "Tinkle Chugh", "title": "Scalarizing Functions in Bayesian Multiobjective Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalarizing functions have been widely used to convert a multiobjective\noptimization problem into a single objective optimization problem. However,\ntheir use in solving (computationally) expensive multi- and many-objective\noptimization problems in Bayesian multiobjective optimization is scarce.\nScalarizing functions can play a crucial role on the quality and number of\nevaluations required when doing the optimization. In this article, we study and\nreview 15 different scalarizing functions in the framework of Bayesian\nmultiobjective optimization and build Gaussian process models (as surrogates,\nmetamodels or emulators) on them. We use expected improvement as infill\ncriterion (or acquisition function) to update the models. In particular, we\ncompare different scalarizing functions and analyze their performance on\nseveral benchmark problems with different number of objectives to be optimized.\nThe review and experiments on different functions provide useful insights when\nusing and selecting a scalarizing function when using a Bayesian multiobjective\noptimization method.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 15:17:38 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Chugh", "Tinkle", ""]]}, {"id": "1904.05815", "submitter": "MArk Hoogendoorn", "authors": "Mark Hoogendoorn, Ward van Breda, and Jeroen Ruwaard", "title": "GP-HD: Using Genetic Programming to Generate Dynamical Systems Models\n  for Health Care", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The huge wealth of data in the health domain can be exploited to create\nmodels that predict development of health states over time. Temporal learning\nalgorithms are well suited to learn relationships between health states and\nmake predictions about their future developments. However, these algorithms:\n(1) either focus on learning one generic model for all patients, providing\ngeneral insights but often with limited predictive performance, or (2) learn\nindividualized models from which it is hard to derive generic concepts. In this\npaper, we present a middle ground, namely parameterized dynamical systems\nmodels that are generated from data using a Genetic Programming (GP) framework.\nA fitness function suitable for the health domain is exploited. An evaluation\nof the approach in the mental health domain shows that performance of the model\ngenerated by the GP is on par with a dynamical systems model developed based on\ndomain knowledge, significantly outperforms a generic Long Term Short Term\nMemory (LSTM) model and in some cases also outperforms an individualized LSTM\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 16:13:22 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Hoogendoorn", "Mark", ""], ["van Breda", "Ward", ""], ["Ruwaard", "Jeroen", ""]]}, {"id": "1904.06110", "submitter": "Stefano Nichele", "authors": "Joachim Berg, Nils Gustav Andreas Berggren, Sivert Allergodt\n  Borgeteien, Christian Ruben Alexander Jahren, Arqam Sajid, Stefano Nichele", "title": "Evolved Art with Transparent, Overlapping, and Geometric Shapes", "comments": "Proceedings of the Norwegian AI Symposium 2019 (NAIS 2019),\n  Trondheim, Norway", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, an evolutionary art project is presented where images are\napproximated by transparent, overlapping and geometric shapes of different\ntypes, e.g., polygons, circles, lines. Genotypes representing features and\norder of the geometric shapes are evolved with a fitness function that has the\ncorresponding pixels of an input image as a target goal. A\ngenotype-to-phenotype mapping is therefore applied to render images, as the\nchosen genetic representation is indirect, i.e., genotypes do not include\npixels but a combination of shapes with their properties. Different\ncombinations of shapes, quantity of shapes, mutation types and populations are\ntested. The goal of the work herein is twofold: (1) to approximate images as\nprecisely as possible with evolved indirect encodings, (2) to produce visually\nappealing results and novel artistic styles.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 09:09:56 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 13:44:43 GMT"}, {"version": "v3", "created": "Thu, 16 May 2019 11:57:16 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Berg", "Joachim", ""], ["Berggren", "Nils Gustav Andreas", ""], ["Borgeteien", "Sivert Allergodt", ""], ["Jahren", "Christian Ruben Alexander", ""], ["Sajid", "Arqam", ""], ["Nichele", "Stefano", ""]]}, {"id": "1904.06194", "submitter": "Ze-Feng Gao", "authors": "Ze-Feng Gao, Song Cheng, Rong-Qiang He, Z. Y. Xie, Hui-Hai Zhao,\n  Zhong-Yi Lu, Tao Xiang", "title": "Compressing deep neural networks by matrix product operators", "comments": "8+9 pages, 3+7 figures, 2+11 tables", "journal-ref": "Phys. Rev. Research 2, 023300 (2020)", "doi": "10.1103/PhysRevResearch.2.023300", "report-no": null, "categories": "cs.LG cs.CV cs.NE physics.comp-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep neural network is a parametrization of a multilayer mapping of signals\nin terms of many alternatively arranged linear and nonlinear transformations.\nThe linear transformations, which are generally used in the fully connected as\nwell as convolutional layers, contain most of the variational parameters that\nare trained and stored. Compressing a deep neural network to reduce its number\nof variational parameters but not its prediction power is an important but\nchallenging problem toward the establishment of an optimized scheme in training\nefficiently these parameters and in lowering the risk of overfitting. Here we\nshow that this problem can be effectively solved by representing linear\ntransformations with matrix product operators (MPOs), which is a tensor network\noriginally proposed in physics to characterize the short-range entanglement in\none-dimensional quantum states. We have tested this approach in five typical\nneural networks, including FC2, LeNet-5, VGG, ResNet, and DenseNet on two\nwidely used data sets, namely, MNIST and CIFAR-10, and found that this MPO\nrepresentation indeed sets up a faithful and efficient mapping between input\nand output signals, which can keep or even improve the prediction accuracy with\na dramatically reduced number of parameters. Our method greatly simplifies the\nrepresentations in deep learning, and opens a possible route toward\nestablishing a framework of modern neural networks which might be simpler and\ncheaper, but more efficient.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 17:59:00 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 03:26:01 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Gao", "Ze-Feng", ""], ["Cheng", "Song", ""], ["He", "Rong-Qiang", ""], ["Xie", "Z. Y.", ""], ["Zhao", "Hui-Hai", ""], ["Lu", "Zhong-Yi", ""], ["Xiang", "Tao", ""]]}, {"id": "1904.06230", "submitter": "George Hall", "authors": "George T. Hall, Pietro S. Oliveto, Dirk Sudholt", "title": "On the Impact of the Cutoff Time on the Performance of Algorithm\n  Configurators", "comments": "This work is accepted at GECCO 2019, and is extended to contain\n  proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithm configurators are automated methods to optimise the parameters of\nan algorithm for a class of problems. We evaluate the performance of a simple\nrandom local search configurator (ParamRLS) for tuning the neighbourhood size\n$k$ of the RLS$_k$ algorithm. We measure performance as the expected number of\nconfiguration evaluations required to identify the optimal value for the\nparameter. We analyse the impact of the cutoff time $\\kappa$ (the time spent\nevaluating a configuration for a problem instance) on the expected number of\nconfiguration evaluations required to find the optimal parameter value, where\nwe compare configurations using either best found fitness values (ParamRLS-F)\nor optimisation times (ParamRLS-T). We consider tuning RLS$_k$ for a variant of\nthe Ridge function class (Ridge*), where the performance of each parameter\nvalue does not change during the run, and for the OneMax function class, where\nlonger runs favour smaller $k$. We rigorously prove that ParamRLS-F efficiently\ntunes RLS$_k$ for Ridge* for any $\\kappa$ while ParamRLS-T requires at least\nquadratic $\\kappa$. For OneMax ParamRLS-F identifies $k=1$ as optimal with\nlinear $\\kappa$ while ParamRLS-T requires a $\\kappa$ of at least $\\Omega(n\\log\nn)$. For smaller $\\kappa$ ParamRLS-F identifies that $k>1$ performs better\nwhile ParamRLS-T returns $k$ chosen uniformly at random.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 13:35:47 GMT"}, {"version": "v2", "created": "Tue, 21 May 2019 07:05:09 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Hall", "George T.", ""], ["Oliveto", "Pietro S.", ""], ["Sudholt", "Dirk", ""]]}, {"id": "1904.06239", "submitter": "James Butterworth", "authors": "James Butterworth, Rahul Savani, Karl Tuyls", "title": "Evolving Indoor Navigational Strategies Using Gated Recurrent Units In\n  NEAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous Localisation and Mapping (SLAM) algorithms are expensive to run\non smaller robotic platforms such as Micro-Aerial Vehicles. Bug algorithms are\nan alternative that use relatively little processing power, and avoid high\nmemory consumption by not building an explicit map of the environment. Bug\nAlgorithms achieve relatively good performance in simulated and robotic maze\nsolving domains. However, because they are hand-designed, a natural question is\nwhether they are globally optimal control policies. In this work we explore the\nperformance of Neuroevolution - specifically NEAT - at evolving control\npolicies for simulated differential drive robots carrying out generalised maze\nnavigation. We extend NEAT to include Gated Recurrent Units (GRUs) to help deal\nwith long term dependencies. We show that both NEAT and our NEAT-GRU can\nrepeatably generate controllers that outperform I-Bug (an algorithm\nparticularly well-suited for use in real robots) on a test set of 209 indoor\nmaze like environments. We show that NEAT-GRU is superior to NEAT in this task\nbut also that out of the 2 systems, only NEAT-GRU can continuously evolve\nsuccessful controllers for a much harder task in which no bearing information\nabout the target is provided to the agent.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 14:04:10 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Butterworth", "James", ""], ["Savani", "Rahul", ""], ["Tuyls", "Karl", ""]]}, {"id": "1904.06269", "submitter": "Daniel Saunders", "authors": "Daniel J. Saunders, Devdhar Patel, Hananel Hazan, Hava T. Siegelmann,\n  Robert Kozma", "title": "Locally Connected Spiking Neural Networks for Unsupervised Feature\n  Learning", "comments": "22 pages, 7 figures, and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Spiking Neural Networks (SNNs) have demonstrated great\nsuccesses in completing various Machine Learning tasks. We introduce a method\nfor learning image features by \\textit{locally connected layers} in SNNs using\nspike-timing-dependent plasticity (STDP) rule. In our approach, sub-networks\ncompete via competitive inhibitory interactions to learn features from\ndifferent locations of the input space. These \\textit{Locally-Connected SNNs}\n(LC-SNNs) manifest key topological features of the spatial interaction of\nbiological neurons. We explore biologically inspired n-gram classification\napproach allowing parallel processing over various patches of the the image\nspace. We report the classification accuracy of simple two-layer LC-SNNs on two\nimage datasets, which match the state-of-art performance and are the first\nresults to date. LC-SNNs have the advantage of fast convergence to a dataset\nrepresentation, and they require fewer learnable parameters than other SNN\napproaches with unsupervised learning. Robustness tests demonstrate that\nLC-SNNs exhibit graceful degradation of performance despite the random deletion\nof large amounts of synapses and neurons.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 15:20:37 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Saunders", "Daniel J.", ""], ["Patel", "Devdhar", ""], ["Hazan", "Hananel", ""], ["Siegelmann", "Hava T.", ""], ["Kozma", "Robert", ""]]}, {"id": "1904.06302", "submitter": "Mingde Zhao", "authors": "Mingde Zhao and Hongwei Ge and Kai Zhang and Yaqing Hou", "title": "A Reference Vector based Many-Objective Evolutionary Algorithm with\n  Feasibility-aware Adaptation", "comments": "Revision 1 submitted to Applied Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The infeasible parts of the objective space in difficult many-objective\noptimization problems cause trouble for evolutionary algorithms. This paper\nproposes a reference vector based algorithm which uses two interacting engines\nto adapt the reference vectors and to evolve the population towards the true\nPareto Front (PF) s.t. the reference vectors are always evenly distributed\nwithin the current PF to provide appropriate guidance for selection. The\ncurrent PF is tracked by maintaining an archive of undominated individuals, and\nadaptation of reference vectors is conducted with the help of another archive\nthat contains layers of reference vectors corresponding to different density.\nExperimental results show the expected characteristics and competitive\nperformance of the proposed algorithm TEEA.\n", "versions": [{"version": "v1", "created": "Fri, 12 Apr 2019 16:12:46 GMT"}], "update_date": "2019-04-15", "authors_parsed": [["Zhao", "Mingde", ""], ["Ge", "Hongwei", ""], ["Zhang", "Kai", ""], ["Hou", "Yaqing", ""]]}, {"id": "1904.06960", "submitter": "Mischa Schmidt", "authors": "Mischa Schmidt, Shahd Safarani, Julia Gastinger, Tobias Jacobs,\n  Sebastien Nicolas, Anett Sch\\\"ulke", "title": "On the Performance of Differential Evolution for Hyperparameter Tuning", "comments": "2019 International Joint Conference on Neural Networks (IJCNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated hyperparameter tuning aspires to facilitate the application of\nmachine learning for non-experts. In the literature, different optimization\napproaches are applied for that purpose. This paper investigates the\nperformance of Differential Evolution for tuning hyperparameters of supervised\nlearning algorithms for classification tasks. This empirical study involves a\nrange of different machine learning algorithms and datasets with various\ncharacteristics to compare the performance of Differential Evolution with\nSequential Model-based Algorithm Configuration (SMAC), a reference Bayesian\nOptimization approach. The results indicate that Differential Evolution\noutperforms SMAC for most datasets when tuning a given machine learning\nalgorithm - particularly when breaking ties in a first-to-report fashion. Only\nfor the tightest of computational budgets SMAC performs better. On small\ndatasets, Differential Evolution outperforms SMAC by 19% (37% after\ntie-breaking). In a second experiment across a range of representative datasets\ntaken from the literature, Differential Evolution scores 15% (23% after\ntie-breaking) more wins than SMAC.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 10:58:14 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Schmidt", "Mischa", ""], ["Safarani", "Shahd", ""], ["Gastinger", "Julia", ""], ["Jacobs", "Tobias", ""], ["Nicolas", "Sebastien", ""], ["Sch\u00fclke", "Anett", ""]]}, {"id": "1904.06972", "submitter": "Faizal Hafiz", "authors": "Faizal Hafiz and Akshya Swain and Chirag Naik and Nitish Patel", "title": "Efficient Feature Selection of Power Quality Events using Two\n  Dimensional (2D) Particle Swarms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel two-dimensional (2D) learning framework has been proposed to address\nthe feature selection problem in Power Quality (PQ) events. Unlike the existing\nfeature selection approaches, the proposed 2D learning explicitly incorporates\nthe information about the subset cardinality (i.e., the number of features) as\nan additional learning dimension to effectively guide the search process. The\nefficacy of this approach has been demonstrated considering fourteen distinct\nclasses of PQ events which conform to the IEEE Standard 1159. The search\nperformance of the 2D learning approach has been compared to the other six\nwell-known feature selection wrappers by considering two induction algorithms:\nNaive Bayes (NB) and k-Nearest Neighbors (k-NN). Further, the robustness of the\nselected/reduced feature subsets has been investigated considering seven\ndifferent levels of noise. The results of this investigation convincingly\ndemonstrate that the proposed 2D learning can identify significantly better and\nrobust feature subsets for PQ events.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 11:32:58 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Hafiz", "Faizal", ""], ["Swain", "Akshya", ""], ["Naik", "Chirag", ""], ["Patel", "Nitish", ""]]}, {"id": "1904.06981", "submitter": "Denis Antipov", "authors": "Denis Antipov and Benjamin Doerr and Quentin Yang", "title": "The Efficiency Threshold for the Offspring Population Size of the\n  ($\\mu$, $\\lambda$) EA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding when evolutionary algorithms are efficient or not, and how they\nefficiently solve problems, is one of the central research tasks in\nevolutionary computation. In this work, we make progress in understanding the\ninterplay between parent and offspring population size of the $(\\mu,\\lambda)$\nEA. Previous works, roughly speaking, indicate that for $\\lambda \\ge\n(1+\\varepsilon) e \\mu$, this EA easily optimizes the OneMax function, whereas\nan offspring population size $\\lambda \\le (1 -\\varepsilon) e \\mu$ leads to an\nexponential runtime.\n  Motivated also by the observation that in the efficient regime the\n$(\\mu,\\lambda)$ EA loses its ability to escape local optima, we take a closer\nlook into this phase transition. Among other results, we show that when $\\mu\n\\le n^{1/2 - c}$ for any constant $c > 0$, then for any $\\lambda \\le e \\mu$ we\nhave a super-polynomial runtime. However, if $\\mu \\ge n^{2/3 + c}$, then for\nany $\\lambda \\ge e \\mu$, the runtime is polynomial. For the latter result we\nobserve that the $(\\mu,\\lambda)$ EA profits from better individuals also\nbecause these, by creating slightly worse offspring, stabilize slightly\nsub-optimal sub-populations. While these first results close to the phase\ntransition do not yet give a complete picture, they indicate that the boundary\nbetween efficient and super-polynomial is not just the line $\\lambda = e \\mu$,\nand that the reasons for efficiency or not are more complex than what was known\nso far.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 12:02:07 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Antipov", "Denis", ""], ["Doerr", "Benjamin", ""], ["Yang", "Quentin", ""]]}, {"id": "1904.06991", "submitter": "Samuli Laine", "authors": "Tuomas Kynk\\\"a\\\"anniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen,\n  Timo Aila", "title": "Improved Precision and Recall Metric for Assessing Generative Models", "comments": "NeurIPS 2019 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to automatically estimate the quality and coverage of the samples\nproduced by a generative model is a vital requirement for driving algorithm\nresearch. We present an evaluation metric that can separately and reliably\nmeasure both of these aspects in image generation tasks by forming explicit,\nnon-parametric representations of the manifolds of real and generated data. We\ndemonstrate the effectiveness of our metric in StyleGAN and BigGAN by providing\nseveral illustrative examples where existing metrics yield uninformative or\ncontradictory results. Furthermore, we analyze multiple design variants of\nStyleGAN to better understand the relationships between the model architecture,\ntraining methods, and the properties of the resulting sample distribution. In\nthe process, we identify new variants that improve the state-of-the-art. We\nalso perform the first principled analysis of truncation methods and identify\nan improved method. Finally, we extend our metric to estimate the perceptual\nquality of individual samples, and use this to study latent space\ninterpolations.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 12:20:32 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2019 13:03:04 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2019 12:33:29 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Kynk\u00e4\u00e4nniemi", "Tuomas", ""], ["Karras", "Tero", ""], ["Laine", "Samuli", ""], ["Lehtinen", "Jaakko", ""], ["Aila", "Timo", ""]]}, {"id": "1904.07043", "submitter": "Mehdi Neshat", "authors": "Mehdi Neshat, Bradley Alexander, Nataliia Sergiienko, Markus Wagner", "title": "A Hybrid Evolutionary Algorithm Framework for Optimising Power Take Off\n  and Placements of Wave Energy Converters", "comments": null, "journal-ref": "GECCO 2019: 1293-1301", "doi": "10.1145/3321707.3321806", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ocean wave energy is a source of renewable energy that has gained much\nattention for its potential to contribute significantly to meeting the global\nenergy demand. In this research, we investigate the problem of maximising the\nenergy delivered by farms of wave energy converters (WEC's). We consider\nstate-of-the-art fully submerged three-tether converters deployed in arrays.\nThe goal of this work is to use heuristic search to optimise the power output\nof arrays in a size-constrained environment by configuring WEC locations and\nthe power-take-off (PTO) settings for each WEC. Modelling the complex\nhydrodynamic interactions in wave farms is expensive, which constrains search\nto only a few thousand model evaluations. We explore a variety of heuristic\napproaches including cooperative and hybrid methods. The effectiveness of these\napproaches is assessed in two real wave scenarios (Sydney and Perth) with farms\nof two different scales. We find that a combination of symmetric local search\nwith Nelder-Mead Simplex direct search combined with a back-tracking\noptimization strategy is able to outperform previously defined search\ntechniques by up to 3\\%.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 13:46:38 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Neshat", "Mehdi", ""], ["Alexander", "Bradley", ""], ["Sergiienko", "Nataliia", ""], ["Wagner", "Markus", ""]]}, {"id": "1904.07180", "submitter": "Qinbing Fu", "authors": "Qinbing Fu, Cheng Hu, Pengcheng Liu, Shigang Yue", "title": "Synthetic Neural Vision System Design for Motion Pattern Recognition in\n  Dynamic Robot Scenes", "comments": "8 pages, IEEE format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Insects have tiny brains but complicated visual systems for motion\nperception. A handful of insect visual neurons have been computationally\nmodeled and successfully applied for robotics. How different neurons\ncollaborate on motion perception, is an open question to date. In this paper,\nwe propose a novel embedded vision system in autonomous micro-robots, to\nrecognize motion patterns in dynamic robot scenes. Here, the basic motion\npatterns are categorized into movements of looming (proximity), recession,\ntranslation, and other irrelevant ones. The presented system is a synthetic\nneural network, which comprises two complementary sub-systems with four spiking\nneurons -- the lobula giant movement detectors (LGMD1 and LGMD2) in locusts for\nsensing looming and recession, and the direction selective neurons (DSN-R and\nDSN-L) in flies for translational motion extraction. Images are transformed to\nspikes via spatiotemporal computations towards a switch function and decision\nmaking mechanisms, in order to invoke proper robot behaviors amongst collision\navoidance, tracking and wandering, in dynamic robot scenes. Our robot\nexperiments demonstrated two main contributions: (1) This neural vision system\nis effective to recognize the basic motion patterns corresponding to timely and\nproper robot behaviors in dynamic scenes. (2) The arena tests with multi-robots\ndemonstrated the effectiveness in recognizing more abundant motion features for\ncollision detection, which is a great improvement compared with former studies.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 16:53:36 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Fu", "Qinbing", ""], ["Hu", "Cheng", ""], ["Liu", "Pengcheng", ""], ["Yue", "Shigang", ""]]}, {"id": "1904.07206", "submitter": "Qinbing Fu", "authors": "Jiannan Zhao, Xingzao Ma, Qinbing Fu, Cheng Hu, Shigang Yue", "title": "An LGMD Based Competitive Collision Avoidance Strategy for UAV", "comments": "12 pages, Springer conference format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building a reliable and efficient collision avoidance system for unmanned\naerial vehicles (UAVs) is still a challenging problem. This research takes\ninspiration from locusts, which can fly in dense swarms for hundreds of miles\nwithout collision. In the locust's brain, a visual pathway of LGMD-DCMD (lobula\ngiant movement detector and descending contra-lateral motion detector) has been\nidentified as collision perception system guiding fast collision avoidance for\nlocusts, which is ideal for designing artificial vision systems. However, there\nis very few works investigating its potential in real-world UAV applications.\nIn this paper, we present an LGMD based competitive collision avoidance method\nfor UAV indoor navigation. Compared to previous works, we divided the UAV's\nfield of view into four subfields each handled by an LGMD neuron. Therefore,\nfour individual competitive LGMDs (C-LGMD) compete for guiding the directional\ncollision avoidance of UAV. With more degrees of freedom compared to ground\nrobots and vehicles, the UAV can escape from collision along four cardinal\ndirections (e.g. the object approaching from the left-side triggers a rightward\nshifting of the UAV). Our proposed method has been validated by both\nsimulations and real-time quadcopter arena experiments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 17:30:56 GMT"}], "update_date": "2019-04-16", "authors_parsed": [["Zhao", "Jiannan", ""], ["Ma", "Xingzao", ""], ["Fu", "Qinbing", ""], ["Hu", "Cheng", ""], ["Yue", "Shigang", ""]]}, {"id": "1904.07284", "submitter": "Maxim Buzdalov", "authors": "Anton Bassin, Maxim Buzdalov", "title": "The 1/5-th Rule with Rollbacks: On Self-Adjustment of the Population\n  Size in the $(1+(\\lambda,\\lambda))$ GA", "comments": "17 pages, 2 figures, 1 table. An extended two-page abstract of this\n  work will appear in proceedings of the Genetic and Evolutionary Computation\n  Conference, GECCO'19", "journal-ref": null, "doi": "10.1145/3319619.3322067", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-adjustment of parameters can significantly improve the performance of\nevolutionary algorithms. A notable example is the $(1+(\\lambda,\\lambda))$\ngenetic algorithm, where the adaptation of the population size helps to achieve\nthe linear runtime on the OneMax problem. However, on problems which interfere\nwith the assumptions behind the self-adjustment procedure, its usage can lead\nto performance degradation compared to static parameter choices. In particular,\nthe one fifth rule, which guides the adaptation in the example above, is able\nto raise the population size too fast on problems which are too far away from\nthe perfect fitness-distance correlation.\n  We propose a modification of the one fifth rule in order to have less\nnegative impact on the performance in scenarios when the original rule reduces\nthe performance. Our modification, while still having a good performance on\nOneMax, both theoretically and in practice, also shows better results on linear\nfunctions with random weights and on random satisfiable MAX-SAT instances.\n", "versions": [{"version": "v1", "created": "Mon, 15 Apr 2019 18:40:52 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Bassin", "Anton", ""], ["Buzdalov", "Maxim", ""]]}, {"id": "1904.07636", "submitter": "Darren Chitty", "authors": "Darren M. Chitty, Elizabeth Wanner, Rakhi Parmar and Peter R. Lewis", "title": "Applying Partial-ACO to Large-scale Vehicle Fleet Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimisation of fleets of commercial vehicles with regards scheduling tasks\nfrom various locations to vehicles can result in considerably lower fleet\ntraversal times. This has significant benefits including reduced expenses for\nthe company and more importantly, a reduction in the degree of road use and\nhence vehicular emissions. Exact optimisation methods fail to scale to real\ncommercial problem instances, thus meta-heuristics are more suitable. Ant\nColony Optimisation (ACO) generally provides good solutions on small to medium\nproblem sizes. However, commercial fleet optimisation problems are typically\nlarge and complex, in which ACO fails to scale well. Partial-ACO is a new ACO\nvariant designed to scale to larger problem instances. Therefore this paper\ninvestigates the application of Partial-ACO on the problem of fleet\noptimisation, demonstrating the capacity of Partial-ACO to successfully scale\nto larger problems. Indeed, for real-world fleet optimisation problems supplied\nby a Birmingham based company with up to 298 jobs and 32 vehicles, Partial-ACO\ncan improve upon their fleet traversal times by over 44%. Moreover, Partial-ACO\ndemonstrates its ability to scale with considerably improved results over\nstandard ACO and competitive results against a Genetic Algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 13:07:51 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Chitty", "Darren M.", ""], ["Wanner", "Elizabeth", ""], ["Parmar", "Rakhi", ""], ["Lewis", "Peter R.", ""]]}, {"id": "1904.07801", "submitter": "Carola Doerr", "authors": "Diederick Vermetten, Sander van Rijn, Thomas B\\\"ack, Carola Doerr", "title": "Online Selection of CMA-ES Variants", "comments": "To appear at Genetic and Evolutionary Computation Conference\n  (GECCO'19) Appendix will be added in due time", "journal-ref": null, "doi": "10.1145/3321707.3321803", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the field of evolutionary computation, one of the most challenging topics\nis algorithm selection. Knowing which heuristics to use for which optimization\nproblem is key to obtaining high-quality solutions. We aim to extend this\nresearch topic by taking a first step towards a selection method for adaptive\nCMA-ES algorithms. We build upon the theoretical work done by van Rijn\n\\textit{et al.} [PPSN'18], in which the potential of switching between\ndifferent CMA-ES variants was quantified in the context of a modular CMA-ES\nframework.\n  We demonstrate in this work that their proposed approach is not very\nreliable, in that implementing the suggested adaptive configurations does not\nyield the predicted performance gains. We propose a revised approach, which\nresults in a more robust fit between predicted and actual performance. The\nadaptive CMA-ES approach obtains performance gains on 18 out of 24 tested\nfunctions of the BBOB benchmark, with stable advantages of up to 23\\%. An\nanalysis of module activation indicates which modules are most crucial for the\ndifferent phases of optimizing each of the 24 benchmark problems. The module\nactivation also suggests that additional gains are possible when including the\n(B)IPOP modules, which we have excluded for this present work.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 16:32:44 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Vermetten", "Diederick", ""], ["van Rijn", "Sander", ""], ["B\u00e4ck", "Thomas", ""], ["Doerr", "Carola", ""]]}, {"id": "1904.07818", "submitter": "Carola Doerr", "authors": "Nathan Buskulic and Carola Doerr", "title": "Maximizing Drift is Not Optimal for Solving OneMax", "comments": "To appear in Evolutionary Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It may seem very intuitive that for the maximization of the OneMax problem\n$\\OM(x):=\\sum_{i=1}^n{x_i}$ the best that an elitist unary unbiased search\nalgorithm can do is to store a best so far solution, and to modify it with the\noperator that yields the best possible expected progress in function value.\nThis assumption has been implicitly used in several empirical works. In [Doerr,\nDoerr, Yang: Optimal parameter choices via precise black-box analysis, TCS,\n2020] it was formally proven that this approach is indeed almost optimal.\n  In this work we prove that drift maximization is not optimal. More precisely,\nwe show that for most fitness levels between $n/2$ and $2n/3$ the optimal\nmutation strengths are larger than the drift-maximizing ones. This implies that\nthe optimal RLS is more risk-affine than the variant maximizing the step-wise\nexpected progress. We show similar results for the mutation rates of the\nclassic (1+1) Evolutionary Algorithm (EA) and its resampling variant, the (1+1)\nEA$_{>0}$.\n  As a result of independent interest we show that the optimal mutation\nstrengths, unlike the drift-maximizing ones, can be even.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 16:48:35 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 22:45:48 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Buskulic", "Nathan", ""], ["Doerr", "Carola", ""]]}, {"id": "1904.07952", "submitter": "Linda Wang", "authors": "Linda Wang", "title": "Response of Selective Attention in Middle Temporal Area", "comments": "9 pages, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primary visual cortex processes a large amount of visual information,\nhowever, due to its large receptive fields, when multiple stimuli fall within\none receptive field, there are computational problems. To solve this problem,\nthe visual system uses selective attention, which allocates resources to a\nspecific spatial location, to attend to one of the stimuli in the receptive\nfield. During this process, the center and width of the attending receptive\nfield change. The model presented in the paper, which is extended and altered\nfrom Bobier et al., simulates the selective attention between the primary\nvisual cortex, V1, and middle temporal (MT) area. The responses of the MT\ncolumns, which encode the target stimulus, are compared to the results of an\nexperiment conducted by Womelsdorf et al. on the receptive field shift and\nshrinkage in macaque MT area from selective attention. Based on the results,\nthe responses in the MT area are similar to the Gaussian shaped receptive\nfields found in the experiment. As well, the responses of the MT columns are\nalso measured for accuracy of representing the target visual stimulus and is\nfound to represent the stimulus with a root mean squared error around 0.17 to\n0.18. The paper also explores varying model parameters, such as the membrane\ntime constant and maximum firing rates, and how those affect the measurement.\nThis model is a start to modeling the responses of selective attention, however\nthere are still improvements that can be made to better compare with the\nexperiment, produce more accurate responses and incorporate more biologically\nplausible features.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 20:04:32 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Wang", "Linda", ""]]}, {"id": "1904.07964", "submitter": "Wentai Zhang", "authors": "Wentai Zhang, Zhangsihao Yang, Haoliang Jiang, Suyash Nigam, Soji\n  Yamakawa, Tomotake Furuhata, Kenji Shimada, Levent Burak Kara", "title": "3D Shape Synthesis for Conceptual Design and Optimization Using\n  Variational Autoencoders", "comments": "Preprint accepted by ASME IDETC/CIE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-driven 3D shape design method that can learn a generative\nmodel from a corpus of existing designs, and use this model to produce a wide\nrange of new designs. The approach learns an encoding of the samples in the\ntraining corpus using an unsupervised variational autoencoder-decoder\narchitecture, without the need for an explicit parametric representation of the\noriginal designs. To facilitate the generation of smooth final surfaces, we\ndevelop a 3D shape representation based on a distance transformation of the\noriginal 3D data, rather than using the commonly utilized binary voxel\nrepresentation. Once established, the generator maps the latent space\nrepresentations to the high-dimensional distance transformation fields, which\nare then automatically surfaced to produce 3D representations amenable to\nphysics simulations or other objective function evaluation modules. We\ndemonstrate our approach for the computational design of gliders that are\noptimized to attain prescribed performance scores. Our results show that when\ncombined with genetic optimization, the proposed approach can generate a rich\nset of candidate concept designs that achieve prescribed functional goals, even\nwhen the original dataset has only a few or no solutions that achieve these\ngoals.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 20:26:53 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Zhang", "Wentai", ""], ["Yang", "Zhangsihao", ""], ["Jiang", "Haoliang", ""], ["Nigam", "Suyash", ""], ["Yamakawa", "Soji", ""], ["Furuhata", "Tomotake", ""], ["Shimada", "Kenji", ""], ["Kara", "Levent Burak", ""]]}, {"id": "1904.08032", "submitter": "Carola Doerr", "authors": "Anna Rodionova, Kirill Antonov, Arina Buzdalova, Carola Doerr", "title": "Offspring Population Size Matters when Comparing Evolutionary Algorithms\n  with Self-Adjusting Mutation Rates", "comments": "To appear at Genetic and Evolutionary Computation Conference\n  (GECCO'19). v2: minor language revision", "journal-ref": null, "doi": "10.1145/3321707.3321827", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the performance of the 2-rate $(1+\\lambda)$ Evolutionary Algorithm\n(EA) with self-adjusting mutation rate control, its 3-rate counterpart, and a\n$(1+\\lambda)$~EA variant using multiplicative update rules on the OneMax\nproblem. We compare their efficiency for offspring population sizes ranging up\nto $\\lambda=3,200$ and problem sizes up to $n=100,000$.\n  Our empirical results show that the ranking of the algorithms is very\nconsistent across all tested dimensions, but strongly depends on the population\nsize. While for small values of $\\lambda$ the 2-rate EA performs best, the\nmultiplicative updates become superior for starting for some threshold value of\n$\\lambda$ between 50 and 100. Interestingly, for population sizes around 50,\nthe $(1+\\lambda)$~EA with static mutation rates performs on par with the best\nof the self-adjusting algorithms.\n  We also consider how the lower bound $p_{\\min}$ for the mutation rate\ninfluences the efficiency of the algorithms. We observe that for the 2-rate EA\nand the EA with multiplicative update rules the more generous bound\n$p_{\\min}=1/n^2$ gives better results than $p_{\\min}=1/n$ when $\\lambda$ is\nsmall. For both algorithms the situation reverses for large~$\\lambda$.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 00:43:38 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2019 17:21:48 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Rodionova", "Anna", ""], ["Antonov", "Kirill", ""], ["Buzdalova", "Arina", ""], ["Doerr", "Carola", ""]]}, {"id": "1904.08050", "submitter": "Najeeb Khan", "authors": "Najeeb Khan and Ian Stavness", "title": "Sparseout: Controlling Sparsity in Deep Networks", "comments": "Code: https://github.com/najeebkhan/sparseout", "journal-ref": null, "doi": "10.1007/978-3-030-18305-9_24", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dropout is commonly used to help reduce overfitting in deep neural networks.\nSparsity is a potentially important property of neural networks, but is not\nexplicitly controlled by Dropout-based regularization. In this work, we propose\nSparseout a simple and efficient variant of Dropout that can be used to control\nthe sparsity of the activations in a neural network. We theoretically prove\nthat Sparseout is equivalent to an $L_q$ penalty on the features of a\ngeneralized linear model and that Dropout is a special case of Sparseout for\nneural networks. We empirically demonstrate that Sparseout is computationally\ninexpensive and is able to control the desired level of sparsity in the\nactivations. We evaluated Sparseout on image classification and language\nmodelling tasks to see the effect of sparsity on these tasks. We found that\nsparsity of the activations is favorable for language modelling performance\nwhile image classification benefits from denser activations. Sparseout provides\na way to investigate sparsity in state-of-the-art deep learning models. Source\ncode for Sparseout could be found at\n\\url{https://github.com/najeebkhan/sparseout}.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 02:10:25 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Khan", "Najeeb", ""], ["Stavness", "Ian", ""]]}, {"id": "1904.08149", "submitter": "Ozan \\c{C}atal", "authors": "Ozan \\c{C}atal, Johannes Nauta, Tim Verbelen, Pieter Simoens and Bart\n  Dhoedt", "title": "Bayesian policy selection using active inference", "comments": "ICLR 2019 Workshop on Structure & priors in reinforcement learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning to take actions based on observations is a core requirement for\nartificial agents to be able to be successful and robust at their task.\nReinforcement Learning (RL) is a well-known technique for learning such\npolicies. However, current RL algorithms often have to deal with reward\nshaping, have difficulties generalizing to other environments and are most\noften sample inefficient. In this paper, we explore active inference and the\nfree energy principle, a normative theory from neuroscience that explains how\nself-organizing biological systems operate by maintaining a model of the world\nand casting action selection as an inference problem. We apply this concept to\na typical problem known to the RL community, the mountain car problem, and show\nhow active inference encompasses both RL and learning from demonstrations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 09:18:07 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 14:28:32 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["\u00c7atal", "Ozan", ""], ["Nauta", "Johannes", ""], ["Verbelen", "Tim", ""], ["Simoens", "Pieter", ""], ["Dhoedt", "Bart", ""]]}, {"id": "1904.08378", "submitter": "Benjamin Krause", "authors": "Ben Krause, Emmanuel Kahembwe, Iain Murray, Steve Renals", "title": "Dynamic Evaluation of Transformer Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research note combines two methods that have recently improved the state\nof the art in language modeling: Transformers and dynamic evaluation.\nTransformers use stacked layers of self-attention that allow them to capture\nlong range dependencies in sequential data. Dynamic evaluation fits models to\nthe recent sequence history, allowing them to assign higher probabilities to\nre-occurring sequential patterns. By applying dynamic evaluation to\nTransformer-XL models, we improve the state of the art on enwik8 from 0.99 to\n0.94 bits/char, text8 from 1.08 to 1.04 bits/char, and WikiText-103 from 18.3\nto 16.4 perplexity points.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 17:26:01 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Krause", "Ben", ""], ["Kahembwe", "Emmanuel", ""], ["Murray", "Iain", ""], ["Renals", "Steve", ""]]}, {"id": "1904.08415", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr", "title": "An Exponential Lower Bound for the Runtime of the cGA on Jump Functions", "comments": "To appear in the Proceedings of FOGA 2019. arXiv admin note: text\n  overlap with arXiv:1903.10983", "journal-ref": null, "doi": "10.1145/3299904.3340304", "report-no": null, "categories": "cs.NE cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the first runtime analysis of an estimation-of-distribution algorithm\n(EDA) on the multi-modal jump function class, Hasen\\\"ohrl and Sutton (GECCO\n2018) proved that the runtime of the compact genetic algorithm with suitable\nparameter choice on jump functions with high probability is at most polynomial\n(in the dimension) if the jump size is at most logarithmic (in the dimension),\nand is at most exponential in the jump size if the jump size is\nsuper-logarithmic. The exponential runtime guarantee was achieved with a\nhypothetical population size that is also exponential in the jump size.\nConsequently, this setting cannot lead to a better runtime.\n  In this work, we show that any choice of the hypothetical population size\nleads to a runtime that, with high probability, is at least exponential in the\njump size. This result might be the first non-trivial exponential lower bound\nfor EDAs that holds for arbitrary parameter settings.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 09:39:23 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 13:59:44 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Doerr", "Benjamin", ""]]}, {"id": "1904.08513", "submitter": "Charlotte Frenkel", "authors": "Charlotte Frenkel, Jean-Didier Legat, David Bol", "title": "MorphIC: A 65-nm 738k-Synapse/mm$^2$ Quad-Core Binary-Weight Digital\n  Neuromorphic Processor with Stochastic Spike-Driven Online Learning", "comments": "This document is the paper as accepted for publication in the IEEE\n  Transactions on Biomedical Circuits and Systems journal (2019), the\n  fully-edited paper is available at\n  https://ieeexplore.ieee.org/document/8764001", "journal-ref": null, "doi": "10.1109/TBCAS.2019.2928793", "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent trends in the field of neural network accelerators investigate weight\nquantization as a means to increase the resource- and power-efficiency of\nhardware devices. As full on-chip weight storage is necessary to avoid the high\nenergy cost of off-chip memory accesses, memory reduction requirements for\nweight storage pushed toward the use of binary weights, which were demonstrated\nto have a limited accuracy reduction on many applications when\nquantization-aware training techniques are used. In parallel, spiking neural\nnetwork (SNN) architectures are explored to further reduce power when\nprocessing sparse event-based data streams, while on-chip spike-based online\nlearning appears as a key feature for applications constrained in power and\nresources during the training phase. However, designing power- and\narea-efficient spiking neural networks still requires the development of\nspecific techniques in order to leverage on-chip online learning on binary\nweights without compromising the synapse density. In this work, we demonstrate\nMorphIC, a quad-core binary-weight digital neuromorphic processor embedding a\nstochastic version of the spike-driven synaptic plasticity (S-SDSP) learning\nrule and a hierarchical routing fabric for large-scale chip interconnection.\nThe MorphIC SNN processor embeds a total of 2k leaky integrate-and-fire (LIF)\nneurons and more than two million plastic synapses for an active silicon area\nof 2.86mm$^2$ in 65nm CMOS, achieving a high density of 738k synapses/mm$^2$.\nMorphIC demonstrates an order-of-magnitude improvement in the area-accuracy\ntradeoff on the MNIST classification task compared to previously-proposed SNNs,\nwhile having no penalty in the energy-accuracy tradeoff.\n", "versions": [{"version": "v1", "created": "Wed, 17 Apr 2019 21:38:32 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 10:56:10 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Frenkel", "Charlotte", ""], ["Legat", "Jean-Didier", ""], ["Bol", "David", ""]]}, {"id": "1904.08577", "submitter": "William La Cava", "authors": "William La Cava, Jason H. Moore", "title": "Semantic variation operators for multidimensional genetic programming", "comments": "9 pages, 8 figures, GECCO 2019", "journal-ref": null, "doi": "10.1145/3321707.3321776", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multidimensional genetic programming represents candidate solutions as sets\nof programs, and thereby provides an interesting framework for exploiting\nbuilding block identification. Towards this goal, we investigate the use of\nmachine learning as a way to bias which components of programs are promoted,\nand propose two semantic operators to choose where useful building blocks are\nplaced during crossover. A forward stagewise crossover operator we propose\nleads to significant improvements on a set of regression problems, and produces\nstate-of-the-art results in a large benchmark study. We discuss this\narchitecture and others in terms of their propensity for allowing heuristic\nsearch to utilize information during the evolutionary process. Finally, we look\nat the collinearity and complexity of the data representations that result from\nthese architectures, with a view towards disentangling factors of variation in\napplication.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 03:05:37 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["La Cava", "William", ""], ["Moore", "Jason H.", ""]]}, {"id": "1904.08658", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Vinicius V. Melo, Danilo Vasconcellos Vargas, Wolfgang Banzhaf", "title": "Batch Tournament Selection for Genetic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexicase selection achieves very good solution quality by introducing ordered\ntest cases. However, the computational complexity of lexicase selection can\nprohibit its use in many applications. In this paper, we introduce Batch\nTournament Selection (BTS), a hybrid of tournament and lexicase selection which\nis approximately one order of magnitude faster than lexicase selection while\nachieving a competitive quality of solutions. Tests on a number of regression\ndatasets show that BTS compares well with lexicase selection in terms of mean\nabsolute error while having a speed-up of up to 25 times. Surprisingly, BTS and\nlexicase selection have almost no difference in both diversity and performance.\nThis reveals that batches and ordered test cases are completely different\nmechanisms which share the same general principle fostering the specialization\nof individuals. This work introduces an efficient algorithm that sheds light\nonto the main principles behind the success of lexicase, potentially opening up\na new range of possibilities for algorithms to come.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 09:53:20 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Melo", "Vinicius V.", ""], ["Vargas", "Danilo Vasconcellos", ""], ["Banzhaf", "Wolfgang", ""]]}, {"id": "1904.08809", "submitter": "Dario  Izzo", "authors": "Dario Izzo, Ekin \\\"Ozt\\\"urk, Marcus M\\\"artens", "title": "Interplanetary Transfers via Deep Representations of the Optimal Policy\n  and/or of the Value Function", "comments": null, "journal-ref": null, "doi": "10.1145/3319619.3326834", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of applications to interplanetary trajectories have been recently\nproposed based on deep networks. These approaches often rely on the\navailability of a large number of optimal trajectories to learn from. In this\npaper we introduce a new method to quickly create millions of optimal\nspacecraft trajectories from a single nominal trajectory. Apart from the\ngeneration of the nominal trajectory, no additional optimal control problems\nneed to be solved as all the trajectories, by construction, satisfy\nPontryagin's minimum principle and the relevant transversality conditions. We\nthen consider deep feed forward neural networks and benchmark three learning\nmethods on the created dataset: policy imitation, value function learning and\nvalue function gradient learning. Our results are shown for the case of the\ninterplanetary trajectory optimization problem of reaching Venus orbit, with\nthe nominal trajectory starting from the Earth. We find that both policy\nimitation and value function gradient learning are able to learn the optimal\nstate feedback, while in the case of value function learning the optimal policy\nis not captured, only the final value of the optimal propellant mass is.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 14:33:34 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Izzo", "Dario", ""], ["\u00d6zt\u00fcrk", "Ekin", ""], ["M\u00e4rtens", "Marcus", ""]]}, {"id": "1904.08823", "submitter": "Cheikh Toure", "authors": "Cheikh Tour\\'e, Nikolaus Hansen, Anne Auger, Dimo Brockhoff", "title": "Uncrowded Hypervolume Improvement: COMO-CMA-ES and the Sofomore\n  framework", "comments": null, "journal-ref": null, "doi": "10.1145/3321707.3321852", "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework to build a multiobjective algorithm from\nsingle-objective ones. This framework addresses the $p \\times n$-dimensional\nproblem of finding p solutions in an n-dimensional search space, maximizing an\nindicator by dynamic subspace optimization. Each single-objective algorithm\noptimizes the indicator function given $p - 1$ fixed solutions. Crucially,\ndominated solutions minimize their distance to the empirical Pareto front\ndefined by these $p - 1$ solutions. We instantiate the framework with CMA-ES as\nsingle-objective optimizer. The new algorithm, COMO-CMA-ES, is empirically\nshown to converge linearly on bi-objective convex-quadratic problems and is\ncompared to MO-CMA-ES, NSGA-II and SMS-EMOA.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 14:57:15 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Tour\u00e9", "Cheikh", ""], ["Hansen", "Nikolaus", ""], ["Auger", "Anne", ""], ["Brockhoff", "Dimo", ""]]}, {"id": "1904.08839", "submitter": "Yuriy Pershin", "authors": "Y. V. Pershin and M. Di Ventra", "title": "On the validity of memristor modeling in the neural network literature", "comments": null, "journal-ref": "Neural Networks 121, 52 (2020)", "doi": "10.1016/j.neunet.2019.08.026", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An analysis of the literature shows that there are two types of\nnon-memristive models that have been widely used in the modeling of so-called\n\"memristive\" neural networks. Here, we demonstrate that such models have\nnothing in common with the concept of memristive elements: they describe either\nnon-linear resistors or certain bi-state systems, which all are devices without\nmemory. Therefore, the results presented in a significant number of\npublications are at least questionable, if not completely irrelevant to the\nactual field of memristive neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 15:21:45 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Pershin", "Y. V.", ""], ["Di Ventra", "M.", ""]]}, {"id": "1904.08972", "submitter": "Ahmed Khalifa", "authors": "Ahmed Khalifa, Michael Cerny Green, Gabriella Barros, Julian Togelius", "title": "Intentional Computational Level Design", "comments": "8 pages, 10 figures, 3 tables, GECCO 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The procedural generation of levels and content in video games is a\nchallenging AI problem. Often such generation relies on an intelligent way of\nevaluating the content being generated so that constraints are satisfied and/or\nobjectives maximized. In this work, we address the problem of creating levels\nthat are not only playable but also revolve around specific mechanics in the\ngame. We use constrained evolutionary algorithms and quality-diversity\nalgorithms to generate small sections of Super Mario Bros levels called scenes,\nusing three different simulation approaches: Limited Agents, Punishing Model,\nand Mechanics Dimensions. All three approaches are able to create scenes that\ngive opportunity for a player to encounter or use targeted mechanics with\ndifferent properties. We conclude by discussing the advantages and\ndisadvantages of each approach and compare them to each other.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 19:10:58 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Khalifa", "Ahmed", ""], ["Green", "Michael Cerny", ""], ["Barros", "Gabriella", ""], ["Togelius", "Julian", ""]]}, {"id": "1904.09035", "submitter": "Bin Wang", "authors": "Bin Wang, Yanan Sun, Bing Xue and Mengjie Zhang", "title": "Evolving Deep Neural Networks by Multi-objective Particle Swarm\n  Optimization for Image Classification", "comments": "conditionally accepted by gecco2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, convolutional neural networks (CNNs) have become deeper in\norder to achieve better classification accuracy in image classification.\nHowever, it is difficult to deploy the state-of-the-art deep CNNs for\nindustrial use due to the difficulty of manually fine-tuning the\nhyperparameters and the trade-off between classification accuracy and\ncomputational cost. This paper proposes a novel multi-objective optimization\nmethod for evolving state-of-the-art deep CNNs in real-life applications, which\nautomatically evolves the non-dominant solutions at the Pareto front. Three\nmajor contributions are made: Firstly, a new encoding strategy is designed to\nencode one of the best state-of-the-art CNNs; With the classification accuracy\nand the number of floating point operations as the two objectives, a\nmulti-objective particle swarm optimization method is developed to evolve the\nnon-dominant solutions; Last but not least, a new infrastructure is designed to\nboost the experiments by concurrently running the experiments on multiple GPUs\nacross multiple machines, and a Python library is developed and released to\nmanage the infrastructure. The experimental results demonstrate that the\nnon-dominant solutions found by the proposed algorithm form a clear Pareto\nfront, and the proposed infrastructure is able to almost linearly reduce the\nrunning time.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 02:55:14 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 04:07:17 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Wang", "Bin", ""], ["Sun", "Yanan", ""], ["Xue", "Bing", ""], ["Zhang", "Mengjie", ""]]}, {"id": "1904.09090", "submitter": "Shayan Hassantabar", "authors": "Shayan Hassantabar, Zeyu Wang, Niraj K. Jha", "title": "SCANN: Synthesis of Compact and Accurate Neural Networks", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks (DNNs) have become the driving force behind recent\nartificial intelligence (AI) research. An important problem with implementing a\nneural network is the design of its architecture. Typically, such an\narchitecture is obtained manually by exploring its hyperparameter space and\nkept fixed during training. This approach is time-consuming and inefficient.\nAnother issue is that modern neural networks often contain millions of\nparameters, whereas many applications and devices require small inference\nmodels. However, efforts to migrate DNNs to such devices typically entail a\nsignificant loss of classification accuracy. To address these challenges, we\npropose a two-step neural network synthesis methodology, called DR+SCANN, that\ncombines two complementary approaches to design compact and accurate DNNs. At\nthe core of our framework is the SCANN methodology that uses three basic\narchitecture-changing operations, namely connection growth, neuron growth, and\nconnection pruning, to synthesize feed-forward architectures with arbitrary\nstructure. SCANN encapsulates three synthesis methodologies that apply a\nrepeated grow-and-prune paradigm to three architectural starting points.\nDR+SCANN combines the SCANN methodology with dataset dimensionality reduction\nto alleviate the curse of dimensionality. We demonstrate the efficacy of SCANN\nand DR+SCANN on various image and non-image datasets. We evaluate SCANN on\nMNIST and ImageNet benchmarks. In addition, we also evaluate the efficacy of\nusing dimensionality reduction alongside SCANN (DR+SCANN) on nine small to\nmedium-size datasets. We also show that our synthesis methodology yields neural\nnetworks that are much better at navigating the accuracy vs. energy efficiency\nspace. This would enable neural network-based inference even on\nInternet-of-Things sensors.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 06:26:03 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 03:02:43 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Hassantabar", "Shayan", ""], ["Wang", "Zeyu", ""], ["Jha", "Niraj K.", ""]]}, {"id": "1904.09098", "submitter": "Ashutosh Pednekar", "authors": "Ashutosh Mahesh Pednekar", "title": "Optimal initialization of K-means using Particle Swarm Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the use of an optimization algorithm, namely PSO to\ndecide the initial centroids in K-means, to eventually get better accuracy. The\nvectorized notation of the optimal centroids can be thought of as entities in\nan optimization space, where the accuracy of K-means over a random subset of\nthe data could act as a fitness measure. The resultant optimal vector can be\nused as the initial centroids for K-means.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 06:59:10 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Pednekar", "Ashutosh Mahesh", ""]]}, {"id": "1904.09103", "submitter": "Junghwan Lee", "authors": "Junghwan Lee and Yong-Hyuk Kim", "title": "Epistasis-based Basis Estimation Method for Simplifying the Problem\n  Space of an Evolutionary Search in Binary Representation", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An evolutionary search space can be smoothly transformed via a suitable\nchange of basis; however, it can be difficult to determine an appropriate\nbasis. In this paper, a method is proposed to select an optimum basis can be\nused to simplify an evolutionary search space in a binary encoding scheme. The\nbasis search method is based on a genetic algorithm and the fitness evaluation\nis based on the epistasis, which is an indicator of the complexity of a genetic\nalgorithm. Two tests were conducted to validate the proposed method when\napplied to two different evolutionary search problems. The first searched for\nan appropriate basis to apply, while the second searched for a solution to the\ntest problem. The results obtained after the identified basis had been applied\nwere compared to those with the original basis, and it was found that the\nproposed method provided superior results.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 07:36:50 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Lee", "Junghwan", ""], ["Kim", "Yong-Hyuk", ""]]}, {"id": "1904.09105", "submitter": "Yiwen Guo", "authors": "Yiwen Guo, Ming Lu, Wangmeng Zuo, Changshui Zhang, Yurong Chen", "title": "Deep Likelihood Network for Image Restoration with Multiple Degradation\n  Levels", "comments": "Accepted by IEEE Transactions on Image Processing; 13 pages, 6\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks have been proven effective in a variety of\nimage restoration tasks. Most state-of-the-art solutions, however, are trained\nusing images with a single particular degradation level, and their performance\ndeteriorates drastically when applied to other degradation settings. In this\npaper, we propose deep likelihood network (DL-Net), aiming at generalizing\noff-the-shelf image restoration networks to succeed over a spectrum of\ndegradation levels. We slightly modify an off-the-shelf network by appending a\nsimple recursive module, which is derived from a fidelity term, for\ndisentangling the computation for multiple degradation levels. Extensive\nexperimental results on image inpainting, interpolation, and super-resolution\nshow the effectiveness of our DL-Net.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 07:45:28 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 06:25:48 GMT"}, {"version": "v3", "created": "Tue, 19 Nov 2019 01:39:20 GMT"}, {"version": "v4", "created": "Sun, 10 Jan 2021 02:07:26 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Guo", "Yiwen", ""], ["Lu", "Ming", ""], ["Zuo", "Wangmeng", ""], ["Zhang", "Changshui", ""], ["Chen", "Yurong", ""]]}, {"id": "1904.09233", "submitter": "Ata Mahjoubfar", "authors": "Yueqin Li, Ata Mahjoubfar, Claire Lifan Chen, Kayvan Reza Niazi, Li\n  Pei, Bahram Jalali", "title": "Deep Cytometry: Deep learning with Real-time Inference in Cell Sorting\n  and Flow Cytometry", "comments": null, "journal-ref": "Scientific Reports 9 (2019) 11088", "doi": "10.1038/s41598-019-47193-6", "report-no": null, "categories": "q-bio.QM cs.NE physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved spectacular performance in image and speech\nrecognition and synthesis. It outperforms other machine learning algorithms in\nproblems where large amounts of data are available. In the area of measurement\ntechnology, instruments based on the photonic time stretch have established\nrecord real-time measurement throughput in spectroscopy, optical coherence\ntomography, and imaging flow cytometry. These extreme-throughput instruments\ngenerate approximately 1 Tbit/s of continuous measurement data and have led to\nthe discovery of rare phenomena in nonlinear and complex systems as well as new\ntypes of biomedical instruments. Owing to the abundance of data they generate,\ntime-stretch instruments are a natural fit to deep learning classification.\nPreviously we had shown that high-throughput label-free cell classification\nwith high accuracy can be achieved through a combination of time-stretch\nmicroscopy, image processing and feature extraction, followed by deep learning\nfor finding cancer cells in the blood. Such a technology holds promise for\nearly detection of primary cancer or metastasis. Here we describe a new deep\nlearning pipeline, which entirely avoids the slow and computationally costly\nsignal processing and feature extraction steps by a convolutional neural\nnetwork that directly operates on the measured signals. The improvement in\ncomputational efficiency enables low-latency inference and makes this pipeline\nsuitable for cell sorting via deep learning. Our neural network takes less than\na few milliseconds to classify the cells, fast enough to provide a decision to\na cell sorter for real-time separation of individual target cells. We\ndemonstrate the applicability of our new method in the classification of OT-II\nwhite blood cells and SW-480 epithelial cancer cells with more than 95%\naccuracy in a label-free fashion.\n", "versions": [{"version": "v1", "created": "Tue, 9 Apr 2019 07:09:26 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 07:50:43 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Li", "Yueqin", ""], ["Mahjoubfar", "Ata", ""], ["Chen", "Claire Lifan", ""], ["Niazi", "Kayvan Reza", ""], ["Pei", "Li", ""], ["Jalali", "Bahram", ""]]}, {"id": "1904.09239", "submitter": "Phan Trung Hai Nguyen", "authors": "Per Kristian Lehre and Phan Trung Hai Nguyen", "title": "Runtime Analysis of the Univariate Marginal Distribution Algorithm under\n  Low Selective Pressure and Prior Noise", "comments": "To appear at GECCO 2019, Prague, Czech Republic", "journal-ref": null, "doi": "10.1145/3321707.3321834", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform a rigorous runtime analysis for the Univariate Marginal\nDistribution Algorithm on the LeadingOnes function, a well-known benchmark\nfunction in the theory community of evolutionary computation with a high\ncorrelation between decision variables. For a problem instance of size $n$, the\ncurrently best known upper bound on the expected runtime is\n$\\mathcal{O}(n\\lambda\\log\\lambda+n^2)$ (Dang and Lehre, GECCO 2015), while a\nlower bound necessary to understand how the algorithm copes with variable\ndependencies is still missing. Motivated by this, we show that the algorithm\nrequires a $e^{\\Omega(\\mu)}$ runtime with high probability and in expectation\nif the selective pressure is low; otherwise, we obtain a lower bound of\n$\\Omega(\\frac{n\\lambda}{\\log(\\lambda-\\mu)})$ on the expected runtime.\nFurthermore, we for the first time consider the algorithm on the function under\na prior noise model and obtain an $\\mathcal{O}(n^2)$ expected runtime for the\noptimal parameter settings. In the end, our theoretical results are accompanied\nby empirical findings, not only matching with rigorous analyses but also\nproviding new insights into the behaviour of the algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 15:49:27 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Lehre", "Per Kristian", ""], ["Nguyen", "Phan Trung Hai", ""]]}, {"id": "1904.09317", "submitter": "Christopher Kanan", "authors": "Kushal Kafle, Robik Shrestha, Christopher Kanan", "title": "Challenges and Prospects in Vision and Language Research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language grounded image understanding tasks have often been proposed as a\nmethod for evaluating progress in artificial intelligence. Ideally, these tasks\nshould test a plethora of capabilities that integrate computer vision,\nreasoning, and natural language understanding. However, rather than behaving as\nvisual Turing tests, recent studies have demonstrated state-of-the-art systems\nare achieving good performance through flaws in datasets and evaluation\nprocedures. We review the current state of affairs and outline a path forward.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 19:04:12 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 22:10:33 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Kafle", "Kushal", ""], ["Shrestha", "Robik", ""], ["Kanan", "Christopher", ""]]}, {"id": "1904.09330", "submitter": "Pouya Bashivan", "authors": "Pouya Bashivan, Martin Schrimpf, Robert Ajemian, Irina Rish, Matthew\n  Riemer, Yuhai Tu", "title": "Continual Learning with Self-Organizing Maps", "comments": "Continual Learning Workshop - NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite remarkable successes achieved by modern neural networks in a wide\nrange of applications, these networks perform best in domain-specific\nstationary environments where they are trained only once on large-scale\ncontrolled data repositories. When exposed to non-stationary learning\nenvironments, current neural networks tend to forget what they had previously\nlearned, a phenomena known as catastrophic forgetting. Most previous approaches\nto this problem rely on memory replay buffers which store samples from\npreviously learned tasks, and use them to regularize the learning on new ones.\nThis approach suffers from the important disadvantage of not scaling well to\nreal-life problems in which the memory requirements become enormous. We propose\na memoryless method that combines standard supervised neural networks with\nself-organizing maps to solve the continual learning problem. The role of the\nself-organizing map is to adaptively cluster the inputs into appropriate task\ncontexts - without explicit labels - and allocate network resources\naccordingly. Thus, it selectively routes the inputs in accord with previous\nexperience, ensuring that past learning is maintained and does not interfere\nwith current learning. Out method is intuitive, memoryless, and performs on par\nwith current state-of-the-art approaches on standard benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 20:21:23 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Bashivan", "Pouya", ""], ["Schrimpf", "Martin", ""], ["Ajemian", "Robert", ""], ["Rish", "Irina", ""], ["Riemer", "Matthew", ""], ["Tu", "Yuhai", ""]]}, {"id": "1904.09352", "submitter": "Tarik A. Rashid", "authors": "Ahmed S. Shamsaldin, Tarik A. Rashid, Rawan A. Al-Rashid Agha, Nawzad\n  K. Al-Salihi, Mokhtar Mohammadi (Computer Science and Engineering Department,\n  University of Kurdistan Hewler, Erbil, Kurdistan, Iraq and Department of\n  Information Technology, University of Human Development, Sulaymaniyah,\n  Kurdistan, Iraq.)", "title": "Donkey and Smuggler Optimization Algorithm: A Collaborative Working\n  Approach to Path Finding", "comments": "29 pages, Journal of Computational Design and Engineering, 2109", "journal-ref": null, "doi": "10.1016/j.jcde.2019.04.004", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Swarm Intelligence is a metaheuristic optimization approach that has become\nvery predominant over the last few decades. These algorithms are inspired by\nanimals' physical behaviors and their evolutionary perceptions. The simplicity\nof these algorithms allows researchers to simulate different natural phenomena\nto solve various real-world problems. This paper suggests a novel algorithm\ncalled Donkey and Smuggler Optimization Algorithm (DSO). The DSO is inspired by\nthe searching behavior of donkeys. The algorithm imitates transportation\nbehavior such as searching and selecting routes for movement by donkeys in the\nactual world. Two modes are established for implementing the search behavior\nand route-selection in this algorithm. These are the Smuggler and Donkeys. In\nthe Smuggler mode, all the possible paths are discovered and the shortest path\nis then found. In the Donkeys mode, several donkey behaviors are utilized such\nas Run, Face & Suicide, and Face & Support. Real world data and applications\nare used to test the algorithm. The experimental results consisted of two\nparts, firstly, we used the standard benchmark test functions to evaluate the\nperformance of the algorithm in respect to the most popular and the state of\nthe art algorithms. Secondly, the DSO is adapted and implemented on three\nreal-world applications namely; traveling salesman problem, packet routing, and\nambulance routing. The experimental results of DSO on these real-world problems\nare very promising. The results exhibit that the suggested DSO is appropriate\nto tackle other unfamiliar search spaces and complex problems.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 21:45:34 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Shamsaldin", "Ahmed S.", "", "Computer Science and Engineering Department,\n  University of Kurdistan Hewler, Erbil, Kurdistan, Iraq and Department of\n  Information Technology, University of Human Development, Sulaymaniyah,\n  Kurdistan, Iraq."], ["Rashid", "Tarik A.", "", "Computer Science and Engineering Department,\n  University of Kurdistan Hewler, Erbil, Kurdistan, Iraq and Department of\n  Information Technology, University of Human Development, Sulaymaniyah,\n  Kurdistan, Iraq."], ["Agha", "Rawan A. Al-Rashid", "", "Computer Science and Engineering Department,\n  University of Kurdistan Hewler, Erbil, Kurdistan, Iraq and Department of\n  Information Technology, University of Human Development, Sulaymaniyah,\n  Kurdistan, Iraq."], ["Al-Salihi", "Nawzad K.", "", "Computer Science and Engineering Department,\n  University of Kurdistan Hewler, Erbil, Kurdistan, Iraq and Department of\n  Information Technology, University of Human Development, Sulaymaniyah,\n  Kurdistan, Iraq."], ["Mohammadi", "Mokhtar", "", "Computer Science and Engineering Department,\n  University of Kurdistan Hewler, Erbil, Kurdistan, Iraq and Department of\n  Information Technology, University of Human Development, Sulaymaniyah,\n  Kurdistan, Iraq."]]}, {"id": "1904.09477", "submitter": "Eisa Alanazi", "authors": "Abdulaziz Alashaikh and Eisa Alanazi", "title": "Preference-based Multiobjective Virtual Machine Placement: A Ceteris\n  Paribus Approach", "comments": "a pre-print for GECCO 2019 2 pages poster", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work adopts the notion of Ceteris Paribus (CP) as an interpretation of\nthe Decision Maker (DM) preferences and incorporates it in a constrained\nmultiobjective problem known as virtual machine placement (VMP). VMP is an\nessential multiobjective problem in the design and operation of cloud data\ncenters concerned about placing each virtual machine to a physical machine (a\nserver) in the data center. We analyze the effectiveness of CP interpretation\non VMP problems and propose an NSGA-II variant with which preferred solutions\nare returned at almost no extra time cost.\n", "versions": [{"version": "v1", "created": "Sat, 20 Apr 2019 18:26:03 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Alashaikh", "Abdulaziz", ""], ["Alanazi", "Eisa", ""]]}, {"id": "1904.09599", "submitter": "Mehdi Neshat", "authors": "Mehdi Neshat, Bradley Alexander, Nataliia Sergiienko, Markus Wagner", "title": "A new insight into the Position Optimization of Wave Energy Converters\n  by a Hybrid Local Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Renewable energy, such as ocean wave energy, plays a pivotal role in\naddressing the tremendous growth of global energy demand. It is expected that\nwave energy will be one of the fastest-growing energy resources in the next\ndecade, offering an enormous potential source of sustainable energy. This\nresearch investigates the placement optimization of oscillating buoy-type wave\nenergy converters (WEC). The design of a wave farm consisting of an array of\nfully submerged three-tether buoys is evaluated. In a wave farm, buoy positions\nhave a notable impact on the farm's output. Optimizing the buoy positions is a\nchallenging research problem because of very complex interactions (constructive\nand destructive) between buoys. The main purpose of this research is maximizing\nthe power output of the farm through the placement of buoys in a\nsize-constrained environment. This paper proposes a new hybrid approach of the\nheuristic local search combined with a numerical optimization method that\nutilizes a knowledge-based surrogate power model.\n  We compare the proposed hybrid method with other state-of-the-art search\nmethods in five different wave scenarios -- one simplified irregular wave model\nand four real wave climates. Our method considerably outperforms all previous\nheuristic methods in terms of both quality of achieved solutions and the\nconvergence-rate of search in all tested wave regimes.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 13:18:51 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 13:26:24 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Neshat", "Mehdi", ""], ["Alexander", "Bradley", ""], ["Sergiienko", "Nataliia", ""], ["Wagner", "Markus", ""]]}, {"id": "1904.09681", "submitter": "Evangelos Pournaras", "authors": "Jovan Nikolic, Evangelos Pournaras", "title": "Structural Self-adaptation for Decentralized Pervasive Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication structure plays a key role in the learning capability of\ndecentralized systems. Structural self-adaptation, by means of\nself-organization, changes the order as well as the input information of the\nagents' collective decision-making. This paper studies the role of agents'\nrepositioning on the same communication structure, i.e. a tree, as the means to\nexpand the learning capacity in complex combinatorial optimization problems,\nfor instance, load-balancing power demand to prevent blackouts or efficient\nutilization of bike sharing stations. The optimality of structural\nself-adaptations is rigorously studied by constructing a novel large-scale\nbenchmark that consists of 4000 agents with synthetic and real-world data\nperforming 4 million structural self-adaptations during which almost 320\nbillion learning messages are exchanged. Based on this benchmark dataset, 124\ndeterministic structural criteria, applied as learning meta-features, are\nsystematically evaluated as well as two online structural self-adaptation\nstrategies designed to expand learning capacity. Experimental evaluation\nidentifies metrics that capture agents with influential information and their\noptimal positioning. Significant gain in learning performance is observed for\nthe two strategies especially under low-performing initialization. Strikingly,\nthe strategy that triggers structural self-adaptation in a more exploratory\nfashion is the most cost-effective.\n", "versions": [{"version": "v1", "created": "Sun, 21 Apr 2019 23:55:01 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 11:31:09 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Nikolic", "Jovan", ""], ["Pournaras", "Evangelos", ""]]}, {"id": "1904.09813", "submitter": "Hao Tong", "authors": "Hao Tong, Jialin Liu, Xin Yao", "title": "Algorithm Portfolio for Individual-based Surrogate-Assisted Evolutionary\n  Algorithms", "comments": null, "journal-ref": null, "doi": "10.1145/3321707.3321715", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surrogate-assisted evolutionary algorithms (SAEAs) are powerful optimisation\ntools for computationally expensive problems (CEPs). However, a randomly\nselected algorithm may fail in solving unknown problems due to no free lunch\ntheorems, and it will cause more computational resource if we re-run the\nalgorithm or try other algorithms to get a much solution, which is more serious\nin CEPs. In this paper, we consider an algorithm portfolio for SAEAs to reduce\nthe risk of choosing an inappropriate algorithm for CEPs. We propose two\nportfolio frameworks for very expensive problems in which the maximal number of\nfitness evaluations is only 5 times of the problem's dimension. One framework\nnamed Par-IBSAEA runs all algorithm candidates in parallel and a more\nsophisticated framework named UCB-IBSAEA employs the Upper Confidence Bound\n(UCB) policy from reinforcement learning to help select the most appropriate\nalgorithm at each iteration. An effective reward definition is proposed for the\nUCB policy. We consider three state-of-the-art individual-based SAEAs on\ndifferent problems and compare them to the portfolios built from their\ninstances on several benchmark problems given limited computation budgets. Our\nexperimental studies demonstrate that our proposed portfolio frameworks\nsignificantly outperform any single algorithm on the set of benchmark problems.\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 12:09:52 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 09:12:25 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Tong", "Hao", ""], ["Liu", "Jialin", ""], ["Yao", "Xin", ""]]}, {"id": "1904.09872", "submitter": "Evgenii Zheltonozhskii", "authors": "Yochai Zur, Chaim Baskin, Evgenii Zheltonozhskii, Brian Chmiel, Itay\n  Evron, Alex M. Bronstein and Avi Mendelson", "title": "Towards Learning of Filter-Level Heterogeneous Compression of\n  Convolutional Neural Networks", "comments": "Accepted to ICML Workshop on AutoML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, deep learning has become a de facto standard in machine learning\nwith convolutional neural networks (CNNs) demonstrating spectacular success on\na wide variety of tasks. However, CNNs are typically very demanding\ncomputationally at inference time. One of the ways to alleviate this burden on\ncertain hardware platforms is quantization relying on the use of low-precision\narithmetic representation for the weights and the activations. Another popular\nmethod is the pruning of the number of filters in each layer. While mainstream\ndeep learning methods train the neural networks weights while keeping the\nnetwork architecture fixed, the emerging neural architecture search (NAS)\ntechniques make the latter also amenable to training. In this paper, we\nformulate optimal arithmetic bit length allocation and neural network pruning\nas a NAS problem, searching for the configurations satisfying a computational\ncomplexity budget while maximizing the accuracy. We use a differentiable search\nmethod based on the continuous relaxation of the search space proposed by Liu\net al. (arXiv:1806.09055). We show, by grid search, that heterogeneous\nquantized networks suffer from a high variance which renders the benefit of the\nsearch questionable. For pruning, improvement over homogeneous cases is\npossible, but it is still challenging to find those configurations with the\nproposed method. The code is publicly available at\nhttps://github.com/yochaiz/Slimmable and https://github.com/yochaiz/darts-UNIQ\n", "versions": [{"version": "v1", "created": "Mon, 22 Apr 2019 13:43:34 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 09:24:07 GMT"}, {"version": "v3", "created": "Sun, 9 Jun 2019 10:40:41 GMT"}, {"version": "v4", "created": "Thu, 26 Sep 2019 14:45:46 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Zur", "Yochai", ""], ["Baskin", "Chaim", ""], ["Zheltonozhskii", "Evgenii", ""], ["Chmiel", "Brian", ""], ["Evron", "Itay", ""], ["Bronstein", "Alex M.", ""], ["Mendelson", "Avi", ""]]}, {"id": "1904.09879", "submitter": "Alexander Wong", "authors": "Audrey Chung, Paul Fieguth, and Alexander Wong", "title": "Assessing Architectural Similarity in Populations of Deep Neural\n  Networks", "comments": "3 pages. arXiv admin note: text overlap with arXiv:1811.07966", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary deep intelligence has recently shown great promise for producing\nsmall, powerful deep neural network models via the synthesis of increasingly\nefficient architectures over successive generations. Despite recent research\nshowing the efficacy of multi-parent evolutionary synthesis, little has been\ndone to directly assess architectural similarity between networks during the\nsynthesis process for improved parent network selection. In this work, we\npresent a preliminary study into quantifying architectural similarity via the\npercentage overlap of architectural clusters. Results show that networks\nsynthesized using architectural alignment (via gene tagging) maintain higher\narchitectural similarities within each generation, potentially restricting the\nsearch space of highly efficient network architectures.\n", "versions": [{"version": "v1", "created": "Fri, 19 Apr 2019 13:33:49 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Chung", "Audrey", ""], ["Fieguth", "Paul", ""], ["Wong", "Alexander", ""]]}, {"id": "1904.10045", "submitter": "ShiLiang Zhang", "authors": "Shiliang Zhang and Ming Lei and Zhijie Yan", "title": "Automatic Spelling Correction with Transformer for CTC-based End-to-End\n  Speech Recognition", "comments": "6pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.NE cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectionist Temporal Classification (CTC) based end-to-end speech\nrecognition system usually need to incorporate an external language model by\nusing WFST-based decoding in order to achieve promising results. This is more\nessential to Mandarin speech recognition since it owns a special phenomenon,\nnamely homophone, which causes a lot of substitution errors. The linguistic\ninformation introduced by language model will help to distinguish these\nsubstitution errors. In this work, we propose a transformer based spelling\ncorrection model to automatically correct errors especially the substitution\nerrors made by CTC-based Mandarin speech recognition system. Specifically, we\ninvestigate using the recognition results generated by CTC-based systems as\ninput and the ground-truth transcriptions as output to train a transformer with\nencoder-decoder architecture, which is much similar to machine translation.\nResults in a 20,000 hours Mandarin speech recognition task show that the\nproposed spelling correction model can achieve a CER of 3.41%, which results in\n22.9% and 53.2% relative improvement compared to the baseline CTC-based systems\ndecoded with and without language model respectively.\n", "versions": [{"version": "v1", "created": "Wed, 27 Mar 2019 07:16:48 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Zhang", "Shiliang", ""], ["Lei", "Ming", ""], ["Yan", "Zhijie", ""]]}, {"id": "1904.10278", "submitter": "Robert Csordas", "authors": "R\\'obert Csord\\'as, J\\\"urgen Schmidhuber", "title": "Improving Differentiable Neural Computers Through Memory Masking,\n  De-allocation, and Link Distribution Sharpness Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Differentiable Neural Computer (DNC) can learn algorithmic and question\nanswering tasks. An analysis of its internal activation patterns reveals three\nproblems: Most importantly, the lack of key-value separation makes the address\ndistribution resulting from content-based look-up noisy and flat, since the\nvalue influences the score calculation, although only the key should. Second,\nDNC's de-allocation of memory results in aliasing, which is a problem for\ncontent-based look-up. Thirdly, chaining memory reads with the temporal linkage\nmatrix exponentially degrades the quality of the address distribution. Our\nproposed fixes of these problems yield improved performance on arithmetic\ntasks, and also improve the mean error rate on the bAbI question answering\ndataset by 43%.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 12:32:54 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Csord\u00e1s", "R\u00f3bert", ""], ["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1904.10400", "submitter": "Abeegithan Jeyasothy", "authors": "Abeegithan Jeyasothy, Savitha Ramasamy, Suresh Sundaram", "title": "Efficient single input-output layer spiking neural classifier with\n  time-varying weight model", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a supervised learning algorithm, namely, the Synaptic\nEfficacy Function with Meta-neuron based learning algorithm (SEF-M) for a\nspiking neural network with a time-varying weight model. For a given pattern,\nSEF-M uses the learning algorithm derived from meta-neuron based learning\nalgorithm to determine the change in weights corresponding to each presynaptic\nspike times. The changes in weights modulate the amplitude of a Gaussian\nfunction centred at the same presynaptic spike times. The sum of amplitude\nmodulated Gaussian functions represents the synaptic efficacy functions (or\ntime-varying weight models). The performance of SEF-M is evaluated against\nstate-of-the-art spiking neural network learning algorithms on 10 benchmark\ndatasets from UCI machine learning repository. Performance studies show\nsuperior generalization ability of SEF-M. An ablation study on time-varying\nweight model is conducted using JAFFE dataset. The results of the ablation\nstudy indicate that using a time-varying weight model instead of single weight\nmodel improves the classification accuracy by 14%. Thus, it can be inferred\nthat a single input-output layer spiking neural network with time-varying\nweight model is computationally more efficient than a multi-layer spiking\nneural network with long-term or short-term weight model.\n", "versions": [{"version": "v1", "created": "Thu, 21 Mar 2019 06:49:01 GMT"}], "update_date": "2019-04-24", "authors_parsed": [["Jeyasothy", "Abeegithan", ""], ["Ramasamy", "Savitha", ""], ["Sundaram", "Suresh", ""]]}, {"id": "1904.10494", "submitter": "Luca Mariot", "authors": "Luca Manzoni and Luca Mariot and Eva Tuba", "title": "Balanced Crossover Operators in Genetic Algorithms", "comments": "26 pages, 9 figures. General revision of the original draft following\n  reviews", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several combinatorial optimization problems arising in cryptography and\ndesign theory, the admissible solutions must often satisfy a balancedness\nconstraint, such as being represented by bitstrings with a fixed number of\nones. For this reason, several works in the literature tackling these\noptimization problems with Genetic Algorithms (GA) introduced new balanced\ncrossover operators which ensure that the offspring has the same balancedness\ncharacteristics of the parents. However, the use of such operators has never\nbeen thoroughly motivated, except for some generic considerations about search\nspace reduction.\n  In this paper, we undertake a rigorous statistical investigation on the\neffect of balanced and unbalanced crossover operators against three\noptimization problems from the area of cryptography and coding theory:\nnonlinear balanced Boolean functions, binary Orthogonal Arrays (OA) and bent\nfunctions. In particular, we consider three different balanced crossover\noperators (each with two variants: \"left-to-right\" and \"shuffled\"), two of\nwhich have never been published before, and compare their performances with\nclassic one-point crossover. We are able to confirm that the balanced crossover\noperators performs better than all three balanced crossover operators.\nFurthermore, in two out of three crossovers, the \"left-to-right\" version\nperforms better than the \"shuffled\" version.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 18:55:10 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 20:59:14 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Manzoni", "Luca", ""], ["Mariot", "Luca", ""], ["Tuba", "Eva", ""]]}, {"id": "1904.10508", "submitter": "Yasunao Katayama Ph.D.", "authors": "Yasunao Katayama", "title": "Quantum-Inspired Computing: Can it be a Microscopic Computing Model of\n  the Brain?", "comments": "31 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing and the workings of the brain have many aspects in common\nand have been attracting increasing attention in academia and industry. The\ncomputation in both is parallel and non-discrete. Though the underlying\nphysical dynamics (e.g., equation of motion) may be deterministic, the observed\nor interpreted outcomes are often probabilistic. Consequently, various\ninvestigations have been undertaken to understand and reproduce the brain on\nthe basis of quantum physics and computing. However, there have been arguments\non whether the brain can and have to take advantage of quantum phenomena that\nneed to survive in the macroscopic space-time region at room temperature. This\npaper presents a unique microscopic computational model for the brain based on\nan ansatz that the brain computes in a manner similar to quantum computing, but\nwith classical waves. Log-scale encoding of information in the context of\ncomputing with waves is shown to play a critical role in bridging the computing\nmodels with classical and quantum waves. Our quantum-inspired computing model\nopens up a possibility of unifying the computing framework of artificial\nintelligence and quantum computing beyond quantum machine learning approaches.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 01:12:23 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 02:28:54 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Katayama", "Yasunao", ""]]}, {"id": "1904.10656", "submitter": "Amy K Hoover", "authors": "Matthew C. Fontaine, Scott Lee, L.B. Soros, Fernando De Mesentier\n  Silva, Julian Togelius, and Amy K. Hoover", "title": "Mapping Hearthstone Deck Spaces through MAP-Elites with Sliding\n  Boundaries", "comments": "Accepted to the Genetic and Evolutionary Computation Conference\n  (GECCO-2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality diversity (QD) algorithms such as MAP-Elites have emerged as a\npowerful alternative to traditional single-objective optimization methods. They\nwere initially applied to evolutionary robotics problems such as locomotion and\nmaze navigation, but have yet to see widespread application. We argue that\nthese algorithms are perfectly suited to the rich domain of video games, which\ncontains many relevant problems with a multitude of successful strategies and\noften also multiple dimensions along which solutions can vary.\n  This paper introduces a novel modification of the MAP-Elites algorithm called\nMAP-Elites with Sliding Boundaries (MESB) and applies it to the design and\nrebalancing of Hearthstone, a popular collectible card game chosen for its\nnumber of multidimensional behavior features relevant to particular styles of\nplay. To avoid overpopulating cells with conflated behaviors, MESB slides the\nboundaries of cells based on the distribution of evolved individuals.\nExperiments in this paper demonstrate the performance of MESB in Hearthstone.\nResults suggest MESB finds diverse ways of playing the game well along the\nselected behavioral dimensions. Further analysis of the evolved strategies\nreveals common patterns that recur across behavioral dimensions and explores\nhow MESB can help rebalance the game.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 06:37:29 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Fontaine", "Matthew C.", ""], ["Lee", "Scott", ""], ["Soros", "L. B.", ""], ["Silva", "Fernando De Mesentier", ""], ["Togelius", "Julian", ""], ["Hoover", "Amy K.", ""]]}, {"id": "1904.10674", "submitter": "Nicolas Audebert", "authors": "Nicolas Audebert (OBELIX), Bertrand Saux, S\\'ebastien Lef\\`evre\n  (OBELIX)", "title": "Deep Learning for Classification of Hyperspectral Data: A Comparative\n  Review", "comments": null, "journal-ref": null, "doi": "10.1109/MGRS.2019.2912563", "report-no": null, "categories": "cs.LG cs.CV cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning techniques revolutionized the way remote\nsensing data are processed. Classification of hyperspectral data is no\nexception to the rule, but has intrinsic specificities which make application\nof deep learning less straightforward than with other optical data. This\narticle presents a state of the art of previous machine learning approaches,\nreviews the various deep learning approaches currently proposed for\nhyperspectral classification, and identifies the problems and difficulties\nwhich arise to implement deep neural networks for this task. In particular, the\nissues of spatial and spectral resolution, data volume, and transfer of models\nfrom multimedia images to hyperspectral data are addressed. Additionally, a\ncomparative study of various families of network architectures is provided and\na software toolbox is publicly released to allow experimenting with these\nmethods. 1 This article is intended for both data scientists with interest in\nhyperspectral data and remote sensing experts eager to apply deep learning\ntechniques to their own dataset.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 07:56:37 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Audebert", "Nicolas", "", "OBELIX"], ["Saux", "Bertrand", "", "OBELIX"], ["Lef\u00e8vre", "S\u00e9bastien", "", "OBELIX"]]}, {"id": "1904.10924", "submitter": "Muhammad Usman Sadiq", "authors": "Muhammad Usman Sadiq, Diana Svaldi, Trey Shenk, Evan Breedlove,\n  Victoria Poole, Greg Tamer, Kausar Abbas, Thomas Talavage", "title": "Alterations in Structural Correlation Networks with Prior Concussion in\n  Collision-Sport Athletes", "comments": null, "journal-ref": "Originally published at: Annual meeting of the Organization for\n  Human Brain Mapping, OHBM 2018", "doi": null, "report-no": null, "categories": "q-bio.QM cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several studies have used structural correlation networks, derived from\nanatomical covariance of brain regions, to analyze neurologic changes\nassociated with multiple sclerosis, schizophrenia and breast cancer [1][2].\nGraph-theoretical analyses of human brain structural networks have consistently\nshown the characteristic of small-worldness that reflects a network with both\nhigh segregation and high integration. A large neuroimaging literature on\nfootball players, with and without history of concussion, has shown both\nfunctional and anatomical changes. Here we use graph-based topological\nproperties of anatomical correlation networks to study the effect of prior\nconcussion in collision-sport athletes. 40 high school collision-sport athletes\n(23 male football, 17 female soccer; CSA) without self-reported history of\nconcussion (HOC-), 18 athletes (13 male football, 5 female soccer) with\nself-reported history of concussion (HOC+) and 24 healthy controls (19 male, 5\nfemale; CN) participated in imaging sessions before the beginning of a\ncompetition season. The extracted residual volumes for each group were used for\nbuilding the correlation networks and their small-worldness, , is calculated.\nThe small-worldness of CSA without prior history of concussion, , is\nsignificantly greater than that of controls, . CSA with prior history have\nsignificantly higher (vs. 95% confidence interval) small-worldness compared to\nHOC+, over a range of network densities. The longer path lengths in HOC+ group\ncould indicate disrupted neuronal integration relative to healthy controls.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 17:34:17 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Sadiq", "Muhammad Usman", ""], ["Svaldi", "Diana", ""], ["Shenk", "Trey", ""], ["Breedlove", "Evan", ""], ["Poole", "Victoria", ""], ["Tamer", "Greg", ""], ["Abbas", "Kausar", ""], ["Talavage", "Thomas", ""]]}, {"id": "1904.10931", "submitter": "Alex Fedorov", "authors": "Alex Fedorov, R Devon Hjelm, Anees Abrol, Zening Fu, Yuhui Du, Sergey\n  Plis, Vince D. Calhoun", "title": "Prediction of Progression to Alzheimer's disease with Deep InfoMax", "comments": "Accepted to 2019 IEEE Biomedical and Health Informatics (BHI) as a\n  conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Arguably, unsupervised learning plays a crucial role in the majority of\nalgorithms for processing brain imaging. A recently introduced unsupervised\napproach Deep InfoMax (DIM) is a promising tool for exploring brain structure\nin a flexible non-linear way. In this paper, we investigate the use of variants\nof DIM in a setting of progression to Alzheimer's disease in comparison with\nsupervised AlexNet and ResNet inspired convolutional neural networks. As a\nbenchmark, we use a classification task between four groups: patients with\nstable, and progressive mild cognitive impairment (MCI), with Alzheimer's\ndisease, and healthy controls. Our dataset is comprised of 828 subjects from\nthe Alzheimer's Disease Neuroimaging Initiative (ADNI) database. Our\nexperiments highlight encouraging evidence of the high potential utility of DIM\nin future neuroimaging studies.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 17:10:11 GMT"}, {"version": "v2", "created": "Tue, 30 Apr 2019 16:01:34 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 02:13:22 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Fedorov", "Alex", ""], ["Hjelm", "R Devon", ""], ["Abrol", "Anees", ""], ["Fu", "Zening", ""], ["Du", "Yuhui", ""], ["Plis", "Sergey", ""], ["Calhoun", "Vince D.", ""]]}, {"id": "1904.10932", "submitter": "Mikel Malagon", "authors": "Mikel Malagon and Josu Ceberio", "title": "Evolving Neural Networks in Reinforcement Learning by means of UMDAc", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Neural networks are gaining popularity in the reinforcement learning field\ndue to the vast number of successfully solved complex benchmark problems. In\nfact, artificial intelligence algorithms are, in some cases, able to overcome\nhuman professionals. Usually, neural networks have more than a couple of hidden\nlayers, and thus, they involve a large quantity of parameters that need to be\noptimized. Commonly, numeric approaches are used to optimize the inner\nparameters of neural networks, such as the stochastic gradient descent.\nHowever, these techniques tend to be computationally very expensive, and for\nsome tasks, where effectiveness is crucial, high computational costs are not\nacceptable. Along these research lines, in this paper we propose to optimize\nthe parameters of neural networks by means of estimation of distribution\nalgorithms. More precisely, the univariate marginal distribution algorithm is\nused for evolving neural networks in various reinforcement learning tasks. For\nthe sake of validating our idea, we run the proposed algorithm on four OpenAI\nGym benchmark problems. In addition, the obtained results were compared with a\nstandard genetic algorithm. Revealing, that optimizing with UMDAc provides\nbetter results than the genetic algorithm in most of the cases.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 17:12:42 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Malagon", "Mikel", ""], ["Ceberio", "Josu", ""]]}, {"id": "1904.11243", "submitter": "Juan Pedro Dominguez-Morales", "authors": "Daniel Gutierrez-Galan, Juan Pedro Dominguez-Morales, Fernando\n  Perez-Pena, Alejandro Linares-Barranco", "title": "NeuroPod: a real-time neuromorphic spiking CPG applied to robotics", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2019.11.007", "report-no": null, "categories": "cs.RO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Initially, robots were developed with the aim of making our life easier,\ncarrying out repetitive or dangerous tasks for humans. Although they were able\nto perform these tasks, the latest generation of robots are being designed to\ntake a step further, by performing more complex tasks that have been carried\nout by smart animals or humans up to date. To this end, inspiration needs to be\ntaken from biological examples. For instance, insects are able to optimally\nsolve complex environment navigation problems, and many researchers have\nstarted to mimic how these insects behave. Recent interest in neuromorphic\nengineering has motivated us to present a real-time, neuromorphic, spike-based\nCentral Pattern Generator of application in neurorobotics, using an\narthropod-like robot. A Spiking Neural Network was designed and implemented on\nSpiNNaker. The network models a complex, online-change capable Central Pattern\nGenerator which generates three gaits for a hexapod robot locomotion.\nReconfigurable hardware was used to manage both the motors of the robot and the\nreal-time communication interface with the Spiking Neural Networks. Real-time\nmeasurements confirm the simulation results, and locomotion tests show that\nNeuroPod can perform the gaits without any balance loss or added delay.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 09:55:50 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Gutierrez-Galan", "Daniel", ""], ["Dominguez-Morales", "Juan Pedro", ""], ["Perez-Pena", "Fernando", ""], ["Linares-Barranco", "Alejandro", ""]]}, {"id": "1904.11367", "submitter": "Abeegithan Jeyasothy", "authors": "Abeegithan Jeyasothy, Suresh Sundaram, Savitha Ramasamy, Narasimhan\n  Sundararajan", "title": "A novel method for extracting interpretable knowledge from a spiking\n  neural classifier with time-varying synaptic weights", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel method for information interpretability in an\nMC-SEFRON classifier. To develop a method to extract knowledge stored in a\ntrained classifier, first, the binary-class SEFRON classifier developed earlier\nis extended to handle multi-class problems. MC-SEFRON uses the population\nencoding scheme to encode the real-valued input data into spike patterns.\nMC-SEFRON is trained using the same supervised learning rule used in the\nSEFRON. After training, the proposed method extracts the knowledge for a given\nclass stored in the classifier by mapping the weighted postsynaptic potential\nin the time domain to the feature domain as Feature Strength Functions (FSFs).\nA set of FSFs corresponding to each output class represents the extracted\nknowledge from the classifier. This knowledge encoding method is derived to\nmaintain consistency between the classification in the time domain and the\nfeature domain. The correctness of the FSF is quantitatively measured by using\nFSF directly for classification tasks. For a given input, each FSF is sampled\nat the input value to obtain the corresponding feature strength value (FSV).\nThen the aggregated FSVs obtained for each class are used to determine the\noutput class labels during classification. FSVs are also used to interpret the\npredictions during the classification task. Using ten UCI datasets and the\nMNIST dataset, the knowledge extraction method, interpretation and the\nreliability of the FSF are demonstrated. Based on the studies, it can be seen\nthat on an average, the difference in the classification accuracies using the\nFSF directly and those obtained by MC-SEFRON is only around 0.9% & 0.1\\% for\nthe UCI datasets and the MNIST dataset respectively. This clearly shows that\nthe knowledge represented by the FSFs has acceptable reliability and the\ninterpretability of classification using the classifier's knowledge has been\njustified.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 09:49:42 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Jeyasothy", "Abeegithan", ""], ["Sundaram", "Suresh", ""], ["Ramasamy", "Savitha", ""], ["Sundararajan", "Narasimhan", ""]]}, {"id": "1904.11713", "submitter": "Andreas St\\\"ockel", "authors": "Andreas St\\\"ockel, Chris Eliasmith", "title": "Passive nonlinear dendritic interactions as a general computational\n  resource in functional spiking neural networks", "comments": null, "journal-ref": null, "doi": "10.1162/neco_a_01338", "report-no": null, "categories": "q-bio.NC cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear interactions in the dendritic tree play a key role in neural\ncomputation. Nevertheless, modeling frameworks aimed at the construction of\nlarge-scale, functional spiking neural networks, such as the Neural Engineering\nFramework, tend to assume a linear superposition of post-synaptic currents. In\nthis paper, we present a series of extensions to the Neural Engineering\nFramework that facilitate the construction of networks incorporating Dale's\nprinciple and nonlinear conductance-based synapses. We apply these extensions\nto a two-compartment LIF neuron that can be seen as a simple model of passive\ndendritic computation. We show that it is possible to incorporate neuron models\nwith input-dependent nonlinearities into the Neural Engineering Framework\nwithout compromising high-level function and that nonlinear post-synaptic\ncurrents can be systematically exploited to compute a wide variety of\nmultivariate, bandlimited functions, including the Euclidean norm, controlled\nshunting, and non-negative multiplication. By avoiding an additional source of\nspike noise, the function-approximation accuracy of a single layer of\ntwo-compartment LIF neurons is on a par with or even surpasses that of\ntwo-layer spiking neural networks up to a certain target function bandwidth.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 08:32:29 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 01:38:19 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["St\u00f6ckel", "Andreas", ""], ["Eliasmith", "Chris", ""]]}, {"id": "1904.11829", "submitter": "Leila Arras", "authors": "Leila Arras, Ahmed Osman, Klaus-Robert M\\\"uller, Wojciech Samek", "title": "Evaluating Recurrent Neural Network Explanations", "comments": "14 pages, accepted for ACL'19 Workshop BlackboxNLP: Analyzing and\n  Interpreting Neural Networks for NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, several methods have been proposed to explain the predictions of\nrecurrent neural networks (RNNs), in particular of LSTMs. The goal of these\nmethods is to understand the network's decisions by assigning to each input\nvariable, e.g., a word, a relevance indicating to which extent it contributed\nto a particular prediction. In previous works, some of these methods were not\nyet compared to one another, or were evaluated only qualitatively. We close\nthis gap by systematically and quantitatively comparing these methods in\ndifferent settings, namely (1) a toy arithmetic task which we use as a sanity\ncheck, (2) a five-class sentiment prediction of movie reviews, and besides (3)\nwe explore the usefulness of word relevances to build sentence-level\nrepresentations. Lastly, using the method that performed best in our\nexperiments, we show how specific linguistic phenomena such as the negation in\nsentiment analysis reflect in terms of relevance patterns, and how the\nrelevance visualization can help to understand the misclassification of\nindividual samples.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 13:08:43 GMT"}, {"version": "v2", "created": "Mon, 29 Apr 2019 07:49:19 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 13:52:09 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Arras", "Leila", ""], ["Osman", "Ahmed", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1904.11838", "submitter": "Marco Roberti", "authors": "Marco Roberti, Giovanni Bonetta, Rossella Cancelliere, Patrick\n  Gallinari", "title": "Copy mechanism and tailored training for character-based data-to-text\n  generation", "comments": "ECML-PKDD 2019 (Camera ready version)", "journal-ref": null, "doi": "10.1007/978-3-030-46147-8_39", "report-no": null, "categories": "cs.LG cs.CL cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, many different methods have been focusing on using\ndeep recurrent neural networks for natural language generation. The most widely\nused sequence-to-sequence neural methods are word-based: as such, they need a\npre-processing step called delexicalization (conversely, relexicalization) to\ndeal with uncommon or unknown words. These forms of processing, however, give\nrise to models that depend on the vocabulary used and are not completely\nneural.\n  In this work, we present an end-to-end sequence-to-sequence model with\nattention mechanism which reads and generates at a character level, no longer\nrequiring delexicalization, tokenization, nor even lowercasing. Moreover, since\ncharacters constitute the common \"building blocks\" of every text, it also\nallows a more general approach to text generation, enabling the possibility to\nexploit transfer learning for training. These skills are obtained thanks to two\nmajor features: (i) the possibility to alternate between the standard\ngeneration mechanism and a copy one, which allows to directly copy input facts\nto produce outputs, and (ii) the use of an original training pipeline that\nfurther improves the quality of the generated texts.\n  We also introduce a new dataset called E2E+, designed to highlight the\ncopying capabilities of character-based models, that is a modified version of\nthe well-known E2E dataset used in the E2E Challenge. We tested our model\naccording to five broadly accepted metrics (including the widely used BLEU),\nshowing that it yields competitive performance with respect to both\ncharacter-based and word-based approaches.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 13:33:56 GMT"}, {"version": "v2", "created": "Fri, 28 Jun 2019 11:38:07 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2019 15:35:14 GMT"}, {"version": "v4", "created": "Mon, 11 May 2020 12:48:10 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Roberti", "Marco", ""], ["Bonetta", "Giovanni", ""], ["Cancelliere", "Rossella", ""], ["Gallinari", "Patrick", ""]]}, {"id": "1904.11955", "submitter": "Simon Du", "authors": "Sanjeev Arora, Simon S. Du, Wei Hu, Zhiyuan Li, Ruslan Salakhutdinov,\n  Ruosong Wang", "title": "On Exact Computation with an Infinitely Wide Neural Net", "comments": "In NeurIPS 2019. Code available: https://github.com/ruosongwang/cntk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How well does a classic deep net architecture like AlexNet or VGG19 classify\non a standard dataset such as CIFAR-10 when its width --- namely, number of\nchannels in convolutional layers, and number of nodes in fully-connected\ninternal layers --- is allowed to increase to infinity? Such questions have\ncome to the forefront in the quest to theoretically understand deep learning\nand its mysteries about optimization and generalization. They also connect deep\nlearning to notions such as Gaussian processes and kernels. A recent paper\n[Jacot et al., 2018] introduced the Neural Tangent Kernel (NTK) which captures\nthe behavior of fully-connected deep nets in the infinite width limit trained\nby gradient descent; this object was implicit in some other recent papers. An\nattraction of such ideas is that a pure kernel-based method is used to capture\nthe power of a fully-trained deep net of infinite width.\n  The current paper gives the first efficient exact algorithm for computing the\nextension of NTK to convolutional neural nets, which we call Convolutional NTK\n(CNTK), as well as an efficient GPU implementation of this algorithm. This\nresults in a significant new benchmark for the performance of a pure\nkernel-based method on CIFAR-10, being $10\\%$ higher than the methods reported\nin [Novak et al., 2019], and only $6\\%$ lower than the performance of the\ncorresponding finite deep net architecture (once batch normalization, etc. are\nturned off). Theoretically, we also give the first non-asymptotic proof showing\nthat a fully-trained sufficiently wide net is indeed equivalent to the kernel\nregression predictor using NTK.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 17:29:37 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 15:10:47 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Arora", "Sanjeev", ""], ["Du", "Simon S.", ""], ["Hu", "Wei", ""], ["Li", "Zhiyuan", ""], ["Salakhutdinov", "Ruslan", ""], ["Wang", "Ruosong", ""]]}, {"id": "1904.12234", "submitter": "Francisco Avila-Camacho J", "authors": "Jose de Jesus Rubio, Jose Alberto Hernandez-Aguilar, Francisco Jacob\n  Avila-Camacho, Juan Manuel Stein-Carrillo, Adolfo Melendez-Ramirez", "title": "Sistema Sensor para el Monitoreo Ambiental Basado en Redes Neuronales", "comments": "11 pages, in Spanish", "journal-ref": "Ingenier\\'ia Investigaci\\'on y Tecnolog\\'ia,volumen XVII (n\\'umero\n  2), abril-junio 2016: 211-222", "doi": "10.1016/J.RIIT.2016.06.006", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the tasks of environmental monitoring is of great importance to have\ncompact and portable systems able to identify environmental contaminants that\nfacilitate tasks related to waste management and environmental restoration. In\nthis paper, a prototype sensor is described to identify contaminants in the\nenvironment. This prototype is made with an array of tin oxide SnO2 gas sensors\nused to identify chemical vapors, a step of data acquisition implemented with\nARM (Advanced RISC Machine) low-cost platform (Arduino) and a neural network\nable to identify environmental contaminants automatically. The neural network\nis used to identify the composition of contaminant census. In the computer\nsystem, the heavy computational load is presented only in the training process,\nonce the neural network has been trained, the operation is to spread the data\nacross the network with a much lighter computational load, which consists\nmainly of a vector-matrix multiplication and a search table that holds the\nactivation function to quickly identify unknown samples.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 00:23:11 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Rubio", "Jose de Jesus", ""], ["Hernandez-Aguilar", "Jose Alberto", ""], ["Avila-Camacho", "Francisco Jacob", ""], ["Stein-Carrillo", "Juan Manuel", ""], ["Melendez-Ramirez", "Adolfo", ""]]}, {"id": "1904.12591", "submitter": "Cameron Musco", "authors": "Nancy Lynch and Cameron Musco and Merav Parter", "title": "Winner-Take-All Computation in Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cond-mat.dis-nn cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study biological neural networks from an algorithmic\nperspective, focusing on understanding tradeoffs between computation time and\nnetwork complexity. Our goal is to abstract real neural networks in a way that,\nwhile not capturing all interesting features, preserves high-level behavior and\nallows us to make biologically relevant conclusions. Towards this goal, we\nconsider the implementation of algorithmic primitives in a simple yet\nbiologically plausible model of $stochastic\\ spiking\\ neural\\ networks$. In\nparticular, we show how the stochastic behavior of neurons in this model can be\nleveraged to solve a basic $symmetry-breaking\\ task$ in which we are given\nneurons with identical firing rates and want to select a distinguished one. In\ncomputational neuroscience, this is known as the winner-take-all (WTA) problem,\nand it is believed to serve as a basic building block in many tasks, e.g.,\nlearning, pattern recognition, and clustering. We provide efficient\nconstructions of WTA circuits in our stochastic spiking neural network model,\nas well as lower bounds in terms of the number of auxiliary neurons required to\ndrive convergence to WTA in a given number of steps. These lower bounds\ndemonstrate that our constructions are near-optimal in some cases.\n  This work covers and gives more in-depth proofs of a subset of results\noriginally published in [LMP17a]. It is adapted from the last chapter of C.\nMusco's Ph.D. thesis [Mus18].\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 19:49:40 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Lynch", "Nancy", ""], ["Musco", "Cameron", ""], ["Parter", "Merav", ""]]}, {"id": "1904.12651", "submitter": "Kevin Jasberg", "authors": "Kevin Jasberg, Sergej Sizov", "title": "Computational Approaches to Access Probabilistic Population Codes for\n  Higher Cognition an Decision-Making", "comments": "arXiv admin note: text overlap with arXiv:1804.10861", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, research unveiled more and more evidence for the so-called\nBayesian Brain Paradigm, i.e. the human brain is interpreted as a probabilistic\ninference machine and Bayesian modelling approaches are hence used\nsuccessfully. One of the many theories is that of Probabilistic Population\nCodes (PPC). Although this model has so far only been considered as meaningful\nand useful for sensory perception as well as motor control, it has always been\nsuggested that this mechanism also underlies higher cognition and\ndecision-making. However, the adequacy of PPC for this regard cannot be\nconfirmed by means of neurological standard measurement procedures.\n  In this article we combine the parallel research branches of recommender\nsystems and predictive data mining with theoretical neuroscience. The nexus of\nboth fields is given by behavioural variability and resulting internal\ndistributions. We adopt latest experimental settings and measurement approaches\nfrom predictive data mining to obtain these internal distributions, to inform\nthe theoretical PPC approach and to deduce medical correlates which can indeed\nbe measured in vivo. This is a strong hint for the applicability of the PPC\napproach and the Bayesian Brain Paradigm for higher cognition and human\ndecision-making.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 20:32:02 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Jasberg", "Kevin", ""], ["Sizov", "Sergej", ""]]}, {"id": "1904.12738", "submitter": "Shashank Kotyan", "authors": "Shashank Kotyan, Danilo Vasconcellos Vargas and Venkanna U", "title": "Self Training Autonomous Driving Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrinsically, driving is a Markov Decision Process which suits well the\nreinforcement learning paradigm. In this paper, we propose a novel agent which\nlearns to drive a vehicle without any human assistance. We use the concept of\nreinforcement learning and evolutionary strategies to train our agent in a 2D\nsimulation environment. Our model's architecture goes beyond the World Model's\nby introducing difference images in the auto encoder. This novel involvement of\ndifference images in the auto-encoder gives better representation of the latent\nspace with respect to the motion of vehicle and helps an autonomous agent to\nlearn more efficiently how to drive a vehicle. Results show that our method\nrequires fewer (96% less) total agents, (87.5% less) agents per generations,\n(70% less) generations and (90% less) rollouts than the original architecture\nwhile achieving the same accuracy of the original.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 05:22:29 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Kotyan", "Shashank", ""], ["Vargas", "Danilo Vasconcellos", ""], ["U", "Venkanna", ""]]}, {"id": "1904.12774", "submitter": "Clemens Rosenbaum", "authors": "Clemens Rosenbaum, Ignacio Cases, Matthew Riemer, Tim Klinger", "title": "Routing Networks and the Challenges of Modular and Compositional\n  Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compositionality is a key strategy for addressing combinatorial complexity\nand the curse of dimensionality. Recent work has shown that compositional\nsolutions can be learned and offer substantial gains across a variety of\ndomains, including multi-task learning, language modeling, visual question\nanswering, machine comprehension, and others. However, such models present\nunique challenges during training when both the module parameters and their\ncomposition must be learned jointly. In this paper, we identify several of\nthese issues and analyze their underlying causes. Our discussion focuses on\nrouting networks, a general approach to this problem, and examines empirically\nthe interplay of these challenges and a variety of design decisions. In\nparticular, we consider the effect of how the algorithm decides on module\ncomposition, how the algorithm updates the modules, and if the algorithm uses\nregularization.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 15:32:14 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Rosenbaum", "Clemens", ""], ["Cases", "Ignacio", ""], ["Riemer", "Matthew", ""], ["Klinger", "Tim", ""]]}, {"id": "1904.12831", "submitter": "Ian Williamson", "authors": "Tyler W. Hughes, Ian A. D. Williamson, Momchil Minkov, Shanhui Fan", "title": "Wave Physics as an Analog Recurrent Neural Network", "comments": "13 pages, 6 figures", "journal-ref": "Science Advances, vol. 5, no. 12, p. eaay6946, Dec. 2019", "doi": "10.1126/sciadv.aay6946", "report-no": null, "categories": "physics.comp-ph cs.LG cs.NE physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analog machine learning hardware platforms promise to be faster and more\nenergy-efficient than their digital counterparts. Wave physics, as found in\nacoustics and optics, is a natural candidate for building analog processors for\ntime-varying signals. Here we identify a mapping between the dynamics of wave\nphysics, and the computation in recurrent neural networks. This mapping\nindicates that physical wave systems can be trained to learn complex features\nin temporal data, using standard training techniques for neural networks. As a\ndemonstration, we show that an inverse-designed inhomogeneous medium can\nperform vowel classification on raw audio signals as their waveforms scatter\nand propagate through it, achieving performance comparable to a standard\ndigital implementation of a recurrent neural network. These findings pave the\nway for a new class of analog machine learning platforms, capable of fast and\nefficient processing of information in its native domain.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 17:27:35 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 19:22:10 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Hughes", "Tyler W.", ""], ["Williamson", "Ian A. D.", ""], ["Minkov", "Momchil", ""], ["Fan", "Shanhui", ""]]}, {"id": "1904.12834", "submitter": "Bowei Chen", "authors": "Yu Zheng and Yongxin Yang and Bowei Chen", "title": "Incorporating prior financial domain knowledge into neural networks for\n  implied volatility surface prediction", "comments": "8 pages, SIGKDD 2021", "journal-ref": null, "doi": "10.1145/3447548.3467115", "report-no": null, "categories": "q-fin.CP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a novel neural network model for predicting implied\nvolatility surface. Prior financial domain knowledge is taken into account. A\nnew activation function that incorporates volatility smile is proposed, which\nis used for the hidden nodes that process the underlying asset price. In\naddition, financial conditions, such as the absence of arbitrage, the\nboundaries and the asymptotic slope, are embedded into the loss function. This\nis one of the very first studies which discuss a methodological framework that\nincorporates prior financial domain knowledge into neural network architecture\ndesign and model training. The proposed model outperforms the benchmarked\nmodels with the option data on the S&P 500 index over 20 years. More\nimportantly, the domain knowledge is satisfied empirically, showing the model\nis consistent with the existing financial theories and conditions related to\nimplied volatility surface.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 17:35:41 GMT"}, {"version": "v2", "created": "Sun, 26 May 2019 21:13:58 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 22:32:10 GMT"}, {"version": "v4", "created": "Thu, 30 Jan 2020 23:43:33 GMT"}, {"version": "v5", "created": "Fri, 28 May 2021 14:26:23 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Zheng", "Yu", ""], ["Yang", "Yongxin", ""], ["Chen", "Bowei", ""]]}, {"id": "1904.12904", "submitter": "Nathan Wycoff", "authors": "Nathan Wycoff, Prasanna Balaprakash, Fangfang Xia", "title": "Neuromorphic Acceleration for Approximate Bayesian Inference on Neural\n  Networks via Permanent Dropout", "comments": "4 pages, 4 figures. Submitted to International Conference on\n  Neuromorphic Systems (ICONS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As neural networks have begun performing increasingly critical tasks for\nsociety, ranging from driving cars to identifying candidates for drug\ndevelopment, the value of their ability to perform uncertainty quantification\n(UQ) in their predictions has risen commensurately. Permanent dropout, a\npopular method for neural network UQ, involves injecting stochasticity into the\ninference phase of the model and creating many predictions for each of the test\ndata. This shifts the computational and energy burden of deep neural networks\nfrom the training phase to the inference phase. Recent work has demonstrated\nnear-lossless conversion of classical deep neural networks to their spiking\ncounterparts. We use these results to demonstrate the feasibility of conducting\nthe inference phase with permanent dropout on spiking neural networks,\nmitigating the technique's computational and energy burden, which is essential\nfor its use at scale or on edge platforms. We demonstrate the proposed approach\nvia the Nengo spiking neural simulator on a combination drug therapy dataset\nfor cancer treatment, where UQ is critical. Our results indicate that the\nspiking approximation gives a predictive distribution practically\nindistinguishable from that given by the classical network.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 18:43:07 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Wycoff", "Nathan", ""], ["Balaprakash", "Prasanna", ""], ["Xia", "Fangfang", ""]]}, {"id": "1904.12970", "submitter": "S\\'ebastien Bougleux", "authors": "Xuan Son Nguyen and Luc Brun and Olivier L\\'ezoray and S\\'ebastien\n  Bougleux", "title": "A neural network based on SPD manifold learning for skeleton-based hand\n  gesture recognition", "comments": "Accepted at CVPR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a new neural network based on SPD manifold learning for\nskeleton-based hand gesture recognition. Given the stream of hand's joint\npositions, our approach combines two aggregation processes on respectively\nspatial and temporal domains. The pipeline of our network architecture consists\nin three main stages. The first stage is based on a convolutional layer to\nincrease the discriminative power of learned features. The second stage relies\non different architectures for spatial and temporal Gaussian aggregation of\njoint features. The third stage learns a final SPD matrix from skeletal data. A\nnew type of layer is proposed for the third stage, based on a variant of\nstochastic gradient descent on Stiefel manifolds. The proposed network is\nvalidated on two challenging datasets and shows state-of-the-art accuracies on\nboth datasets.\n", "versions": [{"version": "v1", "created": "Mon, 29 Apr 2019 21:59:14 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Nguyen", "Xuan Son", ""], ["Brun", "Luc", ""], ["L\u00e9zoray", "Olivier", ""], ["Bougleux", "S\u00e9bastien", ""]]}, {"id": "1904.13310", "submitter": "Hojjat Salehinejad", "authors": "Alex Labach, Hojjat Salehinejad, Shahrokh Valaee", "title": "Survey of Dropout Methods for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout methods are a family of stochastic techniques used in neural network\ntraining or inference that have generated significant research interest and are\nwidely used in practice. They have been successfully applied in neural network\nregularization, model compression, and in measuring the uncertainty of neural\nnetwork outputs. While original formulated for dense neural network layers,\nrecent advances have made dropout methods also applicable to convolutional and\nrecurrent neural network layers. This paper summarizes the history of dropout\nmethods, their various applications, and current areas of research interest.\nImportant proposed methods are described in additional detail.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 21:21:52 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 04:36:14 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Labach", "Alex", ""], ["Salehinejad", "Hojjat", ""], ["Valaee", "Shahrokh", ""]]}, {"id": "1904.13333", "submitter": "Gerard Serra", "authors": "Gerard Serra and David Miralles", "title": "Coevo: a collaborative design platform with artificial agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Coevo, an online platform that allows both humans and artificial\nagents to design shapes that solve different tasks. Our goal is to explore\ncommon shared design tools that can be used by humans and artificial agents in\na context of creation. This approach can provide a better knowledge transfer\nand interaction with artificial agents since a common language of design is\ndefined. In this paper, we outline the main components of this platform and\ndiscuss the definition of a human-centered language to enhance human-AI\ncollaboration in co-creation scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 15:55:34 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Serra", "Gerard", ""], ["Miralles", "David", ""]]}]