[{"id": "2102.00227", "submitter": "Radu Dogaru", "authors": "Radu Dogaru and Ioana Dogaru", "title": "NL-CNN: A Resources-Constrained Deep Learning Model based on Nonlinear\n  Convolution", "comments": "4 pages, reprint submitted to ATEE 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A novel convolution neural network model, abbreviated NL-CNN is proposed,\nwhere nonlinear convolution is emulated in a cascade of convolution +\nnonlinearity layers. The code for its implementation and some trained models\nare made publicly available. Performance evaluation for several widely known\ndatasets is provided, showing several relevant features: i) for small / medium\ninput image sizes the proposed network gives very good testing accuracy, given\na low implementation complexity and model size; ii) compares favorably with\nother widely known resources-constrained models, for instance in comparison to\nMobileNetv2 provides better accuracy with several times less training times and\nup to ten times less parameters (memory occupied by the model); iii) has a\nrelevant set of hyper-parameters which can be easily and rapidly tuned due to\nthe fast training specific to it. All these features make NL-CNN suitable for\nIoT, smart sensing, bio-medical portable instrumentation and other applications\nwhere artificial intelligence must be deployed in energy-constrained\nenvironments.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 13:38:42 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Dogaru", "Radu", ""], ["Dogaru", "Ioana", ""]]}, {"id": "2102.00292", "submitter": "Seyed Ziae Mousavi Mojab", "authors": "Seyed Ziae Mousavi Mojab, Seyedmohammad Shams, Hamid Soltanian-Zadeh,\n  Farshad Fotouhi", "title": "Epistocracy Algorithm: A Novel Hyper-heuristic Optimization Strategy for\n  Solving Complex Optimization Problems", "comments": "Computing Conference 2021 proceedings will be published in the\n  Springer series \"Advances in Intelligent Systems and Computing\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper proposes a novel evolutionary algorithm called Epistocracy which\nincorporates human socio-political behavior and intelligence to solve complex\noptimization problems. The inspiration of the Epistocracy algorithm originates\nfrom a political regime where educated people have more voting power than the\nuneducated or less educated. The algorithm is a self-adaptive, and\nmulti-population optimizer in which the evolution process takes place in\nparallel for many populations led by a council of leaders. To avoid stagnation\nin poor local optima and to prevent a premature convergence, the algorithm\nemploys multiple mechanisms such as dynamic and adaptive leadership based on\ngravitational force, dynamic population allocation and diversification,\nvariance-based step-size determination, and regression-based leadership\nadjustment. The algorithm uses a stratified sampling method called Latin\nHypercube Sampling (LHS) to distribute the initial population more evenly for\nexploration of the search space and exploitation of the accumulated knowledge.\nTo investigate the performance and evaluate the reliability of the algorithm,\nwe have used a set of multimodal benchmark functions, and then applied the\nalgorithm to the MNIST dataset to further verify the accuracy, scalability, and\nrobustness of the algorithm. Experimental results show that the Epistocracy\nalgorithm outperforms the tested state-of-the-art evolutionary and swarm\nintelligence algorithms in terms of performance, precision, and convergence.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 19:07:09 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Mojab", "Seyed Ziae Mousavi", ""], ["Shams", "Seyedmohammad", ""], ["Soltanian-Zadeh", "Hamid", ""], ["Fotouhi", "Farshad", ""]]}, {"id": "2102.00310", "submitter": "Wendson Barbosa", "authors": "Wendson A. S. Barbosa, Aaron Griffith, Graham E. Rowlands, Luke C. G.\n  Govia, Guilhem J. Ribeill, Minh-Hai Nguyen, Thomas A. Ohki, Daniel J.\n  Gauthier", "title": "Symmetry-Aware Reservoir Computing", "comments": "10 pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that matching the symmetry properties of a reservoir computer\n(RC) to the data being processed dramatically increases its processing power.\nWe apply our method to the parity task, a challenging benchmark problem that\nhighlights inversion and permutation symmetries, and to a chaotic system\ninference task that presents an inversion symmetry rule. For the parity task,\nour symmetry-aware RC obtains zero error using an exponentially reduced neural\nnetwork and training data, greatly speeding up the time to result and\noutperforming hand crafted artificial neural networks. When both symmetries are\nrespected, we find that the network size $N$ necessary to obtain zero error for\n50 different RC instances scales linearly with the parity-order $n$. Moreover,\nsome symmetry-aware RC instances perform a zero error classification with only\n$N=1$ for $n\\leq7$. Furthermore, we show that a symmetry-aware RC only needs a\ntraining data set with size on the order of $(n+n/2)$ to obtain such\nperformance, an exponential reduction in comparison to a regular RC which\nrequires a training data set with size on the order of $n2^n$ to contain all\n$2^n$ possible $n-$bit-long sequences. For the inference task, we show that a\nsymmetry-aware RC presents a normalized root-mean-square error three\norders-of-magnitude smaller than regular RCs. For both tasks, our RC approach\nrespects the symmetries by adjusting only the input and the output layers, and\nnot by problem-based modifications to the neural network. We anticipate that\ngeneralizations of our procedure can be applied in information processing for\nproblems with known symmetries.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 20:59:19 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 15:17:35 GMT"}, {"version": "v3", "created": "Mon, 26 Jul 2021 21:21:03 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Barbosa", "Wendson A. S.", ""], ["Griffith", "Aaron", ""], ["Rowlands", "Graham E.", ""], ["Govia", "Luke C. G.", ""], ["Ribeill", "Guilhem J.", ""], ["Nguyen", "Minh-Hai", ""], ["Ohki", "Thomas A.", ""], ["Gauthier", "Daniel J.", ""]]}, {"id": "2102.00337", "submitter": "Jacob Schrum", "authors": "Benjamin Capps and Jacob Schrum", "title": "Using Multiple Generative Adversarial Networks to Build Better-Connected\n  Levels for Mega Man", "comments": "Accepted to Genetic and Evolutionary Computation Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) can generate levels for a variety of\ngames. This paper focuses on combining GAN-generated segments in a snaking\npattern to create levels for Mega Man. Adjacent segments in such levels can be\northogonally adjacent in any direction, meaning that an otherwise fine segment\nmight impose a barrier between its neighbor depending on what sorts of segments\nin the training set are being most closely emulated: horizontal, vertical, or\ncorner segments. To pick appropriate segments, multiple GANs were trained on\ndifferent types of segments to ensure better flow between segments. Flow was\nfurther improved by evolving the latent vectors for the segments being joined\nin the level to maximize the length of the level's solution path. Using\nmultiple GANs to represent different types of segments results in significantly\nlonger solution paths than using one GAN for all segment types, and a human\nsubject study verifies that these levels are more fun and have more human-like\ndesign than levels produced by one GAN.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 23:34:15 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 14:24:06 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Capps", "Benjamin", ""], ["Schrum", "Jacob", ""]]}, {"id": "2102.00383", "submitter": "Yiming Peng", "authors": "Yiming Peng and Hisao Ishibuchi", "title": "Niching Diversity Estimation for Multi-modal Multi-objective\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Niching is an important and widely used technique in evolutionary\nmulti-objective optimization. Its applications mainly focus on maintaining\ndiversity and avoiding early convergence to local optimum. Recently, a special\nclass of multi-objective optimization problems, namely, multi-modal\nmulti-objective optimization problems (MMOPs), started to receive increasing\nattention. In MMOPs, a solution in the objective space may have multiple\ninverse images in the decision space, which are termed as equivalent solutions.\nSince equivalent solutions are overlapping (i.e., occupying the same position)\nin the objective space, standard diversity estimators such as crowding distance\nare likely to select one of them and discard the others, which may cause\ndiversity loss in the decision space. In this study, a general niching\nmechanism is proposed to make standard diversity estimators more efficient when\nhandling MMOPs. In our experiments, we integrate our proposed niching diversity\nestimation method into SPEA2 and NSGA-II and evaluate their performance on\nseveral MMOPs. Experimental results show that the proposed niching mechanism\nnotably enhances the performance of SPEA2 and NSGA-II on various MMOPs.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 05:23:31 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Peng", "Yiming", ""], ["Ishibuchi", "Hisao", ""]]}, {"id": "2102.00434", "submitter": "Gilad Yehudai", "authors": "Eran Malach, Gilad Yehudai, Shai Shalev-Shwartz, Ohad Shamir", "title": "The Connection Between Approximation, Depth Separation and Learnability\n  in Neural Networks", "comments": "COLT 2021 camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent works have shown separation results between deep neural\nnetworks, and hypothesis classes with inferior approximation capacity such as\nshallow networks or kernel classes. On the other hand, the fact that deep\nnetworks can efficiently express a target function does not mean that this\ntarget function can be learned efficiently by deep neural networks. In this\nwork we study the intricate connection between learnability and approximation\ncapacity. We show that learnability with deep networks of a target function\ndepends on the ability of simpler classes to approximate the target.\nSpecifically, we show that a necessary condition for a function to be learnable\nby gradient descent on deep neural networks is to be able to approximate the\nfunction, at least in a weak sense, with shallow neural networks. We also show\nthat a class of functions can be learned by an efficient statistical query\nalgorithm if and only if it can be approximated in a weak sense by some kernel\nclass. We give several examples of functions which demonstrate depth\nseparation, and conclude that they cannot be efficiently learned, even by a\nhypothesis class that can efficiently approximate them.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 11:32:30 GMT"}, {"version": "v2", "created": "Sun, 18 Jul 2021 12:32:55 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Malach", "Eran", ""], ["Yehudai", "Gilad", ""], ["Shalev-Shwartz", "Shai", ""], ["Shamir", "Ohad", ""]]}, {"id": "2102.00524", "submitter": "Victor Costa", "authors": "Victor Costa, Nuno Louren\\c{c}o, Jo\\~ao Correia, Penousal Machado", "title": "Demonstrating the Evolution of GANs through t-SNE", "comments": "To be published in EvoApplications 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are powerful generative models that\nachieved strong results, mainly in the image domain. However, the training of\nGANs is not trivial, presenting some challenges tackled by different\nstrategies. Evolutionary algorithms, such as COEGAN, were recently proposed as\na solution to improve the GAN training, overcoming common problems that affect\nthe model, such as vanishing gradient and mode collapse. In this work, we\npropose an evaluation method based on t-distributed Stochastic Neighbour\nEmbedding (t-SNE) to assess the progress of GANs and visualize the distribution\nlearned by generators in training. We propose the use of the feature space\nextracted from trained discriminators to evaluate samples produced by\ngenerators and from the input dataset. A metric based on the resulting t-SNE\nmaps and the Jaccard index is proposed to represent the model quality.\nExperiments were conducted to assess the progress of GANs when trained using\nCOEGAN. The results show both by visual inspection and metrics that the\nEvolutionary Algorithm gradually improves discriminators and generators through\ngenerations, avoiding problems such as mode collapse.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 20:07:08 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 10:49:30 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Costa", "Victor", ""], ["Louren\u00e7o", "Nuno", ""], ["Correia", "Jo\u00e3o", ""], ["Machado", "Penousal", ""]]}, {"id": "2102.00554", "submitter": "Torsten Hoefler", "authors": "Torsten Hoefler, Dan Alistarh, Tal Ben-Nun, Nikoli Dryden, Alexandra\n  Peste", "title": "Sparsity in Deep Learning: Pruning and growth for efficient inference\n  and training in neural networks", "comments": "90 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing energy and performance costs of deep learning have driven the\ncommunity to reduce the size of neural networks by selectively pruning\ncomponents. Similarly to their biological counterparts, sparse networks\ngeneralize just as well, if not better than, the original dense networks.\nSparsity can reduce the memory footprint of regular networks to fit mobile\ndevices, as well as shorten training time for ever growing networks. In this\npaper, we survey prior work on sparsity in deep learning and provide an\nextensive tutorial of sparsification for both inference and training. We\ndescribe approaches to remove and add elements of neural networks, different\ntraining strategies to achieve model sparsity, and mechanisms to exploit\nsparsity in practice. Our work distills ideas from more than 300 research\npapers and provides guidance to practitioners who wish to utilize sparsity\ntoday, as well as to researchers whose goal is to push the frontier forward. We\ninclude the necessary background on mathematical methods in sparsification,\ndescribe phenomena such as early structure adaptation, the intricate relations\nbetween sparsity and the training process, and show techniques for achieving\nacceleration on real hardware. We also define a metric of pruned parameter\nefficiency that could serve as a baseline for comparison of different sparse\nnetworks. We close by speculating on how sparsity can improve future workloads\nand outline major open problems in the field.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 22:48:50 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hoefler", "Torsten", ""], ["Alistarh", "Dan", ""], ["Ben-Nun", "Tal", ""], ["Dryden", "Nikoli", ""], ["Peste", "Alexandra", ""]]}, {"id": "2102.00736", "submitter": "Quentin Renau", "authors": "Quentin Renau, Johann Dreo, Carola Doerr and Benjamin Doerr", "title": "Towards Explainable Exploratory Landscape Analysis: Extreme Feature\n  Selection for Classifying BBOB Functions", "comments": "To appear in the proceedings of the 24th International Conference,\n  EvoApplications 2021 Data used in this paper is available at\n  https://doi.org/10.5281/zenodo.4449934", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facilitated by the recent advances of Machine Learning (ML), the automated\ndesign of optimization heuristics is currently shaking up evolutionary\ncomputation (EC). Where the design of hand-picked guidelines for choosing a\nmost suitable heuristic has long dominated research activities in the field,\nautomatically trained heuristics are now seen to outperform human-derived\nchoices even for well-researched optimization tasks. ML-based EC is therefore\nnot any more a futuristic vision, but has become an integral part of our\ncommunity.\n  A key criticism that ML-based heuristics are often faced with is their\npotential lack of explainability, which may hinder future developments. This\napplies in particular to supervised learning techniques which extrapolate\nalgorithms' performance based on exploratory landscape analysis (ELA). In such\napplications, it is not uncommon to use dozens of problem features to build the\nmodels underlying the specific algorithm selection or configuration task. Our\ngoal in this work is to analyze whether this many features are indeed needed.\nUsing the classification of the BBOB test functions as testbed, we show that a\nsurprisingly small number of features -- often less than four -- can suffice to\nachieve a 98\\% accuracy. Interestingly, the number of features required to meet\nthis threshold is found to decrease with the problem dimension. We show that\nthe classification accuracy transfers to settings in which several instances\nare involved in training and testing. In the leave-one-instance-out setting,\nhowever, classification accuracy drops significantly, and the\ntransformation-invariance of the features becomes a decisive success factor.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 10:04:28 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Renau", "Quentin", ""], ["Dreo", "Johann", ""], ["Doerr", "Carola", ""], ["Doerr", "Benjamin", ""]]}, {"id": "2102.00853", "submitter": "Ilona Kulikovskikh", "authors": "Ilona Kulikovskikh and Tarzan Legovi\\'c", "title": "Painless step size adaptation for SGD", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convergence and generalization are two crucial aspects of performance in\nneural networks. When analyzed separately, these properties may lead to\ncontradictory results. Optimizing a convergence rate yields fast training, but\ndoes not guarantee the best generalization error. To avoid the conflict, recent\nstudies suggest adopting a moderately large step size for optimizers, but the\nadded value on the performance remains unclear. We propose the LIGHT function\nwith the four configurations which regulate explicitly an improvement in\nconvergence and generalization on testing. This contribution allows to: 1)\nimprove both convergence and generalization of neural networks with no need to\nguarantee their stability; 2) build more reliable and explainable network\narchitectures with no need for overparameterization. We refer to it as\n\"painless\" step size adaptation.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 14:05:41 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Kulikovskikh", "Ilona", ""], ["Legovi\u0107", "Tarzan", ""]]}, {"id": "2102.00879", "submitter": "Namid Stillman Dr.", "authors": "Namid Stillman, Igor Balaz, Antisthenis Tsompanas, Marina Kovacevic,\n  Sepinoud Azimi, Sebastien Lafond, Andrew Adamatzky, Sabine Hauert", "title": "Evolutionary computational platform for the automatic discovery of\n  nanocarriers for cancer treatment", "comments": "30 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE physics.med-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present the EVONANO platform for the evolution of nanomedicines with\napplication to anti-cancer treatments. EVONANO includes a simulator to grow\ntumours, extract representative scenarios, and then simulate nanoparticle\ntransport through these scenarios to predict nanoparticle distribution. The\nnanoparticle designs are optimised using machine learning to efficiently find\nthe most effective anti-cancer treatments. We demonstrate our platform with two\nexamples optimising the properties of nanoparticles and treatment to\nselectively kill cancer cells over a range of tumour environments.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 14:38:14 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Stillman", "Namid", ""], ["Balaz", "Igor", ""], ["Tsompanas", "Antisthenis", ""], ["Kovacevic", "Marina", ""], ["Azimi", "Sepinoud", ""], ["Lafond", "Sebastien", ""], ["Adamatzky", "Andrew", ""], ["Hauert", "Sabine", ""]]}, {"id": "2102.00941", "submitter": "Weiyu Chen", "authors": "Weiyu Chen, Hisao Ishibuchi, and Ke Shang", "title": "Fast Greedy Subset Selection from Large Candidate Solution Sets in\n  Evolutionary Multi-objective Optimization", "comments": "This paper is under review for publication in the IEEE Trans. on\n  Evolutionary Computation. arXiv admin note: substantial text overlap with\n  arXiv:2007.02050", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subset selection is an interesting and important topic in the field of\nevolutionary multi-objective optimization (EMO). Especially, in an EMO\nalgorithm with an unbounded external archive, subset selection is an essential\npost-processing procedure to select a pre-specified number of solutions as the\nfinal result. In this paper, we discuss the efficiency of greedy subset\nselection for the hypervolume, IGD and IGD+ indicators. Greedy algorithms\nusually efficiently handle subset selection. However, when a large number of\nsolutions are given (e.g., subset selection from tens of thousands of solutions\nin an unbounded external archive), they often become time-consuming. Our idea\nis to use the submodular property, which is known for the hypervolume\nindicator, to improve their efficiency. First, we prove that the IGD and IGD+\nindicators are also submodular. Next, based on the submodular property, we\npropose an efficient greedy inclusion algorithm for each indicator. Then, we\ndemonstrate through computational experiments that the proposed algorithms are\nmuch faster than the standard greedy subset selection algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 16:14:15 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Chen", "Weiyu", ""], ["Ishibuchi", "Hisao", ""], ["Shang", "Ke", ""]]}, {"id": "2102.01011", "submitter": "Yifeng Li", "authors": "Yifeng Li, Hsu Kiang Ooi, Alain Tchagang", "title": "Deep Evolutionary Learning for Molecular Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a deep evolutionary learning (DEL) process that\nintegrates fragment-based deep generative model and multi-objective\nevolutionary computation for molecular design. Our approach enables (1)\nevolutionary operations in the latent space of the generative model, rather\nthan the structural space, to generate novel promising molecular structures for\nthe next evolutionary generation, and (2) generative model fine-tuning using\nnewly generated high-quality samples. Thus, DEL implements a data-model\nco-evolution concept which improves both sample population and generative model\nlearning. Experiments on two public datasets indicate that sample population\nobtained by DEL exhibits improved property distributions, and dominates samples\ngenerated by multi-objective Bayesian optimization algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2020 03:15:46 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Li", "Yifeng", ""], ["Ooi", "Hsu Kiang", ""], ["Tchagang", "Alain", ""]]}, {"id": "2102.01012", "submitter": "Stefanos Tsimenidis", "authors": "Stefanos Tsimenidis", "title": "Evolutionary Algorithms for Fuzzy Cognitive Maps", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fuzzy Cognitive Maps (FCMs) is a complex systems modeling technique which,\ndue to its unique advantages, has lately risen in popularity. They are based on\ngraphs that represent the causal relationships among the parameters of the\nsystem to be modeled, and they stand out for their interpretability and\nflexibility. With the late popularity of FCMs, a plethora of research efforts\nhave taken place to develop and optimize the model. One of the most important\nelements of FCMs is the learning algorithm they use, and their effectiveness is\nlargely determined by it. The learning algorithms learn the node weights of an\nFCM, with the goal of converging towards the desired behavior. The present\nstudy reviews the genetic algorithms used for training FCMs, as well as gives a\ngeneral overview of the FCM learning algorithms, putting evolutionary computing\ninto the wider context.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 15:17:01 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Tsimenidis", "Stefanos", ""]]}, {"id": "2102.01201", "submitter": "Tarik A. Rashid", "authors": "Shahla U. Umar, Tarik A. Rashid", "title": "Critical Analysis: Bat Algorithm based Investigation and Application on\n  Several Domains", "comments": "25 pages, Review paper", "journal-ref": "World Journal of Engineering, 2021", "doi": "10.1108/WJE-10-2020-0495", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In recent years several swarm optimization algorithms, such as Bat Algorithm\n(BA) have emerged, which was proposed by Xin-She Yang in 2010. The idea of the\nalgorithm was taken from the echolocation ability of bats.\n  Purpose: The purpose of this study is to provide the reader with a full study\nof the Bat Algorithm, including its limitations, the fields that the algorithm\nhas been applied, versatile optimization problems in different domains, and all\nthe studies that assess its performance against other meta-heuristic\nalgorithms.\n  Approach: Bat Algorithm is given in-depth in terms of backgrounds,\ncharacteristics, limitations, it has also displayed the algorithms that\nhybridized with BA (K-Medoids, Back-propagation neural network, Harmony Search\nAlgorithm, Differential Evaluation Strategies, Enhanced Particle Swarm\nOptimization, and Cuckoo Search Algorithm) and their theoretical results, as\nwell as to the modifications that have been performed of the algorithm\n(Modified Bat Algorithm (MBA), Enhanced Bat Algorithm (EBA), Bat Algorithm with\nMutation (BAM), Uninhabited Combat Aerial Vehicle-Bat algorithm with Mutation\n(UCAV-BAM), Nonlinear Optimization)...\n  Findings: Shed light on the advantages and disadvantages of this algorithm\nthrough all the researches that dealt with the algorithm in addition to the\nfields and applications it has addressed in the hope that it will help\nscientists understand and develop it.\n  Originality/value: As far as the research community knowledge, there is no\ncomprehensive survey study conducted on this algorithm cover{\\i}ng all its\naspects.\n  Keywords: Swarm Intelligence; Nature-Inspired Algorithms; Metaheuristic\nAlgorithms; Optimization Algorithms; Bat Algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2021 19:25:12 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Umar", "Shahla U.", ""], ["Rashid", "Tarik A.", ""]]}, {"id": "2102.01344", "submitter": "Mikail Yayla", "authors": "Sebastian Buschj\\\"ager, Jian-Jia Chen, Kuan-Hsun Chen, Mario G\\\"unzel,\n  Katharina Morik, Rodion Novkin, Lukas Pfahler, Mikail Yayla", "title": "Bit Error Tolerance Metrics for Binarized Neural Networks", "comments": "Presented at DATE Friday Workshop on System-level Design Methods for\n  Deep Learning on Heterogeneous Architectures (SLOHA 2021) (arXiv:2102.00818)", "journal-ref": null, "doi": null, "report-no": "SLOHA/2021/02", "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To reduce the resource demand of neural network (NN) inference systems, it\nhas been proposed to use approximate memory, in which the supply voltage and\nthe timing parameters are tuned trading accuracy with energy consumption and\nperformance. Tuning these parameters aggressively leads to bit errors, which\ncan be tolerated by NNs when bit flips are injected during training. However,\nbit flip training, which is the state of the art for achieving bit error\ntolerance, does not scale well; it leads to massive overheads and cannot be\napplied for high bit error rates (BERs). Alternative methods to achieve bit\nerror tolerance in NNs are needed, but the underlying principles behind the bit\nerror tolerance of NNs have not been reported yet. With this lack of\nunderstanding, further progress in the research on NN bit error tolerance will\nbe restrained.\n  In this study, our objective is to investigate the internal changes in the\nNNs that bit flip training causes, with a focus on binarized NNs (BNNs). To\nthis end, we quantify the properties of bit error tolerant BNNs with two\nmetrics. First, we propose a neuron-level bit error tolerance metric, which\ncalculates the margin between the pre-activation values and batch normalization\nthresholds. Secondly, to capture the effects of bit error tolerance on the\ninterplay of neurons, we propose an inter-neuron bit error tolerance metric,\nwhich measures the importance of each neuron and computes the variance over all\nimportance values. Our experimental results support that these two metrics are\nstrongly related to bit error tolerance.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 06:44:55 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Buschj\u00e4ger", "Sebastian", ""], ["Chen", "Jian-Jia", ""], ["Chen", "Kuan-Hsun", ""], ["G\u00fcnzel", "Mario", ""], ["Morik", "Katharina", ""], ["Novkin", "Rodion", ""], ["Pfahler", "Lukas", ""], ["Yayla", "Mikail", ""]]}, {"id": "2102.01345", "submitter": "Etienne Dupuis", "authors": "Etienne Dupuis, David Novo, Ian O'Connor, Alberto Bosio", "title": "Fast Exploration of Weight Sharing Opportunities for CNN Compression", "comments": "Presented at DATE Friday Workshop on System-level Design Methods for\n  Deep Learning on Heterogeneous Architectures (SLOHA 2021) (arXiv:2102.00818)", "journal-ref": null, "doi": null, "report-no": "SLOHA/2021/05", "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational workload involved in Convolutional Neural Networks (CNNs)\nis typically out of reach for low-power embedded devices. There are a large\nnumber of approximation techniques to address this problem. These methods have\nhyper-parameters that need to be optimized for each CNNs using design space\nexploration (DSE). The goal of this work is to demonstrate that the DSE phase\ntime can easily explode for state of the art CNN. We thus propose the use of an\noptimized exploration process to drastically reduce the exploration time\nwithout sacrificing the quality of the output.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 06:45:56 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Dupuis", "Etienne", ""], ["Novo", "David", ""], ["O'Connor", "Ian", ""], ["Bosio", "Alberto", ""]]}, {"id": "2102.01355", "submitter": "Andrew Lensen", "authors": "Andrew Lensen", "title": "Mining Feature Relationships in Data", "comments": "16 pages, accepted in EuroGP '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  When faced with a new dataset, most practitioners begin by performing\nexploratory data analysis to discover interesting patterns and characteristics\nwithin data. Techniques such as association rule mining are commonly applied to\nuncover relationships between features (attributes) of the data. However,\nassociation rules are primarily designed for use on binary or categorical data,\ndue to their use of rule-based machine learning. A large proportion of\nreal-world data is continuous in nature, and discretisation of such data leads\nto inaccurate and less informative association rules. In this paper, we propose\nan alternative approach called feature relationship mining (FRM), which uses a\ngenetic programming approach to automatically discover symbolic relationships\nbetween continuous or categorical features in data. To the best of our\nknowledge, our proposed approach is the first such symbolic approach with the\ngoal of explicitly discovering relationships between features. Empirical\ntesting on a variety of real-world datasets shows the proposed method is able\nto find high-quality, simple feature relationships which can be easily\ninterpreted and which provide clear and non-trivial insight into data.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 07:06:16 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Lensen", "Andrew", ""]]}, {"id": "2102.01431", "submitter": "Florian Wirthm\\\"uller", "authors": "Florian Wirthm\\\"uller, Marvin Klimke, Julian Schlechtriemen, Jochen\n  Hipp and Manfred Reichert", "title": "Predicting the Time Until a Vehicle Changes the Lane Using LSTM-based\n  Recurrent Neural Networks", "comments": "the article has been accepted for publication in IEEE Robotics and\n  Automation Letters (RA-L); the article has been submitted to RA-L with IEEE\n  ICRA conference option; if the article will be presented during the\n  conference will be decided independently; 8 pages, 5 figures, 6 tables", "journal-ref": null, "doi": "10.1109/LRA.2021.3058930", "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To plan safe and comfortable trajectories for automated vehicles on highways,\naccurate predictions of traffic situations are needed. So far, a lot of\nresearch effort has been spent on detecting lane change maneuvers rather than\non estimating the point in time a lane change actually happens. In practice,\nhowever, this temporal information might be even more useful. This paper deals\nwith the development of a system that accurately predicts the time to the next\nlane change of surrounding vehicles on highways using long short-term\nmemory-based recurrent neural networks. An extensive evaluation based on a\nlarge real-world data set shows that our approach is able to make reliable\npredictions, even in the most challenging situations, with a root mean squared\nerror around 0.7 seconds. Already 3.5 seconds prior to lane changes the\npredictions become highly accurate, showing a median error of less than 0.25\nseconds. In summary, this article forms a fundamental step towards downstreamed\nhighly accurate position predictions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 11:04:22 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 09:07:53 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Wirthm\u00fcller", "Florian", ""], ["Klimke", "Marvin", ""], ["Schlechtriemen", "Julian", ""], ["Hipp", "Jochen", ""], ["Reichert", "Manfred", ""]]}, {"id": "2102.01503", "submitter": "Mohammed Elkomy Alaa", "authors": "Mohammed ElKomy", "title": "A Survey On (Stochastic Fractal Search) Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Evolutionary Algorithms are naturally inspired approximation optimisation\nalgorithms that usually interfere with science problems when common\nmathematical methods are unable to provide a good solution or finding the exact\nsolution requires an unreasonable amount of time using traditional exhaustive\nsearch algorithms. The success of these population-based frameworks is mainly\ndue to their flexibility and ease of adaptation to the most different and\ncomplex optimisation problems. This paper presents a metaheuristic algorithm\ncalled Stochastic Fractal Search, inspired by the natural phenomenon of growth\nbased on a mathematical concept called the fractal, which is shown to be able\nto explore the search space more efficiently. This paper also focuses on the\nalgorithm steps and some example applications of engineering design\noptimisation problems commonly used in the literature being applied to the\nproposed algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2021 22:44:04 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["ElKomy", "Mohammed", ""]]}, {"id": "2102.01512", "submitter": "Takeshi Ishida", "authors": "Takeshi Ishida", "title": "Mimicry mechanism model of octopus epidermis pattern by inverse\n  operation of Turing reaction model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cephalopods such as octopus and squid change their skin color\npurposefully within a very short time. Furthermore, it is widely known that\nsome octopuses have the ability to change the color and unevenness of the skin\nand to mimic the surroundings in short time. However, much research has not\nbeen done on the entire mimicry mechanism in which the octopus recognizes the\nsurrounding landscape and changes the skin pattern. It seems that there is no\nhypothetical model to explain the whole mimicry mechanism yet. In this study,\nthe mechanism of octopus skin pattern formation was assumed to be based on the\nTuring model. Here, the pattern formation by the Turing model was realized by\nthe equivalent filter calculation model using the cellular automaton, instead\nof directly solving the differential equations. It was shown that this model\ncan create various patterns with two feature parameters. Furthermore, for the\neyes recognition part where two features are extracted from the Turing pattern\nimage, our study proposed a method that can be calculated back with small\namount of calculation using the characteristics of the cellular Turing pattern\nmodel. These two calculations can be expressed in the same mathematical frame\nbased on the cellular automaton model using the convolution filter. As a\nresult, it can be created a model which is capable of extracting features from\npatterns and reconstructing patterns in a short time, the model is considered\nto be a basic model for considering the mimicry mechanism of octopus. Also, in\nterms of application to machine learning, it is considered that it shows the\npossibility of leading to a model with a small amount of learning calculation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2021 05:46:23 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Ishida", "Takeshi", ""]]}, {"id": "2102.01621", "submitter": "Luca Venturi", "authors": "Luca Venturi, Samy Jelassi, Tristan Ozuch, Joan Bruna", "title": "Depth separation beyond radial functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional depth separation results for neural networks show that\ncertain functions can be efficiently approximated by two-hidden-layer networks\nbut not by one-hidden-layer ones in high-dimensions $d$. Existing results of\nthis type mainly focus on functions with an underlying radial or\none-dimensional structure, which are usually not encountered in practice. The\nfirst contribution of this paper is to extend such results to a more general\nclass of functions, namely functions with piece-wise oscillatory structure, by\nbuilding on the proof strategy of (Eldan and Shamir, 2016). We complement these\nresults by showing that, if the domain radius and the rate of oscillation of\nthe objective function are constant, then approximation by one-hidden-layer\nnetworks holds at a $\\mathrm{poly}(d)$ rate for any fixed error threshold.\n  A common theme in the proof of such results is the fact that one-hidden-layer\nnetworks fail to approximate high-energy functions whose Fourier representation\nis spread in the domain. On the other hand, existing approximation results of a\nfunction by one-hidden-layer neural networks rely on the function having a\nsparse Fourier representation. The choice of the domain also represents a\nsource of gaps between upper and lower approximation bounds. Focusing on a\nfixed approximation domain, namely the sphere $\\mathbb{S}^{d-1}$ in dimension\n$d$, we provide a characterization of both functions which are efficiently\napproximable by one-hidden-layer networks and of functions which are provably\nnot, in terms of their Fourier expansion.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 17:25:02 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 17:49:56 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Venturi", "Luca", ""], ["Jelassi", "Samy", ""], ["Ozuch", "Tristan", ""], ["Bruna", "Joan", ""]]}, {"id": "2102.01633", "submitter": "Ji\\v{r}\\'i \\v{S}\\'ima", "authors": "Ji\\v{r}\\'i \\v{S}\\'ima", "title": "Stronger Separation of Analog Neuron Hierarchy by Deterministic\n  Context-Free Languages", "comments": "30 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the computational power of discrete-time recurrent neural networks\n(NNs) with the saturated-linear activation function within the Chomsky\nhierarchy. This model restricted to integer weights coincides with binary-state\nNNs with the Heaviside activation function, which are equivalent to finite\nautomata (Chomsky level 3) recognizing regular languages (REG), while rational\nweights make this model Turing-complete even for three analog-state units\n(Chomsky level 0). For the intermediate model $\\alpha$ANN of a binary-state NN\nthat is extended with $\\alpha\\geq 0$ extra analog-state neurons with rational\nweights, we have established the analog neuron hierarchy 0ANNs $\\subset$ 1ANNs\n$\\subset$ 2ANNs $\\subseteq$ 3ANNs. The separation 1ANNs $\\subsetneqq$ 2ANNs has\nbeen witnessed by the non-regular deterministic context-free language (DCFL)\n$L_\\#=\\{0^n1^n\\mid n\\geq 1\\}$ which cannot be recognized by any 1ANN even with\nreal weights, while any DCFL (Chomsky level 2) is accepted by a 2ANN with\nrational weights. In this paper, we strengthen this separation by showing that\nany non-regular DCFL cannot be recognized by 1ANNs with real weights, which\nmeans (DCFLs $\\setminus$ REG) $\\subset$ (2ANNs $\\setminus$ 1ANNs), implying\n1ANNs $\\cap$ DCFLs = 0ANNs. For this purpose, we have shown that $L_\\#$ is the\nsimplest non-regular DCFL by reducing $L_\\#$ to any language in this class,\nwhich is by itself an interesting achievement in computability theory.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 17:44:19 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["\u0160\u00edma", "Ji\u0159\u00ed", ""]]}, {"id": "2102.01645", "submitter": "Federico Galatolo", "authors": "Federico A. Galatolo and Mario G.C.A. Cimino and Gigliola Vaglini", "title": "Generating images from caption and vice versa via CLIP-Guided Generative\n  Latent Space Search", "comments": null, "journal-ref": null, "doi": "10.5220/0010503701660174", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research work we present CLIP-GLaSS, a novel zero-shot framework to\ngenerate an image (or a caption) corresponding to a given caption (or image).\nCLIP-GLaSS is based on the CLIP neural network, which, given an image and a\ndescriptive caption, provides similar embeddings. Differently, CLIP-GLaSS takes\na caption (or an image) as an input, and generates the image (or the caption)\nwhose CLIP embedding is the most similar to the input one. This optimal image\n(or caption) is produced via a generative network, after an exploration by a\ngenetic algorithm. Promising results are shown, based on the experimentation of\nthe image Generators BigGAN and StyleGAN2, and of the text Generator GPT2\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 18:00:13 GMT"}, {"version": "v2", "created": "Wed, 3 Feb 2021 12:14:49 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2021 22:42:49 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Galatolo", "Federico A.", ""], ["Cimino", "Mario G. C. A.", ""], ["Vaglini", "Gigliola", ""]]}, {"id": "2102.01830", "submitter": "Ricardo Di Pasquale", "authors": "Ricardo Di Pasquale and Javier Marenco", "title": "Machine learning for improving performance in an evolutionary algorithm\n  for minimum path with uncertain costs given by massively simulated scenarios", "comments": "6 pages, 7 figures, IEEE IJCAI DSO 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work we introduce an implementation for which machine learning\ntechniques helped improve the overall performance of an evolutionary algorithm\nfor an optimization problem, namely a variation of robust minimum-cost path in\ngraphs. In this big data optimization problem, a path achieving a good cost in\nmost scenarios from an available set of scenarios (generated by a simulation\nprocess) must be obtained. The most expensive task of our evolutionary\nalgorithm, in terms of computational resources, is the evaluation of candidate\npaths: the fitness function must calculate the cost of the candidate path in\nevery generated scenario. Given the large number of scenarios, this task must\nbe implemented in a distributed environment. We implemented gradient boosting\ndecision trees to classify candidate paths in order to identify good\ncandidates. The cost of the not-so-good candidates is simply forecasted. We\nstudied the training process, gain performance, accuracy, and other variables.\nOur computational experiments show that the computational performance was\nsignificantly improved at the expense of a limited loss of accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 01:38:35 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Di Pasquale", "Ricardo", ""], ["Marenco", "Javier", ""]]}, {"id": "2102.01832", "submitter": "Ricardo Di Pasquale", "authors": "Ricardo Di Pasquale and Javier Marenco", "title": "Optimization meets Big Data: A survey", "comments": "8 pages, 3 figures, IEEE CEC DSO 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DB cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper reviews recent advances in big data optimization, providing the\nstate-of-art of this emerging field. The main focus in this review are\noptimization techniques being applied in big data analysis environments.\nInteger linear programming, coordinate descent methods, alternating direction\nmethod of multipliers, simulation optimization and metaheuristics like\nevolutionary and genetic algorithms, particle swarm optimization, differential\nevolution, fireworks, bat, firefly and cuckoo search algorithms implementations\nare reviewed and discussed. The relation between big data optimization and\nsoftware engineering topics like information work-flow styles, software\narchitectures, and software framework is discussed. Comparative analysis in\nplatforms being used in big data optimization environments are highlighted in\norder to bring a state-or-art of possible architectures and topologies.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 01:44:39 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Di Pasquale", "Ricardo", ""], ["Marenco", "Javier", ""]]}, {"id": "2102.01852", "submitter": "Hiroki Kojima", "authors": "Hiroki Kojima and Takashi Ikegami", "title": "Organization of a Latent Space structure in VAE/GAN trained by\n  navigation data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel artificial cognitive mapping system using generative deep\nneural networks (VAE/GAN), which can map input images to latent vectors and\ngenerate temporal sequences internally. The results show that the distance of\nthe predicted image is reflected in the distance of the corresponding latent\nvector after training. This indicates that the latent space is constructed to\nreflect the proximity structure of the data set, and may provide a mechanism by\nwhich many aspects of cognition are spatially represented. The present study\nallows the network to internally generate temporal sequences analogous to\nhippocampal replay/pre-play, where VAE produces only near-accurate replays of\npast experiences, but by introducing GANs, latent vectors of temporally close\nimages are closely aligned and sequence acquired some instability. This may be\nthe origin of the generation of the new sequences found in the hippocampus.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 03:13:26 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Kojima", "Hiroki", ""], ["Ikegami", "Takashi", ""]]}, {"id": "2102.01968", "submitter": "Claire Theobald", "authors": "Claire Theobald (LORIA), Fr\\'ed\\'eric Pennerath (LORIA), Brieuc\n  Conan-Guez (LORIA), Miguel Couceiro (LORIA), Amedeo Napoli (LORIA)", "title": "A Bayesian Neural Network based on Dropout Regulation", "comments": null, "journal-ref": "Workshop on Uncertainty in Machine Learning (WUML) at ECML-PKDD\n  2020 Conference, Eyke H{\\\"u}llermeier; S{\\'e}bastien Destercke, 2020, N.A.\n  (online), France", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Neural Networks (BNN) have recently emerged in the Deep Learning\nworld for dealing with uncertainty estimation in classification tasks, and are\nused in many application domains such as astrophysics, autonomous driving...BNN\nassume a prior over the weights of a neural network instead of point estimates,\nenabling in this way the estimation of both aleatoric and epistemic uncertainty\nof the model prediction.Moreover, a particular type of BNN, namely MC Dropout,\nassumes a Bernoulli distribution on the weights by using Dropout.Several\nattempts to optimize the dropout rate exist, e.g. using a variational\napproach.In this paper, we present a new method called \"Dropout Regulation\"\n(DR), which consists of automatically adjusting the dropout rate during\ntraining using a controller as used in automation.DR allows for a precise\nestimation of the uncertainty which is comparable to the state-of-the-art while\nremaining simple to implement.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 09:39:50 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Theobald", "Claire", "", "LORIA"], ["Pennerath", "Fr\u00e9d\u00e9ric", "", "LORIA"], ["Conan-Guez", "Brieuc", "", "LORIA"], ["Couceiro", "Miguel", "", "LORIA"], ["Napoli", "Amedeo", "", "LORIA"]]}, {"id": "2102.02202", "submitter": "Agrim Gupta", "authors": "Agrim Gupta, Silvio Savarese, Surya Ganguli, Li Fei-Fei", "title": "Embodied Intelligence via Learning and Evolution", "comments": "Video available at https://youtu.be/MMrIiNavkuY", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The intertwined processes of learning and evolution in complex environmental\nniches have resulted in a remarkable diversity of morphological forms.\nMoreover, many aspects of animal intelligence are deeply embodied in these\nevolved morphologies. However, the principles governing relations between\nenvironmental complexity, evolved morphology, and the learnability of\nintelligent control, remain elusive, partially due to the substantial challenge\nof performing large-scale in silico experiments on evolution and learning. We\nintroduce Deep Evolutionary Reinforcement Learning (DERL): a novel\ncomputational framework which can evolve diverse agent morphologies to learn\nchallenging locomotion and manipulation tasks in complex environments using\nonly low level egocentric sensory information. Leveraging DERL we demonstrate\nseveral relations between environmental complexity, morphological intelligence\nand the learnability of control. First, environmental complexity fosters the\nevolution of morphological intelligence as quantified by the ability of a\nmorphology to facilitate the learning of novel tasks. Second, evolution rapidly\nselects morphologies that learn faster, thereby enabling behaviors learned late\nin the lifetime of early ancestors to be expressed early in the lifetime of\ntheir descendants. In agents that learn and evolve in complex environments,\nthis result constitutes the first demonstration of a long-conjectured\nmorphological Baldwin effect. Third, our experiments suggest a mechanistic\nbasis for both the Baldwin effect and the emergence of morphological\nintelligence through the evolution of morphologies that are more physically\nstable and energy efficient, and can therefore facilitate learning and control.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 18:58:31 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Gupta", "Agrim", ""], ["Savarese", "Silvio", ""], ["Ganguli", "Surya", ""], ["Fei-Fei", "Li", ""]]}, {"id": "2102.02332", "submitter": "Jon McCormack", "authors": "Jon McCormack, Camilo Cruz Gambardella and Andy Lomas", "title": "The Enigma of Complexity", "comments": "Preprint of paper accepted for EvoMUSART 2021 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.GR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper we examine the concept of complexity as it applies to\ngenerative art and design. Complexity has many different, discipline specific\ndefinitions, such as complexity in physical systems (entropy), algorithmic\nmeasures of information complexity and the field of \"complex systems\". We apply\na series of different complexity measures to three different generative art\ndatasets and look at the correlations between complexity and individual\naesthetic judgement by the artist (in the case of two datasets) or the\nphysically measured complexity of 3D forms. Our results show that the degree of\ncorrelation is different for each set and measure, indicating that there is no\noverall \"better\" measure. However, specific measures do perform well on\nindividual datasets, indicating that careful choice can increase the value of\nusing such measures. We conclude by discussing the value of direct measures in\ngenerative and evolutionary art, reinforcing recent findings from neuroimaging\nand psychology which suggest human aesthetic judgement is informed by many\nextrinsic factors beyond the measurable properties of the object being judged.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 23:26:49 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["McCormack", "Jon", ""], ["Gambardella", "Camilo Cruz", ""], ["Lomas", "Andy", ""]]}, {"id": "2102.02336", "submitter": "Emmanouil Vasileios Vlatakis Gkaragkounis", "authors": "Daniel Hsu, Clayton Sanford, Rocco A. Servedio, Emmanouil-Vasileios\n  Vlatakis-Gkaragkounis", "title": "On the Approximation Power of Two-Layer Networks of Random ReLUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the following question: how well can depth-two ReLU\nnetworks with randomly initialized bottom-level weights represent smooth\nfunctions? We give near-matching upper- and lower-bounds for\n$L_2$-approximation in terms of the Lipschitz constant, the desired accuracy,\nand the dimension of the problem, as well as similar results in terms of\nSobolev norms. Our positive results employ tools from harmonic analysis and\nridgelet representation theory, while our lower-bounds are based on (robust\nversions of) dimensionality arguments.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 23:41:34 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Hsu", "Daniel", ""], ["Sanford", "Clayton", ""], ["Servedio", "Rocco A.", ""], ["Vlatakis-Gkaragkounis", "Emmanouil-Vasileios", ""]]}, {"id": "2102.02558", "submitter": "Eneko Osaba", "authors": "Eneko Osaba, Aritz D. Martinez and Javier Del Ser", "title": "Evolutionary Multitask Optimization: a Methodological Overview,\n  Challenges and Future Research Directions", "comments": "29 pages, 4 figures, under review for its consideration in Applied\n  Soft Computing journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we consider multitasking in the context of solving multiple\noptimization problems simultaneously by conducting a single search process. The\nprincipal goal when dealing with this scenario is to dynamically exploit the\nexisting complementarities among the problems (tasks) being optimized, helping\neach other through the exchange of valuable knowledge. Additionally, the\nemerging paradigm of Evolutionary Multitasking tackles multitask optimization\nscenarios by using as inspiration concepts drawn from Evolutionary Computation.\nThe main purpose of this survey is to collect, organize and critically examine\nthe abundant literature published so far in Evolutionary Multitasking, with an\nemphasis on the methodological patterns followed when designing new algorithmic\nproposals in this area (namely, multifactorial optimization and\nmultipopulation-based multitasking). We complement our critical analysis with\nan identification of challenges that remain open to date, along with promising\nresearch directions that can stimulate future efforts in this topic. Our\ndiscussions held throughout this manuscript are offered to the audience as a\nreference of the general trajectory followed by the community working in this\nfield in recent times, as well as a self-contained entry point for newcomers\nand researchers interested to join this exciting research avenue.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 11:48:11 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Osaba", "Eneko", ""], ["Martinez", "Aritz D.", ""], ["Del Ser", "Javier", ""]]}, {"id": "2102.02579", "submitter": "Kazuya Horibe", "authors": "Kazuya Horibe, Kathryn Walker, Sebastian Risi", "title": "Regenerating Soft Robots through Neural Cellular Automata", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.RO q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Morphological regeneration is an important feature that highlights the\nenvironmental adaptive capacity of biological systems. Lack of this\nregenerative capacity significantly limits the resilience of machines and the\nenvironments they can operate in. To aid in addressing this gap, we develop an\napproach for simulated soft robots to regrow parts of their morphology when\nbeing damaged. Although numerical simulations using soft robots have played an\nimportant role in their design, evolving soft robots with regenerative\ncapabilities have so far received comparable little attention. Here we propose\na model for soft robots that regenerate through a neural cellular automata.\nImportantly, this approach only relies on local cell information to regrow\ndamaged components, opening interesting possibilities for physical regenerable\nsoft robots in the future. Our approach allows simulated soft robots that are\ndamaged to partially regenerate their original morphology through local cell\ninteractions alone and regain some of their ability to locomote. These results\ntake a step towards equipping artificial systems with regenerative capacities\nand could potentially allow for more robust operations in a variety of\nsituations and environments. The code for the experiments in this paper is\navailable at: \\url{github.com/KazuyaHoribe/RegeneratingSoftRobots}.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 12:44:38 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2021 11:55:06 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Horibe", "Kazuya", ""], ["Walker", "Kathryn", ""], ["Risi", "Sebastian", ""]]}, {"id": "2102.02810", "submitter": "Marco Roberti", "authors": "Cl\\'ement Rebuffel, Marco Roberti, Laure Soulier, Geoffrey\n  Scoutheeten, Rossella Cancelliere, Patrick Gallinari", "title": "Controlling Hallucinations at Word Level in Data-to-Text Generation", "comments": "20 pages, 6 figures, 5 tables (excluding Appendix). Source code:\n  https://github.com/KaijuML/dtt-multi-branch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-to-Text Generation (DTG) is a subfield of Natural Language Generation\naiming at transcribing structured data in natural language descriptions. The\nfield has been recently boosted by the use of neural-based generators which\nexhibit on one side great syntactic skills without the need of hand-crafted\npipelines; on the other side, the quality of the generated text reflects the\nquality of the training data, which in realistic settings only offer\nimperfectly aligned structure-text pairs. Consequently, state-of-art neural\nmodels include misleading statements - usually called hallucinations - in their\noutputs. The control of this phenomenon is today a major challenge for DTG, and\nis the problem addressed in the paper.\n  Previous work deal with this issue at the instance level: using an alignment\nscore for each table-reference pair. In contrast, we propose a finer-grained\napproach, arguing that hallucinations should rather be treated at the word\nlevel. Specifically, we propose a Multi-Branch Decoder which is able to\nleverage word-level labels to learn the relevant parts of each training\ninstance. These labels are obtained following a simple and efficient scoring\nprocedure based on co-occurrence analysis and dependency parsing. Extensive\nevaluations, via automated metrics and human judgment on the standard WikiBio\nbenchmark, show the accuracy of our alignment labels and the effectiveness of\nthe proposed Multi-Branch Decoder. Our model is able to reduce and control\nhallucinations, while keeping fluency and coherence in generated texts. Further\nexperiments on a degraded version of ToTTo show that our model could be\nsuccessfully used on very noisy settings.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 18:58:28 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 16:29:49 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Rebuffel", "Cl\u00e9ment", ""], ["Roberti", "Marco", ""], ["Soulier", "Laure", ""], ["Scoutheeten", "Geoffrey", ""], ["Cancelliere", "Rossella", ""], ["Gallinari", "Patrick", ""]]}, {"id": "2102.02886", "submitter": "Daniel Lenton", "authors": "Daniel Lenton, Fabio Pardo, Fabian Falck, Stephen James, Ronald Clark", "title": "Ivy: Templated Deep Learning for Inter-Framework Portability", "comments": "Code at https://github.com/ivy-dl/ivy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce Ivy, a templated Deep Learning (DL) framework which abstracts\nexisting DL frameworks. Ivy unifies the core functions of these frameworks to\nexhibit consistent call signatures, syntax and input-output behaviour. New\nhigh-level framework-agnostic functions and classes, which are usable alongside\nframework-specific code, can then be implemented as compositions of the unified\nlow-level Ivy functions. Ivy currently supports TensorFlow, PyTorch, MXNet, Jax\nand NumPy. We also release four pure-Ivy libraries for mechanics, 3D vision,\nrobotics, and differentiable environments. Through our evaluations, we show\nthat Ivy can significantly reduce lines of code with a runtime overhead of less\nthan 1% in most cases. We welcome developers to join the Ivy community by\nwriting their own functions, layers and libraries in Ivy, maximizing their\naudience and helping to accelerate DL research through inter-framework\ncodebases. More information can be found at https://ivy-dl.org.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 20:58:37 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2021 18:26:14 GMT"}, {"version": "v3", "created": "Mon, 5 Apr 2021 17:59:16 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Lenton", "Daniel", ""], ["Pardo", "Fabio", ""], ["Falck", "Fabian", ""], ["James", "Stephen", ""], ["Clark", "Ronald", ""]]}, {"id": "2102.03140", "submitter": "Giuseppe Paolo Mr", "authors": "Giuseppe Paolo (1 and 2), Alexandre Coninx (1), Stephane Doncieux (1),\n  Alban Laflaqui\\`ere (2) ((1) ISIR, (2) SBRE)", "title": "Sparse Reward Exploration via Novelty Search and Emitters", "comments": "In 2021 Genetic and Evolutionary Computation Conference (GECCO 21),\n  July, 2021, Lille, France. ACM, New York, NY, USA, 11 pages", "journal-ref": null, "doi": "10.1145/3449639.3459314", "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reward-based optimization algorithms require both exploration, to find\nrewards, and exploitation, to maximize performance. The need for efficient\nexploration is even more significant in sparse reward settings, in which\nperformance feedback is given sparingly, thus rendering it unsuitable for\nguiding the search process. In this work, we introduce the SparsE Reward\nExploration via Novelty and Emitters (SERENE) algorithm, capable of efficiently\nexploring a search space, as well as optimizing rewards found in potentially\ndisparate areas. Contrary to existing emitters-based approaches, SERENE\nseparates the search space exploration and reward exploitation into two\nalternating processes. The first process performs exploration through Novelty\nSearch, a divergent search algorithm. The second one exploits discovered reward\nareas through emitters, i.e. local instances of population-based optimization\nalgorithms. A meta-scheduler allocates a global computational budget by\nalternating between the two processes, ensuring the discovery and efficient\nexploitation of disjoint reward areas. SERENE returns both a collection of\ndiverse solutions covering the search space and a collection of high-performing\nsolutions for each distinct reward area. We evaluate SERENE on various sparse\nreward environments and show it compares favorably to existing baselines.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 12:34:54 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 08:33:19 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Paolo", "Giuseppe", "", "1 and 2"], ["Coninx", "Alexandre", "", "ISIR"], ["Doncieux", "Stephane", "", "ISIR"], ["Laflaqui\u00e8re", "Alban", "", "SBRE"]]}, {"id": "2102.03280", "submitter": "Hyeryung Jang", "authors": "Hyeryung Jang and Osvaldo Simeone", "title": "Multi-Sample Online Learning for Spiking Neural Networks based on\n  Generalized Expectation Maximization", "comments": "To be presented at ICASSP 2021. Author's Accepted Manuscript. (A\n  longer version can be found at arXiv:2007.11894), Author's Accepted\n  Manuscript. arXiv admin note: text overlap with arXiv:2007.11894", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) offer a novel computational paradigm that\ncaptures some of the efficiency of biological brains by processing through\nbinary neural dynamic activations. Probabilistic SNN models are typically\ntrained to maximize the likelihood of the desired outputs by using unbiased\nestimates of the log-likelihood gradients. While prior work used single-sample\nestimators obtained from a single run of the network, this paper proposes to\nleverage multiple compartments that sample independent spiking signals while\nsharing synaptic weights. The key idea is to use these signals to obtain more\naccurate statistical estimates of the log-likelihood training criterion, as\nwell as of its gradient. The approach is based on generalized\nexpectation-maximization (GEM), which optimizes a tighter approximation of the\nlog-likelihood using importance sampling. The derived online learning algorithm\nimplements a three-factor rule with global per-compartment learning signals.\nExperimental results on a classification task on the neuromorphic MNIST-DVS\ndata set demonstrate significant improvements in terms of log-likelihood,\naccuracy, and calibration when increasing the number of compartments used for\ntraining and inference.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 16:39:42 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Jang", "Hyeryung", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "2102.03380", "submitter": "Manuel L\\'opez-Ib\\'a\\~nez", "authors": "Manuel L\\'opez-Ib\\'a\\~nez (University of M\\'alaga, Spain), Juergen\n  Branke (University of Warwick, UK), Lu\\'is Paquete (University of Coimbra,\n  Portugal)", "title": "Reproducibility in Evolutionary Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental studies are prevalent in Evolutionary Computation (EC), and\nconcerns about the reproducibility and replicability of such studies have\nincreased in recent times, reflecting similar concerns in other scientific\nfields. In this article, we discuss, within the context of EC, the different\ntypes of reproducibility and suggest a classification that refines the badge\nsystem of the Association of Computing Machinery (ACM) adopted by ACM\nTransactions on Evolutionary Learning and Optimization\n(https://dlnext.acm.org/journal/telo). We identify cultural and technical\nobstacles to reproducibility in the EC field. Finally, we provide guidelines\nand suggest tools that may help to overcome some of these reproducibility\nobstacles.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 19:06:35 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 16:24:25 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["L\u00f3pez-Ib\u00e1\u00f1ez", "Manuel", "", "University of M\u00e1laga, Spain"], ["Branke", "Juergen", "", "University of Warwick, UK"], ["Paquete", "Lu\u00eds", "", "University of Coimbra,\n  Portugal"]]}, {"id": "2102.03385", "submitter": "Francesco Caravelli", "authors": "Francesco Caravelli, Forrest C. Sheldon, Fabio L. Traversa", "title": "Global minimization via classical tunneling assisted by collective force\n  field formation", "comments": "8 pages double column + 7 supplementary ; 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mes-hall cond-mat.soft cs.NE nlin.CD physics.class-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simple dynamical models can produce intricate behaviors in large networks.\nThese behaviors can often be observed in a wide variety of physical systems\ncaptured by the network of interactions. Here we describe a phenomenon where\nthe increase of dimensions self-consistently generates a force field due to\ndynamical instabilities. This can be understood as an unstable (\"rumbling\")\ntunneling mechanism between minima in an effective potential. We dub this\ncollective and nonperturbative effect a \"Lyapunov force\" which steers the\nsystem towards the global minimum of the potential function, even if the full\nsystem has a constellation of equilibrium points growing exponentially with the\nsystem size. The system we study has a simple mapping to a flow network,\nequivalent to current-driven memristors. The mechanism is appealing for its\nphysical relevance in nanoscale physics, and to possible applications in\noptimization, novel Monte Carlo schemes and machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 19:09:20 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 15:02:32 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Caravelli", "Francesco", ""], ["Sheldon", "Forrest C.", ""], ["Traversa", "Fabio L.", ""]]}, {"id": "2102.03547", "submitter": "Yuan-Hang Zhang", "authors": "Yuan-Hang Zhang, Massimiliano Di Ventra", "title": "Directed percolation and numerical stability of simulations of digital\n  memcomputing machines", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": "10.1063/5.0045375", "report-no": null, "categories": "cs.ET cond-mat.stat-mech cs.NE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital memcomputing machines (DMMs) are a novel, non-Turing class of\nmachines designed to solve combinatorial optimization problems. They can be\nphysically realized with continuous-time, non-quantum dynamical systems with\nmemory (time non-locality), whose ordinary differential equations (ODEs) can be\nnumerically integrated on modern computers. Solutions of many hard problems\nhave been reported by numerically integrating the ODEs of DMMs, showing\nsubstantial advantages over state-of-the-art solvers. To investigate the\nreasons behind the robustness and effectiveness of this method, we employ three\nexplicit integration schemes (forward Euler, trapezoid and Runge-Kutta 4th\norder) with a constant time step, to solve 3-SAT instances with planted\nsolutions. We show that, (i) even if most of the trajectories in the phase\nspace are destroyed by numerical noise, the solution can still be achieved;\n(ii) the forward Euler method, although having the largest numerical error,\nsolves the instances in the least amount of function evaluations; and (iii)\nwhen increasing the integration time step, the system undergoes a\n\"solvable-unsolvable transition\" at a critical threshold, which needs to decay\nat most as a power law with the problem size, to control the numerical errors.\nTo explain these results, we model the dynamical behavior of DMMs as directed\npercolation of the state trajectory in the phase space in the presence of\nnoise. This viewpoint clarifies the reasons behind their numerical robustness\nand provides an analytical understanding of the unsolvable-solvable transition.\nThese results land further support to the usefulness of DMMs in the solution of\nhard combinatorial optimization problems.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 09:44:28 GMT"}, {"version": "v2", "created": "Wed, 31 Mar 2021 16:41:46 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Zhang", "Yuan-Hang", ""], ["Di Ventra", "Massimiliano", ""]]}, {"id": "2102.03572", "submitter": "Xin Liu", "authors": "Jianyong Sun and Xin Liu and Thomas B\\\"ack and Zongben Xu", "title": "Learning adaptive differential evolution algorithm from optimization\n  experiences by policy gradient", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential evolution is one of the most prestigious population-based\nstochastic optimization algorithm for black-box problems. The performance of a\ndifferential evolution algorithm depends highly on its mutation and crossover\nstrategy and associated control parameters. However, the determination process\nfor the most suitable parameter setting is troublesome and time-consuming.\nAdaptive control parameter methods that can adapt to problem landscape and\noptimization environment are more preferable than fixed parameter settings.\nThis paper proposes a novel adaptive parameter control approach based on\nlearning from the optimization experiences over a set of problems. In the\napproach, the parameter control is modeled as a finite-horizon Markov decision\nprocess. A reinforcement learning algorithm, named policy gradient, is applied\nto learn an agent (i.e. parameter controller) that can provide the control\nparameters of a proposed differential evolution adaptively during the search\nprocedure. The differential evolution algorithm based on the learned agent is\ncompared against nine well-known evolutionary algorithms on the CEC'13 and\nCEC'17 test suites. Experimental results show that the proposed algorithm\nperforms competitively against these compared algorithms on the test suites.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 12:01:20 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Sun", "Jianyong", ""], ["Liu", "Xin", ""], ["B\u00e4ck", "Thomas", ""], ["Xu", "Zongben", ""]]}, {"id": "2102.03626", "submitter": "Markus Rummel", "authors": "Zakaria Patel and Markus Rummel", "title": "Extremal learning: extremizing the output of a neural network in\n  regression problems", "comments": "12 pages, 3 figures, code available at\n  https://github.com/ZakariaPZ/Extremal-Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks allow us to model complex relationships between variables. We\nshow how to efficiently find extrema of a trained neural network in regression\nproblems. Finding the extremizing input of an approximated model is formulated\nas the training of an additional neural network with a loss function that\nminimizes when the extremizing input is achieved. We further show how to\nincorporate additional constraints on the input vector such as limiting the\nextrapolation of the extremizing input vector from the original training data\nset. An instructional example of this approach using TensorFlow is included.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 18:01:17 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Patel", "Zakaria", ""], ["Rummel", "Markus", ""]]}, {"id": "2102.03740", "submitter": "Haiping Huang", "authors": "Wenxuan Zou, Chan Li, and Haiping Huang", "title": "Ensemble perspective for understanding temporal credit assignment", "comments": "17 pages, 18 figures, comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are widely used for modeling spatio-temporal\nsequences in both nature language processing and neural population dynamics.\nHowever, understanding the temporal credit assignment is hard. Here, we propose\nthat each individual connection in the recurrent computation is modeled by a\nspike and slab distribution, rather than a precise weight value. We then derive\nthe mean-field algorithm to train the network at the ensemble level. The method\nis then applied to classify handwritten digits when pixels are read in\nsequence, and to the multisensory integration task that is a fundamental\ncognitive function of animals. Our model reveals important connections that\ndetermine the overall performance of the network. The model also shows how\nspatio-temporal information is processed through the hyperparameters of the\ndistribution, and moreover reveals distinct types of emergent neural\nselectivity. It is thus promising to study the temporal credit assignment in\nrecurrent neural networks from the ensemble perspective.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 08:14:05 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Zou", "Wenxuan", ""], ["Li", "Chan", ""], ["Huang", "Haiping", ""]]}, {"id": "2102.03888", "submitter": "Fengyang Sun", "authors": "Minfang Lu, Fengyang Sun, Lin Wang, Shuai Ning, Shuangrong Liu, Bo\n  Yang", "title": "OPT-GAN: Global Black-box Optimization by Learning Distribution of\n  Optima", "comments": "12 pages, 6 figures, 2 tables, M. Lu and F. Sun contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Black-box optimization (BBO) algorithms are concerned with finding the best\nsolutions for problems with missing analytical details. Most classical methods\nfor such problems are based on strong and fixed \\emph{a priori} assumptions,\nsuch as Gaussian distribution. However, the complex real-world problems,\nespecially when the global optimum is desired, could be very far from the\n\\emph{a priori} assumptions because of their diversities, bringing some\nunexpected obstacles to these methods. In this paper, we present an optimizer\nusing generative adversarial nets (OPT-GAN) to adapt to diverse black-box\nproblems via estimating the distribution of optima. The method learns the\nextensive distribution of the optimal region dominated by selective and\nrandomly moving candidates, balancing the exploration and exploitation.\nExperiments demonstrate that on BBOB problems and several other benchmarks with\natypical distributions, OPT-GAN outperforms other classical BBO algorithms, in\nparticular the ones with Gaussian assumptions.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 19:12:09 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 09:46:24 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Lu", "Minfang", ""], ["Sun", "Fengyang", ""], ["Wang", "Lin", ""], ["Ning", "Shuai", ""], ["Liu", "Shuangrong", ""], ["Yang", "Bo", ""]]}, {"id": "2102.04013", "submitter": "Rohit Kumar Sachan Dr.", "authors": "Sachan Rohit Kumar and Kushwaha Dharmender Singh", "title": "Nature-Inspired Optimization Algorithms: Research Direction and Survey", "comments": "35 pages, 2 figures, 13 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nature-inspired algorithms are commonly used for solving the various\noptimization problems. In past few decades, various researchers have proposed a\nlarge number of nature-inspired algorithms. Some of these algorithms have\nproved to be very efficient as compared to other classical optimization\nmethods. A young researcher attempting to undertake or solve a problem using\nnature-inspired algorithms is bogged down by a plethora of proposals that exist\ntoday. Not every algorithm is suited for all kinds of problem. Some score over\nothers. In this paper, an attempt has been made to summarize various leading\nresearch proposals that shall pave way for any new entrant to easily understand\nthe journey so far. Here, we classify the nature-inspired algorithms as natural\nevolution based, swarm intelligence based, biological based, science based and\nothers. In this survey, widely acknowledged nature-inspired algorithms namely-\nACO, ABC, EAM, FA, FPA, GA, GSA, JAYA, PSO, SFLA, TLBO and WCA, have been\nstudied. The purpose of this review is to present an exhaustive analysis of\nvarious nature-inspired algorithms based on its source of inspiration, basic\noperators, control parameters, features, variants and area of application where\nthese algorithms have been successfully applied. It shall also assist in\nidentifying and short listing the methodologies that are best suited for the\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 06:03:36 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Kumar", "Sachan Rohit", ""], ["Singh", "Kushwaha Dharmender", ""]]}, {"id": "2102.04159", "submitter": "Wei Fang", "authors": "Wei Fang, Zhaofei Yu, Yanqi Chen, Tiejun Huang, Timoth\\'ee Masquelier,\n  Yonghong Tian", "title": "Deep Residual Learning in Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Spiking Neural Networks (SNNs) present optimization difficulties for\ngradient-based approaches due to discrete binary activation and complex\nspatial-temporal dynamics. Considering the huge success of ResNet in deep\nlearning, it would be natural to train deep SNNs with residual learning.\nPrevious Spiking ResNet mimics the standard residual block in ANNs and simply\nreplaces ReLU activation layers with spiking neurons, which suffers the\ndegradation problem and can hardly implement residual learning. In this paper,\nwe propose the spike-element-wise (SEW) ResNet to realize residual learning in\ndeep SNNs. We prove that the SEW ResNet can easily implement identity mapping\nand overcome the vanishing/exploding gradient problems of Spiking ResNet. We\nevaluate our SEW ResNet on ImageNet and DVS Gesture datasets, and show that SEW\nResNet outperforms the state-of-the-art directly trained SNNs in both accuracy\nand time-steps. Moreover, SEW ResNet can achieve higher performance by simply\nadding more layers, providing a simple method to train deep SNNs. To our best\nknowledge, this is the first time that directly training deep SNNs with more\nthan 100 layers becomes possible.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 12:22:33 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 12:15:28 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Fang", "Wei", ""], ["Yu", "Zhaofei", ""], ["Chen", "Yanqi", ""], ["Huang", "Tiejun", ""], ["Masquelier", "Timoth\u00e9e", ""], ["Tian", "Yonghong", ""]]}, {"id": "2102.04172", "submitter": "Johannes Jakubik", "authors": "Johannes Jakubik, Adrian Binding, Stefan Feuerriegel", "title": "Directed particle swarm optimization with Gaussian-process-based\n  function forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle swarm optimization (PSO) is an iterative search method that moves a\nset of candidate solution around a search-space towards the best known global\nand local solutions with randomized step lengths. PSO frequently accelerates\noptimization in practical applications, where gradients are not available and\nfunction evaluations expensive. Yet the traditional PSO algorithm ignores the\npotential knowledge that could have been gained of the objective function from\nthe observations by individual particles. Hence, we draw upon concepts from\nBayesian optimization and introduce a stochastic surrogate model of the\nobjective function. That is, we fit a Gaussian process to past evaluations of\nthe objective function, forecast its shape and then adapt the particle\nmovements based on it. Our computational experiments demonstrate that baseline\nimplementations of PSO (i.e., SPSO2011) are outperformed. Furthermore, compared\nto, state-of-art surrogate-assisted evolutionary algorithms, we achieve\nsubstantial performance improvements on several popular benchmark functions.\nOverall, we find that our algorithm attains desirable properties for\nexploratory and exploitative behavior.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 13:02:57 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 08:31:07 GMT"}, {"version": "v3", "created": "Wed, 24 Feb 2021 11:25:47 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Jakubik", "Johannes", ""], ["Binding", "Adrian", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "2102.04231", "submitter": "Vadim Liventsev", "authors": "Vadim Liventsev, Aki H\\\"arm\\\"a and Milan Petkovi\\'c", "title": "Neurogenetic Programming Framework for Explainable Reinforcement\n  Learning", "comments": "Source code is available at https://github.com/vadim0x60/cibi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic programming, the task of generating computer programs compliant\nwith a specification without a human developer, is usually tackled either via\ngenetic programming methods based on mutation and recombination of programs, or\nvia neural language models. We propose a novel method that combines both\napproaches using a concept of a virtual neuro-genetic programmer: using\nevolutionary methods as an alternative to gradient descent for neural network\ntraining}, or scrum team. We demonstrate its ability to provide performant and\nexplainable solutions for various OpenAI Gym tasks, as well as inject expert\nknowledge into the otherwise data-driven search for solutions.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 14:26:02 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Liventsev", "Vadim", ""], ["H\u00e4rm\u00e4", "Aki", ""], ["Petkovi\u0107", "Milan", ""]]}, {"id": "2102.04312", "submitter": "Henrik Daniel Mettler", "authors": "Henrik D. Mettler, Maximilian Schmidt, Walter Senn, Mihai A.\n  Petrovici, Jakob Jordan", "title": "Evolving Neuronal Plasticity Rules using Cartesian Genetic Programming", "comments": "2 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We formulate the search for phenomenological models of synaptic plasticity as\nan optimization problem. We employ Cartesian genetic programming to evolve\nbiologically plausible human-interpretable plasticity rules that allow a given\nnetwork to successfully solve tasks from specific task families. While our\nevolving-to-learn approach can be applied to various learning paradigms, here\nwe illustrate its power by evolving plasticity rules that allow a network to\nefficiently determine the first principal component of its input distribution.\nWe demonstrate that the evolved rules perform competitively with known\nhand-designed solutions. We explore how the statistical properties of the\ndatasets used during the evolutionary search influences the form of the\nplasticity rules and discover new rules which are adapted to the structure of\nthe corresponding datasets.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 16:17:15 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Mettler", "Henrik D.", ""], ["Schmidt", "Maximilian", ""], ["Senn", "Walter", ""], ["Petrovici", "Mihai A.", ""], ["Jordan", "Jakob", ""]]}, {"id": "2102.04681", "submitter": "Dennis Bautembach", "authors": "Dennis Bautembach, Iason Oikonomidis, Antonis Argyros", "title": "Multi-GPU SNN Simulation with Static Load Balancing", "comments": "Camera-ready version, accepted to IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a SNN simulator which scales to millions of neurons, billions of\nsynapses, and 8 GPUs. This is made possible by 1) a novel, cache-aware spike\ntransmission algorithm 2) a model parallel multi-GPU distribution scheme and 3)\na static, yet very effective load balancing strategy. The simulator further\nfeatures an easy to use API and the ability to create custom models. We compare\nthe proposed simulator against two state of the art ones on a series of\nbenchmarks using three well-established models. We find that our simulator is\nfaster, consumes less memory, and scales linearly with the number of GPUs.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 07:07:34 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 18:50:23 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Bautembach", "Dennis", ""], ["Oikonomidis", "Iason", ""], ["Argyros", "Antonis", ""]]}, {"id": "2102.04700", "submitter": "Peidong Liu", "authors": "Peidong Liu, Gengwei Zhang, Bochao Wang, Hang Xu, Xiaodan Liang, Yong\n  Jiang, Zhenguo Li", "title": "Loss Function Discovery for Object Detection via Convergence-Simulation\n  Driven Search", "comments": "Accepted by ICLR2021 Poster", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing proper loss functions for vision tasks has been a long-standing\nresearch direction to advance the capability of existing models. For object\ndetection, the well-established classification and regression loss functions\nhave been carefully designed by considering diverse learning challenges.\nInspired by the recent progress in network architecture search, it is\ninteresting to explore the possibility of discovering new loss function\nformulations via directly searching the primitive operation combinations. So\nthat the learned losses not only fit for diverse object detection challenges to\nalleviate huge human efforts, but also have better alignment with evaluation\nmetric and good mathematical convergence property. Beyond the previous\nauto-loss works on face recognition and image classification, our work makes\nthe first attempt to discover new loss functions for the challenging object\ndetection from primitive operation levels. We propose an effective\nconvergence-simulation driven evolutionary search algorithm, called\nCSE-Autoloss, for speeding up the search progress by regularizing the\nmathematical rationality of loss candidates via convergence property\nverification and model optimization simulation. CSE-Autoloss involves the\nsearch space that cover a wide range of the possible variants of existing\nlosses and discovers best-searched loss function combination within a short\ntime (around 1.5 wall-clock days). We conduct extensive evaluations of loss\nfunction search on popular detectors and validate the good generalization\ncapability of searched losses across diverse architectures and datasets. Our\nexperiments show that the best-discovered loss function combinations outperform\ndefault combinations by 1.1% and 0.8% in terms of mAP for two-stage and\none-stage detectors on COCO respectively. Our searched losses are available at\nhttps://github.com/PerdonLiu/CSE-Autoloss.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 08:34:52 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Liu", "Peidong", ""], ["Zhang", "Gengwei", ""], ["Wang", "Bochao", ""], ["Xu", "Hang", ""], ["Liang", "Xiaodan", ""], ["Jiang", "Yong", ""], ["Li", "Zhenguo", ""]]}, {"id": "2102.04822", "submitter": "Gregory Gay", "authors": "Hussein Almulla and Gregory Gay", "title": "Learning How to Search: Generating Effective Test Cases Through Adaptive\n  Fitness Function Selection", "comments": "Draft currently under revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Search-based test generation is guided by feedback from one or more fitness\nfunctions -- scoring functions that judge solution optimality. Choosing\ninformative fitness functions is crucial to meeting the goals of a tester.\nUnfortunately, many goals - such as forcing the class-under-test to throw\nexceptions, increasing test suite diversity, and attaining Strong Mutation\nCoverage - do not have effective fitness function formulations. We propose that\nmeeting such goals requires treating fitness function identification as a\nsecondary optimization step. An adaptive algorithm that can vary the selection\nof fitness functions could adjust its selection throughout the generation\nprocess to maximize goal attainment, based on the current population of test\nsuites. To test this hypothesis, we have implemented two reinforcement learning\nalgorithms in the EvoSuite unit test generation framework, and used these\nalgorithms to dynamically set the fitness functions used during generation for\nthe three goals identified above.\n  We have evaluated our framework, EvoSuiteFIT, on a set of Java case examples.\nEvoSuiteFIT techniques attain significant improvements for two of the three\ngoals, and show limited improvements on the third when the number of\ngenerations of evolution is fixed. Additionally, for two of the three goals,\nEvoSuiteFIT detects faults missed by the other techniques. The ability to\nadjust fitness functions allows strategic choices that efficiently produce more\neffective test suites, and examining these choices offers insight into how to\nattain our testing goals. We find that adaptive fitness function selection is a\npowerful technique to apply when an effective fitness function does not already\nexist for achieving a testing goal.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 13:44:37 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 08:08:40 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Almulla", "Hussein", ""], ["Gay", "Gregory", ""]]}, {"id": "2102.04869", "submitter": "Hojjat Salehinejad", "authors": "Hojjat Salehinejad, Jumpei Kitamura, Noah Ditkofsky, Amy Lin, Aditya\n  Bharatha, Suradech Suthiphosuwan, Hui-Ming Lin, Jefferson R. Wilson, Muhammad\n  Mamdani, and Errol Colak", "title": "A Real-World Demonstration of Machine Learning Generalizability:\n  Intracranial Hemorrhage Detection on Head CT", "comments": "This paper is under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) holds great promise in transforming healthcare. While\npublished studies have shown the utility of ML models in interpreting medical\nimaging examinations, these are often evaluated under laboratory settings. The\nimportance of real world evaluation is best illustrated by case studies that\nhave documented successes and failures in the translation of these models into\nclinical environments. A key prerequisite for the clinical adoption of these\ntechnologies is demonstrating generalizable ML model performance under real\nworld circumstances. The purpose of this study was to demonstrate that ML model\ngeneralizability is achievable in medical imaging with the detection of\nintracranial hemorrhage (ICH) on non-contrast computed tomography (CT) scans\nserving as the use case. An ML model was trained using 21,784 scans from the\nRSNA Intracranial Hemorrhage CT dataset while generalizability was evaluated\nusing an external validation dataset obtained from our busy trauma and\nneurosurgical center. This real world external validation dataset consisted of\nevery unenhanced head CT scan (n = 5,965) performed in our emergency department\nin 2019 without exclusion. The model demonstrated an AUC of 98.4%, sensitivity\nof 98.8%, and specificity of 98.0%, on the test dataset. On external\nvalidation, the model demonstrated an AUC of 95.4%, sensitivity of 91.3%, and\nspecificity of 94.1%. Evaluating the ML model using a real world external\nvalidation dataset that is temporally and geographically distinct from the\ntraining dataset indicates that ML generalizability is achievable in medical\nimaging applications.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 15:05:48 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Salehinejad", "Hojjat", ""], ["Kitamura", "Jumpei", ""], ["Ditkofsky", "Noah", ""], ["Lin", "Amy", ""], ["Bharatha", "Aditya", ""], ["Suthiphosuwan", "Suradech", ""], ["Lin", "Hui-Ming", ""], ["Wilson", "Jefferson R.", ""], ["Mamdani", "Muhammad", ""], ["Colak", "Errol", ""]]}, {"id": "2102.04871", "submitter": "Kenneth Reid", "authors": "Kenneth N. Reid, Iliya Miralavy, Stephen Kelly, Wolfgang Banzhaf,\n  Cedric Gondro", "title": "The Factory Must Grow: Automation in Factorio", "comments": "Submitted to GECCO 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficient optimization of resources is paramount to success in many problems\nfaced today. In the field of operational research the efficient scheduling of\nemployees; packing of vans; routing of vehicles; logistics of airlines and\ntransport of materials can be the difference between emission reduction or\nexcess, profits or losses and feasibility or unworkable solutions. The video\ngame Factorio, by Wube Software, has a myriad of problems which are analogous\nto such real-world problems, and is a useful simulator for developing solutions\nfor these problems. In this paper we define the logistic transport belt problem\nand define mathematical integer programming model of it. We developed an\ninterface to allow optimizers in any programming language to interact with\nFactorio, and we provide an initial benchmark of logistic transport belt\nproblems. We present results for Simulated Annealing, quick Genetic Programming\nand Evolutionary Reinforcement Learning, three different meta-heuristic\ntechniques to optimize this novel problem.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 15:14:27 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Reid", "Kenneth N.", ""], ["Miralavy", "Iliya", ""], ["Kelly", "Stephen", ""], ["Banzhaf", "Wolfgang", ""], ["Gondro", "Cedric", ""]]}, {"id": "2102.04944", "submitter": "Maxim Buzdalov", "authors": "Maxim Buzdalov and Carola Doerr", "title": "Optimal Static Mutation Strength Distributions for the $(1+\\lambda)$\n  Evolutionary Algorithm on OneMax", "comments": "Submitted for review to GECCO'21", "journal-ref": null, "doi": "10.1145/3449639.3459389", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most evolutionary algorithms have parameters, which allow a great flexibility\nin controlling their behavior and adapting them to new problems. To achieve the\nbest performance, it is often needed to control some of the parameters during\noptimization, which gave rise to various parameter control methods. In recent\nworks, however, similar advantages have been shown, and even proven, for\nsampling parameter values from certain, often heavy-tailed, fixed\ndistributions. This produced a family of algorithms currently known as \"fast\nevolution strategies\" and \"fast genetic algorithms\".\n  However, only little is known so far about the influence of these\ndistributions on the performance of evolutionary algorithms, and about the\nrelationships between (dynamic) parameter control and (static) parameter\nsampling. We contribute to the body of knowledge by presenting, for the first\ntime, an algorithm that computes the optimal static distributions, which\ndescribe the mutation operator used in the well-known simple $(1+\\lambda)$\nevolutionary algorithm on a classic benchmark problem OneMax. We show that, for\nlarge enough population sizes, such optimal distributions may be surprisingly\ncomplicated and counter-intuitive. We investigate certain properties of these\ndistributions, and also evaluate the performance regrets of the $(1+\\lambda)$\nevolutionary algorithm using commonly used mutation distributions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 16:56:25 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 01:58:28 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Buzdalov", "Maxim", ""], ["Doerr", "Carola", ""]]}, {"id": "2102.05021", "submitter": "Haimonti Dutta", "authors": "Haimonti Dutta, Nitin Nataraj, Saurabh Amarnath Mahindre", "title": "Consensus Based Multi-Layer Perceptrons for Edge Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, storing large volumes of data on distributed devices has\nbecome commonplace. Applications involving sensors, for example, capture data\nin different modalities including image, video, audio, GPS and others. Novel\nalgorithms are required to learn from this rich distributed data. In this\npaper, we present consensus based multi-layer perceptrons for\nresource-constrained devices. Assuming nodes (devices) in the distributed\nsystem are arranged in a graph and contain vertically partitioned data, the\ngoal is to learn a global function that minimizes the loss. Each node learns a\nfeed-forward multi-layer perceptron and obtains a loss on data stored locally.\nIt then gossips with a neighbor, chosen uniformly at random, and exchanges\ninformation about the loss. The updated loss is used to run a back propagation\nalgorithm and adjust weights appropriately. This method enables nodes to learn\nthe global function without exchange of data in the network. Empirical results\nreveal that the consensus algorithm converges to the centralized model and has\nperformance comparable to centralized multi-layer perceptrons and tree-based\nalgorithms including random forests and gradient boosted decision trees.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 18:39:46 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Dutta", "Haimonti", ""], ["Nataraj", "Nitin", ""], ["Mahindre", "Saurabh Amarnath", ""]]}, {"id": "2102.05235", "submitter": "Aneta Neumann", "authors": "William Reid, Aneta Neumann, Simon Ratcliffe, Frank Neumann", "title": "Advanced Ore Mine Optimisation under Uncertainty Using Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the impact of uncertainty in advanced ore mine\noptimisation. We consider Maptek's software system Evolution which optimizes\nextraction sequences based on evolutionary computation techniques and quantify\nthe uncertainty of the obtained solutions with respect to the ore deposit based\non predictions obtained by ensembles of neural networks. Furthermore, we\ninvestigate the impact of staging on the obtained optimized solutions and\ndiscuss a wide range of components for this large scale stochastic optimisation\nproblem which allow to mitigate the uncertainty in the ore deposit while\nmaintaining high profitability.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 03:10:02 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Reid", "William", ""], ["Neumann", "Aneta", ""], ["Ratcliffe", "Simon", ""], ["Neumann", "Frank", ""]]}, {"id": "2102.05303", "submitter": "Yue Xie", "authors": "Yue Xie, Aneta Neumann, Frank Neumann", "title": "Heuristic Strategies for Solving Complex Interacting Stockpile Blending\n  Problem with Chance Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heuristic algorithms have shown a good ability to solve a variety of\noptimization problems. Stockpile blending problem as an important component of\nthe mine scheduling problem is an optimization problem with continuous search\nspace containing uncertainty in the geologic input data. The objective of the\noptimization process is to maximize the total volume of materials of the\noperation and subject to resource capacities, chemical processes, and customer\nrequirements. In this paper, we consider the uncertainty in material grades and\nintroduce chance constraints that are used to ensure the constraints with high\nconfidence. To address the stockpile blending problem with chance constraints,\nwe propose a differential evolution algorithm combining two repair operators\nthat are used to tackle the two complex constraints. In the experiment section,\nwe compare the performance of the approach with the deterministic model and\nstochastic models by considering different chance constraints and evaluate the\neffectiveness of different chance constraints.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 07:56:18 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Xie", "Yue", ""], ["Neumann", "Aneta", ""], ["Neumann", "Frank", ""]]}, {"id": "2102.05370", "submitter": "Carola Doerr", "authors": "Anja Jankovic and Tome Eftimov and Carola Doerr", "title": "Towards Feature-Based Performance Regression Using Trajectory Data", "comments": "To appear in the Proceedings of EvoAPP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Black-box optimization is a very active area of research, with many new\nalgorithms being developed every year. This variety is needed, on the one hand,\nsince different algorithms are most suitable for different types of\noptimization problems. But the variety also poses a meta-problem: which\nalgorithm to choose for a given problem at hand? Past research has shown that\nper-instance algorithm selection based on exploratory landscape analysis (ELA)\ncan be an efficient mean to tackle this meta-problem. Existing approaches,\nhowever, require the approximation of problem features based on a significant\nnumber of samples, which are typically selected through uniform sampling or\nLatin Hypercube Designs. The evaluation of these points is costly, and the\nbenefit of an ELA-based algorithm selection over a default algorithm must\ntherefore be significant in order to pay off. One could hope to by-pass the\nevaluations for the feature approximations by using the samples that a default\nalgorithm would anyway perform, i.e., by using the points of the default\nalgorithm's trajectory.\n  We analyze in this paper how well such an approach can work. Concretely, we\ntest how accurately trajectory-based ELA approaches can predict the final\nsolution quality of the CMA-ES after a fixed budget of function evaluations. We\nobserve that the loss of trajectory-based predictions can be surprisingly small\ncompared to the classical global sampling approach, if the remaining budget for\nwhich solution quality shall be predicted is not too large. Feature selection,\nin contrast, did not show any advantage in our experiments and rather led to\nworsened prediction accuracy. The inclusion of state variables of CMA-ES only\nhas a moderate effect on the prediction accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 10:19:13 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Jankovic", "Anja", ""], ["Eftimov", "Tome", ""], ["Doerr", "Carola", ""]]}, {"id": "2102.05437", "submitter": "Hojjat Salehinejad", "authors": "Hojjat Salehinejad and Shahrokh Valaee", "title": "Pruning of Convolutional Neural Networks Using Ising Energy Model", "comments": "This paper is accepted for presentation at IEEE International\n  Conference on Acoustics, Speech and Signal Processing (IEEE ICASSP), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning is one of the major methods to compress deep neural networks. In this\npaper, we propose an Ising energy model within an optimization framework for\npruning convolutional kernels and hidden units. This model is designed to\nreduce redundancy between weight kernels and detect inactive kernels/hidden\nunits. Our experiments using ResNets, AlexNet, and SqueezeNet on CIFAR-10 and\nCIFAR-100 datasets show that the proposed method on average can achieve a\npruning rate of more than $50\\%$ of the trainable parameters with approximately\n$<10\\%$ and $<5\\%$ drop of Top-1 and Top-5 classification accuracy,\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 14:00:39 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Salehinejad", "Hojjat", ""], ["Valaee", "Shahrokh", ""]]}, {"id": "2102.05451", "submitter": "Yaron Strauch", "authors": "Yaron Strauch (University of Southampton), Jo Grundy (University of\n  Southampton)", "title": "Two Novel Performance Improvements for Evolving CNN Topologies", "comments": "Accepted to AAAI-21 Workshop W17: Learning Network Architecture\n  during Training. 5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) are the state-of-the-art algorithms for\nthe processing of images. However the configuration and training of these\nnetworks is a complex task requiring deep domain knowledge, experience and much\ntrial and error. Using genetic algorithms, competitive CNN topologies for image\nrecognition can be produced for any specific purpose, however in previous work\nthis has come at high computational cost. In this work two novel approaches are\npresented to the utilisation of these algorithms, effective in reducing\ncomplexity and training time by nearly 20%. This is accomplished via\nregularisation directly on training time, and the use of partial training to\nenable early ranking of individual architectures. Both approaches are validated\non the benchmark CIFAR10 data set, and maintain accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 14:17:51 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Strauch", "Yaron", "", "University of Southampton"], ["Grundy", "Jo", "", "University of\n  Southampton"]]}, {"id": "2102.05501", "submitter": "Yanis Bahroun", "authors": "Yanis Bahroun and Dmitri B. Chklovskii", "title": "A Neural Network with Local Learning Rules for Minor Subspace Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The development of neuromorphic hardware and modeling of biological neural\nnetworks requires algorithms with local learning rules. Artificial neural\nnetworks using local learning rules to perform principal subspace analysis\n(PSA) and clustering have recently been derived from principled objective\nfunctions. However, no biologically plausible networks exist for minor subspace\nanalysis (MSA), a fundamental signal processing task. MSA extracts the\nlowest-variance subspace of the input signal covariance matrix. Here, we\nintroduce a novel similarity matching objective for extracting the minor\nsubspace, Minor Subspace Similarity Matching (MSSM). Moreover, we derive an\nadaptive MSSM algorithm that naturally maps onto a novel neural network with\nlocal learning rules and gives numerical results showing that our method\nconverges at a competitive rate.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 15:44:27 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Bahroun", "Yanis", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "2102.05503", "submitter": "Yanis Bahroun", "authors": "Yanis Bahroun and Anirvan M. Sengupta and Dmitri B. Chklovskii", "title": "A Similarity-preserving Neural Network Trained on Transformed Images\n  Recapitulates Salient Features of the Fly Motion Detection Circuit", "comments": "Body and supplementary materials of NeurIPS 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning to detect content-independent transformations from data is one of\nthe central problems in biological and artificial intelligence. An example of\nsuch problem is unsupervised learning of a visual motion detector from pairs of\nconsecutive video frames. Rao and Ruderman formulated this problem in terms of\nlearning infinitesimal transformation operators (Lie group generators) via\nminimizing image reconstruction error. Unfortunately, it is difficult to map\ntheir model onto a biologically plausible neural network (NN) with local\nlearning rules. Here we propose a biologically plausible model of motion\ndetection. We also adopt the transformation-operator approach but, instead of\nreconstruction-error minimization, start with a similarity-preserving objective\nfunction. An online algorithm that optimizes such an objective function\nnaturally maps onto an NN with biologically plausible learning rules. The\ntrained NN recapitulates major features of the well-studied motion detector in\nthe fly. In particular, it is consistent with the experimental observation that\nlocal motion detectors combine information from at least three adjacent pixels,\nsomething that contradicts the celebrated Hassenstein-Reichardt model.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 15:45:40 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Bahroun", "Yanis", ""], ["Sengupta", "Anirvan M.", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "2102.05588", "submitter": "Frieder Stolzenburg", "authors": "Stefanie Krause, Oliver Otto, Frieder Stolzenburg", "title": "Fast Classification Learning with Neural Networks and Conceptors for\n  Speech Recognition and Car Driving Maneuvers", "comments": "16 pages, 6 figures, 5 tables, extended version", "journal-ref": "In Phatthanaphong Chomphuwiset, Junmo Kim, and Pornntiwa Pawara,\n  editors, Proceedings of the 14th Multi-Disciplinary International Conference\n  on Artificial Intelligence (MIWAI), LNAI 12832, pages 45-57. Springer, 2021", "doi": "10.1007/978-3-030-80253-0_5", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are a powerful means in diverse applications. We\nshow that, together with so-called conceptors, they also allow fast learning,\nin contrast to other deep learning methods. In addition, a relatively small\nnumber of examples suffices to train neural networks with high accuracy. We\ndemonstrate this with two applications, namely speech recognition and detecting\ncar driving maneuvers. We improve the state of the art by application-specific\npreparation techniques: For speech recognition, we use mel frequency cepstral\ncoefficients leading to a compact representation of the frequency spectra, and\ndetecting car driving maneuvers can be done without the commonly used\npolynomial interpolation, as our evaluation suggests.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 17:36:54 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 20:54:12 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 10:21:22 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Krause", "Stefanie", ""], ["Otto", "Oliver", ""], ["Stolzenburg", "Frieder", ""]]}, {"id": "2102.05774", "submitter": "Vojtech Vancura", "authors": "Vojt\\v{e}ch Van\\v{c}ura and Pavel Kord\\'ik", "title": "Deep Variational Autoencoder with Shallow Parallel Path for Top-N\n  Recommendation (VASP)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently introduced EASE algorithm presents a simple and elegant way, how to\nsolve the top-N recommendation task. In this paper, we introduce Neural EASE to\nfurther improve the performance of this algorithm by incorporating techniques\nfor training modern neural networks. Also, there is a growing interest in the\nrecsys community to utilize variational autoencoders (VAE) for this task. We\nintroduce deep autoencoder FLVAE benefiting from multiple non-linear layers\nwithout an information bottleneck while not overfitting towards the identity.\nWe show how to learn FLVAE in parallel with Neural EASE and achieve the state\nof the art performance on the MovieLens 20M dataset and competitive results on\nthe Netflix Prize dataset.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 23:27:07 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Van\u010dura", "Vojt\u011bch", ""], ["Kord\u00edk", "Pavel", ""]]}, {"id": "2102.05778", "submitter": "Yue Xie", "authors": "Yue Xie, Aneta Neumann, Frank Neumann, Andrew M. Sutton", "title": "Runtime Analysis of RLS and the (1+1) EA for the Chance-constrained\n  Knapsack Problem with Correlated Uniform Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Addressing a complex real-world optimization problem is a challenging task.\nThe chance-constrained knapsack problem with correlated uniform weights plays\nan important role in the case where dependent stochastic components are\nconsidered. We perform runtime analysis of a randomized search algorithm (RSA)\nand a basic evolutionary algorithm (EA) for the chance-constrained knapsack\nproblem with correlated uniform weights. We prove bounds for both algorithms\nfor producing a feasible solution. Furthermore, we investigate the behavior of\nthe algorithms and carry out analyses on two settings: uniform profit value and\nthe setting in which every group shares an arbitrary profit profile. We provide\ninsight into the structure of these problems and show how the weight\ncorrelations and the different types of profit profiles influence the runtime\nbehavior of both algorithms in the chance-constrained setting.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 23:40:01 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Xie", "Yue", ""], ["Neumann", "Aneta", ""], ["Neumann", "Frank", ""], ["Sutton", "Andrew M.", ""]]}, {"id": "2102.05814", "submitter": "Mustafa Abdallah", "authors": "Mustafa Abdallah, Wo Jae Lee, Nithin Raghunathan, Charilaos Mousoulis,\n  John W. Sutherland, and Saurabh Bagchi", "title": "Anomaly Detection through Transfer Learning in Agriculture and\n  Manufacturing IoT Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  IoT systems have been facing increasingly sophisticated technical problems\ndue to the growing complexity of these systems and their fast deployment\npractices. Consequently, IoT managers have to judiciously detect failures\n(anomalies) in order to reduce their cyber risk and operational cost. While\nthere is a rich literature on anomaly detection in many IoT-based systems,\nthere is no existing work that documents the use of ML models for anomaly\ndetection in digital agriculture and in smart manufacturing systems. These two\napplication domains pose certain salient technical challenges. In agriculture\nthe data is often sparse, due to the vast areas of farms and the requirement to\nkeep the cost of monitoring low. Second, in both domains, there are multiple\ntypes of sensors with varying capabilities and costs. The sensor data\ncharacteristics change with the operating point of the environment or machines,\nsuch as, the RPM of the motor. The inferencing and the anomaly detection\nprocesses therefore have to be calibrated for the operating point.\n  In this paper, we analyze data from sensors deployed in an agricultural farm\nwith data from seven different kinds of sensors, and from an advanced\nmanufacturing testbed with vibration sensors. We evaluate the performance of\nARIMA and LSTM models for predicting the time series of sensor data. Then,\nconsidering the sparse data from one kind of sensor, we perform transfer\nlearning from a high data rate sensor. We then perform anomaly detection using\nthe predicted sensor data. Taken together, we show how in these two application\ndomains, predictive failure classification can be achieved, thus paving the way\nfor predictive maintenance.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 02:37:27 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Abdallah", "Mustafa", ""], ["Lee", "Wo Jae", ""], ["Raghunathan", "Nithin", ""], ["Mousoulis", "Charilaos", ""], ["Sutherland", "John W.", ""], ["Bagchi", "Saurabh", ""]]}, {"id": "2102.05864", "submitter": "Camilo Cruz Gambardella", "authors": "Camilo Cruz Gambardella and Jon McCormack", "title": "Searching for Designs in-between", "comments": "Preprint of paper accepted for CAADRIA 2021 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The use of evolutionary methods in design and art is increasing in diversity\nand popularity. Approaches to using these methods for creative production\ntypically focus either on optimisation or exploration. In this paper we\nintroduce an evolutionary system for design that combines these two approaches,\nenabling users to explore landscapes of design alternatives using\ndesign-oriented measures of fitness, along with their own aesthetic\npreferences. We test our methods using a biologically-inspired generative\nsystem capable of producing 3D objects that can be exported directly as 3D\nprinting toolpath instructions. For the search stage of our system we combine\nthe use of the CMA-ES algorithm for optimisation and linear interpolation\nbetween generated objects for feature exploration. We investigate the system`s\ncapabilities by evolving highly fit artefacts and then combining them with\naesthetically interesting ones.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 06:44:42 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Gambardella", "Camilo Cruz", ""], ["McCormack", "Jon", ""]]}, {"id": "2102.05875", "submitter": "Kaiwen Li", "authors": "Kaiwen Li, Tao Zhang, Rui Wang Yuheng Wang, and Yi Han", "title": "Deep Reinforcement Learning for Combinatorial Optimization: Covering\n  Salesman Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new deep learning approach to approximately solve the\nCovering Salesman Problem (CSP). In this approach, given the city locations of\na CSP as input, a deep neural network model is designed to directly output the\nsolution. It is trained using the deep reinforcement learning without\nsupervision. Specifically, in the model, we apply the Multi-head Attention to\ncapture the structural patterns, and design a dynamic embedding to handle the\ndynamic patterns of the problem. Once the model is trained, it can generalize\nto various types of CSP tasks (different sizes and topologies) with no need of\nre-training. Through controlled experiments, the proposed approach shows\ndesirable time complexity: it runs more than 20 times faster than the\ntraditional heuristic solvers with a tiny gap of optimality. Moreover, it\nsignificantly outperforms the current state-of-the-art deep learning approaches\nfor combinatorial optimization in the aspect of both training and inference. In\ncomparison with traditional solvers, this approach is highly desirable for most\nof the challenging tasks in practice that are usually large-scale and require\nquick decisions.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 07:25:04 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Li", "Kaiwen", ""], ["Zhang", "Tao", ""], ["Wang", "Rui Wang Yuheng", ""], ["Han", "Yi", ""]]}, {"id": "2102.05892", "submitter": "Laurent Najman", "authors": "Quentin Garrido (LIGM, HCI), Sebastian Damrich (HCI), Alexander\n  J\\\"ager (HCI), Dario Cerletti (HCI), Manfred Claassen, Laurent Najman (LIGM),\n  Fred Hamprecht (HCI)", "title": "Visualizing hierarchies in scRNA-seq data using a density tree-biased\n  autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single cell RNA sequencing (scRNA-seq) data makes studying the development of\ncells possible at unparalleled resolution. Given that many cellular\ndifferentiation processes are hierarchical, their scRNA-seq data is expected to\nbe approximately tree-shaped in gene expression space. Inference and\nrepresentation of this tree-structure in two dimensions is highly desirable for\nbiological interpretation and exploratory analysis. Our two contributions are\nan approach for identifying a meaningful tree structure from high-dimensional\nscRNA-seq data, and a visualization method respecting the tree-structure. We\nextract the tree structure by means of a density based minimum spanning tree on\na vector quantization of the data and show that it captures biological\ninformation well. We then introduce DTAE, a tree-biased autoencoder that\nemphasizes the tree structure of the data in low dimensional space. We compare\nto other dimension reduction methods and demonstrate the success of our method\nexperimentally. Our implementation relying on PyTorch and Higra is available at\ngithub.com/hci-unihd/DTAE.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 08:48:48 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Garrido", "Quentin", "", "LIGM, HCI"], ["Damrich", "Sebastian", "", "HCI"], ["J\u00e4ger", "Alexander", "", "HCI"], ["Cerletti", "Dario", "", "HCI"], ["Claassen", "Manfred", "", "LIGM"], ["Najman", "Laurent", "", "LIGM"], ["Hamprecht", "Fred", "", "HCI"]]}, {"id": "2102.06358", "submitter": "Ye Luo", "authors": "Ye Luo and Shiqing Fan", "title": "Min-Max-Plus Neural Networks", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG math.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a new model of neural networks called Min-Max-Plus Neural Networks\n(MMP-NNs) based on operations in tropical arithmetic. In general, an MMP-NN is\ncomposed of three types of alternately stacked layers, namely linear layers,\nmin-plus layers and max-plus layers. Specifically, the latter two types of\nlayers constitute the nonlinear part of the network which is trainable and more\nsophisticated compared to the nonlinear part of conventional neural networks.\nIn addition, we show that with higher capability of nonlinearity expression,\nMMP-NNs are universal approximators of continuous functions, even when the\nnumber of multiplication operations is tremendously reduced (possibly to none\nin certain extreme cases). Furthermore, we formulate the backpropagation\nalgorithm in the training process of MMP-NNs and introduce an algorithm of\nnormalization to improve the rate of convergence in training.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 06:09:20 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Luo", "Ye", ""], ["Fan", "Shiqing", ""]]}, {"id": "2102.06435", "submitter": "Carola Doerr", "authors": "Amine Aziz-Alaoui and Carola Doerr and Johann Dreo", "title": "Towards Large Scale Automated Algorithm Design by Integrating Modular\n  Benchmarking Frameworks", "comments": "To appear in the Companion Material of ACM Genetic and Evolutionary\n  Computation Conference (GECCO'21) as workshop paper", "journal-ref": null, "doi": "10.1145/3449726.3463155", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a first proof-of-concept use-case that demonstrates the efficiency\nof interfacing the algorithm framework ParadisEO with the automated algorithm\nconfiguration tool irace and the experimental platform IOHprofiler. By combing\nthese three tools, we obtain a powerful benchmarking environment that allows us\nto systematically analyze large classes of algorithms on complex benchmark\nproblems. Key advantages of our pipeline are fast evaluation times, the\npossibility to generate rich data sets to support the analysis of the\nalgorithms, and a standardized interface that can be used to benchmark very\nbroad classes of sampling-based optimization heuristics.\n  In addition to enabling systematic algorithm configuration studies, our\napproach paves a way for assessing the contribution of new ideas in interplay\nwith already existing operators -- a promising avenue for our research domain,\nwhich at present may have a too strong focus on comparing entire algorithm\ninstances.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 10:47:00 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 13:14:27 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Aziz-Alaoui", "Amine", ""], ["Doerr", "Carola", ""], ["Dreo", "Johann", ""]]}, {"id": "2102.06481", "submitter": "Furong Ye", "authors": "Furong Ye, Carola Doerr, Thomas B\\\"ack", "title": "Leveraging Benchmarking Data for Informed One-Shot Dynamic Algorithm\n  Selection", "comments": "Submitted for review to GECCO'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in the application of evolutionary algorithms in practice is\nthe selection of an algorithm instance that best suits the problem at hand.\nWhat complicates this decision further is that different algorithms may be best\nsuited for different stages of the optimization process. Dynamic algorithm\nselection and configuration are therefore well-researched topics in\nevolutionary computation. However, while hyper-heuristics and parameter control\nstudies typically assume a setting in which the algorithm needs to be chosen\nwhile running the algorithms, without prior information, AutoML approaches such\nas hyper-parameter tuning and automated algorithm configuration assume the\npossibility of evaluating different configurations before making a final\nrecommendation. In practice, however, we are often in a middle-ground between\nthese two settings, where we need to decide on the algorithm instance before\nthe run (\"oneshot\" setting), but where we have (possibly lots of) data\navailable on which we can base an informed decision.\n  We analyze in this work how such prior performance data can be used to infer\ninformed dynamic algorithm selection schemes for the solution of pseudo-Boolean\noptimization problems. Our specific use-case considers a family of genetic\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 12:27:02 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Ye", "Furong", ""], ["Doerr", "Carola", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2102.06635", "submitter": "Christoph Hertrich", "authors": "Christoph Hertrich and Leon Sering", "title": "ReLU Neural Networks for Exact Maximum Flow Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the great empirical success of artificial neural networks (NNs)\nfrom a theoretical point of view is currently one of the hottest research\ntopics in computer science. In this paper we study the expressive power of NNs\nwith rectified linear units from a combinatorial optimization perspective. In\nparticular, we show that, given a directed graph with $n$ nodes and $m$ arcs,\nthere exists an NN of polynomial size that computes a maximum flow from any\npossible real-valued arc capacities as input. To prove this, we develop the\npseudo-code language Max-Affine Arithmetic Programs (MAAPs) and show\nequivalence between MAAPs and NNs concerning natural complexity measures. We\nthen design a MAAP to exactly solve the Maximum Flow Problem, which translates\nto an NN of size $\\mathcal{O}(m^2 n^2)$.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 17:23:34 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Hertrich", "Christoph", ""], ["Sering", "Leon", ""]]}, {"id": "2102.06870", "submitter": "Wissam Baddar", "authors": "Wissam J. Baddar, Seungju Han, Seonmin Rhee, Jae-Joon Han", "title": "Self-Reorganizing and Rejuvenating CNNs for Increasing Model Capacity\n  Utilization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose self-reorganizing and rejuvenating convolutional\nneural networks; a biologically inspired method for improving the computational\nresource utilization of neural networks. The proposed method utilizes the\nchannel activations of a convolution layer in order to reorganize that layers\nparameters. The reorganized parameters are clustered to avoid parameter\nredundancies. As such, redundant neurons with similar activations are merged\nleaving room for the remaining parameters to rejuvenate. The rejuvenated\nparameters learn different features to supplement those learned by the\nreorganized surviving parameters. As a result, the network capacity utilization\nincreases improving the baseline network performance without any changes to the\nnetwork structure. The proposed method can be applied to various network\narchitectures during the training stage, or applied to a pre-trained model\nimproving its performance. Experimental results showed that the proposed method\nis model-agnostic and can be applied to any backbone architecture increasing\nits performance due to the elevated utilization of the network capacity.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 06:19:45 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Baddar", "Wissam J.", ""], ["Han", "Seungju", ""], ["Rhee", "Seonmin", ""], ["Han", "Jae-Joon", ""]]}, {"id": "2102.06929", "submitter": "Amir Mosavi Prof", "authors": "Aliakbar Narimani, Mahdi Moghimi, Amir Mosavi", "title": "Hybrid Artificial Intelligence Methods for Predicting Air Demand in Dam\n  Bottom Outlet", "comments": "14 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In large infrastructures such as dams, which have a relatively high economic\nvalue, ensuring the proper operation of the associated hydraulic facilities in\ndifferent operating conditions is of utmost importance. To ensure the correct\nand successful operation of the dam's hydraulic equipment and prevent possible\ndamages, including gates and downstream tunnel, to build laboratory models and\nperform some tests are essential (the advancement of the smart sensors based on\nartificial intelligence is essential). One of the causes of damage to dam\nbottom outlets is cavitation in downstream and between the gates, which can\nimpact on dam facilities, and air aeration can be a solution to improve it. In\nthe present study, six dams in different provinces in Iran has been chosen to\nevaluate the air entrainment in the downstream tunnel experimentally. Three\nartificial neural networks (ANN) based machine learning (ML) algorithms are\nused to model and predict the air aeration in the bottom outlet. The proposed\nmodels are trained with genetic algorithms (GA), particle swarm optimization\n(PSO), i.e., ANN-GA, ANN-PSO, and ANFIS-PSO. Two hydrodynamic variables, namely\nvolume rate and opening percentage of the gate, are used as inputs into all\nbottom outlet models. The results showed that the most optimal model is\nANFIS-PSO to predict the dependent value compared with ANN-GA and ANN-PSO. The\nimportance of the volume rate and opening percentage of the dams' gate\nparameters is more effective for suitable air aeration.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 13:41:03 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Narimani", "Aliakbar", ""], ["Moghimi", "Mahdi", ""], ["Mosavi", "Amir", ""]]}, {"id": "2102.06940", "submitter": "Cameron Shand", "authors": "Cameron Shand, Richard Allmendinger, Julia Handl, Andrew Webb, and\n  John Keane", "title": "HAWKS: Evolving Challenging Benchmark Sets for Cluster Analysis", "comments": "15 pages + 9 pages supplementary, submitted to IEEE Transactions on\n  Evolutionary Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comprehensive benchmarking of clustering algorithms is rendered difficult by\ntwo key factors: (i)~the elusiveness of a unique mathematical definition of\nthis unsupervised learning approach and (ii)~dependencies between the\ngenerating models or clustering criteria adopted by some clustering algorithms\nand indices for internal cluster validation. Consequently, there is no\nconsensus regarding the best practice for rigorous benchmarking, and whether\nthis is possible at all outside the context of a given application. Here, we\nargue that synthetic datasets must continue to play an important role in the\nevaluation of clustering algorithms, but that this necessitates constructing\nbenchmarks that appropriately cover the diverse set of properties that impact\nclustering algorithm performance. Through our framework, HAWKS, we demonstrate\nthe important role evolutionary algorithms play to support flexible generation\nof such benchmarks, allowing simple modification and extension. We illustrate\ntwo possible uses of our framework: (i)~the evolution of benchmark data\nconsistent with a set of hand-derived properties and (ii)~the generation of\ndatasets that tease out performance differences between a given pair of\nalgorithms. Our work has implications for the design of clustering benchmarks\nthat sufficiently challenge a broad range of algorithms, and for furthering\ninsight into the strengths and weaknesses of specific approaches.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 15:01:34 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Shand", "Cameron", ""], ["Allmendinger", "Richard", ""], ["Handl", "Julia", ""], ["Webb", "Andrew", ""], ["Keane", "John", ""]]}, {"id": "2102.06942", "submitter": "Philip M\\\"uller", "authors": "Philip M\\\"uller, Vladimir Golkov, Valentina Tomassini, Daniel Cremers", "title": "Rotation-Equivariant Deep Learning for Diffusion MRI", "comments": "24 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional networks are successful, but they have recently been\noutperformed by new neural networks that are equivariant under rotations and\ntranslations. These new networks work better because they do not struggle with\nlearning each possible orientation of each image feature separately. So far,\nthey have been proposed for 2D and 3D data. Here we generalize them to 6D\ndiffusion MRI data, ensuring joint equivariance under 3D roto-translations in\nimage space and the matching 3D rotations in $q$-space, as dictated by the\nimage formation. Such equivariant deep learning is appropriate for diffusion\nMRI, because microstructural and macrostructural features such as neural fibers\ncan appear at many different orientations, and because even\nnon-rotation-equivariant deep learning has so far been the best method for many\ndiffusion MRI tasks. We validate our equivariant method on multiple-sclerosis\nlesion segmentation. Our proposed neural networks yield better results and\nrequire fewer scans for training compared to non-rotation-equivariant deep\nlearning. They also inherit all the advantages of deep learning over classical\ndiffusion MRI methods. Our implementation is available at\nhttps://github.com/philip-mueller/equivariant-deep-dmri and can be used off the\nshelf without understanding the mathematical background.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 15:18:34 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["M\u00fcller", "Philip", ""], ["Golkov", "Vladimir", ""], ["Tomassini", "Valentina", ""], ["Cremers", "Daniel", ""]]}, {"id": "2102.06960", "submitter": "Sudeep Pasricha", "authors": "Febin Sunny, Asif Mirza, Mahdi Nikdast, and Sudeep Pasricha", "title": "CrossLight: A Cross-Layer Optimized Silicon Photonic Neural Network\n  Accelerator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.ET cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Domain-specific neural network accelerators have seen growing interest in\nrecent years due to their improved energy efficiency and inference performance\ncompared to CPUs and GPUs. In this paper, we propose a novel cross-layer\noptimized neural network accelerator called CrossLight that leverages silicon\nphotonics. CrossLight includes device-level engineering for resilience to\nprocess variations and thermal crosstalk, circuit-level tuning enhancements for\ninference latency reduction, and architecture-level optimization to enable\nhigher resolution, better energy-efficiency, and improved throughput. On\naverage, CrossLight offers 9.5x lower energy-per-bit and 15.9x higher\nperformance-per-watt at 16-bit resolution than state-of-the-art photonic deep\nlearning accelerators.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 17:08:06 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Sunny", "Febin", ""], ["Mirza", "Asif", ""], ["Nikdast", "Mahdi", ""], ["Pasricha", "Sudeep", ""]]}, {"id": "2102.07227", "submitter": "Jeremy Bernstein", "authors": "Yang Liu, Jeremy Bernstein, Markus Meister, Yisong Yue", "title": "Learning by Turning: Neural Architecture Aware Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Descent methods for deep networks are notoriously capricious: they require\ncareful tuning of step size, momentum and weight decay, and which method will\nwork best on a new benchmark is a priori unclear. To address this problem, this\npaper conducts a combined study of neural architecture and optimisation,\nleading to a new optimiser called Nero: the neuronal rotator. Nero trains\nreliably without momentum or weight decay, works in situations where Adam and\nSGD fail, and requires little to no learning rate tuning. Also, Nero's memory\nfootprint is ~ square root that of Adam or LAMB. Nero combines two ideas: (1)\nprojected gradient descent over the space of balanced networks; (2)\nneuron-specific updates, where the step size sets the angle through which each\nneuron's hyperplane turns. The paper concludes by discussing how this geometric\nconnection between architecture and optimisation may impact theories of\ngeneralisation in deep learning.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 19:30:40 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Liu", "Yang", ""], ["Bernstein", "Jeremy", ""], ["Meister", "Markus", ""], ["Yue", "Yisong", ""]]}, {"id": "2102.07277", "submitter": "Radhabai Gopinathan Nair Gayathri", "authors": "R G Gayathri, Atul Sajjanhar, Yong Xiang and Xingjun Ma", "title": "Anomaly Detection for Scenario-based Insider Activities using CGAN\n  Augmented Data", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Insider threats are the cyber attacks from within the trusted entities of an\norganization. Lack of real-world data and issue of data imbalance leave insider\nthreat analysis an understudied research area. To mitigate the effect of skewed\nclass distribution and prove the potential of multinomial classification\nalgorithms for insider threat detection, we propose an approach that combines\ngenerative model with supervised learning to perform multi-class classification\nusing deep learning. The generative adversarial network (GAN) based insider\ndetection model introduces Conditional Generative Adversarial Network (CGAN) to\nenrich minority class samples to provide data for multi-class anomaly\ndetection. The comprehensive experiments performed on the benchmark dataset\ndemonstrates the effectiveness of introducing GAN derived synthetic data and\nthe capability of multi-class anomaly detection in insider activity analysis.\nMoreover, the method is compared with other existing methods against different\nparameters and performance metrics.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 00:08:39 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 05:06:16 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Gayathri", "R G", ""], ["Sajjanhar", "Atul", ""], ["Xiang", "Yong", ""], ["Ma", "Xingjun", ""]]}, {"id": "2102.07495", "submitter": "Youran Sun", "authors": "Naichen Shi and Ruichen Li and Sun Youran", "title": "ScrofaZero: Mastering Trick-taking Poker Game Gongzhu by Deep\n  Reinforcement Learning", "comments": "The very first versoin. Will be improved in the future", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  People have made remarkable progress in game AIs, especially in domain of\nperfect information game. However, trick-taking poker game, as a popular form\nof imperfect information game, has been regarded as a challenge for a long\ntime. Since trick-taking game requires high level of not only reasoning, but\nalso inference to excel, it can be a new milestone for imperfect information\ngame AI. We study Gongzhu, a trick-taking game analogous to, but slightly\nsimpler than contract bridge. Nonetheless, the strategies of Gongzhu are\ncomplex enough for both human and computer players. We train a strong Gongzhu\nAI ScrofaZero from \\textit{tabula rasa} by deep reinforcement learning, while\nfew previous efforts on solving trick-taking poker game utilize the\nrepresentation power of neural networks. Also, we introduce new techniques for\nimperfect information game including stratified sampling, importance weighting,\nintegral over equivalent class, Bayesian inference, etc. Our AI can achieve\nhuman expert level performance. The methodologies in building our program can\nbe easily transferred into a wide range of trick-taking games.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 12:01:44 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Shi", "Naichen", ""], ["Li", "Ruichen", ""], ["Youran", "Sun", ""]]}, {"id": "2102.07503", "submitter": "Gideon Kowadlo", "authors": "Gideon Kowadlo, Abdelrahman Ahmed, David Rawlinson", "title": "One-shot learning for the long term: consolidation with an artificial\n  hippocampal algorithm", "comments": "Accepted to 'The International Joint Conference on Neural Networks\n  (IJCNN) 2021' https://www.ijcnn.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Standard few-shot experiments involve learning to efficiently match\npreviously unseen samples by class. We claim that few-shot learning should be\nlong term, assimilating knowledge for the future, without forgetting previous\nconcepts. In the mammalian brain, the hippocampus is understood to play a\nsignificant role in this process, by learning rapidly and consolidating\nknowledge to the neocortex incrementally over a short period. In this research\nwe tested whether an artificial hippocampal algorithm (AHA), could be used with\na conventional Machine Learning (ML) model that learns incrementally analogous\nto the neocortex, to achieve one-shot learning both short and long term. The\nresults demonstrated that with the addition of AHA, the system could learn in\none-shot and consolidate the knowledge for the long term without catastrophic\nforgetting. This study is one of the first examples of using a CLS model of\nhippocampus to consolidate memories, and it constitutes a step toward few-shot\ncontinual learning.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 12:07:26 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 08:37:13 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Kowadlo", "Gideon", ""], ["Ahmed", "Abdelrahman", ""], ["Rawlinson", "David", ""]]}, {"id": "2102.07589", "submitter": "Nathalia Nascimento", "authors": "Nathalia Nascimento and Paulo Alencar and Donald Cowan and Carlos\n  Lucena", "title": "A Reference Model for IoT Embodied Agents Controlled by Neural Networks", "comments": "6 pages, Accepted to be published in IEEE Big Data Conference\n  Proceedings (IEEE Computer Society Press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embodied agents is a term used to denote intelligent agents, which are a\ncomponent of devices belonging to the Internet of Things (IoT) domain. Each\nagent is provided with sensors and actuators to interact with the environment,\nand with a 'controller' that usually contains an artificial neural network\n(ANN). In previous publications, we introduced three software approaches to\ndesign, implement and test IoT embodied agents. In this paper, we propose a\nreference model based on statecharts that offers abstractions tailored to the\ndevelopment of IoT applications. The model represents embodied agents that are\ncontrolled by neural networks. Our model includes the ANN training process,\nrepresented as a reconfiguration step such as changing agent features or neural\nnet connections. Our contributions include the identification of the main\ncharacteristics of IoT embodied agents, a reference model specification based\non statecharts, and an illustrative application of the model to support\nautonomous street lights. The proposal aims to support the design and\nimplementation of IoT applications by providing high-level design abstractions\nand models, thus enabling the designer to have a uniform approach to\nconceiving, designing and explaining such applications.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 15:02:44 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Nascimento", "Nathalia", ""], ["Alencar", "Paulo", ""], ["Cowan", "Donald", ""], ["Lucena", "Carlos", ""]]}, {"id": "2102.07764", "submitter": "Daniel Lenton", "authors": "Daniel Lenton, Stephen James, Ronald Clark, Andrew J. Davison", "title": "End-to-End Egospheric Spatial Memory", "comments": "Conference paper at ICLR 2021. Implementation:\n  https://github.com/ivy-dl/memory Project page: https://djl11.github.io/ESM/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spatial memory, or the ability to remember and recall specific locations and\nobjects, is central to autonomous agents' ability to carry out tasks in real\nenvironments. However, most existing artificial memory modules are not very\nadept at storing spatial information. We propose a parameter-free module,\nEgospheric Spatial Memory (ESM), which encodes the memory in an ego-sphere\naround the agent, enabling expressive 3D representations. ESM can be trained\nend-to-end via either imitation or reinforcement learning, and improves both\ntraining efficiency and final performance against other memory baselines on\nboth drone and manipulator visuomotor control tasks. The explicit egocentric\ngeometry also enables us to seamlessly combine the learned controller with\nother non-learned modalities, such as local obstacle avoidance. We further show\napplications to semantic segmentation on the ScanNet dataset, where ESM\nnaturally combines image-level and map-level inference modalities. Through our\nbroad set of experiments, we show that ESM provides a general computation graph\nfor embodied spatial reasoning, and the module forms a bridge between real-time\nmapping systems and differentiable memory architectures. Implementation at:\nhttps://github.com/ivy-dl/memory.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 18:59:07 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 18:56:39 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Lenton", "Daniel", ""], ["James", "Stephen", ""], ["Clark", "Ronald", ""], ["Davison", "Andrew J.", ""]]}, {"id": "2102.08211", "submitter": "Laura Kriener", "authors": "Laura Kriener, Julian G\\\"oltz, Mihai A. Petrovici", "title": "The Yin-Yang dataset", "comments": "3 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Yin-Yang dataset was developed for research on biologically plausible\nerror backpropagation and deep learning in spiking neural networks. It serves\nas an alternative to classic deep learning datasets, especially in algorithm-\nand model-prototyping scenarios, by providing several advantages. First, it is\nsmaller and therefore faster to learn, thereby being better suited for the\ndeployment on neuromorphic chips with limited network sizes. Second, it\nexhibits a very clear gap between the accuracies achievable using shallow as\ncompared to deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 15:18:05 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Kriener", "Laura", ""], ["G\u00f6ltz", "Julian", ""], ["Petrovici", "Mihai A.", ""]]}, {"id": "2102.08288", "submitter": "Jinjin Xu", "authors": "Jinjin Xu, Yaochu Jin, Wenli Du, Sai Gu", "title": "A Federated Data-Driven Evolutionary Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data-driven evolutionary optimization has witnessed great success in solving\ncomplex real-world optimization problems. However, existing data-driven\noptimization algorithms require that all data are centrally stored, which is\nnot always practical and may be vulnerable to privacy leakage and security\nthreats if the data must be collected from different devices. To address the\nabove issue, this paper proposes a federated data-driven evolutionary\noptimization framework that is able to perform data driven optimization when\nthe data is distributed on multiple devices. On the basis of federated\nlearning, a sorted model aggregation method is developed for aggregating local\nsurrogates based on radial-basis-function networks. In addition, a federated\nsurrogate management strategy is suggested by designing an acquisition function\nthat takes into account the information of both the global and local surrogate\nmodels. Empirical studies on a set of widely used benchmark functions in the\npresence of various data distributions demonstrate the effectiveness of the\nproposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 17:18:54 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Xu", "Jinjin", ""], ["Jin", "Yaochu", ""], ["Du", "Wenli", ""], ["Gu", "Sai", ""]]}, {"id": "2102.08361", "submitter": "Tarik A. Rashid", "authors": "Bryar A. Hassan, Tarik A. Rashid", "title": "A Multi-disciplinary Ensemble Algorithm for Clustering Heterogeneous\n  Datasets", "comments": "30 pages", "journal-ref": "Neural Computing and Applications, 2021", "doi": "10.1007/s00521-020-05649-1", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Clustering is a commonly used method for exploring and analysing data where\nthe primary objective is to categorise observations into similar clusters. In\nrecent decades, several algorithms and methods have been developed for\nanalysing clustered data. We notice that most of these techniques\ndeterministically define a cluster based on the value of the attributes,\ndistance, and density of homogenous and single-featured datasets. However,\nthese definitions are not successful in adding clear semantic meaning to the\nclusters produced. Evolutionary operators and statistical and\nmulti-disciplinary techniques may help in generating meaningful clusters. Based\non this premise, we propose a new evolutionary clustering algorithm (ECAStar)\nbased on social class ranking and meta-heuristic algorithms for stochastically\nanalysing heterogeneous and multiple-featured datasets. The ECAStar is\nintegrated with recombinational evolutionary operators, Levy flight\noptimisation, and some statistical techniques, such as quartiles and\npercentiles, as well as the Euclidean distance of the K-means algorithm.\nExperiments are conducted to evaluate the ECAStar against five conventional\napproaches: K-means (KM), K-meansPlusPlus (KMPlusPlus), expectation\nmaximisation (EM), learning vector quantisation (LVQ), and the genetic\nalgorithm for clusteringPlusPlus (GENCLUSTPlusPlus).\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2021 07:20:50 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Hassan", "Bryar A.", ""], ["Rashid", "Tarik A.", ""]]}, {"id": "2102.08417", "submitter": "Thorben Schoepe", "authors": "Thorben Schoepe, Ella Janotte, Moritz B. Milde, Olivier J.N. Bertrand,\n  Martin Egelhaaf and Elisabetta Chicca", "title": "Finding the Gap: Neuromorphic Motion Vision in Cluttered Environments", "comments": "7 main pages with two figures, including appendix 26 pages with 14\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many animals meander in environments and avoid collisions. How the underlying\nneuronal machinery can yield robust behaviour in a variety of environments\nremains unclear. In the fly brain, motion-sensitive neurons indicate the\npresence of nearby objects and directional cues are integrated within an area\nknown as the central complex. Such neuronal machinery, in contrast with the\ntraditional stream-based approach to signal processing, uses an event-based\napproach, with events occurring when changes are sensed by the animal. Contrary\nto von Neumann computing architectures, event-based neuromorphic hardware is\ndesigned to process information in an asynchronous and distributed manner.\nInspired by the fly brain, we model, for the first time, a neuromorphic\nclosed-loop system mimicking essential behaviours observed in flying insects,\nsuch as meandering in clutter and gap crossing, which are highly relevant for\nautonomous vehicles. We implemented our system both in software and on\nneuromorphic hardware. While moving through an environment, our agent perceives\nchanges in its surroundings and uses this information for collision avoidance.\nThe agent's manoeuvres result from a closed action-perception loop implementing\nprobabilistic decision-making processes. This loop-closure is thought to have\ndriven the development of neural circuitry in biological agents since the\nCambrian explosion. In the fundamental quest to understand neural computation\nin artificial agents, we come closer to understanding and modelling biological\nintelligence by closing the loop also in neuromorphic systems. As a closed-loop\nsystem, our system deepens our understanding of processing in neural networks\nand computations in biological and artificial systems. With these\ninvestigations, we aim to set the foundations for neuromorphic intelligence in\nthe future, moving towards leveraging the full potential of neuromorphic\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 19:19:23 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Schoepe", "Thorben", ""], ["Janotte", "Ella", ""], ["Milde", "Moritz B.", ""], ["Bertrand", "Olivier J. N.", ""], ["Egelhaaf", "Martin", ""], ["Chicca", "Elisabetta", ""]]}, {"id": "2102.08475", "submitter": "Edgar Galvan", "authors": "Edgar Galv\\'an", "title": "Neuroevolution in Deep Learning: The Role of Neutrality", "comments": "9 pages, 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:2006.05415", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of methods have been applied to the architectural configuration and\nlearning or training of artificial deep neural networks (DNN). These methods\nplay a crucial role in the success or failure of the DNN for most problems and\napplications. Evolutionary Algorithms (EAs) are gaining momentum as a\ncomputationally feasible method for the automated optimisation of DNNs.\nNeuroevolution is a term which describes these processes of automated\nconfiguration and training of DNNs using EAs. However, the automatic design\nand/or training of these modern neural networks through evolutionary algorithms\nis computanalli expensive. Kimura's neutral theory of molecular evolution\nstates that the majority of evolutionary changes at molecular level are the\nresult of random fixation of selectively neutral mutations. A mutation from one\ngene to another is neutral if it does not affect the phenotype. This work\ndiscusses how neutrality, given certain conditions, can help to speed up the\ntraining/design of deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 22:29:59 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Galv\u00e1n", "Edgar", ""]]}, {"id": "2102.08578", "submitter": "Santiago Gonzalez", "authors": "Santiago Gonzalez and Mohak Kant and Risto Miikkulainen", "title": "Evolving GAN Formulations for Higher Quality Image Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have extended deep learning to complex\ngeneration and translation tasks across different data modalities. However,\nGANs are notoriously difficult to train: Mode collapse and other instabilities\nin the training process often degrade the quality of the generated results,\nsuch as images. This paper presents a new technique called TaylorGAN for\nimproving GANs by discovering customized loss functions for each of its two\nnetworks. The loss functions are parameterized as Taylor expansions and\noptimized through multiobjective evolution. On an image-to-image translation\nbenchmark task, this approach qualitatively improves generated image quality\nand quantitatively improves two independent GAN performance metrics. It\ntherefore forms a promising approach for applying GANs to more challenging\ntasks in the future.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 05:11:21 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Gonzalez", "Santiago", ""], ["Kant", "Mohak", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "2102.08634", "submitter": "Javier Del Ser Dr.", "authors": "Alejandro Barredo Arrieta, Sergio Gil-Lopez, Ibai La\\~na, Miren Nekane\n  Bilbao, Javier Del Ser", "title": "On the Post-hoc Explainability of Deep Echo State Networks for Time\n  Series Forecasting, Image and Video Classification", "comments": "22 pages, 9 figures, 3 tables. Currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since their inception, learning techniques under the Reservoir Computing\nparadigm have shown a great modeling capability for recurrent systems without\nthe computing overheads required for other approaches. Among them, different\nflavors of echo state networks have attracted many stares through time, mainly\ndue to the simplicity and computational efficiency of their learning algorithm.\nHowever, these advantages do not compensate for the fact that echo state\nnetworks remain as black-box models whose decisions cannot be easily explained\nto the general audience. This work addresses this issue by conducting an\nexplainability study of Echo State Networks when applied to learning tasks with\ntime series, image and video data. Specifically, the study proposes three\ndifferent techniques capable of eliciting understandable information about the\nknowledge grasped by these recurrent models, namely, potential memory, temporal\npatterns and pixel absence effect. Potential memory addresses questions related\nto the effect of the reservoir size in the capability of the model to store\ntemporal information, whereas temporal patterns unveils the recurrent\nrelationships captured by the model over time. Finally, pixel absence effect\nattempts at evaluating the effect of the absence of a given pixel when the echo\nstate network model is used for image and video classification. We showcase the\nbenefits of our proposed suite of techniques over three different domains of\napplicability: time series modeling, image and, for the first time in the\nrelated literature, video classification. Our results reveal that the proposed\ntechniques not only allow for a informed understanding of the way these models\nwork, but also serve as diagnostic tools capable of detecting issues inherited\nfrom data (e.g. presence of hidden bias).\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 08:56:33 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Arrieta", "Alejandro Barredo", ""], ["Gil-Lopez", "Sergio", ""], ["La\u00f1a", "Ibai", ""], ["Bilbao", "Miren Nekane", ""], ["Del Ser", "Javier", ""]]}, {"id": "2102.08792", "submitter": "Thijs van de Laar PhD", "authors": "Thijs van de Laar, Ismail Senoz, Ay\\c{c}a \\\"Oz\\c{c}elikkale, Henk\n  Wymeersch", "title": "Chance-Constrained Active Inference", "comments": null, "journal-ref": null, "doi": "10.1162/neco_a_01427", "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active Inference (ActInf) is an emerging theory that explains perception and\naction in biological agents, in terms of minimizing a free energy bound on\nBayesian surprise. Goal-directed behavior is elicited by introducing prior\nbeliefs on the underlying generative model. In contrast to prior beliefs, which\nconstrain all realizations of a random variable, we propose an alternative\napproach through chance constraints, which allow for a (typically small)\nprobability of constraint violation, and demonstrate how such constraints can\nbe used as intrinsic drivers for goal-directed behavior in ActInf. We\nillustrate how chance-constrained ActInf weights all imposed (prior)\nconstraints on the generative model, allowing e.g., for a trade-off between\nrobust control and empirical chance constraint violation. Secondly, we\ninterpret the proposed solution within a message passing framework.\nInterestingly, the message passing interpretation is not only relevant to the\ncontext of ActInf, but also provides a general purpose approach that can\naccount for chance constraints on graphical models. The chance constraint\nmessage updates can then be readily combined with other pre-derived message\nupdate rules, without the need for custom derivations. The proposed\nchance-constrained message passing framework thus accelerates the search for\nworkable models in general, and can be used to complement message-passing\nformulations on generative neural models.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 14:36:40 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 13:18:26 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["van de Laar", "Thijs", ""], ["Senoz", "Ismail", ""], ["\u00d6z\u00e7elikkale", "Ay\u00e7a", ""], ["Wymeersch", "Henk", ""]]}, {"id": "2102.08849", "submitter": "Nicola Milano", "authors": "Nicola Milano and Stefano Nolfi", "title": "Automated Curriculum Learning for Embodied Agents: A Neuroevolutionary\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We demonstrate how an evolutionary algorithm can be extended with a\ncurriculum learning process that selects automatically the environmental\nconditions in which the evolving agents are evaluated. The environmental\nconditions are selected so to adjust the level of difficulty to the ability\nlevel of the current evolving agents and so to challenge the weaknesses of the\nevolving agents. The method does not require domain knowledge and does not\nintroduce additional hyperparameters. The results collected on two benchmark\nproblems, that require to solve a task in significantly varying environmental\nconditions, demonstrate that the method proposed outperforms conventional\nalgorithms and generates solutions that are robust to variations\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 16:19:17 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Milano", "Nicola", ""], ["Nolfi", "Stefano", ""]]}, {"id": "2102.08893", "submitter": "Maha Mohammed Khan", "authors": "Maha Mohammed Khan", "title": "An Implementation of Vector Quantization using the Genetic Algorithm\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The application of machine learning(ML) and genetic programming(GP) to the\nimage compression domain has produced promising results in many cases. The need\nfor compression arises due to the exorbitant size of data shared on the\ninternet. Compression is required for text, videos, or images, which are used\nalmost everywhere on web be it news articles, social media posts, blogs,\neducational platforms, medical domain, government services, and many other\nwebsites, need packets for transmission and hence compression is necessary to\navoid overwhelming the network. This paper discusses some of the\nimplementations of image compression algorithms that use techniques such as\nArtificial Neural Networks, Residual Learning, Fuzzy Neural Networks,\nConvolutional Neural Nets, Deep Learning, Genetic Algorithms. The paper also\ndescribes an implementation of Vector Quantization using GA to generate\ncodebook which is used for Lossy image compression. All these approaches prove\nto be very contrasting to the standard approaches to processing images due to\nthe highly parallel and computationally extensive nature of machine learning\nalgorithms. Such non-linear abilities of ML and GP make it widely popular for\nuse in multiple domains. Traditional approaches are also combined with\nartificially intelligent systems, leading to hybrid systems, to achieve better\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 03:57:13 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Khan", "Maha Mohammed", ""]]}, {"id": "2102.08928", "submitter": "Amir Mosavi Prof", "authors": "Hossein Moayedi, Amir Mosavi", "title": "Synthesizing multi-layer perceptron network with ant lion,\n  biogeography-based dragonfly algorithm evolutionary strategy invasive weed\n  and league champion optimization hybrid algorithms in predicting heating load\n  in residential buildings", "comments": "24 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The significance of heating load (HL) accurate approximation is the primary\nmotivation of this research to distinguish the most efficient predictive model\namong several neural-metaheuristic models. The proposed models are through\nsynthesizing multi-layer perceptron network (MLP) with ant lion optimization\n(ALO), biogeography-based optimization (BBO), dragonfly algorithm (DA),\nevolutionary strategy (ES), invasive weed optimization (IWO), and league\nchampion optimization (LCA) hybrid algorithms. Each ensemble is optimized in\nterms of the operating population. Accordingly, the ALO-MLP, BBO-MLP, DA-MLP,\nES-MLP, IWO-MLP, and LCA-MLP presented their best performance for population\nsizes of 350, 400, 200, 500, 50, and 300, respectively. The comparison was\ncarried out by implementing a ranking system. Based on the obtained overall\nscores (OSs), the BBO (OS = 36) featured as the most capable optimization\ntechnique, followed by ALO (OS = 27) and ES (OS = 20). Due to the efficient\nperformance of these algorithms, the corresponding MLPs can be promising\nsubstitutes for traditional methods used for HL analysis.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 14:06:55 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Moayedi", "Hossein", ""], ["Mosavi", "Amir", ""]]}, {"id": "2102.08929", "submitter": "Jamal Toutouh", "authors": "Jamal Toutouh and Una-May O'Reilly", "title": "Signal Propagation in a Gradient-Based and Evolutionary Learning System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) exhibit training pathologies that can\nlead to convergence-related degenerative behaviors, whereas\nspatially-distributed, coevolutionary algorithms (CEAs) for GAN training, e.g.\nLipizzaner, are empirically robust to them. The robustness arises from\ndiversity that occurs by training populations of generators and discriminators\nin each cell of a toroidal grid. Communication, where signals in the form of\nparameters of the best GAN in a cell propagate in four directions: North,\nSouth, West, and East, also plays a role, by communicating adaptations that are\nboth new and fit. We propose Lipi-Ring, a distributed CEA like Lipizzaner,\nexcept that it uses a different spatial topology, i.e. a ring. Our central\nquestion is whether the different directionality of signal propagation\n(effectively migration to one or more neighbors on each side of a cell) meets\nor exceeds the performance quality and training efficiency of Lipizzaner\nExperimental analysis on different datasets (i.e, MNIST, CelebA, and COVID-19\nchest X-ray images) shows that there are no significant differences between the\nperformances of the trained generative models by both methods. However,\nLipi-Ring significantly reduces the computational time (14.2%. . . 41.2%).\nThus, Lipi-Ring offers an alternative to Lipizzaner when the computational cost\nof training matters.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 16:46:44 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Toutouh", "Jamal", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "2102.08930", "submitter": "Randall Clark", "authors": "Jason A. Platt, Adrian Wong, Randall Clark, Stephen G. Penny, and\n  Henry D. I. Abarbanel", "title": "Forecasting Using Reservoir Computing: The Role of Generalized\n  Synchronization", "comments": "This is the Shortened Version of the Paper, the longer paper, Robust\n  Forecasting through Generalized Synchronization in Reservoir Computing, can\n  be found at arXiv:2103.00362", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computers (RC) are a form of recurrent neural network (RNN) used\nfor forecasting time series data. As with all RNNs, selecting the\nhyperparameters presents a challenge when training on new inputs. We present a\nmethod based on generalized synchronization (GS) that gives direction in\ndesigning and evaluating the architecture and hyperparameters of a RC. The\n'auxiliary method' for detecting GS provides a pre-training test that guides\nhyperparameter selection. Furthermore, we provide a metric for a \"well trained\"\nRC using the reproduction of the input system's Lyapunov exponents.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 02:45:06 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 00:50:01 GMT"}, {"version": "v3", "created": "Wed, 14 Apr 2021 23:46:16 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Platt", "Jason A.", ""], ["Wong", "Adrian", ""], ["Clark", "Randall", ""], ["Penny", "Stephen G.", ""], ["Abarbanel", "Henry D. I.", ""]]}, {"id": "2102.09544", "submitter": "Christopher Morris", "authors": "Quentin Cappart, Didier Ch\\'etelat, Elias Khalil, Andrea Lodi,\n  Christopher Morris, Petar Veli\\v{c}kovi\\'c", "title": "Combinatorial optimization and reasoning with graph neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial optimization is a well-established area in operations research\nand computer science. Until recently, its methods have focused on solving\nproblem instances in isolation, ignoring the fact that they often stem from\nrelated data distributions in practice. However, recent years have seen a surge\nof interest in using machine learning, especially graph neural networks (GNNs),\nas a key building block for combinatorial tasks, either directly as solvers or\nby enhancing exact solvers. The inductive bias of GNNs effectively encodes\ncombinatorial and relational input due to their invariance to permutations and\nawareness of input sparsity. This paper presents a conceptual review of recent\nkey advancements in this emerging field, aiming at researchers in both\noptimization and machine learning.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 18:47:20 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 23:47:38 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Cappart", "Quentin", ""], ["Ch\u00e9telat", "Didier", ""], ["Khalil", "Elias", ""], ["Lodi", "Andrea", ""], ["Morris", "Christopher", ""], ["Veli\u010dkovi\u0107", "Petar", ""]]}, {"id": "2102.09634", "submitter": "Lifeth \\'Alvarez", "authors": "Alvarez Lifeth", "title": "Modeling epigenetic evolutionary algorithms: An approach based on the\n  epigenetic regulation process", "comments": "Master in Computer Systems Engineering. Universidad Nacional de\n  Colombia. Thesis, 132 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.PE stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many biological processes have been the source of inspiration for heuristic\nmethods that generate high-quality solutions to solve optimization and search\nproblems. This thesis presents an epigenetic technique for Evolutionary\nAlgorithms, inspired by the epigenetic regulation process, a mechanism to\nbetter understand the ability of individuals to adapt and learn from the\nenvironment. Epigenetic regulation comprises biological mechanisms by which\nsmall molecules, also known as epigenetic tags, are attached to or removed from\na particular gene, affecting the phenotype. Five fundamental elements form the\nbasis of the designed technique: first, a metaphorical representation of\nEpigenetic Tags as binary strings; second, a layer on chromosome top structure\nused to bind the tags (the Epigenotype layer); third, a Marking Function to\nadd, remove, and modify tags; fourth, an Epigenetic Growing Function that acts\nlike an interpreter, or decoder of the tags located over the alleles, in such a\nway that the phenotypic variations can be reflected when evaluating the\nindividuals; and fifth, a tags inheritance mechanism. A set of experiments are\nperformed for determining the applicability of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 21:51:50 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Lifeth", "Alvarez", ""]]}, {"id": "2102.09677", "submitter": "C.-H. Huck Yang", "authors": "Chao-Han Huck Yang, I-Te Danny Hung, Yi Ouyang, Pin-Yu Chen", "title": "Causal Inference Q-Network: Toward Resilient Reinforcement Learning", "comments": "Preprint. Under Review. A Non-archival and preliminary venue was\n  presented in ICLR 2021 Self-supervision for Reinforcement Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Deep reinforcement learning (DRL) has demonstrated impressive performance in\nvarious gaming simulators and real-world applications. In practice, however, a\nDRL agent may receive faulty observation by abrupt interferences such as\nblack-out, frozen-screen, and adversarial perturbation. How to design a\nresilient DRL algorithm against these rare but mission-critical and\nsafety-crucial scenarios is an important yet challenging task. In this paper,\nwe consider a generative DRL framework training with an auxiliary task of\nobservational interferences such as artificial noises. Under this framework, we\ndiscuss the importance of the causal relation and propose a causal inference\nbased DRL algorithm called causal inference Q-network (CIQ). We evaluate the\nperformance of CIQ in several benchmark DRL environments with different types\nof interferences as auxiliary labels. Our experimental results show that the\nproposed CIQ method could achieve higher performance and more resilience\nagainst observational interferences.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 23:50:20 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 22:22:53 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Yang", "Chao-Han Huck", ""], ["Hung", "I-Te Danny", ""], ["Ouyang", "Yi", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "2102.09798", "submitter": "Tillmann Miltzow", "authors": "Mikkel Abrahamsen, Linda Kleist, Tillmann Miltzow", "title": "Training Neural Networks is ER-complete", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.DS cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a neural network, training data, and a threshold, it was known that it\nis NP-hard to find weights for the neural network such that the total error is\nbelow the threshold. We determine the algorithmic complexity of this\nfundamental problem precisely, by showing that it is ER-complete. This means\nthat the problem is equivalent, up to polynomial-time reductions, to deciding\nwhether a system of polynomial equations and inequalities with integer\ncoefficients and real unknowns has a solution. If, as widely expected, ER is\nstrictly larger than NP, our work implies that the problem of training neural\nnetworks is not even in NP.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 08:28:37 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Abrahamsen", "Mikkel", ""], ["Kleist", "Linda", ""], ["Miltzow", "Tillmann", ""]]}, {"id": "2102.09954", "submitter": "Thanh Pham Dinh", "authors": "Huynh Thi Thanh Binh, Ta Bao Thang, Nguyen Duc Thai, Pham Dinh Thanh", "title": "A bi-level encoding scheme for the clustered shortest-path tree problem\n  in multifactorial optimization", "comments": "36 pages, 13 figures, 13 tables", "journal-ref": null, "doi": "10.1016/j.engappai.2021.104187", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Clustered Shortest-Path Tree Problem (CluSPT) plays an important role in\nvarious types of optimization problems in real-life. Recently, some\nMultifactorial Evolutionary Algorithm (MFEA) have been introduced to deal with\nthe CluSPT, however these researches still have some shortcomings such as\nevolution operators only perform on complete graphs, huge resource consumption\nfor finding the solution on large search spaces. To overcome these limitations,\nthis paper describes a MFEA-based approach to solve the CluSPT. The proposed\nalgorithm utilizes Dijkstra's algorithm to construct the spanning trees in\nclusters while using evolutionary operators for building the spanning tree\nconnecting clusters. This approach takes advantage of both exact and\napproximate algorithms so it enables the algorithm to function efficiently on\ncomplete and sparse graphs alike. Furthermore, evolutionary operators such as\nindividual encoding and decoding methods are also designed with great\nconsideration regarding performance and memory usage. We have included a proof\non the repairing method's efficacy in ensuring all solutions are valid. We have\nconducted tests on various types of Euclidean instances to assess the\neffectiveness of the proposed algorithm and methods. Experiment results point\nout the effectiveness of the proposed algorithm existing heuristic algorithms\nin most of the test cases. The impact of the proposed MFEA was analyzed and a\npossible influential factor that may be useful for further study was also\npointed out.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 13:36:07 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Binh", "Huynh Thi Thanh", ""], ["Thang", "Ta Bao", ""], ["Thai", "Nguyen Duc", ""], ["Thanh", "Pham Dinh", ""]]}, {"id": "2102.09972", "submitter": "Noam Razin", "authors": "Noam Razin, Asaf Maman, Nadav Cohen", "title": "Implicit Regularization in Tensor Factorization", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts to unravel the mystery of implicit regularization in deep\nlearning have led to a theoretical focus on matrix factorization -- matrix\ncompletion via linear neural network. As a step further towards practical deep\nlearning, we provide the first theoretical analysis of implicit regularization\nin tensor factorization -- tensor completion via certain type of non-linear\nneural network. We circumvent the notorious difficulty of tensor problems by\nadopting a dynamical systems perspective, and characterizing the evolution\ninduced by gradient descent. The characterization suggests a form of greedy low\ntensor rank search, which we rigorously prove under certain conditions, and\nempirically demonstrate under others. Motivated by tensor rank capturing the\nimplicit regularization of a non-linear neural network, we empirically explore\nit as a measure of complexity, and find that it captures the essence of\ndatasets on which neural networks generalize. This leads us to believe that\ntensor rank may pave way to explaining both implicit regularization in deep\nlearning, and the properties of real-world data translating this implicit\nregularization to generalization.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 15:10:26 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 20:21:46 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 17:16:17 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Razin", "Noam", ""], ["Maman", "Asaf", ""], ["Cohen", "Nadav", ""]]}, {"id": "2102.10021", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge, Alexander Tschantz, Anil Seth, Christopher Buckley", "title": "Neural Kalman Filtering", "comments": "17-02-21 initial upload; 29-04-21 minor fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Kalman filter is a fundamental filtering algorithm that fuses noisy\nsensory data, a previous state estimate, and a dynamics model to produce a\nprincipled estimate of the current state. It assumes, and is optimal for,\nlinear models and white Gaussian noise. Due to its relative simplicity and\ngeneral effectiveness, the Kalman filter is widely used in engineering\napplications. Since many sensory problems the brain faces are, at their core,\nfiltering problems, it is possible that the brain possesses neural circuitry\nthat implements equivalent computations to the Kalman filter. The standard\napproach to Kalman filtering requires complex matrix computations that are\nunlikely to be directly implementable in neural circuits. In this paper, we\nshow that a gradient-descent approximation to the Kalman filter requires only\nlocal computations with variance weighted prediction errors. Moreover, we show\nthat it is possible under the same scheme to adaptively learn the dynamics\nmodel with a learning rule that corresponds directly to Hebbian plasticity. We\ndemonstrate the performance of our method on a simple Kalman filtering task,\nand propose a neural implementation of the required equations.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 16:43:15 GMT"}, {"version": "v2", "created": "Thu, 29 Apr 2021 11:30:37 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Millidge", "Beren", ""], ["Tschantz", "Alexander", ""], ["Seth", "Anil", ""], ["Buckley", "Christopher", ""]]}, {"id": "2102.10148", "submitter": "Roman Vershynin", "authors": "Pierre Baldi, Roman Vershynin", "title": "A theory of capacity and sparse neural encoding", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motivated by biological considerations, we study sparse neural maps from an\ninput layer to a target layer with sparse activity, and specifically the\nproblem of storing $K$ input-target associations $(x,y)$, or memories, when the\ntarget vectors $y$ are sparse. We mathematically prove that $K$ undergoes a\nphase transition and that in general, and somewhat paradoxically, sparsity in\nthe target layers increases the storage capacity of the map. The target vectors\ncan be chosen arbitrarily, including in random fashion, and the memories can be\nboth encoded and decoded by networks trained using local learning rules,\nincluding the simple Hebb rule. These results are robust under a variety of\nstatistical assumptions on the data. The proofs rely on elegant properties of\nrandom polytopes and sub-gaussian random vector variables. Open problems and\nconnections to capacity theories and polynomial threshold maps are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 20:24:50 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Baldi", "Pierre", ""], ["Vershynin", "Roman", ""]]}, {"id": "2102.10435", "submitter": "Shayan Hassantabar", "authors": "Shayan Hassantabar, Joe Zhang, Hongxu Yin, and Niraj K. Jha", "title": "MHDeep: Mental Health Disorder Detection System based on Body-Area and\n  Deep Neural Networks", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mental health problems impact quality of life of millions of people around\nthe world. However, diagnosis of mental health disorders is a challenging\nproblem that often relies on self-reporting by patients about their behavioral\npatterns. Therefore, there is a need for new strategies for diagnosis of mental\nhealth problems. The recent introduction of body-area networks consisting of a\nplethora of accurate sensors embedded in smartwatches and smartphones and deep\nneural networks (DNNs) points towards a possible solution. However, disease\ndiagnosis based on WMSs and DNNs, and their deployment on edge devices, remains\na challenging problem. To this end, we propose a framework called MHDeep that\nutilizes commercially available WMSs and efficient DNN models to diagnose three\nimportant mental health disorders: schizoaffective, major depressive, and\nbipolar. MHDeep uses eight different categories of data obtained from sensors\nintegrated in a smartwatch and smartphone. Due to limited available data,\nMHDeep uses a synthetic data generation module to augment real data with\nsynthetic data drawn from the same probability distribution. We use the\nsynthetic dataset to pre-train the DNN models, thus imposing a prior on the\nweights. We use a grow-and-prune DNN synthesis approach to learn both the\narchitecture and weights during the training process. We use three different\ndata partitions to evaluate the MHDeep models trained with data collected from\n74 individuals. We conduct data instance level and patient level evaluations.\nMHDeep achieves an average test accuracy of 90.4%, 87.3%, and 82.4%,\nrespectively, for classifications between healthy instances and schizoaffective\ndisorder instances, major depressive disorder instances, and bipolar disorder\ninstances. At the patient level, MHDeep DNNs achieve an accuracy of 100%, 100%,\nand 90.0% for the three mental health disorders, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 20:17:07 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Hassantabar", "Shayan", ""], ["Zhang", "Joe", ""], ["Yin", "Hongxu", ""], ["Jha", "Niraj K.", ""]]}, {"id": "2102.10475", "submitter": "Patrik Christen", "authors": "Sebastian Fix, Thomas Probst, Oliver Ruggli, Thomas Hanne, and Patrik\n  Christen", "title": "Open-Ended Automatic Programming Through Combinatorial Evolution", "comments": "6 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It has been already shown that combinatorial evolution - the creation of new\nthings through the combination of existing things - can be a powerful way to\nevolve rather than design technical objects such as electronic circuits in a\ncomputer simulation. Most intriguingly, this seems to be an ongoing and thus\nopen-ended process to create novelty with increasing complexity. In the present\npaper, we want to employ combinatorial evolution in software development. While\ncurrent approaches such as genetic programming are efficient in solving\nparticular problems, they all converge towards a solution and do not create\nanything new anymore afterwards. Combinatorial evolution of complex systems\nsuch as languages and technology are considered open-ended. Therefore,\nopen-ended automatic programming might be possible through combinatorial\nevolution. Here, we implemented a computer program simulating combinatorial\nevolution of code blocks stored in a database to make them available for\ncombining. Automatic programming is achieved by evaluating regular expressions.\nWe found that reserved key words of a programming language are suitable for\ndefining the basic code blocks at the beginning of the simulation. We also\nfound that placeholders can be used to combine code blocks and that code\ncomplexity can be described in terms of the importance to the programming\nlanguage. As in the previous combinatorial evolution simulation of electronic\ncircuits, complexity increased from simple keywords and special characters to\nmore complex variable declarations, to class definitions, to methods, and to\nclasses containing methods and variable declarations. Combinatorial evolution,\ntherefore, seems to be a promising approach for open-ended automatic\nprogramming.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 23:40:27 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 14:52:06 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Fix", "Sebastian", ""], ["Probst", "Thomas", ""], ["Ruggli", "Oliver", ""], ["Hanne", "Thomas", ""], ["Christen", "Patrik", ""]]}, {"id": "2102.10477", "submitter": "Sourav Dutta", "authors": "Sourav Dutta, Georgios Detorakis, Abhishek Khanna, Benjamin Grisafe,\n  Emre Neftci and Suman Datta", "title": "Neural Sampling Machine with Stochastic Synapse allows Brain-like\n  Learning and Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cond-mat.mes-hall cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many real-world mission-critical applications require continual online\nlearning from noisy data and real-time decision making with a defined\nconfidence level. Probabilistic models and stochastic neural networks can\nexplicitly handle uncertainty in data and allow adaptive learning-on-the-fly,\nbut their implementation in a low-power substrate remains a challenge. Here, we\nintroduce a novel hardware fabric that implements a new class of stochastic NN\ncalled Neural-Sampling-Machine that exploits stochasticity in synaptic\nconnections for approximate Bayesian inference. Harnessing the inherent\nnon-linearities and stochasticity occurring at the atomic level in emerging\nmaterials and devices allows us to capture the synaptic stochasticity occurring\nat the molecular level in biological synapses. We experimentally demonstrate\nin-silico hybrid stochastic synapse by pairing a ferroelectric field-effect\ntransistor -based analog weight cell with a two-terminal stochastic selector\nelement. Such a stochastic synapse can be integrated within the\nwell-established crossbar array architecture for compute-in-memory. We\nexperimentally show that the inherent stochastic switching of the selector\nelement between the insulator and metallic state introduces a multiplicative\nstochastic noise within the synapses of NSM that samples the conductance states\nof the FeFET, both during learning and inference. We perform network-level\nsimulations to highlight the salient automatic weight normalization feature\nintroduced by the stochastic synapses of the NSM that paves the way for\ncontinual online learning without any offline Batch Normalization. We also\nshowcase the Bayesian inferencing capability introduced by the stochastic\nsynapse during inference mode, thus accounting for uncertainty in data. We\nreport 98.25%accuracy on standard image classification task as well as\nestimation of data uncertainty in rotated samples.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 23:45:24 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Dutta", "Sourav", ""], ["Detorakis", "Georgios", ""], ["Khanna", "Abhishek", ""], ["Grisafe", "Benjamin", ""], ["Neftci", "Emre", ""], ["Datta", "Suman", ""]]}, {"id": "2102.10530", "submitter": "Kotaro Furuya", "authors": "Kotaro Furuya and Jun Ohkubo", "title": "Semi-supervised learning combining backpropagation and STDP: STDP\n  enhances learning by backpropagation with a small amount of labeled data in a\n  spiking neural network", "comments": "9 pages, 12 figures", "journal-ref": "J. Phys. Soc. Jpn. 90, 074802 (2021)", "doi": "10.7566/JPSJ.90.074802", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A semi-supervised learning method for spiking neural networks is proposed.\nThe proposed method consists of supervised learning by backpropagation and\nsubsequent unsupervised learning by spike-timing-dependent plasticity (STDP),\nwhich is a biologically plausible learning rule. Numerical experiments show\nthat the proposed method improves the accuracy without additional labeling when\na small amount of labeled data is used. This feature has not been achieved by\nexisting semi-supervised learning methods of discriminative models. It is\npossible to implement the proposed learning method for event-driven systems.\nHence, it would be highly efficient in real-time problems if it were\nimplemented on neuromorphic hardware. The results suggest that STDP plays an\nimportant role other than self-organization when applied after supervised\nlearning, which differs from the previous method of using STDP as pre-training\ninterpreted as self-organization.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 06:55:02 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 09:54:50 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Furuya", "Kotaro", ""], ["Ohkubo", "Jun", ""]]}, {"id": "2102.10550", "submitter": "Zhenyu Han", "authors": "Zhenyu Han, Fengli Xu, Jinghan Shi, Yu Shang, Haorui Ma, Pan Hui, Yong\n  Li", "title": "Genetic Meta-Structure Search for Recommendation on Heterogeneous\n  Information Network", "comments": "Published in Proceedings of the 29th ACM International Conference on\n  Information and Knowledge Management (CIKM '20)", "journal-ref": null, "doi": "10.1145/3340531.3412015", "report-no": null, "categories": "cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, the heterogeneous information network (HIN) has become an\nimportant methodology for modern recommender systems. To fully leverage its\npower, manually designed network templates, i.e., meta-structures, are\nintroduced to filter out semantic-aware information. The hand-crafted\nmeta-structure rely on intense expert knowledge, which is both laborious and\ndata-dependent. On the other hand, the number of meta-structures grows\nexponentially with its size and the number of node types, which prohibits\nbrute-force search. To address these challenges, we propose Genetic\nMeta-Structure Search (GEMS) to automatically optimize meta-structure designs\nfor recommendation on HINs. Specifically, GEMS adopts a parallel genetic\nalgorithm to search meaningful meta-structures for recommendation, and designs\ndedicated rules and a meta-structure predictor to efficiently explore the\nsearch space. Finally, we propose an attention based multi-view graph\nconvolutional network module to dynamically fuse information from different\nmeta-structures. Extensive experiments on three real-world datasets suggest the\neffectiveness of GEMS, which consistently outperforms all baseline methods in\nHIN recommendation. Compared with simplified GEMS which utilizes hand-crafted\nmeta-paths, GEMS achieves over $6\\%$ performance gain on most evaluation\nmetrics. More importantly, we conduct an in-depth analysis on the identified\nmeta-structures, which sheds light on the HIN based recommender system design.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 08:29:41 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Han", "Zhenyu", ""], ["Xu", "Fengli", ""], ["Shi", "Jinghan", ""], ["Shang", "Yu", ""], ["Ma", "Haorui", ""], ["Hui", "Pan", ""], ["Li", "Yong", ""]]}, {"id": "2102.10592", "submitter": "Naoya Muramatsu", "authors": "Naoya Muramatsu and Hai-Tao Yu", "title": "Combining Spiking Neural Network and Artificial Neural Network for\n  Enhanced Image Classification", "comments": "This paper written for DEIM 2021 (https://db-event.jpn.org/deim2021/)\n  has 12 pages, 6 figures and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the continued innovations of deep neural networks, spiking neural\nnetworks (SNNs) that more closely resemble biological brain synapses have\nattracted attention owing to their low power consumption.However, for\ncontinuous data values, they must employ a coding process to convert the values\nto spike trains.Thus, they have not yet exceeded the performance of artificial\nneural networks (ANNs), which handle such values directly.To this end, we\ncombine an ANN and an SNN to build versatile hybrid neural networks (HNNs) that\nimprove the concerned performance.To qualify this performance, MNIST and\nCIFAR-10 image datasets are used for various classification tasks in which the\ntraining and coding methods changes.In addition, we present simultaneous and\nseparate methods to train the artificial and spiking layers, considering the\ncoding methods of each.We find that increasing the number of artificial layers\nat the expense of spiking layers improves the HNN performance.For\nstraightforward datasets such as MNIST, it is easy to achieve the same\nperformance as ANNs by using duplicate coding and separate learning.However,\nfor more complex tasks, the use of Gaussian coding and simultaneous learning is\nfound to improve the accuracy of HNNs while utilizing a smaller number of\nartificial layers.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 12:03:16 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2021 10:45:36 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Muramatsu", "Naoya", ""], ["Yu", "Hai-Tao", ""]]}, {"id": "2102.10911", "submitter": "Dmitry Yarotsky", "authors": "Dmitry Yarotsky", "title": "Elementary superexpressive activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We call a finite family of activation functions superexpressive if any\nmultivariate continuous function can be approximated by a neural network that\nuses these activations and has a fixed architecture only depending on the\nnumber of input variables (i.e., to achieve any accuracy we only need to adjust\nthe weights, without increasing the number of neurons). Previously, it was\nknown that superexpressive activations exist, but their form was quite complex.\nWe give examples of very simple superexpressive families: for example, we prove\nthat the family {sin, arcsin} is superexpressive. We also show that most\npractical activations (not involving periodic functions) are not\nsuperexpressive.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 11:29:09 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Yarotsky", "Dmitry", ""]]}, {"id": "2102.10994", "submitter": "Yurui Ming", "authors": "Yurui Ming", "title": "Coherence of Working Memory Study Between Deep Neural Network and\n  Neurophysiology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The auto feature extraction capability of deep neural networks (DNN) endows\nthem the potentiality for analysing complicated electroencephalogram (EEG) data\ncaptured from brain functionality research. This work investigates the\npotential coherent correspondence between the region-of-interest (ROI) for DNN\nto explore, and ROI for conventional neurophysiological oriented methods to\nwork with, exemplified in the case of working memory study. The attention\nmechanism induced by global average pooling (GAP) is applied to a public EEG\ndataset of working memory, to unveil these coherent ROIs via a classification\nproblem. The result shows the alignment of ROIs from different research\ndisciplines. This work asserts the confidence and promise of utilizing DNN for\nEEG data analysis, albeit in lack of the interpretation to network operations.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 09:09:57 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Ming", "Yurui", ""]]}, {"id": "2102.11237", "submitter": "Sulabh Katiyar", "authors": "Sulabh Katiyar, Samir Kumar Borgohain", "title": "Image Captioning using Deep Stacked LSTMs, Contextual Word Embeddings\n  and Data Augmentation", "comments": "Accepted for publication in Springer Book Series: Advances in\n  Intelligent Systems and Computing - ISSN 2194-5357. Upon publication, this\n  article will point to the published one", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Image Captioning, or the automatic generation of descriptions for images, is\none of the core problems in Computer Vision and has seen considerable progress\nusing Deep Learning Techniques. We propose to use Inception-ResNet\nConvolutional Neural Network as encoder to extract features from images,\nHierarchical Context based Word Embeddings for word representations and a Deep\nStacked Long Short Term Memory network as decoder, in addition to using Image\nData Augmentation to avoid over-fitting. For data Augmentation, we use\nHorizontal and Vertical Flipping in addition to Perspective Transformations on\nthe images. We evaluate our proposed methods with two image captioning\nframeworks- Encoder-Decoder and Soft Attention. Evaluation on widely used\nmetrics have shown that our approach leads to considerable improvement in model\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 18:15:39 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Katiyar", "Sulabh", ""], ["Borgohain", "Samir Kumar", ""]]}, {"id": "2102.11275", "submitter": "Sotirios Goudos", "authors": "Sotirios K. Goudos, Achilles D. Boursianis, Ali Wagdy Mohamed, Shaohua\n  Wan, Panagiotis Sarigiannidis, George K. Karagiannidis, Ponnuthurai N.\n  Suganthan", "title": "Large Scale Global Optimization Algorithms for IoT Networks: A\n  Comparative Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The advent of Internet of Things (IoT) has bring a new era in communication\ntechnology by expanding the current inter-networking services and enabling the\nmachine-to-machine communication. IoT massive deployments will create the\nproblem of optimal power allocation. The objective of the optimization problem\nis to obtain a feasible solution that minimizes the total power consumption of\nthe WSN, when the error probability at the fusion center meets certain\ncriteria. This work studies the optimization of a wireless sensor network (WNS)\nat higher dimensions by focusing to the power allocation of decentralized\ndetection. More specifically, we apply and compare four algorithms designed to\ntackle Large scale global optimization (LGSO) problems. These are the memetic\nlinear population size reduction and semi-parameter adaptation (MLSHADE-SPA),\nthe contribution-based cooperative coevolution recursive differential grouping\n(CBCC-RDG3), the differential grouping with spectral clustering-differential\nevolution cooperative coevolution (DGSC-DECC), and the enhanced adaptive\ndifferential evolution (EADE). To the best of the authors knowledge, this is\nthe first time that LGSO algorithms are applied to the optimal power allocation\nproblem in IoT networks. We evaluate the algorithms performance in several\ndifferent cases by applying them in cases with 300, 600 and 800 dimensions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 18:59:22 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Goudos", "Sotirios K.", ""], ["Boursianis", "Achilles D.", ""], ["Mohamed", "Ali Wagdy", ""], ["Wan", "Shaohua", ""], ["Sarigiannidis", "Panagiotis", ""], ["Karagiannidis", "George K.", ""], ["Suganthan", "Ponnuthurai N.", ""]]}, {"id": "2102.11427", "submitter": "Ravi Vadlamani", "authors": "Vangala Sarveswararao, Vadlamani Ravi and Sheik Tanveer Ul Huq", "title": "Optimal Prediction Intervals for Macroeconomic Time Series Using Chaos\n  and NSGA II", "comments": "23 pages, 16 figures and 8 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In a first-of-its-kind study, this paper proposes the formulation of\nconstructing prediction intervals (PIs) in a time series as a bi-objective\noptimization problem and solves it with the help of Nondominated Sorting\nGenetic Algorithm (NSGA-II). We also proposed modeling the chaos present in the\ntime series as a preprocessor in order to model the deterministic uncertainty\npresent in the time series. Even though the proposed models are general in\npurpose, they are used here for quantifying the uncertainty in macroeconomic\ntime series forecasting. Ideal PIs should be as narrow as possible while\ncapturing most of the data points. Based on these two objectives, we formulated\na bi-objective optimization problem to generate PIs in 2-stages, wherein\nreconstructing the phase space using Chaos theory (stage-1) is followed by\ngenerating optimal point prediction using NSGA-II and these point predictions\nare in turn used to obtain PIs (stage-2). We also proposed a 3-stage hybrid,\nwherein the 3rd stage invokes NSGA-II too in order to solve the problem of\nconstructing PIs from the point prediction obtained in 2nd stage. The proposed\nmodels when applied to the macroeconomic time series, yielded better results in\nterms of both prediction interval coverage probability (PICP) and prediction\ninterval average width (PIAW) compared to the state-of-the-art Lower Upper\nBound Estimation Method (LUBE) with Gradient Descent (GD). The 3-stage model\nyielded better PICP compared to the 2-stage model but showed similar\nperformance in PIAW with added computation cost of running NSGA-II second time.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 00:13:12 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Sarveswararao", "Vangala", ""], ["Ravi", "Vadlamani", ""], ["Huq", "Sheik Tanveer Ul", ""]]}, {"id": "2102.11450", "submitter": "Arnav Malawade", "authors": "Arnav V. Malawade, Nathan D. Costa, Deepan Muthirayan, Pramod P.\n  Khargonekar, Mohammad A. Al Faruque", "title": "Neuroscience-Inspired Algorithms for the Predictive Maintenance of\n  Manufacturing Systems", "comments": null, "journal-ref": null, "doi": "10.1109/TII.2021.3062030", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If machine failures can be detected preemptively, then maintenance and\nrepairs can be performed more efficiently, reducing production costs. Many\nmachine learning techniques for performing early failure detection using\nvibration data have been proposed; however, these methods are often power and\ndata-hungry, susceptible to noise, and require large amounts of data\npreprocessing. Also, training is usually only performed once before inference,\nso they do not learn and adapt as the machine ages. Thus, we propose a method\nof performing online, real-time anomaly detection for predictive maintenance\nusing Hierarchical Temporal Memory (HTM). Inspired by the human neocortex, HTMs\nlearn and adapt continuously and are robust to noise. Using the Numenta Anomaly\nBenchmark, we empirically demonstrate that our approach outperforms\nstate-of-the-art algorithms at preemptively detecting real-world cases of\nbearing failures and simulated 3D printer failures. Our approach achieves an\naverage score of 64.71, surpassing state-of-the-art deep-learning (49.38) and\nstatistical (61.06) methods.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 01:31:09 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Malawade", "Arnav V.", ""], ["Costa", "Nathan D.", ""], ["Muthirayan", "Deepan", ""], ["Khargonekar", "Pramod P.", ""], ["Faruque", "Mohammad A. Al", ""]]}, {"id": "2102.11461", "submitter": "Maxim Buzdalov", "authors": "Kirill Antonov, Maxim Buzdalov, Arina Buzdalova, Carola Doerr", "title": "Blending Dynamic Programming with Monte Carlo Simulation for Bounding\n  the Running Time of Evolutionary Algorithms", "comments": "8 pages, 4 figures. Submitted to IEEE Congress on Evolutionary\n  Computation 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the goal to provide absolute lower bounds for the best possible running\ntimes that can be achieved by $(1+\\lambda)$-type search heuristics on common\nbenchmark problems, we recently suggested a dynamic programming approach that\ncomputes optimal expected running times and the regret values inferred when\ndeviating from the optimal parameter choice.\n  Our previous work is restricted to problems for which transition\nprobabilities between different states can be expressed by relatively simple\nmathematical expressions. With the goal to cover broader sets of problems, we\nsuggest in this work an extension of the dynamic programming approach to\nsettings in which the transition probabilities cannot necessarily be computed\nexactly, but in which they can be approximated numerically, up to arbitrary\nprecision, by Monte Carlo sampling.\n  We apply our hybrid Monte Carlo dynamic programming approach to a\nconcatenated jump function and demonstrate how the obtained bounds can be used\nto gain a deeper understanding into parameter control schemes.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 02:23:48 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Antonov", "Kirill", ""], ["Buzdalov", "Maxim", ""], ["Buzdalova", "Arina", ""], ["Doerr", "Carola", ""]]}, {"id": "2102.11469", "submitter": "Anh Viet Do", "authors": "Anh Viet Do and Mingyu Guo and Aneta Neumann and Frank Neumann", "title": "Analysis of Evolutionary Diversity Optimisation for Permutation Problems", "comments": "9 pages, 2 figures, 1 table", "journal-ref": null, "doi": "10.1145/3449639.3459313", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating diverse populations of high quality solutions has gained interest\nas a promising extension to the traditional optimization tasks. We contribute\nto this line of research by studying evolutionary diversity optimization for\ntwo of the most prominent permutation problems, namely the Traveling\nSalesperson Problem (TSP) and Quadratic Assignment Problem (QAP). We explore\nthe worst-case performance of a simple mutation-only evolutionary algorithm\nwith different mutation operators, using an established diversity measure.\nTheoretical results show most mutation operators for both problems ensure\nproduction of maximally diverse populations of sufficiently small size within\ncubic expected run-time. We perform experiments on QAPLIB instances in\nunconstrained and constrained settings, and reveal much more optimistic\npractical performances. Our results should serve as a baseline for future\nstudies.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 03:13:26 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 06:23:55 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Do", "Anh Viet", ""], ["Guo", "Mingyu", ""], ["Neumann", "Aneta", ""], ["Neumann", "Frank", ""]]}, {"id": "2102.11491", "submitter": "Dmytro Humeniuk", "authors": "Dmytro Humeniuk, Giuliano Antoniol, Foutse Khomh", "title": "Data Driven Testing of Cyber Physical Systems", "comments": "4 pages, to be published in SBST2021 workshop proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Consumer grade cyber-physical systems (CPS) are becoming an integral part of\nour life, automatizing and simplifying everyday tasks. Indeed, due to complex\ninteractions between hardware, networking and software, developing and testing\nsuch systems is known to be a challenging task. Various quality assurance and\ntesting strategies have been proposed. The most common approach for\npre-deployment testing is to model the system and run simulations with models\nor software in the loop. In practice, most often, tests are run for a small\nnumber of simulations, which are selected based on the engineers' domain\nknowledge and experience. In this paper we propose an approach to automatically\ngenerate fault-revealing test cases for CPS. We have implemented our approach\nin Python, using standard frameworks and used it to generate scenarios\nviolating temperature constraints for a smart thermostat implemented as a part\nof our IoT testbed. Data collected from an application managing a smart\nbuilding have been used to learn models of the environment under ever changing\nconditions. The suggested approach allowed us to identify several pit-fails,\nscenarios (i.e., environment conditions and inputs), where the system behaves\nnot as expected.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 04:55:10 GMT"}, {"version": "v2", "created": "Tue, 23 Mar 2021 11:52:02 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Humeniuk", "Dmytro", ""], ["Antoniol", "Giuliano", ""], ["Khomh", "Foutse", ""]]}, {"id": "2102.11506", "submitter": "Sulabh Katiyar", "authors": "Sulabh Katiyar, Samir Kumar Borgohain", "title": "Comparative evaluation of CNN architectures for Image Caption Generation", "comments": "Article Published in International Journal of Advanced Computer\n  Science and Applications(IJACSA), Volume 11 Issue 12, 2020", "journal-ref": "in International Journal of Advanced Computer Science and\n  Applications, 11(12), 2020", "doi": "10.14569/IJACSA.2020.0111291", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Aided by recent advances in Deep Learning, Image Caption Generation has seen\ntremendous progress over the last few years. Most methods use transfer learning\nto extract visual information, in the form of image features, with the help of\npre-trained Convolutional Neural Network models followed by transformation of\nthe visual information using a Caption Generator module to generate the output\nsentences. Different methods have used different Convolutional Neural Network\nArchitectures and, to the best of our knowledge, there is no systematic study\nwhich compares the relative efficacy of different Convolutional Neural Network\narchitectures for extracting the visual information. In this work, we have\nevaluated 17 different Convolutional Neural Networks on two popular Image\nCaption Generation frameworks: the first based on Neural Image Caption (NIC)\ngeneration model and the second based on Soft-Attention framework. We observe\nthat model complexity of Convolutional Neural Network, as measured by number of\nparameters, and the accuracy of the model on Object Recognition task does not\nnecessarily co-relate with its efficacy on feature extraction for Image Caption\nGeneration task.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 05:43:54 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Katiyar", "Sulabh", ""], ["Borgohain", "Samir Kumar", ""]]}, {"id": "2102.11667", "submitter": "Larry Bull", "authors": "Larry Bull", "title": "On Sexual Selection", "comments": "arXiv admin note: substantial text overlap with arXiv:1808.03471,\n  arXiv:1903.07429, arXiv:1811.04073, arXiv:2004.10061", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sexual selection is a fundamental aspect of evolution for all eukaryotic\norganisms with mating types. This paper suggests intersexual selection is best\nviewed as a mechanism to compensate for the unavoidable dynamics of coevolution\nbetween sexes that emerge with isogamy. Using the NK model of fitness\nlandscapes, the conditions under which allosomes emerge are first explored.\nThis extends previous work on the evolution of sex where the fitness landscape\nsmoothing of a rudimentary form of the Baldwin effect is suggested as the\nunderlying cause. The NKCS model of coevolution is then used to show how\nvarying fitness landscape size, ruggedness, and connectedness can vary the\nconditions under which a very simple sexual selection mechanism proves\nbeneficial. This is found to be the case whether one or both sexes exploit\nsexual selection.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 12:47:58 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Bull", "Larry", ""]]}, {"id": "2102.11693", "submitter": "Qingxia Shang", "authors": "Liang Feng, Qingxia Shang, Yaqing Hou, Kay Chen Tan and Yew-Soon Ong", "title": "Multi-Space Evolutionary Search for Large-Scale Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, to improve the evolutionary algorithms used to solve\noptimization problems involving a large number of decision variables, many\nattempts have been made to simplify the problem solution space of a given\nproblem for the evolutionary search. In the literature, the existing approaches\ncan generally be categorized as decomposition-based methods and\ndimension-reduction-based methods. The former decomposes a large-scale problem\ninto several smaller subproblems, while the latter transforms the original\nhigh-dimensional solution space into a low-dimensional space. However, it is\nworth noting that a given large-scale optimization problem may not always be\ndecomposable, and it is also difficult to guarantee that the global optimum of\nthe original problem is preserved in the reduced low-dimensional problem space.\nThis paper thus proposes a new search paradigm, namely the multi-space\nevolutionary search, to enhance the existing evolutionary search methods for\nsolving large-scale optimization problems. In contrast to existing approaches\nthat perform an evolutionary search in a single search space, the proposed\nparadigm is designed to conduct a search in multiple solution spaces that are\nderived from the given problem, each possessing a unique landscape. The\nproposed paradigm makes no assumptions about the large-scale optimization\nproblem of interest, such as that the problem is decomposable or that a certain\nrelationship exists among the decision variables. To verify the efficacy of the\nproposed paradigm, comprehensive empirical studies in comparison to four\nstate-of-the-art algorithms were conducted using the CEC2013 large-scale\nbenchmark problems.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 13:50:09 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 01:58:32 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Feng", "Liang", ""], ["Shang", "Qingxia", ""], ["Hou", "Yaqing", ""], ["Tan", "Kay Chen", ""], ["Ong", "Yew-Soon", ""]]}, {"id": "2102.11995", "submitter": "Yingfang Yuan", "authors": "Yingfang Yuan, Wenjun Wang, Wei Pang", "title": "A Genetic Algorithm with Tree-structured Mutation for Hyperparameter\n  Optimisation of Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, graph neural networks (GNNs) have gained increasing\nattention, as they possess the excellent capability of processing graph-related\nproblems. In practice, hyperparameter optimisation (HPO) is critical for GNNs\nto achieve satisfactory results, but this process is costly because the\nevaluations of different hyperparameter settings require excessively training\nmany GNNs. Many approaches have been proposed for HPO, which aims to identify\npromising hyperparameters efficiently. In particular, the genetic algorithm\n(GA) for HPO has been explored, which treats GNNs as a black-box model, of\nwhich only the outputs can be observed given a set of hyperparameters. However,\nbecause GNN models are sophisticated and the evaluations of hyperparameters on\nGNNs are expensive, GA requires advanced techniques to balance the exploration\nand exploitation of the search and make the optimisation more effective given\nlimited computational resources. Therefore, we proposed a tree-structured\nmutation strategy for GA to alleviate this issue. Meanwhile, we reviewed the\nrecent HPO works, which gives room for the idea of tree-structure to develop,\nand we hope our approach can further improve these HPO methods in the future.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 00:31:52 GMT"}, {"version": "v2", "created": "Wed, 28 Apr 2021 13:52:41 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Yuan", "Yingfang", ""], ["Wang", "Wenjun", ""], ["Pang", "Wei", ""]]}, {"id": "2102.12076", "submitter": "Lana Sinapayen", "authors": "Lana Sinapayen", "title": "Perspective: Purposeful Failure in Artificial Life and Artificial\n  Intelligence", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Complex systems fail. I argue that failures can be a blueprint characterizing\nliving organisms and biological intelligence, a control mechanism to increase\ncomplexity in evolutionary simulations, and an alternative to classical fitness\noptimization. Imitating biological successes in Artificial Life and Artificial\nIntelligence can be misleading; imitating failures offers a path towards\nunderstanding and emulating life it in artificial systems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 05:43:44 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Sinapayen", "Lana", ""]]}, {"id": "2102.12133", "submitter": "Min Jiang", "authors": "Dejun Xu, Min Jiang, Weizhen Hu, Shaozi Li, Renhu Pan and Gary G.Yen", "title": "An Online Prediction Approach Based on Incremental Support Vector\n  Machine for Dynamic Multiobjective Optimization", "comments": "13 pages,4 figures, and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world multiobjective optimization problems usually involve conflicting\nobjectives that change over time, which requires the optimization algorithms to\nquickly track the Pareto optimal front (POF) when the environment changes. In\nrecent years, evolutionary algorithms based on prediction models have been\nconsidered promising. However, most existing approaches only make predictions\nbased on the linear correlation between a finite number of optimal solutions in\ntwo or three previous environments. These incomplete information extraction\nstrategies may lead to low prediction accuracy in some instances. In this\npaper, a novel prediction algorithm based on incremental support vector machine\n(ISVM) is proposed, called ISVM-DMOEA. We treat the solving of dynamic\nmultiobjective optimization problems (DMOPs) as an online learning process,\nusing the continuously obtained optimal solution to update an incremental\nsupport vector machine without discarding the solution information at earlier\ntime. ISVM is then used to filter random solutions and generate an initial\npopulation for the next moment. To overcome the obstacle of insufficient\ntraining samples, a synthetic minority oversampling strategy is implemented\nbefore the training of ISVM. The advantage of this approach is that the\nnonlinear correlation between solutions can be explored online by ISVM, and the\ninformation contained in all historical optimal solutions can be exploited to a\ngreater extent. The experimental results and comparison with chosen\nstate-of-the-art algorithms demonstrate that the proposed algorithm can\neffectively tackle dynamic multiobjective optimization problems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 08:51:23 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Xu", "Dejun", ""], ["Jiang", "Min", ""], ["Hu", "Weizhen", ""], ["Li", "Shaozi", ""], ["Pan", "Renhu", ""], ["Yen", "Gary G.", ""]]}, {"id": "2102.12232", "submitter": "Kenshin Abe", "authors": "Kenshin Abe and Takanori Maehara and Issei Sato", "title": "Abelian Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of modeling a binary operation that satisfies some\nalgebraic requirements. We first construct a neural network architecture for\nAbelian group operations and derive a universal approximation property. Then,\nwe extend it to Abelian semigroup operations using the characterization of\nassociative symmetric polynomials. Both models take advantage of the analytic\ninvertibility of invertible neural networks. For each case, by repeating the\nbinary operations, we can represent a function for multiset input thanks to the\nalgebraic structure. Naturally, our multiset architecture has\nsize-generalization ability, which has not been obtained in existing methods.\nFurther, we present modeling the Abelian group operation itself is useful in a\nword analogy task. We train our models over fixed word embeddings and\ndemonstrate improved performance over the original word2vec and another naive\nlearning method.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 11:52:21 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Abe", "Kenshin", ""], ["Maehara", "Takanori", ""], ["Sato", "Issei", ""]]}, {"id": "2102.12279", "submitter": "Dominik Fischer", "authors": "Rohit Salgotra, Thomas Seidelmann, Dominik Fischer, Sanaz Mostaghim,\n  Amiram Moshaiov", "title": "Optimal Control Policies to Address the Pandemic Health-Economy Dilemma", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Non-pharmaceutical interventions (NPIs) are effective measures to contain a\npandemic. Yet, such control measures commonly have a negative effect on the\neconomy. Here, we propose a macro-level approach to support resolving this\nHealth-Economy Dilemma (HED). First, an extension to the well-known SEIR model\nis suggested which includes an economy model. Second, a bi-objective\noptimization problem is defined to study optimal control policies in view of\nthe HED problem. Next, several multi-objective evolutionary algorithms are\napplied to perform a study on the health-economy performance trade-offs that\nare inherent to the obtained optimal policies. Finally, the results from the\napplied algorithms are compared to select a preferred algorithm for future\nstudies. As expected, for the proposed models and strategies, a clear conflict\nbetween the health and economy performances is found. Furthermore, the results\nsuggest that the guided usage of NPIs is preferable as compared to refraining\nfrom employing such strategies at all. This study contributes to pandemic\nmodeling and simulation by providing a novel concept that elaborates on\nintegrating economic aspects while exploring the optimal moment to enable NPIs.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 13:39:07 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Salgotra", "Rohit", ""], ["Seidelmann", "Thomas", ""], ["Fischer", "Dominik", ""], ["Mostaghim", "Sanaz", ""], ["Moshaiov", "Amiram", ""]]}, {"id": "2102.12339", "submitter": "Frederic Jumelle", "authors": "Frederic Jumelle, Kelvin So, Didan Deng", "title": "Functional neural network for decision processing, a racing network of\n  programmable neurons with fuzzy logic where the target operating model relies\n  on the network itself", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we are introducing a novel model of artificial intelligence,\nthe functional neural network for modeling of human decision-making processes.\nThis neural network is composed of multiple artificial neurons racing in the\nnetwork. Each of these neurons has a similar structure programmed independently\nby the users and composed of an intention wheel, a motor core and a sensory\ncore representing the user itself and racing at a specific velocity. The\nmathematics of the neuron's formulation and the racing mechanism of multiple\nnodes in the network will be discussed, and the group decision process with\nfuzzy logic and the transformation of these conceptual methods into practical\nmethods of simulation and in operations will be developed. Eventually, we will\ndescribe some possible future research directions in the fields of finance,\neducation and medicine including the opportunity to design an intelligent\nlearning agent with application in business operations supervision. We believe\nthat this functional neural network has a promising potential to transform the\nway we can compute decision-making and lead to a new generation of neuromorphic\nchips for seamless human-machine interactions.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 15:19:35 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Jumelle", "Frederic", ""], ["So", "Kelvin", ""], ["Deng", "Didan", ""]]}, {"id": "2102.12365", "submitter": "Aymeric Vie", "authors": "Aymeric Vie", "title": "Modelling SARS-CoV-2 coevolution with genetic algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.MA q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the end of 2020, policy responses to the SARS-CoV-2 outbreak have been\nshaken by the emergence of virus variants, impacting public health and policy\nmeasures worldwide. The emergence of these strains suspected to be more\ncontagious, more severe, or even resistant to antibodies and vaccines, seem to\nhave taken by surprise health services and policymakers, struggling to adapt to\nthe new variants constraints. Anticipating the emergence of these mutations to\nplan ahead adequate policies, and understanding how human behaviors may affect\nthe evolution of viruses by coevolution, are key challenges. In this article,\nwe propose coevolution with genetic algorithms (GAs) as a credible approach to\nmodel this relationship, highlighting its implications, potential and\nchallenges. Because of their qualities of exploration of large spaces of\npossible solutions, capacity to generate novelty, and natural genetic focus,\nGAs are relevant for this issue. We present a dual GA model in which both\nviruses aiming for survival and policy measures aiming at minimising infection\nrates in the population, competitively evolve. This artificial coevolution\nsystem may offer us a laboratory to \"debug\" our current policy measures,\nidentify the weaknesses of our current strategies, and anticipate the evolution\nof the virus to plan ahead relevant policies. It also constitutes a decisive\nopportunity to develop new genetic algorithms capable of simulating much more\ncomplex objects. We highlight some structural innovations for GAs for that\nvirus evolution context that may carry promising developments in evolutionary\ncomputation, artificial life and AI.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 15:49:20 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Vie", "Aymeric", ""]]}, {"id": "2102.12638", "submitter": "Xinyun Zou", "authors": "Xinyun Zou, Eric O. Scott, Alexander B. Johnson, Kexin Chen, Douglas\n  A. Nitz, Kenneth A. De Jong, Jeffrey L. Krichmar", "title": "Neuroevolution of a Recurrent Neural Network for Spatial and Working\n  Memory in a Simulated Robotic Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals ranging from rats to humans can demonstrate cognitive map\ncapabilities. We evolved weights in a biologically plausible recurrent neural\nnetwork (RNN) using an evolutionary algorithm to replicate the behavior and\nneural activity observed in rats during a spatial and working memory task in a\ntriple T-maze. The rat was simulated in the Webots robot simulator and used\nvision, distance and accelerometer sensors to navigate a virtual maze. After\nevolving weights from sensory inputs to the RNN, within the RNN, and from the\nRNN to the robot's motors, the Webots agent successfully navigated the space to\nreach all four reward arms with minimal repeats before time-out. Our current\nfindings suggest that it is the RNN dynamics that are key to performance, and\nthat performance is not dependent on any one sensory type, which suggests that\nneurons in the RNN are performing mixed selectivity and conjunctive coding.\nMoreover, the RNN activity resembles spatial information and\ntrajectory-dependent coding observed in the hippocampus. Collectively, the\nevolved RNN exhibits navigation skills, spatial memory, and working memory. Our\nmethod demonstrates how the dynamic activity in evolved RNNs can capture\ninteresting and complex cognitive behavior and may be used to create RNN\ncontrollers for robotic applications.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 02:13:52 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Zou", "Xinyun", ""], ["Scott", "Eric O.", ""], ["Johnson", "Alexander B.", ""], ["Chen", "Kexin", ""], ["Nitz", "Douglas A.", ""], ["De Jong", "Kenneth A.", ""], ["Krichmar", "Jeffrey L.", ""]]}, {"id": "2102.12773", "submitter": "Fengshi Tian Clarence", "authors": "Fengshi Tian, Jie Yang, Shiqi Zhao, Mohamad Sawan", "title": "A New Neuromorphic Computing Approach for Epileptic Seizure Prediction", "comments": "Accepted to 2021 IEEE International Symposium on Circuits and Systems\n  (ISCAS)", "journal-ref": "2021 IEEE International Symposium on Circuits and Systems (ISCAS)", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.HC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several high specificity and sensitivity seizure prediction methods with\nconvolutional neural networks (CNNs) are reported. However, CNNs are\ncomputationally expensive and power hungry. These inconveniences make CNN-based\nmethods hard to be implemented on wearable devices. Motivated by the\nenergy-efficient spiking neural networks (SNNs), a neuromorphic computing\napproach for seizure prediction is proposed in this work. This approach uses a\ndesigned gaussian random discrete encoder to generate spike sequences from the\nEEG samples and make predictions in a spiking convolutional neural network\n(Spiking-CNN) which combines the advantages of CNNs and SNNs. The experimental\nresults show that the sensitivity, specificity and AUC can remain 95.1%, 99.2%\nand 0.912 respectively while the computation complexity is reduced by 98.58%\ncompared to CNN, indicating that the proposed Spiking-CNN is hardware friendly\nand of high precision.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 10:39:18 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Tian", "Fengshi", ""], ["Yang", "Jie", ""], ["Zhao", "Shiqi", ""], ["Sawan", "Mohamad", ""]]}, {"id": "2102.12905", "submitter": "Diederick Vermetten", "authors": "Jacob de Nobel, Diederick Vermetten, Hao Wang, Carola Doerr, Thomas\n  B\\\"ack", "title": "Tuning as a Means of Assessing the Benefits of New Ideas in Interplay\n  with Existing Algorithmic Modules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introducing new algorithmic ideas is a key part of the continuous improvement\nof existing optimization algorithms. However, when introducing a new component\ninto an existing algorithm, assessing its potential benefits is a challenging\ntask. Often, the component is added to a default implementation of the\nunderlying algorithm and compared against a limited set of other variants. This\nassessment ignores any potential interplay with other algorithmic ideas that\nshare the same base algorithm, which is critical in understanding the exact\ncontributions being made. We introduce a more extensive procedure, which uses\nhyperparameter tuning as a means of assessing the benefits of new algorithmic\ncomponents. This allows for a more robust analysis by not only focusing on the\nimpact on performance, but also by investigating how this performance is\nachieved. We implement our suggestion in the context of the Modular CMA-ES\nframework, which was redesigned and extended to include some new modules and\nseveral new options for existing modules, mostly focused on the step-size\nadaptation method. Our analysis highlights the differences between these new\nmodules, and identifies the situations in which they have the largest\ncontribution.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 14:59:55 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 11:56:43 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["de Nobel", "Jacob", ""], ["Vermetten", "Diederick", ""], ["Wang", "Hao", ""], ["Doerr", "Carola", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2102.13188", "submitter": "Hojjat Salehinejad", "authors": "Hojjat Salehinejad, Shahrokh Valaee", "title": "A Framework For Pruning Deep Neural Networks Using Energy-Based Models", "comments": "This paper is accepted for presentation at IEEE International\n  Conference on Acoustics, Speech and Signal Processing (IEEE ICASSP), 2021.\n  arXiv admin note: text overlap with arXiv:2006.04270, arXiv:2102.05437", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A typical deep neural network (DNN) has a large number of trainable\nparameters. Choosing a network with proper capacity is challenging and\ngenerally a larger network with excessive capacity is trained. Pruning is an\nestablished approach to reducing the number of parameters in a DNN. In this\npaper, we propose a framework for pruning DNNs based on a population-based\nglobal optimization method. This framework can use any pruning objective\nfunction. As a case study, we propose a simple but efficient objective function\nbased on the concept of energy-based models. Our experiments on ResNets,\nAlexNet, and SqueezeNet for the CIFAR-10 and CIFAR-100 datasets show a pruning\nrate of more than $50\\%$ of the trainable parameters with approximately $<5\\%$\nand $<1\\%$ drop of Top-1 and Top-5 classification accuracy, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 21:44:19 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Salehinejad", "Hojjat", ""], ["Valaee", "Shahrokh", ""]]}, {"id": "2102.13388", "submitter": "Aur\\'elie Boisbunon", "authors": "Aur\\'elie Boisbunon, Carlo Fanara, Ingrid Grenet, Jonathan Daeden,\n  Alexis Vighi, Marc Schoenauer", "title": "Zoetrope Genetic Programming for Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Zoetrope Genetic Programming (ZGP) algorithm is based on an original\nrepresentation for mathematical expressions, targeting evolutionary symbolic\nregression.The zoetropic representation uses repeated fusion operations between\npartial expressions, starting from the terminal set. Repeated fusions within an\nindividual gradually generate more complex expressions, ending up in what can\nbe viewed as new features. These features are then linearly combined to best\nfit the training data. ZGP individuals then undergo specific crossover and\nmutation operators, and selection takes place between parents and offspring.\nZGP is validated using a large number of public domain regression datasets, and\ncompared to other symbolic regression algorithms, as well as to traditional\nmachine learning algorithms. ZGP reaches state-of-the-art performance with\nrespect to both types of algorithms, and demonstrates a low computational time\ncompared to other symbolic regression approaches.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 10:47:10 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Boisbunon", "Aur\u00e9lie", ""], ["Fanara", "Carlo", ""], ["Grenet", "Ingrid", ""], ["Daeden", "Jonathan", ""], ["Vighi", "Alexis", ""], ["Schoenauer", "Marc", ""]]}, {"id": "2102.13651", "submitter": "Baohe Zhang", "authors": "Baohe Zhang, Raghu Rajan, Luis Pineda, Nathan Lambert, Andr\\'e\n  Biedenkapp, Kurtland Chua, Frank Hutter, Roberto Calandra", "title": "On the Importance of Hyperparameter Optimization for Model-based\n  Reinforcement Learning", "comments": "19 pages, accepted by AISTATS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Model-based Reinforcement Learning (MBRL) is a promising framework for\nlearning control in a data-efficient manner. MBRL algorithms can be fairly\ncomplex due to the separate dynamics modeling and the subsequent planning\nalgorithm, and as a result, they often possess tens of hyperparameters and\narchitectural choices. For this reason, MBRL typically requires significant\nhuman expertise before it can be applied to new problems and domains. To\nalleviate this problem, we propose to use automatic hyperparameter optimization\n(HPO). We demonstrate that this problem can be tackled effectively with\nautomated HPO, which we demonstrate to yield significantly improved performance\ncompared to human experts. In addition, we show that tuning of several MBRL\nhyperparameters dynamically, i.e. during the training itself, further improves\nthe performance compared to using static hyperparameters which are kept fixed\nfor the whole training. Finally, our experiments provide valuable insights into\nthe effects of several hyperparameters, such as plan horizon or learning rate\nand their influence on the stability of training and resulting rewards.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 18:57:47 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Zhang", "Baohe", ""], ["Rajan", "Raghu", ""], ["Pineda", "Luis", ""], ["Lambert", "Nathan", ""], ["Biedenkapp", "Andr\u00e9", ""], ["Chua", "Kurtland", ""], ["Hutter", "Frank", ""], ["Calandra", "Roberto", ""]]}]