[{"id": "2104.00165", "submitter": "Kenneth Stewart", "authors": "Kenneth Stewart, Andreea Danielescu, Lazar Supic, Timothy Shea, Emre\n  Neftci", "title": "Gesture Similarity Analysis on Event Data Using a Hybrid Guided\n  Variational Auto Encoder", "comments": "Submitted to ICCV 2021 for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While commercial mid-air gesture recognition systems have existed for at\nleast a decade, they have not become a widespread method of interacting with\nmachines. This is primarily due to the fact that these systems require rigid,\ndramatic gestures to be performed for accurate recognition that can be\nfatiguing and unnatural. The global pandemic has seen a resurgence of interest\nin touchless interfaces, so new methods that allow for natural mid-air gestural\ninteractions are even more important. To address the limitations of recognition\nsystems, we propose a neuromorphic gesture analysis system which naturally\ndeclutters the background and analyzes gestures at high temporal resolution.\nOur novel model consists of an event-based guided Variational Autoencoder (VAE)\nwhich encodes event-based data sensed by a Dynamic Vision Sensor (DVS) into a\nlatent space representation suitable to analyze and compute the similarity of\nmid-air gesture data. Our results show that the features learned by the VAE\nprovides a similarity measure capable of clustering and pseudo labeling of new\ngestures. Furthermore, we argue that the resulting event-based encoder and\npseudo-labeling system are suitable for implementation in neuromorphic hardware\nfor online adaptation and learning of natural mid-air gestures.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 23:58:34 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Stewart", "Kenneth", ""], ["Danielescu", "Andreea", ""], ["Supic", "Lazar", ""], ["Shea", "Timothy", ""], ["Neftci", "Emre", ""]]}, {"id": "2104.00528", "submitter": "Alexander Wong", "authors": "Saad Abbasi, Mahmoud Famouri, Mohammad Javad Shafiee, and Alexander\n  Wong", "title": "OutlierNets: Highly Compact Deep Autoencoder Network Architectures for\n  On-Device Acoustic Anomaly Detection", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human operators often diagnose industrial machinery via anomalous sounds.\nAutomated acoustic anomaly detection can lead to reliable maintenance of\nmachinery. However, deep learning-driven anomaly detection methods often\nrequire an extensive amount of computational resources which prohibits their\ndeployment in factories. Here we explore a machine-driven design exploration\nstrategy to create OutlierNets, a family of highly compact deep convolutional\nautoencoder network architectures featuring as few as 686 parameters, model\nsizes as small as 2.7 KB, and as low as 2.8 million FLOPs, with a detection\naccuracy matching or exceeding published architectures with as many as 4\nmillion parameters. Furthermore, CPU-accelerated latency experiments show that\nthe OutlierNet architectures can achieve as much as 21x lower latency than\npublished networks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Mar 2021 04:09:30 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 03:25:50 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Abbasi", "Saad", ""], ["Famouri", "Mahmoud", ""], ["Shafiee", "Mohammad Javad", ""], ["Wong", "Alexander", ""]]}, {"id": "2104.00751", "submitter": "Silvija Kokalj-Filipovic", "authors": "Silvija Kokalj-Filipovic, Paul Toliver, William Johnson, Rob Miller", "title": "Reservoir-Based Distributed Machine Learning for Edge Operation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a novel design for in-situ training of machine learning\nalgorithms built into smart sensors, and illustrate distributed training\nscenarios using radio frequency (RF) spectrum sensors. Current RF sensors at\nthe Edge lack the computational resources to support practical, in-situ\ntraining for intelligent signal classification. We propose a solution using\nDeepdelay Loop Reservoir Computing (DLR), a processing architecture that\nsupports machine learning algorithms on resource-constrained edge-devices by\nleveraging delayloop reservoir computing in combination with innovative\nhardware. DLR delivers reductions in form factor, hardware complexity and\nlatency, compared to the State-ofthe- Art (SoA) neural nets. We demonstrate DLR\nfor two applications: RF Specific Emitter Identification (SEI) and wireless\nprotocol recognition. DLR enables mobile edge platforms to authenticate and\nthen track emitters with fast SEI retraining. Once delay loops separate the\ndata classes, traditionally complex, power-hungry classification models are no\nlonger needed for the learning process. Yet, even with simple classifiers such\nas Ridge Regression (RR), the complexity grows at least quadratically with the\ninput size. DLR with a RR classifier exceeds the SoA accuracy, while further\nreducing power consumption by leveraging the architecture of parallel (split)\nloops. To authenticate mobile devices across large regions, DLR can be trained\nin a distributed fashion with very little additional processing and a small\ncommunication cost, all while maintaining accuracy. We illustrate how to merge\nlocally trained DLR classifiers in use cases of interest.\n", "versions": [{"version": "v1", "created": "Thu, 1 Apr 2021 20:06:40 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Kokalj-Filipovic", "Silvija", ""], ["Toliver", "Paul", ""], ["Johnson", "William", ""], ["Miller", "Rob", ""]]}, {"id": "2104.01177", "submitter": "Colin White", "authors": "Colin White, Arber Zela, Binxin Ru, Yang Liu, Frank Hutter", "title": "How Powerful are Performance Predictors in Neural Architecture Search?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early methods in the rapidly developing field of neural architecture search\n(NAS) required fully training thousands of neural networks. To reduce this\nextreme computational cost, dozens of techniques have since been proposed to\npredict the final performance of neural architectures. Despite the success of\nsuch performance prediction methods, it is not well-understood how different\nfamilies of techniques compare to one another, due to the lack of an\nagreed-upon evaluation metric and optimization for different constraints on the\ninitialization time and query time. In this work, we give the first large-scale\nstudy of performance predictors by analyzing 31 techniques ranging from\nlearning curve extrapolation, to weight-sharing, to supervised learning, to\n\"zero-cost\" proxies. We test a number of correlation- and rank-based\nperformance measures in a variety of settings, as well as the ability of each\ntechnique to speed up predictor-based NAS frameworks. Our results act as\nrecommendations for the best predictors to use in different settings, and we\nshow that certain families of predictors can be combined to achieve even better\npredictive power, opening up promising research directions. Our code, featuring\na library of 31 performance predictors, is available at\nhttps://github.com/automl/naslib.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 17:57:16 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["White", "Colin", ""], ["Zela", "Arber", ""], ["Ru", "Binxin", ""], ["Liu", "Yang", ""], ["Hutter", "Frank", ""]]}, {"id": "2104.01242", "submitter": "Peter Turney", "authors": "Peter D. Turney", "title": "Major Cooperative Transitions and Management Theory in the Game of Life", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological and cultural evolution show a trend towards increasing\nhierarchical organization, in which entities at one level combine cooperatively\nto form a new entity at a higher level of organization. In each case where such\na cooperative transition has been studied, we have some understanding of how\nthe transition came about, but it is difficult to formulate a unified theory\nthat covers all of these transitions. John Stewart has proposed a theoretical\nframework called Management Theory, which attempts to explain all of the major\ncooperative transitions in biological and cultural evolution. The idea is that\nsuccessful transitions require the integration of managers and workers into a\ncooperative organization. This theory seems appropriate when we consider the\ncultural evolution of corporations, where managers and workers are clearly\nessential, but it seems less plausible when we consider the biological\nevolution of entities that do not invite anthropomorphic projection. However,\nin the following article, we define managers and workers in an abstract way\nthat enables us to apply these terms over a broad range of cases, including\ncultural evolution, biological evolution, and computational simulations of\nevolution. The core idea is that a worker is an entity that takes the main role\nin the production of something and a manager is an entity that plays a\nsupporting role in the production of something. We apply this abstract view of\nmanagers and workers to a computational simulation of evolving cooperative\ntransitions in John Conway's Game of Life. The simulation confirms the\nexpectations of Management Theory: Manager-worker relations result in robust\nand productive cooperation, whereas workers without managers tend to lack\nrobustness, and managers without workers tend to lack productivity.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 21:23:48 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Turney", "Peter D.", ""]]}, {"id": "2104.01271", "submitter": "C.-H. Huck Yang", "authors": "Chao-Han Huck Yang, Sabato Marco Siniscalchi, Chin-Hui Lee", "title": "PATE-AAE: Incorporating Adversarial Autoencoder into Private Aggregation\n  of Teacher Ensembles for Spoken Command Classification", "comments": "Accepted to Interspeech 2021", "journal-ref": "Proc. Interspeech 2021", "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG cs.NE eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose using an adversarial autoencoder (AAE) to replace generative\nadversarial network (GAN) in the private aggregation of teacher ensembles\n(PATE), a solution for ensuring differential privacy in speech applications.\nThe AAE architecture allows us to obtain good synthetic speech leveraging upon\na discriminative training of latent vectors. Such synthetic speech is used to\nbuild a privacy-preserving classifier when non-sensitive data is not\nsufficiently available in the public domain. This classifier follows the PATE\nscheme that uses an ensemble of noisy outputs to label the synthetic samples\nand guarantee $\\varepsilon$-differential privacy (DP) on its derived\nclassifiers. Our proposed framework thus consists of an AAE-based generator and\na PATE-based classifier (PATE-AAE). Evaluated on the Google Speech Commands\nDataset Version II, the proposed PATE-AAE improves the average classification\naccuracy by +$2.11\\%$ and +$6.60\\%$, respectively, when compared with\nalternative privacy-preserving solutions, namely PATE-GAN and DP-GAN, while\nmaintaining a strong level of privacy target at $\\varepsilon$=0.01 with a fixed\n$\\delta$=10$^{-5}$.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 23:10:57 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 06:09:42 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Yang", "Chao-Han Huck", ""], ["Siniscalchi", "Sabato Marco", ""], ["Lee", "Chin-Hui", ""]]}, {"id": "2104.01489", "submitter": "Daniel Yamins", "authors": "Rosa Cao and Daniel Yamins", "title": "Explanatory models in neuroscience: Part 2 -- constraint-based\n  intelligibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Computational modeling plays an increasingly important role in neuroscience,\nhighlighting the philosophical question of how computational models explain. In\nthe context of neural network models for neuroscience, concerns have been\nraised about model intelligibility, and how they relate (if at all) to what is\nfound in the brain. We claim that what makes a system intelligible is an\nunderstanding of the dependencies between its behavior and the factors that are\ncausally responsible for that behavior. In biological systems, many of these\ndependencies are naturally \"top-down\": ethological imperatives interact with\nevolutionary and developmental constraints under natural selection. We describe\nhow the optimization techniques used to construct NN models capture some key\naspects of these dependencies, and thus help explain why brain systems are as\nthey are -- because when a challenging ecologically-relevant goal is shared by\na NN and the brain, it places tight constraints on the possible mechanisms\nexhibited in both kinds of systems. By combining two familiar modes of\nexplanation -- one based on bottom-up mechanism (whose relation to neural\nnetwork models we address in a companion paper) and the other on top-down\nconstraints, these models illuminate brain function.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 22:14:01 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 16:59:48 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Cao", "Rosa", ""], ["Yamins", "Daniel", ""]]}, {"id": "2104.01490", "submitter": "Daniel Yamins", "authors": "Rosa Cao and Daniel Yamins", "title": "Explanatory models in neuroscience: Part 1 -- taking mechanistic\n  abstraction seriously", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite the recent success of neural network models in mimicking animal\nperformance on visual perceptual tasks, critics worry that these models fail to\nilluminate brain function. We take it that a central approach to explanation in\nsystems neuroscience is that of mechanistic modeling, where understanding the\nsystem is taken to require fleshing out the parts, organization, and activities\nof a system, and how those give rise to behaviors of interest. However, it\nremains somewhat controversial what it means for a model to describe a\nmechanism, and whether neural network models qualify as explanatory.\n  We argue that certain kinds of neural network models are actually good\nexamples of mechanistic models, when the right notion of mechanistic mapping is\ndeployed. Building on existing work on model-to-mechanism mapping (3M), we\ndescribe criteria delineating such a notion, which we call 3M++. These criteria\nrequire us, first, to identify a level of description that is both abstract but\ndetailed enough to be \"runnable\", and then, to construct model-to-brain\nmappings using the same principles as those employed for brain-to-brain mapping\nacross individuals. Perhaps surprisingly, the abstractions required are those\nalready in use in experimental neuroscience, and are of the kind deployed in\nthe construction of more familiar computational models, just as the principles\nof inter-brain mappings are very much in the spirit of those already employed\nin the collection and analysis of data across animals.\n  In a companion paper, we address the relationship between optimization and\nintelligibility, in the context of functional evolutionary explanations. Taken\ntogether, mechanistic interpretations of computational models and the\ndependencies between form and function illuminated by optimization processes\ncan help us to understand why brain systems are built they way they are.\n", "versions": [{"version": "v1", "created": "Sat, 3 Apr 2021 22:17:40 GMT"}, {"version": "v2", "created": "Sat, 10 Apr 2021 23:39:21 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Cao", "Rosa", ""], ["Yamins", "Daniel", ""]]}, {"id": "2104.01521", "submitter": "Omid Tarkhaneh", "authors": "Omid Tarkhaneh, Neda Alipour, Amirahmad Chapnevis, Haifeng Shen", "title": "Golden Tortoise Beetle Optimizer: A Novel Nature-Inspired Meta-heuristic\n  Algorithm for Engineering Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a novel nature-inspired meta-heuristic algorithm called\nthe Golden Tortoise Beetle Optimizer (GTBO) to solve optimization problems. It\nmimics golden tortoise beetle's behavior of changing colors to attract opposite\nsex for mating and its protective strategy that uses a kind of anal fork to\ndeter predators. The algorithm is modeled based on the beetle's dual\nattractiveness and survival strategy to generate new solutions for optimization\nproblems. To measure its performance, the proposed GTBO is compared with five\nother nature-inspired evolutionary algorithms on 24 well-known benchmark\nfunctions investigating the trade-off between exploration and exploitation,\nlocal optima avoidance, and convergence towards the global optima is\nstatistically significant. We particularly applied GTBO to two well-known\nengineering problems including the welded beam design problem and the gear\ntrain design problem. The results demonstrate that the new algorithm is more\nefficient than the five baseline algorithms for both problems. A sensitivity\nanalysis is also performed to reveal different impacts of the algorithm's key\ncontrol parameters and operators on GTBO's performance.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 02:29:47 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Tarkhaneh", "Omid", ""], ["Alipour", "Neda", ""], ["Chapnevis", "Amirahmad", ""], ["Shen", "Haifeng", ""]]}, {"id": "2104.01677", "submitter": "Jo\\~ao Sacramento", "authors": "Nicolas Zucchet and Simon Schug and Johannes von Oswald and Dominic\n  Zhao and Jo\\~ao Sacramento", "title": "A contrastive rule for meta-learning", "comments": "29 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning algorithms leverage regularities that are present on a set of\ntasks to speed up and improve the performance of a subsidiary learning process.\nRecent work on deep neural networks has shown that prior gradient-based\nlearning of meta-parameters can greatly improve the efficiency of subsequent\nlearning. Here, we present a biologically plausible meta-learning algorithm\nbased on equilibrium propagation. Instead of explicitly differentiating the\nlearning process, our contrastive meta-learning rule estimates meta-parameter\ngradients by executing the subsidiary process more than once. This avoids\nreversing the learning dynamics in time and computing second-order derivatives.\nIn spite of this, and unlike previous first-order methods, our rule recovers an\narbitrarily accurate meta-parameter update given enough compute. We establish\ntheoretical bounds on its performance and present experiments on a set of\nstandard benchmarks and neural network architectures.\n", "versions": [{"version": "v1", "created": "Sun, 4 Apr 2021 19:45:41 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 21:04:58 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Zucchet", "Nicolas", ""], ["Schug", "Simon", ""], ["von Oswald", "Johannes", ""], ["Zhao", "Dominic", ""], ["Sacramento", "Jo\u00e3o", ""]]}, {"id": "2104.02032", "submitter": "Kolawole Ogunsina", "authors": "Kolawole Ogunsina and Wendy A. Okolo", "title": "Artificial Neural Network Modeling for Airline Disruption Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Since the 1970s, most airlines have incorporated computerized support for\nmanaging disruptions during flight schedule execution. However, existing\nplatforms for airline disruption management (ADM) employ monolithic system\ndesign methods that rely on the creation of specific rules and requirements\nthrough explicit optimization routines, before a system that meets the\nspecifications is designed. Thus, current platforms for ADM are unable to\nreadily accommodate additional system complexities resulting from the\nintroduction of new capabilities, such as the introduction of unmanned aerial\nsystems (UAS), operations and infrastructure, to the system. To this end, we\nuse historical data on airline scheduling and operations recovery to develop a\nsystem of artificial neural networks (ANNs), which describe a predictive\ntransfer function model (PTFM) for promptly estimating the recovery impact of\ndisruption resolutions at separate phases of flight schedule execution during\nADM. Furthermore, we provide a modular approach for assessing and executing the\nPTFM by employing a parallel ensemble method to develop generative routines\nthat amalgamate the system of ANNs. Our modular approach ensures that current\nindustry standards for tardiness in flight schedule execution during ADM are\nsatisfied, while accurately estimating appropriate time-based performance\nmetrics for the separate phases of flight schedule execution.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 17:37:24 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 13:24:05 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ogunsina", "Kolawole", ""], ["Okolo", "Wendy A.", ""]]}, {"id": "2104.02464", "submitter": "Prerit Terway", "authors": "Prerit Terway, Kenza Hamidouche, and Niraj K. Jha", "title": "Fast Design Space Exploration of Nonlinear Systems: Part II", "comments": "14 pages, 24 figures. arXiv admin note: substantial text overlap with\n  arXiv:2009.10214", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear system design is often a multi-objective optimization problem\ninvolving search for a design that satisfies a number of predefined\nconstraints. The design space is typically very large since it includes all\npossible system architectures with different combinations of components\ncomposing each architecture. In this article, we address nonlinear system\ndesign space exploration through a two-step approach encapsulated in a\nframework called Fast Design Space Exploration of Nonlinear Systems (ASSENT).\nIn the first step, we use a genetic algorithm to search for system\narchitectures that allow discrete choices for component values or else only\ncomponent values for a fixed architecture. This step yields a coarse design\nsince the system may or may not meet the target specifications. In the second\nstep, we use an inverse design to search over a continuous space and fine-tune\nthe component values with the goal of improving the value of the objective\nfunction. We use a neural network to model the system response. The neural\nnetwork is converted into a mixed-integer linear program for active learning to\nsample component values efficiently. We illustrate the efficacy of ASSENT on\nproblems ranging from nonlinear system design to design of electrical circuits.\nExperimental results show that ASSENT achieves the same or better value of the\nobjective function compared to various other optimization techniques for\nnonlinear system design by up to 54%. We improve sample efficiency by 6-10x\ncompared to reinforcement learning based synthesis of electrical circuits.\n", "versions": [{"version": "v1", "created": "Mon, 5 Apr 2021 16:11:50 GMT"}, {"version": "v2", "created": "Thu, 8 Apr 2021 19:35:15 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Terway", "Prerit", ""], ["Hamidouche", "Kenza", ""], ["Jha", "Niraj K.", ""]]}, {"id": "2104.02559", "submitter": "Abdesslem Layeb", "authors": "Abdesslem Layeb", "title": "The Tangent Search Algorithm for Solving Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a new population-based optimization algorithm called\nthe Tangent Search Algorithm (TSA) to solve optimization problems. The TSA uses\na mathematical model based on the tangent function to move a given solution\ntoward a better solution. The tangent flight function has the advantage to\nbalance between the exploitation and the exploration search. Moreover, a novel\nescape procedure is used to avoid to be trapped in local minima. Besides, an\nadaptive variable step size is also integrated in this algorithm to enhance the\nconvergence capacity. The performance of TSA is assessed in three classes of\ntests: classical tests, CEC benchmarks, and engineering optimization problems.\nMoreover, several studies and metrics have been used to observe the behavior of\nthe proposed TSA. The experimental results show that TSA algorithm is capable\nto provide very promising and competitive results on most benchmark functions\nthanks to better balance between exploration and exploitation of the search\nspace. The main characteristics of this new optimization algorithm is its\nsimplicity and efficiency and it requires only a small number of user-defined\nparameters.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2021 14:56:22 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Layeb", "Abdesslem", ""]]}, {"id": "2104.03062", "submitter": "Emma Stensby Norstein", "authors": "Emma Hjellbrekke Stensby, Kai Olav Ellefsen and Kyrre Glette", "title": "Co-optimising Robot Morphology and Controller in a Simulated Open-Ended\n  Environment", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": "10.1007/978-3-030-72699-7_3", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing robots by hand can be costly and time consuming, especially if the\nrobots have to be created with novel materials, or be robust to internal or\nexternal changes. In order to create robots automatically, without the need for\nhuman intervention, it is necessary to optimise both the behaviour and the body\ndesign of the robot. However, when co-optimising the morphology and controller\nof a locomoting agent the morphology tends to converge prematurely, reaching a\nlocal optimum. Approaches such as explicit protection of morphological\ninnovation have been used to reduce this problem, but it might also be possible\nto increase exploration of morphologies using a more indirect approach. We\nexplore how changing the environment, where the agent locomotes, affects the\nconvergence of morphologies. The agents' morphologies and controllers are\nco-optimised, while the environments the agents locomote in are evolved\nopen-endedly with the Paired Open-Ended Trailblazer (POET). We compare the\ndiversity, fitness and robustness of agents evolving in environments generated\nby POET to agents evolved in handcrafted curricula of environments. Our agents\neach contain of a population of individuals being evolved with a genetic\nalgorithm. This population is called the agent-population. We show that\nagent-populations evolving in open-endedly evolving environments exhibit larger\nmorphological diversity than agent-populations evolving in hand crafted\ncurricula of environments. POET proved capable of creating a curriculum of\nenvironments which encouraged both diversity and quality in the populations.\nThis suggests that POET may be capable of reducing premature convergence in\nco-optimisation of morphology and controllers.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 11:28:23 GMT"}], "update_date": "2021-04-08", "authors_parsed": [["Stensby", "Emma Hjellbrekke", ""], ["Ellefsen", "Kai Olav", ""], ["Glette", "Kyrre", ""]]}, {"id": "2104.03349", "submitter": "Kolawole Ogunsina", "authors": "Kolawole Ogunsina and Daniel DeLaurentis", "title": "Enabling Integration and Interaction for Decentralized Artificial\n  Intelligence in Airline Disruption Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Airline disruption management traditionally seeks to address three problem\ndimensions: aircraft scheduling, crew scheduling, and passenger scheduling, in\nthat order. However, current efforts have, at most, only addressed the first\ntwo problem dimensions concurrently and do not account for the propagative\neffects that uncertain scheduling outcomes in one dimension can have on another\ndimension. In addition, existing approaches for airline disruption management\ninclude human specialists who decide on necessary corrective actions for\nairline schedule disruptions on the day of operation. However, human\nspecialists are limited in their ability to process copious amounts of\ninformation imperative for making robust decisions that simultaneously address\nall problem dimensions during disruption management. Therefore, there is a need\nto augment the decision-making capabilities of a human specialist with\nquantitative and qualitative tools that can rationalize complex interactions\namongst all dimensions in airline disruption management, and provide objective\ninsights to the specialists in the airline operations control center. To that\neffect, we provide a discussion and demonstration of an agnostic and systematic\nparadigm for enabling expeditious simultaneously-integrated recovery of all\nproblem dimensions during airline disruption management, through an intelligent\nmulti-agent system that employs principles from artificial intelligence and\ndistributed ledger technology.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 18:59:02 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Ogunsina", "Kolawole", ""], ["DeLaurentis", "Daniel", ""]]}, {"id": "2104.03372", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr and Timo K\\\"otzing", "title": "Lower Bounds from Fitness Levels Made Easy", "comments": "Extended version of a paper appearing in the proceedings of GECCO\n  2021", "journal-ref": null, "doi": "10.1145/3449639.3459352", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the first and easy to use techniques for proving run time bounds for\nevolutionary algorithms is the so-called method of fitness levels by Wegener.\nIt uses a partition of the search space into a sequence of levels which are\ntraversed by the algorithm in increasing order, possibly skipping levels. An\neasy, but often strong upper bound for the run time can then be derived by\nadding the reciprocals of the probabilities to leave the levels (or upper\nbounds for these). Unfortunately, a similarly effective method for proving\nlower bounds has not yet been established. The strongest such method, proposed\nby Sudholt (2013), requires a careful choice of the viscosity parameters\n$\\gamma_{i,j}$, $0 \\le i < j \\le n$.\n  In this paper we present two new variants of the method, one for upper and\none for lower bounds. Besides the level leaving probabilities, they only rely\non the probabilities that levels are visited at all. We show that these can be\ncomputed or estimated without greater difficulties and apply our method to\nreprove the following known results in an easy and natural way. (i) The precise\nrun time of the (1+1) EA on \\textsc{LeadingOnes}. (ii) A lower bound for the\nrun time of the (1+1) EA on \\textsc{OneMax}, tight apart from an $O(n)$ term.\n(iii) A lower bound for the run time of the (1+1) EA on long $k$-paths. We also\nprove a tighter lower bound for the run time of the (1+1) EA on jump functions\nby showing that, regardless of the jump size, only with probability $O(2^{-n})$\nthe algorithm can avoid to jump over the valley of low fitness.\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 19:50:53 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 09:54:13 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 08:18:18 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Doerr", "Benjamin", ""], ["K\u00f6tzing", "Timo", ""]]}, {"id": "2104.03404", "submitter": "Nicholas Guttenberg", "authors": "Nicholas Guttenberg, Marek Rosa", "title": "Bootstrapping of memetic from genetic evolution via inter-agent\n  selection pressures", "comments": "9 pages, 3 figures, submitted to ALife 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We create an artificial system of agents (attention-based neural networks)\nwhich selectively exchange messages with each-other in order to study the\nemergence of memetic evolution and how memetic evolutionary pressures interact\nwith genetic evolution of the network weights. We observe that the ability of\nagents to exert selection pressures on each-other is essential for memetic\nevolution to bootstrap itself into a state which has both high-fidelity\nreplication of memes, as well as continuing production of new memes over time.\nHowever, in this system there is very little interaction between this memetic\n'ecology' and underlying tasks driving individual fitness - the emergent meme\nlayer appears to be neither helpful nor harmful to agents' ability to learn to\nsolve tasks. Sourcecode for these experiments is available at\nhttps://github.com/GoodAI/memes\n", "versions": [{"version": "v1", "created": "Wed, 7 Apr 2021 21:31:05 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Guttenberg", "Nicholas", ""], ["Rosa", "Marek", ""]]}, {"id": "2104.03440", "submitter": "Yue Xie", "authors": "Yue Xie, Aneta Neumann, Frank Neumann", "title": "Heuristic Strategies for Solving Complex Interacting Large-Scale\n  Stockpile Blending Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Stockpile blending problem is an important component of mine production\nscheduling, where stockpiles are used to store and blend raw material. The goal\nof blending material from stockpiles is to create parcels of concentrate which\ncontain optimal metal grades based on the material available. The volume of\nmaterial that each stockpile provides to a given parcel is dependent on a set\nof mine schedule conditions and customer demands. Therefore, the problem can be\nformulated as a continuous optimization problem. In the real-world application,\nthere are several constraints required to guarantee parcels that meet the\ndemand of downstream customers. It is a challenge in solving the stockpile\nblending problems since its scale can be very large. We introduce two repaired\noperators for the problems to convert the infeasible solutions into the\nsolutions without violating the two tight constraints. Besides, we introduce a\nmulti-component fitness function for solving the large-scale stockpile blending\nproblem which can maximize the volume of metal over the plan and maintain the\nbalance between stockpiles according to the usage of metal. Furthermore, we\ninvestigate the well-known approach in this paper, which is used to solve\noptimization problems over continuous space, namely the differential evolution\n(DE) algorithm. The experimental results show that the DE algorithm combined\nwith two proposed duration repair methods is significantly better in terms of\nthe values of results than the results on real-world instances for both\none-month problems and large-scale problems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 00:22:39 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Xie", "Yue", ""], ["Neumann", "Aneta", ""], ["Neumann", "Frank", ""]]}, {"id": "2104.03496", "submitter": "Elliott Skomski", "authors": "Elliott Skomski, Aaron Tuor, Andrew Avila, Lauren Phillips, Zachary\n  New, Henry Kvinge, Courtney D. Corley, and Nathan Hodas", "title": "Prototypical Region Proposal Networks for Few-Shot Localization and\n  Classification", "comments": "9 pages, 1 figure. Submitted to 4th Workshop on Meta-Learning at\n  NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently proposed few-shot image classification methods have generally\nfocused on use cases where the objects to be classified are the central subject\nof images. Despite success on benchmark vision datasets aligned with this use\ncase, these methods typically fail on use cases involving densely-annotated,\nbusy images: images common in the wild where objects of relevance are not the\ncentral subject, instead appearing potentially occluded, small, or among other\nincidental objects belonging to other classes of potential interest. To\nlocalize relevant objects, we employ a prototype-based few-shot segmentation\nmodel which compares the encoded features of unlabeled query images with\nsupport class centroids to produce region proposals indicating the presence and\nlocation of support set classes in a query image. These region proposals are\nthen used as additional conditioning input to few-shot image classifiers. We\ndevelop a framework to unify the two stages (segmentation and classification)\ninto an end-to-end classification model -- PRoPnet -- and empirically\ndemonstrate that our methods improve accuracy on image datasets with natural\nscenes containing multiple object classes.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 04:03:30 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Skomski", "Elliott", ""], ["Tuor", "Aaron", ""], ["Avila", "Andrew", ""], ["Phillips", "Lauren", ""], ["New", "Zachary", ""], ["Kvinge", "Henry", ""], ["Corley", "Courtney D.", ""], ["Hodas", "Nathan", ""]]}, {"id": "2104.03624", "submitter": "Kurt Willis", "authors": "Kurt Willis, Luis Oala", "title": "Post-Hoc Domain Adaptation via Guided Data Homogenization", "comments": "Published as a conference paper at ICLR 2021; 4 pages, plus appendix,\n  5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Addressing shifts in data distributions is an important prerequisite for the\ndeployment of deep learning models to real-world settings. A general approach\nto this problem involves the adjustment of models to a new domain through\ntransfer learning. However, in many cases, this is not applicable in a post-hoc\nmanner to deployed models and further parameter adjustments jeopardize safety\ncertifications that were established beforehand. In such a context, we propose\nto deal with changes in the data distribution via guided data homogenization\nwhich shifts the burden of adaptation from the model to the data. This approach\nmakes use of information about the training data contained implicitly in the\ndeep learning model to learn a domain transfer function. This allows for a\ntargeted deployment of models to unknown scenarios without changing the model\nitself. We demonstrate the potential of data homogenization through experiments\non the CIFAR-10 and MNIST data sets.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 09:18:48 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Willis", "Kurt", ""], ["Oala", "Luis", ""]]}, {"id": "2104.03760", "submitter": "Pierre Tassel", "authors": "Pierre Tassel, Martin Gebser, Konstantin Schekotihin", "title": "A Reinforcement Learning Environment For Job-Shop Scheduling", "comments": "7 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scheduling is a fundamental task occurring in various automated systems\napplications, e.g., optimal schedules for machines on a job shop allow for a\nreduction of production costs and waste. Nevertheless, finding such schedules\nis often intractable and cannot be achieved by Combinatorial Optimization\nProblem (COP) methods within a given time limit. Recent advances of Deep\nReinforcement Learning (DRL) in learning complex behavior enable new COP\napplication possibilities. This paper presents an efficient DRL environment for\nJob-Shop Scheduling -- an important problem in the field. Furthermore, we\ndesign a meaningful and compact state representation as well as a novel, simple\ndense reward function, closely related to the sparse make-span minimization\ncriteria used by COP methods. We demonstrate that our approach significantly\noutperforms existing DRL methods on classic benchmark instances, coming close\nto state-of-the-art COP approaches.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 13:26:30 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Tassel", "Pierre", ""], ["Gebser", "Martin", ""], ["Schekotihin", "Konstantin", ""]]}, {"id": "2104.03936", "submitter": "Achkan Salehi", "authors": "Achkan Salehi, Alexandre Coninx, Stephane Doncieux", "title": "BR-NS: an Archive-less Approach to Novelty Search", "comments": "Author version of the paper accepted at GECCO 21", "journal-ref": null, "doi": "10.1145/3449639.3459303", "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As open-ended learning based on divergent search algorithms such as Novelty\nSearch (NS) draws more and more attention from the research community, it is\nnatural to expect that its application to increasingly complex real-world\nproblems will require the exploration to operate in higher dimensional Behavior\nSpaces which will not necessarily be Euclidean. Novelty Search traditionally\nrelies on k-nearest neighbours search and an archive of previously visited\nbehavior descriptors which are assumed to live in a Euclidean space. This is\nproblematic because of a number of issues. On one hand, Euclidean distance and\nNearest-neighbour search are known to behave differently and become less\nmeaningful in high dimensional spaces. On the other hand, the archive has to be\nbounded since, memory considerations aside, the computational complexity of\nfinding nearest neighbours in that archive grows linearithmically with its\nsize. A sub-optimal bound can result in \"cycling\" in the behavior space, which\ninhibits the progress of the exploration. Furthermore, the performance of NS\ndepends on a number of algorithmic choices and hyperparameters, such as the\nstrategies to add or remove elements to the archive and the number of\nneighbours to use in k-nn search. In this paper, we discuss an alternative\napproach to novelty estimation, dubbed Behavior Recognition based Novelty\nSearch (BR-NS), which does not require an archive, makes no assumption on the\nmetrics that can be defined in the behavior space and does not rely on nearest\nneighbours search. We conduct experiments to gain insight into its feasibility\nand dynamics as well as potential advantages over archive-based NS in terms of\ntime complexity.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 17:31:34 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Salehi", "Achkan", ""], ["Coninx", "Alexandre", ""], ["Doncieux", "Stephane", ""]]}, {"id": "2104.04121", "submitter": "Angel Yanguas-Gil", "authors": "Angel Yanguas-Gil", "title": "Fast, Smart Neuromorphic Sensors Based on Heterogeneous Networks and\n  Mixed Encodings", "comments": "Paper accepted in GOMACTech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic architectures are ideally suited for the implementation of smart\nsensors able to react, learn, and respond to a changing environment. Our work\nuses the insect brain as a model to understand how heterogeneous architectures,\nincorporating different types of neurons and encodings, can be leveraged to\ncreate systems integrating input processing, evaluation, and response. Here we\nshow how the combination of time and rate encodings can lead to fast sensors\nthat are able to generate a hypothesis on the input in only a few cycles and\nthen use that hypothesis as secondary input for more detailed analysis.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 00:26:37 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Yanguas-Gil", "Angel", ""]]}, {"id": "2104.04254", "submitter": "Aymeric Vie", "authors": "Aymeric Vie", "title": "Population network structure impacts genetic algorithm optimisation\n  performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.PF cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A genetic algorithm (GA) is a search method that optimises a population of\nsolutions by simulating natural evolution. Good solutions reproduce together to\ncreate better candidates. The standard GA assumes that any two solutions can\nmate. However, in nature and social contexts, social networks can condition the\nlikelihood that two individuals mate. This impact of population network\nstructure over GAs performance is unknown. Here we introduce the Networked\nGenetic Algorithm (NGA) to evaluate how various random and scale-free\npopulation networks influence the optimisation performance of GAs on benchmark\nfunctions. We show evidence of significant variations in performance of the NGA\nas the network varies. In addition, we find that the best-performing population\nnetworks, characterised by intermediate density and low average shortest path\nlength, significantly outperform the standard complete network GA. These\nresults may constitute a starting point for network tuning and network control:\nseeing the network structure of the population as a parameter that can be tuned\nto improve the performance of evolutionary algorithms, and offer more realistic\nmodelling of social learning.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 09:06:04 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Vie", "Aymeric", ""]]}, {"id": "2104.04269", "submitter": "Leni Kenneth Le Goff", "authors": "L\\'eni K. Le Goff, Edgar Buchanan, Emma Hart, Agoston E. Eiben, Wei\n  Li, Matteo De Carlo, Alan F. Winfield, Matthew F. Hale, Robert Woolley, Mike\n  Angus, Jon Timmis, Andy M. Tyrrell", "title": "Morpho-evolution with learning using a controller archive as an\n  inheritance mechanism", "comments": "14 pages including 2 pages of supplementary materials, 14 figures, 1\n  table. Currently under review for the special issue of IEEE TCDS on Towards\n  autonomous evolution, (re)production and learning in robotic eco-systems.\n  https://www.york.ac.uk/robot-lab/are/ieee_special_issue_2020/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In evolutionary robotics, several approaches have been shown to be capable of\nthe joint optimisation of body-plans and controllers by either using only\nevolution or combining evolution and learning. When working in rich\nmorphological spaces, it is common for offspring to have body-plans that are\nvery different from either of their parents, which can cause difficulties with\nrespect to inheriting a suitable controller. To address this, we propose a\nframework that combines an evolutionary algorithm to generate body-plans and a\nlearning algorithm to optimise the parameters of a neural controller where the\ntopology of this controller is created once the body-plan of each offspring\nbody-plan is generated. The key novelty of the approach is to add an external\narchive for storing learned controllers that map to explicit `types' of robots\n(where this is defined with respect the features of the body-plan). By\ninheriting an appropriate controller from the archive rather than learning from\na randomly initialised one, we show that both the speed and magnitude of\nlearning increases over time when compared to an approach that starts from\nscratch, using three different test-beds. The framework also provides new\ninsights into the complex interactions between evolution and learning, and the\nrole of morphological intelligence in robot design.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 09:32:36 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Goff", "L\u00e9ni K. Le", ""], ["Buchanan", "Edgar", ""], ["Hart", "Emma", ""], ["Eiben", "Agoston E.", ""], ["Li", "Wei", ""], ["De Carlo", "Matteo", ""], ["Winfield", "Alan F.", ""], ["Hale", "Matthew F.", ""], ["Woolley", "Robert", ""], ["Angus", "Mike", ""], ["Timmis", "Jon", ""], ["Tyrrell", "Andy M.", ""]]}, {"id": "2104.04395", "submitter": "Amirhossein Rajabi", "authors": "Amirhossein Rajabi and Carsten Witt", "title": "Stagnation Detection in Highly Multimodal Fitness Landscapes", "comments": "28 pages. Full version of a paper appearing at GECCO 2021. arXiv\n  admin note: text overlap with arXiv:2101.12054", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stagnation detection has been proposed as a mechanism for randomized search\nheuristics to escape from local optima by automatically increasing the size of\nthe neighborhood to find the so-called gap size, i.e., the distance to the next\nimprovement. Its usefulness has mostly been considered in simple multimodal\nlandscapes with few local optima that could be crossed one after another. In\nmultimodal landscapes with a more complex location of optima of similar gap\nsize, stagnation detection suffers from the fact that the neighborhood size is\nfrequently reset to $1$ without using gap sizes that were promising in the\npast.\n  In this paper, we investigate a new mechanism called radius memory which can\nbe added to stagnation detection to control the search radius more carefully by\ngiving preference to values that were successful in the past. We implement this\nidea in an algorithm called SD-RLS$^{\\text{m}}$ and show compared to previous\nvariants of stagnation detection that it yields speed-ups for linear functions\nunder uniform constraints and the minimum spanning tree problem. Moreover, its\nrunning time does not significantly deteriorate on unimodal functions and a\ngeneralization of the Jump benchmark. Finally, we present experimental results\ncarried out to study SD-RLS$^{\\text{m}}$ and compare it with other algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 14:33:52 GMT"}, {"version": "v2", "created": "Fri, 16 Apr 2021 12:48:23 GMT"}, {"version": "v3", "created": "Thu, 22 Apr 2021 13:58:31 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Rajabi", "Amirhossein", ""], ["Witt", "Carsten", ""]]}, {"id": "2104.04657", "submitter": "Max Vladymyrov", "authors": "Mark Sandler and Max Vladymyrov and Andrey Zhmoginov and Nolan Miller\n  and Andrew Jackson and Tom Madams and Blaise Aguera y Arcas", "title": "Meta-Learning Bidirectional Update Rules", "comments": "ICML 2021, 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new type of generalized neural network where\nneurons and synapses maintain multiple states. We show that classical\ngradient-based backpropagation in neural networks can be seen as a special case\nof a two-state network where one state is used for activations and another for\ngradients, with update rules derived from the chain rule. In our generalized\nframework, networks have neither explicit notion of nor ever receive gradients.\nThe synapses and neurons are updated using a bidirectional Hebb-style update\nrule parameterized by a shared low-dimensional \"genome\". We show that such\ngenomes can be meta-learned from scratch, using either conventional\noptimization techniques, or evolutionary strategies, such as CMA-ES. Resulting\nupdate rules generalize to unseen tasks and train faster than gradient descent\nbased optimizers for several standard computer vision and synthetic tasks.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 00:56:35 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 21:13:25 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Sandler", "Mark", ""], ["Vladymyrov", "Max", ""], ["Zhmoginov", "Andrey", ""], ["Miller", "Nolan", ""], ["Jackson", "Andrew", ""], ["Madams", "Tom", ""], ["Arcas", "Blaise Aguera y", ""]]}, {"id": "2104.04710", "submitter": "Claudio Gallicchio", "authors": "Filippo Maria Bianchi, Claudio Gallicchio, Alessio Micheli", "title": "Pyramidal Reservoir Graph Neural Network", "comments": "this is a pre-print version of a paper submitted for journal\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose a deep Graph Neural Network (GNN) model that alternates two types\nof layers. The first type is inspired by Reservoir Computing (RC) and generates\nnew vertex features by iterating a non-linear map until it converges to a fixed\npoint. The second type of layer implements graph pooling operations, that\ngradually reduce the support graph and the vertex features, and further improve\nthe computational efficiency of the RC-based GNN. The architecture is,\ntherefore, pyramidal. In the last layer, the features of the remaining vertices\nare combined into a single vector, which represents the graph embedding.\nThrough a mathematical derivation introduced in this paper, we show formally\nhow graph pooling can reduce the computational complexity of the model and\nspeed-up the convergence of the dynamical updates of the vertex features. Our\nproposed approach to the design of RC-based GNNs offers an advantageous and\nprincipled trade-off between accuracy and complexity, which we extensively\ndemonstrate in experiments on a large set of graph datasets.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 08:34:09 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Bianchi", "Filippo Maria", ""], ["Gallicchio", "Claudio", ""], ["Micheli", "Alessio", ""]]}, {"id": "2104.04768", "submitter": "Alexandre Chenu", "authors": "Alexandre Chenu, Nicolas Perrin-Gilbert, St\\'ephane Doncieux, Olivier\n  Sigaud", "title": "Selection-Expansion: A Unifying Framework for Motion-Planning and\n  Diversity Search Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents need a reward signal to learn successful\npolicies. When this signal is sparse or the corresponding gradient is\ndeceptive, such agents need a dedicated mechanism to efficiently explore their\nsearch space without relying on the reward. Looking for a large diversity of\nbehaviors or using Motion Planning (MP) algorithms are two options in this\ncontext. In this paper, we build on the common roots between these two options\nto investigate the properties of two diversity search algorithms, the Novelty\nSearch and the Goal Exploration Process algorithms. These algorithms look for\ndiversity in an outcome space or behavioral space which is generally\nhand-designed to represent what matters for a given task. The relation to MP\nalgorithms reveals that the smoothness, or lack of smoothness of the mapping\nbetween the policy parameter space and the outcome space plays a key role in\nthe search efficiency. In particular, we show empirically that, if the mapping\nis smooth enough, i.e. if two close policies in the parameter space lead to\nsimilar outcomes, then diversity algorithms tend to inherit exploration\nproperties of MP algorithms. By contrast, if it is not, diversity algorithms\nlose these properties and their performance strongly depends on specific\nheuristics, notably filtering mechanisms that discard some of the explored\npolicies.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 13:52:27 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Chenu", "Alexandre", ""], ["Perrin-Gilbert", "Nicolas", ""], ["Doncieux", "St\u00e9phane", ""], ["Sigaud", "Olivier", ""]]}, {"id": "2104.04795", "submitter": "Anwesh Bhattacharya", "authors": "Urvil Nileshbhai Jivani, Omatharv Bharat Vaidya, Anwesh Bhattacharya,\n  Snehanshu Saha", "title": "A Swarm Variant for the Schr\\\"odinger Solver", "comments": "8 pages, 5 figures, Accepted at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces application of the Exponentially Averaged Momentum\nParticle Swarm Optimization (EM-PSO) as a derivative-free optimizer for Neural\nNetworks. It adopts PSO's major advantages such as search space exploration and\nhigher robustness to local minima compared to gradient-descent optimizers such\nas Adam. Neural network based solvers endowed with gradient optimization are\nnow being used to approximate solutions to Differential Equations. Here, we\ndemonstrate the novelty of EM-PSO in approximating gradients and leveraging the\nproperty in solving the Schr\\\"odinger equation, for the Particle-in-a-Box\nproblem. We also provide the optimal set of hyper-parameters supported by\nmathematical proofs, suited for our algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 15:51:36 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 12:58:32 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Jivani", "Urvil Nileshbhai", ""], ["Vaidya", "Omatharv Bharat", ""], ["Bhattacharya", "Anwesh", ""], ["Saha", "Snehanshu", ""]]}, {"id": "2104.04945", "submitter": "Tomasz Szandala", "authors": "Tomasz Szandala", "title": "Enhancing Deep Neural Network Saliency Visualizations with Gradual\n  Extrapolation", "comments": "Published in IEEE Access:\n  https://ieeexplore.ieee.org/document/9468713", "journal-ref": "IEEE Access, 2021", "doi": "10.1109/ACCESS.2021.3093824", "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, an enhancement technique for the class activation mapping\nmethods such as gradient-weighted class activation maps or excitation\nbackpropagation is proposed to present the visual explanations of decisions\nfrom convolutional neural network-based models. The proposed idea, called\nGradual Extrapolation, can supplement any method that generates a heatmap\npicture by sharpening the output. Instead of producing a coarse localization\nmap that highlights the important predictive regions in the image, the proposed\nmethod outputs the specific shape that most contributes to the model output.\nThus, the proposed method improves the accuracy of saliency maps. The effect\nhas been achieved by the gradual propagation of the crude map obtained in the\ndeep layer through all preceding layers with respect to their activations. In\nvalidation tests conducted on a selected set of images, the faithfulness,\ninterpretability, and applicability of the method are evaluated. The proposed\ntechnique significantly improves the localization detection of the neural\nnetworks attention at low additional computational costs. Furthermore, the\nproposed method is applicable to a variety deep neural network models. The code\nfor the method can be found at\nhttps://github.com/szandala/gradual-extrapolation\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 07:39:35 GMT"}, {"version": "v2", "created": "Sun, 27 Jun 2021 21:37:11 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 15:30:26 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Szandala", "Tomasz", ""]]}, {"id": "2104.05048", "submitter": "Konstantinos Makantasis", "authors": "Konstantinos Makantasis, Alexandros Georgogiannis, Athanasios\n  Voulodimos, Ioannis Georgoulas, Anastasios Doulamis, Nikolaos Doulamis", "title": "Rank-R FNN: A Tensor-Based Learning Model for High-Order Data\n  Classification", "comments": "12 pages, 5 figures, 4 tables, Accepted for publication to IEEE\n  Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An increasing number of emerging applications in data science and engineering\nare based on multidimensional and structurally rich data. The irregularities,\nhowever, of high-dimensional data often compromise the effectiveness of\nstandard machine learning algorithms. We hereby propose the Rank-R Feedforward\nNeural Network (FNN), a tensor-based nonlinear learning model that imposes\nCanonical/Polyadic decomposition on its parameters, thereby offering two core\nadvantages compared to typical machine learning methods. First, it handles\ninputs as multilinear arrays, bypassing the need for vectorization, and can\nthus fully exploit the structural information along every data dimension.\nMoreover, the number of the model's trainable parameters is substantially\nreduced, making it very efficient for small sample setting problems. We\nestablish the universal approximation and learnability properties of Rank-R\nFNN, and we validate its performance on real-world hyperspectral datasets.\nExperimental evaluations show that Rank-R FNN is a computationally inexpensive\nalternative of ordinary FNN that achieves state-of-the-art performance on\nhigher-order tensor data.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 16:37:32 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Makantasis", "Konstantinos", ""], ["Georgogiannis", "Alexandros", ""], ["Voulodimos", "Athanasios", ""], ["Georgoulas", "Ioannis", ""], ["Doulamis", "Anastasios", ""], ["Doulamis", "Nikolaos", ""]]}, {"id": "2104.05089", "submitter": "Bjorn Lutjens", "authors": "Salva R\\\"uhling Cachay, Emma Erickson, Arthur Fender C. Bucker, Ernest\n  Pokropek, Willa Potosnak, Suyash Bire, Salomey Osei, Bj\\\"orn L\\\"utjens", "title": "The World as a Graph: Improving El Ni\\~no Forecasts with Graph Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE physics.ao-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning-based models have recently outperformed state-of-the-art\nseasonal forecasting models, such as for predicting El Ni\\~no-Southern\nOscillation (ENSO). However, current deep learning models are based on\nconvolutional neural networks which are difficult to interpret and can fail to\nmodel large-scale atmospheric patterns. In comparison, graph neural networks\n(GNNs) are capable of modeling large-scale spatial dependencies and are more\ninterpretable due to the explicit modeling of information flow through edge\nconnections. We propose the first application of graph neural networks to\nseasonal forecasting. We design a novel graph connectivity learning module that\nenables our GNN model to learn large-scale spatial interactions jointly with\nthe actual ENSO forecasting task. Our model, \\graphino, outperforms\nstate-of-the-art deep learning-based models for forecasts up to six months\nahead. Additionally, we show that our model is more interpretable as it learns\nsensible connectivity structures that correlate with the ENSO anomaly pattern.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 19:55:55 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 20:57:30 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Cachay", "Salva R\u00fchling", ""], ["Erickson", "Emma", ""], ["Bucker", "Arthur Fender C.", ""], ["Pokropek", "Ernest", ""], ["Potosnak", "Willa", ""], ["Bire", "Suyash", ""], ["Osei", "Salomey", ""], ["L\u00fctjens", "Bj\u00f6rn", ""]]}, {"id": "2104.05225", "submitter": "Won-Yong Shin", "authors": "Yong-Min Shin, Cong Tran, Won-Yong Shin, Xin Cao", "title": "Edgeless-GNN: Unsupervised Inductive Edgeless Network Embedding", "comments": "14 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IT cs.LG cs.NE math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the problem of embedding edgeless nodes such as users who newly\nenter the underlying network, while using graph neural networks (GNNs) widely\nstudied for effective representation learning of graphs thanks to its highly\nexpressive capability via message passing. Our study is motivated by the fact\nthat existing GNNs cannot be adopted for our problem since message passing to\nsuch edgeless nodes having no connections is impossible. To tackle this\nchallenge, we propose Edgeless-GNN, a new framework that enables GNNs to\ngenerate node embeddings even for edgeless nodes through unsupervised inductive\nlearning. Specifically, we start by constructing a $k$-nearest neighbor graph\n($k$NNG) based on the similarity of node attributes to replace the GNN's\ncomputation graph defined by the neighborhood-based aggregation of each node.\nAs our main contributions, the known network structure is used to train model\nparameters, while a new loss function is established using energy-based\nlearning in such a way that our model learns the network structure. For the\nedgeless nodes, we inductively infer embeddings for the edgeless nodes by using\nedges via $k$NNG construction as a computation graph. By evaluating the\nperformance of various downstream machine learning (ML) tasks, we empirically\ndemonstrate that Edgeless-GNN consistently outperforms state-of-the-art methods\nof inductive network embedding. Moreover, our findings corroborate the\neffectiveness of Edgeless-GNN in judiciously combining the replaced computation\ngraph with our newly designed loss. Our framework is GNN-model-agnostic; thus,\nGNN models can be appropriately chosen according to ones' needs and ML tasks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 06:37:31 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 05:30:09 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Shin", "Yong-Min", ""], ["Tran", "Cong", ""], ["Shin", "Won-Yong", ""], ["Cao", "Xin", ""]]}, {"id": "2104.05241", "submitter": "Matteo Cartiglia", "authors": "Matteo Cartiglia, Germain Haessig, Giacomo Indiveri", "title": "An error-propagation spiking neural network compatible with neuromorphic\n  processors", "comments": "2020 2nd IEEE International Conference on Artificial Intelligence\n  Circuits and Systems (AICAS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spiking neural networks have shown great promise for the design of low-power\nsensory-processing and edge-computing hardware platforms. However, implementing\non-chip learning algorithms on such architectures is still an open challenge,\nespecially for multi-layer networks that rely on the back-propagation\nalgorithm. In this paper, we present a spike-based learning method that\napproximates back-propagation using local weight update mechanisms and which is\ncompatible with mixed-signal analog/digital neuromorphic circuits. We introduce\na network architecture that enables synaptic weight update mechanisms to\nback-propagate error signals across layers and present a network that can be\ntrained to distinguish between two spike-based patterns that have identical\nmean firing rates, but different spike-timings. This work represents a first\nstep towards the design of ultra-low power mixed-signal neuromorphic processing\nsystems with on-chip learning circuits that can be trained to recognize\ndifferent spatio-temporal patterns of spiking activity (e.g. produced by\nevent-based vision or auditory sensors).\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 07:21:08 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Cartiglia", "Matteo", ""], ["Haessig", "Germain", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "2104.05401", "submitter": "Alexander Hadjiivanov", "authors": "Alexander Hadjiivanov", "title": "Adaptive conversion of real-valued input into spike trains", "comments": "8 pages", "journal-ref": "2016 International Joint Conference on Neural Networks", "doi": "10.1109/IJCNN.2016.7727314", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a biologically plausible method for converting\nreal-valued input into spike trains for processing with spiking neural\nnetworks. The proposed method mimics the adaptive behaviour of retinal ganglion\ncells and allows input neurons to adapt their response to changes in the\nstatistics of the input. Thus, rather than passively receiving values and\nforwarding them to the hidden and output layers, the input layer acts as a\nself-regulating filter which emphasises deviations from the average while\nallowing the input neurons to become effectively desensitised to the average\nitself. Another merit of the proposed method is that it requires only one input\nneuron per variable, rather than an entire population of neurons as in the case\nof the commonly used conversion method based on Gaussian receptive fields. In\naddition, since the statistics of the input emerge naturally over time, it\nbecomes unnecessary to pre-process the data before feeding it to the network.\nThis enables spiking neural networks to process raw, non-normalised streaming\ndata. A proof-of-concept experiment is performed to demonstrate that the\nproposed method operates as expected.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 12:33:52 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Hadjiivanov", "Alexander", ""]]}, {"id": "2104.05402", "submitter": "Pavel Kuptsov", "authors": "Pavel V. Kuptsov, Anna V. Kuptsova, Nataliya V. Stankevich", "title": "Artificial neural network as a universal model of nonlinear dynamical\n  systems", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.NE nlin.AO nlin.CD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We suggest a universal map capable to recover a behavior of a wide range of\ndynamical systems given by ODEs. The map is built as an artificial neural\nnetwork whose weights encode a modeled system. We assume that ODEs are known\nand prepare training datasets using the equations directly without computing\nnumerical time series. Parameter variations are taken into account in the\ncourse of training so that the network model captures bifurcation scenarios of\nthe modeled system. Theoretical benefit from this approach is that the\nuniversal model admits using common mathematical methods without needing to\ndevelop a unique theory for each particular dynamical equations. Form the\npractical point of view the developed method can be considered as an\nalternative numerical method for solving dynamical ODEs suitable for running on\ncontemporary neural network specific hardware. We consider the Lorenz system,\nthe Roessler system and also Hindmarch-Rose neuron. For these three examples\nthe network model is created and its dynamics is compared with ordinary\nnumerical solutions. High similarity is observed for visual images of\nattractors, power spectra, bifurcation diagrams and Lyapunov exponents.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2021 16:02:41 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Kuptsov", "Pavel V.", ""], ["Kuptsova", "Anna V.", ""], ["Stankevich", "Nataliya V.", ""]]}, {"id": "2104.05411", "submitter": "Alexander Hadjiivanov", "authors": "Alexander Hadjiivanov and Alan Blair", "title": "Epigenetic evolution of deep convolutional models", "comments": "8 pages", "journal-ref": "2019 IEEE Congress on Evolutionary Computation (CEC)", "doi": "10.1109/CEC.2019.8790327", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we build upon a previously proposed neuroevolution framework\nto evolve deep convolutional models. Specifically, the genome encoding and the\ncrossover operator are extended to make them applicable to layered networks. We\nalso propose a convolutional layer layout which allows kernels of different\nshapes and sizes to coexist within the same layer, and present an argument as\nto why this may be beneficial. The proposed layout enables the size and shape\nof individual kernels within a convolutional layer to be evolved with a\ncorresponding new mutation operator. The proposed framework employs a hybrid\noptimisation strategy involving structural changes through epigenetic evolution\nand weight update through backpropagation in a population-based setting.\nExperiments on several image classification benchmarks demonstrate that the\ncrossover operator is sufficiently robust to produce increasingly performant\noffspring even when the parents are trained on only a small random subset of\nthe training dataset in each epoch, thus providing direct confirmation that\nlearned features and behaviour can be successfully transferred from parent\nnetworks to offspring in the next generation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 12:45:16 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Hadjiivanov", "Alexander", ""], ["Blair", "Alan", ""]]}, {"id": "2104.05435", "submitter": "Ruixuan Yan", "authors": "Ruixuan Yan, Agung Julius", "title": "Neural Network for Weighted Signal Temporal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a neuro-symbolic framework called weighted Signal\nTemporal Logic Neural Network (wSTL-NN) that combines the characteristics of\nneural networks and temporal logics. Weighted Signal Temporal Logic (wSTL)\nformulas are recursively composed of subformulas that are combined using\nlogical and temporal operators. The quantitative semantics of wSTL is defined\nsuch that the quantitative satisfaction of subformulas with higher weights has\nmore influence on the quantitative satisfaction of the overall wSTL formula. In\nthe wSTL-NN, each neuron corresponds to a wSTL subformula, and its output\ncorresponds to the quantitative satisfaction of the formula. We use wSTL-NN to\nrepresent wSTL formulas as features to classify time series data. STL features\nare more explainable than those used in classical methods. The wSTL-NN is\nend-to-end differentiable, which allows learning of wSTL formulas to be done\nusing back-propagation. To reduce the number of weights, we introduce two\ntechniques to sparsify the wSTL-NN.We apply our framework to an occupancy\ndetection time-series dataset to learn a classifier that predicts the occupancy\nstatus of an office room.\n", "versions": [{"version": "v1", "created": "Thu, 8 Apr 2021 20:44:26 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Yan", "Ruixuan", ""], ["Julius", "Agung", ""]]}, {"id": "2104.05448", "submitter": "Bing Zha", "authors": "Bing Zha, Alessandro Vanni, Yassin Hassan, Tunc Aldemir, Alper Yilmaz", "title": "Deep Transformer Networks for Time Series Classification: The NPP Safety\n  Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  A challenging part of dynamic probabilistic risk assessment for nuclear power\nplants is the need for large amounts of temporal simulations given various\ninitiating events and branching conditions from which representative feature\nextraction becomes complicated for subsequent applications. Artificial\nIntelligence techniques have been shown to be powerful tools in time-dependent\nsequential data processing to automatically extract and yield complex features\nfrom large data. An advanced temporal neural network referred to as the\nTransformer is used within a supervised learning fashion to model the\ntime-dependent NPP simulation data and to infer whether a given sequence of\nevents leads to core damage or not. The training and testing datasets for the\nTransformer are obtained by running 10,000 RELAP5-3D NPP blackout simulations\nwith the list of variables obtained from the RAVEN software. Each simulation is\nclassified as \"OK\" or \"CORE DAMAGE\" based on the consequence. The results show\nthat the Transformer can learn the characteristics of the sequential data and\nyield promising performance with approximately 99% classification accuracy on\nthe testing dataset.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 14:26:25 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 12:41:36 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Zha", "Bing", ""], ["Vanni", "Alessandro", ""], ["Hassan", "Yassin", ""], ["Aldemir", "Tunc", ""], ["Yilmaz", "Alper", ""]]}, {"id": "2104.05610", "submitter": "Daan Klijn", "authors": "Daan Klijn, A.E. Eiben", "title": "A coevolutionary approach to deep multi-agent reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, Deep Artificial Neural Networks (DNN's) are trained through\ngradient descent. Recent research shows that Deep Neuroevolution (DNE) is also\ncapable of evolving multi-million-parameter DNN's, which proved to be\nparticularly useful in the field of Reinforcement Learning (RL). This is mainly\ndue to its excellent scalability and simplicity compared to the traditional\nMDP-based RL methods. So far, DNE has only been applied to complex single-agent\nproblems. As evolutionary methods are a natural choice for multi-agent\nproblems, the question arises whether DNE can also be applied in a complex\nmulti-agent setting. In this paper, we describe and validate a new approach\nbased on Coevolution. To validate our approach, we benchmark two Deep\nCoevolutionary Algorithms on a range of multi-agent Atari games and compare our\nresults against the results of Ape-X DQN. Our results show that these Deep\nCoevolutionary algorithms (1) can be successfully trained to play various\ngames, (2) outperform Ape-X DQN in some of them, and therefore (3) show that\nCoevolution can be a viable approach to solving complex multi-agent\ndecision-making problems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 16:30:03 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 10:07:16 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Klijn", "Daan", ""], ["Eiben", "A. E.", ""]]}, {"id": "2104.05624", "submitter": "Mario Alejandro Hevia Fajardo", "authors": "Mario Alejandro Hevia Fajardo and Dirk Sudholt", "title": "Self-Adjusting Population Sizes for Non-Elitist Evolutionary Algorithms:\n  Why Success Rates Matter", "comments": "To appear at GECCO 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent theoretical studies have shown that self-adjusting mechanisms can\nprovably outperform the best static parameters in evolutionary algorithms on\ndiscrete problems. However, the majority of these studies concerned elitist\nalgorithms and we do not have a clear answer on whether the same mechanisms can\nbe applied for non-elitist algorithms.\n  We study one of the best-known parameter control mechanisms, the one-fifth\nsuccess rule, to control the offspring population size $\\lambda$ in the\nnon-elitist ${(1 , \\lambda)}$ EA. It is known that the ${(1 , \\lambda)}$ EA has\na sharp threshold with respect to the choice of $\\lambda$ where the runtime on\nOneMax changes from polynomial to exponential time. Hence, it is not clear\nwhether parameter control mechanisms are able to find and maintain suitable\nvalues of $\\lambda$.\n  We show that the answer crucially depends on the success rate $s$ (i.,e. a\none-$(s+1)$-th success rule). We prove that, if the success rate is\nappropriately small, the self-adjusting ${(1 , \\lambda)}$ EA optimises OneMax\nin $O(n)$ expected generations and $O(n \\log n)$ expected evaluations. A small\nsuccess rate is crucial: we also show that if the success rate is too large,\nthe algorithm has an exponential runtime on OneMax.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2021 16:44:54 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Fajardo", "Mario Alejandro Hevia", ""], ["Sudholt", "Dirk", ""]]}, {"id": "2104.05878", "submitter": "James Martens", "authors": "James Martens", "title": "On the validity of kernel approximations for orthogonally-initialized\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we extend kernel function approximation results for neural\nnetworks with Gaussian-distributed weights to single-layer networks initialized\nusing Haar-distributed random orthogonal matrices (with possible rescaling).\nThis is accomplished using recent results from random matrix theory.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 00:57:39 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Martens", "James", ""]]}, {"id": "2104.05926", "submitter": "Darshit Mehta", "authors": "Darshit Mehta, Kenji Aono and Shantanu Chakrabartty", "title": "An Adaptive Synaptic Array using Fowler-Nordheim Dynamic Analog Memory", "comments": "22 pages (incl. 7 supplementary pages), 11 figures (incl. 6\n  supplementary figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a synaptic array that uses dynamical states to\nimplement an analog memory for energy-efficient training of machine learning\n(ML) systems. Each of the analog memory elements is a micro-dynamical system\nthat is driven by the physics of Fowler-Nordheim (FN) quantum tunneling,\nwhereas the system level learning modulates the state trajectory of the memory\nensembles towards the optimal solution. We show that the extrinsic energy\nrequired for modulation can be matched to the dynamics of learning and weight\ndecay leading to a significant reduction in the energy-dissipated during ML\ntraining. With the energy-dissipation as low as 5 fJ per memory update and a\nprogramming resolution up to 14 bits, the proposed synapse array could be used\nto address the energy-efficiency imbalance between the training and the\ninference phases observed in artificial intelligence (AI) systems.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 04:08:04 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Mehta", "Darshit", ""], ["Aono", "Kenji", ""], ["Chakrabartty", "Shantanu", ""]]}, {"id": "2104.05929", "submitter": "Mohammad Nazmul Haque", "authors": "Pablo Moscato, Hugh Craig, Gabriel Egan, Mohammad Nazmul Haque, Kevin\n  Huang, Julia Sloan, Jon Corrales de Oliveira", "title": "Multiple regression techniques for modeling dates of first performances\n  of Shakespeare-era plays", "comments": "Submitted to Expert Systems with Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The date of the first performance of a play of Shakespeare's time must\nusually be guessed with reference to multiple indirect external sources, or to\nsome aspect of the content or style of the play. Identifying these dates is\nimportant to literary history and to accounts of developing authorial styles,\nsuch as Shakespeare's. In this study, we took a set of Shakespeare-era plays\n(181 plays from the period 1585--1610), added the best-guess dates for them\nfrom a standard reference work as metadata, and calculated a set of\nprobabilities of individual words in these samples. We applied 11 regression\nmethods to predict the dates of the plays at an 80/20 training/test split. We\nwithdrew one play at a time, used the best-guess date metadata with the\nprobabilities and weightings to infer its date, and thus built a model of\ndate-probabilities interaction. We introduced a memetic algorithm-based\nContinued Fraction Regression (CFR) which delivered models using a small number\nof variables, leading to an interpretable model and reduced dimensionality. An\nin-depth analysis of the most commonly occurring 20 words in the CFR models in\n100 independent runs helps explain the trends in linguistic and stylistic\nterms. The analysis with the subset of words revealed an interesting\ncorrelation of signature words with the Shakespeare-era play's genre.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 04:13:53 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 23:37:45 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Moscato", "Pablo", ""], ["Craig", "Hugh", ""], ["Egan", "Gabriel", ""], ["Haque", "Mohammad Nazmul", ""], ["Huang", "Kevin", ""], ["Sloan", "Julia", ""], ["de Oliveira", "Jon Corrales", ""]]}, {"id": "2104.05989", "submitter": "Swapna Sasi", "authors": "Mahak Kothari, Swapna Sasi, Jun Chen, Elham Zareian, Basabdatta Sen\n  Bhattacharya", "title": "Bayesian Optimisation for a Biologically Inspired Population Neural\n  Network", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We have used Bayesian Optimisation (BO) to find hyper-parameters in an\nexisting biologically plausible population neural network. The 8-dimensional\noptimal hyper-parameter combination should be such that the network dynamics\nsimulate the resting state alpha rhythm (8 - 13 Hz rhythms in brain signals).\nEach combination of these eight hyper-parameters constitutes a 'datapoint' in\nthe parameter space. The best combination of these parameters leads to the\nneural network's output power spectral peak being constraint within the alpha\nband. Further, constraints were introduced to the BO algorithm based on\nqualitative observation of the network output time series, so that high\namplitude pseudo-periodic oscillations are removed. Upon successful\nimplementation for alpha band, we further optimised the network to oscillate\nwithin the theta (4 - 8 Hz) and beta (13 - 30 Hz) bands. The changing rhythms\nin the model can now be studied using the identified optimal hyper-parameters\nfor the respective frequency bands. We have previously tuned parameters in the\nexisting neural network by the trial-and-error approach; however, due to time\nand computational constraints, we could not vary more than three parameters at\nonce. The approach detailed here, allows an automatic hyper-parameter search,\nproducing reliable parameter sets for the network.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 07:48:42 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Kothari", "Mahak", ""], ["Sasi", "Swapna", ""], ["Chen", "Jun", ""], ["Zareian", "Elham", ""], ["Bhattacharya", "Basabdatta Sen", ""]]}, {"id": "2104.06010", "submitter": "Timothy Praditia", "authors": "Timothy Praditia, Matthias Karlbauer, Sebastian Otte, Sergey\n  Oladyshkin, Martin V. Butz, Wolfgang Nowak", "title": "Finite Volume Neural Network: Modeling Subsurface Contaminant Transport", "comments": "Published as a workshop paper at ICLR 2021 SimDL Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data-driven modeling of spatiotemporal physical processes with general deep\nlearning methods is a highly challenging task. It is further exacerbated by the\nlimited availability of data, leading to poor generalizations in standard\nneural network models. To tackle this issue, we introduce a new approach called\nthe Finite Volume Neural Network (FINN). The FINN method adopts the numerical\nstructure of the well-known Finite Volume Method for handling partial\ndifferential equations, so that each quantity of interest follows its own\nadaptable conservation law, while it concurrently accommodates learnable\nparameters. As a result, FINN enables better handling of fluxes between control\nvolumes and therefore proper treatment of different types of numerical boundary\nconditions. We demonstrate the effectiveness of our approach with a subsurface\ncontaminant transport problem, which is governed by a non-linear\ndiffusion-sorption process. FINN does not only generalize better to differing\nboundary conditions compared to other methods, it is also capable to explicitly\nextract and learn the constitutive relationships (expressed by the retardation\nfactor). More importantly, FINN shows excellent generalization ability when\napplied to both synthetic datasets and real, sparse experimental data, thus\nunderlining its relevance as a data-driven modeling tool.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 08:23:44 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Praditia", "Timothy", ""], ["Karlbauer", "Matthias", ""], ["Otte", "Sebastian", ""], ["Oladyshkin", "Sergey", ""], ["Butz", "Martin V.", ""], ["Nowak", "Wolfgang", ""]]}, {"id": "2104.06060", "submitter": "Marco Virgolin", "authors": "Marco Virgolin, Andrea De Lorenzo, Francesca Randone, Eric Medvet,\n  Mattias Wahde", "title": "Model Learning with Personalized Interpretability Estimation (ML-PIE)", "comments": "fix typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-stakes applications require AI-generated models to be interpretable.\nCurrent algorithms for the synthesis of potentially interpretable models rely\non objectives or regularization terms that represent interpretability only\ncoarsely (e.g., model size) and are not designed for a specific user. Yet,\ninterpretability is intrinsically subjective. In this paper, we propose an\napproach for the synthesis of models that are tailored to the user by enabling\nthe user to steer the model synthesis process according to her or his\npreferences. We use a bi-objective evolutionary algorithm to synthesize models\nwith trade-offs between accuracy and a user-specific notion of\ninterpretability. The latter is estimated by a neural network that is trained\nconcurrently to the evolution using the feedback of the user, which is\ncollected using uncertainty-based active learning. To maximize usability, the\nuser is only asked to tell, given two models at the time, which one is less\ncomplex. With experiments on two real-world datasets involving 61 participants,\nwe find that our approach is capable of learning estimations of\ninterpretability that can be very different for different users. Moreover, the\nusers tend to prefer models found using the proposed approach over models found\nusing non-personalized interpretability indices.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 09:47:48 GMT"}, {"version": "v2", "created": "Wed, 14 Apr 2021 10:43:12 GMT"}, {"version": "v3", "created": "Tue, 27 Apr 2021 08:52:36 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Virgolin", "Marco", ""], ["De Lorenzo", "Andrea", ""], ["Randone", "Francesca", ""], ["Medvet", "Eric", ""], ["Wahde", "Mattias", ""]]}, {"id": "2104.06135", "submitter": "Nis Meinert", "authors": "Nis Meinert and Alexander Lavin", "title": "Multivariate Deep Evidential Regression", "comments": "20 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is significant need for principled uncertainty reasoning in machine\nlearning systems as they are increasingly deployed in safety-critical domains.\nA new approach with uncertainty-aware neural networks (NNs), based on learning\nevidential distributions for aleatoric and epistemic uncertainties, shows\npromise over traditional deterministic methods and typical Bayesian NNs, yet\nseveral important gaps in the theory and implementation of these networks\nremain. We discuss three issues with a proposed solution to extract aleatoric\nand epistemic uncertainties from regression-based neural networks. The approach\nderives a technique by placing evidential priors over the original Gaussian\nlikelihood function and training the NN to infer the hyperparameters of the\nevidential distribution. Doing so allows for the simultaneous extraction of\nboth uncertainties without sampling or utilization of out-of-distribution data\nfor univariate regression tasks. We describe the outstanding issues in detail,\nprovide a possible solution, and generalize the deep evidential regression\ntechnique for multivariate cases.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 12:20:18 GMT"}, {"version": "v2", "created": "Thu, 15 Apr 2021 12:47:38 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 07:41:18 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Meinert", "Nis", ""], ["Lavin", "Alexander", ""]]}, {"id": "2104.06368", "submitter": "David Yevick", "authors": "David Yevick", "title": "Variational Autoencoder Analysis of Ising Model Statistical\n  Distributions and Phase Transitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Variational autoencoders employ an encoding neural network to generate a\nprobabilistic representation of a data set within a low-dimensional space of\nlatent variables followed by a decoding stage that maps the latent variables\nback to the original variable space. Once trained, a statistical ensemble of\nsimulated data realizations can be obtained by randomly assigning values to the\nlatent variables that are subsequently processed by the decoding section of the\nnetwork. To determine the accuracy of such a procedure when applied to lattice\nmodels, an autoencoder is here trained on a thermal equilibrium distribution of\nIsing spin realizations. When the output of the decoder for synthetic data is\ninterpreted probabilistically, spin realizations can be generated by randomly\nassigning spin values according to the computed likelihood. The resulting state\ndistribution in energy-magnetization space then qualitatively resembles that of\nthe training samples. However, because correlations between spins are\nsuppressed, the computed energies are unphysically large for low-dimensional\nlatent variable spaces. The features of the learned distributions as a function\nof temperature, however, provide a qualitative indication of the presence of a\nphase transition and the distribution of realizations with characteristic\ncluster sizes.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 17:24:19 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Yevick", "David", ""]]}, {"id": "2104.06399", "submitter": "Weijian Xu", "authors": "Weijian Xu, Yifan Xu, Tyler Chang, Zhuowen Tu", "title": "Co-Scale Conv-Attentional Image Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present Co-scale conv-attentional image Transformers\n(CoaT), a Transformer-based image classifier equipped with co-scale and\nconv-attentional mechanisms. First, the co-scale mechanism maintains the\nintegrity of Transformers' encoder branches at individual scales, while\nallowing representations learned at different scales to effectively communicate\nwith each other; we design a series of serial and parallel blocks to realize\nthe co-scale attention mechanism. Second, we devise a conv-attentional\nmechanism by realizing a relative position embedding formulation in the\nfactorized attention module with an efficient convolution-like implementation.\nCoaT empowers image Transformers with enriched multi-scale and contextual\nmodeling capabilities. On ImageNet, relatively small CoaT models attain\nsuperior classification results compared with the similar-sized convolutional\nneural networks and image/vision Transformers. The effectiveness of CoaT's\nbackbone is also illustrated on object detection and instance segmentation,\ndemonstrating its applicability to the downstream computer vision tasks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 17:58:29 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Xu", "Weijian", ""], ["Xu", "Yifan", ""], ["Chang", "Tyler", ""], ["Tu", "Zhuowen", ""]]}, {"id": "2104.06510", "submitter": "Pedro Henrique Suruagy Perrusi", "authors": "Pedro Henrique Suruagy Perrusi, Anna Cazzaniga, Paul Baksic, Eleonora\n  Tagliabue, Elena de Momi, Hadrien Courtecuisse", "title": "Robotic needle steering in deformable tissues with extreme learning\n  machines", "comments": null, "journal-ref": "AUTOMED 2021, Jun 2021, Basel, Switzerland", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control strategies for robotic needle steering in soft tissues must account\nfor complex interactions between the needle and the tissue to achieve accurate\nneedle tip positioning. Recent findings show faster robotic command rate can\nimprove the control stability in realistic scenarios. This study proposes the\nuse of Extreme Learning Machines to provide fast commands for robotic needle\nsteering. A synthetic dataset based on the inverse finite element simulation\ncontrol framework is used to train the model. Results show the model is capable\nto infer commands 66% faster than the inverse simulation and reaches acceptable\nprecision even on previously unseen trajectories.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 07:04:29 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Perrusi", "Pedro Henrique Suruagy", ""], ["Cazzaniga", "Anna", ""], ["Baksic", "Paul", ""], ["Tagliabue", "Eleonora", ""], ["de Momi", "Elena", ""], ["Courtecuisse", "Hadrien", ""]]}, {"id": "2104.06585", "submitter": "Hao Tong", "authors": "Hao Tong, Leandro L. Minku, Stefan Menzel, Bernhard Sendhoff, Xin Yao", "title": "A Novel Generalised Meta-Heuristic Framework for Dynamic Capacitated Arc\n  Routing Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capacitated arc routing problem (CARP) is a challenging combinatorial\noptimisation problem abstracted from typical real-world applications, like\nwaste collection and mail delivery. However, few studies considered dynamic\nchanges during the vehicles' service, which can make the original schedule\ninfeasible or obsolete. The few existing studies are limited by dynamic\nscenarios that can suffer single types of dynamic events, and by algorithms\nthat rely on special operators or representations, being unable to benefit from\nthe wealth of contributions provided by the static CARP literature. Here, we\nprovide the first mathematical formulation for dynamic CARP (DCARP) and design\na simulation system to execute the CARP solutions and generate DCARP instances\nwith several common dynamic events. We then propose a novel framework able to\ngeneralise all existing static CARP optimisation algorithms so that they can\ncope with DCARP instances. The framework has the option to enhance optimisation\nperformance for DCARP instances based on a restart strategy that makes no use\nof past history, and a sequence transfer strategy that benefits from past\noptimisation experience. Empirical studies are conducted on a wide range of\nDCARP instances. The results highlight the need for tackling dynamic changes\nand show that the proposed framework significantly improves over existing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 02:13:35 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Tong", "Hao", ""], ["Minku", "Leandro L.", ""], ["Menzel", "Stefan", ""], ["Sendhoff", "Bernhard", ""], ["Yao", "Xin", ""]]}, {"id": "2104.06714", "submitter": "Denis Antipov", "authors": "Denis Antipov, Maxim Buzdalov, Benjamin Doerr", "title": "Lazy Parameter Tuning and Control: Choosing All Parameters Randomly From\n  a Power-Law Distribution", "comments": "Extended version of the paper accepted to GECCO 2021, including all\n  the proofs omitted in the conference version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most evolutionary algorithms have multiple parameters and their values\ndrastically affect the performance. Due to the often complicated interplay of\nthe parameters, setting these values right for a particular problem (parameter\ntuning) is a challenging task . This task becomes even more complicated when\nthe optimal parameter values change significantly during the run of the\nalgorithm since then a dynamic parameter choice (parameter control) is\nnecessary.\n  In this work, we propose a lazy but effective solution, namely choosing all\nparameter values (where this makes sense) in each iteration randomly from a\nsuitably scaled power-law distribution. To demonstrate the effectiveness of\nthis approach, we perform runtime analyses of the $(1+(\\lambda,\\lambda))$\ngenetic algorithm with all three parameters chosen in this manner. We show this\nalgorithm on the one hand can imitate simple hill-climbers like the $(1+1)$ EA,\ngiving the same asymptotic runtime on problems like OneMax, LeadingOnes, or\nMinimum Spanning Tree. On the other hand, this algorithm is also very efficient\non jump functions, where the best static parameters are very different from\nthose necessary to optimize simple problems. We prove a performance guarantee\nthat is comparable, sometimes even better, than the best performance known for\nstatic parameters. We complement our theoretical results with a rigorous\nempirical study confirming what the asymptotic runtime results suggest.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 09:17:18 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Antipov", "Denis", ""], ["Buzdalov", "Maxim", ""], ["Doerr", "Benjamin", ""]]}, {"id": "2104.06831", "submitter": "Weijie Zheng", "authors": "Weijie Zheng, Qiaozhi Zhang, Huanhuan Chen, Xin Yao", "title": "When Non-Elitism Meets Time-Linkage Problems", "comments": "To appear at GECCO2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world applications have the time-linkage property, and the only\ntheoretical analysis is recently given by Zheng, et al. (TEVC 2021) on their\nproposed time-linkage OneMax problem, OneMax$_{(0,1^n)}$. However, only two\nelitist algorithms (1+1)EA and ($\\mu$+1)EA are analyzed, and it is unknown\nwhether the non-elitism mechanism could help to escape the local optima existed\nin OneMax$_{(0,1^n)}$. In general, there are few theoretical results on the\nbenefits of the non-elitism in evolutionary algorithms. In this work, we\nanalyze on the influence of the non-elitism via comparing the performance of\nthe elitist (1+$\\lambda$)EA and its non-elitist counterpart (1,$\\lambda$)EA. We\nprove that with probability $1-o(1)$ (1+$\\lambda$)EA will get stuck in the\nlocal optima and cannot find the global optimum, but with probability $1$,\n(1,$\\lambda$)EA can reach the global optimum and its expected runtime is\n$O(n^{3+c}\\log n)$ with $\\lambda=c \\log_{\\frac{e}{e-1}} n$ for the constant\n$c\\ge 1$. Noting that a smaller offspring size is helpful for escaping from the\nlocal optima, we further resort to the compact genetic algorithm where only two\nindividuals are sampled to update the probabilistic model, and prove its\nexpected runtime of $O(n^3\\log n)$. Our computational experiments also verify\nthe efficiency of the two non-elitist algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 13:03:42 GMT"}], "update_date": "2021-04-15", "authors_parsed": [["Zheng", "Weijie", ""], ["Zhang", "Qiaozhi", ""], ["Chen", "Huanhuan", ""], ["Yao", "Xin", ""]]}, {"id": "2104.07257", "submitter": "Jizhao Liu", "authors": "Jizhao Liu, Jing Lian, J C Sprott, Yide Ma", "title": "A Novel Neuron Model of Visual Processor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulating and imitating the neuronal network of humans or mammals is a\npopular topic that has been explored for many years in the fields of pattern\nrecognition and computer vision. Inspired by neuronal conduction\ncharacteristics in the primary visual cortex of cats, pulse-coupled neural\nnetworks (PCNNs) can exhibit synchronous oscillation behavior, which can\nprocess digital images without training. However, according to the study of\nsingle cells in the cat primary visual cortex, when a neuron is stimulated by\nan external periodic signal, the interspike-interval (ISI) distributions\nrepresent a multimodal distribution. This phenomenon cannot be explained by all\nPCNN models. By analyzing the working mechanism of the PCNN, we present a novel\nneuron model of the primary visual cortex consisting of a continuous-coupled\nneural network (CCNN). Our model inherited the threshold exponential decay and\nsynchronous pulse oscillation property of the original PCNN model, and it can\nexhibit chaotic behavior consistent with the testing results of cat primary\nvisual cortex neurons. Therefore, our CCNN model is closer to real visual\nneural networks. For image segmentation tasks, the algorithm based on CCNN\nmodel has better performance than the state-of-art of visual cortex neural\nnetwork model. The strength of our approach is that it helps neurophysiologists\nfurther understand how the primary visual cortex works and can be used to\nquantitatively predict the temporal-spatial behavior of real neural networks.\nCCNN may also inspire engineers to create brain-inspired deep learning networks\nfor artificial intelligence purposes.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 06:04:31 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Liu", "Jizhao", ""], ["Lian", "Jing", ""], ["Sprott", "J C", ""], ["Ma", "Yide", ""]]}, {"id": "2104.07381", "submitter": "David Issa Mattos", "authors": "David Issa Mattos, Lucas Ruud, Jan Bosch, Helena Holmstr\\\"om Olsson", "title": "On the Assessment of Benchmark Suites for Algorithm Comparison", "comments": "In submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benchmark suites, i.e. a collection of benchmark functions, are widely used\nin the comparison of black-box optimization algorithms. Over the years,\nresearch has identified many desired qualities for benchmark suites, such as\ndiverse topology, different difficulties, scalability, representativeness of\nreal-world problems among others. However, while the topology characteristics\nhave been subjected to previous studies, there is no study that has\nstatistically evaluated the difficulty level of benchmark functions, how well\nthey discriminate optimization algorithms and how suitable is a benchmark suite\nfor algorithm comparison. In this paper, we propose the use of an item response\ntheory (IRT) model, the Bayesian two-parameter logistic model for multiple\nattempts, to statistically evaluate these aspects with respect to the empirical\nsuccess rate of algorithms. With this model, we can assess the difficulty level\nof each benchmark, how well they discriminate different algorithms, the ability\nscore of an algorithm, and how much information the benchmark suite adds in the\nestimation of the ability scores. We demonstrate the use of this model in two\nwell-known benchmark suites, the Black-Box Optimization Benchmark (BBOB) for\ncontinuous optimization and the Pseudo Boolean Optimization (PBO) for discrete\noptimization. We found that most benchmark functions of BBOB suite have high\ndifficulty levels (compared to the optimization algorithms) and low\ndiscrimination. For the PBO, most functions have good discrimination parameters\nbut are often considered too easy. We discuss potential uses of IRT in\nbenchmarking, including its use to improve the design of benchmark suites, to\nmeasure multiple aspects of the algorithms, and to design adaptive suites.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 11:20:11 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Mattos", "David Issa", ""], ["Ruud", "Lucas", ""], ["Bosch", "Jan", ""], ["Olsson", "Helena Holmstr\u00f6m", ""]]}, {"id": "2104.07423", "submitter": "Preslav Nakov", "authors": "Shaden Shaar, Firoj Alam, Giovanni Da San Martino, Preslav Nakov", "title": "The Role of Context in Detecting Previously Fact-Checked Claims", "comments": "detecting previously fact-checked claims, fact-checking,\n  disinformation, fake news, social media, political debates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen the proliferation of disinformation and misinformation\nonline, thanks to the freedom of expression on the Internet and to the rise of\nsocial media. Two solutions were proposed to address the problem: (i) manual\nfact-checking, which is accurate and credible, but slow and non-scalable, and\n(ii) automatic fact-checking, which is fast and scalable, but lacks\nexplainability and credibility. With the accumulation of enough manually\nfact-checked claims, a middle-ground approach has emerged: checking whether a\ngiven claim has previously been fact-checked. This can be made automatically,\nand thus fast, while also offering credibility and explainability, thanks to\nthe human fact-checking and explanations in the associated fact-checking\narticle. This is a relatively new and understudied research direction, and here\nwe focus on claims made in a political debate, where context really matters.\nThus, we study the impact of modeling the context of the claim: both on the\nsource side, i.e., in the debate, as well as on the target side, i.e., in the\nfact-checking explanation document. We do this by modeling the local context,\nthe global context, as well as by means of co-reference resolution, and\nreasoning over the target text using Transformer-XH. The experimental results\nshow that each of these represents a valuable information source, but that\nmodeling the source-side context is more important, and can yield 10+ points of\nabsolute improvement.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 12:39:37 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Shaar", "Shaden", ""], ["Alam", "Firoj", ""], ["Martino", "Giovanni Da San", ""], ["Nakov", "Preslav", ""]]}, {"id": "2104.07715", "submitter": "Samuel Yen-Chi Chen", "authors": "En-Jui Kuo, Yao-Lung L. Fang, Samuel Yen-Chi Chen", "title": "Quantum Architecture Search via Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in quantum computing have drawn considerable attention to\nbuilding realistic application for and using quantum computers. However,\ndesigning a suitable quantum circuit architecture requires expert knowledge.\nFor example, it is non-trivial to design a quantum gate sequence for generating\na particular quantum state with as fewer gates as possible. We propose a\nquantum architecture search framework with the power of deep reinforcement\nlearning (DRL) to address this challenge. In the proposed framework, the DRL\nagent can only access the Pauli-$X$, $Y$, $Z$ expectation values and a\npredefined set of quantum operations for learning the target quantum state, and\nis optimized by the advantage actor-critic (A2C) and proximal policy\noptimization (PPO) algorithms. We demonstrate a successful generation of\nquantum gate sequences for multi-qubit GHZ states without encoding any\nknowledge of quantum physics in the agent. The design of our framework is\nrather general and can be employed with other DRL architectures or optimization\nmethods to study gate synthesis and compilation for many quantum states.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 18:53:26 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Kuo", "En-Jui", ""], ["Fang", "Yao-Lung L.", ""], ["Chen", "Samuel Yen-Chi", ""]]}, {"id": "2104.07903", "submitter": "Fabian Weigend", "authors": "Fabian Clemens Weigend, Jason Siegler, Oliver Obst", "title": "A New Pathway to Approximate Energy Expenditure and Recovery of an\n  Athlete", "comments": "10 pages, 4 figures, 3 tables, to appear in GECCO-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work proposes to use evolutionary computation as a pathway to allow a\nnew perspective on the modeling of energy expenditure and recovery of an\nindividual athlete during exercise. We revisit a theoretical concept called the\n\"three component hydraulic model\" which is designed to simulate metabolic\nsystems during exercise and which is able to address recently highlighted\nshortcomings of currently applied performance models. This hydraulic model has\nnot been entirely validated on individual athletes because it depends on\nphysiological measures that cannot be acquired in the required precision or\nquantity. This paper introduces a generalized interpretation and formalization\nof the three component hydraulic model that removes its ties to concrete\nmetabolic measures and allows to use evolutionary computation to fit its\nparameters to an athlete.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 06:01:38 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Weigend", "Fabian Clemens", ""], ["Siegler", "Jason", ""], ["Obst", "Oliver", ""]]}, {"id": "2104.07959", "submitter": "Joachim Pedersen", "authors": "Joachim Winther Pedersen and Sebastian Risi", "title": "Evolving and Merging Hebbian Learning Rules: Increasing Generalization\n  by Decreasing the Number of Rules", "comments": null, "journal-ref": null, "doi": "10.1145/3449639.3459317", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Generalization to out-of-distribution (OOD) circumstances after training\nremains a challenge for artificial agents. To improve the robustness displayed\nby plastic Hebbian neural networks, we evolve a set of Hebbian learning rules,\nwhere multiple connections are assigned to a single rule. Inspired by the\nbiological phenomenon of the genomic bottleneck, we show that by allowing\nmultiple connections in the network to share the same local learning rule, it\nis possible to drastically reduce the number of trainable parameters, while\nobtaining a more robust agent. During evolution, by iteratively using simple\nK-Means clustering to combine rules, our Evolve and Merge approach is able to\nreduce the number of trainable parameters from 61,440 to 1,920, while at the\nsame time improving robustness, all without increasing the number of\ngenerations used. While optimization of the agents is done on a standard\nquadruped robot morphology, we evaluate the agents' performances on slight\nmorphology modifications in a total of 30 unseen morphologies. Our results add\nto the discussion on generalization, overfitting and OOD adaptation. To create\nagents that can adapt to a wider array of unexpected situations, Hebbian\nlearning combined with a regularising \"genomic bottleneck\" could be a promising\nresearch direction.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 08:24:19 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Pedersen", "Joachim Winther", ""], ["Risi", "Sebastian", ""]]}, {"id": "2104.08048", "submitter": "Arkadiy Dushatskiy", "authors": "Arkadiy Dushatskiy, Tanja Alderliesten, Peter A. N. Bosman", "title": "A Novel Surrogate-assisted Evolutionary Algorithm Applied to\n  Partition-based Ensemble Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel surrogate-assisted Evolutionary Algorithm for solving\nexpensive combinatorial optimization problems. We integrate a surrogate model,\nwhich is used for fitness value estimation, into a state-of-the-art P3-like\nvariant of the Gene-Pool Optimal Mixing Algorithm (GOMEA) and adapt the\nresulting algorithm for solving non-binary combinatorial problems. We test the\nproposed algorithm on an ensemble learning problem. Ensembling several models\nis a common Machine Learning technique to achieve better performance. We\nconsider ensembles of several models trained on disjoint subsets of a dataset.\nFinding the best dataset partitioning is naturally a combinatorial non-binary\noptimization problem. Fitness function evaluations can be extremely expensive\nif complex models, such as Deep Neural Networks, are used as learners in an\nensemble. Therefore, the number of fitness function evaluations is typically\nlimited, necessitating expensive optimization techniques. In our experiments we\nuse five classification datasets from the OpenML-CC18 benchmark and\nSupport-vector Machines as learners in an ensemble. The proposed algorithm\ndemonstrates better performance than alternative approaches, including Bayesian\noptimization algorithms. It manages to find better solutions using just several\nthousand fitness function evaluations for an ensemble learning problem with up\nto 500 variables.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 11:51:18 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Dushatskiy", "Arkadiy", ""], ["Alderliesten", "Tanja", ""], ["Bosman", "Peter A. N.", ""]]}, {"id": "2104.08098", "submitter": "Jacob Nobel", "authors": "Jacob de Nobel, Hao Wang, Thomas B\\\"ack", "title": "Explorative Data Analysis of Time Series based AlgorithmFeatures of\n  CMA-ES Variants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this study, we analyze behaviours of the well-known CMA-ES by extracting\nthe time-series features on its dynamic strategy parameters. An extensive\nexperiment was conducted on twelve CMA-ES variants and 24 test problems taken\nfrom the BBOB (Black-Box Optimization Bench-marking) testbed, where we used two\ndifferent cutoff times to stop those variants. We utilized the tsfresh package\nfor extracting the features and performed the feature selection procedure using\nthe Boruta algorithm, resulting in 32 features to distinguish either CMA-ES\nvariants or the problems. After measuring the number of predefined targets\nreached by those variants, we contrive to predict those measured values on each\ntest problem using the feature. From our analysis, we saw that the features can\nclassify the CMA-ES variants, or the function groups decently, and show a\npotential for predicting the performance of those variants. We conducted a\nhierarchical clustering analysis on the test problems and noticed a drastic\nchange in the clustering outcome when comparing the longer cutoff time to the\nshorter one, indicating a huge change in search behaviour of the algorithm. In\ngeneral, we found that with longer time series, the predictive power of the\ntime series features increase.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 13:09:47 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["de Nobel", "Jacob", ""], ["Wang", "Hao", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2104.08239", "submitter": "Michael O'Neill", "authors": "Michael O'Neill and Anthony Brabazon", "title": "An exploration of asocial and social learning in the evolution of\n  variable-length structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We wish to explore the contribution that asocial and social learning might\nplay as a mechanism for self-adaptation in the search for variable-length\nstructures by an evolutionary algorithm. An extremely challenging, yet simple\nto understand problem landscape is adopted where the probability of randomly\nfinding a solution is approximately one in a trillion. A number of learning\nmechanisms operating on variable-length structures are implemented and their\nperformance analysed. The social learning setup, which combines forms of both\nsocial and asocial learning in combination with evolution is found to be most\nperformant, while the setups exclusively adopting evolution are incapable of\nfinding solutions.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 17:17:28 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["O'Neill", "Michael", ""], ["Brabazon", "Anthony", ""]]}, {"id": "2104.08252", "submitter": "Rune Krauss", "authors": "Rune Krauss, Marcel Merten, Mirco Bockholt, Rolf Drechsler", "title": "ALF -- A Fitness-Based Artificial Life Form for Evolving Large-Scale\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) is becoming increasingly important in daily life. In\nthis context, Artificial Neural Networks (ANNs) are a popular approach within\nML methods to realize an artificial intelligence. Usually, the topology of ANNs\nis predetermined. However, there are problems where it is difficult to find a\nsuitable topology. Therefore, Topology and Weight Evolving Artificial Neural\nNetwork (TWEANN) algorithms have been developed that can find ANN topologies\nand weights using genetic algorithms. A well-known downside for large-scale\nproblems is that TWEANN algorithms often evolve inefficient ANNs and require\nlong runtimes.\n  To address this issue, we propose a new TWEANN algorithm called Artificial\nLife Form (ALF) with the following technical advancements: (1) speciation via\nstructural and semantic similarity to form better candidate solutions, (2)\ndynamic adaptation of the observed candidate solutions for better convergence\nproperties, and (3) integration of solution quality into genetic reproduction\nto increase the probability of optimization success. Experiments on large-scale\nML problems confirm that these approaches allow the fast solving of these\nproblems and lead to efficient evolved ANNs.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 17:36:41 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Krauss", "Rune", ""], ["Merten", "Marcel", ""], ["Bockholt", "Mirco", ""], ["Drechsler", "Rolf", ""]]}, {"id": "2104.08353", "submitter": "Pablo Barros", "authors": "Pablo Barros, Alessandra Sciutti", "title": "I Only Have Eyes for You: The Impact of Masks On Convolutional-Based\n  Facial Expression Recognition", "comments": "Accepted at the LXCV Workshop @ CVPR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The current COVID-19 pandemic has shown us that we are still facing\nunpredictable challenges in our society. The necessary constrain on social\ninteractions affected heavily how we envision and prepare the future of social\nrobots and artificial agents in general. Adapting current affective perception\nmodels towards constrained perception based on the hard separation between\nfacial perception and affective understanding would help us to provide robust\nsystems. In this paper, we perform an in-depth analysis of how recognizing\naffect from persons with masks differs from general facial expression\nperception. We evaluate how the recently proposed FaceChannel adapts towards\nrecognizing facial expressions from persons with masks. In Our analysis, we\nevaluate different training and fine-tuning schemes to understand better the\nimpact of masked facial expressions. We also perform specific feature-level\nvisualization to demonstrate how the inherent capabilities of the FaceChannel\nto learn and combine facial features change when in a constrained social\ninteraction scenario.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 20:03:30 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Barros", "Pablo", ""], ["Sciutti", "Alessandra", ""]]}, {"id": "2104.08426", "submitter": "N. Sukumar", "authors": "N. Sukumar, Ankit Srivastava", "title": "Exact imposition of boundary conditions with distance functions in\n  physics-informed deep neural networks", "comments": "50 pages, 45 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new approach based on distance fields to\nexactly impose boundary conditions in physics-informed deep neural networks.\nThe challenges in satisfying Dirichlet boundary conditions in meshfree and\nparticle methods are well-known. This issue is also pertinent in the\ndevelopment of physics informed neural networks (PINN) for the solution of\npartial differential equations. We introduce geometry-aware trial functions in\nartifical neural networks to improve the training in deep learning for partial\ndifferential equations. To this end, we use concepts from constructive solid\ngeometry (R-functions) and generalized barycentric coordinates (mean value\npotential fields) to construct $\\phi$, an approximate distance function to the\nboundary of a domain. To exactly impose homogeneous Dirichlet boundary\nconditions, the trial function is taken as $\\phi$ multiplied by the PINN\napproximation, and its generalization via transfinite interpolation is used to\na priori satisfy inhomogeneous Dirichlet (essential), Neumann (natural), and\nRobin boundary conditions on complex geometries. In doing so, we eliminate\nmodeling error associated with the satisfaction of boundary conditions in a\ncollocation method and ensure that kinematic admissibility is met pointwise in\na Ritz method. We present numerical solutions for linear and nonlinear\nboundary-value problems over domains with affine and curved boundaries.\nBenchmark problems in 1D for linear elasticity, advection-diffusion, and beam\nbending; and in 2D for the Poisson equation, biharmonic equation, and the\nnonlinear Eikonal equation are considered. The approach extends to higher\ndimensions, and we showcase its use by solving a Poisson problem with\nhomogeneneous Dirichlet boundary conditions over the 4D hypercube. This study\nprovides a pathway for meshfree analysis to be conducted on the exact geometry\nwithout domain discretization.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 03:02:52 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Sukumar", "N.", ""], ["Srivastava", "Ankit", ""]]}, {"id": "2104.08537", "submitter": "Federico Bertoni", "authors": "Federico Bertoni, Noemi Montobbio, Alessandro Sarti and Giovanna Citti", "title": "Emergence of Lie symmetries in functional architectures learned by CNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the spontaneous development of symmetries in the early\nlayers of a Convolutional Neural Network (CNN) during learning on natural\nimages. Our architecture is built in such a way to mimic the early stages of\nbiological visual systems. In particular, it contains a pre-filtering step\n$\\ell^0$ defined in analogy with the Lateral Geniculate Nucleus (LGN).\nMoreover, the first convolutional layer is equipped with lateral connections\ndefined as a propagation driven by a learned connectivity kernel, in analogy\nwith the horizontal connectivity of the primary visual cortex (V1). The layer\n$\\ell^0$ shows a rotational symmetric pattern well approximated by a Laplacian\nof Gaussian (LoG), which is a well-known model of the receptive profiles of LGN\ncells. The convolutional filters in the first layer can be approximated by\nGabor functions, in agreement with well-established models for the profiles of\nsimple cells in V1. We study the learned lateral connectivity kernel of this\nlayer, showing the emergence of orientation selectivity w.r.t. the learned\nfilters. We also examine the association fields induced by the learned kernel,\nand show qualitative and quantitative comparisons with known group-based models\nof V1 horizontal connectivity. These geometric properties arise spontaneously\nduring the training of the CNN architecture, analogously to the emergence of\nsymmetries in visual systems thanks to brain plasticity driven by external\nstimuli.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 13:23:26 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Bertoni", "Federico", ""], ["Montobbio", "Noemi", ""], ["Sarti", "Alessandro", ""], ["Citti", "Giovanna", ""]]}, {"id": "2104.08564", "submitter": "Ho-Kin Tang", "authors": "Ho-Kin Tang, Sim Kuan Goh", "title": "A Novel Non-population-based Meta-heuristic Optimizer Inspired by the\n  Philosophy of Yi Jing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drawing inspiration from the philosophy of Yi Jing, Yin-Yang pair\noptimization (YYPO) has been shown to achieve competitive performance in single\nobjective optimizations. Besides, it has the advantage of low time complexity\nwhen comparing to other population-based optimization. As a conceptual\nextension of YYPO, we proposed the novel Yi optimization (YI) algorithm as one\nof the best non-population-based optimizer. Incorporating both the harmony and\nreversal concept of Yi Jing, we replace the Yin-Yang pair with a Yi-point, in\nwhich we utilize the Levy flight to update the solution and balance both the\neffort of the exploration and the exploitation in the optimization process. As\na conceptual prototype, we examine YI with IEEE CEC 2017 benchmark and compare\nits performance with a Levy flight-based optimizer CV1.0, the state-of-the-art\ndynamical Yin-Yang pair optimization in YYPO family and a few classical\noptimizers. According to the experimental results, YI shows highly competitive\nperformance while keeping the low time complexity. Hence, the results of this\nwork have implications for enhancing meta-heuristic optimizer using the\nphilosophy of Yi Jing, which deserves research attention.\n", "versions": [{"version": "v1", "created": "Sat, 17 Apr 2021 14:57:23 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Tang", "Ho-Kin", ""], ["Goh", "Sim Kuan", ""]]}, {"id": "2104.08774", "submitter": "Antonios Liapis", "authors": "Theodoros Galanos and Antonios Liapis and Georgios N. Yannakakis and\n  Reinhard Koenig", "title": "ARCH-Elites: Quality-Diversity for Urban Design", "comments": "Published at Genetic and Evolutionary Computation Conference\n  Companion, 2021, 2 pages, 1 figure", "journal-ref": null, "doi": "10.1145/3449726.3459490", "report-no": null, "categories": "cs.NE cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces ARCH-Elites, a MAP-Elites implementation that can\nreconfigure large-scale urban layouts at real-world locations via a pre-trained\nsurrogate model instead of costly simulations. In a series of experiments, we\ngenerate novel urban designs for two real-world locations in Boston,\nMassachusetts. Combining the exploration of a possibility space with real-time\nperformance evaluation creates a powerful new paradigm for architectural\ngenerative design that can extract and articulate design intelligence.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 08:46:38 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Galanos", "Theodoros", ""], ["Liapis", "Antonios", ""], ["Yannakakis", "Georgios N.", ""], ["Koenig", "Reinhard", ""]]}, {"id": "2104.08781", "submitter": "Antonios Liapis", "authors": "Konstantinos Sfikas and Antonios Liapis and Georgios N. Yannakakis", "title": "Monte Carlo Elites: Quality-Diversity Selection as a Multi-Armed Bandit\n  Problem", "comments": "Proceedings of the Genetic and Evolutionary Computation Conference, 9\n  pages, 6 figures, 3 tables", "journal-ref": null, "doi": "10.1145/3449639.3459321", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core challenge of evolutionary search is the need to balance between\nexploration of the search space and exploitation of highly fit regions.\nQuality-diversity search has explicitly walked this tightrope between a\npopulation's diversity and its quality. This paper extends a popular\nquality-diversity search algorithm, MAP-Elites, by treating the selection of\nparents as a multi-armed bandit problem. Using variations of the\nupper-confidence bound to select parents from under-explored but potentially\nrewarding areas of the search space can accelerate the discovery of new regions\nas well as improve its archive's total quality. The paper tests an indirect\nmeasure of quality for parent selection: the survival rate of a parent's\noffspring. Results show that maintaining a balance between exploration and\nexploitation leads to the most diverse and high-quality set of solutions in\nthree different testbeds.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 09:11:48 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Sfikas", "Konstantinos", ""], ["Liapis", "Antonios", ""], ["Yannakakis", "Georgios N.", ""]]}, {"id": "2104.08789", "submitter": "Xavier Rafael-Palou", "authors": "Xavier Rafael-Palou, Anton Aubanell, Mario Ceresa, Vicent Ribas, Gemma\n  Piella, Miguel A. Gonz\\'alez Ballester", "title": "An Uncertainty-aware Hierarchical Probabilistic Network for Early\n  Prediction, Quantification and Segmentation of Pulmonary Tumour Growth", "comments": "24 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early detection and quantification of tumour growth would help clinicians to\nprescribe more accurate treatments and provide better surgical planning.\nHowever, the multifactorial and heterogeneous nature of lung tumour progression\nhampers identification of growth patterns. In this study, we present a novel\nmethod based on a deep hierarchical generative and probabilistic framework\nthat, according to radiological guidelines, predicts tumour growth, quantifies\nits size and provides a semantic appearance of the future nodule. Unlike\nprevious deterministic solutions, the generative characteristic of our approach\nalso allows us to estimate the uncertainty in the predictions, especially\nimportant for complex and doubtful cases. Results of evaluating this method on\nan independent test set reported a tumour growth balanced accuracy of 74%, a\ntumour growth size MAE of 1.77 mm and a tumour segmentation Dice score of 78%.\nThese surpassed the performances of equivalent deterministic and alternative\ngenerative solutions (i.e. probabilistic U-Net, Bayesian test dropout and\nPix2Pix GAN) confirming the suitability of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 09:48:58 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Rafael-Palou", "Xavier", ""], ["Aubanell", "Anton", ""], ["Ceresa", "Mario", ""], ["Ribas", "Vicent", ""], ["Piella", "Gemma", ""], ["Ballester", "Miguel A. Gonz\u00e1lez", ""]]}, {"id": "2104.08842", "submitter": "Avijit Basak", "authors": "Avijit Basak", "title": "A Rank based Adaptive Mutation in Genetic Algorithm", "comments": null, "journal-ref": "August 2020 International Journal of Computer Applications 175", "doi": "10.5120/ijca2020920572", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally Genetic Algorithm has been used for optimization of unimodal\nand multimodal functions. Earlier researchers worked with constant\nprobabilities of GA control operators like crossover, mutation etc. for tuning\nthe optimization in specific domains. Recent advancements in this field\nwitnessed adaptive approach in probability determination. In Adaptive mutation\nprimarily poor individuals are utilized to explore state space, so mutation\nprobability is usually generated proportionally to the difference between\nfitness of best chromosome and itself (fMAX - f). However, this approach is\nsusceptible to nature of fitness distribution during optimization. This paper\npresents an alternate approach of mutation probability generation using\nchromosome rank to avoid any susceptibility to fitness distribution.\nExperiments are done to compare results of simple genetic algorithm (SGA) with\nconstant mutation probability and adaptive approaches within a limited resource\nconstraint for unimodal, multimodal functions and Travelling Salesman Problem\n(TSP). Measurements are done for average best fitness, number of generations\nevolved and percentage of global optimum achievements out of several trials.\nThe results demonstrate that the rank-based adaptive mutation approach is\nsuperior to fitness-based adaptive approach as well as SGA in a multimodal\nproblem space.\n", "versions": [{"version": "v1", "created": "Sun, 18 Apr 2021 12:41:33 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Basak", "Avijit", ""]]}, {"id": "2104.09056", "submitter": "Chao-Tsung Huang", "authors": "Chao-Tsung Huang", "title": "RingCNN: Exploiting Algebraically-Sparse Ring Tensors for\n  Energy-Efficient CNN-Based Computational Imaging", "comments": "To Appear in 2021 ACM/IEEE 48th Annual International Symposium on\n  Computer Architecture (ISCA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of artificial intelligence, convolutional neural networks (CNNs)\nare emerging as a powerful technique for computational imaging. They have shown\nsuperior quality for reconstructing fine textures from badly-distorted images\nand have potential to bring next-generation cameras and displays to our daily\nlife. However, CNNs demand intensive computing power for generating\nhigh-resolution videos and defy conventional sparsity techniques when rendering\ndense details. Therefore, finding new possibilities in regular sparsity is\ncrucial to enable large-scale deployment of CNN-based computational imaging.\n  In this paper, we consider a fundamental but yet well-explored approach --\nalgebraic sparsity -- for energy-efficient CNN acceleration. We propose to\nbuild CNN models based on ring algebra that defines multiplication, addition,\nand non-linearity for n-tuples properly. Then the essential sparsity will\nimmediately follow, e.g. n-times reduction for the number of real-valued\nweights. We define and unify several variants of ring algebras into a modeling\nframework, RingCNN, and make comparisons in terms of image quality and hardware\ncomplexity. On top of that, we further devise a novel ring algebra which\nminimizes complexity with component-wise product and achieves the best quality\nusing directional ReLU. Finally, we implement an accelerator, eRingCNN, in two\nsettings, n=2 and 4 (50% and 75% sparsity), with 40 nm technology to support\nadvanced denoising and super-resolution at up to 4K UHD 30 fps. Layout results\nshow that they can deliver equivalent 41 TOPS using 3.76 W and 2.22 W,\nrespectively. Compared to the real-valued counterpart, our ring convolution\nengines for n=2 achieve 2.00x energy efficiency and 2.08x area efficiency with\nsimilar or even better image quality. With n=4, the efficiency gains of energy\nand area are further increased to 3.84x and 3.77x with 0.11 dB drop of PSNR.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 05:26:11 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Huang", "Chao-Tsung", ""]]}, {"id": "2104.09103", "submitter": "Theo Ladune", "authors": "Th\\'eo Ladune (IETR), Pierrick Philippe, Wassim Hamidouche (IETR), Lu\n  Zhang (IETR), Olivier D\\'eforges (IETR)", "title": "Conditional Coding and Variable Bitrate for Practical Learned Video\n  Coding", "comments": null, "journal-ref": "CLIC workshop, CVPR 2021, Jun 2021, Nashville, United States", "doi": null, "report-no": null, "categories": "cs.NE eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a practical learned video codec. Conditional coding and\nquantization gain vectors are used to provide flexibility to a single\nencoder/decoder pair, which is able to compress video sequences at a variable\nbitrate. The flexibility is leveraged at test time by choosing the rate and GOP\nstructure to optimize a rate-distortion cost. Using the CLIC21 video test\nconditions, the proposed approach shows performance on par with HEVC.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 07:48:55 GMT"}, {"version": "v2", "created": "Tue, 20 Apr 2021 09:28:17 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Ladune", "Th\u00e9o", "", "IETR"], ["Philippe", "Pierrick", "", "IETR"], ["Hamidouche", "Wassim", "", "IETR"], ["Zhang", "Lu", "", "IETR"], ["D\u00e9forges", "Olivier", "", "IETR"]]}, {"id": "2104.09163", "submitter": "Louis Annabi", "authors": "Louis Annabi, Alexandre Pitti, Mathias Quoy", "title": "Bidirectional Interaction between Visual and Motor Generative Models\n  using Predictive Coding and Active Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this work, we build upon the Active Inference (AIF) and Predictive Coding\n(PC) frameworks to propose a neural architecture comprising a generative model\nfor sensory prediction, and a distinct generative model for motor trajectories.\nWe highlight how sequences of sensory predictions can act as rails guiding\nlearning, control and online adaptation of motor trajectories. We furthermore\ninquire the effects of bidirectional interactions between the motor and the\nvisual modules. The architecture is tested on the control of a simulated\nrobotic arm learning to reproduce handwritten letters.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 09:41:31 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Annabi", "Louis", ""], ["Pitti", "Alexandre", ""], ["Quoy", "Mathias", ""]]}, {"id": "2104.09252", "submitter": "Nima TaheriNejad", "authors": "Lukas Baischer, Matthias Wess, Nima TaheriNejad", "title": "Learning on Hardware: A Tutorial on Neural Network Accelerators and\n  Co-Processors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have the advantage that they can take into\naccount a large number of parameters, which enables them to solve complex\ntasks. In computer vision and speech recognition, they have a better accuracy\nthan common algorithms, and in some tasks, they boast an even higher accuracy\nthan human experts. With the progress of DNNs in recent years, many other\nfields of application such as diagnosis of diseases and autonomous driving are\ntaking advantage of them. The trend at DNNs is clear: The network size is\ngrowing exponentially, which leads to an exponential increase in computational\neffort and required memory size. For this reason, optimized hardware\naccelerators are used to increase the performance of the inference of neuronal\nnetworks. However, there are various neural network hardware accelerator\nplatforms, such as graphics processing units (GPUs), application specific\nintegrated circuits (ASICs) and field programmable gate arrays (FPGAs). Each of\nthese platforms offer certain advantages and disadvantages. Also, there are\nvarious methods for reducing the computational effort of DNNs, which are\ndifferently suitable for each hardware accelerator. In this article an overview\nof existing neural network hardware accelerators and acceleration methods is\ngiven. Their strengths and weaknesses are shown and a recommendation of\nsuitable applications is given. In particular, we focus on acceleration of the\ninference of convolutional neural networks (CNNs) used for image recognition\ntasks. Given that there exist many different hardware architectures. FPGA-based\nimplementations are well-suited to show the effect of DNN optimization methods\non accuracy and throughput. For this reason, the focus of this work is more on\nFPGA-based implementations.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 12:50:27 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Baischer", "Lukas", ""], ["Wess", "Matthias", ""], ["TaheriNejad", "Nima", ""]]}, {"id": "2104.09272", "submitter": "Anja Jankovic", "authors": "Anja Jankovic, Gorjan Popovski, Tome Eftimov, Carola Doerr", "title": "The Impact of Hyper-Parameter Tuning for Landscape-Aware Performance\n  Regression and Algorithm Selection", "comments": "To appear in the Proceedings of Genetic and Evolutionary Computation\n  Conference (GECCO 2021), ACM", "journal-ref": null, "doi": "10.1145/3449639.3459406", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated algorithm selection and configuration methods that build on\nexploratory landscape analysis (ELA) are becoming very popular in Evolutionary\nComputation. However, despite a significantly growing number of applications,\nthe underlying machine learning models are often chosen in an ad-hoc manner.\n  We show in this work that three classical regression methods are able to\nachieve meaningful results for ELA-based algorithm selection. For those three\nmodels -- random forests, decision trees, and bagging decision trees -- the\nquality of the regression models is highly impacted by the chosen\nhyper-parameters. This has significant effects also on the quality of the\nalgorithm selectors that are built on top of these regressions.\n  By comparing a total number of 30 different models, each coupled with 2\ncomplementary regression strategies, we derive guidelines for the tuning of the\nregression models and provide general recommendations for a more systematic use\nof classical machine learning models in landscape-aware algorithm selection. We\npoint out that a choice of the machine learning model merits to be carefully\nundertaken and further investigated.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 13:16:29 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Jankovic", "Anja", ""], ["Popovski", "Gorjan", ""], ["Eftimov", "Tome", ""], ["Doerr", "Carola", ""]]}, {"id": "2104.09460", "submitter": "Willie Neiswanger", "authors": "Willie Neiswanger, Ke Alexander Wang, Stefano Ermon", "title": "Bayesian Algorithm Execution: Estimating Computable Properties of\n  Black-box Functions Using Mutual Information", "comments": "Appears in Proceedings of the 38th International Conference on\n  Machine Learning (ICML), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IT cs.LG cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world problems, we want to infer some property of an expensive\nblack-box function $f$, given a budget of $T$ function evaluations. One example\nis budget constrained global optimization of $f$, for which Bayesian\noptimization is a popular method. Other properties of interest include local\noptima, level sets, integrals, or graph-structured information induced by $f$.\nOften, we can find an algorithm $\\mathcal{A}$ to compute the desired property,\nbut it may require far more than $T$ queries to execute. Given such an\n$\\mathcal{A}$, and a prior distribution over $f$, we refer to the problem of\ninferring the output of $\\mathcal{A}$ using $T$ evaluations as Bayesian\nAlgorithm Execution (BAX). To tackle this problem, we present a procedure,\nInfoBAX, that sequentially chooses queries that maximize mutual information\nwith respect to the algorithm's output. Applying this to Dijkstra's algorithm,\nfor instance, we infer shortest paths in synthetic and real-world graphs with\nblack-box edge costs. Using evolution strategies, we yield variants of Bayesian\noptimization that target local, rather than global, optima. On these problems,\nInfoBAX uses up to 500 times fewer queries to $f$ than required by the original\nalgorithm. Our method is closely connected to other Bayesian optimal\nexperimental design procedures such as entropy search methods and optimal\nsensor placement using Gaussian processes.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 17:22:11 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 17:56:46 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Neiswanger", "Willie", ""], ["Wang", "Ke Alexander", ""], ["Ermon", "Stefano", ""]]}, {"id": "2104.09736", "submitter": "Ke Shang", "authors": "Ke Shang, Hisao Ishibuchi, Weiyu Chen, Yang Nan, Weiduo Liao", "title": "Hypervolume-Optimal $\\mu$-Distributions on Line/Plane-based Pareto\n  Fronts in Three Dimensions", "comments": "This paper has been submitted to a journal for review", "journal-ref": null, "doi": "10.1109/TEVC.2021.3093114", "report-no": null, "categories": "cs.NE math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hypervolume is widely used in the evolutionary multi-objective optimization\n(EMO) field to evaluate the quality of a solution set. For a solution set with\n$\\mu$ solutions on a Pareto front, a larger hypervolume means a better solution\nset. Investigating the distribution of the solution set with the largest\nhypervolume is an important topic in EMO, which is the so-called hypervolume\noptimal $\\mu$-distribution. Theoretical results have shown that the $\\mu$\nsolutions are uniformly distributed on a linear Pareto front in two dimensions.\nHowever, the $\\mu$ solutions are not always uniformly distributed on a\nsingle-line Pareto front in three dimensions. They are only uniform when the\nsingle-line Pareto front has one constant objective. In this paper, we further\ninvestigate the hypervolume optimal $\\mu$-distribution in three dimensions. We\nconsider the line- and plane-based Pareto fronts. For the line-based Pareto\nfronts, we extend the single-line Pareto front to two-line and three-line\nPareto fronts, where each line has one constant objective. For the plane-based\nPareto fronts, the linear triangular and inverted triangular Pareto fronts are\nconsidered. First, we show that the $\\mu$ solutions are not always uniformly\ndistributed on the line-based Pareto fronts. The uniformity depends on how the\nlines are combined. Then, we show that a uniform solution set on the\nplane-based Pareto front is not always optimal for hypervolume maximization. It\nis locally optimal with respect to a $(\\mu+1)$ selection scheme. Our results\ncan help researchers in the community to better understand and utilize the\nhypervolume indicator.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 03:11:15 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Shang", "Ke", ""], ["Ishibuchi", "Hisao", ""], ["Chen", "Weiyu", ""], ["Nan", "Yang", ""], ["Liao", "Weiduo", ""]]}, {"id": "2104.09764", "submitter": "Jianjun Hu", "authors": "Wenhui Yang, Edirisuriya M. Dilanga Siriwardane, Rongzhi Dong, Yuxin\n  Li, Jianjun Hu", "title": "Crystal structure prediction of materials with high symmetry using\n  differential evolution", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Crystal structure determines properties of materials. With the crystal\nstructure of a chemical substance, many physical and chemical properties can be\npredicted by first-principles calculations or machine learning models. Since it\nis relatively easy to generate a hypothetical chemically valid formula, crystal\nstructure prediction becomes an important method for discovering new materials.\nIn our previous work, we proposed a contact map-based crystal structure\nprediction method, which uses global optimization algorithms such as genetic\nalgorithms to maximize the match between the contact map of the predicted\nstructure and the contact map of the real crystal structure to search for the\ncoordinates at the Wyckoff Positions(WP). However, when predicting the crystal\nstructure with high symmetry, we found that the global optimization algorithm\nhas difficulty to find an effective combination of WPs that satisfies the\nchemical formula, which is mainly caused by the inconsistency between the\ndimensionality of the contact map of the predicted crystal structure and the\ndimensionality of the contact map of the target crystal structure. This makes\nit challenging to predict the crystal structures of high-symmetry crystals. In\norder to solve this problem, here we propose to use PyXtal to generate and\nfilter random crystal structures with given symmetry constraints based on the\ninformation such as chemical formulas and space groups. With contact map as the\noptimization goal, we use differential evolution algorithms to search for\nnon-special coordinates at the Wyckoff positions to realize the structure\nprediction of high-symmetry crystal materials. Our experimental results show\nthat our proposed algorithm CMCrystalHS can effectively solve the problem of\ninconsistent contact map dimensions and predict the crystal structures with\nhigh symmetry.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 05:10:19 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Yang", "Wenhui", ""], ["Siriwardane", "Edirisuriya M. Dilanga", ""], ["Dong", "Rongzhi", ""], ["Li", "Yuxin", ""], ["Hu", "Jianjun", ""]]}, {"id": "2104.09798", "submitter": "Alireza Khadem", "authors": "Alireza Khadem, Haojie Ye, Trevor Mudge", "title": "CoDR: Computation and Data Reuse Aware CNN Accelerator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.LG cs.NE cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computation and Data Reuse is critical for the resource-limited Convolutional\nNeural Network (CNN) accelerators. This paper presents Universal Computation\nReuse to exploit weight sparsity, repetition, and similarity simultaneously in\na convolutional layer. Moreover, CoDR decreases the cost of weight memory\naccess by proposing a customized Run-Length Encoding scheme and the number of\nmemory accesses to the intermediate results by introducing an input and output\nstationary dataflow. Compared to two recent compressed CNN accelerators with\nthe same area of 2.85 mm^2, CoDR decreases SRAM access by 5.08x and 7.99x, and\nconsumes 3.76x and 6.84x less energy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 07:20:17 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Khadem", "Alireza", ""], ["Ye", "Haojie", ""], ["Mudge", "Trevor", ""]]}, {"id": "2104.09884", "submitter": "Chao Qian", "authors": "Chao Qian, Dan-Xuan Liu, Chao Feng, Ke Tang", "title": "Multi-objective Evolutionary Algorithms are Generally Good: Maximizing\n  Monotone Submodular Functions over Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms (EAs) are general-purpose optimization algorithms,\ninspired by natural evolution. Recent theoretical studies have shown that EAs\ncan achieve good approximation guarantees for solving the problem classes of\nsubmodular optimization, which have a wide range of applications, such as\nmaximum coverage, sparse regression, influence maximization, document\nsummarization and sensor placement, just to name a few. Though they have\nprovided some theoretical explanation for the general-purpose nature of EAs,\nthe considered submodular objective functions are defined only over sets or\nmultisets. To complement this line of research, this paper studies the problem\nclass of maximizing monotone submodular functions over sequences, where the\nobjective function depends on the order of items. We prove that for each kind\nof previously studied monotone submodular objective functions over sequences,\ni.e., prefix monotone submodular functions, weakly monotone and strongly\nsubmodular functions, and DAG monotone submodular functions, a simple\nmulti-objective EA, i.e., GSEMO, can always reach or improve the best known\napproximation guarantee after running polynomial time in expectation. Note that\nthese best-known approximation guarantees can be obtained only by different\ngreedy-style algorithms before. Empirical studies on various applications,\ne.g., accomplishing tasks, maximizing information gain, search-and-tracking and\nrecommender systems, show the excellent performance of the GSEMO.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 10:36:10 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Qian", "Chao", ""], ["Liu", "Dan-Xuan", ""], ["Feng", "Chao", ""], ["Tang", "Ke", ""]]}, {"id": "2104.09943", "submitter": "Olga Lukyanova", "authors": "Oleg Nikitin, Olga Lukyanova, Alex Kunin", "title": "The principle of weight divergence facilitation for unsupervised pattern\n  recognition in spiking neural networks", "comments": "9 pages, 5 figures, submitted to the conference ICANN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Parallels between the signal processing tasks and biological neurons lead to\nan understanding of the principles of self-organized optimization of input\nsignal recognition. In the present paper, we discuss such similarities among\nbiological and technical systems. We propose the addition to the well-known\nSTDP synaptic plasticity rule to directs the weight modification towards the\nstate associated with the maximal difference between the background noise and\ncorrelated signals. The principle of physically constrained weight growth is\nused as a basis for such control of the modification of the weights. It is\nproposed, that biological synaptic straight modification is restricted by the\nexistence and production of bio-chemical 'substances' needed for plasticity\ndevelopment. In this paper, the information about the noise-to-signal ratio is\nused to control such a substances' production and storage and to drive the\nneuron's synaptic pressures towards the state with the best signal-to-noise\nratio. Several experiments with different input signal regimes are considered\nto understand the functioning of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 13:11:15 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Nikitin", "Oleg", ""], ["Lukyanova", "Olga", ""], ["Kunin", "Alex", ""]]}, {"id": "2104.10010", "submitter": "Olga Lukyanova", "authors": "Olga Lukyanova, Oleg Nikitin, Alex Kunin", "title": "BraidNet: procedural generation of neural networks for image\n  classification problems using braid theory", "comments": "9 pages, 8 figures, submitted to the conference ICANN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.IT cs.LG math.GT math.IT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this article, we propose the approach to procedural optimization of a\nneural network, based on the combination of information theory and braid\ntheory. The network studied in the article implemented with the intersections\nbetween the braid strands, as well as simplified networks (a network with\nstrands without intersections and a simple convolutional deep neural network),\nare used to solve various problems of multiclass image classification that\nallow us to analyze the comparative effectiveness of the proposed architecture.\nThe simulation results showed BraidNet's comparative advantage in learning\nspeed and classification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 14:40:30 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Lukyanova", "Olga", ""], ["Nikitin", "Oleg", ""], ["Kunin", "Alex", ""]]}, {"id": "2104.10033", "submitter": "Manh Duong Phung", "authors": "Manh Duong Phung and Quang Phuc Ha", "title": "Safety-enhanced UAV Path Planning with Spherical Vector-based Particle\n  Swarm Optimization", "comments": null, "journal-ref": "Applied Soft Computing, Volume 107, August 2021, 107376", "doi": "10.1016/j.asoc.2021.107376", "report-no": null, "categories": "cs.NE cs.AI cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new algorithm named spherical vector-based particle\nswarm optimization (SPSO) to deal with the problem of path planning for\nunmanned aerial vehicles (UAVs) in complicated environments subjected to\nmultiple threats. A cost function is first formulated to convert the path\nplanning into an optimization problem that incorporates requirements and\nconstraints for the feasible and safe operation of the UAV. SPSO is then used\nto find the optimal path that minimizes the cost function by efficiently\nsearching the configuration space of the UAV via the correspondence between the\nparticle position and the speed, turn angle and climb/dive angle of the UAV. To\nevaluate the performance of SPSO, eight benchmarking scenarios have been\ngenerated from real digital elevation model maps. The results show that the\nproposed SPSO outperforms not only other particle swarm optimization (PSO)\nvariants including the classic PSO, phase angle-encoded PSO and quantum-behave\nPSO but also other state-of-the-art metaheuristic optimization algorithms\nincluding the genetic algorithm (GA), artificial bee colony (ABC), and\ndifferential evolution (DE) in most scenarios. In addition, experiments have\nbeen conducted to demonstrate the validity of the generated paths for real UAV\noperations. Source code of the algorithm can be found at\nhttps://github.com/duongpm/SPSO.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2021 06:45:11 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Phung", "Manh Duong", ""], ["Ha", "Quang Phuc", ""]]}, {"id": "2104.10040", "submitter": "Anwesh Bhattacharya", "authors": "Anwesh Bhattacharya, Snehanshu Saha", "title": "Fairly Constricted Particle Swarm Optimization", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We have adapted the use of exponentially averaged momentum in PSO to\nmulti-objective optimization problems. The algorithm was built on top of SMPSO,\na state-of-the-art MOO solver, and we present a novel mathematical analysis of\nconstriction fairness. We extend this analysis to the use of momentum and\npropose rich alternatives of parameter sets which are theoretically sound. We\ncall our proposed algorithm \"Fairly Constricted PSO with Exponentially-Averaged\nMomentum\", FCPSO-em.\n", "versions": [{"version": "v1", "created": "Sat, 10 Apr 2021 14:39:59 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2021 05:00:15 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Bhattacharya", "Anwesh", ""], ["Saha", "Snehanshu", ""]]}, {"id": "2104.10041", "submitter": "Elvis Cui", "authors": "Elvis Cui, Dongyuan Song, Weng Kee Wong", "title": "Particle swarm optimization in constrained maximum likelihood estimation\n  a case study", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of paper is to apply two types of particle swarm optimization, global\nbest andlocal best PSO to a constrained maximum likelihood estimation problem\nin pseudotime anal-ysis, a sub-field in bioinformatics. The results have shown\nthat particle swarm optimizationis extremely useful and efficient when the\noptimization problem is non-differentiable and non-convex so that analytical\nsolution can not be derived and gradient-based methods can not beapplied.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 07:32:14 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Cui", "Elvis", ""], ["Song", "Dongyuan", ""], ["Wong", "Weng Kee", ""]]}, {"id": "2104.10044", "submitter": "Ang Li", "authors": "Yanfei Li, Tong Geng, Ang Li, Huimin Yu", "title": "BCNN: Binary Complex Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binarized neural networks, or BNNs, show great promise in edge-side\napplications with resource limited hardware, but raise the concerns of reduced\naccuracy. Motivated by the complex neural networks, in this paper we introduce\ncomplex representation into the BNNs and propose Binary complex neural network\n-- a novel network design that processes binary complex inputs and weights\nthrough complex convolution, but still can harvest the extraordinary\ncomputation efficiency of BNNs. To ensure fast convergence rate, we propose\nnovel BCNN based batch normalization function and weight initialization\nfunction. Experimental results on Cifar10 and ImageNet using state-of-the-art\nnetwork models (e.g., ResNet, ResNetE and NIN) show that BCNN can achieve\nbetter accuracy compared to the original BNN models. BCNN improves BNN by\nstrengthening its learning capability through complex representation and\nextending its applicability to complex-valued input data. The source code of\nBCNN will be released on GitHub.\n", "versions": [{"version": "v1", "created": "Sun, 28 Mar 2021 03:35:24 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Li", "Yanfei", ""], ["Geng", "Tong", ""], ["Li", "Ang", ""], ["Yu", "Huimin", ""]]}, {"id": "2104.10081", "submitter": "Matthew Andres Moreno", "authors": "Matthew Andres Moreno, Charles Ofria", "title": "Exploring Evolved Multicellular Life Histories in a Open-Ended Digital\n  Evolution System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Evolutionary transitions occur when previously-independent replicating\nentities unite to form more complex individuals. Such transitions have\nprofoundly shaped natural evolutionary history and occur in two forms:\nfraternal transitions involve lower-level entities that are kin (e.g.,\ntransitions to multicellularity or to eusocial colonies), while egalitarian\ntransitions involve unrelated individuals (e.g., the origins of mitochondria).\nThe necessary conditions and evolutionary mechanisms for these transitions to\narise continue to be fruitful targets of scientific interest. Here, we examine\na range of fraternal transitions in populations of open-ended self-replicating\ncomputer programs. These digital cells were allowed to form and replicate kin\ngroups by selectively adjoining or expelling daughter cells. The capability to\nrecognize kin-group membership enabled preferential communication and\ncooperation between cells. We repeatedly observed group-level traits that are\ncharacteristic of a fraternal transition. These included reproductive division\nof labor, resource sharing within kin groups, resource investment in offspring\ngroups, asymmetrical behaviors mediated by messaging, morphological patterning,\nand adaptive apoptosis. We report eight case studies from replicates where\ntransitions occurred and explore the diverse range of adaptive evolved\nmulticellular strategies.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 16:03:09 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Moreno", "Matthew Andres", ""], ["Ofria", "Charles", ""]]}, {"id": "2104.10301", "submitter": "Ryoji Tanabe", "authors": "Ryoji Tanabe", "title": "Towards Exploratory Landscape Analysis for Large-scale Optimization: A\n  Dimensionality Reduction Framework", "comments": "This is an accepted version of a paper published in the proceedings\n  of GECCO 2021", "journal-ref": null, "doi": "10.1145/3449639.3459300", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although exploratory landscape analysis (ELA) has shown its effectiveness in\nvarious applications, most previous studies focused only on low- and\nmoderate-dimensional problems. Thus, little is known about the scalability of\nthe ELA approach for large-scale optimization. In this context, first, this\npaper analyzes the computational cost of features in the flacco package. Our\nresults reveal that two important feature classes (ela_level and ela_meta)\ncannot be applied to large-scale optimization due to their high computational\ncost. To improve the scalability of the ELA approach, this paper proposes a\ndimensionality reduction framework that computes features in a reduced\nlower-dimensional space than the original solution space. We demonstrate that\nthe proposed framework can drastically reduce the computation time of ela_level\nand ela_meta for large dimensions. In addition, the proposed framework can make\nthe cell-mapping feature classes scalable for large-scale optimization. Our\nresults also show that features computed by the proposed framework are\nbeneficial for predicting the high-level properties of the 24 large-scale BBOB\nfunctions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 01:16:57 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Tanabe", "Ryoji", ""]]}, {"id": "2104.10712", "submitter": "Haowen Fang", "authors": "Haowen Fang, Brady Taylor, Ziru Li, Zaidao Mei, Hai Li, Qinru Qiu", "title": "Neuromorphic Algorithm-hardware Codesign for Temporal Pattern Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic computing and spiking neural networks (SNN) mimic the behavior\nof biological systems and have drawn interest for their potential to perform\ncognitive tasks with high energy efficiency. However, some factors such as\ntemporal dynamics and spike timings prove critical for information processing\nbut are often ignored by existing works, limiting the performance and\napplications of neuromorphic computing. On one hand, due to the lack of\neffective SNN training algorithms, it is difficult to utilize the temporal\nneural dynamics. Many existing algorithms still treat neuron activation\nstatistically. On the other hand, utilizing temporal neural dynamics also poses\nchallenges to hardware design. Synapses exhibit temporal dynamics, serving as\nmemory units that hold historical information, but are often simplified as a\nconnection with weight. Most current models integrate synaptic activations in\nsome storage medium to represent membrane potential and institute a hard reset\nof membrane potential after the neuron emits a spike. This is done for its\nsimplicity in hardware, requiring only a \"clear\" signal to wipe the storage\nmedium, but destroys temporal information stored in the neuron.\n  In this work, we derive an efficient training algorithm for Leaky Integrate\nand Fire neurons, which is capable of training a SNN to learn complex spatial\ntemporal patterns. We achieved competitive accuracy on two complex datasets. We\nalso demonstrate the advantage of our model by a novel temporal pattern\nassociation task. Codesigned with this algorithm, we have developed a CMOS\ncircuit implementation for a memristor-based network of neuron and synapses\nwhich retains critical neural dynamics with reduced complexity. This circuit\nimplementation of the neuron model is simulated to demonstrate its ability to\nreact to temporal spiking patterns with an adaptive threshold.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 18:23:31 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 03:41:52 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Fang", "Haowen", ""], ["Taylor", "Brady", ""], ["Li", "Ziru", ""], ["Mei", "Zaidao", ""], ["Li", "Hai", ""], ["Qiu", "Qinru", ""]]}, {"id": "2104.10851", "submitter": "Alexander Hadjiivanov", "authors": "Alexander Hadjiivanov", "title": "Continuous Learning and Adaptation with Membrane Potential and\n  Activation Threshold Homeostasis", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Most classical (non-spiking) neural network models disregard internal neuron\ndynamics and treat neurons as simple input integrators. However, biological\nneurons have an internal state governed by complex dynamics that plays a\ncrucial role in learning, adaptation and the overall network activity and\nbehaviour. This paper presents the Membrane Potential and Activation Threshold\nHomeostasis (MPATH) neuron model, which combines several biologically inspired\nmechanisms to efficiently simulate internal neuron dynamics with a single\nparameter analogous to the membrane time constant in biological neurons. The\nmodel allows neurons to maintain a form of dynamic equilibrium by automatically\nregulating their activity when presented with fluctuating input. One\nconsequence of the MPATH model is that it imbues neurons with a sense of time\nwithout recurrent connections, paving the way for modelling processes that\ndepend on temporal aspects of neuron activity. Experiments demonstrate the\nmodel's ability to adapt to and continually learn from its input.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 04:01:32 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 13:30:55 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 01:24:43 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Hadjiivanov", "Alexander", ""]]}, {"id": "2104.10999", "submitter": "Tome Eftimov", "authors": "Tome Eftimov, Anja Jankovic, Gorjan Popovski, Carola Doerr, Peter\n  Koro\\v{s}ec", "title": "Personalizing Performance Regression Models to Black-Box Optimization\n  Problems", "comments": "To appear in the Proceedings of Genetic and Evolutionary Computation\n  Conference (GECCO 2021), ACM", "journal-ref": null, "doi": "10.1145/3449639.3459407", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting the performance of different optimization algorithms\nfor previously unseen problem instances is crucial for high-performing\nalgorithm selection and configuration techniques. In the context of numerical\noptimization, supervised regression approaches built on top of exploratory\nlandscape analysis are becoming very popular. From the point of view of Machine\nLearning (ML), however, the approaches are often rather naive, using default\nregression or classification techniques without proper investigation of the\nsuitability of the ML tools. With this work, we bring to the attention of our\ncommunity the possibility to personalize regression models to specific types of\noptimization problems. Instead of aiming for a single model that works well\nacross a whole set of possibly diverse problems, our personalized regression\napproach acknowledges that different models may suite different types of\nproblems. Going one step further, we also investigate the impact of selecting\nnot a single regression model per problem, but personalized ensembles. We test\nour approach on predicting the performance of numerical optimization heuristics\non the BBOB benchmark collection.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 11:47:47 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Eftimov", "Tome", ""], ["Jankovic", "Anja", ""], ["Popovski", "Gorjan", ""], ["Doerr", "Carola", ""], ["Koro\u0161ec", "Peter", ""]]}, {"id": "2104.11072", "submitter": "Przemyslaw Grudniewski PhD", "authors": "P.A. Grudniewski (1), A.J. Sobey (1 and 2) ((1) Fluid Structure\n  Interactions Group, University of Southampton, Southampton, England, UK, (2)\n  Marine and Maritime Group, Data-centric Engineering, The Alan Turing\n  Institute, The British Library, London, England, UK)", "title": "cMLSGA: A Co-Evolutionary Multi-Level Selection Genetic Algorithm for\n  Multi-Objective Optimization", "comments": "35 pages, 3 figures, 7 tables. The associated code is available\n  online with detailed instructions at: https://www.bitbucket.org/Pag1c18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In practical optimisation the dominant characteristics of the problem are\noften not known prior. Therefore, there is a need to develop general solvers as\nit is not always possible to tailor a specialised approach to each application.\nThe hybrid form of Multi-Level Selection Genetic Algorithm (MLSGA) already\nshows good performance on range of problems due to its diversity-first\napproach, which is rare among Evolutionary Algorithms. To increase the\ngenerality of its performance this paper proposes a distinct set of\nco-evolutionary mechanisms, which defines co-evolution as competition between\ncollectives rather than individuals. This distinctive approach to\nco-evolutionary provides less regular communication between sub-populations and\ndifferent fitness definitions between individuals and collectives. This\nencourages the collectives to act more independently creating a unique\nsub-regional search, leading to the development of co-evolutionary MLSGA\n(cMLSGA). To test this methodology nine genetic algorithms are selected to\ngenerate several variants of cMLSGA, which incorporates these approaches at the\nindividual level. The new mechanisms are tested on over 100 different functions\nand benchmarked against the 9 state-of-the-art competitors in order to find the\nbest general solver. The results show that the diversity of co-evolutionary\napproaches is more important than their individual performances. This allows\nthe selection of two competing algorithms that improve the generality of\ncMLSGA, without large loss of performance on any specific problem type. When\ncompared to the state-of-the-art, the proposed methodology is the most\nuniversal and robust, leading to an algorithm more likely to solve complex\nproblems with limited knowledge about the search space.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 13:52:21 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Grudniewski", "P. A.", "", "1 and 2"], ["Sobey", "A. J.", "", "1 and 2"]]}, {"id": "2104.11105", "submitter": "Mi{\\l}osz Stypi\\'nski", "authors": "Mi{\\l}osz Stypi\\'nski, Marcin Niemiec", "title": "Synchronization of Tree Parity Machines using non-binary input vectors", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural cryptography is the application of artificial neural networks in the\nsubject of cryptography. The functionality of this solution is based on a tree\nparity machine. It uses artificial neural networks to perform secure key\nexchange between network entities. This article proposes improvements to the\nsynchronization of two tree parity machines. The improvement is based on\nlearning artificial neural network using input vectors which have a wider range\nof values than binary ones. As a result, the duration of the synchronization\nprocess is reduced. Therefore, tree parity machines achieve common weights in a\nshorter time due to the reduction of necessary bit exchanges. This approach\nimproves the security of neural cryptography\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 14:38:55 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Stypi\u0144ski", "Mi\u0142osz", ""], ["Niemiec", "Marcin", ""]]}, {"id": "2104.11169", "submitter": "Seongsik Park", "authors": "Seongsik Park, Dongjin Lee, Sungroh Yoon", "title": "Noise-Robust Deep Spiking Neural Networks with Temporal Information", "comments": "Accepted to DAC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spiking neural networks (SNNs) have emerged as energy-efficient neural\nnetworks with temporal information. SNNs have shown a superior efficiency on\nneuromorphic devices, but the devices are susceptible to noise, which hinders\nthem from being applied in real-world applications. Several studies have\nincreased noise robustness, but most of them considered neither deep SNNs nor\ntemporal information. In this paper, we investigate the effect of noise on deep\nSNNs with various neural coding methods and present a noise-robust deep SNN\nwith temporal information. With the proposed methods, we have achieved a deep\nSNN that is efficient and robust to spike deletion and jitter.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 16:40:33 GMT"}], "update_date": "2021-04-23", "authors_parsed": [["Park", "Seongsik", ""], ["Lee", "Dongjin", ""], ["Yoon", "Sungroh", ""]]}, {"id": "2104.11274", "submitter": "Tapan Gandhi Prof", "authors": "Rohan Wadhawan and Tapan K. Gandhi", "title": "Landmark-Aware and Part-based Ensemble Transfer Learning Network for\n  Facial Expression Recognition from Static images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial Expression Recognition from static images is a challenging problem in\ncomputer vision applications. Convolutional Neural Network (CNN), the\nstate-of-the-art method for various computer vision tasks, has had limited\nsuccess in predicting expressions from faces having extreme poses,\nillumination, and occlusion conditions. To mitigate this issue, CNNs are often\naccompanied by techniques like transfer, multi-task, or ensemble learning that\noften provide high accuracy at the cost of high computational complexity. In\nthis work, we propose a Part-based Ensemble Transfer Learning network, which\nmodels how humans recognize facial expressions by correlating the spatial\norientation pattern of the facial features with a specific expression. It\nconsists of 5 sub-networks, in which each sub-network performs transfer\nlearning from one of the five subsets of facial landmarks: eyebrows, eyes,\nnose, mouth, or jaw to expression classification. We test the proposed network\non the CK+, JAFFE, and SFEW datasets, and it outperforms the benchmark for CK+\nand JAFFE datasets by 0.51\\% and 5.34\\%, respectively. Additionally, it\nconsists of a total of 1.65M model parameters and requires only 3.28 $\\times$\n$10^{6}$ FLOPS, which ensures computational efficiency for real-time\ndeployment. Grad-CAM visualizations of our proposed ensemble highlight the\ncomplementary nature of its sub-networks, a key design parameter of an\neffective ensemble network. Lastly, cross-dataset evaluation results reveal\nthat our proposed ensemble has a high generalization capacity. Our model\ntrained on the SFEW Train dataset achieves an accuracy of 47.53\\% on the CK+\ndataset, which is higher than what it achieves on the SFEW Valid dataset.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 18:38:33 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Wadhawan", "Rohan", ""], ["Gandhi", "Tapan K.", ""]]}, {"id": "2104.11276", "submitter": "Krenare Pireva Nuci", "authors": "Lumbardh Elshani, Krenare Pireva Nu\\c{c}i", "title": "Constructing a personalized learning path using genetic algorithms\n  approach", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A substantial disadvantage of traditional learning is that all students\nfollow the same learning sequence, but not all of them have the same background\nof knowledge, the same preferences, the same learning goals, and the same\nneeds. Traditional teaching resources, such as textbooks, in most cases pursue\nstudents to follow fixed sequences during the learning process, thus impairing\ntheir performance. Learning sequencing is an important research issue as part\nof the learning process because no fixed learning paths will be appropriate for\nall learners. For this reason, many research papers are focused on the\ndevelopment of mechanisms to offer personalization on learning paths,\nconsidering the learner needs, interests, behaviors, and abilities. In most\ncases, these researchers are totally focused on the student's preferences,\nignoring the level of difficulty and the relation degree that exists between\nvarious concepts in a course. This research paper presents the possibility of\nconstructing personalized learning paths using genetic algorithm-based model,\nencountering the level of difficulty and relation degree of the constituent\nconcepts of a course. The experimental results shows that the genetic algorithm\nis suitable to generate optimal learning paths based on learning object\ndifficulty level, duration, rating, and relation degree between each learning\nobject as elementary parts of the sequence of the learning path. From these\nresults compared to the quality of the traditional learning path, we observed\nthat even the quality of the weakest learning path generated by our GA approach\nis in a favor compared to quality of the traditional learning path, with a\ndifference of 3.59\\%, while the highest solution generated in the end resulted\n8.34\\% in favor of our proposal compared to the traditional learning paths.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 18:43:47 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Elshani", "Lumbardh", ""], ["Nu\u00e7i", "Krenare Pireva", ""]]}, {"id": "2104.11410", "submitter": "Tom Portegys PhD", "authors": "Thomas E. Portegys", "title": "A modularity comparison of Long Short-Term Memory and Morphognosis\n  neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study compares the modularity performance of two artificial neural\nnetwork architectures: a Long Short-Term Memory (LSTM) recurrent network, and\nMorphognosis, a neural network based on a hierarchy of spatial and temporal\ncontexts. Mazes are used to measure performance, defined as the ability to\nutilize independently learned mazes to solve mazes composed of them. A maze is\na sequence of rooms connected by doors. The modular task is implemented as\nfollows: at the beginning of the maze, an initial door choice forms a context\nthat must be retained until the end of an intervening maze, where the same door\nmust be chosen again to reach the goal. For testing, the door-association mazes\nand separately trained intervening mazes are presented together for the first\ntime. While both neural networks perform well during training, the testing\nperformance of Morphognosis is significantly better than LSTM on this modular\ntask.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 04:22:26 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Portegys", "Thomas E.", ""]]}, {"id": "2104.11604", "submitter": "Giorgia Dellaferrera", "authors": "Giorgia Dellaferrera, Stanislaw Wozniak, Giacomo Indiveri, Angeliki\n  Pantazi, Evangelos Eleftheriou", "title": "Learning in Deep Neural Networks Using a Biologically Inspired Optimizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plasticity circuits in the brain are known to be influenced by the\ndistribution of the synaptic weights through the mechanisms of synaptic\nintegration and local regulation of synaptic strength. However, the complex\ninterplay of stimulation-dependent plasticity with local learning signals is\ndisregarded by most of the artificial neural network training algorithms\ndevised so far. Here, we propose a novel biologically inspired optimizer for\nartificial (ANNs) and spiking neural networks (SNNs) that incorporates key\nprinciples of synaptic integration observed in dendrites of cortical neurons:\nGRAPES (Group Responsibility for Adjusting the Propagation of Error Signals).\nGRAPES implements a weight-distribution dependent modulation of the error\nsignal at each node of the neural network. We show that this biologically\ninspired mechanism leads to a systematic improvement of the convergence rate of\nthe network, and substantially improves classification accuracy of ANNs and\nSNNs with both feedforward and recurrent architectures. Furthermore, we\ndemonstrate that GRAPES supports performance scalability for models of\nincreasing complexity and mitigates catastrophic forgetting by enabling\nnetworks to generalize to unseen tasks based on previously acquired knowledge.\nThe local characteristics of GRAPES minimize the required memory resources,\nmaking it optimally suited for dedicated hardware implementations. Overall, our\nwork indicates that reconciling neurophysiology insights with machine\nintelligence is key to boosting the performance of neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 13:50:30 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Dellaferrera", "Giorgia", ""], ["Wozniak", "Stanislaw", ""], ["Indiveri", "Giacomo", ""], ["Pantazi", "Angeliki", ""], ["Eleftheriou", "Evangelos", ""]]}, {"id": "2104.11700", "submitter": "Saeedeh Parsaeefard", "authors": "Saeedeh Parsaeefard, Sayed Ehsan Etesami and Alberto Leon Garcia", "title": "Robust Federated Learning by Mixture of Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel weighted average model based on the mixture of experts\n(MoE) concept to provide robustness in Federated learning (FL) against the\npoisoned/corrupted/outdated local models. These threats along with the non-IID\nnature of data sets can considerably diminish the accuracy of the FL model. Our\nproposed MoE-FL setup relies on the trust between users and the server where\nthe users share a portion of their public data sets with the server. The server\napplies a robust aggregation method by solving the optimization problem or the\nSoftmax method to highlight the outlier cases and to reduce their adverse\neffect on the FL process. Our experiments illustrate that MoE-FL outperforms\nthe performance of the traditional aggregation approach for high rate of\npoisoned data from attackers.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 16:41:04 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Parsaeefard", "Saeedeh", ""], ["Etesami", "Sayed Ehsan", ""], ["Garcia", "Alberto Leon", ""]]}, {"id": "2104.11798", "submitter": "Th\\'eophile Champion", "authors": "Th\\'eophile Champion, Marek Grze\\'s, Howard Bowman", "title": "Realising Active Inference in Variational Message Passing: the\n  Outcome-blind Certainty Seeker", "comments": "60 pages, 19 figures, final version accepted for publication in\n  Neural Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Active inference is a state-of-the-art framework in neuroscience that offers\na unified theory of brain function. It is also proposed as a framework for\nplanning in AI. Unfortunately, the complex mathematics required to create new\nmodels -- can impede application of active inference in neuroscience and AI\nresearch. This paper addresses this problem by providing a complete\nmathematical treatment of the active inference framework -- in discrete time\nand state spaces -- and the derivation of the update equations for any new\nmodel. We leverage the theoretical connection between active inference and\nvariational message passing as describe by John Winn and Christopher M. Bishop\nin 2005. Since, variational message passing is a well-defined methodology for\nderiving Bayesian belief update equations, this paper opens the door to\nadvanced generative models for active inference. We show that using a fully\nfactorized variational distribution simplifies the expected free energy -- that\nfurnishes priors over policies -- so that agents seek unambiguous states.\nFinally, we consider future extensions that support deep tree searches for\nsequential policy optimisation -- based upon structure learning and belief\npropagation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 19:40:55 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Champion", "Th\u00e9ophile", ""], ["Grze\u015b", "Marek", ""], ["Bowman", "Howard", ""]]}, {"id": "2104.11889", "submitter": "Tome Eftimov", "authors": "Ana Kostovska, Diederick Vermetten, Carola Doerr, Sa\\v{s}o\n  D\\v{z}eroski, Pan\\v{c}e Panov, Tome Eftimov", "title": "OPTION: OPTImization Algorithm Benchmarking ONtology", "comments": "To appear in the Proceedings of Genetic and Evolutionary Computation\n  Conference Companion (GECCO 2021), ACM", "journal-ref": null, "doi": "10.1145/3449726.3459579", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many platforms for benchmarking optimization algorithms offer users the\npossibility of sharing their experimental data with the purpose of promoting\nreproducible and reusable research. However, different platforms use different\ndata models and formats, which drastically inhibits identification of relevant\ndata sets, their interpretation, and their interoperability. Consequently, a\nsemantically rich, ontology-based, machine-readable data model is highly\ndesired.\n  We report in this paper on the development of such an ontology, which we name\nOPTION (OPTImization algorithm benchmarking ONtology). Our ontology provides\nthe vocabulary needed for semantic annotation of the core entities involved in\nthe benchmarking process, such as algorithms, problems, and evaluation\nmeasures. It also provides means for automated data integration, improved\ninteroperability, powerful querying capabilities and reasoning, thereby\nenriching the value of the benchmark data. We demonstrate the utility of OPTION\nby annotating and querying a corpus of benchmark performance data from the BBOB\nworkshop data - a use case which can be easily extended to cover other\nbenchmarking data collections.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 06:11:30 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Kostovska", "Ana", ""], ["Vermetten", "Diederick", ""], ["Doerr", "Carola", ""], ["D\u017eeroski", "Sa\u0161o", ""], ["Panov", "Pan\u010de", ""], ["Eftimov", "Tome", ""]]}, {"id": "2104.12175", "submitter": "Giovanni Iacca Prof.", "authors": "Enrico Zardini, Davide Zappetti, Davide Zambrano, Giovanni Iacca,\n  Dario Floreano", "title": "Seeking Quality Diversity in Evolutionary Co-design of Morphology and\n  Control of Soft Tensegrity Modular Robots", "comments": "To be published in the proceedings of ACM Genetic and Evolutionary\n  Computation Conference (GECCO) 2021", "journal-ref": null, "doi": "10.1145/3449639.3459311", "report-no": null, "categories": "cs.RO cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Designing optimal soft modular robots is difficult, due to non-trivial\ninteractions between morphology and controller. Evolutionary algorithms (EAs),\ncombined with physical simulators, represent a valid tool to overcome this\nissue. In this work, we investigate algorithmic solutions to improve the\nQuality Diversity of co-evolved designs of Tensegrity Soft Modular Robots\n(TSMRs) for two robotic tasks, namely goal reaching and squeezing trough a\nnarrow passage. To this aim, we use three different EAs, i.e., MAP-Elites and\ntwo custom algorithms: one based on Viability Evolution (ViE) and NEAT\n(ViE-NEAT), the other named Double Map MAP-Elites (DM-ME) and devised to seek\ndiversity while co-evolving robot morphologies and neural network (NN)-based\ncontrollers. In detail, DM-ME extends MAP-Elites in that it uses two distinct\nfeature maps, referring to morphologies and controllers respectively, and\nintegrates a mechanism to automatically define the NN-related feature\ndescriptor. Considering the fitness, in the goal-reaching task ViE-NEAT\noutperforms MAP-Elites and results equivalent to DM-ME. Instead, when\nconsidering diversity in terms of \"illumination\" of the feature space, DM-ME\noutperforms the other two algorithms on both tasks, providing a richer pool of\npossible robotic designs, whereas ViE-NEAT shows comparable performance to\nMAP-Elites on goal reaching, although it does not exploit any map.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 14:49:59 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zardini", "Enrico", ""], ["Zappetti", "Davide", ""], ["Zambrano", "Davide", ""], ["Iacca", "Giovanni", ""], ["Floreano", "Dario", ""]]}, {"id": "2104.12249", "submitter": "Hong-Gyu Yoon", "authors": "Hong-Gyu Yoon and Pilwon Kim", "title": "A STDP-based Encoding/Decoding Algorithm for Associative and Composite\n  Data", "comments": "12 pages of main text. Source for simplified MATLAB programs\n  performing two numerical tests presented in this article can be found in the\n  following link: https://github.com/hkyoon94/NRSTDP.git", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE math.DS nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spike-timing-dependent plasticity(STDP) is a biological process of synaptic\nmodification caused by the difference of firing order and timing between\nneurons. In our separate work, we have rigorously shown that STDP in a network\nof neurons transforms periodic input patterns into a geometrical structure\nnamed memory plane, and a proper memory cue near such structure dynamically\nrevives the stored information. Using these results, in this paper, we\ndemonstrate the following two encoding/decoding algorithms handling practical\ndata. First, we perform an auto-associative memory task with a group of images.\nThe results show that any relevant image to the group can be used as a cue in\norder to reconstruct the original images. The next one deals with the process\nof semantic memory representations that are embedded from sentences. The\nresults show that words can recall multiple sentences simultaneously or one\nexclusively, depending on their grammatical relations. This implies that the\nproposed framework is apt to process multiple groups of associative memories\nwith a composite structure.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 20:26:52 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 00:56:36 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Yoon", "Hong-Gyu", ""], ["Kim", "Pilwon", ""]]}, {"id": "2104.12475", "submitter": "Mauro Innocente", "authors": "Mauro Sebasti\\'an Innocente", "title": "Particle Swarms Reformulated towards a Unified and Flexible Framework", "comments": "Preprint The final authenticated article will be published by\n  Springer-Nature in the Lecture Notes in Computer Science series. This\n  research will be presented at the Twelfth International Conference on Swarm\n  Intelligence (ICSI 2021)", "journal-ref": "Lecture Notes in Computer Science, ICSI 2021", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Particle Swarm Optimisation (PSO) algorithm has undergone countless\nmodifications and adaptations since its original formulation in 1995. Some of\nthese have become mainstream whereas many others have not been adopted and\nfaded away. Thus, a myriad of alternative formulations have been proposed to\nthe extent that the question arises as to what the basic features of an\nalgorithm must be to belong in the PSO family. The aim of this paper is to\nestablish what defines a PSO algorithm and to attempt to formulate it in such a\nway that it encompasses many existing variants. Therefore, different versions\nof the method may be posed as settings within the proposed unified framework.\nIn addition, the proposed formulation generalises, decouples and incorporates\nfeatures to the method providing more flexibility to the behaviour of each\nparticle. The closed forms of the trajectory difference equation are obtained,\ndifferent types of behaviour are identified, stochasticity is decoupled, and\ntraditionally global features such as sociometries and constraint-handling are\nre-defined as particle's attributes.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 11:14:08 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Innocente", "Mauro Sebasti\u00e1n", ""]]}, {"id": "2104.12839", "submitter": "M. Hamed Mozaffari", "authors": "M. Hamed Mozaffari and Li-Lin Tay", "title": "One-dimensional Active Contour Models for Raman Spectrum Baseline\n  Correction", "comments": "4 figures, and 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Raman spectroscopy is a powerful and non-invasive method for analysis of\nchemicals and detection of unknown substances. However, Raman signal is so weak\nthat background noise can distort the actual Raman signal. These baseline\nshifts that exist in the Raman spectrum might deteriorate analytical results.\nIn this paper, a modified version of active contour models in one-dimensional\nspace has been proposed for the baseline correction of Raman spectra. Our\ntechnique, inspired by principles of physics and heuristic optimization\nmethods, iteratively deforms an initialized curve toward the desired baseline.\nThe performance of the proposed algorithm was evaluated and compared with\nsimilar techniques using simulated Raman spectra. The results showed that the\n1D active contour model outperforms many iterative baseline correction methods.\nThe proposed algorithm was successfully applied to experimental Raman spectral\ndata, and the results indicate that the baseline of Raman spectra can be\nautomatically subtracted.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 19:30:34 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Mozaffari", "M. Hamed", ""], ["Tay", "Li-Lin", ""]]}, {"id": "2104.13060", "submitter": "Tome Eftimov", "authors": "Urban \\v{S}kvorc, Tome Eftimov, Peter Koro\\v{s}ec", "title": "A Complementarity Analysis of the COCO Benchmark Problems and\n  Artificially Generated Problems", "comments": "To appear in the Proceedings of Genetic and Evolutionary Computation\n  Conference Companion (GECCO 2021), ACM", "journal-ref": null, "doi": "10.1145/3449726.3459585", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When designing a benchmark problem set, it is important to create a set of\nbenchmark problems that are a good generalization of the set of all possible\nproblems. One possible way of easing this difficult task is by using\nartificially generated problems. In this paper, one such single-objective\ncontinuous problem generation approach is analyzed and compared with the COCO\nbenchmark problem set, a well know problem set for benchmarking numerical\noptimization algorithms. Using Exploratory Landscape Analysis and Singular\nValue Decomposition, we show that such representations allow us to further\nexplore the relations between the problems by applying visualization and\ncorrelation analysis techniques, with the goal of decreasing the bias in\nbenchmark problem assessment.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 09:18:43 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["\u0160kvorc", "Urban", ""], ["Eftimov", "Tome", ""], ["Koro\u0161ec", "Peter", ""]]}, {"id": "2104.13133", "submitter": "Jakob Bossek", "authors": "Jakob Bossek, Aneta Neumann, Frank Neumann", "title": "Breeding Diverse Packings for the Knapsack Problem by Means of\n  Diversity-Tailored Evolutionary Algorithms", "comments": null, "journal-ref": null, "doi": "10.1145/3449639.3459364", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practise, it is often desirable to provide the decision-maker with a rich\nset of diverse solutions of decent quality instead of just a single solution.\nIn this paper we study evolutionary diversity optimization for the knapsack\nproblem (KP). Our goal is to evolve a population of solutions that all have a\nprofit of at least $(1-\\varepsilon)\\cdot OPT$, where OPT is the value of an\noptimal solution. Furthermore, they should differ in structure with respect to\nan entropy-based diversity measure. To this end we propose a simple\n$(\\mu+1)$-EA with initial approximate solutions calculated by a well-known\nFPTAS for the KP. We investigate the effect of different standard mutation\noperators and introduce biased mutation and crossover which puts strong\nprobability on flipping bits of low and/or high frequency within the\npopulation. An experimental study on different instances and settings shows\nthat the proposed mutation operators in most cases perform slightly inferior in\nthe long term, but show strong benefits if the number of function evaluations\nis severely limited.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 12:26:18 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Bossek", "Jakob", ""], ["Neumann", "Aneta", ""], ["Neumann", "Frank", ""]]}, {"id": "2104.13277", "submitter": "Stefan Jaeger", "authors": "Stefan Jaeger", "title": "A Dual Process Model for Optimizing Cross Entropy in Neural Networks", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Minimizing cross-entropy is a widely used method for training artificial\nneural networks. Many training procedures based on backpropagation use\ncross-entropy directly as their loss function. Instead, this theoretical essay\ninvestigates a dual process model with two processes, in which one process\nminimizes the Kullback-Leibler divergence while its dual counterpart minimizes\nthe Shannon entropy. Postulating that learning consists of two dual processes\ncomplementing each other, the model defines an equilibrium state for both\nprocesses in which the loss function assumes its minimum. An advantage of the\nproposed model is that it allows deriving the optimal learning rate and\nmomentum weight to update network weights for backpropagation. Furthermore, the\nmodel introduces the golden ratio and complex numbers as important new concepts\nin machine learning.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 15:45:43 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Jaeger", "Stefan", ""]]}, {"id": "2104.13369", "submitter": "Michal Yarom", "authors": "Oran Lang, Yossi Gandelsman, Michal Yarom, Yoav Wald, Gal Elidan,\n  Avinatan Hassidim, William T. Freeman, Phillip Isola, Amir Globerson, Michal\n  Irani, Inbar Mosseri", "title": "Explaining in Style: Training a GAN to explain a classifier in\n  StyleSpace", "comments": "First four authors contributed equally. Project page:\n  https://explaining-in-style.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image classification models can depend on multiple different semantic\nattributes of the image. An explanation of the decision of the classifier needs\nto both discover and visualize these properties. Here we present StylEx, a\nmethod for doing this, by training a generative model to specifically explain\nmultiple attributes that underlie classifier decisions. A natural source for\nsuch attributes is the StyleSpace of StyleGAN, which is known to generate\nsemantically meaningful dimensions in the image. However, because standard GAN\ntraining is not dependent on the classifier, it may not represent these\nattributes which are important for the classifier decision, and the dimensions\nof StyleSpace may represent irrelevant attributes. To overcome this, we propose\na training procedure for a StyleGAN, which incorporates the classifier model,\nin order to learn a classifier-specific StyleSpace. Explanatory attributes are\nthen selected from this space. These can be used to visualize the effect of\nchanging multiple attributes per image, thus providing image-specific\nexplanations. We apply StylEx to multiple domains, including animals, leaves,\nfaces and retinal images. For these, we show how an image can be modified in\ndifferent ways to change its classifier output. Our results show that the\nmethod finds attributes that align well with semantic ones, generate meaningful\nimage-specific explanations, and are human-interpretable as measured in\nuser-studies.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 17:57:19 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Lang", "Oran", ""], ["Gandelsman", "Yossi", ""], ["Yarom", "Michal", ""], ["Wald", "Yoav", ""], ["Elidan", "Gal", ""], ["Hassidim", "Avinatan", ""], ["Freeman", "William T.", ""], ["Isola", "Phillip", ""], ["Globerson", "Amir", ""], ["Irani", "Michal", ""], ["Mosseri", "Inbar", ""]]}, {"id": "2104.13398", "submitter": "Dominik Dold", "authors": "Dominik Dold, Josep Soler Garrido", "title": "SpikE: spike-based embeddings for multi-relational graph data", "comments": "Accepted for publication at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the recent success of reconciling spike-based coding with the error\nbackpropagation algorithm, spiking neural networks are still mostly applied to\ntasks stemming from sensory processing, operating on traditional data\nstructures like visual or auditory data. A rich data representation that finds\nwide application in industry and research is the so-called knowledge graph - a\ngraph-based structure where entities are depicted as nodes and relations\nbetween them as edges. Complex systems like molecules, social networks and\nindustrial factory systems can be described using the common language of\nknowledge graphs, allowing the usage of graph embedding algorithms to make\ncontext-aware predictions in these information-packed environments. We propose\na spike-based algorithm where nodes in a graph are represented by single spike\ntimes of neuron populations and relations as spike time differences between\npopulations. Learning such spike-based embeddings only requires knowledge about\nspike times and spike time differences, compatible with recently proposed\nframeworks for training spiking neural networks. The presented model is easily\nmapped to current neuromorphic hardware systems and thereby moves inference on\nknowledge graphs into a domain where these architectures thrive, unlocking a\npromising industrial application area for this technology.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 18:00:12 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 09:14:28 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Dold", "Dominik", ""], ["Garrido", "Josep Soler", ""]]}, {"id": "2104.13424", "submitter": "Nemanja Rakicevic", "authors": "Nemanja Rakicevic, Antoine Cully, Petar Kormushev", "title": "Policy Manifold Search: Exploring the Manifold Hypothesis for\n  Diversity-based Neuroevolution", "comments": "Accepted as a full paper at Genetic and Evolutionary Computation\n  Conference, GECCO 2021. arXiv admin note: substantial text overlap with\n  arXiv:2012.08676", "journal-ref": null, "doi": "10.1145/3449639.3459320", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroevolution is an alternative to gradient-based optimisation that has the\npotential to avoid local minima and allows parallelisation. The main limiting\nfactor is that usually it does not scale well with parameter space\ndimensionality. Inspired by recent work examining neural network intrinsic\ndimension and loss landscapes, we hypothesise that there exists a\nlow-dimensional manifold, embedded in the policy network parameter space,\naround which a high-density of diverse and useful policies are located. This\npaper proposes a novel method for diversity-based policy search via\nNeuroevolution, that leverages learned representations of the policy network\nparameters, by performing policy search in this learned representation space.\nOur method relies on the Quality-Diversity (QD) framework which provides a\nprincipled approach to policy search, and maintains a collection of diverse\npolicies, used as a dataset for learning policy representations. Further, we\nuse the Jacobian of the inverse-mapping function to guide the search in the\nrepresentation space. This ensures that the generated samples remain in the\nhigh-density regions, after mapping back to the original space. Finally, we\nevaluate our contributions on four continuous-control tasks in simulated\nenvironments, and compare to diversity-based baselines.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 18:52:03 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Rakicevic", "Nemanja", ""], ["Cully", "Antoine", ""], ["Kormushev", "Petar", ""]]}, {"id": "2104.13467", "submitter": "Tianyu Wang", "authors": "Tianyu Wang, Shi-Yuan Ma, Logan G. Wright, Tatsuhiro Onodera, Brian\n  Richard and Peter L. McMahon", "title": "An optical neural network using less than 1 photon per multiplication", "comments": "42 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has rapidly become a widespread tool in both scientific and\ncommercial endeavors. Milestones of deep learning exceeding human performance\nhave been achieved for a growing number of tasks over the past several years,\nacross areas as diverse as game-playing, natural-language translation, and\nmedical-image analysis. However, continued progress is increasingly hampered by\nthe high energy costs associated with training and running deep neural networks\non electronic processors. Optical neural networks have attracted attention as\nan alternative physical platform for deep learning, as it has been\ntheoretically predicted that they can fundamentally achieve higher energy\nefficiency than neural networks deployed on conventional digital computers.\nHere, we experimentally demonstrate an optical neural network achieving 99%\naccuracy on handwritten-digit classification using ~3.2 detected photons per\nweight multiplication and ~90% accuracy using ~0.64 photons (~$2.4 \\times\n10^{-19}$ J of optical energy) per weight multiplication. This performance was\nachieved using a custom free-space optical processor that executes\nmatrix-vector multiplications in a massively parallel fashion, with up to ~0.5\nmillion scalar (weight) multiplications performed at the same time. Using\ncommercially available optical components and standard neural-network training\nmethods, we demonstrated that optical neural networks can operate near the\nstandard quantum limit with extremely low optical powers and still achieve high\naccuracy. Our results provide a proof-of-principle for low-optical-power\noperation, and with careful system design including the surrounding electronics\nused for data storage and control, open up a path to realizing optical\nprocessors that require only $10^{-16}$ J total energy per scalar\nmultiplication -- which is orders of magnitude more efficient than current\ndigital processors.\n", "versions": [{"version": "v1", "created": "Tue, 27 Apr 2021 20:43:23 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Wang", "Tianyu", ""], ["Ma", "Shi-Yuan", ""], ["Wright", "Logan G.", ""], ["Onodera", "Tatsuhiro", ""], ["Richard", "Brian", ""], ["McMahon", "Peter L.", ""]]}, {"id": "2104.13538", "submitter": "Adel Nikfarjam", "authors": "Adel Nikfarjam, Jakob Bossek, Aneta Neumann, Frank Neumann", "title": "Entropy-Based Evolutionary Diversity Optimisation for the Traveling\n  Salesperson Problem", "comments": null, "journal-ref": null, "doi": "10.1145/3449639.3459384", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing diverse sets of high-quality solutions has gained increasing\nattention among the evolutionary computation community in recent years. It\nallows practitioners to choose from a set of high-quality alternatives. In this\npaper, we employ a population diversity measure, called the high-order entropy\nmeasure, in an evolutionary algorithm to compute a diverse set of high-quality\nsolutions for the Traveling Salesperson Problem. In contrast to previous\nstudies, our approach allows diversifying segments of tours containing several\nedges based on the entropy measure. We examine the resulting evolutionary\ndiversity optimisation approach precisely in terms of the final set of\nsolutions and theoretical properties. Experimental results show significant\nimprovements compared to a recently proposed edge-based diversity optimisation\napproach when working with a large population of solutions or long segments.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 02:36:14 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Nikfarjam", "Adel", ""], ["Bossek", "Jakob", ""], ["Neumann", "Aneta", ""], ["Neumann", "Frank", ""]]}, {"id": "2104.13983", "submitter": "Prasanna Date", "authors": "Prasanna Date, Catherine Schuman, Bill Kay, Thomas Potok", "title": "Neuromorphic Computing is Turing-Complete", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CC cs.CL cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic computing is a non-von Neumann computing paradigm that performs\ncomputation by emulating the human brain. Neuromorphic systems are extremely\nenergy-efficient and known to consume thousands of times less power than CPUs\nand GPUs. They have the potential to drive critical use cases such as\nautonomous vehicles, edge computing and internet of things in the future. For\nthis reason, they are sought to be an indispensable part of the future\ncomputing landscape. Neuromorphic systems are mainly used for spike-based\nmachine learning applications, although there are some non-machine learning\napplications in graph theory, differential equations, and spike-based\nsimulations. These applications suggest that neuromorphic computing might be\ncapable of general-purpose computing. However, general-purpose computability of\nneuromorphic computing has not been established yet. In this work, we prove\nthat neuromorphic computing is Turing-complete and therefore capable of\ngeneral-purpose computing. Specifically, we present a model of neuromorphic\ncomputing, with just two neuron parameters (threshold and leak), and two\nsynaptic parameters (weight and delay). We devise neuromorphic circuits for\ncomputing all the {\\mu}-recursive functions (i.e., constant, successor and\nprojection functions) and all the {\\mu}-recursive operators (i.e., composition,\nprimitive recursion and minimization operators). Given that the {\\mu}-recursive\nfunctions and operators are precisely the ones that can be computed using a\nTuring machine, this work establishes the Turing-completeness of neuromorphic\ncomputing.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 19:25:01 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Date", "Prasanna", ""], ["Schuman", "Catherine", ""], ["Kay", "Bill", ""], ["Potok", "Thomas", ""]]}, {"id": "2104.14117", "submitter": "Hin Wai Lui", "authors": "Hin Wai Lui and Emre Neftci", "title": "Hessian Aware Quantization of Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To achieve the low latency, high throughput, and energy efficiency benefits\nof Spiking Neural Networks (SNNs), reducing the memory and compute requirements\nwhen running on a neuromorphic hardware is an important step. Neuromorphic\narchitecture allows massively parallel computation with variable and local\nbit-precisions. However, how different bit-precisions should be allocated to\ndifferent layers or connections of the network is not trivial. In this work, we\ndemonstrate how a layer-wise Hessian trace analysis can measure the sensitivity\nof the loss to any perturbation of the layer's weights, and this can be used to\nguide the allocation of a layer-specific bit-precision when quantizing an SNN.\nIn addition, current gradient based methods of SNN training use a complex\nneuron model with multiple state variables, which is not ideal for compute and\nmemory efficiency. To address this challenge, we present a simplified neuron\nmodel that reduces the number of state variables by 4-fold while still being\ncompatible with gradient based training. We find that the impact on model\naccuracy when using a layer-wise bit-precision correlated well with that\nlayer's Hessian trace. The accuracy of the optimal quantized network only\ndropped by 0.2%, yet the network size was reduced by 58%. This reduces memory\nusage and allows fixed-point arithmetic with simpler digital circuits to be\nused, increasing the overall throughput and energy efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 05:27:34 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Lui", "Hin Wai", ""], ["Neftci", "Emre", ""]]}, {"id": "2104.14264", "submitter": "Vivek Saraswat", "authors": "Vivek Saraswat, Ajinkya Gorad, Anand Naik, Aakash Patil, Udayan\n  Ganguly", "title": "Hardware-Friendly Synaptic Orders and Timescales in Liquid State\n  Machines for Speech Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.NE cs.SD q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Liquid State Machines are brain inspired spiking neural networks (SNNs) with\nrandom reservoir connectivity and bio-mimetic neuronal and synaptic models.\nReservoir computing networks are proposed as an alternative to deep neural\nnetworks to solve temporal classification problems. Previous studies suggest\n2nd order (double exponential) synaptic waveform to be crucial for achieving\nhigh accuracy for TI-46 spoken digits recognition. The proposal of long-time\nrange (ms) bio-mimetic synaptic waveforms is a challenge to compact and power\nefficient neuromorphic hardware. In this work, we analyze the role of synaptic\norders namely: {\\delta} (high output for single time step), 0th (rectangular\nwith a finite pulse width), 1st (exponential fall) and 2nd order (exponential\nrise and fall) and synaptic timescales on the reservoir output response and on\nthe TI-46 spoken digits classification accuracy under a more comprehensive\nparameter sweep. We find the optimal operating point to be correlated to an\noptimal range of spiking activity in the reservoir. Further, the proposed 0th\norder synapses perform at par with the biologically plausible 2nd order\nsynapses. This is substantial relaxation for circuit designers as synapses are\nthe most abundant components in an in-memory implementation for SNNs. The\ncircuit benefits for both analog and mixed-signal realizations of 0th order\nsynapse are highlighted demonstrating 2-3 orders of savings in area and power\nconsumptions by eliminating Op-Amps and Digital to Analog Converter circuits.\nThis has major implications on a complete neural network implementation with\nfocus on peripheral limitations and algorithmic simplifications to overcome\nthem.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 11:20:39 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Saraswat", "Vivek", ""], ["Gorad", "Ajinkya", ""], ["Naik", "Anand", ""], ["Patil", "Aakash", ""], ["Ganguly", "Udayan", ""]]}, {"id": "2104.14275", "submitter": "Jakob Bossek", "authors": "Jakob Bossek, Markus Wagner", "title": "Generating Instances with Performance Differences for More Than Just Two\n  Algorithms", "comments": null, "journal-ref": null, "doi": "10.1145/3449726.3463165", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Evolutionary Algorithms (EAs) have frequently been adopted\nto evolve instances for optimization problems that pose difficulties for one\nalgorithm while being rather easy for a competitor and vice versa. Typically,\nthis is achieved by either minimizing or maximizing the performance difference\nor ratio which serves as the fitness function. Repeating this process is useful\nto gain insights into strengths/weaknesses of certain algorithms or to build a\nset of instances with strong performance differences as a foundation for\nautomatic per-instance algorithm selection or configuration. We contribute to\nthis branch of research by proposing fitness-functions to evolve instances that\nshow large performance differences for more than just two algorithms\nsimultaneously. As a proof-of-principle, we evolve instances of the\nmulti-component Traveling Thief Problem~(TTP) for three incomplete TTP-solvers.\nOur results point out that our strategies are promising, but unsurprisingly\ntheir success strongly relies on the algorithms' performance complementarity.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 11:48:41 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Bossek", "Jakob", ""], ["Wagner", "Markus", ""]]}, {"id": "2104.14594", "submitter": "Kaveh Akbarzadeh-Sherbaf", "authors": "Kaveh Akbarzadeh-Sherbaf, Mikaeel Bahmani, Danial Ghiaseddin, Saeed\n  Safari, Abdol-Hossein Vahabie", "title": "A Novel Approximate Hamming Weight Computing for Spiking Neural\n  Networks: an FPGA Friendly Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hamming weights of sparse and long binary vectors are important modules in\nmany scientific applications, particularly in spiking neural networks that are\nof our interest. To improve both area and latency of their FPGA\nimplementations, we propose a method inspired from synaptic transmission\nfailure for exploiting FPGA lookup tables to compress long input vectors. To\nevaluate the effectiveness of this approach, we count the number of `1's of the\ncompressed vector using a simple linear adder. We classify the compressors into\nshallow ones with up to two levels of lookup tables and deep ones with more\nthan two levels. The architecture generated by this approach shows up to 82%\nand 35% reductions for different configurations of shallow compressors in area\nand latency respectively. Moreover, our simulation results show that\ncalculating the Hamming weight of a 1024-bit vector of a spiking neural network\nby the use of only deep compressors preserves the chaotic behavior of the\nnetwork while slightly impacts on the learning performance.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 18:27:51 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Akbarzadeh-Sherbaf", "Kaveh", ""], ["Bahmani", "Mikaeel", ""], ["Ghiaseddin", "Danial", ""], ["Safari", "Saeed", ""], ["Vahabie", "Abdol-Hossein", ""]]}, {"id": "2104.14909", "submitter": "Giovanni Iacca Prof.", "authors": "Kateryna Konotopska, Giovanni Iacca", "title": "Graph-Aware Evolutionary Algorithms for Influence Maximization", "comments": "To be published in the proceedings of ACM Genetic and Evolutionary\n  Computation Conference (GECCO) Companion 2021", "journal-ref": null, "doi": "10.1145/3449726.3463138", "report-no": null, "categories": "cs.NE cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social networks represent nowadays in many contexts the main source of\ninformation transmission and the way opinions and actions are influenced. For\ninstance, generic advertisements are way less powerful than suggestions from\nour contacts. However, this process hugely depends on the influence of people\nwho disseminate these suggestions. Therefore modern marketing often involves\npaying some targeted users, or influencers, for advertising products or ideas.\nFinding the set of nodes in a social network that lead to the highest\ninformation spread -- the so-called Influence Maximization (IM) problem -- is\ntherefore a pressing question and as such it has recently attracted a great\nresearch interest. In particular, several approaches based on Evolutionary\nAlgorithms (EAs) have been proposed, although they are known to scale poorly\nwith the graph size. In this paper, we tackle this limitation in two ways.\nFirstly, we use approximate fitness functions to speed up the EA. Secondly, we\ninclude into the EA various graph-aware mechanisms, such as smart\ninitialization, custom mutations and node filtering, to facilitate the EA\nconvergence. Our experiments show that the proposed modifications allow to\nobtain a relevant runtime gain and also improve, in some cases, the spread\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 11:15:39 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Konotopska", "Kateryna", ""], ["Iacca", "Giovanni", ""]]}, {"id": "2104.14970", "submitter": "Luis Sa-Couto", "authors": "Luis Sa-Couto and Andreas Wichert", "title": "Using brain inspired principles to unsupervisedly learn good\n  representations for visual pattern recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning has solved difficult problems in visual pattern\nrecognition, it is mostly successful in tasks where there are lots of labeled\ntraining data available. Furthermore, the global back-propagation based\ntraining rule and the amount of employed layers represents a departure from\nbiological inspiration. The brain is able to perform most of these tasks in a\nvery general way from limited to no labeled data. For these reasons it is still\na key research question to look into computational principles in the brain that\ncan help guide models to unsupervisedly learn good representations which can\nthen be used to perform tasks like classification. In this work we explore some\nof these principles to generate such representations for the MNIST data set. We\ncompare the obtained results with similar recent works and verify extremely\ncompetitive results.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 13:08:14 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Sa-Couto", "Luis", ""], ["Wichert", "Andreas", ""]]}, {"id": "2104.15064", "submitter": "Giovanni Iacca Prof.", "authors": "Hao Qiu, Leonardo Lucio Custode, Giovanni Iacca", "title": "Black-box adversarial attacks using Evolution Strategies", "comments": "To be published in the proceedings of ACM Genetic and Evolutionary\n  Computation Conference (GECCO) Companion 2021", "journal-ref": null, "doi": "10.1145/3449726.3463137", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last decade, deep neural networks have proven to be very powerful in\ncomputer vision tasks, starting a revolution in the computer vision and machine\nlearning fields. However, deep neural networks, usually, are not robust to\nperturbations of the input data. In fact, several studies showed that slightly\nchanging the content of the images can cause a dramatic decrease in the\naccuracy of the attacked neural network. Several methods able to generate\nadversarial samples make use of gradients, which usually are not available to\nan attacker in real-world scenarios. As opposed to this class of attacks,\nanother class of adversarial attacks, called black-box adversarial attacks,\nemerged, which does not make use of information on the gradients, being more\nsuitable for real-world attack scenarios. In this work, we compare three\nwell-known evolution strategies on the generation of black-box adversarial\nattacks for image classification tasks. While our results show that the\nattacked neural networks can be, in most cases, easily fooled by all the\nalgorithms under comparison, they also show that some black-box optimization\nalgorithms may be better in \"harder\" setups, both in terms of attack success\nrate and efficiency (i.e., number of queries).\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 15:33:07 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Qiu", "Hao", ""], ["Custode", "Leonardo Lucio", ""], ["Iacca", "Giovanni", ""]]}, {"id": "2104.15137", "submitter": "Nicholas Alonso", "authors": "Nick Alonso and Emre Neftci", "title": "Tightening the Biological Constraints on Gradient-Based Predictive\n  Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predictive coding (PC) is a general theory of cortical function. The local,\ngradient-based learning rules found in one kind of PC model have recently been\nshown to closely approximate backpropagation. This finding suggests that this\ngradient-based PC model may be useful for understanding how the brain solves\nthe credit assignment problem. The model may also be useful for developing\nlocal learning algorithms that are compatible with neuromorphic hardware. In\nthis paper, we modify this PC model so that it better fits biological\nconstraints, including the constraints that neurons can only have positive\nfiring rates and the constraint that synapses only flow in one direction. We\nalso compute the gradient-based weight and activity updates given the modified\nactivity values. We show that, under certain conditions, these modified PC\nnetworks perform as well or nearly as well on MNIST data as the unmodified PC\nmodel and networks trained with backpropagation.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 17:56:00 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Alonso", "Nick", ""], ["Neftci", "Emre", ""]]}]