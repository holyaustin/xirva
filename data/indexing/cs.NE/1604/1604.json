[{"id": "1604.00279", "submitter": "Moritz August", "authors": "Moritz August, Xiaotong Ni", "title": "Using Recurrent Neural Networks to Optimize Dynamical Decoupling for\n  Quantum Memory", "comments": "18 pages, comments are welcome", "journal-ref": "Phys. Rev. A 95, 012335 (2017)", "doi": "10.1103/PhysRevA.95.012335", "report-no": null, "categories": "quant-ph cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We utilize machine learning models which are based on recurrent neural\nnetworks to optimize dynamical decoupling (DD) sequences. DD is a relatively\nsimple technique for suppressing the errors in quantum memory for certain noise\nmodels. In numerical simulations, we show that with minimum use of prior\nknowledge and starting from random sequences, the models are able to improve\nover time and eventually output DD-sequences with performance better than that\nof the well known DD-families. Furthermore, our algorithm is easy to implement\nin experiments to find solutions tailored to the specific hardware, as it\ntreats the figure of merit as a black box.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 15:24:27 GMT"}, {"version": "v2", "created": "Sat, 17 Sep 2016 14:44:36 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["August", "Moritz", ""], ["Ni", "Xiaotong", ""]]}, {"id": "1604.00289", "submitter": "Brenden Lake", "authors": "Brenden M. Lake, Tomer D. Ullman, Joshua B. Tenenbaum, Samuel J.\n  Gershman", "title": "Building Machines That Learn and Think Like People", "comments": "In press at Behavioral and Brain Sciences. Open call for commentary\n  proposals (until Nov. 22, 2016).\n  https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/information/calls-for-commentary/open-calls-for-commentary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in artificial intelligence (AI) has renewed interest in\nbuilding systems that learn and think like people. Many advances have come from\nusing deep neural networks trained end-to-end in tasks such as object\nrecognition, video games, and board games, achieving performance that equals or\neven beats humans in some respects. Despite their biological inspiration and\nperformance achievements, these systems differ from human intelligence in\ncrucial ways. We review progress in cognitive science suggesting that truly\nhuman-like learning and thinking machines will have to reach beyond current\nengineering trends in both what they learn, and how they learn it.\nSpecifically, we argue that these machines should (a) build causal models of\nthe world that support explanation and understanding, rather than merely\nsolving pattern recognition problems; (b) ground learning in intuitive theories\nof physics and psychology, to support and enrich the knowledge that is learned;\nand (c) harness compositionality and learning-to-learn to rapidly acquire and\ngeneralize knowledge to new tasks and situations. We suggest concrete\nchallenges and promising routes towards these goals that can combine the\nstrengths of recent neural network advances with more structured cognitive\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 15:37:57 GMT"}, {"version": "v2", "created": "Sat, 7 May 2016 18:03:53 GMT"}, {"version": "v3", "created": "Wed, 2 Nov 2016 17:26:50 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Lake", "Brenden M.", ""], ["Ullman", "Tomer D.", ""], ["Tenenbaum", "Joshua B.", ""], ["Gershman", "Samuel J.", ""]]}, {"id": "1604.00317", "submitter": "Ehud Ben-Reuven", "authors": "Ehud Ben-Reuven and Jacob Goldberger", "title": "A Semisupervised Approach for Language Identification based on Ladder\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we address the problem of training a neuralnetwork for language\nidentification using both labeled and unlabeled speech samples in the form of\ni-vectors. We propose a neural network architecture that can also handle\nout-of-set languages. We utilize a modified version of the recently proposed\nLadder Network semisupervised training procedure that optimizes the\nreconstruction costs of a stack of denoising autoencoders. We show that this\napproach can be successfully applied to the case where the training dataset is\ncomposed of both labeled and unlabeled acoustic data. The results show enhanced\nlanguage identification on the NIST 2015 language identification dataset.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 16:26:57 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Ben-Reuven", "Ehud", ""], ["Goldberger", "Jacob", ""]]}, {"id": "1604.00359", "submitter": "Dimo Brockhoff", "authors": "Dimo Brockhoff (RANDOPT), Tea Tusar, Anne Auger (RANDOPT), Nikolaus\n  Hansen (RANDOPT)", "title": "Using Well-Understood Single-Objective Functions in Multiobjective\n  Black-Box Optimization Test Suites", "comments": "ArXiv e-prints, arXiv:1604.00359", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several test function suites are being used for numerical benchmarking of\nmultiobjective optimization algorithms. While they have some desirable\nproperties, like well-understood Pareto sets and Pareto fronts of various\nshapes, most of the currently used functions possess characteristics that are\narguably under-represented in real-world problems. They mainly stem from the\neasier construction of such functions and result in improbable properties such\nas separability, optima located exactly at the boundary constraints, and the\nexistence of variables that solely control the distance between a solution and\nthe Pareto front. Here, we propose an alternative way to constructing\nmultiobjective problems-by combining existing single-objective problems from\nthe literature. We describe in particular the bbob-biobj test suite with 55\nbi-objective functions in continuous domain, and its extended version with 92\nbi-objective functions (bbob-biobj-ext). Both test suites have been implemented\nin the COCO platform for black-box optimization benchmarking. Finally, we\nrecommend a general procedure for creating test suites for an arbitrary number\nof objectives. Besides providing the formal function definitions and presenting\ntheir (known) properties, this paper also aims at giving the rationale behind\nour approach in terms of groups of functions with similar properties, objective\nspace normalization, and problem instances. The latter allows us to easily\ncompare the performance of deterministic and stochastic solvers, which is an\noften overlooked issue in benchmarking.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 18:55:05 GMT"}, {"version": "v2", "created": "Wed, 25 May 2016 06:49:31 GMT"}, {"version": "v3", "created": "Fri, 4 Jan 2019 09:47:43 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Brockhoff", "Dimo", "", "RANDOPT"], ["Tusar", "Tea", "", "RANDOPT"], ["Auger", "Anne", "", "RANDOPT"], ["Hansen", "Nikolaus", "", "RANDOPT"]]}, {"id": "1604.00457", "submitter": "Wenlian Lu", "authors": "Ren Zheng, Xinlei Yi, Wenlian Lu, Tianping Chen", "title": "Stability of Analytic Neural Networks with Event-triggered Synaptic\n  Feedbacks", "comments": "12 pages, 3 figures. arXiv admin note: substantial text overlap with\n  arXiv:1504.08081", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems, Vol.\n  27, No. 2, 483-494, 2016", "doi": "10.1109/TNNLS.2015.2488903", "report-no": null, "categories": "cs.NE math.DS nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate stability of a class of analytic neural\nnetworks with the synaptic feedback via event-triggered rules. This model is\ngeneral and include Hopfield neural network as a special case. These\nevent-trigger rules can efficiently reduces loads of computation and\ninformation transmission at synapses of the neurons. The synaptic feedback of\neach neuron keeps a constant value based on the outputs of the other neurons at\nits latest triggering time but changes at its next triggering time, which is\ndetermined by certain criterion. It is proved that every trajectory of the\nanalytic neural network converges to certain equilibrium under this\nevent-triggered rule for all initial values except a set of zero measure. The\nmain technique of the proof is the Lojasiewicz inequality to prove the\nfiniteness of trajectory length. The realization of this event-triggered rule\nis verified by the exclusion of Zeno behaviors. Numerical examples are provided\nto illustrate the efficiency of the theoretical results.\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2016 04:12:58 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Zheng", "Ren", ""], ["Yi", "Xinlei", ""], ["Lu", "Wenlian", ""], ["Chen", "Tianping", ""]]}, {"id": "1604.00462", "submitter": "Wenlian Lu", "authors": "Wenlian Lu, Ren Zheng, Tianping Chen", "title": "Centralized and Decentralized Global Outer-synchronization of Asymmetric\n  Recurrent Time-varying Neural Network by Data-sampling", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.SY math.CA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the outer-synchronization of the asymmetrically\nconnected recurrent time-varying neural networks. By both centralized and\ndecentralized discretization data sampling principles, we derive several\nsufficient conditions based on diverse vector norms that guarantee that any two\ntrajectories from different initial values of the identical neural network\nsystem converge together. The lower bounds of the common time intervals between\ndata samples in centralized and decentralized principles are proved to be\npositive, which guarantees exclusion of Zeno behavior. A numerical example is\nprovided to illustrate the efficiency of the theoretical results.\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2016 05:04:12 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Lu", "Wenlian", ""], ["Zheng", "Ren", ""], ["Chen", "Tianping", ""]]}, {"id": "1604.00552", "submitter": "Mukhtiar Ali Unar", "authors": "Niaz Ahmed Memon, Mukhtiar Ali Unar, Abdul Khalique Ansari", "title": "pH Prediction by Artificial Neural Networks for the Drinking Water of\n  the Distribution System of Hyderabad City", "comments": "10 pages, Mehran University Research Journal of Engineering and\n  Technology, Vol. 31, No. 1, January 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this research, feedforward ANN (Artificial Neural Network) model is\ndeveloped and validated for predicting the pH at 10 different locations of the\ndistribution system of drinking water of Hyderabad city. The developed model is\nMLP (Multilayer Perceptron) with back propagation algorithm.The data for the\ntraining and testing of the model are collected through an experimental\nanalysis on weekly basis in a routine examination for maintaining the quality\nof drinking water in the city. 17 parameters are taken into consideration\nincluding pH. These all parameters are taken as input variables for the model\nand then pH is predicted for 03 phases;raw water of river Indus,treated water\nin the treatment plants and then treated water in the distribution system of\ndrinking water. The training and testing results of this model reveal that MLP\nneural networks are exceedingly extrapolative for predicting the pH of river\nwater, untreated and treated water at all locations of the distribution system\nof drinking water of Hyderabad city. The optimum input and output weights are\ngenerated with minimum MSE (Mean Square Error) < 5%.Experimental, predicted and\ntested values of pH are plotted and the effectiveness of the model is\ndetermined by calculating the coefficient of correlation (R2=0.999) of trained\nand tested results.\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2016 20:14:18 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Memon", "Niaz Ahmed", ""], ["Unar", "Mukhtiar Ali", ""], ["Ansari", "Abdul Khalique", ""]]}, {"id": "1604.00558", "submitter": "Mukhtiar Ali Unar", "authors": "Saba Baloch, Javed Ali Baloch, Mukhtiar Ali Unar", "title": "Channel Equalization Using Multilayer Perceptron Networks", "comments": "6 pages, Mehran University Research Journal of Engineering and\n  Technology, Vol. 31, No. 3, July 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In most digital communication systems, bandwidth limited channel along with\nmultipath propagation causes ISI (Inter Symbol Interference) to occur. This\nphenomenon causes distortion of the given transmitted symbol due to other\ntransmitted symbols. With the help of equalization ISI can be reduced. This\npaper presents a solution to the ISI problem by performing blind equalization\nusing ANN (Artificial Neural Networks). The simulated network is a multilayer\nfeedforward Perceptron ANN, which has been trained by utilizing the error\nback-propagation algorithm. The weights of the network are updated in\naccordance with training of the network. This paper presents a very effective\nmethod for blind channel equalization, being more efficient than the\npre-existing algorithms. The obtained results show a visible reduction in the\nnoise content.\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2016 21:00:54 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Baloch", "Saba", ""], ["Baloch", "Javed Ali", ""], ["Unar", "Mukhtiar Ali", ""]]}, {"id": "1604.00562", "submitter": "Jacob Andreas", "authors": "Jacob Andreas and Dan Klein", "title": "Reasoning About Pragmatics with Neural Listeners and Speakers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a model for pragmatically describing scenes, in which contrastive\nbehavior results from a combination of inference-driven pragmatics and learned\nsemantics. Like previous learned approaches to language generation, our model\nuses a simple feature-driven architecture (here a pair of neural \"listener\" and\n\"speaker\" models) to ground language in the world. Like inference-driven\napproaches to pragmatics, our model actively reasons about listener behavior\nwhen selecting utterances. For training, our approach requires only ordinary\ncaptions, annotated _without_ demonstration of the pragmatic behavior the model\nultimately exhibits. In human evaluations on a referring expression game, our\napproach succeeds 81% of the time, compared to a 69% success rate using\nexisting techniques.\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2016 21:52:03 GMT"}, {"version": "v2", "created": "Mon, 26 Sep 2016 13:48:20 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Andreas", "Jacob", ""], ["Klein", "Dan", ""]]}, {"id": "1604.00642", "submitter": "Moein Sarvaghad-Moghaddam", "authors": "Moein Sarvaghad-Moghaddam", "title": "Multi-objective design of quantum circuits using genetic programming", "comments": "This paper has been withdrawn by the author due to some of\n  modifications in structures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing is a new way of data processing based on the concept of\nquantum mechanics. Quantum circuit design is a process of converting a quantum\ngate to a series of basic gates and is divided into two general categories\nbased on the decomposition and composition. In the second group, using\nevolutionary algorithms and especially genetic algorithms, multiplication of\nmatrix gates was used to achieve the final characteristic of quantum circuit.\nGenetic programming is a subfield of evolutionary computing in which computer\nprograms evolve to solve studied problems. In past research that has been done\nin the field of quantum circuits design, only one cost metrics (usually quantum\ncost) has been investigated. In this paper for the first time, a\nmulti-objective approach has been provided to design quantum circuits using\ngenetic programming that considers the depth and the cost of nearest neighbor\nmetrics in addition to quantum cost metric. Another innovation of this article\nis the use of two-step fitness function and taking into account the equivalence\nof global phase in quantum gates. The results show that the proposed method is\nable to find a good answer in a short time.\n", "versions": [{"version": "v1", "created": "Sun, 3 Apr 2016 14:33:15 GMT"}, {"version": "v2", "created": "Sat, 28 May 2016 09:19:04 GMT"}, {"version": "v3", "created": "Tue, 14 Mar 2017 15:48:36 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Sarvaghad-Moghaddam", "Moein", ""]]}, {"id": "1604.00644", "submitter": "Fabricio de Franca Olivetti", "authors": "Karine da Silva Miras de Ara\\'ujo, Fabr\\'icio Olivetti de Fran\\c{c}a", "title": "An electronic-game framework for evaluating coevolutionary algorithms", "comments": "This paper is a translation of \\cite{karine2015}, published in\n  Portuguese at Brazilian Congress on Computational Intelligence, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the common artificial intelligence applications in electronic games\nconsists of making an artificial agent learn how to execute some determined\ntask successfully in a game environment. One way to perform this task is\nthrough machine learning algorithms capable of learning the sequence of actions\nrequired to win in a given game environment. There are several supervised\nlearning techniques able to learn the correct answer for a problem through\nexamples. However, when learning how to play electronic games, the correct\nanswer might only be known by the end of the game, after all the actions were\nalready taken. Thus, not being possible to measure the accuracy of each\nindividual action to be taken at each time step. A way for dealing with this\nproblem is through Neuroevolution, a method which trains Artificial Neural\nNetworks using evolutionary algorithms. In this article, we introduce a\nframework for testing optimization algorithms with artificial agent controllers\nin electronic games, called EvoMan, which is inspired in the action-platformer\ngame Mega Man II. The environment can be configured to run in different\nexperiment modes, as single evolution, coevolution and others. To demonstrate\nsome challenges regarding the proposed platform, as initial experiments we\napplied Neuroevolution using Genetic Algorithms and the NEAT algorithm, in the\ncontext of competitively coevolving two distinct agents in this game.\n", "versions": [{"version": "v1", "created": "Sun, 3 Apr 2016 14:57:24 GMT"}, {"version": "v2", "created": "Mon, 11 Apr 2016 18:35:29 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["de Ara\u00fajo", "Karine da Silva Miras", ""], ["de Fran\u00e7a", "Fabr\u00edcio Olivetti", ""]]}, {"id": "1604.00697", "submitter": "Wei Wen", "authors": "Wei Wen, Chunpeng Wu, Yandan Wang, Kent Nixon, Qing Wu, Mark Barnell,\n  Hai Li, Yiran Chen", "title": "A New Learning Method for Inference Accuracy, Core Occupation, and\n  Performance Co-optimization on TrueNorth Chip", "comments": "6 pages; 9 figures; DAC 2016", "journal-ref": null, "doi": "10.1145/2897937.2897968", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IBM TrueNorth chip uses digital spikes to perform neuromorphic computing and\nachieves ultrahigh execution parallelism and power efficiency. However, in\nTrueNorth chip, low quantization resolution of the synaptic weights and spikes\nsignificantly limits the inference (e.g., classification) accuracy of the\ndeployed neural network model. Existing workaround, i.e., averaging the results\nover multiple copies instantiated in spatial and temporal domains, rapidly\nexhausts the hardware resources and slows down the computation. In this work,\nwe propose a novel learning method on TrueNorth platform that constrains the\nrandom variance of each computation copy and reduces the number of needed\ncopies. Compared to the existing learning method, our method can achieve up to\n68.8% reduction of the required neuro-synaptic cores or 6.5X speedup, with even\nslightly improved inference accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 3 Apr 2016 22:44:00 GMT"}, {"version": "v2", "created": "Tue, 12 Jul 2016 03:49:21 GMT"}, {"version": "v3", "created": "Sat, 16 Jul 2016 05:09:04 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Wen", "Wei", ""], ["Wu", "Chunpeng", ""], ["Wang", "Yandan", ""], ["Nixon", "Kent", ""], ["Wu", "Qing", ""], ["Barnell", "Mark", ""], ["Li", "Hai", ""], ["Chen", "Yiran", ""]]}, {"id": "1604.00861", "submitter": "Heikki Huttunen", "authors": "Giambattista Parascandolo, Heikki Huttunen, Tuomas Virtanen", "title": "Recurrent Neural Networks for Polyphonic Sound Event Detection in Real\n  Life Recordings", "comments": "To appean in Proceedings of IEEE ICASSP 2016", "journal-ref": null, "doi": "10.1109/ICASSP.2016.7472917", "report-no": null, "categories": "cs.SD cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an approach to polyphonic sound event detection in\nreal life recordings based on bi-directional long short term memory (BLSTM)\nrecurrent neural networks (RNNs). A single multilabel BLSTM RNN is trained to\nmap acoustic features of a mixture signal consisting of sounds from multiple\nclasses, to binary activity indicators of each event class. Our method is\ntested on a large database of real-life recordings, with 61 classes (e.g.\nmusic, car, speech) from 10 different everyday contexts. The proposed method\noutperforms previous approaches by a large margin, and the results are further\nimproved using data augmentation techniques. Overall, our system reports an\naverage F1-score of 65.5% on 1 second blocks and 64.7% on single frames, a\nrelative improvement over previous state-of-the-art approach of 6.8% and 15.1%\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2016 13:54:09 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Parascandolo", "Giambattista", ""], ["Huttunen", "Heikki", ""], ["Virtanen", "Tuomas", ""]]}, {"id": "1604.00981", "submitter": "Jianmin Chen", "authors": "Jianmin Chen, Xinghao Pan, Rajat Monga, Samy Bengio and Rafal\n  Jozefowicz", "title": "Revisiting Distributed Synchronous SGD", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed training of deep learning models on large-scale training data is\ntypically conducted with asynchronous stochastic optimization to maximize the\nrate of updates, at the cost of additional noise introduced from asynchrony. In\ncontrast, the synchronous approach is often thought to be impractical due to\nidle time wasted on waiting for straggling workers. We revisit these\nconventional beliefs in this paper, and examine the weaknesses of both\napproaches. We demonstrate that a third approach, synchronous optimization with\nbackup workers, can avoid asynchronous noise while mitigating for the worst\nstragglers. Our approach is empirically validated and shown to converge faster\nand to better test accuracies.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2016 18:40:05 GMT"}, {"version": "v2", "created": "Fri, 15 Apr 2016 18:49:12 GMT"}, {"version": "v3", "created": "Tue, 21 Mar 2017 07:44:39 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Chen", "Jianmin", ""], ["Pan", "Xinghao", ""], ["Monga", "Rajat", ""], ["Bengio", "Samy", ""], ["Jozefowicz", "Rafal", ""]]}, {"id": "1604.01088", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr", "title": "Optimal Parameter Settings for the $(1+(\\lambda, \\lambda))$ Genetic\n  Algorithm", "comments": "Extended version of a paper that appeared at GECCO'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $(1+(\\lambda,\\lambda))$ genetic algorithm is one of the few algorithms\nfor which a super-constant speed-up through the use of crossover could be\nproven. So far, this algorithm has been used with parameters based also on\nintuitive considerations. In this work, we rigorously regard the whole\nparameter space and show that the asymptotic time complexity proven by Doerr\nand Doerr (GECCO 2015) for the intuitive choice is best possible among all\nsettings for population size, mutation probability, and crossover bias.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2016 23:19:00 GMT"}, {"version": "v2", "created": "Fri, 29 Jul 2016 00:14:24 GMT"}], "update_date": "2016-08-01", "authors_parsed": [["Doerr", "Benjamin", ""]]}, {"id": "1604.01416", "submitter": "Steven Eliuk", "authors": "Steven Eliuk, Cameron Upright, Anthony Skjellum", "title": "dMath: A Scalable Linear Algebra and Math Library for Heterogeneous\n  GP-GPU Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new scalable parallel math library, dMath, is presented in this paper that\ndemonstrates leading scaling when using intranode, or internode,\nhybrid-parallelism for deep-learning. dMath provides easy-to-use distributed\nbase primitives and a variety of domain-specific algorithms. These include\nmatrix multiplication, convolutions, and others allowing for rapid development\nof highly scalable applications, including Deep Neural Networks (DNN), whereas\npreviously one was restricted to libraries that provided effective primitives\nfor only a single GPU, like Nvidia cublas and cudnn or DNN primitives from\nNervana neon framework. Development of HPC software is difficult,\nlabor-intensive work, requiring a unique skill set. dMath allows a wide range\nof developers to utilize parallel and distributed hardware easily. One\ncontribution of this approach is that data is stored persistently on the GPU\nhardware, avoiding costly transfers between host and device. Advanced memory\nmanagement techniques are utilized, including caching of transferred data and\nmemory reuse through pooling. A key contribution of dMath is that it delivers\nperformance, portability, and productivity to its specific domain of support.\nIt enables algorithm and application programmers to quickly solve problems\nwithout managing the significant complexity associated with multi-level\nparallelism.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 20:28:26 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Eliuk", "Steven", ""], ["Upright", "Cameron", ""], ["Skjellum", "Anthony", ""]]}, {"id": "1604.01485", "submitter": "Ilija Ilievski", "authors": "Ilija Ilievski, Shuicheng Yan, Jiashi Feng", "title": "A Focused Dynamic Attention Model for Visual Question Answering", "comments": "Submitted to ECCV 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual Question and Answering (VQA) problems are attracting increasing\ninterest from multiple research disciplines. Solving VQA problems requires\ntechniques from both computer vision for understanding the visual contents of a\npresented image or video, as well as the ones from natural language processing\nfor understanding semantics of the question and generating the answers.\nRegarding visual content modeling, most of existing VQA methods adopt the\nstrategy of extracting global features from the image or video, which\ninevitably fails in capturing fine-grained information such as spatial\nconfiguration of multiple objects. Extracting features from auto-generated\nregions -- as some region-based image recognition methods do -- cannot\nessentially address this problem and may introduce some overwhelming irrelevant\nfeatures with the question. In this work, we propose a novel Focused Dynamic\nAttention (FDA) model to provide better aligned image content representation\nwith proposed questions. Being aware of the key words in the question, FDA\nemploys off-the-shelf object detector to identify important regions and fuse\nthe information from the regions and global features via an LSTM unit. Such\nquestion-driven representations are then combined with question representation\nand fed into a reasoning unit for generating the answers. Extensive evaluation\non a large-scale benchmark dataset, VQA, clearly demonstrate the superior\nperformance of FDA over well-established baselines.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 05:16:10 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Ilievski", "Ilija", ""], ["Yan", "Shuicheng", ""], ["Feng", "Jiashi", ""]]}, {"id": "1604.01495", "submitter": "Mojgan Pourhassan", "authors": "Mojgan Pourhassan, Feng Shi, Frank Neumann", "title": "Parameterized Analysis of Multi-objective Evolutionary Algorithms and\n  the Weighted Vertex Cover Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rigorous runtime analysis of evolutionary multi-objective optimization for\nthe classical vertex cover problem in the context of parameterized complexity\nanalysis has been presented by Kratsch and Neumann (2013). In this paper, we\nextend the analysis to the weighted vertex cover problem and provide a fixed\nparameter evolutionary algorithm with respect to OPT, the cost of the the\noptimal solution for the problem. Moreover, using a diversity mechanisms, we\npresent a multi-objective evolutionary algorithm that finds a 2-approximation\nin expected polynomial time and introduce a population-based evolutionary\nalgorithm which finds a $(1+\\varepsilon)$-approximation in expected time\n$O(n\\cdot 2^{\\min \\{n,2(1- \\varepsilon)OPT \\}} + n^3)$.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 05:56:26 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Pourhassan", "Mojgan", ""], ["Shi", "Feng", ""], ["Neumann", "Frank", ""]]}, {"id": "1604.01537", "submitter": "Xiaoyuan Yi", "authors": "Xiaoyuan Yi, Ruoyu Li, Maosong Sun", "title": "Generating Chinese Classical Poems with RNN Encoder-Decoder", "comments": "12 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take the generation of Chinese classical poem lines as a\nsequence-to-sequence learning problem, and build a novel system based on the\nRNN Encoder-Decoder structure to generate quatrains (Jueju in Chinese), with a\ntopic word as input. Our system can jointly learn semantic meaning within a\nsingle line, semantic relevance among lines in a poem, and the use of\nstructural, rhythmical and tonal patterns, without utilizing any constraint\ntemplates. Experimental results show that our system outperforms other\ncompetitive systems. We also find that the attention mechanism can capture the\nword associations in Chinese classical poetry and inverting target lines in\ntraining can improve performance.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 08:26:31 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Yi", "Xiaoyuan", ""], ["Li", "Ruoyu", ""], ["Sun", "Maosong", ""]]}, {"id": "1604.01643", "submitter": "Junzhi Li", "authors": "Junzhi Li and Ying Tan", "title": "Information Utilization Ratio in Heuristic Optimization Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heuristic algorithms are able to optimize objective functions efficiently\nbecause they use intelligently the information about the objective functions.\nThus, information utilization is critical to the performance of heuristics.\nHowever, the concept of information utilization has remained vague and abstract\nbecause there is no reliable metric to reflect the extent to which the\ninformation about the objective function is utilized by heuristic algorithms.\nIn this paper, the metric of information utilization ratio (IUR) is defined,\nwhich is the ratio of the utilized information quantity over the acquired\ninformation quantity in the search process. The IUR proves to be well-defined.\nSeveral examples of typical heuristic algorithms are given to demonstrate the\nprocedure of calculating the IUR. Empirical evidences on the correlation\nbetween the IUR and the performance of a heuristic are also provided. The IUR\ncan be an index of how finely an algorithm is designed and guide the invention\nof new heuristics and the improvement of existing ones.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 14:35:11 GMT"}, {"version": "v2", "created": "Thu, 15 Sep 2016 17:53:17 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Li", "Junzhi", ""], ["Tan", "Ying", ""]]}, {"id": "1604.01662", "submitter": "Hao Wang", "authors": "Hao Wang and Dit-Yan Yeung", "title": "A Survey on Bayesian Deep Learning", "comments": "Published in ACM Computing Surveys (CSUR) 2020. Constantly updating\n  project page at https://github.com/js05212/BayesianDeepLearning-Survey", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A comprehensive artificial intelligence system needs to not only perceive the\nenvironment with different `senses' (e.g., seeing and hearing) but also infer\nthe world's conditional (or even causal) relations and corresponding\nuncertainty. The past decade has seen major advances in many perception tasks\nsuch as visual object recognition and speech recognition using deep learning\nmodels. For higher-level inference, however, probabilistic graphical models\nwith their Bayesian nature are still more powerful and flexible. In recent\nyears, Bayesian deep learning has emerged as a unified probabilistic framework\nto tightly integrate deep learning and Bayesian models. In this general\nframework, the perception of text or images using deep learning can boost the\nperformance of higher-level inference and in turn, the feedback from the\ninference process is able to enhance the perception of text or images. This\nsurvey provides a comprehensive introduction to Bayesian deep learning and\nreviews its recent applications on recommender systems, topic models, control,\netc. Besides, we also discuss the relationship and differences between Bayesian\ndeep learning and other related topics such as Bayesian treatment of neural\nnetworks. For a constantly updating project page, please refer to\nhttps://github.com/js05212/BayesianDeepLearning-Survey.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 15:35:08 GMT"}, {"version": "v2", "created": "Thu, 7 Apr 2016 06:17:44 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 03:52:57 GMT"}, {"version": "v4", "created": "Wed, 6 Jan 2021 03:14:13 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Wang", "Hao", ""], ["Yeung", "Dit-Yan", ""]]}, {"id": "1604.01792", "submitter": "Tom Sercu", "authors": "Tom Sercu, Vaibhava Goel", "title": "Advances in Very Deep Convolutional Neural Networks for LVCSR", "comments": "Proc. Interspeech 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Very deep CNNs with small 3x3 kernels have recently been shown to achieve\nvery strong performance as acoustic models in hybrid NN-HMM speech recognition\nsystems. In this paper we investigate how to efficiently scale these models to\nlarger datasets. Specifically, we address the design choice of pooling and\npadding along the time dimension which renders convolutional evaluation of\nsequences highly inefficient. We propose a new CNN design without timepadding\nand without timepooling, which is slightly suboptimal for accuracy, but has two\nsignificant advantages: it enables sequence training and deployment by allowing\nefficient convolutional evaluation of full utterances, and, it allows for batch\nnormalization to be straightforwardly adopted to CNNs on sequence data. Through\nbatch normalization, we recover the lost peformance from removing the\ntime-pooling, while keeping the benefit of efficient convolutional evaluation.\nWe demonstrate the performance of our models both on larger scale data than\nbefore, and after sequence training. Our very deep CNN model sequence trained\non the 2000h switchboard dataset obtains 9.4 word error rate on the Hub5\ntest-set, matching with a single model the performance of the 2015 IBM system\ncombination, which was the previous best published result.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 20:07:52 GMT"}, {"version": "v2", "created": "Sat, 25 Jun 2016 00:27:19 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Sercu", "Tom", ""], ["Goel", "Vaibhava", ""]]}, {"id": "1604.01946", "submitter": "Phil Blunsom", "authors": "Jeremy Appleyard, Tomas Kocisky, Phil Blunsom", "title": "Optimizing Performance of Recurrent Neural Networks on GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As recurrent neural networks become larger and deeper, training times for\nsingle networks are rising into weeks or even months. As such there is a\nsignificant incentive to improve the performance and scalability of these\nnetworks. While GPUs have become the hardware of choice for training and\ndeploying recurrent models, the implementations employed often make use of only\nbasic optimizations for these architectures. In this article we demonstrate\nthat by exposing parallelism between operations within the network, an order of\nmagnitude speedup across a range of network sizes can be achieved over a naive\nimplementation. We describe three stages of optimization that have been\nincorporated into the fifth release of NVIDIA's cuDNN: firstly optimizing a\nsingle cell, secondly a single layer, and thirdly the entire network.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 10:31:01 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Appleyard", "Jeremy", ""], ["Kocisky", "Tomas", ""], ["Blunsom", "Phil", ""]]}, {"id": "1604.01952", "submitter": "David Balduzzi", "authors": "David Balduzzi", "title": "Deep Online Convex Optimization with Gated Games", "comments": "13 pages. This paper renders arXiv:1509.01851 obsolete. It contains\n  the same basic results, with major changes to exposition and minor changes to\n  terminology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods from convex optimization are widely used as building blocks for deep\nlearning algorithms. However, the reasons for their empirical success are\nunclear, since modern convolutional networks (convnets), incorporating\nrectifier units and max-pooling, are neither smooth nor convex. Standard\nguarantees therefore do not apply. This paper provides the first convergence\nrates for gradient descent on rectifier convnets. The proof utilizes the\nparticular structure of rectifier networks which consists in binary\nactive/inactive gates applied on top of an underlying linear network. The\napproach generalizes to max-pooling, dropout and maxout. In other words, to\nprecisely the neural networks that perform best empirically. The key step is to\nintroduce gated games, an extension of convex games with similar convergence\nproperties that capture the gating function of rectifiers. The main result is\nthat rectifier convnets converge to a critical point at a rate controlled by\nthe gated-regret of the units in the network. Corollaries of the main result\ninclude: (i) a game-theoretic description of the representations learned by a\nneural network; (ii) a logarithmic-regret algorithm for training neural nets;\nand (iii) a formal setting for analyzing conditional computation in neural nets\nthat can be applied to recently developed models of attention.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 10:46:54 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Balduzzi", "David", ""]]}, {"id": "1604.02085", "submitter": "Daniel Heger", "authors": "Daniel Heger and Katharina Krischer", "title": "A robust autoassociative memory with coupled networks of Kuramoto-type\n  oscillators", "comments": null, "journal-ref": null, "doi": "10.1103/PhysRevE.94.022309", "report-no": null, "categories": "nlin.AO cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertain recognition success, unfavorable scaling of connection complexity\nor dependence on complex external input impair the usefulness of current\noscillatory neural networks for pattern recognition or restrict technical\nrealizations to small networks. We propose a new network architecture of\ncoupled oscillators for pattern recognition which shows none of the mentioned\naws. Furthermore we illustrate the recognition process with simulation results\nand analyze the new dynamics analytically: Possible output patterns are\nisolated attractors of the system. Additionally, simple criteria for\nrecognition success are derived from a lower bound on the basins of attraction.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 17:31:13 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2016 06:10:29 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Heger", "Daniel", ""], ["Krischer", "Katharina", ""]]}, {"id": "1604.02313", "submitter": "Dimitri Nowicki", "authors": "Artem Chernodub and Dimitri Nowicki", "title": "Norm-preserving Orthogonal Permutation Linear Unit Activation Functions\n  (OPLU)", "comments": "Submitted to conference ICANN'2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel activation function that implements piece-wise orthogonal\nnon-linear mappings based on permutations. It is straightforward to implement,\nand very computationally efficient, also it has little memory requirements. We\ntested it on two toy problems for feedforward and recurrent networks, it shows\nsimilar performance to tanh and ReLU. OPLU activation function ensures norm\npreservance of the backpropagated gradients, therefore it is potentially good\nfor the training of deep, extra deep, and recurrent neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 8 Apr 2016 11:39:31 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2016 16:10:20 GMT"}, {"version": "v3", "created": "Mon, 4 Jul 2016 14:18:29 GMT"}, {"version": "v4", "created": "Thu, 12 Jan 2017 14:30:45 GMT"}, {"version": "v5", "created": "Tue, 31 Jan 2017 21:24:36 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Chernodub", "Artem", ""], ["Nowicki", "Dimitri", ""]]}, {"id": "1604.02355", "submitter": "Carola Doerr", "authors": "Carola Doerr, Johannes Lengler", "title": "The (1+1) Elitist Black-Box Complexity of LeadingOnes", "comments": "An extended abstract of this paper will appear at GECCO 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One important goal of black-box complexity theory is the development of\ncomplexity models allowing to derive meaningful lower bounds for whole classes\nof randomized search heuristics. Complementing classical runtime analysis,\nblack-box models help us understand how algorithmic choices such as the\npopulation size, the variation operators, or the selection rules influence the\noptimization time. One example for such a result is the $\\Omega(n \\log n)$\nlower bound for unary unbiased algorithms on functions with a unique global\noptimum [Lehre/Witt, GECCO 2010], which tells us that higher arity operators or\nbiased sampling strategies are needed when trying to beat this bound. In lack\nof analyzing techniques, almost no non-trivial bounds are known for other\nrestricted models. Proving such bounds therefore remains to be one of the main\nchallenges in black-box complexity theory.\n  With this paper we contribute to our technical toolbox for lower bound\ncomputations by proposing a new type of information-theoretic argument. We\nregard the permutation- and bit-invariant version of \\textsc{LeadingOnes} and\nprove that its (1+1) elitist black-box complexity is $\\Omega(n^2)$, a bound\nthat is matched by (1+1)-type evolutionary algorithms. The (1+1) elitist\ncomplexity of \\textsc{LeadingOnes} is thus considerably larger than its\nunrestricted one, which is known to be of order $n\\log\\log n$ [Afshani et al.,\n2013].\n", "versions": [{"version": "v1", "created": "Fri, 8 Apr 2016 13:36:52 GMT"}], "update_date": "2016-04-11", "authors_parsed": [["Doerr", "Carola", ""], ["Lengler", "Johannes", ""]]}, {"id": "1604.02376", "submitter": "Jyothi Korra", "authors": "Jyothi Korra", "title": "Finding Optimal Combination of Kernels using Genetic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Computer Vision, problem of identifying or classifying the objects present\nin an image is called Object Categorization. It is a challenging problem,\nespecially when the images have clutter background, occlusions or different\nlighting conditions. Many vision features have been proposed which aid object\ncategorization even in such adverse conditions. Past research has shown that,\nemploying multiple features rather than any single features leads to better\nrecognition. Multiple Kernel Learning (MKL) framework has been developed for\nlearning an optimal combination of features for object categorization. Existing\nMKL methods use linear combination of base kernels which may not be optimal for\nobject categorization. Real-world object categorization may need to consider\ncomplex combination of kernels(non-linear) and not only linear combination.\nEvolving non-linear functions of base kernels using Genetic Programming is\nproposed in this report. Experiment results show that non-kernel generated\nusing genetic programming gives good accuracy as compared to linear combination\nof kernels.\n", "versions": [{"version": "v1", "created": "Fri, 8 Apr 2016 15:33:30 GMT"}, {"version": "v2", "created": "Fri, 22 Apr 2016 23:16:20 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Korra", "Jyothi", ""]]}, {"id": "1604.02416", "submitter": "Michael Mozer", "authors": "Mohammad Khajah and Robert V. Lindsey and Michael C. Mozer", "title": "How deep is knowledge tracing?", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In theoretical cognitive science, there is a tension between highly\nstructured models whose parameters have a direct psychological interpretation\nand highly complex, general-purpose models whose parameters and representations\nare difficult to interpret. The former typically provide more insight into\ncognition but the latter often perform better. This tension has recently\nsurfaced in the realm of educational data mining, where a deep learning\napproach to predicting students' performance as they work through a series of\nexercises---termed deep knowledge tracing or DKT---has demonstrated a stunning\nperformance advantage over the mainstay of the field, Bayesian knowledge\ntracing or BKT. In this article, we attempt to understand the basis for DKT's\nadvantage by considering the sources of statistical regularity in the data that\nDKT can leverage but which BKT cannot. We hypothesize four forms of regularity\nthat BKT fails to exploit: recency effects, the contextualized trial sequence,\ninter-skill similarity, and individual variation in ability. We demonstrate\nthat when BKT is extended to allow it more flexibility in modeling statistical\nregularities---using extensions previously proposed in the literature---BKT\nachieves a level of performance indistinguishable from that of DKT. We argue\nthat while DKT is a powerful, useful, general-purpose framework for modeling\nstudent learning, its gains do not come from the discovery of novel\nrepresentations---the fundamental advantage of deep learning. To answer the\nquestion posed in our title, knowledge tracing may be a domain that does not\nrequire `depth'; shallow models like BKT can perform just as well and offer us\ngreater interpretability and explanatory power.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2016 04:20:55 GMT"}, {"version": "v2", "created": "Tue, 21 Jun 2016 04:51:22 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Khajah", "Mohammad", ""], ["Lindsey", "Robert V.", ""], ["Mozer", "Michael C.", ""]]}, {"id": "1604.02594", "submitter": "Zhiyun Lu", "authors": "Zhiyun Lu, Vikas Sindhwani, Tara N. Sainath", "title": "Learning Compact Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs), including long short-term memory (LSTM)\nRNNs, have produced state-of-the-art results on a variety of speech recognition\ntasks. However, these models are often too large in size for deployment on\nmobile devices with memory and latency constraints. In this work, we study\nmechanisms for learning compact RNNs and LSTMs via low-rank factorizations and\nparameter sharing schemes. Our goal is to investigate redundancies in recurrent\narchitectures where compression can be admitted without losing performance. A\nhybrid strategy of using structured matrices in the bottom layers and shared\nlow-rank factors on the top layers is found to be particularly effective,\nreducing the parameters of a standard LSTM by 75%, at a small cost of 0.3%\nincrease in WER, on a 2,000-hr English Voice Search task.\n", "versions": [{"version": "v1", "created": "Sat, 9 Apr 2016 19:09:22 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Lu", "Zhiyun", ""], ["Sindhwani", "Vikas", ""], ["Sainath", "Tara N.", ""]]}, {"id": "1604.02646", "submitter": "Biswajit Paria", "authors": "Biswajit Paria, Vikas Reddy, Anirban Santara, Pabitra Mitra", "title": "Visualization Regularizers for Neural Network based Image Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep neural networks is mostly due their ability to learn\nmeaningful features from the data. Features learned in the hidden layers of\ndeep neural networks trained in computer vision tasks have been shown to be\nsimilar to mid-level vision features. We leverage this fact in this work and\npropose the visualization regularizer for image tasks. The proposed\nregularization technique enforces smoothness of the features learned by hidden\nnodes and turns out to be a special case of Tikhonov regularization. We achieve\nhigher classification accuracy as compared to existing regularizers such as the\nL2 norm regularizer and dropout, on benchmark datasets without changing the\ntraining computational complexity.\n", "versions": [{"version": "v1", "created": "Sun, 10 Apr 2016 07:02:40 GMT"}, {"version": "v2", "created": "Sun, 15 May 2016 14:38:38 GMT"}, {"version": "v3", "created": "Tue, 3 Jan 2017 10:07:22 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Paria", "Biswajit", ""], ["Reddy", "Vikas", ""], ["Santara", "Anirban", ""], ["Mitra", "Pabitra", ""]]}, {"id": "1604.02774", "submitter": "Carlos Leandro", "authors": "Carlos Leandro", "title": "Reverse Engineering and Symbolic Knowledge Extraction on {\\L}ukasiewicz\n  Fuzzy Logics using Linear Neural Networks", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work describes a methodology to combine logic-based systems and\nconnectionist systems. Our approach uses finite truth valued {\\L}ukasiewicz\nlogic, where we take advantage of fact what in this type of logics every\nconnective can be define by a neuron in an artificial network having by\nactivation function the identity truncated to zero and one. This allowed the\ninjection of first-order formulas in a network architecture, and also\nsimplified symbolic rule extraction.\n  Our method trains a neural network using Levenderg-Marquardt algorithm, where\nwe restrict the knowledge dissemination in the network structure. We show how\nthis reduces neural networks plasticity without damage drastically the learning\nperformance. Making the descriptive power of produced neural networks similar\nto the descriptive power of {\\L}ukasiewicz logic language, simplifying the\ntranslation between symbolic and connectionist structures.\n  This method is used in the reverse engineering problem of finding the formula\nused on generation of a truth table for a multi-valued {\\L}ukasiewicz logic.\nFor real data sets the method is particularly useful for attribute selection,\non binary classification problems defined using nominal attribute. After\nattribute selection and possible data set completion in the resulting\nconnectionist model: neurons are directly representable using a disjunctive or\nconjunctive formulas, in the {\\L}ukasiewicz logic, or neurons are\ninterpretations which can be approximated by symbolic rules. This fact is\nexemplified, extracting symbolic knowledge from connectionist models generated\nfor the data set Mushroom from UCI Machine Learning Repository.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 02:05:21 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Leandro", "Carlos", ""]]}, {"id": "1604.02910", "submitter": "Yuan Gao", "authors": "Yuan Gao (University of Helsinki), Dorota Glowacka (University of\n  Helsinki)", "title": "Deep Gate Recurrent Neural Network", "comments": "This paper has been withdrawn by the author due to lacking of enough\n  experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces two recurrent neural network structures called Simple\nGated Unit (SGU) and Deep Simple Gated Unit (DSGU), which are general\nstructures for learning long term dependencies. Compared to traditional Long\nShort-Term Memory (LSTM) and Gated Recurrent Unit (GRU), both structures\nrequire fewer parameters and less computation time in sequence classification\ntasks. Unlike GRU and LSTM, which require more than one gates to control\ninformation flow in the network, SGU and DSGU only use one multiplicative gate\nto control the flow of information. We show that this difference can accelerate\nthe learning speed in tasks that require long dependency information. We also\nshow that DSGU is more numerically stable than SGU. In addition, we also\npropose a standard way of representing inner structure of RNN called RNN\nConventional Graph (RCG), which helps analyzing the relationship between input\nunits and hidden units of RNN.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 12:14:52 GMT"}, {"version": "v2", "created": "Mon, 25 Apr 2016 13:58:35 GMT"}, {"version": "v3", "created": "Fri, 13 May 2016 15:04:14 GMT"}], "update_date": "2016-05-16", "authors_parsed": [["Gao", "Yuan", "", "University of Helsinki"], ["Glowacka", "Dorota", "", "University of\n  Helsinki"]]}, {"id": "1604.02929", "submitter": "Marco Alberto Javarone", "authors": "Marco Alberto Javarone", "title": "Solving Optimization Problems by the Public Goods Game", "comments": "17 pages, 5 figure. accepted for publication in Eur. Phys. J. B", "journal-ref": null, "doi": "10.1140/epjb/e2017-80346-6", "report-no": null, "categories": "physics.soc-ph cs.GT cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a method based on the Public Goods Game for solving optimization\ntasks. In particular, we focus on the Traveling Salesman Problem, i.e. a\nNP-hard problem whose search space exponentially grows increasing the number of\ncities. The proposed method considers a population whose agents are provided\nwith a random solution to the given problem. In doing so, agents interact by\nplaying the Public Goods Game using the fitness of their solution as currency\nof the game. Notably, agents with better solutions provide higher\ncontributions, while those with lower ones tend to imitate the solution of\nricher agents for increasing their fitness. Numerical simulations show that the\nproposed method allows to compute exact solutions, and suboptimal ones, in the\nconsidered search spaces. As result, beyond to propose a new heuristic for\ncombinatorial optimization problems, our work aims to highlight the\npotentiality of evolutionary game theory beyond its current horizons.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 17:45:10 GMT"}, {"version": "v2", "created": "Tue, 29 Aug 2017 12:10:39 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Javarone", "Marco Alberto", ""]]}, {"id": "1604.03058", "submitter": "Xundong Wu", "authors": "Xundong Wu, Yong Wu and Yong Zhao", "title": "Binarized Neural Networks on the ImageNet Classification Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We trained Binarized Neural Networks (BNNs) on the high resolution ImageNet\nILSVRC-2102 dataset classification task and achieved a good performance. With a\nmoderate size network of 13 layers, we obtained top-5 classification accuracy\nrate of 84.1 % on validation set through network distillation, much better than\nprevious published results of 73.2% on XNOR network and 69.1% on binarized\nGoogleNET. We expect networks of better performance can be obtained by\nfollowing our current strategies. We provide a detailed discussion and\npreliminary analysis on strategies used in the network training.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 18:39:33 GMT"}, {"version": "v2", "created": "Wed, 13 Apr 2016 03:22:37 GMT"}, {"version": "v3", "created": "Mon, 24 Oct 2016 15:25:06 GMT"}, {"version": "v4", "created": "Tue, 8 Nov 2016 00:38:03 GMT"}, {"version": "v5", "created": "Sat, 19 Nov 2016 01:37:40 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Wu", "Xundong", ""], ["Wu", "Yong", ""], ["Zhao", "Yong", ""]]}, {"id": "1604.03073", "submitter": "Ashley Prater", "authors": "Ashley Prater", "title": "Reservoir computing for spatiotemporal signal classification without\n  trained output weights", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computing is a recently introduced machine learning paradigm that\nhas been shown to be well-suited for the processing of spatiotemporal data.\nRather than training the network node connections and weights via\nbackpropagation in traditional recurrent neural networks, reservoirs instead\nhave fixed connections and weights among the `hidden layer' nodes, and\ntraditionally only the weights to the output layer of neurons are trained using\nlinear regression. We claim that for signal classification tasks one may forgo\nthe weight training step entirely and instead use a simple supervised\nclustering method based upon principal components of norms of reservoir states.\nThe proposed method is mathematically analyzed and explored through numerical\nexperiments on real-world data. The examples demonstrate that the proposed may\noutperform the traditional trained output weight approach in terms of\nclassification accuracy and sensitivity to reservoir parameters.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 19:14:05 GMT"}, {"version": "v2", "created": "Tue, 19 Jul 2016 13:28:17 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Prater", "Ashley", ""]]}, {"id": "1604.03277", "submitter": "Carola Doerr", "authors": "Benjamin Doerr, Carola Doerr, Timo K\\\"otzing", "title": "The Right Mutation Strength for Multi-Valued Decision Variables", "comments": "an extended abstract of this work is to appear at GECCO 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most common representation in evolutionary computation are bit strings.\nThis is ideal to model binary decision variables, but less useful for variables\ntaking more values. With very little theoretical work existing on how to use\nevolutionary algorithms for such optimization problems, we study the run time\nof simple evolutionary algorithms on some OneMax-like functions defined over\n$\\Omega = \\{0, 1, \\dots, r-1\\}^n$. More precisely, we regard a variety of\nproblem classes requesting the component-wise minimization of the distance to\nan unknown target vector $z \\in \\Omega$. For such problems we see a crucial\ndifference in how we extend the standard-bit mutation operator to these\nmulti-valued domains. While it is natural to select each position of the\nsolution vector to be changed independently with probability $1/n$, there are\nvarious ways to then change such a position. If we change each selected\nposition to a random value different from the original one, we obtain an\nexpected run time of $\\Theta(nr \\log n)$. If we change each selected position\nby either $+1$ or $-1$ (random choice), the optimization time reduces to\n$\\Theta(nr + n\\log n)$. If we use a random mutation strength $i \\in\n\\{0,1,\\ldots,r-1\\}^n$ with probability inversely proportional to $i$ and change\nthe selected position by either $+i$ or $-i$ (random choice), then the\noptimization time becomes $\\Theta(n \\log(r)(\\log(n)+\\log(r)))$, bringing down\nthe dependence on $r$ from linear to polylogarithmic. One of our results\ndepends on a new variant of the lower bounding multiplicative drift theorem.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 07:54:10 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Doerr", "Benjamin", ""], ["Doerr", "Carola", ""], ["K\u00f6tzing", "Timo", ""]]}, {"id": "1604.03351", "submitter": "Nima Sedaghat Alvar", "authors": "Nima Sedaghat, Mohammadreza Zolfaghari, Ehsan Amiri and Thomas Brox", "title": "Orientation-boosted Voxel Nets for 3D Object Recognition", "comments": "BMVC'17 version. Added some experiments + auto-alignment of\n  Modelnet40", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown good recognition results in 3D object recognition using\n3D convolutional networks. In this paper, we show that the object orientation\nplays an important role in 3D recognition. More specifically, we argue that\nobjects induce different features in the network under rotation. Thus, we\napproach the category-level classification task as a multi-task problem, in\nwhich the network is trained to predict the pose of the object in addition to\nthe class label as a parallel task. We show that this yields significant\nimprovements in the classification results. We test our suggested architecture\non several datasets representing various 3D data sources: LiDAR data, CAD\nmodels, and RGB-D images. We report state-of-the-art results on classification\nas well as significant improvements in precision and speed over the baseline on\n3D detection.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 11:43:14 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 21:41:12 GMT"}], "update_date": "2017-10-23", "authors_parsed": [["Sedaghat", "Nima", ""], ["Zolfaghari", "Mohammadreza", ""], ["Amiri", "Ehsan", ""], ["Brox", "Thomas", ""]]}, {"id": "1604.03640", "submitter": "Qianli Liao", "authors": "Qianli Liao, Tomaso Poggio", "title": "Bridging the Gaps Between Residual Learning, Recurrent Neural Networks\n  and Visual Cortex", "comments": "This version was written in Sept. 2016. For April 2016 version see v1\n  below", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We discuss relations between Residual Networks (ResNet), Recurrent Neural\nNetworks (RNNs) and the primate visual cortex. We begin with the observation\nthat a special type of shallow RNN is exactly equivalent to a very deep ResNet\nwith weight sharing among the layers. A direct implementation of such a RNN,\nalthough having orders of magnitude fewer parameters, leads to a performance\nsimilar to the corresponding ResNet. We propose 1) a generalization of both RNN\nand ResNet architectures and 2) the conjecture that a class of moderately deep\nRNNs is a biologically-plausible model of the ventral stream in visual cortex.\nWe demonstrate the effectiveness of the architectures by testing them on the\nCIFAR-10 and ImageNet dataset.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 02:59:34 GMT"}, {"version": "v2", "created": "Thu, 31 Dec 2020 21:10:49 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Liao", "Qianli", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1604.04125", "submitter": "Farahnaz Ahmed Wick", "authors": "Farahnaz Ahmed Wick, Michael L. Wick, Marc Pomplun", "title": "Filling in the details: Perceiving from low fidelity images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans perceive their surroundings in great detail even though most of our\nvisual field is reduced to low-fidelity color-deprived (e.g. dichromatic) input\nby the retina. In contrast, most deep learning architectures are\ncomputationally wasteful in that they consider every part of the input when\nperforming an image processing task. Yet, the human visual system is able to\nperform visual reasoning despite having only a small fovea of high visual\nacuity. With this in mind, we wish to understand the extent to which\nconnectionist architectures are able to learn from and reason with low acuity,\ndistorted inputs. Specifically, we train autoencoders to generate full-detail\nimages from low-detail \"foveations\" of those images and then measure their\nability to reconstruct the full-detail images from the foveated versions. By\nvarying the type of foveation, we can study how well the architectures can cope\nwith various types of distortion. We find that the autoencoder compensates for\nlower detail by learning increasingly global feature functions. In many cases,\nthe learnt features are suitable for reconstructing the original full-detail\nimage. For example, we find that the networks accurately perceive color in the\nperiphery, even when 75\\% of the input is achromatic.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 12:10:23 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Wick", "Farahnaz Ahmed", ""], ["Wick", "Michael L.", ""], ["Pomplun", "Marc", ""]]}, {"id": "1604.04138", "submitter": "Xin-She Yang", "authors": "Eneko Osaba, Xin-She Yang, Fernando Diaz, Pedro Lopez-Garcia, Roberto\n  Carballedo", "title": "An Improved Discrete Bat Algorithm for Symmetric and Asymmetric\n  Traveling Salesman Problems", "comments": "1 figure, 8 tables", "journal-ref": "Engineering Applications of Artificial Intelligence, 48 (1), 59-71\n  (2016)", "doi": "10.1016/j.engappai.2015.10.006", "report-no": null, "categories": "cs.NE cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bat algorithm is a population metaheuristic proposed in 2010 which is based\non the echolocation or bio-sonar characteristics of microbats. Since its first\nimplementation, the bat algorithm has been used in a wide range of fields. In\nthis paper, we present a discrete version of the bat algorithm to solve the\nwell-known symmetric and asymmetric traveling salesman problems. In addition,\nwe propose an improvement in the basic structure of the classic bat algorithm.\nTo prove that our proposal is a promising approximation method, we have\ncompared its performance in 37 instances with the results obtained by five\ndifferent techniques: evolutionary simulated annealing, genetic algorithm, an\nisland based distributed genetic algorithm, a discrete firefly algorithm and an\nimperialist competitive algorithm. In order to obtain fair and rigorous\ncomparisons, we have conducted three different statistical tests along the\npaper: the Student's $t$-test, the Holm's test, and the Friedman test. We have\nalso compared the convergence behaviour shown by our proposal with the ones\nshown by the evolutionary simulated annealing, and the discrete firefly\nalgorithm. The experimentation carried out in this study has shown that the\npresented improved bat algorithm outperforms significantly all the other\nalternatives in most of the cases.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 12:52:20 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Osaba", "Eneko", ""], ["Yang", "Xin-She", ""], ["Diaz", "Fernando", ""], ["Lopez-Garcia", "Pedro", ""], ["Carballedo", "Roberto", ""]]}, {"id": "1604.04144", "submitter": "Jason Kuen", "authors": "Jason Kuen, Kian Ming Lim, Chin Poo Lee", "title": "Self-taught learning of a deep invariant representation for visual\n  tracking via temporal slowness principle", "comments": "Pattern Recognition (Elsevier), 2015", "journal-ref": null, "doi": "10.1016/j.patcog.2015.02.012", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual representation is crucial for a visual tracking method's performances.\nConventionally, visual representations adopted in visual tracking rely on\nhand-crafted computer vision descriptors. These descriptors were developed\ngenerically without considering tracking-specific information. In this paper,\nwe propose to learn complex-valued invariant representations from tracked\nsequential image patches, via strong temporal slowness constraint and stacked\nconvolutional autoencoders. The deep slow local representations are learned\noffline on unlabeled data and transferred to the observational model of our\nproposed tracker. The proposed observational model retains old training samples\nto alleviate drift, and collect negative samples which are coherent with\ntarget's motion pattern for better discriminative tracking. With the learned\nrepresentation and online training samples, a logistic regression classifier is\nadopted to distinguish target from background, and retrained online to adapt to\nappearance changes. Subsequently, the observational model is integrated into a\nparticle filter framework to peform visual tracking. Experimental results on\nvarious challenging benchmark sequences demonstrate that the proposed tracker\nperforms favourably against several state-of-the-art trackers.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 13:12:07 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Kuen", "Jason", ""], ["Lim", "Kian Ming", ""], ["Lee", "Chin Poo", ""]]}, {"id": "1604.04146", "submitter": "Xin-She Yang", "authors": "E. Osaba, Xin-She Yang, F. Diaz, E. Onieva, A. D. Masegosa, A.\n  Perallos", "title": "A Discrete Firefly Algorithm to Solve a Rich Vehicle Routing Problem\n  Modelling a Newspaper Distribution System with Recycling Policy", "comments": "7 tables and 4 figures", "journal-ref": null, "doi": "10.1007/s00500-016-2114-1", "report-no": null, "categories": "cs.NE cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A real-world newspaper distribution problem with recycling policy is tackled\nin this work. In order to meet all the complex restrictions contained in such a\nproblem, it has been modeled as a rich vehicle routing problem, which can be\nmore specifically considered as an asymmetric and clustered vehicle routing\nproblem with simultaneous pickup and deliveries, variable costs and forbidden\npaths (AC-VRP-SPDVCFP). This is the first study of such a problem in the\nliterature. For this reason, a benchmark composed by 15 instances has been also\nproposed. In the design of this benchmark, real geographical positions have\nbeen used, located in the province of Bizkaia, Spain. For the proper treatment\nof this AC-VRP-SPDVCFP, a discrete firefly algorithm (DFA) has been developed.\nThis application is the first application of the firefly algorithm to any rich\nvehicle routing problem. To prove that the proposed DFA is a promising\ntechnique, its performance has been compared with two other well-known\ntechniques: an evolutionary algorithm and an evolutionary simulated annealing.\nOur results have shown that the DFA has outperformed these two classic\nmeta-heuristics.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 13:25:42 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Osaba", "E.", ""], ["Yang", "Xin-She", ""], ["Diaz", "F.", ""], ["Onieva", "E.", ""], ["Masegosa", "A. D.", ""], ["Perallos", "A.", ""]]}, {"id": "1604.04153", "submitter": "Alexander Churchill", "authors": "Alexander W. Churchill, Siddharth Sigtia, Chrisantha Fernando", "title": "Learning to Generate Genotypes with Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks and evolutionary computation have a rich intertwined history.\nThey most commonly appear together when an evolutionary algorithm optimises the\nparameters and topology of a neural network for reinforcement learning\nproblems, or when a neural network is applied as a surrogate fitness function\nto aid the evolutionary optimisation of expensive fitness functions. In this\npaper we take a different approach, asking the question of whether a neural\nnetwork can be used to provide a mutation distribution for an evolutionary\nalgorithm, and what advantages this approach may offer? Two modern neural\nnetwork models are investigated, a Denoising Autoencoder modified to produce\nstochastic outputs and the Neural Autoregressive Distribution Estimator.\nResults show that the neural network approach to learning genotypes is able to\nsolve many difficult discrete problems, such as MaxSat and HIFF, and regularly\noutperforms other evolutionary techniques.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 13:48:26 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Churchill", "Alexander W.", ""], ["Sigtia", "Siddharth", ""], ["Fernando", "Chrisantha", ""]]}, {"id": "1604.04378", "submitter": "Shengxian Wan", "authors": "Shengxian Wan, Yanyan Lan, Jun Xu, Jiafeng Guo, Liang Pang, Xueqi\n  Cheng", "title": "Match-SRNN: Modeling the Recursive Matching Structure with Spatial RNN", "comments": "Accepted by IJCAI-2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic matching, which aims to determine the matching degree between two\ntexts, is a fundamental problem for many NLP applications. Recently, deep\nlearning approach has been applied to this problem and significant improvements\nhave been achieved. In this paper, we propose to view the generation of the\nglobal interaction between two texts as a recursive process: i.e. the\ninteraction of two texts at each position is a composition of the interactions\nbetween their prefixes as well as the word level interaction at the current\nposition. Based on this idea, we propose a novel deep architecture, namely\nMatch-SRNN, to model the recursive matching structure. Firstly, a tensor is\nconstructed to capture the word level interactions. Then a spatial RNN is\napplied to integrate the local interactions recursively, with importance\ndetermined by four types of gates. Finally, the matching score is calculated\nbased on the global interaction. We show that, after degenerated to the exact\nmatching scenario, Match-SRNN can approximate the dynamic programming process\nof longest common subsequence. Thus, there exists a clear interpretation for\nMatch-SRNN. Our experiments on two semantic matching tasks showed the\neffectiveness of Match-SRNN, and its ability of visualizing the learned\nmatching structure.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 07:23:53 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Wan", "Shengxian", ""], ["Lan", "Yanyan", ""], ["Xu", "Jun", ""], ["Guo", "Jiafeng", ""], ["Pang", "Liang", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1604.04428", "submitter": "Harm Berntsen", "authors": "Harm Berntsen, Wouter Kuijper and Tom Heskes", "title": "The Artificial Mind's Eye: Resisting Adversarials for Convolutional\n  Neural Networks using Internal Projection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel artificial neural network architecture that integrates\nrobustness to adversarial input in the network structure. The main idea of our\napproach is to force the network to make predictions on what the given instance\nof the class under consideration would look like and subsequently test those\npredictions. By forcing the network to redraw the relevant parts of the image\nand subsequently comparing this new image to the original, we are having the\nnetwork give a \"proof\" of the presence of the object.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 11:07:45 GMT"}, {"version": "v2", "created": "Thu, 14 Jul 2016 15:18:56 GMT"}], "update_date": "2016-07-15", "authors_parsed": [["Berntsen", "Harm", ""], ["Kuijper", "Wouter", ""], ["Heskes", "Tom", ""]]}, {"id": "1604.04528", "submitter": "Youngbin Park", "authors": "Youngbin Park, Sungphill Moon and Il Hong Suh", "title": "Tracking Human-like Natural Motion Using Deep Recurrent Neural Networks", "comments": "submitted to ECCV 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kinect skeleton tracker is able to achieve considerable human body tracking\nperformance in convenient and a low-cost manner. However, The tracker often\ncaptures unnatural human poses such as discontinuous and vibrated motions when\nself-occlusions occur. A majority of approaches tackle this problem by using\nmultiple Kinect sensors in a workspace. Combination of the measurements from\ndifferent sensors is then conducted in Kalman filter framework or optimization\nproblem is formulated for sensor fusion. However, these methods usually require\nheuristics to measure reliability of measurements observed from each Kinect\nsensor. In this paper, we developed a method to improve Kinect skeleton using\nsingle Kinect sensor, in which supervised learning technique was employed to\ncorrect unnatural tracking motions. Specifically, deep recurrent neural\nnetworks were used for improving joint positions and velocities of Kinect\nskeleton, and three methods were proposed to integrate the refined positions\nand velocities for further enhancement. Moreover, we suggested a novel measure\nto evaluate naturalness of captured motions. We evaluated the proposed approach\nby comparison with the ground truth obtained using a commercial optical\nmaker-based motion capture system.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 14:55:27 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Park", "Youngbin", ""], ["Moon", "Sungphill", ""], ["Suh", "Il Hong", ""]]}, {"id": "1604.04562", "submitter": "Tsung-Hsien Wen", "authors": "Tsung-Hsien Wen, David Vandyke, Nikola Mrksic, Milica Gasic, Lina M.\n  Rojas-Barahona, Pei-Hao Su, Stefan Ultes, Steve Young", "title": "A Network-based End-to-End Trainable Task-oriented Dialogue System", "comments": "published at EACL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teaching machines to accomplish tasks by conversing naturally with humans is\nchallenging. Currently, developing task-oriented dialogue systems requires\ncreating multiple components and typically this involves either a large amount\nof handcrafting, or acquiring costly labelled datasets to solve a statistical\nlearning problem for each component. In this work we introduce a neural\nnetwork-based text-in, text-out end-to-end trainable goal-oriented dialogue\nsystem along with a new way of collecting dialogue data based on a novel\npipe-lined Wizard-of-Oz framework. This approach allows us to develop dialogue\nsystems easily and without making too many assumptions about the task at hand.\nThe results show that the model can converse with human subjects naturally\nwhilst helping them to accomplish tasks in a restaurant search domain.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 16:40:49 GMT"}, {"version": "v2", "created": "Fri, 20 May 2016 14:03:58 GMT"}, {"version": "v3", "created": "Mon, 24 Apr 2017 10:55:12 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Wen", "Tsung-Hsien", ""], ["Vandyke", "David", ""], ["Mrksic", "Nikola", ""], ["Gasic", "Milica", ""], ["Rojas-Barahona", "Lina M.", ""], ["Su", "Pei-Hao", ""], ["Ultes", "Stefan", ""], ["Young", "Steve", ""]]}, {"id": "1604.04573", "submitter": "Jiang Wang Mr.", "authors": "Jiang Wang, Yi Yang, Junhua Mao, Zhiheng Huang, Chang Huang, Wei Xu", "title": "CNN-RNN: A Unified Framework for Multi-label Image Classification", "comments": "CVPR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep convolutional neural networks (CNNs) have shown a great success in\nsingle-label image classification, it is important to note that real world\nimages generally contain multiple labels, which could correspond to different\nobjects, scenes, actions and attributes in an image. Traditional approaches to\nmulti-label image classification learn independent classifiers for each\ncategory and employ ranking or thresholding on the classification results.\nThese techniques, although working well, fail to explicitly exploit the label\ndependencies in an image. In this paper, we utilize recurrent neural networks\n(RNNs) to address this problem. Combined with CNNs, the proposed CNN-RNN\nframework learns a joint image-label embedding to characterize the semantic\nlabel dependency as well as the image-label relevance, and it can be trained\nend-to-end from scratch to integrate both information in a unified framework.\nExperimental results on public benchmark datasets demonstrate that the proposed\narchitecture achieves better performance than the state-of-the-art multi-label\nclassification model\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 17:10:54 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Wang", "Jiang", ""], ["Yang", "Yi", ""], ["Mao", "Junhua", ""], ["Huang", "Zhiheng", ""], ["Huang", "Chang", ""], ["Xu", "Wei", ""]]}, {"id": "1604.04764", "submitter": "Philipp Weidel", "authors": "Philipp Weidel, Mikael Djurfeldt, Renato Duarte, Abigail Morrison", "title": "Closed loop interactions between spiking neural network and robotic\n  simulators based on MUSIC and ROS", "comments": null, "journal-ref": null, "doi": "10.3389/fninf.2016.00031", "report-no": null, "categories": "cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to properly assess the function and computational properties of\nsimulated neural systems, it is necessary to account for the nature of the\nstimuli that drive the system. However, providing stimuli that are rich and yet\nboth reproducible and amenable to experimental manipulations is technically\nchallenging, and even more so if a closed-loop scenario is required. In this\nwork, we present a novel approach to solve this problem, connecting robotics\nand neural network simulators. We implement a middleware solution that bridges\nthe Robotic Operating System (ROS) to the Multi-Simulator Coordinator (MUSIC).\nThis enables any robotic and neural simulators that implement the corresponding\ninterfaces to be efficiently coupled, allowing real-time performance for a wide\nrange of configurations. This work extends the toolset available for\nresearchers in both neurorobotics and computational neuroscience, and creates\nthe opportunity to perform closed-loop experiments of arbitrary complexity to\naddress questions in multiple areas, including embodiment, agency, and\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 15:09:44 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Weidel", "Philipp", ""], ["Djurfeldt", "Mikael", ""], ["Duarte", "Renato", ""], ["Morrison", "Abigail", ""]]}, {"id": "1604.04767", "submitter": "Markus Thom", "authors": "Markus Thom, Matthias Rapp, G\\\"unther Palm", "title": "Efficient Dictionary Learning with Sparseness-Enforcing Projections", "comments": "The final publication is available at Springer via\n  http://dx.doi.org/10.1007/s11263-015-0799-8", "journal-ref": "International Journal of Computer Vision, vol. 114, no. 2, pp.\n  168-194, 2015", "doi": "10.1007/s11263-015-0799-8", "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning dictionaries suitable for sparse coding instead of using engineered\nbases has proven effective in a variety of image processing tasks. This paper\nstudies the optimization of dictionaries on image data where the representation\nis enforced to be explicitly sparse with respect to a smooth, normalized\nsparseness measure. This involves the computation of Euclidean projections onto\nlevel sets of the sparseness measure. While previous algorithms for this\noptimization problem had at least quasi-linear time complexity, here the first\nalgorithm with linear time complexity and constant space complexity is\nproposed. The key for this is the mathematically rigorous derivation of a\ncharacterization of the projection's result based on a soft-shrinkage function.\nThis theory is applied in an original algorithm called Easy Dictionary Learning\n(EZDL), which learns dictionaries with a simple and fast-to-compute\nHebbian-like learning rule. The new algorithm is efficient, expressive and\nparticularly simple to implement. It is demonstrated that despite its\nsimplicity, the proposed learning algorithm is able to generate a rich variety\nof dictionaries, in particular a topographic organization of atoms or separable\natoms. Further, the dictionaries are as expressive as those of benchmark\nlearning algorithms in terms of the reproduction quality on entire images, and\nresult in an equivalent denoising performance. EZDL learns approximately 30 %\nfaster than the already very efficient Online Dictionary Learning algorithm,\nand is therefore eligible for rapid data set analysis and problems with vast\nquantities of learning samples.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 15:42:12 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Thom", "Markus", ""], ["Rapp", "Matthias", ""], ["Palm", "G\u00fcnther", ""]]}, {"id": "1604.04789", "submitter": "Enrico De Santis", "authors": "Enrico De Santis, Antonello Rizzi, Alireza Sadeghian", "title": "A Hierarchical Genetic Optimization of a Fuzzy Logic System for Flow\n  Control in Micro Grids", "comments": null, "journal-ref": null, "doi": "10.1016/j.asoc.2017.05.059", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bio-inspired algorithms like Genetic Algorithms and Fuzzy Inference Systems\n(FIS) are nowadays widely adopted as hybrid techniques in commercial and\nindustrial environment. In this paper we present an interesting application of\nthe fuzzy-GA paradigm to Smart Grids. The main aim consists in performing\ndecision making for power flow management tasks in the proposed microgrid model\nequipped by renewable sources and an energy storage system, taking into account\nthe economical profit in energy trading with the main-grid. In particular, this\nstudy focuses on the application of a Hierarchical Genetic Algorithm (HGA) for\ntuning the Rule Base (RB) of a Fuzzy Inference System (FIS), trying to discover\na minimal fuzzy rules set in a Fuzzy Logic Controller (FLC) adopted to perform\ndecision making in the microgrid. The HGA rationale focuses on a particular\nencoding scheme, based on control genes and parametric genes applied to the\noptimization of the FIS parameters, allowing to perform a reduction in the\nstructural complexity of the RB. This approach will be referred in the\nfollowing as fuzzy-HGA. Results are compared with a simpler approach based on a\nclassic fuzzy-GA scheme, where both FIS parameters and rule weights are tuned,\nwhile the number of fuzzy rules is fixed in advance. Experiments shows how the\nfuzzy-HGA approach adopted for the synthesis of the proposed controller\noutperforms the classic fuzzy-GA scheme, increasing the accounting profit by\n67\\% in the considered energy trading problem yielding at the same time a\nsimpler RB.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 19:38:21 GMT"}, {"version": "v2", "created": "Tue, 24 Jan 2017 12:17:24 GMT"}, {"version": "v3", "created": "Wed, 1 Mar 2017 04:57:14 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["De Santis", "Enrico", ""], ["Rizzi", "Antonello", ""], ["Sadeghian", "Alireza", ""]]}, {"id": "1604.04812", "submitter": "Ehsan Hosseini-Asl", "authors": "Ehsan Hosseini-Asl", "title": "Structured Sparse Convolutional Autoencoder", "comments": "The paper need some improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to improve the feature learning in Convolutional Networks\n(Convnet) by capturing the structure of objects. A new sparsity function is\nimposed on the extracted featuremap to capture the structure and shape of the\nlearned object, extracting interpretable features to improve the prediction\nperformance. The proposed algorithm is based on organizing the activation\nwithin and across featuremap by constraining the node activities through\n$\\ell_{2}$ and $\\ell_{1}$ normalization in a structured form.\n", "versions": [{"version": "v1", "created": "Sun, 17 Apr 2016 00:26:57 GMT"}, {"version": "v2", "created": "Thu, 1 Dec 2016 17:40:29 GMT"}, {"version": "v3", "created": "Mon, 2 Jan 2017 18:33:43 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Hosseini-Asl", "Ehsan", ""]]}, {"id": "1604.04970", "submitter": "Yueying Kao", "authors": "Yueying Kao, Ran He, Kaiqi Huang", "title": "Deep Aesthetic Quality Assessment with Semantic Information", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": "10.1109/TIP.2017.2651399", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human beings often assess the aesthetic quality of an image coupled with the\nidentification of the image's semantic content. This paper addresses the\ncorrelation issue between automatic aesthetic quality assessment and semantic\nrecognition. We cast the assessment problem as the main task among a multi-task\ndeep model, and argue that semantic recognition task offers the key to address\nthis problem. Based on convolutional neural networks, we employ a single and\nsimple multi-task framework to efficiently utilize the supervision of aesthetic\nand semantic labels. A correlation item between these two tasks is further\nintroduced to the framework by incorporating the inter-task relationship\nlearning. This item not only provides some useful insight about the correlation\nbut also improves assessment accuracy of the aesthetic task. Particularly, an\neffective strategy is developed to keep a balance between the two tasks, which\nfacilitates to optimize the parameters of the framework. Extensive experiments\non the challenging AVA dataset and Photo.net dataset validate the importance of\nsemantic recognition in aesthetic quality assessment, and demonstrate that\nmulti-task deep models can discover an effective aesthetic representation to\nachieve state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 03:16:56 GMT"}, {"version": "v2", "created": "Sat, 20 Aug 2016 14:09:48 GMT"}, {"version": "v3", "created": "Fri, 21 Oct 2016 07:46:54 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Kao", "Yueying", ""], ["He", "Ran", ""], ["Huang", "Kaiqi", ""]]}, {"id": "1604.05000", "submitter": "Zhen Li", "authors": "Zhen Li, Yukang Gan, Xiaodan Liang, Yizhou Yu, Hui Cheng and Liang Lin", "title": "LSTM-CF: Unifying Context Modeling and Fusion with LSTMs for RGB-D Scene\n  Labeling", "comments": "17 pages, accepted by ECCV", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic labeling of RGB-D scenes is crucial to many intelligent applications\nincluding perceptual robotics. It generates pixelwise and fine-grained label\nmaps from simultaneously sensed photometric (RGB) and depth channels. This\npaper addresses this problem by i) developing a novel Long Short-Term Memorized\nContext Fusion (LSTM-CF) Model that captures and fuses contextual information\nfrom multiple channels of photometric and depth data, and ii) incorporating\nthis model into deep convolutional neural networks (CNNs) for end-to-end\ntraining. Specifically, contexts in photometric and depth channels are,\nrespectively, captured by stacking several convolutional layers and a long\nshort-term memory layer; the memory layer encodes both short-range and\nlong-range spatial dependencies in an image along the vertical direction.\nAnother long short-term memorized fusion layer is set up to integrate the\ncontexts along the vertical direction from different channels, and perform\nbi-directional propagation of the fused vertical contexts along the horizontal\ndirection to obtain true 2D global contexts. At last, the fused contextual\nrepresentation is concatenated with the convolutional features extracted from\nthe photometric channels in order to improve the accuracy of fine-scale\nsemantic labeling. Our proposed model has set a new state of the art, i.e.,\n48.1% and 49.4% average class accuracy over 37 categories (2.2% and 5.4%\nimprovement) on the large-scale SUNRGBD dataset and the NYUDv2dataset,\nrespectively.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 05:59:50 GMT"}, {"version": "v2", "created": "Mon, 25 Apr 2016 08:15:19 GMT"}, {"version": "v3", "created": "Tue, 26 Jul 2016 16:46:43 GMT"}], "update_date": "2016-07-27", "authors_parsed": [["Li", "Zhen", ""], ["Gan", "Yukang", ""], ["Liang", "Xiaodan", ""], ["Yu", "Yizhou", ""], ["Cheng", "Hui", ""], ["Lin", "Liang", ""]]}, {"id": "1604.05008", "submitter": "Indranil Ghosh", "authors": "Tamal Datta Chaudhuri and Indranil Ghosh", "title": "Forecasting Volatility in Indian Stock Market using Artificial Neural\n  Network with Multiple Inputs and Outputs", "comments": null, "journal-ref": "International Journal of Computer Applications, 2015", "doi": "10.5120/21245-4034", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volatility in stock markets has been extensively studied in the applied\nfinance literature. In this paper, Artificial Neural Network models based on\nvarious back propagation algorithms have been constructed to predict volatility\nin the Indian stock market through volatility of NIFTY returns and volatility\nof gold returns. This model considers India VIX, CBOE VIX, volatility of crude\noil returns (CRUDESDR), volatility of DJIA returns (DJIASDR), volatility of DAX\nreturns (DAXSDR), volatility of Hang Seng returns (HANGSDR) and volatility of\nNikkei returns (NIKKEISDR) as predictor variables. Three sets of experiments\nhave been performed over three time periods to judge the effectiveness of the\napproach.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 06:29:01 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Chaudhuri", "Tamal Datta", ""], ["Ghosh", "Indranil", ""]]}, {"id": "1604.05080", "submitter": "Johannes Schemmel", "authors": "Simon Friedmann, Johannes Schemmel, Andreas Gruebl, Andreas Hartel,\n  Matthias Hock and Karlheinz Meier", "title": "Demonstrating Hybrid Learning in a Flexible Neuromorphic Hardware System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present results from a new approach to learning and plasticity in\nneuromorphic hardware systems: to enable flexibility in implementable learning\nmechanisms while keeping high efficiency associated with neuromorphic\nimplementations, we combine a general-purpose processor with full-custom analog\nelements.\n  This processor is operating in parallel with a fully parallel neuromorphic\nsystem consisting of an array of synapses connected to analog, continuous time\nneuron circuits. Novel analog correlation sensor circuits process spike events\nfor each synapse in parallel and in real-time.\n  The processor uses this pre-processing to compute new weights possibly using\nadditional information following its program.\n  Therefore, learning rules can be defined in software giving a large degree of\nflexibility.\n  Synapses realize correlation detection geared towards Spike-Timing Dependent\nPlasticity (STDP) as central computational primitive in the analog domain.\n  Operating at a speed-up factor of 1000 compared to biological time-scale, we\nmeasure time-constants from tens to hundreds of micro-seconds.\n  We analyze variability across multiple chips and demonstrate learning using a\nmultiplicative STDP rule.\n  We conclude, that the presented approach will enable flexible and efficient\nlearning as a platform for neuroscientific research and technological\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 10:49:38 GMT"}, {"version": "v2", "created": "Thu, 13 Oct 2016 09:15:12 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Friedmann", "Simon", ""], ["Schemmel", "Johannes", ""], ["Gruebl", "Andreas", ""], ["Hartel", "Andreas", ""], ["Hock", "Matthias", ""], ["Meier", "Karlheinz", ""]]}, {"id": "1604.05091", "submitter": "Peter Ondruska", "authors": "Peter Ondruska, Julie Dequaire, Dominic Zeng Wang, Ingmar Posner", "title": "End-to-End Tracking and Semantic Segmentation Using Recurrent Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a novel end-to-end framework for tracking and\nclassifying a robot's surroundings in complex, dynamic and only partially\nobservable real-world environments. The approach deploys a recurrent neural\nnetwork to filter an input stream of raw laser measurements in order to\ndirectly infer object locations, along with their identity in both visible and\noccluded areas. To achieve this we first train the network using unsupervised\nDeep Tracking, a recently proposed theoretical framework for end-to-end space\noccupancy prediction. We show that by learning to track on a large amount of\nunsupervised data, the network creates a rich internal representation of its\nenvironment which we in turn exploit through the principle of inductive\ntransfer of knowledge to perform the task of it's semantic classification. As a\nresult, we show that only a small amount of labelled data suffices to steer the\nnetwork towards mastering this additional task. Furthermore we propose a novel\nrecurrent neural network architecture specifically tailored to tracking and\nsemantic classification in real-world robotics applications. We demonstrate the\ntracking and classification performance of the method on real-world data\ncollected at a busy road junction. Our evaluation shows that the proposed\nend-to-end framework compares favourably to a state-of-the-art, model-free\ntracking solution and that it outperforms a conventional one-shot training\nscheme for semantic classification.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 11:15:56 GMT"}, {"version": "v2", "created": "Tue, 19 Apr 2016 14:09:26 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Ondruska", "Peter", ""], ["Dequaire", "Julie", ""], ["Wang", "Dominic Zeng", ""], ["Posner", "Ingmar", ""]]}, {"id": "1604.05170", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "A Repeated Signal Difference for Recognising Patterns", "comments": null, "journal-ref": "BRAIN, Broad Research in Artificial Intelligence and Neuroscience,\n  Vol. 7, No. 3, pp. 139 - 147, 2016", "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new mechanism that might help with defining pattern\nsequences, by the fact that it can produce an upper bound on the ensemble value\nthat can persistently oscillate with the actual values produced from each\npattern. With every firing event, a node also receives an on/off feedback\nswitch. If the node fires, then it sends a feedback result depending on the\ninput signal strength. If the input signal is positive or larger, it can store\nan 'on' switch feedback for the next iteration. If the signal is negative or\nsmaller, it can store an 'off' switch feedback for the next iteration. If the\nnode does not fire, then it does not affect the current feedback situation and\nreceives the switch command produced by the last active pattern event for the\nsame neuron. The upper bound therefore also represents the largest or most\nenclosing pattern set and the lower value is for the actual set of firing\npatterns. If the pattern sequence repeats, it will oscillate between the two\nvalues, allowing them to be recognised and measured more easily, over time.\nTests show that changing the sequence ordering produces different value sets,\nwhich can also be measured.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 14:13:52 GMT"}, {"version": "v2", "created": "Sat, 30 Apr 2016 12:08:14 GMT"}, {"version": "v3", "created": "Wed, 7 Sep 2016 17:17:54 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "1604.05198", "submitter": "Baogang Hu", "authors": "Linlin Cao, Ran He, Bao-Gang Hu", "title": "Locally Imposing Function for Generalized Constraint Neural Networks - A\n  Study on Equality Constraints", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is a further study on the Generalized Constraint Neural Network\n(GCNN) model [1], [2]. Two challenges are encountered in the study, that is, to\nembed any type of prior information and to select its imposing schemes. The\nwork focuses on the second challenge and studies a new constraint imposing\nscheme for equality constraints. A new method called locally imposing function\n(LIF) is proposed to provide a local correction to the GCNN prediction\nfunction, which therefore falls within Locally Imposing Scheme (LIS). In\ncomparison, the conventional Lagrange multiplier method is considered as\nGlobally Imposing Scheme (GIS) because its added constraint term exhibits a\nglobal impact to its objective function. Two advantages are gained from LIS\nover GIS. First, LIS enables constraints to fire locally and explicitly in the\ndomain only where they need on the prediction function. Second, constraints can\nbe implemented within a network setting directly. We attempt to interpret\nseveral constraint methods graphically from a viewpoint of the locality\nprinciple. Numerical examples confirm the advantages of the proposed method. In\nsolving boundary value problems with Dirichlet and Neumann constraints, the\nGCNN model with LIF is possible to achieve an exact satisfaction of the\nconstraints.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 15:11:13 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Cao", "Linlin", ""], ["He", "Ran", ""], ["Hu", "Bao-Gang", ""]]}, {"id": "1604.05377", "submitter": "Artit Wangperawong", "authors": "Artit Wangperawong, Cyrille Brun, Olav Laudy, Rujikorn Pavasuthipaisit", "title": "Churn analysis using deep convolutional neural networks and autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Customer temporal behavioral data was represented as images in order to\nperform churn prediction by leveraging deep learning architectures prominent in\nimage classification. Supervised learning was performed on labeled data of over\n6 million customers using deep convolutional neural networks, which achieved an\nAUC of 0.743 on the test dataset using no more than 12 temporal features for\neach customer. Unsupervised learning was conducted using autoencoders to better\nunderstand the reasons for customer churn. Images that maximally activate the\nhidden units of an autoencoder trained with churned customers reveal ample\nopportunities for action to be taken to prevent churn among strong data, no\nvoice users.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 23:18:23 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Wangperawong", "Artit", ""], ["Brun", "Cyrille", ""], ["Laudy", "Olav", ""], ["Pavasuthipaisit", "Rujikorn", ""]]}, {"id": "1604.05459", "submitter": "Subhrajit Roy", "authors": "Subhrajit Roy and Arindam Basu", "title": "An Online Structural Plasticity Rule for Generating Better Reservoirs", "comments": "45 pages, 13 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, a novel neuro-inspired low-resolution online unsupervised\nlearning rule is proposed to train the reservoir or liquid of Liquid State\nMachine. The liquid is a sparsely interconnected huge recurrent network of\nspiking neurons. The proposed learning rule is inspired from structural\nplasticity and trains the liquid through formation and elimination of synaptic\nconnections. Hence, the learning involves rewiring of the reservoir connections\nsimilar to structural plasticity observed in biological neural networks. The\nnetwork connections can be stored as a connection matrix and updated in memory\nby using Address Event Representation (AER) protocols which are generally\nemployed in neuromorphic systems. On investigating the 'pairwise separation\nproperty' we find that trained liquids provide 1.36 $\\pm$ 0.18 times more\ninter-class separation while retaining similar intra-class separation as\ncompared to random liquids. Moreover, analysis of the 'linear separation\nproperty' reveals that trained liquids are 2.05 $\\pm$ 0.27 times better than\nrandom liquids. Furthermore, we show that our liquids are able to retain the\n'generalization' ability and 'generality' of random liquids. A memory analysis\nshows that trained liquids have 83.67 $\\pm$ 5.79 ms longer fading memory than\nrandom liquids which have shown 92.8 $\\pm$ 5.03 ms fading memory for a\nparticular type of spike train inputs. We also throw some light on the dynamics\nof the evolution of recurrent connections within the liquid. Moreover, compared\nto 'Separation Driven Synaptic Modification' - a recently proposed algorithm\nfor iteratively refining reservoirs, our learning rule provides 9.30%, 15.21%\nand 12.52% more liquid separations and 2.8%, 9.1% and 7.9% better\nclassification accuracies for four, eight and twelve class pattern recognition\ntasks respectively.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 07:30:46 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Roy", "Subhrajit", ""], ["Basu", "Arindam", ""]]}, {"id": "1604.05791", "submitter": "Andrew Connor", "authors": "Jan Kruse, Ricardo Sosa and Andy M. Connor", "title": "Procedural urban environments for FPS games", "comments": null, "journal-ref": null, "doi": "10.1145/2843043.2843479", "report-no": null, "categories": "cs.AI cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to procedural generation of urban maps\nfor First Person Shooter (FPS) games. A multi-agent evolutionary system is\nemployed to place streets, buildings and other items inside the Unity3D game\nengine, resulting in playable video game levels. A computational agent is\ntrained using machine learning techniques to capture the intent of the game\ndesigner as part of the multi-agent system, and to enable a semi-automated\naesthetic selection for the underlying genetic algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 02:39:04 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Kruse", "Jan", ""], ["Sosa", "Ricardo", ""], ["Connor", "Andy M.", ""]]}, {"id": "1604.05792", "submitter": "Andrew Connor", "authors": "Jan Kruse and Andy M. Connor", "title": "Multi-agent evolutionary systems for the generation of complex virtual\n  worlds", "comments": null, "journal-ref": "EAI Endorsed Transactions on Creative Technologies 2(5) Paper e5\n  (2015)", "doi": "10.4108/eai.20-10-2015.150099", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern films, games and virtual reality applications are dependent on\nconvincing computer graphics. Highly complex models are a requirement for the\nsuccessful delivery of many scenes and environments. While workflows such as\nrendering, compositing and animation have been streamlined to accommodate\nincreasing demands, modelling complex models is still a laborious task. This\npaper introduces the computational benefits of an Interactive Genetic Algorithm\n(IGA) to computer graphics modelling while compensating the effects of user\nfatigue, a common issue with Interactive Evolutionary Computation. An\nintelligent agent is used in conjunction with an IGA that offers the potential\nto reduce the effects of user fatigue by learning from the choices made by the\nhuman designer and directing the search accordingly. This workflow accelerates\nthe layout and distribution of basic elements to form complex models. It\ncaptures the designer's intent through interaction, and encourages playful\ndiscovery.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 02:43:47 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Kruse", "Jan", ""], ["Connor", "Andy M.", ""]]}, {"id": "1604.05878", "submitter": "Johannes Welbl", "authors": "Johannes Welbl, Guillaume Bouchard, Sebastian Riedel", "title": "A Factorization Machine Framework for Testing Bigram Embeddings in\n  Knowledgebase Completion", "comments": "accepted for AKBC 2016 workshop, 6pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding-based Knowledge Base Completion models have so far mostly combined\ndistributed representations of individual entities or relations to compute\ntruth scores of missing links. Facts can however also be represented using\npairwise embeddings, i.e. embeddings for pairs of entities and relations. In\nthis paper we explore such bigram embeddings with a flexible Factorization\nMachine model and several ablations from it. We investigate the relevance of\nvarious bigram types on the fb15k237 dataset and find relative improvements\ncompared to a compositional model.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 09:58:56 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Welbl", "Johannes", ""], ["Bouchard", "Guillaume", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1604.05978", "submitter": "Decebal Constantin Mocanu", "authors": "Decebal Constantin Mocanu, Elena Mocanu, Phuong H. Nguyen, Madeleine\n  Gibescu and Antonio Liotta", "title": "A topological insight into restricted Boltzmann machines", "comments": "http://link.springer.com/article/10.1007/s10994-016-5570-z, Machine\n  Learning, issn=1573-0565, 2016", "journal-ref": null, "doi": "10.1007/s10994-016-5570-z", "report-no": null, "categories": "cs.NE cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann Machines (RBMs) and models derived from them have been\nsuccessfully used as basic building blocks in deep artificial neural networks\nfor automatic features extraction, unsupervised weights initialization, but\nalso as density estimators. Thus, their generative and discriminative\ncapabilities, but also their computational time are instrumental to a wide\nrange of applications. Our main contribution is to look at RBMs from a\ntopological perspective, bringing insights from network science. Firstly, here\nwe show that RBMs and Gaussian RBMs (GRBMs) are bipartite graphs which\nnaturally have a small-world topology. Secondly, we demonstrate both on\nsynthetic and real-world datasets that by constraining RBMs and GRBMs to a\nscale-free topology (while still considering local neighborhoods and data\ndistribution), we reduce the number of weights that need to be computed by a\nfew orders of magnitude, at virtually no loss in generative performance.\nThirdly, we show that, for a fixed number of weights, our proposed sparse\nmodels (which by design have a higher number of hidden neurons) achieve better\ngenerative capabilities than standard fully connected RBMs and GRBMs (which by\ndesign have a smaller number of hidden neurons), at no additional computational\ncosts.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 14:35:12 GMT"}, {"version": "v2", "created": "Mon, 18 Jul 2016 20:14:41 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Mocanu", "Decebal Constantin", ""], ["Mocanu", "Elena", ""], ["Nguyen", "Phuong H.", ""], ["Gibescu", "Madeleine", ""], ["Liotta", "Antonio", ""]]}, {"id": "1604.06057", "submitter": "Karthik Narasimhan", "authors": "Tejas D. Kulkarni, Karthik R. Narasimhan, Ardavan Saeedi, Joshua B.\n  Tenenbaum", "title": "Hierarchical Deep Reinforcement Learning: Integrating Temporal\n  Abstraction and Intrinsic Motivation", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning goal-directed behavior in environments with sparse feedback is a\nmajor challenge for reinforcement learning algorithms. The primary difficulty\narises due to insufficient exploration, resulting in an agent being unable to\nlearn robust value functions. Intrinsically motivated agents can explore new\nbehavior for its own sake rather than to directly solve problems. Such\nintrinsic behaviors could eventually help the agent solve tasks posed by the\nenvironment. We present hierarchical-DQN (h-DQN), a framework to integrate\nhierarchical value functions, operating at different temporal scales, with\nintrinsically motivated deep reinforcement learning. A top-level value function\nlearns a policy over intrinsic goals, and a lower-level function learns a\npolicy over atomic actions to satisfy the given goals. h-DQN allows for\nflexible goal specifications, such as functions over entities and relations.\nThis provides an efficient space for exploration in complicated environments.\nWe demonstrate the strength of our approach on two problems with very sparse,\ndelayed feedback: (1) a complex discrete stochastic decision process, and (2)\nthe classic ATARI game `Montezuma's Revenge'.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 18:47:48 GMT"}, {"version": "v2", "created": "Tue, 31 May 2016 14:45:58 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Kulkarni", "Tejas D.", ""], ["Narasimhan", "Karthik R.", ""], ["Saeedi", "Ardavan", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1604.06154", "submitter": "Xichuan Zhou", "authors": "Xichuan Zhou, Shengli Li, Kai Qin, Kunping Li, Fang Tang, Shengdong\n  Hu, Shujun Liu, Zhi Lin", "title": "Deep Adaptive Network: An Efficient Deep Neural Network with Sparse\n  Binary Connections", "comments": "10 pages, extended and submitted to IEEE Transactions of Systems,\n  Man, and Cybernetics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are state-of-the-art models for understanding the\ncontent of images, video and raw input data. However, implementing a deep\nneural network in embedded systems is a challenging task, because a typical\ndeep neural network, such as a Deep Belief Network using 128x128 images as\ninput, could exhaust Giga bytes of memory and result in bandwidth and computing\nbottleneck. To address this challenge, this paper presents a hardware-oriented\ndeep learning algorithm, named as the Deep Adaptive Network, which attempts to\nexploit the sparsity in the neural connections. The proposed method adaptively\nreduces the weights associated with negligible features to zero, leading to\nsparse feedforward network architecture. Furthermore, since the small\nproportion of important weights are significantly larger than zero, they can be\nrobustly thresholded and represented using single-bit integers (-1 and +1),\nleading to implementations of deep neural networks with sparse and binary\nconnections. Our experiments showed that, for the application of recognizing\nMNIST handwritten digits, the features extracted by a two-layer Deep Adaptive\nNetwork with about 25% reserved important connections achieved 97.2%\nclassification accuracy, which was almost the same with the standard Deep\nBelief Network (97.3%). Furthermore, for efficient hardware implementations,\nthe sparse-and-binary-weighted deep neural network could save about 99.3%\nmemory and 99.9% computation units without significant loss of classification\naccuracy for pattern recognition applications.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 01:47:33 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Zhou", "Xichuan", ""], ["Li", "Shengli", ""], ["Qin", "Kai", ""], ["Li", "Kunping", ""], ["Tang", "Fang", ""], ["Hu", "Shengdong", ""], ["Liu", "Shujun", ""], ["Lin", "Zhi", ""]]}, {"id": "1604.06187", "submitter": "Aneta Neumann", "authors": "Aneta Neumann, Bradley Alexander, Frank Neumann", "title": "Evolutionary Image Transition Based on Theoretical Insights of Random\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms have been widely studied from a theoretical\nperspective. In particular, the area of runtime analysis has contributed\nsignificantly to a theoretical understanding and provided insights into the\nworking behaviour of these algorithms. We study how these insights into\nevolutionary processes can be used for evolutionary art. We introduce the\nnotion of evolutionary image transition which transfers a given starting image\ninto a target image through an evolutionary process. Combining standard\nmutation effects known from the optimization of the classical benchmark\nfunction OneMax and different variants of random walks, we present ways of\nperforming evolutionary image transition with different artistic effects.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 05:47:05 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Neumann", "Aneta", ""], ["Alexander", "Bradley", ""], ["Neumann", "Frank", ""]]}, {"id": "1604.06338", "submitter": "Huy Phan", "authors": "Huy Phan, Lars Hertel, Marco Maass, Alfred Mertins", "title": "Robust Audio Event Recognition with 1-Max Pooling Convolutional Neural\n  Networks", "comments": "To appear in Proceedings of Interspeech 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper a simple, yet efficient convolutional neural network\n(CNN) architecture for robust audio event recognition. Opposing to deep CNN\narchitectures with multiple convolutional and pooling layers topped up with\nmultiple fully connected layers, the proposed network consists of only three\nlayers: convolutional, pooling, and softmax layer. Two further features\ndistinguish it from the deep architectures that have been proposed for the\ntask: varying-size convolutional filters at the convolutional layer and 1-max\npooling scheme at the pooling layer. In intuition, the network tends to select\nthe most discriminative features from the whole audio signals for recognition.\nOur proposed CNN not only shows state-of-the-art performance on the standard\ntask of robust audio event recognition but also outperforms other deep\narchitectures up to 4.5% in terms of recognition accuracy, which is equivalent\nto 76.3% relative error reduction.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 14:51:43 GMT"}, {"version": "v2", "created": "Wed, 22 Jun 2016 13:01:16 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Phan", "Huy", ""], ["Hertel", "Lars", ""], ["Maass", "Marco", ""], ["Mertins", "Alfred", ""]]}, {"id": "1604.06529", "submitter": "Adhiguna Kuncoro", "authors": "Adhiguna Kuncoro, Yuichiro Sawai, Kevin Duh, Yuji Matsumoto", "title": "Dependency Parsing with LSTMs: An Empirical Evaluation", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a transition-based dependency parser using Recurrent Neural\nNetworks with Long Short-Term Memory (LSTM) units. This extends the feedforward\nneural network parser of Chen and Manning (2014) and enables modelling of\nentire sequences of shift/reduce transition decisions. On the Google Web\nTreebank, our LSTM parser is competitive with the best feedforward parser on\noverall accuracy and notably achieves more than 3% improvement for long-range\ndependencies, which has proved difficult for previous transition-based parsers\ndue to error propagation and limited context information. Our findings\nadditionally suggest that dropout regularisation on the embedding layer is\ncrucial to improve the LSTM's generalisation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 03:20:24 GMT"}, {"version": "v2", "created": "Thu, 30 Jun 2016 04:23:07 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["Kuncoro", "Adhiguna", ""], ["Sawai", "Yuichiro", ""], ["Duh", "Kevin", ""], ["Matsumoto", "Yuji", ""]]}, {"id": "1604.06607", "submitter": "Alex Ter-Sarkisov", "authors": "Aram Ter-Sarkisov and Stephen Marsland", "title": "K-Bit-Swap: A New Operator For Real-Coded Evolutionary Algorithms", "comments": "accepted for publication in Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a variety of crossover operators proposed for Real-Coded\nGenetic Algorithms (RCGAs), which recombine values from the same location in\npairs of strings. In this article we present a recombination operator for RC-\nGAs that selects the locations randomly in both parents, and compare it to\nmainstream crossover operators in a set of experiments on a range of standard\nmultidimensional optimization problems and a clustering problem. We present two\nvariants of the operator, either selecting both bits uniformly at random in the\nstrings, or sampling the second bit from a normal distribution centered at the\nselected location in the first string. While the operator is biased towards\nexploitation of fitness space, the random selection of the second bit for swap-\nping makes it slightly less exploitation-biased. Extensive statistical analysis\nusing a non-parametric test shows the advantage of the new recombination\noperators on a range of test functions.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 11:09:18 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Ter-Sarkisov", "Aram", ""], ["Marsland", "Stephen", ""]]}, {"id": "1604.06635", "submitter": "Xipeng Qiu", "authors": "Peng Qian, Xipeng Qiu, Xuanjing Huang", "title": "Bridging LSTM Architecture and the Neural Dynamics during Reading", "comments": "25th International Joint Conference on Artificial Intelligence\n  IJCAI-16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the long short-term memory neural network (LSTM) has attracted wide\ninterest due to its success in many tasks. LSTM architecture consists of a\nmemory cell and three gates, which looks similar to the neuronal networks in\nthe brain. However, there still lacks the evidence of the cognitive\nplausibility of LSTM architecture as well as its working mechanism. In this\npaper, we study the cognitive plausibility of LSTM by aligning its internal\narchitecture with the brain activity observed via fMRI when the subjects read a\nstory. Experiment results show that the artificial memory vector in LSTM can\naccurately predict the observed sequential brain activities, indicating the\ncorrelation between LSTM architecture and the cognitive process of story\nreading.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 12:51:11 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Qian", "Peng", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1604.06727", "submitter": "Chee Chun Gan", "authors": "Chee Chun Gan and Gerard Learmonth", "title": "An improved chromosome formulation for genetic algorithms applied to\n  variable selection with the inclusion of interaction terms", "comments": "20 pages, 4 figures, 4 tables, 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic algorithms are a well-known method for tackling the problem of\nvariable selection. As they are non-parametric and can use a large variety of\nfitness functions, they are well-suited as a variable selection wrapper that\ncan be applied to many different models. In almost all cases, the chromosome\nformulation used in these genetic algorithms consists of a binary vector of\nlength n for n potential variables indicating the presence or absence of the\ncorresponding variables. While the aforementioned chromosome formulation has\nexhibited good performance for relatively small n, there are potential problems\nwhen the size of n grows very large, especially when interaction terms are\nconsidered. We introduce a modification to the standard chromosome formulation\nthat allows for better scalability and model sparsity when interaction terms\nare included in the predictor search space. Experimental results show that the\nindexed chromosome formulation demonstrates improved computational efficiency\nand sparsity on high-dimensional datasets with interaction terms compared to\nthe standard chromosome formulation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 16:14:55 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Gan", "Chee Chun", ""], ["Learmonth", "Gerard", ""]]}, {"id": "1604.06730", "submitter": "Chee Chun Gan", "authors": "Chee Chun Gan and Gerard Learmonth", "title": "Developing an ICU scoring system with interaction terms using a genetic\n  algorithm", "comments": "21 pages, 6 tables, 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ICU mortality scoring systems attempt to predict patient mortality using\npredictive models with various clinical predictors. Examples of such systems\nare APACHE, SAPS and MPM. However, most such scoring systems do not actively\nlook for and include interaction terms, despite physicians intuitively taking\nsuch interactions into account when making a diagnosis. One barrier to\nincluding such terms in predictive models is the difficulty of using most\nvariable selection methods in high-dimensional datasets. A genetic algorithm\nframework for variable selection with logistic regression models is used to\nsearch for two-way interaction terms in a clinical dataset of adult ICU\npatients, with separate models being built for each category of diagnosis upon\nadmittance to the ICU. The models had good discrimination across all\ncategories, with a weighted average AUC of 0.84 (>0.90 for several categories)\nand the genetic algorithm was able to find several significant interaction\nterms, which may be able to provide greater insight into mortality prediction\nfor health practitioners. The GA selected models had improved performance\nagainst stepwise selection and random forest models, and provides greater\nflexibility in terms of variable selection by being able to optimize over any\nmodeler-defined model performance metric instead of a specific variable\nimportance metric.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 16:20:29 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Gan", "Chee Chun", ""], ["Learmonth", "Gerard", ""]]}, {"id": "1604.06751", "submitter": "Mazdak Fatahi", "authors": "Mazdak Fatahi, Mahmood Ahmadi, Mahyar Shahsavari, Arash Ahmadi and\n  Philippe Devienne", "title": "evt_MNIST: A spike based version of traditional MNIST", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benchmarks and datasets have important role in evaluation of machine learning\nalgorithms and neural network implementations. Traditional dataset for images\nsuch as MNIST is applied to evaluate efficiency of different training\nalgorithms in neural networks. This demand is different in Spiking Neural\nNetworks (SNN) as they require spiking inputs. It is widely believed, in the\nbiological cortex the timing of spikes is irregular. Poisson distributions\nprovide adequate descriptions of the irregularity in generating appropriate\nspikes. Here, we introduce a spike-based version of MNSIT (handwritten digits\ndataset),using Poisson distribution and show the Poissonian property of the\ngenerated streams. We introduce a new version of evt_MNIST which can be used\nfor neural network evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 17:06:31 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Fatahi", "Mazdak", ""], ["Ahmadi", "Mahmood", ""], ["Shahsavari", "Mahyar", ""], ["Ahmadi", "Arash", ""], ["Devienne", "Philippe", ""]]}, {"id": "1604.06929", "submitter": "Alireza Goudarzi", "authors": "Alireza Goudarzi and Sarah Marzen and Peter Banda and Guy Feldman and\n  Christof Teuscher and Darko Stefanovic", "title": "Memory and Information Processing in Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNN) are simple dynamical systems whose\ncomputational power has been attributed to their short-term memory. Short-term\nmemory of RNNs has been previously studied analytically only for the case of\northogonal networks, and only under annealed approximation, and uncorrelated\ninput. Here for the first time, we present an exact solution to the memory\ncapacity and the task-solving performance as a function of the structure of a\ngiven network instance, enabling direct determination of the\nfunction--structure relation in RNNs. We calculate the memory capacity for\narbitrary networks with exponentially correlated input and further related it\nto the performance of the system on signal processing tasks in a supervised\nlearning setup. We compute the expected error and the worst-case error bound as\na function of the spectra of the network and the correlation structure of its\ninputs and outputs. Our results give an explanation for learning and\ngeneralization of task solving using short-term memory, which is crucial for\nbuilding alternative computer architectures using physical phenomena based on\nthe short-term memory principle.\n", "versions": [{"version": "v1", "created": "Sat, 23 Apr 2016 17:36:12 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Goudarzi", "Alireza", ""], ["Marzen", "Sarah", ""], ["Banda", "Peter", ""], ["Feldman", "Guy", ""], ["Teuscher", "Christof", ""], ["Stefanovic", "Darko", ""]]}, {"id": "1604.07108", "submitter": "Christopher Marriott", "authors": "Chris Marriott and Jobran Chebib", "title": "Modeling the Evolution of Gene-Culture Divergence", "comments": "8 pages, ALIFE 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.MA q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a model for evolving agents using both genetic and cultural\ninheritance mechanisms. Within each agent our model maintains two distinct\ninformation stores we call the genome and the memome. Processes of adaptation\nare modeled as evolutionary processes at each level of adaptation\n(phylogenetic, ontogenetic, sociogenetic). We review relevant competing models\nand we show how our model improves on previous attempts to model genetic and\ncultural evolutionary processes. In particular we argue our model can achieve\ndivergent gene-culture co-evolution.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 02:18:45 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Marriott", "Chris", ""], ["Chebib", "Jobran", ""]]}, {"id": "1604.07176", "submitter": "Zhen Li", "authors": "Zhen Li and Yizhou Yu", "title": "Protein Secondary Structure Prediction Using Cascaded Convolutional and\n  Recurrent Neural Networks", "comments": "8 pages, 3 figures, Accepted by International Joint Conferences on\n  Artificial Intelligence (IJCAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.AI cs.LG cs.NE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein secondary structure prediction is an important problem in\nbioinformatics. Inspired by the recent successes of deep neural networks, in\nthis paper, we propose an end-to-end deep network that predicts protein\nsecondary structures from integrated local and global contextual features. Our\ndeep architecture leverages convolutional neural networks with different kernel\nsizes to extract multiscale local contextual features. In addition, considering\nlong-range dependencies existing in amino acid sequences, we set up a\nbidirectional neural network consisting of gated recurrent unit to capture\nglobal contextual features. Furthermore, multi-task learning is utilized to\npredict secondary structure labels and amino-acid solvent accessibility\nsimultaneously. Our proposed deep network demonstrates its effectiveness by\nachieving state-of-the-art performance, i.e., 69.7% Q8 accuracy on the public\nbenchmark CB513, 76.9% Q8 accuracy on CASP10 and 73.1% Q8 accuracy on CASP11.\nOur model and results are publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 09:17:18 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Li", "Zhen", ""], ["Yu", "Yizhou", ""]]}, {"id": "1604.07269", "submitter": "Ilya Loshchilov", "authors": "Ilya Loshchilov and Frank Hutter", "title": "CMA-ES for Hyperparameter Optimization of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameters of deep neural networks are often optimized by grid search,\nrandom search or Bayesian optimization. As an alternative, we propose to use\nthe Covariance Matrix Adaptation Evolution Strategy (CMA-ES), which is known\nfor its state-of-the-art performance in derivative-free optimization. CMA-ES\nhas some useful invariance properties and is friendly to parallel evaluations\nof solutions. We provide a toy example comparing CMA-ES and state-of-the-art\nBayesian optimization algorithms for tuning the hyperparameters of a\nconvolutional neural network for the MNIST dataset on 30 GPUs in parallel.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 14:17:08 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Loshchilov", "Ilya", ""], ["Hutter", "Frank", ""]]}, {"id": "1604.07316", "submitter": "Urs Muller", "authors": "Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard\n  Firner, Beat Flepp, Prasoon Goyal, Lawrence D. Jackel, Mathew Monfort, Urs\n  Muller, Jiakai Zhang, Xin Zhang, Jake Zhao, Karol Zieba", "title": "End to End Learning for Self-Driving Cars", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We trained a convolutional neural network (CNN) to map raw pixels from a\nsingle front-facing camera directly to steering commands. This end-to-end\napproach proved surprisingly powerful. With minimum training data from humans\nthe system learns to drive in traffic on local roads with or without lane\nmarkings and on highways. It also operates in areas with unclear visual\nguidance such as in parking lots and on unpaved roads.\n  The system automatically learns internal representations of the necessary\nprocessing steps such as detecting useful road features with only the human\nsteering angle as the training signal. We never explicitly trained it to\ndetect, for example, the outline of roads.\n  Compared to explicit decomposition of the problem, such as lane marking\ndetection, path planning, and control, our end-to-end system optimizes all\nprocessing steps simultaneously. We argue that this will eventually lead to\nbetter performance and smaller systems. Better performance will result because\nthe internal components self-optimize to maximize overall system performance,\ninstead of optimizing human-selected intermediate criteria, e.g., lane\ndetection. Such criteria understandably are selected for ease of human\ninterpretation which doesn't automatically guarantee maximum system\nperformance. Smaller networks are possible because the system learns to solve\nthe problem with the minimal number of processing steps.\n  We used an NVIDIA DevBox and Torch 7 for training and an NVIDIA DRIVE(TM) PX\nself-driving car computer also running Torch 7 for determining where to drive.\nThe system operates at 30 frames per second (FPS).\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 16:03:56 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Bojarski", "Mariusz", ""], ["Del Testa", "Davide", ""], ["Dworakowski", "Daniel", ""], ["Firner", "Bernhard", ""], ["Flepp", "Beat", ""], ["Goyal", "Prasoon", ""], ["Jackel", "Lawrence D.", ""], ["Monfort", "Mathew", ""], ["Muller", "Urs", ""], ["Zhang", "Jiakai", ""], ["Zhang", "Xin", ""], ["Zhao", "Jake", ""], ["Zieba", "Karol", ""]]}, {"id": "1604.07704", "submitter": "Zhaoxiang Zang", "authors": "Zhaoxiang Zang, Zhao Li, Junying Wang, Zhiping Dan", "title": "Tournament selection in zeroth-level classifier systems based on average\n  reward reinforcement learning", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a genetics-based machine learning technique, zeroth-level classifier\nsystem (ZCS) is based on a discounted reward reinforcement learning algorithm,\nbucket-brigade algorithm, which optimizes the discounted total reward received\nby an agent but is not suitable for all multi-step problems, especially\nlarge-size ones. There are some undiscounted reinforcement learning methods\navailable, such as R-learning, which optimize the average reward per time step.\nIn this paper, R-learning is used as the reinforcement learning employed by\nZCS, to replace its discounted reward reinforcement learning approach, and\ntournament selection is used to replace roulette wheel selection in ZCS. The\nmodification results in classifier systems that can support long action chains,\nand thus is able to solve large multi-step problems.\n", "versions": [{"version": "v1", "created": "Tue, 26 Apr 2016 14:57:56 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Zang", "Zhaoxiang", ""], ["Li", "Zhao", ""], ["Wang", "Junying", ""], ["Dan", "Zhiping", ""]]}, {"id": "1604.07796", "submitter": "Henry Lo", "authors": "Henry Z. Lo and Kevin Amaral and Wei Ding", "title": "Scale Normalization", "comments": "Preliminary version submitted to ICLR workshop 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the difficulties of training deep neural networks is caused by\nimproper scaling between layers. Scaling issues introduce exploding / gradient\nproblems, and have typically been addressed by careful scale-preserving\ninitialization. We investigate the value of preserving scale, or isometry,\nbeyond the initial weights. We propose two methods of maintaing isometry, one\nexact and one stochastic. Preliminary experiments show that for both\ndeterminant and scale-normalization effectively speeds up learning. Results\nsuggest that isometry is important in the beginning of learning, and\nmaintaining it leads to faster learning.\n", "versions": [{"version": "v1", "created": "Tue, 26 Apr 2016 19:04:59 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Lo", "Henry Z.", ""], ["Amaral", "Kevin", ""], ["Ding", "Wei", ""]]}, {"id": "1604.07806", "submitter": "Jacob Schrum", "authors": "Jacob Schrum, Joel Lehman, Sebastian Risi", "title": "Using Indirect Encoding of Multiple Brains to Produce Multimodal\n  Behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important challenge in neuroevolution is to evolve complex neural networks\nwith multiple modes of behavior. Indirect encodings can potentially answer this\nchallenge. Yet in practice, indirect encodings do not yield effective\nmultimodal controllers. Thus, this paper introduces novel multimodal extensions\nto HyperNEAT, a popular indirect encoding. A previous multimodal HyperNEAT\napproach called situational policy geometry assumes that multiple brains\nbenefit from being embedded within an explicit geometric space. However,\nexperiments here illustrate that this assumption unnecessarily constrains\nevolution, resulting in lower performance. Specifically, this paper introduces\nHyperNEAT extensions for evolving many brains without assuming geometric\nrelationships between them. The resulting Multi-Brain HyperNEAT can exploit\nhuman-specified task divisions to decide when each brain controls the agent, or\ncan automatically discover when brains should be used, by means of preference\nneurons. A further extension called module mutation allows evolution to\ndiscover the number of brains, enabling multimodal behavior with even less\nexpert knowledge. Experiments in several multimodal domains highlight that\nmulti-brain approaches are more effective than HyperNEAT without multimodal\nextensions, and show that brains without a geometric relation to each other\noutperform situational policy geometry. The conclusion is that Multi-Brain\nHyperNEAT provides several promising techniques for evolving complex multimodal\nbehavior.\n", "versions": [{"version": "v1", "created": "Tue, 26 Apr 2016 19:24:52 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Schrum", "Jacob", ""], ["Lehman", "Joel", ""], ["Risi", "Sebastian", ""]]}, {"id": "1604.07904", "submitter": "Ruck Thawonmas", "authors": "Tung Nguyen, Kazuki Mori, and Ruck Thawonmas", "title": "Image Colorization Using a Deep Convolutional Neural Network", "comments": null, "journal-ref": "Proc. of ASIAGRAPH 2016, Toyama, Japan, pp. 49-50, Mar. 5-6, 2016", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel approach that uses deep learning techniques\nfor colorizing grayscale images. By utilizing a pre-trained convolutional\nneural network, which is originally designed for image classification, we are\nable to separate content and style of different images and recombine them into\na single image. We then propose a method that can add colors to a grayscale\nimage by combining its content with style of a color image having semantic\nsimilarity with the grayscale one. As an application, to our knowledge the\nfirst of its kind, we use the proposed method to colorize images of ukiyo-e a\ngenre of Japanese painting?and obtain interesting results, showing the\npotential of this method in the growing field of computer assisted art.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 02:16:43 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Nguyen", "Tung", ""], ["Mori", "Kazuki", ""], ["Thawonmas", "Ruck", ""]]}, {"id": "1604.08201", "submitter": "Wojciech Samek", "authors": "Irene Sturm, Sebastian Bach, Wojciech Samek, Klaus-Robert M\\\"uller", "title": "Interpretable Deep Neural Networks for Single-Trial EEG Classification", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: In cognitive neuroscience the potential of Deep Neural Networks\n(DNNs) for solving complex classification tasks is yet to be fully exploited.\nThe most limiting factor is that DNNs as notorious 'black boxes' do not provide\ninsight into neurophysiological phenomena underlying a decision. Layer-wise\nRelevance Propagation (LRP) has been introduced as a novel method to explain\nindividual network decisions. New Method: We propose the application of DNNs\nwith LRP for the first time for EEG data analysis. Through LRP the single-trial\nDNN decisions are transformed into heatmaps indicating each data point's\nrelevance for the outcome of the decision. Results: DNN achieves classification\naccuracies comparable to those of CSP-LDA. In subjects with low performance\nsubject-to-subject transfer of trained DNNs can improve the results. The\nsingle-trial LRP heatmaps reveal neurophysiologically plausible patterns,\nresembling CSP-derived scalp maps. Critically, while CSP patterns represent\nclass-wise aggregated information, LRP heatmaps pinpoint neural patterns to\nsingle time points in single trials. Comparison with Existing Method(s): We\ncompare the classification performance of DNNs to that of linear CSP-LDA on two\ndata sets related to motor-imaginery BCI. Conclusion: We have demonstrated that\nDNN is a powerful non-linear tool for EEG analysis. With LRP a new quality of\nhigh-resolution assessment of neural activity can be reached. LRP is a\npotential remedy for the lack of interpretability of DNNs that has limited\ntheir utility in neuroscientific applications. The extreme specificity of the\nLRP-derived heatmaps opens up new avenues for investigating neural activity\nunderlying complex perception or decision-related processes.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 19:50:40 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Sturm", "Irene", ""], ["Bach", "Sebastian", ""], ["Samek", "Wojciech", ""], ["M\u00fcller", "Klaus-Robert", ""]]}, {"id": "1604.08220", "submitter": "Ragav Venkatesan", "authors": "Ragav Venkatesan, Baoxin Li", "title": "Diving deeper into mentee networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern computer vision is all about the possession of powerful image\nrepresentations. Deeper and deeper convolutional neural networks have been\nbuilt using larger and larger datasets and are made publicly available. A large\nswath of computer vision scientists use these pre-trained networks with varying\ndegrees of successes in various tasks. Even though there is tremendous success\nin copying these networks, the representational space is not learnt from the\ntarget dataset in a traditional manner. One of the reasons for opting to use a\npre-trained network over a network learnt from scratch is that small datasets\nprovide less supervision and require meticulous regularization, smaller and\ncareful tweaking of learning rates to even achieve stable learning without\nweight explosion. It is often the case that large deep networks are not\nportable, which necessitates the ability to learn mid-sized networks from\nscratch.\n  In this article, we dive deeper into training these mid-sized networks on\nsmall datasets from scratch by drawing additional supervision from a large\npre-trained network. Such learning also provides better generalization\naccuracies than networks trained with common regularization techniques such as\nl2, l1 and dropouts. We show that features learnt thus, are more general than\nthose learnt independently. We studied various characteristics of such networks\nand found some interesting behaviors.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 20:05:45 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Venkatesan", "Ragav", ""], ["Li", "Baoxin", ""]]}, {"id": "1604.08275", "submitter": "Nicolas Papernot", "authors": "Nicolas Papernot and Patrick McDaniel and Ananthram Swami and Richard\n  Harang", "title": "Crafting Adversarial Input Sequences for Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are frequently used to solve complex security\nproblems, as well as to make decisions in sensitive situations like guiding\nautonomous vehicles or predicting financial market behaviors. Previous efforts\nhave shown that numerous machine learning models were vulnerable to adversarial\nmanipulations of their inputs taking the form of adversarial samples. Such\ninputs are crafted by adding carefully selected perturbations to legitimate\ninputs so as to force the machine learning model to misbehave, for instance by\noutputting a wrong class if the machine learning task of interest is\nclassification. In fact, to the best of our knowledge, all previous work on\nadversarial samples crafting for neural network considered models used to solve\nclassification tasks, most frequently in computer vision applications. In this\npaper, we contribute to the field of adversarial machine learning by\ninvestigating adversarial input sequences for recurrent neural networks\nprocessing sequential data. We show that the classes of algorithms introduced\npreviously to craft adversarial samples misclassified by feed-forward neural\nnetworks can be adapted to recurrent neural networks. In a experiment, we show\nthat adversaries can craft adversarial sequences misleading both categorical\nand sequential recurrent neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 00:35:32 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Papernot", "Nicolas", ""], ["McDaniel", "Patrick", ""], ["Swami", "Ananthram", ""], ["Harang", "Richard", ""]]}, {"id": "1604.08352", "submitter": "Th\\'eodore Bluche", "authors": "Th\\'eodore Bluche", "title": "Joint Line Segmentation and Transcription for End-to-End Handwritten\n  Paragraph Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline handwriting recognition systems require cropped text line images for\nboth training and recognition. On the one hand, the annotation of position and\ntranscript at line level is costly to obtain. On the other hand, automatic line\nsegmentation algorithms are prone to errors, compromising the subsequent\nrecognition. In this paper, we propose a modification of the popular and\nefficient multi-dimensional long short-term memory recurrent neural networks\n(MDLSTM-RNNs) to enable end-to-end processing of handwritten paragraphs. More\nparticularly, we replace the collapse layer transforming the two-dimensional\nrepresentation into a sequence of predictions by a recurrent version which can\nrecognize one line at a time. In the proposed model, a neural network performs\na kind of implicit line segmentation by computing attention weights on the\nimage representation. The experiments on paragraphs of Rimes and IAM database\nyield results that are competitive with those of networks trained at line\nlevel, and constitute a significant step towards end-to-end transcription of\nfull documents.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 09:08:30 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Bluche", "Th\u00e9odore", ""]]}]