[{"id": "1611.00035", "submitter": "Thomas Powers", "authors": "Scott Wisdom, Thomas Powers, John R. Hershey, Jonathan Le Roux, and\n  Les Atlas", "title": "Full-Capacity Unitary Recurrent Neural Networks", "comments": "9 pages, to appear in NIPS", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are powerful models for processing sequential data,\nbut they are generally plagued by vanishing and exploding gradient problems.\nUnitary recurrent neural networks (uRNNs), which use unitary recurrence\nmatrices, have recently been proposed as a means to avoid these issues.\nHowever, in previous experiments, the recurrence matrices were restricted to be\na product of parameterized unitary matrices, and an open question remains: when\ndoes such a parameterization fail to represent all unitary matrices, and how\ndoes this restricted representational capacity limit what can be learned? To\naddress this question, we propose full-capacity uRNNs that optimize their\nrecurrence matrix over all unitary matrices, leading to significantly improved\nperformance over uRNNs that use a restricted-capacity recurrence matrix. Our\ncontribution consists of two main components. First, we provide a theoretical\nargument to determine if a unitary parameterization has restricted capacity.\nUsing this argument, we show that a recently proposed unitary parameterization\nhas restricted capacity for hidden state dimension greater than 7. Second, we\nshow how a complete, full-capacity unitary recurrence matrix can be optimized\nover the differentiable manifold of unitary matrices. The resulting\nmultiplicative gradient step is very simple and does not require gradient\nclipping or learning rate adaptation. We confirm the utility of our claims by\nempirically evaluating our new full-capacity uRNNs on both synthetic and\nnatural data, achieving superior performance compared to both LSTMs and the\noriginal restricted-capacity uRNNs.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 20:43:21 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Wisdom", "Scott", ""], ["Powers", "Thomas", ""], ["Hershey", "John R.", ""], ["Roux", "Jonathan Le", ""], ["Atlas", "Les", ""]]}, {"id": "1611.00260", "submitter": "Vanessa Volz M.Sc.", "authors": "Vanessa Volz, G\\\"unter Rudolph, Boris Naujoks", "title": "Surrogate-Assisted Partial Order-based Evolutionary Optimisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach (SAPEO) to support the survival\nselection process in multi-objective evolutionary algorithms with surrogate\nmodels - it dynamically chooses individuals to evaluate exactly based on the\nmodel uncertainty and the distinctness of the population. We introduce variants\nthat differ in terms of the risk they allow when doing survival selection.\nHere, the anytime performance of different SAPEO variants is evaluated in\nconjunction with an SMS-EMOA using the BBOB bi-objective benchmark. We compare\nthe obtained results with the performance of the regular SMS-EMOA, as well as\nanother surrogate-assisted approach. The results open up general questions\nabout the applicability and required conditions for surrogate-assisted\nmulti-objective evolutionary algorithms to be tackled in the future.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 15:00:52 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Volz", "Vanessa", ""], ["Rudolph", "G\u00fcnter", ""], ["Naujoks", "Boris", ""]]}, {"id": "1611.00577", "submitter": "Elham Shadkam", "authors": "Zeinab Borhanifar and Elham Shadkam", "title": "The new hybrid COAW method for solving multi-objective problems", "comments": null, "journal-ref": null, "doi": "10.5121/ijfcst.2015.5602", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article using Cuckoo Optimization Algorithm and simple additive\nweighting method the hybrid COAW algorithm is presented to solve\nmulti-objective problems. Cuckoo algorithm is an efficient and structured\nmethod for solving nonlinear continuous problems. The created Pareto frontiers\nof the COAW proposed algorithm are exact and have good dispersion. This method\nhas a high speed in finding the Pareto frontiers and identifies the beginning\nand end points of Pareto frontiers properly. In order to validation the\nproposed algorithm, several experimental problems were analyzed. The results of\nwhich indicate the proper effectiveness of COAW algorithm for solving\nmulti-objective problems.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2016 16:32:47 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Borhanifar", "Zeinab", ""], ["Shadkam", "Elham", ""]]}, {"id": "1611.00591", "submitter": "Kshiteej Sheth Jitesh", "authors": "Kshiteej Sheth", "title": "Deep Neural Networks for HDR imaging", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose novel methods of solving two tasks using Convolutional Neural\nNetworks, firstly the task of generating HDR map of a static scene using\ndifferently exposed LDR images of the scene captured using conventional cameras\nand secondly the task of finding an optimal tone mapping operator that would\ngive a better score on the TMQI metric compared to the existing methods. We\nquantitatively show the performance of our networks and illustrate the cases\nwhere our networks performs good as well as bad.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2016 16:20:13 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Sheth", "Kshiteej", ""]]}, {"id": "1611.00710", "submitter": "Jonathan Binas", "authors": "Jonathan Binas, Giacomo Indiveri, Michael Pfeiffer", "title": "Deep counter networks for asynchronous event-based processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their advantages in terms of computational resources, latency, and\npower consumption, event-based implementations of neural networks have not been\nable to achieve the same performance figures as their equivalent\nstate-of-the-art deep network models. We propose counter neurons as minimal\nspiking neuron models which only require addition and comparison operations,\nthus avoiding costly multiplications. We show how inference carried out in deep\ncounter networks converges to the same accuracy levels as are achieved with\nstate-of-the-art conventional networks. As their event-based style of\ncomputation leads to reduced latency and sparse updates, counter networks are\nideally suited for efficient compact and low-power hardware implementation. We\npresent theory and training methods for counter networks, and demonstrate on\nthe MNIST benchmark that counter networks converge quickly, both in terms of\ntime and number of operations required, to state-of-the-art classification\naccuracy.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 18:22:33 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Binas", "Jonathan", ""], ["Indiveri", "Giacomo", ""], ["Pfeiffer", "Michael", ""]]}, {"id": "1611.00736", "submitter": "Wojciech Zaremba", "authors": "Eric Price, Wojciech Zaremba, Ilya Sutskever", "title": "Extensions and Limitations of the Neural GPU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Neural GPU is a recent model that can learn algorithms such as\nmulti-digit binary addition and binary multiplication in a way that generalizes\nto inputs of arbitrary length. We show that there are two simple ways of\nimproving the performance of the Neural GPU: by carefully designing a\ncurriculum, and by increasing model size. The latter requires a memory\nefficient implementation, as a naive implementation of the Neural GPU is memory\nintensive. We find that these techniques increase the set of algorithmic\nproblems that can be solved by the Neural GPU: we have been able to learn to\nperform all the arithmetic operations (and generalize to arbitrarily long\nnumbers) when the arguments are given in the decimal representation (which,\nsurprisingly, has not been possible before). We have also been able to train\nthe Neural GPU to evaluate long arithmetic expressions with multiple operands\nthat require respecting the precedence order of the operands, although these\nhave succeeded only in their binary representation, and not with perfect\naccuracy.\n  In addition, we gain insight into the Neural GPU by investigating its failure\nmodes. We find that Neural GPUs that correctly generalize to arbitrarily long\nnumbers still fail to compute the correct answer on highly-symmetric, atypical\ninputs: for example, a Neural GPU that achieves near-perfect generalization on\ndecimal multiplication of up to 100-digit long numbers can fail on\n$000000\\dots002 \\times 000000\\dots002$ while succeeding at $2 \\times 2$. These\nfailure modes are reminiscent of adversarial examples.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 19:18:17 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2016 20:46:40 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Price", "Eric", ""], ["Zaremba", "Wojciech", ""], ["Sutskever", "Ilya", ""]]}, {"id": "1611.00847", "submitter": "Leslie Smith", "authors": "Leslie N. Smith and Nicholay Topin", "title": "Deep Convolutional Neural Network Design Patterns", "comments": "Submitted as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in the deep learning field has produced a plethora of new\narchitectures. At the same time, a growing number of groups are applying deep\nlearning to new applications. Some of these groups are likely to be composed of\ninexperienced deep learning practitioners who are baffled by the dizzying array\nof architecture choices and therefore opt to use an older architecture (i.e.,\nAlexnet). Here we attempt to bridge this gap by mining the collective knowledge\ncontained in recent deep learning research to discover underlying principles\nfor designing neural network architectures. In addition, we describe several\narchitectural innovations, including Fractal of FractalNet network, Stagewise\nBoosting Networks, and Taylor Series Networks (our Caffe code and prototxt\nfiles is available at https://github.com/iPhysicist/CNNDesignPatterns). We hope\nothers are inspired to build on our preliminary work.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 23:48:04 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2016 00:49:46 GMT"}, {"version": "v3", "created": "Mon, 14 Nov 2016 14:10:41 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Smith", "Leslie N.", ""], ["Topin", "Nicholay", ""]]}, {"id": "1611.00864", "submitter": "R Devon Hjelm", "authors": "R Devon Hjelm and Eswar Damaraju and Kyunghyun Cho and Helmut Laufs\n  and Sergey M. Plis and Vince Calhoun", "title": "Spatio-temporal Dynamics of Intrinsic Networks in Functional Magnetic\n  Imaging Data Using Recurrent Neural Networks", "comments": "Accepted to Frontiers of Neuroscience", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel recurrent neural network (RNN) approach to account for\ntemporal dynamics and dependencies in brain networks observed via functional\nmagnetic resonance imaging (fMRI). Our approach directly parameterizes temporal\ndynamics through recurrent connections, which can be used to formulate blind\nsource separation with a conditional (rather than marginal) independence\nassumption, which we call RNN-ICA. This formulation enables us to visualize the\ntemporal dynamics of both first order (activity) and second order (directed\nconnectivity) information in brain networks that are widely studied in a static\nsense, but not well-characterized dynamically. RNN-ICA predicts dynamics\ndirectly from the recurrent states of the RNN in both task and resting state\nfMRI. Our results show both task-related and group-differentiating directed\nconnectivity.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 02:45:26 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 13:32:41 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Hjelm", "R Devon", ""], ["Damaraju", "Eswar", ""], ["Cho", "Kyunghyun", ""], ["Laufs", "Helmut", ""], ["Plis", "Sergey M.", ""], ["Calhoun", "Vince", ""]]}, {"id": "1611.00890", "submitter": "Jeremy Every Mr", "authors": "Jeremy Every, Li Li, Youguang G. Guo, David G. Dorrell", "title": "Maximizing Investment Value of Small-Scale PV in a Smart Grid\n  Environment", "comments": "To appear the proceedings of the 5th International Conference for\n  Renewable Energy Research and Applications (ICRERA2016), Birmingham, United\n  Kingdom. 6 pages. 3 figures", "journal-ref": "2016 IEEE International Conference on Renewable Energy Research\n  and Applications (ICRERA), 2016, pp. 385-390", "doi": "10.1109/ICRERA.2016.7884366", "report-no": null, "categories": "math.OC cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the optimal size and orientation of small-scale residential based\nPV arrays will become increasingly complex in the future smart grid environment\nwith the introduction of smart meters and dynamic tariffs. However consumers\ncan leverage the availability of smart meter data to conduct a more detailed\nexploration of PV investment options for their particular circumstances. In\nthis paper, an optimization method for PV orientation and sizing is proposed\nwhereby maximizing the PV investment value is set as the defining objective.\nSolar insolation and PV array models are described to form the basis of the PV\narray optimization strategy. A constrained particle swarm optimization\nalgorithm is selected due to its strong performance in non-linear applications.\nThe optimization algorithm is applied to real-world metered data to quantify\nthe possible investment value of a PV installation under different energy\nretailers and tariff structures. The arrangement with the highest value is\ndetermined to enable prospective small-scale PV investors to select the most\ncost-effective system.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 05:57:01 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Every", "Jeremy", ""], ["Li", "Li", ""], ["Guo", "Youguang G.", ""], ["Dorrell", "David G.", ""]]}, {"id": "1611.00945", "submitter": "Dylan Muir", "authors": "Hongzhi You and Giacomo Indiveri and Dylan Richard Muir", "title": "Surround suppression explained by long-range recruitment of local\n  competition, in a columnar V1 model", "comments": "32 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Although neurons in columns of visual cortex of adult carnivores and primates\nshare similar orientation tuning preferences, responses of nearby neurons are\nsurprisingly sparse and temporally uncorrelated, especially in response to\ncomplex visual scenes. The mechanisms underlying this counter-intuitive\ncombination of response properties are still unknown. Here we present a\ncomputational model of columnar visual cortex which explains experimentally\nobserved integration of complex features across the visual field, and which is\nconsistent with anatomical and physiological profiles of cortical excitation\nand inhibition. In this model, sparse local excitatory connections within\ncolumns, coupled with strong unspecific local inhibition and\nfunctionally-specific long-range excitatory connections across columns, give\nrise to competitive dynamics that reproduce experimental observations. Our\nresults explain surround modulation of responses to simple and complex visual\nstimuli, including reduced correlation of nearby excitatory neurons, increased\nexcitatory response selectivity, increased inhibitory selectivity, and complex\norientation-tuning of surround modulation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 10:27:27 GMT"}, {"version": "v2", "created": "Thu, 30 Mar 2017 12:14:21 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["You", "Hongzhi", ""], ["Indiveri", "Giacomo", ""], ["Muir", "Dylan Richard", ""]]}, {"id": "1611.01046", "submitter": "Gilles Louppe", "authors": "Gilles Louppe, Michael Kagan, Kyle Cranmer", "title": "Learning to Pivot with Adversarial Networks", "comments": "v1: Original submission. v2: Fixed references. v3: version submitted\n  to NIPS'2017. Code available at\n  https://github.com/glouppe/paper-learning-to-pivot", "journal-ref": "Advances in Neural Information Processing Systems 30, pages\n  981-990, 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE physics.data-an stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several techniques for domain adaptation have been proposed to account for\ndifferences in the distribution of the data used for training and testing. The\nmajority of this work focuses on a binary domain label. Similar problems occur\nin a scientific context where there may be a continuous family of plausible\ndata generation processes associated to the presence of systematic\nuncertainties. Robust inference is possible if it is based on a pivot -- a\nquantity whose distribution does not depend on the unknown values of the\nnuisance parameters that parametrize this family of data generation processes.\nIn this work, we introduce and derive theoretical results for a training\nprocedure based on adversarial networks for enforcing the pivotal property (or,\nequivalently, fairness with respect to continuous attributes) on a predictive\nmodel. The method includes a hyperparameter to control the trade-off between\naccuracy and robustness. We demonstrate the effectiveness of this approach with\na toy example and examples from particle physics.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 14:41:40 GMT"}, {"version": "v2", "created": "Sat, 19 Nov 2016 12:31:03 GMT"}, {"version": "v3", "created": "Thu, 1 Jun 2017 19:04:01 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Louppe", "Gilles", ""], ["Kagan", "Michael", ""], ["Cranmer", "Kyle", ""]]}, {"id": "1611.01146", "submitter": "Zeyuan Allen-Zhu", "authors": "Naman Agarwal, Zeyuan Allen-Zhu, Brian Bullins, Elad Hazan, Tengyu Ma", "title": "Finding Approximate Local Minima Faster than Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a non-convex second-order optimization algorithm that is guaranteed\nto return an approximate local minimum in time which scales linearly in the\nunderlying dimension and the number of training examples. The time complexity\nof our algorithm to find an approximate local minimum is even faster than that\nof gradient descent to find a critical point. Our algorithm applies to a\ngeneral class of optimization problems including training a neural network and\nother non-convex objectives arising in machine learning.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 19:50:32 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2016 18:38:50 GMT"}, {"version": "v3", "created": "Fri, 3 Feb 2017 18:13:20 GMT"}, {"version": "v4", "created": "Mon, 24 Apr 2017 19:20:07 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Agarwal", "Naman", ""], ["Allen-Zhu", "Zeyuan", ""], ["Bullins", "Brian", ""], ["Hazan", "Elad", ""], ["Ma", "Tengyu", ""]]}, {"id": "1611.01186", "submitter": "Sihan Li", "authors": "Sihan Li, Jiantao Jiao, Yanjun Han, Tsachy Weissman", "title": "Demystifying ResNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Residual Network (ResNet), proposed in He et al. (2015), utilized\nshortcut connections to significantly reduce the difficulty of training, which\nresulted in great performance boosts in terms of both training and\ngeneralization error.\n  It was empirically observed in He et al. (2015) that stacking more layers of\nresidual blocks with shortcut 2 results in smaller training error, while it is\nnot true for shortcut of length 1 or 3. We provide a theoretical explanation\nfor the uniqueness of shortcut 2.\n  We show that with or without nonlinearities, by adding shortcuts that have\ndepth two, the condition number of the Hessian of the loss function at the zero\ninitial point is depth-invariant, which makes training very deep models no more\ndifficult than shallow ones. Shortcuts of higher depth result in an extremely\nflat (high-order) stationary point initially, from which the optimization\nalgorithm is hard to escape. The shortcut 1, however, is essentially equivalent\nto no shortcuts, which has a condition number exploding to infinity as the\nnumber of layers grows. We further argue that as the number of layers tends to\ninfinity, it suffices to only look at the loss function at the zero initial\npoint.\n  Extensive experiments are provided accompanying our theoretical results. We\nshow that initializing the network to small weights with shortcut 2 achieves\nsignificantly better results than random Gaussian (Xavier) initialization,\northogonal initialization, and shortcuts of deeper depth, from various\nperspectives ranging from final loss, learning dynamics and stability, to the\nbehavior of the Hessian along the learning process.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 20:55:49 GMT"}, {"version": "v2", "created": "Sat, 20 May 2017 10:18:06 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Li", "Sihan", ""], ["Jiao", "Jiantao", ""], ["Han", "Yanjun", ""], ["Weissman", "Tsachy", ""]]}, {"id": "1611.01211", "submitter": "Zachary Lipton", "authors": "Zachary C. Lipton, Kamyar Azizzadenesheli, Abhishek Kumar, Lihong Li,\n  Jianfeng Gao, Li Deng", "title": "Combating Reinforcement Learning's Sisyphean Curse with Intrinsic Fear", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many practical environments contain catastrophic states that an optimal agent\nwould visit infrequently or never. Even on toy problems, Deep Reinforcement\nLearning (DRL) agents tend to periodically revisit these states upon forgetting\ntheir existence under a new policy. We introduce intrinsic fear (IF), a learned\nreward shaping that guards DRL agents against periodic catastrophes. IF agents\npossess a fear model trained to predict the probability of imminent\ncatastrophe. This score is then used to penalize the Q-learning objective. Our\ntheoretical analysis bounds the reduction in average return due to learning on\nthe perturbed objective. We also prove robustness to classification errors. As\na bonus, IF models tend to learn faster, owing to reward shaping. Experiments\ndemonstrate that intrinsic-fear DQNs solve otherwise pathological environments\nand improve on several Atari games.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 22:30:10 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 04:22:31 GMT"}, {"version": "v3", "created": "Thu, 1 Dec 2016 01:27:56 GMT"}, {"version": "v4", "created": "Tue, 21 Mar 2017 21:32:25 GMT"}, {"version": "v5", "created": "Mon, 15 May 2017 05:05:08 GMT"}, {"version": "v6", "created": "Tue, 23 May 2017 01:39:00 GMT"}, {"version": "v7", "created": "Sun, 8 Oct 2017 05:40:45 GMT"}, {"version": "v8", "created": "Tue, 13 Mar 2018 21:24:47 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Lipton", "Zachary C.", ""], ["Azizzadenesheli", "Kamyar", ""], ["Kumar", "Abhishek", ""], ["Li", "Lihong", ""], ["Gao", "Jianfeng", ""], ["Deng", "Li", ""]]}, {"id": "1611.01235", "submitter": "Tiffany Hwu", "authors": "Tiffany Hwu, Jacob Isbell, Nicolas Oros, and Jeffrey Krichmar", "title": "A Self-Driving Robot Using Deep Convolutional Neural Networks on\n  Neuromorphic Hardware", "comments": "6 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic computing is a promising solution for reducing the size, weight\nand power of mobile embedded systems. In this paper, we introduce a realization\nof such a system by creating the first closed-loop battery-powered\ncommunication system between an IBM TrueNorth NS1e and an autonomous\nAndroid-Based Robotics platform. Using this system, we constructed a dataset of\npath following behavior by manually driving the Android-Based robot along steep\nmountain trails and recording video frames from the camera mounted on the robot\nalong with the corresponding motor commands. We used this dataset to train a\ndeep convolutional neural network implemented on the TrueNorth NS1e. The NS1e,\nwhich was mounted on the robot and powered by the robot's battery, resulted in\na self-driving robot that could successfully traverse a steep mountain path in\nreal time. To our knowledge, this represents the first time the TrueNorth NS1e\nneuromorphic chip has been embedded on a mobile platform under closed-loop\ncontrol.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 01:10:07 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Hwu", "Tiffany", ""], ["Isbell", "Jacob", ""], ["Oros", "Nicolas", ""], ["Krichmar", "Jeffrey", ""]]}, {"id": "1611.01268", "submitter": "Hyo-Eun Kim", "authors": "Hyo-Eun Kim, Sangheum Hwang, Kyunghyun Cho", "title": "Semantic Noise Modeling for Better Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent representation learned from multi-layered neural networks via\nhierarchical feature abstraction enables recent success of deep learning. Under\nthe deep learning framework, generalization performance highly depends on the\nlearned latent representation which is obtained from an appropriate training\nscenario with a task-specific objective on a designed network model. In this\nwork, we propose a novel latent space modeling method to learn better latent\nrepresentation. We designed a neural network model based on the assumption that\ngood base representation can be attained by maximizing the total correlation\nbetween the input, latent, and output variables. From the base model, we\nintroduce a semantic noise modeling method which enables class-conditional\nperturbation on latent space to enhance the representational power of learned\nlatent feature. During training, latent vector representation can be\nstochastically perturbed by a modeled class-conditional additive noise while\nmaintaining its original semantic feature. It implicitly brings the effect of\nsemantic augmentation on the latent space. The proposed model can be easily\nlearned by back-propagation with common gradient-based optimization algorithms.\nExperimental results show that the proposed method helps to achieve performance\nbenefits against various previous approaches. We also provide the empirical\nanalyses for the proposed class-conditional perturbation process including\nt-SNE visualization.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 05:52:17 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Kim", "Hyo-Eun", ""], ["Hwang", "Sangheum", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1611.01331", "submitter": "Leon Sixt", "authors": "Leon Sixt, Benjamin Wild, Tim Landgraf", "title": "RenderGAN: Generating Realistic Labeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Convolutional Neuronal Networks (DCNNs) are showing remarkable\nperformance on many computer vision tasks. Due to their large parameter space,\nthey require many labeled samples when trained in a supervised setting. The\ncosts of annotating data manually can render the use of DCNNs infeasible. We\npresent a novel framework called RenderGAN that can generate large amounts of\nrealistic, labeled images by combining a 3D model and the Generative\nAdversarial Network framework. In our approach, image augmentations (e.g.\nlighting, background, and detail) are learned from unlabeled data such that the\ngenerated images are strikingly realistic while preserving the labels known\nfrom the 3D model. We apply the RenderGAN framework to generate images of\nbarcode-like markers that are attached to honeybees. Training a DCNN on data\ngenerated by the RenderGAN yields considerably better performance than training\nit on various baselines.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 11:20:38 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 06:28:15 GMT"}, {"version": "v3", "created": "Thu, 17 Nov 2016 17:23:28 GMT"}, {"version": "v4", "created": "Fri, 9 Dec 2016 13:18:13 GMT"}, {"version": "v5", "created": "Thu, 12 Jan 2017 13:37:26 GMT"}], "update_date": "2017-01-13", "authors_parsed": [["Sixt", "Leon", ""], ["Wild", "Benjamin", ""], ["Landgraf", "Tim", ""]]}, {"id": "1611.01427", "submitter": "Arash Ardakani", "authors": "Arash Ardakani, Carlo Condo and Warren J. Gross", "title": "Sparsely-Connected Neural Networks: Towards Efficient VLSI\n  Implementation of Deep Neural Networks", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deep neural networks have received considerable attention due to\ntheir ability to extract and represent high-level abstractions in data sets.\nDeep neural networks such as fully-connected and convolutional neural networks\nhave shown excellent performance on a wide range of recognition and\nclassification tasks. However, their hardware implementations currently suffer\nfrom large silicon area and high power consumption due to the their high degree\nof complexity. The power/energy consumption of neural networks is dominated by\nmemory accesses, the majority of which occur in fully-connected networks. In\nfact, they contain most of the deep neural network parameters. In this paper,\nwe propose sparsely-connected networks, by showing that the number of\nconnections in fully-connected networks can be reduced by up to 90% while\nimproving the accuracy performance on three popular datasets (MNIST, CIFAR10\nand SVHN). We then propose an efficient hardware architecture based on\nlinear-feedback shift registers to reduce the memory requirements of the\nproposed sparsely-connected networks. The proposed architecture can save up to\n90% of memory compared to the conventional implementations of fully-connected\nneural networks. Moreover, implementation results show up to 84% reduction in\nthe energy consumption of a single neuron of the proposed sparsely-connected\nnetworks compared to a single neuron of fully-connected neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 15:47:32 GMT"}, {"version": "v2", "created": "Fri, 17 Mar 2017 15:52:44 GMT"}, {"version": "v3", "created": "Thu, 30 Mar 2017 19:51:47 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Ardakani", "Arash", ""], ["Condo", "Carlo", ""], ["Gross", "Warren J.", ""]]}, {"id": "1611.01576", "submitter": "James Bradbury", "authors": "James Bradbury, Stephen Merity, Caiming Xiong, Richard Socher", "title": "Quasi-Recurrent Neural Networks", "comments": "Submitted to conference track at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are a powerful tool for modeling sequential data,\nbut the dependence of each timestep's computation on the previous timestep's\noutput limits parallelism and makes RNNs unwieldy for very long sequences. We\nintroduce quasi-recurrent neural networks (QRNNs), an approach to neural\nsequence modeling that alternates convolutional layers, which apply in parallel\nacross timesteps, and a minimalist recurrent pooling function that applies in\nparallel across channels. Despite lacking trainable recurrent layers, stacked\nQRNNs have better predictive accuracy than stacked LSTMs of the same hidden\nsize. Due to their increased parallelism, they are up to 16 times faster at\ntrain and test time. Experiments on language modeling, sentiment\nclassification, and character-level neural machine translation demonstrate\nthese advantages and underline the viability of QRNNs as a basic building block\nfor a variety of sequence tasks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 00:31:25 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 20:52:34 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Bradbury", "James", ""], ["Merity", "Stephen", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1611.01578", "submitter": "Quoc Le", "authors": "Barret Zoph and Quoc V. Le", "title": "Neural Architecture Search with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are powerful and flexible models that work well for many\ndifficult learning tasks in image, speech and natural language understanding.\nDespite their success, neural networks are still hard to design. In this paper,\nwe use a recurrent network to generate the model descriptions of neural\nnetworks and train this RNN with reinforcement learning to maximize the\nexpected accuracy of the generated architectures on a validation set. On the\nCIFAR-10 dataset, our method, starting from scratch, can design a novel network\narchitecture that rivals the best human-invented architecture in terms of test\nset accuracy. Our CIFAR-10 model achieves a test error rate of 3.65, which is\n0.09 percent better and 1.05x faster than the previous state-of-the-art model\nthat used a similar architectural scheme. On the Penn Treebank dataset, our\nmodel can compose a novel recurrent cell that outperforms the widely-used LSTM\ncell, and other state-of-the-art baselines. Our cell achieves a test set\nperplexity of 62.4 on the Penn Treebank, which is 3.6 perplexity better than\nthe previous state-of-the-art model. The cell can also be transferred to the\ncharacter language modeling task on PTB and achieves a state-of-the-art\nperplexity of 1.214.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 00:41:37 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 05:28:05 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Zoph", "Barret", ""], ["Le", "Quoc V.", ""]]}, {"id": "1611.01590", "submitter": "Christian Gagn\\'e", "authors": "Farkhondeh Kiaee, Christian Gagn\\'e, and Mahdieh Abbasi", "title": "Alternating Direction Method of Multipliers for Sparse Convolutional\n  Neural Networks", "comments": "Under review as a conference paper at ICLR 2017. arXiv admin note:\n  text overlap with arXiv:1111.6188 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The storage and computation requirements of Convolutional Neural Networks\n(CNNs) can be prohibitive for exploiting these models over low-power or\nembedded devices. This paper reduces the computational complexity of the CNNs\nby minimizing an objective function, including the recognition loss that is\naugmented with a sparsity-promoting penalty term. The sparsity structure of the\nnetwork is identified using the Alternating Direction Method of Multipliers\n(ADMM), which is widely used in large optimization problems. This method\nalternates between promoting the sparsity of the network and optimizing the\nrecognition performance, which allows us to exploit the two-part structure of\nthe corresponding objective functions. In particular, we take advantage of the\nseparability of the sparsity-inducing penalty functions to decompose the\nminimization problem into sub-problems that can be solved sequentially.\nApplying our method to a variety of state-of-the-art CNN models, our proposed\nmethod is able to simplify the original model, generating models with less\ncomputation and fewer parameters, while maintaining and often improving\ngeneralization performance. Accomplishments on a variety of models strongly\nverify that our proposed ADMM-based method can be a very useful tool for\nsimplifying and improving deep CNNs.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 02:51:24 GMT"}, {"version": "v2", "created": "Mon, 5 Dec 2016 04:11:25 GMT"}, {"version": "v3", "created": "Sun, 15 Jan 2017 20:42:48 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Kiaee", "Farkhondeh", ""], ["Gagn\u00e9", "Christian", ""], ["Abbasi", "Mahdieh", ""]]}, {"id": "1611.01600", "submitter": "Lu Hou", "authors": "Lu Hou, Quanming Yao, James T. Kwok", "title": "Loss-aware Binarization of Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network models, though very powerful and highly successful, are\ncomputationally expensive in terms of space and time. Recently, there have been\na number of attempts on binarizing the network weights and activations. This\ngreatly reduces the network size, and replaces the underlying multiplications\nto additions or even XNOR bit operations. However, existing binarization\nschemes are based on simple matrix approximation and ignore the effect of\nbinarization on the loss. In this paper, we propose a proximal Newton algorithm\nwith diagonal Hessian approximation that directly minimizes the loss w.r.t. the\nbinarized weights. The underlying proximal step has an efficient closed-form\nsolution, and the second-order information can be efficiently obtained from the\nsecond moments already computed by the Adam optimizer. Experiments on both\nfeedforward and recurrent networks show that the proposed loss-aware\nbinarization algorithm outperforms existing binarization schemes, and is also\nmore robust for wide and deep networks.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 04:23:42 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 02:49:19 GMT"}, {"version": "v3", "created": "Thu, 10 May 2018 11:20:09 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Hou", "Lu", ""], ["Yao", "Quanming", ""], ["Kwok", "James T.", ""]]}, {"id": "1611.01639", "submitter": "Patrick McClure", "authors": "Patrick McClure, Nikolaus Kriegeskorte", "title": "Robustly representing uncertainty in deep neural networks through\n  sampling", "comments": "Bayesian Deep Learning Workshop (NIPS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep neural networks (DNNs) are applied to increasingly challenging\nproblems, they will need to be able to represent their own uncertainty.\nModeling uncertainty is one of the key features of Bayesian methods. Using\nBernoulli dropout with sampling at prediction time has recently been proposed\nas an efficient and well performing variational inference method for DNNs.\nHowever, sampling from other multiplicative noise based variational\ndistributions has not been investigated in depth. We evaluated Bayesian DNNs\ntrained with Bernoulli or Gaussian multiplicative masking of either the units\n(dropout) or the weights (dropconnect). We tested the calibration of the\nprobabilistic predictions of Bayesian convolutional neural networks (CNNs) on\nMNIST and CIFAR-10. Sampling at prediction time increased the calibration of\nthe DNNs' probabalistic predictions. Sampling weights, whether Gaussian or\nBernoulli, led to more robust representation of uncertainty compared to\nsampling of units. However, using either Gaussian or Bernoulli dropout led to\nincreased test set classification accuracy. Based on these findings we used\nboth Bernoulli dropout and Gaussian dropconnect concurrently, which we show\napproximates the use of a spike-and-slab variational distribution without\nincreasing the number of learned parameters. We found that spike-and-slab\nsampling had higher test set performance than Gaussian dropconnect and more\nrobustly represented its uncertainty compared to Bernoulli dropout.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 12:32:16 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 09:27:46 GMT"}, {"version": "v3", "created": "Thu, 2 Feb 2017 10:21:33 GMT"}, {"version": "v4", "created": "Fri, 1 Sep 2017 02:50:59 GMT"}, {"version": "v5", "created": "Tue, 5 Dec 2017 16:11:17 GMT"}, {"version": "v6", "created": "Fri, 8 Dec 2017 17:36:22 GMT"}, {"version": "v7", "created": "Sat, 20 Jan 2018 13:44:32 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["McClure", "Patrick", ""], ["Kriegeskorte", "Nikolaus", ""]]}, {"id": "1611.01652", "submitter": "Jonas Degrave", "authors": "Jonas Degrave, Michiel Hermans, Joni Dambre, Francis wyffels", "title": "A Differentiable Physics Engine for Deep Learning in Robotics", "comments": "Submitted for International Conference on Learning Representations\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important field in robotics is the optimization of controllers. Currently,\nrobots are often treated as a black box in this optimization process, which is\nthe reason why derivative-free optimization methods such as evolutionary\nalgorithms or reinforcement learning are omnipresent. When gradient-based\nmethods are used, models are kept small or rely on finite difference\napproximations for the Jacobian. This method quickly grows expensive with\nincreasing numbers of parameters, such as found in deep learning. We propose\nthe implementation of a modern physics engine, which can differentiate control\nparameters. This engine is implemented for both CPU and GPU. Firstly, this\npaper shows how such an engine speeds up the optimization process, even for\nsmall problems. Furthermore, it explains why this is an alternative approach to\ndeep Q-learning, for using deep learning in robotics. Finally, we argue that\nthis is a big step for deep learning in robotics, as it opens up new\npossibilities to optimize robots, both in hardware and software.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 13:34:58 GMT"}, {"version": "v2", "created": "Sat, 24 Nov 2018 14:41:48 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Degrave", "Jonas", ""], ["Hermans", "Michiel", ""], ["Dambre", "Joni", ""], ["wyffels", "Francis", ""]]}, {"id": "1611.01673", "submitter": "Ian Gemp", "authors": "Ishan Durugkar, Ian Gemp, Sridhar Mahadevan", "title": "Generative Multi-Adversarial Networks", "comments": "Accepted as a conference paper (poster) at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are a framework for producing a\ngenerative model by way of a two-player minimax game. In this paper, we propose\nthe \\emph{Generative Multi-Adversarial Network} (GMAN), a framework that\nextends GANs to multiple discriminators. In previous work, the successful\ntraining of GANs requires modifying the minimax objective to accelerate\ntraining early on. In contrast, GMAN can be reliably trained with the original,\nuntampered objective. We explore a number of design perspectives with the\ndiscriminator role ranging from formidable adversary to forgiving teacher.\nImage generation tasks comparing the proposed framework to standard GANs\ndemonstrate GMAN produces higher quality samples in a fraction of the\niterations when measured by a pairwise GAM-type metric.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 16:56:44 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 15:33:09 GMT"}, {"version": "v3", "created": "Thu, 2 Mar 2017 21:20:59 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Durugkar", "Ishan", ""], ["Gemp", "Ian", ""], ["Mahadevan", "Sridhar", ""]]}, {"id": "1611.01678", "submitter": "Morsal Madani", "authors": "Mirmorsal Madani", "title": "Comparing learning algorithms in neural network for diagnosing\n  cardiovascular disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today data mining techniques are exploited in medical science for diagnosing,\novercoming and treating diseases. Neural network is one of the techniques which\nare widely used for diagnosis in medical field. In this article efficiency of\nnine algorithms, which are basis of neural network learning in diagnosing\ncardiovascular diseases, will be assessed. Algorithms are assessed in terms of\naccuracy, sensitivity, transparency, AROC and convergence rate by means of 10\nfold cross validation. The results suggest that in training phase, Lonberg-M\nalgorithm has the best efficiency in terms of all metrics, algorithm OSS has\nmaximum accuracy in testing phase, algorithm SCG has the maximum transparency\nand algorithm CGB has the maximum sensitivity.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 17:17:14 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Madani", "Mirmorsal", ""]]}, {"id": "1611.01734", "submitter": "Timothy Dozat", "authors": "Timothy Dozat and Christopher D. Manning", "title": "Deep Biaffine Attention for Neural Dependency Parsing", "comments": "Accepted to ICLR 2017; updated with new results and comparison to\n  more recent models, including current state-of-the-art", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper builds off recent work from Kiperwasser & Goldberg (2016) using\nneural attention in a simple graph-based dependency parser. We use a larger but\nmore thoroughly regularized parser than other recent BiLSTM-based approaches,\nwith biaffine classifiers to predict arcs and labels. Our parser gets state of\nthe art or near state of the art performance on standard treebanks for six\ndifferent languages, achieving 95.7% UAS and 94.1% LAS on the most popular\nEnglish PTB dataset. This makes it the highest-performing graph-based parser on\nthis benchmark---outperforming Kiperwasser Goldberg (2016) by 1.8% and\n2.2%---and comparable to the highest performing transition-based parser\n(Kuncoro et al., 2016), which achieves 95.8% UAS and 94.6% LAS. We also show\nwhich hyperparameter choices had a significant effect on parsing accuracy,\nallowing us to achieve large gains over other graph-based approaches.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 07:26:38 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 02:01:39 GMT"}, {"version": "v3", "created": "Fri, 10 Mar 2017 04:37:03 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Dozat", "Timothy", ""], ["Manning", "Christopher D.", ""]]}, {"id": "1611.01796", "submitter": "Jacob Andreas", "authors": "Jacob Andreas and Dan Klein and Sergey Levine", "title": "Modular Multitask Reinforcement Learning with Policy Sketches", "comments": "To appear at ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a framework for multitask deep reinforcement learning guided by\npolicy sketches. Sketches annotate tasks with sequences of named subtasks,\nproviding information about high-level structural relationships among tasks but\nnot how to implement them---specifically not providing the detailed guidance\nused by much previous work on learning policy abstractions for RL (e.g.\nintermediate rewards, subtask completion signals, or intrinsic motivations). To\nlearn from sketches, we present a model that associates every subtask with a\nmodular subpolicy, and jointly maximizes reward over full task-specific\npolicies by tying parameters across shared subpolicies. Optimization is\naccomplished via a decoupled actor--critic training objective that facilitates\nlearning common behaviors from multiple dissimilar reward functions. We\nevaluate the effectiveness of our approach in three environments featuring both\ndiscrete and continuous control, and with sparse rewards that can be obtained\nonly after completing a number of high-level subgoals. Experiments show that\nusing our approach to learn policies guided by sketches gives better\nperformance than existing techniques for learning task-specific or shared\npolicies, while naturally inducing a library of interpretable primitive\nbehaviors that can be recombined to rapidly adapt to new tasks.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 15:36:56 GMT"}, {"version": "v2", "created": "Sat, 17 Jun 2017 01:49:12 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Andreas", "Jacob", ""], ["Klein", "Dan", ""], ["Levine", "Sergey", ""]]}, {"id": "1611.01843", "submitter": "Misha Denil", "authors": "Misha Denil, Pulkit Agrawal, Tejas D Kulkarni, Tom Erez, Peter\n  Battaglia, Nando de Freitas", "title": "Learning to Perform Physics Experiments via Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG cs.NE physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When encountering novel objects, humans are able to infer a wide range of\nphysical properties such as mass, friction and deformability by interacting\nwith them in a goal driven way. This process of active interaction is in the\nsame spirit as a scientist performing experiments to discover hidden facts.\nRecent advances in artificial intelligence have yielded machines that can\nachieve superhuman performance in Go, Atari, natural language processing, and\ncomplex control problems; however, it is not clear that these systems can rival\nthe scientific intuition of even a young child. In this work we introduce a\nbasic set of tasks that require agents to estimate properties such as mass and\ncohesion of objects in an interactive simulated environment where they can\nmanipulate the objects and observe the consequences. We found that state of art\ndeep reinforcement learning methods can learn to perform the experiments\nnecessary to discover such hidden properties. By systematically manipulating\nthe problem difficulty and the cost incurred by the agent for performing\nexperiments, we found that agents learn different strategies that balance the\ncost of gathering information against the cost of making mistakes in different\nsituations.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2016 20:55:19 GMT"}, {"version": "v2", "created": "Mon, 14 Nov 2016 16:40:58 GMT"}, {"version": "v3", "created": "Thu, 17 Aug 2017 19:51:29 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Denil", "Misha", ""], ["Agrawal", "Pulkit", ""], ["Kulkarni", "Tejas D", ""], ["Erez", "Tom", ""], ["Battaglia", "Peter", ""], ["de Freitas", "Nando", ""]]}, {"id": "1611.01942", "submitter": "Shuochao Yao", "authors": "Shuochao Yao, Shaohan Hu, Yiran Zhao, Aston Zhang, Tarek Abdelzaher", "title": "DeepSense: A Unified Deep Learning Framework for Time-Series Mobile\n  Sensing Data Processing", "comments": "Published in WWW2017. Code available on\n  https://github.com/yscacaca/DeepSense", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile sensing applications usually require time-series inputs from sensors.\nSome applications, such as tracking, can use sensed acceleration and rate of\nrotation to calculate displacement based on physical system models. Other\napplications, such as activity recognition, extract manually designed features\nfrom sensor inputs for classification. Such applications face two challenges.\nOn one hand, on-device sensor measurements are noisy. For many mobile\napplications, it is hard to find a distribution that exactly describes the\nnoise in practice. Unfortunately, calculating target quantities based on\nphysical system and noise models is only as accurate as the noise assumptions.\nSimilarly, in classification applications, although manually designed features\nhave proven to be effective, it is not always straightforward to find the most\nrobust features to accommodate diverse sensor noise patterns and user\nbehaviors. To this end, we propose DeepSense, a deep learning framework that\ndirectly addresses the aforementioned noise and feature customization\nchallenges in a unified manner. DeepSense integrates convolutional and\nrecurrent neural networks to exploit local interactions among similar mobile\nsensors, merge local interactions of different sensory modalities into global\ninteractions, and extract temporal relationships to model signal dynamics.\nDeepSense thus provides a general signal estimation and classification\nframework that accommodates a wide range of applications. We demonstrate the\neffectiveness of DeepSense using three representative and challenging tasks:\ncar tracking with motion sensors, heterogeneous human activity recognition, and\nuser identification with biometric motion analysis. DeepSense significantly\noutperforms the state-of-the-art methods for all three tasks. In addition,\nDeepSense is feasible to implement on smartphones due to its moderate energy\nconsumption and low latency\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 09:10:06 GMT"}, {"version": "v2", "created": "Sun, 2 Jul 2017 22:02:21 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Yao", "Shuochao", ""], ["Hu", "Shaohan", ""], ["Zhao", "Yiran", ""], ["Zhang", "Aston", ""], ["Abdelzaher", "Tarek", ""]]}, {"id": "1611.01967", "submitter": "Pau Rodr\\'iguez L\\'opez", "authors": "Pau Rodr\\'iguez, Jordi Gonz\\`alez, Guillem Cucurull, Josep M. Gonfaus,\n  Xavier Roca", "title": "Regularizing CNNs with Locally Constrained Decorrelations", "comments": "Accepted at ICLR2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization is key for deep learning since it allows training more complex\nmodels while keeping lower levels of overfitting. However, the most prevalent\nregularizations do not leverage all the capacity of the models since they rely\non reducing the effective number of parameters. Feature decorrelation is an\nalternative for using the full capacity of the models but the overfitting\nreduction margins are too narrow given the overhead it introduces. In this\npaper, we show that regularizing negatively correlated features is an obstacle\nfor effective decorrelation and present OrthoReg, a novel regularization\ntechnique that locally enforces feature orthogonality. As a result, imposing\nlocality constraints in feature decorrelation removes interferences between\nnegatively correlated feature weights, allowing the regularizer to reach higher\ndecorrelation bounds, and reducing the overfitting more effectively. In\nparticular, we show that the models regularized with OrthoReg have higher\naccuracy bounds even when batch normalization and dropout are present.\nMoreover, since our regularization is directly performed on the weights, it is\nespecially suitable for fully convolutional neural networks, where the weight\nspace is constant compared to the feature map space. As a result, we are able\nto reduce the overfitting of state-of-the-art CNNs on CIFAR-10, CIFAR-100, and\nSVHN.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 10:15:40 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 08:18:28 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Rodr\u00edguez", "Pau", ""], ["Gonz\u00e0lez", "Jordi", ""], ["Cucurull", "Guillem", ""], ["Gonfaus", "Josep M.", ""], ["Roca", "Xavier", ""]]}, {"id": "1611.02024", "submitter": "Peter O'Connor", "authors": "Peter O'Connor, Max Welling", "title": "Sigma Delta Quantized Networks", "comments": "9 Pages + 1 Reference + 3 Appendix, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks can be obscenely wasteful. When processing video, a\nconvolutional network expends a fixed amount of computation for each frame with\nno regard to the similarity between neighbouring frames. As a result, it ends\nup repeatedly doing very similar computations. To put an end to such waste, we\nintroduce Sigma-Delta networks. With each new input, each layer in this network\nsends a discretized form of its change in activation to the next layer. Thus\nthe amount of computation that the network does scales with the amount of\nchange in the input and layer activations, rather than the size of the network.\nWe introduce an optimization method for converting any pre-trained deep network\ninto an optimally efficient Sigma-Delta network, and show that our algorithm,\nif run on the appropriate hardware, could cut at least an order of magnitude\nfrom the computational cost of processing video data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 12:45:23 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 11:02:54 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["O'Connor", "Peter", ""], ["Welling", "Max", ""]]}, {"id": "1611.02049", "submitter": "Michal Nowicki", "authors": "Micha{\\l} Nowicki and Jan Wietrzykowski", "title": "Low-effort place recognition with WiFi fingerprints using deep learning", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-54042-9_57", "report-no": null, "categories": "cs.RO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using WiFi signals for indoor localization is the main localization modality\nof the existing personal indoor localization systems operating on mobile\ndevices. WiFi fingerprinting is also used for mobile robots, as WiFi signals\nare usually available indoors and can provide rough initial position estimate\nor can be used together with other positioning systems. Currently, the best\nsolutions rely on filtering, manual data analysis, and time-consuming parameter\ntuning to achieve reliable and accurate localization. In this work, we propose\nto use deep neural networks to significantly lower the work-force burden of the\nlocalization system design, while still achieving satisfactory results.\nAssuming the state-of-the-art hierarchical approach, we employ the DNN system\nfor building/floor classification. We show that stacked autoencoders allow to\nefficiently reduce the feature space in order to achieve robust and precise\nclassification. The proposed architecture is verified on the publicly available\nUJIIndoorLoc dataset and the results are compared with other solutions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 13:47:25 GMT"}, {"version": "v2", "created": "Fri, 28 Apr 2017 06:32:25 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Nowicki", "Micha\u0142", ""], ["Wietrzykowski", "Jan", ""]]}, {"id": "1611.02120", "submitter": "Brett Meyer", "authors": "Sean C. Smithson and Guang Yang and Warren J. Gross and Brett H. Meyer", "title": "Neural Networks Designing Neural Networks: Multi-Objective\n  Hyper-Parameter Optimization", "comments": "To appear in ICCAD'16. The authoritative version will appear in the\n  ACM Digital Library", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks have gone through a recent rise in popularity,\nachieving state-of-the-art results in various fields, including image\nclassification, speech recognition, and automated control. Both the performance\nand computational complexity of such models are heavily dependant on the design\nof characteristic hyper-parameters (e.g., number of hidden layers, nodes per\nlayer, or choice of activation functions), which have traditionally been\noptimized manually. With machine learning penetrating low-power mobile and\nembedded areas, the need to optimize not only for performance (accuracy), but\nalso for implementation complexity, becomes paramount. In this work, we present\na multi-objective design space exploration method that reduces the number of\nsolution networks trained and evaluated through response surface modelling.\nGiven spaces which can easily exceed 1020 solutions, manually designing a\nnear-optimal architecture is unlikely as opportunities to reduce network\ncomplexity, while maintaining performance, may be overlooked. This problem is\nexacerbated by the fact that hyper-parameters which perform well on specific\ndatasets may yield sub-par results on others, and must therefore be designed on\na per-application basis. In our work, machine learning is leveraged by training\nan artificial neural network to predict the performance of future candidate\nnetworks. The method is evaluated on the MNIST and CIFAR-10 image datasets,\noptimizing for both recognition accuracy and computational complexity.\nExperimental results demonstrate that the proposed method can closely\napproximate the Pareto-optimal front, while only exploring a small fraction of\nthe design space.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 15:38:39 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Smithson", "Sean C.", ""], ["Yang", "Guang", ""], ["Gross", "Warren J.", ""], ["Meyer", "Brett H.", ""]]}, {"id": "1611.02261", "submitter": "Rasool Fakoor", "authors": "Rasool Fakoor, Abdel-rahman Mohamed, Margaret Mitchell, Sing Bing\n  Kang, Pushmeet Kohli", "title": "Memory-augmented Attention Modelling for Videos", "comments": "Revised version, minor changes, add the link for the source codes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to improve video description generation by modeling\nhigher-order interactions between video frames and described concepts. By\nstoring past visual attention in the video associated to previously generated\nwords, the system is able to decide what to look at and describe in light of\nwhat it has already looked at and described. This enables not only more\neffective local attention, but tractable consideration of the video sequence\nwhile generating each word. Evaluation on the challenging and popular MSVD and\nCharades datasets demonstrates that the proposed architecture outperforms\nprevious video description approaches without requiring external temporal video\nfeatures.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 20:50:08 GMT"}, {"version": "v2", "created": "Mon, 14 Nov 2016 22:39:13 GMT"}, {"version": "v3", "created": "Mon, 13 Feb 2017 02:22:51 GMT"}, {"version": "v4", "created": "Mon, 24 Apr 2017 07:26:01 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Fakoor", "Rasool", ""], ["Mohamed", "Abdel-rahman", ""], ["Mitchell", "Margaret", ""], ["Kang", "Sing Bing", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1611.02272", "submitter": "Alexander Tait", "authors": "Alexander N. Tait, Thomas Ferreira de Lima, Ellen Zhou, Allie X. Wu,\n  Mitchell A. Nahmias, Bhavin J. Shastri, and Paul R. Prucnal", "title": "Neuromorphic Silicon Photonic Networks", "comments": "12 pages, 4 figures, accepted in Scientific Reports", "journal-ref": "Sci.Rep. 7 (2017) 7430", "doi": "10.1038/s41598-017-07754-z", "report-no": null, "categories": "q-bio.NC cs.NE physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photonic systems for high-performance information processing have attracted\nrenewed interest. Neuromorphic silicon photonics has the potential to integrate\nprocessing functions that vastly exceed the capabilities of electronics. We\nreport first observations of a recurrent silicon photonic neural network, in\nwhich connections are configured by microring weight banks. A mathematical\nisomorphism between the silicon photonic circuit and a continuous neural\nnetwork model is demonstrated through dynamical bifurcation analysis.\nExploiting this isomorphism, a simulated 24-node silicon photonic neural\nnetwork is programmed using \"neural compiler\" to solve a differential system\nemulation task. A 294-fold acceleration against a conventional benchmark is\npredicted. We also propose and derive power consumption analysis for\nmodulator-class neurons that, as opposed to laser-class neurons, are compatible\nwith silicon photonic platforms. At increased scale, Neuromorphic silicon\nphotonics could access new regimes of ultrafast information processing for\nradio, control, and scientific computing.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 00:15:59 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 17:35:37 GMT"}, {"version": "v3", "created": "Mon, 12 Jun 2017 15:56:45 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Tait", "Alexander N.", ""], ["de Lima", "Thomas Ferreira", ""], ["Zhou", "Ellen", ""], ["Wu", "Allie X.", ""], ["Nahmias", "Mitchell A.", ""], ["Shastri", "Bhavin J.", ""], ["Prucnal", "Paul R.", ""]]}, {"id": "1611.02320", "submitter": "Juan Maro\\~nas", "authors": "Juan Maro\\~nas Molano, Alberto Albiol Colomer, Roberto Paredes\n  Palacios", "title": "Adversarial Ladder Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of unsupervised data in addition to supervised data in training\ndiscriminative neural networks has improved the performance of this clas-\nsification scheme. However, the best results were achieved with a training\nprocess that is divided in two parts: first an unsupervised pre-training step\nis done for initializing the weights of the network and after these weights are\nrefined with the use of supervised data. On the other hand adversarial noise\nhas improved the results of clas- sical supervised learning. Recently, a new\nneural network topology called Ladder Network, where the key idea is based in\nsome properties of hierar- chichal latent variable models, has been proposed as\na technique to train a neural network using supervised and unsupervised data at\nthe same time with what is called semi-supervised learning. This technique has\nreached state of the art classification. In this work we add adversarial noise\nto the ladder network and get state of the art classification, with several\nimportant conclusions on how adversarial noise can help in addition with new\npossible lines of investi- gation. We also propose an alternative to add\nadversarial noise to unsu- pervised data.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 22:03:43 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 15:22:31 GMT"}, {"version": "v3", "created": "Fri, 27 Apr 2018 08:16:36 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Molano", "Juan Maro\u00f1as", ""], ["Colomer", "Alberto Albiol", ""], ["Palacios", "Roberto Paredes", ""]]}, {"id": "1611.02345", "submitter": "David Balduzzi", "authors": "David Balduzzi, Brian McWilliams, Tony Butler-Yeoman", "title": "Neural Taylor Approximations: Convergence and Exploration in Rectifier\n  Networks", "comments": "ICML 2017, final version", "journal-ref": "PMLR volume 70, 2017", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern convolutional networks, incorporating rectifiers and max-pooling, are\nneither smooth nor convex; standard guarantees therefore do not apply.\nNevertheless, methods from convex optimization such as gradient descent and\nAdam are widely used as building blocks for deep learning algorithms. This\npaper provides the first convergence guarantee applicable to modern convnets,\nwhich furthermore matches a lower bound for convex nonsmooth functions. The key\ntechnical tool is the neural Taylor approximation -- a straightforward\napplication of Taylor expansions to neural networks -- and the associated\nTaylor loss. Experiments on a range of optimizers, layers, and tasks provide\nevidence that the analysis accurately captures the dynamics of neural\noptimization. The second half of the paper applies the Taylor approximation to\nisolate the main difficulty in training rectifier nets -- that gradients are\nshattered -- and investigates the hypothesis that, by exploring the space of\nactivation configurations more thoroughly, adaptive optimizers such as RMSProp\nand Adam are able to converge to better solutions.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 23:47:05 GMT"}, {"version": "v2", "created": "Fri, 24 Feb 2017 02:26:15 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 12:41:26 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Balduzzi", "David", ""], ["McWilliams", "Brian", ""], ["Butler-Yeoman", "Tony", ""]]}, {"id": "1611.02416", "submitter": "Seongsik Park", "authors": "Seongsik Park, Sang-gil Lee, Hyunha Nam, Sungroh Yoon", "title": "An Efficient Approach to Boosting Performance of Deep Spiking Network\n  Training", "comments": "NIPS 2016 - Workshop on Computing with Spikes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays deep learning is dominating the field of machine learning with\nstate-of-the-art performance in various application areas. Recently, spiking\nneural networks (SNNs) have been attracting a great deal of attention, notably\nowning to their power efficiency, which can potentially allow us to implement a\nlow-power deep learning engine suitable for real-time/mobile applications.\nHowever, implementing SNN-based deep learning remains challenging, especially\ngradient-based training of SNNs by error backpropagation. We cannot simply\npropagate errors through SNNs in conventional way because of the property of\nSNNs that process discrete data in the form of a series. Consequently, most of\nthe previous studies employ a workaround technique, which first trains a\nconventional weighted-sum deep neural network and then maps the learning\nweights to the SNN under training, instead of training SNN parameters directly.\nIn order to eliminate this workaround, recently proposed is a new class of SNN\nnamed deep spiking networks (DSNs), which can be trained directly (without a\nmapping from conventional deep networks) by error backpropagation with\nstochastic gradient descent. In this paper, we show that the initialization of\nthe membrane potential on the backward path is an important step in DSN\ntraining, through diverse experiments performed under various conditions.\nFurthermore, we propose a simple and efficient method that can improve DSN\ntraining by controlling the initial membrane potential on the backward path. In\nour experiments, adopting the proposed approach allowed us to boost the\nperformance of DSN training in terms of converging time and accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 07:41:54 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 09:24:09 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Park", "Seongsik", ""], ["Lee", "Sang-gil", ""], ["Nam", "Hyunha", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1611.02512", "submitter": "Wen-Chieh Fang", "authors": "Wen-Chieh Fang and Yi-ting Chiang", "title": "Cognitive Discriminative Mappings for Rapid Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can learn concepts or recognize items from just a handful of examples,\nwhile machines require many more samples to perform the same task. In this\npaper, we build a computational model to investigate the possibility of this\nkind of rapid learning. The proposed method aims to improve the learning task\nof input from sensory memory by leveraging the information retrieved from\nlong-term memory. We present a simple and intuitive technique called cognitive\ndiscriminative mappings (CDM) to explore the cognitive problem. First, CDM\nseparates and clusters the data instances retrieved from long-term memory into\ndistinct classes with a discrimination method in working memory when a sensory\ninput triggers the algorithm. CDM then maps each sensory data instance to be as\nclose as possible to the median point of the data group with the same class.\nThe experimental results demonstrate that the CDM approach is effective for\nlearning the discriminative features of supervised classifications with few\ntraining sensory input instances.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 13:26:32 GMT"}], "update_date": "2016-11-09", "authors_parsed": [["Fang", "Wen-Chieh", ""], ["Chiang", "Yi-ting", ""]]}, {"id": "1611.02554", "submitter": "Lei Yu", "authors": "Lei Yu, Phil Blunsom, Chris Dyer, Edward Grefenstette, Tomas Kocisky", "title": "The Neural Noisy Channel", "comments": "ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate sequence to sequence transduction as a noisy channel decoding\nproblem and use recurrent neural networks to parameterise the source and\nchannel models. Unlike direct models which can suffer from explaining-away\neffects during training, noisy channel models must produce outputs that explain\ntheir inputs, and their component models can be trained with not only paired\ntraining samples but also unpaired samples from the marginal output\ndistribution. Using a latent variable to control how much of the conditioning\nsequence the channel model needs to read in order to generate a subsequent\nsymbol, we obtain a tractable and effective beam search decoder. Experimental\nresults on abstractive sentence summarisation, morphological inflection, and\nmachine translation show that noisy channel models outperform direct models,\nand that they significantly benefit from increased amounts of unpaired output\ndata that direct models cannot easily use.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 15:18:44 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 12:37:12 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Yu", "Lei", ""], ["Blunsom", "Phil", ""], ["Dyer", "Chris", ""], ["Grefenstette", "Edward", ""], ["Kocisky", "Tomas", ""]]}, {"id": "1611.02648", "submitter": "Nat Dilokthanakul", "authors": "Nat Dilokthanakul, Pedro A.M. Mediano, Marta Garnelo, Matthew C.H.\n  Lee, Hugh Salimbeni, Kai Arulkumaran, Murray Shanahan", "title": "Deep Unsupervised Clustering with Gaussian Mixture Variational\n  Autoencoders", "comments": "12 pages, 6 figures, Under review as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a variant of the variational autoencoder model (VAE) with a Gaussian\nmixture as a prior distribution, with the goal of performing unsupervised\nclustering through deep generative models. We observe that the known problem of\nover-regularisation that has been shown to arise in regular VAEs also manifests\nitself in our model and leads to cluster degeneracy. We show that a heuristic\ncalled minimum information constraint that has been shown to mitigate this\neffect in VAEs can also be applied to improve unsupervised clustering\nperformance with our model. Furthermore we analyse the effect of this heuristic\nand provide an intuition of the various processes with the help of\nvisualizations. Finally, we demonstrate the performance of our model on\nsynthetic data, MNIST and SVHN, showing that the obtained clusters are\ndistinct, interpretable and result in achieving competitive performance on\nunsupervised clustering to the state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 18:36:36 GMT"}, {"version": "v2", "created": "Fri, 13 Jan 2017 17:53:10 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Dilokthanakul", "Nat", ""], ["Mediano", "Pedro A. M.", ""], ["Garnelo", "Marta", ""], ["Lee", "Matthew C. H.", ""], ["Salimbeni", "Hugh", ""], ["Arulkumaran", "Kai", ""], ["Shanahan", "Murray", ""]]}, {"id": "1611.02683", "submitter": "Prajit Ramachandran", "authors": "Prajit Ramachandran, Peter J. Liu, Quoc V. Le", "title": "Unsupervised Pretraining for Sequence to Sequence Learning", "comments": "Updated to accepted EMNLP 2017 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a general unsupervised learning method to improve the\naccuracy of sequence to sequence (seq2seq) models. In our method, the weights\nof the encoder and decoder of a seq2seq model are initialized with the\npretrained weights of two language models and then fine-tuned with labeled\ndata. We apply this method to challenging benchmarks in machine translation and\nabstractive summarization and find that it significantly improves the\nsubsequent supervised models. Our main result is that pretraining improves the\ngeneralization of seq2seq models. We achieve state-of-the art results on the\nWMT English$\\rightarrow$German task, surpassing a range of methods using both\nphrase-based machine translation and neural machine translation. Our method\nachieves a significant improvement of 1.3 BLEU from the previous best models on\nboth WMT'14 and WMT'15 English$\\rightarrow$German. We also conduct human\nevaluations on abstractive summarization and find that our method outperforms a\npurely supervised learning baseline in a statistically significant manner.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2016 20:42:26 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 01:57:27 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Ramachandran", "Prajit", ""], ["Liu", "Peter J.", ""], ["Le", "Quoc V.", ""]]}, {"id": "1611.02779", "submitter": "Yan Duan", "authors": "Yan Duan, John Schulman, Xi Chen, Peter L. Bartlett, Ilya Sutskever,\n  Pieter Abbeel", "title": "RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning", "comments": "14 pages. Under review as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (deep RL) has been successful in learning\nsophisticated behaviors automatically; however, the learning process requires a\nhuge number of trials. In contrast, animals can learn new tasks in just a few\ntrials, benefiting from their prior knowledge about the world. This paper seeks\nto bridge this gap. Rather than designing a \"fast\" reinforcement learning\nalgorithm, we propose to represent it as a recurrent neural network (RNN) and\nlearn it from data. In our proposed method, RL$^2$, the algorithm is encoded in\nthe weights of the RNN, which are learned slowly through a general-purpose\n(\"slow\") RL algorithm. The RNN receives all information a typical RL algorithm\nwould receive, including observations, actions, rewards, and termination flags;\nand it retains its state across episodes in a given Markov Decision Process\n(MDP). The activations of the RNN store the state of the \"fast\" RL algorithm on\nthe current (previously unseen) MDP. We evaluate RL$^2$ experimentally on both\nsmall-scale and large-scale problems. On the small-scale side, we train it to\nsolve randomly generated multi-arm bandit problems and finite MDPs. After\nRL$^2$ is trained, its performance on new MDPs is close to human-designed\nalgorithms with optimality guarantees. On the large-scale side, we test RL$^2$\non a vision-based navigation task and show that it scales up to\nhigh-dimensional problems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 00:13:29 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 01:17:36 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Duan", "Yan", ""], ["Schulman", "John", ""], ["Chen", "Xi", ""], ["Bartlett", "Peter L.", ""], ["Sutskever", "Ilya", ""], ["Abbeel", "Pieter", ""]]}, {"id": "1611.02854", "submitter": "Greg Yang", "authors": "Greg Yang, Alexander M. Rush", "title": "Lie-Access Neural Turing Machines", "comments": "Published at ICLR. Rewrite and improvement of arXiv:1602.08671", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  External neural memory structures have recently become a popular tool for\nalgorithmic deep learning (Graves et al. 2014, Weston et al. 2014). These\nmodels generally utilize differentiable versions of traditional discrete\nmemory-access structures (random access, stacks, tapes) to provide the storage\nnecessary for computational tasks. In this work, we argue that these neural\nmemory systems lack specific structure important for relative indexing, and\npropose an alternative model, Lie-access memory, that is explicitly designed\nfor the neural setting. In this paradigm, memory is accessed using a continuous\nhead in a key-space manifold. The head is moved via Lie group actions, such as\nshifts or rotations, generated by a controller, and memory access is performed\nby linear smoothing in key space. We argue that Lie groups provide a natural\ngeneralization of discrete memory structures, such as Turing machines, as they\nprovide inverse and identity operators while maintaining differentiability. To\nexperiment with this approach, we implement a simplified Lie-access neural\nTuring machine (LANTM) with different Lie groups. We find that this approach is\nable to perform well on a range of algorithmic tasks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 08:51:54 GMT"}, {"version": "v2", "created": "Sun, 5 Mar 2017 21:03:22 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Yang", "Greg", ""], ["Rush", "Alexander M.", ""]]}, {"id": "1611.03000", "submitter": "Amirhossein Tavanaei", "authors": "Amirhossein Tavanaei and Anthony S. Maida", "title": "Bio-Inspired Spiking Convolutional Neural Network using Layer-wise\n  Sparse Coding and STDP Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical feature discovery using non-spiking convolutional neural\nnetworks (CNNs) has attracted much recent interest in machine learning and\ncomputer vision. However, it is still not well understood how to create a\nbiologically plausible network of brain-like, spiking neurons with multi-layer,\nunsupervised learning. This paper explores a novel bio-inspired spiking CNN\nthat is trained in a greedy, layer-wise fashion. The proposed network consists\nof a spiking convolutional-pooling layer followed by a feature discovery layer\nextracting independent visual features. Kernels for the convolutional layer are\ntrained using local learning. The learning is implemented using a sparse,\nspiking auto-encoder representing primary visual features. The feature\ndiscovery layer extracts independent features by probabilistic, leaky\nintegrate-and-fire (LIF) neurons that are sparsely active in response to\nstimuli. The layer of the probabilistic, LIF neurons implicitly provides\nlateral inhibitions to extract sparse and independent features. Experimental\nresults show that the convolutional layer is stack-admissible, enabling it to\nsupport a multi-layer learning. The visual features obtained from the proposed\nprobabilistic LIF neurons in the feature discovery layer are utilized for\ntraining a classifier. Classification results contribute to the independent and\ninformative visual features extracted in a hierarchy of convolutional and\nfeature discovery layers. The proposed model is evaluated on the MNIST digit\ndataset using clean and noisy images. The recognition performance for clean\nimages is above 98%. The performance loss for recognizing the noisy images is\nin the range 0.1% to 8.5% depending on noise types and densities. This level of\nperformance loss indicates that the network is robust to additive noise.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 16:25:41 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 16:40:17 GMT"}, {"version": "v3", "created": "Thu, 6 Apr 2017 17:14:05 GMT"}, {"version": "v4", "created": "Sat, 24 Jun 2017 02:20:57 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Tavanaei", "Amirhossein", ""], ["Maida", "Anthony S.", ""]]}, {"id": "1611.03068", "submitter": "Edwin D. de Jong", "authors": "Edwin D. de Jong", "title": "Incremental Sequence Learning", "comments": "Updated version: Clarified the contribution (see abstract, intro, and\n  conclusion); added figures to illustrate the architecture of the network and\n  the difference between training and generation; different selection of\n  experiments in Section 6.4; some textual edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning research over the past years has shown that by increasing the\nscope or difficulty of the learning problem over time, increasingly complex\nlearning problems can be addressed. We study incremental learning in the\ncontext of sequence learning, using generative RNNs in the form of multi-layer\nrecurrent Mixture Density Networks. While the potential of incremental or\ncurriculum learning to enhance learning is known, indiscriminate application of\nthe principle does not necessarily lead to improvement, and it is essential\ntherefore to know which forms of incremental or curriculum learning have a\npositive effect. This research contributes to that aim by comparing three\ninstantiations of incremental or curriculum learning.\n  We introduce Incremental Sequence Learning, a simple incremental approach to\nsequence learning. Incremental Sequence Learning starts out by using only the\nfirst few steps of each sequence as training data. Each time a performance\ncriterion has been reached, the length of the parts of the sequences used for\ntraining is increased.\n  We introduce and make available a novel sequence learning task and data set:\npredicting and classifying MNIST pen stroke sequences. We find that Incremental\nSequence Learning greatly speeds up sequence learning and reaches the best test\nperformance level of regular sequence learning 20 times faster, reduces the\ntest error by 74%, and in general performs more robustly; it displays lower\nvariance and achieves sustained progress after all three comparison methods\nhave stopped improving. The other instantiations of curriculum learning do not\nresult in any noticeable improvement. A trained sequence prediction model is\nalso used in transfer learning to the task of sequence classification, where it\nis found that transfer learning realizes improved classification performance\ncompared to methods that learn to classify from scratch.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 20:12:08 GMT"}, {"version": "v2", "created": "Thu, 1 Dec 2016 21:33:19 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["de Jong", "Edwin D.", ""]]}, {"id": "1611.03130", "submitter": "Lukas Cavigelli", "authors": "Lukas Cavigelli, Dominic Bernath, Michele Magno, Luca Benini", "title": "Computationally Efficient Target Classification in Multispectral Image\n  Data with Deep Neural Networks", "comments": "Presented at SPIE Security + Defence 2016 Proc. SPIE 9997, Target and\n  Background Signatures II", "journal-ref": null, "doi": "10.1117/12.2241383", "report-no": null, "categories": "cs.CV cs.AI cs.NE eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting and classifying targets in video streams from surveillance cameras\nis a cumbersome, error-prone and expensive task. Often, the incurred costs are\nprohibitive for real-time monitoring. This leads to data being stored locally\nor transmitted to a central storage site for post-incident examination. The\nrequired communication links and archiving of the video data are still\nexpensive and this setup excludes preemptive actions to respond to imminent\nthreats. An effective way to overcome these limitations is to build a smart\ncamera that transmits alerts when relevant video sequences are detected. Deep\nneural networks (DNNs) have come to outperform humans in visual classifications\ntasks. The concept of DNNs and Convolutional Networks (ConvNets) can easily be\nextended to make use of higher-dimensional input data such as multispectral\ndata. We explore this opportunity in terms of achievable accuracy and required\ncomputational effort. To analyze the precision of DNNs for scene labeling in an\nurban surveillance scenario we have created a dataset with 8 classes obtained\nin a field experiment. We combine an RGB camera with a 25-channel VIS-NIR\nsnapshot sensor to assess the potential of multispectral image data for target\nclassification. We evaluate several new DNNs, showing that the spectral\ninformation fused together with the RGB frames can be used to improve the\naccuracy of the system or to achieve similar accuracy with a 3x smaller\ncomputation effort. We achieve a very high per-pixel accuracy of 99.1%. Even\nfor scarcely occurring, but particularly interesting classes, such as cars, 75%\nof the pixels are labeled correctly with errors occurring only around the\nborder of the objects. This high accuracy was obtained with a training set of\nonly 30 labeled images, paving the way for fast adaptation to various\napplication scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 23:13:18 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Cavigelli", "Lukas", ""], ["Bernath", "Dominic", ""], ["Magno", "Michele", ""], ["Benini", "Luca", ""]]}, {"id": "1611.03321", "submitter": "Romain Caz\\'e Dr", "authors": "Romain Caz\\'e and Bartozs Tele\\'nczuk and Alain Destexhe", "title": "Computing threshold functions using dendrites", "comments": "5 pages 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neurons, modeled as linear threshold unit (LTU), can in theory compute all\nthresh- old functions. In practice, however, some of these functions require\nsynaptic weights of arbitrary large precision. We show here that dendrites can\nalleviate this requirement. We introduce here the non-Linear Threshold Unit\n(nLTU) that integrates synaptic input sub-linearly within distinct subunits to\ntake into account local saturation in dendrites. We systematically search\nparameter space of the nTLU and TLU to compare them. Firstly, this shows that\nthe nLTU can compute all threshold functions with smaller precision weights\nthan the LTU. Secondly, we show that a nLTU can compute significantly more\nfunctions than a LTU when an input can only make a single synapse. This work\npaves the way for a new generation of network made of nLTU with binary\nsynapses.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 14:47:23 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Caz\u00e9", "Romain", ""], ["Tele\u0144czuk", "Bartozs", ""], ["Destexhe", "Alain", ""]]}, {"id": "1611.03363", "submitter": "Sarah Parisot", "authors": "Sarah Parisot, Jonathan Passerat-Palmbach, Markus D. Schirmer, Boris\n  Gutman", "title": "Proceedings of the Workshop on Brain Analysis using COnnectivity\n  Networks - BACON 2016", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding brain connectivity in a network-theoretic context has shown\nmuch promise in recent years. This type of analysis identifies brain\norganisational principles, bringing a new perspective to neuroscience. At the\nsame time, large public databases of connectomic data are now available.\nHowever, connectome analysis is still an emerging field and there is a crucial\nneed for robust computational methods to fully unravelits potential. This\nworkshop provides a platform to discuss the development of new analytic\ntechniques; methods for evaluating and validating commonly used approaches; as\nwell as the effects of variations in pre-processing steps.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 15:51:42 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 12:21:03 GMT"}, {"version": "v3", "created": "Thu, 24 Nov 2016 17:04:05 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Parisot", "Sarah", ""], ["Passerat-Palmbach", "Jonathan", ""], ["Schirmer", "Markus D.", ""], ["Gutman", "Boris", ""]]}, {"id": "1611.03607", "submitter": "Masaya Inoue", "authors": "Masaya Inoue, Sozo Inoue, Takeshi Nishida", "title": "Deep Recurrent Neural Network for Mobile Human Activity Recognition with\n  High Throughput", "comments": "10 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a method of human activity recognition with high\nthroughput from raw accelerometer data applying a deep recurrent neural network\n(DRNN), and investigate various architectures and its combination to find the\nbest parameter values. The \"high throughput\" refers to short time at a time of\nrecognition. We investigated various parameters and architectures of the DRNN\nby using the training dataset of 432 trials with 6 activity classes from 7\npeople. The maximum recognition rate was 95.42% and 83.43% against the test\ndata of 108 segmented trials each of which has single activity class and 18\nmultiple sequential trials, respectively. Here, the maximum recognition rates\nby traditional methods were 71.65% and 54.97% for each. In addition, the\nefficiency of the found parameters was evaluated by using additional dataset.\nFurther, as for throughput of the recognition per unit time, the constructed\nDRNN was requiring only 1.347 [ms], while the best traditional method required\n11.031 [ms] which includes 11.027 [ms] for feature calculation. These\nadvantages are caused by the compact and small architecture of the constructed\nreal time oriented DRNN.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 08:21:09 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Inoue", "Masaya", ""], ["Inoue", "Sozo", ""], ["Nishida", "Takeshi", ""]]}, {"id": "1611.04023", "submitter": "Gerard Rinkus", "authors": "Gerard J. Rinkus", "title": "Sparsey: Event Recognition via Deep Hierarchical Spare Distributed Codes", "comments": "This is a manuscript form of a paper published in Frontiers in\n  Computational Neuroscience in 2014\n  (http://dx.doi.org/10.3389/fncom.2014.00160). 65 pages, 28 figures, 8 tables", "journal-ref": "Frontiers in Computational Neuroscience, Vol. 8, Article 160\n  (2014)", "doi": "10.3389/fncom.2014.00160", "report-no": null, "categories": "q-bio.NC cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual cortex's hierarchical, multi-level organization is captured in many\nbiologically inspired computational vision models, the general idea being that\nprogressively larger scale, more complex spatiotemporal features are\nrepresented in progressively higher areas. However, most earlier models use\nlocalist representations (codes) in each representational field, which we\nequate with the cortical macrocolumn (mac), at each level. In localism, each\nrepresented feature/event (item) is coded by a single unit. Our model, Sparsey,\nis also hierarchical but crucially, uses sparse distributed coding (SDC) in\nevery mac in all levels. In SDC, each represented item is coded by a small\nsubset of the mac's units. SDCs of different items can overlap and the size of\noverlap between items can represent their similarity. The difference between\nlocalism and SDC is crucial because SDC allows the two essential operations of\nassociative memory, storing a new item and retrieving the best-matching stored\nitem, to be done in fixed time for the life of the model. Since the model's\ncore algorithm, which does both storage and retrieval (inference), makes a\nsingle pass over all macs on each time step, the overall model's\nstorage/retrieval operation is also fixed-time, a criterion we consider\nessential for scalability to huge datasets. A 2010 paper described a\nnonhierarchical version of this model in the context of purely spatial pattern\nprocessing. Here, we elaborate a fully hierarchical model (arbitrary numbers of\nlevels and macs per level), describing novel model principles like progressive\ncritical periods, dynamic modulation of principal cells' activation functions\nbased on a mac-level familiarity measure, representation of multiple\nsimultaneously active hypotheses, a novel method of time warp invariant\nrecognition, and we report results showing learning/recognition of\nspatiotemporal patterns.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 17:35:23 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Rinkus", "Gerard J.", ""]]}, {"id": "1611.04231", "submitter": "Tengyu Ma", "authors": "Moritz Hardt and Tengyu Ma", "title": "Identity Matters in Deep Learning", "comments": "ICLR 2017; fixed minor typos in the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An emerging design principle in deep learning is that each layer of a deep\nartificial neural network should be able to easily express the identity\ntransformation. This idea not only motivated various normalization techniques,\nsuch as \\emph{batch normalization}, but was also key to the immense success of\n\\emph{residual networks}.\n  In this work, we put the principle of \\emph{identity parameterization} on a\nmore solid theoretical footing alongside further empirical progress. We first\ngive a strikingly simple proof that arbitrarily deep linear residual networks\nhave no spurious local optima. The same result for linear feed-forward networks\nin their standard parameterization is substantially more delicate. Second, we\nshow that residual networks with ReLu activations have universal finite-sample\nexpressivity in the sense that the network can represent any function of its\nsample provided that the model has more parameters than the sample size.\n  Directly inspired by our theory, we experiment with a radically simple\nresidual architecture consisting of only residual convolutional layers and ReLu\nactivations, but no batch normalization, dropout, or max pool. Our model\nimproves significantly on previous all-convolutional networks on the CIFAR10,\nCIFAR100, and ImageNet classification benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 02:44:18 GMT"}, {"version": "v2", "created": "Sun, 11 Dec 2016 11:39:00 GMT"}, {"version": "v3", "created": "Fri, 20 Jul 2018 04:38:23 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Hardt", "Moritz", ""], ["Ma", "Tengyu", ""]]}, {"id": "1611.04361", "submitter": "Marek Rei", "authors": "Marek Rei, Gamal K.O. Crichton, Sampo Pyysalo", "title": "Attending to Characters in Neural Sequence Labeling Models", "comments": "Proceedings of COLING 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence labeling architectures use word embeddings for capturing similarity,\nbut suffer when handling previously unseen or rare words. We investigate\ncharacter-level extensions to such models and propose a novel architecture for\ncombining alternative word representations. By using an attention mechanism,\nthe model is able to dynamically decide how much information to use from a\nword- or character-level component. We evaluated different architectures on a\nrange of sequence labeling datasets, and character-level extensions were found\nto improve performance on every benchmark. In addition, the proposed\nattention-based architecture delivered the best results even with a smaller\nnumber of trainable parameters.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 12:36:07 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Rei", "Marek", ""], ["Crichton", "Gamal K. O.", ""], ["Pyysalo", "Sampo", ""]]}, {"id": "1611.04465", "submitter": "Dmitri Strukov B", "authors": "F. Merrikh Bayat, M. Prezioso, B. Chakrabarti, I. Kataeva, and D. B.\n  Strukov", "title": "Advancing Memristive Analog Neuromorphic Networks: Increasing\n  Complexity, and Coping with Imperfect Hardware Components", "comments": "4 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We experimentally demonstrate classification of 4x4 binary images into 4\nclasses, using a 3-layer mixed-signal neuromorphic network (\"MLP perceptron\"),\nbased on two passive 20x20 memristive crossbar arrays, board-integrated with\ndiscrete CMOS components. The network features 10 hidden-layer and 4\noutput-layer analog CMOS neurons and 428 metal-oxide memristors, i.e. is almost\nan order of magnitude more complex than any previously reported functional\nmemristor circuit. Moreover, the inference operation of this classifier is\nperformed entirely in the integrated hardware. To deal with larger crossbar\narrays, we have developed a semi-automatic approach to their forming and\ntesting, and compared several memristor training schemes for coping with\nimperfect behavior of these devices, as well as with variability of analog CMOS\nneurons. The effectiveness of the proposed schemes for defect and variation\ntolerance was verified experimentally using the implemented network and,\nadditionally, by modeling the operation of a larger network, with 300\nhidden-layer neurons, on the MNIST benchmark. Finally, we propose a simple\nmodification of the implemented memristor-based vector-by-matrix multiplier to\nallow its operation in a wider temperature range.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 16:12:51 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Bayat", "F. Merrikh", ""], ["Prezioso", "M.", ""], ["Chakrabarti", "B.", ""], ["Kataeva", "I.", ""], ["Strukov", "D. B.", ""]]}, {"id": "1611.04488", "submitter": "Danica J. Sutherland", "authors": "Danica J. Sutherland, Hsiao-Yu Tung, Heiko Strathmann, Soumyajit De,\n  Aaditya Ramdas, Alex Smola, Arthur Gretton", "title": "Generative Models and Model Criticism via Optimized Maximum Mean\n  Discrepancy", "comments": "Published at ICLR 2017 (public comments:\n  http://openreview.net/forum?id=HJWHIKqgl )", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method to optimize the representation and distinguishability of\nsamples from two probability distributions, by maximizing the estimated power\nof a statistical test based on the maximum mean discrepancy (MMD). This\noptimized MMD is applied to the setting of unsupervised learning by generative\nadversarial networks (GAN), in which a model attempts to generate realistic\nsamples, and a discriminator attempts to tell these apart from data samples. In\nthis context, the MMD may be used in two roles: first, as a discriminator,\neither directly on the samples, or on features of the samples. Second, the MMD\ncan be used to evaluate the performance of a generative model, by testing the\nmodel's samples against a reference data set. In the latter role, the optimized\nMMD is particularly helpful, as it gives an interpretable indication of how the\nmodel and data distributions differ, even in cases where individual model\nsamples are not easily distinguished either by eye or by classifier.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 17:28:27 GMT"}, {"version": "v2", "created": "Tue, 15 Nov 2016 13:07:50 GMT"}, {"version": "v3", "created": "Thu, 17 Nov 2016 20:30:37 GMT"}, {"version": "v4", "created": "Fri, 10 Feb 2017 18:28:49 GMT"}, {"version": "v5", "created": "Thu, 6 Jun 2019 19:54:37 GMT"}, {"version": "v6", "created": "Thu, 14 Jan 2021 06:14:42 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Sutherland", "Danica J.", ""], ["Tung", "Hsiao-Yu", ""], ["Strathmann", "Heiko", ""], ["De", "Soumyajit", ""], ["Ramdas", "Aaditya", ""], ["Smola", "Alex", ""], ["Gretton", "Arthur", ""]]}, {"id": "1611.04500", "submitter": "Siamak Ravanbakhsh", "authors": "Siamak Ravanbakhsh and Jeff Schneider and Barnabas Poczos", "title": "Deep Learning with Sets and Point Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple permutation equivariant layer for deep learning with\nset structure.This type of layer, obtained by parameter-sharing, has a simple\nimplementation and linear-time complexity in the size of each set. We use deep\npermutation-invariant networks to perform point-could classification and\nMNIST-digit summation, where in both cases the output is invariant to\npermutations of the input. In a semi-supervised setting, where the goal is make\npredictions for each instance within a set, we demonstrate the usefulness of\nthis type of layer in set-outlier detection as well as semi-supervised learning\nwith clustering side-information.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 17:55:34 GMT"}, {"version": "v2", "created": "Sat, 26 Nov 2016 22:01:55 GMT"}, {"version": "v3", "created": "Fri, 24 Feb 2017 01:54:59 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Ravanbakhsh", "Siamak", ""], ["Schneider", "Jeff", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1611.04687", "submitter": "Jaekoo Lee", "authors": "Jaekoo Lee, Hyunjae Kim, Jongsun Lee and Sungroh Yoon", "title": "Intrinsic Geometric Information Transfer Learning on Multiple\n  Graph-Structured Datasets", "comments": "AAAI 2017 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs provide a powerful means for representing complex interactions between\nentities. Recently, deep learning approaches are emerging for representing and\nmodeling graph-structured data, although the conventional deep learning methods\n(such as convolutional neural networks and recurrent neural networks) have\nmainly focused on grid-structured inputs (image and audio). Leveraged by the\ncapability of representation learning, deep learning based techniques are\nreporting promising results for graph applications by detecting structural\ncharacteristics of graphs in an automated fashion. In this paper, we attempt to\nadvance deep learning for graph-structured data by incorporating another\ncomponent, transfer learning. By transferring the intrinsic geometric\ninformation learned in the source domain, our approach can help us to construct\na model for a new but related task in the target domain without collecting new\ndata and without training a new model from scratch. We thoroughly test our\napproach with large-scale real corpora and confirm the effectiveness of the\nproposed transfer learning framework for deep learning on graphs. According to\nour experiments, transfer learning is most effective when the source and target\ndomains bear a high level of structural similarity in their graph\nrepresentations.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 03:17:15 GMT"}, {"version": "v2", "created": "Mon, 5 Dec 2016 05:04:35 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Lee", "Jaekoo", ""], ["Kim", "Hyunjae", ""], ["Lee", "Jongsun", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1611.04766", "submitter": "Dario  Izzo", "authors": "Dario Izzo and Francesco Biscani and Alessio Mereta", "title": "Differentiable Genetic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the use of high order automatic differentiation, implemented via\nthe algebra of truncated Taylor polynomials, in genetic programming. Using the\nCartesian Genetic Programming encoding we obtain a high-order Taylor\nrepresentation of the program output that is then used to back-propagate errors\nduring learning. The resulting machine learning framework is called\ndifferentiable Cartesian Genetic Programming (dCGP). In the context of symbolic\nregression, dCGP offers a new approach to the long unsolved problem of constant\nrepresentation in GP expressions. On several problems of increasing complexity\nwe find that dCGP is able to find the exact form of the symbolic expression as\nwell as the constants values. We also demonstrate the use of dCGP to solve a\nlarge class of differential equations and to find prime integrals of dynamical\nsystems, presenting, in both cases, results that confirm the efficacy of our\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 10:01:20 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Izzo", "Dario", ""], ["Biscani", "Francesco", ""], ["Mereta", "Alessio", ""]]}, {"id": "1611.04767", "submitter": "Salvatore Rampone", "authors": "Salvatore Rampone, Alessio Valente", "title": "Prediction of Seasonal Temperature Using Soft Computing Techniques:\n  Application in Benevento (Southern Italy) Area", "comments": null, "journal-ref": "Journal of Ambient Intelligence and Humanized Computing (2016)", "doi": "10.1007/s12652-016-0403-2", "report-no": null, "categories": "cs.NE physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work two soft computing methods, Artificial Neural Networks and\nGenetic Programming, are proposed in order to forecast the mean temperature\nthat will occur in future seasons. The area in which the soft computing\ntechniques were applied is that of the surroundings of the town of Benevento,\nin the south of Italy, having geographic coordinates (lat. 41{\\deg}07'50\"N;\nlong.14{\\deg}47'13\"E). This area is not affected by maritime influences as well\nas by winds coming from the west. The methods are fed by data recorded in the\nmeteorological stations of Benevento and Castelvenere, located in the hilly\narea, which characterizes the territory surrounding this city, at 144 m a.s.l.\nBoth the applied methods show low error rates, while the Genetic Programming\noffers an explicit rule representation (a formula) explaining the prevision.\n  Keywords Seasonal Temperature Forecasting; Soft Computing; Artificial Neural\nNetworks; Genetic Programming; Southern Italy.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 10:03:37 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Rampone", "Salvatore", ""], ["Valente", "Alessio", ""]]}, {"id": "1611.04783", "submitter": "Sofia Ira Ktena", "authors": "Sofia Ira Ktena, Sarah Parisot, Jonathan Passerat-Palmbach, Daniel\n  Rueckert", "title": "Comparison of Brain Networks with Unknown Correspondences", "comments": "Presented at The MICCAI-BACON 16 Workshop\n  (https://arxiv.org/abs/1611.03363)", "journal-ref": null, "doi": null, "report-no": "BACON/2016/03", "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph theory has drawn a lot of attention in the field of Neuroscience during\nthe last decade, mainly due to the abundance of tools that it provides to\nexplore the interactions of elements in a complex network like the brain. The\nlocal and global organization of a brain network can shed light on mechanisms\nof complex cognitive functions, while disruptions within the network can be\nlinked to neurodevelopmental disorders. In this effort, the construction of a\nrepresentative brain network for each individual is critical for further\nanalysis. Additionally, graph comparison is an essential step for inference and\nclassification analyses on brain graphs. In this work we explore a method based\non graph edit distance for evaluating graph similarity, when correspondences\nbetween network elements are unknown due to different underlying subdivisions\nof the brain. We test this method on 30 unrelated subjects as well as 40 twin\npairs and show that this method can accurately reflect the higher similarity\nbetween two related networks compared to unrelated ones, while identifying node\ncorrespondences.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 10:51:15 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Ktena", "Sofia Ira", ""], ["Parisot", "Sarah", ""], ["Passerat-Palmbach", "Jonathan", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1611.05141", "submitter": "Eric Hunsberger", "authors": "Eric Hunsberger, Chris Eliasmith", "title": "Training Spiking Deep Networks for Neuromorphic Hardware", "comments": "10 pages, 3 figures, 4 tables; the \"methods\" section of this article\n  draws heavily on arXiv:1510.08829", "journal-ref": null, "doi": "10.13140/RG.2.2.10967.06566", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method to train spiking deep networks that can be run using\nleaky integrate-and-fire (LIF) neurons, achieving state-of-the-art results for\nspiking LIF networks on five datasets, including the large ImageNet ILSVRC-2012\nbenchmark. Our method for transforming deep artificial neural networks into\nspiking networks is scalable and works with a wide range of neural\nnonlinearities. We achieve these results by softening the neural response\nfunction, such that its derivative remains bounded, and by training the network\nwith noise to provide robustness against the variability introduced by spikes.\nOur analysis shows that implementations of these networks on neuromorphic\nhardware will be many times more power-efficient than the equivalent\nnon-spiking networks on traditional hardware.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 04:32:22 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Hunsberger", "Eric", ""], ["Eliasmith", "Chris", ""]]}, {"id": "1611.05397", "submitter": "Max Jaderberg", "authors": "Max Jaderberg, Volodymyr Mnih, Wojciech Marian Czarnecki, Tom Schaul,\n  Joel Z Leibo, David Silver, Koray Kavukcuoglu", "title": "Reinforcement Learning with Unsupervised Auxiliary Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning agents have achieved state-of-the-art results by\ndirectly maximising cumulative reward. However, environments contain a much\nwider variety of possible training signals. In this paper, we introduce an\nagent that also maximises many other pseudo-reward functions simultaneously by\nreinforcement learning. All of these tasks share a common representation that,\nlike unsupervised learning, continues to develop in the absence of extrinsic\nrewards. We also introduce a novel mechanism for focusing this representation\nupon extrinsic rewards, so that learning can rapidly adapt to the most relevant\naspects of the actual task. Our agent significantly outperforms the previous\nstate-of-the-art on Atari, averaging 880\\% expert human performance, and a\nchallenging suite of first-person, three-dimensional \\emph{Labyrinth} tasks\nleading to a mean speedup in learning of 10$\\times$ and averaging 87\\% expert\nhuman performance on Labyrinth.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 18:21:29 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Jaderberg", "Max", ""], ["Mnih", "Volodymyr", ""], ["Czarnecki", "Wojciech Marian", ""], ["Schaul", "Tom", ""], ["Leibo", "Joel Z", ""], ["Silver", "David", ""], ["Kavukcuoglu", "Koray", ""]]}, {"id": "1611.05552", "submitter": "Jason Kuen", "authors": "Jason Kuen, Xiangfei Kong, Gang Wang, Yap-Peng Tan", "title": "DelugeNets: Deep Networks with Efficient and Flexible Cross-layer\n  Information Inflows", "comments": "Code: https://github.com/xternalz/DelugeNets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deluge Networks (DelugeNets) are deep neural networks which efficiently\nfacilitate massive cross-layer information inflows from preceding layers to\nsucceeding layers. The connections between layers in DelugeNets are established\nthrough cross-layer depthwise convolutional layers with learnable filters,\nacting as a flexible yet efficient selection mechanism. DelugeNets can\npropagate information across many layers with greater flexibility and utilize\nnetwork parameters more effectively compared to ResNets, whilst being more\nefficient than DenseNets. Remarkably, a DelugeNet model with just model\ncomplexity of 4.31 GigaFLOPs and 20.2M network parameters, achieve\nclassification errors of 3.76% and 19.02% on CIFAR-10 and CIFAR-100 dataset\nrespectively. Moreover, DelugeNet-122 performs competitively to ResNet-200 on\nImageNet dataset, despite costing merely half of the computations needed by the\nlatter.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 03:45:48 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2016 07:41:33 GMT"}, {"version": "v3", "created": "Wed, 28 Dec 2016 02:08:45 GMT"}, {"version": "v4", "created": "Fri, 30 Dec 2016 04:56:02 GMT"}, {"version": "v5", "created": "Wed, 23 Aug 2017 14:09:55 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Kuen", "Jason", ""], ["Kong", "Xiangfei", ""], ["Wang", "Gang", ""], ["Tan", "Yap-Peng", ""]]}, {"id": "1611.05827", "submitter": "Hao Shen", "authors": "Hao Shen", "title": "Towards a Mathematical Understanding of the Difficulty in Learning with\n  Feedforward Neural Networks", "comments": "22 pages, 1 figure, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks for solving machine learning problems is one\ngreat challenge in the field, mainly due to its associated optimisation problem\nbeing highly non-convex. Recent developments have suggested that many training\nalgorithms do not suffer from undesired local minima under certain scenario,\nand consequently led to great efforts in pursuing mathematical explanations for\nsuch observations. This work provides an alternative mathematical understanding\nof the challenge from a smooth optimisation perspective. By assuming exact\nlearning of finite samples, sufficient conditions are identified via a critical\npoint analysis to ensure any local minimum to be globally minimal as well.\nFurthermore, a state of the art algorithm, known as the Generalised\nGauss-Newton (GGN) algorithm, is rigorously revisited as an approximate\nNewton's algorithm, which shares the property of being locally quadratically\nconvergent to a global minimum under the condition of exact learning.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 19:29:27 GMT"}, {"version": "v2", "created": "Sun, 2 Apr 2017 21:49:39 GMT"}, {"version": "v3", "created": "Tue, 21 Nov 2017 22:11:13 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Shen", "Hao", ""]]}, {"id": "1611.06086", "submitter": "Timothy Ganesan PhD", "authors": "T. Ganesan, I. Elamvazuthi and P.Vasant", "title": "Swarm Intelligence for Multiobjective Optimization of Extraction Process", "comments": null, "journal-ref": "Handbook of Research on Modern Optimization Algorithms and\n  Applications in Engineering and Economics, (2016), IGI Global, pp 516 - 544", "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi objective (MO) optimization is an emerging field which is increasingly\nbeing implemented in many industries globally. In this work, the MO\noptimization of the extraction process of bioactive compounds from the Gardenia\nJasminoides Ellis fruit was solved. Three swarm-based algorithms have been\napplied in conjunction with normal-boundary intersection (NBI) method to solve\nthis MO problem. The gravitational search algorithm (GSA) and the particle\nswarm optimization (PSO) technique were implemented in this work. In addition,\na novel Hopfield-enhanced particle swarm optimization was developed and applied\nto the extraction problem. By measuring the levels of dominance, the optimality\nof the approximate Pareto frontiers produced by all the algorithms were gauged\nand compared. Besides, by measuring the levels of convergence of the frontier,\nsome understanding regarding the structure of the objective space in terms of\nits relation to the level of frontier dominance is uncovered. Detail\ncomparative studies were conducted on all the algorithms employed and developed\nin this work.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 04:18:19 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Ganesan", "T.", ""], ["Elamvazuthi", "I.", ""], ["Vasant", "P.", ""]]}, {"id": "1611.06148", "submitter": "Yotaro Kubo", "authors": "Yotaro Kubo, George Tucker, Simon Wiesler", "title": "Compacting Neural Network Classifiers via Dropout Training", "comments": "Submitted to AISTATS 2017 (Short-version is accepted to NIPS Workshop\n  on Efficient Methods for Deep Neural Networks)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce dropout compaction, a novel method for training feed-forward\nneural networks which realizes the performance gains of training a large model\nwith dropout regularization, yet extracts a compact neural network for run-time\nefficiency. In the proposed method, we introduce a sparsity-inducing prior on\nthe per unit dropout retention probability so that the optimizer can\neffectively prune hidden units during training. By changing the prior\nhyperparameters, we can control the size of the resulting network. We performed\na systematic comparison of dropout compaction and competing methods on several\nreal-world speech recognition tasks and found that dropout compaction achieved\ncomparable accuracy with fewer than 50% of the hidden units, translating to a\n2.5x speedup in run-time.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 16:20:41 GMT"}, {"version": "v2", "created": "Wed, 24 May 2017 12:26:43 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Kubo", "Yotaro", ""], ["Tucker", "George", ""], ["Wiesler", "Simon", ""]]}, {"id": "1611.06197", "submitter": "Daniel Moyer", "authors": "Daniel Moyer, Boris A. Gutman, Joshua Faskowitz, Neda Jahanshad, Paul\n  M. Thompson", "title": "An Empirical Study of Continuous Connectivity Degree Sequence\n  Equivalents", "comments": "Presented at The MICCAI-BACON 16 Workshop\n  (https://arxiv.org/abs/1611.03363)", "journal-ref": null, "doi": null, "report-no": "BACON/2016/04", "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present work we demonstrate the use of a parcellation free\nconnectivity model based on Poisson point processes. This model produces for\neach subject a continuous bivariate intensity function that represents for\nevery possible pair of points the relative rate at which we observe tracts\nterminating at those points. We fit this model to explore degree sequence\nequivalents for spatial continuum graphs, and to investigate the local\ndifferences between estimated intensity functions for two different\ntractography methods. This is a companion paper to Moyer et al. (2016), where\nthe model was originally defined.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 18:53:45 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Moyer", "Daniel", ""], ["Gutman", "Boris A.", ""], ["Faskowitz", "Joshua", ""], ["Jahanshad", "Neda", ""], ["Thompson", "Paul M.", ""]]}, {"id": "1611.06204", "submitter": "Volkan Cirik", "authors": "Volkan Cirik, Eduard Hovy, Louis-Philippe Morency", "title": "Visualizing and Understanding Curriculum Learning for Long Short-Term\n  Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Curriculum Learning emphasizes the order of training instances in a\ncomputational learning setup. The core hypothesis is that simpler instances\nshould be learned early as building blocks to learn more complex ones. Despite\nits usefulness, it is still unknown how exactly the internal representation of\nmodels are affected by curriculum learning. In this paper, we study the effect\nof curriculum learning on Long Short-Term Memory (LSTM) networks, which have\nshown strong competency in many Natural Language Processing (NLP) problems. Our\nexperiments on sentiment analysis task and a synthetic task similar to sequence\nprediction tasks in NLP show that curriculum learning has a positive effect on\nthe LSTM's internal states by biasing the model towards building constructive\nrepresentations i.e. the internal representation at the previous timesteps are\nused as building blocks for the final prediction. We also find that smaller\nmodels significantly improves when they are trained with curriculum learning.\nLastly, we show that curriculum learning helps more when the amount of training\ndata is limited.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 19:38:59 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Cirik", "Volkan", ""], ["Hovy", "Eduard", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1611.06211", "submitter": "Mohammad Babaeizadeh", "authors": "Mohammad Babaeizadeh, Paris Smaragdis, Roy H. Campbell", "title": "NoiseOut: A Simple Way to Prune Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are usually over-parameterized with significant redundancy in\nthe number of required neurons which results in unnecessary computation and\nmemory usage at inference time. One common approach to address this issue is to\nprune these big networks by removing extra neurons and parameters while\nmaintaining the accuracy. In this paper, we propose NoiseOut, a fully automated\npruning algorithm based on the correlation between activations of neurons in\nthe hidden layers. We prove that adding additional output neurons with entirely\nrandom targets results into a higher correlation between neurons which makes\npruning by NoiseOut even more efficient. Finally, we test our method on various\nnetworks and datasets. These experiments exhibit high pruning rates while\nmaintaining the accuracy of the original network.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 19:55:29 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Babaeizadeh", "Mohammad", ""], ["Smaragdis", "Paris", ""], ["Campbell", "Roy H.", ""]]}, {"id": "1611.06216", "submitter": "Iulian Vlad Serban", "authors": "Iulian Vlad Serban, Ryan Lowe, Laurent Charlin, Joelle Pineau", "title": "Generative Deep Neural Networks for Dialogue: A Short Review", "comments": "6 pages, 1 figure, 3 tables; NIPS 2016 workshop on Learning Methods\n  for Dialogue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers have recently started investigating deep neural networks for\ndialogue applications. In particular, generative sequence-to-sequence (Seq2Seq)\nmodels have shown promising results for unstructured tasks, such as word-level\ndialogue response generation. The hope is that such models will be able to\nleverage massive amounts of data to learn meaningful natural language\nrepresentations and response generation strategies, while requiring a minimum\namount of domain knowledge and hand-crafting. An important challenge is to\ndevelop models that can effectively incorporate dialogue context and generate\nmeaningful and diverse responses. In support of this goal, we review recently\nproposed models based on generative encoder-decoder neural network\narchitectures, and show that these models have better ability to incorporate\nlong-term dialogue history, to model uncertainty and ambiguity in dialogue, and\nto generate responses with high-level compositional structure.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 20:11:51 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Serban", "Iulian Vlad", ""], ["Lowe", "Ryan", ""], ["Charlin", "Laurent", ""], ["Pineau", "Joelle", ""]]}, {"id": "1611.06245", "submitter": "Anders S{\\o}gaard Anders S{\\o}gaard", "authors": "Anders S{\\o}gaard", "title": "Spikes as regularizers", "comments": "Computing with Spikes at NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a confidence-based single-layer feed-forward learning algorithm\nSPIRAL (Spike Regularized Adaptive Learning) relying on an encoding of\nactivation spikes. We adaptively update a weight vector relying on confidence\nestimates and activation offsets relative to previous activity. We regularize\nupdates proportionally to item-level confidence and weight-specific support,\nloosely inspired by the observation from neurophysiology that high spike rates\nare sometimes accompanied by low temporal precision. Our experiments suggest\nthat the new learning algorithm SPIRAL is more robust and less prone to\noverfitting than both the averaged perceptron and AROW.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 21:09:16 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["S\u00f8gaard", "Anders", ""]]}, {"id": "1611.06310", "submitter": "Razvan Pascanu", "authors": "Grzegorz Swirszcz, Wojciech Marian Czarnecki and Razvan Pascanu", "title": "Local minima in training of neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a lot of recent interest in trying to characterize the error\nsurface of deep models. This stems from a long standing question. Given that\ndeep networks are highly nonlinear systems optimized by local gradient methods,\nwhy do they not seem to be affected by bad local minima? It is widely believed\nthat training of deep models using gradient methods works so well because the\nerror surface either has no local minima, or if they exist they need to be\nclose in value to the global minimum. It is known that such results hold under\nvery strong assumptions which are not satisfied by real models. In this paper\nwe present examples showing that for such theorem to be true additional\nassumptions on the data, initialization schemes and/or the model classes have\nto be made. We look at the particular case of finite size datasets. We\ndemonstrate that in this scenario one can construct counter-examples (datasets\nor initialization schemes) when the network does become susceptible to bad\nlocal minima over the weight space.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 05:49:22 GMT"}, {"version": "v2", "created": "Fri, 17 Feb 2017 14:51:54 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Swirszcz", "Grzegorz", ""], ["Czarnecki", "Wojciech Marian", ""], ["Pascanu", "Razvan", ""]]}, {"id": "1611.06321", "submitter": "Jose M. Alvarez", "authors": "Jose M Alvarez and Mathieu Salzmann", "title": "Learning the Number of Neurons in Deep Networks", "comments": "NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the number of layers and of neurons in each layer of a deep network\nare typically set manually. While very deep and wide networks have proven\neffective in general, they come at a high memory and computation cost, thus\nmaking them impractical for constrained platforms. These networks, however, are\nknown to have many redundant parameters, and could thus, in principle, be\nreplaced by more compact architectures. In this paper, we introduce an approach\nto automatically determining the number of neurons in each layer of a deep\nnetwork during learning. To this end, we propose to make use of structured\nsparsity during learning. More precisely, we use a group sparsity regularizer\non the parameters of the network, where each group is defined to act on a\nsingle neuron. Starting from an overcomplete network, we show that our approach\ncan reduce the number of parameters by up to 80\\% while retaining or even\nimproving the network accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 07:18:17 GMT"}, {"version": "v2", "created": "Fri, 13 Jan 2017 05:21:29 GMT"}, {"version": "v3", "created": "Thu, 11 Oct 2018 07:18:09 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Alvarez", "Jose M", ""], ["Salzmann", "Mathieu", ""]]}, {"id": "1611.06342", "submitter": "Sungho Shin", "authors": "Sungho Shin, Kyuyeon Hwang, and Wonyong Sung", "title": "Quantized neural network design under weight capacity constraint", "comments": "This paper is accepted at NIPS 2016 workshop on Efficient Methods for\n  Deep Neural Networks (EMDNN). arXiv admin note: text overlap with\n  arXiv:1511.06488", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of deep neural network algorithms for hardware implementation\ncan be lowered either by scaling the number of units or reducing the\nword-length of weights. Both approaches, however, can accompany the performance\ndegradation although many types of research are conducted to relieve this\nproblem. Thus, it is an important question which one, between the network size\nscaling and the weight quantization, is more effective for hardware\noptimization. For this study, the performances of fully-connected deep neural\nnetworks (FCDNNs) and convolutional neural networks (CNNs) are evaluated while\nchanging the network complexity and the word-length of weights. Based on these\nexperiments, we present the effective compression ratio (ECR) to guide the\ntrade-off between the network size and the precision of weights when the\nhardware resource is limited.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 11:21:25 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Shin", "Sungho", ""], ["Hwang", "Kyuyeon", ""], ["Sung", "Wonyong", ""]]}, {"id": "1611.06453", "submitter": "Haichen Shen", "authors": "Haichen Shen, Seungyeop Han, Matthai Philipose, Arvind Krishnamurthy", "title": "Fast Video Classification via Adaptive Cascading of Deep Models", "comments": "Accepted at IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances have enabled \"oracle\" classifiers that can classify across\nmany classes and input distributions with high accuracy without retraining.\nHowever, these classifiers are relatively heavyweight, so that applying them to\nclassify video is costly. We show that day-to-day video exhibits highly skewed\nclass distributions over the short term, and that these distributions can be\nclassified by much simpler models. We formulate the problem of detecting the\nshort-term skews online and exploiting models based on it as a new sequential\ndecision making problem dubbed the Online Bandit Problem, and present a new\nalgorithm to solve it. When applied to recognizing faces in TV shows and\nmovies, we realize end-to-end classification speedups of 2.4-7.8x/2.6-11.2x (on\nGPU/CPU) relative to a state-of-the-art convolutional neural network, at\ncompetitive accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 00:21:32 GMT"}, {"version": "v2", "created": "Sun, 2 Jul 2017 02:17:00 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Shen", "Haichen", ""], ["Han", "Seungyeop", ""], ["Philipose", "Matthai", ""], ["Krishnamurthy", "Arvind", ""]]}, {"id": "1611.06455", "submitter": "Zhiguang Wang", "authors": "Zhiguang Wang, Weizhong Yan, Tim Oates", "title": "Time Series Classification from Scratch with Deep Neural Networks: A\n  Strong Baseline", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple but strong baseline for time series classification from\nscratch with deep neural networks. Our proposed baseline models are pure\nend-to-end without any heavy preprocessing on the raw data or feature crafting.\nThe proposed Fully Convolutional Network (FCN) achieves premium performance to\nother state-of-the-art approaches and our exploration of the very deep neural\nnetworks with the ResNet structure is also competitive. The global average\npooling in our convolutional model enables the exploitation of the Class\nActivation Map (CAM) to find out the contributing region in the raw data for\nthe specific labels. Our models provides a simple choice for the real world\napplication and a good starting point for the future research. An overall\nanalysis is provided to discuss the generalization capability of our models,\nlearned features, network structures and the classification semantics.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 00:34:09 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 02:32:09 GMT"}, {"version": "v3", "created": "Wed, 30 Nov 2016 06:39:49 GMT"}, {"version": "v4", "created": "Wed, 14 Dec 2016 06:58:08 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Wang", "Zhiguang", ""], ["Yan", "Weizhong", ""], ["Oates", "Tim", ""]]}, {"id": "1611.06539", "submitter": "Sebastian Vogel", "authors": "Sebastian Vogel, Christoph Schorn, Andre Guntoro, Gerd Ascheid", "title": "Efficient Stochastic Inference of Bitwise Deep Neural Networks", "comments": "6 pages, 3 figures, Workshop on Efficient Methods for Deep Neural\n  Networks at Neural Information Processing Systems Conference 2016, NIPS 2016,\n  EMDNN 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently published methods enable training of bitwise neural networks which\nallow reduced representation of down to a single bit per weight. We present a\nmethod that exploits ensemble decisions based on multiple stochastically\nsampled network models to increase performance figures of bitwise neural\nnetworks in terms of classification accuracy at inference. Our experiments with\nthe CIFAR-10 and GTSRB datasets show that the performance of such network\nensembles surpasses the performance of the high-precision base model. With this\ntechnique we achieve 5.81% best classification error on CIFAR-10 test set using\nbitwise networks. Concerning inference on embedded systems we evaluate these\nbitwise networks using a hardware efficient stochastic rounding procedure. Our\nwork contributes to efficient embedded bitwise neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 16:05:07 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Vogel", "Sebastian", ""], ["Schorn", "Christoph", ""], ["Guntoro", "Andre", ""], ["Ascheid", "Gerd", ""]]}, {"id": "1611.06565", "submitter": "David Budden", "authors": "David Budden, Alexander Matveev, Shibani Santurkar, Shraman Ray\n  Chaudhuri and Nir Shavit", "title": "Deep Tensor Convolution on Multicores", "comments": "11 pages, 4 figures, 1 supplementary doc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (ConvNets) of 3-dimensional kernels allow\njoint modeling of spatiotemporal features. These networks have improved\nperformance of video and volumetric image analysis, but have been limited in\nsize due to the low memory ceiling of GPU hardware. Existing CPU\nimplementations overcome this constraint but are impractically slow. Here we\nextend and optimize the faster Winograd-class of convolutional algorithms to\nthe $N$-dimensional case and specifically for CPU hardware. First, we remove\nthe need to manually hand-craft algorithms by exploiting the relaxed\nconstraints and cheap sparse access of CPU memory. Second, we maximize CPU\nutilization and multicore scalability by transforming data matrices to be\ncache-aware, integer multiples of AVX vector widths. Treating 2-dimensional\nConvNets as a special (and the least beneficial) case of our approach, we\ndemonstrate a 5 to 25-fold improvement in throughput compared to previous\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2016 18:41:48 GMT"}, {"version": "v2", "created": "Sat, 28 Jan 2017 15:01:13 GMT"}, {"version": "v3", "created": "Sun, 11 Jun 2017 15:29:16 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Budden", "David", ""], ["Matveev", "Alexander", ""], ["Santurkar", "Shibani", ""], ["Chaudhuri", "Shraman Ray", ""], ["Shavit", "Nir", ""]]}, {"id": "1611.06791", "submitter": "Suraj Srinivas", "authors": "Suraj Srinivas, R. Venkatesh Babu", "title": "Generalized Dropout", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks often require good regularizers to generalize well.\nDropout is one such regularizer that is widely used among Deep Learning\npractitioners. Recent work has shown that Dropout can also be viewed as\nperforming Approximate Bayesian Inference over the network parameters. In this\nwork, we generalize this notion and introduce a rich family of regularizers\nwhich we call Generalized Dropout. One set of methods in this family, called\nDropout++, is a version of Dropout with trainable parameters. Classical Dropout\nemerges as a special case of this method. Another member of this family selects\nthe width of neural network layers. Experiments show that these methods help in\nimproving generalization performance over Dropout.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 14:06:48 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Srinivas", "Suraj", ""], ["Babu", "R. Venkatesh", ""]]}, {"id": "1611.06937", "submitter": "Jonathan Suen", "authors": "Jonathan Y. Suen and Saket Navlakha", "title": "Using inspiration from synaptic plasticity rules to optimize traffic\n  flow in distributed engineered networks", "comments": "43 pages, 5 Figures. Submitted to Neural Computation", "journal-ref": "Neural Comput. 29(5) (2017) 1204-1228", "doi": "10.1162/NECO_a_00945", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controlling the flow and routing of data is a fundamental problem in many\ndistributed networks, including transportation systems, integrated circuits,\nand the Internet. In the brain, synaptic plasticity rules have been discovered\nthat regulate network activity in response to environmental inputs, which\nenable circuits to be stable yet flexible. Here, we develop a new\nneuro-inspired model for network flow control that only depends on modifying\nedge weights in an activity-dependent manner. We show how two fundamental\nplasticity rules (long-term potentiation and long-term depression) can be cast\nas a distributed gradient descent algorithm for regulating traffic flow in\nengineered networks. We then characterize, both via simulation and\nanalytically, how different forms of edge-weight update rules affect network\nrouting efficiency and robustness. We find a close correspondence between\ncertain classes of synaptic weight update rules derived experimentally in the\nbrain and rules commonly used in engineering, suggesting common principles to\nboth.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 18:38:17 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Suen", "Jonathan Y.", ""], ["Navlakha", "Saket", ""]]}, {"id": "1611.06945", "submitter": "Matthew Moskewicz", "authors": "Matthew W. Moskewicz and Ali Jannesari and Kurt Keutzer", "title": "A Metaprogramming and Autotuning Framework for Deploying Deep Learning\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep neural networks (DNNs), have yielded strong results on\na wide range of applications. Graphics Processing Units (GPUs) have been one\nkey enabling factor leading to the current popularity of DNNs. However, despite\nincreasing hardware flexibility and software programming toolchain maturity,\nhigh efficiency GPU programming remains difficult: it suffers from high\ncomplexity, low productivity, and low portability. GPU vendors such as NVIDIA\nhave spent enormous effort to write special-purpose DNN libraries. However, on\nother hardware targets, especially mobile GPUs, such vendor libraries are not\ngenerally available. Thus, the development of portable, open, high-performance,\nenergy-efficient GPU code for DNN operations would enable broader deployment of\nDNN-based algorithms. Toward this end, this work presents a framework to enable\nproductive, high-efficiency GPU programming for DNN computations across\nhardware platforms and programming models. In particular, the framework\nprovides specific support for metaprogramming, autotuning, and DNN-tailored\ndata types. Using our framework, we explore implementing DNN operations on\nthree different hardware targets: NVIDIA, AMD, and Qualcomm GPUs. On NVIDIA\nGPUs, we show both portability between OpenCL and CUDA as well competitive\nperformance compared to the vendor library. On Qualcomm GPUs, we show that our\nframework enables productive development of target-specific optimizations, and\nachieves reasonable absolute performance. Finally, On AMD GPUs, we show initial\nresults that indicate our framework can yield reasonable performance on a new\nplatform with minimal effort.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 18:49:23 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Moskewicz", "Matthew W.", ""], ["Jannesari", "Ali", ""], ["Keutzer", "Kurt", ""]]}, {"id": "1611.06981", "submitter": "Nathan Cahill", "authors": "Nathan D. Cahill, Harmeet Singh, Chao Zhang, Daryl A. Corcoran, Alison\n  M. Prengaman, Paul S. Wenger, John F. Hamilton, Peter Bajorski, and Andrew M.\n  Michael", "title": "Multiple-View Spectral Clustering for Group-wise Functional Community\n  Detection", "comments": "Presented at The MICCAI-BACON 16 Workshop\n  (https://arxiv.org/abs/1611.03363)", "journal-ref": null, "doi": null, "report-no": "BACON/2016/01", "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional connectivity analysis yields powerful insights into our\nunderstanding of the human brain. Group-wise functional community detection\naims to partition the brain into clusters, or communities, in which functional\nactivity is inter-regionally correlated in a common manner across a group of\nsubjects. In this article, we show how to use multiple-view spectral clustering\nto perform group-wise functional community detection. In a series of\nexperiments on 291 subjects from the Human Connectome Project, we compare three\nversions of multiple-view spectral clustering: MVSC (uniform weights), MVSCW\n(weights based on subject-specific embedding quality), and AASC (weights\noptimized along with the embedding) with the competing technique of Joint\nDiagonalization of Laplacians (JDL). Results show that multiple-view spectral\nclustering not only yields group-wise functional communities that are more\nconsistent than JDL when using randomly selected subsets of individual brains,\nbut it is several orders of magnitude faster than JDL.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 19:57:48 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Cahill", "Nathan D.", ""], ["Singh", "Harmeet", ""], ["Zhang", "Chao", ""], ["Corcoran", "Daryl A.", ""], ["Prengaman", "Alison M.", ""], ["Wenger", "Paul S.", ""], ["Hamilton", "John F.", ""], ["Bajorski", "Peter", ""], ["Michael", "Andrew M.", ""]]}, {"id": "1611.07065", "submitter": "Joachim Ott", "authors": "Joachim Ott, Zhouhan Lin, Ying Zhang, Shih-Chii Liu, Yoshua Bengio", "title": "Recurrent Neural Networks With Limited Numerical Precision", "comments": "NIPS 2016 EMDNN Workshop paper, condensed version of arXiv:1608.06902", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) produce state-of-art performance on many\nmachine learning tasks but their demand on resources in terms of memory and\ncomputational power are often high. Therefore, there is a great interest in\noptimizing the computations performed with these models especially when\nconsidering development of specialized low-power hardware for deep networks.\nOne way of reducing the computational needs is to limit the numerical precision\nof the network weights and biases, and this will be addressed for the case of\nRNNs. We present results from the use of different stochastic and deterministic\nreduced precision training methods applied to two major RNN types, which are\nthen tested on three datasets. The results show that the stochastic and\ndeterministic ternarization, pow2- ternarization, and exponential quantization\nmethods gave rise to low-precision RNNs that produce similar and even higher\naccuracy on certain datasets, therefore providing a path towards training more\nefficient implementations of RNNs in specialized hardware.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 21:24:45 GMT"}, {"version": "v2", "created": "Sun, 26 Feb 2017 14:13:25 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Ott", "Joachim", ""], ["Lin", "Zhouhan", ""], ["Zhang", "Ying", ""], ["Liu", "Shih-Chii", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1611.07422", "submitter": "Jiequn Han", "authors": "Jiequn Han, Weinan E", "title": "Deep Learning Approximation for Stochastic Control Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world stochastic control problems suffer from the \"curse of\ndimensionality\". To overcome this difficulty, we develop a deep learning\napproach that directly solves high-dimensional stochastic control problems\nbased on Monte-Carlo sampling. We approximate the time-dependent controls as\nfeedforward neural networks and stack these networks together through model\ndynamics. The objective function for the control problem plays the role of the\nloss function for the deep neural network. We test this approach using examples\nfrom the areas of optimal trading and energy storage. Our results suggest that\nthe algorithm presented here achieves satisfactory accuracy and at the same\ntime, can handle rather high dimensional problems.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 02:47:26 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Han", "Jiequn", ""], ["E", "Weinan", ""]]}, {"id": "1611.07571", "submitter": "Nikolay Savinov", "authors": "Nikolay Savinov, Akihito Seki, Lubor Ladicky, Torsten Sattler and Marc\n  Pollefeys", "title": "Quad-networks: unsupervised learning to rank for interest point\n  detection", "comments": "Accepted at CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several machine learning tasks require to represent the data using only a\nsparse set of interest points. An ideal detector is able to find the\ncorresponding interest points even if the data undergo a transformation typical\nfor a given domain. Since the task is of high practical interest in computer\nvision, many hand-crafted solutions were proposed. In this paper, we ask a\nfundamental question: can we learn such detectors from scratch? Since it is\noften unclear what points are \"interesting\", human labelling cannot be used to\nfind a truly unbiased solution. Therefore, the task requires an unsupervised\nformulation. We are the first to propose such a formulation: training a neural\nnetwork to rank points in a transformation-invariant manner. Interest points\nare then extracted from the top/bottom quantiles of this ranking. We validate\nour approach on two tasks: standard RGB image interest point detection and\nchallenging cross-modal interest point detection between RGB and depth images.\nWe quantitatively show that our unsupervised method performs better or on-par\nwith baselines.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 22:46:17 GMT"}, {"version": "v2", "created": "Mon, 10 Apr 2017 21:15:18 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Savinov", "Nikolay", ""], ["Seki", "Akihito", ""], ["Ladicky", "Lubor", ""], ["Sattler", "Torsten", ""], ["Pollefeys", "Marc", ""]]}, {"id": "1611.07661", "submitter": "Michael Maire", "authors": "Tsung-Wei Ke, Michael Maire, Stella X. Yu", "title": "Multigrid Neural Architectures", "comments": "updated with ImageNet results; to appear at CVPR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multigrid extension of convolutional neural networks (CNNs).\nRather than manipulating representations living on a single spatial grid, our\nnetwork layers operate across scale space, on a pyramid of grids. They consume\nmultigrid inputs and produce multigrid outputs; convolutional filters\nthemselves have both within-scale and cross-scale extent. This aspect is\ndistinct from simple multiscale designs, which only process the input at\ndifferent scales. Viewed in terms of information flow, a multigrid network\npasses messages across a spatial pyramid. As a consequence, receptive field\nsize grows exponentially with depth, facilitating rapid integration of context.\nMost critically, multigrid structure enables networks to learn internal\nattention and dynamic routing mechanisms, and use them to accomplish tasks on\nwhich modern CNNs fail.\n  Experiments demonstrate wide-ranging performance advantages of multigrid. On\nCIFAR and ImageNet classification tasks, flipping from a single grid to\nmultigrid within the standard CNN paradigm improves accuracy, while being\ncompute and parameter efficient. Multigrid is independent of other\narchitectural choices; we show synergy in combination with residual\nconnections. Multigrid yields dramatic improvement on a synthetic semantic\nsegmentation dataset. Most strikingly, relatively shallow multigrid networks\ncan learn to directly perform spatial transformation tasks, where, in contrast,\ncurrent CNNs fail. Together, our results suggest that continuous evolution of\nfeatures on a multigrid pyramid is a more powerful alternative to existing CNN\ndesigns on a flat grid.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 06:55:53 GMT"}, {"version": "v2", "created": "Thu, 11 May 2017 19:24:33 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Ke", "Tsung-Wei", ""], ["Maire", "Michael", ""], ["Yu", "Stella X.", ""]]}, {"id": "1611.07743", "submitter": "Gil Keren", "authors": "Gil Keren, Sivan Sabato, Bj\\\"orn Schuller", "title": "Tunable Sensitivity to Large Errors in Neural Network Training", "comments": "The paper is accepted to the AAAI 2017 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When humans learn a new concept, they might ignore examples that they cannot\nmake sense of at first, and only later focus on such examples, when they are\nmore useful for learning. We propose incorporating this idea of tunable\nsensitivity for hard examples in neural network learning, using a new\ngeneralization of the cross-entropy gradient step, which can be used in place\nof the gradient in any gradient-based training method. The generalized gradient\nis parameterized by a value that controls the sensitivity of the training\nprocess to harder training examples. We tested our method on several benchmark\ndatasets. We propose, and corroborate in our experiments, that the optimal\nlevel of sensitivity to hard example is positively correlated with the depth of\nthe network. Moreover, the test prediction error obtained by our method is\ngenerally lower than that of the vanilla cross-entropy gradient learner. We\ntherefore conclude that tunable sensitivity can be helpful for neural network\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 11:14:01 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Keren", "Gil", ""], ["Sabato", "Sivan", ""], ["Schuller", "Bj\u00f6rn", ""]]}, {"id": "1611.07819", "submitter": "Steven Eliuk", "authors": "Steven Eliuk, Cameron Upright, Hars Vardhan, Stephen Walsh, Trevor\n  Gale", "title": "dMath: Distributed Linear Algebra for DL", "comments": "5 pages. arXiv admin note: text overlap with arXiv:1604.01416", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a parallel math library, dMath, that demonstrates leading\nscaling when using intranode, internode, and hybrid-parallelism for deep\nlearning (DL). dMath provides easy-to-use distributed primitives and a variety\nof domain-specific algorithms including matrix multiplication, convolutions,\nand others allowing for rapid development of scalable applications like deep\nneural networks (DNNs). Persistent data stored in GPU memory and advanced\nmemory management techniques avoid costly transfers between host and device.\ndMath delivers performance, portability, and productivity to its specific\ndomain of support.\n", "versions": [{"version": "v1", "created": "Sat, 19 Nov 2016 00:24:12 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Eliuk", "Steven", ""], ["Upright", "Cameron", ""], ["Vardhan", "Hars", ""], ["Walsh", "Stephen", ""], ["Gale", "Trevor", ""]]}, {"id": "1611.08083", "submitter": "Maithra Raghu", "authors": "Maithra Raghu, Ben Poole, Jon Kleinberg, Surya Ganguli, Jascha\n  Sohl-Dickstein", "title": "Survey of Expressivity in Deep Neural Networks", "comments": "Presented at NIPS 2016 Workshop on Interpretable Machine Learning in\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We survey results on neural network expressivity described in \"On the\nExpressive Power of Deep Neural Networks\". The paper motivates and develops\nthree natural measures of expressiveness, which all display an exponential\ndependence on the depth of the network. In fact, all of these measures are\nrelated to a fourth quantity, trajectory length. This quantity grows\nexponentially in the depth of the network, and is responsible for the depth\nsensitivity observed. These results translate to consequences for networks\nduring and after training. They suggest that parameters earlier in a network\nhave greater influence on its expressive power -- in particular, given a layer,\nits influence on expressivity is determined by the remaining depth of the\nnetwork after that layer. This is verified with experiments on MNIST and\nCIFAR-10. We also explore the effect of training on the input-output map, and\nfind that it trades off between the stability and expressivity.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 07:09:24 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Raghu", "Maithra", ""], ["Poole", "Ben", ""], ["Kleinberg", "Jon", ""], ["Ganguli", "Surya", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1611.08307", "submitter": "Tim Rockt\\\"aschel", "authors": "Avishkar Bhoopchand, Tim Rockt\\\"aschel, Earl Barr, Sebastian Riedel", "title": "Learning Python Code Suggestion with a Sparse Pointer Network", "comments": "Under review as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To enhance developer productivity, all modern integrated development\nenvironments (IDEs) include code suggestion functionality that proposes likely\nnext tokens at the cursor. While current IDEs work well for statically-typed\nlanguages, their reliance on type annotations means that they do not provide\nthe same level of support for dynamic programming languages as for\nstatically-typed languages. Moreover, suggestion engines in modern IDEs do not\npropose expressions or multi-statement idiomatic code. Recent work has shown\nthat language models can improve code suggestion systems by learning from\nsoftware repositories. This paper introduces a neural language model with a\nsparse pointer network aimed at capturing very long-range dependencies. We\nrelease a large-scale code suggestion corpus of 41M lines of Python code\ncrawled from GitHub. On this corpus, we found standard neural language models\nto perform well at suggesting local phenomena, but struggle to refer to\nidentifiers that are introduced many tokens in the past. By augmenting a neural\nlanguage model with a pointer network specialized in referring to predefined\nclasses of identifiers, we obtain a much lower perplexity and a 5 percentage\npoints increase in accuracy for code suggestion compared to an LSTM baseline.\nIn fact, this increase in code suggestion accuracy is due to a 13 times more\naccurate prediction of identifiers. Furthermore, a qualitative analysis shows\nthis model indeed captures interesting long-range dependencies, like referring\nto a class member defined over 60 tokens in the past.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 21:01:46 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Bhoopchand", "Avishkar", ""], ["Rockt\u00e4schel", "Tim", ""], ["Barr", "Earl", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1611.08812", "submitter": "Yulia Dodonova", "authors": "Yulia Dodonova, Mikhail Belyaev, Anna Tkachev, Dmitry Petrov, and\n  Leonid Zhukov", "title": "Kernel classification of connectomes based on earth mover's distance\n  between graph spectra", "comments": "Presented at The MICCAI-BACON 16 Workshop (arXiv:1611.03363)", "journal-ref": null, "doi": null, "report-no": "BACON/2016/05", "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle a problem of predicting phenotypes from structural\nconnectomes. We propose that normalized Laplacian spectra can capture\nstructural properties of brain networks, and hence graph spectral distributions\nare useful for a task of connectome-based classification. We introduce a kernel\nthat is based on earth mover's distance (EMD) between spectral distributions of\nbrain networks. We access performance of an SVM classifier with the proposed\nkernel for a task of classification of autism spectrum disorder versus typical\ndevelopment based on a publicly available dataset. Classification quality (area\nunder the ROC-curve) obtained with the EMD-based kernel on spectral\ndistributions is 0.71, which is higher than that based on simpler graph\nembedding methods.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 09:35:04 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Dodonova", "Yulia", ""], ["Belyaev", "Mikhail", ""], ["Tkachev", "Anna", ""], ["Petrov", "Dmitry", ""], ["Zhukov", "Leonid", ""]]}, {"id": "1611.09149", "submitter": "Hendrik Richter", "authors": "Hendrik Richter", "title": "Dynamic landscape models of coevolutionary games", "comments": "arXiv admin note: substantial text overlap with arXiv:1603.06374", "journal-ref": "BioSystems 153-154, 26-44, 2017", "doi": null, "report-no": null, "categories": "q-bio.PE cs.NE physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Players of coevolutionary games may update not only their strategies but also\ntheir networks of interaction. Based on interpreting the payoff of players as\nfitness, dynamic landscape models are proposed. The modeling procedure is\ncarried out for Prisoner's Dilemma (PD) and Snowdrift (SD) games that both use\neither birth--death (BD) or death--birth (DB) strategy updating. The main focus\nis on using dynamic fitness landscapes as a mathematical model of\ncoevolutionary game dynamics. Hence, an alternative tool for analyzing\ncoevolutionary games becomes available, and landscape measures such as\nmodality, ruggedness and information content can be computed and analyzed. In\naddition, fixation properties of the games and quantifiers characterizing the\ninteraction networks are calculated numerically. Relations are established\nbetween landscape properties expressed by landscape measures and quantifiers of\ncoevolutionary game dynamics such as fixation probabilities, fixation times and\nnetwork properties.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 14:55:50 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 12:50:04 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Richter", "Hendrik", ""]]}, {"id": "1611.09232", "submitter": "Meshia C\\'edric Oveneke", "authors": "Meshia C\\'edric Oveneke, Mitchel Aliosha-Perez, Yong Zhao, Dongmei\n  Jiang and Hichem Sahli", "title": "Efficient Convolutional Auto-Encoding via Random Convexification and\n  Frequency-Domain Minimization", "comments": "Accepted at NIPS 2016 Workshop on Efficient Methods for Deep Neural\n  Networks (EMDNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The omnipresence of deep learning architectures such as deep convolutional\nneural networks (CNN)s is fueled by the synergistic combination of\never-increasing labeled datasets and specialized hardware. Despite the\nindisputable success, the reliance on huge amounts of labeled data and\nspecialized hardware can be a limiting factor when approaching new\napplications. To help alleviating these limitations, we propose an efficient\nlearning strategy for layer-wise unsupervised training of deep CNNs on\nconventional hardware in acceptable time. Our proposed strategy consists of\nrandomly convexifying the reconstruction contractive auto-encoding (RCAE)\nlearning objective and solving the resulting large-scale convex minimization\nproblem in the frequency domain via coordinate descent (CD). The main\nadvantages of our proposed learning strategy are: (1) single tunable\noptimization parameter; (2) fast and guaranteed convergence; (3) possibilities\nfor full parallelization. Numerical experiments show that our proposed learning\nstrategy scales (in the worst case) linearly with image size, number of filters\nand filter size.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 16:42:11 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Oveneke", "Meshia C\u00e9dric", ""], ["Aliosha-Perez", "Mitchel", ""], ["Zhao", "Yong", ""], ["Jiang", "Dongmei", ""], ["Sahli", "Hichem", ""]]}, {"id": "1611.09288", "submitter": "Tom Sercu", "authors": "Tom Sercu and Vaibhava Goel", "title": "Dense Prediction on Sequences with Time-Dilated Convolutions for Speech\n  Recognition", "comments": "Appeared at NIPS 2016 End-to-end Learning for Speech and Audio\n  Processing Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer vision pixelwise dense prediction is the task of predicting a\nlabel for each pixel in the image. Convolutional neural networks achieve good\nperformance on this task, while being computationally efficient. In this paper\nwe carry these ideas over to the problem of assigning a sequence of labels to a\nset of speech frames, a task commonly known as framewise classification. We\nshow that dense prediction view of framewise classification offers several\nadvantages and insights, including computational efficiency and the ability to\napply batch normalization. When doing dense prediction we pay specific\nattention to strided pooling in time and introduce an asymmetric dilated\nconvolution, called time-dilated convolution, that allows for efficient and\nelegant implementation of pooling in time. We show results using time-dilated\nconvolutions in a very deep VGG-style CNN with batch normalization on the Hub5\nSwitchboard-2000 benchmark task. With a big n-gram language model, we achieve\n7.7% WER which is the best single model single-pass performance reported so\nfar.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 19:09:58 GMT"}, {"version": "v2", "created": "Wed, 14 Dec 2016 08:27:41 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Sercu", "Tom", ""], ["Goel", "Vaibhava", ""]]}, {"id": "1611.09430", "submitter": "Brian Cheung", "authors": "Brian Cheung, Eric Weiss, Bruno Olshausen", "title": "Emergence of foveal image sampling from learning to attend in visual\n  scenes", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a neural attention model with a learnable retinal sampling\nlattice. The model is trained on a visual search task requiring the\nclassification of an object embedded in a visual scene amidst background\ndistractors using the smallest number of fixations. We explore the tiling\nproperties that emerge in the model's retinal sampling lattice after training.\nSpecifically, we show that this lattice resembles the eccentricity dependent\nsampling lattice of the primate retina, with a high resolution region in the\nfovea surrounded by a low resolution periphery. Furthermore, we find conditions\nwhere these emergent properties are amplified or eliminated providing clues to\ntheir function.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 23:39:20 GMT"}, {"version": "v2", "created": "Sat, 21 Oct 2017 08:26:16 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Cheung", "Brian", ""], ["Weiss", "Eric", ""], ["Olshausen", "Bruno", ""]]}, {"id": "1611.09434", "submitter": "Jakob Foerster", "authors": "Jakob N. Foerster, Justin Gilmer, Jan Chorowski, Jascha\n  Sohl-Dickstein, David Sussillo", "title": "Input Switched Affine Networks: An RNN Architecture Designed for\n  Interpretability", "comments": "ICLR 2107 submission: https://openreview.net/forum?id=H1MjAnqxg", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There exist many problem domains where the interpretability of neural network\nmodels is essential for deployment. Here we introduce a recurrent architecture\ncomposed of input-switched affine transformations - in other words an RNN\nwithout any explicit nonlinearities, but with input-dependent recurrent\nweights. This simple form allows the RNN to be analyzed via straightforward\nlinear methods: we can exactly characterize the linear contribution of each\ninput to the model predictions; we can use a change-of-basis to disentangle\ninput, output, and computational hidden unit subspaces; we can fully\nreverse-engineer the architecture's solution to a simple task. Despite this\nease of interpretation, the input switched affine network achieves reasonable\nperformance on a text modeling tasks, and allows greater computational\nefficiency than networks with standard nonlinearities.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 23:48:41 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 20:29:48 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Foerster", "Jakob N.", ""], ["Gilmer", "Justin", ""], ["Chorowski", "Jan", ""], ["Sohl-Dickstein", "Jascha", ""], ["Sussillo", "David", ""]]}, {"id": "1611.09755", "submitter": "Saptarshi Das", "authors": "Indranil Pan and Saptarshi Das", "title": "Fractional Order AGC for Distributed Energy Resources Using Robust\n  Optimization", "comments": "12 pages, 16 figures, 5 tables", "journal-ref": "IEEE Transactions on Smart Grid, Volume 7, Issue 5, Pages 2175 -\n  2186, Sept 2016", "doi": "10.1109/TSG.2015.2459766", "report-no": null, "categories": "cs.SY cs.AI cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The applicability of fractional order (FO) automatic generation control (AGC)\nfor power system frequency oscillation damping is investigated in this paper,\nemploying distributed energy generation. The hybrid power system employs\nvarious autonomous generation systems like wind turbine, solar photovoltaic,\ndiesel engine, fuel-cell and aqua electrolyzer along with other energy storage\ndevices like the battery and flywheel. The controller is placed in a remote\nlocation while receiving and sending signals over an unreliable communication\nnetwork with stochastic delay. The controller parameters are tuned using robust\noptimization techniques employing different variants of Particle Swarm\nOptimization (PSO) and are compared with the corresponding optimal solutions.\nAn archival based strategy is used for reducing the number of function\nevaluations for the robust optimization methods. The solutions obtained through\nthe robust optimization are able to handle higher variation in the controller\ngains and orders without significant decrease in the system performance. This\nis desirable from the FO controller implementation point of view, as the design\nis able to accommodate variations in the system parameter which may result due\nto the approximation of FO operators, using different realization methods and\norder of accuracy. Also a comparison is made between the FO and the integer\norder (IO) controllers to highlight the merits and demerits of each scheme.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 17:56:02 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Pan", "Indranil", ""], ["Das", "Saptarshi", ""]]}, {"id": "1611.09802", "submitter": "Saptarshi Das", "authors": "Indranil Pan and Saptarshi Das", "title": "Fractional Order Load-Frequency Control of Interconnected Power Systems\n  Using Chaotic Multi-objective Optimization", "comments": "31 pages, 19 figures, 2 tables", "journal-ref": "Applied Soft Computing, Volume 29, April 2015, Pages 328-344", "doi": "10.1016/j.asoc.2014.12.032", "report-no": null, "categories": "math.OC cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fractional order proportional-integral-derivative (FOPID) controllers are\ndesigned for load frequency control (LFC) of two interconnected power systems.\nConflicting time domain design objectives are considered in a multi objective\noptimization (MOO) based design framework to design the gains and the\nfractional differ-integral orders of the FOPID controllers in the two areas.\nHere, we explore the effect of augmenting two different chaotic maps along with\nthe uniform random number generator (RNG) in the popular MOO algorithm - the\nNon-dominated Sorting Genetic Algorithm-II (NSGA-II). Different measures of\nquality for MOO e.g. hypervolume indicator, moment of inertia based diversity\nmetric, total Pareto spread, spacing metric are adopted to select the best set\nof controller parameters from multiple runs of all the NSGA-II variants (i.e.\nnominal and chaotic versions). The chaotic versions of the NSGA-II algorithm\nare compared with the standard NSGA-II in terms of solution quality and\ncomputational time. In addition, the Pareto optimal fronts showing the\ntrade-off between the two conflicting time domain design objectives are\ncompared to show the advantage of using the FOPID controller over that with\nsimple PID controller. The nature of fast/slow and high/low noise amplification\neffects of the FOPID structure or the four quadrant operation in the two\ninter-connected areas of the power system is also explored. A fuzzy logic based\nmethod has been adopted next to select the best compromise solution from the\nbest Pareto fronts corresponding to each MOO comparison criteria. The time\ndomain system responses are shown for the fuzzy best compromise solutions under\nnominal operating conditions. Comparative analysis on the merits and de-merits\nof each controller structure is reported then. A robustness analysis is also\ndone for the PID and the FOPID controllers.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 19:36:42 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Pan", "Indranil", ""], ["Das", "Saptarshi", ""]]}, {"id": "1611.09835", "submitter": "Saptarshi Das", "authors": "Indranil Pan, Saptarshi Das and Shantanu Das", "title": "Multi-objective Active Control Policy Design for Commensurate and\n  Incommensurate Fractional Order Chaotic Financial Systems", "comments": "26 pages, 8 figures, 2 tables", "journal-ref": "Applied Mathematical Modelling, Volume 39, Issue 2, 15 January\n  2015, Pages 500-514", "doi": "10.1016/j.apm.2014.06.005", "report-no": null, "categories": "math.OC cs.CE cs.NE cs.SY nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an active control policy design for a fractional order (FO)\nfinancial system is attempted, considering multiple conflicting objectives. An\nactive control template as a nonlinear state feedback mechanism is developed\nand the controller gains are chosen within a multi-objective optimization (MOO)\nframework to satisfy the conditions of asymptotic stability, derived\nanalytically. The MOO gives a set of solutions on the Pareto optimal front for\nthe multiple conflicting objectives that are considered. It is shown that there\nis a trade-off between the multiple design objectives and a better performance\nin one objective can only be obtained at the cost of performance deterioration\nin the other objectives. The multi-objective controller design has been\ncompared using three different MOO techniques viz. Non Dominated Sorting\nGenetic Algorithm-II (NSGA-II), epsilon variable Multi-Objective Genetic\nAlgorithm (ev-MOGA), and Multi Objective Evolutionary Algorithm with\nDecomposition (MOEA/D). The robustness of the same control policy designed with\nthe nominal system settings have been investigated also for gradual decrease in\nthe commensurate and incommensurate fractional orders of the financial system.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 20:47:25 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Pan", "Indranil", ""], ["Das", "Saptarshi", ""], ["Das", "Shantanu", ""]]}, {"id": "1611.09913", "submitter": "Jasmine Collins", "authors": "Jasmine Collins, Jascha Sohl-Dickstein and David Sussillo", "title": "Capacity and Trainability in Recurrent Neural Networks", "comments": "Published as a conference paper at ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two potential bottlenecks on the expressiveness of recurrent neural networks\n(RNNs) are their ability to store information about the task in their\nparameters, and to store information about the input history in their units. We\nshow experimentally that all common RNN architectures achieve nearly the same\nper-task and per-unit capacity bounds with careful training, for a variety of\ntasks and stacking depths. They can store an amount of task information which\nis linear in the number of parameters, and is approximately 5 bits per\nparameter. They can additionally store approximately one real number from their\ninput history per hidden unit. We further find that for several tasks it is the\nper-task parameter capacity bound that determines performance. These results\nsuggest that many previous results comparing RNN architectures are driven\nprimarily by differences in training effectiveness, rather than differences in\ncapacity. Supporting this observation, we compare training difficulty for\nseveral architectures, and show that vanilla RNNs are far more difficult to\ntrain, yet have slightly higher capacity. Finally, we propose two novel RNN\narchitectures, one of which is easier to train than the LSTM or GRU for deeply\nstacked architectures.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 22:13:20 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2017 22:21:44 GMT"}, {"version": "v3", "created": "Fri, 3 Mar 2017 17:39:34 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Collins", "Jasmine", ""], ["Sohl-Dickstein", "Jascha", ""], ["Sussillo", "David", ""]]}]