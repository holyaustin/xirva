[{"id": "1212.0083", "submitter": "Laurent Bougrain", "authors": "Laurent Bougrain (INRIA Nancy - Grand Est / LORIA), Olivier Rochel\n  (INRIA), Octave Boussaton (INRIA Nancy - Grand Est / LORIA), Lionel Havet\n  (INRIA Nancy - Grand Est / LORIA)", "title": "From the decoding of cortical activities to the control of a JACO\n  robotic arm: a whole processing chain", "comments": null, "journal-ref": "CAR - Control Architecture of Robots - 2012 (2012)", "doi": null, "report-no": null, "categories": "cs.NE cs.HC cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a complete processing chain for decoding intracranial\ndata recorded in the cortex of a monkey and replicates the associated movements\non a JACO robotic arm by Kinova. We developed specific modules inside the\nOpenViBE platform in order to build a Brain-Machine Interface able to read the\ndata, compute the position of the robotic finger and send this position to the\nrobotic arm. More pre- cisely, two client/server protocols have been tested to\ntransfer the finger positions: VRPN and a light protocol based on TCP/IP\nsockets. According to the requested finger position, the server calls the\nassoci- ated functions of an API by Kinova to move the fin- gers properly.\nFinally, we monitor the gap between the requested and actual fingers positions.\nThis chain can be generalized to any movement of the arm or wrist.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2012 08:27:24 GMT"}], "update_date": "2012-12-05", "authors_parsed": [["Bougrain", "Laurent", "", "INRIA Nancy - Grand Est / LORIA"], ["Rochel", "Olivier", "", "INRIA"], ["Boussaton", "Octave", "", "INRIA Nancy - Grand Est / LORIA"], ["Havet", "Lionel", "", "INRIA Nancy - Grand Est / LORIA"]]}, {"id": "1212.0170", "submitter": "Herve Kabamba Mbikayi", "authors": "Herve Kabamba Mbikayi", "title": "An Evolution Strategy Approach toward Rule-set Generation for Network\n  Intrusion Detection Systems (IDS)", "comments": "5 pages", "journal-ref": "International Journal of Soft Computing and Engineering(TM), 2(5),\n  201 - 205, 2012", "doi": null, "report-no": null, "categories": "cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing number of intrusions in system and network\ninfrastructures, Intrusion Detection Systems (IDS) have become an active area\nof research to develop reliable and effective solutions to detect and counter\nthem. The use of Evolutionary Algorithms in IDS has proved its maturity over\nthe times. Although most of the research works have been based on the use of\ngenetic algorithms in IDS, this paper presents an approach toward the\ngeneration of rules for the identification of anomalous connections using\nevolution strategies . The emphasis is given on how the problem can be modeled\ninto ES primitives and how the fitness of the population can be evaluated in\norder to find the local optima, therefore resulting in optimal rules that can\nbe used for detecting intrusions in intrusion detection systems.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2012 23:46:53 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Mbikayi", "Herve Kabamba", ""]]}, {"id": "1212.0215", "submitter": "Mriganka Chakraborty", "authors": "Mriganka Chakraborty", "title": "Artificial Neural Network for Performance Modeling and Optimization of\n  CMOS Analog Circuits", "comments": "International Journal of Computer Applications November 2012", "journal-ref": null, "doi": "10.5120/9380-3731", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an implementation of multilayer feed forward neural\nnetworks (NN) to optimize CMOS analog circuits. For modeling and design\nrecently neural network computational modules have got acceptance as an\nunorthodox and useful tool. To achieve high performance of active or passive\ncircuit component neural network can be trained accordingly. A well trained\nneural network can produce more accurate outcome depending on its learning\ncapability. Neural network model can replace empirical modeling solutions\nlimited by range and accuracy.[2] Neural network models are easy to obtain for\nnew circuits or devices which can replace analytical methods. Numerical\nmodeling methods can also be replaced by neural network model due to their\ncomputationally expansive behavior.[2][10][20]. The pro- posed implementation\nis aimed at reducing resource requirement, without much compromise on the\nspeed. The NN ensures proper functioning by assigning the appropriate inputs,\nweights, biases, and excitation function of the layer that is currently being\ncomputed. The concept used is shown to be very effective in reducing resource\nrequirements and enhancing speed.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2012 15:07:56 GMT"}], "update_date": "2012-12-13", "authors_parsed": [["Chakraborty", "Mriganka", ""]]}, {"id": "1212.0220", "submitter": "Xin-She Yang", "authors": "Xin-She Yang", "title": "Metaheuristic Optimization: Algorithm Analysis and Open Problems", "comments": "14 pages 2 figures. arXiv admin note: substantial text overlap with\n  arXiv:1208.0527", "journal-ref": "Lecture Notes in Computer Sciences, Vol. 6630 (2011) pp. 21-32", "doi": null, "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metaheuristic algorithms are becoming an important part of modern\noptimization. A wide range of metaheuristic algorithms have emerged over the\nlast two decades, and many metaheuristics such as particle swarm optimization\nare becoming increasingly popular. Despite their popularity, mathematical\nanalysis of these algorithms lacks behind. Convergence analysis still remains\nunsolved for the majority of metaheuristic algorithms, while efficiency\nanalysis is equally challenging. In this paper, we intend to provide an\noverview of convergence and efficiency studies of metaheuristics, and try to\nprovide a framework for analyzing metaheuristics in terms of convergence and\nefficiency. This can form a basis for analyzing other algorithms. We also\noutline some open questions as further research topics.\n", "versions": [{"version": "v1", "created": "Sun, 2 Dec 2012 16:01:23 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Yang", "Xin-She", ""]]}, {"id": "1212.0639", "submitter": "Osama Khalil", "authors": "Osama Khalil", "title": "Evaluation of Particle Swarm Optimization Algorithms for Weighted\n  Max-Sat Problem: Technical Report", "comments": "Not useful", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  An experimental evaluation is conducted to asses the performance of 4\ndifferent Particle Swarm Optimization neighborhood structures in solving\nMax-Sat problem. The experiment has shown that none of the algorithms achieves\nstatistically significant performance over the others under confidence level of\n0.05.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 08:48:29 GMT"}, {"version": "v2", "created": "Fri, 17 Mar 2017 20:06:29 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Khalil", "Osama", ""]]}, {"id": "1212.1524", "submitter": "Ludovic Arnold", "authors": "Ludovic Arnold and Yann Ollivier", "title": "Layer-wise learning of deep generative models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When using deep, multi-layered architectures to build generative models of\ndata, it is difficult to train all layers at once. We propose a layer-wise\ntraining procedure admitting a performance guarantee compared to the global\noptimum. It is based on an optimistic proxy of future performance, the best\nlatent marginal. We interpret auto-encoders in this setting as generative\nmodels, by showing that they train a lower bound of this criterion. We test the\nnew learning procedure against a state of the art method (stacked RBMs), and\nfind it to improve performance. Both theory and experiments highlight the\nimportance, when training deep architectures, of using an inference model (from\ndata to hidden variables) richer than the generative model (from hidden\nvariables to data).\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2012 03:14:50 GMT"}, {"version": "v2", "created": "Sat, 16 Feb 2013 13:24:46 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Arnold", "Ludovic", ""], ["Ollivier", "Yann", ""]]}, {"id": "1212.1744", "submitter": "David Snyder", "authors": "David Snyder, Alireza Goudarzi, Christof Teuscher", "title": "Computational Capabilities of Random Automata Networks for Reservoir\n  Computing", "comments": "9 pages, 6 figures", "journal-ref": "Physical Review E, 87(4):042808 (2013)", "doi": "10.1103/PhysRevE.87.042808", "report-no": null, "categories": "nlin.AO cond-mat.dis-nn cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper underscores the conjecture that intrinsic computation is maximal\nin systems at the \"edge of chaos.\" We study the relationship between dynamics\nand computational capability in Random Boolean Networks (RBN) for Reservoir\nComputing (RC). RC is a computational paradigm in which a trained readout layer\ninterprets the dynamics of an excitable component (called the reservoir) that\nis perturbed by external input. The reservoir is often implemented as a\nhomogeneous recurrent neural network, but there has been little investigation\ninto the properties of reservoirs that are discrete and heterogeneous. Random\nBoolean networks are generic and heterogeneous dynamical systems and here we\nuse them as the reservoir. An RBN is typically a closed system; to use it as a\nreservoir we extend it with an input layer. As a consequence of perturbation,\nthe RBN does not necessarily fall into an attractor. Computational capability\nin RC arises from a trade-off between separability and fading memory of inputs.\nWe find the balance of these properties predictive of classification power and\noptimal at critical connectivity. These results are relevant to the\nconstruction of devices which exploit the intrinsic dynamics of complex\nheterogeneous systems, such as biomolecular substrates.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2012 00:29:50 GMT"}, {"version": "v2", "created": "Sat, 20 Apr 2013 09:19:21 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Snyder", "David", ""], ["Goudarzi", "Alireza", ""], ["Teuscher", "Christof", ""]]}, {"id": "1212.1752", "submitter": "Mriganka Chakraborty", "authors": "Mriganka Chakraborty and Arka Ghosh", "title": "Hybrid Optimized Back propagation Learning Algorithm For Multi-layer\n  Perceptron", "comments": "Accepted for publish in 18th December, 2012,International Journal of\n  Computer Applications, Foundation of Computer Science, New York, USA", "journal-ref": "International Journal of Computer Applications 60(13):1-5, 2012", "doi": "10.5120/9749-3332", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard neural network based on general back propagation learning using\ndelta method or gradient descent method has some great faults like poor\noptimization of error-weight objective function, low learning rate, instability\n.This paper introduces a hybrid supervised back propagation learning algorithm\nwhich uses trust-region method of unconstrained optimization of the error\nobjective function by using quasi-newton method .This optimization leads to\nmore accurate weight update system for minimizing the learning error during\nlearning phase of multi-layer perceptron.[13][14][15] In this paper augmented\nline search is used for finding points which satisfies Wolfe condition. In this\npaper, This hybrid back propagation algorithm has strong global convergence\nproperties & is robust & efficient in practice.\n", "versions": [{"version": "v1", "created": "Sat, 8 Dec 2012 02:47:40 GMT"}], "update_date": "2012-12-20", "authors_parsed": [["Chakraborty", "Mriganka", ""], ["Ghosh", "Arka", ""]]}, {"id": "1212.2044", "submitter": "Gabriel Kronberger", "authors": "Gabriel Kronberger, Stefan Fink, Michael Kommenda and Michael\n  Affenzeller", "title": "Macro-Economic Time Series Modeling and Interaction Networks", "comments": "The original publication is available at\n  http://link.springer.com/chapter/10.1007/978-3-642-20520-0_11", "journal-ref": "Applications of Evolutionary Computation, LNCS 6625 (Springer\n  Berlin Heidelberg), pp. 101-110 (2011)", "doi": "10.1007/978-3-642-20520-0_11", "report-no": null, "categories": "cs.NE stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Macro-economic models describe the dynamics of economic quantities. The\nestimations and forecasts produced by such models play a substantial role for\nfinancial and political decisions. In this contribution we describe an approach\nbased on genetic programming and symbolic regression to identify variable\ninteractions in large datasets. In the proposed approach multiple symbolic\nregression runs are executed for each variable of the dataset to find\npotentially interesting models. The result is a variable interaction network\nthat describes which variables are most relevant for the approximation of each\nvariable of the dataset. This approach is applied to a macro-economic dataset\nwith monthly observations of important economic indicators in order to identify\npotentially interesting dependencies of these indicators. The resulting\ninteraction network of macro-economic indicators is briefly discussed and two\nof the identified models are presented in detail. The two models approximate\nthe help wanted index and the CPI inflation in the US.\n", "versions": [{"version": "v1", "created": "Mon, 10 Dec 2012 12:04:58 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2013 16:58:12 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Kronberger", "Gabriel", ""], ["Fink", "Stefan", ""], ["Kommenda", "Michael", ""], ["Affenzeller", "Michael", ""]]}, {"id": "1212.2529", "submitter": "Francis Cabarle", "authors": "Francis George C. Cabarle, Kelvin C. Bu\\~no, Henry N. Adorna", "title": "On The Delays In Spiking Neural P Systems", "comments": "Presented at the 6th Symposium on the Mathematical Aspects of\n  Computer Science (SMACS2012), Boracay, Philippines. 6 figures, 6 pages, 2\n  columns", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we extend and improve the results done in a previous work on\nsimulating Spiking Neural P systems (SNP systems in short) with delays using\nSNP systems without delays. We simulate the former with the latter over\nsequential, iteration, join, and split routing. Our results provide\nconstructions so that both systems halt at exactly the same time, start with\nonly one spike, and produce the same number of spikes to the environment after\nhalting.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2012 16:40:45 GMT"}], "update_date": "2012-12-12", "authors_parsed": [["Cabarle", "Francis George C.", ""], ["Bu\u00f1o", "Kelvin C.", ""], ["Adorna", "Henry N.", ""]]}, {"id": "1212.2958", "submitter": "Mohammed El-Dosuky", "authors": "M. A. El-Dosuky, M. Z. Rashad, T. T. Hamza and A. H. EL-Bassiouny", "title": "Spike and Tyke, the Quantized Neuron Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling spike firing assumes that spiking statistics are Poisson, but real\ndata violates this assumption. To capture non-Poissonian features, in order to\nfix the inevitable inherent irregularity, researchers rescale the time axis\nwith tedious computational overhead instead of searching for another\ndistribution. Spikes or action potentials are precisely-timed changes in the\nionic transport through synapses adjusting the synaptic weight, successfully\nmodeled and developed as a memristor. Memristance value is multiples of initial\nresistance. This reminds us with the foundations of quantum mechanics. We try\nto quantize potential and resistance, as done with energy. After reviewing\nPlanck curve for blackbody radiation, we propose the quantization equations. We\nintroduce and prove a theorem that quantizes the resistance. Then we define the\ntyke showing its basic characteristics. Finally we give the basic\ntransformations to model spiking and link an energy quantum to a tyke.\nInvestigation shows how this perfectly models the neuron spiking, with over 97%\nmatch.\n", "versions": [{"version": "v1", "created": "Fri, 7 Dec 2012 18:15:58 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2013 00:13:32 GMT"}], "update_date": "2013-03-06", "authors_parsed": [["El-Dosuky", "M. A.", ""], ["Rashad", "M. Z.", ""], ["Hamza", "T. T.", ""], ["EL-Bassiouny", "A. H.", ""]]}, {"id": "1212.3225", "submitter": "Anish Acharya", "authors": "Sayan Saha, Saptarshi Das, Anish Acharya, Abhishek Kumar, Sumit\n  Mukherjee, Indranil Pan, Amitava Gupta", "title": "Identification of Nonlinear Systems From the Knowledge Around Different\n  Operating Conditions: A Feed-Forward Multi-Layer ANN Based Approach", "comments": "\"6 pages, 9 figures; The Second IEEE International Conference on\n  Parallel, Distributed and Grid Computing (PDGC-2012), December 2012, Solan\"", "journal-ref": null, "doi": "10.1109/PDGC.2012.6449856", "report-no": null, "categories": "cs.SY cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper investigates nonlinear system identification using system output\ndata at various linearized operating points. A feed-forward multi-layer\nArtificial Neural Network (ANN) based approach is used for this purpose and\ntested for two target applications i.e. nuclear reactor power level monitoring\nand an AC servo position control system. Various configurations of ANN using\ndifferent activation functions, number of hidden layers and neurons in each\nlayer are trained and tested to find out the best configuration. The training\nis carried out multiple times to check for consistency and the mean and\nstandard deviation of the root mean square errors (RMSE) are reported for each\nconfiguration.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2012 17:15:46 GMT"}, {"version": "v2", "created": "Sat, 15 Dec 2012 18:33:53 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2012 19:16:29 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Saha", "Sayan", ""], ["Das", "Saptarshi", ""], ["Acharya", "Anish", ""], ["Kumar", "Abhishek", ""], ["Mukherjee", "Sumit", ""], ["Pan", "Indranil", ""], ["Gupta", "Amitava", ""]]}, {"id": "1212.3441", "submitter": "Andrew Adamatzky", "authors": "Gerard Howard, Ella Gale, Larry Bull, Ben de Lacy Costello, Andy\n  Adamatzky", "title": "Evolution of Plastic Learning in Spiking Networks via Memristive\n  Connections", "comments": null, "journal-ref": "IEEE Trans Evolutionary Computation 16 (2012) 711--729", "doi": "10.1109/TEVC.2011.2170199", "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a spiking neuroevolutionary system which implements\nmemristors as plastic connections, i.e. whose weights can vary during a trial.\nThe evolutionary design process exploits parameter self-adaptation and variable\ntopologies, allowing the number of neurons, connection weights, and\ninter-neural connectivity pattern to emerge. By comparing two phenomenological\nreal-world memristor implementations with networks comprised of (i) linear\nresistors (ii) constant-valued connections, we demonstrate that this approach\nallows the evolution of networks of appropriate complexity to emerge whilst\nexploiting the memristive properties of the connections to reduce learning\ntime. We extend this approach to allow for heterogeneous mixtures of memristors\nwithin the networks; our approach provides an in-depth analysis of network\nstructure. Our networks are evaluated on simulated robotic navigation tasks;\nresults demonstrate that memristive plasticity enables higher performance than\nconstant-weighted connections in both static and dynamic reward scenarios, and\nthat mixtures of memristive elements provide performance advantages when\ncompared to homogeneous memristive networks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 11:00:55 GMT"}], "update_date": "2012-12-17", "authors_parsed": [["Howard", "Gerard", ""], ["Gale", "Ella", ""], ["Bull", "Larry", ""], ["Costello", "Ben de Lacy", ""], ["Adamatzky", "Andy", ""]]}, {"id": "1212.3765", "submitter": "Mohammad Bavandpour", "authors": "Hamid Soleimani, Arash Ahmadi and Mohammad Bavandpour", "title": "Biologically Inspired Spiking Neurons : Piecewise Linear Models and\n  Digital Implementation", "comments": "14 pages, 16 figures", "journal-ref": "IEEE Transactions On Circuits And Systems I: Regular Papers, Vol.\n  59, NO. 12, December 2012", "doi": "10.1109/TCSI.2012.2206463", "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  There has been a strong push recently to examine biological scale simulations\nof neuromorphic algorithms to achieve stronger inference capabilities. This\npaper presents a set of piecewise linear spiking neuron models, which can\nreproduce different behaviors, similar to the biological neuron, both for a\nsingle neuron as well as a network of neurons. The proposed models are\ninvestigated, in terms of digital implementation feasibility and costs,\ntargeting large scale hardware implementation. Hardware synthesis and physical\nimplementations on FPGA show that the proposed models can produce precise\nneural behaviors with higher performance and considerably lower implementation\ncosts compared with the original model. Accordingly, a compact structure of the\nmodels which can be trained with supervised and unsupervised learning\nalgorithms has been developed. Using this structure and based on a spike rate\ncoding, a character recognition case study has been implemented and tested.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2012 09:05:02 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Soleimani", "Hamid", ""], ["Ahmadi", "Arash", ""], ["Bavandpour", "Mohammad", ""]]}, {"id": "1212.5217", "submitter": "Rui Rodrigues Rui Rodrigues", "authors": "Rui Rodrigues and Paula Couto", "title": "A Neural Network Approach to ECG Denoising", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an ECG denoising method based on a feed forward neural network\nwith three hidden layers. Particulary useful for very noisy signals, this\napproach uses the available ECG channels to reconstruct a noisy channel. We\ntested the method, on all the records from Physionet MIT-BIH Arrhythmia\nDatabase, adding electrode motion artifact noise. This denoising method\nimproved the perfomance of publicly available ECG analysis programs on noisy\nECG signals. This is an offline method that can be used to remove noise from\nvery corrupted Holter records.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 20:11:30 GMT"}], "update_date": "2012-12-21", "authors_parsed": [["Rodrigues", "Rui", ""], ["Couto", "Paula", ""]]}, {"id": "1212.5250", "submitter": "Harry Boyer", "authors": "Alfred Jean Philippe Lauret (PIMENT), Harry Boyer (PIMENT), Carine\n  Riviere (PIMENT), Alain Bastide (PIMENT)", "title": "A genetic algorithm applied to the validation of building thermal models", "comments": null, "journal-ref": "Energy and Buildings 37, 8 (2005) 858-866", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the coupling of a building thermal simulation code with\ngenetic algorithms (GAs). GAs are randomized search algorithms that are based\non the mechanisms of natural selection and genetics. We show that this coupling\nallows the location of defective sub-models of a building thermal model i.e.\nparts of model that are responsible for the disagreements between measurements\nand model predictions. The method first of all is checked and validated on the\nbasis of a numerical model of a building taken as reference. It is then applied\nto a real building case. The results show that the method could constitute an\nefficient tool when checking the model validity.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2012 07:27:27 GMT"}], "update_date": "2012-12-24", "authors_parsed": [["Lauret", "Alfred Jean Philippe", "", "PIMENT"], ["Boyer", "Harry", "", "PIMENT"], ["Riviere", "Carine", "", "PIMENT"], ["Bastide", "Alain", "", "PIMENT"]]}, {"id": "1212.5271", "submitter": "Richard Preen", "authors": "Richard J. Preen and Larry Bull", "title": "Towards the Evolution of Novel Vertical-Axis Wind Turbines", "comments": "14 pages, 11 figures", "journal-ref": "Proceedings of the 13th Annual UK Workshop on Computational\n  Intelligence, UKCI 2013, pp. 74-81. IEEE Computer Society", "doi": "10.1109/UKCI.2013.6651290", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Renewable and sustainable energy is one of the most important challenges\ncurrently facing mankind. Wind has made an increasing contribution to the\nworld's energy supply mix, but still remains a long way from reaching its full\npotential. In this paper, we investigate the use of artificial evolution to\ndesign vertical-axis wind turbine prototypes that are physically instantiated\nand evaluated under approximated wind tunnel conditions. An artificial neural\nnetwork is used as a surrogate model to assist learning and found to reduce the\nnumber of fabrications required to reach a higher aerodynamic efficiency,\nresulting in an important cost reduction. Unlike in other approaches, such as\ncomputational fluid dynamics simulations, no mathematical formulations are used\nand no model assumptions are made.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 21:08:34 GMT"}], "update_date": "2015-05-22", "authors_parsed": [["Preen", "Richard J.", ""], ["Bull", "Larry", ""]]}, {"id": "1212.5594", "submitter": "Harry Boyer", "authors": "Eric Fock (PIMENT), Thierry Alex Mara (PIMENT), Alfred Jean Philippe\n  Lauret (PIMENT), Harry Boyer (PIMENT)", "title": "Black box modelling of HVAC system : improving the performances of\n  neural networks", "comments": "Eighth International IBPSA Conference, Eindhoven : Netherlands\n  (2003); Proceedings available at http://www.ibpsa.org/m_bs2003.asp", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with neural networks modelling of HVAC systems. In order to\nincrease the neural networks performances, a method based on sensitivity\nanalysis is applied. The same technique is also used to compute the relevance\nof each input. To avoid the prediction errors in dry coil conditions, a\nmetamodel for each capacity is derived from the neural networks. The regression\ncoefficients of the polynomial forms are identified through the use of spectral\nanalysis. These methods based on sensitivity and spectral analysis lead to an\noptimized neural network model, as regard to its architecture and predictions.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 13:53:53 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Fock", "Eric", "", "PIMENT"], ["Mara", "Thierry Alex", "", "PIMENT"], ["Lauret", "Alfred Jean Philippe", "", "PIMENT"], ["Boyer", "Harry", "", "PIMENT"]]}, {"id": "1212.5777", "submitter": "Mohammed El-Dosuky", "authors": "M. A. El-Dosuky, M. Z. Rashad, T. T. Hamza and A.H. EL-Bassiouny", "title": "Collaborating Robotics Using Nature-Inspired Meta-Heuristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces collaborating robots which provide the possibility of\nenhanced task performance, high reliability and decreased. Collaborating-bots\nare a collection of mobile robots able to self-assemble and to self-organize in\norder to solve problems that cannot be solved by a single robot. These robots\ncombine the power of swarm intelligence with the flexibility of\nself-reconfiguration as aggregate Collaborating-bots can dynamically change\ntheir structure to match environmental variations. Collaborating robots are\nmore than just networks of independent agents, they are potentially\nreconfigurable networks of communicating agents capable of coordinated sensing\nand interaction with the environment. Robots are going to be an important part\nof the future. Collaborating robots are limited in individual capability, but\nrobots deployed in large numbers can represent a strong force similar to a\ncolony of ants or swarm of bees. We present a mechanism for collaborating\nrobots based on swarm intelligence such as Ant colony optimization and Particle\nswarm Optimization\n", "versions": [{"version": "v1", "created": "Sun, 23 Dec 2012 09:28:54 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["El-Dosuky", "M. A.", ""], ["Rashad", "M. Z.", ""], ["Hamza", "T. T.", ""], ["EL-Bassiouny", "A. H.", ""]]}, {"id": "1212.5921", "submitter": "Miguel \\'A. Carreira-Perpi\\~n\\'an", "authors": "Miguel \\'A. Carreira-Perpi\\~n\\'an and Weiran Wang", "title": "Distributed optimization of deeply nested systems", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In science and engineering, intelligent processing of complex signals such as\nimages, sound or language is often performed by a parameterized hierarchy of\nnonlinear processing layers, sometimes biologically inspired. Hierarchical\nsystems (or, more generally, nested systems) offer a way to generate complex\nmappings using simple stages. Each layer performs a different operation and\nachieves an ever more sophisticated representation of the input, as, for\nexample, in an deep artificial neural network, an object recognition cascade in\ncomputer vision or a speech front-end processing. Joint estimation of the\nparameters of all the layers and selection of an optimal architecture is widely\nconsidered to be a difficult numerical nonconvex optimization problem,\ndifficult to parallelize for execution in a distributed computation\nenvironment, and requiring significant human expert effort, which leads to\nsuboptimal systems in practice. We describe a general mathematical strategy to\nlearn the parameters and, to some extent, the architecture of nested systems,\ncalled the method of auxiliary coordinates (MAC). This replaces the original\nproblem involving a deeply nested function with a constrained problem involving\na different function in an augmented space without nesting. The constrained\nproblem may be solved with penalty-based methods using alternating optimization\nover the parameters and the auxiliary coordinates. MAC has provable\nconvergence, is easy to implement reusing existing algorithms for single\nlayers, can be parallelized trivially and massively, applies even when\nparameter derivatives are not available or not desirable, and is competitive\nwith state-of-the-art nonlinear optimizers even in the serial computation\nsetting, often providing reasonable models within a few iterations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Dec 2012 14:45:25 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Carreira-Perpi\u00f1\u00e1n", "Miguel \u00c1.", ""], ["Wang", "Weiran", ""]]}, {"id": "1212.6276", "submitter": "Sebasti\\'an Basterrech", "authors": "Sebasti\\'an Basterrech and Gerardo Rubino", "title": "Echo State Queueing Network: a new reservoir computing learning tool", "comments": "Proceedings of the 10th IEEE Consumer Communications and Networking\n  Conference (CCNC), Las Vegas, USA, 2013", "journal-ref": null, "doi": "10.1109/CCNC.2013.6488435", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, a new computational paradigm was introduced in the field\nof Machine Learning, under the name of Reservoir Computing (RC). RC models are\nneural networks which a recurrent part (the reservoir) that does not\nparticipate in the learning process, and the rest of the system where no\nrecurrence (no neural circuit) occurs. This approach has grown rapidly due to\nits success in solving learning tasks and other computational applications.\nSome success was also observed with another recently proposed neural network\ndesigned using Queueing Theory, the Random Neural Network (RandNN). Both\napproaches have good properties and identified drawbacks. In this paper, we\npropose a new RC model called Echo State Queueing Network (ESQN), where we use\nideas coming from RandNNs for the design of the reservoir. ESQNs consist in\nESNs where the reservoir has a new dynamics inspired by recurrent RandNNs. The\npaper positions ESQNs in the global Machine Learning area, and provides\nexamples of their use and performances. We show on largely used benchmarks that\nESQNs are very accurate tools, and we illustrate how they compare with standard\nESNs.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2012 22:31:13 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Basterrech", "Sebasti\u00e1n", ""], ["Rubino", "Gerardo", ""]]}, {"id": "1212.6922", "submitter": "Yana Mazwin Mohmad Hassim", "authors": "Yana Mazwin Mohmad Hassim and Rozaida Ghazali", "title": "Training a Functional Link Neural Network Using an Artificial Bee Colony\n  for Solving a Classification Problems", "comments": "6 pages, 3 figures, 4 tables", "journal-ref": "Journal of Computing, Volume 4, Issue 9 (2012), 110-115", "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Neural Networks have emerged as an important tool for\nclassification and have been widely used to classify a non-linear separable\npattern. The most popular artificial neural networks model is a Multilayer\nPerceptron (MLP) as it is able to perform classification task with significant\nsuccess. However due to the complexity of MLP structure and also problems such\nas local minima trapping, over fitting and weight interference have made neural\nnetwork training difficult. Thus, the easy way to avoid these problems is to\nremove the hidden layers. This paper presents the ability of Functional Link\nNeural Network (FLNN) to overcome the complexity structure of MLP by using\nsingle layer architecture and propose an Artificial Bee Colony (ABC)\noptimization for training the FLNN. The proposed technique is expected to\nprovide better learning scheme for a classifier in order to get more accurate\nclassification result\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2012 16:40:50 GMT"}], "update_date": "2013-01-01", "authors_parsed": [["Hassim", "Yana Mazwin Mohmad", ""], ["Ghazali", "Rozaida", ""]]}]