[{"id": "1809.00095", "submitter": "Yoojin Choi", "authors": "Yoojin Choi, Mostafa El-Khamy, Jungwon Lee", "title": "Learning Sparse Low-Precision Neural Networks With Learnable\n  Regularization", "comments": "IEEE Access", "journal-ref": null, "doi": "10.1109/ACCESS.2020.2996936", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning deep neural networks (DNNs) that consist of\nlow-precision weights and activations for efficient inference of fixed-point\noperations. In training low-precision networks, gradient descent in the\nbackward pass is performed with high-precision weights while quantized\nlow-precision weights and activations are used in the forward pass to calculate\nthe loss function for training. Thus, the gradient descent becomes suboptimal,\nand accuracy loss follows. In order to reduce the mismatch in the forward and\nbackward passes, we utilize mean squared quantization error (MSQE)\nregularization. In particular, we propose using a learnable regularization\ncoefficient with the MSQE regularizer to reinforce the convergence of\nhigh-precision weights to their quantized values. We also investigate how\npartial L2 regularization can be employed for weight pruning in a similar\nmanner. Finally, combining weight pruning, quantization, and entropy coding, we\nestablish a low-precision DNN compression pipeline. In our experiments, the\nproposed method yields low-precision MobileNet and ShuffleNet models on\nImageNet classification with the state-of-the-art compression ratios of 7.13\nand 6.79, respectively. Moreover, we examine our method for image super\nresolution networks to produce 8-bit low-precision models at negligible\nperformance loss.\n", "versions": [{"version": "v1", "created": "Sat, 1 Sep 2018 01:28:21 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 00:41:54 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Choi", "Yoojin", ""], ["El-Khamy", "Mostafa", ""], ["Lee", "Jungwon", ""]]}, {"id": "1809.00368", "submitter": "Karen Yeressian", "authors": "Karen Yeressian", "title": "Overcoming the Curse of Dimensionality in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $A$ be a set and $V$ a real Hilbert space. Let $H$ be a real Hilbert\nspace of functions $f:A\\to V$ and assume $H$ is continuously embedded in the\nBanach space of bounded functions. For $i=1,\\cdots,n$, let $(x_i,y_i)\\in\nA\\times V$ comprise our dataset. Let $0<q<1$ and $f^*\\in H$ be the unique\nglobal minimizer of the functional \\begin{equation*} u(f) = \\frac{q}{2}\\Vert\nf\\Vert_{H}^{2} + \\frac{1-q}{2n}\\sum_{i=1}^{n}\\Vert f(x_i)-y_i\\Vert_{V}^{2}.\n\\end{equation*}\n  In this paper we show that for each $k\\in\\mathbb{N}$ there exists a two layer\nnetwork where the first layer has $k$ functions which are Riesz representations\nin the Hilbert space $H$ of point evaluation functionals and the second layer\nis a weighted sum of the first layer, such that the functions $f_k$ realized by\nthese networks satisfy \\begin{equation*} \\Vert f_{k}-f^*\\Vert_{H}^{2} \\leq\n\\Bigl( o(1) + \\frac{C}{q^2} E\\bigl[ \\Vert Du_{I}(f^*)\\Vert_{H^{*}}^{2} \\bigr]\n\\Bigr)\\frac{1}{k}. \\end{equation*}\n  %Let us note that $x_i$ do not need to be in a linear space and $y_i$ are in\na possibly infinite dimensional Hilbert space $V$. %The error estimate is\nindependent of the data size $n$ and in the case $V$ is finite dimensional %the\nerror estimate is also independent of the dimension of $V$.\n  By choosing the Hilbert space $H$ appropriately, the computational complexity\nof evaluating the Riesz representations of point evaluations might be small and\nthus the network has low computational complexity.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 16:36:50 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 12:45:35 GMT"}, {"version": "v3", "created": "Mon, 10 Dec 2018 11:19:03 GMT"}, {"version": "v4", "created": "Fri, 12 Jul 2019 14:00:21 GMT"}, {"version": "v5", "created": "Sun, 21 Jul 2019 07:11:59 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Yeressian", "Karen", ""]]}, {"id": "1809.00596", "submitter": "Ying Huang", "authors": "Ying Huang, Jiyang Dai, Chen Peng", "title": "Optimization Design of Decentralized Control for Complex Decentralized\n  Systems", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A new method is developed to deal with the problem that a complex\ndecentralized control system needs to keep centralized control performance. The\nsystematic procedure emphasizes quickly finding the decentralized\nsubcontrollers that matching the closed-loop performance and robustness\ncharacteristics of the centralized controller, which is featured by the fact\nthat GA is used to optimize the design of centralized H-infinity controller\nK(s) and decentralized engine subcontroller KT(s), and that only one interface\nvariable needs to satisfy decentralized control system requirement according to\nthe proposed selection principle. The optimization design is motivated by the\nimplementation issues where it is desirable to reduce the time in trial and\nerror process and accurately find the best decentralized subcontrollers. The\nmethod is applied to decentralized control system design for a short takeoff\nand landing fighter. By comparing the simulation results of the decentralized\ncontrol system with those of the centralized control system, the target of the\ndecentralized control attains the performance and robustness of centralized\ncontrol is validated.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 13:28:51 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Huang", "Ying", ""], ["Dai", "Jiyang", ""], ["Peng", "Chen", ""]]}, {"id": "1809.00837", "submitter": "Dan Dai", "authors": "Dan Dai, Zhiwen Yu, Yang Hu, Wenming Cao, Mingnan Luo", "title": "Metabolize Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The metabolism of cells is the most basic and important part of human\nfunction. Neural networks in deep learning stem from neuronal activity. It is\nself-evident that the significance of metabolize neuronal network(MetaNet) in\nmodel construction. In this study, we explore neuronal metabolism for shallow\nnetwork from proliferation and autophagy two aspects. First, we propose\ndifferent neuron proliferate methods that constructive the selfgrowing network\nin metabolism cycle. Proliferate neurons alleviate resources wasting and\ninsufficient model learning problem when network initializes more or less\nparameters. Then combined with autophagy mechanism in the process of model self\nconstruction to ablate under-expressed neurons. The MetaNet can automatically\ndetermine the number of neurons during training, further, save more resource\nconsumption. We verify the performance of the proposed methods on datasets:\nMNIST, Fashion-MNIST and CIFAR-10.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 08:42:52 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Dai", "Dan", ""], ["Yu", "Zhiwen", ""], ["Hu", "Yang", ""], ["Cao", "Wenming", ""], ["Luo", "Mingnan", ""]]}, {"id": "1809.00927", "submitter": "Hossein Sabzian", "authors": "Hossein Sabzian, Ehsan Kamrani, Seyyed Mostafa Seyyed Hashemi", "title": "A Neural Network Model for Determining the Success or Failure of\n  High-tech Projects Development: A Case of Pharmaceutical industry", "comments": "23 Pages, 6 Figures, 6 Tables, 33 Equations. arXiv admin note: text\n  overlap with arXiv:1805.10307", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financing high-tech projects always entails a great deal of risk. The lack of\na systematic method to pinpoint the risk of such projects has been recognized\nas one of the most salient barriers for evaluating them. So, in order to\ndevelop a mechanism for evaluating high-tech projects, an Artificial Neural\nNetwork (ANN) has been developed through this study. The structure of this\npaper encompasses four parts. The first part deals with introducing paper's\nwhole body. The second part gives a literature review. The collection process\nof risk related variables and the process of developing a Risk Assessment Index\nsystem (RAIS) through Principal Component Analysis (PCA) are those issues that\nare discussed in the third part. The fourth part particularly deals with\npharmaceutical industry. Finally, the fifth part has focused on developing an\nANN for pattern recognition of failure or success of high-tech projects.\nAnalysis of model's results and a final conclusion are also presented in this\npart.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 12:54:13 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Sabzian", "Hossein", ""], ["Kamrani", "Ehsan", ""], ["Hashemi", "Seyyed Mostafa Seyyed", ""]]}, {"id": "1809.01674", "submitter": "Erfan Nozari", "authors": "Erfan Nozari, Jorge Cort\\'es", "title": "Hierarchical Selective Recruitment in Linear-Threshold Brain Networks,\n  Part I: Single-Layer Dynamics and Selective Inhibition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NE cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-driven selective attention (GDSA) refers to the brain's function of\nprioritizing the activity of a task-relevant subset of its overall network to\nefficiently process relevant information while inhibiting the effects of\ndistractions. Despite decades of research in neuroscience, a comprehensive\nunderstanding of GDSA is still lacking. We propose a novel framework using\nconcepts and tools from control theory as well as insights and structures from\nneuroscience. Central to this framework is an information-processing hierarchy\nwith two main components: selective inhibition of task-irrelevant activity and\ntop-down recruitment of task-relevant activity. We analyze the internal\ndynamics of each layer of the hierarchy described as a network with\nlinear-threshold dynamics and derive conditions on its structure to guarantee\nexistence and uniqueness of equilibria, asymptotic stability, and boundedness\nof trajectories. We also provide mechanisms that enforce selective inhibition\nusing the biologically-inspired schemes of feedforward and feedback inhibition.\nDespite their differences, both lead to the same conclusion: the intrinsic\ndynamical properties of the (not-inhibited) task-relevant subnetworks are the\nsole determiner of the dynamical properties that are achievable under selective\ninhibition.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 18:03:51 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 16:10:54 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 22:29:19 GMT"}, {"version": "v4", "created": "Fri, 18 Dec 2020 18:25:51 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Nozari", "Erfan", ""], ["Cort\u00e9s", "Jorge", ""]]}, {"id": "1809.01942", "submitter": "Augusto Luis Ballardini", "authors": "Augusto Luis Ballardini", "title": "A tutorial on Particle Swarm Optimization Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a tutorial on the Data Clustering technique using the\nParticle Swarm Optimization approach. Following the work proposed by Merwe et\nal. here we present an in-deep analysis of the algorithm together with a Matlab\nimplementation and a short tutorial that explains how to modify the proposed\nimplementation and the effect of the parameters of the original algorithm.\nMoreover, we provide a comparison against the results obtained using the well\nknown K-Means approach. All the source code presented in this paper is publicly\navailable under the GPL-v2 license.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 12:24:44 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Ballardini", "Augusto Luis", ""]]}, {"id": "1809.02032", "submitter": "Tristan Aumentado-Armstrong", "authors": "Tristan Aumentado-Armstrong", "title": "Latent Molecular Optimization for Targeted Therapeutic Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE q-bio.BM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We devise an approach for targeted molecular design, a problem of interest in\ncomputational drug discovery: given a target protein site, we wish to generate\na chemical with both high binding affinity to the target and satisfactory\npharmacological properties. This problem is made difficult by the enormity and\ndiscreteness of the space of potential therapeutics, as well as the\ngraph-structured nature of biomolecular surface sites. Using a dataset of\nprotein-ligand complexes, we surmount these issues by extracting a signature of\nthe target site with a graph convolutional network and by encoding the discrete\nchemical into a continuous latent vector space. The latter embedding permits\ngradient-based optimization in molecular space, which we perform using learned\ndifferentiable models of binding affinity and other pharmacological properties.\nWe show that our approach is able to efficiently optimize these multiple\nobjectives and discover new molecules with potentially useful binding\nproperties, validated via docking methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 17:19:41 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Aumentado-Armstrong", "Tristan", ""]]}, {"id": "1809.02393", "submitter": "Yanghoon Kim", "authors": "Yanghoon Kim and Hwanhee Lee and Joongbo Shin and Kyomin Jung", "title": "Improving Neural Question Generation using Answer Separation", "comments": "The paper is accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural question generation (NQG) is the task of generating a question from a\ngiven passage with deep neural networks. Previous NQG models suffer from a\nproblem that a significant proportion of the generated questions include words\nin the question target, resulting in the generation of unintended questions. In\nthis paper, we propose answer-separated seq2seq, which better utilizes the\ninformation from both the passage and the target answer. By replacing the\ntarget answer in the original passage with a special token, our model learns to\nidentify which interrogative word should be used. We also propose a new module\ntermed keyword-net, which helps the model better capture the key information in\nthe target answer and generate an appropriate question. Experimental results\ndemonstrate that our answer separation method significantly reduces the number\nof improper questions which include answers. Consequently, our model\nsignificantly outperforms previous state-of-the-art NQG models.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 10:35:42 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 01:43:12 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Kim", "Yanghoon", ""], ["Lee", "Hwanhee", ""], ["Shin", "Joongbo", ""], ["Jung", "Kyomin", ""]]}, {"id": "1809.02440", "submitter": "Hugo Richard", "authors": "Hugo Richard (PARIETAL), Ana Pinho (NEUROSPIN), Bertrand Thirion\n  (PARIETAL), Guillaume Charpiat (TAU)", "title": "Optimizing deep video representation to match brain activity", "comments": null, "journal-ref": "2018 Conference on Cognitive Computational Neuroscience, Sep 2018,\n  Philadelphia, United States", "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The comparison of observed brain activity with the statistics generated by\nartificial intelligence systems is useful to probe brain functional\norganization under ecological conditions. Here we study fMRI activity in ten\nsubjects watching color natural movies and compute deep representations of\nthese movies with an architecture that relies on optical flow and image\ncontent. The association of activity in visual areas with the different layers\nof the deep architecture displays complexity-related contrasts across visual\nareas and reveals a striking foveal/peripheral dichotomy.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 12:37:50 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Richard", "Hugo", "", "PARIETAL"], ["Pinho", "Ana", "", "NEUROSPIN"], ["Thirion", "Bertrand", "", "PARIETAL"], ["Charpiat", "Guillaume", "", "TAU"]]}, {"id": "1809.02444", "submitter": "Lei Ma", "authors": "Alvin Chan, Lei Ma, Felix Juefei-Xu, Xiaofei Xie, Yang Liu, and Yew\n  Soon Ong", "title": "Metamorphic Relation Based Adversarial Attacks on Differentiable Neural\n  Computer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN), while becoming the driving force of many novel\ntechnology and achieving tremendous success in many cutting-edge applications,\nare still vulnerable to adversarial attacks. Differentiable neural computer\n(DNC) is a novel computing machine with DNN as its central controller operating\non an external memory module for data processing. The unique architecture of\nDNC contributes to its state-of-the-art performance in tasks which requires the\nability to represent variables and data structure as well as to store data over\nlong timescales. However, there still lacks a comprehensive study on how\nadversarial examples affect DNC in terms of robustness. In this paper, we\npropose metamorphic relation based adversarial techniques for a range of tasks\ndescribed in the natural processing language domain. We show that the\nnear-perfect performance of the DNC in bAbI logical question answering tasks\ncan be degraded by adversarially injected sentences. We further perform\nin-depth study on the role of DNC's memory size in its robustness and analyze\nthe potential reason causing why DNC fails. Our study demonstrates the current\nchallenges and potential opportunities towards constructing more robust DNCs.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 12:44:19 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Chan", "Alvin", ""], ["Ma", "Lei", ""], ["Juefei-Xu", "Felix", ""], ["Xie", "Xiaofei", ""], ["Liu", "Yang", ""], ["Ong", "Yew Soon", ""]]}, {"id": "1809.02493", "submitter": "Erfan Nozari", "authors": "Erfan Nozari, Jorge Cort\\'es", "title": "Hierarchical Selective Recruitment in Linear-Threshold Brain Networks,\n  Part II: Multi-Layer Dynamics and Top-Down Recruitment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NE cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-driven selective attention (GDSA) is a remarkable function that allows\nthe complex dynamical networks of the brain to support coherent perception and\ncognition. Part I of this two-part paper proposes a new control-theoretic\nframework, termed hierarchical selective recruitment (HSR), to rigorously\nexplain the emergence of GDSA from the brain's network structure and dynamics.\nThis part completes the development of HSR by deriving conditions on the joint\nstructure of the hierarchical subnetworks that guarantee top-down recruitment\nof the task-relevant part of each subnetwork by the subnetwork at the layer\nimmediately above, while inhibiting the activity of task-irrelevant subnetworks\nat all the hierarchical layers. To further verify the merit and applicability\nof this framework, we carry out a comprehensive case study of selective\nlistening in rodents and show that a small network with HSR-based structure and\nminimal size can explain the data with remarkable accuracy while satisfying the\ntheoretical requirements of HSR. Our technical approach relies on the theory of\nswitched systems and provides a novel converse Lyapunov theorem for\nstate-dependent switched affine systems that is of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 18:03:14 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 16:20:32 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 22:36:47 GMT"}, {"version": "v4", "created": "Fri, 18 Dec 2020 18:31:13 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Nozari", "Erfan", ""], ["Cort\u00e9s", "Jorge", ""]]}, {"id": "1809.02572", "submitter": "Jeffrey Shainline", "authors": "Jeffrey M. Shainline", "title": "The largest cognitive systems will be optoelectronic", "comments": "10 pages, 5 figures, ICRC 2018 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE physics.app-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrons and photons offer complementary strengths for information\nprocessing. Photons are excellent for communication, while electrons are\nsuperior for computation and memory. Cognition requires distributed computation\nto be communicated across the system for information integration. We present\nreasoning from neuroscience, network theory, and device physics supporting the\nconjecture that large-scale cognitive systems will benefit from electronic\ndevices performing synaptic, dendritic, and neuronal information processing\noperating in conjunction with photonic communication. On the chip scale,\nintegrated dielectric waveguides enable fan-out to thousands of connections. On\nthe system scale, fiber and free-space optics can be employed. The largest\ncognitive systems will be limited by the distance light can travel during the\nperiod of a network oscillation. We calculate that optoelectronic networks the\narea of a large data center ($10^5$\\,m$^2$) will be capable of system-wide\ninformation integration at $1$\\,MHz. At frequencies of cortex-wide integration\nin the human brain ($4$\\,Hz, theta band), optoelectronic systems could\nintegrate information across the surface of the earth.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 16:45:38 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Shainline", "Jeffrey M.", ""]]}, {"id": "1809.02627", "submitter": "Arthur Juliani", "authors": "Arthur Juliani, Vincent-Pierre Berges, Ervin Teng, Andrew Cohen,\n  Jonathan Harper, Chris Elion, Chris Goy, Yuan Gao, Hunter Henry, Marwan\n  Mattar, Danny Lange", "title": "Unity: A General Platform for Intelligent Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in artificial intelligence have been driven by the presence\nof increasingly realistic and complex simulated environments. However, many of\nthe existing environments provide either unrealistic visuals, inaccurate\nphysics, low task complexity, restricted agent perspective, or a limited\ncapacity for interaction among artificial agents. Furthermore, many platforms\nlack the ability to flexibly configure the simulation, making the simulated\nenvironment a black-box from the perspective of the learning system. In this\nwork, we propose a novel taxonomy of existing simulation platforms and discuss\nthe highest level class of general platforms which enable the development of\nlearning environments that are rich in visual, physical, task, and social\ncomplexity. We argue that modern game engines are uniquely suited to act as\ngeneral platforms and as a case study examine the Unity engine and open source\nUnity ML-Agents Toolkit. We then survey the research enabled by Unity and the\nUnity ML-Agents Toolkit, discussing the kinds of research a flexible,\ninteractive and easily configurable general platform can facilitate.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 18:13:25 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 17:59:11 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Juliani", "Arthur", ""], ["Berges", "Vincent-Pierre", ""], ["Teng", "Ervin", ""], ["Cohen", "Andrew", ""], ["Harper", "Jonathan", ""], ["Elion", "Chris", ""], ["Goy", "Chris", ""], ["Gao", "Yuan", ""], ["Henry", "Hunter", ""], ["Mattar", "Marwan", ""], ["Lange", "Danny", ""]]}, {"id": "1809.02651", "submitter": "Samiran Ganguly", "authors": "Samiran Ganguly, Yunfei Gu, Yunkun Xie, Mircea R. Stan, Avik W. Ghosh,\n  Nibir K. Dhar", "title": "Reservoir Computing based Neural Image Filters", "comments": "5 pages, 4 figures, To appear in Conference Proceedings of The 44th\n  Annual Conference of IEEE Industrial Electronics Society (2018): Special\n  Session on Machine Vision, Control and Navigation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clean images are an important requirement for machine vision systems to\nrecognize visual features correctly. However, the environment, optics,\nelectronics of the physical imaging systems can introduce extreme distortions\nand noise in the acquired images. In this work, we explore the use of reservoir\ncomputing, a dynamical neural network model inspired from biological systems,\nin creating dynamic image filtering systems that extracts signal from noise\nusing inverse modeling. We discuss the possibility of implementing these\nnetworks in hardware close to the sensors.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 19:58:53 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Ganguly", "Samiran", ""], ["Gu", "Yunfei", ""], ["Xie", "Yunkun", ""], ["Stan", "Mircea R.", ""], ["Ghosh", "Avik W.", ""], ["Dhar", "Nibir K.", ""]]}, {"id": "1809.02721", "submitter": "Marcelo Prates", "authors": "Marcelo O. R. Prates, Pedro H. C. Avelar, Henrique Lemos, Luis Lamb,\n  Moshe Vardi", "title": "Learning to Solve NP-Complete Problems - A Graph Neural Network for\n  Decision TSP", "comments": "Accepted for presentation at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNN) are a promising technique for bridging\ndifferential programming and combinatorial domains. GNNs employ trainable\nmodules which can be assembled in different configurations that reflect the\nrelational structure of each problem instance. In this paper, we show that GNNs\ncan learn to solve, with very little supervision, the decision variant of the\nTraveling Salesperson Problem (TSP), a highly relevant $\\mathcal{NP}$-Complete\nproblem. Our model is trained to function as an effective message-passing\nalgorithm in which edges (embedded with their weights) communicate with\nvertices for a number of iterations after which the model is asked to decide\nwhether a route with cost $<C$ exists. We show that such a network can be\ntrained with sets of dual examples: given the optimal tour cost $C^{*}$, we\nproduce one decision instance with target cost $x\\%$ smaller and one with\ntarget cost $x\\%$ larger than $C^{*}$. We were able to obtain $80\\%$ accuracy\ntraining with $-2\\%,+2\\%$ deviations, and the same trained model can generalize\nfor more relaxed deviations with increasing performance. We also show that the\nmodel is capable of generalizing for larger problem sizes. Finally, we provide\na method for predicting the optimal route cost within $2\\%$ deviation from the\nground truth. In summary, our work shows that Graph Neural Networks are\npowerful enough to solve $\\mathcal{NP}$-Complete problems which combine\nsymbolic and numeric data.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 00:11:51 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 18:02:19 GMT"}, {"version": "v3", "created": "Fri, 16 Nov 2018 12:10:20 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Prates", "Marcelo O. R.", ""], ["Avelar", "Pedro H. C.", ""], ["Lemos", "Henrique", ""], ["Lamb", "Luis", ""], ["Vardi", "Moshe", ""]]}, {"id": "1809.02731", "submitter": "Shuai Tang", "authors": "Shuai Tang, Virginia R. de Sa", "title": "Exploiting Invertible Decoders for Unsupervised Sentence Representation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The encoder-decoder models for unsupervised sentence representation learning\ntend to discard the decoder after being trained on a large unlabelled corpus,\nsince only the encoder is needed to map the input sentence into a vector\nrepresentation. However, parameters learnt in the decoder also contain useful\ninformation about language. In order to utilise the decoder after learning, we\npresent two types of decoding functions whose inverse can be easily derived\nwithout expensive inverse calculation. Therefore, the inverse of the decoding\nfunction serves as another encoder that produces sentence representations. We\nshow that, with careful design of the decoding functions, the model learns good\nsentence representations, and the ensemble of the representations produced from\nthe encoder and the inverse of the decoder demonstrate even better\ngeneralisation ability and solid transferability.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 01:20:45 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 00:35:49 GMT"}, {"version": "v3", "created": "Fri, 31 May 2019 04:53:58 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Tang", "Shuai", ""], ["de Sa", "Virginia R.", ""]]}, {"id": "1809.02836", "submitter": "Yiding Hao", "authors": "Yiding Hao, William Merrill, Dana Angluin, Robert Frank, Noah Amsel,\n  Andrew Benz, and Simon Mendelsohn", "title": "Context-Free Transductions with Neural Stacks", "comments": "To appear in the proceedings of the Analyzing and Interpreting Neural\n  Networks for NLP workshop at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the behavior of stack-augmented recurrent neural network\n(RNN) models. Due to the architectural similarity between stack RNNs and\npushdown transducers, we train stack RNN models on a number of tasks, including\nstring reversal, context-free language modelling, and cumulative XOR\nevaluation. Examining the behavior of our networks, we show that\nstack-augmented RNNs can discover intuitive stack-based strategies for solving\nour tasks. However, stack RNNs are more difficult to train than classical\narchitectures such as LSTMs. Rather than employ stack-based strategies, more\ncomplex networks often find approximate solutions by using the stack as\nunstructured memory.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 17:04:53 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Hao", "Yiding", ""], ["Merrill", "William", ""], ["Angluin", "Dana", ""], ["Frank", "Robert", ""], ["Amsel", "Noah", ""], ["Benz", "Andrew", ""], ["Mendelsohn", "Simon", ""]]}, {"id": "1809.02942", "submitter": "William Gilpin", "authors": "William Gilpin", "title": "Cellular automata as convolutional neural networks", "comments": "8 pages, 4 figures (+Appendix)", "journal-ref": "Phys. Rev. E 100, 032402 (2019)", "doi": "10.1103/PhysRevE.100.032402", "report-no": null, "categories": "nlin.CG cond-mat.dis-nn cs.NE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques have recently demonstrated broad success in\npredicting complex dynamical systems ranging from turbulence to human speech,\nmotivating broader questions about how neural networks encode and represent\ndynamical rules. We explore this problem in the context of cellular automata\n(CA), simple dynamical systems that are intrinsically discrete and thus\ndifficult to analyze using standard tools from dynamical systems theory. We\nshow that any CA may readily be represented using a convolutional neural\nnetwork with a network-in-network architecture. This motivates our development\nof a general convolutional multilayer perceptron architecture, which we find\ncan learn the dynamical rules for arbitrary CA when given videos of the CA as\ntraining data. In the limit of large network widths, we find that training\ndynamics are nearly identical across replicates, and that common patterns\nemerge in the structure of networks trained on different CA rulesets. We train\nensembles of networks on randomly-sampled CA, and we probe how the trained\nnetworks internally represent the CA rules using an information-theoretic\ntechnique based on distributions of layer activation patterns. We find that CA\nwith simpler rule tables produce trained networks with hierarchical structure\nand layer specialization, while more complex CA produce shallower\nrepresentations---illustrating how the underlying complexity of the CA's rules\ninfluences the specificity of these internal representations. Our results\nsuggest how the entropy of a physical process can affect its representation\nwhen learned by neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 08:54:02 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 21:02:18 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Gilpin", "William", ""]]}, {"id": "1809.03008", "submitter": "Kai Xiao", "authors": "Kai Y. Xiao, Vincent Tjeng, Nur Muhammad Shafiullah, Aleksander Madry", "title": "Training for Faster Adversarial Robustness Verification via Inducing\n  ReLU Stability", "comments": null, "journal-ref": "International Conference on Learning Representations (ICLR) 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the concept of co-design in the context of neural network\nverification. Specifically, we aim to train deep neural networks that not only\nare robust to adversarial perturbations but also whose robustness can be\nverified more easily. To this end, we identify two properties of network models\n- weight sparsity and so-called ReLU stability - that turn out to significantly\nimpact the complexity of the corresponding verification task. We demonstrate\nthat improving weight sparsity alone already enables us to turn computationally\nintractable verification problems into tractable ones. Then, improving ReLU\nstability leads to an additional 4-13x speedup in verification times. An\nimportant feature of our methodology is its \"universality,\" in the sense that\nit can be used with a broad range of training procedures and verification\napproaches.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 17:10:16 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 17:58:07 GMT"}, {"version": "v3", "created": "Tue, 23 Apr 2019 21:04:31 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Xiao", "Kai Y.", ""], ["Tjeng", "Vincent", ""], ["Shafiullah", "Nur Muhammad", ""], ["Madry", "Aleksander", ""]]}, {"id": "1809.03055", "submitter": "T\\\"urker Tuncer", "authors": "Turker Tuncer", "title": "LDW-SCSA: Logistic Dynamic Weight based Sine Cosine Search Algorithm for\n  Numerical Functions Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle swarm optimization (PSO) and Sine Cosine algorithm (SCA) have been\nwidely used optimization methods but these methods have some disadvantages such\nas trapped local optimum point. In order to solve this problem and obtain more\nsuccessful results than others, a novel logistic dynamic weight based sine\ncosine search algorithm (LDW-SCSA) is presented in this paper. In the LDW-SCSA\nmethod, logistic map is used as dynamic weight generator. Logistic map is one\nof the famous and widely used chaotic map in the literature. Search process of\nSCA is modified in the LDW-SCSA. To evaluate performance of the LDW-SCSA, the\nwidely used numerical benchmark functions were utilized as test suite and other\nswarm optimization methods were used to obtain the comparison results. Superior\nperformances of the LDW-SCSA are proved success of this method.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 22:41:57 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Tuncer", "Turker", ""]]}, {"id": "1809.03142", "submitter": "Seongsik Park", "authors": "Seongsik Park, Seijoon Kim, Hyeokjun Choe, Sungroh Yoon", "title": "Fast and Efficient Information Transmission with Burst Spikes in Deep\n  Spiking Neural Networks", "comments": "Accepted to DAC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spiking neural networks (SNNs) are considered as one of the most\npromising artificial neural networks due to their energy efficient computing\ncapability. Recently, conversion of a trained deep neural network to an SNN has\nimproved the accuracy of deep SNNs. However, most of the previous studies have\nnot achieved satisfactory results in terms of inference speed and energy\nefficiency. In this paper, we propose a fast and energy-efficient information\ntransmission method with burst spikes and hybrid neural coding scheme in deep\nSNNs. Our experimental results showed the proposed methods can improve\ninference energy efficiency and shorten the latency.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 05:42:18 GMT"}, {"version": "v2", "created": "Sun, 10 Feb 2019 12:16:19 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Park", "Seongsik", ""], ["Kim", "Seijoon", ""], ["Choe", "Hyeokjun", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1809.03242", "submitter": "Honglei Zhang", "authors": "Honglei Zhang, Serkan Kiranyaz, Moncef Gabbouj", "title": "Finding Better Topologies for Deep Convolutional Neural Networks by\n  Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the nonlinearity of artificial neural networks, designing topologies\nfor deep convolutional neural networks (CNN) is a challenging task and often\nonly heuristic approach, such as trial and error, can be applied. An\nevolutionary algorithm can solve optimization problems where the fitness\nlandscape is unknown. However, evolutionary algorithms are computing resource\nintensive, which makes it difficult for problems when deep CNNs are involved.\nIn this paper, we propose an evolutionary strategy to find better topologies\nfor deep CNNs. Incorporating the concept of knowledge inheritance and knowledge\nlearning, our evolutionary algorithm can be executed with limited computing\nresources. We applied the proposed algorithm in finding effective topologies of\ndeep CNNs for the image classification task using CIFAR-10 dataset. After the\nevolution, we analyzed the topologies that performed well for this task. Our\nstudies verify the techniques that have been commonly used in human designed\ndeep CNNs. We also discovered that some of the graph properties greatly affect\nthe system performance. We applied the guidelines learned from the evolution\nand designed new network topologies that outperform Residual Net with less\nlayers on CIFAR-10, CIFAR-100, and SVHN dataset.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 11:36:22 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Zhang", "Honglei", ""], ["Kiranyaz", "Serkan", ""], ["Gabbouj", "Moncef", ""]]}, {"id": "1809.03330", "submitter": "Stefano Rosa", "authors": "Zhihua Wang, Stefano Rosa, Yishu Miao, Zihang Lai, Linhai Xie, Andrew\n  Markham, Niki Trigoni", "title": "Neural Allocentric Intuitive Physics Prediction from Real Videos", "comments": "Added references, minor changes. arXiv admin note: text overlap with\n  arXiv:1506.02025 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are able to make rich predictions about the future dynamics of\nphysical objects from a glance. On the other hand, most existing computer\nvision approaches require strong assumptions about the underlying system,\nad-hoc modeling, or annotated datasets, to carry out even simple predictions.\nTo tackle this gap, we propose a new perspective on the problem of learning\nintuitive physics that is inspired by the spatial memory representation of\nobjects and spaces in human brains, in particular the co-existence of\negocentric and allocentric spatial representations. We present a generic\nframework that learns a layered representation of the physical world, using a\ncascade of invertible modules. In this framework, real images are first\nconverted to a synthetic domain representation that reduces complexity arising\nfrom lighting and texture. Then, an allocentric viewpoint transformer removes\nviewpoint complexity by projecting images to a canonical view. Finally, a novel\nRecurrent Latent Variation Network (RLVN) architecture learns the dynamics of\nthe objects interacting with the environment and predicts future motion,\nleveraging the availability of unlimited synthetic simulations. Predicted\nframes are then projected back to the original camera view and translated back\nto the real world domain. Experimental results show the ability of the\nframework to consistently and accurately predict several frames in the future\nand the ability to adapt to real images.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 10:33:56 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 12:05:28 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Wang", "Zhihua", ""], ["Rosa", "Stefano", ""], ["Miao", "Yishu", ""], ["Lai", "Zihang", ""], ["Xie", "Linhai", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""]]}, {"id": "1809.03646", "submitter": "Felipe Campelo", "authors": "\\'Athila R. Trindade and Felipe Campelo", "title": "Tuning metaheuristics by sequential optimization of regression models", "comments": "22 pages. 3 figures. Submitted to Information Sciences", "journal-ref": "Applied Soft Computing Volume 85, December 2019, 105829", "doi": "10.1016/j.asoc.2019.105829", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuning parameters is an important step for the application of metaheuristics\nto problem classes of interest. In this work we present a tuning framework\nbased on the sequential optimization of perturbed regression models. Besides\nproviding algorithm configurations with good expected performance, the proposed\nmethodology can also provide insights on the relevance of each parameter and\ntheir interactions, as well as models of expected algorithm performance for a\ngiven problem class, conditional on the parameter values. A test case is\npresented for the tuning of six parameters of a decomposition-based\nmultiobjective optimization algorithm, in which an instantiation of the\nproposed framework is compared against the results obtained by the most recent\nversion the Iterated Racing (Irace) procedure. The results suggest that the\nproposed approach returns solutions that are as good as those of Irace in terms\nof mean performance, with the advantage of providing more information on the\nrelevance and effect of each parameter on the expected performance of the\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 01:06:12 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 16:50:55 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Trindade", "\u00c1thila R.", ""], ["Campelo", "Felipe", ""]]}, {"id": "1809.03721", "submitter": "Seungjoon Yang", "authors": "Jinhyeok Jang, Hyunjoong Cho, Jaehong Kim, Jaeyeon Lee, and Seungjoon\n  Yang", "title": "Deep Asymmetric Networks with a Set of Node-wise Variant Activation\n  Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents deep asymmetric networks with a set of node-wise variant\nactivation functions. The nodes' sensitivities are affected by activation\nfunction selections such that the nodes with smaller indices become\nincreasingly more sensitive. As a result, features learned by the nodes are\nsorted by the node indices in the order of their importance. Asymmetric\nnetworks not only learn input features but also the importance of those\nfeatures. Nodes of lesser importance in asymmetric networks can be pruned to\nreduce the complexity of the networks, and the pruned networks can be retrained\nwithout incurring performance losses. We validate the feature-sorting property\nusing both shallow and deep asymmetric networks as well as deep asymmetric\nnetworks transferred from famous networks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 08:09:25 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 07:24:15 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Jang", "Jinhyeok", ""], ["Cho", "Hyunjoong", ""], ["Kim", "Jaehong", ""], ["Lee", "Jaeyeon", ""], ["Yang", "Seungjoon", ""]]}, {"id": "1809.03864", "submitter": "Ramin M. Hasani", "authors": "Ramin M. Hasani, Alexander Amini, Mathias Lechner, Felix Naser, Radu\n  Grosu, Daniela Rus", "title": "Response Characterization for Auditing Cell Dynamics in Long Short-term\n  Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel method to interpret recurrent neural\nnetworks (RNNs), particularly long short-term memory networks (LSTMs) at the\ncellular level. We propose a systematic pipeline for interpreting individual\nhidden state dynamics within the network using response characterization\nmethods. The ranked contribution of individual cells to the network's output is\ncomputed by analyzing a set of interpretable metrics of their decoupled step\nand sinusoidal responses. As a result, our method is able to uniquely identify\nneurons with insightful dynamics, quantify relationships between dynamical\nproperties and test accuracy through ablation analysis, and interpret the\nimpact of network capacity on a network's dynamical distribution. Finally, we\ndemonstrate generalizability and scalability of our method by evaluating a\nseries of different benchmark sequential datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 13:27:36 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Hasani", "Ramin M.", ""], ["Amini", "Alexander", ""], ["Lechner", "Mathias", ""], ["Naser", "Felix", ""], ["Grosu", "Radu", ""], ["Rus", "Daniela", ""]]}, {"id": "1809.03956", "submitter": "Jinsheng Ren", "authors": "Fei Deng, Jinsheng Ren, Feng Chen", "title": "Abstraction Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a gap between artificial intelligence and human intelligence.\nIn this paper, we identify three key elements forming human intelligence, and\nsuggest that abstraction learning combines these elements and is thus a way to\nbridge the gap. Prior researches in artificial intelligence either specify\nabstraction by human experts, or take abstraction as a qualitative explanation\nfor the model. This paper aims to learn abstraction directly. We tackle three\nmain challenges: representation, objective function, and learning algorithm.\nSpecifically, we propose a partition structure that contains pre-allocated\nabstraction neurons; we formulate abstraction learning as a constrained\noptimization problem, which integrates abstraction properties; we develop a\nnetwork evolution algorithm to solve this problem. This complete framework is\nnamed ONE (Optimization via Network Evolution). In our experiments on MNIST,\nONE shows elementary human-like intelligence, including low energy consumption,\nknowledge sharing, and lifelong learning.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 15:02:24 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Deng", "Fei", ""], ["Ren", "Jinsheng", ""], ["Chen", "Feng", ""]]}, {"id": "1809.04166", "submitter": "C. Daniel Greenidge", "authors": "C. Daniel Greenidge, Noam Miller, and Kenneth A. Norman", "title": "Leabra7: a Python package for modeling recurrent, biologically-realistic\n  neural networks", "comments": "Fix minor typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergent is a software package that uses the AdEx neural dynamics model and\nLEABRA learning algorithm to simulate and train arbitrary recurrent neural\nnetwork architectures in a biologically-realistic manner. We present Leabra7, a\ncomplementary Python library that implements these same algorithms. Leabra7 is\ndeveloped and distributed using modern software development principles, and\nintegrates tightly with Python's scientific stack. We demonstrate recurrent\nLeabra7 networks using traditional pattern-association tasks and a standard\nmachine learning task, classifying the IRIS dataset.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 21:09:25 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 23:17:17 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Greenidge", "C. Daniel", ""], ["Miller", "Noam", ""], ["Norman", "Kenneth A.", ""]]}, {"id": "1809.04397", "submitter": "Krishan Rajaratnam", "authors": "Krishan Rajaratnam and Kunal Shah and Jugal Kalita", "title": "Isolated and Ensemble Audio Preprocessing Methods for Detecting\n  Adversarial Examples against Automatic Speech Recognition", "comments": "Accepted for oral presentation at the 30th Conference on\n  Computational Linguistics and Speech Processing (ROCLING 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.CR cs.LG cs.NE eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adversarial attack is an exploitative process in which minute alterations\nare made to natural inputs, causing the inputs to be misclassified by neural\nmodels. In the field of speech recognition, this has become an issue of\nincreasing significance. Although adversarial attacks were originally\nintroduced in computer vision, they have since infiltrated the realm of speech\nrecognition. In 2017, a genetic attack was shown to be quite potent against the\nSpeech Commands Model. Limited-vocabulary speech classifiers, such as the\nSpeech Commands Model, are used in a variety of applications, particularly in\ntelephony; as such, adversarial examples produced by this attack pose as a\nmajor security threat. This paper explores various methods of detecting these\nadversarial examples with combinations of audio preprocessing. One particular\ncombined defense incorporating compressions, speech coding, filtering, and\naudio panning was shown to be quite effective against the attack on the Speech\nCommands Model, detecting audio adversarial examples with 93.5% precision and\n91.2% recall.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 05:12:15 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Rajaratnam", "Krishan", ""], ["Shah", "Kunal", ""], ["Kalita", "Jugal", ""]]}, {"id": "1809.04423", "submitter": "Ramin M. Hasani", "authors": "Ramin Hasani, Mathias Lechner, Alexander Amini, Daniela Rus, Radu\n  Grosu", "title": "Can a Compact Neuronal Circuit Policy be Re-purposed to Learn Simple\n  Robotic Control?", "comments": "arXiv admin note: substantial text overlap with arXiv:1803.08554", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural information processing system which is obtained by\nre-purposing the function of a biological neural circuit model, to govern\nsimulated and real-world control tasks. Inspired by the structure of the\nnervous system of the soil-worm, C. elegans, we introduce Neuronal Circuit\nPolicies (NCPs), defined as the model of biological neural circuits\nreparameterized for the control of an alternative task. We learn instances of\nNCPs to control a series of robotic tasks, including the autonomous parking of\na real-world rover robot. For reconfiguration of the purpose of the neural\ncircuit, we adopt a search-based optimization algorithm. Neuronal circuit\npolicies perform on par and in some cases surpass the performance of\ncontemporary deep learning models with the advantage leveraging significantly\nfewer learnable parameters and realizing interpretable dynamics at the\ncell-level.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 15:05:12 GMT"}, {"version": "v2", "created": "Sat, 16 Nov 2019 13:12:37 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Hasani", "Ramin", ""], ["Lechner", "Mathias", ""], ["Amini", "Alexander", ""], ["Rus", "Daniela", ""], ["Grosu", "Radu", ""]]}, {"id": "1809.04430", "submitter": "Stanislav Nikolov", "authors": "Stanislav Nikolov, Sam Blackwell, Alexei Zverovitch, Ruheena Mendes,\n  Michelle Livne, Jeffrey De Fauw, Yojan Patel, Clemens Meyer, Harry Askham,\n  Bernardino Romera-Paredes, Christopher Kelly, Alan Karthikesalingam, Carlton\n  Chu, Dawn Carnell, Cheng Boon, Derek D'Souza, Syed Ali Moinuddin, Bethany\n  Garie, Yasmin McQuinlan, Sarah Ireland, Kiarna Hampton, Krystle Fuller, Hugh\n  Montgomery, Geraint Rees, Mustafa Suleyman, Trevor Back, C\\'ian Hughes,\n  Joseph R. Ledsam, Olaf Ronneberger", "title": "Deep learning to achieve clinically applicable segmentation of head and\n  neck anatomy for radiotherapy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over half a million individuals are diagnosed with head and neck cancer each\nyear worldwide. Radiotherapy is an important curative treatment for this\ndisease, but it requires manual time consuming delineation of radio-sensitive\norgans at risk (OARs). This planning process can delay treatment, while also\nintroducing inter-operator variability with resulting downstream radiation dose\ndifferences. While auto-segmentation algorithms offer a potentially time-saving\nsolution, the challenges in defining, quantifying and achieving expert\nperformance remain. Adopting a deep learning approach, we demonstrate a 3D\nU-Net architecture that achieves expert-level performance in delineating 21\ndistinct head and neck OARs commonly segmented in clinical practice. The model\nwas trained on a dataset of 663 deidentified computed tomography (CT) scans\nacquired in routine clinical practice and with both segmentations taken from\nclinical practice and segmentations created by experienced radiographers as\npart of this research, all in accordance with consensus OAR definitions. We\ndemonstrate the model's clinical applicability by assessing its performance on\na test set of 21 CT scans from clinical practice, each with the 21 OARs\nsegmented by two independent experts. We also introduce surface Dice similarity\ncoefficient (surface DSC), a new metric for the comparison of organ\ndelineation, to quantify deviation between OAR surface contours rather than\nvolumes, better reflecting the clinical task of correcting errors in the\nautomated organ segmentations. The model's generalisability is then\ndemonstrated on two distinct open source datasets, reflecting different centres\nand countries to model training. With appropriate validation studies and\nregulatory approvals, this system could improve the efficiency, consistency,\nand safety of radiotherapy pathways.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 13:42:38 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 11:09:59 GMT"}, {"version": "v3", "created": "Wed, 13 Jan 2021 17:43:14 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Nikolov", "Stanislav", ""], ["Blackwell", "Sam", ""], ["Zverovitch", "Alexei", ""], ["Mendes", "Ruheena", ""], ["Livne", "Michelle", ""], ["De Fauw", "Jeffrey", ""], ["Patel", "Yojan", ""], ["Meyer", "Clemens", ""], ["Askham", "Harry", ""], ["Romera-Paredes", "Bernardino", ""], ["Kelly", "Christopher", ""], ["Karthikesalingam", "Alan", ""], ["Chu", "Carlton", ""], ["Carnell", "Dawn", ""], ["Boon", "Cheng", ""], ["D'Souza", "Derek", ""], ["Moinuddin", "Syed Ali", ""], ["Garie", "Bethany", ""], ["McQuinlan", "Yasmin", ""], ["Ireland", "Sarah", ""], ["Hampton", "Kiarna", ""], ["Fuller", "Krystle", ""], ["Montgomery", "Hugh", ""], ["Rees", "Geraint", ""], ["Suleyman", "Mustafa", ""], ["Back", "Trevor", ""], ["Hughes", "C\u00edan", ""], ["Ledsam", "Joseph R.", ""], ["Ronneberger", "Olaf", ""]]}, {"id": "1809.04461", "submitter": "Vinayakumar R", "authors": "Anu Vazhayil, Vinayakumar R and Soman KP", "title": "DeepProteomics: Protein family classification using Shallow and Deep\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The knowledge regarding the function of proteins is necessary as it gives a\nclear picture of biological processes. Nevertheless, there are many protein\nsequences found and added to the databases but lacks functional annotation. The\nlaboratory experiments take a considerable amount of time for annotation of the\nsequences. This arises the need to use computational techniques to classify\nproteins based on their functions. In our work, we have collected the data from\nSwiss-Prot containing 40433 proteins which is grouped into 30 families. We pass\nit to recurrent neural network(RNN), long short term memory(LSTM) and gated\nrecurrent unit(GRU) model and compare it by applying trigram with deep neural\nnetwork and shallow neural network on the same dataset. Through this approach,\nwe could achieve maximum of around 78% accuracy for the classification of\nprotein families.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 17:48:01 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Vazhayil", "Anu", ""], ["R", "Vinayakumar", ""], ["KP", "Soman", ""]]}, {"id": "1809.04497", "submitter": "Abdul Fatir Ansari", "authors": "Abdul Fatir Ansari and Harold Soh", "title": "Hyperprior Induced Unsupervised Disentanglement of Latent\n  Representations", "comments": "AAAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of unsupervised disentanglement of latent\nrepresentations learnt via deep generative models. In contrast to current\napproaches that operate on the evidence lower bound (ELBO), we argue that\nstatistical independence in the latent space of VAEs can be enforced in a\nprincipled hierarchical Bayesian manner. To this effect, we augment the\nstandard VAE with an inverse-Wishart (IW) prior on the covariance matrix of the\nlatent code. By tuning the IW parameters, we are able to encourage (or\ndiscourage) independence in the learnt latent dimensions. Extensive\nexperimental results on a range of datasets (2DShapes, 3DChairs, 3DFaces and\nCelebA) show our approach to outperform the $\\beta$-VAE and is competitive with\nthe state-of-the-art FactorVAE. Our approach achieves significantly better\ndisentanglement and reconstruction on a new dataset (CorrelatedEllipses) which\nintroduces correlations between the factors of variation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 14:53:19 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 10:17:22 GMT"}, {"version": "v3", "created": "Sun, 6 Jan 2019 09:30:19 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Ansari", "Abdul Fatir", ""], ["Soh", "Harold", ""]]}, {"id": "1809.04520", "submitter": "Sergey Rodionov", "authors": "Alexey Potapov, Sergey Rodionov", "title": "Genetic algorithms with DNN-based trainable crossover as an example of\n  partial specialization of general search", "comments": "AGI 2017 procedding, The final publication is available at\n  link.springer.com", "journal-ref": null, "doi": "10.1007/978-3-319-63703-7_10", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal induction relies on some general search procedure that is doomed to\nbe inefficient. One possibility to achieve both generality and efficiency is to\nspecialize this procedure w.r.t. any given narrow task. However, complete\nspecialization that implies direct mapping from the task parameters to\nsolutions (discriminative models) without search is not always possible. In\nthis paper, partial specialization of general search is considered in the form\nof genetic algorithms (GAs) with a specialized crossover operator. We perform a\nfeasibility study of this idea implementing such an operator in the form of a\ndeep feedforward neural network. GAs with trainable crossover operators are\ncompared with the result of complete specialization, which is also represented\nas a deep neural network. Experimental results show that specialized GAs can be\nmore efficient than both general GAs and discriminative models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 10:14:58 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Potapov", "Alexey", ""], ["Rodionov", "Sergey", ""]]}, {"id": "1809.04632", "submitter": "Ali Hebbal", "authors": "Ali Hebbal, Loic Brevault, Mathieu Balesdent, El-Ghazali Talbi and\n  Nouredine Melab", "title": "Efficient Global Optimization using Deep Gaussian Processes", "comments": "12 pages, 11 Figures, 2 Tables, presented to the IEEE Congress on\n  Evolutionary Computation (IEEE CEC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient Global Optimization (EGO) is widely used for the optimization of\ncomputationally expensive black-box functions. It uses a surrogate modeling\ntechnique based on Gaussian Processes (Kriging). However, due to the use of a\nstationary covariance, Kriging is not well suited for approximating non\nstationary functions. This paper explores the integration of Deep Gaussian\nprocesses (DGP) in EGO framework to deal with the non-stationary issues and\ninvestigates the induced challenges and opportunities. Numerical\nexperimentations are performed on analytical problems to highlight the\ndifferent aspects of DGP and EGO.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 13:18:50 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Hebbal", "Ali", ""], ["Brevault", "Loic", ""], ["Balesdent", "Mathieu", ""], ["Talbi", "El-Ghazali", ""], ["Melab", "Nouredine", ""]]}, {"id": "1809.04982", "submitter": "Borna Obradovic", "authors": "Borna Obradovic, Titash Rakshit, Ryan Hatcher, Jorge A. Kittl, and\n  Mark S. Rodder", "title": "High-Accuracy Inference in Neuromorphic Circuits using Hardware-Aware\n  Training", "comments": "12 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic Multiply-And-Accumulate (MAC) circuits utilizing synaptic weight\nelements based on SRAM or novel Non-Volatile Memories (NVMs) provide a\npromising approach for highly efficient hardware representations of neural\nnetworks. NVM density and robustness requirements suggest that off-line\ntraining is the right choice for \"edge\" devices, since the requirements for\nsynapse precision are much less stringent. However, off-line training using\nideal mathematical weights and activations can result in significant loss of\ninference accuracy when applied to non-ideal hardware. Non-idealities such as\nmulti-bit quantization of weights and activations, non-linearity of weights,\nfinite max/min ratios of NVM elements, and asymmetry of positive and negative\nweight components all result in degraded inference accuracy. In this work, it\nis demonstrated that non-ideal Multi-Layer Perceptron (MLP) architectures using\nlow bitwidth weights and activations can be trained with negligible loss of\ninference accuracy relative to their Floating Point-trained counterparts using\na proposed off-line, continuously differentiable HW-aware training algorithm.\nThe proposed algorithm is applicable to a wide range of hardware models, and\nuses only standard neural network training methods. The algorithm is\ndemonstrated on the MNIST and EMNIST datasets, using standard MLPs.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 14:21:07 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Obradovic", "Borna", ""], ["Rakshit", "Titash", ""], ["Hatcher", "Ryan", ""], ["Kittl", "Jorge A.", ""], ["Rodder", "Mark S.", ""]]}, {"id": "1809.05275", "submitter": "Ravindra Guntur", "authors": "Kumar Mrityunjay and Guntur Ravindra", "title": "Learning to Fingerprint the Latent Structure in Question Articulation", "comments": "Pre-Print, ACCEPTED FOR PRESENTATION AT the 17th IEEE INTERNATIONAL\n  CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA2018)", "journal-ref": null, "doi": "10.1109/ICMLA.2018.00019", "report-no": null, "categories": "cs.AI cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract Machine understanding of questions is tightly related to recognition\nof articulation in the context of the computational capabilities of an\nunderlying processing algorithm. In this paper a mathematical model to capture\nand distinguish the latent structure in the articulation of questions is\npresented. We propose an objective-driven approach to represent this latent\nstructure and show that such an approach is beneficial when examples of\ncomplementary objectives are not available. We show that the latent structure\ncan be represented as a system that maximizes a cost function related to the\nunderlying objective. Further, we show that the optimization formulation can be\napproximated to building a memory of patterns represented as a trained neural\nauto-encoder. Experimental evaluation using many clusters of questions, each\nrelated to an objective, shows 80% recognition accuracy and negligible false\npositive across these clusters of questions. We then extend the same memory to\na related task where the goal is to iteratively refine a dataset of questions\nbased on the latent articulation. We also demonstrate a refinement scheme\ncalled K-fingerprints, that achieves nearly 100% recognition with negligible\nfalse positive across the different clusters of questions.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 06:51:01 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Mrityunjay", "Kumar", ""], ["Ravindra", "Guntur", ""]]}, {"id": "1809.05407", "submitter": "Nathan McDonald", "authors": "Lisa Loomis, Nathan McDonald, Cory Merkel", "title": "An FPGA Implementation of a Time Delay Reservoir Using Stochastic Logic", "comments": "accepted for publication in the ACM Journal of Emerging Technologies\n  in Computing Systems. arXiv admin note: substantial text overlap with\n  arXiv:1702.04265", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents and demonstrates a stochastic logic time delay reservoir\ndesign in FPGA hardware. The reservoir network approach is analyzed using a\nnumber of metrics, such as kernel quality, generalization rank, performance on\nsimple benchmarks, and is also compared to a deterministic design. A novel\nre-seeding method is introduced to reduce the adverse effects of stochastic\nnoise, which may also be implemented in other stochastic logic reservoir\ncomputing designs, such as echo state networks. Benchmark results indicate that\nthe proposed design performs well on noise-tolerant classification problems,\nbut more work needs to be done to improve the stochastic logic time delay\nreservoirs robustness for regression problems. In addition, we show that the\nstochastic design can significantly reduce area cost if the conversion between\nbinary and stochastic representations implemented efficiently.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 20:56:46 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Loomis", "Lisa", ""], ["McDonald", "Nathan", ""], ["Merkel", "Cory", ""]]}, {"id": "1809.05522", "submitter": "Tong Wu", "authors": "Tong Wu and Wenfeng Zhao and Edward Keefer and Zhi Yang", "title": "Deep Compressive Autoencoder for Action Potential Compression in\n  Large-Scale Neural Recording", "comments": "19 pages, 13 figures", "journal-ref": null, "doi": "10.1088/1741-2552/aae18d", "report-no": null, "categories": "cs.NE cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the coordinated activity underlying brain computations requires\nlarge-scale, simultaneous recordings from distributed neuronal structures at a\ncellular-level resolution. One major hurdle to design high-bandwidth,\nhigh-precision, large-scale neural interfaces lies in the formidable data\nstreams that are generated by the recorder chip and need to be online\ntransferred to a remote computer. The data rates can require hundreds to\nthousands of I/O pads on the recorder chip and power consumption on the order\nof Watts for data streaming alone. We developed a deep learning-based\ncompression model to reduce the data rate of multichannel action potentials.\nThe proposed model is built upon a deep compressive autoencoder (CAE) with\ndiscrete latent embeddings. The encoder is equipped with residual\ntransformations to extract representative features from spikes, which are\nmapped into the latent embedding space and updated via vector quantization\n(VQ). The decoder network reconstructs spike waveforms from the quantized\nlatent embeddings. Experimental results show that the proposed model\nconsistently outperforms conventional methods by achieving much higher\ncompression ratios (20-500x) and better or comparable reconstruction\naccuracies. Testing results also indicate that CAE is robust against a diverse\nrange of imperfections, such as waveform variation and spike misalignment, and\nhas minor influence on spike sorting accuracy. Furthermore, we have estimated\nthe hardware cost and real-time performance of CAE and shown that it could\nsupport thousands of recording channels simultaneously without excessive\npower/heat dissipation. The proposed model can reduce the required data\ntransmission bandwidth in large-scale recording experiments and maintain good\nsignal qualities. The code of this work has been made available at\nhttps://github.com/tong-wu-umn/spike-compression-autoencoder\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 17:48:23 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 00:25:48 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Wu", "Tong", ""], ["Zhao", "Wenfeng", ""], ["Keefer", "Edward", ""], ["Yang", "Zhi", ""]]}, {"id": "1809.05793", "submitter": "Yujie Wu", "authors": "Yujie Wu, Lei Deng, Guoqi Li, Jun Zhu and Luping Shi", "title": "Direct Training for Spiking Neural Networks: Faster, Larger, Better", "comments": "10 pages, 8 figures. Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) that enables energy efficient implementation\non emerging neuromorphic hardware are gaining more attention. Yet now, SNNs\nhave not shown competitive performance compared with artificial neural networks\n(ANNs), due to the lack of effective learning algorithms and efficient\nprogramming frameworks. We address this issue from two aspects: (1) We propose\na neuron normalization technique to adjust the neural selectivity and develop a\ndirect learning algorithm for deep SNNs. (2) Via narrowing the rate coding\nwindow and converting the leaky integrate-and-fire (LIF) model into an\nexplicitly iterative version, we present a Pytorch-based implementation method\ntowards the training of large-scale SNNs. In this way, we are able to train\ndeep SNNs with tens of times speedup. As a result, we achieve significantly\nbetter accuracy than the reported works on neuromorphic datasets (N-MNIST and\nDVS-CIFAR10), and comparable accuracy as existing ANNs and pre-trained SNNs on\nnon-spiking datasets (CIFAR10). {To our best knowledge, this is the first work\nthat demonstrates direct training of deep SNNs with high performance on\nCIFAR10, and the efficient implementation provides a new way to explore the\npotential of SNNs.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 02:03:22 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 01:40:33 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Wu", "Yujie", ""], ["Deng", "Lei", ""], ["Li", "Guoqi", ""], ["Zhu", "Jun", ""], ["Shi", "Luping", ""]]}, {"id": "1809.05989", "submitter": "Alexander Wong", "authors": "Alexander Wong, Mohammad Javad Shafiee, Brendan Chwyl, and Francis Li", "title": "FermiNets: Learning generative machines to generate efficient neural\n  networks via generative synthesis", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The tremendous potential exhibited by deep learning is often offset by\narchitectural and computational complexity, making widespread deployment a\nchallenge for edge scenarios such as mobile and other consumer devices. To\ntackle this challenge, we explore the following idea: Can we learn generative\nmachines to automatically generate deep neural networks with efficient network\narchitectures? In this study, we introduce the idea of generative synthesis,\nwhich is premised on the intricate interplay between a generator-inquisitor\npair that work in tandem to garner insights and learn to generate highly\nefficient deep neural networks that best satisfies operational requirements.\nWhat is most interesting is that, once a generator has been learned through\ngenerative synthesis, it can be used to generate not just one but a large\nvariety of different, unique highly efficient deep neural networks that satisfy\noperational requirements. Experimental results for image classification,\nsemantic segmentation, and object detection tasks illustrate the efficacy of\ngenerative synthesis in producing generators that automatically generate highly\nefficient deep neural networks (which we nickname FermiNets) with higher model\nefficiency and lower computational costs (reaching >10x more efficient and\nfewer multiply-accumulate operations than several tested state-of-the-art\nnetworks), as well as higher energy efficiency (reaching >4x improvements in\nimage inferences per joule consumed on a Nvidia Tegra X2 mobile processor). As\nsuch, generative synthesis can be a powerful, generalized approach for\naccelerating and improving the building of deep neural networks for on-device\nedge scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 01:26:57 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 19:14:50 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Wong", "Alexander", ""], ["Shafiee", "Mohammad Javad", ""], ["Chwyl", "Brendan", ""], ["Li", "Francis", ""]]}, {"id": "1809.06106", "submitter": "Daniel Rodriguez", "authors": "Javier Moreno, Daniel Rodriguez, Antonio Nebro, Jose A. Lozano", "title": "Merge Non-Dominated Sorting Algorithm for Many-Objective Optimization", "comments": null, "journal-ref": null, "doi": "10.1109/TCYB.2020.2968301", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Pareto-based multi-objective evolutionary algorithms require to rank the\nsolutions of the population in each iteration according to the dominance\nprinciple, what can become a costly operation particularly in the case of\ndealing with many-objective optimization problems. In this paper, we present a\nnew efficient algorithm for computing the non-dominated sorting procedure,\ncalled Merge Non-Dominated Sorting (MNDS), which has a best computational\ncomplexity of $\\Theta(NlogN)$ and a worst computational complexity of\n$\\Theta(MN^2)$. Our approach is based on the computation of the dominance set\nof each solution by taking advantage of the characteristics of the merge sort\nalgorithm. We compare the MNDS against four well-known techniques that can be\nconsidered as the state-of-the-art. The results indicate that the MNDS\nalgorithm outperforms the other techniques in terms of number of comparisons as\nwell as the total running time.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 10:09:29 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Moreno", "Javier", ""], ["Rodriguez", "Daniel", ""], ["Nebro", "Antonio", ""], ["Lozano", "Jose A.", ""]]}, {"id": "1809.06187", "submitter": "Md. Abu Bakr Siddique", "authors": "Rezoana Bente Arif, Md. Abu Bakr Siddique, Mohammad Mahmudur Rahman\n  Khan, Mahjabin Rahman Oishe", "title": "Study and Observation of the Variations of Accuracies for Handwritten\n  Digits Recognition with Various Hidden Layers and Epochs using Convolutional\n  Neural Network", "comments": "To be published in the 4th IEEE International Conference on\n  Electrical Engineering and Information & Communication Technology (iCEEiCT\n  2018)", "journal-ref": "2018 4th International Conference on Electrical Engineering and\n  Information & Communication Technology (iCEEiCT)", "doi": "10.1109/CEEICT.2018.8628078", "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Nowadays, deep learning can be employed to a wide ranges of fields including\nmedicine, engineering, etc. In deep learning, Convolutional Neural Network\n(CNN) is extensively used in the pattern and sequence recognition, video\nanalysis, natural language processing, spam detection, topic categorization,\nregression analysis, speech recognition, image classification, object\ndetection, segmentation, face recognition, robotics, and control. The benefits\nassociated with its near human level accuracies in large applications lead to\nthe growing acceptance of CNN in recent years. The primary contribution of this\npaper is to analyze the impact of the pattern of the hidden layers of a CNN\nover the overall performance of the network. To demonstrate this influence, we\napplied neural network with different layers on the Modified National Institute\nof Standards and Technology (MNIST) dataset. Also, is to observe the variations\nof accuracies of the network for various numbers of hidden layers and epochs\nand to make comparison and contrast among them. The system is trained utilizing\nstochastic gradient and backpropagation algorithm and tested with feedforward\nalgorithm.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 13:28:02 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2018 12:08:57 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 16:56:11 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Arif", "Rezoana Bente", ""], ["Siddique", "Md. Abu Bakr", ""], ["Khan", "Mohammad Mahmudur Rahman", ""], ["Oishe", "Mahjabin Rahman", ""]]}, {"id": "1809.06188", "submitter": "Md. Abu Bakr Siddique", "authors": "Md. Abu Bakr Siddique, Mohammad Mahmudur Rahman Khan, Rezoana Bente\n  Arif, Zahidun Ashrafi", "title": "Study and Observation of the Variations of Accuracies for Handwritten\n  Digits Recognition with Various Hidden Layers and Epochs using Neural Network\n  Algorithm", "comments": "To be published in the 4th IEEE International Conference on\n  Electrical Engineering and Information & Communication Technology (iCEEiCT\n  2018)", "journal-ref": "2018 4th International Conference on Electrical Engineering and\n  Information & Communication Technology (iCEEiCT)", "doi": "10.1109/CEEICT.2018.8628144", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent days, Artificial Neural Network (ANN) can be applied to a vast\nmajority of fields including business, medicine, engineering, etc. The most\npopular areas where ANN is employed nowadays are pattern and sequence\nrecognition, novelty detection, character recognition, regression analysis,\nspeech recognition, image compression, stock market prediction, Electronic\nnose, security, loan applications, data processing, robotics, and control. The\nbenefits associated with its broad applications leads to increasing popularity\nof ANN in the era of 21st Century. ANN confers many benefits such as organic\nlearning, nonlinear data processing, fault tolerance, and self-repairing\ncompared to other conventional approaches. The primary objective of this paper\nis to analyze the influence of the hidden layers of a neural network over the\noverall performance of the network. To demonstrate this influence, we applied\nneural network with different layers on the MNIST dataset. Also, another goal\nis to observe the variations of accuracies of ANN for different numbers of\nhidden layers and epochs and to compare and contrast among them.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 13:28:19 GMT"}, {"version": "v2", "created": "Sat, 22 Sep 2018 12:06:34 GMT"}, {"version": "v3", "created": "Thu, 29 Nov 2018 16:54:07 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Siddique", "Md. Abu Bakr", ""], ["Khan", "Mohammad Mahmudur Rahman", ""], ["Arif", "Rezoana Bente", ""], ["Ashrafi", "Zahidun", ""]]}, {"id": "1809.06463", "submitter": "Eugene Wong", "authors": "Eugene Wong", "title": "Self Configuration in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we first present a class of algorithms for training multi-level\nneural networks with a quadratic cost function one layer at a time starting\nfrom the input layer. The algorithm is based on the fact that for any layer to\nbe trained, the effect of a direct connection to an optimized linear output\nlayer can be computed without the connection being made. Thus, starting from\nthe input layer, we can train each layer in succession in isolation from the\nother layers. Once trained, the weights are kept fixed and the outputs of the\ntrained layer then serve as the inputs to the next layer to be trained. The\nresult is a very fast algorithm. The simplicity of this training arrangement\nallows the activation function and step size in weight adjustment to be\nadaptive and self-adjusting. Furthermore, the stability of the training process\nallows relatively large steps to be taken and thereby achieving in even greater\nspeeds. Finally, in our context configuring the network means determining the\nnumber of outputs for each layer. By decomposing the overall cost function into\nseparate components related to approximation and estimation, we obtain an\noptimization formula for determining the number of outputs for each layer. With\nthe ability to self-configure and set parameters, we now have more than a fast\ntraining algorithm, but the ability to build automatically a fully trained deep\nneural network starting with nothing more than data.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 22:29:28 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Wong", "Eugene", ""]]}, {"id": "1809.07098", "submitter": "Danilo Vasconcellos  Vargas", "authors": "Danilo Vasconcellos Vargas, Hirotaka Takano, Junichi Murata", "title": "Novelty-organizing team of classifiers in noisy and dynamic environments", "comments": null, "journal-ref": "2015 IEEE Congress on Evolutionary Computation (CEC)", "doi": "10.1109/CEC.2015.7257254", "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the real world, the environment is constantly changing with the input\nvariables under the effect of noise. However, few algorithms were shown to be\nable to work under those circumstances. Here, Novelty-Organizing Team of\nClassifiers (NOTC) is applied to the continuous action mountain car as well as\ntwo variations of it: a noisy mountain car and an unstable weather mountain\ncar. These problems take respectively noise and change of problem dynamics into\naccount. Moreover, NOTC is compared with NeuroEvolution of Augmenting\nTopologies (NEAT) in these problems, revealing a trade-off between the\napproaches. While NOTC achieves the best performance in all of the problems,\nNEAT needs less trials to converge. It is demonstrated that NOTC achieves\nbetter performance because of its division of the input space (creating easier\nproblems). Unfortunately, this division of input space also requires a bit of\ntime to bootstrap.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 09:38:20 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Vargas", "Danilo Vasconcellos", ""], ["Takano", "Hirotaka", ""], ["Murata", "Junichi", ""]]}, {"id": "1809.07406", "submitter": "Darren Chitty", "authors": "Darren M. Chitty", "title": "Exploiting Tournament Selection for Efficient Parallel Genetic\n  Programming", "comments": null, "journal-ref": "Chitty, Darren M. \"Exploiting Tournament Selection for Efficient\n  Parallel Genetic Programming.\" In UK Workshop on UK Workshop on Computational\n  Intelligence, pp. 41-53. Springer, Cham, 2018", "doi": "10.1007/978-3-319-97982-3_4", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic Programming (GP) is a computationally intensive technique which is\nnaturally parallel in nature. Consequently, many attempts have been made to\nimprove its run-time from exploiting highly parallel hardware such as GPUs.\nHowever, a second methodology of improving the speed of GP is through\nefficiency techniques such as subtree caching. However achieving parallel\nperformance and efficiency is a difficult task. This paper will demonstrate an\nefficiency saving for GP compatible with the harnessing of parallel CPU\nhardware by exploiting tournament selection. Significant efficiency savings are\ndemonstrated whilst retaining the capability of a high performance parallel\nimplementation of GP. Indeed, a 74% improvement in the speed of GP is achieved\nwith a peak rate of 96 billion GPop/s for classification type problems.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 20:52:52 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Chitty", "Darren M.", ""]]}, {"id": "1809.07692", "submitter": "Christian Lins", "authors": "Christian Lins, Andreas Klausen, Sandra Hellmers, Andreas Hein,\n  Sebastian Fudickar", "title": "Staying Alive - CPR Quality Parameters from Wrist-worn Inertial Sensor\n  Data with Evolutionary Fitted Sinusoidal Models", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a robust sinusoidal model fitting method based on the\nDifferential Evolution (DE) algorithm for determining cardiopulmonary\nresuscitation (CPR) quality-parameters - naming chest compression frequency and\ndepth - as measured by an inertial sensor placed at the wrist is presented.\nOnce included into a smartphone or smartwatch app, the proposed algorithm will\nenable bystanders to improve CPR (as part of a continuous closed-loop\nsupport-system). By evaluating the precision of the model with data recorded by\na Laerdal Resusci Anne mannequin as reference standard, a low variance for\ncompression frequency of $\\pm 2.0$ cpm has been found for the sensor placed at\nthe wrist, making this previously unconsidered position a suitable alternative\nto the typical placement in the hand for CPR-training smartphone apps.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 07:25:20 GMT"}, {"version": "v2", "created": "Fri, 15 Feb 2019 13:47:52 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Lins", "Christian", ""], ["Klausen", "Andreas", ""], ["Hellmers", "Sandra", ""], ["Hein", "Andreas", ""], ["Fudickar", "Sebastian", ""]]}, {"id": "1809.07695", "submitter": "Pedro Henrique da Costa Avelar", "authors": "Pedro H. C. Avelar and Henrique Lemos and Marcelo O. R. Prates and\n  Luis Lamb", "title": "Multitask Learning on Graph Neural Networks: Learning Multiple Graph\n  Centrality Measures with a Unified Network", "comments": "Published at ICANN2019. 10 pages, 3 Figures", "journal-ref": null, "doi": "10.1007/978-3-030-30493-5_63", "report-no": null, "categories": "cs.SI cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of deep learning to symbolic domains remains an active\nresearch endeavour. Graph neural networks (GNN), consisting of trained neural\nmodules which can be arranged in different topologies at run time, are sound\nalternatives to tackle relational problems which lend themselves to graph\nrepresentations. In this paper, we show that GNNs are capable of multitask\nlearning, which can be naturally enforced by training the model to refine a\nsingle set of multidimensional embeddings $\\in \\mathbb{R}^d$ and decode them\ninto multiple outputs by connecting MLPs at the end of the pipeline. We\ndemonstrate the multitask learning capability of the model in the relevant\nrelational problem of estimating network centrality measures, focusing\nprimarily on producing rankings based on these measures, i.e. is vertex $v_1$\nmore central than vertex $v_2$ given centrality $c$?. We then show that a GNN\ncan be trained to develop a \\emph{lingua franca} of vertex embeddings from\nwhich all relevant information about any of the trained centrality measures can\nbe decoded. The proposed model achieves $89\\%$ accuracy on a test dataset of\nrandom instances with up to 128 vertices and is shown to generalise to larger\nproblem sizes. The model is also shown to obtain reasonable accuracy on a\ndataset of real world instances with up to 4k vertices, vastly surpassing the\nsizes of the largest instances with which the model was trained ($n=128$).\nFinally, we believe that our contributions attest to the potential of GNNs in\nsymbolic domains in general and in relational learning in particular.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 12:01:37 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 13:04:48 GMT"}, {"version": "v3", "created": "Thu, 8 Nov 2018 17:56:26 GMT"}, {"version": "v4", "created": "Thu, 28 Nov 2019 18:39:30 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Avelar", "Pedro H. C.", ""], ["Lemos", "Henrique", ""], ["Prates", "Marcelo O. R.", ""], ["Lamb", "Luis", ""]]}, {"id": "1809.08045", "submitter": "Dominik Dold", "authors": "Dominik Dold, Ilja Bytschok, Akos F. Kungl, Andreas Baumbach, Oliver\n  Breitwieser, Walter Senn, Johannes Schemmel, Karlheinz Meier, Mihai A.\n  Petrovici", "title": "Stochasticity from function -- why the Bayesian brain may need no noise", "comments": null, "journal-ref": "Neural Networks 119C (2019) pp. 200-213", "doi": "10.1016/j.neunet.2019.08.002", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.NE physics.bio-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An increasing body of evidence suggests that the trial-to-trial variability\nof spiking activity in the brain is not mere noise, but rather the reflection\nof a sampling-based encoding scheme for probabilistic computing. Since the\nprecise statistical properties of neural activity are important in this\ncontext, many models assume an ad-hoc source of well-behaved, explicit noise,\neither on the input or on the output side of single neuron dynamics, most often\nassuming an independent Poisson process in either case. However, these\nassumptions are somewhat problematic: neighboring neurons tend to share\nreceptive fields, rendering both their input and their output correlated; at\nthe same time, neurons are known to behave largely deterministically, as a\nfunction of their membrane potential and conductance. We suggest that spiking\nneural networks may, in fact, have no need for noise to perform sampling-based\nBayesian inference. We study analytically the effect of auto- and\ncross-correlations in functionally Bayesian spiking networks and demonstrate\nhow their effect translates to synaptic interaction strengths, rendering them\ncontrollable through synaptic plasticity. This allows even small ensembles of\ninterconnected deterministic spiking networks to simultaneously and\nco-dependently shape their output activity through learning, enabling them to\nperform complex Bayesian computation without any need for noise, which we\ndemonstrate in silico, both in classical simulation and in neuromorphic\nemulation. These results close a gap between the abstract models and the\nbiology of functionally Bayesian spiking networks, effectively reducing the\narchitectural constraints imposed on physical neural substrates required to\nperform probabilistic computing, be they biological or artificial.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 11:37:14 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 15:53:49 GMT"}, {"version": "v3", "created": "Sat, 24 Aug 2019 12:58:19 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Dold", "Dominik", ""], ["Bytschok", "Ilja", ""], ["Kungl", "Akos F.", ""], ["Baumbach", "Andreas", ""], ["Breitwieser", "Oliver", ""], ["Senn", "Walter", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""], ["Petrovici", "Mihai A.", ""]]}, {"id": "1809.08085", "submitter": "Gonzalo N\\'apoles", "authors": "Gonzalo N\\'apoles, Frank Vanhoenshoven, Koen Vanhoof", "title": "Short-term Cognitive Networks, Flexible Reasoning and Nonsynaptic\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the machine learning literature dedicated to fully automated reasoning\nalgorithms is abundant, the number of methods enabling the inference process on\nthe basis of previously defined knowledge structures is scanter. Fuzzy\nCognitive Maps (FCMs) are neural networks that can be exploited towards this\ngoal because of their flexibility to handle external knowledge. However, FCMs\nsuffer from a number of issues that range from the limited prediction horizon\nto the absence of theoretically sound learning algorithms able to produce\naccurate predictions. In this paper, we propose a neural network system named\nShort-term Cognitive Networks that tackle some of these limitations. In our\nmodel weights are not constricted and may have a causal nature or not. As a\nsecond contribution, we present a nonsynaptic learning algorithm to improve the\nnetwork performance without modifying the previously defined weights. Moreover,\nwe derive a stop condition to prevent the learning algorithm from iterating\nwithout decreasing the simulation error.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 14:02:30 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["N\u00e1poles", "Gonzalo", ""], ["Vanhoenshoven", "Frank", ""], ["Vanhoof", "Koen", ""]]}, {"id": "1809.08101", "submitter": "Adeyinka K. Akanbi MR", "authors": "A. K. Akanbi, M. Masinde", "title": "Towards the Development of a Rule-based Drought Early Warning Expert\n  Systems using Indigenous Knowledge", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drought forecasting and prediction is a complicated process due to the\ncomplexity and scalability of the environmental parameters involved. Hence, it\nrequired a high level of expertise to predict. In this paper, we describe the\nresearch and development of a rule-based drought early warning expert systems\n(RB-DEWES) for forecasting drought using local indigenous knowledge obtained\nfrom domain experts. The system generates inference by using rule set and\nprovides drought advisory information with attributed certainty factor (CF)\nbased on the user's input. The system is believed to be the first expert system\nfor drought forecasting to use local indigenous knowledge on drought. The\narchitecture and components such as knowledge base, JESS inference engine and\nmodel base of the system and their functions are presented.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2018 20:22:28 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Akanbi", "A. K.", ""], ["Masinde", "M.", ""]]}, {"id": "1809.08377", "submitter": "Reza Katebi", "authors": "Reza Katebi, Yadi Zhou, Ryan Chornock and Razvan Bunescu", "title": "Galaxy morphology prediction using capsule networks", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": "10.1093/mnras/stz915", "report-no": null, "categories": "astro-ph.IM astro-ph.GA cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding morphological types of galaxies is a key parameter for studying\ntheir formation and evolution. Neural networks that have been used previously\nfor galaxy morphology classification have some disadvantages, such as not being\ninvariant under rotation. In this work, we studied the performance of Capsule\nNetwork, a recently introduced neural network architecture that is rotationally\ninvariant and spatially aware, on the task of galaxy morphology classification.\nWe designed two evaluation scenarios based on the answers from the question\ntree in the Galaxy Zoo project. In the first scenario, we used Capsule Network\nfor regression and predicted probabilities for all of the questions. In the\nsecond scenario, we chose the answer to the first morphology question that had\nthe highest user agreement as the class of the object and trained a Capsule\nNetwork classifier, where we also reconstructed galaxy images. We achieved\npromising results in both of these scenarios. Automated approaches such as the\none introduced here will greatly decrease the workload of astronomers and will\nplay a critical role in the upcoming large sky surveys.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 03:41:05 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Katebi", "Reza", ""], ["Zhou", "Yadi", ""], ["Chornock", "Ryan", ""], ["Bunescu", "Razvan", ""]]}, {"id": "1809.08587", "submitter": "Ohad Shamir", "authors": "Ohad Shamir", "title": "Exponential Convergence Time of Gradient Descent for One-Dimensional\n  Deep Linear Neural Networks", "comments": "Comparison to previous version: Fixed a bug in lemma 1 part 3 (does\n  not affect any other part of the paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the dynamics of gradient descent on objective functions of the form\n$f(\\prod_{i=1}^{k} w_i)$ (with respect to scalar parameters $w_1,\\ldots,w_k$),\nwhich arise in the context of training depth-$k$ linear neural networks. We\nprove that for standard random initializations, and under mild assumptions on\n$f$, the number of iterations required for convergence scales exponentially\nwith the depth $k$. We also show empirically that this phenomenon can occur in\nhigher dimensions, where each $w_i$ is a matrix. This highlights a potential\nobstacle in understanding the convergence of gradient-based methods for deep\nlinear neural networks, where $k$ is large.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 12:32:45 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 08:37:45 GMT"}, {"version": "v3", "created": "Thu, 27 Dec 2018 08:31:56 GMT"}, {"version": "v4", "created": "Thu, 13 Jun 2019 07:23:22 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Shamir", "Ohad", ""]]}, {"id": "1809.08660", "submitter": "Vahid Moosavi", "authors": "Lukas Fuhrimann, Vahid Moosavi, Patrick Ole Ohlbrock, Pierluigi\n  Dacunto", "title": "Data-Driven Design: Exploring new Structural Forms using Machine\n  Learning and Graphic Statics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this research is to introduce a novel structural design process\nthat allows architects and engineers to extend their typical design space\nhorizon and thereby promoting the idea of creativity in structural design. The\ntheoretical base of this work builds on the combination of structural\nform-finding and state-of-the-art machine learning algorithms. In the first\nstep of the process, Combinatorial Equilibrium Modelling (CEM) is used to\ngenerate a large variety of spatial networks in equilibrium for given input\nparameters. In the second step, these networks are clustered and represented in\na form-map through the implementation of a Self Organizing Map (SOM) algorithm.\nIn the third step, the solution space is interpreted with the help of a Uniform\nManifold Approximation and Projection algorithm (UMAP). This allows gaining\nimportant insights in the structure of the solution space. A specific case\nstudy is used to illustrate how the infinite equilibrium states of a given\ntopology can be defined and represented by clusters. Furthermore, three\nclasses, related to the non-linear interaction between the input parameters and\nthe form space, are verified and a statement about the entire manifold of the\nsolution space of the case study is made. To conclude, this work presents an\ninnovative approach on how the manifold of a solution space can be grasped with\na minimum amount of data and how to operate within the manifold in order to\nincrease the diversity of solutions.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 19:00:40 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Fuhrimann", "Lukas", ""], ["Moosavi", "Vahid", ""], ["Ohlbrock", "Patrick Ole", ""], ["Dacunto", "Pierluigi", ""]]}, {"id": "1809.08799", "submitter": "Christian Reisswig", "authors": "Anoop Raveendra Katti, Christian Reisswig, Cordula Guder, Sebastian\n  Brarda, Steffen Bickel, Johannes H\\\"ohne, Jean Baptiste Faddoul", "title": "Chargrid: Towards Understanding 2D Documents", "comments": "To be published at EMNLP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel type of text representation that preserves the 2D layout\nof a document. This is achieved by encoding each document page as a\ntwo-dimensional grid of characters. Based on this representation, we present a\ngeneric document understanding pipeline for structured documents. This pipeline\nmakes use of a fully convolutional encoder-decoder network that predicts a\nsegmentation mask and bounding boxes. We demonstrate its capabilities on an\ninformation extraction task from invoices and show that it significantly\noutperforms approaches based on sequential text or document images.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 08:37:02 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Katti", "Anoop Raveendra", ""], ["Reisswig", "Christian", ""], ["Guder", "Cordula", ""], ["Brarda", "Sebastian", ""], ["Bickel", "Steffen", ""], ["H\u00f6hne", "Johannes", ""], ["Faddoul", "Jean Baptiste", ""]]}, {"id": "1809.08836", "submitter": "Thomas Pircher", "authors": "Thomas Pircher, Dominik Haspel and Eberhard Schl\\\"ucker", "title": "Dense neural networks as sparse graphs and the lightning initialization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Even though dense networks have lost importance today, they are still used as\nfinal logic elements. It could be shown that these dense networks can be\nsimplified by the sparse graph interpretation. This in turn shows that the\ninformation flow between input and output is not optimal with an initialization\ncommon today. The lightning initialization sets the weights so that complete\ninformation paths exist between input and output from the start. It turned out\nthat pure dense networks and also more complex networks with additional layers\nbenefit from this initialization. The networks accuracy increases faster. The\nlightning initialization has two parameters which behaved robustly in the tests\ncarried out. However, especially with more complex networks, an improvement\neffect only occurs at lower learning rates, which shows that the initialization\nretains its positive effect over the epochs with learning rate reduction.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 10:59:52 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Pircher", "Thomas", ""], ["Haspel", "Dominik", ""], ["Schl\u00fccker", "Eberhard", ""]]}, {"id": "1809.08860", "submitter": "Seshadhri Srinivasan", "authors": "Mainak Dan and Seshadhri Srinivasan", "title": "A Comparative Study: Adaptive Fuzzy Inference Systems for Energy\n  Prediction in Urban Buildings", "comments": "5 pages, 2 figures, keyword: Short-term energy prediction, evolving\n  Takagi-Sugeno model, meta-cognitive fuzzy inference system, sequential\n  adaptive fuzzy inference system", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This investigation aims to study different adaptive fuzzy inference\nalgorithms capable of real-time sequential learning and prediction of\ntime-series data. A brief qualitative description of these algorithms namely\nmeta-cognitive fuzzy inference system (McFIS), sequential adaptive fuzzy\ninference system (SAFIS) and evolving Takagi-Sugeno (ETS) model provide a\ncomprehensive comparison of their working principle, especially their unique\ncharacteristics are discussed. These algorithms are then simulated with dataset\ncollected at one of the academic buildings at Nanyang Technological University,\nSingapore. The performance are compared by means of the root mean squared error\n(RMSE) and non-destructive error index (NDEI) of the predicted output. Analysis\nshows that McFIS shows promising results either with lower RMSE and NDEI or\nwith lower architectural complexity over ETS and SAFIS. Statistical Analysis\nalso reveals the significance of the outcome of these algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 12:00:37 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Dan", "Mainak", ""], ["Srinivasan", "Seshadhri", ""]]}, {"id": "1809.09087", "submitter": "Ke Li", "authors": "Ke Li and Jitendra Malik", "title": "Implicit Maximum Likelihood Estimation", "comments": "21 pages, 4 figures. In the interest of promoting discussion, we make\n  the reviews available at\n  https://people.eecs.berkeley.edu/~ke.li/papers/imle_reviews.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit probabilistic models are models defined naturally in terms of a\nsampling procedure and often induces a likelihood function that cannot be\nexpressed explicitly. We develop a simple method for estimating parameters in\nimplicit models that does not require knowledge of the form of the likelihood\nfunction or any derived quantities, but can be shown to be equivalent to\nmaximizing likelihood under some conditions. Our result holds in the\nnon-asymptotic parametric setting, where both the capacity of the model and the\nnumber of data examples are finite. We also demonstrate encouraging\nexperimental results.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 17:57:25 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 17:56:37 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Li", "Ke", ""], ["Malik", "Jitendra", ""]]}, {"id": "1809.09096", "submitter": "Davide Bacciu", "authors": "Davide Bacciu and Antonio Bruno", "title": "Text Summarization as Tree Transduction by Top-Down TreeLSTM", "comments": "To appear in IEEE SCCI Deep Learning 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extractive compression is a challenging natural language processing problem.\nThis work contributes by formulating neural extractive compression as a parse\ntree transduction problem, rather than a sequence transduction task. Motivated\nby this, we introduce a deep neural model for learning\nstructure-to-substructure tree transductions by extending the standard Long\nShort-Term Memory, considering the parent-child relationships in the structural\nrecursion. The proposed model can achieve state of the art performance on\nsentence compression benchmarks, both in terms of accuracy and compression\nrate.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 11:00:57 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Bacciu", "Davide", ""], ["Bruno", "Antonio", ""]]}, {"id": "1809.09260", "submitter": "Jeffrey McKinstry", "authors": "Jeffrey L Mckinstry, Davis R. Barch, Deepika Bablani, Michael V.\n  Debole, Steven K. Esser, Jeffrey A. Kusnitz, John V. Arthur, Dharmendra S.\n  Modha", "title": "Low Precision Policy Distillation with Application to Low-Power,\n  Real-time Sensation-Cognition-Action Loop with Neuromorphic Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low precision networks in the reinforcement learning (RL) setting are\nrelatively unexplored because of the limitations of binary activations for\nfunction approximation. Here, in the discrete action ATARI domain, we\ndemonstrate, for the first time, that low precision policy distillation from a\nhigh precision network provides a principled, practical way to train an RL\nagent. As an application, on 10 different ATARI games, we demonstrate real-time\nend-to-end game playing on low-power neuromorphic hardware by converting a\nsequence of game frames into discrete actions.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 00:03:33 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Mckinstry", "Jeffrey L", ""], ["Barch", "Davis R.", ""], ["Bablani", "Deepika", ""], ["Debole", "Michael V.", ""], ["Esser", "Steven K.", ""], ["Kusnitz", "Jeffrey A.", ""], ["Arthur", "John V.", ""], ["Modha", "Dharmendra S.", ""]]}, {"id": "1809.09262", "submitter": "Luca de Alfaro", "authors": "Luca de Alfaro", "title": "Neural Networks with Structural Resistance to Adversarial Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In adversarial attacks to machine-learning classifiers, small perturbations\nare added to input that is correctly classified. The perturbations yield\nadversarial examples, which are virtually indistinguishable from the\nunperturbed input, and yet are misclassified. In standard neural networks used\nfor deep learning, attackers can craft adversarial examples from most input to\ncause a misclassification of their choice.\n  We introduce a new type of network units, called RBFI units, whose non-linear\nstructure makes them inherently resistant to adversarial attacks. On\npermutation-invariant MNIST, in absence of adversarial attacks, networks using\nRBFI units match the performance of networks using sigmoid units, and are\nslightly below the accuracy of networks with ReLU units. When subjected to\nadversarial attacks, networks with RBFI units retain accuracies above 90% for\nattacks that degrade the accuracy of networks with ReLU or sigmoid units to\nbelow 2%. RBFI networks trained with regular input are superior in their\nresistance to adversarial attacks even to ReLU and sigmoid networks trained\nwith the help of adversarial examples.\n  The non-linear structure of RBFI units makes them difficult to train using\nstandard gradient descent. We show that networks of RBFI units can be\nefficiently trained to high accuracies using pseudogradients, computed using\nfunctions especially crafted to facilitate learning instead of their true\nderivatives. We show that the use of pseudogradients makes training deep RBFI\nnetworks practical, and we compare several structural alternatives of RBFI\nnetworks for their accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 00:08:10 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["de Alfaro", "Luca", ""]]}, {"id": "1809.09284", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Saeed Sharifian, Hoda Mohammadzade", "title": "Tree-Based Optimization: A Meta-Algorithm for Metaheuristic Optimization", "comments": "12 pages, 15 figures, 3 tables, key words: Tree, optimization,\n  metaheuristic, high dimensions, meta-algorithm, search", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing search algorithms for finding global optima is one of the most\nactive research fields, recently. These algorithms consist of two main\ncategories, i.e., classic mathematical and metaheuristic algorithms. This\narticle proposes a meta-algorithm, Tree-Based Optimization (TBO), which uses\nother heuristic optimizers as its sub-algorithms in order to improve the\nperformance of search. The proposed algorithm is based on mathematical tree\nsubject and improves performance and speed of search by iteratively removing\nparts of the search space having low fitness, in order to minimize and purify\nthe search space. The experimental results on several well-known benchmarks\nshow the outperforming performance of TBO algorithm in finding the global\nsolution. Experiments on high dimensional search spaces show significantly\nbetter performance when using the TBO algorithm. The proposed algorithm\nimproves the search algorithms in both accuracy and speed aspects, especially\nfor high dimensional searching such as in VLSI CAD tools for Integrated Circuit\n(IC) design.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 02:19:24 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Sharifian", "Saeed", ""], ["Mohammadzade", "Hoda", ""]]}, {"id": "1809.09533", "submitter": "Faik Boray Tek", "authors": "F. Boray Tek", "title": "An Adaptive Locally Connected Neuron Model: Focusing Neuron", "comments": "45 pages, a national patent filed, submitted to Turkish Patent\n  Office, No: -2017/17601, Date: 09.11.2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new artificial neuron model capable of learning its\nreceptive field in the topological domain of inputs. The model provides\nadaptive and differentiable local connectivity (plasticity) applicable to any\ndomain. It requires no other tool than the backpropagation algorithm to learn\nits parameters which control the receptive field locations and apertures. This\nresearch explores whether this ability makes the neuron focus on informative\ninputs and yields any advantage over fully connected neurons. The experiments\ninclude tests of focusing neuron networks of one or two hidden layers on\nsynthetic and well-known image recognition data sets. The results demonstrated\nthat the focusing neurons can move their receptive fields towards more\ninformative inputs. In the simple two-hidden layer networks, the focusing\nlayers outperformed the dense layers in the classification of the 2D spatial\ndata sets. Moreover, the focusing networks performed better than the dense\nnetworks even when 70$\\%$ of the weights were pruned. The tests on\nconvolutional networks revealed that using focusing layers instead of dense\nlayers for the classification of convolutional features may work better in some\ndata sets.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 09:15:32 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 13:29:37 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2020 11:11:40 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Tek", "F. Boray", ""]]}, {"id": "1809.09534", "submitter": "Andrei Nicolae Ph.D", "authors": "Andrei Nicolae", "title": "PLU: The Piecewise Linear Unit Activation Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successive linear transforms followed by nonlinear \"activation\" functions can\napproximate nonlinear functions to arbitrary precision given sufficient layers.\nThe number of necessary layers is dependent on, in part, by the nature of the\nactivation function. The hyperbolic tangent (tanh) has been a favorable choice\nas an activation until the networks grew deeper and the vanishing gradients\nposed a hindrance during training. For this reason the Rectified Linear Unit\n(ReLU) defined by max(0, x) has become the prevailing activation function in\ndeep neural networks. Unlike the tanh function which is smooth, the ReLU yields\nnetworks that are piecewise linear functions with a limited number of facets.\nThis paper presents a new activation function, the Piecewise Linear Unit (PLU)\nthat is a hybrid of tanh and ReLU and shown to outperform the ReLU on a variety\nof tasks while avoiding the vanishing gradients issue of the tanh.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 07:46:44 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Nicolae", "Andrei", ""]]}, {"id": "1809.09563", "submitter": "Aadesh Neupane", "authors": "Bryant Chandler, Aadesh Neupane", "title": "Slogatron: Advanced Wealthiness Generator", "comments": "Project done for CS673 (Computational Creativity)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Creating catchy slogans is a demanding and clearly creative job for ad\nagencies. The process of slogan creation by humans involves finding key\nconcepts of the company and its products, and developing a memorable short\nphrase to describe the key concept. We attempt to follow the same sequence, but\nwith an evolutionary algorithm. A user inputs a paragraph describing describing\nthe company or product to be promoted. The system randomly samples initial\nslogans from a corpus of existing slogans. The initial slogans are then\niteratively mutated and improved using an evolutionary algorithm. Mutation\nrandomly replaces words in an individual with words from the input paragraphs.\nInternal evaluation measures a combination of grammatical correctness, and\nsemantic similarity to the input paragraphs. Subjective analysis of output\nslogans leads to the conclusion that the algorithm certainly outputs valuable\nslogans. External evaluation found that the slogans were somewhat successful in\nconveying a message, because humans were generally able to select the correct\npromoted item given a slogan.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 20:16:00 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Chandler", "Bryant", ""], ["Neupane", "Aadesh", ""]]}, {"id": "1809.09895", "submitter": "Youcef Gheraibia", "authors": "Youcef Gheraibia, Abdelouahab Moussaoui, Peng-Yeng Yin, Yiannis\n  Papadopoulos, and Smaine Maazouzi", "title": "PeSOA: Penguins Search Optimisation Algorithm for Global Optimisation\n  Problems", "comments": null, "journal-ref": "The International Arab Journal of Information Technology (IAJIT),\n  Volume 16, Pages 1-9, May 2019", "doi": null, "report-no": "First online publication 01", "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops Penguin search Optimisation Algorithm (PeSOA), a new\nmetaheuristic algorithm which is inspired by the foraging behaviours of\npenguins. A population of penguins located in the solution space of the given\nsearch and optimisation problem is divided into groups and tasked with finding\noptimal solutions. The penguins of a group perform simultaneous dives and work\nas a team to collaboratively feed on fish the energy content of which\ncorresponds to the fitness of candidate solutions. Fish stocks have higher\nfitness and concentration near areas of solution optima and thus drive the\nsearch. Penguins can migrate to other places if their original habitat lacks\nfood. We identify two forms of penguin communication both intra-group and\ninter-group which are useful in designing intensification and diversification\nstrategies. An efficient intensification strategy allows fast convergence to a\nlocal optimum, whereas an effective diversification strategy avoids cyclic\nbehaviour around local optima and explores more effectively the space of\npotential solutions. The proposed PeSOA algorithm has been validated on a\nwell-known set of benchmark functions. Comparative performances with six other\nnature-inspired metaheuristics show that the PeSOA performs favourably in these\ntests. A run-time analysis shows that the performance obtained by the PeSOA is\nvery stable at any time of the evolution horizon, making the PeSOA a viable\napproach for real world applications.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 10:40:16 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 10:45:45 GMT"}, {"version": "v3", "created": "Mon, 8 Apr 2019 12:14:27 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Gheraibia", "Youcef", ""], ["Moussaoui", "Abdelouahab", ""], ["Yin", "Peng-Yeng", ""], ["Papadopoulos", "Yiannis", ""], ["Maazouzi", "Smaine", ""]]}, {"id": "1809.10245", "submitter": "Hojjat Salehinejad", "authors": "Hojjat Salehinejad, Sumeya Naqvi, Errol Colak, Joseph Barfett,\n  Shahrokh Valaee", "title": "Cylindrical Transform: 3D Semantic Segmentation of Kidneys With Limited\n  Annotated Images", "comments": "This paper is accepted for presentation at IEEE Global Conference on\n  Signal and Information Processing (IEEE GlobalSIP), California, USA, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel technique for sampling sequential images\nusing a cylindrical transform in a cylindrical coordinate system for kidney\nsemantic segmentation in abdominal computed tomography (CT). The images\ngenerated from a cylindrical transform augment a limited annotated set of\nimages in three dimensions. This approach enables us to train contemporary\nclassification deep convolutional neural networks (DCNNs) instead of fully\nconvolutional networks (FCNs) for semantic segmentation. Typical semantic\nsegmentation models segment a sequential set of images (e.g. CT or video) by\nsegmenting each image independently. However, the proposed method not only\nconsiders the spatial dependency in the x-y plane, but also the spatial\nsequential dependency along the z-axis. The results show that classification\nDCNNs, trained on cylindrical transformed images, can achieve a higher\nsegmentation performance value than FCNs using a limited number of annotated\nimages.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 17:58:54 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Salehinejad", "Hojjat", ""], ["Naqvi", "Sumeya", ""], ["Colak", "Errol", ""], ["Barfett", "Joseph", ""], ["Valaee", "Shahrokh", ""]]}, {"id": "1809.10283", "submitter": "Christopher Iliffe Sprague", "authors": "Christopher Iliffe Sprague, Petter \\\"Ogren", "title": "Adding Neural Network Controllers to Behavior Trees without Destroying\n  Performance Guarantees", "comments": "Submitted to IEEE Transactions on Games", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how Behavior Trees that have performance guarantees,\nin terms of safety and goal convergence, can be extended with components that\nwere designed using machine learning, without destroying those performance\nguarantees.\n  Machine learning approaches such as reinforcement learning or learning from\ndemonstration can be very appealing to AI designers that want efficient and\nrealistic behaviors in their agents. However, those algorithms seldom provide\nguarantees for solving the given task in all different situations while keeping\nthe agent safe. Instead, such guarantees are often easier to find for manually\ndesigned model based approaches. In this paper we exploit the modularity of\nBehavior trees to extend a given design with an efficient, but possibly\nunreliable, machine learning component in a way that preserves the guarantees.\nThe approach is illustrated with an inverted pendulum example.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 12:23:19 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 11:36:39 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Sprague", "Christopher Iliffe", ""], ["\u00d6gren", "Petter", ""]]}, {"id": "1809.10847", "submitter": "T.S. Jayram", "authors": "T.S. Jayram and Tomasz Kornuta and Ryan L. McAvoy and Ahmet S. Ozcan", "title": "Using Multi-task and Transfer Learning to Solve Working Memory Tasks", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new architecture called Memory-Augmented Encoder-Solver (MAES)\nthat enables transfer learning to solve complex working memory tasks adapted\nfrom cognitive psychology. It uses dual recurrent neural network controllers,\ninside the encoder and solver, respectively, that interface with a shared\nmemory module and is completely differentiable. We study different types of\nencoders in a systematic manner and demonstrate a unique advantage of\nmulti-task learning in obtaining the best possible encoder. We show by\nextensive experimentation that the trained MAES models achieve task-size\ngeneralization, i.e., they are capable of handling sequential inputs 50 times\nlonger than seen during training, with appropriately large memory modules. We\ndemonstrate that the performance achieved by MAES far outperforms existing and\nwell-known models such as the LSTM, NTM and DNC on the entire suite of tasks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 04:01:06 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Jayram", "T. S.", ""], ["Kornuta", "Tomasz", ""], ["McAvoy", "Ryan L.", ""], ["Ozcan", "Ahmet S.", ""]]}, {"id": "1809.11087", "submitter": "T.S. Jayram", "authors": "T.S. Jayram and Younes Bouhadjar and Ryan L. McAvoy and Tomasz Kornuta\n  and Alexis Asseman and Kamil Rocki and Ahmet S. Ozcan", "title": "Learning to Remember, Forget and Ignore using Attention Control in\n  Memory", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical neural networks with external memory do not effectively separate\ncapacity for episodic and working memory as is required for reasoning in\nhumans. Applying knowledge gained from psychological studies, we designed a new\nmodel called Differentiable Working Memory (DWM) in order to specifically\nemulate human working memory. As it shows the same functional characteristics\nas working memory, it robustly learns psychology inspired tasks and converges\nfaster than comparable state-of-the-art models. Moreover, the DWM model\nsuccessfully generalizes to sequences two orders of magnitude longer than the\nones used in training. Our in-depth analysis shows that the behavior of DWM is\ninterpretable and that it learns to have fine control over memory, allowing it\nto retain, ignore or forget information based on its relevance.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 15:30:54 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Jayram", "T. S.", ""], ["Bouhadjar", "Younes", ""], ["McAvoy", "Ryan L.", ""], ["Kornuta", "Tomasz", ""], ["Asseman", "Alexis", ""], ["Rocki", "Kamil", ""], ["Ozcan", "Ahmet S.", ""]]}]