[{"id": "1905.00249", "submitter": "David Navarro-Alarcon", "authors": "Omar Zahra and David Navarro-Alarcon", "title": "A Self-Organizing Network with Varying Density Structure for\n  Characterizing Sensorimotor Transformations in Robotic Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present the development of a neuro-inspired approach for\ncharacterizing sensorimotor relations in robotic systems. The proposed method\nhas self-organizing and associative properties that enable it to autonomously\nobtain these relations without any prior knowledge of either the motor (e.g.\nmechanical structure) or perceptual (e.g. sensor calibration) models.\nSelf-organizing topographic properties are used to build both sensory and motor\nmaps, then the associative properties rule the stability and accuracy of the\nemerging connections between these maps. Compared to previous works, our method\nintroduces a new varying density self-organizing map (VDSOM) that controls the\nconcentration of nodes in regions with large transformation errors without\naffecting much the computational time. A distortion metric is measured to\nachieve a self-tuning sensorimotor model that adapts to changes in either motor\nor sensory models. The obtained sensorimotor maps prove to have less error than\nconventional self-organizing methods and potential for further development.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 10:27:14 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Zahra", "Omar", ""], ["Navarro-Alarcon", "David", ""]]}, {"id": "1905.00310", "submitter": "Alexander Wong", "authors": "Kaylen J. Pfisterer, Robert Amelard, Braeden Syrnyk, and Alexander\n  Wong", "title": "Towards computer vision powered color-nutrient assessment of pureed food", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With one in four individuals afflicted with malnutrition, computer vision may\nprovide a way of introducing a new level of automation in the nutrition field\nto reliably monitor food and nutrient intake. In this study, we present a novel\napproach to modeling the link between color and vitamin A content using\ntransmittance imaging of a pureed foods dilution series in a computer vision\npowered nutrient sensing system via a fine-tuned deep autoencoder network,\nwhich in this case was trained to predict the relative concentration of sweet\npotato purees. Experimental results show the deep autoencoder network can\nachieve an accuracy of 80% across beginner (6 month) and intermediate (8 month)\ncommercially prepared pureed sweet potato samples. Prediction errors may be\nexplained by fundamental differences in optical properties which are further\ndiscussed.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 13:42:19 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Pfisterer", "Kaylen J.", ""], ["Amelard", "Robert", ""], ["Syrnyk", "Braeden", ""], ["Wong", "Alexander", ""]]}, {"id": "1905.00378", "submitter": "Will Xiao", "authors": "Will Xiao and Gabriel Kreiman", "title": "Gradient-free activation maximization for identifying effective stimuli", "comments": "16 pages, 8 figures, 3 tables", "journal-ref": "PLOS Comp Biol 2020 16(6): e1007973", "doi": "10.1371/journal.pcbi.1007973", "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question for understanding brain function is what types of\nstimuli drive neurons to fire. In visual neuroscience, this question has also\nbeen posted as characterizing the receptive field of a neuron. The search for\neffective stimuli has traditionally been based on a combination of insights\nfrom previous studies, intuition, and luck. Recently, the same question has\nemerged in the study of units in convolutional neural networks (ConvNets), and\ntogether with this question a family of solutions were developed that are\ngenerally referred to as \"feature visualization by activation maximization.\"\n  We sought to bring in tools and techniques developed for studying ConvNets to\nthe study of biological neural networks. However, one key difference that\nimpedes direct translation of tools is that gradients can be obtained from\nConvNets using backpropagation, but such gradients are not available from the\nbrain. To circumvent this problem, we developed a method for gradient-free\nactivation maximization by combining a generative neural network with a genetic\nalgorithm. We termed this method XDream (EXtending DeepDream with real-time\nevolution for activation maximization), and we have shown that this method can\nreliably create strong stimuli for neurons in the macaque visual cortex (Ponce\net al., 2019). In this paper, we describe extensive experiments characterizing\nthe XDream method by using ConvNet units as in silico models of neurons. We\nshow that XDream is applicable across network layers, architectures, and\ntraining sets; examine design choices in the algorithm; and provide practical\nguides for choosing hyperparameters in the algorithm. XDream is an efficient\nalgorithm for uncovering neuronal tuning preferences in black-box networks\nusing a vast and diverse stimulus space.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 16:56:57 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Xiao", "Will", ""], ["Kreiman", "Gabriel", ""]]}, {"id": "1905.00547", "submitter": "George Cevora", "authors": "George Cevora", "title": "The relationship between Biological and Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intelligence can be defined as a predominantly human ability to accomplish\ntasks that are generally hard for computers and animals. Artificial\nIntelligence [AI] is a field attempting to accomplish such tasks with\ncomputers. AI is becoming increasingly widespread, as are claims of its\nrelationship with Biological Intelligence. Often these claims are made to imply\nhigher chances of a given technology succeeding, working on the assumption that\nAI systems which mimic the mechanisms of Biological Intelligence should be more\nsuccessful.\n  In this article I will discuss the similarities and differences between AI\nand the extent of our knowledge about the mechanisms of intelligence in\nbiology, especially within humans. I will also explore the validity of the\nassumption that biomimicry in AI systems aids their advancement, and I will\nargue that existing similarity to biological systems in the way Artificial\nNeural Networks [ANNs] tackle tasks is due to design decisions, rather than\ninherent similarity of underlying mechanisms. This article is aimed at people\nwho understand the basics of AI (especially ANNs), and would like to be better\nable to evaluate the often wild claims about the value of biomimicry in AI.\n", "versions": [{"version": "v1", "created": "Wed, 1 May 2019 13:41:35 GMT"}], "update_date": "2019-05-03", "authors_parsed": [["Cevora", "George", ""]]}, {"id": "1905.01208", "submitter": "Remi Gribonval", "authors": "R\\'emi Gribonval (PANAMA, DANTE), Gitta Kutyniok, Morten Nielsen,\n  Felix Voigtlaender (KU)", "title": "Approximation spaces of deep neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the expressivity of deep neural networks. Measuring a network's\ncomplexity by its number of connections or by its number of neurons, we\nconsider the class of functions for which the error of best approximation with\nnetworks of a given complexity decays at a certain rate when increasing the\ncomplexity budget. Using results from classical approximation theory, we show\nthat this class can be endowed with a (quasi)-norm that makes it a linear\nfunction space, called approximation space. We establish that allowing the\nnetworks to have certain types of \"skip connections\" does not change the\nresulting approximation spaces. We also discuss the role of the network's\nnonlinearity (also known as activation function) on the resulting spaces, as\nwell as the role of depth. For the popular ReLU nonlinearity and its powers, we\nrelate the newly constructed spaces to classical Besov spaces. The established\nembeddings highlight that some functions of very low Besov smoothness can\nnevertheless be well approximated by neural networks, if these networks are\nsufficiently deep.\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2019 14:43:23 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 13:41:03 GMT"}, {"version": "v3", "created": "Fri, 10 Jul 2020 12:30:50 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2020 14:42:08 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Gribonval", "R\u00e9mi", "", "PANAMA, DANTE"], ["Kutyniok", "Gitta", "", "KU"], ["Nielsen", "Morten", "", "KU"], ["Voigtlaender", "Felix", "", "KU"]]}, {"id": "1905.01392", "submitter": "Martin Wistuba", "authors": "Martin Wistuba and Ambrish Rawat and Tejaswini Pedapati", "title": "A Survey on Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing interest in both the automation of machine learning and deep\nlearning has inevitably led to the development of a wide variety of automated\nmethods for neural architecture search. The choice of the network architecture\nhas proven to be critical, and many advances in deep learning spring from its\nimmediate improvements. However, deep learning techniques are computationally\nintensive and their application requires a high level of domain knowledge.\nTherefore, even partial automation of this process helps to make deep learning\nmore accessible to both researchers and practitioners. With this survey, we\nprovide a formalism which unifies and categorizes the landscape of existing\nmethods along with a detailed analysis that compares and contrasts the\ndifferent approaches. We achieve this via a comprehensive discussion of the\ncommonly adopted architecture search spaces and architecture optimization\nalgorithms based on principles of reinforcement learning and evolutionary\nalgorithms along with approaches that incorporate surrogate and one-shot\nmodels. Additionally, we address the new research directions which include\nconstrained and multi-objective architecture search as well as automated data\naugmentation, optimizer and activation function search.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 00:08:49 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 09:32:21 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Wistuba", "Martin", ""], ["Rawat", "Ambrish", ""], ["Pedapati", "Tejaswini", ""]]}, {"id": "1905.01888", "submitter": "Leandro Indrusiak", "authors": "Leandro Soares Indrusiak, Robert I. Davis, Piotr Dziurzanski", "title": "Evolutionary Optimisation of Real-Time Systems and Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design space of networked embedded systems is very large, posing\nchallenges to the optimisation of such platforms when it comes to support\napplications with real-time guarantees. Recent research has shown that a number\nof inter-related optimisation problems have a critical influence over the\nschedulability of a system, i.e. whether all its application components can\nexecute and communicate by their respective deadlines. Examples of such\noptimization problems include task allocation and scheduling, communication\nrouting and arbitration, memory allocation, and voltage and frequency scaling.\nIn this paper, we advocate the use of evolutionary approaches to address such\noptimization problems, aiming to evolve individuals of increased fitness over\nmultiple generations of potential solutions. We refer to plentiful evidence\nthat existing real-time schedulability tests can be used effectively to guide\nevolutionary optimisation, either by themselves or in combination with other\nmetrics such as energy dissipation or hardware overheads. We then push that\nconcept one step further and consider the possibility of using evolutionary\ntechniques to evolve the schedulability tests themselves, aiming to support the\nverification and optimisation of systems which are too complex for\nstate-of-the-art (manual) derivation of schedulability tests.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2019 09:04:02 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 13:59:18 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 12:39:12 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Indrusiak", "Leandro Soares", ""], ["Davis", "Robert I.", ""], ["Dziurzanski", "Piotr", ""]]}, {"id": "1905.02341", "submitter": "Lei Pang", "authors": "Yang Jiang and Cong Zhao and Zeyang Dou and Lei Pang", "title": "Neural Architecture Refinement: A Practical Way for Avoiding Overfitting\n  in NAS", "comments": "9 pages, 1 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural architecture search (NAS) is proposed to automate the architecture\ndesign process and attracts overwhelming interest from both academia and\nindustry. However, it is confronted with overfitting issue due to the\nhigh-dimensional search space composed by operator selection and skip\nconnection of each layer. This paper explores the architecture overfitting\nissue in depth based on the reinforcement learning-based NAS framework. We show\nthat the policy gradient method has deep correlations with the cross entropy\nminimization. Based on this correlation, we further demonstrate that, though\nthe reward of NAS is sparse, the policy gradient method implicitly assign the\nreward to all operations and skip connections based on the sampling frequency.\nHowever, due to the inaccurate reward estimation, curse of dimensionality\nproblem and the hierachical structure of neural networks, reward charateristics\nfor operators and skip connections have intrinsic differences, the assigned\nrewards for the skip connections are extremely noisy and inaccurate. To\nalleviate this problem, we propose a neural architecture refinement approach\nthat working with an initial state-of-the-art network structure and only\nrefining its operators. Extensive experiments have demonstrated that the\nproposed method can achieve fascinated results, including classification, face\nrecognition etc.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 03:41:12 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 06:13:43 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 02:04:20 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Jiang", "Yang", ""], ["Zhao", "Cong", ""], ["Dou", "Zeyang", ""], ["Pang", "Lei", ""]]}, {"id": "1905.02438", "submitter": "George Constantinides", "authors": "George A. Constantinides", "title": "Rethinking Arithmetic for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1098/rsta.2019.0051", "report-no": null, "categories": "cs.LG cs.AR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider efficiency in the implementation of deep neural networks.\nHardware accelerators are gaining interest as machine learning becomes one of\nthe drivers of high-performance computing. In these accelerators, the directed\ngraph describing a neural network can be implemented as a directed graph\ndescribing a Boolean circuit. We make this observation precise, leading\nnaturally to an understanding of practical neural networks as discrete\nfunctions, and show that so-called binarised neural networks are functionally\ncomplete. In general, our results suggest that it is valuable to consider\nBoolean circuits as neural networks, leading to the question of which circuit\ntopologies are promising. We argue that continuity is central to generalisation\nin learning, explore the interaction between data coding, network topology, and\nnode functionality for continuity, and pose some open questions for future\nresearch. As a first step to bridging the gap between continuous and Boolean\nviews of neural network accelerators, we present some recent results from our\nwork on LUTNet, a novel Field-Programmable Gate Array inference approach.\nFinally, we conclude with additional possible fruitful avenues for research\nbridging the continuous and discrete views of neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 09:36:48 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 14:00:24 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Constantinides", "George A.", ""]]}, {"id": "1905.02534", "submitter": "Florian Stelzer", "authors": "Florian Stelzer, Andr\\'e R\\\"ohm, Kathy L\\\"udge, Serhiy Yanchuk", "title": "Performance boost of time-delay reservoir computing by non-resonant\n  clock cycle", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2020.01.010", "report-no": null, "categories": "nlin.AO cs.LG cs.NE math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The time-delay-based reservoir computing setup has seen tremendous success in\nboth experiment and simulation. It allows for the construction of large\nneuromorphic computing systems with only few components. However, until now the\ninterplay of the different timescales has not been investigated thoroughly. In\nthis manuscript, we investigate the effects of a mismatch between the\ntime-delay and the clock cycle for a general model. Typically, these two time\nscales are considered to be equal. Here we show that the case of equal or\nresonant time-delay and clock cycle could be actively detrimental and leads to\nan increase of the approximation error of the reservoir. In particular, we can\nshow that non-resonant ratios of these time scales have maximal memory\ncapacities. We achieve this by translating the periodically driven\ndelay-dynamical system into an equivalent network. Networks that originate from\na system with resonant delay-times and clock cycles fail to utilize all of\ntheir degrees of freedom, which causes the degradation of their performance.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 13:18:14 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 14:06:21 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Stelzer", "Florian", ""], ["R\u00f6hm", "Andr\u00e9", ""], ["L\u00fcdge", "Kathy", ""], ["Yanchuk", "Serhiy", ""]]}, {"id": "1905.02544", "submitter": "Yaroub Elloumi", "authors": "Yaroub Elloumi (LIGM), Mohamed Akil (LIGM), Henda Boudegga", "title": "Ocular Diseases Diagnosis in Fundus Images using a Deep Learning:\n  Approaches, tools and Performance evaluation", "comments": null, "journal-ref": "SPIE Real-Time Image Processing and Deep Learning, Apr 2019,\n  Baltimore, Maryland, United States", "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ocular pathology detection from fundus images presents an important challenge\non health care. In fact, each pathology has different severity stages that may\nbe deduced by verifying the existence of specific lesions. Each lesion is\ncharacterized by morphological features. Moreover, several lesions of different\npathologies have similar features. We note that patient may be affected\nsimultaneously by several pathologies. Consequently, the ocular pathology\ndetection presents a multi-class classification with a complex resolution\nprinciple. Several detection methods of ocular pathologies from fundus images\nhave been proposed. The methods based on deep learning are distinguished by\nhigher performance detection, due to their capability to configure the network\nwith respect to the detection objective. This work proposes a survey of ocular\npathology detection methods based on deep learning. First, we study the\nexisting methods either for lesion segmentation or pathology classification.\nAfterwards, we extract the principle steps of processing and we analyze the\nproposed neural network structures. Subsequently, we identify the hardware and\nsoftware environment required to employ the deep learning architecture.\nThereafter, we investigate about the experimentation principles involved to\nevaluate the methods and the databases used either for training and testing\nphases. The detection performance ratios and execution times are also reported\nand discussed.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 13:21:01 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Elloumi", "Yaroub", "", "LIGM"], ["Akil", "Mohamed", "", "LIGM"], ["Boudegga", "Henda", ""]]}, {"id": "1905.02636", "submitter": "Sam Blakeman", "authors": "Sam Blakeman and Denis Mareschal", "title": "A Complementary Learning Systems Approach to Temporal Difference\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complementary Learning Systems (CLS) theory suggests that the brain uses a\n'neocortical' and a 'hippocampal' learning system to achieve complex behavior.\nThese two systems are complementary in that the 'neocortical' system relies on\nslow learning of distributed representations while the 'hippocampal' system\nrelies on fast learning of pattern-separated representations. Both of these\nsystems project to the striatum, which is a key neural structure in the brain's\nimplementation of Reinforcement Learning (RL). Current deep RL approaches share\nsimilarities with a 'neocortical' system because they slowly learn distributed\nrepresentations through backpropagation in Deep Neural Networks (DNNs). An\nongoing criticism of such approaches is that they are data inefficient and lack\nflexibility. CLS theory suggests that the addition of a 'hippocampal' system\ncould address these criticisms. In the present study we propose a novel\nalgorithm known as Complementary Temporal Difference Learning (CTDL), which\ncombines a DNN with a Self-Organising Map (SOM) to obtain the benefits of both\na 'neocortical' and a 'hippocampal' system. Key features of CTDL include the\nuse of Temporal Difference (TD) error to update a SOM and the combination of a\nSOM and DNN to calculate action values. We evaluate CTDL on grid worlds and the\nCart-Pole environment, and show several benefits over the classic Deep\nQ-Network (DQN) approach. These results demonstrate (1) the utility of\ncomplementary learning systems for the evaluation of actions, (2) that the TD\nerror signal is a useful form of communication between the two systems and (3)\nthe biological plausibility of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 15:17:20 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Blakeman", "Sam", ""], ["Mareschal", "Denis", ""]]}, {"id": "1905.02662", "submitter": "Mikhail Burtsev", "authors": "Artyom Y. Sorokin and Mikhail S. Burtsev", "title": "Continual and Multi-task Reinforcement Learning With Shared Episodic\n  Memory", "comments": "Presented at the Task-Agnostic Reinforcement Learning Workshop at\n  ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Episodic memory plays an important role in the behavior of animals and\nhumans. It allows the accumulation of information about current state of the\nenvironment in a task-agnostic way. This episodic representation can be later\naccessed by down-stream tasks in order to make their execution more efficient.\nIn this work, we introduce the neural architecture with shared episodic memory\n(SEM) for learning and the sequential execution of multiple tasks. We\nexplicitly split the encoding of episodic memory and task-specific memory into\nseparate recurrent sub-networks. An agent augmented with SEM was able to\neffectively reuse episodic knowledge collected during other tasks to improve\nits policy on a current task in the Taxi problem. Repeated use of episodic\nrepresentation in continual learning experiments facilitated acquisition of\nnovel skills in the same environment.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 16:08:36 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Sorokin", "Artyom Y.", ""], ["Burtsev", "Mikhail S.", ""]]}, {"id": "1905.02704", "submitter": "Saima Sharmin", "authors": "Saima Sharmin, Priyadarshini Panda, Syed Shakib Sarwar, Chankyu Lee,\n  Wachirawit Ponghiran and Kaushik Roy", "title": "A Comprehensive Analysis on Adversarial Robustness of Spiking Neural\n  Networks", "comments": "Accepted in IJCNN2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this era of machine learning models, their functionality is being\nthreatened by adversarial attacks. In the face of this struggle for making\nartificial neural networks robust, finding a model, resilient to these attacks,\nis very important. In this work, we present, for the first time, a\ncomprehensive analysis of the behavior of more bio-plausible networks, namely\nSpiking Neural Network (SNN) under state-of-the-art adversarial tests. We\nperform a comparative study of the accuracy degradation between conventional\nVGG-9 Artificial Neural Network (ANN) and equivalent spiking network with\nCIFAR-10 dataset in both whitebox and blackbox setting for different types of\nsingle-step and multi-step FGSM (Fast Gradient Sign Method) attacks. We\ndemonstrate that SNNs tend to show more resiliency compared to ANN under\nblack-box attack scenario. Additionally, we find that SNN robustness is largely\ndependent on the corresponding training mechanism. We observe that SNNs trained\nby spike-based backpropagation are more adversarially robust than the ones\nobtained by ANN-to-SNN conversion rules in several whitebox and blackbox\nscenarios. Finally, we also propose a simple, yet, effective framework for\ncrafting adversarial attacks from SNNs. Our results suggest that attacks\ncrafted from SNNs following our proposed method are much stronger than those\ncrafted from ANNs.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 17:41:36 GMT"}], "update_date": "2019-05-08", "authors_parsed": [["Sharmin", "Saima", ""], ["Panda", "Priyadarshini", ""], ["Sarwar", "Syed Shakib", ""], ["Lee", "Chankyu", ""], ["Ponghiran", "Wachirawit", ""], ["Roy", "Kaushik", ""]]}, {"id": "1905.02776", "submitter": "YangQuan Chen Prof.", "authors": "Jiamin Wei, YangQuan Chen, Yongguang Yu and Yuquan Chen", "title": "Optimal Randomness in Swarm-Based Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  L\\'{e}vy flights is a random walk where the step-lengths have a probability\ndistribution that is heavy-tailed. It has been shown that L\\'{e}vy flights can\nmaximize the efficiency of resource searching in uncertain environments, and\nalso movements of many foragers and wandering animals have been shown to follow\na L\\'{e}vy distribution. The reason mainly comes from that the L\\'{e}vy\ndistribution, has an infinite second moment, and hence is more likely to\ngenerate an offspring that is farther away from its parent. However, the\ninvestigation into the efficiency of other different heavy-tailed probability\ndistributions in swarm-based searches is still insufficient up to now. For\nswarm-based search algorithms, randomness plays a significant role in both\nexploration and exploitation, or diversification and intensification.\nTherefore, it's necessary to discuss the optimal randomness in swarm-based\nsearch algorithms. In this study, CS is taken as a representative method of\nswarm-based optimization algorithms, and the results can be generalized to\nother swarm-based search algorithms. In this paper, four different types of\ncommonly used heavy-tailed distributions, including Mittag-Leffler\ndistribution, Pareto distribution, Cauchy distribution, and Weibull\ndistribution, are considered to enhance the searching ability of CS. Then four\nnovel CS algorithms are proposed and experiments are carried out on 20\nbenchmark functions to compare their searching performances. Finally, the\nproposed methods are used to system identification to demonstrate the\neffectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 19:17:28 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 00:39:21 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Wei", "Jiamin", ""], ["Chen", "YangQuan", ""], ["Yu", "Yongguang", ""], ["Chen", "Yuquan", ""]]}, {"id": "1905.02791", "submitter": "Jonathan Mailoa", "authors": "Jonathan P. Mailoa, Mordechai Kornbluth, Simon L. Batzner, Georgy\n  Samsonidze, Stephen T. Lam, Chris Ablitt, Nicola Molinari, Boris Kozinsky", "title": "Fast Neural Network Approach for Direct Covariant Forces Prediction in\n  Complex Multi-Element Extended Systems", "comments": null, "journal-ref": "Nature Machine Intelligence 1 (2019)", "doi": "10.1038/s42256-019-0098-0", "report-no": null, "categories": "physics.comp-ph cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network force field (NNFF) is a method for performing regression on\natomic structure-force relationships, bypassing expensive quantum mechanics\ncalculation which prevents the execution of long ab-initio quality molecular\ndynamics simulations. However, most NNFF methods for complex multi-element\natomic systems indirectly predict atomic force vectors by exploiting just\natomic structure rotation-invariant features and the network-feature spatial\nderivatives which are computationally expensive. We develop a staggered NNFF\narchitecture exploiting both rotation-invariant and covariant features\nseparately to directly predict atomic force vectors without using spatial\nderivatives, thereby reducing expensive structural feature calculation by\n~180-480x. This acceleration enables us to develop NNFF which directly predicts\natomic forces in complex ternary and quaternary-element extended systems\ncomprised of long polymer chains, amorphous oxide, and surface chemical\nreactions. The staggered rotation-invariant-covariant architecture described\nhere can also directly predict complex covariant vector outputs from local\nphysical structures in domains beyond computational material science.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 19:54:59 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Mailoa", "Jonathan P.", ""], ["Kornbluth", "Mordechai", ""], ["Batzner", "Simon L.", ""], ["Samsonidze", "Georgy", ""], ["Lam", "Stephen T.", ""], ["Ablitt", "Chris", ""], ["Molinari", "Nicola", ""], ["Kozinsky", "Boris", ""]]}, {"id": "1905.02954", "submitter": "Matin Hashemi", "authors": "Alireza Amirshahi, Matin Hashemi", "title": "Ultra Low-Power and Real-time ECG Classification Based on STDP and\n  R-STDP Neural Networks for Wearable Devices", "comments": "Published in IEEE Transactions on Biomedical Circuits and Systems\n  (TBioCAS), 2019", "journal-ref": null, "doi": "10.1109/TBCAS.2019.2948920", "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel ECG classification algorithm for real-time\ncardiac monitoring on ultra low-power wearable devices. The proposed solution\nis based on spiking neural networks which are the third generation of neural\nnetworks. In specific, we employ spike-timing dependent plasticity (STDP), and\nreward-modulated STDP (R-STDP), in which the model weights are trained\naccording to the timings of spike signals, and reward or punishment signals.\nExperiments show that the proposed solution is suitable for real-time\noperation, achieves comparable accuracy with respect to previous methods, and\nmore importantly, its energy consumption is significantly smaller than previous\nneural network based solutions.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 08:26:36 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 14:33:39 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 09:26:36 GMT"}, {"version": "v4", "created": "Thu, 19 Dec 2019 11:06:42 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Amirshahi", "Alireza", ""], ["Hashemi", "Matin", ""]]}, {"id": "1905.02969", "submitter": "Filipe Assun\\c{c}\\~ao", "authors": "Filipe Assun\\c{c}\\~ao, Nuno Louren\\c{c}o, Penousal Machado, Bernardete\n  Ribeiro", "title": "Fast-DENSER++: Evolving Fully-Trained Deep Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new extension to Deep Evolutionary Network Structured\nEvolution (DENSER), called Fast-DENSER++ (F-DENSER++). The vast majority of\nNeuroEvolution methods that optimise Deep Artificial Neural Networks (DANNs)\nonly evaluate the candidate solutions for a fixed amount of epochs; this makes\nit difficult to effectively assess the learning strategy, and requires the best\ngenerated network to be further trained after evolution. F-DENSER++ enables the\ntraining time of the candidate solutions to grow continuously as necessary,\ni.e., in the initial generations the candidate solutions are trained for\nshorter times, and as generations proceed it is expected that longer training\ncycles enable better performances. Consequently, the models discovered by\nF-DENSER++ are fully-trained DANNs, and are ready for deployment after\nevolution, without the need for further training. The results demonstrate the\nability of F-DENSER++ to effectively generate fully-trained DANNs; by the end\nof evolution, whilst the average performance of the models generated by\nF-DENSER++ is of 88.73%, the performance of the models generated by the\nprevious version of DENSER (Fast-DENSER) is 86.91% (statistically significant),\nwhich increases to 87.76% when allowed to train for longer.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 09:14:32 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Assun\u00e7\u00e3o", "Filipe", ""], ["Louren\u00e7o", "Nuno", ""], ["Machado", "Penousal", ""], ["Ribeiro", "Bernardete", ""]]}, {"id": "1905.03046", "submitter": "Peter Meltzer", "authors": "Peter Meltzer, Marcelo Daniel Gutierrez Mallea and Peter J. Bentley", "title": "PiNet: A Permutation Invariant Graph Neural Network for Graph\n  Classification", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end deep learning learning model for graph\nclassification and representation learning that is invariant to permutation of\nthe nodes of the input graphs. We address the challenge of learning a fixed\nsize graph representation for graphs of varying dimensions through a\ndifferentiable node attention pooling mechanism. In addition to a theoretical\nproof of its invariance to permutation, we provide empirical evidence\ndemonstrating the statistically significant gain in accuracy when faced with an\nisomorphic graph classification task given only a small number of training\nexamples. We analyse the effect of four different matrices to facilitate the\nlocal message passing mechanism by which graph convolutions are performed vs. a\nmatrix parametrised by a learned parameter pair able to transition smoothly\nbetween the former. Finally, we show that our model achieves competitive\nclassification performance with existing techniques on a set of molecule\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 12:51:52 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Meltzer", "Peter", ""], ["Mallea", "Marcelo Daniel Gutierrez", ""], ["Bentley", "Peter J.", ""]]}, {"id": "1905.03219", "submitter": "Priyadarshini Panda", "authors": "Priyadarshini Panda, Efstathia Soufleri, and Kaushik Roy", "title": "Evaluating the Stability of Recurrent Neural Models during Training with\n  Eigenvalue Spectra Analysis", "comments": "Accepted in IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the stability of recurrent networks, specifically, reservoir\ncomputing models during training by evaluating the eigenvalue spectra of the\nreservoir dynamics. To circumvent the instability arising in examining a closed\nloop reservoir system with feedback, we propose to break the closed loop\nsystem. Essentially, we unroll the reservoir dynamics over time while\nincorporating the feedback effects that preserve the overall temporal integrity\nof the system. We evaluate our methodology for fixed point and time varying\ntargets with least squares regression and FORCE training, respectively. Our\nanalysis establishes eigenvalue spectra (which is, shrinking of spectral circle\nas training progresses) as a valid and effective metric to gauge the\nconvergence of training as well as the convergence of the chaotic activity of\nthe reservoir toward stable states.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 17:12:51 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Panda", "Priyadarshini", ""], ["Soufleri", "Efstathia", ""], ["Roy", "Kaushik", ""]]}, {"id": "1905.03389", "submitter": "Vladimir Golkov", "authors": "Jan Schuchardt, Vladimir Golkov, Daniel Cremers", "title": "Learning to Evolve", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution and learning are two of the fundamental mechanisms by which life\nadapts in order to survive and to transcend limitations. These biological\nphenomena inspired successful computational methods such as evolutionary\nalgorithms and deep learning. Evolution relies on random mutations and on\nrandom genetic recombination. Here we show that learning to evolve, i.e.\nlearning to mutate and recombine better than at random, improves the result of\nevolution in terms of fitness increase per generation and even in terms of\nattainable fitness. We use deep reinforcement learning to learn to dynamically\nadjust the strategy of evolutionary algorithms to varying circumstances. Our\nmethods outperform classical evolutionary algorithms on combinatorial and\ncontinuous optimization problems.\n", "versions": [{"version": "v1", "created": "Wed, 8 May 2019 23:35:02 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Schuchardt", "Jan", ""], ["Golkov", "Vladimir", ""], ["Cremers", "Daniel", ""]]}, {"id": "1905.03418", "submitter": "arXiv Admin", "authors": "Gael Kamdem De Teyou", "title": "Deep Learning Acceleration Techniques for Real Time Mobile Vision\n  Applications", "comments": "This submission has been withdrawn by arXiv administrators due to\n  inappropriate text reuse from external sources", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) has become a crucial technology for Artificial\nIntelligence (AI). It is a powerful technique to automatically extract\nhigh-level features from complex data which can be exploited for applications\nsuch as computer vision, natural language processing, cybersecurity,\ncommunications, and so on. For the particular case of computer vision, several\nalgorithms like object detection in real time videos have been proposed and\nthey work well on Desktop GPUs and distributed computing platforms. However\nthese algorithms are still heavy for mobile and embedded visual applications.\nThe rapid spreading of smart portable devices and the emerging 5G network are\nintroducing new smart multimedia applications in mobile environments. As a\nconsequence, the possibility of implementing deep neural networks to mobile\nenvironments has attracted a lot of researchers. This paper presents emerging\ndeep learning acceleration techniques that can enable the delivery of real time\nvisual recognition into the hands of end users, anytime and anywhere.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 02:39:37 GMT"}, {"version": "v2", "created": "Fri, 7 Jun 2019 15:31:48 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["De Teyou", "Gael Kamdem", ""]]}, {"id": "1905.03532", "submitter": "Filipe Assun\\c{c}\\~ao", "authors": "Filipe Assun\\c{c}\\~ao and Jo\\~ao Correia and R\\'uben Concei\\c{c}\\~ao\n  and M\\'ario Pimenta and Bernardo Tom\\'e and Nuno Louren\\c{c}o and Penousal\n  Machado", "title": "Automatic Design of Artificial Neural Networks for Gamma-Ray Detection", "comments": null, "journal-ref": "in IEEE Access, vol. 7, pp. 110531-110540, 2019", "doi": "10.1109/ACCESS.2019.2933947", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this work is to investigate the possibility of improving current\ngamma/hadron discrimination based on their shower patterns recorded on the\nground. To this end we propose the use of Convolutional Neural Networks (CNNs)\nfor their ability to distinguish patterns based on automatically designed\nfeatures. In order to promote the creation of CNNs that properly uncover the\nhidden patterns in the data, and at same time avoid the burden of hand-crafting\nthe topology and learning hyper-parameters we resort to NeuroEvolution; in\nparticular we use Fast-DENSER++, a variant of Deep Evolutionary Network\nStructured Representation. The results show that the best CNN generated by\nFast-DENSER++ improves by a factor of 2 when compared with the results reported\nby classic statistical approaches. Additionally, we experiment ensembling the\n10 best generated CNNs, one from each of the evolutionary runs; the ensemble\nleads to an improvement by a factor of 2.3. These results show that it is\npossible to improve the gamma/hadron discrimination based on CNNs that are\nautomatically generated and are trained with instances of the ground impact\npatterns.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 11:13:06 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Assun\u00e7\u00e3o", "Filipe", ""], ["Correia", "Jo\u00e3o", ""], ["Concei\u00e7\u00e3o", "R\u00faben", ""], ["Pimenta", "M\u00e1rio", ""], ["Tom\u00e9", "Bernardo", ""], ["Louren\u00e7o", "Nuno", ""], ["Machado", "Penousal", ""]]}, {"id": "1905.03617", "submitter": "Sungjae Cho", "authors": "Sungjae Cho, Jaeseo Lim, Chris Hickey, Jung Ae Park, Byoung-Tak Zhang", "title": "Simulating Problem Difficulty in Arithmetic Cognition Through Dynamic\n  Connectionist Models", "comments": "7 pages; 15 figures; 5 tables; Published in the proceedings of the\n  17th International Conference on Cognitive Modelling (ICCM 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study aims to investigate similarities between how humans and\nconnectionist models experience difficulty in arithmetic problems. Problem\ndifficulty was operationalized by the number of carries involved in solving a\ngiven problem. Problem difficulty was measured in humans by response time, and\nin models by computational steps. The present study found that both humans and\nconnectionist models experience difficulty similarly when solving binary\naddition and subtraction. Specifically, both agents found difficulty to be\nstrictly increasing with respect to the number of carries. Another notable\nsimilarity is that problem difficulty increases more steeply in subtraction\nthan in addition, for both humans and connectionist models. Further\ninvestigation on two model hyperparameters --- confidence threshold and hidden\ndimension --- shows higher confidence thresholds cause the model to take more\ncomputational steps to arrive at the correct answer. Likewise, larger hidden\ndimensions cause the model to take more computational steps to correctly answer\narithmetic problems; however, this effect by hidden dimensions is negligible.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 13:33:59 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 19:07:40 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 04:55:49 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Cho", "Sungjae", ""], ["Lim", "Jaeseo", ""], ["Hickey", "Chris", ""], ["Park", "Jung Ae", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1905.03642", "submitter": "Andre Pacheco", "authors": "Andre G. C. Pacheco", "title": "Classifica\\c{c}\\~ao de esp\\'ecies de peixe utilizando redes neurais\n  convolucional", "comments": "in Portuguese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data classification is present in different real problems, such as\nrecognizing patterns in images, differentiating defective parts in a production\nline, classifying benign and malignant tumors, among many others. Many of these\nproblems have data patterns that are hard to identify, which requires more\nadvanced techniques for resolution. Recently, several works addressing\ndifferent artificial neural network architectures have been applied to solve\nclassification problems. When the classification problem must be obtained\nthrough images, currently, the standard methodology is the use of convolutional\nneural networks. Thus, in this report convolutional neural networks are used to\nclassify fish species.\n  Classifica\\c{c}\\~ao de dados est\\'a presente em diversos problemas reais,\ntais como: reconhecer padr\\~oes em imagens, diferenciar pe\\c{c}as defeituosas\nem uma linha de produ\\c{c}\\~ao, classificar tumores benignos e malignos, dentre\ndiversas outras. Muitos desses problemas possuem padr\\~oes de dados dif\\'iceis\nde serem identificados, o que requer, consequentemente, t\\'ecnicas mais\navan\\c{c}adas para sua resolu\\c{c}\\~ao. Recentemente, diversos trabalhos\nabordando diferentes arquiteturas de redes neurais artificiais v\\^em sendo\naplicados para solucionar problemas de classifica\\c{c}\\~ao. Quando a\nclassifica\\c{c}\\~ao do problema deve ser obtida por meio de imagens, atualmente\na metodologia padr\\~ao \\'e uso de redes neurais convolucionais. Sendo assim,\nneste trabalho s\\~ao utilizadas redes neurais convolucionais para\nclassifica\\c{c}\\~ao de esp\\'ecies de peixes.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 14:05:42 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Pacheco", "Andre G. C.", ""]]}, {"id": "1905.03726", "submitter": "Luca Mossina", "authors": "Luca Mossina and Emmanuel Rachelson and Daniel Delahaye", "title": "A Reinforcement Learning Perspective on the Optimal Control of Mutation\n  Probabilities for the (1+1) Evolutionary Algorithm: First Results on the\n  OneMax Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how Reinforcement Learning can be employed to optimally control\nparameters in evolutionary algorithms. We control the mutation probability of a\n(1+1) evolutionary algorithm on the OneMax function. This problem is modeled as\na Markov Decision Process and solved with Value Iteration via the known\ntransition probabilities. It is then solved via Q-Learning, a Reinforcement\nLearning algorithm, where the exact transition probabilities are not needed.\nThis approach also allows previous expert or empirical knowledge to be included\ninto learning. It opens new perspectives, both formally and computationally,\nfor the problem of parameter control in optimization.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 16:07:37 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Mossina", "Luca", ""], ["Rachelson", "Emmanuel", ""], ["Delahaye", "Daniel", ""]]}, {"id": "1905.03812", "submitter": "Andrew Stephan", "authors": "Andrew W. Stephan and Steven J. Koester", "title": "Convolutional Neural Networks Utilizing Multifunctional Spin-Hall MTJ\n  Neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new network architecture for standard spin-Hall magnetic tunnel\njunction-based spintronic neurons that allows them to compute multiple critical\nconvolutional neural network functionalities simultaneously and in parallel,\nsaving space and time. An approximation to the Rectified Linear Unit transfer\nfunction and the local pooling function are computed simultaneously with the\nconvolution operation itself. A proof-of-concept simulation is performed on the\nMNIST dataset, achieving up to 98% accuracy at a cost of less than 1 nJ for all\nconvolution, activation and pooling operations combined. The simulations are\nremarkably robust to thermal noise, performing well even with very small\nmagnetic layers.\n", "versions": [{"version": "v1", "created": "Thu, 9 May 2019 18:37:00 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Stephan", "Andrew W.", ""], ["Koester", "Steven J.", ""]]}, {"id": "1905.04042", "submitter": "Lu Liu", "authors": "Lu Liu, Tianyi Zhou, Guodong Long, Jing Jiang, Lina Yao, Chengqi Zhang", "title": "Prototype Propagation Networks (PPN) for Weakly-supervised Few-shot\n  Learning on Category Graph", "comments": "Accepted to IJCAI 2019, Code is publicly available at:\n  https://github.com/liulu112601/PPN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of machine learning applications expect to achieve rapid learning\nfrom a limited number of labeled data. However, the success of most current\nmodels is the result of heavy training on big data. Meta-learning addresses\nthis problem by extracting common knowledge across different tasks that can be\nquickly adapted to new tasks. However, they do not fully explore\nweakly-supervised information, which is usually free or cheap to collect. In\nthis paper, we show that weakly-labeled data can significantly improve the\nperformance of meta-learning on few-shot classification. We propose prototype\npropagation network (PPN) trained on few-shot tasks together with data\nannotated by coarse-label. Given a category graph of the targeted fine-classes\nand some weakly-labeled coarse-classes, PPN learns an attention mechanism which\npropagates the prototype of one class to another on the graph, so that the\nK-nearest neighbor (KNN) classifier defined on the propagated prototypes\nresults in high accuracy across different few-shot tasks. The training tasks\nare generated by subgraph sampling, and the training objective is obtained by\naccumulating the level-wise classification loss on the subgraph. The resulting\ngraph of prototypes can be continually re-used and updated for new tasks and\nclasses. We also introduce two practical test/inference settings which differ\naccording to whether the test task can leverage any weakly-supervised\ninformation as in training. On two benchmarks, PPN significantly outperforms\nmost recent few-shot learning methods in different settings, even when they are\nalso allowed to train on weakly-labeled data.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 09:57:23 GMT"}, {"version": "v2", "created": "Sun, 2 Jun 2019 12:40:13 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Liu", "Lu", ""], ["Zhou", "Tianyi", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Yao", "Lina", ""], ["Zhang", "Chengqi", ""]]}, {"id": "1905.04099", "submitter": "Maryam Hasani-Shoreh", "authors": "Maryam Hasani-Shoreh, Mar\\'ia-Yaneli Ameca-Alducin, Wilson Blaikie,\n  Frank Neumann, Marc Schoenauer", "title": "On the Behaviour of Differential Evolution for Problems with Dynamic\n  Linear Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms have been widely applied for solving dynamic\nconstrained optimization problems (DCOPs) as a common area of research in\nevolutionary optimization. Current benchmarks proposed for testing these\nproblems in the continuous spaces are either not scalable in problem dimension\nor the settings for the environmental changes are not flexible. Moreover, they\nmainly focus on non-linear environmental changes on the objective function.\nWhile the dynamism in some real-world problems exists in the constraints and\ncan be emulated with linear constraint changes. The purpose of this paper is to\nintroduce a framework which produces benchmarks in which a dynamic environment\nis created with simple changes in linear constraints (rotation and translation\nof constraint's hyperplane). Our proposed framework creates dynamic benchmarks\nthat are flexible in terms of number of changes, dimension of the problem and\ncan be applied to test any objective function. Different constraint handling\ntechniques will then be used to compare with our benchmark. The results reveal\nthat with these changes set, there was an observable effect on the performance\nof the constraint handling techniques.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 03:46:14 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 02:06:11 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 02:03:22 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Hasani-Shoreh", "Maryam", ""], ["Ameca-Alducin", "Mar\u00eda-Yaneli", ""], ["Blaikie", "Wilson", ""], ["Neumann", "Frank", ""], ["Schoenauer", "Marc", ""]]}, {"id": "1905.04100", "submitter": "Hung La", "authors": "Adarsh Sehgal, Hung Manh La, Sushil J. Louis, Hai Nguyen", "title": "Deep Reinforcement Learning using Genetic Algorithm for Parameter\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) enables agents to take decision based on a reward\nfunction. However, in the process of learning, the choice of values for\nlearning algorithm parameters can significantly impact the overall learning\nprocess. In this paper, we use a genetic algorithm (GA) to find the values of\nparameters used in Deep Deterministic Policy Gradient (DDPG) combined with\nHindsight Experience Replay (HER), to help speed up the learning agent. We used\nthis method on fetch-reach, slide, push, pick and place, and door opening in\nrobotic manipulation tasks. Our experimental evaluation shows that our method\nleads to better performance, faster than the original algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2019 20:11:08 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Sehgal", "Adarsh", ""], ["La", "Hung Manh", ""], ["Louis", "Sushil J.", ""], ["Nguyen", "Hai", ""]]}, {"id": "1905.04101", "submitter": "Bernd Illing", "authors": "Bernd Illing, Wulfram Gerstner, Johanni Brea", "title": "Biologically plausible deep learning -- but how far can we go with\n  shallow networks?", "comments": "14 pages, 4 figures", "journal-ref": "Neural Networks, Volume 118, October 2019, Pages 90-101", "doi": "10.1016/j.neunet.2019.06.001", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep neural networks with the error backpropagation algorithm is\nconsidered implausible from a biological perspective. Numerous recent\npublications suggest elaborate models for biologically plausible variants of\ndeep learning, typically defining success as reaching around 98% test accuracy\non the MNIST data set. Here, we investigate how far we can go on digit (MNIST)\nand object (CIFAR10) classification with biologically plausible, local learning\nrules in a network with one hidden layer and a single readout layer. The hidden\nlayer weights are either fixed (random or random Gabor filters) or trained with\nunsupervised methods (PCA, ICA or Sparse Coding) that can be implemented by\nlocal learning rules. The readout layer is trained with a supervised, local\nlearning rule. We first implement these models with rate neurons. This\ncomparison reveals, first, that unsupervised learning does not lead to better\nperformance than fixed random projections or Gabor filters for large hidden\nlayers. Second, networks with localized receptive fields perform significantly\nbetter than networks with all-to-all connectivity and can reach backpropagation\nperformance on MNIST. We then implement two of the networks - fixed, localized,\nrandom & random Gabor filters in the hidden layer - with spiking leaky\nintegrate-and-fire neurons and spike timing dependent plasticity to train the\nreadout layer. These spiking models achieve > 98.2% test accuracy on MNIST,\nwhich is close to the performance of rate networks with one hidden layer\ntrained with backpropagation. The performance of our shallow network models is\ncomparable to most current biologically plausible models of deep learning.\nFurthermore, our results with a shallow spiking network provide an important\nreference and suggest the use of datasets other than MNIST for testing the\nperformance of future models of biologically plausible deep learning.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2019 13:16:28 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 15:54:19 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Illing", "Bernd", ""], ["Gerstner", "Wulfram", ""], ["Brea", "Johanni", ""]]}, {"id": "1905.04175", "submitter": "Fabien Lotte", "authors": "Giuseppe Amato (CNR PISA), Malte Behrmann, Fr\\'ed\\'eric Bimbot\n  (PANAMA), Baptiste Caramiaux (LRI, EX-SITU), Fabrizio Falchi (CNR PISA),\n  Ander Garcia, Joost Geurts (Inria), Jaume Gibert, Guillaume Gravier\n  (LinkMedia), Hadmut Holken, Hartmut Koenitz (HKU), Sylvain Lefebvre (MFX),\n  Antoine Liutkus (LORIA, ZENITH), Fabien Lotte (Potioc, LaBRI), Andrew Perkis\n  (NTNU), Rafael Redondo, Enrico Turrin (FEP), Thierry Vieville (Mnemosyne),\n  Emmanuel Vincent (MULTISPEECH)", "title": "AI in the media and creative industries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to the Big Data revolution and increasing computing capacities,\nArtificial Intelligence (AI) has made an impressive revival over the past few\nyears and is now omnipresent in both research and industry. The creative\nsectors have always been early adopters of AI technologies and this continues\nto be the case. As a matter of fact, recent technological developments keep\npushing the boundaries of intelligent systems in creative applications: the\ncritically acclaimed movie \"Sunspring\", released in 2016, was entirely written\nby AI technology, and the first-ever Music Album, called \"Hello World\",\nproduced using AI has been released this year. Simultaneously, the exploratory\nnature of the creative process is raising important technical challenges for AI\nsuch as the ability for AI-powered techniques to be accurate under limited data\nresources, as opposed to the conventional \"Big Data\" approach, or the ability\nto process, analyse and match data from multiple modalities (text, sound,\nimages, etc.) at the same time. The purpose of this white paper is to\nunderstand future technological advances in AI and their growing impact on\ncreative industries. This paper addresses the following questions: Where does\nAI operate in creative Industries? What is its operative role? How will AI\ntransform creative industries in the next ten years? This white paper aims to\nprovide a realistic perspective of the scope of AI actions in creative\nindustries, proposes a vision of how this technology could contribute to\nresearch and development works in such context, and identifies research and\ndevelopment challenges.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 13:56:52 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Amato", "Giuseppe", "", "CNR PISA"], ["Behrmann", "Malte", "", "PANAMA"], ["Bimbot", "Fr\u00e9d\u00e9ric", "", "PANAMA"], ["Caramiaux", "Baptiste", "", "LRI, EX-SITU"], ["Falchi", "Fabrizio", "", "CNR PISA"], ["Garcia", "Ander", "", "Inria"], ["Geurts", "Joost", "", "Inria"], ["Gibert", "Jaume", "", "LinkMedia"], ["Gravier", "Guillaume", "", "LinkMedia"], ["Holken", "Hadmut", "", "HKU"], ["Koenitz", "Hartmut", "", "HKU"], ["Lefebvre", "Sylvain", "", "MFX"], ["Liutkus", "Antoine", "", "LORIA, ZENITH"], ["Lotte", "Fabien", "", "Potioc, LaBRI"], ["Perkis", "Andrew", "", "NTNU"], ["Redondo", "Rafael", "", "FEP"], ["Turrin", "Enrico", "", "FEP"], ["Vieville", "Thierry", "", "Mnemosyne"], ["Vincent", "Emmanuel", "", "MULTISPEECH"]]}, {"id": "1905.04222", "submitter": "Alexander Wong", "authors": "Zhong Qiu Lin, Brendan Chwyl, and Alexander Wong", "title": "EdgeSegNet: A Compact Network for Semantic Segmentation", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we introduce EdgeSegNet, a compact deep convolutional neural\nnetwork for the task of semantic segmentation. A human-machine collaborative\ndesign strategy is leveraged to create EdgeSegNet, where principled network\ndesign prototyping is coupled with machine-driven design exploration to create\nnetworks with customized module-level macroarchitecture and microarchitecture\ndesigns tailored for the task. Experimental results showed that EdgeSegNet can\nachieve semantic segmentation accuracy comparable with much larger and\ncomputationally complex networks (>20x} smaller model size than RefineNet) as\nwell as achieving an inference speed of ~38.5 FPS on an NVidia Jetson AGX\nXavier. As such, the proposed EdgeSegNet is well-suited for low-power edge\nscenarios.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 15:43:23 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Lin", "Zhong Qiu", ""], ["Chwyl", "Brendan", ""], ["Wong", "Alexander", ""]]}, {"id": "1905.04232", "submitter": "Patrik Christen", "authors": "Patrik Christen and Olivier Del Fabbro", "title": "Automatic Programming of Cellular Automata and Artificial Neural\n  Networks Guided by Philosophy", "comments": "12 pages, 1 figure", "journal-ref": "Rolf Dornberger, editor, New Trends in Business Information\n  Systems and Technology: Digital Innovation and Digital Business\n  Transformation, pages 131-146. Springer, Cham, 2020", "doi": "10.1007/978-3-030-48332-6", "report-no": null, "categories": "cs.AI cs.LG cs.MA cs.NE cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many computer models such as cellular automata and artificial neural networks\nhave been developed and successfully applied. However, in some cases, these\nmodels might be restrictive on the possible solutions or their solutions might\nbe difficult to interpret. To overcome this problem, we outline a new approach,\nthe so-called allagmatic method, that automatically programs and executes\nmodels with as little limitations as possible while maintaining human\ninterpretability. Earlier we described a metamodel and its building blocks\naccording to the philosophical concepts of structure (spatial dimension) and\noperation (temporal dimension). They are entity, milieu, and update function\nthat together abstractly describe cellular automata, artificial neural\nnetworks, and possibly any kind of computer model. By automatically combining\nthese building blocks in an evolutionary computation, interpretability might be\nincreased by the relationship to the metamodel, and models might be translated\ninto more interpretable models via the metamodel. We propose generic and\nobject-oriented programming to implement the entities and their milieus as\ndynamic and generic arrays and the update function as a method. We show two\nexperiments where a simple cellular automaton and an artificial neural network\nare automatically programmed, compiled, and executed. A target state is\nsuccessfully evolved and learned in the cellular automaton and artificial\nneural network, respectively. We conclude that the allagmatic method can create\nand execute cellular automaton and artificial neural network models in an\nautomated manner with the guidance of philosophy.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 16:00:09 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 14:03:51 GMT"}, {"version": "v3", "created": "Wed, 24 Jul 2019 10:06:41 GMT"}, {"version": "v4", "created": "Wed, 20 Nov 2019 08:47:05 GMT"}, {"version": "v5", "created": "Sun, 3 May 2020 21:05:20 GMT"}, {"version": "v6", "created": "Mon, 31 Aug 2020 21:45:47 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Christen", "Patrik", ""], ["Del Fabbro", "Olivier", ""]]}, {"id": "1905.04392", "submitter": "Mohsen Joneidi", "authors": "Mohsen Joneidi, Ismail Alkhouri, Nazanin Rahnavard", "title": "Large-Scale Spectrum Occupancy Learning via Tensor Decomposition and\n  LSTM Networks", "comments": "Submitted to the 2019 IEEE Global Communications Conference\n  (GLOBECOM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new paradigm for large-scale spectrum occupancy learning based on long\nshort-term memory (LSTM) recurrent neural networks is proposed. Studies have\nshown that spectrum usage is a highly correlated time series. Moreover, there\nis a correlation for occupancy of spectrum between different frequency\nchannels. Therefore, revealing all these correlations using learning and\nprediction of one-dimensional time series is not a trivial task. In this paper,\nwe introduce a new framework for representing the spectrum measurements in a\ntensor format. Next, a time-series prediction method based on CANDECOMP/PARFAC\n(CP) tensor decomposition and LSTM recurrent neural networks is proposed. The\nproposed method is computationally efficient and is able to capture different\ntypes of correlation within the measured spectrum. Moreover, it is robust\nagainst noise and missing entries of sensed spectrum. The superiority of the\nproposed method is evaluated over a large-scale synthetic dataset in terms of\nprediction accuracy and computational efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 22:22:04 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Joneidi", "Mohsen", ""], ["Alkhouri", "Ismail", ""], ["Rahnavard", "Nazanin", ""]]}, {"id": "1905.04394", "submitter": "Muhammad Aminul Islam", "authors": "Muhammad Aminul Islam, Derek T. Anderson, Anthony J. Pinar, Timothy C.\n  Havens, Grant Scott, James M. Keller", "title": "Enabling Explainable Fusion in Deep Learning with Fuzzy Integral Neural\n  Networks", "comments": "IEEE Transactions on Fuzzy Systems", "journal-ref": null, "doi": "10.1109/TFUZZ.2019.2917124", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information fusion is an essential part of numerous engineering systems and\nbiological functions, e.g., human cognition. Fusion occurs at many levels,\nranging from the low-level combination of signals to the high-level aggregation\nof heterogeneous decision-making processes. While the last decade has witnessed\nan explosion of research in deep learning, fusion in neural networks has not\nobserved the same revolution. Specifically, most neural fusion approaches are\nad hoc, are not understood, are distributed versus localized, and/or\nexplainability is low (if present at all). Herein, we prove that the fuzzy\nChoquet integral (ChI), a powerful nonlinear aggregation function, can be\nrepresented as a multi-layer network, referred to hereafter as ChIMP. We also\nput forth an improved ChIMP (iChIMP) that leads to a stochastic gradient\ndescent-based optimization in light of the exponential number of ChI inequality\nconstraints. An additional benefit of ChIMP/iChIMP is that it enables\neXplainable AI (XAI). Synthetic validation experiments are provided and iChIMP\nis applied to the fusion of a set of heterogeneous architecture deep models in\nremote sensing. We show an improvement in model accuracy and our previously\nestablished XAI indices shed light on the quality of our data, model, and its\ndecisions.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 22:31:22 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Islam", "Muhammad Aminul", ""], ["Anderson", "Derek T.", ""], ["Pinar", "Anthony J.", ""], ["Havens", "Timothy C.", ""], ["Scott", "Grant", ""], ["Keller", "James M.", ""]]}, {"id": "1905.04522", "submitter": "Arijit Nandi", "authors": "Arijit Nandi, Nanda Dulal Jana", "title": "Accuracy Improvement of Neural Network Training using Particle Swarm\n  Optimization and its Stability Analysis for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised classification is the most active and emerging research trends in\ntoday's scenario. In this view, Artificial Neural Network (ANN) techniques have\nbeen widely employed and growing interest to the researchers day by day. ANN\ntraining aims to find the proper setting of parameters such as weights\n($\\textbf{W}$) and biases ($b$) to properly classify the given data samples.\nThe training process is formulated in an error minimization problem which\nconsists of many local optima in the search landscape. In this paper, an\nenhanced Particle Swarm Optimization is proposed to minimize the error function\nfor classifying real-life data sets. A stability analysis is performed to\nestablish the efficiency of the proposed method for improving classification\naccuracy. The performance measurement such as confusion matrix, $F$-measure and\nconvergence graph indicates the significant improvement in the classification\naccuracy.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 13:08:50 GMT"}, {"version": "v2", "created": "Wed, 15 May 2019 04:51:50 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Nandi", "Arijit", ""], ["Jana", "Nanda Dulal", ""]]}, {"id": "1905.04545", "submitter": "Adriano Baldeschi", "authors": "Adriano Baldeschi, Raffaella Margutti, Adam Miller", "title": "Deep Learning: a new definition of artificial neuron with double weight", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is a subset of a broader family of machine learning methods\nbased on learning data representations. These models are inspired by human\nbiological nervous systems, even if there are various differences pertaining to\nthe structural and functional properties of biological brains. The elementary\nconstituents of deep learning models are neurons, which can be considered as\nfunctions that receive inputs and produce an output that is a weighted sum of\nthe inputs fed through an activation function. Several models of neurons were\nproposed in the course of the years that are all based on learnable parameters\ncalled weights. In this paper we present a new type of artificial neuron, the\ndouble-weight neuron,characterized by additional learnable weights that lead to\na more complex and accurate system. We tested a feed-forward and convolutional\nneural network consisting of double-weight neurons on the MNIST dataset, and we\ntested a convolution network on the CIFAR-10 dataset. For MNIST we find a\n$\\approx 4\\%$ and $\\approx 1\\%$ improved classification accuracy, respectively,\nwhen compared to a standard feed-forward and convolutional neural network built\nwith the same sets of hyperparameters. For CIFAR-10 we find a $\\approx 12\\%$\nimproved classification accuracy. We thus conclude that this novel artificial\nneuron can be considered as a valuable alternative to common ones.\n", "versions": [{"version": "v1", "created": "Sat, 11 May 2019 16:00:08 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 18:20:39 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Baldeschi", "Adriano", ""], ["Margutti", "Raffaella", ""], ["Miller", "Adam", ""]]}, {"id": "1905.04842", "submitter": "Jessie(Zexi) Sun", "authors": "Jessie Sun", "title": "A Stock Selection Method Based on Earning Yield Forecast Using Sequence\n  Prediction Models", "comments": "10 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-fin.MF q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-term investors, different from short-term traders, focus on examining\nthe underlying forces that affect the well-being of a company. They rely on\nfundamental analysis which attempts to measure the intrinsic value an equity.\nQuantitative investment researchers have identified some value factors to\ndetermine the cost of investment for a stock and compare different stocks. This\npaper proposes using sequence prediction models to forecast a value factor-the\nearning yield (EBIT/EV) of a company for stock selection. Two advanced sequence\nprediction models-Long Short-term Memory (LSTM) and Gated Recurrent Unit (GRU)\nnetworks are studied. These two models can overcome the inherent problems of a\nstandard Recurrent Neural Network, i.e., vanishing and exploding gradients.\nThis paper firstly introduces the theories of the networks. And then elaborates\nthe workflow of stock pool creation, feature selection, data structuring, model\nsetup and model evaluation. The LSTM and GRU models demonstrate superior\nperformance of forecast accuracy over a traditional Feedforward Neural Network\nmodel. The GRU model slightly outperformed the LSTM model.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 03:02:39 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Sun", "Jessie", ""]]}, {"id": "1905.04926", "submitter": "David Balduzzi", "authors": "Alistair Letcher and David Balduzzi and Sebastien Racaniere and James\n  Martens and Jakob Foerster and Karl Tuyls and Thore Graepel", "title": "Differentiable Game Mechanics", "comments": "JMLR 2019, journal version of arXiv:1802.05642", "journal-ref": "Journal of Machine Learning Research (JMLR), v20 (84) 1-40, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.MA cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is built on the foundational guarantee that gradient descent on\nan objective function converges to local minima. Unfortunately, this guarantee\nfails in settings, such as generative adversarial nets, that exhibit multiple\ninteracting losses. The behavior of gradient-based methods in games is not well\nunderstood -- and is becoming increasingly important as adversarial and\nmulti-objective architectures proliferate. In this paper, we develop new tools\nto understand and control the dynamics in n-player differentiable games.\n  The key result is to decompose the game Jacobian into two components. The\nfirst, symmetric component, is related to potential games, which reduce to\ngradient descent on an implicit function. The second, antisymmetric component,\nrelates to Hamiltonian games, a new class of games that obey a conservation law\nakin to conservation laws in classical mechanical systems. The decomposition\nmotivates Symplectic Gradient Adjustment (SGA), a new algorithm for finding\nstable fixed points in differentiable games. Basic experiments show SGA is\ncompetitive with recently proposed algorithms for finding stable fixed points\nin GANs -- while at the same time being applicable to, and having guarantees\nin, much more general cases.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 09:21:08 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Letcher", "Alistair", ""], ["Balduzzi", "David", ""], ["Racaniere", "Sebastien", ""], ["Martens", "James", ""], ["Foerster", "Jakob", ""], ["Tuyls", "Karl", ""], ["Graepel", "Thore", ""]]}, {"id": "1905.05077", "submitter": "Simon Lucas", "authors": "Simon M. Lucas and Vanessa Volz", "title": "Tile Pattern KL-Divergence for Analysing and Evolving Game Levels", "comments": "8 pages plus references. Proceedings of GECCO 2019", "journal-ref": null, "doi": "10.1145/3321707.3321781", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper provides a detailed investigation of using the Kullback-Leibler\n(KL) Divergence as a way to compare and analyse game-levels, and hence to use\nthe measure as the objective function of an evolutionary algorithm to evolve\nnew levels. We describe the benefits of its asymmetry for level analysis and\ndemonstrate how (not surprisingly) the quality of the results depends on the\nfeatures used. Here we use tile-patterns of various sizes as features.\n  When using the measure for evolution-based level generation, we demonstrate\nthat the choice of variation operator is critical in order to provide an\nefficient search process, and introduce a novel convolutional mutation operator\nto facilitate this. We compare the results with alternative generators,\nincluding evolving in the latent space of generative adversarial networks, and\nWave Function Collapse. The results clearly show the proposed method to provide\ncompetitive performance, providing reasonable quality results with very fast\ntraining and reasonably fast generation.\n", "versions": [{"version": "v1", "created": "Wed, 24 Apr 2019 07:31:34 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Lucas", "Simon M.", ""], ["Volz", "Vanessa", ""]]}, {"id": "1905.05238", "submitter": "Kiran Khatter", "authors": "Kiran Khatter", "title": "Interval Valued Trapezoidal Neutrosophic Set for Prioritization of\n  Non-functional Requirements", "comments": "21 pages, 2 figures, 5 tables", "journal-ref": "J Ambient Intell Human Comput (2020)", "doi": "10.1007/s12652-020-02130-8", "report-no": null, "categories": "cs.AI cs.NE cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the trapezoidal fuzzy number(TrFN); Interval-valued\nintuitionistic fuzzy number(IVIFN); neutrosophic set and its operational laws;\nand, trapezoidal neutrosophic set(TrNS) and its operational laws. Based on the\ncombination of IVIFN and TrNS, an Interval Valued Trapezoidal Neutrosophic Set\n(IVTrNS) is proposed followed by its operational laws. The paper also presents\nthe score and accuracy functions for the proposed Interval Valued Trapezoidal\nNeutrosophic Number (IVTrNN). Then, an interval valued trapezoidal neutrosophic\nweighted arithmetic averaging (IVTrNWAA) operator is introduced to combine the\ntrapezoidal information which is neutrosophic and in the unit interval of real\nnumbers. Finally, a method is developed to handle the problems in the multi\nattribute decision making(MADM) environment using IVTrNWAA operator followed by\na numerical example of NFRs prioritization to illustrate the relevance of the\ndeveloped method.\n", "versions": [{"version": "v1", "created": "Tue, 7 May 2019 06:09:09 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Khatter", "Kiran", ""]]}, {"id": "1905.05300", "submitter": "Alexander Wong", "authors": "Rene Bidart and Alexander Wong", "title": "Affine Variational Autoencoders: An Efficient Approach for Improving\n  Generalization and Robustness to Distribution Shift", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose the Affine Variational Autoencoder (AVAE), a\nvariant of Variational Autoencoder (VAE) designed to improve robustness by\novercoming the inability of VAEs to generalize to distributional shifts in the\nform of affine perturbations. By optimizing an affine transform to maximize\nELBO, the proposed AVAE transforms an input to the training distribution\nwithout the need to increase model complexity to model the full distribution of\naffine transforms. In addition, we introduce a training procedure to create an\nefficient model by learning a subset of the training distribution, and using\nthe AVAE to improve generalization and robustness to distributional shift at\ntest time. Experiments on affine perturbations demonstrate that the proposed\nAVAE significantly improves generalization and robustness to distributional\nshift in the form of affine perturbations without an increase in model\ncomplexity.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 21:56:27 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Bidart", "Rene", ""], ["Wong", "Alexander", ""]]}, {"id": "1905.05478", "submitter": "Ivan Yanchin", "authors": "Ivan Yanchin and Oleg Petrov", "title": "Parallel genetic algorithm for planning safe and optimal route for ship", "comments": "26 pages, 13 figures, 15 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper represents an algorithm for planning safe and optimal routes for\ntransport facilities with unrestricted movement direction that travel within\nareas with obstacles. Paper explains the algorithm using a ship as an example\nof such a transport facility. This paper also provides a survey of several\nexisting solutions for the problem. The method employs an evolutionary\nalgorithm to plan several locally optimal routes and a parallel genetic\nalgorithm to create the final route by optimising the abovementioned set of\nroutes. The routes are optimized against the arrival time, assuming that the\noptimal route is the route with the lowermost arrival time. It is also possible\nto apply additional restriction to the routes.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 09:24:16 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Yanchin", "Ivan", ""], ["Petrov", "Oleg", ""]]}, {"id": "1905.05567", "submitter": "Gorker Alp Malazgirt", "authors": "Gorker Alp Malazgirt, Osman S. Unsal, Adrian Cristal Kestelman", "title": "TauRieL: Targeting Traveling Salesman Problem with a deep reinforcement\n  learning inspired architecture", "comments": "10 pages, 5 figures, 1 Algorithm, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this paper, we propose TauRieL and target Traveling Salesman Problem (TSP)\nsince it has broad applicability in theoretical and applied sciences. TauRieL\nutilizes an actor-critic inspired architecture that adopts ordinary feedforward\nnets to obtain a policy update vector $v$. Then, we use $v$ to improve the\nstate transition matrix from which we generate the policy. Also, the state\ntransition matrix allows the solver to initialize from precomputed solutions\nsuch as nearest neighbors. In an online learning setting, TauRieL unifies the\ntraining and the search where it can generate near-optimal results in seconds.\nThe input to the neural nets in the actor-critic architecture are raw 2-D\ninputs, and the design idea behind this decision is to keep neural nets\nrelatively smaller than the architectures with wide embeddings with the\ntradeoff of omitting any distributed representations of the embeddings.\nConsequently, TauRieL generates TSP solutions two orders of magnitude faster\nper TSP instance as compared to state-of-the-art offline techniques with a\nperformance impact of 6.1\\% in the worst case.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 12:49:32 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Malazgirt", "Gorker Alp", ""], ["Unsal", "Osman S.", ""], ["Kestelman", "Adrian Cristal", ""]]}, {"id": "1905.05614", "submitter": "Xiaoyuan Liang", "authors": "Xiaoyuan Liang, Guiling Wang, Martin Renqiang Min, Yi Qi, Zhu Han", "title": "A Deep Spatio-Temporal Fuzzy Neural Network for Passenger Demand\n  Prediction", "comments": "https://epubs.siam.org/doi/abs/10.1137/1.9781611975673.12", "journal-ref": "Proceedings of the 2019 SIAM International Conference on Data\n  Mining", "doi": "10.1137/1.9781611975673.12", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of its importance, passenger demand prediction is a highly\nchallenging problem, because the demand is simultaneously influenced by the\ncomplex interactions among many spatial and temporal factors and other external\nfactors such as weather. To address this problem, we propose a Spatio-TEmporal\nFuzzy neural Network (STEF-Net) to accurately predict passenger demands\nincorporating the complex interactions of all known important factors. We\ndesign an end-to-end learning framework with different neural networks modeling\ndifferent factors. Specifically, we propose to capture spatio-temporal feature\ninteractions via a convolutional long short-term memory network and model\nexternal factors via a fuzzy neural network that handles data uncertainty\nsignificantly better than deterministic methods. To keep the temporal relations\nwhen fusing two networks and emphasize discriminative spatio-temporal feature\ninteractions, we employ a novel feature fusion method with a convolution\noperation and an attention layer. As far as we know, our work is the first to\nfuse a deep recurrent neural network and a fuzzy neural network to model\ncomplex spatial-temporal feature interactions with additional uncertain input\nfeatures for predictive learning. Experiments on a large-scale real-world\ndataset show that our model achieves more than 10% improvement over the\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 13 May 2019 15:57:14 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Liang", "Xiaoyuan", ""], ["Wang", "Guiling", ""], ["Min", "Martin Renqiang", ""], ["Qi", "Yi", ""], ["Han", "Zhu", ""]]}, {"id": "1905.05849", "submitter": "Shaeke Salman", "authors": "Shaeke Salman, Seyedeh Neelufar Payrovnaziri, Xiuwen Liu, Pablo\n  Rengifo-Moreno, Zhe He", "title": "Consensus-based Interpretable Deep Neural Networks with Application to\n  Mortality Prediction", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved remarkable success in various challenging\ntasks. However, the black-box nature of such networks is not acceptable to\ncritical applications, such as healthcare. In particular, the existence of\nadversarial examples and their overgeneralization to irrelevant,\nout-of-distribution inputs with high confidence makes it difficult, if not\nimpossible, to explain decisions by such networks. In this paper, we analyze\nthe underlying mechanism of generalization of deep neural networks and propose\nan ($n$, $k$) consensus algorithm which is insensitive to adversarial examples\nand can reliably reject out-of-distribution samples. Furthermore, the consensus\nalgorithm is able to improve classification accuracy by using multiple trained\ndeep neural networks. To handle the complexity of deep neural networks, we\ncluster linear approximations of individual models and identify highly\ncorrelated clusters among different models to capture feature importance\nrobustly, resulting in improved interpretability. Motivated by the importance\nof building accurate and interpretable prediction models for healthcare, our\nexperimental results on an ICU dataset show the effectiveness of our algorithm\nin enhancing both the prediction accuracy and the interpretability of deep\nneural network models on one-year patient mortality prediction. In particular,\nwhile the proposed method maintains similar interpretability as conventional\nshallow models such as logistic regression, it improves the prediction accuracy\nsignificantly.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 21:26:56 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 05:32:07 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Salman", "Shaeke", ""], ["Payrovnaziri", "Seyedeh Neelufar", ""], ["Liu", "Xiuwen", ""], ["Rengifo-Moreno", "Pablo", ""], ["He", "Zhe", ""]]}, {"id": "1905.05885", "submitter": "Youhei Akimoto", "authors": "Youhei Akimoto and Nikolaus Hansen", "title": "Diagonal Acceleration for Covariance Matrix Adaptation Evolution\n  Strategies", "comments": "accepted in Evolutionary Computation Journal (MIT Press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an acceleration for covariance matrix adaptation evolution\nstrategies (CMA-ES) by means of adaptive diagonal decoding (dd-CMA). This\ndiagonal acceleration endows the default CMA-ES with the advantages of\nseparable CMA-ES without inheriting its drawbacks. Technically, we introduce a\ndiagonal matrix D that expresses coordinate-wise variances of the sampling\ndistribution in DCD form. The diagonal matrix can learn a rescaling of the\nproblem in the coordinates within linear number of function evaluations.\nDiagonal decoding can also exploit separability of the problem, but, crucially,\ndoes not compromise the performance on non-separable problems. The latter is\naccomplished by modulating the learning rate for the diagonal matrix based on\nthe condition number of the underlying correlation matrix. dd-CMA-ES not only\ncombines the advantages of default and separable CMA-ES, but may achieve\noveradditive speedup: it improves the performance, and even the scaling, of the\nbetter of default and separable CMA-ES on classes of non-separable test\nfunctions that reflect, arguably, a landscape feature commonly observed in\npractice.\n  The paper makes two further secondary contributions: we introduce two\ndifferent approaches to guarantee positive definiteness of the covariance\nmatrix with active CMA, which is valuable in particular with large population\nsize; we revise the default parameter setting in CMA-ES, proposing accelerated\nsettings in particular for large dimension.\n  All our contributions can be viewed as independent improvements of CMA-ES,\nyet they are also complementary and can be seamlessly combined. In numerical\nexperiments with dd-CMA-ES up to dimension 5120, we observe remarkable\nimprovements over the original covariance matrix adaptation on functions with\ncoordinate-wise ill-conditioning. The improvement is observed also for large\npopulation sizes up to about dimension squared.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 23:42:53 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Akimoto", "Youhei", ""], ["Hansen", "Nikolaus", ""]]}, {"id": "1905.05918", "submitter": "David Laredo Razo", "authors": "David Laredo, Zhaoyin Chen, Oliver Sch\\\"utze, Jian-Qiao Sun", "title": "A Neural Network-Evolutionary Computational Framework for Remaining\n  Useful Life Estimation of Mechanical Systems", "comments": "Published at Neural Networks 116, (2019) 178-187", "journal-ref": "Neural Networks 116, (2019) 178-187", "doi": "10.1016/j.neunet.2019.04.016", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a framework for estimating the remaining useful life\n(RUL) of mechanical systems. The framework consists of a multi-layer perceptron\nand an evolutionary algorithm for optimizing the data-related parameters. The\nframework makes use of a strided time window to estimate the RUL for mechanical\ncomponents. Tuning the data-related parameters can become a very time consuming\ntask. The framework presented here automatically reshapes the data such that\nthe efficiency of the model is increased. Furthermore, the complexity of the\nmodel is kept low, e.g. neural networks with few hidden layers and few neurons\nat each layer. Having simple models has several advantages like short training\ntimes and the capacity of being in environments with limited computational\nresources such as embedded systems. The proposed method is evaluated on the\npublicly available C-MAPSS dataset, its accuracy is compared against other\nstate-of-the art methods for the same dataset.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 02:31:45 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Laredo", "David", ""], ["Chen", "Zhaoyin", ""], ["Sch\u00fctze", "Oliver", ""], ["Sun", "Jian-Qiao", ""]]}, {"id": "1905.06012", "submitter": "Brij Rokad", "authors": "Chris Whitmire, Brij Rokad and Caleb Crumley", "title": "Origami Inspired Solar Panel Design", "comments": "8 pages, 4 figures and 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper was to take a flat solar panel and make cuts on the\npanel to make smaller, but still viable solar panels. These smaller solar\npanels could then be arranged in a tree-like design. The hope was that by\nhaving solar panels faced in different directions in 3-dimensional space, the\ntree system would be able to pick up more sunlight than a flat solar panel. The\nresults were promising, but this project did not take every factor into\naccount. Specifically, optimum shape, temperature and the resistance of system,\nreflection of sun-rays were not explored in this project. This paper will take\nan approach from origami paper folding to create the optimum arrangement that\nwill allow the overall system to absorb the maximum energy. Since the system\nstays stationary throughout the day, it can reduce the maintenance cost and\nexcess energy use because it does not require solar tracking. In this project\nwe have implemented a variety of Evolutionary Algorithms to find the most\nefficient way to cut a flat solar panel and arrange the resulting smaller\npanels. Each solution in the population will be tested by computing the amount\nof solar energy that is absorbed at particular times of the day. The EA will be\nexploring different combinations of angles and heights of the smaller panels on\nthe tree such that the system can produce the maximum amount of power\nthroughout the day. The performance of our Evolutionary algorithms are\ncomparable to the performance of flat solar panels.\n  Keywords: - Evolutionary Programming, Evolution Strategy, Genetic Algorithm,\nSolar Panel Optimization.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 08:05:18 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Whitmire", "Chris", ""], ["Rokad", "Brij", ""], ["Crumley", "Caleb", ""]]}, {"id": "1905.06234", "submitter": "Karan Aggarwal", "authors": "Karan Aggarwal, Uday Bondhugula", "title": "Optimizing the Linear Fascicle Evaluation Algorithm for Multi-Core and\n  Many-Core Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse matrix-vector multiplication (SpMV) operations are commonly used in\nvarious scientific applications. The performance of the SpMV operation often\ndepends on exploiting regularity patterns in the matrix. Various\nrepresentations have been proposed to minimize the memory bandwidth bottleneck\narising from the irregular memory access pattern involved. Among recent\nrepresentation techniques, tensor decomposition is a popular one used for very\nlarge but sparse matrices. Post sparse-tensor decomposition, the new\nrepresentation involves indirect accesses, making it challenging to optimize\nfor multi-cores and GPUs.\n  Computational neuroscience algorithms often involve sparse datasets while\nstill performing long-running computations on them. The LiFE application is a\npopular neuroscience algorithm used for pruning brain connectivity graphs. The\ndatasets employed herein involve the Sparse Tucker Decomposition (STD), a\nwidely used tensor decomposition method. Using this decomposition leads to\nirregular array references, making it very difficult to optimize for both CPUs\nand GPUs. Recent codes of the LiFE algorithm show that its SpMV operations are\nthe key bottleneck for performance and scaling. In this work, we first propose\ntarget-independent optimizations to optimize these SpMV operations, followed by\ntarget-dependent optimizations for CPU and GPU systems. The target-independent\ntechniques include: (1) standard compiler optimizations, (2) data restructuring\nmethods, and (3) methods to partition computations among threads. Then we\npresent the optimizations for CPUs and GPUs to exploit platform-specific speed.\nOur highly optimized CPU code obtain a speedup of 27.12x over the original\nsequential CPU code running on 16-core Intel Xeon (Skylake-based) system, and\nour optimized GPU code achieves a speedup of 5.2x over a reference optimized\nGPU code version on NVIDIA's GeForce RTX 2080 Ti GPU.\n", "versions": [{"version": "v1", "created": "Tue, 14 May 2019 11:09:11 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 06:29:42 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Aggarwal", "Karan", ""], ["Bondhugula", "Uday", ""]]}, {"id": "1905.06252", "submitter": "Giovanni Iacca Dr.", "authors": "Cristiano Saltori, Subhankar Roy, Nicu Sebe, Giovanni Iacca", "title": "Regularized Evolutionary Algorithm for Dynamic Neural Topology Search", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-30642-7_20", "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing neural networks for object recognition requires considerable\narchitecture engineering. As a remedy, neuro-evolutionary network architecture\nsearch, which automatically searches for optimal network architectures using\nevolutionary algorithms, has recently become very popular. Although very\neffective, evolutionary algorithms rely heavily on having a large population of\nindividuals (i.e., network architectures) and is therefore memory expensive. In\nthis work, we propose a Regularized Evolutionary Algorithm with low memory\nfootprint to evolve a dynamic image classifier. In details, we introduce novel\ncustom operators that regularize the evolutionary process of a micro-population\nof 10 individuals. We conduct experiments on three different digits datasets\n(MNIST, USPS, SVHN) and show that our evolutionary method obtains competitive\nresults with the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 15:36:56 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 08:49:44 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Saltori", "Cristiano", ""], ["Roy", "Subhankar", ""], ["Sebe", "Nicu", ""], ["Iacca", "Giovanni", ""]]}, {"id": "1905.06379", "submitter": "Ahmed Khalifa", "authors": "Ahmed Khalifa, Dan Gopstein, Julian Togelius", "title": "ELIMINATION from Design to Analysis", "comments": "4 pages, 3 figures, submitted to CoG as a short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elimination is a word puzzle game for browsers and mobile devices, where all\nlevels are generated by a constrained evolutionary algorithm with no human\nintervention. This paper describes the design of the game and its level\ngeneration methods, and analysis of playtraces from almost a thousand users who\nplayed the game since its release. The analysis corroborates that the level\ngenerator creates a sawtooth-shaped difficulty curve, as intended. The analysis\nalso offers insights into player behavior in this game.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2019 18:40:05 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Khalifa", "Ahmed", ""], ["Gopstein", "Dan", ""], ["Togelius", "Julian", ""]]}, {"id": "1905.06562", "submitter": "Chanchal Suman", "authors": "Chanchal Suman, Somanath Tripathy, Sriparna Saha", "title": "Building an Effective Intrusion Detection System using Unsupervised\n  Feature Selection in Multi-objective Optimization Framework", "comments": "3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion Detection Systems (IDS) are developed to protect the network by\ndetecting the attack. The current paper proposes an unsupervised feature\nselection technique for analyzing the network data. The search capability of\nthe non-dominated sorting genetic algorithm (NSGA-II) has been employed for\noptimizing three different objective functions utilizing different information\ntheoretic measures including mutual information, standard deviation, and\ninformation gain to identify mutually exclusive and a high variant subset of\nfeatures. Finally, the Pareto optimal front of the different optimal feature\nsubsets are obtained and these feature subsets are utilized for developing\nclassification systems using different popular machine learning models like\nsupport vector machines, decision trees and k-nearest neighbour (k=5)\nclassifier etc. We have evaluated the results of the algorithm on KDD-99,\nNSL-KDD and Kyoto 2006+ datasets. The experimental results on KDD-99 dataset\nshow that decision tree provides better results than other available\nclassifiers. The proposed system obtains the best results of 99.78% accuracy,\n99.27% detection rate and false alarm rate of 0.2%, which are better than all\nthe previous results for KDD dataset. We achieved an accuracy of 99.83% for 20%\ntesting data of NSL-KDD dataset and 99.65% accuracy for 10-fold\ncross-validation on Kyoto dataset. The most attractive characteristic of the\nproposed scheme is that during the selection of appropriate feature subset, no\nlabeled information is utilized and different feature quality measures are\noptimized simultaneously using the multi-objective optimization framework.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 07:12:57 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Suman", "Chanchal", ""], ["Tripathy", "Somanath", ""], ["Saha", "Sriparna", ""]]}, {"id": "1905.06636", "submitter": "Menouar Boulif", "authors": "Menouar Boulif", "title": "Heterogeneous Parallel Genetic Algorithm Paradigm", "comments": "4 pages, 5 figures, accepted at The 2nd Conference on Informatics and\n  Applied Mathematics (IAM'19), Guelma, Algeria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The encoding representation of the genetic algorithm can boost or hinder its\nperformance albeit the care one can devote to operator design. Unfortunately, a\nrepresentation-theory foundation that helps to find the suitable encoding for\nany problem has not yet become mature. Furthermore, we argue that such a\nbest-performing encoding scheme can differ even for instances of the same\nproblem. In this contribution, we present the basic principles of the\nheterogeneous parallel genetic algorithm that federates the efforts of many\nencoding representations in order to efficiently solve the problem in hand\nwithout prior knowledge of the best encoding.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 10:20:12 GMT"}], "update_date": "2019-05-17", "authors_parsed": [["Boulif", "Menouar", ""]]}, {"id": "1905.06684", "submitter": "Federico Galatolo", "authors": "Federico A. Galatolo, Mario G.C.A. Cimino, Gigliola Vaglini", "title": "Formal derivation of Mesh Neural Networks with their Forward-Only\n  gradient Propagation", "comments": null, "journal-ref": null, "doi": "10.1007/s11063-021-10490-1", "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the Mesh Neural Network (MNN), a novel architecture which\nallows neurons to be connected in any topology, to efficiently route\ninformation. In MNNs, information is propagated between neurons throughout a\nstate transition function. State and error gradients are then directly computed\nfrom state updates without backward computation. The MNN architecture and the\nerror propagation schema is formalized and derived in tensor algebra. The\nproposed computational model can fully supply a gradient descent process, and\nis potentially suitable for very large scale sparse NNs, due to its\nexpressivity and training efficiency, with respect to NNs based on\nback-propagation and computational graphs.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2019 12:22:26 GMT"}, {"version": "v2", "created": "Sun, 19 May 2019 13:22:36 GMT"}, {"version": "v3", "created": "Sat, 2 Nov 2019 12:14:11 GMT"}, {"version": "v4", "created": "Mon, 25 May 2020 20:06:51 GMT"}, {"version": "v5", "created": "Wed, 7 Jul 2021 14:37:36 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Galatolo", "Federico A.", ""], ["Cimino", "Mario G. C. A.", ""], ["Vaglini", "Gigliola", ""]]}, {"id": "1905.07288", "submitter": "Jakub Sawicki", "authors": "Jakub Sawicki, Maciej Smo{\\l}ka, Marcin {\\L}o\\'s, and Robert Schaefer", "title": "Approximation of the objective insensitivity regions using Hierarchic\n  Memetic Strategy coupled with Covariance Matrix Adaptation Evolutionary\n  Strategy", "comments": "presented at OLA2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most challenging types of ill-posedness in global optimization is\nthe presence of insensitivity regions in design parameter space, so the\nidentification of their shape will be crucial, if ill-posedness is\nirrecoverable. Such problems may be solved using global stochastic search\nfollowed by post-processing of a local sample and a local objective\napproximation. We propose a new approach of this type composed of Hierarchic\nMemetic Strategy (HMS) powered by the Covariance Matrix Adaptation Evolutionary\nStrategy (CMA-ES) well-known as an effective, self-adaptable stochastic\noptimization algorithm and we leverage the distribution density knowledge it\naccumulates to better identify and separate insensitivity regions. The results\nof benchmarks prove that the improved HMS-CMA-ES strategy is effective in both\nthe total computational cost and the accuracy of insensitivity region\napproximation. The reference data for the tests was obtained by means of a\nwell-known effective strategy of multimodal stochastic optimization called the\nNiching Evolutionary Algorithm 2 (NEA2), that also uses CMA-ES as a component.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 14:25:27 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Sawicki", "Jakub", ""], ["Smo\u0142ka", "Maciej", ""], ["\u0141o\u015b", "Marcin", ""], ["Schaefer", "Robert", ""]]}, {"id": "1905.07320", "submitter": "Hui Zhu", "authors": "Hui Zhu, Zhulin An, Chuanguang Yang, Kaiqiang Xu, Erhu Zhao, Yongjun\n  Xu", "title": "EENA: Efficient Evolution of Neural Architecture", "comments": "Accepted by ICCV2019 Neural Architects Workshop (ICCVW)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latest algorithms for automatic neural architecture search perform remarkable\nbut are basically directionless in search space and computational expensive in\ntraining of every intermediate architecture. In this paper, we propose a method\nfor efficient architecture search called EENA (Efficient Evolution of Neural\nArchitecture). Due to the elaborately designed mutation and crossover\noperations, the evolution process can be guided by the information have already\nbeen learned. Therefore, less computational effort will be required while the\nsearching and training time can be reduced significantly. On CIFAR-10\nclassification, EENA using minimal computational resources (0.65 GPU-days) can\ndesign highly effective neural architecture which achieves 2.56% test error\nwith 8.47M parameters. Furthermore, the best architecture discovered is also\ntransferable for CIFAR-100.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2019 02:34:23 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 02:25:44 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2019 03:32:59 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Zhu", "Hui", ""], ["An", "Zhulin", ""], ["Yang", "Chuanguang", ""], ["Xu", "Kaiqiang", ""], ["Zhao", "Erhu", ""], ["Xu", "Yongjun", ""]]}, {"id": "1905.07350", "submitter": "Edvinas Byla", "authors": "Edvinas Byla and Wei Pang", "title": "DeepSwarm: Optimising Convolutional Neural Networks using Swarm\n  Intelligence", "comments": "13 pages, 6 figures, to access DeepSwarm code go to\n  https://github.com/Pattio/DeepSwarm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose DeepSwarm, a novel neural architecture search (NAS)\nmethod based on Swarm Intelligence principles. At its core DeepSwarm uses Ant\nColony Optimization (ACO) to generate ant population which uses the pheromone\ninformation to collectively search for the best neural architecture.\nFurthermore, by using local and global pheromone update rules our method\nensures the balance between exploitation and exploration. On top of this, to\nmake our method more efficient we combine progressive neural architecture\nsearch with weight reusability. Furthermore, due to the nature of ACO our\nmethod can incorporate heuristic information which can further speed up the\nsearch process. After systematic and extensive evaluation, we discover that on\nthree different datasets (MNIST, Fashion-MNIST, and CIFAR-10) when compared to\nexisting systems our proposed method demonstrates competitive performance.\nFinally, we open source DeepSwarm as a NAS library and hope it can be used by\nmore deep learning researchers and practitioners.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 16:13:38 GMT"}], "update_date": "2019-05-20", "authors_parsed": [["Byla", "Edvinas", ""], ["Pang", "Wei", ""]]}, {"id": "1905.07490", "submitter": "Jongrae Kim", "authors": "Jongrae Kim", "title": "Sequential training algorithm for neural networks", "comments": "5 pages, 3 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A sequential training method for large-scale feedforward neural networks is\npresented. Each layer of the neural network is decoupled and trained\nseparately. After the training is completed for each layer, they are combined\ntogether. The performance of the network would be sub-optimal compared to the\nfull network training if the optimal solution would be achieved. However,\nachieving the optimal solution for the full network would be infeasible or\nrequire long computing time. The proposed sequential approach reduces the\nrequired computer resources significantly and would have better convergences as\na single layer is optimised for each optimisation step. The required\nmodifications of existing algorithms to implement the sequential training are\nminimal. The performance is verified by a simple example.\n", "versions": [{"version": "v1", "created": "Fri, 17 May 2019 21:52:08 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Kim", "Jongrae", ""]]}, {"id": "1905.07529", "submitter": "Xiawu Zheng", "authors": "Xiawu Zheng, Rongrong Ji, Lang Tang, Baochang Zhang, Jianzhuang Liu,\n  Qi Tian", "title": "Multinomial Distribution Learning for Effective Neural Architecture\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Architectures obtained by Neural Architecture Search (NAS) have achieved\nhighly competitive performance in various computer vision tasks. However, the\nprohibitive computation demand of forward-backward propagation in deep neural\nnetworks and searching algorithms makes it difficult to apply NAS in practice.\nIn this paper, we propose a Multinomial Distribution Learning for extremely\neffective NAS,which considers the search space as a joint multinomial\ndistribution, i.e., the operation between two nodes is sampled from this\ndistribution, and the optimal network structure is obtained by the operations\nwith the most likely probability in this distribution. Therefore, NAS can be\ntransformed to a multinomial distribution learning problem, i.e., the\ndistribution is optimized to have a high expectation of the performance.\nBesides, a hypothesis that the performance ranking is consistent in every\ntraining epoch is proposed and demonstrated to further accelerate the learning\nprocess. Experiments on CIFAR10 and ImageNet demonstrate the effectiveness of\nour method. On CIFAR-10, the structure searched by our method achieves 2.55%\ntest error, while being 6.0x (only 4 GPU hours on GTX1080Ti) faster compared\nwith state-of-the-art NAS algorithms. On ImageNet, our model achieves 75.2%\ntop1 accuracy under MobileNet settings (MobileNet V1/V2), while being 1.2x\nfaster with measured GPU latency. Test code with pre-trained models are\navailable at https://github.com/tanglang96/MDENAS\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 03:30:47 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 07:18:24 GMT"}, {"version": "v3", "created": "Wed, 14 Aug 2019 02:41:43 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Zheng", "Xiawu", ""], ["Ji", "Rongrong", ""], ["Tang", "Lang", ""], ["Zhang", "Baochang", ""], ["Liu", "Jianzhuang", ""], ["Tian", "Qi", ""]]}, {"id": "1905.07628", "submitter": "Aleksandra Faust", "authors": "Aleksandra Faust and Anthony Francis and Dar Mehta", "title": "Evolving Rewards to Automate Reinforcement Learning", "comments": "Accepted to 6th AutoML@ICML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many continuous control tasks have easily formulated objectives, yet using\nthem directly as a reward in reinforcement learning (RL) leads to suboptimal\npolicies. Therefore, many classical control tasks guide RL training using\ncomplex rewards, which require tedious hand-tuning. We automate the reward\nsearch with AutoRL, an evolutionary layer over standard RL that treats reward\ntuning as hyperparameter optimization and trains a population of RL agents to\nfind a reward that maximizes the task objective. AutoRL, evaluated on four\nMujoco continuous control tasks over two RL algorithms, shows improvements over\nbaselines, with the the biggest uplift for more complex tasks. The video can be\nfound at: \\url{https://youtu.be/svdaOFfQyC8}.\n", "versions": [{"version": "v1", "created": "Sat, 18 May 2019 19:20:04 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Faust", "Aleksandra", ""], ["Francis", "Anthony", ""], ["Mehta", "Dar", ""]]}, {"id": "1905.07685", "submitter": "Pedram Rooshenas", "authors": "MohamadAli Torkamani, Phillip Wallis, Shiv Shankar, Amirmohammad\n  Rooshenas", "title": "Learning Compact Neural Networks Using Ordinary Differential Equations\n  as Activation Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep neural networks use simple, fixed activation functions, such as\nsigmoids or rectified linear units, regardless of domain or network structure.\nWe introduce differential equation units (DEUs), an improvement to modern\nneural networks, which enables each neuron to learn a particular nonlinear\nactivation function from a family of solutions to an ordinary differential\nequation. Specifically, each neuron may change its functional form during\ntraining based on the behavior of the other parts of the network. We show that\nusing neurons with DEU activation functions results in a more compact network\ncapable of achieving comparable, if not superior, performance when is compared\nto much larger networks.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 03:49:52 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Torkamani", "MohamadAli", ""], ["Wallis", "Phillip", ""], ["Shankar", "Shiv", ""], ["Rooshenas", "Amirmohammad", ""]]}, {"id": "1905.07785", "submitter": "Rahul Mehta", "authors": "Rahul Mehta", "title": "Sparse Transfer Learning via Winning Lottery Tickets", "comments": "15 pages, 9 figures. Workshop on Learning Transferable Skills, 33rd\n  Conference on Neural Information Processing Systems, Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recently proposed Lottery Ticket Hypothesis of Frankle and Carbin (2019)\nsuggests that the performance of over-parameterized deep networks is due to the\nrandom initialization seeding the network with a small fraction of favorable\nweights. These weights retain their dominant status throughout training -- in a\nvery real sense, this sub-network \"won the lottery\" during initialization. The\nauthors find sub-networks via unstructured magnitude pruning with 85-95% of\nparameters removed that train to the same accuracy as the original network at a\nsimilar speed, which they call winning tickets. In this paper, we extend the\nLottery Ticket Hypothesis to a variety of transfer learning tasks. We show that\nsparse sub-networks with approximately 90-95% of weights removed achieve (and\noften exceed) the accuracy of the original dense network in several realistic\nsettings. We experimentally validate this by transferring the sparse\nrepresentation found via pruning on CIFAR-10 to SmallNORB and FashionMNIST for\nobject recognition tasks.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 17:48:29 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 21:17:07 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Mehta", "Rahul", ""]]}, {"id": "1905.07836", "submitter": "Alexander Wong", "authors": "Linda Wang and Alexander Wong", "title": "Enabling Computer Vision Driven Assistive Devices for the Visually\n  Impaired via Micro-architecture Design Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent improvements in object detection have shown potential to aid in tasks\nwhere previous solutions were not able to achieve. A particular area is\nassistive devices for individuals with visual impairment. While\nstate-of-the-art deep neural networks have been shown to achieve superior\nobject detection performance, their high computational and memory requirements\nmake them cost prohibitive for on-device operation. Alternatively, cloud-based\noperation leads to privacy concerns, both not attractive to potential users. To\naddress these challenges, this study investigates creating an efficient object\ndetection network specifically for OLIV, an AI-powered assistant for object\nlocalization for the visually impaired, via micro-architecture design\nexploration. In particular, we formulate the problem of finding an optimal\nnetwork micro-architecture as an numerical optimization problem, where we find\nthe set of hyperparameters controlling the MobileNetV2-SSD network\nmicro-architecture that maximizes a modified NetScore objective function for\nthe MSCOCO-OLIV dataset of indoor objects. Experimental results show that such\na micro-architecture design exploration strategy leads to a compact deep neural\nnetwork with a balanced trade-off between accuracy, size, and speed, making it\nwell-suited for enabling on-device computer vision driven assistive devices for\nthe visually impaired.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 01:30:15 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Wang", "Linda", ""], ["Wong", "Alexander", ""]]}, {"id": "1905.07917", "submitter": "Luc Brun", "authors": "Xuan Nguyen, Luc Brun, Olivier Lezoray, S\\'ebastien Bougleux", "title": "Skeleton-Based Hand Gesture Recognition by Learning SPD Matrices with\n  Neural Networks", "comments": null, "journal-ref": "14th IEEE International Conference on Automatic Face and Gesture\n  Recognition, May 2019, Lille, France", "doi": null, "report-no": null, "categories": "cs.CV cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new hand gesture recognition method based on\nskeletal data by learning SPD matrices with neural networks. We model the hand\nskeleton as a graph and introduce a neural network for SPD matrix learning,\ntaking as input the 3D coordinates of hand joints. The proposed network is\nbased on two newly designed layers that transform a set of SPD matrices into a\nSPD matrix. For gesture recognition, we train a linear SVM classifier using\nfeatures extracted from our network. Experimental results on a challenging\ndataset (Dynamic Hand Gesture dataset from the SHREC 2017 3D Shape Retrieval\nContest) show that the proposed method outperforms state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 07:10:49 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Nguyen", "Xuan", ""], ["Brun", "Luc", ""], ["Lezoray", "Olivier", ""], ["Bougleux", "S\u00e9bastien", ""]]}, {"id": "1905.07923", "submitter": "Cyrille Morin", "authors": "Cyrille Morin (MARACAS), Leonardo Cardoso (MARACAS), Jakob Hoydis,\n  Jean-Marie Gorce (MARACAS), Thibaud Vial", "title": "Transmitter Classification With Supervised Deep Learning", "comments": null, "journal-ref": "Crowncom, Jun 2019, Poznan, Poland", "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware imperfections in RF transmitters introduce features that can be used\nto identify a specific transmitter amongst others. Supervised deep learning has\nshown good performance in this task but using datasets not applicable to real\nworld situations where topologies evolve over time. To remedy this, the work\nrests on a series of datasets gathered in the Future Internet of Things /\nCognitive Radio Testbed [4] (FIT/CorteXlab) to train a convolutional neural\nnetwork (CNN), where focus has been given to reduce channel bias that has\nplagued previous works and constrained them to a constant environment or to\nsimulations. The most challenging scenarios provide the trained neural network\nwith resilience and show insight on the best signal type to use for\nidentification , namely packet preamble. The generated datasets are published\non the Machine Learning For Communications Emerging Technologies Initiatives\nweb site 4 in the hope that they serve as stepping stones for future progress\nin the area. The community is also invited to reproduce the studied scenarios\nand results by generating new datasets in FIT/CorteXlab.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 07:36:26 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Morin", "Cyrille", "", "MARACAS"], ["Cardoso", "Leonardo", "", "MARACAS"], ["Hoydis", "Jakob", "", "MARACAS"], ["Gorce", "Jean-Marie", "", "MARACAS"], ["Vial", "Thibaud", ""]]}, {"id": "1905.07961", "submitter": "Bartosz Piotrowski", "authors": "Bartosz Piotrowski, Josef Urban", "title": "Guiding Inferences in Connection Tableau by Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a dataset and experiments on applying recurrent neural networks\n(RNNs) for guiding clause selection in the connection tableau proof calculus.\nThe RNN encodes a sequence of literals from the current branch of the partial\nproof tree to a hidden vector state; using it, the system selects a clause for\nextending the proof tree. The training data and learning setup are described,\nand the results are discussed and compared with state of the art using gradient\nboosted trees. Additionally, we perform a conjecturing experiment in which the\nRNN does not just select an existing clause, but completely constructs the next\ntableau goal.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 09:47:41 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 11:56:26 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Piotrowski", "Bartosz", ""], ["Urban", "Josef", ""]]}, {"id": "1905.08006", "submitter": "Mudita Sharma", "authors": "Mudita Sharma, Alexandros Komninos, Manuel Lopez Ibanez, Dimitar\n  Kazakov", "title": "Deep Reinforcement Learning Based Parameter Control in Differential\n  Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive Operator Selection (AOS) is an approach that controls discrete\nparameters of an Evolutionary Algorithm (EA) during the run. In this paper, we\npropose an AOS method based on Double Deep Q-Learning (DDQN), a Deep\nReinforcement Learning method, to control the mutation strategies of\nDifferential Evolution (DE). The application of DDQN to DE requires two phases.\nFirst, a neural network is trained offline by collecting data about the DE\nstate and the benefit (reward) of applying each mutation strategy during\nmultiple runs of DE tackling benchmark functions. We define the DE state as the\ncombination of 99 different features and we analyze three alternative reward\nfunctions. Second, when DDQN is applied as a parameter controller within DE to\na different test set of benchmark functions, DDQN uses the trained neural\nnetwork to predict which mutation strategy should be applied to each parent at\neach generation according to the DE state. Benchmark functions for training and\ntesting are taken from the CEC2005 benchmark with dimensions 10 and 30. We\ncompare the results of the proposed DE-DDQN algorithm to several baseline DE\nalgorithms using no online selection, random selection and other AOS methods,\nand also to the two winners of the CEC2005 competition. The results show that\nDE-DDQN outperforms the non-adaptive methods for all functions in the test set;\nwhile its results are comparable with the last two algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 11:36:07 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Sharma", "Mudita", ""], ["Komninos", "Alexandros", ""], ["Ibanez", "Manuel Lopez", ""], ["Kazakov", "Dimitar", ""]]}, {"id": "1905.08105", "submitter": "Mahesh Patil", "authors": "Mahesh Patil and M. Naveen Naidu and A. Vasan and Murari R. R. Varma", "title": "Water Distribution System Design Using Multi-Objective Genetic Algorithm\n  with External Archive and Local Search", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybridisation of the multi-objective optimisation algorithm NSGA-II and local\nsearch is proposed for water distribution system design. Results obtained with\nthe proposed algorithm are presented for four medium-size water networks taken\nfrom the literature. Local search is found to be beneficial for one of the\nnetworks in terms of finding new solutions not reported earlier. It is also\nshown that simply using an external archive to save all non-dominated solutions\nvisited by the population, even without local search, leads to substantial\nimprovement in the non-dominated set produced by the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 13:33:37 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Patil", "Mahesh", ""], ["Naidu", "M. Naveen", ""], ["Vasan", "A.", ""], ["Varma", "Murari R. R.", ""]]}, {"id": "1905.08126", "submitter": "Darren Chitty", "authors": "Darren M. Chitty, Elizabeth Wanner, Rakhi Parmar and Peter R. Lewis", "title": "Can Bio-Inspired Swarm Algorithms Scale to Modern Societal Problems", "comments": "To be presented at the ALife 2019 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taking inspiration from nature for meta-heuristics has proven popular and\nrelatively successful. Many are inspired by the collective intelligence\nexhibited by insects, fish and birds. However, there is a question over their\nscalability to the types of complex problems experienced in the modern world.\nNatural systems evolved to solve simpler problems effectively, replicating\nthese processes for complex problems may suffer from inefficiencies. Several\ncausal factors can impact scalability; computational complexity, memory\nrequirements or pure problem intractability. Supporting evidence is provided\nusing a case study in Ant Colony Optimisation (ACO) regards tackling\nincreasingly complex real-world fleet optimisation problems. This paper\nhypothesizes that contrary to common intuition, bio-inspired collective\nintelligence techniques by their very nature exhibit poor scalability in cases\nof high dimensionality when large degrees of decision making are required.\nFacilitating scaling of bio-inspired algorithms necessitates reducing this\ndecision making. To support this hypothesis, an enhanced Partial-ACO technique\nis presented which effectively reduces ant decision making. Reducing the\ndecision making required by ants by up to 90% results in markedly improved\neffectiveness and reduced runtimes for increasingly complex fleet optimisation\nproblems. Reductions in traversal timings of 40-50% are achieved for problems\nwith up to 45 vehicles and 437 jobs.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2019 14:07:58 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Chitty", "Darren M.", ""], ["Wanner", "Elizabeth", ""], ["Parmar", "Rakhi", ""], ["Lewis", "Peter R.", ""]]}, {"id": "1905.08453", "submitter": "Hengyu Zhao", "authors": "Hengyu Zhao, Yubo Zhang, Pingfan Meng, Hui Shi, Li Erran Li, Tiancheng\n  Lou, Jishen Zhao", "title": "Towards Safety-Aware Computing System Design in Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, autonomous driving development ignited competition among car makers\nand technical corporations. Low-level automation cars are already commercially\navailable. But high automated vehicles where the vehicle drives by itself\nwithout human monitoring is still at infancy. Such autonomous vehicles (AVs)\nrely on the computing system in the car to to interpret the environment and\nmake driving decisions. Therefore, computing system design is essential\nparticularly in enhancing the attainment of driving safety. However, to our\nknowledge, no clear guideline exists so far regarding safety-aware AV computing\nsystem and architecture design. To understand the safety requirement of AV\ncomputing system, we performed a field study by running industrial Level-4\nautonomous driving fleets in various locations, road conditions, and traffic\npatterns. The field study indicates that traditional computing system\nperformance metrics, such as tail latency, average latency, maximum latency,\nand timeout, cannot fully satisfy the safety requirement for AV computing\nsystem design. To address this issue, we propose a `safety score' as a primary\nmetric for measuring the level of safety in AV computing system design.\nFurthermore, we propose a perception latency model, which helps architects\nestimate the safety score of given architecture and system design without\nphysically testing them in an AV. We demonstrate the use of our safety score\nand latency model, by developing and evaluating a safety-aware AV computing\nsystem computation hardware resource management scheme.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 06:05:25 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 21:43:31 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Zhao", "Hengyu", ""], ["Zhang", "Yubo", ""], ["Meng", "Pingfan", ""], ["Shi", "Hui", ""], ["Li", "Li Erran", ""], ["Lou", "Tiancheng", ""], ["Zhao", "Jishen", ""]]}, {"id": "1905.08503", "submitter": "Corrado Possieri", "authors": "Giuseppe C. Calafiore, Stephane Gaubert, Member and Corrado Possieri", "title": "A Universal Approximation Result for Difference of log-sum-exp Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that a neural network whose output is obtained as the difference of\nthe outputs of two feedforward networks with exponential activation function in\nthe hidden layer and logarithmic activation function in the output node (LSE\nnetworks) is a smooth universal approximator of continuous functions over\nconvex, compact sets. By using a logarithmic transform, this class of networks\nmaps to a family of subtraction-free ratios of generalized posynomials, which\nwe also show to be universal approximators of positive functions over\nlog-convex, compact subsets of the positive orthant. The main advantage of\nDifference-LSE networks with respect to classical feedforward neural networks\nis that, after a standard training phase, they provide surrogate models for\ndesign that possess a specific difference-of-convex-functions form, which makes\nthem optimizable via relatively efficient numerical methods. In particular, by\nadapting an existing difference-of-convex algorithm to these models, we obtain\nan algorithm for performing effective optimization-based design. We illustrate\nthe proposed approach by applying it to data-driven design of a diet for a\npatient with type-2 diabetes.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 08:54:21 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Calafiore", "Giuseppe C.", ""], ["Gaubert", "Stephane", ""], ["Member", "", ""], ["Possieri", "Corrado", ""]]}, {"id": "1905.08537", "submitter": "Shinichi Shirakawa", "authors": "Youhei Akimoto, Shinichi Shirakawa, Nozomu Yoshinari, Kento Uchida,\n  Shota Saito, Kouhei Nishida", "title": "Adaptive Stochastic Natural Gradient Method for One-Shot Neural\n  Architecture Search", "comments": "Accepted to ICML 2019. Code is available at\n  https://github.com/shirakawas/ASNG-NAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High sensitivity of neural architecture search (NAS) methods against their\ninput such as step-size (i.e., learning rate) and search space prevents\npractitioners from applying them out-of-the-box to their own problems, albeit\nits purpose is to automate a part of tuning process. Aiming at a fast, robust,\nand widely-applicable NAS, we develop a generic optimization framework for NAS.\nWe turn a coupled optimization of connection weights and neural architecture\ninto a differentiable optimization by means of stochastic relaxation. It\naccepts arbitrary search space (widely-applicable) and enables to employ a\ngradient-based simultaneous optimization of weights and architecture (fast). We\npropose a stochastic natural gradient method with an adaptive step-size\nmechanism built upon our theoretical investigation (robust). Despite its\nsimplicity and no problem-dependent parameter tuning, our method exhibited near\nstate-of-the-art performances with low computational budgets both on image\nclassification and inpainting tasks.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 10:39:04 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Akimoto", "Youhei", ""], ["Shirakawa", "Shinichi", ""], ["Yoshinari", "Nozomu", ""], ["Uchida", "Kento", ""], ["Saito", "Shota", ""], ["Nishida", "Kouhei", ""]]}, {"id": "1905.08723", "submitter": "Ting-Shuo Yo", "authors": "Ting-Shuo Yo and Edwin de Jong", "title": "A comparison of evaluation methods in coevolution", "comments": "8 pages, 7 figures, GECCO '07: Proceedings of the 9th annual\n  conference on Genetic and evolutionary computation", "journal-ref": null, "doi": "10.1145/1276958.1277060", "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this research, we compare four different evaluation methods in coevolution\non the Majority Function problem. The size of the problem is selected such that\nevaluation against all possible test cases is feasible. Two measures are used\nfor the comparisons, i.e., the objective fitness derived from evaluating\nsolutions against all test cases, and the objective fitness correlation (OFC),\nwhich is defined as the correlation coefficient between subjective and\nobjective fitness. The results of our experiments suggest that a combination of\naverage score and weighted informativeness may provide a more accurate\nevaluation in coevolution. In order to confirm this difference, a series of\nt-tests on the preference between each pair of the evaluation methods is\nperformed. The resulting significance is affirmative, and the tests for two\nquality measures show similar preference on four evaluation methods. %This\nstudy is the first time OFC is actually computed on a real problem. Experiments\non Majority Function problems with larger sizes and Parity problems are in\nprogress, and their results will be added in the final version.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 16:11:00 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Yo", "Ting-Shuo", ""], ["de Jong", "Edwin", ""]]}, {"id": "1905.08885", "submitter": "Benjamin Inden", "authors": "Benjamin Inden and J\\\"urgen Jost", "title": "Evolving neural networks to follow trajectories of arbitrary complexity", "comments": null, "journal-ref": "Neural Networks, Volume 116, 2019, Pages 224-236, ISSN 0893-6080", "doi": "10.1016/j.neunet.2019.04.013", "report-no": null, "categories": "cs.NE cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many experiments have been performed that use evolutionary algorithms for\nlearning the topology and connection weights of a neural network that controls\na robot or virtual agent. These experiments are not only performed to better\nunderstand basic biological principles, but also with the hope that with\nfurther progress of the methods, they will become competitive for automatically\ncreating robot behaviors of interest. However, current methods are limited with\nrespect to the (Kolmogorov) complexity of evolved behavior. Using the evolution\nof robot trajectories as an example, we show that by adding four features,\nnamely (1) freezing of previously evolved structure, (2) temporal scaffolding,\n(3) a homogeneous transfer function for output nodes, and (4) mutations that\ncreate new pathways to outputs, to standard methods for the evolution of neural\nnetworks, we can achieve an approximately linear growth of the complexity of\nbehavior over thousands of generations. Overall, evolved complexity is up to\ntwo orders of magnitude over that achieved by standard methods in the\nexperiments reported here, with the major limiting factor for further growth\nbeing the available run time. Thus, the set of methods proposed here promises\nto be a useful addition to various current neuroevolution methods.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2019 22:07:38 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Inden", "Benjamin", ""], ["Jost", "J\u00fcrgen", ""]]}, {"id": "1905.09372", "submitter": "Thomas Helmuth", "authors": "Thomas Helmuth, Edward Pantridge, Lee Spector", "title": "Lexicase Selection of Specialists", "comments": null, "journal-ref": null, "doi": "10.1145/3321707.3321875", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexicase parent selection filters the population by considering one random\ntraining case at a time, eliminating any individuals with errors for the\ncurrent case that are worse than the best error in the selection pool, until a\nsingle individual remains. This process often stops before considering all\ntraining cases, meaning that it will ignore the error values on any cases that\nwere not yet considered. Lexicase selection can therefore select specialist\nindividuals that have poor errors on some training cases, if they have great\nerrors on others and those errors come near the start of the random list of\ncases used for the parent selection event in question. We hypothesize here that\nselecting these specialists, which may have poor total error, plays an\nimportant role in lexicase selection's observed performance advantages over\nerror-aggregating parent selection methods such as tournament selection, which\nselect specialists much less frequently. We conduct experiments examining this\nhypothesis, and find that lexicase selection's performance and diversity\nmaintenance degrade when we deprive it of the ability of selecting specialists.\nThese findings help explain the improved performance of lexicase selection\ncompared to tournament selection, and suggest that specialists help drive\nevolution under lexicase selection toward global solutions.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 21:26:02 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 14:42:54 GMT"}, {"version": "v3", "created": "Thu, 2 Jan 2020 18:50:32 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Helmuth", "Thomas", ""], ["Pantridge", "Edward", ""], ["Spector", "Lee", ""]]}, {"id": "1905.09374", "submitter": "Thomas Helmuth", "authors": "Lia Jundt, Thomas Helmuth", "title": "Comparing and Combining Lexicase Selection and Novelty Search", "comments": null, "journal-ref": null, "doi": "10.1145/3321707.3321787", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexicase selection and novelty search, two parent selection methods used in\nevolutionary computation, emphasize exploring widely in the search space more\nthan traditional methods such as tournament selection. However, lexicase\nselection is not explicitly driven to select for novelty in the population, and\nnovelty search suffers from lack of direction toward a goal, especially in\nunconstrained, highly-dimensional spaces. We combine the strengths of lexicase\nselection and novelty search by creating a novelty score for each test case,\nand adding those novelty scores to the normal error values used in lexicase\nselection. We use this new novelty-lexicase selection to solve automatic\nprogram synthesis problems, and find it significantly outperforms both novelty\nsearch and lexicase selection. Additionally, we find that novelty search has\nvery little success in the problem domain of program synthesis. We explore the\neffects of each of these methods on population diversity and long-term problem\nsolving performance, and give evidence to support the hypothesis that\nnovelty-lexicase selection resists converging to local optima better than\nlexicase selection.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 21:38:00 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 14:28:15 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Jundt", "Lia", ""], ["Helmuth", "Thomas", ""]]}, {"id": "1905.09419", "submitter": "Hanten Chang", "authors": "Hanten Chang, Shinji Nakaoka, and Hiroyasu Ando", "title": "Effect of shapes of activation functions on predictability in the echo\n  state network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate prediction accuracy for time series of Echo state networks\nwith respect to several kinds of activation functions. As a result, we found\nthat some kinds of activation functions with an appropriate nonlinearity show\nhigh performance compared to the conventional sigmoid function.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2019 10:07:06 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Chang", "Hanten", ""], ["Nakaoka", "Shinji", ""], ["Ando", "Hiroyasu", ""]]}, {"id": "1905.09438", "submitter": "Alexander Long", "authors": "Alex Long, Joel Mason, Alan Blair, Wei Wang", "title": "Multi-hop Reading Comprehension via Deep Reinforcement Learning based\n  Document Traversal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reading Comprehension has received significant attention in recent years as\nhigh quality Question Answering (QA) datasets have become available. Despite\nstate-of-the-art methods achieving strong overall accuracy, Multi-Hop (MH)\nreasoning remains particularly challenging. To address MH-QA specifically, we\npropose a Deep Reinforcement Learning based method capable of learning\nsequential reasoning across large collections of documents so as to pass a\nquery-aware, fixed-size context subset to existing models for answer\nextraction. Our method is comprised of two stages: a linker, which decomposes\nthe provided support documents into a graph of sentences, and an extractor,\nwhich learns where to look based on the current question and already-visited\nsentences. The result of the linker is a novel graph structure at the sentence\nlevel that preserves logical flow while still allowing rapid movement between\ndocuments. Importantly, we demonstrate that the sparsity of the resultant graph\nis invariant to context size. This translates to fewer decisions required from\nthe Deep-RL trained extractor, allowing the system to scale effectively to\nlarge collections of documents.\n  The importance of sequential decision making in the document traversal step\nis demonstrated by comparison to standard IE methods, and we additionally\nintroduce a BM25-based IR baseline that retrieves documents relevant to the\nquery only. We examine the integration of our method with existing models on\nthe recently proposed QAngaroo benchmark and achieve consistent increases in\naccuracy across the board, as well as a 2-3x reduction in training time.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 02:32:34 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Long", "Alex", ""], ["Mason", "Joel", ""], ["Blair", "Alan", ""], ["Wang", "Wei", ""]]}, {"id": "1905.09492", "submitter": "Lianjiang Li", "authors": "Lianjiang Li, Yunrong Yang, Bingna Li", "title": "Combine PPO with NES to Improve Exploration", "comments": "18 pages, 14 figures", "journal-ref": "arXiv:1905.09492v1 [cs.LG] 23 May 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two approaches for combining neural evolution strategy (NES) and\nproximal policy optimization (PPO): parameter transfer and parameter space\nnoise. Parameter transfer is a PPO agent with parameters transferred from a NES\nagent. Parameter space noise is to directly add noise to the PPO agent`s\nparameters. We demonstrate that PPO could benefit from both methods through\nexperimental comparison on discrete action environments as well as continuous\ncontrol tasks\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 06:32:07 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 05:03:27 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Li", "Lianjiang", ""], ["Yang", "Yunrong", ""], ["Li", "Bingna", ""]]}, {"id": "1905.09574", "submitter": "Seongmun Jung", "authors": "Seongmun Jung and Oh Joon Kwon", "title": "Improving Neural Networks by Adopting Amplifying and Attenuating Neurons", "comments": "8 pages, the figure 6-(b) and (c) were exchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present study, an amplifying neuron and attenuating neuron, which can\nbe easily implemented into neural networks without any significant additional\ncomputational effort, are proposed. The activated output value is squared for\nthe amplifying neuron, while the value becomes its reciprocal for the\nattenuating one. Theoretically, the order of neural networks increases when the\namplifying neuron is placed in the hidden layer. The performance assessments of\nneural networks were conducted to verify that the amplifying and attenuating\nneurons enhance the performance of neural networks. From the numerical\nexperiments, it was revealed that the neural networks that contain the\namplifying and attenuating neurons yield more accurate results, compared to\nthose without them.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 10:28:56 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 10:22:34 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Jung", "Seongmun", ""], ["Kwon", "Oh Joon", ""]]}, {"id": "1905.09598", "submitter": "Ravi Vadlamani", "authors": "Rohit Gavval, Vadlamani Ravi, Kalavala Revanth Harshal, Akhilesh\n  Gangwar and Kumar Ravi", "title": "CUDA-Self-Organizing feature map based visual sentiment analysis of bank\n  customer complaints for Analytical CRM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the widespread use of social media, companies now have access to a\nwealth of customer feedback data which has valuable applications to Customer\nRelationship Management (CRM). Analyzing customer grievances data, is paramount\nas their speedy non-redressal would lead to customer churn resulting in lower\nprofitability. In this paper, we propose a descriptive analytics framework\nusing Self-organizing feature map (SOM), for Visual Sentiment Analysis of\ncustomer complaints. The network learns the inherent grouping of the complaints\nautomatically which can then be visualized too using various techniques.\nAnalytical Customer Relationship Management (ACRM) executives can draw useful\nbusiness insights from the maps and take timely remedial action. We also\npropose a high-performance version of the algorithm CUDASOM (CUDA based Self\nOrganizing feature Map) implemented using NVIDIA parallel computing platform,\nCUDA, which speeds up the processing of high-dimensional text data and\ngenerates fast results. The efficacy of the proposed model has been\ndemonstrated on the customer complaints data regarding the products and\nservices of four leading Indian banks. CUDASOM achieved an average speed up of\n44 times. Our approach can expand research into intelligent grievance redressal\nsystem to provide rapid solutions to the complaining customers.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 11:49:48 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Gavval", "Rohit", ""], ["Ravi", "Vadlamani", ""], ["Harshal", "Kalavala Revanth", ""], ["Gangwar", "Akhilesh", ""], ["Ravi", "Kumar", ""]]}, {"id": "1905.09618", "submitter": "Christoph Salge", "authors": "Daniel Ashlock and Christoph Salge", "title": "Automatic Generation of Level Maps with the Do What's Possible\n  Representation", "comments": "8 pages, in proceedings of 2019 IEEE Conference on Games, COG 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic generation of level maps is a popular form of automatic content\ngeneration. In this study, a recently developed technique employing the {\\em do\nwhat's possible} representation is used to create open-ended level maps.\nGeneration of the map can continue indefinitely, yielding a highly scalable\nrepresentation. A parameter study is performed to find good parameters for the\nevolutionary algorithm used to locate high-quality map generators. Variations\non the technique are presented, demonstrating its versatility, and an\nalgorithmic variant is given that both improves performance and changes the\ncharacter of maps located. The ability of the map to adapt to different regions\nwhere the map is permitted to occupy space are also tested.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 12:33:11 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Ashlock", "Daniel", ""], ["Salge", "Christoph", ""]]}, {"id": "1905.09676", "submitter": "Xiaoxi He", "authors": "Xiaoxi He, Dawei Gao, Zimu Zhou, Yongxin Tong, Lothar Thiele", "title": "Pruning-Aware Merging for Efficient Multitask Inference", "comments": "Accepted to KDD'21 as research track paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many mobile applications demand selective execution of multiple correlated\ndeep learning inference tasks on resource-constrained platforms. Given a set of\ndeep neural networks, each pre-trained for a single task, it is desired that\nexecuting arbitrary combinations of tasks yields minimal computation cost.\nPruning each network separately yields suboptimal computation cost due to task\nrelatedness. A promising remedy is to merge the networks into a multitask\nnetwork to eliminate redundancy across tasks before network pruning. However,\npruning a multitask network combined by existing network merging schemes cannot\nminimise the computation cost of every task combination because they do not\nconsider such a future pruning. To this end, we theoretically identify the\nconditions such that pruning a multitask network minimises the computation of\nall task combinations. On this basis, we propose Pruning-Aware Merging (PAM), a\nheuristic network merging scheme to construct a multitask network that\napproximates these conditions. The merged network is then ready to be further\npruned by existing network pruning methods. Evaluations with different pruning\nschemes, datasets, and network architectures show that PAM achieves up to 4.87x\nless computation against the baseline without network merging, and up to 2.01x\nless computation against the baseline with a state-of-the-art network merging\nscheme.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 14:23:46 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 20:35:47 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["He", "Xiaoxi", ""], ["Gao", "Dawei", ""], ["Zhou", "Zimu", ""], ["Tong", "Yongxin", ""], ["Thiele", "Lothar", ""]]}, {"id": "1905.09788", "submitter": "Hiroshi Inoue", "authors": "Hiroshi Inoue", "title": "Multi-Sample Dropout for Accelerated Training and Better Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dropout is a simple but efficient regularization technique for achieving\nbetter generalization of deep neural networks (DNNs); hence it is widely used\nin tasks based on DNNs. During training, dropout randomly discards a portion of\nthe neurons to avoid overfitting. This paper presents an enhanced dropout\ntechnique, which we call multi-sample dropout, for both accelerating training\nand improving generalization over the original dropout. The original dropout\ncreates a randomly selected subset (called a dropout sample) from the input in\neach training iteration while the multi-sample dropout creates multiple dropout\nsamples. The loss is calculated for each sample, and then the sample losses are\naveraged to obtain the final loss. This technique can be easily implemented by\nduplicating a part of the network after the dropout layer while sharing the\nweights among the duplicated fully connected layers. Experimental results using\nimage classification tasks including ImageNet, CIFAR-10, and CIFAR-100 showed\nthat multi-sample dropout accelerates training. Moreover, the networks trained\nusing multi-sample dropout achieved lower error rates compared to networks\ntrained with the original dropout. The additional computation cost due to the\nduplicated operations is not significant for deep convolutional networks\nbecause most of the computation time is consumed in the convolution layers\nbefore the dropout layer, which are not duplicated.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 17:22:57 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 06:25:23 GMT"}, {"version": "v3", "created": "Wed, 21 Oct 2020 02:39:55 GMT"}], "update_date": "2020-10-22", "authors_parsed": [["Inoue", "Hiroshi", ""]]}, {"id": "1905.09950", "submitter": "Andrew Lampinen", "authors": "Andrew K. Lampinen, James L. McClelland", "title": "Zero-shot task adaptation by homoiconic meta-mapping", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can deep learning systems flexibly reuse their knowledge? Toward this\ngoal, we propose a new class of challenges, and a class of architectures that\ncan solve them. The challenges are meta-mappings, which involve systematically\ntransforming task behaviors to adapt to new tasks zero-shot. The key to\nachieving these challenges is representing the task being performed in such a\nway that this task representation is itself transformable. We therefore draw\ninspiration from functional programming and recent work in meta-learning to\npropose a class of Homoiconic Meta-Mapping (HoMM) approaches that represent\ndata points and tasks in a shared latent space, and learn to infer\ntransformations of that space. HoMM approaches can be applied to any type of\nmachine learning task. We demonstrate the utility of this perspective by\nexhibiting zero-shot remapping of behavior to adapt to new tasks.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 22:05:32 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 11:02:03 GMT"}, {"version": "v3", "created": "Tue, 24 Sep 2019 18:09:57 GMT"}, {"version": "v4", "created": "Tue, 12 Nov 2019 22:40:28 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Lampinen", "Andrew K.", ""], ["McClelland", "James L.", ""]]}, {"id": "1905.10094", "submitter": "Katharina Bieker", "authors": "Katharina Bieker, Sebastian Peitz, Steven L. Brunton, J. Nathan Kutz,\n  Michael Dellnitz", "title": "Deep Model Predictive Control with Online Learning for Complex Physical\n  Systems", "comments": null, "journal-ref": null, "doi": "10.1007/s00162-020-00520-4", "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The control of complex systems is of critical importance in many branches of\nscience, engineering, and industry. Controlling an unsteady fluid flow is\nparticularly important, as flow control is a key enabler for technologies in\nenergy (e.g., wind, tidal, and combustion), transportation (e.g., planes,\ntrains, and automobiles), security (e.g., tracking airborne contamination), and\nhealth (e.g., artificial hearts and artificial respiration). However, the\nhigh-dimensional, nonlinear, and multi-scale dynamics make real-time feedback\ncontrol infeasible. Fortunately, these high-dimensional systems exhibit\ndominant, low-dimensional patterns of activity that can be exploited for\neffective control in the sense that knowledge of the entire state of a system\nis not required. Advances in machine learning have the potential to\nrevolutionize flow control given its ability to extract principled, low-rank\nfeature spaces characterizing such complex systems. We present a novel deep\nlearning model predictive control (DeepMPC) framework that exploits low-rank\nfeatures of the flow in order to achieve considerable improvements to control\nperformance. Instead of predicting the entire fluid state, we use a recurrent\nneural network (RNN) to accurately predict the control relevant quantities of\nthe system. The RNN is then embedded into a MPC framework to construct a\nfeedback loop, and incoming sensor data is used to perform online updates to\nimprove prediction accuracy. The results are validated using varying fluid flow\nexamples of increasing complexity.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 08:54:44 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Bieker", "Katharina", ""], ["Peitz", "Sebastian", ""], ["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""], ["Dellnitz", "Michael", ""]]}, {"id": "1905.10224", "submitter": "Dominik Alfke", "authors": "Dominik Alfke and Martin Stoll", "title": "Semi-Supervised Classification on Non-Sparse Graphs Using Low-Rank Graph\n  Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM cs.NE math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) have proven to be successful tools for\nsemi-supervised learning on graph-based datasets. For sparse graphs, linear and\npolynomial filter functions have yielded impressive results. For large\nnon-sparse graphs, however, network training and evaluation becomes\nprohibitively expensive. By introducing low-rank filters, we gain significant\nruntime acceleration and simultaneously improved accuracy. We further propose\nan architecture change mimicking techniques from Model Order Reduction in what\nwe call a reduced-order GCN. Moreover, we present how our method can also be\napplied to hypergraph datasets and how hypergraph convolution can be\nimplemented efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 13:32:09 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Alfke", "Dominik", ""], ["Stoll", "Martin", ""]]}, {"id": "1905.10245", "submitter": "Michael Lones", "authors": "Michael Lones", "title": "Instruction-Level Design of Local Optimisers using Push GP", "comments": "Genetic and Evolutionary Computation Conference (GECCO'19), Prague,\n  Czech Republic, July 13-17, 2019", "journal-ref": null, "doi": "10.1145/3319619.3326806", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work uses genetic programming to explore the design space of local\noptimisation algorithms. Optimisers are expressed in the Push programming\nlanguage, a stack-based language with a wide range of typed primitive\ninstructions. The evolutionary framework provides the evolving optimisers with\nan outer loop and information about whether a solution has improved, but\notherwise they are relatively unconstrained in how they explore optimisation\nlandscapes. To test the utility of this approach, optimisers were evolved on\nfour different types of continuous landscape, and the search behaviours of the\nevolved optimisers analysed. By making use of mathematical functions such as\ntangents and logarithms to explore different neighbourhoods, and also by\nlearning features of the landscapes, it was observed that the evolved\noptimisers were often able to reach the optima using relatively short paths.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 14:17:51 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Lones", "Michael", ""]]}, {"id": "1905.10268", "submitter": "Anna Bosman", "authors": "Anna Sergeevna Bosman, Andries Engelbrecht, Mard\\'e Helbig", "title": "Loss Surface Modality of Feed-Forward Neural Network Architectures", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been argued in the past that high-dimensional neural networks do not\nexhibit local minima capable of trapping an optimisation algorithm. However,\nthe relationship between loss surface modality and the neural architecture\nparameters, such as the number of hidden neurons per layer and the number of\nhidden layers, remains poorly understood. This study employs fitness landscape\nanalysis to study the modality of neural network loss surfaces under various\nfeed-forward architecture settings. An increase in the problem dimensionality\nis shown to yield a more searchable and more exploitable loss surface. An\nincrease in the hidden layer width is shown to effectively reduce the number of\nlocal minima, and simplify the shape of the global attractor. An increase in\nthe architecture depth is shown to sharpen the global attractor, thus making it\nmore exploitable.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 14:59:48 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2020 14:02:16 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Bosman", "Anna Sergeevna", ""], ["Engelbrecht", "Andries", ""], ["Helbig", "Mard\u00e9", ""]]}, {"id": "1905.10337", "submitter": "Zeyuan Allen-Zhu", "authors": "Zeyuan Allen-Zhu, Yuanzhi Li", "title": "What Can ResNet Learn Efficiently, Going Beyond Kernels?", "comments": "V2 slightly improves lower bound, V3 strengthens experiments and adds\n  citation to \"backward feature correction\" which is an even stronger form of\n  hierarchical learning [2]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can neural networks such as ResNet efficiently learn CIFAR-10 with test\naccuracy more than 96%, while other methods, especially kernel methods, fall\nrelatively behind? Can we more provide theoretical justifications for this gap?\n  Recently, there is an influential line of work relating neural networks to\nkernels in the over-parameterized regime, proving they can learn certain\nconcept class that is also learnable by kernels with similar test error. Yet,\ncan neural networks provably learn some concept class BETTER than kernels?\n  We answer this positively in the distribution-free setting. We prove neural\nnetworks can efficiently learn a notable class of functions, including those\ndefined by three-layer residual networks with smooth activations, without any\ndistributional assumption. At the same time, we prove there are simple\nfunctions in this class such that with the same number of training examples,\nthe test error obtained by neural networks can be MUCH SMALLER than ANY kernel\nmethod, including neural tangent kernels (NTK).\n  The main intuition is that multi-layer neural networks can implicitly perform\nhierarchical learning using different layers, which reduces the sample\ncomplexity comparing to \"one-shot\" learning algorithms such as kernel methods.\nIn a follow-up work [2], this theory of hierarchical learning is further\nstrengthened to incorporate the \"backward feature correction\" process when\ntraining deep networks.\n  In the end, we also prove a computation complexity advantage of ResNet with\nrespect to other learning methods including linear regression over arbitrary\nfeature mappings.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 17:02:51 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2019 07:25:18 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 17:25:52 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Allen-Zhu", "Zeyuan", ""], ["Li", "Yuanzhi", ""]]}, {"id": "1905.10540", "submitter": "Xin Qian", "authors": "Xin Qian, Matthew Kennedy, and Diego Klabjan", "title": "Dynamic Cell Structure via Recursive-Recurrent Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recurrent setting, conventional approaches to neural architecture search\nfind and fix a general model for all data samples and time steps. We propose a\nnovel algorithm that can dynamically search for the structure of cells in a\nrecurrent neural network model. Based on a combination of recurrent and\nrecursive neural networks, our algorithm is able to construct customized cell\nstructures for each data sample and time step, allowing for a more efficient\narchitecture search than existing models. Experiments on three common datasets\nshow that the algorithm discovers high-performance cell architectures and\nachieves better prediction accuracy compared to the GRU structure for language\nmodelling and sentiment analysis.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 07:14:05 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Qian", "Xin", ""], ["Kennedy", "Matthew", ""], ["Klabjan", "Diego", ""]]}, {"id": "1905.10585", "submitter": "Jan Melchior", "authors": "Jan Melchior, Laurenz Wiskott", "title": "Hebbian-Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose Hebbian-descent as a biologically plausible learning\nrule for hetero-associative as well as auto-associative learning in single\nlayer artificial neural networks. It can be used as a replacement for gradient\ndescent as well as Hebbian learning, in particular in online learning, as it\ninherits their advantages while not suffering from their disadvantages. We\ndiscuss the drawbacks of Hebbian learning as having problems with correlated\ninput data and not profiting from seeing training patterns several times. For\ngradient descent we identify the derivative of the activation function as\nproblematic especially in online learning. Hebbian-descent addresses these\nproblems by getting rid of the activation function's derivative and by\ncentering, i.e. keeping the neural activities mean free, leading to a\nbiologically plausible update rule that is provably convergent, does not suffer\nfrom the vanishing error term problem, can deal with correlated data, profits\nfrom seeing patterns several times, and enables successful online learning when\ncentering is used. We discuss its relationship to Hebbian learning, contrastive\nlearning, and gradient decent and show that in case of a strictly positive\nderivative of the activation function Hebbian-descent leads to the same update\nrule as gradient descent but for a different loss function. In this case\nHebbian-descent inherits the convergence properties of gradient descent, but we\nalso show empirically that it converges when the derivative of the activation\nfunction is only non-negative, such as for the step function for example.\nFurthermore, in case of the mean squared error loss Hebbian-descent can be\nunderstood as the difference between two Hebb-learning steps, which in case of\nan invertible and integrable activation function actually optimizes a\ngeneralized linear model. ...\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 12:11:19 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Melchior", "Jan", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "1905.10692", "submitter": "Manu V Nair", "authors": "Manu V Nair and Giacomo Indiveri", "title": "Mapping high-performance RNNs to in-memory neuromorphic chips", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing need for compact and low-power computing solutions for machine\nlearning applications has triggered significant interest in energy-efficient\nneuromorphic systems. However, most of these architectures rely on spiking\nneural networks, which typically perform poorly compared to their non-spiking\ncounterparts in terms of accuracy. In this paper, we propose a new adaptive\nspiking neuron model that can be abstracted as a low-pass filter. This\nabstraction enables faster and better training of spiking networks using\nback-propagation, without simulating spikes. We show that this model\ndramatically improves the inference performance of a recurrent neural network\nand validate it with three complex spatio-temporal learning tasks: the temporal\naddition task, the temporal copying task, and a spoken-phrase recognition task.\nWe estimate at least 500x higher energy-efficiency using our models on\ncompatible neuromorphic chips in comparison to Cortex-M4, a popular embedded\nmicroprocessor.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 23:15:33 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 13:29:52 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 12:37:07 GMT"}, {"version": "v4", "created": "Fri, 20 Dec 2019 02:26:53 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Nair", "Manu V", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "1905.10696", "submitter": "Alexander Ororbia", "authors": "Alexander Ororbia, Ankur Mali, Daniel Kifer, C. Lee Giles", "title": "Lifelong Neural Predictive Coding: Learning Cumulatively Online without\n  Forgetting", "comments": "Key updates including results on standard benchmarks, e.g., split\n  mnist/fmnist/not-mnist. Task selection/basal ganglia model has been\n  integrated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In lifelong learning systems, especially those based on artificial neural\nnetworks, one of the biggest obstacles is the severe inability to retain old\nknowledge as new information is encountered. This phenomenon is known as\ncatastrophic forgetting. In this article, we propose a new kind of\nconnectionist architecture, the Sequential Neural Coding Network, that is\nrobust to forgetting when learning from streams of data points and, unlike\nnetworks of today, does not learn via the immensely popular back-propagation of\nerrors. Grounded in the neurocognitive theory of predictive processing, our\nmodel adapts its synapses in a biologically-plausible fashion, while another,\ncomplementary neural system rapidly learns to direct and control this\ncortex-like structure by mimicking the task-executive control functionality of\nthe basal ganglia. In our experiments, we demonstrate that our self-organizing\nsystem experiences significantly less forgetting as compared to standard neural\nmodels and outperforms a wide swath of previously proposed methods even though\nit is trained across task datasets in a stream-like fashion. The promising\nperformance of our complementary system on benchmarks, e.g., SplitMNIST, Split\nFashion MNIST, and Split NotMNIST, offers evidence that by incorporating\nmechanisms prominent in real neuronal systems, such as competition, sparse\nactivation patterns, and iterative input processing, a new possibility for\ntackling the grand challenge of lifelong machine learning opens up.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 23:31:27 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 01:00:59 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ororbia", "Alexander", ""], ["Mali", "Ankur", ""], ["Kifer", "Daniel", ""], ["Giles", "C. Lee", ""]]}, {"id": "1905.10698", "submitter": "Farshid Varno", "authors": "Farshid Varno, Behrouz Haji Soleimani, Marzie Saghayi, Lisa Di Jorio\n  and Stan Matwin", "title": "Efficient Neural Task Adaptation by Maximum Entropy Initialization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferring knowledge from one neural network to another has been shown to\nbe helpful for learning tasks with few training examples. Prevailing\nfine-tuning methods could potentially contaminate pre-trained features by\ncomparably high energy random noise. This noise is mainly delivered from a\ncareless replacement of task-specific parameters. We analyze theoretically such\nknowledge contamination for classification tasks and propose a practical and\neasy to apply method to trap and minimize the contaminant. In our approach, the\nentropy of the output estimates gets maximized initially and the first\nback-propagated error is stalled at the output of the last layer. Our proposed\nmethod not only outperforms the traditional fine-tuning, but also significantly\nspeeds up the convergence of the learner. It is robust to randomness and\nindependent of the choice of architecture. Overall, our experiments show that\nthe power of transfer learning has been substantially underestimated so far.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 23:37:34 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 02:32:53 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Varno", "Farshid", ""], ["Soleimani", "Behrouz Haji", ""], ["Saghayi", "Marzie", ""], ["Di Jorio", "Lisa", ""], ["Matwin", "Stan", ""]]}, {"id": "1905.10761", "submitter": "Kumar Shridhar", "authors": "Kumar Shridhar, Joonho Lee, Hideaki Hayashi, Purvanshi Mehta, Brian\n  Kenji Iwana, Seokjun Kang, Seiichi Uchida, Sheraz Ahmed, Andreas Dengel", "title": "ProbAct: A Probabilistic Activation Function for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activation functions play an important role in training artificial neural\nnetworks. The majority of currently used activation functions are deterministic\nin nature, with their fixed input-output relationship. In this work, we propose\na novel probabilistic activation function, called ProbAct. ProbAct is\ndecomposed into a mean and variance and the output value is sampled from the\nformed distribution, making ProbAct a stochastic activation function. The\nvalues of mean and variances can be fixed using known functions or trained for\neach element. In the trainable ProbAct, the mean and the variance of the\nactivation distribution is trained within the back-propagation framework\nalongside other parameters. We show that the stochastic perturbation induced\nthrough ProbAct acts as a viable generalization technique for feature\naugmentation. In our experiments, we compare ProbAct with well-known activation\nfunctions on classification tasks on different modalities: Images(CIFAR-10,\nCIFAR-100, and STL-10) and Text (Large Movie Review). We show that ProbAct\nincreases the classification accuracy by +2-3% compared to ReLU or other\nconventional activation functions on both original datasets and when datasets\nare reduced to 50% and 25% of the original size. Finally, we show that ProbAct\nlearns an ensemble of models by itself that can be used to estimate the\nuncertainties associated with the prediction and provides robustness to noisy\ninputs.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 08:22:26 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2020 00:39:25 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Shridhar", "Kumar", ""], ["Lee", "Joonho", ""], ["Hayashi", "Hideaki", ""], ["Mehta", "Purvanshi", ""], ["Iwana", "Brian Kenji", ""], ["Kang", "Seokjun", ""], ["Uchida", "Seiichi", ""], ["Ahmed", "Sheraz", ""], ["Dengel", "Andreas", ""]]}, {"id": "1905.10762", "submitter": "Gerard Howard", "authors": "Gerard David Howard and Alberto Elfes", "title": "A Staged Approach to Evolving Real-world UAV Controllers", "comments": "Evolutionary Intelligence preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A testbed has recently been introduced that evolves controllers for arbitrary\nhover-capable UAVs, with evaluations occurring directly on the robot. To\nprepare the testbed for real-world deployment, we investigate the effects of\nstate-space limitations brought about by physical tethering (which prevents\ndamage to the UAV during stochastic tuning), on the generality of the evolved\ncontrollers. We identify generalisation issues in some controllers, and propose\nan improved method that comprises two stages: in the first stage, controllers\nare evolved as normal using standard tethers, but experiments are terminated\nwhen the population displays basic flight competency. Optimisation then\ncontinues on a much less restrictive tether, effectively free-flying, and is\nallowed to explore a larger state-space envelope. We compare the two methods on\na hover task using a real UAV, and show that more general solutions are\ngenerated in fewer generations using the two-stage approach. A secondary\nexperiment undertakes a sensitivity analysis of the evolved controllers.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 08:25:15 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Howard", "Gerard David", ""], ["Elfes", "Alberto", ""]]}, {"id": "1905.10891", "submitter": "Bowei Chen", "authors": "Ji Ni and Bowei Chen and Nigel M. Allinson and Xujiong Ye", "title": "A hybrid model for predicting human physical activity status from\n  lifelogging data", "comments": null, "journal-ref": "European Journal of Operational Research, 281(3): 532-542, 2020", "doi": "10.1016/j.ejor.2019.05.035", "report-no": null, "categories": "cs.CY cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One trend in the recent healthcare transformations is people are encouraged\nto monitor and manage their health based on their daily diets and physical\nactivity habits. However, much attention of the use of operational research and\nanalytical models in healthcare has been paid to the systematic level such as\ncountry or regional policy making or organisational issues. This paper proposes\na model concerned with healthcare analytics at the individual level, which can\npredict human physical activity status from sequential lifelogging data\ncollected from wearable sensors. The model has a two-stage hybrid structure (in\nshort, MOGP-HMM) -- a multi-objective genetic programming (MOGP) algorithm in\nthe first stage to reduce the dimensions of lifelogging data and a hidden\nMarkov model (HMM) in the second stage for activity status prediction over\ntime. It can be used as a decision support tool to provide real-time\nmonitoring, statistical analysis and personalized advice to individuals,\nencouraging positive attitudes towards healthy lifestyles. We validate the\nmodel with the real data collected from a group of participants in the UK, and\ncompare it with other popular two-stage hybrid models. Our experimental results\nshow that the MOGP-HMM can achieve comparable performance. To the best of our\nknowledge, this is the very first study that uses the MOGP in the hybrid\ntwo-stage structure for individuals' activity status prediction. It fits\nseamlessly with the current trend in the UK healthcare transformation of\npatient empowerment as well as contributing to a strategic development for more\nefficient and cost-effective provision of healthcare.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 21:49:40 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 15:08:24 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Ni", "Ji", ""], ["Chen", "Bowei", ""], ["Allinson", "Nigel M.", ""], ["Ye", "Xujiong", ""]]}, {"id": "1905.10901", "submitter": "Alexander Wong", "authors": "Andrew Hryniowski and Alexander Wong", "title": "Seeing Convolution Through the Eyes of Finite Transformation Semigroup\n  Theory: An Abstract Algebraic Interpretation of Convolutional Neural Networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers are actively trying to gain better insights into the\nrepresentational properties of convolutional neural networks for guiding better\nnetwork designs and for interpreting a network's computational nature. Gaining\nsuch insights can be an arduous task due to the number of parameters in a\nnetwork and the complexity of a network's architecture. Current approaches of\nneural network interpretation include Bayesian probabilistic interpretations\nand information theoretic interpretations. In this study, we take a different\napproach to studying convolutional neural networks by proposing an abstract\nalgebraic interpretation using finite transformation semigroup theory.\nSpecifically, convolutional layers are broken up and mapped to a finite space.\nThe state space of the proposed finite transformation semigroup is then defined\nas a single element within the convolutional layer, with the acting elements\ndefined by surrounding state elements combined with convolution kernel\nelements. Generators of the finite transformation semigroup are defined to\ncomplete the interpretation. We leverage this approach to analyze the basic\nproperties of the resulting finite transformation semigroup to gain insights on\nthe representational properties of convolutional neural networks, including\ninsights into quantized network representation. Such a finite transformation\nsemigroup interpretation can also enable better understanding outside of the\nconfines of fixed lattice data structures, thus useful for handling data that\nlie on irregular lattices. Furthermore, the proposed abstract algebraic\ninterpretation is shown to be viable for interpreting convolutional operations\nwithin a variety of convolutional neural network architectures.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 23:11:18 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Hryniowski", "Andrew", ""], ["Wong", "Alexander", ""]]}, {"id": "1905.10952", "submitter": "Xiaoliang Dai", "authors": "Xiaoliang Dai, Hongxu Yin, Niraj K. Jha", "title": "Incremental Learning Using a Grow-and-Prune Paradigm with Efficient\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have become a widely deployed model for numerous\nmachine learning applications. However, their fixed architecture, substantial\ntraining cost, and significant model redundancy make it difficult to\nefficiently update them to accommodate previously unseen data. To solve these\nproblems, we propose an incremental learning framework based on a\ngrow-and-prune neural network synthesis paradigm. When new data arrive, the\nneural network first grows new connections based on the gradients to increase\nthe network capacity to accommodate new data. Then, the framework iteratively\nprunes away connections based on the magnitude of weights to enhance network\ncompactness, and hence recover efficiency. Finally, the model rests at a\nlightweight DNN that is both ready for inference and suitable for future\ngrow-and-prune updates. The proposed framework improves accuracy, shrinks\nnetwork size, and significantly reduces the additional training cost for\nincoming data compared to conventional approaches, such as training from\nscratch and network fine-tuning. For the LeNet-300-100 and LeNet-5 neural\nnetwork architectures derived for the MNIST dataset, the framework reduces\ntraining cost by up to 64% (63%) and 67% (63%) compared to training from\nscratch (network fine-tuning), respectively. For the ResNet-18 architecture\nderived for the ImageNet dataset and DeepSpeech2 for the AN4 dataset, the\ncorresponding training cost reductions against training from scratch (network\nfine-tunning) are 64% (60%) and 67% (62%), respectively. Our derived models\ncontain fewer network parameters but achieve higher accuracy relative to\nconventional baselines.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 03:12:46 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Dai", "Xiaoliang", ""], ["Yin", "Hongxu", ""], ["Jha", "Niraj K.", ""]]}, {"id": "1905.11235", "submitter": "Linhao Dong", "authors": "Linhao Dong, Bo Xu", "title": "CIF: Continuous Integrate-and-Fire for End-to-End Speech Recognition", "comments": "To appear at ICASSP 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel soft and monotonic alignment mechanism used\nfor sequence transduction. It is inspired by the integrate-and-fire model in\nspiking neural networks and employed in the encoder-decoder framework consists\nof continuous functions, thus being named as: Continuous Integrate-and-Fire\n(CIF). Applied to the ASR task, CIF not only shows a concise calculation, but\nalso supports online recognition and acoustic boundary positioning, thus\nsuitable for various ASR scenarios. Several support strategies are also\nproposed to alleviate the unique problems of CIF-based model. With the joint\naction of these methods, the CIF-based model shows competitive performance.\nNotably, it achieves a word error rate (WER) of 2.86% on the test-clean of\nLibrispeech and creates new state-of-the-art result on Mandarin telephone ASR\nbenchmark.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 14:00:45 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 15:33:54 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 04:47:02 GMT"}, {"version": "v4", "created": "Wed, 12 Feb 2020 11:13:58 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Dong", "Linhao", ""], ["Xu", "Bo", ""]]}, {"id": "1905.11368", "submitter": "Wei Hu", "authors": "Wei Hu, Zhiyuan Li, Dingli Yu", "title": "Simple and Effective Regularization Methods for Training on Noisily\n  Labeled Data with Generalization Guarantee", "comments": "International Conference on Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-parameterized deep neural networks trained by simple first-order methods\nare known to be able to fit any labeling of data. Such over-fitting ability\nhinders generalization when mislabeled training examples are present. On the\nother hand, simple regularization methods like early-stopping can often achieve\nhighly nontrivial performance on clean test data in these scenarios, a\nphenomenon not theoretically understood. This paper proposes and analyzes two\nsimple and intuitive regularization methods: (i) regularization by the distance\nbetween the network parameters to initialization, and (ii) adding a trainable\nauxiliary variable to the network output for each training example.\nTheoretically, we prove that gradient descent training with either of these two\nmethods leads to a generalization guarantee on the clean data distribution\ndespite being trained using noisy labels. Our generalization analysis relies on\nthe connection between wide neural network and neural tangent kernel (NTK). The\ngeneralization bound is independent of the network size, and is comparable to\nthe bound one can get when there is no label noise. Experimental results verify\nthe effectiveness of these methods on noisily labeled datasets.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 17:52:28 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 02:43:33 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 03:30:12 GMT"}, {"version": "v4", "created": "Fri, 2 Oct 2020 20:43:58 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Hu", "Wei", ""], ["Li", "Zhiyuan", ""], ["Yu", "Dingli", ""]]}, {"id": "1905.11437", "submitter": "Leonardo Enzo Brito da Silva", "authors": "Leonardo Enzo Brito da Silva, Islam Elnabarawy, Donald C. Wunsch II", "title": "A Survey of Adaptive Resonance Theory Neural Network Models for\n  Engineering Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey samples from the ever-growing family of adaptive resonance theory\n(ART) neural network models used to perform the three primary machine learning\nmodalities, namely, unsupervised, supervised and reinforcement learning. It\ncomprises a representative list from classic to modern ART models, thereby\npainting a general picture of the architectures developed by researchers over\nthe past 30 years. The learning dynamics of these ART models are briefly\ndescribed, and their distinctive characteristics such as code representation,\nlong-term memory and corresponding geometric interpretation are discussed.\nUseful engineering properties of ART (speed, configurability, explainability,\nparallelization and hardware implementation) are examined along with current\nchallenges. Finally, a compilation of online software libraries is provided. It\nis expected that this overview will be helpful to new and seasoned ART\nresearchers.\n", "versions": [{"version": "v1", "created": "Sat, 4 May 2019 00:54:06 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["da Silva", "Leonardo Enzo Brito", ""], ["Elnabarawy", "Islam", ""], ["Wunsch", "Donald C.", "II"]]}, {"id": "1905.11462", "submitter": "Hamidreza Arian", "authors": "Mohammadreza Ghanbari and Hamidreza Arian", "title": "Forecasting Stock Market with Support Vector Regression and Butterfly\n  Optimization Algorithm", "comments": "Preprint submitted to Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support Vector Regression (SVR) has achieved high performance on forecasting\nfuture behavior of random systems. However, the performance of SVR models\nhighly depends upon the appropriate choice of SVR parameters. In this study, a\nnovel BOA-SVR model based on Butterfly Optimization Algorithm (BOA) is\npresented. The performance of the proposed model is compared with eleven other\nmeta-heuristic algorithms on a number of stocks from NASDAQ. The results\nindicate that the presented model here is capable to optimize the SVR\nparameters very well and indeed is one of the best models judged by both\nprediction performance accuracy and time consumption.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 19:20:12 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Ghanbari", "Mohammadreza", ""], ["Arian", "Hamidreza", ""]]}, {"id": "1905.11528", "submitter": "Santiago Gonzalez", "authors": "Santiago Gonzalez and Risto Miikkulainen", "title": "Improved Training Speed, Accuracy, and Data Utilization Through Loss\n  Function Optimization", "comments": null, "journal-ref": "Proceedings of the 2020 IEEE Congress on Evolutionary Computation", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the complexity of neural network models has grown, it has become\nincreasingly important to optimize their design automatically through\nmetalearning. Methods for discovering hyperparameters, topologies, and learning\nrate schedules have lead to significant increases in performance. This paper\nshows that loss functions can be optimized with metalearning as well, and\nresult in similar improvements. The method, Genetic Loss-function Optimization\n(GLO), discovers loss functions de novo, and optimizes them for a target task.\nLeveraging techniques from genetic programming, GLO builds loss functions\nhierarchically from a set of operators and leaf nodes. These functions are\nrepeatedly recombined and mutated to find an optimal structure, and then a\ncovariance-matrix adaptation evolutionary strategy (CMA-ES) is used to find\noptimal coefficients. Networks trained with GLO loss functions are found to\noutperform the standard cross-entropy loss on standard image classification\ntasks. Training with these new loss functions requires fewer steps, results in\nlower test error, and allows for smaller datasets to be used. Loss-function\noptimization thus provides a new dimension of metalearning, and constitutes an\nimportant step towards AutoML.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 22:24:21 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 16:24:16 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 16:31:53 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Gonzalez", "Santiago", ""], ["Miikkulainen", "Risto", ""]]}, {"id": "1905.11530", "submitter": "Xiaocong Du", "authors": "Xiaocong Du, Zheng Li, Yufei Ma, Yu Cao", "title": "Efficient Network Construction through Structural Plasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) on hardware is facing excessive computation cost\ndue to the massive number of parameters. A typical training pipeline to\nmitigate over-parameterization is to pre-define a DNN structure first with\nredundant learning units (filters and neurons) under the goal of high accuracy,\nthen to prune redundant learning units after training with the purpose of\nefficient inference. We argue that it is sub-optimal to introduce redundancy\ninto training for the purpose of reducing redundancy later in inference.\nMoreover, the fixed network structure further results in poor adaption to\ndynamic tasks, such as lifelong learning. In contrast, structural plasticity\nplays an indispensable role in mammalian brains to achieve compact and accurate\nlearning. Throughout the lifetime, active connections are continuously created\nwhile those no longer important are degenerated. Inspired by such observation,\nwe propose a training scheme, namely Continuous Growth and Pruning (CGaP),\nwhere we start the training from a small network seed, then literally execute\ncontinuous growth by adding important learning units and finally prune\nsecondary ones for efficient inference. The inference model generated from CGaP\nis sparse in the structure, largely decreasing the inference power and latency\nwhen deployed on hardware platforms. With popular DNN structures on\nrepresentative datasets, the efficacy of CGaP is benchmarked by both algorithm\nsimulation and architectural modeling on Field-programmable Gate Arrays (FPGA).\nFor example, CGaP decreases the FLOPs, model size, DRAM access energy and\ninference latency by 63.3%, 64.0%, 11.8% and 40.2%, respectively, for\nResNet-110 on CIFAR-10.\n", "versions": [{"version": "v1", "created": "Mon, 27 May 2019 22:39:18 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 02:07:05 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2019 19:03:37 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Du", "Xiaocong", ""], ["Li", "Zheng", ""], ["Ma", "Yufei", ""], ["Cao", "Yu", ""]]}, {"id": "1905.11594", "submitter": "Yuan Zeng", "authors": "Yuan Zeng and Zubayer Ibne Ferdous and Weixiang Zhang and Mufan Xu and\n  Anlan Yu and Drew Patel and Xiaochen Guo and Yevgeny Berdichevsky and Zhiyuan\n  Yan", "title": "Inference with Hybrid Bio-hardware Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand the learning process in brains, biologically plausible\nalgorithms have been explored by modeling the detailed neuron properties and\ndynamics. On the other hand, simplified multi-layer models of neural networks\nhave shown great success on computational tasks such as image classification\nand speech recognition. However, the computational models that can achieve good\naccuracy for these learning applications are very different from the\nbio-plausible models. This paper studies whether a bio-plausible model of a in\nvitro living neural network can be used to perform machine learning tasks and\nachieve good inference accuracy. A novel two-layer bio-hardware hybrid neural\nnetwork is proposed. The biological layer faithfully models variations of\nsynapses, neurons, and network sparsity in in vitro living neural networks. The\nhardware layer is a computational fully-connected layer that tunes parameters\nto optimize for accuracy. Several techniques are proposed to improve the\ninference accuracy of the proposed hybrid neural network. For instance, an\nadaptive pre-processing technique helps the proposed neural network to achieve\ngood learning accuracy for different living neural network sparsity. The\nproposed hybrid neural network with realistic neuron parameters and variations\nachieves a 98.3% testing accuracy for the handwritten digit recognition task on\nthe full MNIST dataset.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 03:38:27 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 16:06:44 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Zeng", "Yuan", ""], ["Ferdous", "Zubayer Ibne", ""], ["Zhang", "Weixiang", ""], ["Xu", "Mufan", ""], ["Yu", "Anlan", ""], ["Patel", "Drew", ""], ["Guo", "Xiaochen", ""], ["Berdichevsky", "Yevgeny", ""], ["Yan", "Zhiyuan", ""]]}, {"id": "1905.11604", "submitter": "Preetum Nakkiran", "authors": "Preetum Nakkiran, Gal Kaplun, Dimitris Kalimeris, Tristan Yang,\n  Benjamin L. Edelman, Fred Zhang, Boaz Barak", "title": "SGD on Neural Networks Learns Functions of Increasing Complexity", "comments": "Submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform an experimental study of the dynamics of Stochastic Gradient\nDescent (SGD) in learning deep neural networks for several real and synthetic\nclassification tasks. We show that in the initial epochs, almost all of the\nperformance improvement of the classifier obtained by SGD can be explained by a\nlinear classifier. More generally, we give evidence for the hypothesis that, as\niterations progress, SGD learns functions of increasing complexity. This\nhypothesis can be helpful in explaining why SGD-learned classifiers tend to\ngeneralize well even in the over-parameterized regime. We also show that the\nlinear classifier learned in the initial stages is \"retained\" throughout the\nexecution even if training is continued to the point of zero training error,\nand complement this with a theoretical result in a simplified model. Key to our\nwork is a new measure of how well one classifier explains the performance of\nanother, based on conditional mutual information.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 04:34:08 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Nakkiran", "Preetum", ""], ["Kaplun", "Gal", ""], ["Kalimeris", "Dimitris", ""], ["Yang", "Tristan", ""], ["Edelman", "Benjamin L.", ""], ["Zhang", "Fred", ""], ["Barak", "Boaz", ""]]}, {"id": "1905.11742", "submitter": "Congzheng Song", "authors": "Congzheng Song, Vitaly Shmatikov", "title": "Overlearning Reveals Sensitive Attributes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Overlearning\" means that a model trained for a seemingly simple objective\nimplicitly learns to recognize attributes and concepts that are (1) not part of\nthe learning objective, and (2) sensitive from a privacy or bias perspective.\nFor example, a binary gender classifier of facial images also learns to\nrecognize races\\textemdash even races that are not represented in the training\ndata\\textemdash and identities.\n  We demonstrate overlearning in several vision and NLP models and analyze its\nharmful consequences. First, inference-time representations of an overlearned\nmodel reveal sensitive attributes of the input, breaking privacy protections\nsuch as model partitioning. Second, an overlearned model can be \"re-purposed\"\nfor a different, privacy-violating task even in the absence of the original\ntraining data.\n  We show that overlearning is intrinsic for some tasks and cannot be prevented\nby censoring unwanted attributes. Finally, we investigate where, when, and why\noverlearning happens during model training.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 11:16:02 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 20:01:43 GMT"}, {"version": "v3", "created": "Sat, 8 Feb 2020 23:45:05 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Song", "Congzheng", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "1905.11874", "submitter": "Antoine Cully", "authors": "Antoine Cully", "title": "Autonomous skill discovery with Quality-Diversity and Unsupervised\n  Descriptors", "comments": "The Genetic and Evolutionary Computation Conference 2019", "journal-ref": null, "doi": "10.1145/3321707.3321804", "report-no": null, "categories": "cs.RO cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Quality-Diversity optimization is a new family of optimization algorithms\nthat, instead of searching for a single optimal solution to solving a task,\nsearches for a large collection of solutions that all solve the task in a\ndifferent way. This approach is particularly promising for learning behavioral\nrepertoires in robotics, as such a diversity of behaviors enables robots to be\nmore versatile and resilient. However, these algorithms require the user to\nmanually define behavioral descriptors, which is used to determine whether two\nsolutions are different or similar. The choice of a behavioral descriptor is\ncrucial, as it completely changes the solution types that the algorithm\nderives. In this paper, we introduce a new method to automatically define this\ndescriptor by combining Quality-Diversity algorithms with unsupervised\ndimensionality reduction algorithms. This approach enables robots to\nautonomously discover the range of their capabilities while interacting with\ntheir environment. The results from two experimental scenarios demonstrate that\nrobot can autonomously discover a large range of possible behaviors, without\nany prior knowledge about their morphology and environment. Furthermore, these\nbehaviors are deemed to be similar to handcrafted solutions that uses domain\nknowledge and significantly more diverse than when using existing unsupervised\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 15:12:55 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Cully", "Antoine", ""]]}, {"id": "1905.11926", "submitter": "Chengxi Ye", "authors": "Chengxi Ye, Matthew Evanusa, Hua He, Anton Mitrokhin, Tom Goldstein,\n  James A. Yorke, Cornelia Ferm\\\"uller, Yiannis Aloimonos", "title": "Network Deconvolution", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution is a central operation in Convolutional Neural Networks (CNNs),\nwhich applies a kernel to overlapping regions shifted across the image.\nHowever, because of the strong correlations in real-world image data,\nconvolutional kernels are in effect re-learning redundant data. In this work,\nwe show that this redundancy has made neural network training challenging, and\npropose network deconvolution, a procedure which optimally removes pixel-wise\nand channel-wise correlations before the data is fed into each layer. Network\ndeconvolution can be efficiently calculated at a fraction of the computational\ncost of a convolution layer. We also show that the deconvolution filters in the\nfirst layer of the network resemble the center-surround structure found in\nbiological neurons in the visual regions of the brain. Filtering with such\nkernels results in a sparse representation, a desired property that has been\nmissing in the training of neural networks. Learning from the sparse\nrepresentation promotes faster convergence and superior results without the use\nof batch normalization. We apply our network deconvolution operation to 10\nmodern neural network models by replacing batch normalization within each.\nExtensive experiments show that the network deconvolution operation is able to\ndeliver performance improvement in all cases on the CIFAR-10, CIFAR-100, MNIST,\nFashion-MNIST, Cityscapes, and ImageNet datasets.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 16:38:34 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 17:44:36 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 19:24:00 GMT"}, {"version": "v4", "created": "Tue, 25 Feb 2020 20:48:22 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Ye", "Chengxi", ""], ["Evanusa", "Matthew", ""], ["He", "Hua", ""], ["Mitrokhin", "Anton", ""], ["Goldstein", "Tom", ""], ["Yorke", "James A.", ""], ["Ferm\u00fcller", "Cornelia", ""], ["Aloimonos", "Yiannis", ""]]}, {"id": "1905.11929", "submitter": "S. R. Nandakumar", "authors": "S. R. Nandakumar, Irem Boybat, Manuel Le Gallo, Evangelos Eleftheriou,\n  Abu Sebastian, Bipin Rajendran", "title": "Supervised Learning in Spiking Neural Networks with Phase-Change Memory\n  Synapses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNN) are artificial computational models that have\nbeen inspired by the brain's ability to naturally encode and process\ninformation in the time domain. The added temporal dimension is believed to\nrender them more computationally efficient than the conventional artificial\nneural networks, though their full computational capabilities are yet to be\nexplored. Recently, computational memory architectures based on non-volatile\nmemory crossbar arrays have shown great promise to implement parallel\ncomputations in artificial and spiking neural networks. In this work, we\nexperimentally demonstrate for the first time, the feasibility to realize\nhigh-performance event-driven in-situ supervised learning systems using\nnanoscale and stochastic phase-change synapses. Our SNN is trained to recognize\naudio signals of alphabets encoded using spikes in the time domain and to\ngenerate spike trains at precise time instances to represent the pixel\nintensities of their corresponding images. Moreover, with a statistical model\ncapturing the experimental behavior of the devices, we investigate\narchitectural and systems-level solutions for improving the training and\ninference performance of our computational memory-based system. Combining the\ncomputational potential of supervised SNNs with the parallel compute power of\ncomputational memory, the work paves the way for next-generation of efficient\nbrain-inspired systems.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 16:43:57 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Nandakumar", "S. R.", ""], ["Boybat", "Irem", ""], ["Gallo", "Manuel Le", ""], ["Eleftheriou", "Evangelos", ""], ["Sebastian", "Abu", ""], ["Rajendran", "Bipin", ""]]}, {"id": "1905.12019", "submitter": "Martin Mundt", "authors": "Martin Mundt, Sagnik Majumder, Iuliia Pliushch, Yong Won Hong,\n  Visvanathan Ramesh", "title": "Unified Probabilistic Deep Continual Learning through Generative Replay\n  and Open Set Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a probabilistic approach to unify open set recognition with the\nprevention of catastrophic forgetting in deep continual learning, based on\nvariational Bayesian inference. Our single model combines a joint probabilistic\nencoder with a generative model and a linear classifier that get shared across\nsequentially arriving tasks. In order to successfully distinguish unseen\nunknown data from trained known tasks, we propose to bound the class specific\napproximate posterior by fitting regions of high density on the basis of\ncorrectly classified data points. These bounds are further used to\nsignificantly alleviate catastrophic forgetting by avoiding samples from low\ndensity areas in generative replay. Our approach requires neither storing of\nold, nor upfront knowledge of future data, and is empirically validated on\nvisual and audio tasks in class incremental, as well as cross-dataset scenarios\nacross modalities.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 18:26:04 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 15:24:33 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2020 15:14:34 GMT"}, {"version": "v4", "created": "Fri, 4 Sep 2020 10:54:47 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Mundt", "Martin", ""], ["Majumder", "Sagnik", ""], ["Pliushch", "Iuliia", ""], ["Hong", "Yong Won", ""], ["Ramesh", "Visvanathan", ""]]}, {"id": "1905.12116", "submitter": "Tianlin Liu", "authors": "Tianlin Liu", "title": "Harnessing Slow Dynamics in Neuromorphic Computation", "comments": "Master thesis of Tianlin Liu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic Computing is a nascent research field in which models and\ndevices are designed to process information by emulating biological neural\nsystems. Thanks to their superior energy efficiency, analog neuromorphic\nsystems are highly promising for embedded, wearable, and implantable systems.\nHowever, optimizing neural networks deployed on these systems is challenging.\nOne main challenge is the so-called timescale mismatch: Dynamics of analog\ncircuits tend to be too fast to process real-time sensory inputs. In this\nthesis, we propose a few working solutions to slow down dynamics of on-chip\nspiking neural networks. We empirically show that, by harnessing slow dynamics,\nspiking neural networks on analog neuromorphic systems can gain non-trivial\nperformance boosts on a battery of real-time signal processing tasks.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 22:20:38 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Liu", "Tianlin", ""]]}, {"id": "1905.12130", "submitter": "James Aimone", "authors": "James B Aimone, William Severa, and Craig M Vineyard", "title": "Composing Neural Algorithms with Fugu", "comments": "Accepted to 2019 International Conference on Neuromorphic Systems\n  (ICONS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic hardware architectures represent a growing family of potential\npost-Moore's Law Era platforms. Largely due to event-driving processing\ninspired by the human brain, these computer platforms can offer significant\nenergy benefits compared to traditional von Neumann processors. Unfortunately\nthere still remains considerable difficulty in successfully programming,\nconfiguring and deploying neuromorphic systems. We present the Fugu framework\nas an answer to this need. Rather than necessitating a developer attain\nintricate knowledge of how to program and exploit spiking neural dynamics to\nutilize the potential benefits of neuromorphic computing, Fugu is designed to\nprovide a higher level abstraction as a hardware-independent mechanism for\nlinking a variety of scalable spiking neural algorithms from a variety of\nsources. Individual kernels linked together provide sophisticated processing\nthrough compositionality. Fugu is intended to be suitable for a wide-range of\nneuromorphic applications, including machine learning, scientific computing,\nand more brain-inspired neural algorithms. Ultimately, we hope the community\nadopts this and other open standardization attempts allowing for free exchange\nand easy implementations of the ever-growing list of spiking neural algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 28 May 2019 23:13:07 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Aimone", "James B", ""], ["Severa", "William", ""], ["Vineyard", "Craig M", ""]]}, {"id": "1905.12207", "submitter": "Joe Kileel", "authors": "Joe Kileel, Matthew Trager, Joan Bruna", "title": "On the Expressive Power of Deep Polynomial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.AG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study deep neural networks with polynomial activations, particularly their\nexpressive power. For a fixed architecture and activation degree, a polynomial\nneural network defines an algebraic map from weights to polynomials. The image\nof this map is the functional space associated to the network, and it is an\nirreducible algebraic variety upon taking closure. This paper proposes the\ndimension of this variety as a precise measure of the expressive power of\npolynomial neural networks. We obtain several theoretical results regarding\nthis dimension as a function of architecture, including an exact formula for\nhigh activation degrees, as well as upper and lower bounds on layer widths in\norder for deep polynomials networks to fill the ambient functional space. We\nalso present computational evidence that it is profitable in terms of\nexpressiveness for layer widths to increase monotonically and then decrease\nmonotonically. Finally, we link our study to favorable optimization properties\nwhen training weights, and we draw intriguing connections with tensor and\npolynomial decompositions.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 04:21:40 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Kileel", "Joe", ""], ["Trager", "Matthew", ""], ["Bruna", "Joan", ""]]}, {"id": "1905.12300", "submitter": "Ghouthi Boukli Hacene", "authors": "Ghouthi Boukli Hacene (IMT Atlantique - ELEC), Carlos Lassance,\n  Vincent Gripon (IMT Atlantique - ELEC), Matthieu Courbariaux, Yoshua Bengio\n  (DIRO)", "title": "Attention Based Pruning for Shift Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many application domains such as computer vision, Convolutional Layers\n(CLs) are key to the accuracy of deep learning methods. However, it is often\nrequired to assemble a large number of CLs, each containing thousands of\nparameters, in order to reach state-of-the-art accuracy, thus resulting in\ncomplex and demanding systems that are poorly fitted to resource-limited\ndevices. Recently, methods have been proposed to replace the generic\nconvolution operator by the combination of a shift operation and a simpler 1x1\nconvolution. The resulting block, called Shift Layer (SL), is an efficient\nalternative to CLs in the sense it allows to reach similar accuracies on\nvarious tasks with faster computations and fewer parameters. In this\ncontribution, we introduce Shift Attention Layers (SALs), which extend SLs by\nusing an attention mechanism that learns which shifts are the best at the same\ntime the network function is trained. We demonstrate SALs are able to\noutperform vanilla SLs (and CLs) on various object recognition benchmarks while\nsignificantly reducing the number of float operations and parameters for the\ninference.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 09:59:23 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Hacene", "Ghouthi Boukli", "", "IMT Atlantique - ELEC"], ["Lassance", "Carlos", "", "IMT Atlantique - ELEC"], ["Gripon", "Vincent", "", "IMT Atlantique - ELEC"], ["Courbariaux", "Matthieu", "", "DIRO"], ["Bengio", "Yoshua", "", "DIRO"]]}, {"id": "1905.12506", "submitter": "Sjoerd van Steenkiste", "authors": "Sjoerd van Steenkiste, Francesco Locatello, J\\\"urgen Schmidhuber,\n  Olivier Bachem", "title": "Are Disentangled Representations Helpful for Abstract Visual Reasoning?", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A disentangled representation encodes information about the salient factors\nof variation in the data independently. Although it is often argued that this\nrepresentational format is useful in learning to solve many real-world\ndown-stream tasks, there is little empirical evidence that supports this claim.\nIn this paper, we conduct a large-scale study that investigates whether\ndisentangled representations are more suitable for abstract reasoning tasks.\nUsing two new tasks similar to Raven's Progressive Matrices, we evaluate the\nusefulness of the representations learned by 360 state-of-the-art unsupervised\ndisentanglement models. Based on these representations, we train 3600 abstract\nreasoning models and observe that disentangled representations do in fact lead\nto better down-stream performance. In particular, they enable quicker learning\nusing fewer samples.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 14:52:32 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 17:00:42 GMT"}, {"version": "v3", "created": "Tue, 7 Jan 2020 14:36:07 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["van Steenkiste", "Sjoerd", ""], ["Locatello", "Francesco", ""], ["Schmidhuber", "J\u00fcrgen", ""], ["Bachem", "Olivier", ""]]}, {"id": "1905.12600", "submitter": "Hanie Sedghi", "authors": "Philip M. Long and Hanie Sedghi", "title": "Generalization bounds for deep convolutional neural networks", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove bounds on the generalization error of convolutional networks. The\nbounds are in terms of the training loss, the number of parameters, the\nLipschitz constant of the loss and the distance from the weights to the initial\nweights. They are independent of the number of pixels in the input, and the\nheight and width of hidden feature maps. We present experiments using CIFAR-10\nwith varying hyperparameters of a deep convolutional network, comparing our\nbounds with practical generalization gaps.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 17:20:36 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 16:54:56 GMT"}, {"version": "v3", "created": "Fri, 26 Jul 2019 16:39:20 GMT"}, {"version": "v4", "created": "Fri, 27 Sep 2019 01:55:42 GMT"}, {"version": "v5", "created": "Sun, 9 Feb 2020 20:00:07 GMT"}, {"version": "v6", "created": "Wed, 8 Apr 2020 05:10:39 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Long", "Philip M.", ""], ["Sedghi", "Hanie", ""]]}, {"id": "1905.12601", "submitter": "Nithin Nagaraj", "authors": "Harikrishnan N B and Nithin Nagaraj", "title": "A Novel Chaos Theory Inspired Neuronal Architecture", "comments": "6 pages, 5 figures. This is a pre-print version of the manuscript\n  which we will be submitting soon to an international conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The practical success of widely used machine learning (ML) and deep learning\n(DL) algorithms in Artificial Intelligence (AI) community owes to availability\nof large datasets for training and huge computational resources. Despite the\nenormous practical success of AI, these algorithms are only loosely inspired\nfrom the biological brain and do not mimic any of the fundamental properties of\nneurons in the brain, one such property being the chaotic firing of biological\nneurons. This motivates us to develop a novel neuronal architecture where the\nindividual neurons are intrinsically chaotic in nature. By making use of the\ntopological transitivity property of chaos, our neuronal network is able to\nperform classification tasks with very less number of training samples. For the\nMNIST dataset, with as low as $0.1 \\%$ of the total training data, our method\noutperforms ML and matches DL in classification accuracy for up to $7$ training\nsamples/class. For the Iris dataset, our accuracy is comparable with ML\nalgorithms, and even with just two training samples/class, we report an\naccuracy as high as $95.8 \\%$. This work highlights the effectiveness of chaos\nand its properties for learning and paves the way for chaos-inspired neuronal\narchitectures by closely mimicking the chaotic nature of neurons in the brain.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2019 07:45:57 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["B", "Harikrishnan N", ""], ["Nagaraj", "Nithin", ""]]}, {"id": "1905.12679", "submitter": "Andrew Stephan", "authors": "Andrew W. Stephan, Qiuwen Lou, Michael Niemier, X. Sharon Hu and\n  Steven J. Koester", "title": "Nonvolatile Spintronic Memory Cells for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new spintronic nonvolatile memory cell analogous to 1T DRAM with\nnon-destructive read is proposed. The cells can be used as neural computing\nunits. A dual-circuit neural network architecture is proposed to leverage these\ndevices against the complex operations involved in convolutional networks.\nSimulations based on HSPICE and Matlab were performed to study the performance\nof this architecture when classifying images as well as the effect of varying\nthe size and stability of the nanomagnets. The spintronic cells outperform a\npurely charge-based implementation of the same network, consuming about 100 pJ\ntotal per image processed.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 18:57:22 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Stephan", "Andrew W.", ""], ["Lou", "Qiuwen", ""], ["Niemier", "Michael", ""], ["Hu", "X. Sharon", ""], ["Koester", "Steven J.", ""]]}, {"id": "1905.12702", "submitter": "Jamal Toutouh", "authors": "Jamal Toutouh, Erik Hemberg and Una-May O'Reilly", "title": "Spatial Evolutionary Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3321707.3321860", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversary networks (GANs) suffer from training pathologies such as\ninstability and mode collapse. These pathologies mainly arise from a lack of\ndiversity in their adversarial interactions. Evolutionary generative\nadversarial networks apply the principles of evolutionary computation to\nmitigate these problems. We hybridize two of these approaches that promote\ntraining diversity. One, E-GAN, at each batch, injects mutation diversity by\ntraining the (replicated) generator with three independent objective functions\nthen selecting the resulting best performing generator for the next batch. The\nother, Lipizzaner, injects population diversity by training a two-dimensional\ngrid of GANs with a distributed evolutionary algorithm that includes neighbor\nexchanges of additional training adversaries, performance based selection and\npopulation-based hyper-parameter tuning. We propose to combine mutation and\npopulation approaches to diversity improvement. We contribute a superior\nevolutionary GANs training method, Mustangs, that eliminates the single loss\nfunction used across Lipizzaner's grid. Instead, each training round, a loss\nfunction is selected with equal probability, from among the three E-GAN uses.\nExperimental analyses on standard benchmarks, MNIST and CelebA, demonstrate\nthat Mustangs provides a statistically faster training method resulting in more\naccurate networks.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2019 20:03:03 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Toutouh", "Jamal", ""], ["Hemberg", "Erik", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "1905.12797", "submitter": "Yuping Lin", "authors": "Yuping Lin, Kasra Ahmadi K. A., Hui Jiang", "title": "Bandlimiting Neural Networks Against Adversarial Attacks", "comments": "Summitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the adversarial attack and defence problem in deep\nlearning from the perspective of Fourier analysis. We first explicitly compute\nthe Fourier transform of deep ReLU neural networks and show that there exist\ndecaying but non-zero high frequency components in the Fourier spectrum of\nneural networks. We demonstrate that the vulnerability of neural networks\ntowards adversarial samples can be attributed to these insignificant but\nnon-zero high frequency components. Based on this analysis, we propose to use a\nsimple post-averaging technique to smooth out these high frequency components\nto improve the robustness of neural networks against adversarial attacks.\nExperimental results on the ImageNet dataset have shown that our proposed\nmethod is universally effective to defend many existing adversarial attacking\nmethods proposed in the literature, including FGSM, PGD, DeepFool and C&W\nattacks. Our post-averaging method is simple since it does not require any\nre-training, and meanwhile it can successfully defend over 95% of the\nadversarial samples generated by these methods without introducing any\nsignificant performance degradation (less than 1%) on the original clean\nimages.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 00:34:50 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Lin", "Yuping", ""], ["A.", "Kasra Ahmadi K.", ""], ["Jiang", "Hui", ""]]}, {"id": "1905.12892", "submitter": "Aditya Grover", "authors": "Aditya Grover, Christopher Chute, Rui Shu, Zhangjie Cao, Stefano Ermon", "title": "AlignFlow: Cycle Consistent Learning from Multiple Domains via\n  Normalizing Flows", "comments": "AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given datasets from multiple domains, a key challenge is to efficiently\nexploit these data sources for modeling a target domain. Variants of this\nproblem have been studied in many contexts, such as cross-domain translation\nand domain adaptation. We propose AlignFlow, a generative modeling framework\nthat models each domain via a normalizing flow. The use of normalizing flows\nallows for a) flexibility in specifying learning objectives via adversarial\ntraining, maximum likelihood estimation, or a hybrid of the two methods; and b)\nlearning and exact inference of a shared representation in the latent space of\nthe generative model. We derive a uniform set of conditions under which\nAlignFlow is marginally-consistent for the different learning objectives.\nFurthermore, we show that AlignFlow guarantees exact cycle consistency in\nmapping datapoints from a source domain to target and back to the source\ndomain. Empirically, AlignFlow outperforms relevant baselines on image-to-image\ntranslation and unsupervised domain adaptation and can be used to\nsimultaneously interpolate across the various domains using the learned\nrepresentation.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 07:28:26 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 08:31:42 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Grover", "Aditya", ""], ["Chute", "Christopher", ""], ["Shu", "Rui", ""], ["Cao", "Zhangjie", ""], ["Ermon", "Stefano", ""]]}, {"id": "1905.12921", "submitter": "Yifan Qian", "authors": "Yifan Qian, Paul Expert, Tom Rieu, Pietro Panzarasa and Mauricio\n  Barahona", "title": "Quantifying the Alignment of Graph and Features in Deep Learning", "comments": "Published in IEEE Transactions on Neural Networks and Learning\n  Systems; Date of Publication: 11 January 2021", "journal-ref": null, "doi": "10.1109/TNNLS.2020.3043196", "report-no": null, "categories": "cs.LG cs.NE cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the classification performance of graph convolutional networks\n(GCNs) is related to the alignment between features, graph, and ground truth,\nwhich we quantify using a subspace alignment measure (SAM) corresponding to the\nFrobenius norm of the matrix of pairwise chordal distances between three\nsubspaces associated with features, graph, and ground truth. The proposed\nmeasure is based on the principal angles between subspaces and has both\nspectral and geometrical interpretations. We showcase the relationship between\nthe SAM and the classification performance through the study of limiting cases\nof GCNs and systematic randomizations of both features and graph structure\napplied to a constructive example and several examples of citation networks of\ndifferent origins. The analysis also reveals the relative importance of the\ngraph and features for classification purposes.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 09:14:58 GMT"}, {"version": "v2", "created": "Sun, 6 Dec 2020 22:22:01 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 17:04:26 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Qian", "Yifan", ""], ["Expert", "Paul", ""], ["Rieu", "Tom", ""], ["Panzarasa", "Pietro", ""], ["Barahona", "Mauricio", ""]]}, {"id": "1905.12937", "submitter": "Jan Melchior", "authors": "Jan Melchior and Mehdi Bayati and Amir Azizi and Sen Cheng and Laurenz\n  Wiskott", "title": "A Hippocampus Model for Online One-Shot Storage of Pattern Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a computational model based on the CRISP theory (Content\nRepresentation, Intrinsic Sequences, and Pattern completion) of the hippocampus\nthat allows to continuously store pattern sequences online in a one-shot\nfashion. Rather than storing a sequence in CA3, CA3 provides a pre-trained\nsequence that is hetero-associated with the input sequence, which allows the\nsystem to perform one-shot learning. Plasticity on a short time scale therefore\nonly happens in the incoming and outgoing connections of CA3. Stored sequences\ncan later be recalled from a single cue pattern. We identify the pattern\nseparation performed by subregion DG to be necessary for storing sequences that\ncontain correlated patterns. A design principle of the model is that we use a\nsingle learning rule named Hebbiand-escent to train all parts of the system.\nHebbian-descent has an inherent forgetting mechanism that allows the system to\ncontinuously memorize new patterns while forgetting early stored ones. The\nmodel shows a plausible behavior when noisy and new patterns are presented and\nhas a rather high capacity of about 40% in terms of the number of neurons in\nCA3. One notable property of our model is that it is capable of\n`boot-strapping' (improving) itself without external input in a process we\nrefer to as `dreaming'. Besides artificially generated input sequences we also\nshow that the model works with sequences of encoded handwritten digits or\nnatural images. To our knowledge this is the first model of the hippocampus\nthat allows to store correlated pattern sequences online in a one-shot fashion\nwithout a consolidation process, which can instantaneously be recalled later.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 09:51:58 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Melchior", "Jan", ""], ["Bayati", "Mehdi", ""], ["Azizi", "Amir", ""], ["Cheng", "Sen", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "1905.13209", "submitter": "Michael S. Ryoo", "authors": "Michael S. Ryoo, AJ Piergiovanni, Mingxing Tan, Anelia Angelova", "title": "AssembleNet: Searching for Multi-Stream Neural Connectivity in Video\n  Architectures", "comments": null, "journal-ref": "ICLR 2020", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to represent videos is a very challenging task both algorithmically\nand computationally. Standard video CNN architectures have been designed by\ndirectly extending architectures devised for image understanding to include the\ntime dimension, using modules such as 3D convolutions, or by using two-stream\ndesign to capture both appearance and motion in videos. We interpret a video\nCNN as a collection of multi-stream convolutional blocks connected to each\nother, and propose the approach of automatically finding neural architectures\nwith better connectivity and spatio-temporal interactions for video\nunderstanding. This is done by evolving a population of overly-connected\narchitectures guided by connection weight learning. Architectures combining\nrepresentations that abstract different input types (i.e., RGB and optical\nflow) at multiple temporal resolutions are searched for, allowing different\ntypes or sources of information to interact with each other. Our method,\nreferred to as AssembleNet, outperforms prior approaches on public video\ndatasets, in some cases by a great margin. We obtain 58.6% mAP on Charades and\n34.27% accuracy on Moments-in-Time.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:51:03 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 17:54:13 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2020 17:48:45 GMT"}, {"version": "v4", "created": "Wed, 27 May 2020 15:56:37 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Ryoo", "Michael S.", ""], ["Piergiovanni", "AJ", ""], ["Tan", "Mingxing", ""], ["Angelova", "Anelia", ""]]}, {"id": "1905.13211", "submitter": "Keyulu Xu", "authors": "Keyulu Xu, Jingling Li, Mozhi Zhang, Simon S. Du, Ken-ichi\n  Kawarabayashi, Stefanie Jegelka", "title": "What Can Neural Networks Reason About?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have succeeded in many reasoning tasks. Empirically, these\ntasks require specialized network structures, e.g., Graph Neural Networks\n(GNNs) perform well on many such tasks, but less structured networks fail.\nTheoretically, there is limited understanding of why and when a network\nstructure generalizes better than others, although they have equal expressive\npower. In this paper, we develop a framework to characterize which reasoning\ntasks a network can learn well, by studying how well its computation structure\naligns with the algorithmic structure of the relevant reasoning process. We\nformally define this algorithmic alignment and derive a sample complexity bound\nthat decreases with better alignment. This framework offers an explanation for\nthe empirical success of popular reasoning models, and suggests their\nlimitations. As an example, we unify seemingly different reasoning tasks, such\nas intuitive physics, visual question answering, and shortest paths, via the\nlens of a powerful algorithmic paradigm, dynamic programming (DP). We show that\nGNNs align with DP and thus are expected to solve these tasks. On several\nreasoning tasks, our theory is supported by empirical results.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 17:53:30 GMT"}, {"version": "v2", "created": "Fri, 31 May 2019 21:50:31 GMT"}, {"version": "v3", "created": "Sun, 29 Sep 2019 20:42:29 GMT"}, {"version": "v4", "created": "Sat, 15 Feb 2020 06:56:25 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Xu", "Keyulu", ""], ["Li", "Jingling", ""], ["Zhang", "Mozhi", ""], ["Du", "Simon S.", ""], ["Kawarabayashi", "Ken-ichi", ""], ["Jegelka", "Stefanie", ""]]}, {"id": "1905.13266", "submitter": "William La Cava", "authors": "William La Cava, Lee Spector, Kourosh Danai", "title": "Epsilon-Lexicase Selection for Regression", "comments": "9 pages, 9 figures. Presented at GECCO '16. Includes correction", "journal-ref": null, "doi": "10.1145/2908812.2908898", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexicase selection is a parent selection method that considers test cases\nseparately, rather than in aggregate, when performing parent selection. It\nperforms well in discrete error spaces but not on the continuous-valued\nproblems that compose most system identification tasks. In this paper, we\ndevelop a new form of lexicase selection for symbolic regression, named\nepsilon-lexicase selection, that redefines the pass condition for individuals\non each test case in a more effective way. We run a series of experiments on\nreal-world and synthetic problems with several treatments of epsilon and\nquantify how epsilon affects parent selection and model performance.\nepsilon-lexicase selection is shown to be effective for regression, producing\nbetter fit models compared to other techniques such as tournament selection and\nage-fitness Pareto optimization. We demonstrate that epsilon can be adapted\nautomatically for individual test cases based on the population performance\ndistribution. Our experiments show that epsilon-lexicase selection with\nautomatic epsilon produces the most accurate models across tested problems with\nnegligible computational overhead. We show that behavioral diversity is\nexceptionally high in lexicase selection treatments, and that epsilon-lexicase\nselection makes use of more fitness cases when selecting parents than lexicase\nselection, which helps explain the performance improvement.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 19:10:29 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["La Cava", "William", ""], ["Spector", "Lee", ""], ["Danai", "Kourosh", ""]]}, {"id": "1905.13298", "submitter": "Mostafa Elhoushi", "authors": "Mostafa Elhoushi, Zihao Chen, Farhan Shafiq, Ye Henry Tian, Joey Yiwei\n  Li", "title": "DeepShift: Towards Multiplication-Less Neural Networks", "comments": "-Added results for 8-bit and 16-bit fixed point activations, as well\n  as 5-bit, 4-bit, 3-bit, and 2-bit weights. - Added link to GitHub code -\n  Updated and fixed the training algorithm - Introduced 2 approaches for\n  backward and forward pases - Showed better results for training from scratch\n  on CIFAR10 and Imagenet - Added implementation on NVIDIA's GPU -Accepted in\n  CVPR Mobile AI 2021 Workshop", "journal-ref": "Proceedings of the IEEE/CVF Conference on Computer Vision and\n  Pattern Recognition (CVPR) Workshops, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high computation, memory, and power budgets of inferring convolutional\nneural networks (CNNs) are major bottlenecks of model deployment to edge\ncomputing platforms, e.g., mobile devices and IoT. Moreover, training CNNs is\ntime and energy-intensive even on high-grade servers. Convolution layers and\nfully connected layers, because of their intense use of multiplications, are\nthe dominant contributor to this computation budget.\n  We propose to alleviate this problem by introducing two new operations:\nconvolutional shifts and fully-connected shifts which replace multiplications\nwith bitwise shift and sign flipping during both training and inference. During\ninference, both approaches require only 5 bits (or less) to represent the\nweights. This family of neural network architectures (that use convolutional\nshifts and fully connected shifts) is referred to as DeepShift models. We\npropose two methods to train DeepShift models: DeepShift-Q which trains regular\nweights constrained to powers of 2, and DeepShift-PS that trains the values of\nthe shifts and sign flips directly.\n  Very close accuracy, and in some cases higher accuracy, to baselines are\nachieved. Converting pre-trained 32-bit floating-point baseline models of\nResNet18, ResNet50, VGG16, and GoogleNet to DeepShift and training them for 15\nto 30 epochs, resulted in Top-1/Top-5 accuracies higher than that of the\noriginal model.\n  Last but not least, we implemented the convolutional shifts and fully\nconnected shift GPU kernels and showed a reduction in latency time of 25% when\ninferring ResNet18 compared to unoptimized multiplication-based GPU kernels.\nThe code can be found at https://github.com/mostafaelhoushi/DeepShift.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 20:50:21 GMT"}, {"version": "v2", "created": "Thu, 6 Jun 2019 13:55:06 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 04:01:26 GMT"}, {"version": "v4", "created": "Sun, 13 Jun 2021 23:50:32 GMT"}, {"version": "v5", "created": "Thu, 8 Jul 2021 00:45:34 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Elhoushi", "Mostafa", ""], ["Chen", "Zihao", ""], ["Shafiq", "Farhan", ""], ["Tian", "Ye Henry", ""], ["Li", "Joey Yiwei", ""]]}, {"id": "1905.13308", "submitter": "Jesse Livezey", "authors": "Jesse A. Livezey, Ahyeon Hwang, Jacob Yeung, Kristofer E. Bouchard", "title": "Hangul Fonts Dataset: a Hierarchical and Compositional Dataset for\n  Investigating Learned Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchy and compositionality are common latent properties in many natural\nand scientific datasets. Determining when a deep network's hidden activations\nrepresent hierarchy and compositionality is important both for understanding\ndeep representation learning and for applying deep networks in domains where\ninterpretability is crucial. However, current benchmark machine learning\ndatasets either have little hierarchical or compositional structure, or the\nstructure is not known. This gap impedes precise analysis of a network's\nrepresentations and thus hinders development of new methods that can learn such\nproperties. To address this gap, we developed a new benchmark dataset with\nknown hierarchical and compositional structure. The Hangul Fonts Dataset (HFD)\nis comprised of 35 fonts from the Korean writing system (Hangul), each with\n11,172 blocks (syllables) composed from the product of initial consonant,\nmedial vowel, and final consonant glyphs. All blocks can be grouped into a few\ngeometric types which induces a hierarchy across blocks. In addition, each\nblock is composed of individual glyphs with rotations, translations, scalings,\nand naturalistic style variation across fonts. We find that both shallow and\ndeep unsupervised methods only show modest evidence of hierarchy and\ncompositionality in their representations of the HFD compared to supervised\ndeep networks. Supervised deep network representations contain structure\nrelated to the geometrical hierarchy of the characters, but the compositional\nstructure of the data is not evident. Thus, HFD enables the identification of\nshortcomings in existing methods, a critical first step toward developing new\nmachine learning algorithms to extract hierarchical and compositional structure\nin the context of naturalistic variability.\n", "versions": [{"version": "v1", "created": "Thu, 23 May 2019 21:20:58 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 17:13:10 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Livezey", "Jesse A.", ""], ["Hwang", "Ahyeon", ""], ["Yeung", "Jacob", ""], ["Bouchard", "Kristofer E.", ""]]}, {"id": "1905.13469", "submitter": "Ben Deverett", "authors": "Ben Deverett, Ryan Faulkner, Meire Fortunato, Greg Wayne, Joel Z.\n  Leibo", "title": "Interval timing in deep reinforcement learning agents", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The measurement of time is central to intelligent behavior. We know that both\nanimals and artificial agents can successfully use temporal dependencies to\nselect actions. In artificial agents, little work has directly addressed (1)\nwhich architectural components are necessary for successful development of this\nability, (2) how this timing ability comes to be represented in the units and\nactions of the agent, and (3) whether the resulting behavior of the system\nconverges on solutions similar to those of biology. Here we studied interval\ntiming abilities in deep reinforcement learning agents trained end-to-end on an\ninterval reproduction paradigm inspired by experimental literature on\nmechanisms of timing. We characterize the strategies developed by recurrent and\nfeedforward agents, which both succeed at temporal reproduction using distinct\nmechanisms, some of which bear specific and intriguing similarities to\nbiological systems. These findings advance our understanding of how agents come\nto represent time, and they highlight the value of experimentally inspired\napproaches to characterizing agent abilities.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 09:05:31 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 15:56:26 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Deverett", "Ben", ""], ["Faulkner", "Ryan", ""], ["Fortunato", "Meire", ""], ["Wayne", "Greg", ""], ["Leibo", "Joel Z.", ""]]}, {"id": "1905.13570", "submitter": "Tan Zhi-Xuan", "authors": "Tan Zhi-Xuan, Harold Soh, Desmond C. Ong", "title": "Factorized Inference in Deep Markov Models for Incomplete Multimodal\n  Time Series", "comments": "8 pages, 4 figures, accepted to AAAI 2020, code available at:\n  https://github.com/ztangent/multimodal-dmm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating deep learning with latent state space models has the potential to\nyield temporal models that are powerful, yet tractable and interpretable.\nUnfortunately, current models are not designed to handle missing data or\nmultiple data modalities, which are both prevalent in real-world data. In this\nwork, we introduce a factorized inference method for Multimodal Deep Markov\nModels (MDMMs), allowing us to filter and smooth in the presence of missing\ndata, while also performing uncertainty-aware multimodal fusion. We derive this\nmethod by factorizing the posterior p(z|x) for non-linear state space models,\nand develop a variational backward-forward algorithm for inference. Because our\nmethod handles incompleteness over both time and modalities, it is capable of\ninterpolation, extrapolation, conditional generation, label prediction, and\nweakly supervised learning of multimodal time series. We demonstrate these\ncapabilities on both synthetic and real-world multimodal data under high levels\nof data deletion. Our method performs well even with more than 50% missing\ndata, and outperforms existing deep approaches to inference in latent time\nseries.\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 10:20:32 GMT"}, {"version": "v2", "created": "Sun, 11 Aug 2019 11:41:49 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2019 13:34:39 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Zhi-Xuan", "Tan", ""], ["Soh", "Harold", ""], ["Ong", "Desmond C.", ""]]}, {"id": "1905.13607", "submitter": "Richard Jiang", "authors": "Gary Storey, Richard Jiang, Shelagh Keogh, Ahmed Bouridane and\n  Chang-Tsun Li", "title": "3DPalsyNet: A Facial Palsy Grading and Motion Recognition Framework\n  using Fully 3D Convolutional Neural Networks", "comments": null, "journal-ref": "IEEE Access 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capability to perform facial analysis from video sequences has\nsignificant potential to positively impact in many areas of life. One such area\nrelates to the medical domain to specifically aid in the diagnosis and\nrehabilitation of patients with facial palsy. With this application in mind,\nthis paper presents an end-to-end framework, named 3DPalsyNet, for the tasks of\nmouth motion recognition and facial palsy grading. 3DPalsyNet utilizes a 3D CNN\narchitecture with a ResNet backbone for the prediction of these dynamic tasks.\nLeveraging transfer learning from a 3D CNNs pre-trained on the Kinetics data\nset for general action recognition, the model is modified to apply joint\nsupervised learning using center and softmax loss concepts. 3DPalsyNet is\nevaluated on a test set consisting of individuals with varying ranges of facial\npalsy and mouth motions and the results have shown an attractive level of\nclassification accuracy in these task of 82% and 86% respectively. The frame\nduration and the loss function affect was studied in terms of the predictive\nqualities of the proposed 3DPalsyNet, where it was found shorter frame\nduration's of 8 performed best for this specific task. Centre loss and softmax\nhave shown improvements in spatio-temporal feature learning than softmax loss\nalone, this is in agreement with earlier work involving the spatial domain.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 13:24:30 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Storey", "Gary", ""], ["Jiang", "Richard", ""], ["Keogh", "Shelagh", ""], ["Bouridane", "Ahmed", ""], ["Li", "Chang-Tsun", ""]]}, {"id": "1905.13633", "submitter": "Maxence Ernoult", "authors": "Maxence Ernoult, Julie Grollier, Damien Querlioz, Yoshua Bengio,\n  Benjamin Scellier", "title": "Updates of Equilibrium Prop Match Gradients of Backprop Through Time in\n  an RNN with Static Input", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equilibrium Propagation (EP) is a biologically inspired learning algorithm\nfor convergent recurrent neural networks, i.e. RNNs that are fed by a static\ninput x and settle to a steady state. Training convergent RNNs consists in\nadjusting the weights until the steady state of output neurons coincides with a\ntarget y. Convergent RNNs can also be trained with the more conventional\nBackpropagation Through Time (BPTT) algorithm. In its original formulation EP\nwas described in the case of real-time neuronal dynamics, which is\ncomputationally costly. In this work, we introduce a discrete-time version of\nEP with simplified equations and with reduced simulation time, bringing EP\ncloser to practical machine learning tasks. We first prove theoretically, as\nwell as numerically that the neural and weight updates of EP, computed by\nforward-time dynamics, are step-by-step equal to the ones obtained by BPTT,\nwith gradients computed backward in time. The equality is strict when the\ntransition function of the dynamics derives from a primitive function and the\nsteady state is maintained long enough. We then show for more standard\ndiscrete-time neural network dynamics that the same property is approximately\nrespected and we subsequently demonstrate training with EP with equivalent\nperformance to BPTT. In particular, we define the first convolutional\narchitecture trained with EP achieving ~ 1% test error on MNIST, which is the\nlowest error reported with EP. These results can guide the development of deep\nneural networks trained with EP.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:26:39 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Ernoult", "Maxence", ""], ["Grollier", "Julie", ""], ["Querlioz", "Damien", ""], ["Bengio", "Yoshua", ""], ["Scellier", "Benjamin", ""]]}, {"id": "1905.13655", "submitter": "Nadav Cohen", "authors": "Sanjeev Arora, Nadav Cohen, Wei Hu, Yuping Luo", "title": "Implicit Regularization in Deep Matrix Factorization", "comments": "Published at the conference on Neural Information Processing Systems\n  (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efforts to understand the generalization mystery in deep learning have led to\nthe belief that gradient-based optimization induces a form of implicit\nregularization, a bias towards models of low \"complexity.\" We study the\nimplicit regularization of gradient descent over deep linear neural networks\nfor matrix completion and sensing, a model referred to as deep matrix\nfactorization. Our first finding, supported by theory and experiments, is that\nadding depth to a matrix factorization enhances an implicit tendency towards\nlow-rank solutions, oftentimes leading to more accurate recovery. Secondly, we\npresent theoretical and empirical arguments questioning a nascent view by which\nimplicit regularization in matrix factorization can be captured using simple\nmathematical norms. Our results point to the possibility that the language of\nstandard regularizers may not be rich enough to fully encompass the implicit\nregularization brought forth by gradient-based optimization.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 14:54:36 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 16:46:10 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 07:09:24 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Arora", "Sanjeev", ""], ["Cohen", "Nadav", ""], ["Hu", "Wei", ""], ["Luo", "Yuping", ""]]}, {"id": "1905.13715", "submitter": "Emin Orhan", "authors": "A. Emin Orhan, Xaq Pitkow", "title": "Improved memory in recurrent neural networks with sequential non-normal\n  dynamics", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training recurrent neural networks (RNNs) is a hard problem due to\ndegeneracies in the optimization landscape, a problem also known as\nvanishing/exploding gradients. Short of designing new RNN architectures,\nprevious methods for dealing with this problem usually boil down to\northogonalization of the recurrent dynamics, either at initialization or during\nthe entire training period. The basic motivation behind these methods is that\northogonal transformations are isometries of the Euclidean space, hence they\npreserve (Euclidean) norms and effectively deal with vanishing/exploding\ngradients. However, this ignores the crucial effects of non-linearity and\nnoise. In the presence of a non-linearity, orthogonal transformations no longer\npreserve norms, suggesting that alternative transformations might be better\nsuited to non-linear networks. Moreover, in the presence of noise, norm\npreservation itself ceases to be the ideal objective. A more sensible objective\nis maximizing the signal-to-noise ratio (SNR) of the propagated signal instead.\nPrevious work has shown that in the linear case, recurrent networks that\nmaximize the SNR display strongly non-normal, sequential dynamics and\northogonal networks are highly suboptimal by this measure. Motivated by this\nfinding, here we investigate the potential of non-normal RNNs, i.e. RNNs with a\nnon-normal recurrent connectivity matrix, in sequential processing tasks. Our\nexperimental results show that non-normal RNNs outperform their orthogonal\ncounterparts in a diverse range of benchmarks. We also find evidence for\nincreased non-normality and hidden chain-like feedforward motifs in trained\nRNNs initialized with orthogonal recurrent connectivity matrices.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 16:50:46 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 15:46:22 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Orhan", "A. Emin", ""], ["Pitkow", "Xaq", ""]]}]