[{"id": "1312.0086", "submitter": "Filomena Ferrucci", "authors": "Filomena Ferrucci, M-Tahar Kechadi, Pasquale Salza, Federica Sarro", "title": "A Framework for Genetic Algorithms Based on Hadoop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic Algorithms (GAs) are powerful metaheuristic techniques mostly used in\nmany real-world applications. The sequential execution of GAs requires\nconsiderable computational power both in time and resources. Nevertheless, GAs\nare naturally parallel and accessing a parallel platform such as Cloud is easy\nand cheap. Apache Hadoop is one of the common services that can be used for\nparallel applications. However, using Hadoop to develop a parallel version of\nGAs is not simple without facing its inner workings. Even though some\nsequential frameworks for GAs already exist, there is no framework supporting\nthe development of GA applications that can be executed in parallel. In this\npaper is described a framework for parallel GAs on the Hadoop platform,\nfollowing the paradigm of MapReduce. The main purpose of this framework is to\nallow the user to focus on the aspects of GA that are specific to the problem\nto be addressed, being sure that this task is going to be correctly executed on\nthe Cloud with a good performance. The framework has been also exploited to\ndevelop an application for Feature Subset Selection problem. A preliminary\nanalysis of the performance of the developed GA application has been performed\nusing three datasets and shown very promising performance.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2013 10:41:29 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2013 23:01:10 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Ferrucci", "Filomena", ""], ["Kechadi", "M-Tahar", ""], ["Salza", "Pasquale", ""], ["Sarro", "Federica", ""]]}, {"id": "1312.1423", "submitter": "Muhammad Marwan  Muhammad Fuad", "authors": "Muhammad Marwan Muhammad Fuad", "title": "ABC-SG: A New Artificial Bee Colony Algorithm-Based Distance of\n  Sequential Data Using Sigma Grams", "comments": "The Tenth Australasian Data Mining Conference - AusDM 2012, Sydney,\n  Australia, 5-7 December, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of similarity search is one of the main problems in computer\nscience. This problem has many applications in text-retrieval, web search,\ncomputational biology, bioinformatics and others. Similarity between two data\nobjects can be depicted using a similarity measure or a distance metric. There\nare numerous distance metrics in the literature, some are used for a particular\ndata type, and others are more general. In this paper we present a new distance\nmetric for sequential data which is based on the sum of n-grams. The novelty of\nour distance is that these n-grams are weighted using artificial bee colony; a\nrecent optimization algorithm based on the collective intelligence of a swarm\nof bees on their search for nectar. This algorithm has been used in optimizing\na large number of numerical problems. We validate the new distance\nexperimentally.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2013 03:19:51 GMT"}], "update_date": "2013-12-06", "authors_parsed": [["Fuad", "Muhammad Marwan Muhammad", ""]]}, {"id": "1312.1752", "submitter": "Muhammad Marwan Muhammad Fuad", "authors": "Muhammad Marwan Muhammad Fuad", "title": "Particle Swarm Optimization of Information-Content Weighting of Symbolic\n  Aggregate Approximation", "comments": "The 8th International Conference on Advanced Data Mining and\n  Applications (ADMA 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bio-inspired optimization algorithms have been gaining more popularity\nrecently. One of the most important of these algorithms is particle swarm\noptimization (PSO). PSO is based on the collective intelligence of a swam of\nparticles. Each particle explores a part of the search space looking for the\noptimal position and adjusts its position according to two factors; the first\nis its own experience and the second is the collective experience of the whole\nswarm. PSO has been successfully used to solve many optimization problems. In\nthis work we use PSO to improve the performance of a well-known representation\nmethod of time series data which is the symbolic aggregate approximation (SAX).\nAs with other time series representation methods, SAX results in loss of\ninformation when applied to represent time series. In this paper we use PSO to\npropose a new minimum distance WMD for SAX to remedy this problem. Unlike the\noriginal minimum distance, the new distance sets different weights to different\nsegments of the time series according to their information content. This\nweighted minimum distance enhances the performance of SAX as we show through\nexperiments using different time series datasets.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 02:22:59 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Fuad", "Muhammad Marwan Muhammad", ""]]}, {"id": "1312.1760", "submitter": "Muhammad Marwan Muhammad Fuad", "authors": "Muhammad Marwan Muhammad Fuad", "title": "Towards Normalizing the Edit Distance Using a Genetic Algorithms Based\n  Scheme", "comments": "The 8th International Conference on Advanced Data Mining and\n  Applications (ADMA 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The normalized edit distance is one of the distances derived from the edit\ndistance. It is useful in some applications because it takes into account the\nlengths of the two strings compared. The normalized edit distance is not\ndefined in terms of edit operations but rather in terms of the edit path. In\nthis paper we propose a new derivative of the edit distance that also takes\ninto consideration the lengths of the two strings, but the new distance is\nrelated directly to the edit distance. The particularity of the new distance is\nthat it uses the genetic algorithms to set the values of the parameters it\nuses. We conduct experiments to test the new distance and we obtain promising\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 02:50:42 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Fuad", "Muhammad Marwan Muhammad", ""]]}, {"id": "1312.1858", "submitter": "Dominic Wilson", "authors": "Dominic Wilson and Devinder Kaur", "title": "How Santa Fe Ants Evolve", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Santa Fe Ant model problem has been extensively used to investigate, test\nand evaluate Evolutionary Computing systems and methods over the past two\ndecades. There is however no literature on its program structures that are\nsystematically used for fitness improvement, the geometries of those structures\nand their dynamics during optimization. This paper analyzes the Santa Fe Ant\nProblem using a new phenotypic schema and landscape analysis based on executed\ninstruction sequences. For the first time we detail systematic structural\nfeatures that give high fitness and the evolutionary dynamics of such\nstructures. The new schema avoids variances due to introns. We develop a\nphenotypic variation method that tests the new understanding of the landscape.\nWe also develop a modified function set that tests newly identified\nsynchronization constraints. We obtain favorable computational efforts compared\nto those in the literature, on testing the new variation and function set on\nboth the Santa Fe Trail, and the more computationally demanding Los Altos\nTrail. Our findings suggest that for the Santa Fe Ant problem, a perspective of\nprogram assembly from repetition of highly fit responses to trail conditions\nleads to better analysis and performance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 13:37:37 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2014 20:23:47 GMT"}], "update_date": "2014-02-10", "authors_parsed": [["Wilson", "Dominic", ""], ["Kaur", "Devinder", ""]]}, {"id": "1312.1909", "submitter": "Qi Wang", "authors": "Qi Wang and Joseph JaJa", "title": "From Maxout to Channel-Out: Encoding Information on Sparse Pathways", "comments": "10 pages including the appendix, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by an important insight from neural science, we propose a new\nframework for understanding the success of the recently proposed \"maxout\"\nnetworks. The framework is based on encoding information on sparse pathways and\nrecognizing the correct pathway at inference time. Elaborating further on this\ninsight, we propose a novel deep network architecture, called \"channel-out\"\nnetwork, which takes a much better advantage of sparse pathway encoding. In\nchannel-out networks, pathways are not only formed a posteriori, but they are\nalso actively selected according to the inference outputs from the lower\nlayers. From a mathematical perspective, channel-out networks can represent a\nwider class of piece-wise continuous functions, thereby endowing the network\nwith more expressive power than that of maxout networks. We test our\nchannel-out networks on several well-known image classification benchmarks,\nsetting new state-of-the-art performance on CIFAR-100 and STL-10, which\nrepresent some of the \"harder\" image classification benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 17:56:11 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Wang", "Qi", ""], ["JaJa", "Joseph", ""]]}, {"id": "1312.2137", "submitter": "Dimitri Palaz", "authors": "Dimitri Palaz, Ronan Collobert, Mathew Magimai.-Doss", "title": "End-to-end Phoneme Sequence Recognition using Convolutional Neural\n  Networks", "comments": "NIPS Deep Learning Workshop, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most phoneme recognition state-of-the-art systems rely on a classical neural\nnetwork classifiers, fed with highly tuned features, such as MFCC or PLP\nfeatures. Recent advances in ``deep learning'' approaches questioned such\nsystems, but while some attempts were made with simpler features such as\nspectrograms, state-of-the-art systems still rely on MFCCs. This might be\nviewed as a kind of failure from deep learning approaches, which are often\nclaimed to have the ability to train with raw signals, alleviating the need of\nhand-crafted features. In this paper, we investigate a convolutional neural\nnetwork approach for raw speech signals. While convolutional architectures got\ntremendous success in computer vision or text processing, they seem to have\nbeen let down in the past recent years in the speech processing field. We show\nthat it is possible to learn an end-to-end phoneme sequence classifier system\ndirectly from raw signal, with similar performance on the TIMIT and WSJ\ndatasets than existing systems based on MFCC, questioning the need of complex\nhand-crafted features on large datasets.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2013 19:55:02 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Palaz", "Dimitri", ""], ["Collobert", "Ronan", ""], ["-Doss", "Mathew Magimai.", ""]]}, {"id": "1312.2366", "submitter": "Ramachandra Rao Kurada Mr.", "authors": "Ramachandra Rao Kurada, Dr. K Karteeka Pavan, Dr. AV Dattareya Rao", "title": "A preliminary survey on optimized multiobjective metaheuristic methods\n  for data clustering using evolutionary approaches", "comments": "21 Pages", "journal-ref": "International Journal of Computer Science & Information Technology\n  (IJCSIT) Vol 5,No 5, Oct 2013, ISSN:0975-3826", "doi": "10.5121/ijcsit.2013.5504", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present survey provides the state-of-the-art of research, copiously\ndevoted to Evolutionary Approach (EAs) for clustering exemplified with a\ndiversity of evolutionary computations. The Survey provides a nomenclature that\nhighlights some aspects that are very important in the context of evolutionary\ndata clustering. The paper missions the clustering trade-offs branched out with\nwide-ranging Multi Objective Evolutionary Approaches (MOEAs) methods. Finally,\nthis study addresses the potential challenges of MOEA design and data\nclustering, along with conclusions and recommendations for novice and\nresearchers by positioning most promising paths of future research. MOEAs have\nsubstantial success across a variety of MOP applications, from pedagogical\nmultifunction optimization to real-world engineering design. The survey paper\nnoticeably organizes the developments witnessed in the past three decades for\nEAs based metaheuristics to solve multiobjective optimization problems (MOP)\nand to derive significant progression in ruling high quality elucidations in a\nsingle run. Data clustering is an exigent task, whose intricacy is caused by a\nlack of unique and precise definition of a cluster. The discrete optimization\nproblem uses the cluster space to derive a solution for Multiobjective data\nclustering. Discovery of a majority or all of the clusters (of illogical\nshapes) present in the data is a long-standing goal of unsupervised predictive\nlearning problems or exploratory pattern analysis.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2013 10:23:49 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Kurada", "Ramachandra Rao", ""], ["Pavan", "Dr. K Karteeka", ""], ["Rao", "Dr. AV Dattareya", ""]]}, {"id": "1312.2368", "submitter": "Jun He", "authors": "Jun He and Feidun He and Xin Yao", "title": "A Unified Markov Chain Approach to Analysing Randomised Search\n  Heuristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convergence, convergence rate and expected hitting time play fundamental\nroles in the analysis of randomised search heuristics. This paper presents a\nunified Markov chain approach to studying them. Using the approach, the\nsufficient and necessary conditions of convergence in distribution are\nestablished. Then the average convergence rate is introduced to randomised\nsearch heuristics and its lower and upper bounds are derived. Finally, novel\naverage drift analysis and backward drift analysis are proposed for bounding\nthe expected hitting time. A computational study is also conducted to\ninvestigate the convergence, convergence rate and expected hitting time. The\ntheoretical study belongs to a prior and general study while the computational\nstudy belongs to a posterior and case study.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2013 10:26:25 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["He", "Jun", ""], ["He", "Feidun", ""], ["Yao", "Xin", ""]]}, {"id": "1312.2853", "submitter": "Chanabasayya Vastrad M", "authors": "Doreswamy and Chanabasayya .M. Vastrad", "title": "Performance Analysis Of Neural Network Models For Oxazolines And\n  Oxazoles Derivatives Descriptor Dataset", "comments": null, "journal-ref": "published International Journal of Information Sciences and\n  Techniques (IJIST) Vol.3, No.6, November 2013", "doi": "10.5121/ijist.2013.3601", "report-no": null, "categories": "cs.CE cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Neural networks have been used successfully to a broad range of areas such as\nbusiness, data mining, drug discovery and biology. In medicine, neural networks\nhave been applied widely in medical diagnosis, detection and evaluation of new\ndrugs and treatment cost estimation. In addition, neural networks have begin\npractice in data mining strategies for the aim of prediction, knowledge\ndiscovery. This paper will present the application of neural networks for the\nprediction and analysis of antitubercular activity of Oxazolines and Oxazoles\nderivatives. This study presents techniques based on the development of Single\nhidden layer neural network (SHLFFNN), Gradient Descent Back propagation neural\nnetwork (GDBPNN), Gradient Descent Back propagation with momentum neural\nnetwork (GDBPMNN), Back propagation with Weight decay neural network (BPWDNN)\nand Quantile regression neural network (QRNN) of artificial neural network\n(ANN) models Here, we comparatively evaluate the performance of five neural\nnetwork techniques. The evaluation of the efficiency of each model by ways of\nbenchmark experiments is an accepted application. Cross-validation and\nresampling techniques are commonly used to derive point estimates of the\nperformances which are compared to identify methods with good properties.\nPredictive accuracy was evaluated using the root mean squared error (RMSE),\nCoefficient determination(???), mean absolute error(MAE), mean percentage\nerror(MPE) and relative square error(RSE). We found that all five neural\nnetwork models were able to produce feasible models. QRNN model is outperforms\nwith all statistical tests amongst other four models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 16:15:48 GMT"}], "update_date": "2013-12-13", "authors_parsed": [["Doreswamy", "", ""], ["Vastrad", "Chanabasayya . M.", ""]]}, {"id": "1312.2877", "submitter": "Mohammad H. Alomari", "authors": "Mohammad H. Alomari, Aya Samaha, Khaled AlKamha", "title": "Automated Classification of L/R Hand Movement EEG Signals using Advanced\n  Feature Extraction and Machine Learning", "comments": "6 pages, 4 figures", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications (ijacsa) 07/2013; 4(6):207-212", "doi": "10.14569/IJACSA.2013.040628", "report-no": null, "categories": "cs.NE cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an automated computer platform for the purpose of\nclassifying Electroencephalography (EEG) signals associated with left and right\nhand movements using a hybrid system that uses advanced feature extraction\ntechniques and machine learning algorithms. It is known that EEG represents the\nbrain activity by the electrical voltage fluctuations along the scalp, and\nBrain-Computer Interface (BCI) is a device that enables the use of the brain\nneural activity to communicate with others or to control machines, artificial\nlimbs, or robots without direct physical movements. In our research work, we\naspired to find the best feature extraction method that enables the\ndifferentiation between left and right executed fist movements through various\nclassification algorithms. The EEG dataset used in this research was created\nand contributed to PhysioNet by the developers of the BCI2000 instrumentation\nsystem. Data was preprocessed using the EEGLAB MATLAB toolbox and artifacts\nremoval was done using AAR. Data was epoched on the basis of Event-Related (De)\nSynchronization (ERD/ERS) and movement-related cortical potentials (MRCP)\nfeatures. Mu/beta rhythms were isolated for the ERD/ERS analysis and delta\nrhythms were isolated for the MRCP analysis. The Independent Component Analysis\n(ICA) spatial filter was applied on related channels for noise reduction and\nisolation of both artifactually and neutrally generated EEG sources. The final\nfeature vector included the ERD, ERS, and MRCP features in addition to the\nmean, power and energy of the activations of the resulting independent\ncomponents of the epoched feature datasets. The datasets were inputted into two\nmachine-learning algorithms: Neural Networks (NNs) and Support Vector Machines\n(SVMs). Intensive experiments were carried out and optimum classification\nperformances of 89.8 and 97.1 were obtained using NN and SVM, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 17:04:18 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Alomari", "Mohammad H.", ""], ["Samaha", "Aya", ""], ["AlKamha", "Khaled", ""]]}, {"id": "1312.4044", "submitter": "Mohammed El-Dosuky", "authors": "M. A. El-Dosuky", "title": "CACO : Competitive Ant Colony Optimization, A Nature-Inspired\n  Metaheuristic For Large-Scale Global Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale problems are nonlinear problems that need metaheuristics, or\nglobal optimization algorithms. This paper reviews nature-inspired\nmetaheuristics, then it introduces a framework named Competitive Ant Colony\nOptimization inspired by the chemical communications among insects. Then a case\nstudy is presented to investigate the proposed framework for large-scale global\noptimization.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2013 13:33:48 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["El-Dosuky", "M. A.", ""]]}, {"id": "1312.4078", "submitter": "Ahmad Mozaffari", "authors": "Ahmad Mozaffari and Alireza Fathi", "title": "A natural-inspired optimization machine based on the annual migration of\n  salmons in nature", "comments": "12 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bio inspiration is a branch of artificial simulation science that shows\npervasive contributions to variety of engineering fields such as automate\npattern recognition, systematic fault detection and applied optimization. In\nthis paper, a new metaheuristic optimizing algorithm that is the simulation of\nThe Great Salmon Run(TGSR) is developed. The obtained results imply on the\nacceptable performance of implemented method in optimization of complex non\nconvex, multi dimensional and multi-modal problems. To prove the superiority of\nTGSR in both robustness and quality, it is also compared with most of the well\nknown proposed optimizing techniques such as Simulated Annealing (SA), Parallel\nMigrating Genetic Algorithm (PMGA), Differential Evolutionary Algorithm (DEA),\nParticle Swarm Optimization (PSO), Bee Algorithm (BA), Artificial Bee Colony\n(ABC), Firefly Algorithm (FA) and Cuckoo Search (CS). The obtained results\nconfirm the acceptable performance of the proposed method in both robustness\nand quality for different bench-mark optimizing problems and also prove the\nauthors claim.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2013 19:05:11 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Mozaffari", "Ahmad", ""], ["Fathi", "Alireza", ""]]}, {"id": "1312.4132", "submitter": "Ahmad Mozaffari", "authors": "Ahmad Mozaffari and Alireza Fathi", "title": "An introduction to synchronous self-learning Pareto strategy", "comments": "17 pages, 7 figure, 3 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In last decades optimization and control of complex systems that possessed\nvarious conflicted objectives simultaneously attracted an incremental interest\nof scientists. This is because of the vast applications of these systems in\nvarious fields of real life engineering phenomena that are generally multi\nmodal, non convex and multi criterion. Hence, many researchers utilized\nversatile intelligent models such as Pareto based techniques, game theory\n(cooperative and non cooperative games), neuro evolutionary systems, fuzzy\nlogic and advanced neural networks for handling these types of problems. In\nthis paper a novel method called Synchronous Self Learning Pareto Strategy\nAlgorithm (SSLPSA) is presented which utilizes Evolutionary Computing (EC),\nSwarm Intelligence (SI) techniques and adaptive Classical Self Organizing Map\n(CSOM) simultaneously incorporating with a data shuffling behavior.\nEvolutionary Algorithms (EA) which attempt to simulate the phenomenon of\nnatural evolution are powerful numerical optimization algorithms that reach an\napproximate global maximum of a complex multi variable function over a wide\nsearch space and swarm base technique can improved the intensity and the\nrobustness in EA. CSOM is a neural network capable of learning and can improve\nthe quality of obtained optimal Pareto front. To prove the efficient\nperformance of proposed algorithm, authors utilized some well known benchmark\ntest functions. Obtained results indicate that the cited method is best suit in\nthe case of vector optimization.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2013 10:21:05 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Mozaffari", "Ahmad", ""], ["Fathi", "Alireza", ""]]}, {"id": "1312.4149", "submitter": "Alaa Sagheer", "authors": "Alaa Sagheer and Mohammed Zidan", "title": "Autonomous Quantum Perceptron Neural Network", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, with the rapid development of technology, there are a lot of\napplications require to achieve low-cost learning. However the computational\npower of classical artificial neural networks, they are not capable to provide\nlow-cost learning. In contrast, quantum neural networks may be representing a\ngood computational alternate to classical neural network approaches, based on\nthe computational power of quantum bit (qubit) over the classical bit. In this\npaper we present a new computational approach to the quantum perceptron neural\nnetwork can achieve learning in low-cost computation. The proposed approach has\nonly one neuron can construct self-adaptive activation operators capable to\naccomplish the learning process in a limited number of iterations and, thereby,\nreduce the overall computational cost. The proposed approach is capable to\nconstruct its own set of activation operators to be applied widely in both\nquantum and classical applications to overcome the linearity limitation of\nclassical perceptron. The computational power of the proposed approach is\nillustrated via solving variety of problems where promising and comparable\nresults are given.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2013 13:57:16 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Sagheer", "Alaa", ""], ["Zidan", "Mohammed", ""]]}, {"id": "1312.4384", "submitter": "Eren Golge", "authors": "Eren Golge and Pinar Duygulu", "title": "Rectifying Self Organizing Maps for Automatic Concept Learning from Web\n  Images", "comments": "present CVPR2014 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We attack the problem of learning concepts automatically from noisy web image\nsearch results. Going beyond low level attributes, such as colour and texture,\nwe explore weakly-labelled datasets for the learning of higher level concepts,\nsuch as scene categories. The idea is based on discovering common\ncharacteristics shared among subsets of images by posing a method that is able\nto organise the data while eliminating irrelevant instances. We propose a novel\nclustering and outlier detection method, namely Rectifying Self Organizing Maps\n(RSOM). Given an image collection returned for a concept query, RSOM provides\nclusters pruned from outliers. Each cluster is used to train a model\nrepresenting a different characteristics of the concept. The proposed method\noutperforms the state-of-the-art studies on the task of learning low-level\nconcepts, and it is competitive in learning higher level concepts as well. It\nis capable to work at large scale with no supervision through exploiting the\navailable sources.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 14:51:00 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Golge", "Eren", ""], ["Duygulu", "Pinar", ""]]}, {"id": "1312.4400", "submitter": "Min Lin", "authors": "Min Lin, Qiang Chen, Shuicheng Yan", "title": "Network In Network", "comments": "10 pages, 4 figures, for iclr2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel deep network structure called \"Network In Network\" (NIN)\nto enhance model discriminability for local patches within the receptive field.\nThe conventional convolutional layer uses linear filters followed by a\nnonlinear activation function to scan the input. Instead, we build micro neural\nnetworks with more complex structures to abstract the data within the receptive\nfield. We instantiate the micro neural network with a multilayer perceptron,\nwhich is a potent function approximator. The feature maps are obtained by\nsliding the micro networks over the input in a similar manner as CNN; they are\nthen fed into the next layer. Deep NIN can be implemented by stacking mutiple\nof the above described structure. With enhanced local modeling via the micro\nnetwork, we are able to utilize global average pooling over feature maps in the\nclassification layer, which is easier to interpret and less prone to\noverfitting than traditional fully connected layers. We demonstrated the\nstate-of-the-art classification performances with NIN on CIFAR-10 and\nCIFAR-100, and reasonable performances on SVHN and MNIST datasets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 15:34:13 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2013 09:30:27 GMT"}, {"version": "v3", "created": "Tue, 4 Mar 2014 05:15:42 GMT"}], "update_date": "2014-03-05", "authors_parsed": [["Lin", "Min", ""], ["Chen", "Qiang", ""], ["Yan", "Shuicheng", ""]]}, {"id": "1312.4569", "submitter": "Vu Pham", "authors": "Vu Pham, Th\\'eodore Bluche, Christopher Kermorvant, J\\'er\\^ome\n  Louradour", "title": "Dropout improves Recurrent Neural Networks for Handwriting Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) with Long Short-Term memory cells currently\nhold the best known results in unconstrained handwriting recognition. We show\nthat their performance can be greatly improved using dropout - a recently\nproposed regularization method for deep architectures. While previous works\nshowed that dropout gave superior performance in the context of convolutional\nnetworks, it had never been applied to RNNs. In our approach, dropout is\ncarefully used in the network so that it does not affect the recurrent\nconnections, hence the power of RNNs in modeling sequence is preserved.\nExtensive experiments on a broad range of handwritten databases confirm the\neffectiveness of dropout on deep architectures even when the network mainly\nconsists of recurrent and shared connections.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2013 10:45:48 GMT"}, {"version": "v2", "created": "Mon, 10 Mar 2014 15:34:55 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Pham", "Vu", ""], ["Bluche", "Th\u00e9odore", ""], ["Kermorvant", "Christopher", ""], ["Louradour", "J\u00e9r\u00f4me", ""]]}, {"id": "1312.5045", "submitter": "Anupriya Gogna", "authors": "Anupriya Gogna, Akash Tayal", "title": "Comparative analysis of evolutionary algorithms for image enhancement", "comments": null, "journal-ref": "International Journal of Metaheuristics Volume 2 Issue 1, July\n  2012 Pages 80-100", "doi": "10.1504/IJMHEUR.2012.048219", "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms are metaheuristic techniques that derive inspiration\nfrom the natural process of evolution. They can efficiently solve (generate\nacceptable quality of solution in reasonable time) complex optimization\n(NP-Hard) problems. In this paper, automatic image enhancement is considered as\nan optimization problem and three evolutionary algorithms (Genetic Algorithm,\nDifferential Evolution and Self Organizing Migration Algorithm) are employed to\nsearch for an optimum solution. They are used to find an optimum parameter set\nfor an image enhancement transfer function. The aim is to maximize a fitness\ncriterion which is a measure of image contrast and the visibility of details in\nthe enhanced image. The enhancement results obtained using all three\nevolutionary algorithms are compared amongst themselves and also with the\noutput of histogram equalization method.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2013 05:33:27 GMT"}], "update_date": "2013-12-20", "authors_parsed": [["Gogna", "Anupriya", ""], ["Tayal", "Akash", ""]]}, {"id": "1312.5242", "submitter": "Alexey Dosovitskiy", "authors": "Alexey Dosovitskiy, Jost Tobias Springenberg and Thomas Brox", "title": "Unsupervised feature learning by augmenting single images", "comments": "ICLR 2014 workshop track submission (7 pages, 4 figures, 1 table)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When deep learning is applied to visual object recognition, data augmentation\nis often used to generate additional training data without extra labeling cost.\nIt helps to reduce overfitting and increase the performance of the algorithm.\nIn this paper we investigate if it is possible to use data augmentation as the\nmain component of an unsupervised feature learning architecture. To that end we\nsample a set of random image patches and declare each of them to be a separate\nsingle-image surrogate class. We then extend these trivial one-element classes\nby applying a variety of transformations to the initial 'seed' patches. Finally\nwe train a convolutional neural network to discriminate between these surrogate\nclasses. The feature representation learned by the network can then be used in\nvarious vision tasks. We find that this simple feature learning algorithm is\nsurprisingly successful, achieving competitive classification results on\nseveral popular vision datasets (STL-10, CIFAR-10, Caltech-101).\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2013 17:44:17 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2014 18:02:09 GMT"}, {"version": "v3", "created": "Sun, 16 Feb 2014 13:07:23 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Dosovitskiy", "Alexey", ""], ["Springenberg", "Jost Tobias", ""], ["Brox", "Thomas", ""]]}, {"id": "1312.5355", "submitter": "Phillip Verbancsics", "authors": "Phillip Verbancsics and Josh Harguess", "title": "Generative NeuroEvolution for Deep Learning", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  An important goal for the machine learning (ML) community is to create\napproaches that can learn solutions with human-level capability. One domain\nwhere humans have held a significant advantage is visual processing. A\nsignificant approach to addressing this gap has been machine learning\napproaches that are inspired from the natural systems, such as artificial\nneural networks (ANNs), evolutionary computation (EC), and generative and\ndevelopmental systems (GDS). Research into deep learning has demonstrated that\nsuch architectures can achieve performance competitive with humans on some\nvisual tasks; however, these systems have been primarily trained through\nsupervised and unsupervised learning algorithms. Alternatively, research is\nshowing that evolution may have a significant role in the development of visual\nsystems. Thus this paper investigates the role neuro-evolution (NE) can take in\ndeep learning. In particular, the Hypercube-based NeuroEvolution of Augmenting\nTopologies is a NE approach that can effectively learn large neural structures\nby training an indirect encoding that compresses the ANN weight pattern as a\nfunction of geometry. The results show that HyperNEAT struggles with performing\nimage classification by itself, but can be effective in training a feature\nextractor that other ML approaches can learn from. Thus NeuroEvolution combined\nwith other ML methods provides an intriguing area of research that can\nreplicate the processes in nature.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2013 22:14:31 GMT"}], "update_date": "2013-12-20", "authors_parsed": [["Verbancsics", "Phillip", ""], ["Harguess", "Josh", ""]]}, {"id": "1312.5394", "submitter": "Michael S. Gashler Ph.D.", "authors": "Michael S. Gashler, Michael R. Smith, Richard Morris, Tony Martinez", "title": "Missing Value Imputation With Unsupervised Backpropagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many data mining and data analysis techniques operate on dense matrices or\ncomplete tables of data. Real-world data sets, however, often contain unknown\nvalues. Even many classification algorithms that are designed to operate with\nmissing values still exhibit deteriorated accuracy. One approach to handling\nmissing values is to fill in (impute) the missing values. In this paper, we\npresent a technique for unsupervised learning called Unsupervised\nBackpropagation (UBP), which trains a multi-layer perceptron to fit to the\nmanifold sampled by a set of observed point-vectors. We evaluate UBP with the\ntask of imputing missing values in datasets, and show that UBP is able to\npredict missing values with significantly lower sum-squared error than other\ncollaborative filtering and imputation techniques. We also demonstrate with 24\ndatasets and 9 supervised learning algorithms that classification accuracy is\nusually higher when randomly-withheld values are imputed using UBP, rather than\nwith other methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2013 02:38:40 GMT"}], "update_date": "2013-12-20", "authors_parsed": [["Gashler", "Michael S.", ""], ["Smith", "Michael R.", ""], ["Morris", "Richard", ""], ["Martinez", "Tony", ""]]}, {"id": "1312.5548", "submitter": "Juergen Schmidhuber", "authors": "J\\\"urgen Schmidhuber", "title": "My First Deep Learning System of 1991 + Deep Learning Timeline 1962-2013", "comments": "11 pages. As a machine learning researcher I am obsessed with proper\n  credit assignment. This draft is the result of an experiment in rapid massive\n  open online peer review. Since 20 September 2013, subsequent revisions\n  published under http://www.deeplearning.me have absorbed many suggestions for\n  improvements by experts", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning has attracted significant attention in recent years. Here I\npresent a brief overview of my first Deep Learner of 1991, and its historic\ncontext, with a timeline of Deep Learning highlights.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2013 13:45:45 GMT"}], "update_date": "2013-12-20", "authors_parsed": [["Schmidhuber", "J\u00fcrgen", ""]]}, {"id": "1312.5673", "submitter": "Xin-She Yang", "authors": "Xin-She Yang", "title": "Flower Pollination Algorithm for Global Optimization", "comments": "10 pages", "journal-ref": "Unconventional Computation and Natural Computation 2012, Lecture\n  Notes in Computer Science, Vol. 7445, pp. 240-249 (2012)", "doi": "10.1007/978-3-642-32894-7_27", "report-no": null, "categories": "math.OC cs.NE nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flower pollination is an intriguing process in the natural world. Its\nevolutionary characteristics can be used to design new optimization algorithms.\nIn this paper, we propose a new algorithm, namely, flower pollination\nalgorithm, inspired by the pollination process of flowers. We first use ten\ntest functions to validate the new algorithm, and compare its performance with\ngenetic algorithms and particle swarm optimization. Our simulation results show\nthe flower algorithm is more efficient than both GA and PSO. We also use the\nflower algorithm to solve a nonlinear design benchmark, which shows the\nconvergence rate is almost exponential.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2013 18:02:39 GMT"}], "update_date": "2013-12-20", "authors_parsed": [["Yang", "Xin-She", ""]]}, {"id": "1312.5783", "submitter": "Yunlong He `", "authors": "Yunlong He, Koray Kavukcuoglu, Yun Wang, Arthur Szlam, Yanjun Qi", "title": "Unsupervised Feature Learning by Deep Sparse Coding", "comments": "9 pages, submitted to ICLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new unsupervised feature learning framework,\nnamely Deep Sparse Coding (DeepSC), that extends sparse coding to a multi-layer\narchitecture for visual object recognition tasks. The main innovation of the\nframework is that it connects the sparse-encoders from different layers by a\nsparse-to-dense module. The sparse-to-dense module is a composition of a local\nspatial pooling step and a low-dimensional embedding process, which takes\nadvantage of the spatial smoothness information in the image. As a result, the\nnew method is able to learn several levels of sparse representation of the\nimage which capture features at a variety of abstraction levels and\nsimultaneously preserve the spatial smoothness between the neighboring image\npatches. Combining the feature representations from multiple layers, DeepSC\nachieves the state-of-the-art performance on multiple object recognition tasks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 00:21:36 GMT"}], "update_date": "2013-12-23", "authors_parsed": [["He", "Yunlong", ""], ["Kavukcuoglu", "Koray", ""], ["Wang", "Yun", ""], ["Szlam", "Arthur", ""], ["Qi", "Yanjun", ""]]}, {"id": "1312.5813", "submitter": "Jun Li", "authors": "Jun Li, Wei Luo, Jian Yang, Xiaotong Yuan", "title": "Unsupervised Pretraining Encourages Moderate-Sparseness", "comments": "6 pages, 2 figures, (to appear) ICML-Workshop on Unsupervised\n  Learning from Bioacoustic Big Data (uLearnBio) 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  It is well known that direct training of deep neural networks will generally\nlead to poor results. A major progress in recent years is the invention of\nvarious pretraining methods to initialize network parameters and it was shown\nthat such methods lead to good prediction performance. However, the reason for\nthe success of pretraining has not been fully understood, although it was\nargued that regularization and better optimization play certain roles. This\npaper provides another explanation for the effectiveness of pretraining, where\nwe show pretraining leads to a sparseness of hidden unit activation in the\nresulting neural networks. The main reason is that the pretraining models can\nbe interpreted as an adaptive sparse coding. Compared to deep neural network\nwith sigmoid function, our experimental results on MNIST and Birdsong further\nsupport this sparseness observation.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 05:22:20 GMT"}, {"version": "v2", "created": "Mon, 9 Jun 2014 08:39:37 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Li", "Jun", ""], ["Luo", "Wei", ""], ["Yang", "Jian", ""], ["Yuan", "Xiaotong", ""]]}, {"id": "1312.5814", "submitter": "Chittineni Suneetha", "authors": "suneetha chittineni, Raveendra Babu Bhogapathi", "title": "Optimal parameter selection for unsupervised neural network using\n  genetic algorithm", "comments": "15 pages,4 figures,4 tables, International Journal of Computer\n  Science, Engineering and Applications (IJCSEA) Vol.3, No.5, October 2013", "journal-ref": null, "doi": "10.5121/ijcsea.2013.3502", "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  K-means Fast Learning Artificial Neural Network (K-FLANN) is an unsupervised\nneural network requires two parameters: tolerance and vigilance. Best\nClustering results are feasible only by finest parameters specified to the\nneural network. Selecting optimal values for these parameters is a major\nproblem. To solve this issue, Genetic Algorithm (GA) is used to determine\noptimal parameters of K-FLANN for finding groups in multidimensional data.\nK-FLANN is a simple topological network, in which output nodes grows\ndynamically during the clustering process on receiving input patterns. Original\nK-FLANN is enhanced to select winner unit out of the matched nodes so that\nstable clusters are formed with in a less number of epochs. The experimental\nresults show that the GA is efficient in finding optimal values of parameters\nfrom the large search space and is tested using artificial and synthetic data\nsets.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 05:39:51 GMT"}], "update_date": "2013-12-23", "authors_parsed": [["chittineni", "suneetha", ""], ["Bhogapathi", "Raveendra Babu", ""]]}, {"id": "1312.5845", "submitter": "Takashi Shinozaki", "authors": "Takashi Shinozaki and Yasushi Naruse", "title": "Competitive Learning with Feedforward Supervisory Signal for Pre-trained\n  Multilayered Networks", "comments": "This paper has been withdrawn by the author since the review process\n  for the conference to which it was applied ended", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel learning method for multilayered neural networks which\nuses feedforward supervisory signal and associates classification of a new\ninput with that of pre-trained input. The proposed method effectively uses rich\ninput information in the earlier layer for robust leaning and revising internal\nrepresentation in a multilayer neural network.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 08:24:48 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2013 08:59:56 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2014 11:09:07 GMT"}, {"version": "v4", "created": "Mon, 17 Feb 2014 19:11:14 GMT"}, {"version": "v5", "created": "Fri, 21 Feb 2014 02:11:46 GMT"}, {"version": "v6", "created": "Fri, 9 May 2014 00:50:33 GMT"}, {"version": "v7", "created": "Mon, 16 Feb 2015 09:37:18 GMT"}], "update_date": "2015-02-17", "authors_parsed": [["Shinozaki", "Takashi", ""], ["Naruse", "Yasushi", ""]]}, {"id": "1312.5847", "submitter": "Sergey Plis", "authors": "Sergey M. Plis and Devon R. Hjelm and Ruslan Salakhutdinov and Vince\n  D. Calhoun", "title": "Deep learning for neuroimaging: a validation study", "comments": "ICLR 2014 revisions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods have recently made notable advances in the tasks of\nclassification and representation learning. These tasks are important for brain\nimaging and neuroscience discovery, making the methods attractive for porting\nto a neuroimager's toolbox. Success of these methods is, in part, explained by\nthe flexibility of deep learning models. However, this flexibility makes the\nprocess of porting to new areas a difficult parameter optimization problem. In\nthis work we demonstrate our results (and feasible parameter ranges) in\napplication of deep learning methods to structural and functional brain imaging\ndata. We also describe a novel constraint-based approach to visualizing high\ndimensional data. We use it to analyze the effect of parameter choices on data\ntransformations. Our results show that deep learning methods are able to learn\nphysiologically important representations and detect latent relations in\nneuroimaging data.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 08:30:55 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2014 04:22:55 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2014 16:00:08 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Plis", "Sergey M.", ""], ["Hjelm", "Devon R.", ""], ["Salakhutdinov", "Ruslan", ""], ["Calhoun", "Vince D.", ""]]}, {"id": "1312.5851", "submitter": "Mikael Henaff", "authors": "Michael Mathieu, Mikael Henaff, Yann LeCun", "title": "Fast Training of Convolutional Networks through FFTs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional networks are one of the most widely employed architectures in\ncomputer vision and machine learning. In order to leverage their ability to\nlearn complex functions, large amounts of data are required for training.\nTraining a large convolutional network to produce state-of-the-art results can\ntake weeks, even when using modern GPUs. Producing labels using a trained\nnetwork can also be costly when dealing with web-scale datasets. In this work,\nwe present a simple algorithm which accelerates training and inference by a\nsignificant factor, and can yield improvements of over an order of magnitude\ncompared to existing state-of-the-art implementations. This is done by\ncomputing convolutions as pointwise products in the Fourier domain while\nreusing the same transformed feature map many times. The algorithm is\nimplemented on a GPU architecture and addresses a number of related challenges.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 08:42:21 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2014 00:28:06 GMT"}, {"version": "v3", "created": "Tue, 28 Jan 2014 01:33:21 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2014 03:20:51 GMT"}, {"version": "v5", "created": "Thu, 6 Mar 2014 23:27:18 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Mathieu", "Michael", ""], ["Henaff", "Mikael", ""], ["LeCun", "Yann", ""]]}, {"id": "1312.5853", "submitter": "Marc'Aurelio Ranzato", "authors": "Omry Yadan, Keith Adams, Yaniv Taigman, Marc'Aurelio Ranzato", "title": "Multi-GPU Training of ConvNets", "comments": "Machine Learning, Deep Learning, Convolutional Networks, Computer\n  Vision, GPU, CUDA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we evaluate different approaches to parallelize computation of\nconvolutional neural networks across several GPUs.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 08:45:07 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2013 15:50:49 GMT"}, {"version": "v3", "created": "Sat, 28 Dec 2013 08:31:12 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2014 21:35:13 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Yadan", "Omry", ""], ["Adams", "Keith", ""], ["Taigman", "Yaniv", ""], ["Ranzato", "Marc'Aurelio", ""]]}, {"id": "1312.6002", "submitter": "Mathias Berglund", "authors": "Mathias Berglund, Tapani Raiko", "title": "Stochastic Gradient Estimate Variance in Contrastive Divergence and\n  Persistent Contrastive Divergence", "comments": "ICLR2014 Workshop Track submission. Rephrased parts of text. Results\n  unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive Divergence (CD) and Persistent Contrastive Divergence (PCD) are\npopular methods for training the weights of Restricted Boltzmann Machines.\nHowever, both methods use an approximate method for sampling from the model\ndistribution. As a side effect, these approximations yield significantly\ndifferent biases and variances for stochastic gradient estimates of individual\ndata points. It is well known that CD yields a biased gradient estimate. In\nthis paper we however show empirically that CD has a lower stochastic gradient\nestimate variance than exact sampling, while the mean of subsequent PCD\nestimates has a higher variance than exact sampling. The results give one\nexplanation to the finding that CD can be used with smaller minibatches or\nhigher learning rates than PCD.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 16:13:54 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2014 11:27:22 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2014 09:47:11 GMT"}], "update_date": "2014-02-17", "authors_parsed": [["Berglund", "Mathias", ""], ["Raiko", "Tapani", ""]]}, {"id": "1312.6026", "submitter": "KyungHyun Cho", "authors": "Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho, Yoshua Bengio", "title": "How to Construct Deep Recurrent Neural Networks", "comments": "Accepted at ICLR 2014 (Conference Track). 10-page text + 3-page\n  references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore different ways to extend a recurrent neural network\n(RNN) to a \\textit{deep} RNN. We start by arguing that the concept of depth in\nan RNN is not as clear as it is in feedforward neural networks. By carefully\nanalyzing and understanding the architecture of an RNN, however, we find three\npoints of an RNN which may be made deeper; (1) input-to-hidden function, (2)\nhidden-to-hidden transition and (3) hidden-to-output function. Based on this\nobservation, we propose two novel architectures of a deep RNN which are\northogonal to an earlier attempt of stacking multiple recurrent layers to build\na deep RNN (Schmidhuber, 1992; El Hihi and Bengio, 1996). We provide an\nalternative interpretation of these deep RNNs using a novel framework based on\nneural operators. The proposed deep RNNs are empirically evaluated on the tasks\nof polyphonic music prediction and language modeling. The experimental result\nsupports our claim that the proposed deep RNNs benefit from the depth and\noutperform the conventional, shallow RNNs.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 16:39:39 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2014 18:39:22 GMT"}, {"version": "v3", "created": "Wed, 29 Jan 2014 22:56:47 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2014 18:15:46 GMT"}, {"version": "v5", "created": "Thu, 24 Apr 2014 15:17:07 GMT"}], "update_date": "2014-04-25", "authors_parsed": [["Pascanu", "Razvan", ""], ["Gulcehre", "Caglar", ""], ["Cho", "Kyunghyun", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1312.6098", "submitter": "Razvan Pascanu", "authors": "Razvan Pascanu and Guido Montufar and Yoshua Bengio", "title": "On the number of response regions of deep feed forward networks with\n  piece-wise linear activations", "comments": "17 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the complexity of deep feedforward networks with linear\npre-synaptic couplings and rectified linear activations. This is a contribution\nto the growing body of work contrasting the representational power of deep and\nshallow network architectures. In particular, we offer a framework for\ncomparing deep and shallow models that belong to the family of piecewise linear\nfunctions based on computational geometry. We look at a deep rectifier\nmulti-layer perceptron (MLP) with linear outputs units and compare it with a\nsingle layer version of the model. In the asymptotic regime, when the number of\ninputs stays constant, if the shallow model has $kn$ hidden units and $n_0$\ninputs, then the number of linear regions is $O(k^{n_0}n^{n_0})$. For a $k$\nlayer model with $n$ hidden units on each layer it is $\\Omega(\\left\\lfloor\n{n}/{n_0}\\right\\rfloor^{k-1}n^{n_0})$. The number\n$\\left\\lfloor{n}/{n_0}\\right\\rfloor^{k-1}$ grows faster than $k^{n_0}$ when $n$\ntends to infinity or when $k$ tends to infinity and $n \\geq 2n_0$.\nAdditionally, even when $k$ is small, if we restrict $n$ to be $2n_0$, we can\nshow that a deep model has considerably more linear regions that a shallow one.\nWe consider this as a first step towards understanding the complexity of these\nmodels and specifically towards providing suitable mathematical tools for\nfuture analysis.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 20:22:31 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2014 19:53:34 GMT"}, {"version": "v3", "created": "Mon, 27 Jan 2014 22:13:09 GMT"}, {"version": "v4", "created": "Mon, 10 Feb 2014 17:24:12 GMT"}, {"version": "v5", "created": "Fri, 14 Feb 2014 17:52:12 GMT"}], "update_date": "2014-02-17", "authors_parsed": [["Pascanu", "Razvan", ""], ["Montufar", "Guido", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1312.6108", "submitter": "Nan Wang", "authors": "Nan Wang, Dirk Jancke, Laurenz Wiskott", "title": "Modeling correlations in spontaneous activity of visual cortex with\n  centered Gaussian-binary deep Boltzmann machines", "comments": "9 pages, 4 figures, for openreview ICLR2014, 2nd revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spontaneous cortical activity -- the ongoing cortical activities in absence\nof intentional sensory input -- is considered to play a vital role in many\naspects of both normal brain functions and mental dysfunctions. We present a\ncentered Gaussian-binary Deep Boltzmann Machine (GDBM) for modeling the\nactivity in early cortical visual areas and relate the random sampling in GDBMs\nto the spontaneous cortical activity. After training the proposed model on\nnatural image patches, we show that the samples collected from the model's\nprobability distribution encompass similar activity patterns as found in the\nspontaneous activity. Specifically, filters having the same orientation\npreference tend to be active together during random sampling. Our work\ndemonstrates the centered GDBM is a meaningful model approach for basic\nreceptive field properties and the emergence of spontaneous activity patterns\nin early cortical visual areas. Besides, we show empirically that centered\nGDBMs do not suffer from the difficulties during training as GDBMs do and can\nbe properly trained without the layer-wise pretraining.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 20:47:28 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2014 13:46:25 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2014 16:41:30 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Wang", "Nan", ""], ["Jancke", "Dirk", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "1312.6115", "submitter": "David Reichert", "authors": "David P. Reichert, Thomas Serre", "title": "Neuronal Synchrony in Complex-Valued Deep Networks", "comments": "ICLR 2014, accepted to conference track. This version: added\n  proceedings note, minor additions", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has recently led to great successes in tasks such as image\nrecognition (e.g Krizhevsky et al., 2012). However, deep networks are still\noutmatched by the power and versatility of the brain, perhaps in part due to\nthe richer neuronal computations available to cortical circuits. The challenge\nis to identify which neuronal mechanisms are relevant, and to find suitable\nabstractions to model them. Here, we show how aspects of spike timing, long\nhypothesized to play a crucial role in cortical information processing, could\nbe incorporated into deep networks to build richer, versatile representations.\n  We introduce a neural network formulation based on complex-valued neuronal\nunits that is not only biologically meaningful but also amenable to a variety\nof deep learning frameworks. Here, units are attributed both a firing rate and\na phase, the latter indicating properties of spike timing. We show how this\nformulation qualitatively captures several aspects thought to be related to\nneuronal synchrony, including gating of information processing and dynamic\nbinding of distributed object representations. Focusing on the latter, we\ndemonstrate the potential of the approach in several simple experiments. Thus,\nneuronal synchrony could be a flexible mechanism that fulfills multiple\nfunctional roles in deep networks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 20:59:11 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2013 13:34:08 GMT"}, {"version": "v3", "created": "Mon, 30 Dec 2013 18:42:17 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2014 01:28:47 GMT"}, {"version": "v5", "created": "Sat, 22 Mar 2014 20:25:27 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["Reichert", "David P.", ""], ["Serre", "Thomas", ""]]}, {"id": "1312.6116", "submitter": "Jost Tobias Springenberg", "authors": "Jost Tobias Springenberg, Martin Riedmiller", "title": "Improving Deep Neural Networks with Probabilistic Maxout Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic variant of the recently introduced maxout unit.\nThe success of deep neural networks utilizing maxout can partly be attributed\nto favorable performance under dropout, when compared to rectified linear\nunits. It however also depends on the fact that each maxout unit performs a\npooling operation over a group of linear transformations and is thus partially\ninvariant to changes in its input. Starting from this observation we ask the\nquestion: Can the desirable properties of maxout units be preserved while\nimproving their invariance properties ? We argue that our probabilistic maxout\n(probout) units successfully achieve this balance. We quantitatively verify\nthis claim and report classification performance matching or exceeding the\ncurrent state of the art on three challenging image classification benchmarks\n(CIFAR-10, CIFAR-100 and SVHN).\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 20:59:15 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2014 11:13:48 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Springenberg", "Jost Tobias", ""], ["Riedmiller", "Martin", ""]]}, {"id": "1312.6120", "submitter": "Andrew Saxe", "authors": "Andrew M. Saxe, James L. McClelland, Surya Ganguli", "title": "Exact solutions to the nonlinear dynamics of learning in deep linear\n  neural networks", "comments": "Submission to ICLR2014. Revised based on reviewer feedback", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn cs.CV cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the widespread practical success of deep learning methods, our\ntheoretical understanding of the dynamics of learning in deep neural networks\nremains quite sparse. We attempt to bridge the gap between the theory and\npractice of deep learning by systematically analyzing learning dynamics for the\nrestricted case of deep linear neural networks. Despite the linearity of their\ninput-output map, such networks have nonlinear gradient descent dynamics on\nweights that change with the addition of each new hidden layer. We show that\ndeep linear networks exhibit nonlinear learning phenomena similar to those seen\nin simulations of nonlinear networks, including long plateaus followed by rapid\ntransitions to lower error solutions, and faster convergence from greedy\nunsupervised pretraining initial conditions than from random initial\nconditions. We provide an analytical description of these phenomena by finding\nnew exact solutions to the nonlinear dynamics of deep learning. Our theoretical\nanalysis also reveals the surprising finding that as the depth of a network\napproaches infinity, learning speed can nevertheless remain finite: for a\nspecial class of initial conditions on the weights, very deep networks incur\nonly a finite, depth independent, delay in learning speed relative to shallow\nnetworks. We show that, under certain conditions on the training data,\nunsupervised pretraining can find this special class of initial conditions,\nwhile scaled random Gaussian initializations cannot. We further exhibit a new\nclass of random orthogonal initial conditions on weights that, like\nunsupervised pre-training, enjoys depth independent learning times. We further\nshow that these initial conditions also lead to faithful propagation of\ngradients even in deep nonlinear networks, as long as they operate in a special\nregime known as the edge of chaos.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 20:24:00 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2014 20:39:04 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2014 17:26:57 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Saxe", "Andrew M.", ""], ["McClelland", "James L.", ""], ["Ganguli", "Surya", ""]]}, {"id": "1312.6157", "submitter": "Mohammad Pezeshki", "authors": "Mohammad Pezeshki, Sajjad Gholami, Ahmad Nickabadi", "title": "Distinction between features extracted using deep belief networks", "comments": "4 pages, 4 figures, ICLR 2014 workshop track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data representation is an important pre-processing step in many machine\nlearning algorithms. There are a number of methods used for this task such as\nDeep Belief Networks (DBNs) and Discrete Fourier Transforms (DFTs). Since some\nof the features extracted using automated feature extraction methods may not\nalways be related to a specific machine learning task, in this paper we propose\ntwo methods in order to make a distinction between extracted features based on\ntheir relevancy to the task. We applied these two methods to a Deep Belief\nNetwork trained for a face recognition task.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 21:52:08 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2014 17:06:25 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Pezeshki", "Mohammad", ""], ["Gholami", "Sajjad", ""], ["Nickabadi", "Ahmad", ""]]}, {"id": "1312.6158", "submitter": "Mohammad Pezeshki", "authors": "Mohammad Ali Keyvanrad, Mohammad Pezeshki, and Mohammad Ali\n  Homayounpour", "title": "Deep Belief Networks for Image Denoising", "comments": "ICLR 2014 Conference track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Belief Networks which are hierarchical generative models are effective\ntools for feature representation and extraction. Furthermore, DBNs can be used\nin numerous aspects of Machine Learning such as image denoising. In this paper,\nwe propose a novel method for image denoising which relies on the DBNs' ability\nin feature representation. This work is based upon learning of the noise\nbehavior. Generally, features which are extracted using DBNs are presented as\nthe values of the last layer nodes. We train a DBN a way that the network\ntotally distinguishes between nodes presenting noise and nodes presenting image\ncontent in the last later of DBN, i.e. the nodes in the last layer of trained\nDBN are divided into two distinct groups of nodes. After detecting the nodes\nwhich are presenting the noise, we are able to make the noise nodes inactive\nand reconstruct a noiseless image. In section 4 we explore the results of\napplying this method on the MNIST dataset of handwritten digits which is\ncorrupted with additive white Gaussian noise (AWGN). A reduction of 65.9% in\naverage mean square error (MSE) was achieved when the proposed method was used\nfor the reconstruction of the noisy images.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 21:56:38 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2014 17:04:35 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Keyvanrad", "Mohammad Ali", ""], ["Pezeshki", "Mohammad", ""], ["Homayounpour", "Mohammad Ali", ""]]}, {"id": "1312.6171", "submitter": "Daniel Silver Dr.", "authors": "Ti Wang and Daniel L. Silver", "title": "Learning Paired-associate Images with An Unsupervised Deep Learning\n  Architecture", "comments": "9 pages, for ICLR-2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an unsupervised multi-modal learning system that learns\nassociative representation from two input modalities, or channels, such that\ninput on one channel will correctly generate the associated response at the\nother and vice versa. In this way, the system develops a kind of supervised\nclassification model meant to simulate aspects of human associative memory. The\nsystem uses a deep learning architecture (DLA) composed of two input/output\nchannels formed from stacked Restricted Boltzmann Machines (RBM) and an\nassociative memory network that combines the two channels. The DLA is trained\non pairs of MNIST handwritten digit images to develop hierarchical features and\nassociative representations that are able to reconstruct one image given its\npaired-associate. Experiments show that the multi-modal learning system\ngenerates models that are as accurate as back-propagation networks but with the\nadvantage of a bi-directional network and unsupervised learning from either\npaired or non-paired training examples.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 23:07:25 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2014 23:19:26 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Wang", "Ti", ""], ["Silver", "Daniel L.", ""]]}, {"id": "1312.6184", "submitter": "Jimmy Ba", "authors": "Lei Jimmy Ba, Rich Caruana", "title": "Do Deep Nets Really Need to be Deep?", "comments": "final revision coming soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, deep neural networks are the state of the art on problems such as\nspeech recognition and computer vision. In this extended abstract, we show that\nshallow feed-forward networks can learn the complex functions previously\nlearned by deep nets and achieve accuracies previously only achievable with\ndeep models. Moreover, in some cases the shallow neural nets can learn these\ndeep functions using a total number of parameters similar to the original deep\nmodel. We evaluate our method on the TIMIT phoneme recognition task and are\nable to train shallow fully-connected nets that perform similarly to complex,\nwell-engineered, deep convolutional architectures. Our success in training\nshallow neural nets to mimic deeper models suggests that there probably exist\nbetter algorithms for training shallow feed-forward nets than those currently\navailable.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2013 00:47:43 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2014 03:32:10 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2014 20:49:04 GMT"}, {"version": "v4", "created": "Wed, 8 Jan 2014 17:34:30 GMT"}, {"version": "v5", "created": "Fri, 21 Feb 2014 20:04:00 GMT"}, {"version": "v6", "created": "Tue, 7 Oct 2014 21:12:27 GMT"}, {"version": "v7", "created": "Sat, 11 Oct 2014 00:19:10 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Ba", "Lei Jimmy", ""], ["Caruana", "Rich", ""]]}, {"id": "1312.6186", "submitter": "Tom Paine", "authors": "Thomas Paine, Hailin Jin, Jianchao Yang, Zhe Lin, Thomas Huang", "title": "GPU Asynchronous Stochastic Gradient Descent to Speed Up Neural Network\n  Training", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to train large-scale neural networks has resulted in\nstate-of-the-art performance in many areas of computer vision. These results\nhave largely come from computational break throughs of two forms: model\nparallelism, e.g. GPU accelerated training, which has seen quick adoption in\ncomputer vision circles, and data parallelism, e.g. A-SGD, whose large scale\nhas been used mostly in industry. We report early experiments with a system\nthat makes use of both model parallelism and data parallelism, we call GPU\nA-SGD. We show using GPU A-SGD it is possible to speed up training of large\nconvolutional neural networks useful for computer vision. We believe GPU A-SGD\nwill make it possible to train larger networks on larger training sets in a\nreasonable amount of time.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2013 00:56:56 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Paine", "Thomas", ""], ["Jin", "Hailin", ""], ["Yang", "Jianchao", ""], ["Lin", "Zhe", ""], ["Huang", "Thomas", ""]]}, {"id": "1312.6197", "submitter": "David Warde-Farley", "authors": "David Warde-Farley, Ian J. Goodfellow, Aaron Courville and Yoshua\n  Bengio", "title": "An empirical analysis of dropout in piecewise linear networks", "comments": "Extensive updates; 8 pages plus acknowledgements/references", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently introduced dropout training criterion for neural networks has\nbeen the subject of much attention due to its simplicity and remarkable\neffectiveness as a regularizer, as well as its interpretation as a training\nprocedure for an exponentially large ensemble of networks that share\nparameters. In this work we empirically investigate several questions related\nto the efficacy of dropout, specifically as it concerns networks employing the\npopular rectified linear activation function. We investigate the quality of the\ntest time weight-scaling inference procedure by evaluating the geometric\naverage exactly in small models, as well as compare the performance of the\ngeometric mean to the arithmetic mean more commonly employed by ensemble\ntechniques. We explore the effect of tied weights on the ensemble\ninterpretation by training ensembles of masked networks without tied weights.\nFinally, we investigate an alternative criterion based on a biased estimator of\nthe maximum likelihood ensemble gradient.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2013 03:19:33 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2014 12:26:53 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Warde-Farley", "David", ""], ["Goodfellow", "Ian J.", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1312.6199", "submitter": "Joan Bruna", "authors": "Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna,\n  Dumitru Erhan, Ian Goodfellow, Rob Fergus", "title": "Intriguing properties of neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Deep neural networks are highly expressive models that have recently achieved\nstate of the art performance on speech and visual recognition tasks. While\ntheir expressiveness is the reason they succeed, it also causes them to learn\nuninterpretable solutions that could have counter-intuitive properties. In this\npaper we report two such properties.\n  First, we find that there is no distinction between individual high level\nunits and random linear combinations of high level units, according to various\nmethods of unit analysis. It suggests that it is the space, rather than the\nindividual units, that contains of the semantic information in the high layers\nof neural networks.\n  Second, we find that deep neural networks learn input-output mappings that\nare fairly discontinuous to a significant extend. We can cause the network to\nmisclassify an image by applying a certain imperceptible perturbation, which is\nfound by maximizing the network's prediction error. In addition, the specific\nnature of these perturbations is not a random artifact of learning: the same\nperturbation can cause a different network, that was trained on a different\nsubset of the dataset, to misclassify the same input.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2013 03:36:08 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2014 04:37:34 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2014 17:40:08 GMT"}, {"version": "v4", "created": "Wed, 19 Feb 2014 16:33:14 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Szegedy", "Christian", ""], ["Zaremba", "Wojciech", ""], ["Sutskever", "Ilya", ""], ["Bruna", "Joan", ""], ["Erhan", "Dumitru", ""], ["Goodfellow", "Ian", ""], ["Fergus", "Rob", ""]]}, {"id": "1312.6203", "submitter": "Joan Bruna", "authors": "Joan Bruna, Wojciech Zaremba, Arthur Szlam and Yann LeCun", "title": "Spectral Networks and Locally Connected Networks on Graphs", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks are extremely efficient architectures in image\nand audio recognition tasks, thanks to their ability to exploit the local\ntranslational invariance of signal classes over their domain. In this paper we\nconsider possible generalizations of CNNs to signals defined on more general\ndomains without the action of a translation group. In particular, we propose\ntwo constructions, one based upon a hierarchical clustering of the domain, and\nanother based on the spectrum of the graph Laplacian. We show through\nexperiments that for low-dimensional graphs it is possible to learn\nconvolutional layers with a number of parameters independent of the input size,\nresulting in efficient deep architectures.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2013 04:25:53 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2014 23:23:06 GMT"}, {"version": "v3", "created": "Wed, 21 May 2014 16:27:09 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Bruna", "Joan", ""], ["Zaremba", "Wojciech", ""], ["Szlam", "Arthur", ""], ["LeCun", "Yann", ""]]}, {"id": "1312.6204", "submitter": "Judy Hoffman", "authors": "Judy Hoffman, Eric Tzeng, Jeff Donahue, Yangqing Jia, Kate Saenko,\n  Trevor Darrell", "title": "One-Shot Adaptation of Supervised Deep Convolutional Models", "comments": null, "journal-ref": "ICLR Workshop 2014", "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dataset bias remains a significant barrier towards solving real world\ncomputer vision tasks. Though deep convolutional networks have proven to be a\ncompetitive approach for image classification, a question remains: have these\nmodels have solved the dataset bias problem? In general, training or\nfine-tuning a state-of-the-art deep model on a new domain requires a\nsignificant amount of data, which for many applications is simply not\navailable. Transfer of models directly to new domains without adaptation has\nhistorically led to poor recognition performance. In this paper, we pose the\nfollowing question: is a single image dataset, much larger than previously\nexplored for adaptation, comprehensive enough to learn general deep models that\nmay be effectively applied to new image domains? In other words, are deep CNNs\ntrained on large amounts of labeled data as susceptible to dataset bias as\nprevious methods have been shown to be? We show that a generic supervised deep\nCNN model trained on a large dataset reduces, but does not remove, dataset\nbias. Furthermore, we propose several methods for adaptation with deep models\nthat are able to operate with little (one example per category) or no labeled\ndomain specific data. Our experiments show that adaptation of deep models on\nbenchmark visual domain adaptation datasets can provide a significant\nperformance boost.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2013 04:32:51 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2014 02:57:42 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Hoffman", "Judy", ""], ["Tzeng", "Eric", ""], ["Donahue", "Jeff", ""], ["Jia", "Yangqing", ""], ["Saenko", "Kate", ""], ["Darrell", "Trevor", ""]]}, {"id": "1312.6211", "submitter": "Ian Goodfellow", "authors": "Ian J. Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, Yoshua\n  Bengio", "title": "An Empirical Investigation of Catastrophic Forgetting in Gradient-Based\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting is a problem faced by many machine learning models\nand algorithms. When trained on one task, then trained on a second task, many\nmachine learning models \"forget\" how to perform the first task. This is widely\nbelieved to be a serious problem for neural networks. Here, we investigate the\nextent to which the catastrophic forgetting problem occurs for modern neural\nnetworks, comparing both established and recent gradient-based training\nalgorithms and activation functions. We also examine the effect of the\nrelationship between the first task and the second task on catastrophic\nforgetting. We find that it is always best to train using the dropout\nalgorithm--the dropout algorithm is consistently best at adapting to the new\ntask, remembering the old task, and has the best tradeoff curve between these\ntwo extremes. We find that different tasks and relationships between tasks\nresult in very different rankings of activation function performance. This\nsuggests the choice of activation function should always be cross-validated.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2013 06:31:41 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2014 21:27:34 GMT"}, {"version": "v3", "created": "Wed, 4 Mar 2015 01:43:31 GMT"}], "update_date": "2015-03-05", "authors_parsed": [["Goodfellow", "Ian J.", ""], ["Mirza", "Mehdi", ""], ["Xiao", "Da", ""], ["Courville", "Aaron", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1312.6461", "submitter": "Sho Sonoda", "authors": "Sho Sonoda, Noboru Murata", "title": "Nonparametric Weight Initialization of Neural Networks via Integral\n  Representation", "comments": "For ICLR2014, revised into 9 pages; revised into 12 pages (with\n  supplements)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new initialization method for hidden parameters in a neural network is\nproposed. Derived from the integral representation of the neural network, a\nnonparametric probability distribution of hidden parameters is introduced. In\nthis proposal, hidden parameters are initialized by samples drawn from this\ndistribution, and output parameters are fitted by ordinary linear regression.\nNumerical experiments show that backpropagation with proposed initialization\nconverges faster than uniformly random initialization. Also it is shown that\nthe proposed method achieves enough accuracy by itself without backpropagation\nin some cases.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 03:23:04 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2013 02:54:29 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2014 20:02:05 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Sonoda", "Sho", ""], ["Murata", "Noboru", ""]]}, {"id": "1312.6609", "submitter": "Iztok Fister", "authors": "Iztok Fister, Iztok Fister Jr., Xin-She Yang, Janez Brest", "title": "A comprehensive review of firefly algorithms", "comments": null, "journal-ref": "I. Fister, I. Fister Jr., X.-S. Yang, and J. Brest, A\n  comprehensive review of firefly algorithms, Swarm and Evolutionary\n  Computation, vol. 13, pp. 34-46, 2013", "doi": "10.1016/j.swevo.2013.06.001", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The firefly algorithm has become an increasingly important tool of Swarm\nIntelligence that has been applied in almost all areas of optimization, as well\nas engineering practice. Many problems from various areas have been\nsuccessfully solved using the firefly algorithm and its variants. In order to\nuse the algorithm to solve diverse problems, the original firefly algorithm\nneeds to be modified or hybridized. This paper carries out a comprehensive\nreview of this living and evolving discipline of Swarm Intelligence, in order\nto show that the firefly algorithm could be applied to every problem arising in\npractice. On the other hand, it encourages new researchers and algorithm\ndevelopers to use this simple and yet very efficient algorithm for problem\nsolving. It often guarantees that the obtained results will meet the\nexpectations.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 17:16:46 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Fister", "Iztok", ""], ["Fister", "Iztok", "Jr."], ["Yang", "Xin-She", ""], ["Brest", "Janez", ""]]}, {"id": "1312.6885", "submitter": "Brody Huval", "authors": "Brody Huval, Adam Coates, Andrew Ng", "title": "Deep learning for class-generic object detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of deep neural networks for the novel task of class\ngeneric object detection. We show that neural networks originally designed for\nimage recognition can be trained to detect objects within images, regardless of\ntheir class, including objects for which no bounding box labels have been\nprovided. In addition, we show that bounding box labels yield a 1% performance\nincrease on the ImageNet recognition challenge.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2013 20:38:18 GMT"}], "update_date": "2013-12-25", "authors_parsed": [["Huval", "Brody", ""], ["Coates", "Adam", ""], ["Ng", "Andrew", ""]]}, {"id": "1312.7302", "submitter": "Arjun Jain", "authors": "Arjun Jain, Jonathan Tompson, Mykhaylo Andriluka, Graham W. Taylor,\n  Christoph Bregler", "title": "Learning Human Pose Estimation Features with Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "NYU-TR-2013-CS0999", "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new architecture for human pose estimation using a\nmulti- layer convolutional network architecture and a modified learning\ntechnique that learns low-level features and higher-level weak spatial models.\nUnconstrained human pose estimation is one of the hardest problems in computer\nvision, and our new architecture and learning schema shows significant\nimprovement over the current state-of-the-art results. The main contribution of\nthis paper is showing, for the first time, that a specific variation of deep\nlearning is able to outperform all existing traditional architectures on this\ntask. The paper also discusses several lessons learned while researching\nalternatives, most notably, that it is possible to learn strong low-level\nfeature detectors on features that might even just cover a few pixels in the\nimage. Higher-level spatial models improve somewhat the overall result, but to\na much lesser extent then expected. Many researchers previously argued that the\nkinematic structure and top-down information is crucial for this domain, but\nwith our purely bottom up, and weak spatial model, we could improve other more\ncomplicated architectures that currently produce the best results. This mirrors\nwhat many other researchers, like those in the speech recognition, object\nrecognition, and other domains have experienced.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2013 17:41:13 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2013 04:29:34 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2014 20:56:34 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2014 16:22:38 GMT"}, {"version": "v5", "created": "Tue, 25 Feb 2014 05:32:32 GMT"}, {"version": "v6", "created": "Wed, 23 Apr 2014 19:23:46 GMT"}], "update_date": "2014-04-24", "authors_parsed": [["Jain", "Arjun", ""], ["Tompson", "Jonathan", ""], ["Andriluka", "Mykhaylo", ""], ["Taylor", "Graham W.", ""], ["Bregler", "Christoph", ""]]}, {"id": "1312.7852", "submitter": "Christiaan Erdbrink", "authors": "C.D. Erdbrink, V.V. Krzhizhanovskaya, P.M.A. Sloot", "title": "Evolutionary Design of Numerical Methods: Generating Finite Difference\n  and Integration Schemes by Differential Evolution", "comments": "19 pages, 7 figures, 10 tables, 4 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical and new numerical schemes are generated using evolutionary\ncomputing. Differential Evolution is used to find the coefficients of finite\ndifference approximations of function derivatives, and of single and multi-step\nintegration methods. The coefficients are reverse engineered based on samples\nfrom a target function and its derivative used for training. The Runge-Kutta\nschemes are trained using the order condition equations. An appealing feature\nof the evolutionary method is the low number of model parameters. The\npopulation size, termination criterion and number of training points are\ndetermined in a sensitivity analysis. Computational results show good agreement\nbetween evolved and analytical coefficients. In particular, a new fifth-order\nRunge-Kutta scheme is computed which adheres to the order conditions with a sum\nof absolute errors of order 10^-14. Execution of the evolved schemes proved the\nintended orders of accuracy. The outcome of this study is valuable for future\ndevelopments in the design of complex numerical methods that are out of reach\nby conventional means.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2013 20:21:44 GMT"}], "update_date": "2014-01-02", "authors_parsed": [["Erdbrink", "C. D.", ""], ["Krzhizhanovskaya", "V. V.", ""], ["Sloot", "P. M. A.", ""]]}]