[{"id": "0906.0231", "submitter": "Kimikazu Kato", "authors": "Kimikazu Kato and Tikara Hosino", "title": "Solving $k$-Nearest Neighbor Problem on Multiple Graphics Processors", "comments": "5 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS cs.NE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The recommendation system is a software system to predict customers' unknown\npreferences from known preferences. In the recommendation system, customers'\npreferences are encoded into vectors, and finding the nearest vectors to each\nvector is an essential part. This vector-searching part of the problem is\ncalled a $k$-nearest neighbor problem. We give an effective algorithm to solve\nthis problem on multiple graphics processor units (GPUs).\n  Our algorithm consists of two parts: an $N$-body problem and a partial sort.\nFor a algorithm of the $N$-body problem, we applied the idea of a known\nalgorithm for the $N$-body problem in physics, although another trick is need\nto overcome the problem of small sized shared memory. For the partial sort, we\ngive a novel GPU algorithm which is effective for small $k$. In our partial\nsort algorithm, a heap is accessed in parallel by threads with a low cost of\nsynchronization. Both of these two parts of our algorithm utilize maximal power\nof coalesced memory access, so that a full bandwidth is achieved.\n  By an experiment, we show that when the size of the problem is large, an\nimplementation of the algorithm on two GPUs runs more than 330 times faster\nthan a single core implementation on a latest CPU. We also show that our\nalgorithm scales well with respect to the number of GPUs.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2009 08:14:13 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2009 06:48:21 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2010 02:23:22 GMT"}], "update_date": "2010-07-16", "authors_parsed": [["Kato", "Kimikazu", ""], ["Hosino", "Tikara", ""]]}, {"id": "0906.0798", "submitter": "Subhash Kak", "authors": "Subhash Kak", "title": "Single Neuron Memories and the Network's Proximity Matrix", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends the treatment of single-neuron memories obtained by the\nB-matrix approach. The spreading of the activity within the network is\ndetermined by the network's proximity matrix which represents the separations\namongst the neurons through the neural pathways.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2009 23:10:25 GMT"}], "update_date": "2009-06-05", "authors_parsed": [["Kak", "Subhash", ""]]}, {"id": "0906.0861", "submitter": "Florentina Pintea", "authors": "A. A. Shumeyko, S. L. Sotnik", "title": "Using Genetic Algorithms for Texts Classification Problems", "comments": "16 pages, exposed on 5th International Conference \"Actualities and\n  Perspectives on Hardware and Software\" - APHS2009, Timisoara, Romania", "journal-ref": "Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),325-340", "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The avalanche quantity of the information developed by mankind has led to\nconcept of automation of knowledge extraction - Data Mining ([1]). This\ndirection is connected with a wide spectrum of problems - from recognition of\nthe fuzzy set to creation of search machines. Important component of Data\nMining is processing of the text information. Such problems lean on concept of\nclassification and clustering ([2]). Classification consists in definition of\nan accessory of some element (text) to one of in advance created classes.\nClustering means splitting a set of elements (texts) on clusters which quantity\nare defined by localization of elements of the given set in vicinities of these\nsome natural centers of these clusters. Realization of a problem of\nclassification initially should lean on the given postulates, basic of which -\nthe aprioristic information on primary set of texts and a measure of affinity\nof elements and classes.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2009 09:41:47 GMT"}], "update_date": "2009-06-05", "authors_parsed": [["Shumeyko", "A. A.", ""], ["Sotnik", "S. L.", ""]]}, {"id": "0906.0872", "submitter": "Boris Yangel", "authors": "Boris Yangel", "title": "Fast Weak Learner Based on Genetic Algorithm", "comments": "4 pages, acmsiggraph latex style packed with the latex source in the\n  single archive", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach to the acceleration of parametric weak classifier boosting is\nproposed. Weak classifier is called parametric if it has fixed number of\nparameters and, so, can be represented as a point into multidimensional space.\nGenetic algorithm is used instead of exhaustive search to learn parameters of\nsuch classifier. Proposed approach also takes cases when effective algorithm\nfor learning some of the classifier parameters exists into account. Experiments\nconfirm that such an approach can dramatically decrease classifier training\ntime while keeping both training and test errors small.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2009 10:25:08 GMT"}], "update_date": "2009-06-05", "authors_parsed": [["Yangel", "Boris", ""]]}, {"id": "0906.1900", "submitter": "Philippe Thomas", "authors": "Philippe Thomas (CRAN), Andr\\'e Thomas (CRAN)", "title": "How deals with discrete data for the reduction of simulation models\n  using neural network", "comments": null, "journal-ref": "13th IFAC Symp. On Information Control Problems in Manufacturing\n  INCOM'09, Moscou : Russie (2009)", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation is useful for the evaluation of a Master Production/distribution\nSchedule (MPS). Also, the goal of this paper is the study of the design of a\nsimulation model by reducing its complexity. According to theory of\nconstraints, we want to build reduced models composed exclusively by\nbottlenecks and a neural network. Particularly a multilayer perceptron, is\nused. The structure of the network is determined by using a pruning procedure.\nThis work focuses on the impact of discrete data on the results and compares\ndifferent approaches to deal with these data. This approach is applied to\nsawmill internal supply chain\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2009 09:56:29 GMT"}], "update_date": "2009-06-11", "authors_parsed": [["Thomas", "Philippe", "", "CRAN"], ["Thomas", "Andr\u00e9", "", "CRAN"]]}, {"id": "0906.4154", "submitter": "Oliver Obst", "authors": "Oliver Obst", "title": "Distributed Fault Detection in Sensor Networks using a Recurrent Neural\n  Network", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In long-term deployments of sensor networks, monitoring the quality of\ngathered data is a critical issue. Over the time of deployment, sensors are\nexposed to harsh conditions, causing some of them to fail or to deliver less\naccurate data. If such a degradation remains undetected, the usefulness of a\nsensor network can be greatly reduced. We present an approach that learns\nspatio-temporal correlations between different sensors, and makes use of the\nlearned model to detect misbehaving sensors by using distributed computation\nand only local communication between nodes. We introduce SODESN, a distributed\nrecurrent neural network architecture, and a learning method to train SODESN\nfor fault detection in a distributed scenario. Our approach is evaluated using\ndata from different types of sensors and is able to work well even with\nless-than-perfect link qualities and more than 50% of failed nodes.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2009 01:54:55 GMT"}], "update_date": "2009-12-05", "authors_parsed": [["Obst", "Oliver", ""]]}, {"id": "0906.4838", "submitter": "R Doomun", "authors": "Siddhivinayak Kulkarni, Imad Haidar", "title": "Forecasting Model for Crude Oil Price Using Artificial Neural Networks\n  and Commodity Futures Prices", "comments": "8 Pages, International Journal of Computer Science and Information\n  Security (IJCSIS)", "journal-ref": "IJCSIS June 2009 Issue, Vol. 2, No. 1", "doi": null, "report-no": null, "categories": "cs.NE q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a model based on multilayer feedforward neural network to\nforecast crude oil spot price direction in the short-term, up to three days\nahead. A great deal of attention was paid on finding the optimal ANN model\nstructure. In addition, several methods of data pre-processing were tested. Our\napproach is to create a benchmark based on lagged value of pre-processed spot\nprice, then add pre-processed futures prices for 1, 2, 3,and four months to\nmaturity, one by one and also altogether. The results on the benchmark suggest\nthat a dynamic model of 13 lags is the optimal to forecast spot price direction\nfor the short-term. Further, the forecast accuracy of the direction of the\nmarket was 78%, 66%, and 53% for one, two, and three days in future\nconclusively. For all the experiments, that include futures data as an input,\nthe results show that on the short-term, futures prices do hold new information\non the spot price direction. The results obtained will generate comprehensive\nunderstanding of the crude oil dynamic which help investors and individuals for\nrisk managements.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2009 04:25:12 GMT"}], "update_date": "2009-06-29", "authors_parsed": [["Kulkarni", "Siddhivinayak", ""], ["Haidar", "Imad", ""]]}, {"id": "0906.4846", "submitter": "Lorentz Jantschi", "authors": "Lorentz Jantschi", "title": "A genetic algorithm for structure-activity relationships: software\n  implementation", "comments": "21 pages; 10 figures; 14 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The design and the implementation of a genetic algorithm are described. The\napplicability domain is on structure-activity relationships expressed as\nmultiple linear regressions and predictor variables are from families of\nstructure-based molecular descriptors. An experiment to compare different\nselection and survival strategies was designed and realized. The genetic\nalgorithm was run using the designed experiment on a set of 206 polychlorinated\nbiphenyls searching on structure-activity relationships having known the\nmeasured octanol-water partition coefficients and a family of molecular\ndescriptors. The experiment shows that different selection and survival\nstrategies create different partitions on the entire population of all possible\ngenotypes.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2009 06:25:07 GMT"}], "update_date": "2009-06-29", "authors_parsed": [["Jantschi", "Lorentz", ""]]}]