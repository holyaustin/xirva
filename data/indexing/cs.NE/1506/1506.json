[{"id": "1506.00019", "submitter": "Zachary Lipton", "authors": "Zachary C. Lipton, John Berkowitz, Charles Elkan", "title": "A Critical Review of Recurrent Neural Networks for Sequence Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Countless learning tasks require dealing with sequential data. Image\ncaptioning, speech synthesis, and music generation all require that a model\nproduce outputs that are sequences. In other domains, such as time series\nprediction, video analysis, and musical information retrieval, a model must\nlearn from inputs that are sequences. Interactive tasks, such as translating\nnatural language, engaging in dialogue, and controlling a robot, often demand\nboth capabilities. Recurrent neural networks (RNNs) are connectionist models\nthat capture the dynamics of sequences via cycles in the network of nodes.\nUnlike standard feedforward neural networks, recurrent networks retain a state\nthat can represent information from an arbitrarily long context window.\nAlthough recurrent neural networks have traditionally been difficult to train,\nand often contain millions of parameters, recent advances in network\narchitectures, optimization techniques, and parallel computation have enabled\nsuccessful large-scale learning with them. In recent years, systems based on\nlong short-term memory (LSTM) and bidirectional (BRNN) architectures have\ndemonstrated ground-breaking performance on tasks as varied as image\ncaptioning, language translation, and handwriting recognition. In this survey,\nwe review and synthesize the research that over the past three decades first\nyielded and then made practical these powerful learning models. When\nappropriate, we reconcile conflicting notation and nomenclature. Our goal is to\nprovide a self-contained explication of the state of the art together with a\nhistorical perspective and references to primary research.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2015 20:16:51 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2015 20:01:00 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2015 04:59:24 GMT"}, {"version": "v4", "created": "Sat, 17 Oct 2015 05:06:11 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Lipton", "Zachary C.", ""], ["Berkowitz", "John", ""], ["Elkan", "Charles", ""]]}, {"id": "1506.00074", "submitter": "Yibin Huang", "authors": "Yi-bin Huang, Kang Li, Ge Wang, Min Cao, Pin Li, Yu-jia Zhang", "title": "Recognition of convolutional neural network based on CUDA Technology", "comments": "The novelty is too limited, we don't want to mislead others anymore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  For the problem whether Graphic Processing Unit(GPU),the stream processor\nwith high performance of floating-point computing is applicable to neural\nnetworks, this paper proposes the parallel recognition algorithm of\nConvolutional Neural Networks(CNNs).It adopts Compute Unified Device\nArchitecture(CUDA)technology, definite the parallel data structures, and\ndescribes the mapping mechanism for computing tasks on CUDA. It compares the\nparallel recognition algorithm achieved on GPU of GTX200 hardware architecture\nwith the serial algorithm on CPU. It improves speed by nearly 60 times. Result\nshows that GPU based the stream processor architecture ate more applicable to\nsome related applications about neural networks than CPU.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2015 05:38:00 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 14:48:55 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Huang", "Yi-bin", ""], ["Li", "Kang", ""], ["Wang", "Ge", ""], ["Cao", "Min", ""], ["Li", "Pin", ""], ["Zhang", "Yu-jia", ""]]}, {"id": "1506.00122", "submitter": "Mohammad Sabokrou", "authors": "Mohammad Sabokrou, Mahmood Fathy and Mojtaba Hoseini", "title": "IDSA: Intelligent Distributed Sensor Activation Algorithm For Target\n  Tracking With Wireless Sensor Network", "comments": "We have found several mistake in this our paper. (1) The English\n  writing of paper must improved (2) the experimental results especially Figure\n  9, 10 and 12 are wrong (3) Some references must revised. We are providing new\n  version of paper. We are concern about, this version make confusion for\n  readers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One important application of the Wireless Sensor Network(WSN) is target\ntracking, the aim of this application is converging to an event or object in an\narea. In this paper, we propose an energy-efficient distributed sensor\nactivation protocol based on predicted location technique, called Intelligent\nDistributed Sensor Activation Algorithm (IDSA). The proposed algorithm predicts\nthe location of target in the next time interval, by analyzing current location\nand movement history of the target, this prediction is done by computational\nintelligence. The fewest essential number of sensor nodes within the predicted\nlocation will be activated to cover the target. The results show that the\nproposed method outperforms the existing methods such as Na\\\"ive and DSA in\nterms of energy consumption and the number of nodes that was involved in\ntracking the target.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2015 14:32:19 GMT"}, {"version": "v2", "created": "Tue, 29 Mar 2016 09:15:40 GMT"}, {"version": "v3", "created": "Mon, 25 Apr 2016 12:00:13 GMT"}, {"version": "v4", "created": "Wed, 15 Feb 2017 08:28:32 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Sabokrou", "Mohammad", ""], ["Fathy", "Mahmood", ""], ["Hoseini", "Mojtaba", ""]]}, {"id": "1506.00195", "submitter": "Kaisheng Yao", "authors": "Baolin Peng and Kaisheng Yao", "title": "Recurrent Neural Networks with External Memory for Language\n  Understanding", "comments": "submitted to Interspeech 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) have become increasingly popular for the\ntask of language understanding. In this task, a semantic tagger is deployed to\nassociate a semantic label to each word in an input sequence. The success of\nRNN may be attributed to its ability to memorize long-term dependence that\nrelates the current-time semantic label prediction to the observations many\ntime instances away. However, the memory capacity of simple RNNs is limited\nbecause of the gradient vanishing and exploding problem. We propose to use an\nexternal memory to improve memorization capability of RNNs. We conducted\nexperiments on the ATIS dataset, and observed that the proposed model was able\nto achieve the state-of-the-art results. We compare our proposed model with\nalternative models and report analysis results that may provide insights for\nfuture research.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2015 05:10:03 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Peng", "Baolin", ""], ["Yao", "Kaisheng", ""]]}, {"id": "1506.00327", "submitter": "Zhiguang Wang", "authors": "Zhiguang Wang and Tim Oates", "title": "Imaging Time-Series to Improve Classification and Imputation", "comments": "Accepted by IJCAI-2015 ML track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Inspired by recent successes of deep learning in computer vision, we propose\na novel framework for encoding time series as different types of images,\nnamely, Gramian Angular Summation/Difference Fields (GASF/GADF) and Markov\nTransition Fields (MTF). This enables the use of techniques from computer\nvision for time series classification and imputation. We used Tiled\nConvolutional Neural Networks (tiled CNNs) on 20 standard datasets to learn\nhigh-level features from the individual and compound GASF-GADF-MTF images. Our\napproaches achieve highly competitive results when compared to nine of the\ncurrent best time series classification approaches. Inspired by the bijection\nproperty of GASF on 0/1 rescaled data, we train Denoised Auto-encoders (DA) on\nthe GASF images of four standard and one synthesized compound dataset. The\nimputation MSE on test data is reduced by 12.18%-48.02% when compared to using\nthe raw data. An analysis of the features and weights learned via tiled CNNs\nand DAs explains why the approaches work.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 02:17:06 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Wang", "Zhiguang", ""], ["Oates", "Tim", ""]]}, {"id": "1506.00333", "submitter": "Lin Ma", "authors": "Lin Ma, Zhengdong Lu, Hang Li", "title": "Learning to Answer Questions From Image Using Convolutional Neural\n  Network", "comments": "7 pages, 4 figures. Accepted by AAAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose to employ the convolutional neural network (CNN)\nfor the image question answering (QA). Our proposed CNN provides an end-to-end\nframework with convolutional architectures for learning not only the image and\nquestion representations, but also their inter-modal interactions to produce\nthe answer. More specifically, our model consists of three CNNs: one image CNN\nto encode the image content, one sentence CNN to compose the words of the\nquestion, and one multimodal convolution layer to learn their joint\nrepresentation for the classification in the space of candidate answer words.\nWe demonstrate the efficacy of our proposed model on the DAQUAR and COCO-QA\ndatasets, which are two benchmark datasets for the image QA, with the\nperformances significantly outperforming the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 03:09:49 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2015 09:54:59 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Ma", "Lin", ""], ["Lu", "Zhengdong", ""], ["Li", "Hang", ""]]}, {"id": "1506.00354", "submitter": "Yasser Roudi", "authors": "Yasser Roudi and Graham Taylor", "title": "Learning with hidden variables", "comments": "revised version accepted in Current Opinion in Neurobiology", "journal-ref": "Current Opinion in Neurobiology (2015), 35: 110-118", "doi": "10.1016/j.conb.2015.07.006", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning and inferring features that generate sensory input is a task\ncontinuously performed by cortex. In recent years, novel algorithms and\nlearning rules have been proposed that allow neural network models to learn\nsuch features from natural images, written text, audio signals, etc. These\nnetworks usually involve deep architectures with many layers of hidden neurons.\nHere we review recent advancements in this area emphasizing, amongst other\nthings, the processing of dynamical inputs by networks with hidden nodes and\nthe role of single neuron models. These points and the questions they arise can\nprovide conceptual advancements in understanding of learning in the cortex and\nthe relationship between machine learning approaches to learning with hidden\nnodes and those in cortical circuits.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 05:36:19 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2015 20:37:48 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Roudi", "Yasser", ""], ["Taylor", "Graham", ""]]}, {"id": "1506.00511", "submitter": "Jimmy Ba", "authors": "Jimmy Ba, Kevin Swersky, Sanja Fidler and Ruslan Salakhutdinov", "title": "Predicting Deep Zero-Shot Convolutional Neural Networks using Textual\n  Descriptions", "comments": "Correct the typos in table 1 regarding [5]. To appear in ICCV 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges in Zero-Shot Learning of visual categories is\ngathering semantic attributes to accompany images. Recent work has shown that\nlearning from textual descriptions, such as Wikipedia articles, avoids the\nproblem of having to explicitly define these attributes. We present a new model\nthat can classify unseen categories from their textual description.\nSpecifically, we use text features to predict the output weights of both the\nconvolutional and the fully connected layers in a deep convolutional neural\nnetwork (CNN). We take advantage of the architecture of CNNs and learn features\nat different layers, rather than just learning an embedding space for both\nmodalities, as is common with existing approaches. The proposed model also\nallows us to automatically generate a list of pseudo- attributes for each\nvisual category consisting of words from Wikipedia articles. We train our\nmodels end-to-end us- ing the Caltech-UCSD bird and flower datasets and\nevaluate both ROC and Precision-Recall curves. Our empirical results show that\nthe proposed model significantly outperforms previous methods.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 14:37:06 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2015 16:20:44 GMT"}], "update_date": "2015-09-28", "authors_parsed": [["Ba", "Jimmy", ""], ["Swersky", "Kevin", ""], ["Fidler", "Sanja", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1506.00619", "submitter": "Bart van Merri\\\"enboer", "authors": "Bart van Merri\\\"enboer, Dzmitry Bahdanau, Vincent Dumoulin, Dmitriy\n  Serdyuk, David Warde-Farley, Jan Chorowski, Yoshua Bengio", "title": "Blocks and Fuel: Frameworks for deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two Python frameworks to train neural networks on large\ndatasets: Blocks and Fuel. Blocks is based on Theano, a linear algebra compiler\nwith CUDA-support. It facilitates the training of complex neural network models\nby providing parametrized Theano operations, attaching metadata to Theano's\nsymbolic computational graph, and providing an extensive set of utilities to\nassist training the networks, e.g. training algorithms, logging, monitoring,\nvisualization, and serialization. Fuel provides a standard format for machine\nlearning datasets. It allows the user to easily iterate over large datasets,\nperforming many types of pre-processing on the fly.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 19:28:27 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["van Merri\u00ebnboer", "Bart", ""], ["Bahdanau", "Dzmitry", ""], ["Dumoulin", "Vincent", ""], ["Serdyuk", "Dmitriy", ""], ["Warde-Farley", "David", ""], ["Chorowski", "Jan", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1506.00768", "submitter": "Madhu Khurana", "authors": "Madhu Khurana and Vikas Saxena", "title": "Soft Computing Techniques for Change Detection in remotely sensed images\n  : A Review", "comments": "9 pages, 1 table, 1 figure", "journal-ref": "International Journal of Computer Science Issues, Volume 12, Issue\n  2, March 2015, pp 245-253", "doi": null, "report-no": null, "categories": "cs.NE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of remote sensing satellites, a huge repository of remotely\nsensed images is available. Change detection in remotely sensed images has been\nan active research area as it helps us understand the transitions that are\ntaking place on the Earths surface. This paper discusses the methods and their\nclassifications proposed by various researchers for change detection. Since use\nof soft computing based techniques are now very popular among research\ncommunity, this paper also presents a classification based on learning\ntechniques used in soft-computing methods for change detection.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 06:38:54 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 07:45:40 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Khurana", "Madhu", ""], ["Saxena", "Vikas", ""]]}, {"id": "1506.01069", "submitter": "Xinyu Wu", "authors": "Xinyu Wu, Vishal Saxena, Kehan Zhu", "title": "A CMOS Spiking Neuron for Dense Memristor-Synapse Connectivity for\n  Brain-Inspired Computing", "comments": "This is a preprint of an article accepted for publication in\n  International Joint Conference on Neural Networks (IJCNN) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic systems that densely integrate CMOS spiking neurons and\nnano-scale memristor synapses open a new avenue of brain-inspired computing.\nExisting silicon neurons have molded neural biophysical dynamics but are\nincompatible with memristor synapses, or used extra training circuitry thus\neliminating much of the density advantages gained by using memristors, or were\nenergy inefficient. Here we describe a novel CMOS spiking leaky\nintegrate-and-fire neuron circuit. Building on a reconfigurable architecture\nwith a single opamp, the described neuron accommodates a large number of\nmemristor synapses, and enables online spike timing dependent plasticity (STDP)\nlearning with optimized power consumption. Simulation results of an 180nm CMOS\ndesign showed 97% power efficiency metric when realizing STDP learning in\n10,000 memristor synapses with a nominal 1M{\\Omega} memristance, and only\n13{\\mu}A current consumption when integrating input spikes. Therefore, the\ndescribed CMOS neuron contributes a generalized building block for large-scale\nbrain-inspired neuromorphic systems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 21:28:56 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2015 21:35:19 GMT"}], "update_date": "2015-06-10", "authors_parsed": [["Wu", "Xinyu", ""], ["Saxena", "Vishal", ""], ["Zhu", "Kehan", ""]]}, {"id": "1506.01072", "submitter": "Xinyu Wu", "authors": "Xinyu Wu, Vishal Saxena, Kehan Zhu", "title": "Homogeneous Spiking Neuromorphic System for Real-World Pattern\n  Recognition", "comments": "This is a preprint of an article accepted for publication in IEEE\n  Journal on Emerging and Selected Topics in Circuits and Systems, vol 5, no.\n  2, June 2015", "journal-ref": "IEEE Journal on Emerging and Selected Topics in Circuits and\n  Systems, vol 5, no. 2, June 2015", "doi": "10.1109/JETCAS.2015.2433552", "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A neuromorphic chip that combines CMOS analog spiking neurons and memristive\nsynapses offers a promising solution to brain-inspired computing, as it can\nprovide massive neural network parallelism and density. Previous hybrid analog\nCMOS-memristor approaches required extensive CMOS circuitry for training, and\nthus eliminated most of the density advantages gained by the adoption of\nmemristor synapses. Further, they used different waveforms for pre and\npost-synaptic spikes that added undesirable circuit overhead. Here we describe\na hardware architecture that can feature a large number of memristor synapses\nto learn real-world patterns. We present a versatile CMOS neuron that combines\nintegrate-and-fire behavior, drives passive memristors and implements\ncompetitive learning in a compact circuit module, and enables in-situ\nplasticity in the memristor synapses. We demonstrate handwritten-digits\nrecognition using the proposed architecture using transistor-level circuit\nsimulations. As the described neuromorphic architecture is homogeneous, it\nrealizes a fundamental building block for large-scale energy-efficient\nbrain-inspired silicon chips that could lead to next-generation cognitive\ncomputing.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 21:35:51 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2015 20:32:49 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Wu", "Xinyu", ""], ["Saxena", "Vishal", ""], ["Zhu", "Kehan", ""]]}, {"id": "1506.01186", "submitter": "Leslie Smith", "authors": "Leslie N. Smith", "title": "Cyclical Learning Rates for Training Neural Networks", "comments": "Presented at WACV 2017; see https://github.com/bckenstler/CLR for\n  instructions to implement CLR in Keras", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that the learning rate is the most important hyper-parameter to\ntune for training deep neural networks. This paper describes a new method for\nsetting the learning rate, named cyclical learning rates, which practically\neliminates the need to experimentally find the best values and schedule for the\nglobal learning rates. Instead of monotonically decreasing the learning rate,\nthis method lets the learning rate cyclically vary between reasonable boundary\nvalues. Training with cyclical learning rates instead of fixed values achieves\nimproved classification accuracy without a need to tune and often in fewer\niterations. This paper also describes a simple way to estimate \"reasonable\nbounds\" -- linearly increasing the learning rate of the network for a few\nepochs. In addition, cyclical learning rates are demonstrated on the CIFAR-10\nand CIFAR-100 datasets with ResNets, Stochastic Depth networks, and DenseNets,\nand the ImageNet dataset with the AlexNet and GoogLeNet architectures. These\nare practical tools for everyone who trains neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2015 09:54:31 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2015 20:40:18 GMT"}, {"version": "v3", "created": "Wed, 26 Oct 2016 19:07:58 GMT"}, {"version": "v4", "created": "Thu, 29 Dec 2016 15:20:01 GMT"}, {"version": "v5", "created": "Thu, 23 Mar 2017 11:38:19 GMT"}, {"version": "v6", "created": "Tue, 4 Apr 2017 11:34:46 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Smith", "Leslie N.", ""]]}, {"id": "1506.01195", "submitter": "Tianyi Liu", "authors": "Tianyi Liu, Shuangsang Fang, Yuehui Zhao, Peng Wang, Jun Zhang", "title": "Implementation of Training Convolutional Neural Networks", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning refers to the shining branch of machine learning that is based\non learning levels of representations. Convolutional Neural Networks (CNN) is\none kind of deep neural network. It can study concurrently. In this article, we\ngave a detailed analysis of the process of CNN algorithm both the forward\nprocess and back propagation. Then we applied the particular convolutional\nneural network to implement the typical face recognition problem by java. Then,\na parallel strategy was proposed in section4. In addition, by measuring the\nactual time of forward and backward computing, we analysed the maximal speed up\nand parallel efficiency theoretically.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2015 10:18:49 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2015 02:10:39 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Liu", "Tianyi", ""], ["Fang", "Shuangsang", ""], ["Zhao", "Yuehui", ""], ["Wang", "Peng", ""], ["Zhang", "Jun", ""]]}, {"id": "1506.01573", "submitter": "Lance Williams", "authors": "Lance R. Williams", "title": "Programs as Polypeptides", "comments": "in European Conference on Artificial Life (ECAL '15), York, UK, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a visual programming language for defining behaviors manifested\nby reified actors in a 2D virtual world that can be compiled into programs\ncomprised of sequences of combinators that are themselves reified as actors.\nThis makes it possible to build programs that build programs from components of\na few fixed types delivered by diffusion using processes that resemble\nchemistry as much as computation.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 13:08:04 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Williams", "Lance R.", ""]]}, {"id": "1506.01911", "submitter": "Lionel Pigou", "authors": "Lionel Pigou, A\\\"aron van den Oord, Sander Dieleman, Mieke Van\n  Herreweghe, Joni Dambre", "title": "Beyond Temporal Pooling: Recurrence and Temporal Convolutions for\n  Gesture Recognition in Video", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have demonstrated the power of recurrent neural networks for\nmachine translation, image captioning and speech recognition. For the task of\ncapturing temporal structure in video, however, there still remain numerous\nopen research questions. Current research suggests using a simple temporal\nfeature pooling strategy to take into account the temporal aspect of video. We\ndemonstrate that this method is not sufficient for gesture recognition, where\ntemporal information is more discriminative compared to general video\nclassification tasks. We explore deep architectures for gesture recognition in\nvideo and propose a new end-to-end trainable neural network architecture\nincorporating temporal convolutions and bidirectional recurrence. Our main\ncontributions are twofold; first, we show that recurrence is crucial for this\ntask; second, we show that adding temporal convolutions leads to significant\nimprovements. We evaluate the different approaches on the Montalbano gesture\nrecognition dataset, where we achieve state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 13:43:01 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2015 16:20:26 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2016 16:50:29 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Pigou", "Lionel", ""], ["Oord", "A\u00e4ron van den", ""], ["Dieleman", "Sander", ""], ["Van Herreweghe", "Mieke", ""], ["Dambre", "Joni", ""]]}, {"id": "1506.02078", "submitter": "Andrej Karpathy", "authors": "Andrej Karpathy, Justin Johnson, Li Fei-Fei", "title": "Visualizing and Understanding Recurrent Networks", "comments": "changing style, adding references, minor changes to text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs), and specifically a variant with Long\nShort-Term Memory (LSTM), are enjoying renewed interest as a result of\nsuccessful applications in a wide range of machine learning problems that\ninvolve sequential data. However, while LSTMs provide exceptional results in\npractice, the source of their performance and their limitations remain rather\npoorly understood. Using character-level language models as an interpretable\ntestbed, we aim to bridge this gap by providing an analysis of their\nrepresentations, predictions and error types. In particular, our experiments\nreveal the existence of interpretable cells that keep track of long-range\ndependencies such as line lengths, quotes and brackets. Moreover, our\ncomparative analysis with finite horizon n-gram models traces the source of the\nLSTM improvements to long-range structural dependencies. Finally, we provide\nanalysis of the remaining errors and suggests areas for further study.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2015 22:33:04 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2015 02:42:24 GMT"}], "update_date": "2015-11-18", "authors_parsed": [["Karpathy", "Andrej", ""], ["Johnson", "Justin", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1506.02256", "submitter": "Zhiyuan Tang", "authors": "Zhiyuan Tang, Dong Wang, Yiqiao Pan, Zhiyong Zhang", "title": "Knowledge Transfer Pre-training", "comments": "arXiv admin note: text overlap with arXiv:1505.04630", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-training is crucial for learning deep neural networks. Most of existing\npre-training methods train simple models (e.g., restricted Boltzmann machines)\nand then stack them layer by layer to form the deep structure. This layer-wise\npre-training has found strong theoretical foundation and broad empirical\nsupport. However, it is not easy to employ such method to pre-train models\nwithout a clear multi-layer structure,e.g., recurrent neural networks (RNNs).\nThis paper presents a new pre-training approach based on knowledge transfer\nlearning. In contrast to the layer-wise approach which trains model components\nincrementally, the new approach trains the entire model as a whole but with an\neasier objective function. This is achieved by utilizing soft targets produced\nby a prior trained model (teacher model). Compared to the conventional\nlayer-wise methods, this new method does not care about the model structure, so\ncan be used to pre-train very complex models. Experiments on a speech\nrecognition task demonstrated that with this approach, complex RNNs can be well\ntrained with a weaker deep neural network (DNN) model. Furthermore, the new\nmethod can be combined with conventional layer-wise pre-training to deliver\nadditional gains.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2015 11:55:33 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Tang", "Zhiyuan", ""], ["Wang", "Dong", ""], ["Pan", "Yiqiao", ""], ["Zhang", "Zhiyong", ""]]}, {"id": "1506.02327", "submitter": "Cheng-Tao Chung", "authors": "Cheng-Tao Chung, Cheng-Yu Tsai, Hsiang-Hung Lu, Yuan-ming Liou,\n  Yen-Chen Wu, Yen-Ju Lu, Hung-yi Lee and Lin-shan Lee", "title": "A Multi-layered Acoustic Tokenizing Deep Neural Network (MAT-DNN) for\n  Unsupervised Discovery of Linguistic Units and Generation of High Quality\n  Features", "comments": "submitted to Interspeech 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes the work done by the authors for the Zero Resource\nSpeech Challenge organized in the technical program of Interspeech 2015. The\ngoal of the challenge is to discover linguistic units directly from unlabeled\nspeech data. The Multi-layered Acoustic Tokenizer (MAT) proposed in this work\nautomatically discovers multiple sets of acoustic tokens from the given corpus.\nEach acoustic token set is specified by a set of hyperparameters that describe\nthe model configuration. These sets of acoustic tokens carry different\ncharacteristics of the given corpus and the language behind thus can be\nmutually reinforced. The multiple sets of token labels are then used as the\ntargets of a Multi-target DNN (MDNN) trained on low-level acoustic features.\nBottleneck features extracted from the MDNN are used as feedback for the MAT\nand the MDNN itself. We call this iterative system the Multi-layered Acoustic\nTokenizing Deep Neural Network (MAT-DNN) which generates high quality features\nfor track 1 of the challenge and acoustic tokens for track 2 of the challenge.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2015 23:52:54 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Chung", "Cheng-Tao", ""], ["Tsai", "Cheng-Yu", ""], ["Lu", "Hsiang-Hung", ""], ["Liou", "Yuan-ming", ""], ["Wu", "Yen-Chen", ""], ["Lu", "Yen-Ju", ""], ["Lee", "Hung-yi", ""], ["Lee", "Lin-shan", ""]]}, {"id": "1506.02351", "submitter": "Junbo Zhao", "authors": "Junbo Zhao, Michael Mathieu, Ross Goroshin, Yann LeCun", "title": "Stacked What-Where Auto-encoders", "comments": "Workshop track - ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel architecture, the \"stacked what-where auto-encoders\"\n(SWWAE), which integrates discriminative and generative pathways and provides a\nunified approach to supervised, semi-supervised and unsupervised learning\nwithout relying on sampling during training. An instantiation of SWWAE uses a\nconvolutional net (Convnet) (LeCun et al. (1998)) to encode the input, and\nemploys a deconvolutional net (Deconvnet) (Zeiler et al. (2010)) to produce the\nreconstruction. The objective function includes reconstruction terms that\ninduce the hidden states in the Deconvnet to be similar to those of the\nConvnet. Each pooling layer produces two sets of variables: the \"what\" which\nare fed to the next layer, and its complementary variable \"where\" that are fed\nto the corresponding layer in the generative decoder.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 04:45:33 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2015 02:38:59 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2015 02:59:39 GMT"}, {"version": "v4", "created": "Sat, 4 Jul 2015 23:36:39 GMT"}, {"version": "v5", "created": "Wed, 11 Nov 2015 04:06:00 GMT"}, {"version": "v6", "created": "Sun, 15 Nov 2015 00:23:14 GMT"}, {"version": "v7", "created": "Tue, 17 Nov 2015 20:36:18 GMT"}, {"version": "v8", "created": "Sun, 14 Feb 2016 21:09:22 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Zhao", "Junbo", ""], ["Mathieu", "Michael", ""], ["Goroshin", "Ross", ""], ["LeCun", "Yann", ""]]}, {"id": "1506.02361", "submitter": "Marie Doumic Jauffret", "authors": "Julien Chevallier (JAD), Maria J. Caceres, Marie Doumic (LJLL, MAMBA),\n  Patricia Reynaud-Bouret (JAD)", "title": "Microscopic approach of a time elapsed neural model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spike trains are the main components of the information processing in the\nbrain. To model spike trains several point processes have been investigated in\nthe literature. And more macroscopic approaches have also been studied, using\npartial differential equation models. The main aim of the present article is to\nbuild a bridge between several point processes models (Poisson, Wold, Hawkes)\nthat have been proved to statistically fit real spike trains data and\nage-structured partial differential equations as introduced by Pakdaman,\nPerthame and Salort.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 06:41:37 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Chevallier", "Julien", "", "JAD"], ["Caceres", "Maria J.", "", "LJLL, MAMBA"], ["Doumic", "Marie", "", "LJLL, MAMBA"], ["Reynaud-Bouret", "Patricia", "", "JAD"]]}, {"id": "1506.02516", "submitter": "Edward Grefenstette", "authors": "Edward Grefenstette, Karl Moritz Hermann, Mustafa Suleyman, Phil\n  Blunsom", "title": "Learning to Transduce with Unbounded Memory", "comments": "14 pages, 4 figures, NIPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, strong results have been demonstrated by Deep Recurrent Neural\nNetworks on natural language transduction problems. In this paper we explore\nthe representational power of these models using synthetic grammars designed to\nexhibit phenomena similar to those found in real transduction problems such as\nmachine translation. These experiments lead us to propose new memory-based\nrecurrent networks that implement continuously differentiable analogues of\ntraditional data structures such as Stacks, Queues, and DeQues. We show that\nthese architectures exhibit superior generalisation performance to Deep RNNs\nand are often able to learn the underlying generating algorithms in our\ntransduction experiments.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 14:23:30 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2015 16:24:40 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2015 14:07:29 GMT"}], "update_date": "2015-11-04", "authors_parsed": [["Grefenstette", "Edward", ""], ["Hermann", "Karl Moritz", ""], ["Suleyman", "Mustafa", ""], ["Blunsom", "Phil", ""]]}, {"id": "1506.02617", "submitter": "Behnam Neyshabur", "authors": "Behnam Neyshabur, Ruslan Salakhutdinov, Nathan Srebro", "title": "Path-SGD: Path-Normalized Optimization in Deep Neural Networks", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the choice of SGD for training deep neural networks by\nreconsidering the appropriate geometry in which to optimize the weights. We\nargue for a geometry invariant to rescaling of weights that does not affect the\noutput of the network, and suggest Path-SGD, which is an approximate steepest\ndescent method with respect to a path-wise regularizer related to max-norm\nregularization. Path-SGD is easy and efficient to implement and leads to\nempirical gains over SGD and AdaGrad.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 19:01:33 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Neyshabur", "Behnam", ""], ["Salakhutdinov", "Ruslan", ""], ["Srebro", "Nathan", ""]]}, {"id": "1506.02626", "submitter": "Song Han", "authors": "Song Han, Jeff Pool, John Tran, William J. Dally", "title": "Learning both Weights and Connections for Efficient Neural Networks", "comments": "Published as a conference paper at NIPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are both computationally intensive and memory intensive,\nmaking them difficult to deploy on embedded systems. Also, conventional\nnetworks fix the architecture before training starts; as a result, training\ncannot improve the architecture. To address these limitations, we describe a\nmethod to reduce the storage and computation required by neural networks by an\norder of magnitude without affecting their accuracy by learning only the\nimportant connections. Our method prunes redundant connections using a\nthree-step method. First, we train the network to learn which connections are\nimportant. Next, we prune the unimportant connections. Finally, we retrain the\nnetwork to fine tune the weights of the remaining connections. On the ImageNet\ndataset, our method reduced the number of parameters of AlexNet by a factor of\n9x, from 61 million to 6.7 million, without incurring accuracy loss. Similar\nexperiments with VGG-16 found that the number of parameters can be reduced by\n13x, from 138 million to 10.3 million, again with no loss of accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 19:28:43 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2015 22:27:31 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2015 23:29:27 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Han", "Song", ""], ["Pool", "Jeff", ""], ["Tran", "John", ""], ["Dally", "William J.", ""]]}, {"id": "1506.02690", "submitter": "Zhiguang Wang", "authors": "Zhiguang Wang, Tim Oates, James Lo", "title": "Adaptive Normalized Risk-Averting Training For Deep Neural Networks", "comments": "AAAI 2016, 0.39%~0.4% ER on MNIST with single 32-32-256-10 ConvNets,\n  code available at https://github.com/cauchyturing/ANRAE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a set of new error criteria and learning approaches,\nAdaptive Normalized Risk-Averting Training (ANRAT), to attack the non-convex\noptimization problem in training deep neural networks (DNNs). Theoretically, we\ndemonstrate its effectiveness on global and local convexity lower-bounded by\nthe standard $L_p$-norm error. By analyzing the gradient on the convexity index\n$\\lambda$, we explain the reason why to learn $\\lambda$ adaptively using\ngradient descent works. In practice, we show how this method improves training\nof deep neural networks to solve visual recognition tasks on the MNIST and\nCIFAR-10 datasets. Without using pretraining or other tricks, we obtain results\ncomparable or superior to those reported in recent literature on the same tasks\nusing standard ConvNets + MSE/cross entropy. Performance on deep/shallow\nmultilayer perceptrons and Denoised Auto-encoders is also explored. ANRAT can\nbe combined with other quasi-Newton training methods, innovative network\nvariants, regularization techniques and other specific tricks in DNNs. Other\nthan unsupervised pretraining, it provides a new perspective to address the\nnon-convex optimization problem in DNNs.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 20:42:12 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2015 14:53:46 GMT"}, {"version": "v3", "created": "Thu, 9 Jun 2016 04:10:22 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Wang", "Zhiguang", ""], ["Oates", "Tim", ""], ["Lo", "James", ""]]}, {"id": "1506.02750", "submitter": "C\\'esar A. Astudillo", "authors": "C\\'esar A. Astudillo and B. John Oommen", "title": "Self Organizing Maps Whose Topologies Can Be Learned With Adaptive\n  Binary Search Trees Using Conditional Rotations", "comments": null, "journal-ref": "C\\'esar A. Astudillo and B. John Oommen. Self Organizing Maps\n  Whose Topologies Can Be Learned With Adaptive Binary Search Trees Using\n  Conditional Rotations. Pattern Recognition, 47(1), 2014", "doi": "10.1016/j.patcog.2013.04.012", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous variants of Self-Organizing Maps (SOMs) have been proposed in the\nliterature, including those which also possess an underlying structure, and in\nsome cases, this structure itself can be defined by the user Although the\nconcepts of growing the SOM and updating it have been studied, the whole issue\nof using a self-organizing Adaptive Data Structure (ADS) to further enhance the\nproperties of the underlying SOM, has been unexplored. In an earlier work, we\nimpose an arbitrary, user-defined, tree-like topology onto the codebooks, which\nconsequently enforced a neighborhood phenomenon and the so-called tree-based\nBubble of Activity. In this paper, we consider how the underlying tree itself\ncan be rendered dynamic and adaptively transformed. To do this, we present\nmethods by which a SOM with an underlying Binary Search Tree (BST) structure\ncan be adaptively re-structured using Conditional Rotations (CONROT). These\nrotations on the nodes of the tree are local, can be done in constant time, and\nperformed so as to decrease the Weighted Path Length (WPL) of the entire tree.\nIn doing this, we introduce the pioneering concept referred to as Neural\nPromotion, where neurons gain prominence in the Neural Network (NN) as their\nsignificance increases. We are not aware of any research which deals with the\nissue of Neural Promotion. The advantages of such a scheme is that the user\nneed not be aware of any of the topological peculiarities of the stochastic\ndata distribution. Rather, the algorithm, referred to as the TTOSOM with\nConditional Rotations (TTOCONROT), converges in such a manner that the neurons\nare ultimately placed in the input space so as to represent its stochastic\ndistribution, and additionally, the neighborhood properties of the neurons suit\nthe best BST that represents the data. These properties have been confirmed by\nour experimental results on a variety of data sets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 02:29:57 GMT"}], "update_date": "2015-06-10", "authors_parsed": [["Astudillo", "C\u00e9sar A.", ""], ["Oommen", "B. John", ""]]}, {"id": "1506.02753", "submitter": "Alexey Dosovitskiy", "authors": "Alexey Dosovitskiy and Thomas Brox", "title": "Inverting Visual Representations with Convolutional Networks", "comments": "Version 4 - final version to appear in CVPR-2016. Visually better\n  results obtained with feature similarity and adversarial training are in a\n  different paper - arXiv:1602.02644", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature representations, both hand-designed and learned ones, are often hard\nto analyze and interpret, even when they are extracted from visual data. We\npropose a new approach to study image representations by inverting them with an\nup-convolutional neural network. We apply the method to shallow representations\n(HOG, SIFT, LBP), as well as to deep networks. For shallow representations our\napproach provides significantly better reconstructions than existing methods,\nrevealing that there is surprisingly rich information contained in these\nfeatures. Inverting a deep network trained on ImageNet provides several\ninsights into the properties of the feature representation learned by the\nnetwork. Most strikingly, the colors and the rough contours of an image can be\nreconstructed from activations in higher network layers and even from the\npredicted class probabilities.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 02:31:40 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 16:35:56 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2015 18:18:57 GMT"}, {"version": "v4", "created": "Tue, 26 Apr 2016 23:30:11 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Dosovitskiy", "Alexey", ""], ["Brox", "Thomas", ""]]}, {"id": "1506.02914", "submitter": "Eric Tramel", "authors": "Marylou Gabri\\'e and Eric W. Tramel and Florent Krzakala", "title": "Training Restricted Boltzmann Machines via the Thouless-Anderson-Palmer\n  Free Energy", "comments": "8 pages, 7 figures, demo online at\n  http://www.lps.ens.fr/~krzakala/WASP.html", "journal-ref": "Advances in Neural Information Processing Systems (NIPS 2015) 28,\n  pages 640--648", "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann machines are undirected neural networks which have been\nshown to be effective in many applications, including serving as\ninitializations for training deep multi-layer neural networks. One of the main\nreasons for their success is the existence of efficient and practical\nstochastic algorithms, such as contrastive divergence, for unsupervised\ntraining. We propose an alternative deterministic iterative procedure based on\nan improved mean field method from statistical physics known as the\nThouless-Anderson-Palmer approach. We demonstrate that our algorithm provides\nperformance equal to, and sometimes superior to, persistent contrastive\ndivergence, while also providing a clear and easy to evaluate objective\nfunction. We believe that this strategy can be easily generalized to other\nmodels as well as to more accurate higher-order approximations, paving the way\nfor systematic improvements in training Boltzmann machines with hidden units.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 14:02:02 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2015 08:30:06 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Gabri\u00e9", "Marylou", ""], ["Tramel", "Eric W.", ""], ["Krzakala", "Florent", ""]]}, {"id": "1506.03059", "submitter": "Nadav Cohen", "authors": "Nadav Cohen, Or Sharir and Amnon Shashua", "title": "Deep SimNets", "comments": null, "journal-ref": "The IEEE Conference on Computer Vision and Pattern Recognition\n  (CVPR), 2016, pp. 4782-4791", "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep layered architecture that generalizes convolutional neural\nnetworks (ConvNets). The architecture, called SimNets, is driven by two\noperators: (i) a similarity function that generalizes inner-product, and (ii) a\nlog-mean-exp function called MEX that generalizes maximum and average. The two\noperators applied in succession give rise to a standard neuron but in \"feature\nspace\". The feature spaces realized by SimNets depend on the choice of the\nsimilarity operator. The simplest setting, which corresponds to a convolution,\nrealizes the feature space of the Exponential kernel, while other settings\nrealize feature spaces of more powerful kernels (Generalized Gaussian, which\nincludes as special cases RBF and Laplacian), or even dynamically learned\nfeature spaces (Generalized Multiple Kernel Learning). As a result, the SimNet\ncontains a higher abstraction level compared to a traditional ConvNet. We argue\nthat enhanced expressiveness is important when the networks are small due to\nrun-time constraints (such as those imposed by mobile applications). Empirical\nevaluation validates the superior expressiveness of SimNets, showing a\nsignificant gain in accuracy over ConvNets when computational resources at\nrun-time are limited. We also show that in large-scale settings, where\ncomputational complexity is less of a concern, the additional capacity of\nSimNets can be controlled with proper regularization, yielding accuracies\ncomparable to state of the art ConvNets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 19:40:05 GMT"}, {"version": "v2", "created": "Tue, 29 Mar 2016 14:30:45 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Cohen", "Nadav", ""], ["Sharir", "Or", ""], ["Shashua", "Amnon", ""]]}, {"id": "1506.03134", "submitter": "Oriol Vinyals", "authors": "Oriol Vinyals, Meire Fortunato, Navdeep Jaitly", "title": "Pointer Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CG cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new neural architecture to learn the conditional probability\nof an output sequence with elements that are discrete tokens corresponding to\npositions in an input sequence. Such problems cannot be trivially addressed by\nexistent approaches such as sequence-to-sequence and Neural Turing Machines,\nbecause the number of target classes in each step of the output depends on the\nlength of the input, which is variable. Problems such as sorting variable sized\nsequences, and various combinatorial optimization problems belong to this\nclass. Our model solves the problem of variable size output dictionaries using\na recently proposed mechanism of neural attention. It differs from the previous\nattention attempts in that, instead of using attention to blend hidden units of\nan encoder to a context vector at each decoder step, it uses attention as a\npointer to select a member of the input sequence as the output. We call this\narchitecture a Pointer Net (Ptr-Net). We show Ptr-Nets can be used to learn\napproximate solutions to three challenging geometric problems -- finding planar\nconvex hulls, computing Delaunay triangulations, and the planar Travelling\nSalesman Problem -- using training examples alone. Ptr-Nets not only improve\nover sequence-to-sequence with input attention, but also allow us to generalize\nto variable size output dictionaries. We show that the learnt models generalize\nbeyond the maximum lengths they were trained on. We hope our results on these\ntasks will encourage a broader exploration of neural learning for discrete\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 23:38:16 GMT"}, {"version": "v2", "created": "Mon, 2 Jan 2017 10:25:29 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Vinyals", "Oriol", ""], ["Fortunato", "Meire", ""], ["Jaitly", "Navdeep", ""]]}, {"id": "1506.03172", "submitter": "Manoj Gopalkrishnan", "authors": "Manoj Gopalkrishnan", "title": "A Scheme for Molecular Computation of Maximum Likelihood Estimators for\n  Log-Linear Models", "comments": "13 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.ST q-bio.MN stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel molecular computing scheme for statistical inference. We\nfocus on the much-studied statistical inference problem of computing maximum\nlikelihood estimators for log-linear models. Our scheme takes log-linear models\nto reaction systems, and the observed data to initial conditions, so that the\ncorresponding equilibrium of each reaction system encodes the corresponding\nmaximum likelihood estimator. The main idea is to exploit the coincidence\nbetween thermodynamic entropy and statistical entropy. We map a Maximum Entropy\ncharacterization of the maximum likelihood estimator onto a Maximum Entropy\ncharacterization of the equilibrium concentrations for the reaction system.\nThis allows for an efficient encoding of the problem, and reveals that reaction\nnetworks are superbly suited to statistical inference tasks. Such a scheme may\nalso provide a template to understanding how in vivo biochemical signaling\npathways integrate extensive information about their environment and history.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 05:34:40 GMT"}, {"version": "v2", "created": "Fri, 10 Jun 2016 11:45:50 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Gopalkrishnan", "Manoj", ""]]}, {"id": "1506.03264", "submitter": "Giacomo Indiveri", "authors": "Giacomo Indiveri and Shih-Chii Liu", "title": "Memory and information processing in neuromorphic systems", "comments": "Submitted to Proceedings of IEEE, review of recently proposed\n  neuromorphic computing platforms and systems", "journal-ref": "Proceedings of the IEEE, Vol 13, No. 8, (2015), pg. 1379 - 1397", "doi": "10.1109/JPROC.2015.2444094", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A striking difference between brain-inspired neuromorphic processors and\ncurrent von Neumann processors architectures is the way in which memory and\nprocessing is organized. As Information and Communication Technologies continue\nto address the need for increased computational power through the increase of\ncores within a digital processor, neuromorphic engineers and scientists can\ncomplement this need by building processor architectures where memory is\ndistributed with the processing. In this paper we present a survey of\nbrain-inspired processor architectures that support models of cortical networks\nand deep neural networks. These architectures range from serial clocked\nimplementations of multi-neuron systems to massively parallel asynchronous ones\nand from purely digital systems to mixed analog/digital systems which implement\nmore biological-like models of neurons and synapses together with a suite of\nadaptation and learning mechanisms analogous to the ones found in biological\nnervous systems. We describe the advantages of the different approaches being\npursued and present the challenges that need to be addressed for building\nartificial neural processing systems that can display the richness of behaviors\nseen in biological systems.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 11:42:28 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Indiveri", "Giacomo", ""], ["Liu", "Shih-Chii", ""]]}, {"id": "1506.03340", "submitter": "Karl Moritz Hermann", "authors": "Karl Moritz Hermann, Tom\\'a\\v{s} Ko\\v{c}isk\\'y, Edward Grefenstette,\n  Lasse Espeholt, Will Kay, Mustafa Suleyman and Phil Blunsom", "title": "Teaching Machines to Read and Comprehend", "comments": "Appears in: Advances in Neural Information Processing Systems 28\n  (NIPS 2015). 14 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teaching machines to read natural language documents remains an elusive\nchallenge. Machine reading systems can be tested on their ability to answer\nquestions posed on the contents of documents that they have seen, but until now\nlarge scale training and test datasets have been missing for this type of\nevaluation. In this work we define a new methodology that resolves this\nbottleneck and provides large scale supervised reading comprehension data. This\nallows us to develop a class of attention based deep neural networks that learn\nto read real documents and answer complex questions with minimal prior\nknowledge of language structure.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 14:54:39 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2015 15:04:49 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2015 15:43:23 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Hermann", "Karl Moritz", ""], ["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Grefenstette", "Edward", ""], ["Espeholt", "Lasse", ""], ["Kay", "Will", ""], ["Suleyman", "Mustafa", ""], ["Blunsom", "Phil", ""]]}, {"id": "1506.03412", "submitter": "Vamsi Ithapu", "authors": "Vamsi K. Ithapu, Sathya Ravi, Vikas Singh", "title": "Convergence rates for pretraining and dropout: Guiding learning\n  parameters using network structure", "comments": "This manuscript is now superseded by arXiv:1511.05297 and the\n  corresponding accepted paper in 54th Allerton Conference on Communication,\n  Control and Computing (2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised pretraining and dropout have been well studied, especially with\nrespect to regularization and output consistency. However, our understanding\nabout the explicit convergence rates of the parameter estimates, and their\ndependence on the learning (like denoising and dropout rate) and structural\n(like depth and layer lengths) aspects of the network is less mature. An\ninteresting question in this context is to ask if the network structure could\n\"guide\" the choices of such learning parameters. In this work, we explore these\ngaps between network structure, the learning mechanisms and their interaction\nwith parameter convergence rates. We present a way to address these issues\nbased on the backpropagation convergence rates for general nonconvex objectives\nusing first-order information. We then incorporate two learning mechanisms into\nthis general framework -- denoising autoencoder and dropout, and subsequently\nderive the convergence rates of deep networks. Building upon these bounds, we\nprovide insights into the choices of learning parameters and network sizes that\nachieve certain levels of convergence accuracy. The results derived here\nsupport existing empirical observations, and we also conduct a set of\nexperiments to evaluate them.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 17:59:57 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2015 04:52:53 GMT"}, {"version": "v3", "created": "Wed, 22 Feb 2017 17:32:07 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Ithapu", "Vamsi K.", ""], ["Ravi", "Sathya", ""], ["Singh", "Vikas", ""]]}, {"id": "1506.03599", "submitter": "Sakyasingha Dasgupta", "authors": "Sakyasingha Dasgupta and Dennis Goldschmidt and Florentin\n  W\\\"org\\\"otter and Poramate Manoonpong", "title": "Distributed Recurrent Neural Forward Models with Synaptic Adaptation for\n  Complex Behaviors of Walking Robots", "comments": "26 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.RO q-bio.NC", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Walking animals, like stick insects, cockroaches or ants, demonstrate a\nfascinating range of locomotive abilities and complex behaviors. The locomotive\nbehaviors can consist of a variety of walking patterns along with adaptation\nthat allow the animals to deal with changes in environmental conditions, like\nuneven terrains, gaps, obstacles etc. Biological study has revealed that such\ncomplex behaviors are a result of a combination of biome- chanics and neural\nmechanism thus representing the true nature of embodied interactions. While the\nbiomechanics helps maintain flexibility and sustain a variety of movements, the\nneural mechanisms generate movements while making appropriate predictions\ncrucial for achieving adaptation. Such predictions or planning ahead can be\nachieved by way of in- ternal models that are grounded in the overall behavior\nof the animal. Inspired by these findings, we present here, an artificial\nbio-inspired walking system which effectively com- bines biomechanics (in terms\nof the body and leg structures) with the underlying neural mechanisms. The\nneural mechanisms consist of 1) central pattern generator based control for\ngenerating basic rhythmic patterns and coordinated movements, 2) distributed\n(at each leg) recurrent neural network based adaptive forward models with\nefference copies as internal models for sensory predictions and instantaneous\nstate estimations, and 3) searching and elevation control for adapting the\nmovement of an individual leg to deal with different environmental conditions.\nUsing simulations we show that this bio-inspired approach with adaptive\ninternal models allows the walking robot to perform complex loco- motive\nbehaviors as observed in insects, including walking on undulated terrains,\ncrossing large gaps as well as climbing over high obstacles...\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 09:30:09 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Dasgupta", "Sakyasingha", ""], ["Goldschmidt", "Dennis", ""], ["W\u00f6rg\u00f6tter", "Florentin", ""], ["Manoonpong", "Poramate", ""]]}, {"id": "1506.03899", "submitter": "Yiyi Liao", "authors": "Yiyi Liao, Sarath Kodagoda, Yue Wang, Lei Shi, Yong Liu", "title": "Place classification with a graph regularized deep neural network model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Place classification is a fundamental ability that a robot should possess to\ncarry out effective human-robot interactions. It is a nontrivial classification\nproblem which has attracted many research. In recent years, there is a high\nexploitation of Artificial Intelligent algorithms in robotics applications.\nInspired by the recent successes of deep learning methods, we propose an\nend-to-end learning approach for the place classification problem. With the\ndeep architectures, this methodology automatically discovers features and\ncontributes in general to higher classification accuracies. The pipeline of our\napproach is composed of three parts. Firstly, we construct multiple layers of\nlaser range data to represent the environment information in different levels\nof granularity. Secondly, each layer of data is fed into a deep neural network\nmodel for classification, where a graph regularization is imposed to the deep\narchitecture for keeping local consistency between adjacent samples. Finally,\nthe predicted labels obtained from all the layers are fused based on confidence\ntrees to maximize the overall confidence. Experimental results validate the\neffective- ness of our end-to-end place classification framework in which both\nthe multi-layer structure and the graph regularization promote the\nclassification performance. Furthermore, results show that the features\nautomatically learned from the raw input range data can achieve competitive\nresults to the features constructed based on statistical and geometrical\ninformation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 05:45:36 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Liao", "Yiyi", ""], ["Kodagoda", "Sarath", ""], ["Wang", "Yue", ""], ["Shi", "Lei", ""], ["Liu", "Yong", ""]]}, {"id": "1506.04002", "submitter": "Mahshid Majd", "authors": "Farzaneh Shoeleh, Mahshid Majd, Ali Hamzeh, Sattar Hashemi", "title": "Knowledge Representation in Learning Classifier Systems: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge representation is a key component to the success of all rule based\nsystems including learning classifier systems (LCSs). This component brings\ninsight into how to partition the problem space what in turn seeks prominent\nrole in generalization capacity of the system as a whole. Recently, knowledge\nrepresentation component has received great deal of attention within data\nmining communities due to its impacts on rule based systems in terms of\nefficiency and efficacy. The current work is an attempt to find a comprehensive\nand yet elaborate view into the existing knowledge representation techniques in\nLCS domain in general and XCS in specific. To achieve the objectives, knowledge\nrepresentation techniques are grouped into different categories based on the\nclassification approach in which they are incorporated. In each category, the\nunderlying rule representation schema and the format of classifier condition to\nsupport the corresponding representation are presented. Furthermore, a precise\nexplanation on the way that each technique partitions the problem space along\nwith the extensive experimental results is provided. To have an elaborated view\non the functionality of each technique, a comparative analysis of existing\ntechniques on some conventional problems is provided. We expect this survey to\nbe of interest to the LCS researchers and practitioners since it provides a\nguideline for choosing a proper knowledge representation technique for a given\nproblem and also opens up new streams of research on this topic.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 12:29:31 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Shoeleh", "Farzaneh", ""], ["Majd", "Mahshid", ""], ["Hamzeh", "Ali", ""], ["Hashemi", "Sattar", ""]]}, {"id": "1506.04089", "submitter": "Hongyuan Mei", "authors": "Hongyuan Mei, Mohit Bansal, Matthew R. Walter", "title": "Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to\n  Action Sequences", "comments": "To appear at AAAI 2016 (and an extended version of a NIPS 2015\n  Multimodal Machine Learning workshop paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural sequence-to-sequence model for direction following, a\ntask that is essential to realizing effective autonomous agents. Our\nalignment-based encoder-decoder model with long short-term memory recurrent\nneural networks (LSTM-RNN) translates natural language instructions to action\nsequences based upon a representation of the observable world state. We\nintroduce a multi-level aligner that empowers our model to focus on sentence\n\"regions\" salient to the current world state by using multiple abstractions of\nthe input sentence. In contrast to existing methods, our model uses no\nspecialized linguistic resources (e.g., parsers) or task-specific annotations\n(e.g., seed lexicons). It is therefore generalizable, yet still achieves the\nbest results reported to-date on a benchmark single-sentence dataset and\ncompetitive results for the limited-training multi-sentence setting. We analyze\nour model through a series of ablations that elucidate the contributions of the\nprimary components of our model.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 18:05:00 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2015 19:22:33 GMT"}, {"version": "v3", "created": "Wed, 2 Dec 2015 20:46:09 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2015 17:57:42 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["Mei", "Hongyuan", ""], ["Bansal", "Mohit", ""], ["Walter", "Matthew R.", ""]]}, {"id": "1506.04449", "submitter": "Wenlin Chen", "authors": "Wenlin Chen, James T. Wilson, Stephen Tyree, Kilian Q. Weinberger,\n  Yixin Chen", "title": "Compressing Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNN) are increasingly used in many areas of\ncomputer vision. They are particularly attractive because of their ability to\n\"absorb\" great quantities of labeled data through millions of parameters.\nHowever, as model sizes increase, so do the storage and memory requirements of\nthe classifiers. We present a novel network architecture, Frequency-Sensitive\nHashed Nets (FreshNets), which exploits inherent redundancy in both\nconvolutional layers and fully-connected layers of a deep learning model,\nleading to dramatic savings in memory and storage consumption. Based on the key\nobservation that the weights of learned convolutional filters are typically\nsmooth and low-frequency, we first convert filter weights to the frequency\ndomain with a discrete cosine transform (DCT) and use a low-cost hash function\nto randomly group frequency parameters into hash buckets. All parameters\nassigned the same hash bucket share a single value learned with standard\nback-propagation. To further reduce model size we allocate fewer hash buckets\nto high-frequency components, which are generally less important. We evaluate\nFreshNets on eight data sets, and show that it leads to drastically better\ncompressed performance than several relevant baselines.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2015 23:16:40 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Chen", "Wenlin", ""], ["Wilson", "James T.", ""], ["Tyree", "Stephen", ""], ["Weinberger", "Kilian Q.", ""], ["Chen", "Yixin", ""]]}, {"id": "1506.04891", "submitter": "Douglas Bagnall", "authors": "Douglas Bagnall", "title": "Author Identification using Multi-headed Recurrent Neural Networks", "comments": "8 pages, 3 figures Version 1 was a notebook for the PAN@CLEF Author\n  Identification challenge. Version 2 is expanded to be a full paper for\n  CLEF2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are very good at modelling the flow of text,\nbut typically need to be trained on a far larger corpus than is available for\nthe PAN 2015 Author Identification task. This paper describes a novel approach\nwhere the output layer of a character-level RNN language model is split into\nseveral independent predictive sub-models, each representing an author, while\nthe recurrent layer is shared by all. This allows the recurrent layer to model\nthe language as a whole without over-fitting, while the outputs select aspects\nof the underlying model that reflect their author's style. The method proves\ncompetitive, ranking first in two of the four languages.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 09:41:55 GMT"}, {"version": "v2", "created": "Tue, 16 Aug 2016 05:04:57 GMT"}], "update_date": "2016-08-17", "authors_parsed": [["Bagnall", "Douglas", ""]]}, {"id": "1506.05082", "submitter": "No\\'e Casas", "authors": "Noe Casas", "title": "A review of landmark articles in the field of co-evolutionary computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coevolution is a powerful tool in evolutionary computing that mitigates some\nof its endemic problems, namely stagnation in local optima and lack of\nconvergence in high dimensionality problems. Since its inception in 1990, there\nare multiple articles that have contributed greatly to the development and\nimprovement of the coevolutionary techniques. In this report we review some of\nthose landmark articles dwelving in the techniques they propose and how they\nfit to conform robust evolutionary algorithms\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 15:38:17 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2015 14:25:18 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Casas", "Noe", ""]]}, {"id": "1506.05163", "submitter": "Mikael Henaff", "authors": "Mikael Henaff, Joan Bruna, Yann LeCun", "title": "Deep Convolutional Networks on Graph-Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning's recent successes have mostly relied on Convolutional\nNetworks, which exploit fundamental statistical properties of images, sounds\nand video data: the local stationarity and multi-scale compositional structure,\nthat allows expressing long range interactions in terms of shorter, localized\ninteractions. However, there exist other important examples, such as text\ndocuments or bioinformatic data, that may lack some or all of these strong\nstatistical regularities.\n  In this paper we consider the general question of how to construct deep\narchitectures with small learning complexity on general non-Euclidean domains,\nwhich are typically unknown and need to be estimated from the data. In\nparticular, we develop an extension of Spectral Networks which incorporates a\nGraph Estimation procedure, that we test on large-scale classification\nproblems, matching or improving over Dropout Networks with far less parameters\nto estimate.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 22:31:09 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Henaff", "Mikael", ""], ["Bruna", "Joan", ""], ["LeCun", "Yann", ""]]}, {"id": "1506.05212", "submitter": "Subhrajit Roy", "authors": "Subhrajit Roy, Phyo Phyo San, Shaista Hussain, Lee Wang Wei and\n  Arindam Basu", "title": "Learning Spike time codes through Morphological Learning with Binary\n  Synapses", "comments": "6 pages, 4 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a neuron with nonlinear dendrites (NNLD) and binary synapses\nthat is able to learn temporal features of spike input patterns is considered.\nSince binary synapses are considered, learning happens through formation and\nelimination of connections between the inputs and the dendritic branches to\nmodify the structure or \"morphology\" of the NNLD. A morphological learning\nalgorithm inspired by the 'Tempotron', i.e., a recently proposed temporal\nlearning algorithm-is presented in this work. Unlike 'Tempotron', the proposed\nlearning rule uses a technique to automatically adapt the NNLD threshold during\ntraining. Experimental results indicate that our NNLD with 1-bit synapses can\nobtain similar accuracy as a traditional Tempotron with 4-bit synapses in\nclassifying single spike random latency and pair-wise synchrony patterns.\nHence, the proposed method is better suited for robust hardware implementation\nin the presence of statistical variations. We also present results of applying\nthis rule to real life spike classification problems from the field of tactile\nsensing.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 05:49:50 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Roy", "Subhrajit", ""], ["San", "Phyo Phyo", ""], ["Hussain", "Shaista", ""], ["Wei", "Lee Wang", ""], ["Basu", "Arindam", ""]]}, {"id": "1506.05424", "submitter": "Conrado Miranda", "authors": "Conrado Silva Miranda, Fernando Jos\\'e Von Zuben", "title": "Hybrid Algorithm for Multi-Objective Optimization by Greedy Hypervolume\n  Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a high-performance hybrid algorithm, called Hybrid\nHypervolume Maximization Algorithm (H2MA), for multi-objective optimization\nthat alternates between exploring the decision space and exploiting the already\nobtained non-dominated solutions. The proposal is centered on maximizing the\nhypervolume indicator, thus converting the multi-objective problem into a\nsingle-objective one. The exploitation employs gradient-based methods, but\nconsidering a single candidate efficient solution at a time, to overcome\nlimitations associated with population-based approaches and also to allow an\neasy control of the number of solutions provided. There is an interchange\nbetween two steps. The first step is a deterministic local exploration, endowed\nwith an automatic procedure to detect stagnation. When stagnation is detected,\nthe search is switched to a second step characterized by a stochastic global\nexploration using an evolutionary algorithm. Using five ZDT benchmarks with 30\nvariables, the performance of the new algorithm is compared to state-of-the-art\nalgorithms for multi-objective optimization, more specifically NSGA-II, SPEA2,\nand SMS-EMOA. The solutions found by the H2MA guide to higher hypervolume and\nsmaller distance to the true Pareto frontier with significantly less function\nevaluations, even when the gradient is estimated numerically. Furthermore,\nalthough only continuous decision spaces have been considered here, discrete\ndecision spaces could also have been treated, replacing gradient-based search\nby hill-climbing. Finally, a thorough explanation is provided to support the\nexpressive gain in performance that was achieved.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 18:52:18 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Miranda", "Conrado Silva", ""], ["Von Zuben", "Fernando Jos\u00e9", ""]]}, {"id": "1506.05427", "submitter": "Massimiliano Giulioni", "authors": "Massimiliano Giulioni, Federico Corradi, Vittorio Dante, Paolo del\n  Giudice", "title": "Real time unsupervised learning of visual stimuli in neuromorphic VLSI\n  systems", "comments": "submitted to Scientific Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic chips embody computational principles operating in the nervous\nsystem, into microelectronic devices. In this domain it is important to\nidentify computational primitives that theory and experiments suggest as\ngeneric and reusable cognitive elements. One such element is provided by\nattractor dynamics in recurrent networks. Point attractors are equilibrium\nstates of the dynamics (up to fluctuations), determined by the synaptic\nstructure of the network; a `basin' of attraction comprises all initial states\nleading to a given attractor upon relaxation, hence making attractor dynamics\nsuitable to implement robust associative memory. The initial network state is\ndictated by the stimulus, and relaxation to the attractor state implements the\nretrieval of the corresponding memorized prototypical pattern. In a previous\nwork we demonstrated that a neuromorphic recurrent network of spiking neurons\nand suitably chosen, fixed synapses supports attractor dynamics. Here we focus\non learning: activating on-chip synaptic plasticity and using a theory-driven\nstrategy for choosing network parameters, we show that autonomous learning,\nfollowing repeated presentation of simple visual stimuli, shapes a synaptic\nconnectivity supporting stimulus-selective attractors. Associative memory\ndevelops on chip as the result of the coupled stimulus-driven neural activity\nand ensuing synaptic dynamics, with no artificial separation between learning\nand retrieval phases.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 19:02:51 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Giulioni", "Massimiliano", ""], ["Corradi", "Federico", ""], ["Dante", "Vittorio", ""], ["del Giudice", "Paolo", ""]]}, {"id": "1506.05849", "submitter": "Xundong Wu", "authors": "Xundong Wu", "title": "An Iterative Convolutional Neural Network Algorithm Improves Electron\n  Microscopy Image Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  To build the connectomics map of the brain, we developed a new algorithm that\ncan automatically refine the Membrane Detection Probability Maps (MDPM)\ngenerated to perform automatic segmentation of electron microscopy (EM) images.\nTo achieve this, we executed supervised training of a convolutional neural\nnetwork to recover the removed center pixel label of patches sampled from a\nMDPM. MDPM can be generated from other machine learning based algorithms\nrecognizing whether a pixel in an image corresponds to the cell membrane. By\niteratively applying this network over MDPM for multiple rounds, we were able\nto significantly improve membrane segmentation results.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 23:11:40 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Wu", "Xundong", ""]]}, {"id": "1506.05913", "submitter": "Carola Doerr", "authors": "Benjamin Doerr, Carola Doerr, and Timo K\\\"otzing", "title": "Solving Problems with Unknown Solution Length at (Almost) No Extra Cost", "comments": "This is a preliminary version of a paper that is to appear at the\n  Genetic and Evolutionary Computation Conference (GECCO 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most research in the theory of evolutionary computation assumes that the\nproblem at hand has a fixed problem size. This assumption does not always apply\nto real-world optimization challenges, where the length of an optimal solution\nmay be unknown a priori.\n  Following up on previous work of Cathabard, Lehre, and Yao [FOGA 2011] we\nanalyze variants of the (1+1) evolutionary algorithm for problems with unknown\nsolution length. For their setting, in which the solution length is sampled\nfrom a geometric distribution, we provide mutation rates that yield an expected\noptimization time that is of the same order as that of the (1+1) EA knowing the\nsolution length.\n  We then show that almost the same run times can be achieved even if \\emph{no}\na priori information on the solution length is available.\n  Finally, we provide mutation rates suitable for settings in which neither the\nsolution length nor the positions of the relevant bits are known. Again we\nobtain almost optimal run times for the \\textsc{OneMax} and\n\\textsc{LeadingOnes} test functions, thus solving an open problem from\nCathabard et al.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 08:43:36 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Doerr", "Benjamin", ""], ["Doerr", "Carola", ""], ["K\u00f6tzing", "Timo", ""]]}, {"id": "1506.05937", "submitter": "Carola Doerr", "authors": "Benjamin Doerr and Carola Doerr", "title": "A Tight Runtime Analysis of the $(1+(\\lambda, \\lambda))$ Genetic\n  Algorithm on OneMax", "comments": "This is a preliminary version of a paper that is to appear at Genetic\n  and Evolutionary Computation Conference (GECCO 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how crossover works is still one of the big challenges in\nevolutionary computation research, and making our understanding precise and\nproven by mathematical means might be an even bigger one. As one of few\nexamples where crossover provably is useful, the $(1+(\\lambda, \\lambda))$\nGenetic Algorithm (GA) was proposed recently in [Doerr, Doerr, Ebel: TCS 2015].\nUsing the fitness level method, the expected optimization time on general\nOneMax functions was analyzed and a $O(\\max\\{n\\log(n)/\\lambda, \\lambda n\\})$\nbound was proven for any offspring population size $\\lambda \\in [1..n]$.\n  We improve this work in several ways, leading to sharper bounds and a better\nunderstanding of how the use of crossover speeds up the runtime in this\nalgorithm. We first improve the upper bound on the runtime to\n$O(\\max\\{n\\log(n)/\\lambda, n\\lambda \\log\\log(\\lambda)/\\log(\\lambda)\\})$. This\nimprovement is made possible from observing that in the parallel generation of\n$\\lambda$ offspring via crossover (but not mutation), the best of these often\nis better than the expected value, and hence several fitness levels can be\ngained in one iteration.\n  We then present the first lower bound for this problem. It matches our upper\nbound for all values of $\\lambda$. This allows to determine the asymptotically\noptimal value for the population size. It is $\\lambda =\n\\Theta(\\sqrt{\\log(n)\\log\\log(n)/\\log\\log\\log(n)})$, which gives an optimization\ntime of $\\Theta(n \\sqrt{\\log(n)\\log\\log\\log(n)/\\log\\log(n)})$. Hence the\nimproved runtime analysis gives a better runtime guarantee along with a better\nsuggestion for the parameter $\\lambda$.\n  We finally give a tail bound for the upper tail of the runtime distribution,\nwhich shows that the actual runtime exceeds our runtime guarantee by a factor\nof $(1+\\delta)$ with probability $O((n/\\lambda^2)^{-\\delta})$ only.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 09:51:43 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Doerr", "Benjamin", ""], ["Doerr", "Carola", ""]]}, {"id": "1506.06046", "submitter": "Poonam Yadav Dr", "authors": "Poonam Yadav", "title": "Face Prediction Model for an Automatic Age-invariant Face Recognition\n  System", "comments": "3 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Automated face recognition and identification softwares are becoming part of\nour daily life; it finds its abode not only with Facebook's auto photo tagging,\nApple's iPhoto, Google's Picasa, Microsoft's Kinect, but also in Homeland\nSecurity Department's dedicated biometric face detection systems. Most of these\nautomatic face identification systems fail where the effects of aging come into\nthe picture. Little work exists in the literature on the subject of face\nprediction that accounts for aging, which is a vital part of the computer face\nrecognition systems. In recent years, individual face components' (e.g. eyes,\nnose, mouth) features based matching algorithms have emerged, but these\napproaches are still not efficient. Therefore, in this work we describe a Face\nPrediction Model (FPM), which predicts human face aging or growth related image\nvariation using Principle Component Analysis (PCA) and Artificial Neural\nNetwork (ANN) learning techniques. The FPM captures the facial changes, which\noccur with human aging and predicts the facial image with a few years of gap\nwith an acceptable accuracy of face matching from 76 to 86%.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2015 12:26:21 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Yadav", "Poonam", ""]]}, {"id": "1506.06366", "submitter": "He-Wen Chen", "authors": "He-Wen Chen and Zih-Ci Wang and Shu-Yu Kuo and Yao-Hsin Chou", "title": "A Novel Method for Stock Forecasting based on Fuzzy Time Series Combined\n  with the Longest Common/Repeated Sub-sequence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stock price forecasting is an important issue for investors since extreme\naccuracy in forecasting can bring about high profits. Fuzzy Time Series (FTS)\nand Longest Common/Repeated Sub-sequence (LCS/LRS) are two important issues for\nforecasting prices. However, to the best of our knowledge, there are no\nsignificant studies using LCS/LRS to predict stock prices. It is impossible\nthat prices stay exactly the same as historic prices. Therefore, this paper\nproposes a state-of-the-art method which combines FTS and LCS/LRS to predict\nstock prices. This method is based on the principle that history will repeat\nitself. It uses different interval lengths in FTS to fuzzify the prices, and\nLCS/LRS to look for the same pattern in the historical prices to predict future\nstock prices. In the experiment, we examine various intervals of fuzzy time\nsets in order to achieve high prediction accuracy. The proposed method\noutperforms traditional methods in terms of prediction accuracy and,\nfurthermore, it is easy to implement.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2015 14:03:42 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Chen", "He-Wen", ""], ["Wang", "Zih-Ci", ""], ["Kuo", "Shu-Yu", ""], ["Chou", "Yao-Hsin", ""]]}, {"id": "1506.06442", "submitter": "Fandong Meng", "authors": "Fandong Meng, Zhengdong Lu, Zhaopeng Tu, Hang Li, and Qun Liu", "title": "A Deep Memory-based Architecture for Sequence-to-Sequence Learning", "comments": "13 pages, Under review as a conference paper at ICLR 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose DEEPMEMORY, a novel deep architecture for sequence-to-sequence\nlearning, which performs the task through a series of nonlinear transformations\nfrom the representation of the input sequence (e.g., a Chinese sentence) to the\nfinal output sequence (e.g., translation to English). Inspired by the recently\nproposed Neural Turing Machine (Graves et al., 2014), we store the intermediate\nrepresentations in stacked layers of memories, and use read-write operations on\nthe memories to realize the nonlinear transformations between the\nrepresentations. The types of transformations are designed in advance but the\nparameters are learned from data. Through layer-by-layer transformations,\nDEEPMEMORY can model complicated relations between sequences necessary for\napplications such as machine translation between distant languages. The\narchitecture can be trained with normal back-propagation on sequenceto-sequence\ndata, and the learning can be easily scaled up to a large corpus. DEEPMEMORY is\nbroad enough to subsume the state-of-the-art neural translation model in\n(Bahdanau et al., 2015) as its special case, while significantly improving upon\nthe model with its deeper architecture. Remarkably, DEEPMEMORY, being purely\nneural network-based, can achieve performance comparable to the traditional\nphrase-based machine translation system Moses with a small vocabulary and a\nmodest parameter size.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 02:12:54 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 13:55:44 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2015 14:23:34 GMT"}, {"version": "v4", "created": "Thu, 7 Jan 2016 08:14:08 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Meng", "Fandong", ""], ["Lu", "Zhengdong", ""], ["Tu", "Zhaopeng", ""], ["Li", "Hang", ""], ["Liu", "Qun", ""]]}, {"id": "1506.06472", "submitter": "Peter Sadowski", "authors": "Pierre Baldi and Peter Sadowski", "title": "A Theory of Local Learning, the Learning Channel, and the Optimality of\n  Backpropagation", "comments": null, "journal-ref": "Neural Networks, vol. 83, pp. 51-74, Nov. 2016", "doi": "10.1016/j.neunet.2016.07.006", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a physical neural system, where storage and processing are intimately\nintertwined, the rules for adjusting the synaptic weights can only depend on\nvariables that are available locally, such as the activity of the pre- and\npost-synaptic neurons, resulting in local learning rules. A systematic\nframework for studying the space of local learning rules is obtained by first\nspecifying the nature of the local variables, and then the functional form that\nties them together into each learning rule. Such a framework enables also the\nsystematic discovery of new learning rules and exploration of relationships\nbetween learning rules and group symmetries. We study polynomial local learning\nrules stratified by their degree and analyze their behavior and capabilities in\nboth linear and non-linear units and networks. Stacking local learning rules in\ndeep feedforward networks leads to deep local learning. While deep local\nlearning can learn interesting representations, it cannot learn complex\ninput-output functions, even when targets are available for the top layer.\nLearning complex input-output functions requires local deep learning where\ntarget information is communicated to the deep layers through a backward\nlearning channel. The nature of the communicated information about the targets\nand the structure of the learning channel partition the space of learning\nalgorithms. We estimate the learning channel capacity associated with several\nalgorithms and show that backpropagation outperforms them by simultaneously\nmaximizing the information rate and minimizing the computational cost, even in\nrecurrent networks. The theory clarifies the concept of Hebbian learning,\nestablishes the power and limitations of local learning rules, introduces the\nlearning channel which enables a formal analysis of the optimality of\nbackpropagation, and explains the sparsity of the space of learning rules\ndiscovered so far.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 05:16:57 GMT"}, {"version": "v2", "created": "Fri, 21 Oct 2016 23:24:25 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Baldi", "Pierre", ""], ["Sadowski", "Peter", ""]]}, {"id": "1506.06579", "submitter": "Jason Yosinski", "authors": "Jason Yosinski and Jeff Clune and Anh Nguyen and Thomas Fuchs and Hod\n  Lipson", "title": "Understanding Neural Networks Through Deep Visualization", "comments": "12 pages. To appear at ICML Deep Learning Workshop 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Recent years have produced great advances in training large, deep neural\nnetworks (DNNs), including notable successes in training convolutional neural\nnetworks (convnets) to recognize natural images. However, our understanding of\nhow these models work, especially what computations they perform at\nintermediate layers, has lagged behind. Progress in the field will be further\naccelerated by the development of better tools for visualizing and interpreting\nneural nets. We introduce two such tools here. The first is a tool that\nvisualizes the activations produced on each layer of a trained convnet as it\nprocesses an image or video (e.g. a live webcam stream). We have found that\nlooking at live activations that change in response to user input helps build\nvaluable intuitions about how convnets work. The second tool enables\nvisualizing features at each layer of a DNN via regularized optimization in\nimage space. Because previous versions of this idea produced less recognizable\nimages, here we introduce several new regularization methods that combine to\nproduce qualitatively clearer, more interpretable visualizations. Both tools\nare open source and work on a pre-trained convnet with minimal setup.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 12:57:15 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Yosinski", "Jason", ""], ["Clune", "Jeff", ""], ["Nguyen", "Anh", ""], ["Fuchs", "Thomas", ""], ["Lipson", "Hod", ""]]}, {"id": "1506.06714", "submitter": "Michel Galley", "authors": "Alessandro Sordoni, Michel Galley, Michael Auli, Chris Brockett,\n  Yangfeng Ji, Margaret Mitchell, Jian-Yun Nie, Jianfeng Gao, Bill Dolan", "title": "A Neural Network Approach to Context-Sensitive Generation of\n  Conversational Responses", "comments": "A. Sordoni, M. Galley, M. Auli, C. Brockett, Y. Ji, M. Mitchell,\n  J.-Y. Nie, J. Gao, B. Dolan. 2015. A Neural Network Approach to\n  Context-Sensitive Generation of Conversational Responses. In Proc. of\n  NAACL-HLT. Pages 196-205", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel response generation system that can be trained end to end\non large quantities of unstructured Twitter conversations. A neural network\narchitecture is used to address sparsity issues that arise when integrating\ncontextual information into classic statistical models, allowing the system to\ntake into account previous dialog utterances. Our dynamic-context generative\nmodels show consistent gains over both context-sensitive and\nnon-context-sensitive Machine Translation and Information Retrieval baselines.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 18:29:03 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Sordoni", "Alessandro", ""], ["Galley", "Michel", ""], ["Auli", "Michael", ""], ["Brockett", "Chris", ""], ["Ji", "Yangfeng", ""], ["Mitchell", "Margaret", ""], ["Nie", "Jian-Yun", ""], ["Gao", "Jianfeng", ""], ["Dolan", "Bill", ""]]}, {"id": "1506.06796", "submitter": "Carlos Gershenson", "authors": "Carlos Gershenson and Dirk Helbing", "title": "When slower is faster", "comments": null, "journal-ref": "Complexity, 21(2):9-15. 2015", "doi": "10.1002/cplx.21736", "report-no": null, "categories": "nlin.AO cond-mat.dis-nn cs.NE physics.soc-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The slower is faster (SIF) effect occurs when a system performs worse as its\ncomponents try to do better. Thus, a moderate individual efficiency actually\nleads to a better systemic performance. The SIF effect takes place in a variety\nof phenomena. We review studies and examples of the SIF effect in pedestrian\ndynamics, vehicle traffic, traffic light control, logistics, public transport,\nsocial dynamics, ecological systems, and adaptation. Drawing on these examples,\nwe generalize common features of the SIF effect and suggest possible future\nlines of research.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 21:35:52 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2015 20:50:49 GMT"}], "update_date": "2016-04-01", "authors_parsed": [["Gershenson", "Carlos", ""], ["Helbing", "Dirk", ""]]}, {"id": "1506.06848", "submitter": "Shayan Poursoltan Mr", "authors": "Shayan Poursoltan, FranK Neumann", "title": "A Feature-Based Analysis on the Impact of Set of Constraints for\n  e-Constrained Differential Evolution", "comments": "17 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different types of evolutionary algorithms have been developed for\nconstrained continuous optimization. We carry out a feature-based analysis of\nevolved constrained continuous optimization instances to understand the\ncharacteristics of constraints that make problems hard for evolutionary\nalgorithm. In our study, we examine how various sets of constraints can\ninfluence the behaviour of e-Constrained Differential Evolution. Investigating\nthe evolved instances, we obtain knowledge of what type of constraints and\ntheir features make a problem difficult for the examined algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 03:24:05 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Poursoltan", "Shayan", ""], ["Neumann", "FranK", ""]]}, {"id": "1506.07285", "submitter": "Richard Socher", "authors": "Ankit Kumar and Ozan Irsoy and Peter Ondruska and Mohit Iyyer and\n  James Bradbury and Ishaan Gulrajani and Victor Zhong and Romain Paulus and\n  Richard Socher", "title": "Ask Me Anything: Dynamic Memory Networks for Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most tasks in natural language processing can be cast into question answering\n(QA) problems over language input. We introduce the dynamic memory network\n(DMN), a neural network architecture which processes input sequences and\nquestions, forms episodic memories, and generates relevant answers. Questions\ntrigger an iterative attention process which allows the model to condition its\nattention on the inputs and the result of previous iterations. These results\nare then reasoned over in a hierarchical recurrent sequence model to generate\nanswers. The DMN can be trained end-to-end and obtains state-of-the-art results\non several types of tasks and datasets: question answering (Facebook's bAbI\ndataset), text classification for sentiment analysis (Stanford Sentiment\nTreebank) and sequence modeling for part-of-speech tagging (WSJ-PTB). The\ntraining for these different tasks relies exclusively on trained word vector\nrepresentations and input-question-answer triplets.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 08:27:02 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2015 22:21:29 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2015 05:02:29 GMT"}, {"version": "v4", "created": "Tue, 9 Feb 2016 08:19:30 GMT"}, {"version": "v5", "created": "Sat, 5 Mar 2016 20:18:55 GMT"}], "update_date": "2016-03-08", "authors_parsed": [["Kumar", "Ankit", ""], ["Irsoy", "Ozan", ""], ["Ondruska", "Peter", ""], ["Iyyer", "Mohit", ""], ["Bradbury", "James", ""], ["Gulrajani", "Ishaan", ""], ["Zhong", "Victor", ""], ["Paulus", "Romain", ""], ["Socher", "Richard", ""]]}, {"id": "1506.07503", "submitter": "Jan Chorowski", "authors": "Jan Chorowski, Dzmitry Bahdanau, Dmitriy Serdyuk, Kyunghyun Cho,\n  Yoshua Bengio", "title": "Attention-Based Models for Speech Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent sequence generators conditioned on input data through an attention\nmechanism have recently shown very good performance on a range of tasks in-\ncluding machine translation, handwriting synthesis and image caption gen-\neration. We extend the attention-mechanism with features needed for speech\nrecognition. We show that while an adaptation of the model used for machine\ntranslation in reaches a competitive 18.7% phoneme error rate (PER) on the\nTIMIT phoneme recognition task, it can only be applied to utterances which are\nroughly as long as the ones it was trained on. We offer a qualitative\nexplanation of this failure and propose a novel and generic method of adding\nlocation-awareness to the attention mechanism to alleviate this issue. The new\nmethod yields a model that is robust to long inputs and achieves 18% PER in\nsingle utterances and 20% in 10-times longer (repeated) utterances. Finally, we\npropose a change to the at- tention mechanism that prevents it from\nconcentrating too much on single frames, which further reduces PER to 17.6%\nlevel.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 19:10:33 GMT"}], "update_date": "2015-06-25", "authors_parsed": [["Chorowski", "Jan", ""], ["Bahdanau", "Dzmitry", ""], ["Serdyuk", "Dmitriy", ""], ["Cho", "Kyunghyun", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1506.07545", "submitter": "Emmanuel Osegi", "authors": "N.E. Osegi, P. Enyindah", "title": "Learning Representations from Deep Networks Using Mode Synthesizers", "comments": "10 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning Networks play a crucial role in the evolution of a vast number\nof current machine learning models for solving a variety of real world\nnon-trivial tasks. Such networks use big data which is generally unlabeled\nunsupervised and multi-layered requiring no form of supervision for training\nand learning data and has been used to successfully build automatic supervisory\nneural networks. However the question still remains how well the learned data\nrepresents interestingness, and their effectiveness i.e. efficiency in deep\nlearning models or applications. If the output of a network of deep learning\nmodels can be beamed unto a scene of observables, we could learn the\nvariational frequencies of these stacked networks in a parallel and\ndistributive way.This paper seeks to discover and represent interesting\npatterns in an efficient and less complex way by incorporating the concept of\nMode synthesizers in the deep learning process models\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 20:22:40 GMT"}], "update_date": "2015-06-26", "authors_parsed": [["Osegi", "N. E.", ""], ["Enyindah", "P.", ""]]}, {"id": "1506.07980", "submitter": "Jose Pereira C.", "authors": "Jos\\'e C. Pereira and Fernando G. Lobo", "title": "A Java Implementation of the SGA, UMDA, ECGA, and HBOA", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Simple Genetic Algorithm, the Univariate Marginal Distribution Algorithm,\nthe Extended Compact Genetic Algorithm, and the Hierarchical Bayesian\nOptimization Algorithm are all well known Evolutionary Algorithms.\n  In this report we present a Java implementation of these four algorithms with\ndetailed instructions on how to use each of them to solve a given set of\noptimization problems. Additionally, it is explained how to implement and\nintegrate new problems within the provided set. The source and binary files of\nthe Java implementations are available for free download at\nhttps://github.com/JoseCPereira/2015EvolutionaryAlgorithmsJava.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 07:44:38 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Pereira", "Jos\u00e9 C.", ""], ["Lobo", "Fernando G.", ""]]}, {"id": "1506.08004", "submitter": "Jayanta Basak", "authors": "Jayanta Basak", "title": "ASOC: An Adaptive Parameter-free Stochastic Optimization Techinique for\n  Continuous Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic optimization is an important task in many optimization problems\nwhere the tasks are not expressible as convex optimization problems. In the\ncase of non-convex optimization problems, various different stochastic\nalgorithms like simulated annealing, evolutionary algorithms, and tabu search\nare available. Most of these algorithms require user-defined parameters\nspecific to the problem in order to find out the optimal solution. Moreover, in\nmany situations, iterative fine-tunings are required for the user-defined\nparameters, and therefore these algorithms cannot adapt if the search space and\nthe optima changes over time. In this paper we propose an \\underline{a}daptive\nparameter-free \\underline{s}tochastic \\underline{o}ptimization technique for\n\\underline{c}ontinuous random variables called ASOC.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 09:13:57 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Basak", "Jayanta", ""]]}, {"id": "1506.08230", "submitter": "Mark Tygert", "authors": "Mark Tygert, Arthur Szlam, Soumith Chintala, Marc'Aurelio Ranzato,\n  Yuandong Tian, and Wojciech Zaremba", "title": "Convolutional networks and learning invariant to homogeneous\n  multiplicative scalings", "comments": "12 pages, 6 figures, 4 tables", "journal-ref": "Appl. Comput. Harmon. Anal., 42 (1): 154-166, 2017", "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conventional classification schemes -- notably multinomial logistic\nregression -- used in conjunction with convolutional networks (convnets) are\nclassical in statistics, designed without consideration for the usual coupling\nwith convnets, stochastic gradient descent, and backpropagation. In the\nspecific application to supervised learning for convnets, a simple\nscale-invariant classification stage turns out to be more robust than\nmultinomial logistic regression, appears to result in slightly lower errors on\nseveral standard test sets, has similar computational costs, and features\nprecise control over the actual rate of learning. \"Scale-invariant\" means that\nmultiplying the input values by any nonzero scalar leaves the output unchanged.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 22:22:21 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2015 18:10:04 GMT"}, {"version": "v3", "created": "Thu, 24 Dec 2015 20:20:48 GMT"}, {"version": "v4", "created": "Tue, 16 Feb 2016 22:55:43 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Tygert", "Mark", ""], ["Szlam", "Arthur", ""], ["Chintala", "Soumith", ""], ["Ranzato", "Marc'Aurelio", ""], ["Tian", "Yuandong", ""], ["Zaremba", "Wojciech", ""]]}, {"id": "1506.08349", "submitter": "Lantian Li Mr.", "authors": "Lantian Li and Yiye Lin and Zhiyong Zhang and Dong Wang", "title": "Improved Deep Speaker Feature Learning for Text-Dependent Speaker\n  Recognition", "comments": "arXiv admin note: substantial text overlap with arXiv:1505.06427", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep learning approach has been proposed recently to derive speaker\nidentifies (d-vector) by a deep neural network (DNN). This approach has been\napplied to text-dependent speaker recognition tasks and shows reasonable\nperformance gains when combined with the conventional i-vector approach.\nAlthough promising, the existing d-vector implementation still can not compete\nwith the i-vector baseline. This paper presents two improvements for the deep\nlearning approach: a phonedependent DNN structure to normalize phone variation,\nand a new scoring approach based on dynamic time warping (DTW). Experiments on\na text-dependent speaker recognition task demonstrated that the proposed\nmethods can provide considerable performance improvement over the existing\nd-vector implementation.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2015 03:32:02 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Li", "Lantian", ""], ["Lin", "Yiye", ""], ["Zhang", "Zhiyong", ""], ["Wang", "Dong", ""]]}, {"id": "1506.08361", "submitter": "Jaderick Pabico", "authors": "Jaderick P. Pabico", "title": "Simultaneously Solving Computational Problems Using an Artificial\n  Chemical Reactor", "comments": "6 pages, appeared in R.P. Salda\\~na (ed.) Proceedings (CDROM) of the\n  6th Philippine Computing Science Congress (PCSC 2006), Ateneo De Manila\n  University, Loyola Heights, Quezon City, Philippines, 28-29 March 2006, pp\n  48-53 (ISSN 1908-1146)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper is centered on using chemical reaction as a computational metaphor\nfor simultaneously solving problems. An artificial chemical reactor that can\nsimultaneously solve instances of three unrelated problems was created. The\nreactor is a distributed stochastic algorithm that simulates a chemical\nuniverse wherein the molecular species are being represented either by a human\ngenomic contig panel, a Hamiltonian cycle, or an aircraft landing schedule. The\nchemical universe is governed by reactions that can alter genomic sequences,\nre-order Hamiltonian cycles, or reschedule an aircraft landing program.\nMolecular masses were considered as measures of goodness of solutions, and\nrepresented radiation hybrid (RH) vector similarities, costs of Hamiltonian\ncycles, and penalty costs for landing an aircraft before and after target\nlanding times. This method, tested by solving in tandem with deterministic\nalgorithms, has been shown to find quality solutions in finding the minima RH\nvector similarities of genomic data, minima costs in Hamiltonian cycles of the\ntraveling salesman, and minima costs for landing aircrafts before or after\ntarget landing times.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2015 06:01:50 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Pabico", "Jaderick P.", ""]]}, {"id": "1506.08425", "submitter": "Chee Seng Chan", "authors": "Sue Han Lee, Chee Seng Chan, Paul Wilkin and Paolo Remagnino", "title": "Deep-Plant: Plant Identification with convolutional neural networks", "comments": "6 pages, 8 figures, accepted as oral presentation in ICIP2015,\n  Qu\\'ebec City, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies convolutional neural networks (CNN) to learn unsupervised\nfeature representations for 44 different plant species, collected at the Royal\nBotanic Gardens, Kew, England. To gain intuition on the chosen features from\nthe CNN model (opposed to a 'black box' solution), a visualisation technique\nbased on the deconvolutional networks (DN) is utilized. It is found that\nvenations of different order have been chosen to uniquely represent each of the\nplant species. Experimental results using these CNN features with different\nclassifiers show consistency and superiority compared to the state-of-the art\nsolutions which rely on hand-crafted features.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2015 16:58:47 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Lee", "Sue Han", ""], ["Chan", "Chee Seng", ""], ["Wilkin", "Paul", ""], ["Remagnino", "Paolo", ""]]}, {"id": "1506.08473", "submitter": "Majid Janzamin", "authors": "Majid Janzamin and Hanie Sedghi and Anima Anandkumar", "title": "Beating the Perils of Non-Convexity: Guaranteed Training of Neural\n  Networks using Tensor Methods", "comments": "The tensor decomposition analysis is expanded, and the analysis of\n  ridge regression is added for recovering the parameters of last layer of\n  neural network", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training neural networks is a challenging non-convex optimization problem,\nand backpropagation or gradient descent can get stuck in spurious local optima.\nWe propose a novel algorithm based on tensor decomposition for guaranteed\ntraining of two-layer neural networks. We provide risk bounds for our proposed\nmethod, with a polynomial sample complexity in the relevant parameters, such as\ninput dimension and number of neurons. While learning arbitrary target\nfunctions is NP-hard, we provide transparent conditions on the function and the\ninput for learnability. Our training method is based on tensor decomposition,\nwhich provably converges to the global optimum, under a set of mild\nnon-degeneracy conditions. It consists of simple embarrassingly parallel linear\nand multi-linear operations, and is competitive with standard stochastic\ngradient descent (SGD), in terms of computational complexity. Thus, we propose\na computationally efficient method with guaranteed risk bounds for training\nneural networks with one hidden layer.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2015 23:19:49 GMT"}, {"version": "v2", "created": "Mon, 24 Aug 2015 19:31:24 GMT"}, {"version": "v3", "created": "Tue, 12 Jan 2016 03:19:42 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Janzamin", "Majid", ""], ["Sedghi", "Hanie", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1506.08694", "submitter": "Jose Pereira C.", "authors": "Jos\\'e C. Pereira and Fernando G. Lobo", "title": "A Java Implementation of Parameter-less Evolutionary Algorithms", "comments": "12 pages. arXiv admin note: text overlap with arXiv:1506.07980", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Parameter-less Genetic Algorithm was first presented by Harik and Lobo in\n1999 as an alternative to the usual trial-and-error method of finding, for each\ngiven problem, an acceptable set-up of the parameter values of the genetic\nalgorithm. Since then, the same strategy has been successfully applied to\ncreate parameter-less versions of other population-based search algorithms such\nas the Extended Compact Genetic Algorithm and the Hierarchical Bayesian\nOptimization Algorithm. This report describes a Java implementation,\nParameter-less Evolutionary Algorithm (P-EAJava), that integrates several\nparameter-less evolutionary algorithms into a single platform. Along with a\nbrief description of P-EAJava, we also provide detailed instructions on how to\nuse it, how to implement new problems, and how to generate new parameter-less\nversions of evolutionary algorithms.\n  At present time, P-EAJava already includes parameter-less versions of the\nSimple Genetic Algorithm, the Extended Compact Genetic Algorithm, the\nUnivariate Marginal Distribution Algorithm, and the Hierarchical Bayesian\nOptimization Algorithm. The source and binary files of the Java implementation\nof P-EAJava are available for free download at\nhttps://github.com/JoseCPereira/2015ParameterlessEvolutionaryAlgorithmsJava.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 07:53:57 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Pereira", "Jos\u00e9 C.", ""], ["Lobo", "Fernando G.", ""]]}, {"id": "1506.08781", "submitter": "Richard Preen", "authors": "Richard J. Preen and Larry Bull", "title": "On Design Mining: Coevolution and Surrogate Models", "comments": null, "journal-ref": "Artificial Life (2017), 23(2):186-205", "doi": "10.1162/ARTL_a_00225", "report-no": null, "categories": "cs.NE cs.AI cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design mining is the use of computational intelligence techniques to\niteratively search and model the attribute space of physical objects evaluated\ndirectly through rapid prototyping to meet given objectives. It enables the\nexploitation of novel materials and processes without formal models or complex\nsimulation. In this paper, we focus upon the coevolutionary nature of the\ndesign process when it is decomposed into concurrent sub-design threads due to\nthe overall complexity of the task. Using an abstract, tuneable model of\ncoevolution we consider strategies to sample sub-thread designs for whole\nsystem testing and how best to construct and use surrogate models within the\ncoevolutionary scenario. Drawing on our findings, the paper then describes the\neffective design of an array of six heterogeneous vertical-axis wind turbines.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 18:57:34 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2015 14:05:42 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2015 17:29:20 GMT"}, {"version": "v4", "created": "Mon, 15 Feb 2016 14:43:39 GMT"}, {"version": "v5", "created": "Wed, 26 Oct 2016 22:09:08 GMT"}, {"version": "v6", "created": "Wed, 23 Nov 2016 20:24:17 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Preen", "Richard J.", ""], ["Bull", "Larry", ""]]}, {"id": "1506.08867", "submitter": "Jose Pereira C.", "authors": "Jos\\'e C. Pereira and Fernando G. Lobo", "title": "Java Implementation of a Parameter-less Evolutionary Portfolio", "comments": "7 pages. arXiv admin note: substantial text overlap with\n  arXiv:1506.08694, arXiv:1506.07980", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Java implementation of a portfolio of parameter-less evolutionary\nalgorithms is presented. The Parameter-less Evolutionary Portfolio implements a\nheuristic that performs adaptive selection of parameter-less evolutionary\nalgorithms in accordance with performance criteria that are measured during\nrunning time. At present time, the portfolio includes three parameter-less\nevolutionary algorithms: Parameter-less Univariate Marginal Distribution\nAlgorithm, Parameter-less Extended Compact Genetic Algorithm, and\nParameter-less Hierarchical Bayesian Optimization Algorithm. Initial\nexperiments showed that the parameter-less portfolio can solve various classes\nof problems without the need for any prior parameter setting technique and with\nan increase in computational effort that can be considered acceptable.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 07:58:32 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Pereira", "Jos\u00e9 C.", ""], ["Lobo", "Fernando G.", ""]]}, {"id": "1506.08909", "submitter": "Ryan Lowe T.", "authors": "Ryan Lowe, Nissan Pow, Iulian Serban, Joelle Pineau", "title": "The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured\n  Multi-Turn Dialogue Systems", "comments": "SIGDIAL 2015. 10 pages, 5 figures. Update includes link to new\n  version of the dataset, with some added features and bug fixes. See:\n  https://github.com/rkadlec/ubuntu-ranking-dataset-creator", "journal-ref": null, "doi": null, "report-no": "Proc. SIGDIAL 16 (2015) pp. 285-294", "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Ubuntu Dialogue Corpus, a dataset containing almost\n1 million multi-turn dialogues, with a total of over 7 million utterances and\n100 million words. This provides a unique resource for research into building\ndialogue managers based on neural language models that can make use of large\namounts of unlabeled data. The dataset has both the multi-turn property of\nconversations in the Dialog State Tracking Challenge datasets, and the\nunstructured nature of interactions from microblog services such as Twitter. We\nalso describe two neural learning architectures suitable for analyzing this\ndataset, and provide benchmark performance on the task of selecting the best\nnext response.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 00:37:09 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2015 16:11:29 GMT"}, {"version": "v3", "created": "Thu, 4 Feb 2016 01:21:35 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Lowe", "Ryan", ""], ["Pow", "Nissan", ""], ["Serban", "Iulian", ""], ["Pineau", "Joelle", ""]]}, {"id": "1506.09019", "submitter": "Jaderick Pabico", "authors": "Jaderick P. Pabico", "title": "Artificial Catalytic Reactions in 2D for Combinatorial Optimization", "comments": "8 pages, 2 figures, In H.N. Adorna (ed.) Proceedings of the 3rd\n  Symposium on Mathematical Aspects of Computer Science (SMACS 2006), Adventist\n  University of the Philippines, Silang, Cavite, Philippines, 19-20 October\n  2006 (Published by the Computing Society of the Philippines)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Presented in this paper is a derivation of a 2D catalytic reaction-based\nmodel to solve combinatorial optimization problems (COPs). The simulated\ncatalytic reactions, a computational metaphor, occurs in an artificial chemical\nreactor that finds near-optimal solutions to COPs. The artificial environment\nis governed by catalytic reactions that can alter the structure of artificial\nmolecular elements. Altering the molecular structure means finding new\nsolutions to the COP. The molecular mass of the elements was considered as a\nmeasure of goodness of fit of the solutions. Several data structures and\nmatrices were used to record the directions and locations of the molecules.\nThese provided the model the 2D topology. The Traveling Salesperson Problem\n(TSP) was used as a working example. The performance of the model in finding a\nsolution for the TSP was compared to the performance of a topology-less model.\nExperimental results show that the 2D model performs better than the\ntopology-less one.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 10:16:20 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Pabico", "Jaderick P.", ""]]}, {"id": "1506.09081", "submitter": "Raphael Cerf", "authors": "Rapha\\\"el Cerf", "title": "The quasispecies regime for the simple genetic algorithm with\n  roulette-wheel selection", "comments": "The proof of theorem 3.1 is now included. References have been added.\n  arXiv admin note: text overlap with arXiv:1403.5427", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new parameter to discuss the behavior of a genetic algorithm.\nThis parameter is the mean number of exact copies of the best fit chromosomes\nfrom one generation to the next. We argue that the genetic algorithm should\noperate efficiently when this parameter is slightly larger than $1$. We\nconsider the case of the simple genetic algorithm with the roulette--wheel\nselection mechanism. We denote by $\\ell$ the length of the chromosomes, by $m$\nthe population size, by $p_C$ the crossover probability and by $p_M$ the\nmutation probability. We start the genetic algorithm with an initial population\nwhose maximal fitness is equal to $f_0^*$ and whose mean fitness is equal to\n${\\overline{f_0}}$. We show that, in the limit of large populations, the\ndynamics of the genetic algorithm depends in a critical way on the parameter\n$\\pi \\,=\\,\\big({f_0^*}/{\\overline{f_0}}\\big) (1-p_C)(1-p_M)^\\ell\\,.$ Our\nresults suggest that the mutation and crossover probabilities should be tuned\nso that, at each generation, $\\text{maximal fitness} \\times (1-p_C)\n(1-p_M)^\\ell > \\text{mean fitness}$.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 13:35:00 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2015 09:54:21 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Cerf", "Rapha\u00ebl", ""]]}]