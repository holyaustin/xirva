[{"id": "1509.00028", "submitter": "Kanchan Sarkar", "authors": "Kanchan Sarkar and S. P. Bhattacharyya", "title": "Pure and Hybrid Evolutionary Computing in Global Optimization of\n  Chemical Structures: from Atoms and Molecules to Clusters and Crystals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.NE physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth of evolutionary computing (EC) methods in the exploration of\ncomplex potential energy landscapes of atomic and molecular clusters, as well\nas crystals over the last decade or so is reviewed. The trend of growth\nindicates that pure as well as hybrid evolutionary computing techniques in\nconjunction of DFT has been emerging as a powerful tool, although work on\nmolecular clusters has been rather limited so far. Some attempts to solve the\natomic/molecular Schrodinger Equation (SE) directly by genetic algorithms (GA)\nare available in literature. At the Born-Oppenheimer level of approximation\nGA-density methods appear to be a viable tool which could be more extensively\nexplored in the coming years, specially in the context of designing molecules\nand materials with targeted properties.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 20:18:50 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Sarkar", "Kanchan", ""], ["Bhattacharyya", "S. P.", ""]]}, {"id": "1509.00105", "submitter": "Gerard Howard", "authors": "David Howard, Larry Bull and Ben De Lacy Costello", "title": "Evolving Unipolar Memristor Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic computing --- brainlike computing in hardware --- typically\nrequires myriad CMOS spiking neurons interconnected by a dense mesh of\nnanoscale plastic synapses. Memristors are frequently citepd as strong synapse\ncandidates due to their statefulness and potential for low-power\nimplementations. To date, plentiful research has focused on the bipolar\nmemristor synapse, which is capable of incremental weight alterations and can\nprovide adaptive self-organisation under a Hebbian learning scheme. In this\npaper we consider the Unipolar memristor synapse --- a device capable of\nnon-Hebbian switching between only two states (conductive and resistive)\nthrough application of a suitable input voltage --- and discuss its suitability\nfor neuromorphic systems. A self-adaptive evolutionary process is used to\nautonomously find highly fit network configurations. Experimentation on a two\nrobotics tasks shows that unipolar memristor networks evolve task-solving\ncontrollers faster than both bipolar memristor networks and networks containing\nconstant nonplastic connections whilst performing at least comparably.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 01:00:57 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Howard", "David", ""], ["Bull", "Larry", ""], ["Costello", "Ben De Lacy", ""]]}, {"id": "1509.00174", "submitter": "Mauro Brunato", "authors": "Mauro Brunato, Roberto Battiti", "title": "A Telescopic Binary Learning Machine for Training Neural Networks", "comments": "Submitted to IEEE Transactions on Neural Networks and Learning\n  Systems, special issue on New Developments in Neural Network Structures for\n  Signal Processing, Autonomous Decision, and Adaptive Control", "journal-ref": null, "doi": "10.1109/TNNLS.2016.2537300", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new algorithm based on multi-scale stochastic local\nsearch with binary representation for training neural networks.\n  In particular, we study the effects of neighborhood evaluation strategies,\nthe effect of the number of bits per weight and that of the maximum weight\nrange used for mapping binary strings to real values. Following this\npreliminary investigation, we propose a telescopic multi-scale version of local\nsearch where the number of bits is increased in an adaptive manner, leading to\na faster search and to local minima of better quality. An analysis related to\nadapting the number of bits in a dynamic way is also presented. The control on\nthe number of bits, which happens in a natural manner in the proposed method,\nis effective to increase the generalization performance. Benchmark tasks\ninclude a highly non-linear artificial problem, a control problem requiring\neither feed-forward or recurrent architectures for feedback control, and\nchallenging real-world tasks in different application domains.\n  The results demonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 08:22:33 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Brunato", "Mauro", ""], ["Battiti", "Roberto", ""]]}, {"id": "1509.00595", "submitter": "Elham Shadkam", "authors": "Mahdi Gorjestani, Elham Shadkam, Mehdi Parvizi, Sajedeh Aminzadegan", "title": "A hybrid COA-DEA method for solving multi-objective problems", "comments": null, "journal-ref": null, "doi": "10.5121/ijcsa.2015.5405", "report-no": null, "categories": "math.OC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cuckoo optimization algorithm (COA) is developed for solving\nsingle-objective problems and it cannot be used for solving multi-objective\nproblems. So the multi-objective cuckoo optimization algorithm based on data\nenvelopment analysis (DEA) is developed in this paper and it can gain the\nefficient Pareto frontiers. This algorithm is presented by the CCR model of DEA\nand the output-oriented approach of it. The selection criterion is higher\nefficiency for next iteration of the proposed hybrid method. So the profit\nfunction of the COA is replaced by the efficiency value that is obtained from\nDEA. This algorithm is compared with other methods using some test problems.\nThe results shows using COA and DEA approach for solving multi-objective\nproblems increases the speed and the accuracy of the generated solutions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 08:05:41 GMT"}], "update_date": "2015-09-03", "authors_parsed": [["Gorjestani", "Mahdi", ""], ["Shadkam", "Elham", ""], ["Parvizi", "Mehdi", ""], ["Aminzadegan", "Sajedeh", ""]]}, {"id": "1509.00764", "submitter": "Darren Strash", "authors": "Sebastian Lamm, Peter Sanders, Christian Schulz, Darren Strash, and\n  Renato F. Werneck", "title": "Finding Near-Optimal Independent Sets at Scale", "comments": "17 pages, 1 figure, 8 tables. arXiv admin note: text overlap with\n  arXiv:1502.01687", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.NE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The independent set problem is NP-hard and particularly difficult to solve in\nlarge sparse graphs. In this work, we develop an advanced evolutionary\nalgorithm, which incorporates kernelization techniques to compute large\nindependent sets in huge sparse networks. A recent exact algorithm has shown\nthat large networks can be solved exactly by employing a branch-and-reduce\ntechnique that recursively kernelizes the graph and performs branching.\nHowever, one major drawback of their algorithm is that, for huge graphs,\nbranching still can take exponential time. To avoid this problem, we\nrecursively choose vertices that are likely to be in a large independent set\n(using an evolutionary approach), then further kernelize the graph. We show\nthat identifying and removing vertices likely to be in large independent sets\nopens up the reduction space---which not only speeds up the computation of\nlarge independent sets drastically, but also enables us to compute high-quality\nindependent sets on much larger instances than previously reported in the\nliterature.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 16:04:59 GMT"}], "update_date": "2015-09-03", "authors_parsed": [["Lamm", "Sebastian", ""], ["Sanders", "Peter", ""], ["Schulz", "Christian", ""], ["Strash", "Darren", ""], ["Werneck", "Renato F.", ""]]}, {"id": "1509.00838", "submitter": "Hongyuan Mei", "authors": "Hongyuan Mei and Mohit Bansal and Matthew R. Walter", "title": "What to talk about and how? Selective Generation using LSTMs with\n  Coarse-to-Fine Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an end-to-end, domain-independent neural encoder-aligner-decoder\nmodel for selective generation, i.e., the joint task of content selection and\nsurface realization. Our model first encodes a full set of over-determined\ndatabase event records via an LSTM-based recurrent neural network, then\nutilizes a novel coarse-to-fine aligner to identify the small subset of salient\nrecords to talk about, and finally employs a decoder to generate free-form\ndescriptions of the aligned, selected records. Our model achieves the best\nselection and generation results reported to-date (with 59% relative\nimprovement in generation) on the benchmark WeatherGov dataset, despite using\nno specialized features or linguistic resources. Using an improved k-nearest\nneighbor beam filter helps further. We also perform a series of ablations and\nvisualizations to elucidate the contributions of our key model components.\nLastly, we evaluate the generalizability of our model on the RoboCup dataset,\nand get results that are competitive with or better than the state-of-the-art,\ndespite being severely data-starved.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 19:52:56 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 23:07:32 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Mei", "Hongyuan", ""], ["Bansal", "Mohit", ""], ["Walter", "Matthew R.", ""]]}, {"id": "1509.00962", "submitter": "Chetan Singh Thakur", "authors": "Runchun Wang, Chetan Singh Thakur, Tara Julia Hamilton, Jonathan\n  Tapson, Andre van Schaik", "title": "A compact aVLSI conductance-based silicon neuron", "comments": "BioCAS-2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present an analogue Very Large Scale Integration (aVLSI) implementation\nthat uses first-order lowpass filters to implement a conductance-based silicon\nneuron for high-speed neuromorphic systems. The aVLSI neuron consists of a soma\n(cell body) and a single synapse, which is capable of linearly summing both the\nexcitatory and inhibitory postsynaptic potentials (EPSP and IPSP) generated by\nthe spikes arriving from different sources. Rather than biasing the silicon\nneuron with different parameters for different spiking patterns, as is\ntypically done, we provide digital control signals, generated by an FPGA, to\nthe silicon neuron to obtain different spiking behaviours. The proposed neuron\nis only ~26.5 um2 in the IBM 130nm process and thus can be integrated at very\nhigh density. Circuit simulations show that this neuron can emulate different\nspiking behaviours observed in biological neurons.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 07:22:38 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Wang", "Runchun", ""], ["Thakur", "Chetan Singh", ""], ["Hamilton", "Tara Julia", ""], ["Tapson", "Jonathan", ""], ["van Schaik", "Andre", ""]]}, {"id": "1509.00967", "submitter": "Chetan Singh Thakur", "authors": "Ying Xu, Chetan Singh Thakur, Tara Julia Hamilton, Jonathan Tapson,\n  Runchun Wang, Andre van Schaik", "title": "A Reconfigurable Mixed-signal Implementation of a Neuromorphic ADC", "comments": "BioCAS-2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a neuromorphic Analogue-to-Digital Converter (ADC), which uses\nintegrate-and-fire (I&F) neurons as the encoders of the analogue signal, with\nmodulated inhibitions to decohere the neuronal spikes trains. The architecture\nconsists of an analogue chip and a control module. The analogue chip comprises\ntwo scan chains and a twodimensional integrate-and-fire neuronal array.\nIndividual neurons are accessed via the chains one by one without any encoder\ndecoder or arbiter. The control module is implemented on an FPGA (Field\nProgrammable Gate Array), which sends scan enable signals to the scan chains\nand controls the inhibition for individual neurons. Since the control module is\nimplemented on an FPGA, it can be easily reconfigured. Additionally, we propose\na pulse width modulation methodology for the lateral inhibition, which makes\nuse of different pulse widths indicating different strengths of inhibition for\neach individual neuron to decohere neuronal spikes. Software simulations in\nthis paper tested the robustness of the proposed ADC architecture to fixed\nrandom noise. A circuit simulation using ten neurons shows the performance and\nthe feasibility of the architecture.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 07:51:24 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Xu", "Ying", ""], ["Thakur", "Chetan Singh", ""], ["Hamilton", "Tara Julia", ""], ["Tapson", "Jonathan", ""], ["Wang", "Runchun", ""], ["van Schaik", "Andre", ""]]}, {"id": "1509.00998", "submitter": "Zhaofei Yu", "authors": "Zhaofei Yu, Feng Chen, Jianwu Dong, Qionghai Dai", "title": "Sampling-based Causal Inference in Cue Combination and its Neural\n  Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference in cue combination is to decide whether the cues have a\nsingle cause or multiple causes. Although the Bayesian causal inference model\nexplains the problem of causal inference in cue combination successfully, how\ncausal inference in cue combination could be implemented by neural circuits, is\nunclear. The existing method based on calculating log posterior ratio with\nvariable elimination has the problem of being unrealistic and task-specific. In\nthis paper, we take advantages of the special structure of the Bayesian causal\ninference model and propose a hierarchical inference algorithm based on\nimportance sampling. A simple neural circuit is designed to implement the\nproposed inference algorithm. Theoretical analyses and experimental results\ndemonstrate that our algorithm converges to the accurate value as the sample\nsize goes to infinite. Moreover, the neural circuit we design can be easily\ngeneralized to implement inference for other problems, such as the\nmulti-stimuli cause inference and the same-different judgment.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 09:13:05 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Yu", "Zhaofei", ""], ["Chen", "Feng", ""], ["Dong", "Jianwu", ""], ["Dai", "Qionghai", ""]]}, {"id": "1509.01126", "submitter": "Pushpa  Potluri", "authors": "Pushpa Sree Potluri", "title": "Training of CC4 Neural Network with Spread Unary Coding", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper adapts the corner classification algorithm (CC4) to train the\nneural networks using spread unary inputs. This is an important problem as\nspread unary appears to be at the basis of data representation in biological\nlearning. The modified CC4 algorithm is tested using the pattern classification\nexperiment and the results are found to be good. Specifically, we show that the\nnumber of misclassified points is not particularly sensitive to the chosen\nradius of generalization.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 15:28:55 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Potluri", "Pushpa Sree", ""]]}, {"id": "1509.01549", "submitter": "Matthew Lai", "authors": "Matthew Lai", "title": "Giraffe: Using Deep Reinforcement Learning to Play Chess", "comments": "MSc Dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report presents Giraffe, a chess engine that uses self-play to discover\nall its domain-specific knowledge, with minimal hand-crafted knowledge given by\nthe programmer. Unlike previous attempts using machine learning only to perform\nparameter-tuning on hand-crafted evaluation functions, Giraffe's learning\nsystem also performs automatic feature extraction and pattern recognition. The\ntrained evaluation function performs comparably to the evaluation functions of\nstate-of-the-art chess engines - all of which containing thousands of lines of\ncarefully hand-crafted pattern recognizers, tuned over many years by both\ncomputer chess experts and human chess masters. Giraffe is the most successful\nattempt thus far at using end-to-end machine learning to play chess.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 18:21:52 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2015 15:42:35 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Lai", "Matthew", ""]]}, {"id": "1509.01851", "submitter": "David Balduzzi", "authors": "David Balduzzi", "title": "Deep Online Convex Optimization by Putting Forecaster to Sleep", "comments": "Rendered obsolete by arXiv:1604.01952. The new version contains the\n  same basic results, with major changes to exposition and minor changes to\n  terminology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods from convex optimization such as accelerated gradient descent are\nwidely used as building blocks for deep learning algorithms. However, the\nreasons for their empirical success are unclear, since neural networks are not\nconvex and standard guarantees do not apply. This paper develops the first\nrigorous link between online convex optimization and error backpropagation on\nconvolutional networks. The first step is to introduce circadian games, a mild\ngeneralization of convex games with similar convergence properties. The main\nresult is that error backpropagation on a convolutional network is equivalent\nto playing out a circadian game. It follows immediately that the waking-regret\nof players in the game (the units in the neural network) controls the overall\nrate of convergence of the network. Finally, we explore some implications of\nthe results: (i) we describe the representations learned by a neural network\ngame-theoretically, (ii) propose a learning setting at the level of individual\nunits that can be plugged into deep architectures, and (iii) propose a new\napproach to adaptive model selection by applying bandit algorithms to choose\nwhich players to wake on each round.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2015 20:25:32 GMT"}, {"version": "v2", "created": "Fri, 8 Apr 2016 00:44:00 GMT"}], "update_date": "2016-04-11", "authors_parsed": [["Balduzzi", "David", ""]]}, {"id": "1509.01951", "submitter": "Atul Katole", "authors": "Atul Laxman Katole, Krishna Prasad Yellapragada, Amish Kumar Bedi,\n  Sehaj Singh Kalra and Mynepalli Siva Chaitanya", "title": "Hierarchical Deep Learning Architecture For 10K Objects Classification", "comments": "As appeared in proceedings for CS & IT 2015 - Second International\n  Conference on Computer Science & Engineering (CSEN 2015)", "journal-ref": "Computer Science & Information Technology (CS & IT) (2015) 77-93", "doi": "10.5121/csit.2015.51408", "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution of visual object recognition architectures based on Convolutional\nNeural Networks & Convolutional Deep Belief Networks paradigms has\nrevolutionized artificial Vision Science. These architectures extract & learn\nthe real world hierarchical visual features utilizing supervised & unsupervised\nlearning approaches respectively. Both the approaches yet cannot scale up\nrealistically to provide recognition for a very large number of objects as high\nas 10K. We propose a two level hierarchical deep learning architecture inspired\nby divide & conquer principle that decomposes the large scale recognition\narchitecture into root & leaf level model architectures. Each of the root &\nleaf level models is trained exclusively to provide superior results than\npossible by any 1-level deep learning architecture prevalent today. The\nproposed architecture classifies objects in two steps. In the first step the\nroot level model classifies the object in a high level category. In the second\nstep, the leaf level recognition model for the recognized high level category\nis selected among all the leaf models. This leaf level model is presented with\nthe same input object image which classifies it in a specific category. Also we\npropose a blend of leaf level models trained with either supervised or\nunsupervised learning approaches. Unsupervised learning is suitable whenever\nlabelled data is scarce for the specific leaf level models. Currently the\ntraining of leaf level models is in progress; where we have trained 25 out of\nthe total 47 leaf level models as of now. We have trained the leaf models with\nthe best case top-5 error rate of 3.2% on the validation data set for the\nparticular leaf models. Also we demonstrate that the validation error of the\nleaf level models saturates towards the above mentioned accuracy as the number\nof epochs are increased to more than sixty.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 08:49:39 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Katole", "Atul Laxman", ""], ["Yellapragada", "Krishna Prasad", ""], ["Bedi", "Amish Kumar", ""], ["Kalra", "Sehaj Singh", ""], ["Chaitanya", "Mynepalli Siva", ""]]}, {"id": "1509.02417", "submitter": "Carlos Garcia-Saura", "authors": "Carlos Garcia-Saura", "title": "Central Pattern Generators for the control of robotic systems", "comments": "Report supervised by Prof. Murray Shanahan at Imperial College London", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Bio-inspired control of motion is an active field of research with many\napplications in real world tasks. In the case of robotic systems that need to\nexhibit oscillatory behaviour (i.e. locomotion of snake-type or legged robots),\nCentral Pattern Generators (CPGs) are among the most versatile solutions. These\ncontrollers are often based on loosely-coupled oscillators similar to those\nfound in the neural circuits of many animal species, and can be more robust to\nuncertainty (i.e. external perturbations) than traditional control approaches.\nThis project provides an overview of the state-of-the-art in the field of CPGs,\nand in particular their applications within robotic systems. The project also\ntackles the implementation of a CPG-based controller in a small 3D-printed\nhexapod.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 15:32:16 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Garcia-Saura", "Carlos", ""]]}, {"id": "1509.02459", "submitter": "Mihai Oltean", "authors": "Mihai Oltean, D. Dumitrescu", "title": "Evolving TSP heuristics using Multi Expression Programming", "comments": "International Conference on Computational Sciences, ICCS'04, 6-9\n  June, Krakow, Poland, Edited by M. Bubak, G.van Albada, P. Sloot, and J.\n  Dongarra, Vol II, pp. 670-673, Springer-Verlag, Berlin, 2004. Source code\n  available for download at:\n  http://www.cs.ubbcluj.ro/~moltean/evolve_heuristics.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi Expression Programming (MEP) is an evolutionary technique that may be\nused for solving computationally difficult problems. MEP uses a linear solution\nrepresentation. Each MEP individual is a string encoding complex expressions\n(computer programs). A MEP individual may encode multiple solutions of the\ncurrent problem. In this paper MEP is used for evolving a Traveling Salesman\nProblem (TSP) heuristic for graphs satisfying triangle inequality. Evolved MEP\nheuristic is compared with Nearest Neighbor Heuristic (NN) and Minimum Spanning\nTree Heuristic (MST) on some difficult problems in TSPLIB. For most of the\nconsidered problems the evolved MEP heuristic outperforms NN and MST. The\nobtained algorithm was tested against some problems in TSPLIB. The results\nemphasizes that evolved MEP heuristic is a powerful tool for solving difficult\nTSP instances.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 17:37:01 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Oltean", "Mihai", ""], ["Dumitrescu", "D.", ""]]}, {"id": "1509.02470", "submitter": "Jianguo Li", "authors": "Jianwei Luo and Jianguo Li and Jun Wang and Zhiguo Jiang and Yurong\n  Chen", "title": "Deep Attributes from Context-Aware Regional Neural Codes", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, many researches employ middle-layer output of convolutional neural\nnetwork models (CNN) as features for different visual recognition tasks.\nAlthough promising results have been achieved in some empirical studies, such\ntype of representations still suffer from the well-known issue of semantic gap.\nThis paper proposes so-called deep attribute framework to alleviate this issue\nfrom three aspects. First, we introduce object region proposals as intermedia\nto represent target images, and extract features from region proposals. Second,\nwe study aggregating features from different CNN layers for all region\nproposals. The aggregation yields a holistic yet compact representation of\ninput images. Results show that cross-region max-pooling of soft-max layer\noutput outperform all other layers. As soft-max layer directly corresponds to\nsemantic concepts, this representation is named \"deep attributes\". Third, we\nobserve that only a small portion of generated regions by object proposals\nalgorithm are correlated to classification target. Therefore, we introduce\ncontext-aware region refining algorithm to pick out contextual regions and\nbuild context-aware classifiers.\n  We apply the proposed deep attributes framework for various vision tasks.\nExtensive experiments are conducted on standard benchmarks for three visual\nrecognition tasks, i.e., image classification, fine-grained recognition and\nvisual instance retrieval. Results show that deep attribute approaches achieve\nstate-of-the-art results, and outperforms existing peer methods with a\nsignificant margin, even though some benchmarks have little overlap of concepts\nwith the pre-trained CNN models.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 17:53:54 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Luo", "Jianwei", ""], ["Li", "Jianguo", ""], ["Wang", "Jun", ""], ["Jiang", "Zhiguo", ""], ["Chen", "Yurong", ""]]}, {"id": "1509.02512", "submitter": "Justice Amoh", "authors": "Justice Amoh and Kofi Odame", "title": "DeepCough: A Deep Convolutional Neural Network in A Wearable Cough\n  Detection System", "comments": "BioCAS-2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we present a system that employs a wearable acoustic sensor\nand a deep convolutional neural network for detecting coughs. We evaluate the\nperformance of our system on 14 healthy volunteers and compare it to that of\nother cough detection systems that have been reported in the literature.\nExperimental results show that our system achieves a classification sensitivity\nof 95.1% and a specificity of 99.5%.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 19:59:19 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Amoh", "Justice", ""], ["Odame", "Kofi", ""]]}, {"id": "1509.02807", "submitter": "Cosmin Stamate Mr.", "authors": "Cosmin Stamate, George D. Magoulas and Michael S.C. Thomas", "title": "Transfer learning approach for financial applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks learn how to solve new problems through a\ncomputationally intense and time consuming process. One way to reduce the\namount of time required is to inject preexisting knowledge into the network. To\nmake use of past knowledge, we can take advantage of techniques that transfer\nthe knowledge learned from one task, and reuse it on another (sometimes\nunrelated) task. In this paper we propose a novel selective breeding technique\nthat extends the transfer learning with behavioural genetics approach proposed\nby Kohli, Magoulas and Thomas (2013), and evaluate its performance on financial\ndata. Numerical evidence demonstrates the credibility of the new approach. We\nprovide insights on the operation of transfer learning and highlight the\nbenefits of using behavioural principles and selective breeding when tackling a\nset of diverse financial applications problems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 15:22:21 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["Stamate", "Cosmin", ""], ["Magoulas", "George D.", ""], ["Thomas", "Michael S. C.", ""]]}, {"id": "1509.03005", "submitter": "David Balduzzi", "authors": "David Balduzzi, Muhammad Ghifary", "title": "Compatible Value Gradients for Reinforcement Learning of Continuous Deep\n  Policies", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes GProp, a deep reinforcement learning algorithm for\ncontinuous policies with compatible function approximation. The algorithm is\nbased on two innovations. Firstly, we present a temporal-difference based\nmethod for learning the gradient of the value-function. Secondly, we present\nthe deviator-actor-critic (DAC) model, which comprises three neural networks\nthat estimate the value function, its gradient, and determine the actor's\npolicy respectively. We evaluate GProp on two challenging tasks: a contextual\nbandit problem constructed from nonparametric regression datasets that is\ndesigned to probe the ability of reinforcement learning algorithms to\naccurately estimate gradients; and the octopus arm, a challenging reinforcement\nlearning benchmark. GProp is competitive with fully supervised methods on the\nbandit task and achieves the best performance to date on the octopus arm.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 04:14:54 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Balduzzi", "David", ""], ["Ghifary", "Muhammad", ""]]}, {"id": "1509.03221", "submitter": "Sudip Mandal", "authors": "Sudip Mandal, Goutam Saha and Rajat K. Pal", "title": "Recurrent Neural Network Based Modeling of Gene Regulatory Network Using\n  Bat Algorithm", "comments": "14 pages, 4 figure. arXiv admin note: text overlap with\n  arXiv:1004.4170 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Correct inference of genetic regulations inside a cell is one of the greatest\nchallenges in post genomic era for the biologist and researchers. Several\nintelligent techniques and models were already proposed to identify the\nregulatory relations among genes from the biological database like time series\nmicroarray data. Recurrent Neural Network (RNN) is one of the most popular and\nsimple approach to model the dynamics as well as to infer correct dependencies\namong genes. In this paper, Bat Algorithm (BA) is applied to optimize the model\nparameters of RNN model of Gene Regulatory Network (GRN). Initially the\nproposed method is tested against small artificial network without any noise\nand the efficiency is observed in term of number of iteration, number of\npopulation and BA optimization parameters. The model is also validated in\npresence of different level of random noise for the small artificial network\nand that proved its ability to infer the correct inferences in presence of\nnoise like real world dataset. In the next phase of this research, BA based RNN\nis applied to real world benchmark time series microarray dataset of E. coli.\nThe results prove that it can able to identify the maximum number of true\npositive regulation but also include some false positive regulations.\nTherefore, BA is very suitable for identifying biological plausible GRN with\nthe help RNN model.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2015 10:20:44 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 08:25:40 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Mandal", "Sudip", ""], ["Saha", "Goutam", ""], ["Pal", "Rajat K.", ""]]}, {"id": "1509.03475", "submitter": "Minhyung Cho", "authors": "Minhyung Cho, Chandra Shekhar Dhir, Jaehyung Lee", "title": "Hessian-free Optimization for Learning Deep Multidimensional Recurrent\n  Neural Networks", "comments": "to appear at NIPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multidimensional recurrent neural networks (MDRNNs) have shown a remarkable\nperformance in the area of speech and handwriting recognition. The performance\nof an MDRNN is improved by further increasing its depth, and the difficulty of\nlearning the deeper network is overcome by using Hessian-free (HF)\noptimization. Given that connectionist temporal classification (CTC) is\nutilized as an objective of learning an MDRNN for sequence labeling, the\nnon-convexity of CTC poses a problem when applying HF to the network. As a\nsolution, a convex approximation of CTC is formulated and its relationship with\nthe EM algorithm and the Fisher information matrix is discussed. An MDRNN up to\na depth of 15 layers is successfully trained using HF, resulting in an improved\nperformance for sequence labeling.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 12:28:36 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2015 07:14:04 GMT"}], "update_date": "2015-10-26", "authors_parsed": [["Cho", "Minhyung", ""], ["Dhir", "Chandra Shekhar", ""], ["Lee", "Jaehyung", ""]]}, {"id": "1509.04210", "submitter": "Wei Zhang", "authors": "Suyog Gupta, Wei Zhang, Fei Wang", "title": "Model Accuracy and Runtime Tradeoff in Distributed Deep Learning:A\n  Systematic Study", "comments": "Accepted by The IEEE International Conference on Data Mining 2016\n  (ICDM 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Rudra, a parameter server based distributed computing\nframework tuned for training large-scale deep neural networks. Using variants\nof the asynchronous stochastic gradient descent algorithm we study the impact\nof synchronization protocol, stale gradient updates, minibatch size, learning\nrates, and number of learners on runtime performance and model accuracy. We\nintroduce a new learning rate modulation strategy to counter the effect of\nstale gradients and propose a new synchronization protocol that can effectively\nbound the staleness in gradients, improve runtime performance and achieve good\nmodel accuracy. Our empirical investigation reveals a principled approach for\ndistributed training of neural networks: the mini-batch size per learner should\nbe reduced as more learners are added to the system to preserve the model\naccuracy. We validate this approach using commonly-used image classification\nbenchmarks: CIFAR10 and ImageNet.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 17:14:52 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2015 01:31:18 GMT"}, {"version": "v3", "created": "Mon, 5 Dec 2016 21:26:38 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Gupta", "Suyog", ""], ["Zhang", "Wei", ""], ["Wang", "Fei", ""]]}, {"id": "1509.04438", "submitter": "Tobias Strau{\\ss}", "authors": "Tobias Strau{\\ss}, Gundram Leifert, Tobias Gr\\\"uning, and Roger Labahn", "title": "Regular expressions for decoding of neural network outputs", "comments": "21 pages, 8 (+2) figures, 2 tables", "journal-ref": null, "doi": "10.1016/j.neunet.2016.03.003", "report-no": "NN3600", "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes a convenient tool for decoding the output of neural\nnetworks trained by Connectionist Temporal Classification (CTC) for handwritten\ntext recognition. We use regular expressions to describe the complex structures\nexpected in the writing. The corresponding finite automata are employed to\nbuild a decoder. We analyze theoretically which calculations are relevant and\nwhich can be avoided. A great speed-up results from an approximation. We\nconclude that the approximation most likely fails if the regular expression\ndoes not match the ground truth which is not harmful for many applications\nsince the low probability will be even underestimated. The proposed decoder is\nvery efficient compared to other decoding methods. The variety of applications\nreaches from information retrieval to full text recognition. We refer to\napplications where we integrated the proposed decoder successfully.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 08:24:37 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2016 09:35:53 GMT"}], "update_date": "2016-03-31", "authors_parsed": [["Strau\u00df", "Tobias", ""], ["Leifert", "Gundram", ""], ["Gr\u00fcning", "Tobias", ""], ["Labahn", "Roger", ""]]}, {"id": "1509.04612", "submitter": "Alan Mosca", "authors": "Alan Mosca and George D. Magoulas", "title": "Adapting Resilient Propagation for Deep Learning", "comments": "Published in the proceedings of the UK workshop on Computational\n  Intelligence 2015 (UKCI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Resilient Propagation (Rprop) algorithm has been very popular for\nbackpropagation training of multilayer feed-forward neural networks in various\napplications. The standard Rprop however encounters difficulties in the context\nof deep neural networks as typically happens with gradient-based learning\nalgorithms. In this paper, we propose a modification of the Rprop that combines\nstandard Rprop steps with a special drop out technique. We apply the method for\ntraining Deep Neural Networks as standalone components and in ensemble\nformulations. Results on the MNIST dataset show that the proposed modification\nalleviates standard Rprop's problems demonstrating improved learning speed and\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 15:55:29 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2015 11:45:48 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Mosca", "Alan", ""], ["Magoulas", "George D.", ""]]}, {"id": "1509.05009", "submitter": "Nadav Cohen", "authors": "Nadav Cohen, Or Sharir, Amnon Shashua", "title": "On the Expressive Power of Deep Learning: A Tensor Analysis", "comments": null, "journal-ref": "29th Annual Conference on Learning Theory, pp. 698-728, 2016", "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has long been conjectured that hypotheses spaces suitable for data that is\ncompositional in nature, such as text or images, may be more efficiently\nrepresented with deep hierarchical networks than with shallow ones. Despite the\nvast empirical evidence supporting this belief, theoretical justifications to\ndate are limited. In particular, they do not account for the locality, sharing\nand pooling constructs of convolutional networks, the most successful deep\nlearning architecture to date. In this work we derive a deep network\narchitecture based on arithmetic circuits that inherently employs locality,\nsharing and pooling. An equivalence between the networks and hierarchical\ntensor factorizations is established. We show that a shallow network\ncorresponds to CP (rank-1) decomposition, whereas a deep network corresponds to\nHierarchical Tucker decomposition. Using tools from measure theory and matrix\nalgebra, we prove that besides a negligible set, all functions that can be\nimplemented by a deep network of polynomial size, require exponential size in\norder to be realized (or even approximated) by a shallow network. Since\nlog-space computation transforms our networks into SimNets, the result applies\ndirectly to a deep learning architecture demonstrating promising empirical\nperformance. The construction and theory developed in this paper shed new light\non various practices and ideas employed by the deep learning community.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2015 19:32:54 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2016 16:31:49 GMT"}, {"version": "v3", "created": "Fri, 27 May 2016 19:07:22 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Cohen", "Nadav", ""], ["Sharir", "Or", ""], ["Shashua", "Amnon", ""]]}, {"id": "1509.05177", "submitter": "Kumar Eswaran Dr.", "authors": "K. Eswaran and Vishwajeet Singh", "title": "Some Theorems for Feed Forward Neural Networks", "comments": "15 pages 13 figures", "journal-ref": null, "doi": "10.5120/ijca2015907021", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new method which employs the concept of\n\"Orientation Vectors\" to train a feed forward neural network and suitable for\nproblems where large dimensions are involved and the clusters are\ncharacteristically sparse. The new method is not NP hard as the problem size\nincreases. We `derive' the method by starting from Kolmogrov's method and then\nrelax some of the stringent conditions. We show for most classification\nproblems three layers are sufficient and the network size depends on the number\nof clusters. We prove as the number of clusters increase from N to N+dN the\nnumber of processing elements in the first layer only increases by d(logN), and\nare proportional to the number of classes, and the method is not NP hard.\n  Many examples are solved to demonstrate that the method of Orientation\nVectors requires much less computational effort than Radial Basis Function\nmethods and other techniques wherein distance computations are required, in\nfact the present method increases logarithmically with problem size compared to\nthe Radial Basis Function method and the other methods which depend on distance\ncomputations e.g statistical methods where probabilistic distances are\ncalculated. A practical method of applying the concept of Occum's razor to\nchoose between two architectures which solve the same classification problem\nhas been described. The ramifications of the above findings on the field of\nDeep Learning have also been briefly investigated and we have found that it\ndirectly leads to the existence of certain types of NN architectures which can\nbe used as a \"mapping engine\", which has the property of \"invertibility\", thus\nimproving the prospect of their deployment for solving problems involving Deep\nLearning and hierarchical classification. The latter possibility has a lot of\nfuture scope in the areas of machine learning and cloud computing.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 09:17:59 GMT"}, {"version": "v2", "created": "Mon, 21 Sep 2015 09:11:04 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2015 15:55:06 GMT"}, {"version": "v4", "created": "Thu, 15 Oct 2015 11:31:46 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Eswaran", "K.", ""], ["Singh", "Vishwajeet", ""]]}, {"id": "1509.05646", "submitter": "Peter Kvam", "authors": "Peter Kvam, Joseph Cesario, Jory Schossau, Heather Eisthen, Arend\n  Hintze", "title": "Computational evolution of decision-making strategies", "comments": "Conference paper, 6 pages / 3 figures", "journal-ref": "Proceedings of the 37th Annual Meeting of the Cognitive Science\n  Society, 2015, pp. 1225-1230. Cognitive Science Society, Austin, TX", "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most research on adaptive decision-making takes a strategy-first approach,\nproposing a method of solving a problem and then examining whether it can be\nimplemented in the brain and in what environments it succeeds. We present a\nmethod for studying strategy development based on computational evolution that\ntakes the opposite approach, allowing strategies to develop in response to the\ndecision-making environment via Darwinian evolution. We apply this approach to\na dynamic decision-making problem where artificial agents make decisions about\nthe source of incoming information. In doing so, we show that the complexity of\nthe brains and strategies of evolved agents are a function of the environment\nin which they develop. More difficult environments lead to larger brains and\nmore information use, resulting in strategies resembling a sequential sampling\napproach. Less difficult environments drive evolution toward smaller brains and\nless information use, resulting in simpler heuristic-like strategies.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 15:02:39 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Kvam", "Peter", ""], ["Cesario", "Joseph", ""], ["Schossau", "Jory", ""], ["Eisthen", "Heather", ""], ["Hintze", "Arend", ""]]}, {"id": "1509.05936", "submitter": "Yoshua Bengio", "authors": "Yoshua Bengio, Thomas Mesnard, Asja Fischer, Saizheng Zhang and Yuhuai\n  Wu", "title": "STDP as presynaptic activity times rate of change of postsynaptic\n  activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a weight update formula that is expressed only in terms of\nfiring rates and their derivatives and that results in changes consistent with\nthose associated with spike-timing dependent plasticity (STDP) rules and\nbiological observations, even though the explicit timing of spikes is not\nneeded. The new rule changes a synaptic weight in proportion to the product of\nthe presynaptic firing rate and the temporal rate of change of activity on the\npostsynaptic side. These quantities are interesting for studying theoretical\nexplanation for synaptic changes from a machine learning perspective. In\nparticular, if neural dynamics moved neural activity towards reducing some\nobjective function, then this STDP rule would correspond to stochastic gradient\ndescent on that objective function.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2015 21:05:18 GMT"}, {"version": "v2", "created": "Mon, 21 Mar 2016 10:54:18 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Bengio", "Yoshua", ""], ["Mesnard", "Thomas", ""], ["Fischer", "Asja", ""], ["Zhang", "Saizheng", ""], ["Wu", "Yuhuai", ""]]}, {"id": "1509.05962", "submitter": "Rakesh Achanta", "authors": "Rakesh Achanta, Trevor Hastie", "title": "Telugu OCR Framework using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the task of Optical Character Recognition(OCR) for\nthe Telugu script. We present an end-to-end framework that segments the text\nimage, classifies the characters and extracts lines using a language model. The\nsegmentation is based on mathematical morphology. The classification module,\nwhich is the most challenging task of the three, is a deep convolutional neural\nnetwork. The language is modelled as a third degree markov chain at the glyph\nlevel. Telugu script is a complex alphasyllabary and the language is\nagglutinative, making the problem hard. In this paper we apply the latest\nadvances in neural networks to achieve state-of-the-art error rates. We also\nreview convolutional neural networks in great detail and expound the\nstatistical justification behind the many tricks needed to make Deep Learning\nwork.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2015 03:35:05 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 02:29:04 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Achanta", "Rakesh", ""], ["Hastie", "Trevor", ""]]}, {"id": "1509.05982", "submitter": "Dan Stowell", "authors": "Dan Stowell and Richard E. Turner", "title": "Denoising without access to clean data using a partitioned autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Training a denoising autoencoder neural network requires access to truly\nclean data, a requirement which is often impractical. To remedy this, we\nintroduce a method to train an autoencoder using only noisy data, having\nexamples with and without the signal class of interest. The autoencoder learns\na partitioned representation of signal and noise, learning to reconstruct each\nseparately. We illustrate the method by denoising birdsong audio (available\nabundantly in uncontrolled noisy datasets) using a convolutional autoencoder.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2015 09:03:48 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2015 20:51:05 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Stowell", "Dan", ""], ["Turner", "Richard E.", ""]]}, {"id": "1509.06057", "submitter": "Carlos Hugo L\\'opez Caraballo", "authors": "C. H. L\\'opez-Caraballo, J. A. Lazz\\'us, I. Salfate, P. Rojas, M.\n  Rivera and L. Palma-Chilla (Departamento de F\\'isica y Astronom\\'ia,\n  Universidad de La Serena, Casilla 554, La Serena, Chile)", "title": "Impact of noise on a dynamical system: prediction and uncertainties from\n  a swarm-optimized neural network", "comments": "11 pages, 8 figures", "journal-ref": "Computational Intelligence and Neuroscience. Volume 2015 (2015),\n  Article ID 145874, 10 pages", "doi": "10.1155/2015/145874", "report-no": null, "categories": "physics.comp-ph cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, an artificial neural network (ANN) based on particle swarm\noptimization (PSO) was developed for the time series prediction. The hybrid\nANN+PSO algorithm was applied on Mackey--Glass chaotic time series in the\nshort-term $x(t+6)$. The performance prediction was evaluated and compared with\nanother studies available in the literature. Also, we presented properties of\nthe dynamical system via the study of chaotic behaviour obtained from the\npredicted time series. Next, the hybrid ANN+PSO algorithm was complemented with\na Gaussian stochastic procedure (called {\\it stochastic} hybrid ANN+PSO) in\norder to obtain a new estimator of the predictions, which also allowed us to\ncompute uncertainties of predictions for noisy Mackey--Glass chaotic time\nseries. Thus, we studied the impact of noise for several cases with a white\nnoise level ($\\sigma_{N}$) from 0.01 to 0.1.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2015 21:09:35 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["L\u00f3pez-Caraballo", "C. H.", "", "Departamento de F\u00edsica y Astronom\u00eda,\n  Universidad de La Serena, Casilla 554, La Serena, Chile"], ["Lazz\u00fas", "J. A.", "", "Departamento de F\u00edsica y Astronom\u00eda,\n  Universidad de La Serena, Casilla 554, La Serena, Chile"], ["Salfate", "I.", "", "Departamento de F\u00edsica y Astronom\u00eda,\n  Universidad de La Serena, Casilla 554, La Serena, Chile"], ["Rojas", "P.", "", "Departamento de F\u00edsica y Astronom\u00eda,\n  Universidad de La Serena, Casilla 554, La Serena, Chile"], ["Rivera", "M.", "", "Departamento de F\u00edsica y Astronom\u00eda,\n  Universidad de La Serena, Casilla 554, La Serena, Chile"], ["Palma-Chilla", "L.", "", "Departamento de F\u00edsica y Astronom\u00eda,\n  Universidad de La Serena, Casilla 554, La Serena, Chile"]]}, {"id": "1509.06420", "submitter": "Soumya Banerjee", "authors": "Soumya Banerjee and Joshua Hecker", "title": "A Multi-Agent System Approach to Load-Balancing and Resource Allocation\n  for Distributed Computing", "comments": "Complex Systems Digital Campus 2015 World eConference Conference on\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research we use a decentralized computing approach to allocate and\nschedule tasks on a massively distributed grid. Using emergent properties of\nmulti-agent systems, the algorithm dynamically creates and dissociates clusters\nto serve the changing resource demands of a global task queue. The algorithm is\ncompared to a standard First-in First-out (FIFO) scheduling algorithm.\nExperiments done on a simulator show that the distributed resource allocation\nprotocol (dRAP) algorithm outperforms the FIFO scheduling algorithm on time to\nempty queue, average waiting time and CPU utilization. Such a decentralized\ncomputing approach holds promise for massively distributed processing scenarios\nlike SETI@home and Google MapReduce.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 22:41:36 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Banerjee", "Soumya", ""], ["Hecker", "Joshua", ""]]}, {"id": "1509.06535", "submitter": "Malte Probst", "authors": "Malte Probst, Franz Rothlauf", "title": "Deep Boltzmann Machines in Estimation of Distribution Algorithms for\n  Combinatorial Optimization", "comments": "arXiv admin note: text overlap with arXiv:1503.01954", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of Distribution Algorithms (EDAs) require flexible probability\nmodels that can be efficiently learned and sampled. Deep Boltzmann Machines\n(DBMs) are generative neural networks with these desired properties. We\nintegrate a DBM into an EDA and evaluate the performance of this system in\nsolving combinatorial optimization problems with a single objective. We compare\nthe results to the Bayesian Optimization Algorithm. The performance of DBM-EDA\nwas superior to BOA for difficult additively decomposable functions, i.e.,\nconcatenated deceptive traps of higher order. For most other benchmark\nproblems, DBM-EDA cannot clearly outperform BOA, or other neural network-based\nEDAs. In particular, it often yields optimal solutions for a subset of the runs\n(with fewer evaluations than BOA), but is unable to provide reliable\nconvergence to the global optimum competitively. At the same time, the model\nbuilding process is computationally more expensive than that of other EDAs\nusing probabilistic models from the neural network family, such as DAE-EDA.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2015 10:03:43 GMT"}, {"version": "v2", "created": "Mon, 8 Aug 2016 13:22:40 GMT"}], "update_date": "2016-08-09", "authors_parsed": [["Probst", "Malte", ""], ["Rothlauf", "Franz", ""]]}, {"id": "1509.06569", "submitter": "Alexander Novikov", "authors": "Alexander Novikov, Dmitry Podoprikhin, Anton Osokin, Dmitry Vetrov", "title": "Tensorizing Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks currently demonstrate state-of-the-art performance in\nseveral domains. At the same time, models of this class are very demanding in\nterms of computational resources. In particular, a large amount of memory is\nrequired by commonly used fully-connected layers, making it hard to use the\nmodels on low-end devices and stopping the further increase of the model size.\nIn this paper we convert the dense weight matrices of the fully-connected\nlayers to the Tensor Train format such that the number of parameters is reduced\nby a huge factor and at the same time the expressive power of the layer is\npreserved. In particular, for the Very Deep VGG networks we report the\ncompression factor of the dense weight matrix of a fully-connected layer up to\n200000 times leading to the compression factor of the whole network up to 7\ntimes.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2015 12:31:03 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2015 11:44:05 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Novikov", "Alexander", ""], ["Podoprikhin", "Dmitry", ""], ["Osokin", "Anton", ""], ["Vetrov", "Dmitry", ""]]}, {"id": "1509.06664", "submitter": "Tim Rockt\\\"aschel", "authors": "Tim Rockt\\\"aschel, Edward Grefenstette, Karl Moritz Hermann,\n  Tom\\'a\\v{s} Ko\\v{c}isk\\'y, Phil Blunsom", "title": "Reasoning about Entailment with Neural Attention", "comments": "ICLR 2016 camera-ready, 9 pages, 10 figures (incl. subfigures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most approaches to automatically recognizing entailment relations have\nused classifiers employing hand engineered features derived from complex\nnatural language processing pipelines, in practice their performance has been\nonly slightly better than bag-of-word pair classifiers using only lexical\nsimilarity. The only attempt so far to build an end-to-end differentiable\nneural network for entailment failed to outperform such a simple similarity\nclassifier. In this paper, we propose a neural model that reads two sentences\nto determine entailment using long short-term memory units. We extend this\nmodel with a word-by-word neural attention mechanism that encourages reasoning\nover entailments of pairs of words and phrases. Furthermore, we present a\nqualitative analysis of attention weights produced by this model, demonstrating\nsuch reasoning capabilities. On a large entailment dataset this model\noutperforms the previous best neural model and a classifier with engineered\nfeatures by a substantial margin. It is the first generic end-to-end\ndifferentiable system that achieves state-of-the-art accuracy on a textual\nentailment dataset.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2015 16:08:24 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2015 22:12:52 GMT"}, {"version": "v3", "created": "Mon, 18 Jan 2016 17:28:30 GMT"}, {"version": "v4", "created": "Tue, 1 Mar 2016 10:32:06 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Rockt\u00e4schel", "Tim", ""], ["Grefenstette", "Edward", ""], ["Hermann", "Karl Moritz", ""], ["Ko\u010disk\u00fd", "Tom\u00e1\u0161", ""], ["Blunsom", "Phil", ""]]}, {"id": "1509.06839", "submitter": "Srinivasan Seshadhri", "authors": "B. Sreram, F. Bounapane, B. Subathra, Seshadhri Srinivasan", "title": "Estimating Random Delays in Modbus Network Using Experiments and General\n  Linear Regression Neural Networks with Genetic Algorithm Smoothing", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-varying delays adversely affect the performance of networked control\nsys-tems (NCS) and in the worst-case can destabilize the entire system.\nTherefore, modelling network delays is important for designing NCS. However,\nmodelling time-varying delays is challenging because of their dependence on\nmultiple pa-rameters such as length, contention, connected devices, protocol\nemployed, and channel loading. Further, these multiple parameters are\ninherently random and de-lays vary in a non-linear fashion with respect to\ntime. This makes estimating ran-dom delays challenging. This investigation\npresents a methodology to model de-lays in NCS using experiments and general\nregression neural network (GRNN) due to their ability to capture non-linear\nrelationship. To compute the optimal smoothing parameter that computes the best\nestimates, genetic algorithm is used. The objective of the genetic algorithm is\nto compute the optimal smoothing pa-rameter that minimizes the mean absolute\npercentage error (MAPE). Our results illustrate that the resulting GRNN is able\nto predict the delays with less than 3% error. The proposed delay model gives a\nframework to design compensation schemes for NCS subjected to time-varying\ndelays.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 20:32:39 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Sreram", "B.", ""], ["Bounapane", "F.", ""], ["Subathra", "B.", ""], ["Srinivasan", "Seshadhri", ""]]}, {"id": "1509.06842", "submitter": "Shayan Poursoltan Mr", "authors": "Shayan Poursoltan, Frank Neumann", "title": "A Feature-Based Comparison of Evolutionary Computing Techniques for\n  Constrained Continuous Optimisation", "comments": "16 Pagesm 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary algorithms have been frequently applied to constrained\ncontinuous optimisation problems. We carry out feature based comparisons of\ndifferent types of evolutionary algorithms such as evolution strategies,\ndifferential evolution and particle swarm optimisation for constrained\ncontinuous optimisation. In our study, we examine how sets of constraints\ninfluence the difficulty of obtaining close to optimal solutions. Using a\nmulti-objective approach, we evolve constrained continuous problems having a\nset of linear and/or quadratic constraints where the different evolutionary\napproaches show a significant difference in performance. Afterwards, we discuss\nthe features of the constraints that exhibit a difference in performance of the\ndifferent evolutionary approaches under consideration.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 04:30:05 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Poursoltan", "Shayan", ""], ["Neumann", "Frank", ""]]}, {"id": "1509.07035", "submitter": "David Sousa-Rodrigues", "authors": "Cristian Jimenez-Romero and David Sousa-Rodrigues and Jeffrey H.\n  Johnson", "title": "Designing Behaviour in Bio-inspired Robots Using Associative Topologies\n  of Spiking-Neural-Networks", "comments": "Paper submitted to the BICT 2015 Conference in New York City, United\n  States", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study explores the design and control of the behaviour of agents and\nrobots using simple circuits of spiking neurons and Spike Timing Dependent\nPlasticity (STDP) as a mechanism of associative and unsupervised learning.\nBased on a \"reward and punishment\" classical conditioning, it is demonstrated\nthat these robots learnt to identify and avoid obstacles as well as to identify\nand look for rewarding stimuli. Using the simulation and programming\nenvironment NetLogo, a software engine for the Integrate and Fire model was\ndeveloped, which allowed us to monitor in discrete time steps the dynamics of\neach single neuron, synapse and spike in the proposed neural networks. These\nspiking neural networks (SNN) served as simple brains for the experimental\nrobots. The Lego Mindstorms robot kit was used for the embodiment of the\nsimulated agents. In this paper the topological building blocks are presented\nas well as the neural parameters required to reproduce the experiments. This\npaper summarizes the resulting behaviour as well as the observed dynamics of\nthe neural circuits. The Internet-link to the NetLogo code is included in the\nannex.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 15:40:30 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2015 14:29:14 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Jimenez-Romero", "Cristian", ""], ["Sousa-Rodrigues", "David", ""], ["Johnson", "Jeffrey H.", ""]]}, {"id": "1509.07079", "submitter": "Soumi Chaki", "authors": "Soumi Chaki, Akhilesh K Verma, Aurobinda Routray, William K Mohanty,\n  Mamata Jenamani", "title": "Well Tops Guided Prediction of Reservoir Properties using Modular Neural\n  Network Concept A Case Study from Western Onshore, India", "comments": "in Journal of Petroleum Science and Engineering, 2014", "journal-ref": null, "doi": "10.1016/j.petrol.2014.06.019", "report-no": null, "categories": "cs.NE cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a complete framework consisting pre-processing, modeling,\nand post-processing stages to carry out well tops guided prediction of a\nreservoir property (sand fraction) from three seismic attributes (seismic\nimpedance, instantaneous amplitude, and instantaneous frequency) using the\nconcept of modular artificial neural network (MANN). The data set used in this\nstudy comprising three seismic attributes and well log data from eight wells,\nis acquired from a western onshore hydrocarbon field of India. Firstly, the\nacquired data set is integrated and normalized. Then, well log analysis and\nsegmentation of the total depth range into three different units (zones)\nseparated by well tops are carried out. Secondly, three different networks are\ntrained corresponding to three different zones using combined data set of seven\nwells and then trained networks are validated using the remaining test well.\nThe target property of the test well is predicted using three different tuned\nnetworks corresponding to three zones; and then the estimated values obtained\nfrom three different networks are concatenated to represent the predicted log\nalong the complete depth range of the testing well. The application of multiple\nsimpler networks instead of a single one improves the prediction accuracy in\nterms of performance metrics such as correlation coefficient, root mean square\nerror, absolute error mean and program execution time.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 18:09:36 GMT"}], "update_date": "2015-10-06", "authors_parsed": [["Chaki", "Soumi", ""], ["Verma", "Akhilesh K", ""], ["Routray", "Aurobinda", ""], ["Mohanty", "William K", ""], ["Jenamani", "Mamata", ""]]}, {"id": "1509.07093", "submitter": "Pablo Estevez Prof.", "authors": "David Nova and Pablo A. Estevez", "title": "A review of learning vector quantization classifiers", "comments": "14 pages", "journal-ref": "Neural Computing & Applications, vol. 25, pp. 511-524, 2014", "doi": "10.1007/s00521-013-1535-3", "report-no": null, "categories": "cs.LG astro-ph.IM cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present a review of the state of the art of Learning Vector\nQuantization (LVQ) classifiers. A taxonomy is proposed which integrates the\nmost relevant LVQ approaches to date. The main concepts associated with modern\nLVQ approaches are defined. A comparison is made among eleven LVQ classifiers\nusing one real-world and two artificial datasets.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 18:46:31 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Nova", "David", ""], ["Estevez", "Pablo A.", ""]]}, {"id": "1509.07302", "submitter": "Bruno Umbria Pedroni", "authors": "Bruno U. Pedroni, Srinjoy Das, John V. Arthur, Paul A. Merolla, Bryan\n  L. Jackson, Dharmendra S. Modha, Kenneth Kreutz-Delgado, and Gert\n  Cauwenberghs", "title": "Mapping Generative Models onto a Network of Digital Spiking Neurons", "comments": "A similar version of this manuscript has been submitted to IEEE\n  TBioCAS for revision in October 2015", "journal-ref": null, "doi": "10.1109/TBCAS.2016.2539352", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic neural networks such as Restricted Boltzmann Machines (RBMs) have\nbeen successfully used in applications ranging from speech recognition to image\nclassification. Inference and learning in these algorithms use a Markov Chain\nMonte Carlo procedure called Gibbs sampling, where a logistic function forms\nthe kernel of this sampler. On the other side of the spectrum, neuromorphic\nsystems have shown great promise for low-power and parallelized cognitive\ncomputing, but lack well-suited applications and automation procedures. In this\nwork, we propose a systematic method for bridging the RBM algorithm and digital\nneuromorphic systems, with a generative pattern completion task as proof of\nconcept. For this, we first propose a method of producing the Gibbs sampler\nusing bio-inspired digital noisy integrate-and-fire neurons. Next, we describe\nthe process of mapping generative RBMs trained offline onto the IBM TrueNorth\nneurosynaptic processor -- a low-power digital neuromorphic VLSI substrate.\nMapping these algorithms onto neuromorphic hardware presents unique challenges\nin network connectivity and weight and bias quantization, which, in turn,\nrequire architectural and design strategies for the physical realization.\nGenerative performance metrics are analyzed to validate the neuromorphic\nrequirements and to best select the neuron parameters for the model. Lastly, we\ndescribe a design automation procedure which achieves optimal resource usage,\naccounting for the novel hardware adaptations. This work represents the first\nimplementation of generative RBM inference on a neuromorphic VLSI substrate.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 10:25:03 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2015 21:06:02 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Pedroni", "Bruno U.", ""], ["Das", "Srinjoy", ""], ["Arthur", "John V.", ""], ["Merolla", "Paul A.", ""], ["Jackson", "Bryan L.", ""], ["Modha", "Dharmendra S.", ""], ["Kreutz-Delgado", "Kenneth", ""], ["Cauwenberghs", "Gert", ""]]}, {"id": "1509.07385", "submitter": "Uri Shaham", "authors": "Uri Shaham, Alexander Cloninger, Ronald R. Coifman", "title": "Provable approximation properties for deep neural networks", "comments": "accepted for publication in Applied and Computational Harmonic\n  Analysis", "journal-ref": null, "doi": "10.1016/j.acha.2016.04.003", "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss approximation of functions using deep neural nets. Given a\nfunction $f$ on a $d$-dimensional manifold $\\Gamma \\subset \\mathbb{R}^m$, we\nconstruct a sparsely-connected depth-4 neural network and bound its error in\napproximating $f$. The size of the network depends on dimension and curvature\nof the manifold $\\Gamma$, the complexity of $f$, in terms of its wavelet\ndescription, and only weakly on the ambient dimension $m$. Essentially, our\nnetwork computes wavelet functions, which are computed from Rectified Linear\nUnits (ReLU)\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 14:20:29 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2015 14:31:54 GMT"}, {"version": "v3", "created": "Mon, 28 Mar 2016 13:46:06 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Shaham", "Uri", ""], ["Cloninger", "Alexander", ""], ["Coifman", "Ronald R.", ""]]}, {"id": "1509.07946", "submitter": "Bo Song", "authors": "Bo Song and Victor O.K. Li", "title": "A Revisit of Infinite Population Models for Evolutionary Algorithms on\n  Continuous Optimization Problems", "comments": "Submitted to IEEE Transactions on Evolutionary Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infinite population models are important tools for studying population\ndynamics of evolutionary algorithms. They describe how the distributions of\npopulations change between consecutive generations. In general, infinite\npopulation models are derived from Markov chains by exploiting symmetries\nbetween individuals in the population and analyzing the limit as the population\nsize goes to infinity. In this paper, we study the theoretical foundations of\ninfinite population models of evolutionary algorithms on continuous\noptimization problems. First, we show that the convergence proofs in a widely\ncited study were in fact problematic and incomplete. We further show that the\nmodeling assumption of exchangeability of individuals cannot yield the\ntransition equation. Then, in order to analyze infinite population models, we\nbuild an analytical framework based on convergence in distribution of random\nelements which take values in the metric space of infinite sequences. The\nframework is concise and mathematically rigorous. It also provides an\ninfrastructure for studying the convergence of the stacking of operators and of\niterating the algorithm which previous studies failed to address. Finally, we\nuse the framework to prove the convergence of infinite population models for\nthe mutation operator and the $k$-ary recombination operator. We show that\nthese operators can provide accurate predictions for real population dynamics\nas the population size goes to infinity, provided that the initial population\nis identically and independently distributed.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2015 05:36:00 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Song", "Bo", ""], ["Li", "Victor O. K.", ""]]}, {"id": "1509.08038", "submitter": "Wentao Zhu", "authors": "Wentao Zhu, Jun Miao, Laiyun Qing, Xilin Chen", "title": "Deep Trans-layer Unsupervised Networks for Representation Learning", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning features from massive unlabelled data is a vast prevalent topic for\nhigh-level tasks in many machine learning applications. The recent great\nimprovements on benchmark data sets achieved by increasingly complex\nunsupervised learning methods and deep learning models with lots of parameters\nusually requires many tedious tricks and much expertise to tune. However,\nfilters learned by these complex architectures are quite similar to standard\nhand-crafted features visually. In this paper, unsupervised learning methods,\nsuch as PCA or auto-encoder, are employed as the building block to learn filter\nbanks at each layer. The lower layer responses are transferred to the last\nlayer (trans-layer) to form a more complete representation retaining more\ninformation. In addition, some beneficial methods such as local contrast\nnormalization and whitening are added to the proposed deep trans-layer networks\nto further boost performance. The trans-layer representations are followed by\nblock histograms with binary encoder schema to learn translation and rotation\ninvariant representations, which are utilized to do high-level tasks such as\nrecognition and classification. Compared to traditional deep learning methods,\nthe implemented feature learning method has much less parameters and is\nvalidated in several typical experiments, such as digit recognition on MNIST\nand MNIST variations, object recognition on Caltech 101 dataset and face\nverification on LFW dataset. The deep trans-layer unsupervised learning\nachieves 99.45% accuracy on MNIST dataset, 67.11% accuracy on 15 samples per\nclass and 75.98% accuracy on 30 samples per class on Caltech 101 dataset,\n87.10% on LFW dataset.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2015 00:46:08 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Zhu", "Wentao", ""], ["Miao", "Jun", ""], ["Qing", "Laiyun", ""], ["Chen", "Xilin", ""]]}, {"id": "1509.08101", "submitter": "Matus Telgarsky", "authors": "Matus Telgarsky", "title": "Representation Benefits of Deep Feedforward Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note provides a family of classification problems, indexed by a positive\ninteger $k$, where all shallow networks with fewer than exponentially (in $k$)\nmany nodes exhibit error at least $1/6$, whereas a deep network with 2 nodes in\neach of $2k$ layers achieves zero error, as does a recurrent network with 3\ndistinct nodes iterated $k$ times. The proof is elementary, and the networks\nare standard feedforward networks with ReLU (Rectified Linear Unit)\nnonlinearities.\n", "versions": [{"version": "v1", "created": "Sun, 27 Sep 2015 15:26:58 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2015 13:44:37 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Telgarsky", "Matus", ""]]}, {"id": "1509.08255", "submitter": "Fergal Byrne", "authors": "Fergal Byrne", "title": "Encoding Reality: Prediction-Assisted Cortical Learning Algorithm in\n  Hierarchical Temporal Memory", "comments": "Updated reference to unofficial revision of Hawkins and Ahmad, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In the decade since Jeff Hawkins proposed Hierarchical Temporal Memory (HTM)\nas a model of neocortical computation, the theory and the algorithms have\nevolved dramatically. This paper presents a detailed description of HTM's\nCortical Learning Algorithm (CLA), including for the first time a rigorous\nmathematical formulation of all aspects of the computations. Prediction\nAssisted CLA (paCLA), a refinement of the CLA is presented, which is both\ncloser to the neuroscience and adds significantly to the computational power.\nFinally, we summarise the key functions of neocortex which are expressed in\npaCLA implementations.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 09:54:08 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2015 16:13:44 GMT"}], "update_date": "2015-10-09", "authors_parsed": [["Byrne", "Fergal", ""]]}, {"id": "1509.08302", "submitter": "Elham Shadkam", "authors": "Mahdi parvizi, Elham Shadkam, Niloofar Jahani", "title": "A hybrid COA$\\epsilon$-constraint method for solving multi-objective\n  problems", "comments": null, "journal-ref": null, "doi": "10.5121/ijfcst.2015.5503", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a hybrid method for solving multi-objective problem has been\nprovided. The proposed method is combining the {\\epsilon}-Constraint and the\nCuckoo algorithm. First the multi objective problem transfers into a\nsingle-objective problem using $\\epsilon$-Constraint, then the Cuckoo\noptimization algorithm will optimize the problem in each task. At last the\noptimized Pareto frontier will be drawn. The advantage of this method is the\nhigh accuracy and the dispersion of its Pareto frontier. In order to testing\nthe efficiency of the suggested method, a lot of test problems have been solved\nusing this method. Comparing the results of this method with the results of\nother similar methods shows that the Cuckoo algorithm is more suitable for\nsolving the multi-objective problems.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2015 11:26:39 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["parvizi", "Mahdi", ""], ["Shadkam", "Elham", ""], ["Jahani", "Niloofar", ""]]}, {"id": "1509.08627", "submitter": "David Balduzzi", "authors": "David Balduzzi", "title": "Semantics, Representations and Grammars for Deep Learning", "comments": "20 pages, many diagrams", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is currently the subject of intensive study. However,\nfundamental concepts such as representations are not formally defined --\nresearchers \"know them when they see them\" -- and there is no common language\nfor describing and analyzing algorithms. This essay proposes an abstract\nframework that identifies the essential features of current practice and may\nprovide a foundation for future developments.\n  The backbone of almost all deep learning algorithms is backpropagation, which\nis simply a gradient computation distributed over a neural network. The main\ningredients of the framework are thus, unsurprisingly: (i) game theory, to\nformalize distributed optimization; and (ii) communication protocols, to track\nthe flow of zeroth and first-order information. The framework allows natural\ndefinitions of semantics (as the meaning encoded in functions), representations\n(as functions whose semantics is chosen to optimized a criterion) and grammars\n(as communication protocols equipped with first-order convergence guarantees).\n  Much of the essay is spent discussing examples taken from the literature. The\nultimate aim is to develop a graphical language for describing the structure of\ndeep learning algorithms that backgrounds the details of the optimization\nprocedure and foregrounds how the components interact. Inspiration is taken\nfrom probabilistic graphical models and factor graphs, which capture the\nessential structural features of multivariate distributions.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 08:14:21 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Balduzzi", "David", ""]]}, {"id": "1509.08634", "submitter": "Takayuki Osogami", "authors": "Takayuki Osogami and Makoto Otsuka", "title": "Learning dynamic Boltzmann machines with spike-timing dependent\n  plasticity", "comments": "Preliminary and substantially different version of the paper appeared\n  in http://www.nature.com/articles/srep14149", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a particularly structured Boltzmann machine, which we refer to as\na dynamic Boltzmann machine (DyBM), as a stochastic model of a\nmulti-dimensional time-series. The DyBM can have infinitely many layers of\nunits but allows exact and efficient inference and learning when its parameters\nhave a proposed structure. This proposed structure is motivated by postulates\nand observations, from biological neural networks, that the synaptic weight is\nstrengthened or weakened, depending on the timing of spikes (i.e., spike-timing\ndependent plasticity or STDP). We show that the learning rule of updating the\nparameters of the DyBM in the direction of maximizing the likelihood of given\ntime-series can be interpreted as STDP with long term potentiation and long\nterm depression. The learning rule has a guarantee of convergence and can be\nperformed in a distributed matter (i.e., local in space) with limited memory\n(i.e., local in time).\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 08:30:12 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Osogami", "Takayuki", ""], ["Otsuka", "Makoto", ""]]}, {"id": "1509.08644", "submitter": "Krzysztof Wo{\\l}k", "authors": "Krzysztof Wo{\\l}k, Krzysztof Marasek", "title": "Neural-based machine translation for medical text domain. Based on\n  European Medicines Agency leaflet texts", "comments": "machine translation, statistical machine translation, neural machine\n  trasnlation, nlp, text processing, medical communication", "journal-ref": "Procedia Computer Science, 2015, 64: 2-9", "doi": "10.1016/j.procs.2015.08.456", "report-no": null, "categories": "cs.CL cs.CY cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quality of machine translation is rapidly evolving. Today one can find\nseveral machine translation systems on the web that provide reasonable\ntranslations, although the systems are not perfect. In some specific domains,\nthe quality may decrease. A recently proposed approach to this domain is neural\nmachine translation. It aims at building a jointly-tuned single neural network\nthat maximizes translation performance, a very different approach from\ntraditional statistical machine translation. Recently proposed neural machine\ntranslation models often belong to the encoder-decoder family in which a source\nsentence is encoded into a fixed length vector that is, in turn, decoded to\ngenerate a translation. The present research examines the effects of different\ntraining methods on a Polish-English Machine Translation system used for\nmedical data. The European Medicines Agency parallel text corpus was used as\nthe basis for training of neural and statistical network-based translation\nsystems. The main machine translation evaluation metrics have also been used in\nanalysis of the systems. A comparison and implementation of a real-time medical\ntranslator is the main focus of our experiments.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 08:54:48 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Wo\u0142k", "Krzysztof", ""], ["Marasek", "Krzysztof", ""]]}, {"id": "1509.08745", "submitter": "Vincent Gripon", "authors": "Guillaume Souli\\'e, Vincent Gripon, Ma\\\"elys Robert", "title": "Compression of Deep Neural Networks on the Fly", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to their state-of-the-art performance, deep neural networks are\nincreasingly used for object recognition. To achieve these results, they use\nmillions of parameters to be trained. However, when targeting embedded\napplications the size of these models becomes problematic. As a consequence,\ntheir usage on smartphones or other resource limited devices is prohibited. In\nthis paper we introduce a novel compression method for deep neural networks\nthat is performed during the learning phase. It consists in adding an extra\nregularization term to the cost function of fully-connected layers. We combine\nthis method with Product Quantization (PQ) of the trained weights for higher\nsavings in storage consumption. We evaluate our method on two data sets (MNIST\nand CIFAR10), on which we achieve significantly larger compression rates than\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 13:32:30 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2015 10:22:13 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2015 13:08:50 GMT"}, {"version": "v4", "created": "Thu, 7 Jan 2016 12:58:32 GMT"}, {"version": "v5", "created": "Fri, 18 Mar 2016 09:33:01 GMT"}], "update_date": "2016-03-21", "authors_parsed": [["Souli\u00e9", "Guillaume", ""], ["Gripon", "Vincent", ""], ["Robert", "Ma\u00eblys", ""]]}, {"id": "1509.08967", "submitter": "Tom Sercu", "authors": "Tom Sercu, Christian Puhrsch, Brian Kingsbury, Yann LeCun", "title": "Very Deep Multilingual Convolutional Neural Networks for LVCSR", "comments": "Accepted for publication at ICASSP 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are a standard component of many current\nstate-of-the-art Large Vocabulary Continuous Speech Recognition (LVCSR)\nsystems. However, CNNs in LVCSR have not kept pace with recent advances in\nother domains where deeper neural networks provide superior performance. In\nthis paper we propose a number of architectural advances in CNNs for LVCSR.\nFirst, we introduce a very deep convolutional network architecture with up to\n14 weight layers. There are multiple convolutional layers before each pooling\nlayer, with small 3x3 kernels, inspired by the VGG Imagenet 2014 architecture.\nThen, we introduce multilingual CNNs with multiple untied layers. Finally, we\nintroduce multi-scale input features aimed at exploiting more context at\nnegligible computational cost. We evaluate the improvements first on a Babel\ntask for low resource speech recognition, obtaining an absolute 5.77% WER\nimprovement over the baseline PLP DNN by training our CNN on the combined data\nof six different languages. We then evaluate the very deep CNNs on the Hub5'00\nbenchmark (using the 262 hours of SWB-1 training data) achieving a word error\nrate of 11.8% after cross-entropy training, a 1.4% WER improvement (10.6%\nrelative) over the best published CNN result so far.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 22:28:11 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2016 18:18:58 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Sercu", "Tom", ""], ["Puhrsch", "Christian", ""], ["Kingsbury", "Brian", ""], ["LeCun", "Yann", ""]]}, {"id": "1509.08972", "submitter": "Arash Ardakani", "authors": "Arash Ardakani, Fran\\c{c}ois Leduc-Primeau, Naoya Onizawa, Takahiro\n  Hanyu and Warren J. Gross", "title": "VLSI Implementation of Deep Neural Network Using Integral Stochastic\n  Computing", "comments": "11 pages, 12 figures", "journal-ref": "IEEE Transactions on Very Large Scale Integration (VLSI) Systems ,\n  vol.PP, no.99, pp.1-12, 2017", "doi": "10.1109/TVLSI.2017.2654298", "report-no": null, "categories": "cs.NE cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hardware implementation of deep neural networks (DNNs) has recently\nreceived tremendous attention: many applications in fact require high-speed\noperations that suit a hardware implementation. However, numerous elements and\ncomplex interconnections are usually required, leading to a large area\noccupation and copious power consumption. Stochastic computing has shown\npromising results for low-power area-efficient hardware implementations, even\nthough existing stochastic algorithms require long streams that cause long\nlatencies. In this paper, we propose an integer form of stochastic computation\nand introduce some elementary circuits. We then propose an efficient\nimplementation of a DNN based on integral stochastic computing. The proposed\narchitecture has been implemented on a Virtex7 FPGA, resulting in 45% and 62%\naverage reductions in area and latency compared to the best reported\narchitecture in literature. We also synthesize the circuits in a 65 nm CMOS\ntechnology and we show that the proposed integral stochastic architecture\nresults in up to 21% reduction in energy consumption compared to the binary\nradix implementation at the same misclassification rate. Due to fault-tolerant\nnature of stochastic architectures, we also consider a quasi-synchronous\nimplementation which yields 33% reduction in energy consumption w.r.t. the\nbinary radix implementation without any compromise on performance.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 23:16:18 GMT"}, {"version": "v2", "created": "Wed, 24 Aug 2016 18:30:55 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Ardakani", "Arash", ""], ["Leduc-Primeau", "Fran\u00e7ois", ""], ["Onizawa", "Naoya", ""], ["Hanyu", "Takahiro", ""], ["Gross", "Warren J.", ""]]}, {"id": "1509.08985", "submitter": "Chen-Yu Lee", "authors": "Chen-Yu Lee, Patrick W. Gallagher, Zhuowen Tu", "title": "Generalizing Pooling Functions in Convolutional Neural Networks: Mixed,\n  Gated, and Tree", "comments": "Patent disclosure, UCSD Docket No. SD2015-184, \"Forest Convolutional\n  Neural Network\", filed on March 4, 2015. UCSD Docket No. SD2016-053,\n  \"Generalizing Pooling Functions in Convolutional Neural Network\", filed on\n  Sept 23, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to improve deep neural networks by generalizing the pooling\noperations that play a central role in current architectures. We pursue a\ncareful exploration of approaches to allow pooling to learn and to adapt to\ncomplex and variable patterns. The two primary directions lie in (1) learning a\npooling function via (two strategies of) combining of max and average pooling,\nand (2) learning a pooling function in the form of a tree-structured fusion of\npooling filters that are themselves learned. In our experiments every\ngeneralized pooling operation we explore improves performance when used in\nplace of average or max pooling. We experimentally demonstrate that the\nproposed pooling operations provide a boost in invariance properties relative\nto conventional pooling and set the state of the art on several widely adopted\nbenchmark datasets; they are also easy to implement, and can be applied within\nvarious deep neural network architectures. These benefits come with only a\nlight increase in computational overhead during training and a very modest\nincrease in the number of model parameters.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 01:06:36 GMT"}, {"version": "v2", "created": "Sat, 10 Oct 2015 03:18:45 GMT"}], "update_date": "2015-10-13", "authors_parsed": [["Lee", "Chen-Yu", ""], ["Gallagher", "Patrick W.", ""], ["Tu", "Zhuowen", ""]]}, {"id": "1509.09060", "submitter": "Jun He", "authors": "Tao Xu and Jun He", "title": "Multi-objective Differential Evolution with Helper Functions for\n  Constrained Optimization", "comments": "Accepted by The 15th UK Workshop on Computational Intelligence (UKCI\n  2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving constrained optimization problems by multi-objective evolutionary\nalgorithms has scored tremendous achievements in the last decade. Standard\nmulti-objective schemes usually aim at minimizing the objective function and\nalso the degree of constraint violation simultaneously. This paper proposes a\nnew multi-objective method for solving constrained optimization problems. The\nnew method keeps two standard objectives: the original objective function and\nthe sum of degrees of constraint violation. But besides them, four more\nobjectives are added. One is based on the feasible rule. The other three come\nfrom the penalty functions. This paper conducts an initial experimental study\non thirteen benchmark functions. A simplified version of CMODE is applied to\nsolving multi-objective optimization problems. Our initial experimental results\nconfirm our expectation that adding more helper functions could be useful. The\nperformance of SMODE with more helper functions (four or six) is better than\nthat with only two helper functions.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 08:19:04 GMT"}, {"version": "v2", "created": "Thu, 1 Oct 2015 06:49:08 GMT"}], "update_date": "2015-10-02", "authors_parsed": [["Xu", "Tao", ""], ["He", "Jun", ""]]}, {"id": "1509.09199", "submitter": "Mark Zwolinski", "authors": "Anton Kulakov, Mark Zwolinski, Jeff Reeve", "title": "Fault Tolerance in Distributed Neural Computing", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.1.1387.0800", "report-no": null, "categories": "cs.NE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing complexity of computing systems, complete hardware\nreliability can no longer be guaranteed. We need, however, to ensure overall\nsystem reliability. One of the most important features of artificial neural\nnetworks is their intrinsic fault-tolerance. The aim of this work is to\ninvestigate whether such networks have features that can be applied to wider\ncomputational systems. This paper presents an analysis, in both the learning\nand operational phases, of a distributed feed-forward neural network with\ndecentralised event-driven time management, which is insensitive to\nintermittent faults caused by unreliable communication or faulty hardware\ncomponents. The learning rules used in the model are local in space and time,\nwhich allows efficient scalable distributed implementation. We investigate the\noverhead caused by injected faults and analyse the sensitivity to limited\nfailures in the computational hardware in different areas of the network.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 14:46:44 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Kulakov", "Anton", ""], ["Zwolinski", "Mark", ""], ["Reeve", "Jeff", ""]]}, {"id": "1509.09235", "submitter": "Malte Probst", "authors": "Malte Probst", "title": "Generative Adversarial Networks in Estimation of Distribution Algorithms\n  for Combinatorial Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of Distribution Algorithms (EDAs) require flexible probability\nmodels that can be efficiently learned and sampled. Generative Adversarial\nNetworks (GAN) are generative neural networks which can be trained to\nimplicitly model the probability distribution of given data, and it is possible\nto sample this distribution. We integrate a GAN into an EDA and evaluate the\nperformance of this system when solving combinatorial optimization problems\nwith a single objective. We use several standard benchmark problems and compare\nthe results to state-of-the-art multivariate EDAs. GAN-EDA doe not yield\ncompetitive results - the GAN lacks the ability to quickly learn a good\napproximation of the probability distribution. A key reason seems to be the\nlarge amount of noise present in the first EDA generations.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 16:02:59 GMT"}, {"version": "v2", "created": "Mon, 8 Aug 2016 13:01:39 GMT"}], "update_date": "2016-08-09", "authors_parsed": [["Probst", "Malte", ""]]}, {"id": "1509.09292", "submitter": "David Duvenaud", "authors": "David Duvenaud, Dougal Maclaurin, Jorge Aguilera-Iparraguirre, Rafael\n  G\\'omez-Bombarelli, Timothy Hirzel, Al\\'an Aspuru-Guzik, Ryan P. Adams", "title": "Convolutional Networks on Graphs for Learning Molecular Fingerprints", "comments": "9 pages, 5 figures. To appear in Neural Information Processing\n  Systems (NIPS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a convolutional neural network that operates directly on graphs.\nThese networks allow end-to-end learning of prediction pipelines whose inputs\nare graphs of arbitrary size and shape. The architecture we present generalizes\nstandard molecular feature extraction methods based on circular fingerprints.\nWe show that these data-driven features are more interpretable, and have better\npredictive performance on a variety of tasks.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 18:33:50 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2015 17:18:32 GMT"}], "update_date": "2015-11-04", "authors_parsed": [["Duvenaud", "David", ""], ["Maclaurin", "Dougal", ""], ["Aguilera-Iparraguirre", "Jorge", ""], ["G\u00f3mez-Bombarelli", "Rafael", ""], ["Hirzel", "Timothy", ""], ["Aspuru-Guzik", "Al\u00e1n", ""], ["Adams", "Ryan P.", ""]]}, {"id": "1509.09308", "submitter": "Andrew Lavin", "authors": "Andrew Lavin and Scott Gray", "title": "Fast Algorithms for Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks take GPU days of compute time to train on\nlarge data sets. Pedestrian detection for self driving cars requires very low\nlatency. Image recognition for mobile phones is constrained by limited\nprocessing resources. The success of convolutional neural networks in these\nsituations is limited by how fast we can compute them. Conventional FFT based\nconvolution is fast for large filters, but state of the art convolutional\nneural networks use small, 3x3 filters. We introduce a new class of fast\nalgorithms for convolutional neural networks using Winograd's minimal filtering\nalgorithms. The algorithms compute minimal complexity convolution over small\ntiles, which makes them fast with small filters and small batch sizes. We\nbenchmark a GPU implementation of our algorithm with the VGG network and show\nstate of the art throughput at batch sizes from 1 to 64.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 19:39:20 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2015 20:08:41 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Lavin", "Andrew", ""], ["Gray", "Scott", ""]]}]