[{"id": "1801.00062", "submitter": "Jo\\~ao Sacramento", "authors": "Jo\\~ao Sacramento and Rui Ponte Costa and Yoshua Bengio and Walter\n  Senn", "title": "Dendritic error backpropagation in deep cortical microcircuits", "comments": "27 pages, 5 figures, 10 pages supplementary information", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animal behaviour depends on learning to associate sensory stimuli with the\ndesired motor command. Understanding how the brain orchestrates the necessary\nsynaptic modifications across different brain areas has remained a longstanding\npuzzle. Here, we introduce a multi-area neuronal network model in which\nsynaptic plasticity continuously adapts the network towards a global desired\noutput. In this model synaptic learning is driven by a local dendritic\nprediction error that arises from a failure to predict the top-down input given\nthe bottom-up activities. Such errors occur at apical dendrites of pyramidal\nneurons where both long-range excitatory feedback and local inhibitory\npredictions are integrated. When local inhibition fails to match excitatory\nfeedback an error occurs which triggers plasticity at bottom-up synapses at\nbasal dendrites of the same pyramidal neurons. We demonstrate the learning\ncapabilities of the model in a number of tasks and show that it approximates\nthe classical error backpropagation algorithm. Finally, complementing this\ncortical circuit with a disinhibitory mechanism enables attention-like stimulus\ndenoising and generation. Our framework makes several experimental predictions\non the function of dendritic integration and cortical microcircuits, is\nconsistent with recent observations of cross-area learning, and suggests a\nbiological implementation of deep learning.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 00:16:56 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Sacramento", "Jo\u00e3o", ""], ["Costa", "Rui Ponte", ""], ["Bengio", "Yoshua", ""], ["Senn", "Walter", ""]]}, {"id": "1801.00096", "submitter": "Timothy Rozario", "authors": "Timothy Rozario, Troy Long, Mingli Chen, Weiguo Lu and Steve Jiang", "title": "Towards automated patient data cleaning using deep learning: A\n  feasibility study on the standardization of organ labeling", "comments": "17 pages, 7 figures, 3 tables, 39 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CV cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data cleaning consumes about 80% of the time spent on data analysis for\nclinical research projects. This is a much bigger problem in the era of big\ndata and machine learning in the field of medicine where large volumes of data\nare being generated. We report an initial effort towards automated patient data\ncleaning using deep learning: the standardization of organ labeling in\nradiation therapy. Organs are often labeled inconsistently at different\ninstitutions (sometimes even within the same institution) and at different time\nperiods, which poses a problem for clinical research, especially for\nmulti-institutional collaborative clinical research where the acquired patient\ndata is not being used effectively. We developed a convolutional neural network\n(CNN) to automatically identify each organ in the CT image and then label it\nwith the standardized nomenclature presented at AAPM Task Group 263. We tested\nthis model on the CT images of 54 patients with prostate and 100 patients with\nhead and neck cancer who previously received radiation therapy. The model\nachieved 100% accuracy in detecting organs and assigning standardized labels\nfor the patients tested. This work shows the feasibility of using deep learning\nin patient data cleaning that enables standardized datasets to be generated for\neffective intra- and interinstitutional collaborative clinical research.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 07:56:46 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Rozario", "Timothy", ""], ["Long", "Troy", ""], ["Chen", "Mingli", ""], ["Lu", "Weiguo", ""], ["Jiang", "Steve", ""]]}, {"id": "1801.00119", "submitter": "Pawel Koperek", "authors": "W{\\l}odzimierz Funika and Pawe{\\l} Koperek", "title": "Towards co-evolution of fitness predictors and Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks proved to be a very useful and powerful tool with many\npractical applications. They especially excel at learning from large data sets\nwith labeled samples. However, in order to achieve good learning results, the\nnetwork architecture has to be carefully designed. Creating an optimal topology\nrequires a lot of experience and knowledge. Unfortunately there are no\npractically applicable algorithms which could help in this situation. Using an\nevolutionary process to develop new network topologies might solve this\nproblem. The limiting factor in this case is the speed of evaluation of a\nsingle specimen (a single network architecture), which includes learning based\non the whole large dataset. In this paper we propose to overcome this problem\nby using a fitness prediction technique: use subsets of the original training\nset to conduct the training process and use its results as an approximation of\nspecimen's fitness. We discuss the feasibility of this approach in context of\nthe desired fitness predictor features and analyze whether subsets obtained in\nan evolutionary process can be used to estimate the fitness of the network\ntopology. Finally we draw conclusions from our experiments and outline plans\nfor future work.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 11:40:50 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Funika", "W\u0142odzimierz", ""], ["Koperek", "Pawe\u0142", ""]]}, {"id": "1801.00318", "submitter": "Abien Fred Agarap", "authors": "Abien Fred Agarap", "title": "Towards Building an Intelligent Anti-Malware System: A Deep Learning\n  Approach using Support Vector Machine (SVM) for Malware Classification", "comments": "5 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CR cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Effective and efficient mitigation of malware is a long-time endeavor in the\ninformation security community. The development of an anti-malware system that\ncan counteract an unknown malware is a prolific activity that may benefit\nseveral sectors. We envision an intelligent anti-malware system that utilizes\nthe power of deep learning (DL) models. Using such models would enable the\ndetection of newly-released malware through mathematical generalization. That\nis, finding the relationship between a given malware $x$ and its corresponding\nmalware family $y$, $f: x \\mapsto y$. To accomplish this feat, we used the\nMalimg dataset (Nataraj et al., 2011) which consists of malware images that\nwere processed from malware binaries, and then we trained the following DL\nmodels 1 to classify each malware family: CNN-SVM (Tang, 2013), GRU-SVM\n(Agarap, 2017), and MLP-SVM. Empirical evidence has shown that the GRU-SVM\nstands out among the DL models with a predictive accuracy of ~84.92%. This\nstands to reason for the mentioned model had the relatively most sophisticated\narchitecture design among the presented models. The exploration of an even more\noptimal DL-SVM model is the next stage towards the engineering of an\nintelligent anti-malware system.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 17:13:55 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 06:19:41 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Agarap", "Abien Fred", ""]]}, {"id": "1801.00512", "submitter": "Haik Manukian", "authors": "Haik Manukian, Fabio L. Traversa, Massimiliano Di Ventra", "title": "Accelerating Deep Learning with Memcomputing", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann machines (RBMs) and their extensions, called\n'deep-belief networks', are powerful neural networks that have found\napplications in the fields of machine learning and artificial intelligence. The\nstandard way to training these models resorts to an iterative unsupervised\nprocedure based on Gibbs sampling, called 'contrastive divergence' (CD), and\nadditional supervised tuning via back-propagation. However, this procedure has\nbeen shown not to follow any gradient and can lead to suboptimal solutions. In\nthis paper, we show an efficient alternative to CD by means of simulations of\ndigital memcomputing machines (DMMs). We test our approach on pattern\nrecognition using a modified version of the MNIST data set. DMMs sample\neffectively the vast phase space given by the model distribution of the RBM,\nand provide a very good approximation close to the optimum. This efficient\nsearch significantly reduces the number of pretraining iterations necessary to\nachieve a given level of accuracy, as well as a total performance gain over CD.\nIn fact, the acceleration of pretraining achieved by simulating DMMs is\ncomparable to, in number of iterations, the recently reported hardware\napplication of the quantum annealing method on the same network and data set.\nNotably, however, DMMs perform far better than the reported quantum annealing\nresults in terms of quality of the training. We also compare our method to\nadvances in supervised training, like batch-normalization and rectifiers, that\nwork to reduce the advantage of pretraining. We find that the memcomputing\nmethod still maintains a quality advantage ($>1\\%$ in accuracy, and a $20\\%$\nreduction in error rate) over these approaches. Furthermore, our method is\nagnostic about the connectivity of the network. Therefore, it can be extended\nto train full Boltzmann machines, and even deep networks at once.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 21:27:11 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 01:33:19 GMT"}, {"version": "v3", "created": "Tue, 23 Oct 2018 19:23:11 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Manukian", "Haik", ""], ["Traversa", "Fabio L.", ""], ["Di Ventra", "Massimiliano", ""]]}, {"id": "1801.00609", "submitter": "Ke Li Kl", "authors": "Ke Li, Renzhi Chen, Dragan Savic, Xin Yao", "title": "Interactive Decomposition Multi-Objective Optimization via Progressively\n  Learned Value Functions", "comments": "25 pages, 18 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decomposition has become an increasingly popular technique for evolutionary\nmulti-objective optimization (EMO). A decomposition-based EMO algorithm is\nusually designed to approximate a whole Pareto-optimal front (PF). However, in\npractice, the decision maker (DM) might only be interested in her/his region of\ninterest (ROI), i.e., a part of the PF. Solutions outside that might be useless\nor even noisy to the decision-making procedure. Furthermore, there is no\nguarantee to find the preferred solutions when tackling many-objective\nproblems. This paper develops an interactive framework for the\ndecomposition-based EMO algorithm to lead a DM to the preferred solutions of\nher/his choice. It consists of three modules, i.e., consultation, preference\nelicitation and optimization. Specifically, after every several generations,\nthe DM is asked to score a few candidate solutions in a consultation session.\nThereafter, an approximated value function, which models the DM's preference\ninformation, is progressively learned from the DM's behavior. In the preference\nelicitation session, the preference information learned in the consultation\nmodule is translated into the form that can be used in a decomposition-based\nEMO algorithm, i.e., a set of reference points that are biased toward to the\nROI. The optimization module, which can be any decomposition-based EMO\nalgorithm in principle, utilizes the biased reference points to direct its\nsearch process. Extensive experiments on benchmark problems with three to ten\nobjectives fully demonstrate the effectiveness of our proposed method for\nfinding the DM's preferred solutions.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 11:10:50 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 20:12:00 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Li", "Ke", ""], ["Chen", "Renzhi", ""], ["Savic", "Dragan", ""], ["Yao", "Xin", ""]]}, {"id": "1801.00746", "submitter": "Yu Ji", "authors": "Yu Ji, YouHui Zhang, WenGuang Chen, Yuan Xie", "title": "Bridging the Gap Between Neural Networks and Neuromorphic Hardware with\n  A Neural Network Compiler", "comments": "Accepted by ASPLOS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different from developing neural networks (NNs) for general-purpose\nprocessors, the development for NN chips usually faces with some\nhardware-specific restrictions, such as limited precision of network signals\nand parameters, constrained computation scale, and limited types of non-linear\nfunctions.\n  This paper proposes a general methodology to address the challenges. We\ndecouple the NN applications from the target hardware by introducing a compiler\nthat can transform an existing trained, unrestricted NN into an equivalent\nnetwork that meets the given hardware's constraints. We propose multiple\ntechniques to make the transformation adaptable to different kinds of NN chips,\nand reliable for restrict hardware constraints.\n  We have built such a software tool that supports both spiking neural networks\n(SNNs) and traditional artificial neural networks (ANNs). We have demonstrated\nits effectiveness with a fabricated neuromorphic chip and a\nprocessing-in-memory (PIM) design. Tests show that the inference error caused\nby this solution is insignificant and the transformation time is much shorter\nthan the retraining time. Also, we have studied the parameter-sensitivity\nevaluations to explore the tradeoffs between network error and resource\nutilization for different transformation strategies, which could provide\ninsights for co-design optimization of neuromorphic hardware and software.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 22:52:34 GMT"}, {"version": "v2", "created": "Fri, 12 Jan 2018 01:16:42 GMT"}, {"version": "v3", "created": "Thu, 18 Jan 2018 18:05:39 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Ji", "Yu", ""], ["Zhang", "YouHui", ""], ["Chen", "WenGuang", ""], ["Xie", "Yuan", ""]]}, {"id": "1801.01078", "submitter": "Hojjat Salehinejad", "authors": "Hojjat Salehinejad, Sharan Sankar, Joseph Barfett, Errol Colak,\n  Shahrokh Valaee", "title": "Recent Advances in Recurrent Neural Networks", "comments": "arXiv admin note: text overlap with arXiv:1602.04335", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are capable of learning features and long\nterm dependencies from sequential and time-series data. The RNNs have a stack\nof non-linear units where at least one connection between units forms a\ndirected cycle. A well-trained RNN can model any dynamical system; however,\ntraining RNNs is mostly plagued by issues in learning long-term dependencies.\nIn this paper, we present a survey on RNNs and several new advances for\nnewcomers and professionals in the field. The fundamentals and recent advances\nare explained and the research challenges are introduced.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 00:57:22 GMT"}, {"version": "v2", "created": "Mon, 8 Jan 2018 07:18:19 GMT"}, {"version": "v3", "created": "Thu, 22 Feb 2018 19:28:28 GMT"}], "update_date": "2018-02-26", "authors_parsed": [["Salehinejad", "Hojjat", ""], ["Sankar", "Sharan", ""], ["Barfett", "Joseph", ""], ["Colak", "Errol", ""], ["Valaee", "Shahrokh", ""]]}, {"id": "1801.01423", "submitter": "Joan Serr\\`a", "authors": "Joan Serr\\`a, D\\'idac Sur\\'is, Marius Miron, Alexandros Karatzoglou", "title": "Overcoming catastrophic forgetting with hard attention to the task", "comments": "Includes appendix. Accepted for ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting occurs when a neural network loses the information\nlearned in a previous task after training on subsequent tasks. This problem\nremains a hurdle for artificial intelligence systems with sequential learning\ncapabilities. In this paper, we propose a task-based hard attention mechanism\nthat preserves previous tasks' information without affecting the current task's\nlearning. A hard attention mask is learned concurrently to every task, through\nstochastic gradient descent, and previous masks are exploited to condition such\nlearning. We show that the proposed mechanism is effective for reducing\ncatastrophic forgetting, cutting current rates by 45 to 80%. We also show that\nit is robust to different hyperparameter choices, and that it offers a number\nof monitoring capabilities. The approach features the possibility to control\nboth the stability and compactness of the learned knowledge, which we believe\nmakes it also attractive for online learning or network compression\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 16:22:22 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 09:01:55 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 09:00:04 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Serr\u00e0", "Joan", ""], ["Sur\u00eds", "D\u00eddac", ""], ["Miron", "Marius", ""], ["Karatzoglou", "Alexandros", ""]]}, {"id": "1801.01443", "submitter": "Wellington Pinheiro dos Santos", "authors": "Filipe Rolim Cordeiro, Wellington Pinheiro dos Santos, Abel\n  Guilhermino da Silva Filho", "title": "A semi-supervised fuzzy GrowCut algorithm to segment and classify\n  regions of interest of mammographic images", "comments": null, "journal-ref": "Expert Systems With Applications, 65 (2016), 116-126", "doi": "10.1016/j.eswa.2016.08.016", "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the World Health Organization, breast cancer is the most common\nform of cancer in women. It is the second leading cause of death among women\nround the world, becoming the most fatal form of cancer. Mammographic image\nsegmentation is a fundamental task to support image analysis and diagnosis,\ntaking into account shape analysis of mammary lesions and their borders.\nHowever, mammogram segmentation is a very hard process, once it is highly\ndependent on the types of mammary tissues. In this work we present a new\nsemi-supervised segmentation algorithm based on the modification of the GrowCut\nalgorithm to perform automatic mammographic image segmentation once a region of\ninterest is selected by a specialist. In our proposal, we used fuzzy Gaussian\nmembership functions to modify the evolution rule of the original GrowCut\nalgorithm, in order to estimate the uncertainty of a pixel being object or\nbackground. The main impact of the proposed method is the significant reduction\nof expert effort in the initialization of seed points of GrowCut to perform\naccurate segmentation, once it removes the need of selection of background\nseeds. We also constructed an automatic point selection process based on the\nsimulated annealing optimization method, avoiding the need of human\nintervention. The proposed approach was qualitatively compared with other\nstate-of-the-art segmentation techniques, considering the shape of segmented\nregions. In order to validate our proposal, we built an image classifier using\na classical multilayer perceptron. We used Zernike moments to extract segmented\nimage features. This analysis employed 685 mammograms from IRMA breast cancer\ndatabase, using fat and fibroid tissues. Results show that the proposed\ntechnique could achieve a classification rate of 91.28\\% for fat tissues,\nevidencing the feasibility of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 3 Dec 2017 17:31:01 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Cordeiro", "Filipe Rolim", ""], ["Santos", "Wellington Pinheiro dos", ""], ["Filho", "Abel Guilhermino da Silva", ""]]}, {"id": "1801.01539", "submitter": "Fatema Zohora", "authors": "Fatema Tuz Zohora, Ngoc Hieu Tran, Xianglilan Zhang, Lei Xin, Baozhen\n  Shan, and Ming Li", "title": "DeepIso: A Deep Learning Model for Peptide Feature Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.NE physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Liquid chromatography with tandem mass spectrometry (LC-MS/MS) based\nproteomics is a well-established research field with major applications such as\nidentification of disease biomarkers, drug discovery, drug design and\ndevelopment. In proteomics, protein identification and quantification is a\nfundamental task, which is done by first enzymatically digesting it into\npeptides, and then analyzing peptides by LC-MS/MS instruments. The peptide\nfeature detection and quantification from an LC-MS map is the first step in\ntypical analysis workflows. In this paper we propose a novel deep learning\nbased model, DeepIso, that uses Convolutional Neural Networks (CNNs) to scan an\nLC-MS map to detect peptide features and estimate their abundance. Existing\ntools are often designed with limited engineered features based on domain\nknowledge, and depend on pretrained parameters which are hardly updated despite\nhuge amount of new coming proteomic data. Our proposed model, on the other\nhand, is capable of learning multiple levels of representation of high\ndimensional data through its many layers of neurons and continuously evolving\nwith newly acquired data. To evaluate our proposed model, we use an antibody\ndataset including a heavy and a light chain, each digested by Asp-N,\nChymotrypsin, Trypsin, thus giving six LC-MS maps for the experiment. Our model\nachieves 93.21% sensitivity with specificity of 99.44% on this dataset. Our\nresults demonstrate that novel deep learning tools are desirable to advance the\nstate-of-the-art in protein identification and quantification.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 04:55:39 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Zohora", "Fatema Tuz", ""], ["Tran", "Ngoc Hieu", ""], ["Zhang", "Xianglilan", ""], ["Xin", "Lei", ""], ["Shan", "Baozhen", ""], ["Li", "Ming", ""]]}, {"id": "1801.01554", "submitter": "Michael Witbrock", "authors": "Michael Witbrock and Marco Zagha", "title": "An Implementation of Back-Propagation Learning on GF11, a Large SIMD\n  Parallel Computer", "comments": null, "journal-ref": "Witbrock, M., and Zagha, M. (1989). \"An Implementation of\n  Back-Propagation Learning on GF11, a Large SIMD Parallel Computer.\" School of\n  Computer Science, Carnegie Mellon University, Pittsburgh, PA, Technical\n  Report CMU-CS-89-208", "doi": null, "report-no": "CMU-CS-89-208", "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current connectionist simulations require huge computational resources. We\ndescribe a neural network simulator for the IBM GF11, an experimental SIMD\nmachine with 566 processors and a peak arithmetic performance of 11 Gigaflops.\nWe present our parallel implementation of the backpropagation learning\nalgorithm, techniques for increasing efficiency, performance measurements on\nthe NetTalk text-to-speech benchmark, and a performance model for the\nsimulator. Our simulator currently runs the back-propagation learning algorithm\nat 900 million connections per second, where each \"connection per second\"\nincludes both a forward and backward pass. This figure was obtained on the\nmachine when only 356 processors were working; with all 566 processors\noperational, our simulation will run at over one billion connections per\nsecond. We conclude that the GF11 is well-suited to neural network simulation,\nand we analyze our use of the machine to determine which features are the most\nimportant for high performance.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 21:52:28 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Witbrock", "Michael", ""], ["Zagha", "Marco", ""]]}, {"id": "1801.01563", "submitter": "Filipe Assun\\c{c}\\~ao", "authors": "Filipe Assun\\c{c}\\~ao, Nuno Louren\\c{c}o, Penousal Machado, Bernardete\n  Ribeiro", "title": "DENSER: Deep Evolutionary Network Structured Representation", "comments": null, "journal-ref": null, "doi": "10.1007/s10710-018-9339-y", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Evolutionary Network Structured Representation (DENSER) is a novel\napproach to automatically design Artificial Neural Networks (ANNs) using\nEvolutionary Computation. The algorithm not only searches for the best network\ntopology (e.g., number of layers, type of layers), but also tunes\nhyper-parameters, such as, learning parameters or data augmentation parameters.\nThe automatic design is achieved using a representation with two distinct\nlevels, where the outer level encodes the general structure of the network,\ni.e., the sequence of layers, and the inner level encodes the parameters\nassociated with each layer. The allowed layers and range of the\nhyper-parameters values are defined by means of a human-readable Context-Free\nGrammar. DENSER was used to evolve ANNs for CIFAR-10, obtaining an average test\naccuracy of 94.13%. The networks evolved for the CIFA--10 are tested on the\nMNIST, Fashion-MNIST, and CIFAR-100; the results are highly competitive, and on\nthe CIFAR-100 we report a test accuracy of 78.75%. To the best of our\nknowledge, our CIFAR-100 results are the highest performing models generated by\nmethods that aim at the automatic design of Convolutional Neural Networks\n(CNNs), and are amongst the best for manually designed and fine-tuned CNNs.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 22:17:52 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 16:38:42 GMT"}, {"version": "v3", "created": "Fri, 1 Jun 2018 09:53:57 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Assun\u00e7\u00e3o", "Filipe", ""], ["Louren\u00e7o", "Nuno", ""], ["Machado", "Penousal", ""], ["Ribeiro", "Bernardete", ""]]}, {"id": "1801.01574", "submitter": "Meik D\\\"orpinghaus", "authors": "Meik D\\\"orpinghaus, Izaak Neri, \\'Edgar Rold\\'an, Heinrich Meyr, and\n  Frank J\\\"ulicher", "title": "Testing Optimality of Sequential Decision-Making", "comments": "42 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cond-mat.stat-mech cs.NE math.IT physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a statistical method to test whether a system that\nperforms a binary sequential hypothesis test is optimal in the sense of\nminimizing the average decision times while taking decisions with given\nreliabilities. The proposed method requires samples of the decision times, the\ndecision outcomes, and the true hypotheses, but does not require knowledge on\nthe statistics of the observations or the properties of the decision-making\nsystem. The method is based on fluctuation relations for decision time\ndistributions which are proved for sequential probability ratio tests. These\nrelations follow from the martingale property of probability ratios and hold\nunder fairly general conditions. We illustrate these tests with numerical\nexperiments and discuss potential applications.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 23:03:25 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["D\u00f6rpinghaus", "Meik", ""], ["Neri", "Izaak", ""], ["Rold\u00e1n", "\u00c9dgar", ""], ["Meyr", "Heinrich", ""], ["J\u00fclicher", "Frank", ""]]}, {"id": "1801.01586", "submitter": "David Charte", "authors": "David Charte and Francisco Charte and Salvador Garc\\'ia and Mar\\'ia J.\n  del Jesus and Francisco Herrera", "title": "A practical tutorial on autoencoders for nonlinear feature fusion:\n  Taxonomy, models, software and guidelines", "comments": null, "journal-ref": "Information Fusion 44 (2018) 78-96", "doi": "10.1016/j.inffus.2017.12.007", "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the existing machine learning algorithms, both supervised and\nunsupervised, depend on the quality of the input characteristics to generate a\ngood model. The amount of these variables is also important, since performance\ntends to decline as the input dimensionality increases, hence the interest in\nusing feature fusion techniques, able to produce feature sets that are more\ncompact and higher level. A plethora of procedures to fuse original variables\nfor producing new ones has been developed in the past decades. The most basic\nones use linear combinations of the original variables, such as PCA (Principal\nComponent Analysis) and LDA (Linear Discriminant Analysis), while others find\nmanifold embeddings of lower dimensionality based on non-linear combinations,\nsuch as Isomap or LLE (Linear Locally Embedding) techniques.\n  More recently, autoencoders (AEs) have emerged as an alternative to manifold\nlearning for conducting nonlinear feature fusion. Dozens of AE models have been\nproposed lately, each with its own specific traits. Although many of them can\nbe used to generate reduced feature sets through the fusion of the original\nones, there also AEs designed with other applications in mind.\n  The goal of this paper is to provide the reader with a broad view of what an\nAE is, how they are used for feature fusion, a taxonomy gathering a broad range\nof models, and how they relate to other classical techniques. In addition, a\nset of didactic guidelines on how to choose the proper AE for a given task is\nsupplied, together with a discussion of the software tools available. Finally,\ntwo case studies illustrate the usage of AEs with datasets of handwritten\ndigits and breast cancer.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 23:51:05 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Charte", "David", ""], ["Charte", "Francisco", ""], ["Garc\u00eda", "Salvador", ""], ["del Jesus", "Mar\u00eda J.", ""], ["Herrera", "Francisco", ""]]}, {"id": "1801.01620", "submitter": "Jia Wu", "authors": "Qinxue Meng, Jia Wu, John Ellisy, Paul J. Kennedy", "title": "Dynamic Island Model based on Spectral Clustering in Genetic Algorithm", "comments": "8 pages", "journal-ref": "Q. Meng, J. Wu, J. Ellis and P. J. Kennedy, \"Dynamic island model\n  based on spectral clustering in genetic algorithm,\" 2017 International Joint\n  Conference on Neural Networks (IJCNN), Anchorage, AK, 2017, pp. 1724-1731", "doi": "10.1109/IJCNN.2017.7966059", "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to maintain relative high diversity is important to avoid premature\nconvergence in population-based optimization methods. Island model is widely\nconsidered as a major approach to achieve this because of its flexibility and\nhigh efficiency. The model maintains a group of sub-populations on different\nislands and allows sub-populations to interact with each other via predefined\nmigration policies. However, current island model has some drawbacks. One is\nthat after a certain number of generations, different islands may retain quite\nsimilar, converged sub-populations thereby losing diversity and decreasing\nefficiency. Another drawback is that determining the number of islands to\nmaintain is also very challenging. Meanwhile initializing many sub-populations\nincreases the randomness of island model. To address these issues, we proposed\na dynamic island model~(DIM-SP) which can force each island to maintain\ndifferent sub-populations, control the number of islands dynamically and starts\nwith one sub-population. The proposed island model outperforms the other three\nstate-of-the-art island models in three baseline optimization problems\nincluding job shop scheduler problem, travelling salesmen problem and quadratic\nmultiple knapsack problem.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 03:29:35 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Meng", "Qinxue", ""], ["Wu", "Jia", ""], ["Ellisy", "John", ""], ["Kennedy", "Paul J.", ""]]}, {"id": "1801.01743", "submitter": "Alberto Fachechi", "authors": "Adriano Barra, Matteo Beccaria and Alberto Fachechi", "title": "A relativistic extension of Hopfield neural networks via the mechanical\n  analogy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a modification of the cost function of the Hopfield model whose\nsalient features shine in its Taylor expansion and result in more than pairwise\ninteractions with alternate signs, suggesting a unified framework for handling\nboth with deep learning and network pruning. In our analysis, we heavily rely\non the Hamilton-Jacobi correspondence relating the statistical model with a\nmechanical system. In this picture, our model is nothing but the relativistic\nextension of the original Hopfield model (whose cost function is a quadratic\nform in the Mattis magnetization which mimics the non-relativistic Hamiltonian\nfor a free particle). We focus on the low-storage regime and solve the model\nanalytically by taking advantage of the mechanical analogy, thus obtaining a\ncomplete characterization of the free energy and the associated\nself-consistency equations in the thermodynamic limit. On the numerical side,\nwe test the performances of our proposal with MC simulations, showing that the\nstability of spurious states (limiting the capabilities of the standard Hebbian\nconstruction) is sensibly reduced due to presence of unlearning contributions\nin this extended framework.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 12:57:18 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Barra", "Adriano", ""], ["Beccaria", "Matteo", ""], ["Fachechi", "Alberto", ""]]}, {"id": "1801.02003", "submitter": "Vivek Parmar", "authors": "Vivek Parmar, Manan Suri", "title": "Design Exploration of Hybrid CMOS-OxRAM Deep Generative Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning and its applications have gained tremendous interest recently\nin both academia and industry. Restricted Boltzmann Machines (RBMs) offer a key\nmethodology to implement deep learning paradigms. This paper presents a novel\napproach for realizing hybrid CMOS-OxRAM based deep generative models (DGM). In\nour proposed hybrid DGM architectures, HfOx based (filamentary-type switching)\nOxRAM devices are extensively used for realizing multiple computational and\nnon-computational functions such as: (i) Synapses (weights), (ii) internal\nneuron-state storage, (iii) stochastic neuron activation and (iv) programmable\nsignal normalization. To validate the proposed scheme we have simulated two\ndifferent architectures: (i) Deep Belief Network (DBN) and (ii) Stacked\nDenoising Autoencoder for classification and reconstruction of hand-written\ndigits from a reduced MNIST dataset of 6000 images. Contrastive-divergence (CD)\nspecially optimized for OxRAM devices was used to drive the synaptic weight\nupdate mechanism of each layer in the network. Overall learning rule was based\non greedy-layer wise learning with no back propagation which allows the network\nto be trained to a good pre-training stage. Performance of the simulated hybrid\nCMOS-RRAM DGM model matches closely with software based model for a 2-layers\ndeep network. Top-3 test accuracy achieved by the DBN was 95.5%. MSE of the SDA\nnetwork was 0.003, lower than software based approach. Endurance analysis of\nthe simulated architectures show that for 200 epochs of training (single RBM\nlayer), maximum switching events/per OxRAM device was ~ 7000 cycles.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 11:32:01 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Parmar", "Vivek", ""], ["Suri", "Manan", ""]]}, {"id": "1801.02037", "submitter": "Carola Doerr", "authors": "Carola Doerr", "title": "Complexity Theory for Discrete Black-Box Optimization Heuristics", "comments": "This survey article is to appear (in a slightly modified form) in the\n  book \"Theory of Randomized Search Heuristics in Discrete Search Spaces\",\n  which will be published by Springer in 2018. The book is edited by Benjamin\n  Doerr and Frank Neumann. Missing numbers of pointers to other chapters of\n  this book will be added as soon as possible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A predominant topic in the theory of evolutionary algorithms and, more\ngenerally, theory of randomized black-box optimization techniques is running\ntime analysis. Running time analysis aims at understanding the performance of a\ngiven heuristic on a given problem by bounding the number of function\nevaluations that are needed by the heuristic to identify a solution of a\ndesired quality. As in general algorithms theory, this running time perspective\nis most useful when it is complemented by a meaningful complexity theory that\nstudies the limits of algorithmic solutions.\n  In the context of discrete black-box optimization, several black-box\ncomplexity models have been developed to analyze the best possible performance\nthat a black-box optimization algorithm can achieve on a given problem. The\nmodels differ in the classes of algorithms to which these lower bounds apply.\nThis way, black-box complexity contributes to a better understanding of how\ncertain algorithmic choices (such as the amount of memory used by a heuristic,\nits selective pressure, or properties of the strategies that it uses to create\nnew solution candidates) influences performance.\n  In this chapter we review the different black-box complexity models that have\nbeen proposed in the literature, survey the bounds that have been obtained for\nthese models, and discuss how the interplay of running time analysis and\nblack-box complexity can inspire new algorithmic solutions to well-researched\nproblems in evolutionary computation. We also discuss in this chapter several\ninteresting open questions for future work.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 15:44:04 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 21:44:07 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Doerr", "Carola", ""]]}, {"id": "1801.02148", "submitter": "Nima Joorabloo", "authors": "Homayoun Hamedmoghadam and Nima Joorabloo and Mahdi Jalili", "title": "Australia's long-term electricity demand forecasting using deep neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate prediction of long-term electricity demand has a significant role in\ndemand side management and electricity network planning and operation. Demand\nover-estimation results in over-investment in network assets, driving up the\nelectricity prices, while demand under-estimation may lead to under-investment\nresulting in unreliable and insecure electricity. In this manuscript, we apply\ndeep neural networks to predict Australia's long-term electricity demand. A\nstacked autoencoder is used in combination with multilayer perceptrons or\ncascade-forward multilayer perceptrons to predict the nation-wide electricity\nconsumption rates for 1-24 months ahead of time. The experimental results show\nthat the deep structures have better performance than classical neural\nnetworks, especially for 12-month to 24-month prediction horizon.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 06:37:50 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 23:07:16 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Hamedmoghadam", "Homayoun", ""], ["Joorabloo", "Nima", ""], ["Jalili", "Mahdi", ""]]}, {"id": "1801.02335", "submitter": "Esra'a Alkafaween", "authors": "Ahmad B. A. Hassanat, Esra'a Alkafaween", "title": "On Enhancing Genetic Algorithms Using New Crossovers", "comments": "15 pages and 11 figure", "journal-ref": "International Journal of Computer Applications in Technology 55,\n  no. 3 (2017): 202-212", "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates the use of more than one crossover operator to\nenhance the performance of genetic algorithms. Novel crossover operators are\nproposed such as the Collision crossover, which is based on the physical rules\nof elastic collision, in addition to proposing two selection strategies for the\ncrossover operators, one of which is based on selecting the best crossover\noperator and the other randomly selects any operator. Several experiments on\nsome Travelling Salesman Problems (TSP) have been conducted to evaluate the\nproposed methods, which are compared to the well-known Modified crossover\noperator and partially mapped Crossover (PMX) crossover. The results show the\nimportance of some of the proposed methods, such as the collision crossover, in\naddition to the significant enhancement of the genetic algorithms performance,\nparticularly when using more than one crossover operator.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 08:25:29 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Hassanat", "Ahmad B. A.", ""], ["Alkafaween", "Esra'a", ""]]}, {"id": "1801.02508", "submitter": "Ella Gale", "authors": "Ella M. Gale", "title": "Spiking memristor logic gates are a type of time-variant perceptron", "comments": "8 pages, 3 figures. Poster presentation at a conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memristors are low-power memory-holding resistors thought to be useful for\nneuromophic computing, which can compute via spike-interactions mediated\nthrough the device's short-term memory. Using interacting spikes, it is\npossible to build an AND gate that computes OR at the same time, similarly a\nfull adder can be built that computes the arithmetical sum of its inputs. Here\nwe show how these gates can be understood by modelling the memristors as a\nnovel type of perceptron: one which is sensitive to input order. The\nmemristor's memory can change the input weights for later inputs, and thus the\nmemristor gates cannot be accurately described by a single perceptron,\nrequiring either a network of time-invarient perceptrons or a complex\ntime-varying self-reprogrammable perceptron. This work demonstrates the high\nfunctionality of memristor logic gates, and also that the addition of\ntheasholding could enable the creation of a standard perceptron in hardware,\nwhich may have use in building neural net chips.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 15:33:53 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Gale", "Ella M.", ""]]}, {"id": "1801.02567", "submitter": "Enrique Romero", "authors": "Enrique Romero Merino and Ferran Mazzanti Castrillejo and Jordi\n  Delgado Pin and David Buchaca Prats", "title": "Weighted Contrastive Divergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning algorithms for energy based Boltzmann architectures that rely on\ngradient descent are in general computationally prohibitive, typically due to\nthe exponential number of terms involved in computing the partition function.\nIn this way one has to resort to approximation schemes for the evaluation of\nthe gradient. This is the case of Restricted Boltzmann Machines (RBM) and its\nlearning algorithm Contrastive Divergence (CD). It is well-known that CD has a\nnumber of shortcomings, and its approximation to the gradient has several\ndrawbacks. Overcoming these defects has been the basis of much research and new\nalgorithms have been devised, such as persistent CD. In this manuscript we\npropose a new algorithm that we call Weighted CD (WCD), built from small\nmodifications of the negative phase in standard CD. However small these\nmodifications may be, experimental work reported in this paper suggest that WCD\nprovides a significant improvement over standard CD and persistent CD at a\nsmall additional computational cost.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 17:20:17 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 16:54:11 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Merino", "Enrique Romero", ""], ["Castrillejo", "Ferran Mazzanti", ""], ["Pin", "Jordi Delgado", ""], ["Prats", "David Buchaca", ""]]}, {"id": "1801.02726", "submitter": "Eliya Nachmani", "authors": "Eliya Nachmani, Yaron Bachar, Elad Marciano, David Burshtein and Yair\n  Be'ery", "title": "Near Maximum Likelihood Decoding with Deep Learning", "comments": "The paper will be presented at IZS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel and efficient neural decoder algorithm is proposed. The proposed\ndecoder is based on the neural Belief Propagation algorithm and the\nAutomorphism Group. By combining neural belief propagation with permutations\nfrom the Automorphism Group we achieve near maximum likelihood performance for\nHigh Density Parity Check codes. Moreover, the proposed decoder significantly\nimproves the decoding complexity, compared to our earlier work on the topic. We\nalso investigate the training process and show how it can be accelerated.\nSimulations of the hessian and the condition number show why the learning\nprocess is accelerated. We demonstrate the decoding algorithm for various\nlinear block codes of length up to 63 bits.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 23:49:42 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Nachmani", "Eliya", ""], ["Bachar", "Yaron", ""], ["Marciano", "Elad", ""], ["Burshtein", "David", ""], ["Be'ery", "Yair", ""]]}, {"id": "1801.02797", "submitter": "Xinyu Wu", "authors": "Xinyu Wu and Vishal Saxena", "title": "Dendritic-Inspired Processing Enables Bio-Plausible STDP in Compound\n  Binary Synapses", "comments": null, "journal-ref": null, "doi": "10.1109/TNANO.2018.2871680", "report-no": null, "categories": "cs.NE cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-inspired learning mechanisms, e.g. spike timing dependent plasticity\n(STDP), enable agile and fast on-the-fly adaptation capability in a spiking\nneural network. When incorporating emerging nanoscale resistive non-volatile\nmemory (NVM) devices, with ultra-low power consumption and high-density\nintegration capability, a spiking neural network hardware would result in\nseveral orders of magnitude reduction in energy consumption at a very small\nform factor and potentially herald autonomous learning machines. However,\nactual memory devices have shown to be intrinsically binary with stochastic\nswitching, and thus impede the realization of ideal STDP with continuous analog\nvalues. In this work, a dendritic-inspired processing architecture is proposed\nin addition to novel CMOS neuron circuits. The utilization of spike\nattenuations and delays transforms the traditionally undesired stochastic\nbehavior of binary NVMs into a useful leverage that enables\nbiologically-plausible STDP learning. As a result, this work paves a pathway to\nadopt practical binary emerging NVM devices in brain-inspired neuromorphic\ncomputing.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 05:09:56 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Wu", "Xinyu", ""], ["Saxena", "Vishal", ""]]}, {"id": "1801.02805", "submitter": "Lex Fridman", "authors": "Lex Fridman, Jack Terwilliger, Benedikt Jenik", "title": "DeepTraffic: Crowdsourced Hyperparameter Tuning of Deep Reinforcement\n  Learning Systems for Multi-Agent Dense Traffic Navigation", "comments": "Neural Information Processing Systems (NIPS 2018) Deep Reinforcement\n  Learning Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a traffic simulation named DeepTraffic where the planning systems\nfor a subset of the vehicles are handled by a neural network as part of a\nmodel-free, off-policy reinforcement learning process. The primary goal of\nDeepTraffic is to make the hands-on study of deep reinforcement learning\naccessible to thousands of students, educators, and researchers in order to\ninspire and fuel the exploration and evaluation of deep Q-learning network\nvariants and hyperparameter configurations through large-scale, open\ncompetition. This paper investigates the crowd-sourced hyperparameter tuning of\nthe policy network that resulted from the first iteration of the DeepTraffic\ncompetition where thousands of participants actively searched through the\nhyperparameter space.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 05:56:15 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 01:36:43 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Fridman", "Lex", ""], ["Terwilliger", "Jack", ""], ["Jenik", "Benedikt", ""]]}, {"id": "1801.02827", "submitter": "Esra'a Alkafaween", "authors": "Esra'a O Alkafaween", "title": "Novel Methods for Enhancing the Performance of Genetic Algorithms", "comments": "88 pages, Master's thesis, Information Technology, Mutah university,\n  2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this thesis we propose new methods for crossover operator namely: cut on\nworst gene (COWGC), cut on worst L+R gene (COWLRGC) and Collision Crossovers.\nAnd also we propose several types of mutation operator such as: worst gene with\nrandom gene mutation (WGWRGM) , worst LR gene with random gene mutation\n(WLRGWRGM), worst gene with worst gene mutation (WGWWGM), worst gene with\nnearest neighbour mutation (WGWNNM), worst gene with the worst around the\nnearest neighbour mutation (WGWWNNM), worst gene inserted beside nearest\nneighbour mutation (WGIBNNM), random gene inserted beside nearest neighbour\nmutation (RGIBNNM), Swap worst gene locally mutation (SWGLM), Insert best\nrandom gene before worst gene mutation (IBRGBWGM) and Insert best random gene\nbefore random gene mutation (IBRGBRGM). In addition to proposing four selection\nstrategies, namely: select any crossover (SAC), select any mutation (SAM),\nselect best crossover (SBC) and select best mutation (SBM). The first two are\nbased on selection of the best crossover and mutation operator respectively,\nand the other two strategies randomly select any operator. So we investigate\nthe use of more than one crossover/mutation operator (based on the proposed\nstrategies) to enhance the performance of genetic algorithms. Our experiments,\nconducted on several Travelling Salesman Problems (TSP), show the superiority\nof some of the proposed methods in crossover and mutation over some of the\nwell-known crossover and mutation operators described in the literature. In\naddition, using any of the four strategies (SAC, SAM, SBC and SBM), found to be\nbetter than using one crossover/mutation operator in general, because those\nallow the GA to avoid local optima, or the so-called premature convergence.\nKeywords: GAs, Collision crossover, Multi crossovers, Multi mutations, TSP.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 07:37:23 GMT"}, {"version": "v2", "created": "Sun, 14 Jan 2018 06:27:03 GMT"}, {"version": "v3", "created": "Thu, 25 Jan 2018 18:08:15 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Alkafaween", "Esra'a O", ""]]}, {"id": "1801.03143", "submitter": "Artit Wangperawong", "authors": "Artit Wangperawong, Kettip Kriangchaivech, Austin Lanari, Supui Lam,\n  Panthong Wangperawong", "title": "Comparing heterogeneous entities using artificial neural networks of\n  trainable weighted structural components and machine-learned activation\n  functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To compare entities of differing types and structural components, the\nartificial neural network paradigm was used to cross-compare structural\ncomponents between heterogeneous documents. Trainable weighted structural\ncomponents were input into machine-learned activation functions of the neurons.\nThe model was used for matching news articles and videos, where the inputs and\nactivation functions respectively consisted of term vectors and cosine\nsimilarity measures between the weighted structural components. The model was\ntested with different weights, achieving as high as 59.2% accuracy for matching\nvideos to news articles. A mobile application user interface for recommending\nrelated videos for news articles was developed to demonstrate consumer value,\nincluding its potential usefulness for cross-selling products from unrelated\ncategories.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 21:20:08 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Wangperawong", "Artit", ""], ["Kriangchaivech", "Kettip", ""], ["Lanari", "Austin", ""], ["Lam", "Supui", ""], ["Wangperawong", "Panthong", ""]]}, {"id": "1801.03373", "submitter": "Pierrick Bruneau", "authors": "Pierrick Bruneau and Philippe Pinheiro and Yoann Didry", "title": "Data-driven forecasting of solar irradiance", "comments": "Published in French In EGC 2018, vol. RNTI-E-34, pp.439-450\n  https://editions-rnti.fr/?inprocid=1002422", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a flexible approach to short term prediction of\nmeteorological variables. In particular, we focus on the prediction of the\nsolar irradiance one hour ahead, a task that has high practical value when\noptimizing solar energy resources. As D\\'efi EGC 2018 provides us with time\nseries data for multiple sensors (e.g. solar irradiance, temperature,\nhygrometry), recorded every minute for two years and 5 geographical sites from\nLa R\\'eunion island, we test the value of using recently observed data as input\nfor prediction models, as well as the performance of models across sites. After\ndescribing our data cleaning and normalization process, we combine a variable\nselection step based on AutoRegressive Integrated Moving Average (ARIMA)\nmodels, to using general purpose regression techniques such as neural networks\nand regression trees.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 13:45:13 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 13:40:54 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Bruneau", "Pierrick", ""], ["Pinheiro", "Philippe", ""], ["Didry", "Yoann", ""]]}, {"id": "1801.03523", "submitter": "Fernando Fernandes Neto", "authors": "Fernando Fernandes Neto", "title": "Generative Models for Stochastic Processes Using Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.NE physics.comp-ph q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper aims to demonstrate the usage of Convolutional Neural\nNetworks as a generative model for stochastic processes, enabling researchers\nfrom a wide range of fields (such as quantitative finance and physics) to\ndevelop a general tool for forecasts and simulations without the need to\nidentify/assume a specific system structure or estimate its parameters.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 03:35:20 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Neto", "Fernando Fernandes", ""]]}, {"id": "1801.04326", "submitter": "Liangzhen Lai", "authors": "Liangzhen Lai, Naveen Suda, Vikas Chandra", "title": "Not All Ops Are Created Equal!", "comments": "Accepted at SysML Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient and compact neural network models are essential for enabling the\ndeployment on mobile and embedded devices. In this work, we point out that\ntypical design metrics for gauging the efficiency of neural network\narchitectures -- total number of operations and parameters -- are not\nsufficient. These metrics may not accurately correlate with the actual\ndeployment metrics such as energy and memory footprint. We show that throughput\nand energy varies by up to 5X across different neural network operation types\non an off-the-shelf Arm Cortex-M7 microcontroller. Furthermore, we show that\nthe memory required for activation data also need to be considered, apart from\nthe model parameters, for network architecture exploration studies.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 21:43:56 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 22:20:26 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Lai", "Liangzhen", ""], ["Suda", "Naveen", ""], ["Chandra", "Vikas", ""]]}, {"id": "1801.04487", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr", "title": "Better Runtime Guarantees Via Stochastic Domination", "comments": "Significantly extended version of a paper that appeared in the\n  proceedings of EvoCOP 2018", "journal-ref": "Theoretical Computer Science, 773:115-137, 2019", "doi": "10.1016/j.tcs.2018.09.024", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Apart from few exceptions, the mathematical runtime analysis of evolutionary\nalgorithms is mostly concerned with expected runtimes. In this work, we argue\nthat stochastic domination is a notion that should be used more frequently in\nthis area. Stochastic domination allows to formulate much more informative\nperformance guarantees, it allows to decouple the algorithm analysis into the\ntrue algorithmic part of detecting a domination statement and the\nprobability-theoretical part of deriving the desired probabilistic guarantees\nfrom this statement, and it helps finding simpler and more natural proofs. As\nparticular results, we prove a fitness level theorem which shows that the\nruntime is dominated by a sum of independent geometric random variables, we\nprove the first tail bounds for several classic runtime problems, and we give a\nshort and natural proof for Witt's result that the runtime of any $(\\mu,p)$\nmutation-based algorithm on any function with unique optimum is subdominated by\nthe runtime of a variant of the \\oea on the \\onemax function. As side-products,\nwe determine the fastest unbiased (1+1) algorithm for the \\leadingones\nbenchmark problem, both in the general case and when restricted to static\nmutation operators, and we prove a Chernoff-type tail bound for sums of\nindependent coupon collector distributions.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 21:30:09 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 13:06:08 GMT"}, {"version": "v3", "created": "Fri, 15 Jun 2018 09:10:45 GMT"}, {"version": "v4", "created": "Mon, 18 Jun 2018 16:21:46 GMT"}, {"version": "v5", "created": "Thu, 23 Aug 2018 06:37:03 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Doerr", "Benjamin", ""]]}, {"id": "1801.04530", "submitter": "Jiannan Zhao", "authors": "Jiannan Zhao, Cheng Hu, Chun Zhang, Zhihua Wang and Shigang Yue", "title": "A Bio-inspired Collision Detecotr for Small Quadcopter", "comments": "7 pages, 29 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sense and avoid capability enables insects to fly versatilely and robustly in\ndynamic complex environment. Their biological principles are so practical and\nefficient that inspired we human imitating them in our flying machines. In this\npaper, we studied a novel bio-inspired collision detector and its application\non a quadcopter. The detector is inspired from LGMD neurons in the locusts, and\nmodeled into an STM32F407 MCU. Compared to other collision detecting methods\napplied on quadcopters, we focused on enhancing the collision selectivity in a\nbio-inspired way that can considerably increase the computing efficiency during\nan obstacle detecting task even in complex dynamic environment. We designed the\nquadcopter's responding operation imminent collisions and tested this\nbio-inspired system in an indoor arena. The observed results from the\nexperiments demonstrated that the LGMD collision detector is feasible to work\nas a vision module for the quadcopter's collision avoidance task.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 09:22:43 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Zhao", "Jiannan", ""], ["Hu", "Cheng", ""], ["Zhang", "Chun", ""], ["Wang", "Zhihua", ""], ["Yue", "Shigang", ""]]}, {"id": "1801.04734", "submitter": "Maurice G\\\"uttler", "authors": "Kai Zoschke, Maurice G\\\"uttler, Lars B\\\"ottcher, Andreas Gr\\\"ubl, Dan\n  Husmann, Johannes Schemmel, Karlheinz Meier, Oswin Ehrmann", "title": "Full Wafer Redistribution and Wafer Embedding as Key Technologies for a\n  Multi-Scale Neuromorphic Hardware Cluster", "comments": "Accepted at EPTC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Together with the Kirchhoff-Institute for Physics(KIP) the Fraunhofer IZM has\ndeveloped a full wafer redistribution and embedding technology as base for a\nlarge-scale neuromorphic hardware system. The paper will give an overview of\nthe neuromorphic computing platform at the KIP and the associated hardware\nrequirements which drove the described technological developments. In the first\nphase of the project standard redistribution technologies from wafer level\npackaging were adapted to enable a high density reticle-to-reticle routing on\n200mm CMOS wafers. Neighboring reticles were interconnected across the scribe\nlines with an 8{\\mu}m pitch routing based on semi-additive copper\nmetallization. Passivation by photo sensitive benzocyclobutene was used to\nenable a second intra-reticle routing layer. Final IO pads with flash gold were\ngenerated on top of each reticle. With that concept neuromorphic systems based\non full wafers could be assembled and tested. The fabricated high density\ninter-reticle routing revealed a very high yield of larger than 99.9%. In order\nto allow an upscaling of the system size to a large number of wafers with\nfeasible effort a full wafer embedding concept for printed circuit boards was\ndeveloped and proven in the second phase of the project. The wafers were\nthinned to 250{\\mu}m and laminated with additional prepreg layers and copper\nfoils into a core material. After lamination of the PCB panel the reticle IOs\nof the embedded wafer were accessed by micro via drilling, copper\nelectroplating, lithography and subtractive etching of the PCB wiring\nstructure. The created wiring with 50um line width enabled an access of the\nreticle IOs on the embedded wafer as well as a board level routing. The panels\nwith the embedded wafers were subsequently stressed with up to 1000 thermal\ncycles between 0C and 100C and have shown no severe failure formation over the\ncycle time.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 10:59:31 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Zoschke", "Kai", ""], ["G\u00fcttler", "Maurice", ""], ["B\u00f6ttcher", "Lars", ""], ["Gr\u00fcbl", "Andreas", ""], ["Husmann", "Dan", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""], ["Ehrmann", "Oswin", ""]]}, {"id": "1801.05156", "submitter": "Shumeet Baluja", "authors": "Shumeet Baluja", "title": "Empirical Explorations in Training Networks with Discrete Activations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present extensive experiments training and testing hidden units in deep\nnetworks that emit only a predefined, static, number of discretized values.\nThese units provide benefits in real-world deployment in systems in which\nmemory and/or computation may be limited. Additionally, they are particularly\nwell suited for use in large recurrent network models that require the\nmaintenance of large amounts of internal state in memory. Surprisingly, we find\nthat despite reducing the number of values that can be represented in the\noutput activations from $2^{32}-2^{64}$ to between 64 and 256, there is little\nto no degradation in network performance across a variety of different\nsettings. We investigate simple classification and regression tasks, as well as\nmemorization and compression problems. We compare the results with more\nstandard activations, such as tanh and relu. Unlike previous discretization\nstudies which often concentrate only on binary units, we examine the effects of\nvarying the number of allowed activation levels. Compared to existing\napproaches for discretization, the approach presented here is both conceptually\nand programatically simple, has no stochastic component, and allows the\ntraining, testing, and usage phases to be treated in exactly the same manner.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 08:47:18 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Baluja", "Shumeet", ""]]}, {"id": "1801.05387", "submitter": "Mohammad Javad Shafiee", "authors": "Mohammad Javad Shafiee, Brendan Chwyl, Francis Li, Rongyan Chen,\n  Michelle Karg, Christian Scharfenberger, Alexander Wong", "title": "StressedNets: Efficient Feature Representations via Stress-induced\n  Evolutionary Synthesis of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational complexity of leveraging deep neural networks for\nextracting deep feature representations is a significant barrier to its\nwidespread adoption, particularly for use in embedded devices. One particularly\npromising strategy to addressing the complexity issue is the notion of\nevolutionary synthesis of deep neural networks, which was demonstrated to\nsuccessfully produce highly efficient deep neural networks while retaining\nmodeling performance. Here, we further extend upon the evolutionary synthesis\nstrategy for achieving efficient feature extraction via the introduction of a\nstress-induced evolutionary synthesis framework, where stress signals are\nimposed upon the synapses of a deep neural network during training to induce\nstress and steer the synthesis process towards the production of more efficient\ndeep neural networks over successive generations and improved model fidelity at\na greater efficiency. The proposed stress-induced evolutionary synthesis\napproach is evaluated on a variety of different deep neural network\narchitectures (LeNet5, AlexNet, and YOLOv2) on different tasks (object\nclassification and object detection) to synthesize efficient StressedNets over\nmultiple generations. Experimental results demonstrate the efficacy of the\nproposed framework to synthesize StressedNets with significant improvement in\nnetwork architecture efficiency (e.g., 40x for AlexNet and 33x for YOLOv2) and\nspeed improvements (e.g., 5.5x inference speed-up for YOLOv2 on an Nvidia Tegra\nX1 mobile processor).\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 17:47:13 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Shafiee", "Mohammad Javad", ""], ["Chwyl", "Brendan", ""], ["Li", "Francis", ""], ["Chen", "Rongyan", ""], ["Karg", "Michelle", ""], ["Scharfenberger", "Christian", ""], ["Wong", "Alexander", ""]]}, {"id": "1801.05984", "submitter": "Ferdi Kara", "authors": "Ferdi Kara, Hakan Kaya, Okan Erkaymaz, Ertan Ozturk", "title": "Prediction of the Optimal Threshold Value in DF Relay Selection Schemes\n  Based on Artificial Neural Networks", "comments": "6 pages,IEEE INnovations in Intelligent SysTems and Applications\n  (INISTA), 2016 International Symposium on", "journal-ref": null, "doi": "10.1109/INISTA.2016.7571823", "report-no": null, "categories": "eess.SP cs.LG cs.NE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In wireless communications, the cooperative communication (CC) technology\npromises performance gains compared to traditional Single-Input Single Output\n(SISO) techniques. Therefore, the CC technique is one of the nominees for 5G\nnetworks. In the Decode-and-Forward (DF) relaying scheme which is one of the CC\ntechniques, determination of the threshold value at the relay has a key role\nfor the system performance and power usage. In this paper, we propose\nprediction of the optimal threshold values for the best relay selection scheme\nin cooperative communications, based on Artificial Neural Networks (ANNs) for\nthe first time in literature. The average link qualities and number of relays\nhave been used as inputs in the prediction of optimal threshold values using\nArtificial Neural Networks (ANNs): Multi-Layer Perceptron (MLP) and Radial\nBasis Function (RBF) networks. The MLP network has better performance from the\nRBF network on the prediction of optimal threshold value when the same number\nof neurons is used at the hidden layer for both networks. Besides, the optimal\nthreshold values obtained using ANNs are verified by the optimal threshold\nvalues obtained numerically using the closed form expression derived for the\nsystem. The results show that the optimal threshold values obtained by ANNs on\nthe best relay selection scheme provide a minimum Bit-Error-Rate (BER) because\nof the reduction of the probability that error propagation may occur. Also, for\nthe same BER performance goal, prediction of optimal threshold values provides\n2dB less power usage, which is great gain in terms of green communicationBER\nperformance goal, prediction of optimal threshold values provides 2dB less\npower usage, which is great gain in terms of green communication.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 12:36:38 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Kara", "Ferdi", ""], ["Kaya", "Hakan", ""], ["Erkaymaz", "Okan", ""], ["Ozturk", "Ertan", ""]]}, {"id": "1801.06007", "submitter": "Pieter Gijsbers", "authors": "Pieter Gijsbers, Joaquin Vanschoren, Randal S. Olson", "title": "Layered TPOT: Speeding up Tree-based Pipeline Optimization", "comments": "Update to include a reference to Zutty et al. after it was brought to\n  our attention", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the demand for machine learning increasing, so does the demand for tools\nwhich make it easier to use. Automated machine learning (AutoML) tools have\nbeen developed to address this need, such as the Tree-Based Pipeline\nOptimization Tool (TPOT) which uses genetic programming to build optimal\npipelines. We introduce Layered TPOT, a modification to TPOT which aims to\ncreate pipelines equally good as the original, but in significantly less time.\nThis approach evaluates candidate pipelines on increasingly large subsets of\nthe data according to their fitness, using a modified evolutionary algorithm to\nallow for separate competition between pipelines trained on different sample\nsizes. Empirical evaluation shows that, on sufficiently large datasets, Layered\nTPOT indeed finds better models faster.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 13:36:51 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 14:45:22 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Gijsbers", "Pieter", ""], ["Vanschoren", "Joaquin", ""], ["Olson", "Randal S.", ""]]}, {"id": "1801.06105", "submitter": "Yuhuang Hu", "authors": "Yuhuang Hu, Adrian Huber, Jithendar Anumula, and Shih-Chii Liu", "title": "Overcoming the vanishing gradient problem in plain recurrent networks", "comments": "20 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plain recurrent networks greatly suffer from the vanishing gradient problem\nwhile Gated Neural Networks (GNNs) such as Long-short Term Memory (LSTM) and\nGated Recurrent Unit (GRU) deliver promising results in many sequence learning\ntasks through sophisticated network designs. This paper shows how we can\naddress this problem in a plain recurrent network by analyzing the gating\nmechanisms in GNNs. We propose a novel network called the Recurrent Identity\nNetwork (RIN) which allows a plain recurrent network to overcome the vanishing\ngradient problem while training very deep models without the use of gates. We\ncompare this model with IRNNs and LSTMs on multiple sequence modeling\nbenchmarks. The RINs demonstrate competitive performance and converge faster in\nall tasks. Notably, small RIN models produce 12%--67% higher accuracy on the\nSequential and Permuted MNIST datasets and reach state-of-the-art performance\non the bAbI question answering dataset.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 15:54:55 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 15:06:50 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 14:04:52 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Hu", "Yuhuang", ""], ["Huber", "Adrian", ""], ["Anumula", "Jithendar", ""], ["Liu", "Shih-Chii", ""]]}, {"id": "1801.06176", "submitter": "Xiujun Li", "authors": "Baolin Peng and Xiujun Li and Jianfeng Gao and Jingjing Liu and\n  Kam-Fai Wong and Shang-Yu Su", "title": "Deep Dyna-Q: Integrating Planning for Task-Completion Dialogue Policy\n  Learning", "comments": "11 pages, 8 figures, Accepted in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training a task-completion dialogue agent via reinforcement learning (RL) is\ncostly because it requires many interactions with real users. One common\nalternative is to use a user simulator. However, a user simulator usually lacks\nthe language complexity of human interlocutors and the biases in its design may\ntend to degrade the agent. To address these issues, we present Deep Dyna-Q,\nwhich to our knowledge is the first deep RL framework that integrates planning\nfor task-completion dialogue policy learning. We incorporate into the dialogue\nagent a model of the environment, referred to as the world model, to mimic real\nuser response and generate simulated experience. During dialogue policy\nlearning, the world model is constantly updated with real user experience to\napproach real user behavior, and in turn, the dialogue agent is optimized using\nboth real experience and simulated experience. The effectiveness of our\napproach is demonstrated on a movie-ticket booking task in both simulated and\nhuman-in-the-loop settings.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 18:57:33 GMT"}, {"version": "v2", "created": "Sun, 13 May 2018 22:31:38 GMT"}, {"version": "v3", "created": "Wed, 23 May 2018 17:52:27 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Peng", "Baolin", ""], ["Li", "Xiujun", ""], ["Gao", "Jianfeng", ""], ["Liu", "Jingjing", ""], ["Wong", "Kam-Fai", ""], ["Su", "Shang-Yu", ""]]}, {"id": "1801.06274", "submitter": "Yuhao Zhu", "authors": "Yuhao Zhu, Matthew Mattina, Paul Whatmough", "title": "Mobile Machine Learning Hardware at ARM: A Systems-on-Chip (SoC)\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is playing an increasingly significant role in emerging\nmobile application domains such as AR/VR, ADAS, etc. Accordingly, hardware\narchitects have designed customized hardware for machine learning algorithms,\nespecially neural networks, to improve compute efficiency. However, machine\nlearning is typically just one processing stage in complex end-to-end\napplications, involving multiple components in a mobile Systems-on-a-chip\n(SoC). Focusing only on ML accelerators loses bigger optimization opportunity\nat the system (SoC) level. This paper argues that hardware architects should\nexpand the optimization scope to the entire SoC. We demonstrate one particular\ncase-study in the domain of continuous computer vision where camera sensor,\nimage signal processor (ISP), memory, and NN accelerator are synergistically\nco-designed to achieve optimal system-level efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 02:42:10 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 23:54:27 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Zhu", "Yuhao", ""], ["Mattina", "Matthew", ""], ["Whatmough", "Paul", ""]]}, {"id": "1801.06434", "submitter": "Lutz Roese-Koerner", "authors": "Ido Freeman, Lutz Roese-Koerner, Anton Kummert", "title": "EffNet: An Efficient Structure for Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever increasing application of Convolutional Neural Networks to\ncustomer products the need emerges for models to efficiently run on embedded,\nmobile hardware. Slimmer models have therefore become a hot research topic with\nvarious approaches which vary from binary networks to revised convolution\nlayers. We offer our contribution to the latter and propose a novel convolution\nblock which significantly reduces the computational burden while surpassing the\ncurrent state-of-the-art. Our model, dubbed EffNet, is optimised for models\nwhich are slim to begin with and is created to tackle issues in existing models\nsuch as MobileNet and ShuffleNet.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 14:57:23 GMT"}, {"version": "v2", "created": "Mon, 12 Feb 2018 12:50:36 GMT"}, {"version": "v3", "created": "Mon, 19 Feb 2018 22:25:23 GMT"}, {"version": "v4", "created": "Thu, 1 Mar 2018 16:10:33 GMT"}, {"version": "v5", "created": "Wed, 14 Mar 2018 08:52:59 GMT"}, {"version": "v6", "created": "Tue, 5 Jun 2018 12:10:12 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Freeman", "Ido", ""], ["Roese-Koerner", "Lutz", ""], ["Kummert", "Anton", ""]]}, {"id": "1801.06597", "submitter": "Yu Shi", "authors": "Yu Shi, Fangqiu Han, Xinwei He, Xinran He, Carl Yang, Jie Luo, Jiawei\n  Han", "title": "mvn2vec: Preservation and Collaboration in Multi-View Network Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view networks are broadly present in real-world applications. In the\nmeantime, network embedding has emerged as an effective representation learning\napproach for networked data. Therefore, we are motivated to study the problem\nof multi-view network embedding with a focus on the optimization objectives\nthat are specific and important in embedding this type of network. In our\npractice of embedding real-world multi-view networks, we explicitly identify\ntwo such objectives, which we refer to as preservation and collaboration. The\nin-depth analysis of these two objectives is discussed throughout this paper.\nIn addition, the mvn2vec algorithms are proposed to (i) study how varied extent\nof preservation and collaboration can impact embedding learning and (ii)\nexplore the feasibility of achieving better embedding quality by modeling them\nsimultaneously. With experiments on a series of synthetic datasets, a\nlarge-scale internal Snapchat dataset, and two public datasets, we confirm the\nvalidity and importance of preservation and collaboration as two objectives for\nmulti-view network embedding. These experiments further demonstrate that better\nembedding can be obtained by simultaneously modeling the two objectives, while\nnot over-complicating the model or requiring additional supervision. The code\nand the processed datasets are available at\nhttp://yushi2.web.engr.illinois.edu/.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 23:14:08 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 20:57:12 GMT"}, {"version": "v3", "created": "Sun, 3 Nov 2019 01:52:09 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Shi", "Yu", ""], ["Han", "Fangqiu", ""], ["He", "Xinwei", ""], ["He", "Xinran", ""], ["Yang", "Carl", ""], ["Luo", "Jie", ""], ["Han", "Jiawei", ""]]}, {"id": "1801.06601", "submitter": "Vikas Chandra", "authors": "Liangzhen Lai, Naveen Suda, Vikas Chandra", "title": "CMSIS-NN: Efficient Neural Network Kernels for Arm Cortex-M CPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks are becoming increasingly popular in always-on IoT edge\ndevices performing data analytics right at the source, reducing latency as well\nas energy consumption for data communication. This paper presents CMSIS-NN,\nefficient kernels developed to maximize the performance and minimize the memory\nfootprint of neural network (NN) applications on Arm Cortex-M processors\ntargeted for intelligent IoT edge devices. Neural network inference based on\nCMSIS-NN kernels achieves 4.6X improvement in runtime/throughput and 4.9X\nimprovement in energy efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 23:39:15 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Lai", "Liangzhen", ""], ["Suda", "Naveen", ""], ["Chandra", "Vikas", ""]]}, {"id": "1801.06687", "submitter": "Hongxin Wang", "authors": "Hongxin Wang, Jigen Peng and Shigang Yue", "title": "A Directionally Selective Small Target Motion Detecting Visual Neural\n  Network in Cluttered Backgrounds", "comments": "14 pages, 21 figures", "journal-ref": null, "doi": "10.1109/TCYB.2018.2869384", "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discriminating targets moving against a cluttered background is a huge\nchallenge, let alone detecting a target as small as one or a few pixels and\ntracking it in flight. In the fly's visual system, a class of specific neurons,\ncalled small target motion detectors (STMDs), have been identified as showing\nexquisite selectivity for small target motion. Some of the STMDs have also\ndemonstrated directional selectivity which means these STMDs respond strongly\nonly to their preferred motion direction. Directional selectivity is an\nimportant property of these STMD neurons which could contribute to tracking\nsmall targets such as mates in flight. However, little has been done on\nsystematically modeling these directional selective STMD neurons. In this\npaper, we propose a directional selective STMD-based neural network (DSTMD) for\nsmall target detection in a cluttered background. In the proposed neural\nnetwork, a new correlation mechanism is introduced for direction selectivity\nvia correlating signals relayed from two pixels. Then, a lateral inhibition\nmechanism is implemented on the spatial field for size selectivity of STMD\nneurons. Extensive experiments showed that the proposed neural network not only\nis in accord with current biological findings, i.e. showing directional\npreferences, but also worked reliably in detecting small targets against\ncluttered backgrounds.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 15:11:07 GMT"}, {"version": "v2", "created": "Tue, 10 Jul 2018 22:12:33 GMT"}, {"version": "v3", "created": "Wed, 18 Jul 2018 22:08:56 GMT"}, {"version": "v4", "created": "Sat, 11 Aug 2018 16:51:54 GMT"}, {"version": "v5", "created": "Sat, 29 Sep 2018 10:37:55 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Wang", "Hongxin", ""], ["Peng", "Jigen", ""], ["Yue", "Shigang", ""]]}, {"id": "1801.06700", "submitter": "Iulian Vlad Serban", "authors": "Iulian V. Serban, Chinnadhurai Sankar, Mathieu Germain, Saizheng\n  Zhang, Zhouhan Lin, Sandeep Subramanian, Taesup Kim, Michael Pieper, Sarath\n  Chandar, Nan Rosemary Ke, Sai Rajeswar, Alexandre de Brebisson, Jose M. R.\n  Sotelo, Dendi Suhubdy, Vincent Michalski, Alexandre Nguyen, Joelle Pineau,\n  Yoshua Bengio", "title": "A Deep Reinforcement Learning Chatbot (Short Version)", "comments": "9 pages, 1 figure, 2 tables; presented at NIPS 2017, Conversational\n  AI: \"Today's Practice and Tomorrow's Potential\" Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MILABOT: a deep reinforcement learning chatbot developed by the\nMontreal Institute for Learning Algorithms (MILA) for the Amazon Alexa Prize\ncompetition. MILABOT is capable of conversing with humans on popular small talk\ntopics through both speech and text. The system consists of an ensemble of\nnatural language generation and retrieval models, including neural network and\ntemplate-based models. By applying reinforcement learning to crowdsourced data\nand real-world user interactions, the system has been trained to select an\nappropriate response from the models in its ensemble. The system has been\nevaluated through A/B testing with real-world users, where it performed\nsignificantly better than other systems. The results highlight the potential of\ncoupling ensemble systems with deep reinforcement learning as a fruitful path\nfor developing real-world, open-domain conversational agents.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 17:22:06 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Serban", "Iulian V.", ""], ["Sankar", "Chinnadhurai", ""], ["Germain", "Mathieu", ""], ["Zhang", "Saizheng", ""], ["Lin", "Zhouhan", ""], ["Subramanian", "Sandeep", ""], ["Kim", "Taesup", ""], ["Pieper", "Michael", ""], ["Chandar", "Sarath", ""], ["Ke", "Nan Rosemary", ""], ["Rajeswar", "Sai", ""], ["de Brebisson", "Alexandre", ""], ["Sotelo", "Jose M. R.", ""], ["Suhubdy", "Dendi", ""], ["Michalski", "Vincent", ""], ["Nguyen", "Alexandre", ""], ["Pineau", "Joelle", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1801.06733", "submitter": "Benjamin Doerr", "authors": "Benjamin Doerr", "title": "Probabilistic Tools for the Analysis of Randomized Optimization\n  Heuristics", "comments": "91 pages", "journal-ref": "In Benjamin Doerr and Frank Neumann, editors, Theory of\n  Evolutionary Computation: Recent Developments in Discrete Optimization, pages\n  1-87. Springer, 2020", "doi": "10.1007/978-3-030-29414-4_1", "report-no": null, "categories": "cs.DS cs.DM cs.NE math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter collects several probabilistic tools that proved to be useful in\nthe analysis of randomized search heuristics. This includes classic material\nlike Markov, Chebyshev and Chernoff inequalities, but also lesser known topics\nlike stochastic domination and coupling or Chernoff bounds for geometrically\ndistributed random variables and for negatively correlated random variables.\nMost of the results presented here have appeared previously, some, however,\nonly in recent conference publications. While the focus is on collecting tools\nfor the analysis of randomized search heuristics, many of these may be useful\nas well in the analysis of classic randomized algorithms or discrete random\nstructures.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 21:47:13 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 21:29:21 GMT"}, {"version": "v3", "created": "Thu, 14 Jun 2018 21:42:36 GMT"}, {"version": "v4", "created": "Wed, 18 Mar 2020 17:20:34 GMT"}, {"version": "v5", "created": "Sun, 18 Apr 2021 20:09:30 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Doerr", "Benjamin", ""]]}, {"id": "1801.06976", "submitter": "Hongxin Wang", "authors": "Hongxin Wang, Jigen Peng and Shigang Yue", "title": "An Improved LPTC Neural Model for Background Motion Direction Estimation", "comments": "6 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A class of specialized neurons, called lobula plate tangential cells (LPTCs)\nhas been shown to respond strongly to wide-field motion. The classic model,\nelementary motion detector (EMD) and its improved model, two-quadrant detector\n(TQD) have been proposed to simulate LPTCs. Although EMD and TQD can percept\nbackground motion, their outputs are so cluttered that it is difficult to\ndiscriminate actual motion direction of the background. In this paper, we\npropose a max operation mechanism to model a newly-found transmedullary neuron\nTm9 whose physiological properties do not map onto EMD and TQD. This proposed\nmax operation mechanism is able to improve the detection performance of TQD in\ncluttered background by filtering out irrelevant motion signals. We will\ndemonstrate the functionality of this proposed mechanism in wide-field motion\nperception.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 06:57:05 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Wang", "Hongxin", ""], ["Peng", "Jigen", ""], ["Yue", "Shigang", ""]]}, {"id": "1801.07233", "submitter": "Esra'a Alkafaween", "authors": "Esra'a Alkafaween, Ahmad B. A. Hassanat", "title": "Improving TSP Solutions Using GA with a New Hybrid Mutation Based on\n  Knowledge and Randomness", "comments": "18 pages, 9 figure and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Genetic algorithm (GA) is an efficient tool for solving optimization problems\nby evolving solutions, as it mimics the Darwinian theory of natural evolution.\nThe mutation operator is one of the key success factors in GA, as it is\nconsidered the exploration operator of GA. Various mutation operators exist to\nsolve hard combinatorial problems such as the TSP. In this paper, we propose a\nhybrid mutation operator called \"IRGIBNNM\", this mutation is a combination of\ntwo existing mutations, a knowledge-based mutation, and a random-based\nmutation. We also improve the existing \"select best mutation\" strategy using\nthe proposed mutation. We conducted several experiments on twelve benchmark\nSymmetric traveling salesman problem (STSP) instances. The results of our\nexperiments show the efficiency of the proposed mutation, particularly when we\nuse it with some other mutations. Keyword: Knowledge-based mutation, Inversion\nmutation, Slide mutation, RGIBNNM, SBM.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 18:29:47 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Alkafaween", "Esra'a", ""], ["Hassanat", "Ahmad B. A.", ""]]}, {"id": "1801.07353", "submitter": "Hokchhay Tann", "authors": "Hokchhay Tann, Soheil Hashemi, Sherief Reda", "title": "Flexible Deep Neural Network Processing", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of Deep Neural Networks (DNNs) has drastically improved\nthe state of the art for many application domains. While achieving high\naccuracy performance, deploying state-of-the-art DNNs is a challenge since they\ntypically require billions of expensive arithmetic computations. In addition,\nDNNs are typically deployed in ensemble to boost accuracy performance, which\nfurther exacerbates the system requirements. This computational overhead is an\nissue for many platforms, e.g. data centers and embedded systems, with tight\nlatency and energy budgets. In this article, we introduce flexible DNNs\nensemble processing technique, which achieves large reduction in average\ninference latency while incurring small to negligible accuracy drop. Our\ntechnique is flexible in that it allows for dynamic adaptation between quality\nof results (QoR) and execution runtime. We demonstrate the effectiveness of the\ntechnique on AlexNet and ResNet-50 using the ImageNet dataset. This technique\ncan also easily handle other types of networks.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 00:02:57 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Tann", "Hokchhay", ""], ["Hashemi", "Soheil", ""], ["Reda", "Sherief", ""]]}, {"id": "1801.07546", "submitter": "John Warwicker", "authors": "Andrei Lissovoi, Pietro S. Oliveto, John Alasdair Warwicker", "title": "Simple Hyper-heuristics Control the Neighbourhood Size of Randomised\n  Local Search Optimally for LeadingOnes", "comments": "This work is accepted in Evolutionary Computation Journal. Abstract\n  shortened for ArXiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selection HHs are randomised search methodologies which choose and execute\nheuristics during the optimisation process from a set of low-level heuristics.\nA machine learning mechanism is generally used to decide which low-level\nheuristic should be applied in each decision step. In this paper we analyse\nwhether sophisticated learning mechanisms are always necessary for HHs to\nperform well. To this end we consider the most simple HHs from the literature\nand rigorously analyse their performance for the LeadingOnes function. Our\nanalysis shows that the standard Simple Random, Permutation, Greedy and Random\nGradient HHs show no signs of learning. While the former HHs do not attempt to\nlearn from the past performance of low-level heuristics, the idea behind the\nRandom Gradient HH is to continue to exploit the currently selected heuristic\nas long as it is successful. Hence, it is embedded with a reinforcement\nlearning mechanism with the shortest possible memory. However, the probability\nthat a promising heuristic is successful in the next step is relatively low\nwhen perturbing a reasonable solution to a combinatorial optimisation problem.\nWe generalise the simple Random Gradient HH so success can be measured over a\nfixed period of time tau, instead of a single iteration. For LO we prove that\nthe Generalised Random Gradient HH can learn to adapt the neighbourhood size of\nRLS to optimality during the run. We prove it has the best possible performance\nachievable with the low-level heuristics. We also prove that the performance of\nthe HH improves as the number of low-level local search heuristics to choose\nfrom increases. Finally, we show that the advantages of GRG over RLS and EAs\nusing standard bit mutation increase if the anytime performance is considered.\nExperimental analyses confirm these results for different problem sizes.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 14:13:53 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 17:49:26 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 11:13:13 GMT"}, {"version": "v4", "created": "Fri, 3 May 2019 12:45:51 GMT"}, {"version": "v5", "created": "Tue, 14 May 2019 14:01:33 GMT"}, {"version": "v6", "created": "Wed, 15 May 2019 10:43:08 GMT"}], "update_date": "2019-05-16", "authors_parsed": [["Lissovoi", "Andrei", ""], ["Oliveto", "Pietro S.", ""], ["Warwicker", "John Alasdair", ""]]}, {"id": "1801.07648", "submitter": "Elie Aljalbout", "authors": "Elie Aljalbout, Vladimir Golkov, Yawar Siddiqui, Maximilian Strobel,\n  Daniel Cremers", "title": "Clustering with Deep Learning: Taxonomy and New Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering methods based on deep neural networks have proven promising for\nclustering real-world data because of their high representational power. In\nthis paper, we propose a systematic taxonomy of clustering methods that utilize\ndeep neural networks. We base our taxonomy on a comprehensive review of recent\nwork and validate the taxonomy in a case study. In this case study, we show\nthat the taxonomy enables researchers and practitioners to systematically\ncreate new clustering methods by selectively recombining and replacing distinct\naspects of previous methods with the goal of overcoming their individual\nlimitations. The experimental evaluation confirms this and shows that the\nmethod created for the case study achieves state-of-the-art clustering quality\nand surpasses it in some cases.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 16:41:03 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2018 19:41:22 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Aljalbout", "Elie", ""], ["Golkov", "Vladimir", ""], ["Siddiqui", "Yawar", ""], ["Strobel", "Maximilian", ""], ["Cremers", "Daniel", ""]]}, {"id": "1801.07650", "submitter": "Shinichi Shirakawa", "authors": "Shinichi Shirakawa, Yasushi Iwata, Youhei Akimoto", "title": "Dynamic Optimization of Neural Network Structures Using Probabilistic\n  Modeling", "comments": "To appear in the Thirty-Second AAAI Conference on Artificial\n  Intelligence (AAAI-18), 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are powerful machine learning models and have\nsucceeded in various artificial intelligence tasks. Although various\narchitectures and modules for the DNNs have been proposed, selecting and\ndesigning the appropriate network structure for a target problem is a\nchallenging task. In this paper, we propose a method to simultaneously optimize\nthe network structure and weight parameters during neural network training. We\nconsider a probability distribution that generates network structures, and\noptimize the parameters of the distribution instead of directly optimizing the\nnetwork structure. The proposed method can apply to the various network\nstructure optimization problems under the same framework. We apply the proposed\nmethod to several structure optimization problems such as selection of layers,\nselection of unit types, and selection of connections using the MNIST,\nCIFAR-10, and CIFAR-100 datasets. The experimental results show that the\nproposed method can find the appropriate and competitive network structures.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 16:43:59 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Shirakawa", "Shinichi", ""], ["Iwata", "Yasushi", ""], ["Akimoto", "Youhei", ""]]}, {"id": "1801.07668", "submitter": "Ivo Gon\\c{c}alves", "authors": "Mauro Castelli, Ivo Gon\\c{c}alves, Luca Manzoni, Leonardo Vanneschi", "title": "Pruning Techniques for Mixed Ensembles of Genetic Programming Models", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-77553-1_4", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this paper is to define an effective strategy for building\nan ensemble of Genetic Programming (GP) models. Ensemble methods are widely\nused in machine learning due to their features: they average out biases, they\nreduce the variance and they usually generalize better than single models.\nDespite these advantages, building ensemble of GP models is not a\nwell-developed topic in the evolutionary computation community. To fill this\ngap, we propose a strategy that blends individuals produced by standard\nsyntax-based GP and individuals produced by geometric semantic genetic\nprogramming, one of the newest semantics-based method developed in GP. In fact,\nrecent literature showed that combining syntax and semantics could improve the\ngeneralization ability of a GP model. Additionally, to improve the diversity of\nthe GP models used to build up the ensemble, we propose different pruning\ncriteria that are based on correlation and entropy, a commonly used measure in\ninformation theory. Experimental results,obtained over different complex\nproblems, suggest that the pruning criteria based on correlation and entropy\ncould be effective in improving the generalization ability of the ensemble\nmodel and in reducing the computational burden required to build it.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 17:29:22 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Castelli", "Mauro", ""], ["Gon\u00e7alves", "Ivo", ""], ["Manzoni", "Luca", ""], ["Vanneschi", "Leonardo", ""]]}, {"id": "1801.08113", "submitter": "Alianna Maren", "authors": "Alianna J. Maren", "title": "Free Energy Minimization Using the 2-D Cluster Variation Method: Initial\n  Code Verification and Validation", "comments": "26 pages, 14 figures; minor rewording, references added", "journal-ref": null, "doi": null, "report-no": "THM TR2018-001.v2(ajm)", "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new approach for general artificial intelligence (GAI), building on neural\nnetwork deep learning architectures, can make use of one or more hidden layers\nthat have the ability to continuously reach a free energy minimum even after\ninput stimulus is removed, allowing for a variety of possible behaviors. One\nreason that this approach has not been developed until now has been the lack of\na suitable free energy equation. The Cluster Variation Method (CVM) offers a\nmeans for characterizing 2-D local pattern distributions, or configuration\nvariables, and provides a free energy formalism in terms of these configuration\nvariables. The equilibrium distribution of these configuration variables is\ndefined in terms of a single interaction enthalpy parameter, h, for the case of\nequiprobable distribution of bistate units. For non-equiprobable distributions,\nthe equilibrium distribution can be characterized by providing a fixed value\nfor the fraction of units in the active state (x1), corresponding to the\ninfluence of a per-unit activation enthalpy, together with the pairwise\ninteraction enthalpy parameter h. This paper provides verification and\nvalidation (V&V) for code that computes the configuration variable and\nthermodynamic values for 2-D CVM grids characterized by different interaction\nenthalpy parameters, or h-values. This work provides a foundation for\nexperimenting with a 2-D CVM-based hidden layer that can, as an alternative to\nresponding strictly to inputs, also now independently come to its own free\nenergy minimum and also return to a free energy-minimized state after\nperturbations, which will enable a range of input-independent behaviors. A\nfurther use of this 2-D CVM grid is that by characterizing local patterns in\nterms of their corresponding h-values (together with their x1 values), we have\na means for quantitatively characterizing different kinds of neural\ntopographies.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 18:29:28 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 20:09:08 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Maren", "Alianna J.", ""]]}, {"id": "1801.08116", "submitter": "Joel Leibo", "authors": "Joel Z. Leibo, Cyprien de Masson d'Autume, Daniel Zoran, David Amos,\n  Charles Beattie, Keith Anderson, Antonio Garc\\'ia Casta\\~neda, Manuel\n  Sanchez, Simon Green, Audrunas Gruslys, Shane Legg, Demis Hassabis, Matthew\n  M. Botvinick", "title": "Psychlab: A Psychology Laboratory for Deep Reinforcement Learning Agents", "comments": "28 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Psychlab is a simulated psychology laboratory inside the first-person 3D game\nworld of DeepMind Lab (Beattie et al. 2016). Psychlab enables implementations\nof classical laboratory psychological experiments so that they work with both\nhuman and artificial agents. Psychlab has a simple and flexible API that\nenables users to easily create their own tasks. As examples, we are releasing\nPsychlab implementations of several classical experimental paradigms including\nvisual search, change detection, random dot motion discrimination, and multiple\nobject tracking. We also contribute a study of the visual psychophysics of a\nspecific state-of-the-art deep reinforcement learning agent: UNREAL (Jaderberg\net al. 2016). This study leads to the surprising conclusion that UNREAL learns\nmore quickly about larger target stimuli than it does about smaller stimuli. In\nturn, this insight motivates a specific improvement in the form of a simple\nmodel of foveal vision that turns out to significantly boost UNREAL's\nperformance, both on Psychlab tasks, and on standard DeepMind Lab tasks. By\nopen-sourcing Psychlab we hope to facilitate a range of future such studies\nthat simultaneously advance deep reinforcement learning and improve its links\nwith cognitive science.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 18:31:51 GMT"}, {"version": "v2", "created": "Sun, 4 Feb 2018 19:29:12 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Leibo", "Joel Z.", ""], ["d'Autume", "Cyprien de Masson", ""], ["Zoran", "Daniel", ""], ["Amos", "David", ""], ["Beattie", "Charles", ""], ["Anderson", "Keith", ""], ["Casta\u00f1eda", "Antonio Garc\u00eda", ""], ["Sanchez", "Manuel", ""], ["Green", "Simon", ""], ["Gruslys", "Audrunas", ""], ["Legg", "Shane", ""], ["Hassabis", "Demis", ""], ["Botvinick", "Matthew M.", ""]]}, {"id": "1801.08230", "submitter": "Philip Bontrager", "authors": "Philip Bontrager, Wending Lin, Julian Togelius, Sebastian Risi", "title": "Deep Interactive Evolution", "comments": "16 pages, 5 figures, Published at EvoMUSART EvoStar 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an approach that combines generative adversarial\nnetworks (GANs) with interactive evolutionary computation (IEC). While GANs can\nbe trained to produce lifelike images, they are normally sampled randomly from\nthe learned distribution, providing limited control over the resulting output.\nOn the other hand, interactive evolution has shown promise in creating various\nartifacts such as images, music and 3D objects, but traditionally relies on a\nhand-designed evolvable representation of the target domain. The main insight\nin this paper is that a GAN trained on a specific target domain can act as a\ncompact and robust genotype-to-phenotype mapping (i.e. most produced phenotypes\ndo resemble valid domain artifacts). Once such a GAN is trained, the latent\nvector given as input to the GAN's generator network can be put under\nevolutionary control, allowing controllable and high-quality image generation.\nIn this paper, we demonstrate the advantage of this novel approach through a\nuser study in which participants were able to evolve images that strongly\nresemble specific target images.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 22:46:11 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Bontrager", "Philip", ""], ["Lin", "Wending", ""], ["Togelius", "Julian", ""], ["Risi", "Sebastian", ""]]}, {"id": "1801.08485", "submitter": "Soheyl Khalilpourazari", "authors": "Seyed Hamid Reza Pasandideh and Soheyl Khalilpourazari", "title": "Sine Cosine Crow Search Algorithm: A powerful hybrid meta heuristic for\n  global optimization", "comments": "Third International Conference on Artificial Intelligence and Soft\n  Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel hybrid algorithm named Since Cosine Crow Search\nAlgorithm. To propose the SCCSA, two novel algorithms are considered including\nCrow Search Algorithm (CSA) and Since Cosine Algorithm (SCA). The advantages of\nthe two algorithms are considered and utilize to design an efficient hybrid\nalgorithm which can perform significantly better in various benchmark\nfunctions. The combination of concept and operators of the two algorithms\nenable the SCCSA to make an appropriate trade-off between exploration and\nexploitation abilities of the algorithm. To evaluate the performance of the\nproposed SCCSA, seven well-known benchmark functions are utilized. The results\nindicated that the proposed hybrid algorithm is able to provide very\ncompetitive solution comparing to other state-of-the-art meta heuristics.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 17:00:25 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Pasandideh", "Seyed Hamid Reza", ""], ["Khalilpourazari", "Soheyl", ""]]}, {"id": "1801.09335", "submitter": "Jason Kuen", "authors": "Jason Kuen, Xiangfei Kong, Zhe Lin, Gang Wang, Jianxiong Yin, Simon\n  See, Yap-Peng Tan", "title": "Stochastic Downsampling for Cost-Adjustable Inference and Improved\n  Regularization in Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is desirable to train convolutional networks (CNNs) to run more\nefficiently during inference. In many cases however, the computational budget\nthat the system has for inference cannot be known beforehand during training,\nor the inference budget is dependent on the changing real-time resource\navailability. Thus, it is inadequate to train just inference-efficient CNNs,\nwhose inference costs are not adjustable and cannot adapt to varied inference\nbudgets. We propose a novel approach for cost-adjustable inference in CNNs -\nStochastic Downsampling Point (SDPoint). During training, SDPoint applies\nfeature map downsampling to a random point in the layer hierarchy, with a\nrandom downsampling ratio. The different stochastic downsampling configurations\nknown as SDPoint instances (of the same model) have computational costs\ndifferent from each other, while being trained to minimize the same prediction\nloss. Sharing network parameters across different instances provides\nsignificant regularization boost. During inference, one may handpick a SDPoint\ninstance that best fits the inference budget. The effectiveness of SDPoint, as\nboth a cost-adjustable inference approach and a regularizer, is validated\nthrough extensive experiments on image classification.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 01:16:03 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Kuen", "Jason", ""], ["Kong", "Xiangfei", ""], ["Lin", "Zhe", ""], ["Wang", "Gang", ""], ["Yin", "Jianxiong", ""], ["See", "Simon", ""], ["Tan", "Yap-Peng", ""]]}, {"id": "1801.09555", "submitter": "Wentao Zhu", "authors": "Wentao Zhu, Chaochun Liu, Wei Fan, Xiaohui Xie", "title": "DeepLung: Deep 3D Dual Path Nets for Automated Pulmonary Nodule\n  Detection and Classification", "comments": "9 pages, 8 figures, IEEE WACV conference. arXiv admin note:\n  substantial text overlap with arXiv:1709.05538", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a fully automated lung computed tomography (CT)\ncancer diagnosis system, DeepLung. DeepLung consists of two components, nodule\ndetection (identifying the locations of candidate nodules) and classification\n(classifying candidate nodules into benign or malignant). Considering the 3D\nnature of lung CT data and the compactness of dual path networks (DPN), two\ndeep 3D DPN are designed for nodule detection and classification respectively.\nSpecifically, a 3D Faster Regions with Convolutional Neural Net (R-CNN) is\ndesigned for nodule detection with 3D dual path blocks and a U-net-like\nencoder-decoder structure to effectively learn nodule features. For nodule\nclassification, gradient boosting machine (GBM) with 3D dual path network\nfeatures is proposed. The nodule classification subnetwork was validated on a\npublic dataset from LIDC-IDRI, on which it achieved better performance than\nstate-of-the-art approaches and surpassed the performance of experienced\ndoctors based on image modality. Within the DeepLung system, candidate nodules\nare detected first by the nodule detection subnetwork, and nodule diagnosis is\nconducted by the classification subnetwork. Extensive experimental results\ndemonstrate that DeepLung has performance comparable to experienced doctors\nboth for the nodule-level and patient-level diagnosis on the LIDC-IDRI\ndataset.\\footnote{https://github.com/uci-cbcl/DeepLung.git}\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 23:22:00 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Zhu", "Wentao", ""], ["Liu", "Chaochun", ""], ["Fan", "Wei", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1801.09856", "submitter": "Hu Wang", "authors": "Hu Wang", "title": "ReNN: Rule-embedded Neural Networks", "comments": "poster paper in ICPR, 6 pages, 4 figures, and 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The artificial neural network shows powerful ability of inference, but it is\nstill criticized for lack of interpretability and prerequisite needs of big\ndataset. This paper proposes the Rule-embedded Neural Network (ReNN) to\novercome the shortages. ReNN first makes local-based inferences to detect local\npatterns, and then uses rules based on domain knowledge about the local\npatterns to generate rule-modulated map. After that, ReNN makes global-based\ninferences that synthesizes the local patterns and the rule-modulated map. To\nsolve the optimization problem caused by rules, we use a two-stage optimization\nstrategy to train the ReNN model. By introducing rules into ReNN, we can\nstrengthen traditional neural networks with long-term dependencies which are\ndifficult to learn with limited empirical dataset, thus improving inference\naccuracy. The complexity of neural networks can be reduced since long-term\ndependencies are not modeled with neural connections, and thus the amount of\ndata needed to optimize the neural networks can be reduced. Besides, inferences\nfrom ReNN can be analyzed with both local patterns and rules, and thus have\nbetter interpretability. In this paper, ReNN has been validated with a\ntime-series detection problem.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 05:47:01 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2018 06:57:05 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Wang", "Hu", ""]]}, {"id": "1801.10087", "submitter": "Dirk Sudholt", "authors": "Dirk Sudholt", "title": "The Benefits of Population Diversity in Evolutionary Algorithms: A\n  Survey of Rigorous Runtime Analyses", "comments": "This is a preliminary version of a chapter in the upcoming book\n  \"Theory of Randomized Search Heuristics in Discrete Search Spaces\", edited by\n  Benjamin Doerr and Frank Neumann, to be published by Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population diversity is crucial in evolutionary algorithms to enable global\nexploration and to avoid poor performance due to premature convergence. This\nbook chapter reviews runtime analyses that have shown benefits of population\ndiversity, either through explicit diversity mechanisms or through naturally\nemerging diversity. These works show that the benefits of diversity are\nmanifold: diversity is important for global exploration and the ability to find\nseveral global optima. Diversity enhances crossover and enables crossover to be\nmore effective than mutation. Diversity can be crucial in dynamic optimization,\nwhen the problem landscape changes over time. And, finally, it facilitates\nsearch for the whole Pareto front in evolutionary multiobjective optimization.\nThe presented analyses rigorously quantify the performance of evolutionary\nalgorithms in the light of population diversity, laying the foundation for a\nrigorous understanding of how search dynamics are affected by the presence or\nabsence of population diversity and the introduction of diversity mechanisms.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 16:29:19 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Sudholt", "Dirk", ""]]}, {"id": "1801.10472", "submitter": "Siddique Latif", "authors": "Muhammad Atif, Siddique Latif, Rizwan Ahmad, Adnan Khalid Kiani,\n  Junaid Qadir, Adeel Baig, Hisao Ishibuchi and Waseem Abbas", "title": "Soft Computing Techniques for Dependable Cyber-Physical Systems", "comments": "IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-Physical Systems (CPS) allow us to manipulate objects in the physical\nworld by providing a communication bridge between computation and actuation\nelements. In the current scheme of things, this sought-after control is marred\nby limitations inherent in the underlying communication network(s) as well as\nby the uncertainty found in the physical world. These limitations hamper\nfine-grained control of elements that may be separated by large-scale\ndistances. In this regard, soft computing is an emerging paradigm that can help\nto overcome the vulnerabilities, and unreliability of CPS by using techniques\nincluding fuzzy systems, neural network, evolutionary computation,\nprobabilistic reasoning and rough sets. In this paper, we present a\ncomprehensive contemporary review of soft computing techniques for CPS\ndependability modeling, analysis, and improvement. This paper provides an\noverview of CPS applications, explores the foundations of dependability\nengineering, and highlights the potential role of soft computing techniques for\nCPS dependability with various case studies, while identifying common pitfalls\nand future directions. In addition, this paper provides a comprehensive survey\non the use of various soft computing techniques for making CPS dependable.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 15:03:22 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 01:46:05 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Atif", "Muhammad", ""], ["Latif", "Siddique", ""], ["Ahmad", "Rizwan", ""], ["Kiani", "Adnan Khalid", ""], ["Qadir", "Junaid", ""], ["Baig", "Adeel", ""], ["Ishibuchi", "Hisao", ""], ["Abbas", "Waseem", ""]]}, {"id": "1801.10492", "submitter": "Charles Martin", "authors": "Charles P. Martin and Kai Olav Ellefsen and Jim Torresen", "title": "Deep Predictive Models in Interactive Music", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.HC cs.NE eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Musical performance requires prediction to operate instruments, to perform in\ngroups and to improvise. In this paper, we investigate how a number of digital\nmusical instruments (DMIs), including two of our own, have applied predictive\nmachine learning models that assist users by predicting unknown states of\nmusical processes. We characterise these predictions as focussed within a\nmusical instrument, at the level of individual performers, and between members\nof an ensemble. These models can connect to existing frameworks for DMI design\nand have parallels in the cognitive predictions of human musicians.\n  We discuss how recent advances in deep learning highlight the role of\nprediction in DMIs, by allowing data-driven predictive models with a long\nmemory of past states. The systems we review are used to motivate musical\nuse-cases where prediction is a necessary component, and to highlight a number\nof challenges for DMI designers seeking to apply deep predictive models in\ninteractive music systems of the future.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 15:30:32 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 08:48:26 GMT"}, {"version": "v3", "created": "Wed, 19 Dec 2018 22:16:26 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Martin", "Charles P.", ""], ["Ellefsen", "Kai Olav", ""], ["Torresen", "Jim", ""]]}, {"id": "1801.10546", "submitter": "Sheng Xin Zhang", "authors": "Sheng Xin Zhang, Li Ming Zheng, Kit Sang Tang, Shao Yong Zheng, Wing\n  Shing Chan", "title": "Multi-Layer Competitive-Cooperative Framework for Performance\n  Enhancement of Differential Evolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential Evolution (DE) is recognized as one of the most powerful\noptimizers in the evolutionary algorithm (EA) family. Many DE variants were\nproposed in recent years, but significant differences in performances between\nthem are hardly observed. Therefore, this paper suggests a multi-layer\ncompetitive-cooperative (MLCC) framework to facilitate the competition and\ncooperation of multiple DEs, which in turns, achieve a significant performance\nimprovement. Unlike other multi-method strategies which adopt a\nmulti-population based structure, with individuals only evolving in their\ncorresponding subpopulations, MLCC implements a parallel structure with the\nentire population simultaneously monitored by multiple DEs assigned to their\ncorresponding layers. An individual can store, utilize and update its evolution\ninformation in different layers based on an individual preference based layer\nselecting (IPLS) mechanism and a computational resource allocation bias (RAB)\nmechanism. In IPLS, individuals connect to only one favorite layer. While in\nRAB, high-quality solutions are evolved by considering all the layers. Thus DEs\nassociated in the layers work in a competitive and cooperative manner. The\nproposed MLCC framework has been implemented on several highly competitive DEs.\nExperimental studies show that the MLCC variants significantly outperform the\nbaseline DEs as well as several state-of-the-art and up-to-date DEs on CEC\nbenchmark functions.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 16:57:58 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 16:36:02 GMT"}, {"version": "v3", "created": "Mon, 7 Jan 2019 13:06:52 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Zhang", "Sheng Xin", ""], ["Zheng", "Li Ming", ""], ["Tang", "Kit Sang", ""], ["Zheng", "Shao Yong", ""], ["Chan", "Wing Shing", ""]]}]