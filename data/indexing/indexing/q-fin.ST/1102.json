[{"id": "1102.0683", "submitter": "Michel Fliess", "authors": "Michel Fliess (LIX), C\\'edric Join (INRIA Saclay - Ile de France,\n  CRAN), Fr\\'ed\\'eric Hatt", "title": "Volatility made observable at last", "comments": null, "journal-ref": "3\\`emes Journ\\'ees Identification et Mod\\'elisation\n  Exp\\'erimentale, Douai : France (2011)", "doi": null, "report-no": null, "categories": "q-fin.CP cs.CE q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Cartier-Perrin theorem, which was published in 1995 and is expressed in\nthe language of nonstandard analysis, permits, for the first time perhaps, a\nclear-cut mathematical definition of the volatility of a financial asset. It\nyields as a byproduct a new understanding of the means of returns, of the beta\ncoefficient, and of the Sharpe and Treynor ratios. New estimation techniques\nfrom automatic control and signal processing, which were already successfully\napplied in quantitative finance, lead to several computer experiments with some\nquite convincing forecasts.\n", "versions": [{"version": "v1", "created": "Thu, 3 Feb 2011 13:46:49 GMT"}], "update_date": "2011-02-07", "authors_parsed": [["Fliess", "Michel", "", "LIX"], ["Join", "C\u00e9dric", "", "INRIA Saclay - Ile de France,\n  CRAN"], ["Hatt", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1102.1099", "submitter": "Michael Christopher M\\\"unnix", "authors": "Michael C. M\\\"unnix, Rudi Sch\\\"afer", "title": "A Copula Approach on the Dynamics of Statistical Dependencies in the US\n  Stock Market", "comments": null, "journal-ref": null, "doi": "10.1016/j.physa.2011.06.032", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the statistical dependency structure of the S&P 500 constituents\nin the 4-year period from 2007 to 2010 using intraday data from the New York\nStock Exchange's TAQ database. With a copula-based approach, we find that the\nstatistical dependencies are very strong in the tails of the marginal\ndistributions. This tail dependence is higher than in a bivariate Gaussian\ndistribution, which is implied in the calculation of many correlation\ncoefficients. We compare the tail dependence to the market's average\ncorrelation level as a commonly used quantity and disclose an nearly linear\nrelation.\n", "versions": [{"version": "v1", "created": "Sat, 5 Feb 2011 20:55:45 GMT"}, {"version": "v2", "created": "Thu, 3 Mar 2011 17:04:03 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["M\u00fcnnix", "Michael C.", ""], ["Sch\u00e4fer", "Rudi", ""]]}, {"id": "1102.1339", "submitter": "Leonidas Sandoval", "authors": "Leonidas Sandoval Junior and Italo De Paula Franca", "title": "Correlation of financial markets in times of crisis", "comments": "33 pages, 46 figures", "journal-ref": "Physica A 391 (2012) 187--208", "doi": "10.1016/j.physa.2011.07.023", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the eigenvalues and eigenvectors of correlations matrices of some of\nthe main financial market indices in the world, we show that high volatility of\nmarkets is directly linked with strong correlations between them. This means\nthat markets tend to behave as one during great crashes. In order to do so, we\ninvestigate several financial market crises that occurred in the years 1987\n(Black Monday), 1989 (Russian crisis), 2001 (Burst of the dot-com bubble and\nSeptember 11), and 2008 (Subprime Mortgage Crisis), which mark some of the\nlargest downturns of financial markets in the last three decades.\n", "versions": [{"version": "v1", "created": "Mon, 7 Feb 2011 15:40:43 GMT"}, {"version": "v2", "created": "Thu, 10 Mar 2011 11:19:27 GMT"}], "update_date": "2014-08-11", "authors_parsed": [["Junior", "Leonidas Sandoval", ""], ["Franca", "Italo De Paula", ""]]}, {"id": "1102.1624", "submitter": "Iacopo Mastromatteo", "authors": "Iacopo Mastromatteo, Matteo Marsili", "title": "On the criticality of inferred models", "comments": "6 pages, 2 figures, version to appear in JSTAT", "journal-ref": "J. Stat. Mech. (2011) P10012", "doi": "10.1088/1742-5468/2011/10/P10012", "report-no": null, "categories": "physics.data-an cond-mat.dis-nn q-fin.CP q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced inference techniques allow one to reconstruct the pattern of\ninteraction from high dimensional data sets. We focus here on the statistical\nproperties of inferred models and argue that inference procedures are likely to\nyield models which are close to a phase transition. On one side, we show that\nthe reparameterization invariant metrics in the space of probability\ndistributions of these models (the Fisher Information) is directly related to\nthe model's susceptibility. As a result, distinguishable models tend to\naccumulate close to critical points, where the susceptibility diverges in\ninfinite systems. On the other, this region is the one where the estimate of\ninferred parameters is most stable. In order to illustrate these points, we\ndiscuss inference of interacting point processes with application to financial\ndata and show that sensible choices of observation time-scales naturally yield\nmodels which are close to criticality.\n", "versions": [{"version": "v1", "created": "Tue, 8 Feb 2011 15:13:38 GMT"}, {"version": "v2", "created": "Tue, 20 Sep 2011 07:59:58 GMT"}], "update_date": "2013-10-09", "authors_parsed": [["Mastromatteo", "Iacopo", ""], ["Marsili", "Matteo", ""]]}, {"id": "1102.2138", "submitter": "Wei-Xing Zhou", "authors": "Kun Guo (CAS), Wei-Xing Zhou (ECUST), Si-Wei Cheng (CAS), Didier\n  Sornette (ETH Zurich)", "title": "The US stock market leads the Federal funds rate and Treasury bond\n  yields", "comments": "12 pages, 7 figures, 1 table", "journal-ref": "PLoS ONE 6 (8), e22794 (2011)", "doi": "10.1371/journal.pone.0022794", "report-no": null, "categories": "q-fin.ST physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a recently introduced method to quantify the time varying lead-lag\ndependencies between pairs of economic time series (the thermal optimal path\nmethod), we test two fundamental tenets of the theory of fixed income: (i) the\nstock market variations and the yield changes should be anti-correlated; (ii)\nthe change in central bank rates, as a proxy of the monetary policy of the\ncentral bank, should be a predictor of the future stock market direction. Using\nboth monthly and weekly data, we found very similar lead-lag dependence between\nthe S&P500 stock market index and the yields of bonds inside two groups: bond\nyields of short-term maturities (Federal funds rate (FFR), 3M, 6M, 1Y, 2Y, and\n3Y) and bond yields of long-term maturities (5Y, 7Y, 10Y, and 20Y). In all\ncases, we observe the opposite of (i) and (ii). First, the stock market and\nyields move in the same direction. Second, the stock market leads the yields,\nincluding and especially the FFR. Moreover, we find that the short-term yields\nin the first group lead the long-term yields in the second group before the\nfinancial crisis that started mid-2007 and the inverse relationship holds\nafterwards. These results suggest that the Federal Reserve is increasingly\nmindful of the stock market behavior, seen at key to the recovery and health of\nthe economy. Long-term investors seem also to have been more reactive and\nmindful of the signals provided by the financial stock markets than the Federal\nReserve itself after the start of the financial crisis. The lead of the S&P500\nstock market index over the bond yields of all maturities is confirmed by the\ntraditional lagged cross-correlation analysis.\n", "versions": [{"version": "v1", "created": "Thu, 10 Feb 2011 15:08:26 GMT"}], "update_date": "2011-09-26", "authors_parsed": [["Guo", "Kun", "", "CAS"], ["Zhou", "Wei-Xing", "", "ECUST"], ["Cheng", "Si-Wei", "", "CAS"], ["Sornette", "Didier", "", "ETH Zurich"]]}, {"id": "1102.2240", "submitter": "Duan Wang", "authors": "Duan Wang, Boris Podobnik, Davor Horvati\\'c, and H.Eugene Stanley", "title": "Quantifying and Modeling Long-Range Cross-Correlations in Multiple Time\n  Series with Applications to World Stock Indices", "comments": "Accepted by Phys. Rev. E", "journal-ref": null, "doi": "10.1103/PhysRevE.83.046121", "report-no": null, "categories": "q-fin.ST physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a modified time lag random matrix theory in order to study time\nlag cross-correlations in multiple time series. We apply the method to 48 world\nindices, one for each of 48 different countries. We find long-range power-law\ncross-correlations in the absolute values of returns that quantify risk, and\nfind that they decay much more slowly than cross-correlations between the\nreturns. The magnitude of the cross-correlations constitute \"bad news\" for\ninternational investment managers who may believe that risk is reduced by\ndiversifying across countries. We find that when a market shock is transmitted\naround the world, the risk decays very slowly. We explain these time lag\ncross-correlations by introducing a global factor model (GFM) in which all\nindex returns fluctuate in response to a single global factor. For each pair of\nindividual time series of returns, the cross-correlations between returns (or\nmagnitudes) can be modeled with the auto-correlations of the global factor\nreturns (or magnitudes). We estimate the global factor using principal\ncomponent analysis, which minimizes the variance of the residuals after\nremoving the global trend. Using random matrix theory, a significant fraction\nof the world index cross-correlations can be explained by the global factor,\nwhich supports the utility of the GFM. We demonstrate applications of the GFM\nin forecasting risks at the world level, and in finding uncorrelated individual\nindices. We find 10 indices are practically uncorrelated with the global factor\nand with the remainder of the world indices, which is relevant information for\nworld managers in reducing their portfolio risk. Finally, we argue that this\ngeneral method can be applied to a wide range of phenomena in which time series\nare measured, ranging from seismology and physiology to atmospheric geophysics.\n", "versions": [{"version": "v1", "created": "Thu, 10 Feb 2011 21:23:18 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Wang", "Duan", ""], ["Podobnik", "Boris", ""], ["Horvati\u0107", "Davor", ""], ["Stanley", "H. Eugene", ""]]}, {"id": "1102.2412", "submitter": "Zhuowei Zhou", "authors": "T. R. Hurd and Zhuowei Zhou", "title": "Statistical Inference for Time-changed Brownian Motion Credit Risk\n  Models", "comments": "21 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider structural credit modeling in the important special case where\nthe log-leverage ratio of the firm is a time-changed Brownian motion (TCBM)\nwith the time-change taken to be an independent increasing process. Following\nthe approach of Black and Cox, one defines the time of default to be the first\npassage time for the log-leverage ratio to cross the level zero. Rather than\nadopt the classical notion of first passage, with its associated numerical\nchallenges, we accept an alternative notion applicable for TCBMs called \"first\npassage of the second kind\". We demonstrate how statistical inference can be\nefficiently implemented in this new class of models. This allows us to compare\nthe performance of two versions of TCBMs, the variance gamma (VG) model and the\nexponential jump model (EXP), to the Black-Cox model. When applied to a 4.5\nyear long data set of weekly credit default swap (CDS) quotes for Ford Motor\nCo, the conclusion is that the two TCBM models, with essentially one extra\nparameter, can significantly outperform the classic Black-Cox model.\n", "versions": [{"version": "v1", "created": "Fri, 11 Feb 2011 18:53:53 GMT"}], "update_date": "2011-02-14", "authors_parsed": [["Hurd", "T. R.", ""], ["Zhou", "Zhuowei", ""]]}, {"id": "1102.2620", "submitter": "Yaneer Bar-Yam", "authors": "Dion Harmon, Marcus A. M. de Aguiar, David D. Chinellato, Dan Braha,\n  Irving R. Epstein and Yaneer Bar-Yam", "title": "Predicting economic market crises using measures of collective panic", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": "NECSI Report 2010-08-01", "categories": "q-fin.ST cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting panic is of critical importance in many areas of human and animal\nbehavior, notably in the context of economics. The recent financial crisis is a\ncase in point. Panic may be due to a specific external threat, or\nself-generated nervousness. Here we show that the recent economic crisis and\nearlier large single-day panics were preceded by extended periods of high\nlevels of market mimicry --- direct evidence of uncertainty and nervousness,\nand of the comparatively weak influence of external news. High levels of\nmimicry can be a quite general indicator of the potential for self-organized\ncrises.\n", "versions": [{"version": "v1", "created": "Sun, 13 Feb 2011 17:50:11 GMT"}], "update_date": "2011-02-15", "authors_parsed": [["Harmon", "Dion", ""], ["de Aguiar", "Marcus A. M.", ""], ["Chinellato", "David D.", ""], ["Braha", "Dan", ""], ["Epstein", "Irving R.", ""], ["Bar-Yam", "Yaneer", ""]]}, {"id": "1102.3702", "submitter": "Anouar Ben Mabrouk", "authors": "Olfa Zaafrane and Anouar Ben Mabrouk", "title": "A dynamic hybrid model based on wavelets and fuzzy regression for time\n  series estimation", "comments": "15 pages, 15 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, a fuzzy logic based method is combined with wavelet\ndecomposition to develop a step-by-step dynamic hybrid model for the estimation\nof financial time series. Empirical tests on fuzzy regression, wavelet\ndecomposition as well as the new hybrid model are conducted on the well known\n$SP500$ index financial time series. The empirical tests show an efficiency of\nthe hybrid model.\n", "versions": [{"version": "v1", "created": "Thu, 17 Feb 2011 21:11:06 GMT"}], "update_date": "2011-02-21", "authors_parsed": [["Zaafrane", "Olfa", ""], ["Mabrouk", "Anouar Ben", ""]]}, {"id": "1102.3712", "submitter": "Rafal Weron", "authors": "Joanna Janczura, Rafal Weron", "title": "Black swans or dragon kings? A simple test for deviations from the power\n  law", "comments": null, "journal-ref": null, "doi": "10.1140/epjst/e2012-01563-9", "report-no": null, "categories": "q-fin.ST physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a simple test for deviations from power law tails, which is based\non the asymptotic properties of the empirical distribution function. We use\nthis test to answer the question whether great natural disasters, financial\ncrashes or electricity price spikes should be classified as dragon kings or\n'only' as black swans.\n", "versions": [{"version": "v1", "created": "Thu, 17 Feb 2011 21:58:06 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Janczura", "Joanna", ""], ["Weron", "Rafal", ""]]}, {"id": "1102.4076", "submitter": "Giacomo Livan M. Sc.", "authors": "G. Livan, S. Alfarano, E. Scalas", "title": "The fine structure of spectral properties for random correlation\n  matrices: an application to financial markets", "comments": "21 pages, 10 figures", "journal-ref": "Phys. Rev. E 84, 016113 (2011)", "doi": "10.1103/PhysRevE.84.016113", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study some properties of eigenvalue spectra of financial correlation\nmatrices. In particular, we investigate the nature of the large eigenvalue\nbulks which are observed empirically, and which have often been regarded as a\nconsequence of the supposedly large amount of noise contained in financial\ndata. We challenge this common knowledge by acting on the empirical correlation\nmatrices of two data sets with a filtering procedure which highlights some of\nthe cluster structure they contain, and we analyze the consequences of such\nfiltering on eigenvalue spectra. We show that empirically observed eigenvalue\nbulks emerge as superpositions of smaller structures, which in turn emerge as a\nconsequence of cross-correlations between stocks. We interpret and corroborate\nthese findings in terms of factor models, and and we compare empirical spectra\nto those predicted by Random Matrix Theory for such models.\n", "versions": [{"version": "v1", "created": "Sun, 20 Feb 2011 15:05:00 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Livan", "G.", ""], ["Alfarano", "S.", ""], ["Scalas", "E.", ""]]}, {"id": "1102.4819", "submitter": "S\\'ilvio Duarte Queir\\'os M.", "authors": "Silvio M. Duarte Queiros, Evaldo M. F. Curado, Fernando D. Nobre", "title": "Minding impacting events in a model of stochastic variance", "comments": "18 pages, 5 figures, 1 table. To published in PLoS one", "journal-ref": "PLoS ONE 6(3): e18149 (2011)", "doi": "10.1371/journal.pone.0018149", "report-no": null, "categories": "q-fin.ST cond-mat.stat-mech physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a generalisation of the well-known ARCH process, widely used for\ngenerating uncorrelated stochastic time series with long-term non-Gaussian\ndistributions and long-lasting correlations in the (instantaneous) standard\ndeviation exhibiting a clustering profile. Specifically, inspired by the fact\nthat in a variety of systems impacting events are hardly forgot, we split the\nprocess into two different regimes: a first one for regular periods where the\naverage volatility of the fluctuations within a certain period of time is below\na certain threshold and another one when the local standard deviation\noutnumbers it. In the former situation we use standard rules for\nheteroscedastic processes whereas in the latter case the system starts\nrecalling past values that surpassed the threshold. Our results show that for\nappropriate parameter values the model is able to provide fat tailed\nprobability density functions and strong persistence of the instantaneous\nvariance characterised by large values of the Hurst exponent is greater than\n0.8, which are ubiquitous features in complex systems.\n", "versions": [{"version": "v1", "created": "Wed, 23 Feb 2011 19:02:02 GMT"}, {"version": "v2", "created": "Thu, 24 Feb 2011 18:42:48 GMT"}], "update_date": "2011-04-12", "authors_parsed": [["Queiros", "Silvio M. Duarte", ""], ["Curado", "Evaldo M. F.", ""], ["Nobre", "Fernando D.", ""]]}, {"id": "1102.5431", "submitter": "Mohamed Boutahar", "authors": "Mohamed Boutahar (GREQAM)", "title": "Testing for change in mean of heteroskedastic time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a Lagrange Multiplier-type test (LM) to detect\nchange in the mean of time series with heteroskedasticity of unknown form. We\nderive the limiting distribution under the null, and prove the consistency of\nthe test against the alternative of either an abrupt or smooth changes in the\nmean. We perform also some Monte Carlo simulations to analyze the size\ndistortion and the power of the proposed test. We conclude that for moderate\nsample size, the test has a good performance. We finally carry out an empirical\napplication using the daily closing level of the S&P 500 stock index, in order\nto illustrate the usefulness of the proposed test.\n", "versions": [{"version": "v1", "created": "Sat, 26 Feb 2011 17:55:44 GMT"}], "update_date": "2011-03-02", "authors_parsed": [["Boutahar", "Mohamed", "", "GREQAM"]]}, {"id": "1102.5457", "submitter": "Austin Gerig", "authors": "J. Doyne Farmer, Austin Gerig, Fabrizio Lillo, and Henri Waelbroeck", "title": "How efficiency shapes market impact", "comments": "34 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a theory for the market impact of large trading orders, which we\ncall metaorders because they are typically split into small pieces and executed\nincrementally. Market impact is empirically observed to be a concave function\nof metaorder size, i.e., the impact per share of large metaorders is smaller\nthan that of small metaorders. We formulate a stylized model of an algorithmic\nexecution service and derive a fair pricing condition, which says that the\naverage transaction price of the metaorder is equal to the price after trading\nis completed. We show that at equilibrium the distribution of trading volume\nadjusts to reflect information, and dictates the shape of the impact function.\nThe resulting theory makes empirically testable predictions for the functional\nform of both the temporary and permanent components of market impact. Based on\nthe commonly observed asymptotic distribution for the volume of large trades,\nit says that market impact should increase asymptotically roughly as the square\nroot of metaorder size, with average permanent impact relaxing to about two\nthirds of peak impact.\n", "versions": [{"version": "v1", "created": "Sat, 26 Feb 2011 22:31:37 GMT"}, {"version": "v2", "created": "Sun, 1 Jan 2012 03:02:00 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2013 17:18:32 GMT"}, {"version": "v4", "created": "Thu, 26 Sep 2013 20:50:12 GMT"}], "update_date": "2013-09-30", "authors_parsed": [["Farmer", "J. Doyne", ""], ["Gerig", "Austin", ""], ["Lillo", "Fabrizio", ""], ["Waelbroeck", "Henri", ""]]}]