[{"id": "1803.00261", "submitter": "Andreas M\\\"uhlbacher", "authors": "Andreas M\\\"uhlbacher and Thomas Guhr", "title": "Credit Risk Meets Random Matrices: Coping with Non-Stationary Asset\n  Correlations", "comments": "Review of a new random matrix approach to credit risk", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review recent progress in modeling credit risk for correlated assets. We\nstart from the Merton model which default events and losses are derived from\nthe asset values at maturity. To estimate the time development of the asset\nvalues, the stock prices are used whose correlations have a strong impact on\nthe loss distribution, particularly on its tails. These correlations are\nnon-stationary which also influences the tails. We account for the asset\nfluctuations by averaging over an ensemble of random matrices that models the\ntruly existing set of measured correlation matrices. As a most welcome side\neffect, this approach drastically reduces the parameter dependence of the loss\ndistribution, allowing us to obtain very explicit results which show\nquantitatively that the heavy tails prevail over diversification benefits even\nfor small correlations. We calibrate our random matrix model with market data\nand show how it is capable of grasping different market situations.\nFurthermore, we present numerical simulations for concurrent portfolio risks,\ni.e., for the joint probability densities of losses for two portfolios. For the\nconvenience of the reader, we give an introduction to the Wishart random matrix\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 09:11:41 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["M\u00fchlbacher", "Andreas", ""], ["Guhr", "Thomas", ""]]}, {"id": "1803.00374", "submitter": "Matteo Farn\\`e Dr.", "authors": "Matteo Farn\\'e and Angela Montanari", "title": "A bootstrap test to detect prominent Granger-causalities across\n  frequencies", "comments": null, "journal-ref": null, "doi": "10.1007/s10614-021-10112-x", "report-no": null, "categories": "q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Granger-causality in the frequency domain is an emerging tool to analyze the\ncausal relationship between two time series. We propose a bootstrap test on\nunconditional and conditional Granger-causality spectra, as well as on their\ndifference, to catch particularly prominent causality cycles in relative terms.\nIn particular, we consider a stochastic process derived applying independently\nthe stationary bootstrap to the original series. Our null hypothesis is that\neach causality or causality difference is equal to the median across\nfrequencies computed on that process. In this way, we are able to disambiguate\ncausalities which depart significantly from the median one obtained ignoring\nthe causality structure. Our test shows power one as the process tends to\nnon-stationarity, thus being more conservative than parametric alternatives. As\nan example, we infer about the relationship between money stock and GDP in the\nEuro Area via our approach, considering inflation, unemployment and interest\nrates as conditioning variables. We point out that during the period 1999-2017\nthe money stock aggregate M1 had a significant impact on economic output at all\nfrequencies, while the opposite relationship is significant only at high\nfrequencies.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 14:17:07 GMT"}, {"version": "v2", "created": "Sat, 20 Oct 2018 21:35:59 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Farn\u00e9", "Matteo", ""], ["Montanari", "Angela", ""]]}, {"id": "1803.01389", "submitter": "Zhongzhi Lawrence He", "authors": "Zhongzhi Lawrence He", "title": "Comparing Asset Pricing Models: Distance-based Metrics and Bayesian\n  Interpretations", "comments": "50 pages, 1 figure, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In light of the power problems of statistical tests and undisciplined use of\nalpha-based statistics to compare models, this paper proposes a unified set of\ndistance-based performance metrics, derived as the square root of the sum of\nsquared alphas and squared standard errors. The Bayesian investor views model\nperformance as the shortest distance between his dogmatic belief (model-implied\ndistribution) and complete skepticism (data-based distribution) in the model,\nand favors models that produce low dispersion of alphas with high explanatory\npower. In this view, the momentum factor is a crucial addition to the\nfive-factor model of Fama and French (2015), alleviating his prior concern of\nmodel mispricing by -8% to 8% per annum. The distance metrics complement the\nfrequentist p-values with a diagnostic tool to guard against bad models.\n", "versions": [{"version": "v1", "created": "Sun, 4 Mar 2018 17:31:58 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["He", "Zhongzhi Lawrence", ""]]}, {"id": "1803.02019", "submitter": "Fei Ren", "authors": "Ming-Yuan Yang, Sai-Ping Li, Li-Xin Zhong, Fei Ren", "title": "Modelling stock correlations with expected returns from investors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stock correlations is crucial to asset pricing, investor decision-making, and\nfinancial risk regulations. However, microscopic explanation based on\nagent-based modeling is still lacking. We here propose a model derived from\nminority game for modeling stock correlations, in which an agent's expected\nreturn for one stock is influenced by the historical return of the other stock.\nEach agent makes a decision based on his expected return with reference to\ninformation dissemination and the historical return of the stock. We find that\nthe returns of the stocks are positively (negatively) correlated when agents'\nexpected returns for one stock are positively (negatively) correlated with the\nhistorical return of the other. We provide both numerical simulations and\nanalytical studies and give explanations to stock correlations for cases with\nagents having either homogeneous or heterogeneous expected returns. The result\nstill holds when other factors such as holding decisions and external events\nare included which broadens the practicability of the model.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 04:56:00 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 04:49:35 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Yang", "Ming-Yuan", ""], ["Li", "Sai-Ping", ""], ["Zhong", "Li-Xin", ""], ["Ren", "Fei", ""]]}, {"id": "1803.02962", "submitter": "Yong Jiang", "authors": "Yong Jiang, Zhongbao Zhou", "title": "Does the time horizon of the return predictive effect of investor\n  sentiment vary with stock characteristics? A Granger causality analysis in\n  the frequency domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavioral theories posit that investor sentiment exhibits predictive power\nfor stock returns, whereas there is little study have investigated the\nrelationship between the time horizon of the predictive effect of investor\nsentiment and the firm characteristics. To this end, by using a Granger\ncausality analysis in the frequency domain proposed by Lemmens et al. (2008),\nthis paper examine whether the time horizon of the predictive effect of\ninvestor sentiment on the U.S. returns of stocks vary with different firm\ncharacteristics (e.g., firm size (Size), book-to-market equity (B/M) rate,\noperating profitability (OP) and investment (Inv)). The empirical results\nindicate that investor sentiment has a long-term (more than 12 months) or\nshort-term (less than 12 months) predictive effect on stock returns with\ndifferent firm characteristics. Specifically, the investor sentiment has strong\npredictability in the stock returns for smaller Size stocks, lower B/M stocks\nand lower OP stocks, both in the short term and long term, but only has a\nshort-term predictability for higher quantile ones. The investor sentiment\nmerely has predictability for the returns of smaller Inv stocks in the short\nterm, but has a strong short-term and long-term predictability for larger Inv\nstocks. These results have important implications for the investors for the\nplanning of the short and the long run stock investment strategy.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 04:19:54 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Jiang", "Yong", ""], ["Zhou", "Zhongbao", ""]]}, {"id": "1803.03573", "submitter": "Nestor Parolya Jun.-Prof. Dr.", "authors": "David Bauder, Taras Bodnar, Nestor Parolya, Wolfgang Schmid", "title": "Bayesian mean-variance analysis: Optimal portfolio selection under\n  parameter uncertainty", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper solves the problem of optimal portfolio choice when the parameters\nof the asset returns distribution, like the mean vector and the covariance\nmatrix are unknown and have to be estimated by using historical data of the\nasset returns. The new approach employs the Bayesian posterior predictive\ndistribution which is the distribution of the future realization of the asset\nreturns given the observable sample. The parameters of the posterior predictive\ndistributions are functions of the observed data values and, consequently, the\nsolution of the optimization problem is expressed in terms of data only and\ndoes not depend on unknown quantities. In contrast, the optimization problem of\nthe traditional approach is based on unknown quantities which are estimated in\nthe second step leading to a suboptimal solution. We also derive a very useful\nstochastic representation of the posterior predictive distribution whose\napplication leads not only to the solution of the considered optimization\nproblem, but provides the posterior predictive distribution of the optimal\nportfolio return used to construct a prediction interval. A Bayesian efficient\nfrontier, a set of optimal portfolios obtained by employing the posterior\npredictive distribution, is constructed as well. Theoretically and using real\ndata we show that the Bayesian efficient frontier outperforms the sample\nefficient frontier, a common estimator of the set of optimal portfolios known\nto be overoptimistic.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 15:46:39 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Bauder", "David", ""], ["Bodnar", "Taras", ""], ["Parolya", "Nestor", ""], ["Schmid", "Wolfgang", ""]]}, {"id": "1803.04094", "submitter": "Sebastian Jaimungal", "authors": "Philippe Casgrain, Sebastian Jaimungal", "title": "Mean Field Games with Partial Information for Algorithmic Trading", "comments": "34 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF math.PR q-fin.ST q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial markets are often driven by latent factors which traders cannot\nobserve. Here, we address an algorithmic trading problem with collections of\nheterogeneous agents who aim to perform optimal execution or statistical\narbitrage, where all agents filter the latent states of the world, and their\ntrading actions have permanent and temporary price impact. This leads to a\nlarge stochastic game with heterogeneous agents. We solve the stochastic game\nby investigating its mean-field game (MFG) limit, with sub-populations of\nheterogeneous agents, and, using a convex analysis approach, we show that the\nsolution is characterized by a vector-valued forward-backward stochastic\ndifferential equation (FBSDE). We demonstrate that the FBSDE admits a unique\nsolution, obtain it in closed-form, and characterize the optimal behaviour of\nthe agents in the MFG equilibrium. Moreover, we prove the MFG equilibrium\nprovides an $\\epsilon$-Nash equilibrium for the finite player game. We conclude\nby illustrating the behaviour of agents using the optimal MFG strategy through\nsimulated examples.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 02:38:09 GMT"}, {"version": "v2", "created": "Sun, 31 Mar 2019 13:34:28 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Casgrain", "Philippe", ""], ["Jaimungal", "Sebastian", ""]]}, {"id": "1803.04591", "submitter": "Atul Deshpande", "authors": "Atul Deshpande and B. Ross Barmish", "title": "A Generalization of the Robust Positive Expectation Theorem for Stock\n  Trading via Feedback Control", "comments": "accepted at the European Control Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The starting point of this paper is the so-called Robust Positive Expectation\n(RPE) Theorem, a result which appears in literature in the context of\nSimultaneous Long-Short stock trading. This theorem states that using a\ncombination of two specially-constructed linear feedback trading controllers,\none long and one short, the expected value of the resulting gain-loss function\nis guaranteed to be robustly positive with respect to a large class of\nstochastic processes for the stock price. The main result of this paper is a\ngeneralization of this theorem. Whereas previous work applies to a single\nstock, in this paper, we consider a pair of stocks. To this end, we make two\nassumptions on their expected returns. The first assumption involves price\ncorrelation between the two stocks and the second involves a bounded non-zero\nmomentum condition. With known uncertainty bounds on the parameters associated\nwith these assumptions, our new version of the RPE Theorem provides necessary\nand sufficient conditions on the positive feedback parameter K of the\ncontroller under which robust positive expectation is assured. We also\ndemonstrate that our result generalizes the one existing for the single-stock\ncase. Finally, it is noted that our results also can be interpreted in the\ncontext of pairs trading.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 01:39:51 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Deshpande", "Atul", ""], ["Barmish", "B. Ross", ""]]}, {"id": "1803.06223", "submitter": "Xin-Jian Xu", "authors": "Xin-Jian Xu, Kuo Wang, Liucun Zhu, Li-Jie Zhang", "title": "Efficient construction of threshold networks of stock markets", "comments": "latex, 16 pages, 6 figures", "journal-ref": "Physica A 509 (2018) 1080-1086", "doi": "10.1016/j.physa.2018.06.083", "report-no": null, "categories": "q-fin.ST physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the threshold network is one of the most used tools to characterize\nthe underlying structure of a stock market, the identification of the optimal\nthreshold to construct a reliable stock network remains challenging. In this\npaper, the concept of dynamic consistence between the threshold network and the\nstock market is proposed. The optimal threshold is estimated by maximizing the\nconsistence function. The application of this procedure to stocks belonging to\nStandard \\& Pool's 500 Index from January 2006 to December 2011 yields the\nthreshold value 0.28. In analyzing topological characteristics of the generated\nnetwork, three globally financial crises can be distinguished well from the\nevolutionary perspective.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 05:55:48 GMT"}, {"version": "v2", "created": "Fri, 24 Aug 2018 01:22:40 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Xu", "Xin-Jian", ""], ["Wang", "Kuo", ""], ["Zhu", "Liucun", ""], ["Zhang", "Li-Jie", ""]]}, {"id": "1803.06386", "submitter": "Akbar Siami Namin", "authors": "Sima Siami-Namini and Akbar Siami Namin", "title": "Forecasting Economics and Financial Time Series: ARIMA vs. LSTM", "comments": "19 pages, 2 figures, 1 diagram, 2 listings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Forecasting time series data is an important subject in economics, business,\nand finance. Traditionally, there are several techniques to effectively\nforecast the next lag of time series data such as univariate Autoregressive\n(AR), univariate Moving Average (MA), Simple Exponential Smoothing (SES), and\nmore notably Autoregressive Integrated Moving Average (ARIMA) with its many\nvariations. In particular, ARIMA model has demonstrated its outperformance in\nprecision and accuracy of predicting the next lags of time series. With the\nrecent advancement in computational power of computers and more importantly\ndeveloping more advanced machine learning algorithms and approaches such as\ndeep learning, new algorithms are developed to forecast time series data. The\nresearch question investigated in this article is that whether and how the\nnewly developed deep learning-based algorithms for forecasting time series\ndata, such as \"Long Short-Term Memory (LSTM)\", are superior to the traditional\nalgorithms. The empirical studies conducted and reported in this article show\nthat deep learning-based algorithms such as LSTM outperform traditional-based\nalgorithms such as ARIMA model. More specifically, the average reduction in\nerror rates obtained by LSTM is between 84 - 87 percent when compared to ARIMA\nindicating the superiority of LSTM to ARIMA. Furthermore, it was noticed that\nthe number of training times, known as \"epoch\" in deep learning, has no effect\non the performance of the trained forecast model and it exhibits a truly random\nbehavior.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 20:01:48 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Siami-Namini", "Sima", ""], ["Namin", "Akbar Siami", ""]]}, {"id": "1803.06653", "submitter": "Jo\\~ao Carmo", "authors": "Jo\\~ao Pedro Rodrigues do Carmo", "title": "Modeling stock markets through the reconstruction of market processes", "comments": "49 pages, dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  There are two possible ways of interpreting the seemingly stochastic nature\nof financial markets: the Efficient Market Hypothesis (EMH) and a set of\nstylized facts that drive the behavior of the markets. We show evidence for\nsome of the stylized facts such as memory-like phenomena in price volatility in\nthe short term, a power-law behavior and non-linear dependencies on the\nreturns.\n  Given this, we construct a model of the market using Markov chains. Then, we\ndevelop an algorithm that can be generalized for any N-symbol alphabet and\nK-length Markov chain. Using this tool, we are able to show that it's, at\nleast, always better than a completely random model such as a Random Walk. The\ncode is written in MATLAB and maintained in GitHub.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 12:43:24 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Carmo", "Jo\u00e3o Pedro Rodrigues do", ""]]}, {"id": "1803.06738", "submitter": "Kenichiro McAlinn", "authors": "Daniele Bianchi and Kenichiro McAlinn", "title": "Large-Scale Dynamic Predictive Regressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME econ.EM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel \"decouple-recouple\" dynamic predictive strategy and\ncontribute to the literature on forecasting and economic decision making in a\ndata-rich environment. Under this framework, clusters of predictors generate\ndifferent latent states in the form of predictive densities that are later\nsynthesized within an implied time-varying latent factor model. As a result,\nthe latent inter-dependencies across predictive densities and biases are\nsequentially learned and corrected. Unlike sparse modeling and variable\nselection procedures, we do not assume a priori that there is a given subset of\nactive predictors, which characterize the predictive density of a quantity of\ninterest. We test our procedure by investigating the predictive content of a\nlarge set of financial ratios and macroeconomic variables on both the equity\npremium across different industries and the inflation rate in the U.S., two\ncontexts of topical interest in finance and macroeconomics. We find that our\npredictive synthesis framework generates both statistically and economically\nsignificant out-of-sample benefits while maintaining interpretability of the\nforecasting variables. In addition, the main empirical results highlight that\nour proposed framework outperforms both LASSO-type shrinkage regressions,\nfactor based dimension reduction, sequential variable selection, and\nequal-weighted linear pooling methodologies.\n", "versions": [{"version": "v1", "created": "Sun, 18 Mar 2018 21:01:01 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Bianchi", "Daniele", ""], ["McAlinn", "Kenichiro", ""]]}, {"id": "1803.06917", "submitter": "Justin Sirignano", "authors": "Justin Sirignano and Rama Cont", "title": "Universal features of price formation in financial markets: perspectives\n  from Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a large-scale Deep Learning approach applied to a high-frequency\ndatabase containing billions of electronic market quotes and transactions for\nUS equities, we uncover nonparametric evidence for the existence of a universal\nand stationary price formation mechanism relating the dynamics of supply and\ndemand for a stock, as revealed through the order book, to subsequent\nvariations in its market price. We assess the model by testing its\nout-of-sample predictions for the direction of price moves given the history of\nprice and order flow, across a wide range of stocks and time periods. The\nuniversal price formation model is shown to exhibit a remarkably stable\nout-of-sample prediction accuracy across time, for a wide range of stocks from\ndifferent sectors. Interestingly, these results also hold for stocks which are\nnot part of the training sample, showing that the relations captured by the\nmodel are universal and not asset-specific.\n  The universal model --- trained on data from all stocks --- outperforms, in\nterms of out-of-sample prediction accuracy, asset-specific linear and nonlinear\nmodels trained on time series of any given stock, showing that the universal\nnature of price formation weighs in favour of pooling together financial data\nfrom various stocks, rather than designing asset- or sector-specific models as\ncommonly done. Standard data normalizations based on volatility, price level or\naverage spread, or partitioning the training data into sectors or categories\nsuch as large/small tick stocks, do not improve training results. On the other\nhand, inclusion of price and order flow history over many past observations is\nshown to improve forecasting performance, showing evidence of path-dependence\nin price dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 13:46:37 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Sirignano", "Justin", ""], ["Cont", "Rama", ""]]}, {"id": "1803.07152", "submitter": "G\\'abor Petneh\\'azi", "authors": "G\\'abor Petneh\\'azi and J\\'ozsef G\\'all", "title": "Exploring the predictability of range-based volatility estimators using\n  RNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the predictability of several range-based stock volatility\nestimators, and compare them to the standard close-to-close estimator which is\nmost commonly acknowledged as the volatility. The patterns of volatility\nchanges are analyzed using LSTM recurrent neural networks, which are a state of\nthe art method of sequence learning. We implement the analysis on all current\nconstituents of the Dow Jones Industrial Average index, and report averaged\nevaluation results. We find that changes in the values of range-based\nestimators are more predictable than that of the estimator using daily closing\nvalues only.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 20:31:09 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Petneh\u00e1zi", "G\u00e1bor", ""], ["G\u00e1ll", "J\u00f3zsef", ""]]}, {"id": "1803.08390", "submitter": "Kevin Primicerio", "authors": "Kevin Primicerio, Damien Challet", "title": "Large large-trader activity weakens the long memory of limit order\n  markets", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using more than 6.7 billions of trades, we explore how the tick-by-tick\ndynamics of limit order books depends on the aggregate actions of large\ninvestment funds on a much larger (quarterly) timescale. In particular, we find\nthat the well-established long memory of market order signs is markedly weaker\nwhen large investment funds trade either in a directional way and even weaker\nwhen their aggregate participation ratio is large. Conversely, we investigate\nto what respect a weaker memory of market order signs predicts that an asset is\nbeing actively traded by large funds. Theoretical arguments suggest two simple\nmechanisms that contribute to the observed effect: a larger number of active\nmeta-orders and a modification of the distribution of size of meta-orders.\nEmpirical evidence suggests that the number of active meta-orders is the most\nimportant contributor to the loss of market order sign memory.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 15:02:11 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Primicerio", "Kevin", ""], ["Challet", "Damien", ""]]}, {"id": "1803.08405", "submitter": "Stjepan Begu\\v{s}i\\'c", "authors": "Stjepan Begu\\v{s}i\\'c, Zvonko Kostanj\\v{c}ar, H. Eugene Stanley, and\n  Boris Podobnik", "title": "Scaling properties of extreme price fluctuations in Bitcoin markets", "comments": null, "journal-ref": null, "doi": "10.1016/j.physa.2018.06.131", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detection of power-law behavior and studies of scaling exponents uncover the\ncharacteristics of complexity in many real world phenomena. The complexity of\nfinancial markets has always presented challenging issues and provided\ninteresting findings, such as the inverse cubic law in the tails of stock price\nfluctuation distributions. Motivated by the rise of novel digital assets based\non blockchain technology, we study the distributions of cryptocurrency price\nfluctuations. We consider Bitcoin returns over various time intervals and from\nmultiple digital exchanges, in order to investigate the existence of universal\nscaling behavior in the tails, and ascertain whether the scaling exponent\nsupports the presence of a finite second moment. We provide empirical evidence\non slowly decaying tails in the distributions of returns over multiple time\nintervals and different exchanges, corresponding to a power-law. We estimate\nthe scaling exponent and find an asymptotic power-law behavior with 2 <\n{\\alpha} < 2.5 suggesting that Bitcoin returns, in addition to being more\nvolatile, also exhibit heavier tails than stocks, which are known to be around\n3. Our results also imply the existence of a finite second moment, thus\nproviding a fundamental basis for the usage of standard financial theories and\ncovariance-based techniques in risk management and portfolio optimization\nscenarios.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 15:27:28 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Begu\u0161i\u0107", "Stjepan", ""], ["Kostanj\u010dar", "Zvonko", ""], ["Stanley", "H. Eugene", ""], ["Podobnik", "Boris", ""]]}, {"id": "1803.09422", "submitter": "Wei-Xing Zhou", "authors": "Yu-Lei Wan (ECUST), Gang-Jin Wang (HNU), Zhi-Qiang Jiang (ECUST),\n  Wen-Jie Xie (ECUST), Wei-Xing Zhou (ECUST)", "title": "The cooling-off effect of price limits in the Chinese stock markets", "comments": null, "journal-ref": "Physica A 505, 153-163 (2018)", "doi": "10.1016/j.physa.2018.03.066", "report-no": null, "categories": "q-fin.ST q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the cooling-off effect (opposite to the magnet\neffect) from two aspects. Firstly, from the viewpoint of dynamics, we study the\nexistence of the cooling-off effect by following the dynamical evolution of\nsome financial variables over a period of time before the stock price hits its\nlimit. Secondly, from the probability perspective, we investigate, with the\nlogit model, the existence of the cooling-off effect through analyzing the\nhigh-frequency data of all A-share common stocks traded on the Shanghai Stock\nExchange and the Shenzhen Stock Exchange from 2000 to 2011 and inspecting the\ntrading period from the opening phase prior to the moment that the stock price\nhits its limits. A comparison is made of the properties between up-limit hits\nand down-limit hits, and the possible difference will also be compared between\nbullish and bearish market state by dividing the whole period into three\nalternating bullish periods and three bearish periods. We find that the\ncooling-off effect emerges for both up-limit hits and down-limit hits, and the\ncooling-off effect of the down-limit hits is stronger than that of the up-limit\nhits. The difference of the cooling-off effect between bullish period and\nbearish period is quite modest. Moreover, we examine the sub-optimal orders\neffect, and infer that the professional individual investors and institutional\ninvestors play a positive role in the cooling-off effects. All these findings\nindicate that the price limit trading rule exerts a positive effect on\nmaintaining the stability of the Chinese stock markets.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 05:40:32 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Wan", "Yu-Lei", "", "ECUST"], ["Wang", "Gang-Jin", "", "HNU"], ["Jiang", "Zhi-Qiang", "", "ECUST"], ["Xie", "Wen-Jie", "", "ECUST"], ["Zhou", "Wei-Xing", "", "ECUST"]]}, {"id": "1803.09432", "submitter": "Wei-Xing Zhou", "authors": "Hai-Chuan Xu (ECUST), Wei-Xing Zhou (ECUST), Didier Sornette (ETH\n  Zurich)", "title": "Time-dependent lead-lag relationship between the onshore and offshore\n  Renminbi exchange rates", "comments": null, "journal-ref": "Journal of International Financial Markets, Institutions & Money\n  49, 173-183 (2017)", "doi": "10.1016/j.intfin.2017.05.001", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We employ the thermal optimal path method to explore both the long-term and\nshort-term interaction patterns between the onshore CNY and offshore CNH\nexchange rates (2012-2015). For the daily data, the CNY and CNH exchange rates\nshow a weak alternate lead-lag structure in most of the time periods. When CNY\nand CNH display a large disparity, the lead-lag relationship is uncertain and\ndepends on the prevailing market factors. The minute-scale interaction pattern\nbetween the CNY and CNH exchange rates change over time according to different\nmarket situations. We find that US dollar appreciation is associated with a\nlead-lag relationship running from offshore to onshore, while a (contrarian)\nRenminbi appreciation is associated with a lead-lag relationship running from\nonshore to offshore. These results are robust with respect to different\nsub-sample analyses and variations of the key smoothing parameter of the TOP\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 06:33:00 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Xu", "Hai-Chuan", "", "ECUST"], ["Zhou", "Wei-Xing", "", "ECUST"], ["Sornette", "Didier", "", "ETH\n  Zurich"]]}, {"id": "1803.09514", "submitter": "Charu Sharma", "authors": "Charu Sharma (Shiv Nadar University, UP), Amber Habib (Shiv Nadar\n  University, UP), Sunil Bowry (Shiv Nadar University, UP)", "title": "Cluster analysis of stocks using price movements of high frequency data\n  from National Stock Exchange", "comments": "presented in conference IPECS2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper aims to develop new techniques to describe joint behavior of\nstocks, beyond regression and correlation. For example, we want to identify the\nclusters of the stocks that move together. Our work is based on applying Kernel\nPrincipal Component Analysis(KPCA) and Functional Principal Component\nAnalysis(FPCA) to high frequency data from NSE. Since we dealt with high\nfrequency data with a tick size of 30 seconds, FPCA seems to be an ideal\nchoice. FPCA is a functional variant of PCA where each sample point is\nconsidered to be a function in Hilbert space L^2. On the other hand, KPCA is an\nextension of PCA using kernel methods. Results obtained from FPCA and Gaussian\nKernel PCA seems to be in synergy but with a lag. There were two prominent\nclusters that showed up in our analysis, one corresponding to the banking\nsector and another corresponding to the IT sector. The other smaller clusters\nwere seen from the automobile industry and the energy sector. IT sector was\nseen interacting with these small clusters. The learning gained from these\ninteractions is substantial as one can use it significantly to develop trading\nstrategies for intraday traders.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 11:22:56 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Sharma", "Charu", "", "Shiv Nadar University, UP"], ["Habib", "Amber", "", "Shiv Nadar\n  University, UP"], ["Bowry", "Sunil", "", "Shiv Nadar University, UP"]]}]