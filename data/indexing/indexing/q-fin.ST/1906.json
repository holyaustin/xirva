[{"id": "1906.00573", "submitter": "Steven Pav", "authors": "Steven E. Pav", "title": "Conditional inference on the asset with maximum Sharpe ratio", "comments": "code and latex source available from github repo,\n  github.com/shabbychef/maxsharpe", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.PM stat.AP", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We apply the procedure of Lee et al. to the problem of performing inference\non the signal-noise ratio of the asset which displays maximum sample Sharpe\nratio over a set of possibly correlated assets. We find a multivariate analogue\nof the commonly used approximate standard error of the Sharpe ratio to use in\nthis conditional estimation procedure. We also consider several alternative\nprocedures, including the simple Bonferroni correction for multiple hypothesis\ntesting, which we fix for the case of positive common correlation among assets,\nthe chi-bar square test against one-sided alternatives, Follman's test, and\nHansen's asymptotic adjustments.\n  Testing indicates the conditional inference procedure achieves nominal type I\nrate, and does not appear to suffer from non-normality of returns. The\nconditional estimation test has low power under the alternative where there is\nlittle spread in the signal-noise ratios of the assets, and high power under\nthe alternative where a single asset has high signal-noise ratio. Unlike the\nalternative procedures, it appears to enjoy rejection probabilities montonic in\nthe signal-noise ratio of the selected asset.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 04:50:52 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2019 17:01:48 GMT"}, {"version": "v3", "created": "Tue, 23 Jul 2019 05:33:21 GMT"}, {"version": "v4", "created": "Fri, 26 Jul 2019 01:26:37 GMT"}, {"version": "v5", "created": "Sun, 27 Oct 2019 00:48:31 GMT"}, {"version": "v6", "created": "Mon, 25 Nov 2019 05:36:01 GMT"}, {"version": "v7", "created": "Sat, 7 Dec 2019 06:47:47 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Pav", "Steven E.", ""]]}, {"id": "1906.01427", "submitter": "Adriano Koshiyama", "authors": "Nick Firoozye and Adriano Koshiyama", "title": "Optimal Dynamic Strategies on Gaussian Returns", "comments": "Accepted by Journal of Investment Strategies. arXiv admin note: text\n  overlap with arXiv:1905.05023", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.RM q-fin.ST q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic trading strategies, in the spirit of trend-following or\nmean-reversion, represent an only partly understood but lucrative and pervasive\narea of modern finance. Assuming Gaussian returns and Gaussian dynamic weights\nor signals, (e.g., linear filters of past returns, such as simple moving\naverages, exponential weighted moving averages, forecasts from ARIMA models),\nwe are able to derive closed-form expressions for the first four moments of the\nstrategy's returns, in terms of correlations between the random signals and\nunknown future returns. By allowing for randomness in the asset-allocation and\nmodelling the interaction of strategy weights with returns, we demonstrate that\npositive skewness and excess kurtosis are essential components of all positive\nSharpe dynamic strategies, which is generally observed empirically; demonstrate\nthat total least squares (TLS) or orthogonal least squares is more appropriate\nthan OLS for maximizing the Sharpe ratio, while canonical correlation analysis\n(CCA) is similarly appropriate for the multi-asset case; derive standard errors\non Sharpe ratios which are tighter than the commonly used standard errors from\nLo; and derive standard errors on the skewness and kurtosis of strategies,\napparently new results. We demonstrate these results are applicable\nasymptotically for a wide range of stationary time-series.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2019 20:25:08 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Firoozye", "Nick", ""], ["Koshiyama", "Adriano", ""]]}, {"id": "1906.02306", "submitter": "Rostislav Serota", "authors": "M. Dashti Moghaddam, Jiong Liu and R. A. Serota", "title": "Implied and Realized Volatility: A Study of Distributions and the\n  Distribution of Difference", "comments": "16 pages, 11 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributions of realized variance (squared realized volatility) and\nsquared implied volatility, as represented by VIX and VXO indices. We find that\nGeneralized Beta distribution provide the best fits. These fits are much more\naccurate for realized variance than for squared VIX and VXO -- possibly another\nindicator that the latter have deficiencies in predicting the former. We also\nshow that there are noticeable differences between the distributions of the\n1970-2017 realized variance and its 1990-2017 portion, for which VIX and VXO\nbecame available. This may be indicative of a feedback effect that implied\nvolatility has on realized volatility. We also discuss the distribution of the\ndifference between squared implied volatility and realized variance and show\nthat, at the basic level, it is consistent with Pearson's correlations obtained\nfrom linear regression.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 20:52:57 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Moghaddam", "M. Dashti", ""], ["Liu", "Jiong", ""], ["Serota", "R. A.", ""]]}, {"id": "1906.03232", "submitter": "Brandon Da Silva", "authors": "Brandon Da Silva and Sylvie Shang Shi", "title": "Style Transfer with Time Series: Generating Synthetic Financial Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep learning models that generalize well to live deployment is a\nchallenging problem in the financial markets. The challenge arises because of\nhigh dimensionality, limited observations, changing data distributions, and a\nlow signal-to-noise ratio. High dimensionality can be dealt with using robust\nfeature selection or dimensionality reduction, but limited observations often\nresult in a model that overfits due to the large parameter space of most deep\nneural networks. We propose a generative model for financial time series, which\nallows us to train deep learning models on millions of simulated paths. We show\nthat our generative model is able to create realistic paths that embed the\nunderlying structure of the markets in a way stochastic processes cannot.\n", "versions": [{"version": "v1", "created": "Fri, 24 May 2019 03:33:14 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 21:27:28 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Da Silva", "Brandon", ""], ["Shi", "Sylvie Shang", ""]]}, {"id": "1906.03305", "submitter": "Andreea Minca", "authors": "Xin Qian, Yudong Chen, Andreea Minca", "title": "Clustering Degree-Corrected Stochastic Block Model with Outliers", "comments": "32 pages, 8 Fig", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the degree corrected stochastic block model in the presence of arbitrary\nor even adversarial outliers, we develop a convex-optimization-based clustering\nalgorithm that includes a penalization term depending on the positive deviation\nof a node from the expected number of edges to other inliers. We prove that\nunder mild conditions, this method achieves exact recovery of the underlying\nclusters. Our synthetic experiments show that our algorithm performs well on\nheterogeneous networks, and in particular those with Pareto degree\ndistributions, for which outliers have a broad range of possible degrees that\nmay enhance their adversarial power. We also demonstrate that our method allows\nfor recovery with significantly lower error rates compared to existing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 19:28:27 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Qian", "Xin", ""], ["Chen", "Yudong", ""], ["Minca", "Andreea", ""]]}, {"id": "1906.04322", "submitter": "Jean-Fran\\c{c}ois B\\'egin", "authors": "Jean-Fran\\c{c}ois B\\'egin and Mathieu Boudreault", "title": "Likelihood Evaluation of Jump-Diffusion Models Using Deterministic\n  Nonlinear Filters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we develop a deterministic nonlinear filtering algorithm based\non a high-dimensional version of Kitagawa (1987) to evaluate the likelihood\nfunction of models that allow for stochastic volatility and jumps whose arrival\nintensity is also stochastic. We show numerically that the deterministic\nfiltering method is precise and much faster than the particle filter, in\naddition to yielding a smooth function over the parameter space. We then find\nthe maximum likelihood estimates of various models that include stochastic\nvolatility, jumps in the returns and variance, and also stochastic jump arrival\nintensity with the S&P 500 daily returns. During the Great Recession, the jump\narrival intensity increases significantly and contributes to the clustering of\nvolatility and negative returns.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 23:31:49 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 19:48:46 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["B\u00e9gin", "Jean-Fran\u00e7ois", ""], ["Boudreault", "Mathieu", ""]]}, {"id": "1906.04822", "submitter": "Rostislav Serota", "authors": "M. Dashti Moghaddam, Jeffrey Mills and R. A. Serota", "title": "Generalized Beta Prime Distribution: Stochastic Model of Economic\n  Exchange and Properties of Inequality Indices", "comments": "19 pages, 14 figures, 16 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM econ.TH q-fin.MF q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that a stochastic model of economic exchange, whose steady-state\ndistribution is a Generalized Beta Prime (also known as GB2), and some unique\nproperties of the latter, are the reason for GB2's success in describing\nwealth/income distributions. We use housing sale prices as a proxy to\nwealth/income distribution to numerically illustrate this point. We also\nexplore parametric limits of the distribution to do so analytically. We discuss\nparametric properties of the inequality indices -- Gini, Hoover, Theil T and\nTheil L -- vis-a-vis those of GB2 and introduce a new inequality index, which\nserves a similar purpose. We argue that Hoover and Theil L are more appropriate\nmeasures for distributions with power-law dependencies, especially fat tails,\nsuch as GB2.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 21:17:05 GMT"}], "update_date": "2019-06-13", "authors_parsed": [["Moghaddam", "M. Dashti", ""], ["Mills", "Jeffrey", ""], ["Serota", "R. A.", ""]]}, {"id": "1906.05057", "submitter": "Kartikay Gupta Mr", "authors": "Kartikay Gupta, Niladri Chatterjee", "title": "Selecting stock pairs for pairs trading while incorporating lead-lag\n  relationship", "comments": "Better updated version in lots of ways to be uploaded soon", "journal-ref": null, "doi": "10.1016/j.physa.2019.124103", "report-no": null, "categories": "q-fin.ST cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairs Trading is carried out in the financial market to earn huge profits\nfrom known equilibrium relation between pairs of stock. In financial markets,\nseldom it is seen that stock pairs are correlated at particular lead or lag.\nThis lead-lag relationship has been empirically studied in various financial\nmarkets. Earlier research works have suggested various measures for identifying\nthe best pairs for pairs trading, but they do not consider this lead-lag\neffect. The present study proposes a new distance measure which incorporates\nthe lead-lag relationship between the stocks while selecting the best pairs for\npairs trading. Further, the lead-lag value between the stocks is allowed to\nvary continuously over time. The proposed measures importance has been\nshow-cased through experimentation on two different datasets, one corresponding\nto Indian companies and another corresponding to American companies. When the\nproposed measure is clubbed with SSD measure, i.e., when pairs are identified\nthrough optimising both these measures, then the selected pairs consistently\ngenerate the best profit, as compared to all other measures. Finally, possible\ngeneralisation and extension of the proposed distance measure have been\ndiscussed.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 11:02:08 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 05:29:39 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Gupta", "Kartikay", ""], ["Chatterjee", "Niladri", ""]]}, {"id": "1906.05327", "submitter": "Luiz Capretz Dr.", "authors": "Yuxuan Huang, Luiz Fernando Capretz, Danny Ho", "title": "Neural Network Models for Stock Selection Based on Fundamental Analysis", "comments": "4 pages", "journal-ref": "32nd Canadian Conference on Electrical & Computer Engineering,\n  Edmonton, Canada, 2019", "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application of neural network architectures for financial prediction has been\nactively studied in recent years. This paper presents a comparative study that\ninvestigates and compares feed-forward neural network (FNN) and adaptive neural\nfuzzy inference system (ANFIS) on stock prediction using fundamental financial\nratios. The study is designed to evaluate the performance of each architecture\nbased on the relative return of the selected portfolios with respect to the\nbenchmark stock index. The results show that both architectures possess the\nability to separate winners and losers from a sample universe of stocks, and\nthe selected portfolios outperform the benchmark. Our study argues that FNN\nshows superior performance over ANFIS.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 18:57:50 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Huang", "Yuxuan", ""], ["Capretz", "Luiz Fernando", ""], ["Ho", "Danny", ""]]}, {"id": "1906.05420", "submitter": "Othmane Mounjid", "authors": "Othmane Mounjid, Mathieu Rosenbaum, Pamela Saliba", "title": "From asymptotic properties of general point processes to the ranking of\n  financial agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general non-linear order book model that is built from the\nindividual behaviours of the agents. Our framework encompasses Markovian and\nHawkes based models. Under mild assumptions, we prove original results on the\nergodicity and diffusivity of such system. Then we provide closed form formulas\nfor various quantities of interest: stationary distribution of the best bid and\nask quantities, spread, liquidity fluctuations and price volatility. These\nformulas are expressed in terms of individual order flows of market\nparticipants. Our approach enables us to establish a ranking methodology for\nthe market makers with respect to the quality of their trading.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 23:10:03 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Mounjid", "Othmane", ""], ["Rosenbaum", "Mathieu", ""], ["Saliba", "Pamela", ""]]}, {"id": "1906.05494", "submitter": "Md Nurujjaman Ph D", "authors": "Ajit Mahata and Md Nurujjaman", "title": "Time scales in stock markets", "comments": null, "journal-ref": "Front. Phys., 12 November 2020", "doi": "10.3389/fphy.2020.590623", "report-no": null, "categories": "q-fin.ST nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different investment strategies are adopted in short-term and long-term\ndepending on the time scales, even though time scales are adhoc in nature.\nEmpirical mode decomposition based Hurst exponent analysis and variance\ntechnique have been applied to identify the time scales for short-term and\nlong-term investment from the decomposed intrinsic mode functions(IMF). Hurst\nexponent ($H$) is around 0.5 for the IMFs with time scales from few days to 3\nmonths, and $H\\geq0.75$ for the IMFs with the time scales $\\geq5$ months. Short\nterm time series [$X_{ST}(t)$] with time scales from few days to 3 months and\n$H~0.5$ and long term time series [$X_{LT}(t)$] with time scales $\\geq5$ and\n$H\\geq0.75$, which represent the dynamics of the market, are constructed from\nthe IMFs. The $X_{ST}(t)$ and $X_{LT}(t)$ show that the market is random in\nshort-term and correlated in long term. The study also show that the\n$X_{LT}(t)$ is correlated with fundamentals of the company. The analysis will\nbe useful for investors to design the investment and trading strategy.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 05:55:22 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Mahata", "Ajit", ""], ["Nurujjaman", "Md", ""]]}, {"id": "1906.06248", "submitter": "Simon Schn\\\"urch", "authors": "Simon Schn\\\"urch and Andreas Wagner", "title": "Machine Learning on EPEX Order Books: Insights and Forecasts", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper employs machine learning algorithms to forecast German electricity\nspot market prices. The forecasts utilize in particular bid and ask order book\ndata from the spot market but also fundamental market data like renewable\ninfeed and expected demand. Appropriate feature extraction for the order book\ndata is developed. Using cross-validation to optimise hyperparameters, neural\nnetworks and random forests are proposed and compared to statistical reference\nmodels. The machine learning models outperform traditional approaches.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 15:21:58 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 08:43:38 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 08:00:07 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Schn\u00fcrch", "Simon", ""], ["Wagner", "Andreas", ""]]}, {"id": "1906.07491", "submitter": "Marcin W\\k{a}torek", "authors": "Robert G\\k{e}barowski, Pawe{\\l} O\\'swi\\k{e}cimka, Marcin W\\k{a}torek,\n  Stanis{\\l}aw Dro\\.zd\\.z", "title": "Detecting correlations and triangular arbitrage opportunities in the\n  Forex by means of multifractal detrended cross-correlations analysis", "comments": "accepted in Nonlinear Dynamics", "journal-ref": "Nonlinear Dynamics 98, 2349-2364 (2019)", "doi": "10.1007/s11071-019-05335-5", "report-no": null, "categories": "q-fin.ST cs.CE econ.GN physics.data-an q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multifractal detrended cross-correlation methodology is described and applied\nto Foreign exchange (Forex) market time series. Fluctuations of high frequency\nexchange rates of eight major world currencies over 2010-2018 period are used\nto study cross-correlations. The study is motivated by fundamental questions in\ncomplex systems' response to significant environmental changes and by potential\napplications in investment strategies, including detecting triangular arbitrage\nopportunities. Dominant multiscale cross-correlations between the exchange\nrates are found to typically occur at smaller fluctuation levels. However\nhierarchical organization of ties expressed in terms of dendrograms, with a\nnovel application of the multiscale cross-correlation coefficient, are more\npronounced at large fluctuations. The cross-correlations are quantified to be\nstronger on average between those exchange rate pairs that are bound within\ntriangular relations. Some pairs from outside triangular relations are however\nidentified to be exceptionally strongly correlated as compared to the average\nstrength of triangular correlations.This in particular applies to those\nexchange rates that involve Australian and New Zealand dollars and reflects\ntheir economic relations. Significant events with impact on the Forex are shown\nto induce triangular arbitrage opportunities which at the same time reduce\ncross--correlations on the smallest time scales and act destructively on the\nmultiscale organization of correlations. In 2010--2018 such instances took\nplace in connection with the Swiss National Bank intervention and the weakening\nof British pound sterling accompanying the initiation of Brexit procedure. The\nmethodology could be applicable to temporal and multiscale pattern detection in\nany time series.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 10:56:40 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 11:59:49 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["G\u0119barowski", "Robert", ""], ["O\u015bwi\u0119cimka", "Pawe\u0142", ""], ["W\u0105torek", "Marcin", ""], ["Dro\u017cd\u017c", "Stanis\u0142aw", ""]]}, {"id": "1906.07834", "submitter": "Marcin W\\k{a}torek", "authors": "Stanis{\\l}aw Dro\\.zd\\.z, Ludovico Minati, Pawe{\\l} O\\'swi\\k{e}cimka,\n  Marek Stanuszek, Marcin W\\k{a}torek", "title": "Signatures of crypto-currency market decoupling from the Forex", "comments": null, "journal-ref": "Future Internet 11(7), 154 (2019)", "doi": "10.3390/fi11070154", "report-no": null, "categories": "q-fin.ST econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the high-frequency recordings from Kraken, a cryptocurrency exchange\nand professional trading platform that aims to bring Bitcoin and other\ncryptocurrencies into the mainstream, the multiscale cross-correlations\ninvolving the Bitcoin (BTC), Ethereum (ETH), Euro (EUR) and US dollar (USD) are\nstudied over the period between July 1, 2016 and December 31, 2018. It is shown\nthat the multiscaling characteristics of the exchange rate fluctuations related\nto the cryptocurrency market approach those of the Forex. This, in particular,\napplies to the BTC/ETH exchange rate, whose Hurst exponent by the end of 2018\nstarted approaching the value of 0.5, which is characteristic of the mature\nworld markets. Furthermore, the BTC/ETH direct exchange rate has already\ndeveloped multifractality, which manifests itself via broad singularity\nspectra. A particularly significant result is that the measures applied for\ndetecting cross-correlations between the dynamics of the BTC/ETH and EUR/USD\nexchange rates do not show any noticeable relationships. This may be taken as\nan indication that the cryptocurrency market has begun decoupling itself from\nthe Forex.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 22:36:37 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 11:14:50 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Dro\u017cd\u017c", "Stanis\u0142aw", ""], ["Minati", "Ludovico", ""], ["O\u015bwi\u0119cimka", "Pawe\u0142", ""], ["Stanuszek", "Marek", ""], ["W\u0105torek", "Marcin", ""]]}, {"id": "1906.08088", "submitter": "Tianhai Tian", "authors": "Xue Guo, Hu Zhang, Tianhai Tian", "title": "Multi-Likelihood Methods for Developing Stock Relationship Networks\n  Using Financial Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of stock networks is an important approach to explore the\nrelationship between different stocks in the era of big-data. Although a number\nof methods have been designed to construct the stock correlation networks, it\nis still a challenge to balance the selection of prominent correlations and\nconnectivity of networks. To address this issue, we propose a new approach to\nselect essential edges in stock networks and also maintain the connectivity of\nestablished networks. This approach uses different threshold values for\nchoosing the edges connecting to a particular stock, rather than employing a\nsingle threshold value in the existing asset-value method. The innovation of\nour algorithm includes the multiple distributions in a maximum likelihood\nestimator for selecting the threshold value rather than the single distribution\nestimator in the existing methods. Using the Chinese Shanghai security market\ndata of 151 stocks, we develop a stock relationship network and analyze the\ntopological properties of the developed network. Our results suggest that the\nproposed method is able to develop networks that maintain appropriate\nconnectivities in the type of assets threshold methods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jun 2019 13:23:26 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Guo", "Xue", ""], ["Zhang", "Hu", ""], ["Tian", "Tianhai", ""]]}, {"id": "1906.08636", "submitter": "Sharada Mohanty", "authors": "Shanka Subhra Mondal, Sharada Prasanna Mohanty, Benjamin Harlander,\n  Mehmet Koseoglu, Lance Rane, Kirill Romanov, Wei-Kai Liu, Pranoot Hatwar,\n  Marcel Salathe, Joe Byrum", "title": "Investment Ranking Challenge: Identifying the best performing stocks\n  based on their semi-annual returns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the IEEE Investment ranking challenge 2018, participants were asked to\nbuild a model which would identify the best performing stocks based on their\nreturns over a forward six months window. Anonymized financial predictors and\nsemi-annual returns were provided for a group of anonymized stocks from 1996 to\n2017, which were divided into 42 non-overlapping six months period. The second\nhalf of 2017 was used as an out-of-sample test of the model's performance.\nMetrics used were Spearman's Rank Correlation Coefficient and Normalized\nDiscounted Cumulative Gain (NDCG) of the top 20% of a model's predicted\nrankings. The top six participants were invited to describe their approach. The\nsolutions used were varied and were based on selecting a subset of data to\ntrain, combination of deep and shallow neural networks, different boosting\nalgorithms, different models with different sets of features, linear support\nvector machine, combination of convoltional neural network (CNN) and Long short\nterm memory (LSTM).\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 14:04:59 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Mondal", "Shanka Subhra", ""], ["Mohanty", "Sharada Prasanna", ""], ["Harlander", "Benjamin", ""], ["Koseoglu", "Mehmet", ""], ["Rane", "Lance", ""], ["Romanov", "Kirill", ""], ["Liu", "Wei-Kai", ""], ["Hatwar", "Pranoot", ""], ["Salathe", "Marcel", ""], ["Byrum", "Joe", ""]]}, {"id": "1906.09024", "submitter": "Xin Huang", "authors": "Joshua Zoen Git Hiew, Xin Huang, Hao Mou, Duan Li, Qi Wu, Yabo Xu", "title": "BERT-based Financial Sentiment Index and LSTM-based Stock Return\n  Predictability", "comments": "10 pages, 1 figure, 5 tables, submitted to NeurIPS 2019, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional sentiment construction in finance relies heavily on the\ndictionary-based approach, with a few exceptions using simple machine learning\ntechniques such as Naive Bayes classifier. While the current literature has not\nyet invoked the rapid advancement in the natural language processing, we\nconstruct in this research a textual-based sentiment index using a novel model\nBERT recently developed by Google, especially for three actively trading\nindividual stocks in Hong Kong market with hot discussion on Weibo.com. On the\none hand, we demonstrate a significant enhancement of applying BERT in\nsentiment analysis when compared with existing models. On the other hand, by\ncombining with the other two existing methods commonly used on building the\nsentiment index in the financial literature, i.e., option-implied and\nmarket-implied approaches, we propose a more general and comprehensive\nframework for financial sentiment analysis, and further provide convincing\noutcomes for the predictability of individual stock return for the above three\nstocks using LSTM (with a feature of a nonlinear mapping), in contrast to the\ndominating econometric methods in sentiment influence analysis that are all of\na nature of linear regression.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 09:25:10 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Hiew", "Joshua Zoen Git", ""], ["Huang", "Xin", ""], ["Mou", "Hao", ""], ["Li", "Duan", ""], ["Wu", "Qi", ""], ["Xu", "Yabo", ""]]}, {"id": "1906.09632", "submitter": "Silvia Bartolucci", "authors": "Silvia Bartolucci and Andrei Kirilenko", "title": "A Model of the Optimal Selection of Crypto Assets", "comments": "19 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY q-fin.RM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a modelling framework for the optimal selection of crypto assets.\nCrypto assets differ by two essential features: security (technological) and\nstability (governance). Investors make choices over crypto assets similarly to\nhow they make choices by using a recommender app: the app presents each\ninvestor with a pair of crypto assets with certain security-stability\ncharacteristics to be compared. Each investor submits its preference for\nadopting one of the two assets to the app. The app, in turn, provides a\nrecommendation on whether the proposed adoption is sensible given the assets'\nessential features, information about the adoption choices of all other\ninvestors, and expected future economic benefits of adoption. Investors\ncontinue making their adoption choices over all pairs of crypto assets until\ntheir expected future economic benefits can no longer be improved upon. This\nconstitutes an optimal selection decision. We simulate optimal selection\ndecisions considering the behaviour of different types of investors, driven by\ntheir attitudes towards assets' features. We find a variety of possible\nemergent outcomes for the investments in the crypto-ecosystem and the future\nadoption of the crypto assets.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 19:16:34 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Bartolucci", "Silvia", ""], ["Kirilenko", "Andrei", ""]]}, {"id": "1906.10121", "submitter": "Absalom Ezugwu", "authors": "Bradley J. Pillay and Absalom E. Ezugwu", "title": "Metaheuristics optimized feedforward neural networks for efficient stock\n  price prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The prediction of stock prices is an important task in economics, investment\nand making financial decisions. This has, for decades, spurred the interest of\nmany researchers to make focused contributions to the design of accurate stock\nprice predictive models; of which some have been utilized to predict the next\nday opening and closing prices of the stock indices. This paper proposes the\ndesign and implementation of a hybrid symbiotic organisms search trained\nfeedforward neural network model for effective and accurate stock price\nprediction. The symbiotic organisms search algorithm is used as an efficient\noptimization technique to train the feedforward neural networks, while the\nresulting training process is used to build a better stock price prediction\nmodel. Furthermore, the study also presents a comparative performance\nevaluation of three different stock price forecasting models; namely, the\nparticle swarm optimization trained feedforward neural network model, the\ngenetic algorithm trained feedforward neural network model and the well-known\nARIMA model. The system developed in support of this study utilizes sixteen\nstock indices as time series datasets for training and testing purpose. Three\nstatistical evaluation measures are used to compare the results of the\nimplemented models, namely the root mean squared error, the mean absolute\npercentage error and the mean absolution deviation. The computational results\nobtained reveal that the symbiotic organisms search trained feedforward neural\nnetwork model exhibits outstanding predictive performance compared to the other\nmodels. However, the performance study shows that the three metaheuristics\ntrained feedforward neural network models have promising predictive competence\nfor solving problems of high dimensional nonlinear time series data, which are\ndifficult to capture by traditional models.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jun 2019 11:31:52 GMT"}, {"version": "v2", "created": "Thu, 27 Jun 2019 12:19:40 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 16:13:42 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Pillay", "Bradley J.", ""], ["Ezugwu", "Absalom E.", ""]]}, {"id": "1906.10325", "submitter": "David Toth", "authors": "David Toth, Bruce Jones", "title": "Against the Norm: Modeling Daily Stock Returns with the Laplace\n  Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modeling stock returns is not a new task for mathematicians, investors, and\nportfolio managers, but it remains a difficult objective due to the ebb and\nflow of stock markets. One common solution is to approximate the distribution\nof stock returns with a normal distribution. However, normal distributions\nplace infinitesimal probabilities on extreme outliers, but these outliers are\nof particular importance in the practice of investing. In this paper, we\ninvestigate the normality of the distribution of daily returns of major stock\nmarket indices. We find that the normal distribution is not a good model for\nstock returns, even over several years' worth of data. Moreover, we propose\nusing the Laplace distribution as a model for daily stock returns.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 05:36:29 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Toth", "David", ""], ["Jones", "Bruce", ""]]}, {"id": "1906.10372", "submitter": "Nick Whiteley Prof.", "authors": "Nick Whiteley", "title": "Dynamic time series clustering via volatility change-points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note outlines a method for clustering time series based on a statistical\nmodel in which volatility shifts at unobserved change-points. The model\naccommodates some classical stylized features of returns and its relation to\nGARCH is discussed. Clustering is performed using a probability metric\nevaluated between posterior distributions of the most recent change-point\nassociated with each series. This implies series are grouped together at a\ngiven time if there is evidence the most recent shifts in their respective\nvolatilities were coincident or closely timed. The clustering method is\ndynamic, in that groupings may be updated in an online manner as data arrive.\nNumerical results are given analyzing daily returns of constituents of the S&P\n500.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 08:18:58 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Whiteley", "Nick", ""]]}, {"id": "1906.10388", "submitter": "Viktor Stojkoski MSc", "authors": "Lasko Basnarkov, Viktor Stojkoski, Zoran Utkovski and Ljupco Kocarev", "title": "Lead-lag Relationships in Foreign Exchange Markets", "comments": null, "journal-ref": null, "doi": "10.1016/j.physa.2019.122986", "report-no": null, "categories": "q-fin.ST q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lead-lag relationships among assets represent a useful tool for analyzing\nhigh frequency financial data. However, research on these relationships\npredominantly focuses on correlation analyses for the dynamics of stock prices,\nspots and futures on market indexes, whereas foreign exchange data have been\nless explored. To provide a valuable insight on the nature of the lead-lag\nrelationships in foreign exchange markets here we perform a detailed study for\nthe one-minute log returns on exchange rates through three different\napproaches: i) lagged correlations, ii) lagged partial correlations and iii)\nGranger causality. In all studies, we find that even though for most pairs of\nexchange rates lagged effects are absent, there are many pairs which pass\nstatistical significance tests. Out of the statistically significant\nrelationships, we construct directed networks and investigate the influence of\nindividual exchange rates through the PageRank algorithm. The algorithm, in\ngeneral, ranks stock market indexes quoted in their respective currencies, as\nmost influential. In contrast to the claims of the efficient market hypothesis,\nthese findings suggest that all market information does not spread\ninstantaneously.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 08:51:02 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 11:27:11 GMT"}, {"version": "v3", "created": "Sun, 15 Sep 2019 12:27:33 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Basnarkov", "Lasko", ""], ["Stojkoski", "Viktor", ""], ["Utkovski", "Zoran", ""], ["Kocarev", "Ljupco", ""]]}, {"id": "1906.12123", "submitter": "Darjus Hosszejni", "authors": "Darjus Hosszejni and Gregor Kastner", "title": "Modeling Univariate and Multivariate Stochastic Volatility in R with\n  stochvol and factorstochvol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO econ.EM q-fin.CP q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic volatility (SV) models are nonlinear state-space models that enjoy\nincreasing popularity for fitting and predicting heteroskedastic time series.\nHowever, due to the large number of latent quantities, their efficient\nestimation is non-trivial and software that allows to easily fit SV models to\ndata is rare. We aim to alleviate this issue by presenting novel\nimplementations of four SV models delivered in two R packages. Several unique\nfeatures are included and documented. As opposed to previous versions, stochvol\nis now capable of handling linear mean models, heavy-tailed SV, and SV with\nleverage. Moreover, we newly introduce factorstochvol which caters for\nmultivariate SV. Both packages offer a user-friendly interface through the\nconventional R generics and a range of tailor-made methods. Computational\nefficiency is achieved via interfacing R to C++ and doing the heavy work in the\nlatter. In the paper at hand, we provide a detailed discussion on Bayesian SV\nestimation and showcase the use of the new software through various examples.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 10:35:36 GMT"}, {"version": "v2", "created": "Fri, 27 Nov 2020 10:25:56 GMT"}, {"version": "v3", "created": "Sat, 6 Feb 2021 15:57:14 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Hosszejni", "Darjus", ""], ["Kastner", "Gregor", ""]]}, {"id": "1906.12134", "submitter": "Gregor Kastner", "authors": "Gregor Kastner", "title": "Dealing with Stochastic Volatility in Time Series Using the R Package\n  stochvol", "comments": null, "journal-ref": "Journal of Statistical Software, 69(5), 1-30 (2016)", "doi": "10.18637/jss.v069.i05", "report-no": null, "categories": "stat.CO econ.EM q-fin.CP q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The R package stochvol provides a fully Bayesian implementation of\nheteroskedasticity modeling within the framework of stochastic volatility. It\nutilizes Markov chain Monte Carlo (MCMC) samplers to conduct inference by\nobtaining draws from the posterior distribution of parameters and latent\nvariables which can then be used for predicting future volatilities. The\npackage can straightforwardly be employed as a stand-alone tool; moreover, it\nallows for easy incorporation into other MCMC samplers. The main focus of this\npaper is to show the functionality of stochvol. In addition, it provides a\nbrief mathematical description of the model, an overview of the sampling\nschemes used, and several illustrative examples using exchange rate data.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 11:16:00 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Kastner", "Gregor", ""]]}]