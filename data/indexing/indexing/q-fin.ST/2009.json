[{"id": "2009.01317", "submitter": "Zhiqiang Ma", "authors": "Zhiqiang Ma, Grace Bang, Chong Wang, Xiaomo Liu", "title": "Towards Earnings Call and Stock Price Movement", "comments": "Accepted by KDD 2020 MLF workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Earnings calls are hosted by management of public companies to discuss the\ncompany's financial performance with analysts and investors. Information\ndisclosed during an earnings call is an essential source of data for analysts\nand investors to make investment decisions. Thus, we leverage earnings call\ntranscripts to predict future stock price dynamics. We propose to model the\nlanguage in transcripts using a deep learning framework, where an attention\nmechanism is applied to encode the text data into vectors for the\ndiscriminative network classifier to predict stock price movements. Our\nempirical experiments show that the proposed model is superior to the\ntraditional machine learning baselines and earnings call information can boost\nthe stock price prediction performance.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2020 20:38:14 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Ma", "Zhiqiang", ""], ["Bang", "Grace", ""], ["Wang", "Chong", ""], ["Liu", "Xiaomo", ""]]}, {"id": "2009.03094", "submitter": "Zhengxin Ye", "authors": "Zhengxin Joseph Ye and Bjorn W. Schuller", "title": "Capturing dynamics of post-earnings-announcement drift using genetic\n  algorithm-optimised supervised learning", "comments": "13 pages of main article plus 6 pages of data in appendix. 7 figures\n  and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Post-Earnings-Announcement Drift (PEAD) is one of the most studied\nstock market anomalies, the current literature is often limited in explaining\nthis phenomenon by a small number of factors using simpler regression methods.\nIn this paper, we use a machine learning based approach instead, and aim to\ncapture the PEAD dynamics using data from a large group of stocks and a wide\nrange of both fundamental and technical factors. Our model is built around the\nExtreme Gradient Boosting (XGBoost) and uses a long list of engineered input\nfeatures based on quarterly financial announcement data from 1,106 companies in\nthe Russell 1000 index between 1997 and 2018. We perform numerous experiments\non PEAD predictions and analysis and have the following contributions to the\nliterature. First, we show how Post-Earnings-Announcement Drift can be analysed\nusing machine learning methods and demonstrate such methods' prowess in\nproducing credible forecasting on the drift direction. It is the first time\nPEAD dynamics are studied using XGBoost. We show that the drift direction is in\nfact driven by different factors for stocks from different industrial sectors\nand in different quarters and XGBoost is effective in understanding the\nchanging drivers. Second, we show that an XGBoost well optimised by a Genetic\nAlgorithm can help allocate out-of-sample stocks to form portfolios with higher\npositive returns to long and portfolios with lower negative returns to short, a\nfinding that could be adopted in the process of developing market neutral\nstrategies. Third, we show how theoretical event-driven stock strategies have\nto grapple with ever changing market prices in reality, reducing their\neffectiveness. We present a tactic to remedy the difficulty of buying into a\nmoving market when dealing with PEAD signals.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 13:27:06 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ye", "Zhengxin Joseph", ""], ["Schuller", "Bjorn W.", ""]]}, {"id": "2009.03362", "submitter": "Rodrigo Rivera-Castro", "authors": "Rodrigo Rivera-Castro, Polina Pilyugina, Evgeny Burnaev", "title": "Topological Data Analysis for Portfolio Management of Cryptocurrencies", "comments": null, "journal-ref": "2019 International Conference on Data Mining Workshops (ICDMW)", "doi": "10.1109/ICDMW.2019.00044", "report-no": null, "categories": "q-fin.PM cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Portfolio management is essential for any investment decision. Yet,\ntraditional methods in the literature are ill-suited for the characteristics\nand dynamics of cryptocurrencies. This work presents a method to build an\ninvestment portfolio consisting of more than 1500 cryptocurrencies covering 6\nyears of market data. It is centred around Topological Data Analysis (TDA), a\nrecent approach to analyze data sets from the perspective of their topological\nstructure. This publication proposes a system combining persistence landscapes\nto identify suitable investment opportunities in cryptocurrencies. Using a\nnovel and comprehensive data set of cryptocurrency prices, this research shows\nthat the proposed system enables analysts to outperform a classic method from\nthe literature without requiring any feature engineering or domain knowledge in\nTDA. This work thus introduces TDA-based portfolio management of\ncryptocurrencies as a viable tool for the practitioner.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 18:30:36 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Rivera-Castro", "Rodrigo", ""], ["Pilyugina", "Polina", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "2009.04824", "submitter": "David Thesmar", "authors": "Antoine Falck, Adam Rej, David Thesmar", "title": "Is Factor Momentum More than Stock Momentum?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Yes, but only at short lags. In this paper we investigate the relationship\nbetween factor momentum and stock momentum. Using a sample of 72 factors\ndocumented in the literature, we first replicate earlier findings that factor\nmomentum exists and works both directionally and cross-sectionally. We then ask\nif factor momentum is spanned by stock momentum. A simple spanning test reveals\nthat after controlling for stock momentum and factor exposure, statistically\nsignificant Sharpe ratios only belong to implementations which include the last\nmonth of returns. We conclude this study with a simple theoretical model that\ncaptures these forces: (1) there is stock-level mean reversion at short lags\nand momentum at longer lags, (2) there is stock and factor momentum at all lags\nand (3) there is natural comovement between the PNLs of stock and factor\nmomentums at all horizons.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 12:52:43 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Falck", "Antoine", ""], ["Rej", "Adam", ""], ["Thesmar", "David", ""]]}, {"id": "2009.05507", "submitter": "Sudiksha Joshi", "authors": "Sudiksha Joshi", "title": "Forecasting the Leading Indicator of a Recession: The 10-Year minus\n  3-Month Treasury Yield Spread", "comments": "43 pages, 27 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research paper, I have applied various econometric time series and\ntwo machine learning models to forecast the daily data on the yield spread.\nFirst, I decomposed the yield curve into its principal components, then\nsimulated various paths of the yield spread using the Vasicek model. After\nconstructing univariate ARIMA models, and multivariate models such as ARIMAX,\nVAR, and Long Short Term Memory, I calibrated the root mean squared error to\nmeasure how far the results deviate from the current values. Through impulse\nresponse functions, I measured the impact of various shocks on the difference\nyield spread. The results indicate that the parsimonious univariate ARIMA model\noutperforms the richly parameterized VAR method, and the complex LSTM with\nmultivariate data performs equally well as the simple ARIMA model.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 18:47:01 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Joshi", "Sudiksha", ""]]}, {"id": "2009.05508", "submitter": "G\\'abor Petneh\\'azi", "authors": "Bernadett Aradi, G\\'abor Petneh\\'azi, J\\'ozsef G\\'all", "title": "Volatility Forecasting with 1-dimensional CNNs via transfer learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volatility is a natural risk measure in finance as it quantifies the\nvariation of stock prices. A frequently considered problem in mathematical\nfinance is to forecast different estimates of volatility. What makes it\npromising to use deep learning methods for the prediction of volatility is the\nfact, that stock price returns satisfy some common properties, referred to as\n`stylized facts'. Also, the amount of data used can be high, favoring the\napplication of neural networks. We used 10 years of daily prices for hundreds\nof frequently traded stocks, and compared different CNN architectures: some\nnetworks use only the considered stock, but we tried out a construction which,\nfor training, uses much more series, but not the considered stocks.\nEssentially, this is an application of transfer learning, and its performance\nturns out to be much better in terms of prediction error. We also compare our\ndilated causal CNNs to the classical ARIMA method using an automatic model\nselection procedure.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2020 19:09:33 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Aradi", "Bernadett", ""], ["Petneh\u00e1zi", "G\u00e1bor", ""], ["G\u00e1ll", "J\u00f3zsef", ""]]}, {"id": "2009.05636", "submitter": "C. Bayan Bruss", "authors": "Jason Wittenbach, Brian d'Alessandro, C. Bayan Bruss", "title": "Machine Learning for Temporal Data in Finance: Challenges and\n  Opportunities", "comments": "KDD '20 ML in Finance Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal data are ubiquitous in the financial services (FS) industry --\ntraditional data like economic indicators, operational data such as bank\naccount transactions, and modern data sources like website clickstreams -- all\nof these occur as a time-indexed sequence. But machine learning efforts in FS\noften fail to account for the temporal richness of these data, even in cases\nwhere domain knowledge suggests that the precise temporal patterns between\nevents should contain valuable information. At best, such data are often\ntreated as uniform time series, where there is a sequence but no sense of exact\ntiming. At worst, rough aggregate features are computed over a pre-selected\nwindow so that static sample-based approaches can be applied (e.g. number of\nopen lines of credit in the previous year or maximum credit utilization over\nthe previous month). Such approaches are at odds with the deep learning\nparadigm which advocates for building models that act directly on raw or\nlightly processed data and for leveraging modern optimization techniques to\ndiscover optimal feature transformations en route to solving the modeling task\nat hand. Furthermore, a full picture of the entity being modeled (customer,\ncompany, etc.) might only be attainable by examining multiple data streams that\nunfold across potentially vastly different time scales. In this paper, we\nexamine the different types of temporal data found in common FS use cases,\nreview the current machine learning approaches in this area, and finally assess\nchallenges and opportunities for researchers working at the intersection of\nmachine learning for temporal data and applications in FS.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 19:39:27 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Wittenbach", "Jason", ""], ["d'Alessandro", "Brian", ""], ["Bruss", "C. Bayan", ""]]}, {"id": "2009.05652", "submitter": "Aurelio F. Bariviera", "authors": "M. Bel\\'en Arouxet, Aurelio F. Bariviera, Ver\\'onica E. Pastor,\n  Victoria Vampa", "title": "Covid-19 impact on cryptocurrencies: evidence from a wavelet-based Hurst\n  exponent", "comments": "4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrency history begins in 2008 as a means of payment proposal.\nHowever, cryptocurrencies evolved into complex, high yield speculative assets.\nContrary to traditional financial instruments, they are not (mostly) traded in\norganized, law-abiding venues, but on online platforms, where anonymity reigns.\nThis paper examines the long term memory in return and volatility, using high\nfrequency time series of eleven important coins. Our study covers the\npre-Covid-19 and the subsequent pandemia period. We use a recently developed\nmethod, based on the wavelet transform, which provides more robust estimators\nof the Hurst exponent. We detect that, during the peak of Covid-19 pandemic\n(around March 2020), the long memory of returns was only mildly affected.\nHowever, volatility suffered a temporary impact in its long range correlation\nstructure. Our results could be of interest for both academics and\npractitioners.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 20:49:12 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Arouxet", "M. Bel\u00e9n", ""], ["Bariviera", "Aurelio F.", ""], ["Pastor", "Ver\u00f3nica E.", ""], ["Vampa", "Victoria", ""]]}, {"id": "2009.06221", "submitter": "Toma\\v{z} Ko\\v{s}ir", "authors": "Damjana Kokol Bukov\\v{s}ek, Toma\\v{z} Ko\\v{s}ir, Bla\\v{z}\n  Moj\\v{s}kerc, Matja\\v{z} Omladi\\v{c}", "title": "Spearman's footrule and Gini's gamma: Local bounds for bivariate copulas\n  and the exact region with respect to Blomqvist's beta", "comments": "30 pages, 13 figures", "journal-ref": null, "doi": "10.1016/j.cam.2021.113385", "report-no": null, "categories": "math.ST math.PR q-fin.RM q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Copulas are becoming an essential tool in analyzing data thus encouraging\ninterest in related questions. In the early stage of exploratory data analysis,\nsay, it is helpful to know local copula bounds with a fixed value of a given\nmeasure of association. These bounds have been computed for Spearman's rho,\nKendall's tau, and Blomqvist's beta. The importance of another two measures of\nassociation, Spearman's footrule and Gini's gamma, has been reconfirmed\nrecently. It is the main purpose of this paper to fill in the gap and present\nthe mentioned local bounds for these two measures as well. It turns out that\nthis is a quite non-trivial endeavor as the bounds are quasi-copulas that are\nnot copulas for certain values of the two measures. We also give relations\nbetween these two measures of association and Blomqvist's beta.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 06:33:45 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 12:03:04 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Bukov\u0161ek", "Damjana Kokol", ""], ["Ko\u0161ir", "Toma\u017e", ""], ["Moj\u0161kerc", "Bla\u017e", ""], ["Omladi\u010d", "Matja\u017e", ""]]}, {"id": "2009.06874", "submitter": "Tetsuya Takaishi", "authors": "Tetsuya Takaishi", "title": "Recent scaling properties of Bitcoin price returns", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": "10.1088/1742-6596/1730/1/012124", "report-no": null, "categories": "q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While relevant stylized facts are observed for Bitcoin markets, we find a\ndistinct property for the scaling behavior of the cumulative return\ndistribution. For various assets, the tail index $\\mu$ of the cumulative return\ndistribution exhibits $\\mu \\approx 3$, which is referred to as \"the inverse\ncubic law.\" On the other hand, that of the Bitcoin return is claimed to be $\\mu\n\\approx 2$, which is known as \"the inverse square law.\" We investigate the\nscaling properties using recent Bitcoin data and find that the tail index\nchanges to $\\mu \\approx 3$, which is consistent with the inverse cubic law.\nThis suggests that some properties of the Bitcoin market could vary over time.\nWe also investigate the autocorrelation of absolute returns and find that it is\ndescribed by a power-law with two scaling exponents. By analyzing the absolute\nreturns standardized by the realized volatility, we verify that the Bitcoin\nreturn time series is consistent with normal random variables with time-varying\nvolatility.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 05:42:01 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Takaishi", "Tetsuya", ""]]}, {"id": "2009.06910", "submitter": "Wolfgang Karl H\\\"ardle", "authors": "Marius Lux, Wolfgang Karl H\\\"ardle, Stefan Lessmann", "title": "Data driven value-at-risk forecasting using a SVR-GARCH-KDE hybrid", "comments": null, "journal-ref": "Computational Statistics (2020)", "doi": "10.1007/s00180-019-00934-7", "report-no": null, "categories": "q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Appropriate risk management is crucial to ensure the competitiveness of\nfinancial institutions and the stability of the economy. One widely used\nfinancial risk measure is Value-at-Risk (VaR). VaR estimates based on linear\nand parametric models can lead to biased results or even underestimation of\nrisk due to time varying volatility, skewness and leptokurtosis of financial\nreturn series. The paper proposes a nonlinear and nonparametric framework to\nforecast VaR that is motivated by overcoming the disadvantages of parametric\nmodels with a purely data driven approach. Mean and volatility are modeled via\nsupport vector regression (SVR) where the volatility model is motivated by the\nstandard generalized autoregressive conditional heteroscedasticity (GARCH)\nformulation. Based on this, VaR is derived by applying kernel density\nestimation (KDE). This approach allows for flexible tail shapes of the profit\nand loss distribution, adapts for a wide class of tail events and is able to\ncapture complex structures regarding mean and volatility.\n  The SVR-GARCH-KDE hybrid is compared to standard, exponential and threshold\nGARCH models coupled with different error distributions. To examine the\nperformance in different markets, one-day-ahead and ten-days-ahead forecasts\nare produced for different financial indices. Model evaluation using a\nlikelihood ratio based test framework for interval forecasts and a test for\nsuperior predictive ability indicates that the SVR-GARCH-KDE hybrid performs\ncompetitive to benchmark models and reduces potential losses especially for\nten-days-ahead forecasts significantly. Especially models that are coupled with\na normal distribution are systematically outperformed.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 08:01:35 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Lux", "Marius", ""], ["H\u00e4rdle", "Wolfgang Karl", ""], ["Lessmann", "Stefan", ""]]}, {"id": "2009.07947", "submitter": "Thomas Dierckx", "authors": "Thomas Dierckx, Jesse Davis and Wim Schoutens", "title": "Using Machine Learning and Alternative Data to Predict Movements in\n  Market Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using machine learning and alternative data for the prediction of financial\nmarkets has been a popular topic in recent years. Many financial variables such\nas stock price, historical volatility and trade volume have already been\nthrough extensive investigation. Remarkably, we found no existing research on\nthe prediction of an asset's market implied volatility within this context.\nThis forward-looking measure gauges the sentiment on the future volatility of\nan asset, and is deemed one of the most important parameters in the world of\nderivatives. The ability to predict this statistic may therefore provide a\ncompetitive edge to practitioners of market making and asset management alike.\nConsequently, in this paper we investigate Google News statistics and Wikipedia\nsite traffic as alternative data sources to quantitative market data and\nconsider Logistic Regression, Support Vector Machines and AdaBoost as machine\nlearning models. We show that movements in market implied volatility can indeed\nbe predicted through the help of machine learning techniques. Although the\nemployed alternative data appears to not enhance predictive accuracy, we reveal\npreliminary evidence of non-linear relationships between features obtained from\nWikipedia page traffic and movements in market implied volatility.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 21:36:03 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Dierckx", "Thomas", ""], ["Davis", "Jesse", ""], ["Schoutens", "Wim", ""]]}, {"id": "2009.08794", "submitter": "Jeremy Turiel", "authors": "Jeremy D. Turiel, Paolo Barucca and Tomaso Aste", "title": "Simplicial persistence of financial markets: filtering, generative\n  processes and portfolio risk", "comments": "8 pages, 5 figures, 3 tables. arXiv admin note: substantial text\n  overlap with arXiv:1910.08628", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST physics.soc-ph q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce simplicial persistence, a measure of time evolution of network\nmotifs in subsequent temporal layers. We observe long memory in the evolution\nof structures from correlation filtering, with a two regime power law decay in\nthe number of persistent simplicial complexes. Null models of the underlying\ntime series are tested to investigate properties of the generative process and\nits evolutional constraints. Networks are generated with both TMFG filtering\ntechnique and thresholding showing that embedding-based filtering methods\n(TMFG) are able to identify higher order structures throughout the market\nsample, where thresholding methods fail. The decay exponents of these long\nmemory processes are used to characterise financial markets based on their\nstage of development and liquidity. We find that more liquid markets tend to\nhave a slower persistence decay. This is in contrast with the common\nunderstanding that developed markets are more random. We find that they are\nindeed less predictable for what concerns the dynamics of each single variable\nbut they are more predictable for what concerns the collective evolution of the\nvariables. This could imply higher fragility to systemic shocks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 18:00:21 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Turiel", "Jeremy D.", ""], ["Barucca", "Paolo", ""], ["Aste", "Tomaso", ""]]}, {"id": "2009.09713", "submitter": "Wolfgang Karl H\\\"ardle", "authors": "Sergey Nasekin, Wolfgang Karl H\\\"ardle", "title": "Model-driven statistical arbitrage on LETF option markets", "comments": null, "journal-ref": "Quantitative Finance Quantitative Finance, Volume 19, 2019 - Issue\n  11", "doi": "10.1080/14697688.2019.1605186", "report-no": null, "categories": "q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the statistical properties of the moneyness scaling\ntransformation by Leung and Sircar (2015). This transformation adjusts the\nmoneyness coordinate of the implied volatility smile in an attempt to remove\nthe discrepancy between the IV smiles for levered and unlevered ETF options. We\nconstruct bootstrap uniform confidence bands which indicate that the implied\nvolatility smiles are statistically different after moneyness scaling has been\nperformed. An empirical application shows that there are trading opportunities\npossible on the LETF market. A statistical arbitrage type strategy based on a\ndynamic semiparametric factor model is presented. This strategy presents a\nstatistical decision algorithm which generates trade recommendations based on\ncomparison of model and observed LETF implied volatility surface. It is shown\nto generate positive returns with a high probability. Extensive econometric\nanalysis of LETF implied volatility process is performed including\nout-of-sample forecasting based on a semiparametric factor model and uniform\nconfidence bands' study. It provides new insights into the latent dynamics of\nthe implied volatility surface. We also incorporate Heston stochastic\nvolatility into the moneyness scaling method for better tractability of the\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 09:27:05 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Nasekin", "Sergey", ""], ["H\u00e4rdle", "Wolfgang Karl", ""]]}, {"id": "2009.09739", "submitter": "Wolfgang Karl H\\\"ardle", "authors": "Shi Chen, Wolfgang Karl H\\\"ardle, Brenda L\\'opez Cabrera", "title": "Regularization Approach for Network Modeling of German Power Derivative\n  Market", "comments": null, "journal-ref": "Energy Economics, Volume 83, September 2019, Pages 180-196", "doi": "10.1016/j.eneco.2019.06.021", "report-no": null, "categories": "q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we propose a regularization approach for network modeling of\nGerman power derivative market. To deal with the large portfolio, we combine\nhigh-dimensional variable selection techniques with dynamic network analysis.\nThe estimated sparse interconnectedness of the full German power derivative\nmarket, clearly identify the significant channels of relevant potential risk\nspillovers. Our empirical findings show the importance of interdependence\nbetween different contract types, and identify the main risk contributors. We\nfurther observe strong pairwise interconnections between the neighboring\ncontracts especially for the spot contracts trading in the peak hours, its\nimplications for regulators and investors are also discussed. The network\nanalysis of the full German power derivative market helps us to complement a\nfull picture of system risk, and have a better understanding of the German\npower market functioning and environment.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 10:12:59 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Chen", "Shi", ""], ["H\u00e4rdle", "Wolfgang Karl", ""], ["Cabrera", "Brenda L\u00f3pez", ""]]}, {"id": "2009.09770", "submitter": "Wolfgang Karl H\\\"ardle", "authors": "Wolfgang Karl H\\\"ardle, Elena Silyakova", "title": "Implied Basket Correlation Dynamics", "comments": null, "journal-ref": "Statistics & Risk Modeling 2016, Volume 33: Issue 1-2", "doi": "10.1515/strm-2014-1176", "report-no": null, "categories": "q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Equity basket correlation can be estimated both using the physical measure\nfrom stock prices, and also using the risk neutral measure from option prices.\nThe difference between the two estimates motivates a so-called \"dispersion\nstrategy''. We study the performance of this strategy on the German market and\npropose several profitability improvement schemes based on implied correlation\n(IC) forecasts. Modelling IC conceals several challenges. Firstly the number of\ncorrelation coefficients would grow with the size of the basket. Secondly, IC\nis not constant over maturities and strikes. Finally, IC changes over time. We\nreduce the dimensionality of the problem by assuming equicorrelation. The IC\nsurface (ICS) is then approximated from the implied volatilities of stocks and\nthe implied volatility of the basket. To analyze the dynamics of the ICS we\nemploy a dynamic semiparametric factor model.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 11:45:40 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["H\u00e4rdle", "Wolfgang Karl", ""], ["Silyakova", "Elena", ""]]}, {"id": "2009.09782", "submitter": "Wolfgang Karl H\\\"ardle", "authors": "Simon Trimborn, Wolfgang Karl H\\\"ardle", "title": "CRIX an index for cryptocurrencies", "comments": null, "journal-ref": "Journal of Empirical Finance, Volume 49, December 2018, Pages\n  107-122", "doi": "10.1016/j.jempfin.2018.08.004", "report-no": null, "categories": "q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The cryptocurrency market is unique on many levels: Very volatile, frequently\nchanging market structure, emerging and vanishing of cryptocurrencies on a\ndaily level. Following its development became a difficult task with the success\nof cryptocurrencies (CCs) other than Bitcoin. For fiat currency markets, the\nIMF offers the index SDR and, prior to the EUR, the ECU existed, which was an\nindex representing the development of European currencies. Index providers\ndecide on a fixed number of index constituents which will represent the market\nsegment. It is a challenge to fix a number and develop rules for the\nconstituents in view of the market changes. In the frequently changing CC\nmarket, this challenge is even more severe. A method relying on the AIC is\nproposed to quickly react to market changes and therefore enable us to create\nan index, referred to as CRIX, for the cryptocurrency market. CRIX is chosen by\nmodel selection such that it represents the market well to enable each\ninterested party studying economic questions in this market and to invest into\nthe market. The diversified nature of the CC market makes the inclusion of\naltcoins in the index product critical to improve tracking performance. We have\nshown that assigning optimal weights to altcoins helps to reduce the tracking\nerrors of a CC portfolio, despite the fact that their market cap is much\nsmaller relative to Bitcoin. The codes used here are available via\nwww.quantlet.de.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 12:04:20 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Trimborn", "Simon", ""], ["H\u00e4rdle", "Wolfgang Karl", ""]]}, {"id": "2009.10030", "submitter": "Jaroslaw Kwapien", "authors": "Stanis{\\l}aw Dro\\.zd\\.z, Jaros{\\l}aw Kwapie\\'n, Pawe{\\l}\n  O\\'swi\\k{e}cimka, Tomasz Stanisz, and Marcin W\\k{a}torek", "title": "Complexity in economic and social systems: cryptocurrency market at\n  around COVID-19", "comments": null, "journal-ref": "Entropy 22, 1043 (2020)", "doi": "10.3390/e22091043", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social systems are characterized by an enormous network of connections and\nfactors that can influence the structure and dynamics of these systems. All\nfinancial markets, including the cryptocurrency market, belong to the\neconomical sphere of human activity that seems to be the most interrelated and\ncomplex. The cryptocurrency market complexity can be studied from different\nperspectives. First, the dynamics of the cryptocurrency exchange rates to other\ncryptocurrencies and fiat currencies can be studied and quantified by means of\nmultifractal formalism. Second, coupling and decoupling of the cryptocurrencies\nand the conventional assets can be investigated with the advanced\ncross-correlation analyses based on fractal analysis. Third, an internal\nstructure of the cryptocurrency market can also be a subject of analysis that\nexploits, for example, a network representation of the market. We approach this\nsubject from all three perspectives based on data recorded between January 2019\nand June 2020. This period includes the Covid-19 pandemic and we pay particular\nattention to this event and investigate how strong its impact on the structure\nand dynamics of the market was. Besides, the studied data covers a few other\nsignificant events like double bull and bear phases in 2019. We show that,\nthroughout the considered interval, the exchange rate returns were multifractal\nwith intermittent signatures of bifractality that can be associated with the\nmost volatile periods of the market dynamics like a bull market onset in April\n2019 and the Covid-19 outburst in March 2020. The topology of a minimal\nspanning tree representation of the market also used to alter during these\nevents from a distributed type without any dominant node to a highly\ncentralized type with a dominating hub of USDT. However, the MST topology\nduring the pandemic differs in some details from other volatile periods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2020 17:12:12 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Dro\u017cd\u017c", "Stanis\u0142aw", ""], ["Kwapie\u0144", "Jaros\u0142aw", ""], ["O\u015bwi\u0119cimka", "Pawe\u0142", ""], ["Stanisz", "Tomasz", ""], ["W\u0105torek", "Marcin", ""]]}, {"id": "2009.10392", "submitter": "Wolfgang Karl H\\\"ardle", "authors": "Junni L. Zhang, Wolfgang Karl H\\\"ardle, Cathy Y. Chen, Elisabeth\n  Bommes", "title": "Distillation of News Flow into Analysis of Stock Reactions", "comments": null, "journal-ref": "Journal of Business and Economic Statistics, Volume 34, 2016,\n  Issue 4: Special Issues on Big Data", "doi": "10.1080/07350015.2015.1110525", "report-no": null, "categories": "q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The gargantuan plethora of opinions, facts and tweets on financial business\noffers the opportunity to test and analyze the influence of such text sources\non future directions of stocks. It also creates though the necessity to distill\nvia statistical technology the informative elements of this prodigious and\nindeed colossal data source. Using mixed text sources from professional\nplatforms, blog fora and stock message boards we distill via different lexica\nsentiment variables. These are employed for an analysis of stock reactions:\nvolatility, volume and returns. An increased sentiment, especially for those\nwith negative prospection, will influence volatility as well as volume. This\ninfluence is contingent on the lexical projection and different across Global\nIndustry Classification Standard (GICS) sectors. Based on review articles on\n100 S&P 500 constituents for the period of October 20, 2009, to October 13,\n2014, we project into BL, MPQA, LM lexica and use the distilled sentiment\nvariables to forecast individual stock indicators in a panel context.\nExploiting different lexical projections to test different stock reaction\nindicators we aim at answering the following research questions: (i) Are the\nlexica consistent in their analytic ability? (ii) To which degree is there an\nasymmetric response given the sentiment scales (positive v.s. negative)? (iii)\nAre the news of high attention firms diffusing faster and result in more timely\nand efficient stock reaction? (iv) Is there a sector-specific reaction from the\ndistilled sentiment measures? We find there is significant incremental\ninformation in the distilled news flow and the sentiment effect is\ncharacterized as an asymmetric, attention-specific and sector-specific response\nof stock reactions.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 08:50:53 GMT"}], "update_date": "2020-09-23", "authors_parsed": [["Zhang", "Junni L.", ""], ["H\u00e4rdle", "Wolfgang Karl", ""], ["Chen", "Cathy Y.", ""], ["Bommes", "Elisabeth", ""]]}, {"id": "2009.10764", "submitter": "Michele Leonardo Bianchi", "authors": "Michele Leonardo Bianchi and Giovanni De Luca and Giorgia Rivieccio", "title": "CoVaR with volatility clustering, heavy tails and non-linear dependence", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.CP q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we estimate the conditional value-at-risk by fitting different\nmultivariate parametric models capturing some stylized facts about multivariate\nfinancial time series of equity returns: heavy tails, negative skew, asymmetric\ndependence, and volatility clustering. While the volatility clustering effect\nis got by AR-GARCH dynamics of the GJR type, the other stylized facts are\ncaptured through non-Gaussian multivariate models and copula functions. The\nCoVaR$^{\\leq}$ is computed on the basis on the multivariate normal model, the\nmultivariate normal tempered stable (MNTS) model, the multivariate generalized\nhyperbolic model (MGH) and four possible copula functions. These risk measure\nestimates are compared to the CoVaR$^{=}$ based on the multivariate normal\nGARCH model. The comparison is conducted by backtesting the competitor models\nover the time span from January 2007 to March 2020. In the empirical study we\nconsider a sample of listed banks of the euro area belonging to the main or to\nthe additional global systemically important banks (GSIBs) assessment sample.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 19:03:06 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Bianchi", "Michele Leonardo", ""], ["De Luca", "Giovanni", ""], ["Rivieccio", "Giorgia", ""]]}, {"id": "2009.10819", "submitter": "Jaydip Sen", "authors": "Sidra Mehtab, Jaydip Sen, Abhishek Dutta", "title": "Stock Price Prediction Using Machine Learning and LSTM-Based Deep\n  Learning Models", "comments": "The paper has been accepted for publication in the Proceedings of the\n  Second Symposium on Machine Learning and Metaheuristic Algorithms and\n  Applications (SOMMA'20): http://www.acn-conference.org/2020/somma2020/. The\n  paper is 18 pages long, and it contains 8 Figures and 12 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of stock prices has been an important area of research for a long\ntime. While supporters of the efficient market hypothesis believe that it is\nimpossible to predict stock prices accurately, there are formal propositions\ndemonstrating that accurate modeling and designing of appropriate variables may\nlead to models using which stock prices and stock price movement patterns can\nbe very accurately predicted. In this work, we propose an approach of hybrid\nmodeling for stock price prediction building different machine learning and\ndeep learning-based models. For the purpose of our study, we have used NIFTY 50\nindex values of the National Stock Exchange (NSE) of India, during the period\nDecember 29, 2014 till July 31, 2020. We have built eight regression models\nusing the training data that consisted of NIFTY 50 index records during\nDecember 29, 2014 till December 28, 2018. Using these regression models, we\npredicted the open values of NIFTY 50 for the period December 31, 2018 till\nJuly 31, 2020. We, then, augment the predictive power of our forecasting\nframework by building four deep learning-based regression models using long-and\nshort-term memory (LSTM) networks with a novel approach of walk-forward\nvalidation. We exploit the power of LSTM regression models in forecasting the\nfuture NIFTY 50 open values using four different models that differ in their\narchitecture and in the structure of their input data. Extensive results are\npresented on various metrics for the all the regression models. The results\nclearly indicate that the LSTM-based univariate model that uses one-week prior\ndata as input for predicting the next week open value of the NIFTY 50 time\nseries is the most accurate model.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2020 20:32:33 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Mehtab", "Sidra", ""], ["Sen", "Jaydip", ""], ["Dutta", "Abhishek", ""]]}, {"id": "2009.11007", "submitter": "Wolfgang Karl H\\\"ardle", "authors": "Ai Jun Hou, Weining Wang, Cathy Y. H. Chen, Wolfgang Karl H\\\"ardle", "title": "Pricing Cryptocurrency Options", "comments": null, "journal-ref": "Journal of Financial Econometrics, Volume 18, Issue 2, Spring\n  2020, Pages 250 to 279", "doi": "10.1093/jjfinec/nbaa006", "report-no": null, "categories": "q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cryptocurrencies, especially Bitcoin (BTC), which comprise a new digital\nasset class, have drawn extraordinary worldwide attention. The characteristics\nof the cryptocurrency/BTC include a high level of speculation, extreme\nvolatility and price discontinuity. We propose a pricing mechanism based on a\nstochastic volatility with a correlated jump (SVCJ) model and compare it to a\nflexible co-jump model by Bandi and Ren\\`o (2016). The estimation results of\nboth models confirm the impact of jumps and co-jumps on options obtained via\nsimulation and an analysis of the implied volatility curve. We show that a\nsizeable proportion of price jumps are significantly and contemporaneously\nanti-correlated with jumps in volatility. Our study comprises pioneering\nresearch on pricing BTC options. We show how the proposed pricing mechanism\nunderlines the importance of jumps in cryptocurrency markets.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2020 09:04:17 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Hou", "Ai Jun", ""], ["Wang", "Weining", ""], ["Chen", "Cathy Y. H.", ""], ["H\u00e4rdle", "Wolfgang Karl", ""]]}, {"id": "2009.12092", "submitter": "Wolfgang Karl H\\\"ardle", "authors": "Meng-Jou Lu, Cathy Yi-Hsuan Chen, Wolfgang Karl H\\\"ardle", "title": "Copula-Based Factor Model for Credit Risk Analysis", "comments": null, "journal-ref": "Review of Quantitative Finance and Accounting, 49, pages 949 to\n  971, 2017", "doi": "10.1007/s11156-016-0613-x", "report-no": null, "categories": "q-fin.RM q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A standard quantitative method to access credit risk employs a factor model\nbased on joint multivariate normal distribution properties. By extending a\none-factor Gaussian copula model to make a more accurate default forecast, this\npaper proposes to incorporate a state-dependent recovery rate into the\nconditional factor loading, and model them by sharing a unique common factor.\nThe common factor governs the default rate and recovery rate simultaneously and\ncreates their association implicitly. In accordance with Basel III, this paper\nshows that the tendency of default is more governed by systematic risk rather\nthan idiosyncratic risk during a hectic period. Among the models considered,\nthe one with random factor loading and a state-dependent recovery rate turns\nout to be the most superior on the default prediction.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 08:54:49 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2020 13:09:29 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Lu", "Meng-Jou", ""], ["Chen", "Cathy Yi-Hsuan", ""], ["H\u00e4rdle", "Wolfgang Karl", ""]]}, {"id": "2009.12129", "submitter": "Wolfgang Karl H\\\"ardle", "authors": "Shi Chen, Cathy Yi-Hsuan Chen, Wolfgang Karl H\\\"ardle", "title": "A first econometric analysis of the CRIX family", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.RM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to price contingent claims one needs to first understand the\ndynamics of these indices. Here we provide a first econometric analysis of the\nCRIX family within a time-series framework. The key steps of our analysis\ninclude model selection, estimation and testing. Linear dependence is removed\nby an ARIMA model, the diagnostic checking resulted in an ARIMA(2,0,2) model\nfor the available sample period from Aug 1st, 2014 to April 6th, 2016. The\nmodel residuals showed the well known phenomenon of volatility clustering.\nTherefore a further refinement lead us to an ARIMA(2,0,2)-t-GARCH(1,1) process.\nThis specification conveniently takes care of fat-tail properties that are\ntypical for financial markets. The multivariate GARCH models are implemented on\nthe CRIX index family to explore the interaction.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 11:06:34 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Chen", "Shi", ""], ["Chen", "Cathy Yi-Hsuan", ""], ["H\u00e4rdle", "Wolfgang Karl", ""]]}, {"id": "2009.12155", "submitter": "Samuel Holt", "authors": "Evans Rozario, Samuel Holt, James West, Shaun Ng", "title": "A Decade of Evidence of Trend Following Investing in Cryptocurrencies", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cryptocurrency markets have many of the characteristics of 20th century\ncommodities markets, making them an attractive candidate for trend following\nstrategies. We present a decade of evidence from the infancy of bitcoin,\nshowcasing the potential investor returns in cryptocurrency trend following,\n255% walkforward annualised returns. We find that cryptocurrencies offer\nsimilar returns characteristics to commodities with similar risk-adjusted\nreturns, and strong bear market diversification against traditional equities.\nCode available at https://github.com/Globe-Research/bittrends.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 12:07:04 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Rozario", "Evans", ""], ["Holt", "Samuel", ""], ["West", "James", ""], ["Ng", "Shaun", ""]]}, {"id": "2009.12335", "submitter": "Anirban Chakraborti", "authors": "Areejit Samal, Hirdesh K. Pharasi, Sarath Jyotsna Ramaia, Harish\n  Kannan, Emil Saucan, J\\\"urgen Jost, and Anirban Chakraborti", "title": "Network geometry and market instability", "comments": "34 pages, 17 figures, including Supplementary Material", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of financial markets arise from the strategic interactions\namong agents trading stocks, which manifest in the form of vibrant correlation\npatterns among stock prices. Over the past few decades, complex financial\nmarkets have often been represented as networks whose interacting pairs of\nnodes are stocks, connected by edges that signify the correlation strengths.\nHowever, we often have interactions that occur in groups of three or more\nnodes, and these cannot be described simply by pairwise interactions but we\nalso need to take the relations between these interactions into account. Only\nrecently, researchers have started devoting attention to the higher-order\narchitecture of complex financial systems, that can significantly enhance our\nability to estimate systemic risk as well as measure the robustness of\nfinancial systems in terms of market efficiency. Geometry-inspired network\nmeasures, such as the Ollivier-Ricci curvature and Forman-Ricci curvature, can\nbe used to capture the network fragility and continuously monitor financial\ndynamics. Here, we explore the utility of such discrete Ricci curvatures in\ncharacterizing the structure of financial systems, and further, evaluate them\nas generic indicators of the market instability. For this purpose, we examine\nthe daily returns from a set of stocks comprising the USA S&P-500 and the\nJapanese Nikkei-225 over a 32-year period, and monitor the changes in the\nedge-centric network curvatures. We find that the different geometric measures\ncapture well the system-level features of the market and hence we can\ndistinguish between the normal or `business-as-usual' periods and all the major\nmarket crashes. This can be very useful in strategic designing of financial\nsystems and regulating the markets in order to tackle financial instabilities.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2020 16:51:39 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 21:29:48 GMT"}, {"version": "v3", "created": "Fri, 29 Jan 2021 21:59:41 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Samal", "Areejit", ""], ["Pharasi", "Hirdesh K.", ""], ["Ramaia", "Sarath Jyotsna", ""], ["Kannan", "Harish", ""], ["Saucan", "Emil", ""], ["Jost", "J\u00fcrgen", ""], ["Chakraborti", "Anirban", ""]]}, {"id": "2009.13076", "submitter": "Md Nurujjaman Ph D", "authors": "Ajit Mahata, Anish rai, Om Prakash, Md Nurujjaman", "title": "Modeling and analysis of the effect of COVID-19 on the stock price: V\n  and L-shape recovery", "comments": null, "journal-ref": "Physica A, Volume 574, 15 July 2021, 126008", "doi": "10.1016/j.physa.2021.126008", "report-no": null, "categories": "q-fin.ST nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of the COVID-19 pandemic, a new and novel risk factor, leads to\nthe stock price crash due to the investors' rapid and synchronous sell-off.\nHowever, within a short period, the quality sectors start recovering from the\nbottom. A stock price model has been developed during such crises based on the\nnet-fund-flow ($\\Psi_t$) due to institutional investors, and financial\nantifragility ($\\phi$) of a company. We assume that during the crash, the stock\nprice fall is independent of the $\\phi$. We study the effects of shock lengths\nand $\\phi$ on the stock price during the crises period using the $\\Psi_t$\nobtained from synthetic and real fund flow data. We observed that the\npossibility of recovery of stock with $\\phi>0$, termed as quality stock,\ndecreases with an increase in shock-length beyond a specific period. A quality\nstock with higher $\\phi$ shows V-shape recovery and outperform others. The\nshock length and recovery period of quality stock are almost equal that is seen\nin the Indian market. Financially stressed stocks, i.e., the stocks with\n$\\phi<0$, show L-shape recovery during the pandemic. The stock data and model\nanalysis shows that the investors, in uncertainty like COVID-19, invest in\nquality stocks to restructure their portfolio to reduce the risk. The study may\nhelp the investors to make the right investment decision during a crisis.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 04:55:34 GMT"}, {"version": "v2", "created": "Wed, 14 Oct 2020 04:46:02 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 06:14:17 GMT"}], "update_date": "2021-04-16", "authors_parsed": [["Mahata", "Ajit", ""], ["rai", "Anish", ""], ["Prakash", "Om", ""], ["Nurujjaman", "Md", ""]]}, {"id": "2009.13215", "submitter": "Wolfgang Karl H\\\"ardle", "authors": "Xiu Xu, Andrija Mihoci, Wolfgang Karl H\\\"ardle", "title": "lCARE -- localizing Conditional AutoRegressive Expectiles", "comments": null, "journal-ref": "Journal of Empirical Finance, Volume 48, September 2018, Pages\n  198-220", "doi": "10.1016/j.jempfin.2018.06.006", "report-no": null, "categories": "q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We account for time-varying parameters in the conditional expectile-based\nvalue at risk (EVaR) model. The EVaR downside risk is more sensitive to the\nmagnitude of portfolio losses compared to the quantile-based value at risk\n(QVaR). Rather than fitting the expectile models over ad-hoc fixed data\nwindows, this study focuses on parameter instability of tail risk dynamics by\nutilising a local parametric approach. Our framework yields a data-driven\noptimal interval length at each time point by a sequential test. Empirical\nevidence at three stock markets from 2005-2016 shows that the selected lengths\naccount for approximately 3-6 months of daily observations. This method\nperforms favorable compared to the models with one-year fixed intervals, as\nwell as quantile based candidates while employing a time invariant portfolio\nprotection (TIPP) strategy for the DAX, FTSE 100 and S&P 500 portfolios. The\ntail risk measure implied by our model finally provides valuable insights for\nasset allocation and portfolio insurance.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 11:02:54 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Xu", "Xiu", ""], ["Mihoci", "Andrija", ""], ["H\u00e4rdle", "Wolfgang Karl", ""]]}, {"id": "2009.13390", "submitter": "Raymond Ka-Kay Pang", "authors": "Raymond Ka-Kay Pang, Oscar Granados, Harsh Chhajer and Erika Fille\n  Legara", "title": "An analysis of network filtering methods to sovereign bond yields during\n  COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the impact of the COVID-19 pandemic on sovereign\nbond yields. We consider the temporal changes from financial correlations using\nnetwork filtering methods. These methods consider a subset of links within the\ncorrelation matrix, which gives rise to a network structure. We use sovereign\nbond yield data from 17 European countries between the 2010 and 2020 period. We\nfind the mean correlation to decrease across all filtering methods during the\nCOVID-19 period. We also observe a distinctive trend between filtering methods\nunder multiple network centrality measures. We then relate the significance of\neconomic and health variables towards filtered networks within the COVID-19\nperiod. Under an exponential random graph model, we are able to identify key\nrelations between economic groups across different filtering methods.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 15:10:16 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2021 12:27:27 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Pang", "Raymond Ka-Kay", ""], ["Granados", "Oscar", ""], ["Chhajer", "Harsh", ""], ["Legara", "Erika Fille", ""]]}, {"id": "2009.13595", "submitter": "Kasun Chandrarathna", "authors": "Kasun Chandrarathna, Arman Edalati, AhmadReza Fourozan tabar", "title": "Forecasting Short-term load using Econometrics time series model with\n  T-student Distribution", "comments": "6 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": "e-ISSN:2582-5208", "categories": "q-fin.ST cs.SY eess.SY stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By significant improvements in modern electrical systems, planning for unit\ncommitment and power dispatching of them are two big concerns between the\nresearchers. Short-term load forecasting plays a significant role in planning\nand dispatching them. In recent years, numerous works have been done on\nShort-term load forecasting. Having an accurate model for predicting the load\ncan be beneficial for optimizing the electrical sources and protecting energy.\nSeveral models such as Artificial Intelligence and Statistics model have been\nused to improve the accuracy of load forecasting. Among the statistics models,\ntime series models show a great performance. In this paper, an Autoregressive\nintegrated moving average (SARIMA) - generalized autoregressive conditional\nheteroskedasticity (GARCH) model as a powerful tool for modeling the\nconditional mean and volatility of time series with the T-student Distribution\nis used to forecast electric load in short period of time. The attained model\nis compared with the ARIMA model with Normal Distribution. Finally, the\neffectiveness of the proposed approach is validated by applying real electric\nload data from the Electric Reliability Council of Texas (ERCOT). KEYWORDS:\nElectricity load, Forecasting, Econometrics Time Series Forecasting, SARIMA\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2020 19:33:33 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Chandrarathna", "Kasun", ""], ["Edalati", "Arman", ""], ["tabar", "AhmadReza Fourozan", ""]]}, {"id": "2009.14561", "submitter": "Aurelio F. Bariviera", "authors": "Nektarios Aslanidis, Aurelio F. Bariviera, Alejandro Perez-Laborda", "title": "Are cryptocurrencies becoming more interconnected?", "comments": "15 pages, 5 figures, 5 tables, supplementary material included", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the dynamic market linkages among cryptocurrencies during\nAugust 2015 - July 2020 and finds a substantial increase in market linkages for\nboth returns and volatilities. We use different methodologies to check the\ndifferent aspects of market linkages. Financial and regulatory implications are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2020 11:04:56 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Aslanidis", "Nektarios", ""], ["Bariviera", "Aurelio F.", ""], ["Perez-Laborda", "Alejandro", ""]]}]