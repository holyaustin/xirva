[{"id": "1005.0051", "submitter": "Ivan Kitov O.", "authors": "Ivan O. Kitov, Oleg I. Kitov", "title": "Crude oil and motor fuel: Fair price revisited", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In April 2009, we introduced a model representing the evolution of motor fuel\nprice (a subcategory of the consumer price index of transportation) relative to\nthe overall CPI as a linear function of time. Under our framework, all price\ndeviations from the linear trend are transient and the price must promptly\nreturn to the trend. Specifically, the model predicted that \"the price for\nmotor fuel in the US will also grow by 50% by the end of 2009. Oil price is\nexpected to rise by ~50% as well, from its current value of ~$50 per barrel\".\nThe behavior of actual price has shown that this prediction is accurate in both\namplitude and trajectory shape. Hence, one can conclude that the concept of\nprice decomposition into a short-term (oscillating) and long-term (linear\ntrend) components is valid. According to the model, the price of motor fuel and\ncrude oil will be falling to the level of $30 per barrel during the next 5 to 8\nyears.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2010 07:11:32 GMT"}], "update_date": "2010-05-04", "authors_parsed": [["Kitov", "Ivan O.", ""], ["Kitov", "Oleg I.", ""]]}, {"id": "1005.0182", "submitter": "Marco Bartolozzi Dr", "authors": "Marco Bartolozzi", "title": "A Multi Agent Model for the Limit Order Book Dynamics", "comments": "20 pages, 11 figures, in press European Physical Journal B (EPJB)", "journal-ref": null, "doi": "10.1140/epjb/e2010-10406-4", "report-no": null, "categories": "q-fin.TR q-fin.CP q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present work we introduce a novel multi-agent model with the aim to\nreproduce the dynamics of a double auction market at microscopic time scale\nthrough a faithful simulation of the matching mechanics in the limit order\nbook. The agents follow a noise decision making process where their actions are\nrelated to a stochastic variable, \"the market sentiment\", which we define as a\nmixture of public and private information. The model, despite making just few\nbasic assumptions over the trading strategies of the agents, is able to\nreproduce several empirical features of the high-frequency dynamics of the\nmarket microstructure not only related to the price movements but also to the\ndeposition of the orders in the book.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2010 03:52:52 GMT"}, {"version": "v2", "created": "Thu, 28 Oct 2010 14:01:35 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Bartolozzi", "Marco", ""]]}, {"id": "1005.0378", "submitter": "Ingve Simonsen", "authors": "Emeric Balogh, Ingve Simonsen, Balint Zs. Nagy, and Zoltan Neda", "title": "Persistent collective trend in stock markets", "comments": "LaTeX 9 pages, 7 figures", "journal-ref": "Phys. Rev. E 82, 066113 (2010)", "doi": "10.1103/PhysRevE.82.066113", "report-no": null, "categories": "q-fin.ST physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical evidence is given for a significant difference in the collective\ntrend of the share prices during the stock index rising and falling periods.\nData on the Dow Jones Industrial Average and its stock components are studied\nbetween 1991 and 2008. Pearson-type correlations are computed between the\nstocks and averaged over stock-pairs and time. The results indicate a general\ntrend: whenever the stock index is falling the stock prices are changing in a\nmore correlated manner than in case the stock index is ascending. A thorough\nstatistical analysis of the data shows that the observed difference is\nsignificant, suggesting a constant-fear factor among stockholders.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2010 19:39:14 GMT"}], "update_date": "2011-06-06", "authors_parsed": [["Balogh", "Emeric", ""], ["Simonsen", "Ingve", ""], ["Nagy", "Balint Zs.", ""], ["Neda", "Zoltan", ""]]}, {"id": "1005.0728", "submitter": "R. Liptser", "authors": "V. Abramov, F. Klebaner, R. Liptser", "title": "The Euler-Maruyama approximations for the CEV model", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR q-fin.ST", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The CEV model is given by the stochastic differential equation\n$X_t=X_0+\\int_0^t\\mu X_sds+\\int_0^t\\sigma (X^+_s)^pdW_s$, $\\frac{1}{2}\\le p<1$.\nIt features a non-Lipschitz diffusion coefficient and gets absorbed at zero\nwith a positive probability. We show the weak convergence of Euler-Maruyama\napproximations $X_t^n$ to the process $X_t$, $0\\le t\\le T$, in the Skorokhod\nmetric. We give a new approximation by continuous processes which allows to\nrelax some technical conditions in the proof of weak convergence in \\cite{HZa}\ndone in terms of discrete time martingale problem. We calculate ruin\nprobabilities as an example of such approximation. We establish that the ruin\nprobability evaluated by simulations is not guaranteed to converge to the\ntheoretical one, because the point zero is a discontinuity point of the\nlimiting distribution. To establish such convergence we use the Levy metric,\nand also confirm the convergence numerically. Although the result is given for\nthe specific model, our method works in a more general case of non-Lipschitz\ndiffusion with absorbtion.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2010 12:17:43 GMT"}], "update_date": "2010-05-06", "authors_parsed": [["Abramov", "V.", ""], ["Klebaner", "F.", ""], ["Liptser", "R.", ""]]}, {"id": "1005.0877", "submitter": "Gao-Feng Gu", "authors": "Gao-Feng Gu and Wei-Xing Zhou", "title": "Detrending moving average algorithm for multifractals", "comments": "13 pages, 3 figures, 2 tables. We provide the MATLAB codes for the\n  one-dimensional and two-dimensional MFDMA Algorithms", "journal-ref": "Physical Review E 82, 011136 (2010)", "doi": "10.1103/PhysRevE.82.011136", "report-no": null, "categories": "q-fin.ST physics.comp-ph physics.data-an q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detrending moving average (DMA) algorithm is a widely used technique to\nquantify the long-term correlations of non-stationary time series and the\nlong-range correlations of fractal surfaces, which contains a parameter\n$\\theta$ determining the position of the detrending window. We develop\nmultifractal detrending moving average (MFDMA) algorithms for the analysis of\none-dimensional multifractal measures and higher-dimensional multifractals,\nwhich is a generalization of the DMA method. The performance of the\none-dimensional and two-dimensional MFDMA methods is investigated using\nsynthetic multifractal measures with analytical solutions for backward\n($\\theta=0$), centered ($\\theta=0.5$), and forward ($\\theta=1$) detrending\nwindows. We find that the estimated multifractal scaling exponent $\\tau(q)$ and\nthe singularity spectrum $f(\\alpha)$ are in good agreement with the theoretical\nvalues. In addition, the backward MFDMA method has the best performance, which\nprovides the most accurate estimates of the scaling exponents with lowest error\nbars, while the centered MFDMA method has the worse performance. It is found\nthat the backward MFDMA algorithm also outperforms the multifractal detrended\nfluctuation analysis (MFDFA). The one-dimensional backward MFDMA method is\napplied to analyzing the time series of Shanghai Stock Exchange Composite Index\nand its multifractal nature is confirmed.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2010 02:44:33 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2010 04:15:19 GMT"}], "update_date": "2010-08-03", "authors_parsed": [["Gu", "Gao-Feng", ""], ["Zhou", "Wei-Xing", ""]]}, {"id": "1005.1476", "submitter": "Nataliya  Horbenko", "authors": "Peter Ruckdeschel, Nataliya Horbenko (Fraunhofer ITWM, Department of\n  Financial Mathematics, Dept. of Mathematics, Univerisity of Kaiserslautern)", "title": "Robust Estimators in Generalized Pareto Models", "comments": "26pages, 6 figures", "journal-ref": null, "doi": "10.1080/02331888.2011.628022", "report-no": null, "categories": "q-fin.ST math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with optimally-robust parameter estimation in generalized\nPareto distributions (GPDs). These arise naturally in many situations where one\nis interested in the behavior of extreme events as motivated by the\nPickands-Balkema-de Haan extreme value theorem (PBHT). The application we have\nin mind is calculation of the regulatory capital required by Basel II for a\nbank to cover operational risk. In this context the tail behavior of the\nunderlying distribution is crucial. This is where extreme value theory enters,\nsuggesting to estimate these high quantiles parameterically using, e.g. GPDs.\nRobust statistics in this context offers procedures bounding the influence of\nsingle observations, so provides reliable inference in the presence of moderate\ndeviations from the distributional model assumptions, respectively from the\nmechanisms underlying the PBHT.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2010 09:06:38 GMT"}, {"version": "v2", "created": "Tue, 24 Aug 2010 10:02:25 GMT"}, {"version": "v3", "created": "Mon, 11 Apr 2011 17:59:36 GMT"}, {"version": "v4", "created": "Thu, 21 Apr 2011 08:29:34 GMT"}, {"version": "v5", "created": "Thu, 21 Jul 2011 13:30:11 GMT"}, {"version": "v6", "created": "Thu, 29 Sep 2011 14:55:20 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Ruckdeschel", "Peter", "", "Fraunhofer ITWM, Department of\n  Financial Mathematics, Dept. of Mathematics, Univerisity of Kaiserslautern"], ["Horbenko", "Nataliya", "", "Fraunhofer ITWM, Department of\n  Financial Mathematics, Dept. of Mathematics, Univerisity of Kaiserslautern"]]}, {"id": "1005.1760", "submitter": "Schehr Gregory", "authors": "Gleb Oshanin, Gregory Schehr", "title": "Two stock options at the races: Black-Scholes forecasts", "comments": "16 pages, 5 figures. Revised version: references have been added,\n  figure 4 has been modified. Accepted version", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.PR q-fin.GN q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose one buys two very similar stocks and is curious about how much, after\nsome time T, one of them will contribute to the overall asset, expecting, of\ncourse, that it should be around 1/2 of the sum. Here we examine this question\nwithin the classical Black and Scholes (BS) model, focusing on the evolution of\nthe probability density function P(w) of a random variable w =\na_T^{(1)}/(a_T^{(1)} + a_T^{(2)}) where a_T^{(1)} and a_T^{(2)} are the values\nof two (either European- or the Asian-style) options produced by two absolutely\nidentical BS stochastic equations. We show that within the realm of the BS\nmodel the behavior of P(w) is surprisingly different from common-sense-based\nexpectations. For the European-style options P(w) always undergoes a\ntransition, (when T approaches a certain threshold value), from a unimodal to a\nbimodal form with the most probable values being close to 0 and 1, and,\nstrikingly, w =1/2 being the least probable value. This signifies that the\nsymmetry between two options spontaneously breaks and just one of them\ncompletely dominates the sum. For path-dependent Asian-style options we observe\nthe same anomalous behavior, but only for a certain range of parameters.\nOutside of this range, P(w) is always a bell-shaped function with a maximum at\nw = 1/2.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2010 08:51:57 GMT"}, {"version": "v2", "created": "Mon, 30 May 2011 19:46:01 GMT"}], "update_date": "2011-05-31", "authors_parsed": [["Oshanin", "Gleb", ""], ["Schehr", "Gregory", ""]]}, {"id": "1005.1862", "submitter": "Xinghua Zheng", "authors": "Xinghua Zheng, Yingying Li", "title": "On the estimation of integrated covariance matrices of high dimensional\n  diffusion processes", "comments": "Published in at http://dx.doi.org/10.1214/11-AOS939 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 6, 3121-3151", "doi": "10.1214/11-AOS939", "report-no": "IMS-AOS-AOS939", "categories": "stat.ME math.PR math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the estimation of integrated covariance (ICV) matrices of high\ndimensional diffusion processes based on high frequency observations. We start\nby studying the most commonly used estimator, the realized covariance (RCV)\nmatrix. We show that in the high dimensional case when the dimension $p$ and\nthe observation frequency $n$ grow in the same rate, the limiting spectral\ndistribution (LSD) of RCV depends on the covolatility process not only through\nthe targeting ICV, but also on how the covolatility process varies in time. We\nestablish a Mar\\v{c}enko--Pastur type theorem for weighted sample covariance\nmatrices, based on which we obtain a Mar\\v{c}enko--Pastur type theorem for RCV\nfor a class $\\mathcal{C}$ of diffusion processes. The results explicitly\ndemonstrate how the time variability of the covolatility process affects the\nLSD of RCV. We further propose an alternative estimator, the time-variation\nadjusted realized covariance (TVARCV) matrix. We show that for processes in\nclass $\\mathcal {C}$, the TVARCV possesses the desirable property that its LSD\ndepends solely on that of the targeting ICV through the Mar\\v{c}enko--Pastur\nequation, and hence, in particular, the TVARCV can be used to recover the\nempirical spectral distribution of the ICV by using existing algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2010 15:29:29 GMT"}, {"version": "v2", "created": "Sat, 19 Feb 2011 16:55:53 GMT"}, {"version": "v3", "created": "Mon, 10 Oct 2011 13:21:02 GMT"}, {"version": "v4", "created": "Tue, 13 Mar 2012 08:38:31 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Zheng", "Xinghua", ""], ["Li", "Yingying", ""]]}, {"id": "1005.2044", "submitter": "Piotr Kosinski", "authors": "Katarzyna Bolonek-Lason and Piotr Kosinski", "title": "Note on log-periodic description of 2008 financial crash", "comments": "13 pages, 7 figures; references and few comments added;", "journal-ref": null, "doi": "10.1016/j.physa.2011.06.060", "report-no": null, "categories": "q-fin.ST physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the financial crash in 2008 for different financial markets from\nthe point of view of log-periodic function model. In particular, we consider\nDow Jones index, DAX index and Hang Seng index. We shortly discuss the possible\nrelation of the theory of critical phenomena in physics to financial markets.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2010 10:55:02 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2010 13:51:11 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Bolonek-Lason", "Katarzyna", ""], ["Kosinski", "Piotr", ""]]}, {"id": "1005.5021", "submitter": "Thomas Conlon", "authors": "Thomas Conlon, Heather J. Ruskin, Martin Crane", "title": "Random Matrix Theory and Fund of Funds Portfolio Optimisation", "comments": "17 Pages", "journal-ref": "Physica A 382(2), (2007) 565-576", "doi": "10.1016/j.physa.2007.04.039", "report-no": null, "categories": "q-fin.ST q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proprietary nature of Hedge Fund investing means that it is common\npractise for managers to release minimal information about their returns. The\nconstruction of a Fund of Hedge Funds portfolio requires a correlation matrix\nwhich often has to be estimated using a relatively small sample of monthly\nreturns data which induces noise. In this paper random matrix theory (RMT) is\napplied to a cross-correlation matrix C, constructed using hedge fund returns\ndata. The analysis reveals a number of eigenvalues that deviate from the\nspectrum suggested by RMT. The components of the deviating eigenvectors are\nfound to correspond to distinct groups of strategies that are applied by hedge\nfund managers. The Inverse Participation ratio is used to quantify the number\nof components that participate in each eigenvector. Finally, the correlation\nmatrix is cleaned by separating the noisy part from the non-noisy part of C.\nThis technique is found to greatly reduce the difference between the predicted\nand realised risk of a portfolio, leading to an improved risk profile for a\nfund of hedge funds.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2010 10:20:02 GMT"}], "update_date": "2010-05-28", "authors_parsed": [["Conlon", "Thomas", ""], ["Ruskin", "Heather J.", ""], ["Crane", "Martin", ""]]}, {"id": "1005.5082", "submitter": "Yu-Min Yen", "authors": "Yu-Min Yen", "title": "A Note on Sparse Minimum Variance Portfolios and Coordinate-Wise Descent\n  Algorithms", "comments": "This paper has been withdrawn by the author due to a crucial sign\n  error in equation 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short report, we discuss how coordinate-wise descent algorithms can\nbe used to solve minimum variance portfolio (MVP) problems in which the\nportfolio weights are constrained by $l_{q}$ norms, where $1\\leq q \\leq 2$. A\nportfolio which weights are regularised by such norms is called a sparse\nportfolio (Brodie et al.), since these constraints facilitate sparsity (zero\ncomponents) of the weight vector. We first consider a case when the portfolio\nweights are regularised by a weighted $l_{1}$ and squared $l_{2}$ norm. Then\ntwo benchmark data sets (Fama and French 48 industries and 100 size and BM\nratio portfolios) are used to examine performances of the sparse portfolios.\nWhen the sample size is not relatively large to the number of assets, sparse\nportfolios tend to have lower out-of-sample portfolio variances, turnover\nrates, active assets, short-sale positions, but higher Sharpe ratios than the\nunregularised MVP. We then show some possible extensions; particularly we\nderive an efficient algorithm for solving an MVP problem in which assets are\nallowed to be chosen grouply.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2010 14:42:36 GMT"}, {"version": "v2", "created": "Fri, 28 May 2010 15:59:38 GMT"}, {"version": "v3", "created": "Mon, 16 Sep 2013 10:32:53 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Yen", "Yu-Min", ""]]}, {"id": "1005.5538", "submitter": "Florian Steiger", "authors": "Florian Steiger", "title": "The Impact of Credit Risk and Implied Volatility on Stock Returns", "comments": "JEL Classification: G10, G12, G17", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the possibility of using derivative-implied risk premia\nto explain stock returns. The rapid development of derivative markets has led\nto the possibility of trading various kinds of risks, such as credit and\ninterest rate risk, separately from each other. This paper uses credit default\nswaps and equity options to determine risk premia which are then used to form\nportfolios that are regressed against the returns of stock portfolios. It turns\nout that both, credit risk and implied volatility, have high explanatory power\nin regard to stock returns. Especially the returns of distressed stocks are\nhighly dependent on credit risk fluctuations. This finding leads to practical\nimplications, such as cross-hedging opportunities between equity and credit\ninstruments and potentially allows forecasting stock returns based on movements\nin the credit market.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2010 15:05:01 GMT"}], "update_date": "2010-06-01", "authors_parsed": [["Steiger", "Florian", ""]]}, {"id": "1005.5675", "submitter": "Ryan Woodard", "authors": "Didier Sornette, Ryan Woodard, Maxim Fedorovsky, Stefan Reimann,\n  Hilary Woodard, Wei-Xing Zhou (The Financial Crisis Observatory)", "title": "The Financial Bubble Experiment: Advanced Diagnostics and Forecasts of\n  Bubble Terminations Volume II-Master Document", "comments": "Uploaded new version with names of 7 assets and link to original\n  assets document, where checksum can be verified", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the second installment of the Financial Bubble Experiment. Here we\nprovide the digital fingerprint of an electronic document in which we identify\n7 bubbles in 7 different global assets; for 4 of these assets, we present\nwindows of dates of the most likely ending time of each bubble. We will provide\nthat document of the original analysis on 1 November 2010.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2010 12:39:20 GMT"}, {"version": "v2", "created": "Tue, 2 Nov 2010 21:03:55 GMT"}], "update_date": "2010-11-04", "authors_parsed": [["Sornette", "Didier", "", "The Financial Crisis Observatory"], ["Woodard", "Ryan", "", "The Financial Crisis Observatory"], ["Fedorovsky", "Maxim", "", "The Financial Crisis Observatory"], ["Reimann", "Stefan", "", "The Financial Crisis Observatory"], ["Woodard", "Hilary", "", "The Financial Crisis Observatory"], ["Zhou", "Wei-Xing", "", "The Financial Crisis Observatory"]]}]