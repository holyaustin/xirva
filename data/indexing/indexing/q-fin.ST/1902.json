[{"id": "1902.00786", "submitter": "Joseph Attia", "authors": "Joseph Attia", "title": "The Applications of Graph Theory to Investing", "comments": "53 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.DM q-fin.MF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  How can graph theory be applied to investing in the stock market? The answer\nmay help investors realize the true risks of their investments, help prevent\nrecessions like that of 2008, and increase financial literacy amongst students.\nUsing several original Python programs, we take a correlation matrix with\ncorrelations between the stock prices and then transform that into a graphable\nbinary adjacency matrix. From this graph, we take a graph in which each edge\nrepresents weak correlations between two stocks. Finding the largest complete\ngraph will produce a diversified portfolio. Numerous trials have shown that\ndiversified portfolios consistently outperform the market during times of\neconomic stability, but undiversified portfolios prove to be riskier and more\nunpredictable, either producing huge profits or even larger losses.\nFurthermore, once deciding among which stocks our portfolio would consist of,\nhow do we know when to invest in each stock to maximize profits? Can taking\nstock price data and shifting values help predict how a stock will perform\ntoday if another stock performs a certain way n days prior? It was found that\nthis method of predicting the optimal time to investment failed to improve\nreturns when based solely on correlations. Although a trial with random stocks\nwith varied correlations produced more profits than continuously investing.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2019 20:39:54 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Attia", "Joseph", ""]]}, {"id": "1902.00924", "submitter": "Aleksejus Kononovicius dr.", "authors": "Aleksejus Kononovicius, Vygintas Gontis", "title": "Approximation of the first passage time distribution for the birth-death\n  processes", "comments": "12 pages, 6 figures", "journal-ref": "Journal of Statistical Mechanics 2019: 073402 (2019)", "doi": "10.1088/1742-5468/ab2709", "report-no": null, "categories": "q-fin.ST physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general method to obtain approximation of the first passage time\ndistribution for the birth-death processes. We rely on the general properties\nof birth-death processes, Keilson's theorem and the concept of Riemann sum to\nobtain closed-form expressions. We apply the method to the three selected\nbirth-death processes and the sophisticated order-book model exhibiting\nlong-range memory. We discuss how our approach contributes to the competition\nbetween spurious and true long-range memory models.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2019 16:44:50 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Kononovicius", "Aleksejus", ""], ["Gontis", "Vygintas", ""]]}, {"id": "1902.01802", "submitter": "Adam Rej", "authors": "Adam Rej, Philip Seager and Jean-Philippe Bouchaud", "title": "How should you discount your backtest PnL?", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-sample overfitting is a drawback of any backtest-based investment\nstrategy. It is thus of paramount importance to have an understanding of why\nand how the in-sample overfitting occurs. In this article we propose a simple\nframework that allows one to model and quantify in-sample PnL overfitting. This\nallows us to compute the factor appropriate for discounting PnLs of in-sample\ninvestment strategies.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2019 17:21:45 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Rej", "Adam", ""], ["Seager", "Philip", ""], ["Bouchaud", "Jean-Philippe", ""]]}, {"id": "1902.02040", "submitter": "Kei Katahira", "authors": "Kei Katahira, Yu Chen, Gaku Hashimoto, Hiroshi Okuda", "title": "Development of an agent-based speculation game for higher\n  reproducibility of financial stylized facts", "comments": "37 pages, 15 figures", "journal-ref": null, "doi": "10.1016/j.physa.2019.04.157", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous reproduction of all financial stylized facts is so difficult\nthat most existing stochastic process-based and agent-based models are unable\nto achieve the goal. In this study, by extending the decision-making structure\nof Minority Game, we propose a novel agent-based model called \"Speculation\nGame,\" for a better reproducibility of the stylized facts. The new model has\nthree distinct characteristics comparing with preceding agent-based adaptive\nmodels for the financial market: the enabling of nonuniform holding and idling\nperiods, the inclusion of magnitude information of price change in history, and\nthe implementation of a cognitive world for the evaluation of investment\nstrategies with capital gains and losses. With these features, Speculation Game\nsucceeds in reproducing 10 out of the currently well studied 11 stylized facts\nunder a single parameter setting.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2019 06:24:47 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Katahira", "Kei", ""], ["Chen", "Yu", ""], ["Hashimoto", "Gaku", ""], ["Okuda", "Hiroshi", ""]]}, {"id": "1902.03125", "submitter": "Chariton Chalvatzis", "authors": "Chariton Chalvatzis, Dimitrios Hristu-Varsakelis", "title": "High-performance stock index trading: making effective use of a deep\n  LSTM neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deep long short-term memory (LSTM)-based neural network for\npredicting asset prices, together with a successful trading strategy for\ngenerating profits based on the model's predictions. Our work is motivated by\nthe fact that the effectiveness of any prediction model is inherently coupled\nto the trading strategy it is used with, and vise versa. This highlights the\ndifficulty in developing models and strategies which are jointly optimal, but\nalso points to avenues of investigation which are broader than prevailing\napproaches. Our LSTM model is structurally simple and generates predictions\nbased on price observations over a modest number of past trading days. The\nmodel's architecture is tuned to promote profitability, as opposed to accuracy,\nunder a strategy that does not trade simply based on whether the price is\npredicted to rise or fall, but rather takes advantage of the distribution of\npredicted returns, and the fact that a prediction's position within that\ndistribution carries useful information about the expected profitability of a\ntrade. The proposed model and trading strategy were tested on the S&P 500, Dow\nJones Industrial Average (DJIA), NASDAQ and Russel 2000 stock indices, and\nachieved cumulative returns of 340%, 185%, 371% and 360%, respectively, over\n2010-2018, far outperforming the benchmark buy-and-hold strategy as well as\nother recent efforts.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2019 09:08:07 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 07:51:55 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Chalvatzis", "Chariton", ""], ["Hristu-Varsakelis", "Dimitrios", ""]]}, {"id": "1902.03350", "submitter": "Nicholas James Mr", "authors": "Nick James, Roman Marchant, Richard Gerlach, Sally Cripps", "title": "Bayesian Nonparametric Adaptive Spectral Density Estimation for\n  Financial Time Series", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrimination between non-stationarity and long-range dependency is a\ndifficult and long-standing issue in modelling financial time series. This\npaper uses an adaptive spectral technique which jointly models the\nnon-stationarity and dependency of financial time series in a non-parametric\nfashion assuming that the time series consists of a finite, but unknown number,\nof locally stationary processes, the locations of which are also unknown. The\nmodel allows a non-parametric estimate of the dependency structure by modelling\nthe auto-covariance function in the spectral domain. All our estimates are made\nwithin a Bayesian framework where we use aReversible Jump Markov Chain Monte\nCarlo algorithm for inference. We study the frequentist properties of our\nestimates via a simulation study, and present a novel way of generating time\nseries data from a nonparametric spectrum. Results indicate that our techniques\nperform well across a range of data generating processes. We apply our method\nto a number of real examples and our results indicate that several financial\ntime series exhibit both long-range dependency and non-stationarity.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 01:58:48 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["James", "Nick", ""], ["Marchant", "Roman", ""], ["Gerlach", "Richard", ""], ["Cripps", "Sally", ""]]}, {"id": "1902.03714", "submitter": "Achraf Bahamou", "authors": "Achraf Bahamou, Maud Doumergue, Philippe Donnat", "title": "Hawkes processes for credit indices time series analysis: How random are\n  trades arrival times?", "comments": "ITISE 2018 International Conference on Time Series and Forecasting\n  accepted paper", "journal-ref": "Proceedings - International Conference on Time Series and\n  Forecasting, ITISE 2018. Granada: University of Granada, pp. 1178-1192", "doi": null, "report-no": null, "categories": "stat.AP q-fin.ST q-fin.TR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Targeting a better understanding of credit market dynamics, the authors have\nstudied a stochastic model named the Hawkes process. Describing trades arrival\ntimes, this kind of model allows for the capture of self-excitement and mutual\ninteractions phenomena. The authors propose here a simple yet conclusive method\nfor fitting multidimensional Hawkes processes with exponential kernels, based\non a maximum likelihood non-convex optimization. The method was successfully\ntested on simulated data, then used on new publicly available real trading data\nfor three European credit indices, thus enabling quantification of\nself-excitement as well as volume impacts or cross indices influences.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 03:39:20 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Bahamou", "Achraf", ""], ["Doumergue", "Maud", ""], ["Donnat", "Philippe", ""]]}, {"id": "1902.03797", "submitter": "Shintaro Mori", "authors": "Masato Hisakado and Shintaro Mori", "title": "Phase transition in the Bayesian estimation of the default portfolio", "comments": "24 pages, 9 figures", "journal-ref": "Physica A: Statistical Mechanics and its Applications Volume 544,\n  15 April 2020, 123480", "doi": "10.1016/j.physa.2019.123480", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The probability of default (PD) estimation is an important process for\nfinancial institutions. The difficulty of the estimation depends on the\ncorrelations between borrowers. In this paper, we introduce a hierarchical\nBayesian estimation method using the beta binomial distribution and consider a\nmulti-year case with a temporal correlation. A phase transition occurs when the\ntemporal correlation decays by power decay. When the power index is less than\none, the PD estimator does not converge. It is difficult to estimate the PD\nwith limited historical data. Conversely, when the power index is greater than\none, the convergence is the same as that of the binomial distribution. We\nprovide a condition for the estimation of the PD and discuss the universality\nclass of the phase transition. We investigate the empirical default data\nhistory of rating agencies and their Fourier transformations to confirm the\nform of the correlation decay. The power spectrum of the decay history seems to\nbe 1/f, which corresponds to a long memory. But the estimated power index is\nmuch greater than one. If we collect adequate historical data,the parameters\ncan be estimated correctly.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 10:06:05 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 09:37:47 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Hisakado", "Masato", ""], ["Mori", "Shintaro", ""]]}, {"id": "1902.03982", "submitter": "Marco Bottone Dr", "authors": "Marco Bottone and Mauro Bernardi and Lea Petrella", "title": "Unified Bayesian Conditional Autoregressive Risk Measures using the Skew\n  Exponential Power Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Autoregressive Value-at-Risk and Conditional Autoregressive\nExpectile have become two popular approaches for direct measurement of market\nrisk. Since their introduction several improvements both in the Bayesian and in\nthe classical framework have been proposed to better account for asymmetry and\nlocal non-linearity. Here we propose a unified Bayesian Conditional\nAutoregressive Risk Measures approach by using the Skew Exponential Power\ndistribution. Further, we extend the proposed models using a semiparametric\nP-spline approximation answering for a flexible way to consider the presence of\nnon-linearity. To make the statistical inference we adapt the MCMC algorithm\nproposed in Bernardi et al. (2018) to our case. The effectiveness of the whole\napproach is demonstrated using real data on daily return of five stock market\nindices.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 16:41:26 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 09:18:35 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Bottone", "Marco", ""], ["Bernardi", "Mauro", ""], ["Petrella", "Lea", ""]]}, {"id": "1902.04437", "submitter": "Wei-Xing Zhou", "authors": "Hai-Chuan Xu, Gao-Feng Gu and Wei-Xing Zhou (ECUST)", "title": "Direct determination approach for the multifractal detrending moving\n  average analysis", "comments": "12 pages including 8 figures", "journal-ref": "Physical Review E 96 (5), 052201 (2017)", "doi": "10.1103/PhysRevE.96.052201", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the canonical framework, we propose an alternative approach for the\nmultifractal analysis based on the detrending moving average method (MF-DMA).\nWe define a canonical measure such that the multifractal mass exponent\n$\\tau(q)$ is related to the partition function and the multifractal spectrum\n$f(\\alpha)$ can be directly determined. The performances of the direct\ndetermination approach and the traditional approach of the MF-DMA are compared\nbased on three synthetic multifractal and monofractal measures generated from\nthe one-dimensional $p$-model, the two-dimensional $p$-model and the fractional\nBrownian motions. We find that both approaches have comparable performances to\nunveil the fractal and multifractal nature. In other words, without loss of\naccuracy, the multifractal spectrum $f(\\alpha)$ can be directly determined\nusing the new approach with less computation cost. We also apply the new MF-DMA\napproach to the volatility time series of stock prices and confirm the presence\nof multifractality.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2019 12:45:57 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Xu", "Hai-Chuan", "", "ECUST"], ["Gu", "Gao-Feng", "", "ECUST"], ["Zhou", "Wei-Xing", "", "ECUST"]]}, {"id": "1902.05418", "submitter": "Emilio Said", "authors": "Emilio Said (FiQuant, MICS, BNP Paribas), Ahmed Bel Hadj Ayed, Damien\n  Thillou, Jean-Jacques Rabeyrin, Fr\\'ed\\'eric Abergel (FiQuant, MICS)", "title": "Market Impact: A Systematic Study of the High Frequency Options Market", "comments": "arXiv admin note: substantial text overlap with arXiv:1802.08502", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with a fundamental subject that has seldom been addressed in\nrecent years, that of market impact in the options market. Our analysis is\nbased on a proprietary database of metaorders-large orders that are split into\nsmaller pieces before being sent to the market on one of the main Asian\nmarkets. In line with our previous work on the equity market [Said et al.,\n2018], we propose an algorithmic approach to identify metaorders, based on some\nimplied volatility parameters, the at the money forward volatility and at the\nmoney forward skew. In both cases, we obtain results similar to the now well\nunderstood equity market: Square-root law, Fair Pricing Condition and Market\nImpact Dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 10:10:14 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 07:43:34 GMT"}, {"version": "v3", "created": "Wed, 20 Feb 2019 12:23:15 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Said", "Emilio", "", "FiQuant, MICS, BNP Paribas"], ["Ayed", "Ahmed Bel Hadj", "", "FiQuant, MICS"], ["Thillou", "Damien", "", "FiQuant, MICS"], ["Rabeyrin", "Jean-Jacques", "", "FiQuant, MICS"], ["Abergel", "Fr\u00e9d\u00e9ric", "", "FiQuant, MICS"]]}, {"id": "1902.06175", "submitter": "Jason Anquandah", "authors": "Jason S. Anquandah and Leonid V. Bogachev", "title": "Optimal Stopping and Utility in a Simple Model of Unemployment Insurance", "comments": "45 pages, 8 figures", "journal-ref": "Risks, vol. 7 (2019), issue 3, paper #94, pages 1-41; Special\n  Issue \"Applications of Stochastic Optimal Control to Economics and Finance\"", "doi": "10.3390/risks7030094", "report-no": null, "categories": "q-fin.ST math.OC q-fin.MF stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Managing unemployment is one of the key issues in social policies.\nUnemployment insurance schemes are designed to cushion the financial and morale\nblow of loss of job but also to encourage the unemployed to seek new jobs more\npro-actively due to the continuous reduction of benefit payments. In the\npresent paper, a simple model of unemployment insurance is proposed with a\nfocus on optimality of the individual's entry to the scheme. The corresponding\noptimal stopping problem is solved, and its similarity and differences with the\nperpetual American call option are discussed. Beyond a purely financial point\nof view, we argue that in the actuarial context the optimal decisions should\ntake into account other possible preferences through a suitable utility\nfunction. Some examples in this direction are worked out.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2019 23:28:25 GMT"}, {"version": "v2", "created": "Sun, 7 Jul 2019 14:15:05 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 09:24:33 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Anquandah", "Jason S.", ""], ["Bogachev", "Leonid V.", ""]]}, {"id": "1902.06483", "submitter": "Viktor Stojkoski MSc", "authors": "Lasko Basnarkov, Viktor Stojkoski, Zoran Utkovski and Ljupco Kocarev", "title": "Correlation Patterns in Foreign Exchange Markets", "comments": null, "journal-ref": null, "doi": "10.1016/j.physa.2019.04.044", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The value of an asset in a financial market is given in terms of another\nasset known as numeraire. The dynamics of the value is non-stationary and\nhence, to quantify the relationships between different assets, one requires\nconvenient measures such as the means and covariances of the respective log\nreturns. Here, we develop transformation equations for these means and\ncovariances when one changes the numeraire. The results are verified by a\nthorough empirical analysis capturing the dynamics of numerous assets in a\nforeign exchange market. We show that the partial correlations between pairs of\nassets are invariant under the change of the numeraire. This observable\nquantifies the relationship between two assets, while the influence of the rest\nis removed. As such the partial correlations uncover intriguing observations\nwhich may not be easily noticed in the ordinary correlation analysis.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2019 09:53:30 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 13:37:27 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Basnarkov", "Lasko", ""], ["Stojkoski", "Viktor", ""], ["Utkovski", "Zoran", ""], ["Kocarev", "Ljupco", ""]]}, {"id": "1902.08684", "submitter": "Dejan Lavbi\\v{c}", "authors": "Marko Po\\v{z}enel and Dejan Lavbi\\v{c}", "title": "Discovering Language of the Stocks", "comments": "15 pages, 2 figures, 5 tables", "journal-ref": "Frontiers in Artificial Intelligence and Applications - Databases\n  and Information Systems X 315 2019", "doi": "10.3233/978-1-61499-941-6-243", "report-no": null, "categories": "cs.CE q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stock prediction has always been attractive area for researchers and\ninvestors since the financial gains can be substantial. However, stock\nprediction can be a challenging task since stocks are influenced by a multitude\nof factors whose influence vary rapidly through time. This paper proposes a\nnovel approach (Word2Vec) for stock trend prediction combining NLP and Japanese\ncandlesticks. First, we create a simple language of Japanese candlesticks from\nthe source OHLC data. Then, sentences of words are used to train the NLP\nWord2Vec model where training data classification also takes into account\ntrading commissions. Finally, the model is used to predict trading actions. The\nproposed approach was compared to three trading models Buy & Hold, MA and MACD\naccording to the yield achieved. We first evaluated Word2Vec on three shares of\nApple, Microsoft and Coca-Cola where it outperformed the comparative models.\nNext we evaluated Word2Vec on stocks from Russell Top 50 Index where our\nWord2Vec method was also very successful in test phase and only fall behind the\nBuy & Hold method in validation phase. Word2Vec achieved positive results in\nall scenarios while the average yields of MA and MACD were still lower compared\nto Word2Vec.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2019 15:56:51 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Po\u017eenel", "Marko", ""], ["Lavbi\u010d", "Dejan", ""]]}, {"id": "1902.08938", "submitter": "Quanxi Wang", "authors": "Quanxi Wang", "title": "Working Paper: Improved Stock Price Forecasting Algorithm based on\n  Feature-weighed Support Vector Regression by using Grey Correlation Degree", "comments": "22 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the widespread engineering applications ranging from artificial\nintelligence and big data decision-making, originally a lot of tedious\nfinancial data processing, processing and analysis have become more and more\nconvenient and effective. This paper aims to improve the accuracy of stock\nprice forecasting. It improves the support vector machine regression algorithm\nby using grey correlation analysis (GCA) and improves the accuracy of stock\nprediction. This article first divides the factors affecting the stock price\nmovement into behavioral factors and technical factors. The behavioral factors\nmainly include weather indicators and emotional indicators. The technical\nfactors mainly include the daily closing data and the HS 300 Index, and then\nmeasure relation through the method of grey correlation analysis. The\nrelationship between the stock price and its impact factors during the trading\nday, and this relationship is transformed into the characteristic weight of\neach impact factor. The weight of the impact factors of all trading days is\nweighted by the feature weight, and finally the support vector regression (SVR)\nis used. The forecast of the revised stock trading data was compared based on\nthe forecast results of technical indicators (MSE, MAE, SCC, and DS) and\nunmodified transaction data, and it was found that the forecast results were\nsignificantly improved.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2019 13:10:30 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Wang", "Quanxi", ""]]}, {"id": "1902.09205", "submitter": "Manuele Leonelli", "authors": "Chiara Lattanzi and Manuele Leonelli", "title": "A changepoint approach for the identification of financial extreme\n  regimes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference over tails is usually performed by fitting an appropriate limiting\ndistribution over observations that exceed a fixed threshold. However, the\nchoice of such threshold is critical and can affect the inferential results.\nExtreme value mixture models have been defined to estimate the threshold using\nthe full dataset and to give accurate tail estimates. Such models assume that\nthe tail behavior is constant for all observations. However, the extreme\nbehavior of financial returns often changes considerably in time and such\nchanges occur by sudden shocks of the market. Here we extend the extreme value\nmixture model class to formally take into account distributional extreme\nchangepoints, by allowing for the presence of regime-dependent parameters\nmodelling the tail of the distribution. This extension formally uses the full\ndataset to both estimate the thresholds and the extreme changepoint locations,\ngiving uncertainty measures for both quantities. Estimation of functions of\ninterest in extreme value analyses is performed via MCMC algorithms. Our\napproach is evaluated through a series of simulations, applied to real data\nsets and assessed against competing approaches. Evidence demonstrates that the\ninclusion of different extreme regimes outperforms both static and dynamic\ncompeting approaches in financial applications.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 11:45:04 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Lattanzi", "Chiara", ""], ["Leonelli", "Manuele", ""]]}, {"id": "1902.09253", "submitter": "Tetsuya Takaishi", "authors": "Tetsuya Takaishi and Takanori Adachi", "title": "Market efficiency, liquidity, and multifractality of Bitcoin: A dynamic\n  study", "comments": "10 pages, 6 figures", "journal-ref": "Asia-Pacific Financial Markets 27 (2020) 145-154", "doi": "10.1007/s10690-019-09286-0", "report-no": null, "categories": "q-fin.ST physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter investigates the dynamic relationship between market efficiency,\nliquidity, and multifractality of Bitcoin. We find that before 2013 liquidity\nis low and the Hurst exponent is less than 0.5, indicating that the Bitcoin\ntime series is anti-persistent. After 2013, as liquidity increased, the Hurst\nexponent rose to approximately 0.5, improving market efficiency. For several\nperiods, however, the Hurst exponent was found to be significantly less than\n0.5, making the time series anti-persistent during those periods. We also\ninvestigate the multifractal degree of the Bitcoin time series using the\ngeneralized Hurst exponent and find that the multifractal degree is related to\nmarket efficiency in a non-linear manner.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 13:27:03 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Takaishi", "Tetsuya", ""], ["Adachi", "Takanori", ""]]}, {"id": "1902.09425", "submitter": "Alexander Jurisch", "authors": "Alexander Jurisch", "title": "Statistical mechanics and time-series analysis by L\\'evy-parameters with\n  the possibility of real-time application", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method that relates the truncated cumulant-function of the\nfourth order with the L\\'evian cumulant-function. This gives us explicit\nformulas for the L\\'evy-parameters, which allow a real-time analysis of the\nstate of a random-motion. Cumbersome procedures like maximum-likelihood or\nleast-square methods are unnecessary. Furthermore, we treat the L\\'evy-system\nin terms of statistical mechanics and work out it's thermodynamic properties.\nThis also includes a discussion of the fractal nature of relativistic\ncorrections. As examples for a time-series analysis, we apply our results on\nthe time-series of the German DAX and the American S\\&P-500\\,.\n", "versions": [{"version": "v1", "created": "Mon, 25 Feb 2019 16:41:22 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Jurisch", "Alexander", ""]]}, {"id": "1902.10044", "submitter": "Marcin Pitera", "authors": "Tomasz R. Bielecki, Igor Cialenco, Marcin Pitera, Thorsten Schmidt", "title": "Fair Estimation of Capital Risk Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.PR q-fin.MF q-fin.PM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a novel methodology for estimation of risk capital\nallocation. The methodology is rooted in the theory of risk measures. We work\nwithin a general, but tractable class of law-invariant coherent risk measures,\nwith a particular focus on expected shortfall. We introduce the concept of fair\ncapital allocations and provide explicit formulae for fair capital allocations\nin case when the constituents of the risky portfolio are jointly normally\ndistributed. The main focus of the paper is on the problem of approximating\nfair portfolio allocations in the case of not fully known law of the portfolio\nconstituents. We define and study the concepts of fair allocation estimators\nand asymptotically fair allocation estimators. A substantial part of our study\nis devoted to the problem of estimating fair risk allocations for expected\nshortfall. We study this problem under normality as well as in a nonparametric\nsetup. We derive several estimators, and prove their fairness and/or asymptotic\nfairness. Last, but not least, we propose two backtesting methodologies that\nare oriented at assessing the performance of the allocation estimation\nprocedure. The paper closes with a substantial numerical study of the subject.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2019 16:41:06 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 22:27:01 GMT"}], "update_date": "2019-11-25", "authors_parsed": [["Bielecki", "Tomasz R.", ""], ["Cialenco", "Igor", ""], ["Pitera", "Marcin", ""], ["Schmidt", "Thorsten", ""]]}, {"id": "1902.10500", "submitter": "Karina Arias-Calluari Miss", "authors": "Alonso-Marroquin Fernando, Arias-Calluari Karina, Harre Michael,\n  Najafi Morteza N. and Herrmann Hans J", "title": "Q-Gaussian diffusion in stock markets", "comments": "Field of study: Condensed-matter physics, 5 pages and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the Standard & Poor's 500 stock market index from the last 22\nyears. The probability density function of price returns exhibits two\nwell-distinguished regimes with self-similar structure: the first one displays\nstrong super-diffusion together with short-time correlations, and the second\none corresponds to weak super-diffusion with weak time correlations. Both\nregimes are well-described by q-Gaussian distributions. The porous media\nequation is used to derive the governing equation for these regimes, and the\nBlack-Scholes diffusion coefficient is explicitly obtained from the governing\nequation.\n", "versions": [{"version": "v1", "created": "Mon, 11 Feb 2019 05:16:26 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Fernando", "Alonso-Marroquin", ""], ["Karina", "Arias-Calluari", ""], ["Michael", "Harre", ""], ["N.", "Najafi Morteza", ""], ["J", "Herrmann Hans", ""]]}, {"id": "1902.10877", "submitter": "Sangyeon Kim", "authors": "Sangyeon Kim, Myungjoo Kang", "title": "Financial series prediction using Attention LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial time series prediction, especially with machine learning\ntechniques, is an extensive field of study. In recent times, deep learning\nmethods (especially time series analysis) have performed outstandingly for\nvarious industrial problems, with better prediction than machine learning\nmethods. Moreover, many researchers have used deep learning methods to predict\nfinancial time series with various models in recent years. In this paper, we\nwill compare various deep learning models, such as multilayer perceptron (MLP),\none-dimensional convolutional neural networks (1D CNN), stacked long short-term\nmemory (stacked LSTM), attention networks, and weighted attention networks for\nfinancial time series prediction. In particular, attention LSTM is not only\nused for prediction, but also for visualizing intermediate outputs to analyze\nthe reason of prediction; therefore, we will show an example for understanding\nthe model prediction intuitively with attention vectors. In addition, we focus\non time and factors, which lead to an easy understanding of why certain trends\nare predicted when accessing a given time series table. We also modify the loss\nfunctions of the attention models with weighted categorical cross entropy; our\nproposed model produces a 0.76 hit ratio, which is superior to those of other\nmethods for predicting the trends of the KOSPI 200.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 03:09:25 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Kim", "Sangyeon", ""], ["Kang", "Myungjoo", ""]]}, {"id": "1902.10948", "submitter": "Jinho Lee", "authors": "Jinho Lee, Raehyun Kim, Yookyung Koh, and Jaewoo Kang", "title": "Global Stock Market Prediction Based on Stock Chart Images Using Deep\n  Q-Network", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": "10.1109/ACCESS.2019.2953542", "report-no": null, "categories": "q-fin.GN cs.CE q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We applied Deep Q-Network with a Convolutional Neural Network function\napproximator, which takes stock chart images as input, for making global stock\nmarket predictions. Our model not only yields profit in the stock market of the\ncountry where it was trained but generally yields profit in global stock\nmarkets. We trained our model only in the US market and tested it in 31\ndifferent countries over 12 years. The portfolios constructed based on our\nmodel's output generally yield about 0.1 to 1.0 percent return per transaction\nprior to transaction costs in 31 countries. The results show that there are\nsome patterns on stock chart image, that tend to predict the same future stock\nprice movements across global stock markets. Moreover, the results show that\nfuture stock prices can be predicted even if the training and testing\nprocedures are done in different countries. Training procedure could be done in\nrelatively large and liquid markets (e.g., USA) and tested in small markets.\nThis result demonstrates that artificial intelligence based stock price\nforecasting models can be used in relatively small markets (emerging countries)\neven though they do not have a sufficient amount of data for training.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2019 08:40:24 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Lee", "Jinho", ""], ["Kim", "Raehyun", ""], ["Koh", "Yookyung", ""], ["Kang", "Jaewoo", ""]]}]