[{"id": "1408.1494", "submitter": "Claudio Tessone", "authors": "David Garcia, Claudio Juan Tessone, Pavlin Mavrodiev and Nicolas\n  Perony", "title": "The digital traces of bubbles: feedback cycles between socio-economic\n  signals in the Bitcoin economy", "comments": "16 pages, 3 figures, supplementary material", "journal-ref": "Journal of the Royal Society Interface, pp. 20140623, vol. 11\n  (2014)", "doi": "10.1098/?rsif.2014.0623", "report-no": null, "categories": "physics.soc-ph cs.SI nlin.AO q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the role of social interactions in the creation of price bubbles?\nAnswering this question requires obtaining collective behavioural traces\ngenerated by the activity of a large number of actors. Digital currencies offer\na unique possibility to measure socio-economic signals from such digital\ntraces. Here, we focus on Bitcoin, the most popular cryptocurrency. Bitcoin has\nexperienced periods of rapid increase in exchange rates (price) followed by\nsharp decline; we hypothesise that these fluctuations are largely driven by the\ninterplay between different social phenomena. We thus quantify four\nsocio-economic signals about Bitcoin from large data sets: price on on-line\nexchanges, volume of word-of-mouth communication in on-line social media,\nvolume of information search, and user base growth. By using vector\nautoregression, we identify two positive feedback loops that lead to price\nbubbles in the absence of exogenous stimuli: one driven by word of mouth, and\nthe other by new Bitcoin adopters. We also observe that spikes in information\nsearch, presumably linked to external events, precede drastic price declines.\nUnderstanding the interplay between the socio-economic signals we measured can\nlead to applications beyond cryptocurrencies to other phenomena which leave\ndigital footprints, such as on-line social network usage.\n", "versions": [{"version": "v1", "created": "Thu, 7 Aug 2014 06:47:48 GMT"}], "update_date": "2014-08-11", "authors_parsed": [["Garcia", "David", ""], ["Tessone", "Claudio Juan", ""], ["Mavrodiev", "Pavlin", ""], ["Perony", "Nicolas", ""]]}, {"id": "1408.1728", "submitter": "Leonidas Sandoval", "authors": "Leonidas Sandoval Junior", "title": "Dynamics in two networks based on stocks of the US stock market", "comments": "For the complete version, with the 22 figures, please contact the\n  author or download from\n  https://insper.academia.edu/LeonidasSandoval/Papers?s=nav#add", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We follow the main stocks belonging to the New York Stock Exchange and to\nNasdaq from 2003 to 2012, through years of normality and of crisis, and study\nthe dynamics of networks built on two measures expressing relations between\nthose stocks: correlation, which is symmetric and measures how similar two\nstocks behave, and Transfer Entropy, which is non-symmetric and measures the\ninfluence of the time series of one stock onto another in terms of the\ninformation that the time series of one stock transmits to the time series of\nanother stock. The two measures are used in the creation of two networks that\nevolve in time, revealing how the relations between stocks and industrial\nsectors changed in times of crisis. The two networks are also used in\nconjunction with a dynamic model of the spreading of volatility in order to\ndetect which are the stocks that are most likely to spread crises, according to\nthe model. This information may be used in the building of policies aiming to\nreduce the effect of financial crises.\n", "versions": [{"version": "v1", "created": "Thu, 7 Aug 2014 22:56:34 GMT"}, {"version": "v2", "created": "Mon, 1 Sep 2014 03:07:38 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Junior", "Leonidas Sandoval", ""]]}, {"id": "1408.2794", "submitter": "Patrick Zeng", "authors": "Angela Gu, Patrick Zeng", "title": "Sector-Based Factor Models for Asset Returns", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factor analysis is a statistical technique employed to evaluate how observed\nvariables correlate through common factors and unique variables. While it is\noften used to analyze price movement in the unstable stock market, it does not\nalways yield easily interpretable results. In this study, we develop improved\nfactor models by explicitly incorporating sector information on our studied\nstocks. We add eleven sectors of stocks as defined by the IBES, represented by\nrespective sector-specific factors, to non-specific market factors to revise\nthe factor model. We then develop an expectation maximization (EM) algorithm to\ncompute our revised model with 15 years' worth of S&P 500 stocks' daily close\nprices. Our results in most sectors show that nearly all of these factor\ncomponents have the same sign, consistent with the intuitive idea that stocks\nin the same sector tend to rise and fall in coordination over time. Results\nobtained by the classic factor model, in contrast, had a homogeneous blend of\npositive and negative components. We conclude that results produced by our\nsector-based factor model are more interpretable than those produced by the\nclassic non-sector-based model for at least some stock sectors.\n", "versions": [{"version": "v1", "created": "Mon, 11 Aug 2014 17:05:51 GMT"}], "update_date": "2014-08-13", "authors_parsed": [["Gu", "Angela", ""], ["Zeng", "Patrick", ""]]}, {"id": "1408.2985", "submitter": "Tom\\'a\\v{s} V\\'yrost", "authors": "Tom\\'a\\v{s} V\\'yrost, \\v{S}tefan Ly\\'ocsa, Eduard Baum\\\"ohl", "title": "Granger Causality Stock Market Networks: Temporal Proximity and\n  Preferential Attachment", "comments": "This work was supported by the Slovak Research and Development Agency\n  under the contract No. APVV-0666-11", "journal-ref": null, "doi": "10.1016/j.physa.2015.02.017", "report-no": null, "categories": "q-fin.GN q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The structure of return spillovers is examined by constructing Granger\ncausality networks using daily closing prices of 20 developed markets from 2nd\nJanuary 2006 to 31st December 2013. The data is properly aligned to take into\naccount non-synchronous trading effects. The study of the resulting networks of\nover 94 sub-samples revealed three significant findings. First, after the\nrecent financial crisis the impact of the US stock market has declined. Second,\nspatial probit models confirmed the role of the temporal proximity between\nmarket closing times for return spillovers, i.e. the time distance between\nnational stock markets matters. Third, preferential attachment between stock\nmarkets exists, i.e. spillover from market j to market i is more likely if A)\nmarket j influences other markets other than i, or when B) market i is\ninfluenced by other markets other than j.\n", "versions": [{"version": "v1", "created": "Wed, 13 Aug 2014 12:01:59 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["V\u00fdrost", "Tom\u00e1\u0161", ""], ["Ly\u00f3csa", "\u0160tefan", ""], ["Baum\u00f6hl", "Eduard", ""]]}, {"id": "1408.3650", "submitter": "Eric Aldrich", "authors": "Eric M. Aldrich, Indra Heckenbach, Gregory Laughlin", "title": "The Random Walk of High Frequency Trading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper builds a model of high-frequency equity returns by separately\nmodeling the dynamics of trade-time returns and trade arrivals. Our main\ncontributions are threefold. First, we characterize the distributional behavior\nof high-frequency asset returns both in ordinary clock time and in trade time.\nWe show that when controlling for pre-scheduled market news events, trade-time\nreturns of the highly liquid near-month E-mini S&P 500 futures contract are\nwell characterized by a Gaussian distribution at very fine time scales. Second,\nwe develop a structured and parsimonious model of clock-time returns by\nsubordinating a trade-time Gaussian distribution with a trade arrival process\nthat is associated with a modified Markov-Switching Multifractal Duration\n(MSMD) model. This model provides an excellent characterization of\nhigh-frequency inter-trade durations. Over-dispersion in this distribution of\ninter-trade durations leads to leptokurtosis and volatility clustering in\nclock-time returns, even when trade-time returns are Gaussian. Finally, we use\nour model to extrapolate the empirical relationship between trade rate and\nvolatility in an effort to understand conditions of market failure. Our model\nsuggests that the 1,200 km physical separation of financial markets in Chicago\nand New York/New Jersey provides a natural ceiling on systemic volatility and\nmay contribute to market stability during periods of extremely heavy trading.\n", "versions": [{"version": "v1", "created": "Fri, 15 Aug 2014 20:49:01 GMT"}, {"version": "v2", "created": "Tue, 19 Aug 2014 16:36:46 GMT"}, {"version": "v3", "created": "Sat, 30 Aug 2014 16:05:35 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Aldrich", "Eric M.", ""], ["Heckenbach", "Indra", ""], ["Laughlin", "Gregory", ""]]}, {"id": "1408.3728", "submitter": "Pawe{\\l} Fiedor", "authors": "Pawe{\\l} Fiedor", "title": "Maximum Entropy Production Principle for Stock Returns", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our previous studies we have investigated the structural complexity of\ntime series describing stock returns on New York's and Warsaw's stock\nexchanges, by employing two estimators of Shannon's entropy rate based on\nLempel-Ziv and Context Tree Weighting algorithms, which were originally used\nfor data compression. Such structural complexity of the time series describing\nlogarithmic stock returns can be used as a measure of the inherent (model-free)\npredictability of the underlying price formation processes, testing the\nEfficient-Market Hypothesis in practice. We have also correlated the estimated\npredictability with the profitability of standard trading algorithms, and found\nthat these do not use the structure inherent in the stock returns to any\nsignificant degree. To find a way to use the structural complexity of the stock\nreturns for the purpose of predictions we propose the Maximum Entropy\nProduction Principle as applied to stock returns, and test it on the two\nmentioned markets, inquiring into whether it is possible to enhance prediction\nof stock returns based on the structural complexity of these and the mentioned\nprinciple.\n", "versions": [{"version": "v1", "created": "Sat, 16 Aug 2014 09:37:46 GMT"}], "update_date": "2014-08-19", "authors_parsed": [["Fiedor", "Pawe\u0142", ""]]}, {"id": "1408.4746", "submitter": "Amelia Carolina Sparavigna", "authors": "Amelia Carolina Sparavigna", "title": "Recurrence plots of exchange rates of currencies", "comments": "Keywords: Recurrence Plots, Texture Transitions, Currencies, Euro, US\n  Dollar, GB Pound, Japanese Yen, Exchange Rates, Autoregressive Models,\n  Econometrics", "journal-ref": "The International Journal of Sciences, 2014, Volume 3, Issue 7,\n  Pages 87-95", "doi": "10.18483/ijSci.545", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Used to investigate the presence of distinctive recurrent behaviours in\nnatural processes, the recurrence plots can be applied to the analysis of\neconomic data, and, in particular, to the characterization of exchange rates of\ncurrencies too. In this paper, we will show that these plots are able to\ncharacterize the periods of oscillation and random walk of currencies and\nenhance their reply to news and events, by means of texture transitions. The\nexamples of recurrence plots given here are obtained from time series of\nexchange rates of Euro.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jul 2014 10:44:27 GMT"}], "update_date": "2015-08-06", "authors_parsed": [["Sparavigna", "Amelia Carolina", ""]]}, {"id": "1408.5618", "submitter": "Wei-Xing Zhou", "authors": "Hao Meng (ECUST), Hai-Chuan Xu (ECUST), Wei-Xing Zhou (ECUST), Didier\n  Sornette (ETH Zurich)", "title": "Symmetric thermal optimal path and time-dependent lead-lag relationship:\n  Novel statistical tests and application to UK and US real-estate and monetary\n  policies", "comments": null, "journal-ref": "Quantitative Finance 17 (6), 959-977 (2017)", "doi": "10.1080/14697688.2016.1241424", "report-no": null, "categories": "q-fin.ST q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the symmetric thermal optimal path (TOPS) method to determine the\ntime-dependent lead-lag relationship between two stochastic time series. This\nnovel version of the previously introduced TOP method alleviates some\ninconsistencies by imposing that the lead-lag relationship should be invariant\nwith respect to a time reversal of the time series after a change of sign. This\nmeans that, if `$X$ comes before $Y$', this transforms into `$Y$ comes before\n$X$' under a time reversal. We show that previously proposed bootstrap test\nlacks power and leads too often to a lack of rejection of the null that there\nis no lead-lag correlation when it is present. We introduce instead two novel\ntests. The first the free energy p-value $\\rho$ criterion quantifies the\nprobability that a given lead-lag structure could be obtained from random time\nseries with similar characteristics except for the lead-lag information. The\nsecond self-consistent test embodies the idea that, for the lead-lag path to be\nsignificant, synchronizing the two time series using the time varying lead-lag\npath should lead to a statistically significant correlation. We perform\nintensive synthetic tests to demonstrate their performance and limitations.\nFinally, we apply the TOPS method with the two new tests to the time dependent\nlead-lag structures of house price and monetary policy of the United Kingdom\n(UK) and United States (US) from 1991 to 2011. The TOPS approach stresses the\nimportance of accounting for change of regimes, so that similar pieces of\ninformation or policies may have drastically different impacts and\ndevelopments, conditional on the economic, financial and geopolitical\nconditions. This study reinforces the view that the hypothesis of statistical\nstationarity is highly questionable.\n", "versions": [{"version": "v1", "created": "Sun, 24 Aug 2014 16:20:25 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 23:21:16 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Meng", "Hao", "", "ECUST"], ["Xu", "Hai-Chuan", "", "ECUST"], ["Zhou", "Wei-Xing", "", "ECUST"], ["Sornette", "Didier", "", "ETH Zurich"]]}, {"id": "1408.6255", "submitter": "Tomasz Gubiec", "authors": "T. Gubiec and M. Wili\\'nski", "title": "Intra-day variability of the stock market activity versus stationarity\n  of the financial time series", "comments": null, "journal-ref": null, "doi": "10.1016/j.physa.2015.03.033", "report-no": null, "categories": "q-fin.ST physics.data-an q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the impact of the intra-day activity pattern on the\nautocorrelation function estimator. We obtain an exact formula relating\nestimators of the autocorrelation functions of non-stationary process to its\nstationary counterpart. Hence, we proved that the day seasonality of\ninter-transaction times extends the memory of as well the process itself as its\nabsolute value. That is, both processes relaxation to zero is longer.\n", "versions": [{"version": "v1", "created": "Tue, 26 Aug 2014 20:46:56 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Gubiec", "T.", ""], ["Wili\u0144ski", "M.", ""]]}, {"id": "1408.6279", "submitter": "Alberto  Ohashi", "authors": "Marcio Laurini and Alberto Ohashi", "title": "A Noisy Principal Component Analysis for Forward Rate Curves", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal Component Analysis (PCA) is the most common nonparametric method\nfor estimating the volatility structure of Gaussian interest rate models. One\nmajor difficulty in the estimation of these models is the fact that forward\nrate curves are not directly observable from the market so that non-trivial\nobservational errors arise in any statistical analysis. In this work, we point\nout that the classical PCA analysis is not suitable for estimating factors of\nforward rate curves due to the presence of measurement errors induced by market\nmicrostructure effects and numerical interpolation. Our analysis indicates that\nthe PCA based on the long-run covariance matrix is capable to extract the true\ncovariance structure of the forward rate curves in the presence of\nobservational errors. Moreover, it provides a significant reduction in the\npricing errors due to noisy data typically founded in forward rate curves.\n", "versions": [{"version": "v1", "created": "Tue, 26 Aug 2014 23:04:41 GMT"}], "update_date": "2014-08-28", "authors_parsed": [["Laurini", "Marcio", ""], ["Ohashi", "Alberto", ""]]}, {"id": "1408.6637", "submitter": "Ladislav Kristoufek", "authors": "Ladislav Kristoufek", "title": "Spectrum-based estimators of the bivariate Hurst exponent", "comments": "15 pages, 4 figures", "journal-ref": "Physical Review E 90, 062802 (2014)", "doi": "10.1103/PhysRevE.90.062802", "report-no": null, "categories": "q-fin.ST physics.data-an", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We introduce two new estimators of the bivariate Hurst exponent in the\npower-law cross-correlations setting -- the cross-periodogram and local\n$X$-Whittle estimators -- as generalizations of their univariate counterparts.\nAs the spectrum-based estimators are dependent on a part of the spectrum taken\ninto consideration during estimation, a simulation study showing performance of\nthe estimators under varying bandwidth parameter as well as correlation between\nprocesses and their specification is provided as well. The newly introduced\nestimators are less biased than the already existent averaged periodogram\nestimator which, however, has slightly lower variance. The spectrum-based\nestimators can serve as a good complement to the popular time domain\nestimators.\n", "versions": [{"version": "v1", "created": "Thu, 28 Aug 2014 07:41:14 GMT"}, {"version": "v2", "created": "Fri, 21 Nov 2014 08:42:40 GMT"}], "update_date": "2014-12-11", "authors_parsed": [["Kristoufek", "Ladislav", ""]]}]