[{"id": "2008.00462", "submitter": "Anindya Goswami Mr.", "authors": "Anindya Goswami and Sharan Rajani and Atharva Tanksale", "title": "Data-Driven Option Pricing using Single and Multi-Asset Supervised\n  Learning", "comments": "18 figures, 11 tables, 25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose three different data-driven approaches for pricing European-style\ncall options using supervised machine-learning algorithms. These approaches\nyield models that give a range of fair prices instead of a single price point.\nThe performance of the models are tested on two stock market indices: NIFTY$50$\nand BANKNIFTY from the Indian equity market. Although neither historical nor\nimplied volatility is used as an input, the results show that the trained\nmodels have been able to capture the option pricing mechanism better than or\nsimilar to the Black-Scholes formula for all the experiments. Our choice of\nscale free I/O allows us to train models using combined data of multiple\ndifferent assets from a financial market. This not only allows the models to\nachieve far better generalization and predictive capability, but also solves\nthe problem of paucity of data, the primary limitation of using machine\nlearning techniques. We also illustrate the performance of the trained models\nin the period leading up to the 2020 Stock Market Crash (Jan 2019 to April\n2020).\n", "versions": [{"version": "v1", "created": "Sun, 2 Aug 2020 11:14:43 GMT"}, {"version": "v2", "created": "Sat, 5 Dec 2020 14:26:37 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Goswami", "Anindya", ""], ["Rajani", "Sharan", ""], ["Tanksale", "Atharva", ""]]}, {"id": "2008.00860", "submitter": "Akihiko Noda", "authors": "Kenichi Hirayama, Akihiko Noda", "title": "Evaluating the Financial Market Function in Prewar Japan using a\n  Time-Varying Parameter Model", "comments": "25 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST econ.GN q-fin.EC q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores when the financial market lost the price formation\nfunction in prewar Japan in the sense of Fama's (1970) semi-strong form market\nefficiency using a new dataset. We particularly focus on the relationship\nbetween the prewar Japanese financial market and several government policy\ninterventions to explore whether the semi-strong form market efficiency evolves\nover time. To capture the long-run impact of government policy interventions\nagainst the markets, we measure the time-varying joint degree of market\nefficiency and the time-varying impulse responses based on Ito et al.'s (2014;\n2017) generalized least squares-based time-varying vector autoregressive model.\nThe empirical results reveal that (1) the joint degree of market efficiency in\nthe prewar Japanese financial market fluctuated over time because of external\nevents such as policy changes and wars, (2) the semi-strong form EMH is almost\nsupported in the prewar Japanese financial market, (3) Lo's (2004) adaptive\nmarket hypothesis is supported in the prewar Japanese financial market even if\nwe consider that the public information affects the financial markets, and (4)\nthe prewar Japanese financial markets lost the price formation function in 1932\nand that was a turning point in the market.\n", "versions": [{"version": "v1", "created": "Mon, 3 Aug 2020 13:28:50 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 01:21:11 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Hirayama", "Kenichi", ""], ["Noda", "Akihiko", ""]]}, {"id": "2008.01649", "submitter": "Valerio Ficcadenti", "authors": "Roy Cerqueti and Valerio Ficcadenti", "title": "Anxiety for the pandemic and trust in financial markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The COVID-19 pandemic has generated disruptive changes in many fields. Here\nwe focus on the relationship between the anxiety felt by people during the\npandemic and the trust in the future performance of financial markets.\nPrecisely, we move from the idea that the volume of Google searches about\n\"coronavirus\" can be considered as a proxy of the anxiety and, jointly with the\nstock index prices, can be used to produce mood indicators -- in terms of\npessimism and optimism -- at country level. We analyse the \"very high human\ndeveloped countries\" according to the Human Development Index plus China and\ntheir respective main stock market indexes. Namely, we propose both a temporal\nand a global measure of pessimism and optimism and provide accordingly a\nclassification of indexes and countries. The results show the existence of\ndifferent clusters of countries and markets in terms of pessimism and optimism.\nMoreover, specific regimes along the time emerge, with an increasing optimism\nspreading during the mid of June 2020. Furthermore, countries with different\ngovernment responses to the pandemic have experienced different levels of mood\nindicators, so that countries with less strict lockdown had a higher level of\noptimism.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2020 20:48:36 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Cerqueti", "Roy", ""], ["Ficcadenti", "Valerio", ""]]}, {"id": "2008.01670", "submitter": "Zhongfang Zhuang", "authors": "Zhongfang Zhuang, Chin-Chia Michael Yeh, Liang Wang, Wei Zhang,\n  Junpeng Wang", "title": "Multi-stream RNN for Merchant Transaction Prediction", "comments": "Accepted by KDD 2020 Workshop on Machine Learning in Finance", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, digital payment systems have significantly changed people's\nlifestyles. New challenges have surfaced in monitoring and guaranteeing the\nintegrity of payment processing systems. One important task is to predict the\nfuture transaction statistics of each merchant. These predictions can thus be\nused to steer other tasks, ranging from fraud detection to recommendation. This\nproblem is challenging as we need to predict not only multivariate time series\nbut also multi-steps into the future. In this work, we propose a multi-stream\nRNN model for multi-step merchant transaction predictions tailored to these\nrequirements. The proposed multi-stream RNN summarizes transaction data in\ndifferent granularity and makes predictions for multiple steps in the future.\nOur extensive experimental results have demonstrated that the proposed model is\ncapable of outperforming existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 01:20:48 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Zhuang", "Zhongfang", ""], ["Yeh", "Chin-Chia Michael", ""], ["Wang", "Liang", ""], ["Zhang", "Wei", ""], ["Wang", "Junpeng", ""]]}, {"id": "2008.01687", "submitter": "Claudio Nordio", "authors": "A. R. Provenzano, D. Trifir\\`o, A. Datteo, L. Giada, N. Jean, A.\n  Riciputi, G. Le Pera, M. Spadaccino, L. Massaron and C. Nordio", "title": "Machine Learning approach for Credit Scoring", "comments": "28 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.RM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we build a stack of machine learning models aimed at composing a\nstate-of-the-art credit rating and default prediction system, obtaining\nexcellent out-of-sample performances. Our approach is an excursion through the\nmost recent ML / AI concepts, starting from natural language processes (NLP)\napplied to economic sectors' (textual) descriptions using embedding and\nautoencoders (AE), going through the classification of defaultable firms on the\nbase of a wide range of economic features using gradient boosting machines\n(GBM) and calibrating their probabilities paying due attention to the treatment\nof unbalanced samples. Finally we assign credit ratings through genetic\nalgorithms (differential evolution, DE). Model interpretability is achieved by\nimplementing recent techniques such as SHAP and LIME, which explain predictions\nlocally in features' space.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2020 21:29:06 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Provenzano", "A. R.", ""], ["Trifir\u00f2", "D.", ""], ["Datteo", "A.", ""], ["Giada", "L.", ""], ["Jean", "N.", ""], ["Riciputi", "A.", ""], ["Pera", "G. Le", ""], ["Spadaccino", "M.", ""], ["Massaron", "L.", ""], ["Nordio", "C.", ""]]}, {"id": "2008.05527", "submitter": "Peter B. Lerner", "authors": "Peter B. Lerner", "title": "Transmission of market orders through communication line with\n  relativistic delay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The notion of \"relativistic finance\" became ingrained in public imagination\nand has been asserted in many mass-media reports. Yet, despite an observed\ndrive of the most reputable Wall Street firms to establish their servers ever\ncloser to the trading hubs, there is surprisingly little \"hard\" information\nrelated to relativistic delay of the trading orders. In this paper, the author\nuses modified M/M/G queue theory to describe propagation of the trading signal\nwith finite velocity.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 18:53:07 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Lerner", "Peter B.", ""]]}, {"id": "2008.06130", "submitter": "Neil Shephard", "authors": "Neil Shephard", "title": "An estimator for predictive regression: reliable inference for financial\n  economics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating linear regression using least squares and reporting robust\nstandard errors is very common in financial economics, and indeed, much of the\nsocial sciences and elsewhere. For thick tailed predictors under\nheteroskedasticity this recipe for inference performs poorly, sometimes\ndramatically so. Here, we develop an alternative approach which delivers an\nunbiased, consistent and asymptotically normal estimator so long as the means\nof the outcome and predictors are finite. The new method has standard errors\nunder heteroskedasticity which are easy to reliably estimate and tests which\nare close to their nominal size. The procedure works well in simulations and in\nan empirical exercise. An extension is given to quantile regression.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2020 23:23:25 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Shephard", "Neil", ""]]}, {"id": "2008.06225", "submitter": "Jie Fang", "authors": "Jie Fang, Jianwu Lin, Shutao Xia, Yong Jiang, Zhikang Xia, Xiang Liu", "title": "Neural Network-based Automatic Factor Construction", "comments": "Accepted by the Journal, Quantitative Finance. 21 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instead of conducting manual factor construction based on traditional and\nbehavioural finance analysis, academic researchers and quantitative investment\nmanagers have leveraged Genetic Programming (GP) as an automatic feature\nconstruction tool in recent years, which builds reverse polish mathematical\nexpressions from trading data into new factors. However, with the development\nof deep learning, more powerful feature extraction tools are available. This\npaper proposes Neural Network-based Automatic Factor Construction (NNAFC), a\ntailored neural network framework that can automatically construct diversified\nfinancial factors based on financial domain knowledge and a variety of neural\nnetwork structures. The experiment results show that NNAFC can construct more\ninformative and diversified factors than GP, to effectively enrich the current\nfactor pool. For the current market, both fully connected and recurrent neural\nnetwork structures are better at extracting information from financial time\nseries than convolution neural network structures. Moreover, new factors\nconstructed by NNAFC can always improve the return, Sharpe ratio, and the max\ndraw-down of a multi-factor quantitative investment strategy due to their\nintroducing more information and diversification to the existing factor pool.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2020 07:44:49 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 16:20:53 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2020 16:20:18 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Fang", "Jie", ""], ["Lin", "Jianwu", ""], ["Xia", "Shutao", ""], ["Jiang", "Yong", ""], ["Xia", "Zhikang", ""], ["Liu", "Xiang", ""]]}, {"id": "2008.07822", "submitter": "Matthieu Garcin", "authors": "Matthieu Garcin and Martino Grasselli", "title": "Long vs Short Time Scales: the Rough Dilemma and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a large dataset on major stock indexes and FX rates, we test the\nrobustness of the rough fractional volatility model over different time scales.\nWe include the estimation error as well as the microstructure noise into the\nanalysis. Our findings lead to new stylized facts regarding the volatility that\nare not described by models introduced so far: in the fractal analysis using\nthe absolute moment approach, log-log plots are nonlinear and reveal very low\nperceived Hurst exponents at small scales, consistent with the rough framework,\nand higher perceived Hurst exponents for larger scales, along with stationarity\nof the volatility. These results, obtained for time series of realized\nvolatilities, are confirmed by another measure of volatility, namely\nParkinson's volatility, taking into account its specificities regarding\nmeasurement errors.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 09:31:15 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Garcin", "Matthieu", ""], ["Grasselli", "Martino", ""]]}, {"id": "2008.07836", "submitter": "Tomoshiro Ochiai", "authors": "Tomoshiro Ochiai and Jose C. Nacher", "title": "Unveiling the directional network behind the financial statements data\n  using volatility constraint correlation", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN q-fin.CP q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial data, such as financial statements, stores valuable and critical\ninformation to potentially assist stakeholders and investors optimize their\ncapital so that it maximizes overall economic growth. Since there are many\nvariables in financial statements, it is important to determine the causal\nrelationships, that is, the directional influence between them in a structural\nway, as well as to understand the related accounting mechanisms. However, the\nanalysis of variable-to-variable relationships in financial information by\nusing the standard correlation functions is not sufficient to unveil\ndirectionality. Here, we use the volatility constrained correlation (VC\ncorrelation) method that enables us to predict the directional relationship\nbetween the two variables. To be precise, we apply the VC correlation method to\nfive major financial information variables (revenue, net income, operating\nincome, own capital and market capitalization) of 2321 firms in 28 years from\n1990 to 2018 listed on Tokyo Stock Exchange in order to identify which\nvariables are influential and which are susceptible variables. Our findings\nshow that operating income is the most influential variable and market capital\nand revenue are the most susceptible variables among the five major accounting\nvariables. Surprisingly, the results are different from the existing intuitive\nunderstanding suggested by widely used investment strategy indicators known as\nPER and PBR, which report that net income and own capital are the most\ninfluential variable on market capital. Taken together, the presented analysis\nmay assist managers, stakeholders and investors to improve performance of\nfinancial management as well as optimize financial strategies for firms in\nfuture operations.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 10:17:09 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ochiai", "Tomoshiro", ""], ["Nacher", "Jose C.", ""]]}, {"id": "2008.07907", "submitter": "Victor Olkhov", "authors": "Victor Olkhov", "title": "Volatility Depend on Market Trades and Macro Theory", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.PM q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents probability distributions for price and returns random\nprocesses for averaging time interval {\\Delta}. These probabilities determine\nproperties of price and returns volatility. We define statistical moments for\nprice and returns random processes as functions of the costs and the volumes of\nmarket trades aggregated during interval {\\Delta}. These sets of statistical\nmoments determine characteristic functionals for price and returns probability\ndistributions. Volatilities are described by first two statistical moments.\nSecond statistical moments are described by functions of second degree of the\ncost and the volumes of market trades aggregated during interval {\\Delta}. We\npresent price and returns volatilities as functions of number of trades and\nsecond degree costs and volumes of market trades aggregated during interval\n{\\Delta}. These expressions support numerous results on correlations between\nreturns volatility, number of trades and the volume of market transactions.\nForecasting the price and returns volatilities depend on modeling the second\ndegree of the costs and the volumes of market trades aggregated during interval\n{\\Delta}. Second degree market trades impact second degree of macro variables\nand expectations. Description of the second degree market trades, macro\nvariables and expectations doubles the complexity of the current macroeconomic\nand financial theory.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2020 12:32:48 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Olkhov", "Victor", ""]]}, {"id": "2008.08004", "submitter": "Jesus Lago", "authors": "Jesus Lago, Grzegorz Marcjasz, Bart De Schutter, Rafa{\\l} Weron", "title": "Forecasting day-ahead electricity prices: A review of state-of-the-art\n  algorithms, best practices and an open-access benchmark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the field of electricity price forecasting has benefited from plenty of\ncontributions in the last two decades, it arguably lacks a rigorous approach to\nevaluating new predictive algorithms. The latter are often compared using\nunique, not publicly available datasets and across too short and limited to one\nmarket test samples. The proposed new methods are rarely benchmarked against\nwell established and well performing simpler models, the accuracy metrics are\nsometimes inadequate and testing the significance of differences in predictive\nperformance is seldom conducted. Consequently, it is not clear which methods\nperform well nor what are the best practices when forecasting electricity\nprices. In this paper, we tackle these issues by performing a literature survey\nof state-of-the-art models, comparing state-of-the-art statistical and deep\nlearning methods across multiple years and markets, and by putting forward a\nset of best practices. In addition, we make available the considered datasets,\nforecasts of the state-of-the-art models, and a specifically designed python\ntoolbox, so that new algorithms can be rigorously evaluated in future studies.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 16:19:20 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 15:01:59 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Lago", "Jesus", ""], ["Marcjasz", "Grzegorz", ""], ["De Schutter", "Bart", ""], ["Weron", "Rafa\u0142", ""]]}, {"id": "2008.08006", "submitter": "Jesus Lago", "authors": "Grzegorz Marcjasz, Jesus Lago, Rafa{\\l} Weron", "title": "Neural networks in day-ahead electricity price forecasting: Single vs.\n  multiple outputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advancements in the fields of artificial intelligence and machine\nlearning methods resulted in a significant increase of their popularity in the\nliterature, including electricity price forecasting. Said methods cover a very\nbroad spectrum, from decision trees, through random forests to various\nartificial neural network models and hybrid approaches. In electricity price\nforecasting, neural networks are the most popular machine learning method as\nthey provide a non-linear counterpart for well-tested linear regression models.\nTheir application, however, is not straightforward, with multiple\nimplementation factors to consider. One of such factors is the network's\nstructure. This paper provides a comprehensive comparison of two most common\nstructures when using the deep neural networks -- one that focuses on each hour\nof the day separately, and one that reflects the daily auction structure and\nmodels vectors of the prices. The results show a significant accuracy advantage\nof using the latter, confirmed on data from five distinct power exchanges.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2020 16:20:31 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Marcjasz", "Grzegorz", ""], ["Lago", "Jesus", ""], ["Weron", "Rafa\u0142", ""]]}, {"id": "2008.09471", "submitter": "Matloob Khushi Dr", "authors": "Zezheng Zhang and Matloob Khushi", "title": "GA-MSSR: Genetic Algorithm Maximizing Sharpe and Sterling Ratio Method\n  for RoboTrading", "comments": null, "journal-ref": "IJCNN 2020", "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Foreign exchange is the largest financial market in the world, and it is also\none of the most volatile markets. Technical analysis plays an important role in\nthe forex market and trading algorithms are designed utilizing machine learning\ntechniques. Most literature used historical price information and technical\nindicators for training. However, the noisy nature of the market affects the\nconsistency and profitability of the algorithms. To address this problem, we\ndesigned trading rule features that are derived from technical indicators and\ntrading rules. The parameters of technical indicators are optimized to maximize\ntrading performance. We also proposed a novel cost function that computes the\nrisk-adjusted return, Sharpe and Sterling Ratio (SSR), in an effort to reduce\nthe variance and the magnitude of drawdowns. An automatic robotic trading\n(RoboTrading) strategy is designed with the proposed Genetic Algorithm\nMaximizing Sharpe and Sterling Ratio model (GA-MSSR) model. The experiment was\nconducted on intraday data of 6 major currency pairs from 2018 to 2019. The\nresults consistently showed significant positive returns and the performance of\nthe trading system is superior using the optimized rule-based features. The\nhighest return obtained was 320% annually using 5-minute AUDUSD currency pair.\nBesides, the proposed model achieves the best performance on risk factors,\nincluding maximum drawdowns and variance in return, comparing to benchmark\nmodels. The code can be accessed at\nhttps://github.com/zzzac/rule-based-forextrading-system\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2020 05:33:35 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Zhang", "Zezheng", ""], ["Khushi", "Matloob", ""]]}, {"id": "2008.09481", "submitter": "Joel Da Costa", "authors": "Joel da Costa, Tim Gebbie", "title": "Learning low-frequency temporal patterns for quantitative trading", "comments": "9 pages, 7 figures", "journal-ref": "2020 IEEE Symposium Series on Computational Intelligence (SSCI),\n  Canberra, Australia, 2020, pp. 1091-1099", "doi": "10.1109/SSCI47803.2020.9308232", "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the viability of a modularised mechanistic online machine\nlearning framework to learn signals in low-frequency financial time series\ndata. The framework is proved on daily sampled closing time-series data from\nJSE equity markets. The input patterns are vectors of pre-processed sequences\nof daily, weekly and monthly or quarterly sampled feature changes. The data\nprocessing is split into a batch processed step where features are learnt using\na stacked autoencoder via unsupervised learning, and then both batch and online\nsupervised learning are carried out using these learnt features, with the\noutput being a point prediction of measured time-series feature fluctuations.\nWeight initializations are implemented with restricted Boltzmann machine\npre-training, and variance based initializations. Historical simulations are\nthen run using an online feedforward neural network initialised with the\nweights from the batch training and validation step. The validity of results\nare considered under a rigorous assessment of backtest overfitting using both\ncombinatorially symmetrical cross validation and probabilistic and deflated\nSharpe ratios. Results are used to develop a view on the phenomenology of\nfinancial markets and the value of complex historical data-analysis for trading\nunder the unstable adaptive dynamics that characterise financial markets.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2020 11:59:15 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["da Costa", "Joel", ""], ["Gebbie", "Tim", ""]]}, {"id": "2008.09482", "submitter": "Shiyang Lai", "authors": "Pengfei Xi, Shiyang Lai, Xueying Wang, Weiqiang Huang", "title": "Using detrended deconvolution foreign exchange network to identify\n  currency status", "comments": "9 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposed a hybrid detrended deconvolution foreign exchange\nnetwork construction method (DDFEN), which combined the detrended\ncross-correlation analysis coefficient (DCCC) and the network deconvolution\nmethod together. DDFEN is designed to reveal the `true' correlation of\ncurrencies by filtering indirect effects in the foreign exchange networks\n(FXNs). The empirical results show that DDFEN can reflect the change of\ncurrency status in the long term and also perform more stable than traditional\nnetwork construction methods.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2020 12:26:42 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Xi", "Pengfei", ""], ["Lai", "Shiyang", ""], ["Wang", "Xueying", ""], ["Huang", "Weiqiang", ""]]}, {"id": "2008.09667", "submitter": "Xiao Li", "authors": "Xiao Li and Weili Wu", "title": "A Blockchain Transaction Graph based Machine Learning Method for Bitcoin\n  Price Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin, as one of the most popular cryptocurrency, is recently attracting\nmuch attention of investors. Bitcoin price prediction task is consequently a\nrising academic topic for providing valuable insights and suggestions. Existing\nbitcoin prediction works mostly base on trivial feature engineering, that\nmanually designs features or factors from multiple areas, including Bticoin\nBlockchain information, finance and social media sentiments. The feature\nengineering not only requires much human effort, but the effectiveness of the\nintuitively designed features can not be guaranteed. In this paper, we aim to\nmining the abundant patterns encoded in bitcoin transactions, and propose\nk-order transaction graph to reveal patterns under different scope. We propose\nthe transaction graph based feature to automatically encode the patterns. A\nnovel prediction method is proposed to accept the features and make price\nprediction, which can take advantage from particular patterns from different\nhistory period. The results of comparison experiments demonstrate that the\nproposed method outperforms the most recent state-of-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2020 20:08:17 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Li", "Xiao", ""], ["Wu", "Weili", ""]]}, {"id": "2008.10885", "submitter": "Asim Dey", "authors": "Asim Kumer Dey, Toufiqul Haq, Kumer Das, and Irina Panovska", "title": "Quantifying the impact of COVID-19 on the US stock market: An analysis\n  from multi-source information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel temporal complex network approach to quantify the US\ncounty level spread dynamics of COVID-19. The objective is to study the effects\nof the local spread dynamics, COVID-19 cases and death, and Google search\nactivities on the US stock market. We use both conventional econometric and\nMachine Learning (ML) models. The results suggest that COVID-19 cases and\ndeaths, its local spread, and Google searches have impacts on abnormal stock\nprices between January 2020 to May 2020. In addition, incorporating information\nabout local spread significantly improves the performance of forecasting models\nof the abnormal stock prices at longer forecasting horizons. On the other hand,\nalthough a few COVID-19 related variables, e.g., US total deaths and US new\ncases exhibit causal relationships on price volatility, COVID-19 cases and\ndeaths, local spread of COVID-19, and Google search activities do not have\nimpacts on price volatility.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 08:46:37 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 01:50:19 GMT"}, {"version": "v3", "created": "Sat, 3 Oct 2020 01:33:22 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Dey", "Asim Kumer", ""], ["Haq", "Toufiqul", ""], ["Das", "Kumer", ""], ["Panovska", "Irina", ""]]}, {"id": "2008.10930", "submitter": "Valentin Courgeau", "authors": "Valentin Courgeau, Almut E.D. Veraart", "title": "High-frequency Estimation of the L\\'evy-driven Graph Ornstein-Uhlenbeck\n  process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Graph Ornstein-Uhlenbeck (GrOU) process observed on a\nnon-uniform discrete time grid and introduce discretised maximum likelihood\nestimators with parameters specific to the whole graph or specific to each\ncomponent, or node. Under a high-frequency sampling scheme, we study the\nasymptotic behaviour of those estimators as the mesh size of the observation\ngrid goes to zero. We prove two stable central limit theorems to the same\ndistribution as in the continuously-observed case under both finite and\ninfinite jump activity for the L\\'evy driving noise. When a graph structure is\nnot explicitly available, the stable convergence allows to consider\npurpose-specific sparse inference procedures, i.e. pruning, on the edges\nthemselves in parallel to the GrOU inference and preserve its asymptotic\nproperties. We apply the new estimators to wind capacity factor measurements,\ni.e. the ratio between the wind power produced locally compared to its rated\npeak power, across fifty locations in Northern Spain and Portugal. We show the\nsuperiority of those estimators compared to the standard least squares\nestimator through a simulation study extending known univariate results across\ngraph configurations, noise types and amplitudes.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2020 10:26:40 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Courgeau", "Valentin", ""], ["Veraart", "Almut E. D.", ""]]}, {"id": "2008.11558", "submitter": "Younng-Jin Kim Ph.D.", "authors": "Wonse Kim, Younng-Jin Kim, Gihyun Lee, Woong Kook", "title": "Investigation of Flash Crash via Topological Data Analysis", "comments": "11 pages, 4 figures, the Third PPICTA", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological data analysis has been acknowledged as one of the most successful\nmathematical data analytic methodologies in various fields including medicine,\ngenetics, and image analysis. In this paper, we explore the potential of this\nmethodology in finance by applying persistence landscape and dynamic time\nseries analysis to analyze an extreme event in the stock market, known as Flash\nCrash. We will provide results of our empirical investigation to confirm the\neffectiveness of our new method not only for the characterization of this\nextreme event but also for its prediction purposes.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 13:40:29 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Kim", "Wonse", ""], ["Kim", "Younng-Jin", ""], ["Lee", "Gihyun", ""], ["Kook", "Woong", ""]]}, {"id": "2008.11788", "submitter": "Hongmei He Ph.D", "authors": "Linyu Zheng and Hongmei He", "title": "Share Price Prediction of Aerospace Relevant Companies with Recurrent\n  Neural Networks based on PCA", "comments": "38 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capital market plays a vital role in marketing operations for aerospace\nindustry. However, due to the uncertainty and complexity of the stock market\nand many cyclical factors, the stock prices of listed aerospace companies\nfluctuate significantly. This makes the share price prediction challengeable.\nTo improve the prediction of share price for aerospace industry sector and well\nunderstand the impact of various indicators on stock prices, we provided a\nhybrid prediction model by the combination of Principal Component Analysis\n(PCA) and Recurrent Neural Networks. We investigated two types of aerospace\nindustries (manufacturer and operator). The experimental results show that PCA\ncould improve both accuracy and efficiency of prediction. Various factors could\ninfluence the performance of prediction models, such as finance data, extracted\nfeatures, optimisation algorithms, and parameters of the prediction model. The\nselection of features may depend on the stability of historical data: technical\nfeatures could be the first option when the share price is stable, whereas\nfundamental features could be better when the share price has high fluctuation.\nThe delays of RNN also depend on the stability of historical data for different\ntypes of companies. It would be more accurate through using short-term\nhistorical data for aerospace manufacturers, whereas using long-term historical\ndata for aerospace operating airlines. The developed model could be an\nintelligent agent in an automatic stock prediction system, with which, the\nfinancial industry could make a prompt decision for their economic strategies\nand business activities in terms of predicted future share price, thus\nimproving the return on investment. Currently, COVID-19 severely influences\naerospace industries. The developed approach can be used to predict the share\nprice of aerospace industries at post COVID-19 time.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2020 20:16:33 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Zheng", "Linyu", ""], ["He", "Hongmei", ""]]}, {"id": "2008.11806", "submitter": "Shengfeng Mei", "authors": "Shengfeng Mei and Hong Gao", "title": "The time function of stock price", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper tends to define the quantitative relationship between the stock\nprice and time as a time function. Based on the empirical evidence that the\nlog-return of a stock is the series of white noise, a mathematical model of the\nintegral white noise is established to describe the phenomenon of stock price\nmovement. A deductive approach is used to derive the auto-correlation function,\ndisplacement formula and power spectral density of the stock price movement,\nwhich reveals not only the characteristics and rules of the movement but also\nthe predictability of the stock price. The deductive fundamental is provided\nfor the price analysis, prediction and risk management of portfolio investment.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2020 03:02:14 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Mei", "Shengfeng", ""], ["Gao", "Hong", ""]]}]