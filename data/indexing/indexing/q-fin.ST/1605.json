[{"id": "1605.00868", "submitter": "Mikkel Bennedsen", "authors": "Mikkel Bennedsen and Ulrich Hounyo and Asger Lunde and Mikko S.\n  Pakkanen", "title": "The Local Fractional Bootstrap", "comments": null, "journal-ref": "Scandinavian Journal of Statistics 2018, Vol. 46, No. 1, 329-359", "doi": "10.1111/sjos.12355", "report-no": null, "categories": "math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a bootstrap procedure for high-frequency statistics of Brownian\nsemistationary processes. More specifically, we focus on a hypothesis test on\nthe roughness of sample paths of Brownian semistationary processes, which uses\nan estimator based on a ratio of realized power variations. Our new resampling\nmethod, the local fractional bootstrap, relies on simulating an auxiliary\nfractional Brownian motion that mimics the fine properties of high frequency\ndifferences of the Brownian semistationary process under the null hypothesis.\nWe prove the first order validity of the bootstrap method and in simulations we\nobserve that the bootstrap-based hypothesis test provides considerable\nfinite-sample improvements over an existing test that is based on a central\nlimit theorem. This is important when studying the roughness properties of time\nseries data; we illustrate this by applying the bootstrap method to two\nempirical data sets: we assess the roughness of a time series of high-frequency\nasset prices and we test the validity of Kolmogorov's scaling law in\natmospheric turbulence data.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 12:36:17 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 12:42:07 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Bennedsen", "Mikkel", ""], ["Hounyo", "Ulrich", ""], ["Lunde", "Asger", ""], ["Pakkanen", "Mikko S.", ""]]}, {"id": "1605.01028", "submitter": "Philip Ernst", "authors": "Philip Ernst, Dean Foster, and Larry Shepp", "title": "On Optimal Retirement (How to Retire Early)", "comments": "14 pages, 2 figures", "journal-ref": "Journal of Applied Probability (2014), 51(2): 333-345", "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.MF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We pose an optimal control problem arising in a perhaps new model for\nretirement investing. Given a control function $f$ and our current net worth as\n$X(t)$ for any $t$, we invest an amount $f(X(t))$ in the market. We need a\nfortune of $M$ \"superdollars\" to retire and want to retire as early as\npossible. We model our change in net worth over each infinitesimal time\ninterval by the Ito process $dX(t)= (1+f(X(t))dt+ f(X(t))dW(t)$. We show how to\nchoose the optimal $f=f_0$ and show that the choice of $f_0$ is optimal among\nall nonanticipative investment strategies, not just among Markovian ones.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 19:15:33 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Ernst", "Philip", ""], ["Foster", "Dean", ""], ["Shepp", "Larry", ""]]}, {"id": "1605.02188", "submitter": "Donya Rahmani", "authors": "Donya Rahmani, Saeed Heravi, Hossein Hassani, Mansi Ghodsi", "title": "Forecasting time series with structural breaks with Singular Spectrum\n  Analysis, using a general form of recurrent formula", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study extends and evaluates the forecasting performance of the Singular\nSpectrum Analysis (SSA) technique using a general non-linear form for the re-\ncurrent formula. In this study, we consider 24 series measuring the monthly\nseasonally adjusted industrial production of important sectors of the German,\nFrench and UK economies. This is tested by comparing the performance of the new\nproposed model with basic SSA and the SSA bootstrap forecasting, especially\nwhen there is evidence of structural breaks in both in-sample and out-of-sample\nperiods. According to root mean-square error (RMSE), SSA using the general\nrecursive formula outperforms both the SSA and the bootstrap forecasting at\nhorizons of up to a year. We found no significant difference in predicting the\ndirection of change between these methods. Therefore, it is suggested that the\nSSA model with the general recurrent formula should be chosen by users in the\ncase of structural breaks in the series.\n", "versions": [{"version": "v1", "created": "Sat, 7 May 2016 12:44:00 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Rahmani", "Donya", ""], ["Heravi", "Saeed", ""], ["Hassani", "Hossein", ""], ["Ghodsi", "Mansi", ""]]}, {"id": "1605.02283", "submitter": "Xin Jiang", "authors": "Shangmei Zhao, Qiuchao Xie, Qing Lu, Xin Jiang and Wei Chen", "title": "Coherence and incoherence collective behavior in financial market", "comments": "6 pages, 6 figures", "journal-ref": "EPL (Europhysics Letters), Volume 112, Number 2,2015", "doi": "10.1209/0295-5075/112/28002", "report-no": null, "categories": "q-fin.ST nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial markets have been extensively studied as highly complex evolving\nsystems. In this paper, we quantify financial price fluctuations through a\ncoupled dynamical system composed of phase oscillators. We find a Financial\nCoherence and Incoherence (FCI) coexistence collective behavior emerges as the\nsystem evolves into the stable state, in which the stocks split into two\ngroups: one is represented by coherent, phase-locked oscillators, the other is\ncomposed of incoherent, drifting oscillators. It is demonstrated that the size\nof the coherent stock groups fluctuates during the economic periods according\nto real-world financial instabilities or shocks. Further, we introduce the\ncoherent characteristic matrix to characterize the involvement dynamics of\nstocks in the coherent groups. Clustering results on the matrix provides a\nnovel manifestation of the correlations among stocks in the economic periods.\nOur analysis for components of the groups is consistent with the Global\nIndustry Classification Standard (GICS) classification and can also figure out\nfeatures for newly developed industries. These results can provide potentially\nimplications on characterizing inner dynamical structure of financial markets\nand making optimal investment tragedies.\n", "versions": [{"version": "v1", "created": "Sun, 8 May 2016 06:46:59 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Zhao", "Shangmei", ""], ["Xie", "Qiuchao", ""], ["Lu", "Qing", ""], ["Jiang", "Xin", ""], ["Chen", "Wei", ""]]}, {"id": "1605.02418", "submitter": "Pritam Ranjan", "authors": "Sujay Mukhoti, Pritam Ranjan", "title": "Mean-correction and Higher Order Moments for a Stochastic Volatility\n  Model with Correlated Errors", "comments": "15 pages; 5 figures, submitted to IJSP", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an efficient stock market, the log-returns and their time-dependent\nvariances are often jointly modelled by stochastic volatility models (SVMs).\nMany SVMs assume that errors in log-return and latent volatility process are\nuncorrelated, which is unrealistic. It turns out that if a non-zero correlation\nis included in the SVM (e.g., Shephard (2005)), then the expected log-return at\ntime t conditional on the past returns is non-zero, which is not a desirable\nfeature of an efficient stock market. In this paper, we propose a\nmean-correction for such an SVM for discrete-time returns with non-zero\ncorrelation. We also find closed form analytical expressions for higher moments\nof log-return and its lead-lag correlations with the volatility process. We\ncompare the performance of the proposed and classical SVMs on S&P 500 index\nreturns obtained from NYSE.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 05:01:35 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Mukhoti", "Sujay", ""], ["Ranjan", "Pritam", ""]]}, {"id": "1605.03559", "submitter": "Rene Kempen", "authors": "Ren\\'e Kempen and Stanislaus Maier-Paape", "title": "Survey on log-normally distributed market-technical trend data", "comments": "17 pages, 21 figures, 23 tables, Keywords: log-normal,\n  market-technical trend, MinMax-process, trend statistics, market analysis,\n  empirical distribution, quantitative finance", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this survey, a short introduction in the recent discovery of log-normally\ndistributed market-technical trend data will be given. The results of the\nstatistical evaluation of typical market-technical trend variables will be\npresented. It will be shown that the log-normal assumption fits better to\nempirical trend data than to daily returns of stock prices. This enables to\nmathematically evaluate trading systems depending on such variables. In this\nmanner, a basic approach to an anti cyclic trading system will be given as an\nexample.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 19:41:25 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Kempen", "Ren\u00e9", ""], ["Maier-Paape", "Stanislaus", ""]]}, {"id": "1605.04940", "submitter": "Khizar Qureshi", "authors": "Khizar Qureshi", "title": "Value-at-Risk: The Effect of Autoregression in a Quantile Process", "comments": "Columbia Economics Review, November 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Value-at-Risk (VaR) is an institutional measure of risk favored by financial\nregulators. VaR may be interpreted as a quantile of future portfolio values\nconditional on the information available, where the most common quantile used\nis 95%. Here we demonstrate Conditional Autoregressive Value at Risk, first\nintroduced by Engle, Manganelli (2001). CAViaR suggests that negative/positive\nreturns are not i.i.d., and that there is significant autocorrelation. The\nmodel is tested using data from 1986- 1999 and 1999-2009 for GM, IBM, XOM, SPX,\nand then validated via the dynamic quantile test. Results suggest that the\ntails (upper/lower quantile) of a distribution of returns behave differently\nthan the core.\n", "versions": [{"version": "v1", "created": "Sat, 5 Mar 2016 22:33:01 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Qureshi", "Khizar", ""]]}, {"id": "1605.04945", "submitter": "Leszek Szybisz", "authors": "M A Szybisz and L Szybisz", "title": "Extended nonlinear feedback model for describing episodes of high\n  inflation", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An extension of the nonlinear feedback (NLF) formalism to describe regimes of\nhyper- and high-inflation in economy is proposed in the present work. In the\nNLF model the consumer price index (CPI) exhibits a finite time singularity of\nthe type $1/(t_c -t)^{(1- \\beta)/\\beta}$, with $\\beta>0$, predicting a blow up\nof the economy at a critical time $t_c$. However, this model fails in\ndetermining $t_c$ in the case of weak hyperinflation regimes like, e.g., that\noccurred in Israel. To overcome this trouble, the NLF model is extended by\nintroducing a parameter $\\gamma$, which multiplies all therms with past growth\nrate index (GRI). In this novel approach the solution for CPI is also analytic\nbeing proportional to the Gaussian hypergeometric function\n$_2F_1(1/\\beta,1/\\beta,1+1/\\beta;z)$, where $z$ is a function of $\\beta$,\n$\\gamma$, and $t_c$. For $z \\to 1$ this hypergeometric function diverges\nleading to a finite time singularity, from which a value of $t_c$ can be\ndetermined. This singularity is also present in GRI. It is shown that the\ninterplay between parameters $\\beta$ and $\\gamma$ may produce phenomena of\nmultiple equilibria. An analysis of the severe hyperinflation occurred in\nHungary proves that the novel model is robust. When this model is used for\nexamining data of Israel a reasonable $t_c$ is got. High-inflation regimes in\nMexico and Iceland, which exhibit weaker inflations than that of Israel, are\nalso successfully described.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 17:28:29 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Szybisz", "M A", ""], ["Szybisz", "L", ""]]}, {"id": "1605.06482", "submitter": "Kenichiro McAlinn", "authors": "Kenichiro McAlinn, Asahi Ushio, Teruo Nakatsuma", "title": "Volatility Forecasts Using Nonlinear Leverage Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The leverage effect-- the correlation between an asset's return and its\nvolatility-- has played a key role in forecasting and understanding volatility\nand risk. While it is a long standing consensus that leverage effects exist and\nimprove forecasts, empirical evidence paradoxically do not show that most\nindividual stocks exhibit this phenomena, mischaracterizing risk and therefore\nleading to poor predictive performance. We examine this paradox, with the goal\nto improve density forecasts, by relaxing the assumption of linearity in the\nleverage effect. Nonlinear generalizations of the leverage effect are proposed\nwithin the Bayesian stochastic volatility framework in order to capture\nflexible leverage structures, where small fluctuations in prices have a\ndifferent effect from large shocks. Efficient Bayesian sequential computation\nis developed and implemented to estimate this effect in a practical, on-line\nmanner. Examining 615 stocks that comprise the S\\&P500 and Nikkei 225, we find\nthat relaxing the linear assumption to our proposed nonlinear leverage effect\nfunction improves predictive performances for 89\\% of all stocks compared to\nthe conventional model assumption.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 19:35:35 GMT"}, {"version": "v2", "created": "Thu, 11 Aug 2016 07:42:49 GMT"}, {"version": "v3", "created": "Wed, 18 Oct 2017 08:34:43 GMT"}, {"version": "v4", "created": "Mon, 11 Dec 2017 04:47:54 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["McAlinn", "Kenichiro", ""], ["Ushio", "Asahi", ""], ["Nakatsuma", "Teruo", ""]]}, {"id": "1605.06700", "submitter": "Aurelio Fernandez Bariviera", "authors": "Lisana B. Martinez, M. Belen Guercio, Aurelio F. Bariviera, Antonio\n  Terce\\~no", "title": "The impact of the financial crisis on the long-range memory of European\n  corporate bond and stock markets", "comments": null, "journal-ref": "Empirica, pp. 1-15, 2016", "doi": "10.1007/s10663-016-9340-8", "report-no": null, "categories": "q-fin.ST q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the presence of long memory in corporate bond and\nstock indices of six European Union countries from July 1998 to February 2015.\nWe compute the Hurst exponent by means of the DFA method and using a sliding\nwindow in order to measure long range dependence. We detect that Hurst\nexponents behave differently in the stock and bond markets, being smoother in\nthe stock indices than in the bond indices. We verify that the level of\ninformational efficiency is time-varying. Moreover we find an asymmetric impact\nof the 2008 financial crisis in the fixed income and the stock markets,\naffecting the former but not the latter. Similar results are obtained using the\nR/S method.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 21:09:22 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Martinez", "Lisana B.", ""], ["Guercio", "M. Belen", ""], ["Bariviera", "Aurelio F.", ""], ["Terce\u00f1o", "Antonio", ""]]}, {"id": "1605.07278", "submitter": "Dhanya Jothimani", "authors": "Dhanya Jothimani, Ravi Shankar, Surendra S. Yadav", "title": "Discrete Wavelet Transform-Based Prediction of Stock Index: A Study on\n  National Stock Exchange Fifty Index", "comments": null, "journal-ref": "Journal of Financial Management and Analysis Vol. 28 Iss. 2 (2015)\n  35-49", "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial Times Series such as stock price and exchange rates are, often,\nnon-linear and non-stationary. Use of decomposition models has been found to\nimprove the accuracy of predictive models. The paper proposes a hybrid approach\nintegrating the advantages of both decomposition model (namely, Maximal Overlap\nDiscrete Wavelet Transform (MODWT)) and machine learning models (ANN and SVR)\nto predict the National Stock Exchange Fifty Index. In first phase, the data is\ndecomposed into a smaller number of subseries using MODWT. In next phase, each\nsubseries is predicted using machine learning models (i.e., ANN and SVR). The\npredicted subseries are aggregated to obtain the final forecasts. In final\nstage, the effectiveness of the proposed approach is evaluated using error\nmeasures and statistical test. The proposed methods (MODWT-ANN and MODWT-SVR)\nare compared with ANN and SVR models and, it was observed that the return on\ninvestment obtained based on trading rules using predicted values of MODWT-SVR\nmodel was higher than that of Buy-and-hold strategy.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 03:41:41 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Jothimani", "Dhanya", ""], ["Shankar", "Ravi", ""], ["Yadav", "Surendra S.", ""]]}, {"id": "1605.08025", "submitter": "Siwat Nakmai", "authors": "Siwat Nakmai", "title": "Foreign exchange risk premia: from traditional to state-space analyses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.EC q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines foreign exchange risk premia from simple univariate\nregressions to the state-space method. The adjusted traditional regressions\nproperly figure out the existence and time-evolving property of the risk\npremia. Successively, the state-space estimations overall are quite rationally\ncompetent in examining the essence of time variability of the unobservable risk\npremia. To be more precise, the coefficients on the lagged estimated\ntime-series are significant and the disturbance combined from the observation\nand transition equations in the state-space system, rational and premium\nerrors, respectively, is statistically white noise. Such the two residuals are\ndiscovered to move oppositely with their covariance approaching zero suggested\nby the empirics. Besides, foreign exchange risk premia are projected and found\nsignificantly stationary at level and relatively volatile throughout time with\nsome clustering. This volatility is however not quite dominant in the\ndeviations of forward prediction errors.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 19:47:01 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Nakmai", "Siwat", ""]]}, {"id": "1605.09484", "submitter": "Man Chung Fung", "authors": "Man Chung Fung, Gareth W. Peters, Pavel V. Shevchenko", "title": "A unified approach to mortality modelling using state-space framework:\n  characterisation, identification, estimation and forecasting", "comments": "46 pages", "journal-ref": "Annals of Actuarial Science 11 (2), pp. 343-389, 2017", "doi": "10.1017/S1748499517000069", "report-no": null, "categories": "q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores and develops alternative statistical representations and\nestimation approaches for dynamic mortality models. The framework we adopt is\nto reinterpret popular mortality models such as the Lee-Carter class of models\nin a general state-space modelling methodology, which allows modelling,\nestimation and forecasting of mortality under a unified framework. Furthermore,\nwe propose an alternative class of model identification constraints which is\nmore suited to statistical inference in filtering and parameter estimation\nsettings based on maximization of the marginalized likelihood or in Bayesian\ninference. We then develop a novel class of Bayesian state-space models which\nincorporate apriori beliefs about the mortality model characteristics as well\nas for more flexible and appropriate assumptions relating to heteroscedasticity\nthat present in observed mortality data. We show that multiple period and\ncohort effect can be cast under a state-space structure. To study long term\nmortality dynamics, we introduce stochastic volatility to the period effect.\nThe estimation of the resulting stochastic volatility model of mortality is\nperformed using a recent class of Monte Carlo procedure specifically designed\nfor state and parameter estimation in Bayesian state-space models, known as the\nclass of particle Markov chain Monte Carlo methods. We illustrate the framework\nwe have developed using Danish male mortality data, and show that incorporating\nheteroscedasticity and stochastic volatility markedly improves model fit\ndespite an increase of model complexity. Forecasting properties of the enhanced\nmodels are examined with long term and short term calibration periods on the\nreconstruction of life tables.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 03:51:17 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Fung", "Man Chung", ""], ["Peters", "Gareth W.", ""], ["Shevchenko", "Pavel V.", ""]]}]