[{"id": "2007.00017", "submitter": "Roman Orus", "authors": "Samuel Mugel, Carlos Kuchkovsky, Escolastico Sanchez, Samuel\n  Fernandez-Lorenzo, Jorge Luis-Hita, Enrique Lizaso, Roman Orus", "title": "Dynamic Portfolio Optimization with Real Datasets Using Quantum\n  Processors and Quantum-Inspired Tensor Networks", "comments": "11 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.CE q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we tackle the problem of dynamic portfolio optimization, i.e.,\ndetermining the optimal trading trajectory for an investment portfolio of\nassets over a period of time, taking into account transaction costs and other\npossible constraints. This problem, well-known to be NP-Hard, is central to\nquantitative finance. After a detailed introduction to the problem, we\nimplement a number of quantum and quantum-inspired algorithms on different\nhardware platforms to solve its discrete formulation using real data from daily\nprices over 8 years of 52 assets, and do a detailed comparison of the obtained\nSharpe ratios, profits and computing times. In particular, we implement\nclassical solvers (Gekko, exhaustive), D-Wave Hybrid quantum annealing, two\ndifferent approaches based on Variational Quantum Eigensolvers on IBM-Q (one of\nthem brand-new and tailored to the problem), and for the first time in this\ncontext also a quantum-inspired optimizer based on Tensor Networks. In order to\nfit the data into each specific hardware platform, we also consider doing a\npreprocessing based on clustering of assets. From our comparison, we conclude\nthat D-Wave Hybrid and Tensor Networks are able to handle the largest systems,\nwhere we do calculations up to 1272 fully-connected qubits for demonstrative\npurposes. Finally, we also discuss how to mathematically implement other\npossible real-life constraints, as well as several ideas to further improve the\nperformance of the studied methods.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 18:00:03 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Mugel", "Samuel", ""], ["Kuchkovsky", "Carlos", ""], ["Sanchez", "Escolastico", ""], ["Fernandez-Lorenzo", "Samuel", ""], ["Luis-Hita", "Jorge", ""], ["Lizaso", "Enrique", ""], ["Orus", "Roman", ""]]}, {"id": "2007.00254", "submitter": "Arabin Kumar Dey", "authors": "Shankhyajyoti De, Arabin Kumar Dey, and Deepak Gauda", "title": "Construction of confidence interval for a univariate stock price signal\n  predicted through Long Short Term Memory Network", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show an innovative way to construct bootstrap confidence\ninterval of a signal estimated based on a univariate LSTM model. We take three\ndifferent types of bootstrap methods for dependent set up. We prescribe some\nuseful suggestions to select the optimal block length while performing the\nbootstrapping of the sample. We also propose a benchmark to compare the\nconfidence interval measured through different bootstrap strategies. We\nillustrate the experimental results through some stock price data set.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 05:28:20 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["De", "Shankhyajyoti", ""], ["Dey", "Arabin Kumar", ""], ["Gauda", "Deepak", ""]]}, {"id": "2007.02673", "submitter": "Daniel \\v{S}tifani\\'c", "authors": "Daniel \\v{S}tifani\\'c, Jelena Musulin, Adrijana Mio\\v{c}evi\\'c, Sandi\n  Baressi \\v{S}egota, Roman \\v{S}ubi\\'c, Zlatan Car", "title": "Impact of COVID-19 on Forecasting Stock Prices: An Integration of\n  Stationary Wavelet Transform and Bidirectional Long Short-Term Memory", "comments": "26 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  COVID-19 is an infectious disease that mostly affects the respiratory system.\nAt the time of this research being performed, there were more than 1.4 million\ncases of COVID-19, and one of the biggest anxieties is not just our health, but\nour livelihoods, too. In this research, authors investigate the impact of\nCOVID-19 on the global economy, more specifically, the impact of COVID-19 on\nfinancial movement of Crude Oil price and three U.S. stock indexes: DJI, S&P\n500 and NASDAQ Composite. The proposed system for predicting commodity and\nstock prices integrates the Stationary Wavelet Transform (SWT) and\nBidirectional Long Short-Term Memory (BDLSTM) networks. Firstly, SWT is used to\ndecompose the data into approximation and detail coefficients. After\ndecomposition, data of Crude Oil price and stock market indexes along with\nCOVID-19 confirmed cases were used as input variables for future price movement\nforecasting. As a result, the proposed system BDLSTM+WT-ADA achieved\nsatisfactory results in terms of five-day Crude Oil price forecast.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 14:03:39 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["\u0160tifani\u0107", "Daniel", ""], ["Musulin", "Jelena", ""], ["Mio\u010devi\u0107", "Adrijana", ""], ["\u0160egota", "Sandi Baressi", ""], ["\u0160ubi\u0107", "Roman", ""], ["Car", "Zlatan", ""]]}, {"id": "2007.03453", "submitter": "Patrick Chang", "authors": "Patrick Chang", "title": "Fourier instantaneous estimators and the Epps effect", "comments": "17 pages, 10 figures, 2 tables. Link to the supporting Julia code:\n  https://github.com/CHNPAT005/PC-FIE", "journal-ref": "PLoS ONE 15(9): e0239415, 2020", "doi": "10.1371/journal.pone.0239415", "report-no": null, "categories": "q-fin.ST q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the Malliavin-Mancino and Cuchiero-Teichmann Fourier instantaneous\nestimators to investigate the impact of the Epps effect arising from asynchrony\nin the instantaneous estimates. We demonstrate the instantaneous Epps effect\nunder a simulation setting and provide a simple method to ameliorate the\neffect. We find that using the previous tick interpolation in the\nCuchiero-Teichmann estimator results in unstable estimates when dealing with\nasynchrony, while the ability to bypass the time domain with the\nMalliavin-Mancino estimator allows it to produce stable estimates and is\ntherefore better suited for ultra-high frequency finance. An empirical analysis\nusing Trade and Quote data from the Johannesburg Stock Exchange illustrates the\ninstantaneous Epps effect and how the intraday correlation dynamics can vary\nbetween days for the same equity pair.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 16:49:30 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 11:40:42 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Chang", "Patrick", ""]]}, {"id": "2007.03980", "submitter": "Matthias Raddant", "authors": "Matthias Raddant and Hiroshi Takahashi", "title": "Network effects and the appointment of female board members in Japan", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN q-fin.EC q-fin.GN q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the dynamics in the networks of Japanese corporates and its\ninterplay with the appointment of female board members. We find that firms with\nfemale board members show homophily with respect to gender and often have above\naverage profitability. We also find that new appointments of women are more\nlikely at boards which observe female board members at other firms to which\nthey are tied by either ownership relations or corporate board interlocks.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 09:37:07 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Raddant", "Matthias", ""], ["Takahashi", "Hiroshi", ""]]}, {"id": "2007.04082", "submitter": "Lakshay Chauhan", "authors": "Lakshay Chauhan, John Alberg, Zachary C. Lipton", "title": "Uncertainty-Aware Lookahead Factor Models for Quantitative Investing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On a periodic basis, publicly traded companies report fundamentals, financial\ndata including revenue, earnings, debt, among others. Quantitative finance\nresearch has identified several factors, functions of the reported data that\nhistorically correlate with stock market performance. In this paper, we first\nshow through simulation that if we could select stocks via factors calculated\non future fundamentals (via oracle), that our portfolios would far outperform\nstandard factor models. Motivated by this insight, we train deep nets to\nforecast future fundamentals from a trailing 5-year history. We propose\nlookahead factor models which plug these predicted future fundamentals into\ntraditional factors. Finally, we incorporate uncertainty estimates from both\nneural heteroscedastic regression and a dropout-based heuristic, improving\nperformance by adjusting our portfolios to avert risk. In retrospective\nanalysis, we leverage an industry-grade portfolio simulator (backtester) to\nshow simultaneous improvement in annualized return and Sharpe ratio.\nSpecifically, the simulated annualized return for the uncertainty-aware model\nis 17.7% (vs 14.0% for a standard factor model) and the Sharpe ratio is 0.84\n(vs 0.52).\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 00:18:40 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2020 16:52:16 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Chauhan", "Lakshay", ""], ["Alberg", "John", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2007.04829", "submitter": "Zoltan Neda", "authors": "Tam\\'as S. Bir\\'o and Zolt\\'an N\\'eda", "title": "Gintropy: Gini index based generalization of Entropy", "comments": "13 pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy is being used in physics, mathematics, informatics and in related\nareas to describe equilibration, dissipation, maximal probability states and\noptimal compression of information. The Gini index on the other hand is an\nestablished measure for social and economical inequalities in a society. In\nthis paper we explore the mathematical similarities and connections in these\ntwo quantities and introduce a new measure that is capable to connect these two\nat an interesting analogy level. This supports the idea that a generalization\nof the Gibbs--Boltzmann--Shannon entropy, based on a transformation of the\nLorenz curve, can properly serve in quantifying different aspects of complexity\nin socio- and econo-physics.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 14:22:56 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Bir\u00f3", "Tam\u00e1s S.", ""], ["N\u00e9da", "Zolt\u00e1n", ""]]}, {"id": "2007.04838", "submitter": "Thierry Roncalli", "authors": "Edmond Lezmi, Jules Roche, Thierry Roncalli, Jiali Xu", "title": "Improving the Robustness of Trading Strategy Backtesting with Boltzmann\n  Machines and Generative Adversarial Networks", "comments": "72 pages, 30 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.PM q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article explores the use of machine learning models to build a market\ngenerator. The underlying idea is to simulate artificial multi-dimensional\nfinancial time series, whose statistical properties are the same as those\nobserved in the financial markets. In particular, these synthetic data must\npreserve the probability distribution of asset returns, the stochastic\ndependence between the different assets and the autocorrelation across time.\nThe article proposes then a new approach for estimating the probability\ndistribution of backtest statistics. The final objective is to develop a\nframework for improving the risk management of quantitative investment\nstrategies, in particular in the space of smart beta, factor investing and\nalternative risk premia.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 14:37:45 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Lezmi", "Edmond", ""], ["Roche", "Jules", ""], ["Roncalli", "Thierry", ""], ["Xu", "Jiali", ""]]}, {"id": "2007.06262", "submitter": "Filippo Petroni", "authors": "Guglielmo D'Amico and Filippo Petroni", "title": "A micro-to-macro approach to returns, volumes and waiting times", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fundamental variables in financial market are not only price and return but a\nvery important role is also played by trading volumes. Here we propose a new\nmultivariate model that takes into account price returns, logarithmic variation\nof trading volumes and also waiting times, the latter to be intended as the\ntime interval between changes in trades, price, and volume of stocks. Our\napproach is based on a generalization of semi-Markov chains where an endogenous\nindex process is introduced. We also take into account the dependence structure\nbetween the above mentioned variables by means of copulae. The proposed model\nis motivated by empirical evidences which are known in financial literature and\nthat are also confirmed in this work by analysing real data from Italian stock\nmarket in the period August 2015 - August 2017. By using Monte Carlo\nsimulations, we show that the model reproduces all these empirical evidences.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 09:31:49 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["D'Amico", "Guglielmo", ""], ["Petroni", "Filippo", ""]]}, {"id": "2007.06848", "submitter": "Jungsik Hwang", "authors": "Jungsik Hwang", "title": "Modeling Financial Time Series using LSTM with Trainable Initial Hidden\n  States", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting previously unknown patterns and information in time series is\ncentral to many real-world applications. In this study, we introduce a novel\napproach to modeling financial time series using a deep learning model. We use\na Long Short-Term Memory (LSTM) network equipped with the trainable initial\nhidden states. By learning to reconstruct time series, the proposed model can\nrepresent high-dimensional time series data with its parameters. An experiment\nwith the Korean stock market data showed that the model was able to capture the\nrelative similarity between a large number of stock prices in its latent space.\nBesides, the model was also able to predict the future stock trends from the\nlatent space. The proposed method can help to identify relationships among many\ntime series, and it could be applied to financial applications, such as\noptimizing the investment portfolios.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 06:36:10 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Hwang", "Jungsik", ""]]}, {"id": "2007.08115", "submitter": "Vassilis Polimenis", "authors": "Vassilis Polimenis", "title": "Uncovering a factor-based expected return conditioning structure with\n  Regression Trees jointly for many stocks", "comments": "11 pages, 5 tables, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the success and almost universal acceptance of the simple linear\nregression three-factor model, it is interesting to analyze the informational\ncontent of the three factors in explaining stock returns when the analysis is\nallowed to consider non-linear dependencies between factors and stock returns.\nIn order to better understand factor-based conditioning information with\nrespect to expected stock returns within a regression tree setting, the\nanalysis of stock returns is demonstrated using daily stock return data for 5\nmajor US corporations. The first finding is that in all cases (solo and joint)\nthe most informative factor is always the market excess return factor. Further,\nthree major issues are discussed: a) the balance of a depth=1 tree as it\nrelates to properties of the stock return distribution, b) the mechanism behind\ndepth=1 tree balance in a joint regression tree and c) the dominant stock in a\njoint regression tree. It is shown that high skew values alone cannot explain\nthe imbalance of the resulting tree split as stocks with pronounced skew may\nproduce balanced tree splits.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 05:01:39 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Polimenis", "Vassilis", ""]]}, {"id": "2007.09043", "submitter": "Matthieu Garcin", "authors": "Matthieu Garcin, Jules Klein, Sana Laaribi", "title": "Estimation of time-varying kernel densities and chronology of the impact\n  of COVID-19 on financial markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The time-varying kernel density estimation relies on two free parameters: the\nbandwidth and the discount factor. We propose to select these parameters so as\nto minimize a criterion consistent with the traditional requirements of the\nvalidation of a probability density forecast. These requirements are both the\nuniformity and the independence of the so-called probability integral\ntransforms, which are the forecast time-varying cumulated distributions applied\nto the observations. We thus build a new numerical criterion incorporating both\nthe uniformity and independence properties by the mean of an adapted\nKolmogorov-Smirnov statistic. We apply this method to financial markets during\nthe COVID-19 crisis. We determine the time-varying density of daily price\nreturns of several stock indices and, using various divergence statistics, we\nare able to describe the chronology of the crisis as well as regional\ndisparities. For instance, we observe a more limited impact of COVID-19 on\nfinancial markets in China, a strong impact in the US, and a slow recovery in\nEurope.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 15:13:52 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Garcin", "Matthieu", ""], ["Klein", "Jules", ""], ["Laaribi", "Sana", ""]]}, {"id": "2007.10727", "submitter": "Matthieu Garcin", "authors": "Ayoub Ammy-Driss and Matthieu Garcin", "title": "Efficiency of the financial markets during the COVID-19 crisis:\n  time-varying parameters of fractional stable dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.GN stat.AP stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates the impact of COVID-19 on financial markets. It\nfocuses on the evolution of the market efficiency, using two efficiency\nindicators: the Hurst exponent and the memory parameter of a fractional\nL\\'evy-stable motion. The second approach combines, in the same model of\ndynamic, an alpha-stable distribution and a dependence structure between price\nreturns. We provide a dynamic estimation method for the two efficiency\nindicators. This method introduces a free parameter, the discount factor, which\nwe select so as to get the best alpha-stable density forecasts for observed\nprice returns. The application to stock indices during the COVID-19 crisis\nshows a strong loss of efficiency for US indices. On the opposite, Asian and\nAustralian indices seem less affected and the inefficiency of these markets\nduring the COVID-19 crisis is even questionable.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2020 11:39:41 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 17:16:15 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Ammy-Driss", "Ayoub", ""], ["Garcin", "Matthieu", ""]]}, {"id": "2007.11098", "submitter": "Omid Safarzadeh", "authors": "Omid Safarzadeh", "title": "Generating Trading Signals by ML algorithms or time series ones?", "comments": "20 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research investigates efficiency on-line learning Algorithms to generate\ntrading signals.I employed technical indicators based on high frequency stock\nprices and generated trading signals through ensemble of Random Forests.\nSimilarly, Kalman Filter was used for signaling trading positions. Comparing\nTime Series methods with Machine Learning methods, results spurious of Kalman\nFilter to Random Forests in case of on-line learning predictions of stock\nprices\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2020 12:41:22 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Safarzadeh", "Omid", ""]]}, {"id": "2007.11546", "submitter": "Jiawei Du", "authors": "Jiawei Du", "title": "A Research on Cross-sectional Return Dispersion and Volatility of US\n  Stock Market during COVID-19", "comments": "1. The code for the caculation of CSAD and CSSD has some mistakes. 2.\n  There are some vague points in the description of herding effect. 3.I update\n  all the mistakes, typo and the inaccurate description and enrich the data and\n  models to contribute to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We studied the volatility and cross-sectional return dispersion effect of S&P\nHealth Care Sector under the covid-19 epidemic. We innovatively used the Google\nindex to proxy the impact of the epidemic and modeled the volatility. We also\nstudied the influencing factors of the log-return of S&P Energy Sector and S&P\nHealth Care Sector. We found that volatility is significantly affected by both\nthe epidemic and cross-sectional return dispersion, and the coefficients in\nfront of them are all positive, which means that the herding behaviour did not\nexist and as the cross-sectional return dispersion increases and the epidemic\nbecomes more severe, the volatility of stock returns is also increasing. We\nalso found that the epidemic has a significant negative impact on the return of\nthe energy sector, and finally we provided our suggestions to investors.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 17:00:24 GMT"}, {"version": "v2", "created": "Wed, 24 Mar 2021 12:21:04 GMT"}], "update_date": "2021-03-25", "authors_parsed": [["Du", "Jiawei", ""]]}, {"id": "2007.12620", "submitter": "Yang Li", "authors": "Yang Li and Yi Pan", "title": "A Novel Ensemble Deep Learning Model for Stock Prediction Based on Stock\n  Prices and News", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, machine learning and deep learning have become popular\nmethods for financial data analysis, including financial textual data,\nnumerical data, and graphical data. This paper proposes to use sentiment\nanalysis to extract useful information from multiple textual data sources and a\nblending ensemble deep learning model to predict future stock movement. The\nblending ensemble model contains two levels. The first level contains two\nRecurrent Neural Networks (RNNs), one Long-Short Term Memory network (LSTM) and\none Gated Recurrent Units network (GRU), followed by a fully connected neural\nnetwork as the second level model. The RNNs, LSTM, and GRU models can\neffectively capture the time-series events in the input data, and the fully\nconnected neural network is used to ensemble several individual prediction\nresults to further improve the prediction accuracy. The purpose of this work is\nto explain our design philosophy and show that ensemble deep learning\ntechnologies can truly predict future stock price trends more effectively and\ncan better assist investors in making the right investment decision than other\ntraditional methods.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 15:25:37 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Li", "Yang", ""], ["Pan", "Yi", ""]]}, {"id": "2007.12838", "submitter": "Peng-Fei Dai", "authors": "Peng-Fei Dai (TJU), Xiong Xiong (TJU), Wei-Xing Zhou (ECUST)", "title": "The role of global economic policy uncertainty in predicting crude oil\n  futures volatility: Evidence from a two-factor GARCH-MIDAS model", "comments": "19 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to examine whether the global economic policy uncertainty\n(GEPU) and uncertainty changes have different impacts on crude oil futures\nvolatility. We establish single-factor and two-factor models under the\nGARCH-MIDAS framework to investigate the predictive power of GEPU and GEPU\nchanges excluding and including realized volatility. The findings show that the\nmodels with rolling-window specification perform better than those with\nfixed-span specification. For single-factor models, the GEPU index and its\nchanges, as well as realized volatility, are consistent effective factors in\npredicting the volatility of crude oil futures. Specially, GEPU changes have\nstronger predictive power than the GEPU index. For two-factor models, GEPU is\nnot an effective forecast factor for the volatility of WTI crude oil futures or\nBrent crude oil futures. The two-factor model with GEPU changes contains more\ninformation and exhibits stronger forecasting ability for crude oil futures\nmarket volatility than the single-factor models. The GEPU changes are indeed\nthe main source of long-term volatility of the crude oil futures.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 02:52:44 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Dai", "Peng-Fei", "", "TJU"], ["Xiong", "Xiong", "", "TJU"], ["Zhou", "Wei-Xing", "", "ECUST"]]}, {"id": "2007.12880", "submitter": "Peng-Fei Dai", "authors": "Peng-Fei Dai (TJU), Xiong Xiong (TJU), Wei-Xing Zhou (ECUST)", "title": "Visibility graph analysis of economy policy uncertainty indices", "comments": "9 pages, 13 figures", "journal-ref": "Physica A 0378-4371(2019)", "doi": "10.1016/j.physa.2019.121748", "report-no": null, "categories": "q-fin.ST econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty plays an important role in the global economy. In this paper, the\neconomic policy uncertainty (EPU) indices of the United States and China are\nselected as the proxy variable corresponding to the uncertainty of national\neconomic policy. By adopting the visibility graph algorithm, the four economic\npolicy uncertainty indices of the United States and China are mapped into\ncomplex networks, and the topological properties of the corresponding networks\nare studied. The Hurst exponents of all the four indices are within\n$\\left[0.5,1\\right]$, which implies that the economic policy uncertainty is\npersistent. The degree distributions of the EPU networks have power-law tails\nand are thus scale-free. The average clustering coefficients of the four EPU\nnetworks are high and close to each other, while these networks exhibit weak\nassortative mixing. We also find that the EPU network in United States based on\ndaily data shows the small-world feature since the average shortest path length\nincreases logarithmically with the network size such that\n$L\\left(N\\right)=0.626\\ln N+0.405$. Our research highlights the possibility to\nstudy the EPU from the view angle of complex networks.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 08:12:17 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Dai", "Peng-Fei", "", "TJU"], ["Xiong", "Xiong", "", "TJU"], ["Zhou", "Wei-Xing", "", "ECUST"]]}, {"id": "2007.13566", "submitter": "Luca Rossini", "authors": "Claudia Foroni and Francesco Ravazzolo and Luca Rossini", "title": "Are low frequency macroeconomic variables important for high frequency\n  electricity prices?", "comments": "This paper has previously circulated with the title: \"Forecasting\n  daily electricity prices with monthly macroeconomic variables\" (ECB Working\n  paper Series No. 2250)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the importance of low frequency hard and soft macroeconomic\ninformation, respectively the industrial production index and the manufacturing\nPurchasing Managers' Index surveys, for forecasting high-frequency daily\nelectricity prices in two of the main European markets, Germany and Italy. We\ndo that by means of mixed-frequency models, introducing a Bayesian approach to\nreverse unrestricted MIDAS models (RU-MIDAS). Despite the general parsimonious\nstructure of standard MIDAS models, the RU-MIDAS has a large set of parameters\nwhen several predictors are considered simultaneously and Bayesian inference is\nuseful for imposing parameter restrictions. We study the forecasting accuracy\nfor different horizons (from $1$ day ahead to $28$ days ahead) and by\nconsidering different specifications of the models. Results indicate that the\nmacroeconomic low frequency variables are more important for short horizons\nthan for longer horizons. Moreover, accuracy increases by combining hard and\nsoft information, and using only surveys gives less accurate forecasts than\nusing only industrial production data.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 12:21:30 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Foroni", "Claudia", ""], ["Ravazzolo", "Francesco", ""], ["Rossini", "Luca", ""]]}, {"id": "2007.14447", "submitter": "Gholamreza Jafari", "authors": "Ali Namaki, Jamshid Ardalankia, Reza Raei, Leila Hedayatifar, Ali\n  Hosseiny, Emmanuel Haven, G.Reza Jafari", "title": "Analysis of the Global Banking Network by Random Matrix Theory", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since 2008, the network analysis of financial systems is one of the most\nimportant subjects in economics. In this paper, we have used the complexity\napproach and Random Matrix Theory (RMT) for analyzing the global banking\nnetwork. By applying this method on a cross border lending network, it is shown\nthat the network has been denser and the connectivity between peripheral nodes\nand the central section has risen. Also, by considering the collective behavior\nof the system and comparing it with the shuffled one, we can see that this\nnetwork obtains a specific structure. By using the inverse participation ratio\nconcept, we can see that after 2000, the participation of different modes to\nthe network has increased and tends to the market mode of the system. Although\nno important change in the total market share of trading occurs, through the\npassage of time, the contribution of some countries in the network structure\nhas increased. The technique proposed in the paper can be useful for analyzing\ndifferent types of interaction networks between countries.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 19:39:11 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Namaki", "Ali", ""], ["Ardalankia", "Jamshid", ""], ["Raei", "Reza", ""], ["Hedayatifar", "Leila", ""], ["Hosseiny", "Ali", ""], ["Haven", "Emmanuel", ""], ["Jafari", "G. Reza", ""]]}, {"id": "2007.14630", "submitter": "Hideaki Aoyama", "authors": "Yoshi Fujiwara, Hiroyasu Inoue, Takayuki Yamaguchi, Hideaki Aoyama,\n  and Takuma Tanaka", "title": "Money flow network among firms' accounts in a regional bank of Japan", "comments": "22 pages with 13 figures and 5 tables", "journal-ref": null, "doi": null, "report-no": "RIKEN-iTHEMS-Report-20", "categories": "q-fin.GN q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we investigate the flow of money among bank accounts possessed\nby firms in a region by employing an exhaustive list of all the bank transfers\nin a regional bank in Japan, to clarify how the network of money flow is\nrelated to the economic activities of the firms. The network statistics and\nstructures are examined and shown to be similar to those of a nationwide\nproduction network. Specifically, the bowtie analysis indicates what we refer\nto as a \"walnut\" structure with core and upstream/downstream components. To\nquantify the location of an individual account in the network, we used the\nHodge decomposition method and found that the Hodge potential of the account\nhas a significant correlation to its position in the bowtie structure as well\nas to its net flow of incoming and outgoing money and links, namely the net\ndemand/supply of individual accounts. In addition, we used non-negative matrix\nfactorization to identify important factors underlying the entire flow of\nmoney; it can be interpreted that these factors are associated with regional\neconomic activities.One factor has a feature whereby the remittance source is\nlocalized to the largest city in the region, while the destination is\nscattered. The other factors correspond to the economic activities specific to\ndifferent local places.This study serves as a basis for further investigation\non the relationship between money flow and economic activities of firms.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 06:50:50 GMT"}, {"version": "v2", "created": "Thu, 30 Jul 2020 08:24:17 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Fujiwara", "Yoshi", ""], ["Inoue", "Hiroyasu", ""], ["Yamaguchi", "Takayuki", ""], ["Aoyama", "Hideaki", ""], ["Tanaka", "Takuma", ""]]}, {"id": "2007.14874", "submitter": "Lennart Oelschl\\\"ager", "authors": "Lennart Oelschl\\\"ager and Timo Adam", "title": "Detecting bearish and bullish markets in financial time series using\n  hierarchical hidden Markov models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial markets exhibit alternating periods of rising and falling prices.\nStock traders seeking to make profitable investment decisions have to account\nfor those trends, where the goal is to accurately predict switches from bullish\ntowards bearish markets and vice versa. Popular tools for modeling financial\ntime series are hidden Markov models, where a latent state process is used to\nexplicitly model switches among different market regimes. In their basic form,\nhowever, hidden Markov models are not capable of capturing both short- and\nlong-term trends, which can lead to a misinterpretation of short-term price\nfluctuations as changes in the long-term trend. In this paper, we demonstrate\nhow hierarchical hidden Markov models can be used to draw a comprehensive\npicture of financial markets, which can contribute to the development of more\nsophisticated trading strategies. The feasibility of the suggested approach is\nillustrated in two real-data applications, where we model data from two major\nstock indices, the Deutscher Aktienindex and the Standard & Poor's 500.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 14:50:00 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Oelschl\u00e4ger", "Lennart", ""], ["Adam", "Timo", ""]]}, {"id": "2007.15128", "submitter": "Alexandre Carbonneau", "authors": "Alexandre Carbonneau", "title": "Deep Hedging of Long-Term Financial Derivatives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.CP q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents a deep reinforcement learning approach for global hedging\nof long-term financial derivatives. A similar setup as in Coleman et al. (2007)\nis considered with the risk management of lookback options embedded in\nguarantees of variable annuities with ratchet features. The deep hedging\nalgorithm of Buehler et al. (2019a) is applied to optimize neural networks\nrepresenting global hedging policies with both quadratic and non-quadratic\npenalties. To the best of the author's knowledge, this is the first paper that\npresents an extensive benchmarking of global policies for long-term contingent\nclaims with the use of various hedging instruments (e.g. underlying and\nstandard options) and with the presence of jump risk for equity. Monte Carlo\nexperiments demonstrate the vast superiority of non-quadratic global hedging as\nit results simultaneously in downside risk metrics two to three times smaller\nthan best benchmarks and in significant hedging gains. Analyses show that the\nneural networks are able to effectively adapt their hedging decisions to\ndifferent penalties and stylized facts of risky asset dynamics only by\nexperiencing simulations of the financial market exhibiting these features.\nNumerical results also indicate that non-quadratic global policies are\nsignificantly more geared towards being long equity risk which entails earning\nthe equity risk premium.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 21:57:29 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Carbonneau", "Alexandre", ""]]}, {"id": "2007.15475", "submitter": "Roland Ramsahai", "authors": "Roland R. Ramsahai", "title": "Connecting actuarial judgment to probabilistic learning techniques with\n  graph theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical models have been widely used in applications ranging from medical\nexpert systems to natural language processing. Their popularity partly arises\nsince they are intuitive representations of complex inter-dependencies among\nvariables with efficient algorithms for performing computationally intensive\ninference in high-dimensional models. It is argued that the formalism is very\nuseful for applications in the modelling of non-life insurance claims data. It\nis also shown that actuarial models in current practice can be expressed\ngraphically to exploit the advantages of the approach. More general models are\nproposed within the framework to demonstrate the potential use of graphical\nmodels for probabilistic learning with telematics and other dynamic actuarial\ndata. The discussion also demonstrates throughout that the intuitive nature of\nthe models allows the inclusion of qualitative knowledge or actuarial judgment\nin analyses.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 13:24:40 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Ramsahai", "Roland R.", ""]]}, {"id": "2007.15545", "submitter": "Carlo Campajola", "authors": "Carlo Campajola and Domenico Di Gangi and Fabrizio Lillo and Daniele\n  Tantari", "title": "Modelling time-varying interactions in complex systems: the Score Driven\n  Kinetic Ising Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cond-mat.dis-nn physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a generalization of the Kinetic Ising Model using the\nscore-driven approach, which allows the efficient estimation and filtering of\ntime-varying parameters from time series data. We show that this approach\nallows to overcome systematic errors in the parameter estimation, and is useful\nto study complex systems of interacting variables where the strength of the\ninteractions is not constant in time: in particular we propose to quantify the\namount of noise in the data and the reliability of forecasts, as well as to\ndiscriminate between periods of higher or lower endogeneity in the observed\ndynamics, namely when interactions are more or less relevant in determining the\nrealization of the observations. We apply our methodology to three different\nfinancial settings to showcase some realistic applications, focusing on\nforecasting high-frequency volatility of stocks, measuring its endogenous\ncomponent during extreme events in the market, and analysing the strategic\nbehaviour of traders around news releases. We find interesting results on\nfinancial systems and, given the widespread use of Ising models in multiple\nfields, we believe our approach can be efficiently adapted to a variety of\nsettings, ranging from neuroscience to social sciences and machine learning.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 15:51:11 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Campajola", "Carlo", ""], ["Di Gangi", "Domenico", ""], ["Lillo", "Fabrizio", ""], ["Tantari", "Daniele", ""]]}, {"id": "2007.15982", "submitter": "Trent Spears", "authors": "Trent Spears, Stefan Zohren and Stephen Roberts", "title": "Investment sizing with deep learning prediction uncertainties for\n  high-frequency Eurodollar futures trading", "comments": "15 pages, 6 Figures, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we show that prediction uncertainty estimates gleaned from deep\nlearning models can be useful inputs for influencing the relative allocation of\nrisk capital across trades. In this way, consideration of uncertainty is\nimportant because it permits the scaling of investment size across trade\nopportunities in a principled and data-driven way. We showcase this insight\nwith a prediction model and find clear outperformance based on a Sharpe ratio\nmetric, relative to trading strategies that either do not take uncertainty into\naccount, or that utilize an alternative market-based statistic as a proxy for\nuncertainty. Of added novelty is our modelling of high-frequency data at the\ntop level of the Eurodollar Futures limit order book for each trading day of\n2018, whereby we predict interest rate curve changes on small time horizons. We\nare motivated to study the market for these popularly-traded interest rate\nderivatives since it is deep and liquid, and contributes to the efficient\nfunctioning of global finance -- though there is relatively little by way of\nits modelling contained in the academic literature. Hence, we verify the\nutility of prediction models and uncertainty estimates for trading applications\nin this complex and multi-dimensional asset price space.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 11:44:07 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Spears", "Trent", ""], ["Zohren", "Stefan", ""], ["Roberts", "Stephen", ""]]}]