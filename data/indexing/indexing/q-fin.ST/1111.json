[{"id": "1111.1113", "submitter": "Jean-Philippe Bruneton", "authors": "Jean-Philippe Bruneton", "title": "Copula-based Hierarchical Aggregation of Correlated Risks. The behaviour\n  of the diversification benefit in Gaussian and Lognormal Trees", "comments": "38 pages, 7 figures; Version 2: added contact information. Submitted\n  to Finance and Stochastics", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.CP q-fin.PM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The benefits of diversifying risks are difficult to estimate quantitatively\nbecause of the uncertainties in the dependence structure between the risks.\nAlso, the modelling of multidimensional dependencies is a non-trivial task.\nThis paper focuses on one such technique for portfolio aggregation, namely the\naggregation of risks within trees, where dependencies are set at each step of\nthe aggregation with the help of some copulas. We define rigorously this\nprocedure and then study extensively the Gaussian Tree of quite arbitrary size\nand shape, where individual risks are normal, and where the Gaussian copula is\nused. We derive exact analytical results for the diversification benefit of the\nGaussian tree as a function of its shape and of the dependency parameters.\n  Such a \"toy-model\" of an aggregation tree enables one to understand the basic\nphenomena's at play while aggregating risks in this way. In particular, it is\nshown that, for a fixed number of individual risks, \"thin\" trees diversify\nbetter than \"fat\" trees. Related to this, it is shown that hierarchical trees\nhave the natural tendency to lower the overall dependency with respect to the\ndependency parameter chosen at each step of the aggregation. We also show that\nthese results hold in more general cases outside the gaussian world, and apply\nnotably to more realistic portfolios (LogNormal trees). We believe that any\ninsurer or reinsurer using such a tool should be aware of these systematic\neffects, and that this awareness should strongly call for designing trees that\nadequately fit the business.\n  We finally address the issue of specifying the full joint distribution\nbetween the risks. We show that the hierarchical mechanism does not require nor\nspecify the joint distribution, but that the latter can be determined exactly\n(in the Gaussian case) by adding conditional independence hypotheses between\nthe risks and their sums.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2011 12:57:34 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2011 08:51:31 GMT"}], "update_date": "2011-11-11", "authors_parsed": [["Bruneton", "Jean-Philippe", ""]]}, {"id": "1111.1133", "submitter": "Xi Luo", "authors": "Xi Luo", "title": "Recovering Model Structures from Large Low Rank and Sparse Covariance\n  Matrix Estimation", "comments": "35 pages, 3 figures. Presented at JSM 2011 and various invited\n  seminars since February, 2011. R package available from\n  http://cran.r-project.org/web/packages/lorec/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-fin.PM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many popular statistical models, such as factor and random effects models,\ngive arise a certain type of covariance structures that is a summation of low\nrank and sparse matrices. This paper introduces a penalized approximation\nframework to recover such model structures from large covariance matrix\nestimation. We propose an estimator based on minimizing a non-likelihood loss\nwith separable non-smooth penalty functions. This estimator is shown to recover\nexactly the rank and sparsity patterns of these two components, and thus\npartially recovers the model structures. Convergence rates under various matrix\nnorms are also presented. To compute this estimator, we further develop a\nfirst-order iterative algorithm to solve a convex optimization problem that\ncontains separa- ble non-smooth functions, and the algorithm is shown to\nproduce a solution within O(1/t^2) of the optimal, after any finite t\niterations. Numerical performance is illustrated using simulated data and stock\nportfolio selection on S&P 100.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2011 14:12:49 GMT"}, {"version": "v2", "created": "Sat, 16 Mar 2013 20:21:23 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Luo", "Xi", ""]]}, {"id": "1111.2038", "submitter": "C\\'esar A. Terrero-Escalante", "authors": "Lester Alfonso, Ricardo Mansilla, and Cesar A. Terrero-Escalante", "title": "On the scaling of the distribution of daily price fluctuations in\n  Mexican financial market index", "comments": "13 pages, 4 figures, 4 tables", "journal-ref": null, "doi": "10.1016/j.physa.2012.01.023", "report-no": null, "categories": "q-fin.ST physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a statistical analysis of log-return fluctuations of the IPC,\nthe Mexican Stock Market Index is presented. A sample of daily data covering\nthe period from $04/09/2000-04/09/2010$ was analyzed, and fitted to different\ndistributions. Tests of the goodness of fit were performed in order to\nquantitatively asses the quality of the estimation. Special attention was paid\nto the impact of the size of the sample on the estimated decay of the\ndistributions tail. In this study a forceful rejection of normality was\nobtained. On the other hand, the null hypothesis that the log-fluctuations are\nfitted to a $\\alpha$-stable L\\'evy distribution cannot be rejected at 5%\nsignificance level.\n", "versions": [{"version": "v1", "created": "Tue, 8 Nov 2011 20:42:51 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Alfonso", "Lester", ""], ["Mansilla", "Ricardo", ""], ["Terrero-Escalante", "Cesar A.", ""]]}, {"id": "1111.3127", "submitter": "Argimiro Arratia", "authors": "Argimiro Arratia and Alejandra Caba\\~na", "title": "Tracing the temporal evolution of clusters in a financial stock market", "comments": "22 pages, 3 figures (submitted for publication)", "journal-ref": null, "doi": "10.1007/s10614-012-9327-x", "report-no": null, "categories": "cs.CE math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a methodology for clustering financial time series of stocks'\nreturns, and a graphical set-up to quantify and visualise the evolution of\nthese clusters through time. The proposed graphical representation allows for\nthe application of well known algorithms for solving classical combinatorial\ngraph problems, which can be interpreted as problems relevant to portfolio\ndesign and investment strategies. We illustrate this graph representation of\nthe evolution of clusters in time and its use on real data from the Madrid\nStock Exchange market.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2011 08:04:16 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Arratia", "Argimiro", ""], ["Caba\u00f1a", "Alejandra", ""]]}, {"id": "1111.4414", "submitter": "Wayne Tarrant", "authors": "Dominique Gu\\'egan, Wayne Tarrant", "title": "On the Necessity of Five Risk Measures", "comments": "23 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The banking systems that deal with risk management depend on underlying risk\nmeasures. Following the Basel II accord, there are two separate methods by\nwhich banks may determine their capital requirement. The Value at Risk measure\nplays an important role in computing the capital for both approaches. In this\npaper we analyze the errors produced by using this measure. We discuss other\nmeasures, demonstrating their strengths and shortcomings. We give examples,\nshowing the need for the information from multiple risk measures in order to\ndetermine a bank's loss distribution. We conclude by suggesting a regulatory\nrequirement of multiple risk measures being reported by banks, giving specific\nrecommendations.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2011 16:29:31 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Gu\u00e9gan", "Dominique", ""], ["Tarrant", "Wayne", ""]]}, {"id": "1111.4417", "submitter": "Wayne Tarrant", "authors": "Dominique Gu/'egan, Wayne Tarrant", "title": "Viewing Risk Measures as Information", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regulation and risk management in banks depend on underlying risk measures.\nIn general this is the only purpose that is seen for risk measures. In this\npaper we suggest that the reporting of risk measures can be used to determine\nthe loss distribution function for a financial entity. We demonstrate that a\nlack of sufficient information can lead to ambiguous risk situations. We give\nexamples, showing the need for the reporting of multiple risk measures in order\nto determine a bank's loss distribution. We conclude by suggesting a regulatory\nrequirement of multiple risk measures being reported by banks, giving specific\nrecommendations.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2011 16:38:22 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Gu/'egan", "Dominique", ""], ["Tarrant", "Wayne", ""]]}, {"id": "1111.4637", "submitter": "Jun-Ichi Maskawa", "authors": "Jun-ichi Maskawa", "title": "Collective behavior of stock prices as a precursor to market crash", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": "10.1143/PTPS.194.1", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study precursors to the global market crash that occurred on all main\nstock exchanges throughout the world in October 2008 about three weeks after\nthe bankruptcy of Lehman Brothers Holdings Inc. on 15 September. We examine the\ncollective behavior of stock returns and analyze the market mode, which is a\nmarket-wide collective mode, with constituent issues of the FTSE 100 index\nlisted on the London Stock Exchange. Before the market crash, a sharp rise in a\nmeasure of the collective behavior was observed. It was shown to be associated\nwith news including the words \"financial crisis.\" They did not impact stock\nprices severely alone, but they exacerbated the pessimistic mood that prevailed\namong stock market participants. Such news increased after the Lehman shock\npreceding the market crash. The variance increased along with the cumulative\namount of news according to a power law.\n", "versions": [{"version": "v1", "created": "Sun, 20 Nov 2011 14:50:58 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Maskawa", "Jun-ichi", ""]]}, {"id": "1111.5069", "submitter": "Leonidas Sandoval", "authors": "Leonidas Sandoval Junior", "title": "Cluster formation and evolution in networks of financial market indices", "comments": null, "journal-ref": null, "doi": "10.3233/AF-13015", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using data from world stock exchange indices prior to and during periods of\nglobal financial crises, clusters and networks of indices are built for\ndifferent thresholds and diverse periods of time, so that it is then possible\nto analyze how clusters are formed according to correlations among indices and\nhow they evolve in time, particularly during times of financial crises. Further\nanalysis is made on the eigenvectors corresponding to the second highest\neigenvalues of the correlation matrices, revealing a structure peculiar to\nmarkets that operate in different time zones.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2011 00:40:54 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Junior", "Leonidas Sandoval", ""]]}, {"id": "1111.5254", "submitter": "Vladimir Saptsin", "authors": "Vladimir Soloviev and Vladimir Saptsin and Dmitry Chabanenko", "title": "Markov Chains application to the financial-economic time series\n  prediction", "comments": "24 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST physics.data-an", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this research the technology of complex Markov chains is applied to\npredict financial time series. The main distinction of complex or high-order\nMarkov Chains and simple first-order ones is the existing of aftereffect or\nmemory. The technology proposes prediction with the hierarchy of time\ndiscretization intervals and splicing procedure for the prediction results at\nthe different frequency levels to the single prediction output time series. The\nhierarchy of time discretizations gives a possibility to use fractal properties\nof the given time series to make prediction on the different frequencies of the\nseries. The prediction results for world's stock market indices is presented.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2011 17:10:09 GMT"}], "update_date": "2011-11-23", "authors_parsed": [["Soloviev", "Vladimir", ""], ["Saptsin", "Vladimir", ""], ["Chabanenko", "Dmitry", ""]]}, {"id": "1111.5265", "submitter": "Martin Rypdal", "authors": "M. Rypdal and O. L{\\o}vsletten", "title": "Multifractal modeling of short-term interest rates", "comments": "16 pages, 3 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multifractal model for short-term interest rates. The model is a\nversion of the Markov-Switching Multifractal (MSM), which incorporates the\nwell-known level effect observed in interest rates. Unlike previously suggested\nmodels, the level-MSM model captures the power-law scaling of the structure\nfunctions and the slowly decaying dependency in the absolute value of returns.\nWe apply the model to the Norwegian Interbank Offered Rate with three months\nmaturity (NIBORM3) and the U.S. Treasury Bill with three months maturity\n(TBM3). The performance of the model is compared to level-GARCH models,\nlevel-EGARCH models and jump-diffusions. For the TBM3 data the multifractal\nout-performs all the alternatives considered.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2011 17:59:27 GMT"}], "update_date": "2011-11-23", "authors_parsed": [["Rypdal", "M.", ""], ["L\u00f8vsletten", "O.", ""]]}]