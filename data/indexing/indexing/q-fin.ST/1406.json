[{"id": "1406.0268", "submitter": "Ladislav Kristoufek", "authors": "Ladislav Kristoufek", "title": "What are the main drivers of the Bitcoin price? Evidence from wavelet\n  coherence analysis", "comments": "19 pages, 5 figures", "journal-ref": "PLoS ONE 10(4): e0123923, 2015", "doi": "10.1371/journal.pone.0123923", "report-no": null, "categories": "q-fin.CP physics.data-an q-fin.ST", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Bitcoin has emerged as a fascinating phenomenon of the financial markets.\nWithout any central authority issuing the currency, it has been associated with\ncontroversy ever since its popularity and public interest reached high levels.\nHere, we contribute to the discussion by examining potential drivers of Bitcoin\nprices ranging from fundamental to speculative and technical sources as well as\na potential influence of the Chinese market. The evolution of the relationships\nis examined in both time and frequency domains utilizing the continuous\nwavelets framework so that we comment on development of the interconnections in\ntime but we can also distinguish between short-term and long-term connections.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jun 2014 07:07:34 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Kristoufek", "Ladislav", ""]]}, {"id": "1406.0437", "submitter": "Nestor Parolya Jun.-Prof. Dr.", "authors": "Taras Bodnar, Nestor Parolya and Wolfgang Schmid", "title": "Estimation of the Global Minimum Variance Portfolio in High Dimensions", "comments": "38 pages inc. 16 figures. Revised and corrected version", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.ST q-fin.PM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We estimate the global minimum variance (GMV) portfolio in the\nhigh-dimensional case using results from random matrix theory. This approach\nleads to a shrinkage-type estimator which is distribution-free and it is\noptimal in the sense of minimizing the out-of-sample variance. Its asymptotic\nproperties are investigated assuming that the number of assets $p$ depends on\nthe sample size $n$ such that $\\frac{p}{n}\\rightarrow c\\in (0,+\\infty)$ as $n$\ntends to infinity. The results are obtained under weak assumptions imposed on\nthe distribution of the asset returns, namely it is only required the fourth\nmoments existence. Furthermore, we make no assumption on the upper bound of the\nspectrum of the covariance matrix. As a result, the theoretical findings are\nalso valid if the dependencies between the asset returns are described by a\nfactor model which appears to be very popular in financial literature nowadays.\nThis is also well-documented in a numerical study where the small- and\nlarge-sample behavior of the derived estimator are compared with existing\nestimators of the GMV portfolio. The resulting estimator shows significant\nimprovements and it turns out to be robust to the deviations from normality.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jun 2014 16:34:36 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2015 10:47:39 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Bodnar", "Taras", ""], ["Parolya", "Nestor", ""], ["Schmid", "Wolfgang", ""]]}, {"id": "1406.0455", "submitter": "Cheng Chen", "authors": "Cheng Chen, Lan Zheng, Venkatesh Srinivasan, Alex Thomo, Kui Wu,\n  Anthony Sukow", "title": "Buyer to Seller Recommendation under Constraints", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.GT q-fin.GN q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of recommender systems are designed to recommend items (such as\nmovies and products) to users. We focus on the problem of recommending buyers\nto sellers which comes with new challenges: (1) constraints on the number of\nrecommendations buyers are part of before they become overwhelmed, (2)\nconstraints on the number of recommendations sellers receive within their\nbudget, and (3) constraints on the set of buyers that sellers want to receive\n(e.g., no more than two people from the same household). We propose the\nfollowing critical problems of recommending buyers to sellers: Constrained\nRecommendation (C-REC) capturing the first two challenges, and Conflict-Aware\nConstrained Recommendation (CAC-REC) capturing all three challenges at the same\ntime. We show that C-REC can be modeled using linear programming and can be\nefficiently solved using modern solvers. On the other hand, we show that\nCAC-REC is NP-hard. We propose two approximate algorithms to solve CAC-REC and\nshow that they achieve close to optimal solutions via comprehensive experiments\nusing real-world datasets.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jun 2014 17:45:52 GMT"}, {"version": "v2", "created": "Mon, 9 Jun 2014 05:32:29 GMT"}, {"version": "v3", "created": "Fri, 13 Jun 2014 17:34:26 GMT"}], "update_date": "2014-06-16", "authors_parsed": [["Chen", "Cheng", ""], ["Zheng", "Lan", ""], ["Srinivasan", "Venkatesh", ""], ["Thomo", "Alex", ""], ["Wu", "Kui", ""], ["Sukow", "Anthony", ""]]}, {"id": "1406.0496", "submitter": "Nicol\\'o Musmeci Mr", "authors": "Nicolo Musmeci, Tomaso Aste and Tiziana Di Matteo", "title": "Relation between Financial Market Structure and the Real Economy:\n  Comparison between Clustering Methods", "comments": "31 pages, 17 figures", "journal-ref": "Journal of Network Theory in Finance, VOLUME 4, NUMBER 2 (2018)", "doi": "10.21314/JNTF.2018.040", "report-no": null, "categories": "q-fin.ST cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We quantify the amount of information filtered by different hierarchical\nclustering methods on correlations between stock returns comparing it with the\nunderlying industrial activity structure. Specifically, we apply, for the first\ntime to financial data, a novel hierarchical clustering approach, the Directed\nBubble Hierarchical Tree and we compare it with other methods including the\nLinkage and k-medoids. In particular, by taking the industrial sector\nclassification of stocks as a benchmark partition, we evaluate how the\ndifferent methods retrieve this classification. The results show that the\nDirected Bubble Hierarchical Tree can outperform other methods, being able to\nretrieve more information with fewer clusters. Moreover, we show that the\neconomic information is hidden at different levels of the hierarchical\nstructures depending on the clustering method. The dynamical analysis on a\nrolling window also reveals that the different methods show different degrees\nof sensitivity to events affecting financial markets, like crises. These\nresults can be of interest for all the applications of clustering methods to\nportfolio optimization and risk hedging.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jun 2014 20:38:32 GMT"}, {"version": "v2", "created": "Wed, 21 Jan 2015 16:25:03 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Musmeci", "Nicolo", ""], ["Aste", "Tomaso", ""], ["Di Matteo", "Tiziana", ""]]}, {"id": "1406.0824", "submitter": "Sukru Burc Eryilmaz", "authors": "Sercan Arik, Sukru Burc Eryilmaz, Adam Goldberg", "title": "Supervised classification-based stock prediction and portfolio\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE cs.LG q-fin.PM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the number of publicly traded companies as well as the amount of their\nfinancial data grows rapidly, it is highly desired to have tracking, analysis,\nand eventually stock selections automated. There have been few works focusing\non estimating the stock prices of individual companies. However, many of those\nhave worked with very small number of financial parameters. In this work, we\napply machine learning techniques to address automated stock picking, while\nusing a larger number of financial parameters for individual companies than the\nprevious studies. Our approaches are based on the supervision of prediction\nparameters using company fundamentals, time-series properties, and correlation\ninformation between different stocks. We examine a variety of supervised\nlearning techniques and found that using stock fundamentals is a useful\napproach for the classification problem, when combined with the high\ndimensional data handling capabilities of support vector machine. The portfolio\nour system suggests by predicting the behavior of stocks results in a 3% larger\ngrowth on average than the overall market within a 3-month time period, as the\nout-of-sample test suggests.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jun 2014 19:32:09 GMT"}], "update_date": "2014-06-04", "authors_parsed": [["Arik", "Sercan", ""], ["Eryilmaz", "Sukru Burc", ""], ["Goldberg", "Adam", ""]]}, {"id": "1406.3967", "submitter": "Mehdi Lallouache", "authors": "Mehdi Lallouache, Damien Challet", "title": "The limits of statistical significance of Hawkes processes fitted to\n  financial data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many fits of Hawkes processes to financial data look rather good but most of\nthem are not statistically significant. This raises the question of what part\nof market dynamics this model is able to account for exactly. We document the\naccuracy of such processes as one varies the time interval of calibration and\ncompare the performance of various types of kernels made up of sums of\nexponentials. Because of their around-the-clock opening times, FX markets are\nideally suited to our aim as they allow us to avoid the complications of the\nlong daily overnight closures of equity markets. One can achieve statistical\nsignificance according to three simultaneous tests provided that one uses\nkernels with two exponentials for fitting an hour at a time, and two or three\nexponentials for full days, while longer periods could not be fitted within\nstatistical satisfaction because of the non-stationarity of the endogenous\nprocess. Fitted timescales are relatively short and endogeneity factor is high\nbut sub-critical at about 0.8.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jun 2014 10:55:20 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2015 16:04:51 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Lallouache", "Mehdi", ""], ["Challet", "Damien", ""]]}, {"id": "1406.4783", "submitter": "Alexey Avdeenko", "authors": "A. M. Avdeenko", "title": "Advisors and indicators based on the SSA models and non-linear\n  generalizations", "comments": "6 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers method of creation of an advisor and indicator based on\nthe spectral stochastic analysis model, both with linear and non-linear\napproximation. The problem of entrance to one or another trade position is\nsolved on the basis of combined analysis of dynamics of quotations of all\ncurrency pairs, what allows to actively hedge open positions.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jun 2014 16:14:27 GMT"}], "update_date": "2014-06-19", "authors_parsed": [["Avdeenko", "A. M.", ""]]}, {"id": "1406.5083", "submitter": "Faustino Prieto", "authors": "Jos\\'e Mar\\'ia Sarabia, Faustino Prieto, Vanesa Jord\\'a", "title": "A variation of the Dragulescu-Yakovenko income model", "comments": "This is a preprint (7 pages, 4 tables, 2 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of the Dragulescu-Yakovenko (2000) model, we show that\nempirical income distribution with truncated datasets, cannot be properly\nmodeled by the one-parameter exponential distribution. However, a truncated\nversion characterized by an exponential distribution with two parameters gives\nan accurate fit.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jun 2014 15:38:20 GMT"}], "update_date": "2014-06-20", "authors_parsed": [["Sarabia", "Jos\u00e9 Mar\u00eda", ""], ["Prieto", "Faustino", ""], ["Jord\u00e1", "Vanesa", ""]]}, {"id": "1406.5386", "submitter": "Desislava Chetalova", "authors": "Desislava Chetalova, Rudi Sch\\\"afer and Thomas Guhr", "title": "Zooming into market states", "comments": "13 pages, 9 figures", "journal-ref": "J. Stat. Mech., P01029 (2015)", "doi": "10.1088/1742-5468/2015/01/P01029", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the daily stock data of the Nasdaq Composite index in the 22-year\nperiod 1992-2013 and identify market states as clusters of correlation matrices\nwith similar correlation structures. We investigate the stability of the\ncorrelation structure of each state by estimating the statistical fluctuations\nof correlations due to their non-stationarity. Our study is based on a random\nmatrix approach recently introduced to model the non-stationarity of\ncorrelations by an ensemble of random matrices. This approach reduces the\ncomplexity of the correlated market to a single parameter which characterizes\nthe fluctuations of the correlations and can be determined directly from the\nempirical return distributions. This parameter provides an insight into the\nstability of the correlation structure of each market state as well as into the\ncorrelation structure dynamics in the whole observation period. The analysis\nreveals an intriguing relationship between average correlation and correlation\nfluctuations. The strongest fluctuations occur during periods of high average\ncorrelation which is the case particularly in times of crisis.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jun 2014 13:45:30 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Chetalova", "Desislava", ""], ["Sch\u00e4fer", "Rudi", ""], ["Guhr", "Thomas", ""]]}, {"id": "1406.5486", "submitter": "Efstathios Panayi", "authors": "Efstathios Panayi, Gareth Peters and Ioannis Kosmidis", "title": "Liquidity commonality does not imply liquidity resilience commonality: A\n  functional characterisation for ultra-high frequency cross-sectional LOB data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a large-scale study of commonality in liquidity and resilience\nacross assets in an ultra high-frequency (millisecond-timestamped) Limit Order\nBook (LOB) dataset from a pan-European electronic equity trading facility. We\nfirst show that extant work in quantifying liquidity commonality through the\ndegree of explanatory power of the dominant modes of variation of liquidity\n(extracted through Principal Component Analysis) fails to account for heavy\ntailed features in the data, thus producing potentially misleading results. We\nemploy Independent Component Analysis, which both decorrelates the liquidity\nmeasures in the asset cross-section, but also reduces higher-order statistical\ndependencies.\n  To measure commonality in liquidity resilience, we utilise a novel\ncharacterisation as the time required for return to a threshold liquidity\nlevel. This reflects a dimension of liquidity that is not captured by the\nmajority of liquidity measures and has important ramifications for\nunderstanding supply and demand pressures for market makers in electronic\nexchanges, as well as regulators and HFTs. When the metric is mapped out across\na range of thresholds, it produces the daily Liquidity Resilience Profile (LRP)\nfor a given asset. This daily summary of liquidity resilience behaviour from\nthe vast LOB dataset is then amenable to a functional data representation. This\nenables the comparison of liquidity resilience in the asset cross-section via\nfunctional linear sub-space decompositions and functional regression. The\nfunctional regression results presented here suggest that market factors for\nliquidity resilience (as extracted through functional principal components\nanalysis) can explain between 10 and 40% of the variation in liquidity\nresilience at low liquidity thresholds, but are less explanatory at more\nextreme levels, where individual asset factors take effect.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jun 2014 18:50:27 GMT"}], "update_date": "2014-06-23", "authors_parsed": [["Panayi", "Efstathios", ""], ["Peters", "Gareth", ""], ["Kosmidis", "Ioannis", ""]]}, {"id": "1406.5487", "submitter": "Efstathios Panayi", "authors": "Efstathios Panayi and Gareth Peters", "title": "Survival Models for the Duration of Bid-Ask Spread Deviations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many commonly used liquidity measures are based on snapshots of the state of\nthe limit order book (LOB) and can thus only provide information about\ninstantaneous liquidity, and not regarding the local liquidity regime. However,\ntrading in the LOB is characterised by many intra-day liquidity shocks, where\nthe LOB generally recovers after a short period of time. In this paper, we\ncapture this dynamic aspect of liquidity using a survival regression framework,\nwhere the variable of interest is the duration of the deviations of the spread\nfrom a pre-specified level. We explore a large number of model structures using\na branch-and-bound subset selection algorithm and illustrate the explanatory\nperformance of our model.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jun 2014 18:50:58 GMT"}], "update_date": "2014-06-23", "authors_parsed": [["Panayi", "Efstathios", ""], ["Peters", "Gareth", ""]]}, {"id": "1406.5718", "submitter": "Denis Filatov", "authors": "Denis M. Filatov, Maksim A. Vanyarkho", "title": "An Unconventional Attempt to Tame Mandelbrot's Grey Swans", "comments": "37 pages (paper 13 pages, supplementary materials 24 pages), 6\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.GN q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest an original physical approach to describe the mechanism of market\npricing. The core of our approach is to consider pricing at different time\nscales separately, using independent equations of motion. Such an approach\nleads to a pricing model that not only allows estimating the volatility of\nfuture market prices, but also permits forecasting the direction of the price\nmove. Alongside with that, it is crucial that our model implies no calibration\non historical market data. And last but not least, properties of the model's\nsolution are consistent with those of real markets: it has fat tails, possesses\nscaling and evinces nonlinear market memory. As our model has been derived with\nthe tip of the pen, it may be not a yet another confirmation of the known\nempirical facts, but a theoretical justification thereto. Tests on real\nfinancial instruments prove the competence of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jun 2014 12:38:58 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Filatov", "Denis M.", ""], ["Vanyarkho", "Maksim A.", ""]]}, {"id": "1406.6559", "submitter": "Ersin Kantar", "authors": "Ersin Kantar, Bayram Deviren and Mustafa Keskin", "title": "Hierarchical structure of the European countries based on debts as a\n  percentage of GDP during the 2000-2011 period", "comments": "7 pages, 9 figures, and 1 table", "journal-ref": null, "doi": "10.1016/j.physa.2014.07.001", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate hierarchical structures of the European countries by using\ndebt as a percentage of Gross Domestic Product (GDP) of the countries as they\nchange over a certain period of time. We obtain the topological properties\namong the countries based on debt as a percentage of GDP of European countries\nover the period 2000-2011 by using the concept of hierarchical structure\nmethods (minimal spanning tree, (MST) and hierarchical tree, (HT)). This period\nis also divided into two sub-periods related to 2004 enlargement of the\nEuropean Union, namely 2000-2004 and 2005-2011, in order to test various\ntime-window and observe the temporal evolution. The bootstrap techniques is\napplied to see a value of statistical reliability of the links of the MSTs and\nHTs. The clustering linkage procedure is also used to observe the cluster\nstructure more clearly. From the structural topologies of these trees, we\nidentify different clusters of countries according to their level of debts and\neconomic ties. Our results show that by the debt crisis, the less and most\naffected Eurozones economies are formed as a cluster with each other in the\nMSTs and hierarchical trees.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2014 13:12:06 GMT"}, {"version": "v2", "created": "Fri, 27 Jun 2014 05:00:43 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Kantar", "Ersin", ""], ["Deviren", "Bayram", ""], ["Keskin", "Mustafa", ""]]}, {"id": "1406.6562", "submitter": "Ersin Kantar", "authors": "Ersin Kantar, Alper Aslan, Bayram Deviren and Mustafa Keskin", "title": "Hierarchical structure of the countries based on electricity consumption\n  and economic growth", "comments": "9 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the hierarchical structures of countries based on electricity\nconsumption and economic growth by using the real amounts of their consumption\nover a certain time period. We use of electricity consumption data to detect\nthe topological properties of 60 countries from 1971 to 2008. These countries\nare divided into three subgroups: low income group, middle income group and\nhigh income group countries. Firstly, a relationship between electricity\nconsumption and economic growth is investigated by using the concept of\nhierarchical structure methods (minimal spanning tree (MST) and hierarchical\ntree (HT)). Secondly, we perform bootstrap techniques to investigate a value of\nthe statistical reliability to the links of the MST. Finally, we use a\nclustering linkage procedure in order to observe the cluster structure more\nclearly. The results of the structural topologies of these trees are as\nfollows: i) we identified different clusters of countries according to their\ngeographical location and economic growth, ii) we found a strong relation\nbetween energy consumption and economic growth for all the income groups\nconsidered in this study and iii) the results are in good agreement with the\ncausal relationship between electricity consumption and economic growth.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2014 13:18:18 GMT"}, {"version": "v2", "created": "Fri, 27 Jun 2014 05:06:49 GMT"}], "update_date": "2014-06-30", "authors_parsed": [["Kantar", "Ersin", ""], ["Aslan", "Alper", ""], ["Deviren", "Bayram", ""], ["Keskin", "Mustafa", ""]]}, {"id": "1406.6651", "submitter": "Ishanu Chattopadhyay", "authors": "Ishanu Chattopadhyay", "title": "Causality Networks", "comments": "22 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While correlation measures are used to discern statistical relationships\nbetween observed variables in almost all branches of data-driven scientific\ninquiry, what we are really interested in is the existence of causal\ndependence. Designing an efficient causality test, that may be carried out in\nthe absence of restrictive pre-suppositions on the underlying dynamical\nstructure of the data at hand, is non-trivial. Nevertheless, ability to\ncomputationally infer statistical prima facie evidence of causal dependence may\nyield a far more discriminative tool for data analysis compared to the\ncalculation of simple correlations. In the present work, we present a new\nnon-parametric test of Granger causality for quantized or symbolic data streams\ngenerated by ergodic stationary sources. In contrast to state-of-art binary\ntests, our approach makes precise and computes the degree of causal dependence\nbetween data streams, without making any restrictive assumptions, linearity or\notherwise. Additionally, without any a priori imposition of specific dynamical\nstructure, we infer explicit generative models of causal cross-dependence,\nwhich may be then used for prediction. These explicit models are represented as\ngeneralized probabilistic automata, referred to crossed automata, and are shown\nto be sufficient to capture a fairly general class of causal dependence. The\nproposed algorithms are computationally efficient in the PAC sense; $i.e.$, we\nfind good models of cross-dependence with high probability, with polynomial\nrun-times and sample complexities. The theoretical results are applied to\nweekly search-frequency data from Google Trends API for a chosen set of\nsocially \"charged\" keywords. The causality network inferred from this dataset\nreveals, quite expectedly, the causal importance of certain keywords. It is\nalso illustrated that correlation analysis fails to gather such insight.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2014 17:46:32 GMT"}], "update_date": "2014-06-26", "authors_parsed": [["Chattopadhyay", "Ishanu", ""]]}, {"id": "1406.6862", "submitter": "Egil Ferkingstad", "authors": "Egil Ferkingstad and Anders L{\\o}land", "title": "Coping with area price risk in electricity markets: Forecasting\n  Contracts for Difference in the Nordic power market", "comments": "29 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contracts for Difference (CfDs) are forwards on the spread between an area\nprice and the system price. Together with the system price forwards, these\nproducts are used to hedge the area price risk in the Nordic electricity\nmarket. The CfDs are typically available for the next two months, three\nquarters and three years. This is fine, except that CfDs are not traded at\nNASDAQ OMX Commodities for every Nord Pool Spot price area. We therefore ask\nthe hypothetical question: What would the CfD market price have been, say in\nthe price area NO2, if it had been traded? We build regression models for each\nobservable price area, and use Bayesian elicitation techniques to obtain prior\ninformation on how similar the different price areas are to forecast the price\nin an area where CfDs are not traded.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jun 2014 12:21:51 GMT"}], "update_date": "2014-06-27", "authors_parsed": [["Ferkingstad", "Egil", ""], ["L\u00f8land", "Anders", ""]]}, {"id": "1406.7064", "submitter": "Ersin Kantar", "authors": "Ersin Kantar", "title": "Hierarchical Structure of the Foreign Trade: The Case of the United\n  State", "comments": "7 pages, 6 figures, 1 table. arXiv admin note: substantial text\n  overlap with arXiv:1010.5653, arXiv:1406.6559; and text overlap with\n  arXiv:1406.6562 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study uses hierarchical structure methods (minimal spanning tree, (MST)\nand hierarchical tree, (HT)) to examine the hierarchical structures of the\nUnited State (US) foreign trade by using the real prices of their commodity\nexport and import move together over time. We obtain the topological properties\namong the countries based on US foreign trade over the periods of 1985-2011. We\nalso perform the bootstrap techniques to investigate a value of the statistical\nreliability to the links of the MSTs. Finally, we use a clustering linkage\nprocedure in order to observe the cluster structure much better. The results of\nthe topologies structural of these trees are as follows: i) We identified\ndifferent clusters of countries according to their geographical location and\neconomic growth. ii) Our results show that the European Union and Asian\ncountries are more important within the network, due to a tighter connection\nwith other countries. The country's most important trading partners are the\nCanada, China, Mexico, Japan, Germany, United Kingdom, South Korea, France,\nTaiwan, India, Singapore and Netherlands iii) We have also found that these\ncountries play a significance role for US foreign trade and have important\nimplications for the design of portfolio and investment strategies.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jun 2014 05:19:42 GMT"}], "update_date": "2014-06-30", "authors_parsed": [["Kantar", "Ersin", ""]]}, {"id": "1406.7330", "submitter": "Zhenming Liu", "authors": "Felix Ming Fai Wong, Zhenming Liu, Mung Chiang", "title": "Stock Market Prediction from WSJ: Text Mining via Sparse Matrix\n  Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of predicting directional movements of stock prices\nbased on news articles: here our algorithm uses daily articles from The Wall\nStreet Journal to predict the closing stock prices on the same day. We propose\na unified latent space model to characterize the \"co-movements\" between stock\nprices and news articles. Unlike many existing approaches, our new model is\nable to simultaneously leverage the correlations: (a) among stock prices, (b)\namong news articles, and (c) between stock prices and news articles. Thus, our\nmodel is able to make daily predictions on more than 500 stocks (most of which\nare not even mentioned in any news article) while having low complexity. We\ncarry out extensive backtesting on trading strategies based on our algorithm.\nThe result shows that our model has substantially better accuracy rate (55.7%)\ncompared to many widely used algorithms. The return (56%) and Sharpe ratio due\nto a trading strategy based on our model are also much higher than baseline\nindices.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jun 2014 22:34:47 GMT"}], "update_date": "2014-07-03", "authors_parsed": [["Wong", "Felix Ming Fai", ""], ["Liu", "Zhenming", ""], ["Chiang", "Mung", ""]]}, {"id": "1406.7526", "submitter": "Pawe{\\l} Fiedor", "authors": "Pawe{\\l} Fiedor and Odd Magnus Trondrud", "title": "Predictability of Volatility Homogenised Financial Time Series", "comments": "8 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling financial time series as a time change of a simpler process has\nbeen proposed in various forms over the years. One of such recent approaches is\ncalled volatility homogenisation decomposition, and has been designed\nspecifically to aid the forecasting of price changes on financial markets. The\nauthors of this method have attempted to prove the its usefulness by applying a\nspecific forecasting procedure and determining the effectiveness of this\nprocedure on the decomposed time series, as compared with the original time\nseries. This is problematic in at least two ways. First, the choice of the\nforecasting procedure obviously has an effect on the results, rendering them\nnon-exhaustive. Second, the results obtained were not completely convincing,\nwith some values falling under 50% guessing rate. Additionally, only nine\nAustralian stocks were being investigated, which further limits the scope of\nthis proof. In this study we propose to find the usefulness of volatility\nhomogenisation by calculating the predictability of the decomposed time series\nand comparing it to the predictability of the original time series. We are\napplying information-theoretic notion of entropy rate to quantify\npredictability, which guarantees the result is not tied to a specific method of\nprediction, and additionally we base our calculations on a large number of\nstocks from the Warsaw Stock Exchange.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jun 2014 17:14:22 GMT"}], "update_date": "2014-07-01", "authors_parsed": [["Fiedor", "Pawe\u0142", ""], ["Trondrud", "Odd Magnus", ""]]}]