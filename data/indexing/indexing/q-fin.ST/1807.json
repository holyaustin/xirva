[{"id": "1807.00573", "submitter": "Damien Challet", "authors": "Damien Challet", "title": "Strategic behaviour and indicative price diffusion in Paris Stock\n  Exchange auctions", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report statistical regularities of the opening and closing auctions of\nFrench equities, focusing on the diffusive properties of the indicative auction\nprice. Two mechanisms are at play as the auction end time nears: the typical\nprice change magnitude decreases, favoring underdiffusion, while the rate of\nthese events increases, potentially leading to overdiffusion. A third\nmechanism, caused by the strategic behavior of traders, is needed to produce\nnearly diffusive prices: waiting to submit buy orders until sell orders have\ndecreased the indicative price and vice-versa.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 10:00:03 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Challet", "Damien", ""]]}, {"id": "1807.00939", "submitter": "Sheikh Rabiul Islam", "authors": "Sheikh Rabiul Islam, Sheikh Khaled Ghafoor, William Eberle", "title": "Mining Illegal Insider Trading of Stocks: A Proactive Approach", "comments": "Accepted in IEEE BigData 2018", "journal-ref": "2018 IEEE International Conference on Big Data (Big Data)", "doi": "10.1109/BigData.2018.8622303", "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Illegal insider trading of stocks is based on releasing non-public\ninformation (e.g., new product launch, quarterly financial report, acquisition\nor merger plan) before the information is made public. Detecting illegal\ninsider trading is difficult due to the complex, nonlinear, and non-stationary\nnature of the stock market. In this work, we present an approach that detects\nand predicts illegal insider trading proactively from large heterogeneous\nsources of structured and unstructured data using a deep-learning based\napproach combined with discrete signal processing on the time series data. In\naddition, we use a tree-based approach that visualizes events and actions to\naid analysts in their understanding of large amounts of unstructured data.\nUsing existing data, we have discovered that our approach has a good success\nrate in detecting illegal insider trading patterns.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 04:21:10 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 16:00:02 GMT"}, {"version": "v3", "created": "Wed, 7 Nov 2018 20:04:31 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Islam", "Sheikh Rabiul", ""], ["Ghafoor", "Sheikh Khaled", ""], ["Eberle", "William", ""]]}, {"id": "1807.01934", "submitter": "Jaros{\\l}aw Klamut", "authors": "Jaros{\\l}aw Klamut, Tomasz Gubiec", "title": "Directed Continuous-Time Random Walk with memory", "comments": null, "journal-ref": null, "doi": "10.1140/epjb/e2019-90453-y", "report-no": null, "categories": "q-fin.ST physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new Directed Continuous-Time Random Walk (CTRW) model with\nmemory. As CTRW trajectory consists of spatial jumps preceded by waiting times,\nin Directed CTRW, we consider the case with only positive spatial jumps.\nMoreover, we consider the memory in the model as each spatial jump depends on\nthe previous one. Our model is motivated by the financial application of the\nCTRW presented in [Phys. Rev. E 82:046119][Eur. Phys. J. B 90:50]. As CTRW can\nsuccessfully describe the short term negative autocorrelation of returns in\nhigh-frequency financial data (caused by the bid-ask bounce phenomena), we\nasked ourselves to what extent the observed long-term autocorrelation of\nabsolute values of returns can be explained by the same phenomena. It turned\nout that the bid-ask bounce can be responsible only for the small fraction of\nthe memory observed in the high-frequency financial data.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 10:31:47 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Klamut", "Jaros\u0142aw", ""], ["Gubiec", "Tomasz", ""]]}, {"id": "1807.02422", "submitter": "Chao Wang Dr", "authors": "Chao Wang, Richard Gerlach, Qian Chen", "title": "A Semi-parametric Realized Joint Value-at-Risk and Expected Shortfall\n  Regression Framework", "comments": "45 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:1805.08653, arXiv:1612.08488, arXiv:1707.03715", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A new realized conditional autoregressive Value-at-Risk (VaR) framework is\nproposed, through incorporating a measurement equation into the original\nquantile regression model. The framework is further extended by employing\nvarious Expected Shortfall (ES) components, to jointly estimate and forecast\nVaR and ES. The measurement equation models the contemporaneous dependence\nbetween the realized measure (i.e., Realized Variance and Realized Range) and\nthe latent conditional ES. An adaptive Bayesian Markov Chain Monte Carlo method\nis employed for estimation and forecasting, the properties of which are\nassessed and compared with maximum likelihood through a simulation study. In a\ncomprehensive forecasting study on 1% and 2.5 % quantile levels, the proposed\nmodels are compared to a range of parametric, non-parametric and\nsemi-parametric models, based on 7 market indices and 7 individual assets.\nOne-day-ahead VaR and ES forecasting results favor the proposed models,\nespecially when incorporating the sub-sampled Realized Variance and the\nsub-sampled Realized Range in the model.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 05:47:05 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 05:39:30 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Wang", "Chao", ""], ["Gerlach", "Richard", ""], ["Chen", "Qian", ""]]}, {"id": "1807.04211", "submitter": "Johannes Wiesel", "authors": "Jan Obloj, Johannes Wiesel", "title": "Robust estimation of superhedging prices", "comments": "This work will appear in the Annals of Statistics. The above version\n  merges the main paper to appear in print and its online supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider statistical estimation of superhedging prices using historical\nstock returns in a frictionless market with d traded assets. We introduce a\nplugin estimator based on empirical measures and show it is consistent but\nlacks suitable robustness. To address this we propose novel estimators which\nuse a larger set of martingale measures defined through a tradeoff between the\nradius of Wasserstein balls around the empirical measure and the allowed norm\nof martingale densities. We establish consistency and robustness of these\nestimators and argue that they offer a superior performance relative to the\nplugin estimator. We generalise the results by replacing the superhedging\ncriterion with acceptance relative to a risk measure. We further extend our\nstudy, in part, to the case of markets with traded options, to a multiperiod\nsetting and to settings with model uncertainty. We also study convergence rates\nof estimators and convergence of superhedging strategies.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 15:53:59 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 14:50:52 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 04:54:50 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Obloj", "Jan", ""], ["Wiesel", "Johannes", ""]]}, {"id": "1807.05360", "submitter": "Shinji Kakinaka SK", "authors": "Shinji Kakinaka and Ken Umeno", "title": "Characterizing Cryptocurrency market with Levy's stable distributions", "comments": null, "journal-ref": "J. Phys. Soc. Jpn. 89, 024802 (2020)", "doi": "10.7566/JPSJ.89.024802", "report-no": null, "categories": "q-fin.ST q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent emergence of cryptocurrencies such as Bitcoin and Ethereum has\nposed possible alternatives to global payments as well as financial assets\naround the globe, making investors and financial regulators aware of the\nimportance of modeling them correctly. The Levy's stable distribution is one of\nthe attractive distributions that well describes the fat tails and scaling\nphenomena in economic systems. In this paper, we show that the behaviors of\nprice fluctuations in emerging cryptocurrency markets can be characterized by a\nnon-Gaussian Levy's stable distribution with $\\alpha \\simeq 1.4$ under certain\nconditions on time intervals ranging roughly from 30 minutes to 4 hours. Our\narguments are developed under quantitative valuation defined as a distance\nfunction using the Parseval's relation in addition to the theoretical\nbackground of the General Central Limit Theorem (GCLT). We also discuss the fit\nwith the Levy's stable distribution compared to the fit with other\ndistributions by employing the method based on likelihood ratios. Our approach\ncan be extended for further analysis of statistical properties and contribute\nto developing proper applications for financial modeling.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 08:50:25 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 12:14:32 GMT"}, {"version": "v3", "created": "Thu, 28 Feb 2019 09:48:30 GMT"}, {"version": "v4", "created": "Wed, 4 Sep 2019 05:39:15 GMT"}, {"version": "v5", "created": "Mon, 25 Nov 2019 15:07:51 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Kakinaka", "Shinji", ""], ["Umeno", "Ken", ""]]}, {"id": "1807.05836", "submitter": "Pier Francesco Procacci", "authors": "Pier Francesco Procacci and Tomaso Aste", "title": "Forecasting market states", "comments": "13 pages, 5 figures", "journal-ref": "Quantitative Finance 19 (2019) 1491-1498", "doi": "10.1080/14697688.2019.1622313", "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel methodology to define, analyze and forecast market states.\nIn our approach market states are identified by a reference sparse precision\nmatrix and a vector of expectation values. In our procedure, each multivariate\nobservation is associated with a given market state accordingly to a\nminimization of a penalized Mahalanobis distance. The procedure is made\ncomputationally very efficient and can be used with a large number of assets.\nWe demonstrate that this procedure is successful at clustering different states\nof the markets in an unsupervised manner. In particular, we describe an\nexperiment with one hundred log-returns and two states in which the methodology\nautomatically associates states prevalently to pre- and post- crisis periods\nwith one state gathering periods with average positive returns and the other\nstate periods with average negative returns, therefore discovering\nspontaneously the common classification of `bull' and `bear' markets. In\nanother experiment, with again one hundred log-returns and two states, we\ndemonstrate that this procedure can be efficiently used to forecast off-sample\nfuture market states with significant prediction accuracy. This methodology\nopens the way to a range of applications in risk management and trading\nstrategies in the context where the correlation structure plays a central role.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 16:43:39 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 23:02:16 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 21:21:52 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Procacci", "Pier Francesco", ""], ["Aste", "Tomaso", ""]]}, {"id": "1807.05837", "submitter": "arXiv Admin", "authors": "Vladimir Soloviev, Andrey Belinskiy", "title": "Methods of nonlinear dynamics and the construction of cryptocurrency\n  crisis phenomena precursors", "comments": "arXiv admin note: submission has been withdrawn by arXiv\n  administrators due to inappropriate text reuse from external sources", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article demonstrates the possibility of constructing indicators of\ncritical and crisis phenomena in the volatile market of cryptocurrency. For\nthis purpose, the methods of the theory of complex systems such as recurrent\nanalysis of dynamic systems and the calculation of permutation entropy are\nused. It is shown that it is possible to construct dynamic measures of\ncomplexity, both recurrent and entropy, which behave in a proper way during\nactual pre-crisis periods. This fact is used to build predictors of crisis\nphenomena on the example of the main five crises recorded in the time series of\nthe key cryptocurrency bitcoin, the effectiveness of the proposed\nindicators-precursors of crises has been identified.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 01:06:21 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 19:35:03 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Soloviev", "Vladimir", ""], ["Belinskiy", "Andrey", ""]]}, {"id": "1807.07328", "submitter": "Abdolrahman Khoshrou", "authors": "Abdolrahman Khoshrou and Eric J. Pauwels", "title": "Quantifying Volatility Reduction in German Day-ahead Spot Market in the\n  Period 2006 through 2016", "comments": null, "journal-ref": null, "doi": "10.1109/PESGM.2018.8586020", "report-no": null, "categories": "q-fin.ST cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Europe, Germany is taking the lead in the switch from the conventional to\nrenewable energy. This poses new challenges as wind and solar energy are\nfundamentally intermittent, weather-dependent and less predictable. It is\ntherefore of considerable interest to investigate the evolution of price\nvolatility in this post-transition era. There are a number of reasons, however,\nthat makes the practical studies difficult. For instance, EPEX prices can be\nzero or negative. Consequently, the standard approach in financial time series\nanalysis to switch to logarithmic measures is inapplicable. Furthermore, in\ncontrast to the stock market prices which are only available for trading days,\nEPEX prices cover the whole year, including weekends and holidays. Accordingly,\nthere is a lot of underlying variability in the data which has nothing to do\nwith volatility, but simply reflects diurnal activity patterns. An important\ndistinction of the present work is the application of matrix decomposition\ntechniques, namely the singular value decomposition (SVD), for defining an\nalternative notion of volatility. This approach is systematically more robust\ntoward outliers and also the diurnal patterns. Our observations show that the\nday-ahead market is becoming less volatile in recent years.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 10:17:07 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Khoshrou", "Abdolrahman", ""], ["Pauwels", "Eric J.", ""]]}, {"id": "1807.08390", "submitter": "Bal\\'azs Csan\\'ad Cs\\'aji", "authors": "Bal\\'azs Csan\\'ad Cs\\'aji", "title": "Score Permutation Based Finite Sample Inference for Generalized\n  AutoRegressive Conditional Heteroskedasticity (GARCH) Models", "comments": "19th International Conference on Artificial Intelligence and\n  Statistics (AISTATS)", "journal-ref": "Proceedings of Machine Learning Research, Volume 51, 2016, pp.\n  296-304", "doi": null, "report-no": null, "categories": "stat.ME cs.LG econ.EM math.DS q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A standard model of (conditional) heteroscedasticity, i.e., the phenomenon\nthat the variance of a process changes over time, is the Generalized\nAutoRegressive Conditional Heteroskedasticity (GARCH) model, which is\nespecially important for economics and finance. GARCH models are typically\nestimated by the Quasi-Maximum Likelihood (QML) method, which works under mild\nstatistical assumptions. Here, we suggest a finite sample approach, called\nScoPe, to construct distribution-free confidence regions around the QML\nestimate, which have exact coverage probabilities, despite no additional\nassumptions about moments are made. ScoPe is inspired by the recently developed\nSign-Perturbed Sums (SPS) method, which however cannot be applied in the GARCH\ncase. ScoPe works by perturbing the score function using randomly permuted\nresiduals. This produces alternative samples which lead to exact confidence\nregions. Experiments on simulated and stock market data are also presented, and\nScoPe is compared with the asymptotic theory and bootstrap approaches.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 00:02:36 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Cs\u00e1ji", "Bal\u00e1zs Csan\u00e1d", ""]]}, {"id": "1807.09346", "submitter": "Marcel Ausloos", "authors": "Roy Cerqueti (Macerata), Giulia Rotundo (Roma), and Marcel Ausloos\n  (Leicester)", "title": "Investigating the configurations in cross-shareholding: a joint\n  copula-entropy approach", "comments": "36 pages, 45 references, 16 figures; abstract size hereby reduced to\n  less than 1920 characters", "journal-ref": "Entropy 20 (2018) 134", "doi": "10.3390/e20020134", "report-no": null, "categories": "q-fin.ST q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  --- the companies populating a Stock market, along with their connections,\ncan be effectively modeled through a directed network, where the nodes\nrepresent the companies, and the links indicate the ownership. This paper deals\nwith this theme and discusses the concentration of a market. A\ncross-shareholding matrix is considered, along with two key factors: the node\nout-degree distribution which represents the diversification of investments in\nterms of the number of involved companies, and the node in-degree distribution\nwhich reports the integration of a company due to the sales of its own shares\nto other companies. While diversification is widely explored in the literature,\nintegration is most present in literature on contagions. This paper captures\nsuch quantities of interest in the two frameworks and studies the stochastic\ndependence of diversification and integration through a copula approach. We\nadopt entropies as measures for assessing the concentration in the market. The\nmain question is to assess the dependence structure leading to a better\ndescription of the data or to market polarization (minimal entropy) or market\nfairness (maximal entropy). In so doing, we derive information on the way in\nwhich the in- and out-degrees should be connected in order to shape the market.\nThe question is of interest to regulators bodies, as witnessed by specific\nalert threshold published on the US mergers guidelines for limiting the\npossibility of acquisitions and the prevalence of a single company on the\nmarket. Indeed, all countries and the EU have also rules or guidelines in order\nto limit concentrations, in a country or across borders, respectively. The\ncalibration of copulas and model parameters on the basis of real data serves as\nan illustrative application of the theoretical proposal.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 09:32:51 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Cerqueti", "Roy", "", "Macerata"], ["Rotundo", "Giulia", "", "Roma"], ["Ausloos", "Marcel", "", "Leicester"]]}, {"id": "1807.09423", "submitter": "Stephan Schwill", "authors": "Stephan Schwill", "title": "Entropy Analysis of Financial Time Series", "comments": "Doctoral Thesis, Alliance Manchester Business School, The University\n  of Manchester, 2015. 137 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis applies entropy as a model independent measure to address three\nresearch questions concerning financial time series. In the first study we\napply transfer entropy to drawdowns and drawups in foreign exchange rates, to\nstudy their correlation and cross correlation. When applied to daily and hourly\nEUR/USD and GBP/USD exchange rates, we find evidence of dependence among the\nlargest draws (i.e. 5% and 95% quantiles), but not as strong as the correlation\nbetween the daily returns of the same pair of FX rates. In the second study we\nuse state space models (Hidden Markov Models) of volatility to investigate\nvolatility spill overs between exchange rates. Among the currency pairs, the\nco-movement of EUR/USD and CHF/USD volatility states show the strongest\nobserved relationship. With the use of transfer entropy, we find evidence for\ninformation flows between the volatility state series of AUD, CAD and BRL. The\nthird study uses the entropy of S&P realised volatility in detecting changes of\nvolatility regime in order to re-examine the theme of market volatility timing\nof hedge funds. A one-factor model is used, conditioned on information about\nthe entropy of market volatility, to measure the dynamic of hedge funds equity\nexposure. On a cross section of around 2500 hedge funds with a focus on the US\nequity markets we find that, over the period from 2000 to 2014, hedge funds\nadjust their exposure dynamically in response to changes in volatility regime.\nThis adds to the literature on the volatility timing behaviour of hedge fund\nmanager, but using entropy as a model independent measure of volatility regime.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 03:13:50 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Schwill", "Stephan", ""]]}, {"id": "1807.09864", "submitter": "Eric Benhamou", "authors": "Eric Benhamou and Beatrice Guez", "title": "Incremental Sharpe and other performance ratios", "comments": "18 pages", "journal-ref": "Journal of Statistical and Econometric Methods, vol.7, no.4, 2018,\n  19-37", "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.RM q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new methodology of computing incremental contribution for\nperformance ratios for portfolio like Sharpe, Treynor, Calmar or Sterling\nratios. Using Euler's homogeneous function theorem, we are able to decompose\nthese performance ratios as a linear combination of individual modified\nperformance ratios. This allows understanding the drivers of these performance\nratios as well as deriving a condition for a new asset to provide incremental\nperformance for the portfolio. We provide various numerical examples of this\nperformance ratio decomposition.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 16:30:47 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 01:12:25 GMT"}, {"version": "v3", "created": "Tue, 4 Sep 2018 05:47:16 GMT"}, {"version": "v4", "created": "Sun, 16 Sep 2018 10:52:25 GMT"}, {"version": "v5", "created": "Mon, 17 Dec 2018 07:19:59 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Benhamou", "Eric", ""], ["Guez", "Beatrice", ""]]}, {"id": "1807.10793", "submitter": "Rostislav Serota", "authors": "M. Dashti Moghaddam and R. A. Serota", "title": "Combined Mutiplicative-Heston Model for Stochastic Volatility", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a model of stochastic volatility which combines features of the\nmultiplicative model for large volatilities and of the Heston model for small\nvolatilities. The steady-state distribution in this model is a Beta Prime and\nis characterized by the power-law behavior at both large and small\nvolatilities. We discuss the reasoning behind using this model as well as\nconsequences for our recent analyses of distributions of stock returns and\nrealized volatility.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 18:43:55 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Moghaddam", "M. Dashti", ""], ["Serota", "R. A.", ""]]}, {"id": "1807.11743", "submitter": "Ma{\\l}gorzata Snarska", "authors": "Jarek Duda, Ma{\\l}gorzata Snarska", "title": "Modeling joint probability distribution of yield curve parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  US Yield curve has recently collapsed to its most flattened level since\nsubprime crisis and is close to the inversion. This fact has gathered attention\nof investors around the world and revived the discussion of proper modeling and\nforecasting yield curve, since changes in interest rate structure are believed\nto represent investors expectations about the future state of economy and have\nforeshadowed recessions in the United States. While changes in term structure\nof interest rates are relatively easy to interpret they are however very\ndifficult to model and forecast due to no proper economic theory underlying\nsuch events. Yield curves are usually represented by multivariate sparse time\nseries, at any point in time infinite dimensional curve is portrayed via\nrelatively few points in a multivariate space of data and as a consequence\nmultimodal statistical dependencies behind these curves are relatively hard to\nextract and forecast via typical multivariate statistical methods.We propose to\nmodel yield curves via reconstruction of joint probability distribution of\nparameters in functional space as a high degree polynomial. Thanks to adoption\nof an orthonormal basis, the MSE estimation of coefficients of a given function\nis an average over a data sample in the space of functions. Since such\npolynomial coefficients are independent and have cumulant-like interpretation\nie.describe corresponding perturbation from an uniform joint distribution, our\napproach can also be extended to any d-dimensional space of yield curve\nparameters (also in neighboring times) due to controllable accuracy. We believe\nthat this approach to modeling of local behavior of a sparse multivariate\ncurved time series can complement prediction from standard models like ARIMA,\nthat are using long range dependencies, but provide only inaccurate prediction\nof probability distribution, often as just Gaussian with constant width.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 10:17:16 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Duda", "Jarek", ""], ["Snarska", "Ma\u0142gorzata", ""]]}, {"id": "1807.11751", "submitter": "Adam Majewski", "authors": "Adam Majewski, Stefano Ciliberti and Jean-Philippe Bouchaud", "title": "Co-existence of Trend and Value in Financial Markets: Estimating an\n  Extended Chiarella Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trend and Value are pervasive anomalies, common to all financial markets. We\naddress the problem of their co-existence and interaction within the framework\nof Heterogeneous Agent Based Models (HABM). More specifically, we extend the\nChiarella (1992) model by adding noise traders and a non-linear demand of\nfundamentalists. We use Bayesian filtering techniques to calibrate the model on\ntime series of prices across a variety of asset classes since 1800. The\nfundamental value is an output of the calibration, and does not require the use\nof an external pricing model. Our extended model reproduces many empirical\nobservations, including the non-monotonic relation between past trends and\nfuture returns. The destabilizing activity of trend-followers leads to a\nqualitative change of mispricing distribution, from unimodal to bimodal,\nmeaning that some markets tend to be over- (or under-) valued for long periods\nof time.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 10:50:32 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Majewski", "Adam", ""], ["Ciliberti", "Stefano", ""], ["Bouchaud", "Jean-Philippe", ""]]}]