[{"id": "1801.00185", "submitter": "Piero Mazzarisi", "authors": "Piero Mazzarisi, Paolo Barucca, Fabrizio Lillo, Daniele Tantari", "title": "A dynamic network model with persistent links and node-specific latent\n  variables, with an application to the interbank market", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI physics.soc-ph q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a dynamic network model where two mechanisms control the\nprobability of a link between two nodes: (i) the existence or absence of this\nlink in the past, and (ii) node-specific latent variables (dynamic fitnesses)\ndescribing the propensity of each node to create links. Assuming a Markov\ndynamics for both mechanisms, we propose an Expectation-Maximization algorithm\nfor model estimation and inference of the latent variables. The estimated\nparameters and fitnesses can be used to forecast the presence of a link in the\nfuture. We apply our methodology to the e-MID interbank network for which the\ntwo linkage mechanisms are associated with two different trading behaviors in\nthe process of network formation, namely preferential trading and trading\ndriven by node-specific characteristics. The empirical results allow to\nrecognise preferential lending in the interbank market and indicate how a\nmethod that does not account for time-varying network topologies tends to\noverestimate preferential linkage.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 19:57:35 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Mazzarisi", "Piero", ""], ["Barucca", "Paolo", ""], ["Lillo", "Fabrizio", ""], ["Tantari", "Daniele", ""]]}, {"id": "1801.00588", "submitter": "Xi Zhang", "authors": "Xi Zhang, Yunjia Zhang, Senzhang Wang, Yuntao Yao, Binxing Fang,\n  Philip S. Yu", "title": "Improving Stock Market Prediction via Heterogeneous Information Fusion", "comments": "Accepted by Knowledge-Based Systems", "journal-ref": null, "doi": "10.1016/j.knosys.2017.12.025", "report-no": null, "categories": "cs.SI physics.soc-ph q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional stock market prediction approaches commonly utilize the\nhistorical price-related data of the stocks to forecast their future trends. As\nthe Web information grows, recently some works try to explore financial news to\nimprove the prediction. Effective indicators, e.g., the events related to the\nstocks and the people's sentiments towards the market and stocks, have been\nproved to play important roles in the stocks' volatility, and are extracted to\nfeed into the prediction models for improving the prediction accuracy. However,\na major limitation of previous methods is that the indicators are obtained from\nonly a single source whose reliability might be low, or from several data\nsources but their interactions and correlations among the multi-sourced data\nare largely ignored.\n  In this work, we extract the events from Web news and the users' sentiments\nfrom social media, and investigate their joint impacts on the stock price\nmovements via a coupled matrix and tensor factorization framework.\nSpecifically, a tensor is firstly constructed to fuse heterogeneous data and\ncapture the intrinsic relations among the events and the investors' sentiments.\nDue to the sparsity of the tensor, two auxiliary matrices, the stock\nquantitative feature matrix and the stock correlation matrix, are constructed\nand incorporated to assist the tensor decomposition. The intuition behind is\nthat stocks that are highly correlated with each other tend to be affected by\nthe same event. Thus, instead of conducting each stock prediction task\nseparately and independently, we predict multiple correlated stocks\nsimultaneously through their commonalities, which are enabled via sharing the\ncollaboratively factorized low rank matrices between matrices and the tensor.\nEvaluations on the China A-share stock data and the HK stock data in the year\n2015 demonstrate the effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 09:30:39 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Zhang", "Xi", ""], ["Zhang", "Yunjia", ""], ["Wang", "Senzhang", ""], ["Yao", "Yuntao", ""], ["Fang", "Binxing", ""], ["Yu", "Philip S.", ""]]}, {"id": "1801.00681", "submitter": "Guohao Li", "authors": "Shuheng Wang, Guohao Li, Yifan Bao", "title": "A novel improved fuzzy support vector machine based stock price trend\n  forecast model", "comments": "This paper is accepted by the International Conference on Innovations\n  in Economic Management and Social Science (IEMSS 2017) and International\n  Conference on Humanities, Management Engineering and Education Technology\n  (HMEET 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application of fuzzy support vector machine in stock price forecast. Support\nvector machine is a new type of machine learning method proposed in 1990s. It\ncan deal with classification and regression problems very successfully. Due to\nthe excellent learning performance of support vector machine, the technology\nhas become a hot research topic in the field of machine learning, and it has\nbeen successfully applied in many fields. However, as a new technology, there\nare many limitations to support vector machines. There is a large amount of\nfuzzy information in the objective world. If the training of support vector\nmachine contains noise and fuzzy information, the performance of the support\nvector machine will become very weak and powerless. As the complexity of many\nfactors influence the stock price prediction, the prediction results of\ntraditional support vector machine cannot meet people with precision, this\nstudy improved the traditional support vector machine fuzzy prediction\nalgorithm is proposed to improve the new model precision. NASDAQ Stock Market,\nStandard & Poor's (S&P) Stock market are considered. Novel advanced- fuzzy\nsupport vector machine (NA-FSVM) is the proposed methodology.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 15:17:37 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Wang", "Shuheng", ""], ["Li", "Guohao", ""], ["Bao", "Yifan", ""]]}, {"id": "1801.01777", "submitter": "Masaya Abe", "authors": "Masaya Abe, Hideki Nakayama", "title": "Deep Learning for Forecasting Stock Returns in the Cross-Section", "comments": "12 pages, 2 figures, 8 tables, accepted at PAKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many studies have been undertaken by using machine learning techniques,\nincluding neural networks, to predict stock returns. Recently, a method known\nas deep learning, which achieves high performance mainly in image recognition\nand speech recognition, has attracted attention in the machine learning field.\nThis paper implements deep learning to predict one-month-ahead stock returns in\nthe cross-section in the Japanese stock market and investigates the performance\nof the method. Our results show that deep neural networks generally outperform\nshallow neural networks, and the best networks also outperform representative\nmachine learning models. These results indicate that deep learning shows\npromise as a skillful machine learning method to predict stock returns in the\ncross-section.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 23:47:52 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 00:17:25 GMT"}, {"version": "v3", "created": "Wed, 16 May 2018 00:28:55 GMT"}, {"version": "v4", "created": "Wed, 13 Jun 2018 00:56:57 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Abe", "Masaya", ""], ["Nakayama", "Hideki", ""]]}, {"id": "1801.02205", "submitter": "Danilo Delpini", "authors": "Danilo Delpini, Stefano Battiston, Guido Caldarelli, Massimo Riccaboni", "title": "The Network of U.S. Mutual Fund Investments: Diversification, Similarity\n  and Fragility throughout the Global Financial Crisis", "comments": "27 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network theory proved recently to be useful in the quantification of many\nproperties of financial systems. The analysis of the structure of investment\nportfolios is a major application since their eventual correlation and overlap\nimpact the actual risk diversification by individual investors. We investigate\nthe bipartite network of US mutual fund portfolios and their assets. We follow\nits evolution during the Global Financial Crisis and analyse the interplay\nbetween diversification, as understood in classical portfolio theory, and\nsimilarity of the investments of different funds. We show that, on average,\nportfolios have become more diversified and less similar during the crisis.\nHowever, we also find that large overlap is far more likely than expected from\nmodels of random allocation of investments. This indicates the existence of\nstrong correlations between fund portfolio strategies. We introduce a\nsimplified model of propagation of financial shocks, that we exploit to show\nthat a systemic risk component origins from the similarity of portfolios. The\nnetwork is still vulnerable after crisis because of this effect, despite the\nincrease in the diversification of portfolios. Our results indicate that\ndiversification may even increase systemic risk when funds diversify in the\nsame way. Diversification and similarity can play antagonistic roles and the\ntrade-off between the two should be taken into account to properly assess\nsystemic risk.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 16:09:27 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Delpini", "Danilo", ""], ["Battiston", "Stefano", ""], ["Caldarelli", "Guido", ""], ["Riccaboni", "Massimo", ""]]}, {"id": "1801.05295", "submitter": "Mehdi Elahi", "authors": "Paolo Cremonesi and Chiara Francalanci and Alessandro Poli and Roberto\n  Pagano and Luca Mazzoni and Alberto Maggioni and Mehdi Elahi", "title": "Social Network based Short-Term Stock Trading System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel adaptive algorithm for the automated short-term\ntrading of financial instrument. The algorithm adopts a semantic sentiment\nanalysis technique to inspect the Twitter posts and to use them to predict the\nbehaviour of the stock market. Indeed, the algorithm is specifically developed\nto take advantage of both the sentiment and the past values of a certain\nfinancial instrument in order to choose the best investment decision. This\nallows the algorithm to ensure the maximization of the obtainable profits by\ntrading on the stock market. We have conducted an investment simulation and\ncompared the performance of our proposed with a well-known benchmark (DJTATO\nindex) and the optimal results, in which an investor knows in advance the\nfuture price of a product. The result shows that our approach outperforms the\nbenchmark and achieves the performance score close to the optimal result.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 15:26:46 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Cremonesi", "Paolo", ""], ["Francalanci", "Chiara", ""], ["Poli", "Alessandro", ""], ["Pagano", "Roberto", ""], ["Mazzoni", "Luca", ""], ["Maggioni", "Alberto", ""], ["Elahi", "Mehdi", ""]]}, {"id": "1801.05752", "submitter": "Rilwan Adewoyin", "authors": "Rilwan Adewoyin", "title": "Part 1: Training Sets & ASG Transforms", "comments": "This was an undergraduate project, subsequently the research was not\n  exhaustive", "journal-ref": null, "doi": "10.13140/RG.2.2.25313.81760", "report-no": null, "categories": "q-fin.CP q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, I discuss a method to tackle the issues arising from the small\ndata-sets available to data-scientists when building price predictive\nalgorithms that use monthly/quarterly macro-financial indicators. I approach\nthis by training separate classifiers on the equivalent dataset from a range of\ncountries. Using these classifiers, a three level meta learning algorithm (MLA)\nis developed. I develop a transform, ASG, to create a country agnostic proxy\nfor the macro-financial indicators. Using these proposed methods, I investigate\nthe degree to which a predictive algorithm for the US 5Y bond price,\npredominantly using macro-financial indicators, can outperform an identical\nalgorithm which only uses statistics deriving from previous price.\n  This was an undergraduate project, subsequently the research was not\nexhaustive.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 16:59:20 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 12:25:41 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Adewoyin", "Rilwan", ""]]}, {"id": "1801.05770", "submitter": "Anas Yassine", "authors": "Anas Yassine (MSFGR), Abdelmadjid Ibenrissoul", "title": "The macroeconomics determinants of default of the borrowers: The case of\n  Moroccan bank", "comments": "in French", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article aims to explore an empirical approach to analyze the\nmacroeconomicsdeterminants of default of borrowers. For this purpose, we have\nmeasured the impact of the adverse economic conditions on the degradation of\nthe credit portfolio quality.In our paper, we have shed more light on the\nquestion of the aggravation of default rate. For this, we have undertaken\neconometric modeling of the default rate distribution of a Moroccan bank while\nwe inspired from some studies carried out. Our findings demonstrate that the\ndecline in the economic situation has a positive impact on default of\nborrowers. Hence, the bank also has responsibility for monitoring the adverse\neconomic conditions.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 09:53:49 GMT"}, {"version": "v2", "created": "Mon, 22 Jan 2018 09:33:14 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 13:57:14 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Yassine", "Anas", "", "MSFGR"], ["Ibenrissoul", "Abdelmadjid", ""]]}, {"id": "1801.06373", "submitter": "Christian Hotz-Behofsits", "authors": "Christian Hotz-Behofsits, Florian Huber and Thomas O. Z\\\"orner", "title": "Predicting crypto-currencies using sparse non-Gaussian state space\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we forecast daily returns of crypto-currencies using a wide\nvariety of different econometric models. To capture salient features commonly\nobserved in financial time series like rapid changes in the conditional\nvariance, non-normality of the measurement errors and sharply increasing\ntrends, we develop a time-varying parameter VAR with t-distributed measurement\nerrors and stochastic volatility. To control for overparameterization, we rely\non the Bayesian literature on shrinkage priors that enables us to shrink\ncoefficients associated with irrelevant predictors and/or perform model\nspecification in a flexible manner. Using around one year of daily data we\nperform a real-time forecasting exercise and investigate whether any of the\nproposed models is able to outperform the naive random walk benchmark. To\nassess the economic relevance of the forecasting gains produced by the proposed\nmodels we moreover run a simple trading exercise.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 11:51:27 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 16:26:25 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Hotz-Behofsits", "Christian", ""], ["Huber", "Florian", ""], ["Z\u00f6rner", "Thomas O.", ""]]}, {"id": "1801.06727", "submitter": "Denisa Roberts", "authors": "Denisa Roberts and Douglas Patterson", "title": "A Second Order Cumulant Spectrum Test That a Stochastic Process is\n  Strictly Stationary and a Step Toward a Test for Graph Signal Strict\n  Stationarity", "comments": "6 pages", "journal-ref": "NeurIPS 2018 Workshop for the Spatiotemporal Domain", "doi": null, "report-no": null, "categories": "q-fin.ST math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article develops a statistical test for the null hypothesis of strict\nstationarity of a discrete time stochastic process in the frequency domain.\nWhen the null hypothesis is true, the second order cumulant spectrum is zero at\nall the discrete Fourier frequency pairs in the principal domain. The test uses\na window averaged sample estimate of the second order cumulant spectrum to\nbuild a test statistic with an asymptotic complex standard normal distribution.\nWe derive the test statistic, study the properties of the test and demonstrate\nits application using 137Cs gamma ray decay data. Future areas of research\ninclude testing for strict stationarity of graph signals, with applications in\nlearning convolutional neural networks on graphs, denoising, and inpainting.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jan 2018 20:47:27 GMT"}, {"version": "v2", "created": "Sun, 29 Mar 2020 18:46:52 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Roberts", "Denisa", ""], ["Patterson", "Douglas", ""]]}, {"id": "1801.06896", "submitter": "Theo Diamandis", "authors": "Theo Diamandis, Yonathan Murin, Andrea Goldsmith", "title": "Ranking Causal Influence of Financial Markets via Directed Information\n  Graphs", "comments": "To be presented at Conference on Information Sciences and Systems\n  (CISS) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A non-parametric method for ranking stock indices according to their mutual\ncausal influences is presented. Under the assumption that indices reflect the\nunderlying economy of a country, such a ranking indicates which countries exert\nthe most economic influence in an examined subset of the global economy. The\nproposed method represents the indices as nodes in a directed graph, where the\nedges' weights are estimates of the pair-wise causal influences, quantified\nusing the directed information functional. This method facilitates using a\nrelatively small number of samples from each index. The indices are then ranked\naccording to their net-flow in the estimated graph (sum of the incoming weights\nsubtracted from the sum of outgoing weights). Daily and minute-by-minute data\nfrom nine indices (three from Asia, three from Europe and three from the US)\nwere analyzed. The analysis of daily data indicates that the US indices are the\nmost influential, which is consistent with intuition that the indices\nrepresenting larger economies usually exert more influence. Yet, it is also\nshown that an index representing a small economy can strongly influence an\nindex representing a large economy if the smaller economy is indicative of a\nlarger phenomenon. Finally, it is shown that while inter-region interactions\ncan be captured using daily data, intra-region interactions require more\nfrequent samples.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 21:25:47 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Diamandis", "Theo", ""], ["Murin", "Yonathan", ""], ["Goldsmith", "Andrea", ""]]}, {"id": "1801.07941", "submitter": "Aurelio Fernandez Bariviera", "authors": "Aurelio F. Bariviera, Angelo Plastino, George Judge", "title": "Spurious seasonality detection: a non-parametric test proposal", "comments": null, "journal-ref": "Econometrics 6, no. 1: 3", "doi": "10.3390/econometrics6010003", "report-no": null, "categories": "q-fin.ST q-fin.CP q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper offers a general and comprehensive definition of the\nday-of-the-week effect. Using symbolic dynamics, we develop a unique test based\non ordinal patterns in order to detect it. This test uncovers the fact that the\nso-called \"day-of-the-week\" effect is partly an artifact of the hidden\ncorrelation structure of the data. We present simulations based on artificial\ntime series as well. Whereas time series generated with long memory are prone\nto exhibit daily seasonality, pure white noise signals exhibit no pattern\npreference. Since ours is a non parametric test, it requires no assumptions\nabout the distribution of returns so that it could be a practical alternative\nto conventional econometric tests. We made also an exhaustive application of\nthe here proposed technique to 83 stock indices around the world. Finally, the\npaper highlights the relevance of symbolic analysis in economic time series\nstudies.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 11:54:24 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Bariviera", "Aurelio F.", ""], ["Plastino", "Angelo", ""], ["Judge", "George", ""]]}, {"id": "1801.07960", "submitter": "Aurelio Fernandez Bariviera", "authors": "Martin Iglesias Caride, Aurelio F. Bariviera, Laura Lanzarini", "title": "Stock returns forecast: an examination by means of Artificial Neural\n  Networks", "comments": null, "journal-ref": "Studies in Systems, Decision and Control, vol 125. Springer, Cham", "doi": "10.1007/978-3-319-69989-9_23", "report-no": null, "categories": "q-fin.CP q-fin.PR q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The validity of the Efficient Market Hypothesis has been under severe\nscrutiny since several decades. However, the evidence against it is not\nconclusive. Artificial Neural Networks provide a model-free means to analize\nthe prediction power of past returns on current returns. This chapter analizes\nthe predictability in the intraday Brazilian stock market using a\nbackpropagation Artificial Neural Network. We selected 20 stocks from Bovespa\nindex, according to different market capitalization, as a proxy for stock size.\nWe find that predictability is related to capitalization. In particular, larger\nstocks are less predictable than smaller ones.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 12:38:59 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Caride", "Martin Iglesias", ""], ["Bariviera", "Aurelio F.", ""], ["Lanzarini", "Laura", ""]]}, {"id": "1801.08007", "submitter": "Ricardo Cris\\'ostomo", "authors": "Ricardo Crisostomo, Lorena Couso", "title": "Financial density forecasts: A comprehensive comparison of risk-neutral\n  and historical schemes", "comments": "Journal of Forecasting, 2018", "journal-ref": null, "doi": "10.1002/for.2521", "report-no": null, "categories": "q-fin.RM math.PR q-fin.ST stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the forecasting ability of the most commonly used benchmarks\nin financial economics. We approach the usual caveats of probabilistic\nforecasts studies -small samples, limited models and non-holistic validations-\nby performing a comprehensive comparison of 15 predictive schemes during a time\nperiod of over 21 years. All densities are evaluated in terms of their\nstatistical consistency, local accuracy and forecasting errors. Using a new\ncomposite indicator, the Integrated Forecast Score (IFS), we show that\nrisk-neutral densities outperform historical-based predictions in terms of\ninformation content. We find that the Variance Gamma model generates the\nhighest out-of-sample likelihood of observed prices and the lowest predictive\nerrors, whereas the ARCH-based GJR-FHS delivers the most consistent forecasts\nacross the entire density range. In contrast, lognormal densities, the Heston\nmodel or the Breeden-Litzenberger formula yield biased predictions and are\nrejected in statistical tests.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 14:50:49 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 14:28:47 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Crisostomo", "Ricardo", ""], ["Couso", "Lorena", ""]]}, {"id": "1801.08256", "submitter": "Ishanu Chattopadhyay", "authors": "Ishanu Chattopadhyay", "title": "A Hilbert Space of Stationary Ergodic Processes", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DM q-fin.ST stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying meaningful signal buried in noise is a problem of interest\narising in diverse scenarios of data-driven modeling. We present here a\ntheoretical framework for exploiting intrinsic geometry in data that resists\nnoise corruption, and might be identifiable under severe obfuscation. Our\napproach is based on uncovering a valid complete inner product on the space of\nergodic stationary finite valued processes, providing the latter with the\nstructure of a Hilbert space on the real field. This rigorous construction,\nbased on non-standard generalizations of the notions of sum and scalar\nmultiplication of finite dimensional probability vectors, allows us to\nmeaningfully talk about \"angles\" between data streams and data sources, and,\nmake precise the notion of orthogonal stochastic processes. In particular, the\nrelative angles appear to be preserved, and identifiable, under severe noise,\nand will be developed in future as the underlying principle for robust\nclassification, clustering and unsupervised featurization algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 02:18:49 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Chattopadhyay", "Ishanu", ""]]}, {"id": "1801.09956", "submitter": "Moritz Schauer", "authors": "Shota Gugushvili, Frank van der Meulen, Moritz Schauer, Peter Spreij", "title": "Nonparametric Bayesian volatility estimation", "comments": null, "journal-ref": "2017 MATRIX Annals, Springer International Publishing, 2019", "doi": "10.1007/978-3-030-04161-8_19", "report-no": null, "categories": "stat.ME math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given discrete time observations over a fixed time interval, we study a\nnonparametric Bayesian approach to estimation of the volatility coefficient of\na stochastic differential equation. We postulate a histogram-type prior on the\nvolatility with piecewise constant realisations on bins forming a partition of\nthe time interval. The values on the bins are assigned an inverse Gamma Markov\nchain (IGMC) prior. Posterior inference is straightforward to implement via\nGibbs sampling, as the full conditional distributions are available explicitly\nand turn out to be inverse Gamma. We also discuss in detail the hyperparameter\nselection for our method. Our nonparametric Bayesian approach leads to good\npractical results in representative simulation examples. Finally, we apply it\non a classical data set in change-point analysis: weekly closings of the\nDow-Jones industrial averages.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 12:31:06 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 14:48:17 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Gugushvili", "Shota", ""], ["van der Meulen", "Frank", ""], ["Schauer", "Moritz", ""], ["Spreij", "Peter", ""]]}, {"id": "1801.10583", "submitter": "Rick Steinert", "authors": "Rick Steinert, Florian Ziel", "title": "Short- to Mid-term Day-Ahead Electricity Price Forecasting Using Futures", "comments": null, "journal-ref": "The Energy Journal, 40.1 (2019) 105-127", "doi": "10.5547/01956574.40.1.rste", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the liberalization of markets, the change in the energy mix and the\nsurrounding energy laws, electricity research is a dynamically altering field\nwith steadily changing challenges. One challenge especially for investment\ndecisions is to provide reliable short to mid-term forecasts despite high\nvariation in the time series of electricity prices. This paper tackles this\nissue in a promising and novel approach. By combining the precision of\neconometric autoregressive models in the short-run with the expectations of\nmarket participants reflected in future prices for the short- and mid-run we\nshow that the forecasting performance can be vastly increased while maintaining\nhourly precision. We investigate the day-ahead electricity price of the EPEX\nSpot for Germany and Austria and setup a model which incorporates the Phelix\nfuture of the EEX for Germany and Austria. The model can be considered as an\nAR24-X model with one distinct model for each hour of the day. We are able to\nshow that future data contains relevant price information for future time\nperiods of the day-ahead electricity price. We show that relying only on\ndeterministic external regressors can provide stability for forecast horizons\nof multiple weeks. By implementing a fast and efficient lasso estimation\napproach we demonstrate that our model can outperform several other models in\nthe literature.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 18:09:20 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Steinert", "Rick", ""], ["Ziel", "Florian", ""]]}]