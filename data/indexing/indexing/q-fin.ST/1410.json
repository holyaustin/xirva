[{"id": "1410.0112", "submitter": "Nien-Lin Liu", "authors": "Jir\\^o Akahori, Nien-Lin Liu, Maria Elvira Mancino and Yukie Yasuda", "title": "The Fourier estimation method with positive semi-definite estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a slight modification of the Fourier estimation\nmethod of the spot volatility (matrix) process of a continuous It\\^o\nsemimartingale where the estimators are always non-negative definite. Since the\nestimators are factorized, computational cost will be saved a lot.\n", "versions": [{"version": "v1", "created": "Wed, 1 Oct 2014 05:53:45 GMT"}], "update_date": "2014-10-02", "authors_parsed": [["Akahori", "Jir\u00f4", ""], ["Liu", "Nien-Lin", ""], ["Mancino", "Maria Elvira", ""], ["Yasuda", "Yukie", ""]]}, {"id": "1410.3394", "submitter": "Mathieu Rosenbaum", "authors": "Jim Gatheral, Thibault Jaisson and Mathieu Rosenbaum", "title": "Volatility is rough", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.MF q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating volatility from recent high frequency data, we revisit the\nquestion of the smoothness of the volatility process. Our main result is that\nlog-volatility behaves essentially as a fractional Brownian motion with Hurst\nexponent H of order 0.1, at any reasonable time scale. This leads us to adopt\nthe fractional stochastic volatility (FSV) model of Comte and Renault. We call\nour model Rough FSV (RFSV) to underline that, in contrast to FSV, H<1/2. We\ndemonstrate that our RFSV model is remarkably consistent with financial time\nseries data; one application is that it enables us to obtain improved forecasts\nof realized volatility. Furthermore, we find that although volatility is not\nlong memory in the RFSV model, classical statistical procedures aiming at\ndetecting volatility persistence tend to conclude the presence of long memory\nin data generated from it. This sheds light on why long memory of volatility\nhas been widely accepted as a stylized fact. Finally, we provide a quantitative\nmarket microstructure-based foundation for our findings, relating the roughness\nof volatility to high frequency trading and order splitting.\n", "versions": [{"version": "v1", "created": "Mon, 13 Oct 2014 17:04:11 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Gatheral", "Jim", ""], ["Jaisson", "Thibault", ""], ["Rosenbaum", "Mathieu", ""]]}, {"id": "1410.5513", "submitter": "Zurab Kakushadze", "authors": "Zura Kakushadze", "title": "4-Factor Model for Overnight Returns", "comments": "19 pages; a minor remark and references added; to appear in Wilmott\n  Magazine", "journal-ref": "Wilmott Magazine 2015(79) (2015) 56-62", "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a 4-factor model for overnight returns and give explicit\ndefinitions of our 4 factors. Long horizon fundamental factors such as value\nand growth lack predictive power for overnight (or similar short horizon)\nreturns and are not included. All 4 factors are constructed based on intraday\nprice and volume data and are analogous to size (price), volatility, momentum\nand liquidity (volume). Historical regressions a la Fama and MacBeth (1973)\nsuggest that our 4 factors have sizable serial t-statistic and appear to be\nrelevant predictors for overnight returns. We check this by using our 4-factor\nmodel in an explicit intraday mean-reversion alpha.\n", "versions": [{"version": "v1", "created": "Tue, 21 Oct 2014 01:29:21 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2015 13:51:57 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Kakushadze", "Zura", ""]]}, {"id": "1410.6005", "submitter": "Enrique Salvador PhD", "authors": "John Cotter and Enrique Salvador", "title": "The non-linear trade-off between return and risk: a regime-switching\n  multi-factor framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study develops a multi-factor framework where not only market risk is\nconsidered but also potential changes in the investment opportunity set.\nAlthough previous studies find no clear evidence about a positive and\nsignificant relation between return and risk, favourable evidence can be\nobtained if a non-linear relation is pursued. The positive and significant\nrisk-return trade-off is essentially observed during low volatility periods.\nHowever, this relationship is not obtained during periods of high volatility.\nAlso, different patterns for the risk premium dynamics in low and high\nvolatility periods are obtained both in prices of risk and market risk\ndynamics.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 11:35:14 GMT"}], "update_date": "2014-10-23", "authors_parsed": [["Cotter", "John", ""], ["Salvador", "Enrique", ""]]}, {"id": "1410.6841", "submitter": "Yuri A. Katz", "authors": "Yuri A. Katz", "title": "qGaussian model of default", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the qGaussian generalization of the Merton framework, which takes\ninto account slow fluctuations of the volatility of the firms market value of\nfinancial assets. The minimal version of the model depends on the Tsallis\nentropic parameter q and the generalized distance to default. The empirical\nfoundation and implications of the model are illustrated by the study of 645\nNorth American industrial firms during the financial crisis, 2006 - 2012. All\ndefaulters in the sample have exceptionally large, corresponding to unusually\nfat-tailed unconditional distributions of log-asset-returns. Using Receiver\nOperating Characteristic curves, we demonstrate the high forecasting power of\nthe model in prediction of 1-year defaults. Our study suggests that the level\nof complexity of the realized time series, quantified by q, should be taken\ninto account to improve valuations of default risk.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 21:28:29 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Katz", "Yuri A.", ""]]}, {"id": "1410.6898", "submitter": "Mauro Bernardi", "authors": "Mauro Bernardi, Leopoldo Catania and Lea Petrella", "title": "Are news important to predict large losses?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.RM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the impact of news to predict extreme financial\nreturns using high frequency data. We consider several model specifications\ndiffering for the dynamic property of the underlying stochastic process as well\nas for the innovation process. Since news are essentially qualitative measures,\nthey are firstly transformed into quantitative measures which are subsequently\nintroduced as exogenous regressors into the conditional volatility dynamics.\nThree basic sentiment indexes are constructed starting from three list of words\ndefined by historical market news response and by a discriminant analysis.\nModels are evaluated in terms of their predictive accuracy to forecast\nout-of-sample Value-at-Risk of the STOXX Europe 600 sectors at different\nconfidence levels using several statistic tests and the Model Confidence Set\nprocedure of Hansen et al. (2011). Since the Hansen's procedure usually\ndelivers a set of models having the same VaR predictive ability, we propose a\nnew forecasting combination technique that dynamically weights the VaR\npredictions obtained by the models belonging to the optimal final set. Our\nresults confirms that the inclusion of exogenous information as well as the\nright specification of the returns' conditional distribution significantly\ndecrease the number of actual versus expected VaR violations towards one, as\nthis is especially true for higher confidence levels.\n", "versions": [{"version": "v1", "created": "Sat, 25 Oct 2014 08:53:09 GMT"}, {"version": "v2", "created": "Tue, 28 Oct 2014 11:15:14 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Bernardi", "Mauro", ""], ["Catania", "Leopoldo", ""], ["Petrella", "Lea", ""]]}, {"id": "1410.7799", "submitter": "Adrian Raftery", "authors": "Luca Onorante and Adrian E. Raftery", "title": "Dynamic Model Averaging in Large Model Spaces Using Dynamic Occam's\n  Window", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian model averaging has become a widely used approach to accounting for\nuncertainty about the structural form of the model generating the data. When\ndata arrive sequentially and the generating model can change over time, Dynamic\nModel Averaging (DMA) extends model averaging to deal with this situation.\nOften in macroeconomics, however, many candidate explanatory variables are\navailable and the number of possible models becomes too large for DMA to be\napplied in its original form. We propose a new method for this situation which\nallows us to perform DMA without considering the whole model space, but using a\nsubset of models and dynamically optimizing the choice of models at each point\nin time. This yields a dynamic form of Occam's window. We evaluate the method\nin the context of the problem of nowcasting GDP in the Euro area. We find that\nits forecasting performance compares well that of other methods.\n  Keywords: Bayesian model averaging; Model uncertainty; Nowcasting; Occam's\nwindow.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 20:43:05 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Onorante", "Luca", ""], ["Raftery", "Adrian E.", ""]]}, {"id": "1410.8427", "submitter": "Ivan Medovikov", "authors": "Ivan Medovikov", "title": "When does the stock market listen to economic news? New evidence from\n  copulas and news wires", "comments": "37 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.EC q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study association between macroeconomic news and stock market returns\nusing the statistical theory of copulas, and a new comprehensive measure of\nnews based on the indexing of news wires. We find the impact of economic news\non equity returns to be nonlinear and asymmetric. In particular, controlling\nfor economic conditions and surprises associated with releases of economic\ndata, we find that the market reacts strongly and negatively to the most\nunfavourable macroeconomic news, but appears to largely discount the good news.\nThis relationship persists throughout the different stages of the business\ncycle.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 16:23:08 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Medovikov", "Ivan", ""]]}, {"id": "1410.8504", "submitter": "Leopoldo Catania", "authors": "Mauro Bernardi and Leopoldo Catania", "title": "The Model Confidence Set package for R", "comments": "20 pages, 2 tables, 15 code chunk", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the R package MCS which implements the Model Confidence\nSet (MCS) procedure recently developed by Hansen et al. (2011). The Hansen's\nprocedure consists on a sequence of tests which permits to construct a set of\n'superior' models, where the null hypothesis of Equal Predictive Ability (EPA)\nis not rejected at a certain confidence level. The EPA statistic tests is\ncalculated for an arbitrary loss function, meaning that we could test models on\nvarious aspects, for example punctual forecasts. The relevance of the package\nis shown using an example which aims at illustrating in details the use of the\nfunctions provided by the package. The example compares the ability of\ndifferent models belonging to the ARCH family to predict large financial\nlosses. We also discuss the implementation of the ARCH--type models and their\nmaximum likelihood estimation using the popular R package rugarch developed by\nGhalanos (2014).\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 19:24:45 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Bernardi", "Mauro", ""], ["Catania", "Leopoldo", ""]]}]