[{"id": "2004.00047", "submitter": "Ladislav Kristoufek", "authors": "Ladislav Kristoufek", "title": "Grandpa, grandpa, tell me the one about Bitcoin being a safe haven:\n  Evidence from the COVID-19 pandemics", "comments": "8 pages, 4 figures", "journal-ref": "Frontiers in Physics 8:296 (2020)", "doi": "10.3389/fphy.2020.00296", "report-no": null, "categories": "q-fin.ST q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin being a safe haven asset is one of the traditional stories in the\ncryptocurrency community. However, during its existence and relevant presence,\ni.e. approximately since 2013, there has been no severe situation on the\nfinancial markets globally to prove or disprove this story until the COVID-19\npandemics. We study the quantile correlations of Bitcoin and two benchmarks --\nS\\&P500 and VIX -- and we make comparison with gold as the traditional safe\nhaven asset. The Bitcoin safe haven story is shown and discussed to be\nunsubstantiated and far-fetched, while gold comes out as a clear winner in this\ncontest.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:16:17 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Kristoufek", "Ladislav", ""]]}, {"id": "2004.00201", "submitter": "Jianbin Lin Lin", "authors": "Jianbin Lin, Zhiqiang Zhang, Jun Zhou, Xiaolong Li, Jingli Fang,\n  Yanming Fang, Quan Yu, Yuan Qi", "title": "NetDP: An Industrial-Scale Distributed Network Representation Framework\n  for Default Prediction in Ant Credit Pay", "comments": "2018 IEEE International Conference on Big Data (Big Data)", "journal-ref": null, "doi": "10.1109/BigData.2018.8622169", "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ant Credit Pay is a consumer credit service in Ant Financial Service Group.\nSimilar to credit card, loan default is one of the major risks of this credit\nproduct. Hence, effective algorithm for default prediction is the key to losses\nreduction and profits increment for the company. However, the challenges facing\nin our scenario are different from those in conventional credit card service.\nThe first one is scalability. The huge volume of users and their behaviors in\nAnt Financial requires the ability to process industrial-scale data and perform\nmodel training efficiently. The second challenges is the cold-start problem.\nDifferent from the manual review for credit card application in conventional\nbanks, the credit limit of Ant Credit Pay is automatically offered to users\nbased on the knowledge learned from big data. However, default prediction for\nnew users is suffered from lack of enough credit behaviors. It requires that\nthe proposal should leverage other new data source to alleviate the cold-start\nproblem. Considering the above challenges and the special scenario in Ant\nFinancial, we try to incorporate default prediction with network information to\nalleviate the cold-start problem. In this paper, we propose an industrial-scale\ndistributed network representation framework, termed NetDP, for default\nprediction in Ant Credit Pay. The proposal explores network information\ngenerated by various interaction between users, and blends unsupervised and\nsupervised network representation in a unified framework for default prediction\nproblem. Moreover, we present a parameter-server-based distributed implement of\nour proposal to handle the scalability challenge. Experimental results\ndemonstrate the effectiveness of our proposal, especially in cold-start\nproblem, as well as the efficiency for industrial-scale dataset.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 02:22:33 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Lin", "Jianbin", ""], ["Zhang", "Zhiqiang", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""], ["Fang", "Jingli", ""], ["Fang", "Yanming", ""], ["Yu", "Quan", ""], ["Qi", "Yuan", ""]]}, {"id": "2004.00550", "submitter": "Irena Barja\\v{s}i\\'c", "authors": "Irena Barja\\v{s}i\\'c and Nino Antulov-Fantulin", "title": "Time-varying volatility in Bitcoin market and information flow at\n  minute-level frequency", "comments": "17 pages,11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we analyze the time-series of minute price returns on the\nBitcoin market through the statistical models of generalized autoregressive\nconditional heteroskedasticity (GARCH) family. Several mathematical models have\nbeen proposed in finance, to model the dynamics of price returns, each of them\nintroducing a different perspective on the problem, but none without\nshortcomings. We combine an approach that uses historical values of returns and\ntheir volatilities - GARCH family of models, with a so-called \"Mixture of\nDistribution Hypothesis\", which states that the dynamics of price returns are\ngoverned by the information flow about the market. Using time-series of\nBitcoin-related tweets and volume of transactions as external information, we\ntest for improvement in volatility prediction of several GARCH model variants\non a minute level Bitcoin price time series. Statistical tests show that the\nsimplest GARCH(1,1) reacts the best to the addition of external signal to model\nvolatility process on out-of-sample data.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 16:21:33 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 20:43:09 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Barja\u0161i\u0107", "Irena", ""], ["Antulov-Fantulin", "Nino", ""]]}, {"id": "2004.01489", "submitter": "Bohdan Pavlyshenko", "authors": "Bohdan M. Pavlyshenko", "title": "Regression Approach for Modeling COVID-19 Spread and its Impact On Stock\n  Market", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper studies different regression approaches for modeling COVID-19\nspread and its impact on the stock market. The logistic curve model was used\nwith Bayesian regression for predictive analytics of the coronavirus spread.\nThe impact of COVID-19 was studied using regression approach and compared to\nother crises influence. In practical analytics, it is important to find the\nmaximum of coronavirus cases per day, this point means the estimated half time\nof coronavirus spread in the region under investigation. The obtained results\nshow that different crises with different reasons have different impact on the\nsame stocks. It is important to analyze their impact separately. Bayesian\ninference makes it possible to analyze the uncertainty of crisis impacts.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 10:54:50 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Pavlyshenko", "Bohdan M.", ""]]}, {"id": "2004.01496", "submitter": "Antoniya Shivarova", "authors": "Sven Husmann, Antoniya Shivarova, Rick Steinert", "title": "Company classification using machine learning", "comments": "16 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent advancements in computational power and machine learning\nalgorithms have led to vast improvements in manifold areas of research.\nEspecially in finance, the application of machine learning enables both\nresearchers and practitioners to gain new insights into financial data and\nwell-studied areas such as company classification. In our paper, we demonstrate\nthat unsupervised machine learning algorithms can be used to visualize and\nclassify company data in an economically meaningful and effective way. In\nparticular, we implement the data-driven dimension reduction and visualization\ntool t-distributed stochastic neighbor embedding (t-SNE) in combination with\nspectral clustering. The resulting company groups can then be utilized by\nexperts in the field for empirical analysis and optimal decision making. By\nproviding an exemplary out-of-sample study within a portfolio optimization\nframework, we show that the application of t-SNE and spectral clustering\nimproves the overall portfolio performance. Therefore, we introduce our\napproach to the financial community as a valuable technique in the context of\ndata analysis and company classification.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 23:36:27 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 08:41:06 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Husmann", "Sven", ""], ["Shivarova", "Antoniya", ""], ["Steinert", "Rick", ""]]}, {"id": "2004.01497", "submitter": "Amir Mosavi Prof", "authors": "Mojtaba Nabipour, Pooyan Nayyeri, Hamed Jabani, Amir Mosavi", "title": "Deep learning for Stock Market Prediction", "comments": "25 pages, 35 tables, 6 figures", "journal-ref": null, "doi": "10.3390/e22080840", "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prediction of stock groups' values has always been attractive and challenging\nfor shareholders. This paper concentrates on the future prediction of stock\nmarket groups. Four groups named diversified financials, petroleum,\nnon-metallic minerals and basic metals from Tehran stock exchange are chosen\nfor experimental evaluations. Data are collected for the groups based on ten\nyears of historical records. The values predictions are created for 1, 2, 5,\n10, 15, 20 and 30 days in advance. The machine learning algorithms utilized for\nprediction of future values of stock market groups. We employed Decision Tree,\nBagging, Random Forest, Adaptive Boosting (Adaboost), Gradient Boosting and\neXtreme Gradient Boosting (XGBoost), and Artificial neural network (ANN),\nRecurrent Neural Network (RNN) and Long short-term memory (LSTM). Ten technical\nindicators are selected as the inputs into each of the prediction models.\nFinally, the result of predictions is presented for each technique based on\nthree metrics. Among all the algorithms used in this paper, LSTM shows more\naccurate results with the highest model fitting ability. Also, for tree-based\nmodels, there is often an intense competition between Adaboost, Gradient\nBoosting, and XGBoost.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 22:50:01 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Nabipour", "Mojtaba", ""], ["Nayyeri", "Pooyan", ""], ["Jabani", "Hamed", ""], ["Mosavi", "Amir", ""]]}, {"id": "2004.01498", "submitter": "Ye-Sheen Lim", "authors": "Ye-Sheen Lim, Denise Gorse", "title": "Deep Probabilistic Modelling of Price Movements for High-Frequency\n  Trading", "comments": "8 pages, 2 columns, IJCNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a deep recurrent architecture for the probabilistic\nmodelling of high-frequency market prices, important for the risk management of\nautomated trading systems. Our proposed architecture incorporates probabilistic\nmixture models into deep recurrent neural networks. The resulting deep mixture\nmodels simultaneously address several practical challenges important in the\ndevelopment of automated high-frequency trading strategies that were previously\nneglected in the literature: 1) probabilistic forecasting of the price\nmovements; 2) single objective prediction of both the direction and size of the\nprice movements. We train our models on high-frequency Bitcoin market data and\nevaluate them against benchmark models obtained from the literature. We show\nthat our model outperforms the benchmark models in both a metric-based test and\nin a simulated trading scenario\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 19:25:40 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Lim", "Ye-Sheen", ""], ["Gorse", "Denise", ""]]}, {"id": "2004.01499", "submitter": "Ye-Sheen Lim", "authors": "Ye-Sheen Lim, Denise Gorse", "title": "Deep Recurrent Modelling of Stationary Bitcoin Price Formation Using the\n  Order Flow", "comments": "10 pages, The 19th International Conference on Artificial\n  Intelligence and Soft Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a deep recurrent model based on the order flow for\nthe stationary modelling of the high-frequency directional prices movements.\nThe order flow is the microsecond stream of orders arriving at the exchange,\ndriving the formation of prices seen on the price chart of a stock or currency.\nTo test the stationarity of our proposed model we train our model on data\nbefore the 2017 Bitcoin bubble period and test our model during and after the\nbubble. We show that without any retraining, the proposed model is temporally\nstable even as Bitcoin trading shifts into an extremely volatile \"bubble\ntrouble\" period. The significance of the result is shown by benchmarking\nagainst existing state-of-the-art models in the literature for modelling price\nformation using deep learning.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:13:04 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Lim", "Ye-Sheen", ""], ["Gorse", "Denise", ""]]}, {"id": "2004.01502", "submitter": "JongHyeon Min", "authors": "Jonghyeon Min", "title": "Financial Market Trend Forecasting and Performance Analysis Using LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The financial market trend forecasting method is emerging as a hot topic in\nfinancial markets today. Many challenges still currently remain, and various\nresearches related thereto have been actively conducted. Especially, recent\nresearch of neural network-based financial market trend prediction has\nattracted much attention. However, previous researches do not deal with the\nfinancial market forecasting method based on LSTM which has good performance in\ntime series data. There is also a lack of comparative analysis in the\nperformance of neural network-based prediction techniques and traditional\nprediction techniques. In this paper, we propose a financial market trend\nforecasting method using LSTM and analyze the performance with existing\nfinancial market trend forecasting methods through experiments. This method\nprepares the input data set through the data preprocessing process so as to\nreflect all the fundamental data, technical data and qualitative data used in\nthe financial data analysis, and makes comprehensive financial market analysis\nthrough LSTM. In this paper, we experiment and compare performances of existing\nfinancial market trend forecasting models, and performance according to the\nfinancial market environment. In addition, we implement the proposed method\nusing open sources and platform and forecast financial market trends using\nvarious financial data indicators.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 01:30:36 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Min", "Jonghyeon", ""]]}, {"id": "2004.01504", "submitter": "Philip Ndikum", "authors": "Philip Ndikum", "title": "Machine Learning Algorithms for Financial Asset Price Forecasting", "comments": "16 pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research paper explores the performance of Machine Learning (ML)\nalgorithms and techniques that can be used for financial asset price\nforecasting. The prediction and forecasting of asset prices and returns remains\none of the most challenging and exciting problems for quantitative finance and\npractitioners alike. The massive increase in data generated and captured in\nrecent years presents an opportunity to leverage Machine Learning algorithms.\nThis study directly compares and contrasts state-of-the-art implementations of\nmodern Machine Learning algorithms on high performance computing (HPC)\ninfrastructures versus the traditional and highly popular Capital Asset Pricing\nModel (CAPM) on U.S equities data. The implemented Machine Learning models -\ntrained on time series data for an entire stock universe (in addition to\nexogenous macroeconomic variables) significantly outperform the CAPM on\nout-of-sample (OOS) test data.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:14:18 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Ndikum", "Philip", ""]]}, {"id": "2004.01509", "submitter": "Amir Mosavi Prof", "authors": "Amir Mosavi, Pedram Ghamisi, Yaser Faghan, Puhong Duan", "title": "Comprehensive Review of Deep Reinforcement Learning Methods and\n  Applications in Economics", "comments": "42 pages, 26 figures", "journal-ref": null, "doi": "10.20944/preprints202003.0309.v1", "report-no": null, "categories": "q-fin.ST cs.LG econ.GN q-fin.EC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The popularity of deep reinforcement learning (DRL) methods in economics have\nbeen exponentially increased. DRL through a wide range of capabilities from\nreinforcement learning (RL) and deep learning (DL) for handling sophisticated\ndynamic business environments offers vast opportunities. DRL is characterized\nby scalability with the potential to be applied to high-dimensional problems in\nconjunction with noisy and nonlinear patterns of economic data. In this work,\nwe first consider a brief review of DL, RL, and deep RL methods in diverse\napplications in economics providing an in-depth insight into the state of the\nart. Furthermore, the architecture of DRL applied to economic applications is\ninvestigated in order to highlight the complexity, robustness, accuracy,\nperformance, computational tasks, risk constraints, and profitability. The\nsurvey results indicate that DRL can provide better performance and higher\naccuracy as compared to the traditional algorithms while facing real economic\nproblems at the presence of risk parameters and the ever-increasing\nuncertainties.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 14:07:59 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Mosavi", "Amir", ""], ["Ghamisi", "Pedram", ""], ["Faghan", "Yaser", ""], ["Duan", "Puhong", ""]]}, {"id": "2004.01865", "submitter": "Jose Figueroa-Lopez", "authors": "Jos\\'e E. Figueroa-L\\'opez and Bei Wu", "title": "Kernel Estimation of Spot Volatility with Microstructure Noise Using\n  Pre-Averaging", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first revisit the problem of estimating the spot volatility of an It\\^o\nsemimartingale using a kernel estimator. We prove a Central Limit Theorem with\noptimal convergence rate for a general two-sided kernel. Next, we introduce a\nnew pre-averaging/kernel estimator for spot volatility to handle the\nmicrostructure noise of ultra high-frequency observations. We prove a Central\nLimit Theorem for the estimation error with an optimal rate and study the\noptimal selection of the bandwidth and kernel functions. We show that the\npre-averaging/kernel estimator's asymptotic variance is minimal for exponential\nkernels, hence, justifying the need of working with kernels of unbounded\nsupport as proposed in this work. We also develop a feasible implementation of\nthe proposed estimators with optimal bandwidth. Monte Carlo experiments confirm\nthe superior performance of the devised method.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 05:43:25 GMT"}, {"version": "v2", "created": "Tue, 5 Jan 2021 16:41:09 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Figueroa-L\u00f3pez", "Jos\u00e9 E.", ""], ["Wu", "Bei", ""]]}, {"id": "2004.02670", "submitter": "Olivier Scaillet", "authors": "Stelios Arvanitis, Olivier Scaillet, Nikolas Topaloglou", "title": "Spanning analysis of stock market anomalies under Prospect Stochastic\n  Dominance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM econ.EM q-fin.ST stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop and implement methods for determining whether introducing new\nsecurities or relaxing investment constraints improves the investment\nopportunity set for prospect investors. We formulate a new testing procedure\nfor prospect spanning for two nested portfolio sets based on subsampling and\nLinear Programming. In an application, we use the prospect spanning framework\nto evaluate whether well-known anomalies are spanned by standard factors. We\nfind that of the strategies considered, many expand the opportunity set of the\nprospect type investors, thus have real economic value for them. In-sample and\nout-of-sample results prove remarkably consistent in identifying genuine\nanomalies for prospect investors.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 13:41:32 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Arvanitis", "Stelios", ""], ["Scaillet", "Olivier", ""], ["Topaloglou", "Nikolas", ""]]}, {"id": "2004.03319", "submitter": "Pawe{\\l} O\\'swi\\k{e}cimka", "authors": "Pawe{\\l} O\\'swi\\k{e}cimka, Stanis{\\l}aw Dro\\.zd\\.z, Mattia Frasca,\n  Robert G\\k{e}barowski, Natsue Yoshimura, Luciano Zunino, Ludovico Minati", "title": "Wavelet-based discrimination of isolated singularities masquerading as\n  multifractals in detrended fluctuation analyses", "comments": "To appear in Nonlinear Dynamics", "journal-ref": null, "doi": "10.1007/s11071-020-05581-y", "report-no": null, "categories": "physics.data-an nlin.CD q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robustness of two widespread multifractal analysis methods, one based on\ndetrended fluctuation analysis and one on wavelet leaders, is discussed in the\ncontext of time-series containing non-uniform structures with only isolated\nsingularities. Signals generated by simulated and experimentally-realized chaos\ngenerators, together with synthetic data addressing particular aspects, are\ntaken into consideration. The results reveal essential limitations affecting\nthe ability of both methods to correctly infer the non-multifractal nature of\nsignals devoid of a cascade-like hierarchy of singularities. Namely, signals\nharboring only isolated singularities are found to artefactually give rise to\nbroad multifractal spectra, resembling those expected in the presence of a\nwell-developed underlying multifractal structure. Hence, there is a real risk\nof incorrectly inferring multifractality due to isolated singularities. The\ncareful consideration of local scaling properties and the distribution of\nH\\\"older exponent obtained, for example, through wavelet analysis, is\nindispensable for rigorously assessing the presence or absence of\nmultifractality.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 12:42:56 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["O\u015bwi\u0119cimka", "Pawe\u0142", ""], ["Dro\u017cd\u017c", "Stanis\u0142aw", ""], ["Frasca", "Mattia", ""], ["G\u0119barowski", "Robert", ""], ["Yoshimura", "Natsue", ""], ["Zunino", "Luciano", ""], ["Minati", "Ludovico", ""]]}, {"id": "2004.05325", "submitter": "Wen-Jie Xie", "authors": "Wen-Jie Xie, Na Wei, Wei-Xing Zhou", "title": "Evolving efficiency and robustness of global oil trade networks", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a vital strategic resource, oil has an essential influence on the world\neconomy, diplomacy and military development. Using oil trade data to\ndynamically monitor and warn about international trade risks is an urgent need.\nBased on the UN Comtrade data from 1988 to 2017, we construct unweighted and\nweighted global oil trade networks (OTNs). Complex network theories have some\nadvantages in analyzing global oil trade as a system with numerous economies\nand complicated relationships. This paper establishes a trading-based network\nmodel for global oil trade to study the evolving efficiency, criticality and\nrobustness of economies and the relationships between oil trade partners. The\nresults show that for unweighted OTNs, the efficiency of oil flows gradually\nincreases with growing complexity of the OTNs, and the weighted efficiency\nindicators are more capable of highlighting the impact of major events on the\nOTNs. The identified critical economies and trade relationships have more\nimportant strategic significance in the real market. The simulated deliberate\nattacks corresponding to national bankruptcy, trade blockade, and economic\nsanctions have a more significant impact on the robustness than random attacks.\nWhen the economies are promoting high-quality economic development, and\ncontinuously enhancing positions in the OTN, more attention needs be paid to\nthe identified critical economies and trade relationships. To conclude, some\nsuggestions for application are given according to the results.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 07:14:56 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Xie", "Wen-Jie", ""], ["Wei", "Na", ""], ["Zhou", "Wei-Xing", ""]]}, {"id": "2004.05870", "submitter": "Edgardo Brigatti", "authors": "F.N.M. de Sousa Filho, J.N. Silva, M.A. Bertella and E. Brigatti", "title": "The leverage effect and other stylized facts displayed by Bitcoin\n  returns", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": "10.1007/s13538-020-00846-8", "report-no": null, "categories": "q-fin.ST q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore some stylized facts of the Bitcoin market using the\nBTC-USD exchange rate time series of historical intraday data from 2013 to\n2020. Bitcoin presents some very peculiar idiosyncrasies, like the absence of\nmacroeconomic fundamentals or connections with underlying assets or benchmarks,\nan asymmetry between demand and supply and the presence of inefficiency in the\nform of strong arbitrage opportunity. Nevertheless, all these elements seem to\nbe marginal in the definition of the structural statistical properties of this\nvirtual financial asset, which result to be analogous to general individual\nstocks or indices. In contrast, we find some clear differences, compared to\nfiat money exchange rates time series, in the values of the linear\nautocorrelation and, more surprisingly, in the presence of the leverage effect.\nWe also explore the dynamics of correlations, monitoring the shifts in the\nevolution of the Bitcoin market. This analysis is able to distinguish between\ntwo different regimes: a stochastic process with weaker memory signatures and\ncloser to Gaussianity between the Mt. Gox incident and the late 2015, and a\ndynamics with relevant correlations and strong deviations from Gaussianity\nbefore and after this interval.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 11:23:02 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 17:41:10 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Filho", "F. N. M. de Sousa", ""], ["Silva", "J. N.", ""], ["Bertella", "M. A.", ""], ["Brigatti", "E.", ""]]}, {"id": "2004.05894", "submitter": "Nassim Nicholas Taleb", "authors": "Nassim Nicholas Taleb", "title": "What You See and What You Don't See: The Hidden Moments of a Probability\n  Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empirical distributions have their in-sample maxima as natural censoring. We\nlook at the \"hidden tail\", that is, the part of the distribution in excess of\nthe maximum for a sample size of $n$. Using extreme value theory, we examine\nthe properties of the hidden tail and calculate its moments of order $p$. The\nmethod is useful in showing how large a bias one can expect, for a given $n$,\nbetween the visible in-sample mean and the true statistical mean (or higher\nmoments), which is considerable for $\\alpha$ close to 1. Among other\nproperties, we note that the \"hidden\" moment of order $0$, that is, the\nexceedance probability for power law distributions, follows an exponential\ndistribution and has for expectation $\\frac{1}{n}$ regardless of the\nparametrization of the scale and tail index.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 19:43:13 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Taleb", "Nassim Nicholas", ""]]}, {"id": "2004.06200", "submitter": "Peter B. Lerner", "authors": "P. B. Lerner", "title": "Dual State-Space Model of Market Liquidity: The Chinese Experience\n  2009-2010", "comments": "Only the abstract has been changed from the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes and motivates a dynamical model of the Chinese stock\nmarket based on a linear regression in a dual state space connected to the\noriginal state space of correlations between the volume-at-price buckets by a\nFourier transform. We apply our model to the price migration of executed orders\nby the Chinese brokerages in 2009-2010. Regulatory brokerage tapes were used to\nconduct a natural experiment assuming that tapes correspond to randomly\nassigned, informed and uninformed traders. Our analysis demonstrated that\ncustomers' orders were tightly correlated--in a highly nonlinear sense of the\nneural networks--with the Chinese market sentiment index, significantly\ncorrelated with the stock returns and exhibited no correlation with the\nbellwether bond of the Bank of China. We did not notice any spike of\nilliquidity transmitting from the US Flash Crash in May 2010 to trading in\nChina.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 20:57:44 GMT"}, {"version": "v2", "created": "Wed, 13 May 2020 20:58:48 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Lerner", "P. B.", ""]]}, {"id": "2004.06565", "submitter": "Chirag Nagpal", "authors": "Chirag Nagpal, Robert E. Tillman, Prashant Reddy, Manuela Veloso", "title": "Bayesian Consensus: Consensus Estimates from Miscalibrated Instruments\n  under Heteroscedastic Noise", "comments": null, "journal-ref": "NeurIPS 2019 Workshop on Robust AI in Financial Services: Data,\n  Fairness, Explainability, Trustworthiness and Privacy", "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of aggregating predictions or measurements from a set\nof human forecasters, models, sensors or other instruments which may be subject\nto bias or miscalibration and random heteroscedastic noise. We propose a\nBayesian consensus estimator that adjusts for miscalibration and noise and show\nthat this estimator is unbiased and asymptotically more efficient than naive\nalternatives. We further propose a Hierarchical Bayesian Model that leverages\nour proposed estimator and apply it to two real world forecasting challenges\nthat require consensus estimates from error prone individual estimates:\nforecasting influenza like illness (ILI) weekly percentages and forecasting\nannual earnings of public companies. We demonstrate that our approach is\neffective at mitigating bias and error and results in more accurate forecasts\nthan existing consensus models.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 15:10:21 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 23:49:43 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Nagpal", "Chirag", ""], ["Tillman", "Robert E.", ""], ["Reddy", "Prashant", ""], ["Veloso", "Manuela", ""]]}, {"id": "2004.06586", "submitter": "Xiaochun Meng", "authors": "Carol Alexander, Xiaochun Meng, Wei Wei", "title": "Extensions of Random Orthogonal Matrix Simulation for Targetting Kollo\n  Skewness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST q-fin.CP q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling multivariate systems is important for many applications in\nengineering and operational research. The multivariate distributions under\nscrutiny usually have no analytic or closed form. Therefore their modelling\nemploys a numerical technique, typically multivariate simulations, which can\nhave very high dimensions. Random Orthogonal Matrix (ROM) simulation is a\nmethod that has gained some popularity because of the absence of certain\nsimulation errors. Specifically, it exactly matches a target mean, covariance\nmatrix and certain higher moments with every simulation. This paper extends the\nROM simulation algorithm presented by Hanke et al. (2017), hereafter referred\nto as HPSW, which matches the target mean, covariance matrix and Kollo skewness\nvector exactly. Our first contribution is to establish necessary and sufficient\nconditions for the HPSW algorithm to work. Our second contribution is to\ndevelop a general approach for constructing admissible values in the HPSW. Our\nthird theoretical contribution is to analyse the effect of multivariate sample\nconcatenation on the target Kollo skewness. Finally, we illustrate the\nextensions we develop here using a simulation study.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 15:18:20 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2021 16:51:37 GMT"}], "update_date": "2021-02-01", "authors_parsed": [["Alexander", "Carol", ""], ["Meng", "Xiaochun", ""], ["Wei", "Wei", ""]]}, {"id": "2004.06676", "submitter": "Erick Trevino Aguilar", "authors": "Erick Trevi\\~no Aguilar", "title": "The interdependency structure in the Mexican stock exchange: A network\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our goal in this paper is to study and characterize the interdependency\nstructure of the Mexican Stock Exchange (mainly stocks from BMV) in the period\n2000-2019 and provide visualizations which in a one shot provide a big-picture\npanorama. To this end, we estimate correlation/concentration matrices from\ndifferent models and then compute metrics from network theory including\neigencentralities and network modularity\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 17:27:15 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Aguilar", "Erick Trevi\u00f1o", ""]]}, {"id": "2004.07290", "submitter": "Lorenzo Lucchini", "authors": "Lorenzo Lucchini, Laura Alessandretti, Bruno Lepri, Angela Gallo, and\n  Andrea Baronchelli", "title": "From code to market: Network of developers and correlated returns of\n  cryptocurrencies", "comments": null, "journal-ref": "Science Advances, 16 Dec 2020: Vol. 6, no. 51, eabd2204", "doi": "10.1126/sciadv.abd2204", "report-no": null, "categories": "q-fin.ST cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Code is law\" is the funding principle of cryptocurrencies. The security,\ntransferability, availability and other properties of a crypto-asset are\ndetermined by the code through which it is created. If code is open source, as\nit happens for most cryptocurrencies, this principle would prevent\nmanipulations and grant transparency to users and traders. However, this\napproach considers cryptocurrencies as isolated entities thus neglecting\npossible connections between them. Here, we show that 4% of developers\ncontribute to the code of more than one cryptocurrency and that the market\nreflects these cross-asset dependencies. In particular, we reveal that the\nfirst coding event linking two cryptocurrencies through a common developer\nleads to the synchronisation of their returns in the following months. Our\nresults identify a clear link between the collaborative development of\ncryptocurrencies and their market behaviour. More broadly, our work reveals a\nso-far overlooked systemic dimension for the transparency of code-based\necosystems and we anticipate it will be of interest to researchers, investors\nand regulators.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 18:48:47 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2020 20:40:47 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Lucchini", "Lorenzo", ""], ["Alessandretti", "Laura", ""], ["Lepri", "Bruno", ""], ["Gallo", "Angela", ""], ["Baronchelli", "Andrea", ""]]}, {"id": "2004.07612", "submitter": "Wei-Xing Zhou", "authors": "Peng Yue (ECUST), Yaodong Fan (UTS), Jonathan A. Batten (UUM),\n  Wei-Xing Zhou (ECUST)", "title": "Information transfer between stock market sectors: A comparison between\n  the USA and China", "comments": "12 pages including 8 figures", "journal-ref": "Entropy 22 (2), 194 (2020)", "doi": "10.3390/e22020194", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information diffusion within financial markets plays a crucial role in the\nprocess of price formation and the propagation of sentiment and risk. We\nperform a comparative analysis of information transfer between industry sectors\nof the Chinese and the USA stock markets, using daily sector indices for the\nperiod from 2000 to 2017. The information flow from one sector to another is\nmeasured by the transfer entropy of the daily returns of the two sector\nindices. We find that the most active sector in information exchange (i.e., the\nlargest total information inflow and outflow) is the {\\textit{non-bank\nfinancial}} sector in the Chinese market and the {\\textit{technology}} sector\nin the USA market. This is consistent with the role of the non-bank sector in\ncorporate financing in China and the impact of technological innovation in the\nUSA. In each market, the most active sector is also the largest information\nsink that has the largest information inflow (i.e., inflow minus outflow). In\ncontrast, we identify that the main information source is the {\\textit{bank}}\nsector in the Chinese market and the {\\textit{energy}} sector in the USA\nmarket. In the case of China, this is due to the importance of net bank lending\nas a signal of corporate activity and the role of energy pricing in affecting\ncorporate profitability. There are sectors such as the {\\textit{real estate}}\nsector that could be an information sink in one market but an information\nsource in the other, showing the complex behavior of different markets.\nOverall, these findings show that stock markets are more synchronized, or\nordered, during periods of turmoil than during periods of stability.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 11:46:53 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Yue", "Peng", "", "ECUST"], ["Fan", "Yaodong", "", "UTS"], ["Batten", "Jonathan A.", "", "UUM"], ["Zhou", "Wei-Xing", "", "ECUST"]]}, {"id": "2004.08550", "submitter": "Avishek Bhandari", "authors": "Avishek Bhandari and Bandi Kamaiah", "title": "Long memory in select stock returns using an alternative wavelet\n  log-scale alignment approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST eess.SP math.DS nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study investigates the efficiency of some select stock markets. Using an\nimproved wavelet estimator of long range dependence, we show evidence of long\nmemory in the stock returns of some emerging Asian economies. However,\ndeveloped markets of Europe and the United States did not exhibit long memory\nthereby confirming the efficiency of developed stock markets. On the other\nhand, emerging Asian markets are found to be less efficient as long memory is\nmore pronounced in these markets.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2020 08:15:19 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Bhandari", "Avishek", ""], ["Kamaiah", "Bandi", ""]]}, {"id": "2004.08759", "submitter": "Wei-Xing Zhou", "authors": "Peng Yue (ECUST), Qing Cai, Wanfeng Yan (Zhicang Tech) and Wei-Xing\n  Zhou (ECUST)", "title": "Information flow networks of Chinese stock market sectors", "comments": "12 pages including 9 figures", "journal-ref": "IEEE Access 8 (1), 13066-13077 (2020)", "doi": "10.1109/ACCESS.2020.2966278", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer entropy measures the strength and direction of information flow\nbetween different time series. We study the information flow networks of the\nChinese stock market and identify important sectors and information flow paths.\nThis paper uses the daily closing price data of the 28 level-1 sectors from\nShenyin \\& Wanguo Securities ranging from 2000 to 2017 to study the information\ntransmission between different sectors. We construct information flow networks\nwith the sectors as the nodes and the transfer entropy between them as the\ncorresponding edges. Then we adopt the maximum spanning arborescence (MSA) to\nextracting important information flows and the hierarchical structure of the\nnetworks. We find that, during the whole sample period, the \\textit{composite}\nsector is an information source of the whole stock market, while the\n\\textit{non-bank financial} sector is the information sink. We also find that\nthe \\textit{non-bank finance}, \\textit{bank}, \\textit{computer},\n\\textit{media}, \\textit{real estate}, \\textit{medical biology} and\n\\textit{non-ferrous metals} sectors appear as high-degree root nodes in the\noutgoing and incoming information flow MSAs. Especially, the \\textit{non-bank\nfinance} and \\textit{bank} sectors have significantly high degrees after 2008\nin the outgoing information flow networks. We uncover how stock market turmoils\naffect the structure of the MSAs. Finally, we reveal the specificity of\ninformation source and sink sectors and make a conclusion that the root node\nsector as the information sink of the incoming information flow networks.\nOverall, our analyses show that the structure of information flow networks\nchanges with time and the market exhibits a sector rotation phenomenon. Our\nwork has important implications for market participants and policy makers in\nmanaging market risks and controlling the contagion of risks.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 03:13:59 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Yue", "Peng", "", "ECUST"], ["Cai", "Qing", "", "Zhicang Tech"], ["Yan", "Wanfeng", "", "Zhicang Tech"], ["Zhou", "Wei-Xing", "", "ECUST"]]}, {"id": "2004.08891", "submitter": "Weiguan Wang", "authors": "Johannes Ruf, Weiguan Wang", "title": "Hedging with Linear Regressions and Neural Networks", "comments": "Forthcoming in the Journal of Business & Economic Statistics", "journal-ref": null, "doi": "10.1080/07350015.2021.1931241", "report-no": null, "categories": "q-fin.RM cs.LG q-fin.MF q-fin.ST stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We study neural networks as nonparametric estimation tools for the hedging of\noptions. To this end, we design a network, named HedgeNet, that directly\noutputs a hedging strategy. This network is trained to minimise the hedging\nerror instead of the pricing error. Applied to end-of-day and tick prices of\nS&P 500 and Euro Stoxx 50 options, the network is able to reduce the mean\nsquared hedging error of the Black-Scholes benchmark significantly. However, a\nsimilar benefit arises by simple linear regressions that incorporate the\nleverage effect.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 16:07:45 GMT"}, {"version": "v2", "created": "Mon, 25 May 2020 15:23:09 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 08:11:17 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ruf", "Johannes", ""], ["Wang", "Weiguan", ""]]}, {"id": "2004.09963", "submitter": "Nick James", "authors": "Arjun Prakash, Nick James, Max Menzies, Gilad Francis", "title": "Structural clustering of volatility regimes for dynamic trading\n  strategies", "comments": "Expression edits and small methodological changes relative to v1", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE cs.LG q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new method to find the number of volatility regimes in a\nnonstationary financial time series by applying unsupervised learning to its\nvolatility structure. We use change point detection to partition a time series\ninto locally stationary segments and then compute a distance matrix between\nsegment distributions. The segments are clustered into a learned number of\ndiscrete volatility regimes via an optimization routine. Using this framework,\nwe determine a volatility clustering structure for financial indices, large-cap\nequities, exchange-traded funds and currency pairs. Our method overcomes the\nrigid assumptions necessary to implement many parametric regime-switching\nmodels, while effectively distilling a time series into several characteristic\nbehaviours. Our results provide significant simplification of these time series\nand a strong descriptive analysis of prior behaviours of volatility. This\nempirical analysis could be used with other regime-switching implementations,\njustifying the parametric structure encoded in any candidate model. Finally, we\ncreate and validate a dynamic trading strategy that learns the optimal match\nbetween the current distribution of a time series and its past regimes, thereby\nmaking online risk-avoidance decisions in the present.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 12:54:23 GMT"}, {"version": "v2", "created": "Mon, 15 Mar 2021 10:54:34 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Prakash", "Arjun", ""], ["James", "Nick", ""], ["Menzies", "Max", ""], ["Francis", "Gilad", ""]]}, {"id": "2004.10178", "submitter": "Ariel Neufeld", "authors": "Pushpendu Ghosh, Ariel Neufeld, Jajati Keshari Sahoo", "title": "Forecasting directional movements of stock prices for intraday trading\n  using LSTM and random forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We employ both random forests and LSTM networks (more precisely CuDNNLSTM) as\ntraining methodologies to analyze their effectiveness in forecasting\nout-of-sample directional movements of constituent stocks of the S&P 500 from\nJanuary 1993 till December 2018 for intraday trading. We introduce a\nmulti-feature setting consisting not only of the returns with respect to the\nclosing prices, but also with respect to the opening prices and intraday\nreturns. As trading strategy, we use Krauss et al. (2017) and Fischer & Krauss\n(2018) as benchmark. On each trading day, we buy the 10 stocks with the highest\nprobability and sell short the 10 stocks with the lowest probability to\noutperform the market in terms of intraday returns -- all with equal monetary\nweight. Our empirical results show that the multi-feature setting provides a\ndaily return, prior to transaction costs, of 0.64% using LSTM networks, and\n0.54% using random forests. Hence we outperform the single-feature setting in\nFischer & Krauss (2018) and Krauss et al. (2017) consisting only of the daily\nreturns with respect to the closing prices, having corresponding daily returns\nof 0.41% and of 0.39% with respect to LSTM and random forests, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 17:35:48 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 19:16:18 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Ghosh", "Pushpendu", ""], ["Neufeld", "Ariel", ""], ["Sahoo", "Jajati Keshari", ""]]}, {"id": "2004.10560", "submitter": "Kartikay Gupta Mr", "authors": "Kartikay Gupta and Niladri Chatterjee", "title": "Examining Lead-Lag Relationships In-Depth, With Focus On FX Market As\n  Covid-19 Crises Unfolds", "comments": "Suggestions are welcome. In the second version, a citation has been\n  updated on request from the corresponding author", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lead-lag relationship plays a vital role in financial markets. It is the\nphenomenon where a certain price-series lags behind and partially replicates\nthe movement of leading time-series. The present research proposes a new\ntechnique which helps better identify the lead-lag relationship empirically.\nApart from better identifying the lead-lag path, the technique also gives a\nmeasure for adjudging closeness between financial time-series. Also, the\nproposed measure is closely related to correlation, and it uses Dynamic\nProgramming technique for finding the optimal lead-lag path. Further, it\nretains most of the properties of a metric, so much so, it is termed as loose\nmetric. Tests are performed on Synthetic Time Series (STS) with known lead-lag\nrelationship and comparisons are done with other state-of-the-art models on the\nbasis of significance and forecastability. The proposed technique gives the\nbest results in both the tests. It finds paths which are all statistically\nsignificant, and its forecasts are closest to the target values. Then, we use\nthe measure to study the topology evolution of the Foreign Exchange market, as\nthe COVID-19 pandemic unfolds. Here, we study the FX currency prices of 29\nprominent countries of the world. It is observed that as the crises unfold, all\nthe currencies become strongly interlinked to each other. Also, USA Dollar\nstarts playing even more central role in the FX market. Finally, we mention\nseveral other application areas of the proposed technique for designing\nintelligent systems.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 13:24:31 GMT"}, {"version": "v2", "created": "Sat, 9 May 2020 17:41:00 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Gupta", "Kartikay", ""], ["Chatterjee", "Niladri", ""]]}, {"id": "2004.11485", "submitter": "Dimitris Korobilis Prof", "authors": "Dimitris Korobilis", "title": "High-dimensional macroeconomic forecasting using message passing\n  algorithms", "comments": "89 pages; to appear in Journal of Business and Economic Statistics", "journal-ref": null, "doi": "10.1080/07350015.2019.1677472", "report-no": null, "categories": "stat.ME econ.EM q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes two distinct contributions to econometric analysis of\nlarge information sets and structural instabilities. First, it treats a\nregression model with time-varying coefficients, stochastic volatility and\nexogenous predictors, as an equivalent high-dimensional static regression\nproblem with thousands of covariates. Inference in this specification proceeds\nusing Bayesian hierarchical priors that shrink the high-dimensional vector of\ncoefficients either towards zero or time-invariance. Second, it introduces the\nframeworks of factor graphs and message passing as a means of designing\nefficient Bayesian estimation algorithms. In particular, a Generalized\nApproximate Message Passing (GAMP) algorithm is derived that has low\nalgorithmic complexity and is trivially parallelizable. The result is a\ncomprehensive methodology that can be used to estimate time-varying parameter\nregressions with arbitrarily large number of exogenous predictors. In a\nforecasting exercise for U.S. price inflation this methodology is shown to work\nvery well.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 23:10:04 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Korobilis", "Dimitris", ""]]}, {"id": "2004.11674", "submitter": "Roy Cerqueti", "authors": "Roy Cerqueti and Massimiliano Giacalone and Raffaele Mattera", "title": "Skewed non-Gaussian GARCH models for cryptocurrencies volatility\n  modelling", "comments": "54 pages, 7 figures, 34 tables. To be published in Information\n  Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, cryptocurrencies have attracted a growing interest from investors,\npractitioners and researchers. Nevertheless, few studies have focused on the\npredictability of them. In this paper we propose a new and comprehensive study\nabout cryptocurrency market, evaluating the forecasting performance for three\nof the most important cryptocurrencies (Bitcoin, Ethereum and Litecoin) in\nterms of market capitalization. At this aim, we consider non-Gaussian GARCH\nvolatility models, which form a class of stochastic recursive systems commonly\nadopted for financial predictions. Results show that the best specification and\nforecasting accuracy are achieved under the Skewed Generalized Error\nDistribution when Bitcoin/USD and Litecoin/USD exchange rates are considered,\nwhile the best performances are obtained for skewed Distribution in the case of\nEthereum/USD exchange rate. The obtain findings state the effectiveness -- in\nterms of prediction performance -- of relaxing the normality assumption and\nconsidering skewed distributions.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 14:24:37 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Cerqueti", "Roy", ""], ["Giacalone", "Massimiliano", ""], ["Mattera", "Raffaele", ""]]}, {"id": "2004.11686", "submitter": "Hasan Fallahgoul", "authors": "Hasan Fallahgoul", "title": "Inside the Mind of Investors During the COVID-19 Pandemic: Evidence from\n  the StockTwits Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST econ.GN q-fin.EC q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the investor beliefs, sentiment and disagreement, about stock market\nreturns during the COVID-19 pandemic using a large number of messages of\ninvestors on a social media investing platform, \\textit{StockTwits}. The rich\nand multimodal features of StockTwits data allow us to explore the evolution of\nsentiment and disagreement within and across investors, sectors, and even\nindustries. We find that the sentiment (disagreement) has a sharp decrease\n(increase) across all investors with any investment philosophy, horizon, and\nexperience between February 19, 2020, and March 23, 2020, where a historical\nmarket high followed by a record drop. Surprisingly, these measures have a\nsharp reverse toward the end of March. However, the performance of these\nmeasures across various sectors is heterogeneous. Financial and healthcare\nsectors are the most pessimistic and optimistic divisions, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 12:25:43 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 15:28:32 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Fallahgoul", "Hasan", ""]]}, {"id": "2004.11697", "submitter": "Jaydip Sen", "authors": "Sidra Mehtab and Jaydip Sen", "title": "A Time Series Analysis-Based Stock Price Prediction Using Machine\n  Learning and Deep Learning Models", "comments": "This is the preprint of our paper accepted for publication in the\n  Inderscience Journal International Journal of Business Forecasting and\n  Marketing Intelligence. The paper consists of 53 pages, 26 Tables, and 46\n  Figures", "journal-ref": "International Journal of Business Forecasting and Marketing\n  Intelligence (IJBFMI), Vol 6, No 4, pp. 272 - 335, 2020. Inderscience\n  Publishers", "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of future movement of stock prices has always been a challenging\ntask for the researchers. While the advocates of the efficient market\nhypothesis (EMH) believe that it is impossible to design any predictive\nframework that can accurately predict the movement of stock prices, there are\nseminal work in the literature that have clearly demonstrated that the\nseemingly random movement patterns in the time series of a stock price can be\npredicted with a high level of accuracy. Design of such predictive models\nrequires choice of appropriate variables, right transformation methods of the\nvariables, and tuning of the parameters of the models. In this work, we present\na very robust and accurate framework of stock price prediction that consists of\nan agglomeration of statistical, machine learning and deep learning models. We\nuse the daily stock price data, collected at five minutes interval of time, of\na very well known company that is listed in the National Stock Exchange (NSE)\nof India. The granular data is aggregated into three slots in a day, and the\naggregated data is used for building and training the forecasting models. We\ncontend that the agglomerative approach of model building that uses a\ncombination of statistical, machine learning, and deep learning approaches, can\nvery effectively learn from the volatile and random movement patterns in a\nstock price data. We build eight classification and eight regression models\nbased on statistical and machine learning approaches. In addition to these\nmodels, a deep learning regression model using a long-and-short-term memory\n(LSTM) network is also built. Extensive results have been presented on the\nperformance of these models, and the results are critically analyzed.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 19:41:22 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 14:46:58 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Mehtab", "Sidra", ""], ["Sen", "Jaydip", ""]]}, {"id": "2004.11953", "submitter": "Johannes Bleher", "authors": "Johannes Bleher, Michael Bleher and Thomas Dimpfl", "title": "From orders to prices: A stochastic description of the limit order book\n  to forecast intraday returns", "comments": "82 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR econ.EM q-fin.MF q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a microscopic model to describe the dynamics of the fundamental\nevents in the limit order book (LOB): order arrivals and cancellations. It is\nbased on an operator algebra for individual orders and describes their effect\non the LOB. The model inputs are arrival and cancellation rate distributions\nthat emerge from individual behavior of traders, and we show how prices and\nliquidity arise from the LOB dynamics. In a simulation study we illustrate how\nthe model works and highlight its sensitivity with respect to assumptions\nregarding the collective behavior of market participants. Empirically, we test\nthe model on a LOB snapshot of XETRA, estimate several linearized model\nspecifications, and conduct in- and out-of-sample forecasts.The in-sample\nresults based on contemporaneous information suggest that our model describes\nreturns very well, resulting in an adjusted $R^2$ of roughly 80%. In the more\nrealistic setting where only past information enters the model, we observe an\nadjusted $R^2$ around 15%. The direction of the next return can be predicted\n(out-of-sample) with an accuracy above 75% for time horizons below 10 minutes.\nOn average, we obtain an RMSPE that is 10 times lower than values documented in\nthe literature.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 19:28:54 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 22:33:22 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Bleher", "Johannes", ""], ["Bleher", "Michael", ""], ["Dimpfl", "Thomas", ""]]}, {"id": "2004.12011", "submitter": "Sebastian Jaimungal", "authors": "\\'Alvaro Cartea, Sebastian Jaimungal, Tianyi Jia", "title": "Trading Foreign Exchange Triplets", "comments": "35 pages, 14 figures, 1 table", "journal-ref": "Forthcoming, SIAM J. Financial Mathematics, 2020", "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.MF q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop the optimal trading strategy for a foreign exchange (FX) broker\nwho must liquidate a large position in an illiquid currency pair. To maximize\nrevenues, the broker considers trading in a currency triplet which consists of\nthe illiquid pair and two other liquid currency pairs. The liquid pairs in the\ntriplet are chosen so that one of the pairs is redundant. The broker is\nrisk-neutral and accounts for model ambiguity in the FX rates to make her\nstrategy robust to model misspecification. When the broker is ambiguity neutral\n(averse) the trading strategy in each pair is independent (dependent) of the\ninventory in the other two pairs in the triplet. We employ simulations to\nillustrate how the robust strategies perform. For a range of ambiguity aversion\nparameters, we find the mean Profit and Loss (P&L) of the strategy increases\nand the standard deviation of the P&L decreases as ambiguity aversion\nincreases.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 22:35:45 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Cartea", "\u00c1lvaro", ""], ["Jaimungal", "Sebastian", ""], ["Jia", "Tianyi", ""]]}, {"id": "2004.12336", "submitter": "Anton Josef Heckens", "authors": "Anton J. Heckens, Sebastian M. Krause, Thomas Guhr", "title": "Uncovering the Dynamics of Correlation Structures Relative to the\n  Collective Market Motion", "comments": "30 pages, 17 figures", "journal-ref": "J. Stat. Mech. (2020) 103402", "doi": "10.1088/1742-5468/abb6e2", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The measured correlations of financial time series in subsequent epochs\nchange considerably as a function of time. When studying the whole correlation\nmatrices, quasi-stationary patterns, referred to as market states, are seen by\napplying clustering methods. They emerge, disappear or reemerge, but they are\ndominated by the collective motion of all stocks. In the jargon, one speaks of\nthe market motion, it is always associated with the largest eigenvalue of the\ncorrelation matrices. Thus the question arises, if one can extract more refined\ninformation on the system by subtracting the dominating market motion in a\nproper way. To this end we introduce a new approach by clustering reduced-rank\ncorrelation matrices which are obtained by subtracting the dyadic matrix\nbelonging to the largest eigenvalue from the standard correlation matrices. We\nanalyze daily data of 262 companies of the S&P 500 index over a period of\nalmost 15 years from 2002 to 2016. The resulting dynamics is remarkably\ndifferent, and the corresponding market states are quasi-stationary over a long\nperiod of time. Our approach adds to the attempts to separate endogenous from\nexogenous effects.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 09:53:03 GMT"}, {"version": "v2", "created": "Mon, 7 Sep 2020 12:49:33 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Heckens", "Anton J.", ""], ["Krause", "Sebastian M.", ""], ["Guhr", "Thomas", ""]]}, {"id": "2004.12400", "submitter": "Fabrizio Cipollini", "authors": "Fabrizio Cipollini, Giampiero M. Gallo, Alessandro Palandri", "title": "A dynamic conditional approach to portfolio weights forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build the time series of optimal realized portfolio weights from\nhigh-frequency data and we suggest a novel Dynamic Conditional Weights (DCW)\nmodel for their dynamics. DCW is benchmarked against popular model-based and\nmodel-free specifications in terms of weights forecasts and portfolio\nallocations. Next to portfolio variance, certainty equivalent and turnover, we\nintroduce the break-even transaction costs as an additional measure that\nidentifies the range of transaction costs for which one allocation is preferred\nto another. By comparing minimum-variance portfolios built on the components of\nthe Dow Jones 30 Index, the proposed DCW overall attains the best allocations\nwith respect to the measures considered, for any degree of risk-aversion,\ntransaction costs and exposure.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 14:53:30 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Cipollini", "Fabrizio", ""], ["Gallo", "Giampiero M.", ""], ["Palandri", "Alessandro", ""]]}, {"id": "2004.13708", "submitter": "Victor Olkhov", "authors": "Victor Olkhov", "title": "Classical Option Pricing and Some Steps Further", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the asset price p as relations C=pV between the value C\nand the volume V of the executed transactions and studies the consequences of\nthis definition for the option pricing equations. We show that the classical\nBSM model implicitly assumes that value C and volume V of transactions follow\nidentical Brownian processes. Violation of this identity leads to 2-dimensional\nBSM-like equation with two constant volatilities. We show that agents\nexpectations those approve execution of transactions can further increase the\ndimension of the BSM model. We study the case when agents expectations may\ndepend on the option price data and show that such assumption can lead to the\nnonlinear BSM-like equations. We reconsider the Heston stochastic volatility\nmodel for the price determined by the value and the volume and derive\n3-dimensional BSM-like model with stochastic value volatility and constant\nvolume volatility. Variety of the BSM-like equations states the problem of\nreasonable balance between the accuracy and the complexity of the option\npricing equations.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 19:16:45 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 14:43:10 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Olkhov", "Victor", ""]]}, {"id": "2004.14736", "submitter": "Anna Carbone", "authors": "Pietro Murialdo, Linda Ponta, Anna Carbone", "title": "Long-Range Dependence in Financial Markets: a Moving Average Cluster\n  Entropy Approach", "comments": null, "journal-ref": null, "doi": "10.3390/e22060634", "report-no": null, "categories": "q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A perspective is taken on the intangible complexity of economic and social\nsystems by investigating the underlying dynamical processes that produce, store\nand transmit information in financial time series in terms of the\n\\textit{moving average cluster entropy}. An extensive analysis has evidenced\nmarket and horizon dependence of the \\textit{moving average cluster entropy} in\nreal world financial assets. The origin of the behavior is scrutinized by\napplying the \\textit{moving average cluster entropy} approach to long-range\ncorrelated stochastic processes as the Autoregressive Fractionally Integrated\nMoving Average (ARFIMA) and Fractional Brownian motion (FBM). To that end, an\nextensive set of series is generated with a broad range of values of the Hurst\nexponent $H$ and of the autoregressive, differencing and moving average\nparameters $p,d,q$. A systematic relation between \\textit{moving average\ncluster entropy}, \\textit{Market Dynamic Index} and long-range correlation\nparameters $H$, $d$ is observed. This study shows that the characteristic\nbehaviour exhibited by the horizon dependence of the cluster entropy is related\nto long-range positive correlation in financial markets. Specifically, long\nrange positively correlated ARFIMA processes with differencing parameter $\nd\\simeq 0.05$, $d\\simeq 0.15$ and $ d\\simeq 0.25$ are consistent with\n\\textit{moving average cluster entropy} results obtained in time series of\nDJIA, S\\&P500 and NASDAQ.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 12:54:25 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Murialdo", "Pietro", ""], ["Ponta", "Linda", ""], ["Carbone", "Anna", ""]]}]