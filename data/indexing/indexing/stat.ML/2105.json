[{"id": "2105.00026", "submitter": "Cl\\'ement Chadebec", "authors": "Cl\\'ement Chadebec, Elina Thibeau-Sutre, Ninon Burgos and St\\'ephanie\n  Allassonni\\`ere", "title": "Data Augmentation in High Dimensional Low Sample Size Setting Using a\n  Geometry-Based Variational Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new method to perform data augmentation in a\nreliable way in the High Dimensional Low Sample Size (HDLSS) setting using a\ngeometry-based variational autoencoder. Our approach combines a proper latent\nspace modeling of the VAE seen as a Riemannian manifold with a new generation\nscheme which produces more meaningful samples especially in the context of\nsmall data sets. The proposed method is tested through a wide experimental\nstudy where its robustness to data sets, classifiers and training samples size\nis stressed. It is also validated on a medical imaging classification task on\nthe challenging ADNI database where a small number of 3D brain MRIs are\nconsidered and augmented using the proposed VAE framework. In each case, the\nproposed method allows for a significant and reliable gain in the\nclassification metrics. For instance, balanced accuracy jumps from 66.3% to\n74.3% for a state-of-the-art CNN classifier trained with 50 MRIs of cognitively\nnormal (CN) and 50 Alzheimer disease (AD) patients and from 77.7% to 86.3% when\ntrained with 243 CN and 210 AD while improving greatly sensitivity and\nspecificity metrics.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 18:10:33 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Chadebec", "Cl\u00e9ment", ""], ["Thibeau-Sutre", "Elina", ""], ["Burgos", "Ninon", ""], ["Allassonni\u00e8re", "St\u00e9phanie", ""]]}, {"id": "2105.00191", "submitter": "Ozan \\\"Ozdenizci", "authors": "Ozan Ozdenizci, Deniz Erdogmus", "title": "Stochastic Mutual Information Gradient Estimation for Dimensionality\n  Reduction Networks", "comments": "Accepted for publication at Elsevier - Information Sciences", "journal-ref": null, "doi": "10.1016/j.ins.2021.04.066", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Feature ranking and selection is a widely used approach in various\napplications of supervised dimensionality reduction in discriminative machine\nlearning. Nevertheless there exists significant evidence on feature ranking and\nselection algorithms based on any criterion leading to potentially sub-optimal\nsolutions for class separability. In that regard, we introduce emerging\ninformation theoretic feature transformation protocols as an end-to-end neural\nnetwork training approach. We present a dimensionality reduction network\n(MMINet) training procedure based on the stochastic estimate of the mutual\ninformation gradient. The network projects high-dimensional features onto an\noutput feature space where lower dimensional representations of features carry\nmaximum mutual information with their associated class labels. Furthermore, we\nformulate the training objective to be estimated non-parametrically with no\ndistributional assumptions. We experimentally evaluate our method with\napplications to high-dimensional biological data sets, and relate it to\nconventional feature selection algorithms to form a special case of our\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 08:20:04 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ozdenizci", "Ozan", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "2105.00211", "submitter": "Emmanuel Ramasso", "authors": "Pablo Juesas, Emmanuel Ramasso, S\\'ebastien Drujont, Vincent Placet", "title": "Autoregressive Hidden Markov Models with partial knowledge on latent\n  space applied to aero-engines prognostics", "comments": null, "journal-ref": "European Conference of the PHM Society 2016, selected for extended\n  version in IJPHM", "doi": "10.36001/phme.2016.v3i1.1642", "report-no": "hal-02131233", "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  [This paper was initially published in PHME conference in 2016, selected for\nfurther publication in International Journal of Prognostics and Health\nManagement.]\n  This paper describes an Autoregressive Partially-hidden Markov model (ARPHMM)\nfor fault detection and prognostics of equipments based on sensors' data. It is\na particular dynamic Bayesian network that allows to represent the dynamics of\na system by means of a Hidden Markov Model (HMM) and an autoregressive (AR)\nprocess. The Markov chain assumes that the system is switching back and forth\nbetween internal states while the AR process ensures a temporal coherence on\nsensor measurements. A sound learning procedure of standard ARHMM based on\nmaximum likelihood allows to iteratively estimate all parameters\nsimultaneously. This paper suggests a modification of the learning procedure\nconsidering that one may have prior knowledge about the structure which becomes\npartially hidden. The integration of the prior is based on the Theory of\nWeighted Distributions which is compatible with the Expectation-Maximization\nalgorithm in the sense that the convergence properties are still satisfied. We\nshow how to apply this model to estimate the remaining useful life based on\nhealth indicators. The autoregressive parameters can indeed be used for\nprediction while the latent structure can be used to get information about the\ndegradation level. The interest of the proposed method for prognostics and\nhealth assessment is demonstrated on CMAPSS datasets.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 10:23:22 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Juesas", "Pablo", ""], ["Ramasso", "Emmanuel", ""], ["Drujont", "S\u00e9bastien", ""], ["Placet", "Vincent", ""]]}, {"id": "2105.00233", "submitter": "Koki Okajima", "authors": "Koki Okajima and Yoshiyuki Kabashima", "title": "Matrix completion based on Gaussian belief propagation", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a message-passing algorithm for noisy matrix completion problems\nbased on matrix factorization. The algorithm is derived by approximating\nmessage distributions of belief propagation with Gaussian distributions that\nshare the same first and second moments. We also derive a memory-friendly\nversion of the proposed algorithm by applying a perturbation treatment commonly\nused in the literature of approximate message passing. In addition, a damping\ntechnique, which is demonstrated to be crucial for optimal performance, is\nintroduced without computational strain, and the relationship to the\nmessage-passing version of alternating least squares, a method reported to be\noptimal in certain settings, is discussed. Experiments on synthetic datasets\nshow that while the proposed algorithm quantitatively exhibits almost the same\nperformance under settings where the earlier algorithm is optimal, it is\nadvantageous when the observed datasets are corrupted by non-Gaussian noise.\nExperiments on real-world datasets also emphasize the performance differences\nbetween the two algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 12:16:49 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Okajima", "Koki", ""], ["Kabashima", "Yoshiyuki", ""]]}, {"id": "2105.00244", "submitter": "Aleksandr Aravkin", "authors": "Metin Vural, Aleksandr Y. Aravkin, and S{\\l}awomir Stan'czak", "title": "l1-Norm Minimization with Regula Falsi Type Root Finding Methods", "comments": "l1 -norm minimization, nonconvex models, Regula-Falsi, root-finding", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sparse level-set formulations allow practitioners to find the minimum 1-norm\nsolution subject to likelihood constraints. Prior art requires this constraint\nto be convex. In this letter, we develop an efficient approach for nonconvex\nlikelihoods, using Regula Falsi root-finding techniques to solve the level-set\nformulation. Regula Falsi methods are simple, derivative-free, and efficient,\nand the approach provably extends level-set methods to the broader class of\nnonconvex inverse problems. Practical performance is illustrated using\nl1-regularized Student's t inversion, which is a nonconvex approach used to\ndevelop outlier-robust formulations.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 13:24:38 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Vural", "Metin", ""], ["Aravkin", "Aleksandr Y.", ""], ["Stan'czak", "S\u0142awomir", ""]]}, {"id": "2105.00262", "submitter": "Hanjing Zhu", "authors": "Jiaming Xu and Hanjing Zhu", "title": "One-pass Stochastic Gradient Descent in Overparametrized Two-layer\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent surge of interest in understanding the convergence of\ngradient descent (GD) and stochastic gradient descent (SGD) in\noverparameterized neural networks. Most previous works assume that the training\ndata is provided a priori in a batch, while less attention has been paid to the\nimportant setting where the training data arrives in a stream. In this paper,\nwe study the streaming data setup and show that with overparamterization and\nrandom initialization, the prediction error of two-layer neural networks under\none-pass SGD converges in expectation. The convergence rate depends on the\neigen-decomposition of the integral operator associated with the so-called\nneural tangent kernel (NTK). A key step of our analysis is to show a random\nkernel function converges to the NTK with high probability using the VC\ndimension and McDiarmid's inequality.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 14:34:03 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Xu", "Jiaming", ""], ["Zhu", "Hanjing", ""]]}, {"id": "2105.00277", "submitter": "Zhang Chen", "authors": "Chen Zhang, Siwei Wang, Jiyuan Liu, Sihang Zhou, Pei Zhang, Xinwang\n  Liu, En Zhu, Changwang Zhang", "title": "Multi-view Clustering via Deep Matrix Factorization and Partition\n  Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-view clustering (MVC) has been extensively studied to collect multiple\nsource information in recent years. One typical type of MVC methods is based on\nmatrix factorization to effectively perform dimension reduction and clustering.\nHowever, the existing approaches can be further improved with following\nconsiderations: i) The current one-layer matrix factorization framework cannot\nfully exploit the useful data representations. ii) Most algorithms only focus\non the shared information while ignore the view-specific structure leading to\nsuboptimal solutions. iii) The partition level information has not been\nutilized in existing work. To solve the above issues, we propose a novel\nmulti-view clustering algorithm via deep matrix decomposition and partition\nalignment. To be specific, the partition representations of each view are\nobtained through deep matrix decomposition, and then are jointly utilized with\nthe optimal partition representation for fusing multi-view information.\nFinally, an alternating optimization algorithm is developed to solve the\noptimization problem with proven convergence. The comprehensive experimental\nresults conducted on six benchmark multi-view datasets clearly demonstrates the\neffectiveness of the proposed algorithm against the SOTA methods.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 15:06:57 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 12:26:50 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhang", "Chen", ""], ["Wang", "Siwei", ""], ["Liu", "Jiyuan", ""], ["Zhou", "Sihang", ""], ["Zhang", "Pei", ""], ["Liu", "Xinwang", ""], ["Zhu", "En", ""], ["Zhang", "Changwang", ""]]}, {"id": "2105.00303", "submitter": "Saurabh Garg", "authors": "Saurabh Garg, Sivaraman Balakrishnan, J. Zico Kolter, Zachary C.\n  Lipton", "title": "RATT: Leveraging Unlabeled Data to Guarantee Generalization", "comments": "Pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To assess generalization, machine learning scientists typically either (i)\nbound the generalization gap and then (after training) plug in the empirical\nrisk to obtain a bound on the true risk; or (ii) validate empirically on\nholdout data. However, (i) typically yields vacuous guarantees for\noverparameterized models. Furthermore, (ii) shrinks the training set and its\nguarantee erodes with each re-use of the holdout set. In this paper, we\nintroduce a method that leverages unlabeled data to produce generalization\nbounds. After augmenting our (labeled) training set with randomly labeled fresh\nexamples, we train in the standard fashion. Whenever classifiers achieve low\nerror on clean data and high error on noisy data, our bound provides a tight\nupper bound on the true risk. We prove that our bound is valid for 0-1\nempirical risk minimization and with linear classifiers trained by gradient\ndescent. Our approach is especially useful in conjunction with deep learning\ndue to the early learning phenomenon whereby networks fit true labels before\nnoisy labels but requires one intuitive assumption. Empirically, on canonical\ncomputer vision and NLP tasks, our bound provides non-vacuous generalization\nguarantees that track actual performance closely. This work provides\npractitioners with an option for certifying the generalization of deep nets\neven when unseen labeled data is unavailable and provides theoretical insights\ninto the relationship between random label noise and generalization.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 17:05:29 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Garg", "Saurabh", ""], ["Balakrishnan", "Sivaraman", ""], ["Kolter", "J. Zico", ""], ["Lipton", "Zachary C.", ""]]}, {"id": "2105.00351", "submitter": "Moo K. Chung", "authors": "Moo K. Chung, Hernando Ombao", "title": "Lattice Paths for Persistent Diagrams with Application to COVID-19 Virus\n  Spike Proteins", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.BM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Topological data analysis, including persistent homology, has undergone\nsignificant development in recent years. However, one outstanding challenge is\nto build a coherent statistical inference procedure on persistent diagrams. The\npaired dependent data structure, which are the births and deaths in persistent\ndiagrams, adds complexity to statistical inference. In this paper, we present a\nnew lattice path representation for persistent diagrams. A new exact\nstatistical inference procedure is developed for lattice paths via\ncombinatorial enumerations. The proposed lattice path method is applied to\nstudy the topological characterization of the protein structures of the\nCOVID-19 virus. We demonstrate that there are topological changes during the\nconformational change of spike proteins, a necessary step in infecting host\ncells.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 22:12:57 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 07:45:49 GMT"}, {"version": "v3", "created": "Sat, 19 Jun 2021 12:34:39 GMT"}, {"version": "v4", "created": "Sat, 26 Jun 2021 20:21:19 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Chung", "Moo K.", ""], ["Ombao", "Hernando", ""]]}, {"id": "2105.00393", "submitter": "Huiming Zhang", "authors": "Chang Cui, Jinzhu Jia, Yijun Xiao, Huiming Zhang", "title": "Directional FDR Control for Sub-Gaussian Sparse GLMs", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional sparse generalized linear models (GLMs) have emerged in the\nsetting that the number of samples and the dimension of variables are large,\nand even the dimension of variables grows faster than the number of samples.\nFalse discovery rate (FDR) control aims to identify some small number of\nstatistically significantly nonzero results after getting the sparse penalized\nestimation of GLMs. Using the CLIME method for precision matrix estimations, we\nconstruct the debiased-Lasso estimator and prove the asymptotical normality by\nminimax-rate oracle inequalities for sparse GLMs. In practice, it is often\nneeded to accurately judge each regression coefficient's positivity and\nnegativity, which determines whether the predictor variable is positively or\nnegatively related to the response variable conditionally on the rest\nvariables. Using the debiased estimator, we establish multiple testing\nprocedures. Under mild conditions, we show that the proposed debiased\nstatistics can asymptotically control the directional (sign) FDR and\ndirectional false discovery variables at a pre-specified significance level.\nMoreover, it can be shown that our multiple testing procedure can approximately\nachieve a statistical power of 1. We also extend our methods to the two-sample\nproblems and propose the two-sample test statistics. Under suitable conditions,\nwe can asymptotically achieve directional FDR control and directional FDV\ncontrol at the specified significance level for two-sample problems. Some\nnumerical simulations have successfully verified the FDR control effects of our\nproposed testing procedures, which sometimes outperforms the classical knockoff\nmethod.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 05:34:32 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Cui", "Chang", ""], ["Jia", "Jinzhu", ""], ["Xiao", "Yijun", ""], ["Zhang", "Huiming", ""]]}, {"id": "2105.00400", "submitter": "Remy Kusters", "authors": "Gert-Jan Both, Georges Tod, Remy Kusters", "title": "Model discovery in the sparse sampling regime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To improve the physical understanding and the predictions of complex dynamic\nsystems, such as ocean dynamics and weather predictions, it is of paramount\ninterest to identify interpretable models from coarsely and off-grid sampled\nobservations. In this work, we investigate how deep learning can improve model\ndiscovery of partial differential equations when the spacing between sensors is\nlarge and the samples are not placed on a grid. We show how leveraging physics\ninformed neural network interpolation and automatic differentiation, allow to\nbetter fit the data and its spatiotemporal derivatives, compared to more\nclassic spline interpolation and numerical differentiation techniques. As a\nresult, deep learning-based model discovery allows to recover the underlying\nequations, even when sensors are placed further apart than the data's\ncharacteristic length scale and in the presence of high noise levels. We\nillustrate our claims on both synthetic and experimental data sets where\ncombinations of physical processes such as (non)-linear advection, reaction,\nand diffusion are correctly identified.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 06:27:05 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Both", "Gert-Jan", ""], ["Tod", "Georges", ""], ["Kusters", "Remy", ""]]}, {"id": "2105.00455", "submitter": "Eric Strobl", "authors": "Eric V. Strobl, Thomas A. Lasko", "title": "Synthesized Difference in Differences", "comments": "Accepted to ACM BCB 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider estimating the conditional average treatment effect for everyone\nby eliminating confounding and selection bias. Unfortunately, randomized\nclinical trials (RCTs) eliminate confounding but impose strict exclusion\ncriteria that prevent sampling of the entire clinical population. Observational\ndatasets are more inclusive but suffer from confounding. We therefore analyze\nRCT and observational data simultaneously in order to extract the strengths of\neach. Our solution builds upon Difference in Differences (DD), an algorithm\nthat eliminates confounding from observational data by comparing outcomes\nbefore and after treatment administration. DD requires a parallel slopes\nassumption that may not apply in practice when confounding shifts across time.\nWe instead propose Synthesized Difference in Differences (SDD) that infers the\ncorrect (possibly non-parallel) slopes by linearly adjusting a conditional\nversion of DD using additional RCT data. The algorithm achieves state of the\nart performance across multiple synthetic and real datasets even when the RCT\nexcludes the majority of patients.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 12:19:16 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 02:19:44 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Strobl", "Eric V.", ""], ["Lasko", "Thomas A.", ""]]}, {"id": "2105.00470", "submitter": "Wenxiao Wang", "authors": "Tianyu Hua, Wenxiao Wang, Zihui Xue, Yue Wang, Sucheng Ren, Hang Zhao", "title": "On Feature Decorrelation in Self-Supervised Learning", "comments": "The first two authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In self-supervised representation learning, a common idea behind most of the\nstate-of-the-art approaches is to enforce the robustness of the representations\nto predefined augmentations. A potential issue of this idea is the existence of\ncompletely collapsed solutions (i.e., constant features), which are typically\navoided implicitly by carefully chosen implementation details. In this work, we\nstudy a relatively concise framework containing the most common components from\nrecent approaches. We verify the existence of complete collapse and discover\nanother reachable collapse pattern that is usually overlooked, namely\ndimensional collapse. We connect dimensional collapse with strong correlations\nbetween axes and consider such connection as a strong motivation for feature\ndecorrelation (i.e., standardizing the covariance matrix). The capability of\ncorrelation as an unsupervised metric and the gains from feature decorrelation\nare verified empirically to highlight the importance and the potential of this\ninsight.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 13:28:18 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Hua", "Tianyu", ""], ["Wang", "Wenxiao", ""], ["Xue", "Zihui", ""], ["Wang", "Yue", ""], ["Ren", "Sucheng", ""], ["Zhao", "Hang", ""]]}, {"id": "2105.00488", "submitter": "Polina Suter", "authors": "Polina Suter and Jack Kuipers and Giusi Moffa and Niko Beerenwinkel", "title": "Bayesian structure learning and sampling of Bayesian networks with the R\n  package BiDAG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The R package BiDAG implements Markov chain Monte Carlo (MCMC) methods for\nstructure learning and sampling of Bayesian networks. The package includes\ntools to search for a maximum a posteriori (MAP) graph and to sample graphs\nfrom the posterior distribution given the data. A new hybrid approach to\nstructure learning enables inference in large graphs. In the first step, we\ndefine a reduced search space by means of the PC algorithm or based on prior\nknowledge. In the second step, an iterative order MCMC scheme proceeds to\noptimize within the restricted search space and estimate the MAP graph.\nSampling from the posterior distribution is implemented using either order or\npartition MCMC. The models and algorithms can handle both discrete and\ncontinuous data. The BiDAG package also provides an implementation of MCMC\nschemes for structure learning and sampling of dynamic Bayesian networks.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 14:42:32 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Suter", "Polina", ""], ["Kuipers", "Jack", ""], ["Moffa", "Giusi", ""], ["Beerenwinkel", "Niko", ""]]}, {"id": "2105.00507", "submitter": "Dmitry Yarotsky", "authors": "Maksim Velikanov and Dmitry Yarotsky", "title": "Universal scaling laws in the gradient descent training of neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current theoretical results on optimization trajectories of neural networks\ntrained by gradient descent typically have the form of rigorous but potentially\nloose bounds on the loss values. In the present work we take a different\napproach and show that the learning trajectory can be characterized by an\nexplicit asymptotic at large training times. Specifically, the leading term in\nthe asymptotic expansion of the loss behaves as a power law $L(t) \\sim\nt^{-\\xi}$ with exponent $\\xi$ expressed only through the data dimension, the\nsmoothness of the activation function, and the class of function being\napproximated. Our results are based on spectral analysis of the integral\noperator representing the linearized evolution of a large network trained on\nthe expected loss. Importantly, the techniques we employ do not require\nspecific form of a data distribution, for example Gaussian, thus making our\nfindings sufficiently universal.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 16:46:38 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Velikanov", "Maksim", ""], ["Yarotsky", "Dmitry", ""]]}, {"id": "2105.00545", "submitter": "Farzad Pourbabaee", "authors": "Farzad Pourbabaee", "title": "High Dimensional Decision Making, Upper and Lower Bounds", "comments": null, "journal-ref": "Economics Letters, 2021, Elsevier", "doi": null, "report-no": null, "categories": "econ.TH stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A decision maker's utility depends on her action $a\\in A \\subset\n\\mathbb{R}^d$ and the payoff relevant state of the world $\\theta\\in \\Theta$.\nOne can define the value of acquiring new information as the difference between\nthe maximum expected utility pre- and post information acquisition. In this\npaper, I find asymptotic results on the expected value of information as $d \\to\n\\infty$, by using tools from the theory of (sub)-Guassian processes and generic\nchaining.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 20:12:05 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Pourbabaee", "Farzad", ""]]}, {"id": "2105.00581", "submitter": "Guanhua Chen", "authors": "Rui Chen, Jared D. Huling, Guanhua Chen, Menggang Yu", "title": "Robust Sample Weighting to Facilitate Individualized Treatment Rule\n  Learning for a Target Population", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning individualized treatment rules (ITRs) is an important topic in\nprecision medicine. Current literature mainly focuses on deriving ITRs from a\nsingle source population. We consider the observational data setting when the\nsource population differs from a target population of interest. We assume\nsubject covariates are available from both populations, but treatment and\noutcome data are only available from the source population. Although adjusting\nfor differences between source and target populations can potentially lead to\nan improved ITR for the target population, it can substantially increase the\nvariability in ITR estimation. To address this dilemma, we develop a weighting\nframework that aims to tailor an ITR for a given target population and protect\nagainst high variability due to superfluous covariate shift adjustments. Our\nmethod seeks covariate balance over a nonparametric function class\ncharacterized by a reproducing kernel Hilbert space and can improve many ITR\nlearning methods that rely on weights. We show that the proposed method\nencompasses importance weights and the so-called overlap weights as two extreme\ncases, allowing for a better bias-variance trade-off in between. Numerical\nexamples demonstrate that the use of our weighting method can greatly improve\nITR estimation for the target population compared with other weighting methods.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 00:05:18 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Chen", "Rui", ""], ["Huling", "Jared D.", ""], ["Chen", "Guanhua", ""], ["Yu", "Menggang", ""]]}, {"id": "2105.00619", "submitter": "Salman Ahmed", "authors": "Salman Ahmed, Hammad Naveed", "title": "OpTorch: Optimized deep learning architectures for resource limited\n  environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning algorithms have made many breakthroughs and have various\napplications in real life. Computational resources become a bottleneck as the\ndata and complexity of the deep learning pipeline increases. In this paper, we\npropose optimized deep learning pipelines in multiple aspects of training\nincluding time and memory. OpTorch is a machine learning library designed to\novercome weaknesses in existing implementations of neural network training.\nOpTorch provides features to train complex neural networks with limited\ncomputational resources. OpTorch achieved the same accuracy as existing\nlibraries on Cifar-10 and Cifar-100 datasets while reducing memory usage to\napproximately 50%. We also explore the effect of weights on total memory usage\nin deep learning pipelines. In our experiments, parallel encoding-decoding\nalong with sequential checkpoints results in much improved memory and time\nusage while keeping the accuracy similar to existing pipelines. OpTorch python\npackage is available at available at https://github.com/cbrl-nuces/optorch\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 03:58:57 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 09:25:55 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Ahmed", "Salman", ""], ["Naveed", "Hammad", ""]]}, {"id": "2105.00728", "submitter": "Yiming Liu", "authors": "Yiming Liu, Ying Chen, Guangming Pan, Weichung Wang, Wei-Chih Liao,\n  Yee Liang Thian, Cheng E. Chee and Constantinos P. Anastassiades", "title": "Spectral Machine Learning for Pancreatic Mass Imaging Classification", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel spectral machine learning (SML) method in screening for\npancreatic mass using CT imaging. Our algorithm is trained with approximately\n30,000 images from 250 patients (50 patients with normal pancreas and 200\npatients with abnormal pancreas findings) based on public data sources. A test\naccuracy of 94.6 percents was achieved in the out-of-sample diagnosis\nclassification based on a total of approximately 15,000 images from 113\npatients, whereby 26 out of 32 patients with normal pancreas and all 81\npatients with abnormal pancreas findings were correctly diagnosed. SML is able\nto automatically choose fundamental images (on average 5 or 9 images for each\npatient) in the diagnosis classification and achieve the above mentioned\naccuracy. The computational time is 75 seconds for diagnosing 113 patients in a\nlaptop with standard CPU running environment. Factors that influenced high\nperformance of a well-designed integration of spectral learning and machine\nlearning included: 1) use of eigenvectors corresponding to several of the\nlargest eigenvalues of sample covariance matrix (spike eigenvectors) to choose\ninput attributes in classification training, taking into account only the\nfundamental information of the raw images with less noise; 2) removal of\nirrelevant pixels based on mean-level spectral test to lower the challenges of\nmemory capacity and enhance computational efficiency while maintaining superior\nclassification accuracy; 3) adoption of state-of-the-art machine learning\nclassification, gradient boosting and random forest. Our methodology showcases\npractical utility and improved accuracy of image diagnosis in pancreatic mass\nscreening in the era of AI.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 10:17:32 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Liu", "Yiming", ""], ["Chen", "Ying", ""], ["Pan", "Guangming", ""], ["Wang", "Weichung", ""], ["Liao", "Wei-Chih", ""], ["Thian", "Yee Liang", ""], ["Chee", "Cheng E.", ""], ["Anastassiades", "Constantinos P.", ""]]}, {"id": "2105.00773", "submitter": "Michael Hughes", "authors": "Gian Marco Visani, Alexandra Hope Lee, Cuong Nguyen, David M. Kent,\n  John B. Wong, Joshua T. Cohen, and Michael C. Hughes", "title": "Approximate Bayesian Computation for an Explicit-Duration Hidden Markov\n  Model of COVID-19 Hospital Trajectories", "comments": "To appear in the Proceedings of the Machine Learning for Healthcare\n  (MLHC) conference, 2021. 20 pages, 7 figures and 1 table. 26 additional pages\n  of supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of modeling constrained hospital resources in the\nmidst of the COVID-19 pandemic in order to inform decision-makers of future\ndemand and assess the societal value of possible interventions. For broad\napplicability, we focus on the common yet challenging scenario where\npatient-level data for a region of interest are not available. Instead, given\ndaily admissions counts, we model aggregated counts of observed resource use,\nsuch as the number of patients in the general ward, in the intensive care unit,\nor on a ventilator. In order to explain how individual patient trajectories\nproduce these counts, we propose an aggregate count explicit-duration hidden\nMarkov model, nicknamed the ACED-HMM, with an interpretable, compact\nparameterization. We develop an Approximate Bayesian Computation approach that\ndraws samples from the posterior distribution over the model's transition and\nduration parameters given aggregate counts from a specific location, thus\nadapting the model to a region or individual hospital site of interest. Samples\nfrom this posterior can then be used to produce future forecasts of any counts\nof interest. Using data from the United States and the United Kingdom, we show\nour mechanistic approach provides competitive probabilistic forecasts for the\nfuture even as the dynamics of the pandemic shift. Furthermore, we show how our\nmodel provides insight about recovery probabilities or length of stay\ndistributions, and we suggest its potential to answer challenging what-if\nquestions about the societal value of possible interventions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 15:32:42 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 15:51:01 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Visani", "Gian Marco", ""], ["Lee", "Alexandra Hope", ""], ["Nguyen", "Cuong", ""], ["Kent", "David M.", ""], ["Wong", "John B.", ""], ["Cohen", "Joshua T.", ""], ["Hughes", "Michael C.", ""]]}, {"id": "2105.00887", "submitter": "Nawaf Bou-Rabee", "authors": "Nawaf Bou-Rabee and Andreas Eberle", "title": "Mixing Time Guarantees for Unadjusted Hamiltonian Monte Carlo", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.NA math.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide quantitative upper bounds on the total variation mixing time of\nthe Markov chain corresponding to the unadjusted Hamiltonian Monte Carlo (uHMC)\nalgorithm. For two general classes of models and fixed time discretization step\nsize $h$, the mixing time is shown to depend only logarithmically on the\ndimension. Moreover, we provide quantitative upper bounds on the total\nvariation distance between the invariant measure of the uHMC chain and the true\ntarget measure. As a consequence, we show that an $\\varepsilon$-accurate\napproximation of the target distribution $\\mu$ in total variation distance can\nbe achieved by uHMC for a broad class of models with\n$O\\left(d^{3/4}\\varepsilon^{-1/2}\\log (d/\\varepsilon )\\right)$ gradient\nevaluations, and for mean field models with weak interactions with\n$O\\left(d^{1/2}\\varepsilon^{-1/2}\\log (d/\\varepsilon )\\right)$ gradient\nevaluations. The proofs are based on the construction of successful couplings\nfor uHMC that realize the upper bounds.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 14:13:47 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Bou-Rabee", "Nawaf", ""], ["Eberle", "Andreas", ""]]}, {"id": "2105.00894", "submitter": "George De Ath", "authors": "George De Ath, Richard Everson and Jonathan Fieldsend", "title": "How Bayesian Should Bayesian Optimisation Be?", "comments": "To appear in the Proceedings of Genetic and Evolutionary Computation\n  Conference Companion (GECCO 2021), ACM. 10 pages (main paper) + 26 pages\n  (supplement)", "journal-ref": null, "doi": "10.1145/3449726.3463164", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimisation (BO) uses probabilistic surrogate models - usually\nGaussian processes (GPs) - for the optimisation of expensive black-box\nfunctions. At each BO iteration, the GP hyperparameters are fit to\npreviously-evaluated data by maximising the marginal likelihood. However, this\nfails to account for uncertainty in the hyperparameters themselves, leading to\noverconfident model predictions. This uncertainty can be accounted for by\ntaking the Bayesian approach of marginalising out the model hyperparameters.\n  We investigate whether a fully-Bayesian treatment of the Gaussian process\nhyperparameters in BO (FBBO) leads to improved optimisation performance. Since\nan analytic approach is intractable, we compare FBBO using three approximate\ninference schemes to the maximum likelihood approach, using the Expected\nImprovement (EI) and Upper Confidence Bound (UCB) acquisition functions paired\nwith ARD and isotropic Matern kernels, across 15 well-known benchmark problems\nfor 4 observational noise settings. FBBO using EI with an ARD kernel leads to\nthe best performance in the noise-free setting, with much less difference\nbetween combinations of BO components when the noise is increased. FBBO leads\nto over-exploration with UCB, but is not detrimental with EI. Therefore, we\nrecommend that FBBO using EI with an ARD kernel as the default choice for BO.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 14:28:11 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["De Ath", "George", ""], ["Everson", "Richard", ""], ["Fieldsend", "Jonathan", ""]]}, {"id": "2105.00987", "submitter": "Patrick Rubin-Delanchy Dr", "authors": "Alexander Modell and Patrick Rubin-Delanchy", "title": "Spectral clustering under degree heterogeneity: a case for the random\n  walk Laplacian", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows that graph spectral embedding using the random walk\nLaplacian produces vector representations which are completely corrected for\nnode degree. Under a generalised random dot product graph, the embedding\nprovides uniformly consistent estimates of degree-corrected latent positions,\nwith asymptotically Gaussian error. In the special case of a degree-corrected\nstochastic block model, the embedding concentrates about K distinct points,\nrepresenting communities. These can be recovered perfectly, asymptotically,\nthrough a subsequent clustering step, without spherical projection, as commonly\nrequired by algorithms based on the adjacency or normalised, symmetric\nLaplacian matrices. While the estimand does not depend on degree, the\nasymptotic variance of its estimate does -- higher degree nodes are embedded\nmore accurately than lower degree nodes. Our central limit theorem therefore\nsuggests fitting a weighted Gaussian mixture model as the subsequent clustering\nstep, for which we provide an expectation-maximisation algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 16:36:27 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 07:20:12 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Modell", "Alexander", ""], ["Rubin-Delanchy", "Patrick", ""]]}, {"id": "2105.00997", "submitter": "Daphna Keidar", "authors": "Cristina Guzman, Daphna Keidar, Tristan Meynier, Andreas Opedal,\n  Niklas Stoehr", "title": "Recovering Barab\\'asi-Albert Parameters of Graphs through\n  Disentanglement", "comments": "Accepted at the 9th International Conference on Learning\n  Representations (ICLR 2021), Workshop on Geometrical and Topological\n  Representation Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Classical graph modeling approaches such as Erd\\H{o}s R\\'{e}nyi (ER) random\ngraphs or Barab\\'asi-Albert (BA) graphs, here referred to as stylized models,\naim to reproduce properties of real-world graphs in an interpretable way. While\nuseful, graph generation with stylized models requires domain knowledge and\niterative trial and error simulation. Previous work by Stoehr et al. (2019)\naddresses these issues by learning the generation process from graph data,\nusing a disentanglement-focused deep autoencoding framework, more specifically,\na $\\beta$-Variational Autoencoder ($\\beta$-VAE). While they successfully\nrecover the generative parameters of ER graphs through the model's latent\nvariables, their model performs badly on sequentially generated graphs such as\nBA graphs, due to their oversimplified decoder. We focus on recovering the\ngenerative parameters of BA graphs by replacing their $\\beta$-VAE decoder with\na sequential one. We first learn the generative BA parameters in a supervised\nfashion using a Graph Neural Network (GNN) and a Random Forest Regressor, by\nminimizing the squared loss between the true generative parameters and the\nlatent variables. Next, we train a $\\beta$-VAE model, combining the GNN encoder\nfrom the first stage with an LSTM-based decoder with a customized loss.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 16:45:43 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 10:40:07 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Guzman", "Cristina", ""], ["Keidar", "Daphna", ""], ["Meynier", "Tristan", ""], ["Opedal", "Andreas", ""], ["Stoehr", "Niklas", ""]]}, {"id": "2105.01015", "submitter": "Thomas Elsken", "authors": "Julia Guerrero-Viu, Sven Hauns, Sergio Izquierdo, Guilherme Miotto,\n  Simon Schrodi, Andre Biedenkapp, Thomas Elsken, Difan Deng, Marius Lindauer,\n  Frank Hutter", "title": "Bag of Baselines for Multi-objective Joint Neural Architecture Search\n  and Hyperparameter Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural architecture search (NAS) and hyperparameter optimization (HPO) make\ndeep learning accessible to non-experts by automatically finding the\narchitecture of the deep neural network to use and tuning the hyperparameters\nof the used training pipeline. While both NAS and HPO have been studied\nextensively in recent years, NAS methods typically assume fixed hyperparameters\nand vice versa - there exists little work on joint NAS + HPO. Furthermore, NAS\nhas recently often been framed as a multi-objective optimization problem, in\norder to take, e.g., resource requirements into account. In this paper, we\npropose a set of methods that extend current approaches to jointly optimize\nneural architectures and hyperparameters with respect to multiple objectives.\nWe hope that these methods will serve as simple baselines for future research\non multi-objective joint NAS + HPO. To facilitate this, all our code is\navailable at https://github.com/automl/multi-obj-baselines.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 17:04:56 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Guerrero-Viu", "Julia", ""], ["Hauns", "Sven", ""], ["Izquierdo", "Sergio", ""], ["Miotto", "Guilherme", ""], ["Schrodi", "Simon", ""], ["Biedenkapp", "Andre", ""], ["Elsken", "Thomas", ""], ["Deng", "Difan", ""], ["Lindauer", "Marius", ""], ["Hutter", "Frank", ""]]}, {"id": "2105.01029", "submitter": "Mikhail Khodak", "authors": "Mikhail Khodak and Neil Tenenholtz and Lester Mackey and Nicol\\`o Fusi", "title": "Initialization and Regularization of Factorized Neural Layers", "comments": "ICLR 2021 Camera-Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorized layers--operations parameterized by products of two or more\nmatrices--occur in a variety of deep learning contexts, including compressed\nmodel training, certain types of knowledge distillation, and multi-head\nself-attention architectures. We study how to initialize and regularize deep\nnets containing such layers, examining two simple, understudied schemes,\nspectral initialization and Frobenius decay, for improving their performance.\nThe guiding insight is to design optimization routines for these networks that\nare as close as possible to that of their well-tuned, non-decomposed\ncounterparts; we back this intuition with an analysis of how the initialization\nand regularization schemes impact training with gradient descent, drawing on\nmodern attempts to understand the interplay of weight-decay and\nbatch-normalization. Empirically, we highlight the benefits of spectral\ninitialization and Frobenius decay across a variety of settings. In model\ncompression, we show that they enable low-rank methods to significantly\noutperform both unstructured sparsity and tensor methods on the task of\ntraining low-memory residual networks; analogs of the schemes also improve the\nperformance of tensor decomposition techniques. For knowledge distillation,\nFrobenius decay enables a simple, overcomplete baseline that yields a compact\nmodel from over-parameterized training without requiring retraining with or\npruning a teacher network. Finally, we show how both schemes applied to\nmulti-head attention lead to improved performance on both translation and\nunsupervised pre-training.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 17:28:07 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Khodak", "Mikhail", ""], ["Tenenholtz", "Neil", ""], ["Mackey", "Lester", ""], ["Fusi", "Nicol\u00f2", ""]]}, {"id": "2105.01108", "submitter": "Alex Dytso", "authors": "Luc Devroye and Alex Dytso", "title": "Consistent Density Estimation Under Discrete Mixture Models", "comments": "Reason for withdrawal: There is an issue with the proof of Theorem~1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work considers a problem of estimating a mixing probability density $f$\nin the setting of discrete mixture models. The paper consists of three parts.\n  The first part focuses on the construction of an $L_1$ consistent estimator\nof $f$. In particular, under the assumptions that the probability measure $\\mu$\nof the observation is atomic, and the map from $f$ to $\\mu$ is bijective, it is\nshown that there exists an estimator $f_n$ such that for every density $f$\n$\\lim_{n\\to \\infty} \\mathbb{E} \\left[ \\int |f_n -f | \\right]=0$.\n  The second part discusses the implementation details. Specifically, it is\nshown that the consistency for every $f$ can be attained with a computationally\nfeasible estimator.\n  The third part, as a study case, considers a Poisson mixture model. In\nparticular, it is shown that in the Poisson noise setting, the bijection\ncondition holds and, hence, estimation can be performed consistently for every\n$f$.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 18:30:02 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 12:49:46 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Devroye", "Luc", ""], ["Dytso", "Alex", ""]]}, {"id": "2105.01136", "submitter": "Chengzhuo Ni", "authors": "Chengzhuo Ni, Anru Zhang, Yaqi Duan, Mengdi Wang", "title": "Learning Good State and Action Representations via Tensor Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The transition kernel of a continuous-state-action Markov decision process\n(MDP) admits a natural tensor structure. This paper proposes a tensor-inspired\nunsupervised learning method to identify meaningful low-dimensional state and\naction representations from empirical trajectories. The method exploits the\nMDP's tensor structure by kernelization, importance sampling and\nlow-Tucker-rank approximation. This method can be further used to cluster\nstates and actions respectively and find the best discrete MDP abstraction. We\nprovide sharp statistical error bounds for tensor concentration and the\npreservation of diffusion distance after embedding.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 19:24:55 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Ni", "Chengzhuo", ""], ["Zhang", "Anru", ""], ["Duan", "Yaqi", ""], ["Wang", "Mengdi", ""]]}, {"id": "2105.01187", "submitter": "Zhengling Qi", "authors": "Zhengling Qi, Rui Miao, Xiaoke Zhang", "title": "Proximal Learning for Individualized Treatment Regimes Under Unmeasured\n  Confounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven individualized decision making has recently received increasing\nresearch interests. Most existing methods rely on the assumption of no\nunmeasured confounding, which unfortunately cannot be ensured in practice\nespecially in observational studies. Motivated by the recent proposed proximal\ncausal inference, we develop several proximal learning approaches to estimating\noptimal individualized treatment regimes (ITRs) in the presence of unmeasured\nconfounding. In particular, we establish several identification results for\ndifferent classes of ITRs, exhibiting the trade-off between the risk of making\nuntestable assumptions and the value function improvement in decision making.\nBased on these results, we propose several classification-based approaches to\nfinding a variety of restricted in-class optimal ITRs and develop their\ntheoretical properties. The appealing numerical performance of our proposed\nmethods is demonstrated via an extensive simulation study and one real data\napplication.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 21:49:49 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 02:35:00 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Qi", "Zhengling", ""], ["Miao", "Rui", ""], ["Zhang", "Xiaoke", ""]]}, {"id": "2105.01228", "submitter": "Yulong Lu", "authors": "Jianfeng Lu and Yulong Lu", "title": "A Priori Generalization Error Analysis of Two-Layer Neural Networks for\n  Solving High Dimensional Schr\\\"odinger Eigenvalue Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math-ph math.AP math.MP math.PR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper analyzes the generalization error of two-layer neural networks for\ncomputing the ground state of the Schr\\\"odinger operator on a $d$-dimensional\nhypercube. We prove that the convergence rate of the generalization error is\nindependent of the dimension $d$, under the a priori assumption that the ground\nstate lies in a spectral Barron space. We verify such assumption by proving a\nnew regularity estimate for the ground state in the spectral Barron space. The\nlater is achieved by a fixed point argument based on the Krein-Rutman theorem.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 00:37:46 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Lu", "Jianfeng", ""], ["Lu", "Yulong", ""]]}, {"id": "2105.01264", "submitter": "Jue Hou", "authors": "Jue Hou, Zijian Guo and Tianxi Cai", "title": "Surrogate Assisted Semi-supervised Inference for High Dimensional Risk\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Risk modeling with EHR data is challenging due to a lack of direct\nobservations on the disease outcome, and the high dimensionality of the\ncandidate predictors. In this paper, we develop a surrogate assisted\nsemi-supervised-learning (SAS) approach to risk modeling with high dimensional\npredictors, leveraging a large unlabeled data on candidate predictors and\nsurrogates of outcome, as well as a small labeled data with annotated outcomes.\nThe SAS procedure borrows information from surrogates along with candidate\npredictors to impute the unobserved outcomes via a sparse working imputation\nmodel with moment conditions to achieve robustness against mis-specification in\nthe imputation model and a one-step bias correction to enable interval\nestimation for the predicted risk. We demonstrate that the SAS procedure\nprovides valid inference for the predicted risk derived from a high dimensional\nworking model, even when the underlying risk prediction model is dense and the\nrisk model is mis-specified. We present an extensive simulation study to\ndemonstrate the superiority of our SSL approach compared to existing supervised\nmethods. We apply the method to derive genetic risk prediction of type-2\ndiabetes mellitus using a EHR biobank cohort.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 03:08:51 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Hou", "Jue", ""], ["Guo", "Zijian", ""], ["Cai", "Tianxi", ""]]}, {"id": "2105.01346", "submitter": "Hachem Kadri", "authors": "Paolo Milanesi (QARMA), Hachem Kadri (LIS, QARMA, AMU SCI), St\\'ephane\n  Ayache (QARMA), Thierry Arti\\`eres (QARMA)", "title": "Implicit Regularization in Deep Tensor Factorization", "comments": null, "journal-ref": "International Joint Conference on Neural Networks (IJCNN), Jul\n  2021, Online, China", "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attempts of studying implicit regularization associated to gradient descent\n(GD) have identified matrix completion as a suitable test-bed. Late findings\nsuggest that this phenomenon cannot be phrased as a minimization-norm problem,\nimplying that a paradigm shift is required and that dynamics has to be taken\ninto account. In the present work we address the more general setup of tensor\ncompletion by leveraging two popularized tensor factorization, namely Tucker\nand TensorTrain (TT). We track relevant quantities such as tensor nuclear norm,\neffective rank, generalized singular values and we introduce deep Tucker and TT\nunconstrained factorization to deal with the completion task. Experiments on\nboth synthetic and real data show that gradient descent promotes solution with\nlow-rank, and validate the conjecture saying that the phenomenon has to be\naddressed from a dynamical perspective.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 07:48:40 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Milanesi", "Paolo", "", "QARMA"], ["Kadri", "Hachem", "", "LIS, QARMA, AMU SCI"], ["Ayache", "St\u00e9phane", "", "QARMA"], ["Arti\u00e8res", "Thierry", "", "QARMA"]]}, {"id": "2105.01420", "submitter": "Burak Bartan", "authors": "Burak Bartan, Mert Pilanci", "title": "Training Quantized Neural Networks to Global Optimality via Semidefinite\n  Programming", "comments": "v2: Minor edits in the text. The results are unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks (NNs) have been extremely successful across many tasks in\nmachine learning. Quantization of NN weights has become an important topic due\nto its impact on their energy efficiency, inference time and deployment on\nhardware. Although post-training quantization is well-studied, training optimal\nquantized NNs involves combinatorial non-convex optimization problems which\nappear intractable. In this work, we introduce a convex optimization strategy\nto train quantized NNs with polynomial activations. Our method leverages hidden\nconvexity in two-layer neural networks from the recent literature, semidefinite\nlifting, and Grothendieck's identity. Surprisingly, we show that certain\nquantized NN problems can be solved to global optimality in polynomial-time in\nall relevant parameters via semidefinite relaxations. We present numerical\nexamples to illustrate the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 11:11:33 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 09:29:13 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Bartan", "Burak", ""], ["Pilanci", "Mert", ""]]}, {"id": "2105.01426", "submitter": "Martin Huber", "authors": "Martin Huber, Jonas Meier, Hannes Wallimann", "title": "Business analytics meets artificial intelligence: Assessing the demand\n  effects of discounts on Swiss train tickets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN q-fin.EC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We assess the demand effects of discounts on train tickets issued by the\nSwiss Federal Railways, the so-called `supersaver tickets', based on machine\nlearning, a subfield of artificial intelligence. Considering a survey-based\nsample of buyers of supersaver tickets, we investigate which customer- or\ntrip-related characteristics (including the discount rate) predict buying\nbehavior, namely: booking a trip otherwise not realized by train, buying a\nfirst- rather than second-class ticket, or rescheduling a trip (e.g.\\ away from\nrush hours) when being offered a supersaver ticket. Predictive machine learning\nsuggests that customer's age, demand-related information for a specific\nconnection (like departure time and utilization), and the discount level permit\nforecasting buying behavior to a certain extent. Furthermore, we use causal\nmachine learning to assess the impact of the discount rate on rescheduling a\ntrip, which seems relevant in the light of capacity constraints at rush hours.\nAssuming that (i) the discount rate is quasi-random conditional on our rich set\nof characteristics and (ii) the buying decision increases weakly monotonically\nin the discount rate, we identify the discount rate's effect among `always\nbuyers', who would have traveled even without a discount, based on our survey\nthat asks about customer behavior in the absence of discounts. We find that on\naverage, increasing the discount rate by one percentage point increases the\nshare of rescheduled trips by 0.16 percentage points among always buyers.\nInvestigating effect heterogeneity across observables suggests that the effects\nare higher for leisure travelers and during peak hours when controlling several\nother characteristics.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 11:29:54 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 14:55:12 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 15:58:06 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Huber", "Martin", ""], ["Meier", "Jonas", ""], ["Wallimann", "Hannes", ""]]}, {"id": "2105.01441", "submitter": "Christoph Kern", "authors": "Matthias Kuppler, Christoph Kern, Ruben L. Bach, Frauke Kreuter", "title": "Distributive Justice and Fairness Metrics in Automated Decision-making:\n  How Much Overlap Is There?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of powerful prediction algorithms led to increased automation of\nhigh-stake decisions regarding the allocation of scarce resources such as\ngovernment spending and welfare support. This automation bears the risk of\nperpetuating unwanted discrimination against vulnerable and historically\ndisadvantaged groups. Research on algorithmic discrimination in computer\nscience and other disciplines developed a plethora of fairness metrics to\ndetect and correct discriminatory algorithms. Drawing on robust sociological\nand philosophical discourse on distributive justice, we identify the\nlimitations and problematic implications of prominent fairness metrics. We show\nthat metrics implementing equality of opportunity only apply when resource\nallocations are based on deservingness, but fail when allocations should\nreflect concerns about egalitarianism, sufficiency, and priority. We argue that\nby cleanly distinguishing between prediction tasks and decision tasks, research\non fair machine learning could take better advantage of the rich literature on\ndistributive justice.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 12:09:26 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 10:26:34 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Kuppler", "Matthias", ""], ["Kern", "Christoph", ""], ["Bach", "Ruben L.", ""], ["Kreuter", "Frauke", ""]]}, {"id": "2105.01463", "submitter": "Berkan Kadioglu", "authors": "Berkan Kadioglu, Peng Tian, Jennifer Dy, Deniz Erdogmus and Stratis\n  Ioannidis", "title": "On the Sample Complexity of Rank Regression from Pairwise Comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a rank regression setting, in which a dataset of $N$ samples with\nfeatures in $\\mathbb{R}^d$ is ranked by an oracle via $M$ pairwise comparisons.\nSpecifically, there exists a latent total ordering of the samples; when\npresented with a pair of samples, a noisy oracle identifies the one ranked\nhigher with respect to the underlying total ordering. A learner observes a\ndataset of such comparisons and wishes to regress sample ranks from their\nfeatures. We show that to learn the model parameters with $\\epsilon > 0$\naccuracy, it suffices to conduct $M \\in \\Omega(dN\\log^3 N/\\epsilon^2)$\ncomparisons uniformly at random when $N$ is $\\Omega(d/\\epsilon^2)$.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 12:45:53 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Kadioglu", "Berkan", ""], ["Tian", "Peng", ""], ["Dy", "Jennifer", ""], ["Erdogmus", "Deniz", ""], ["Ioannidis", "Stratis", ""]]}, {"id": "2105.01536", "submitter": "Michael Backenk\\\"ohler", "authors": "Michael Backenk\\\"ohler, Luca Bortolussi, Gerrit Gro{\\ss}mann, Verena\n  Wolf", "title": "Abstraction-Guided Truncations for Stationary Distributions of Markov\n  Population Models", "comments": "arXiv admin note: text overlap with arXiv:2010.10096", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.SY eess.SY q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand the long-run behavior of Markov population models, the\ncomputation of the stationary distribution is often a crucial part. We propose\na truncation-based approximation that employs a state-space lumping scheme,\naggregating states in a grid structure. The resulting approximate stationary\ndistribution is used to iteratively refine relevant and truncate irrelevant\nparts of the state-space. This way, the algorithm learns a well-justified\nfinite-state projection tailored to the stationary behavior. We demonstrate the\nmethod's applicability to a wide range of non-linear problems with complex\nstationary behaviors.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 08:53:36 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Backenk\u00f6hler", "Michael", ""], ["Bortolussi", "Luca", ""], ["Gro\u00dfmann", "Gerrit", ""], ["Wolf", "Verena", ""]]}, {"id": "2105.01550", "submitter": "Yutao Zhong", "authors": "Pranjal Awasthi, Anqi Mao, Mehryar Mohri, Yutao Zhong", "title": "A Finer Calibration Analysis for Adversarial Robustness", "comments": "arXiv admin note: text overlap with arXiv:2104.09658", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a more general analysis of $H$-calibration for adversarially\nrobust classification. By adopting a finer definition of calibration, we can\ncover settings beyond the restricted hypothesis sets studied in previous work.\nIn particular, our results hold for most common hypothesis sets used in machine\nlearning. We both fix some previous calibration results (Bao et al., 2020) and\ngeneralize others (Awasthi et al., 2021). Moreover, our calibration results,\ncombined with the previous study of consistency by Awasthi et al. (2021), also\nlead to more general $H$-consistency results covering common hypothesis sets.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 14:59:39 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 15:59:29 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Mao", "Anqi", ""], ["Mohri", "Mehryar", ""], ["Zhong", "Yutao", ""]]}, {"id": "2105.01593", "submitter": "Daniel Vial", "authors": "Daniel Vial, Advait Parulekar, Sanjay Shakkottai, R. Srikant", "title": "Regret Bounds for Stochastic Shortest Path Problems with Linear Function\n  Approximation", "comments": "Main addition to prior version is a computationally efficient\n  algorithm with K^{3/4} regret", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two algorithms that use linear function approximation (LFA) for\nstochastic shortest path (SSP) and bound their regret over $K$ episodes. When\nall stationary policies are proper, our first algorithm obtains sublinear\nregret ($K^{3/4}$), is computationally efficient, and uses stationary policies.\nThis is the first LFA algorithm with these three properties, to the best of our\nknowledge. Our second algorithm improves the regret to $\\sqrt{K}$ when the\nfeature vectors satisfy certain assumptions. Both algorithms are special cases\nof a more general one, which has $\\sqrt{K}$ regret for general features given\naccess to a certain computation oracle. These algorithms and regret bounds are\nthe first for SSP with function approximation.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 16:05:08 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 21:34:08 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Vial", "Daniel", ""], ["Parulekar", "Advait", ""], ["Shakkottai", "Sanjay", ""], ["Srikant", "R.", ""]]}, {"id": "2105.01636", "submitter": "Andreas Mayr", "authors": "Andreas Mayr, Sebastian Lehner, Arno Mayrhofer, Christoph Kloss, Sepp\n  Hochreiter, Johannes Brandstetter", "title": "Learning 3D Granular Flow Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the application of machine learning models has gained momentum in\nnatural sciences and engineering, which is a natural fit due to the abundance\nof data in these fields. However, the modeling of physical processes from\nsimulation data without first principle solutions remains difficult. Here, we\npresent a Graph Neural Networks approach towards accurate modeling of complex\n3D granular flow simulation processes created by the discrete element method\nLIGGGHTS and concentrate on simulations of physical systems found in real world\napplications like rotating drums and hoppers. We discuss how to implement Graph\nNeural Networks that deal with 3D objects, boundary conditions, particle -\nparticle, and particle - boundary interactions such that an accurate modeling\nof relevant physical quantities is made possible. Finally, we compare the\nmachine learning based trajectories to LIGGGHTS trajectories in terms of\nparticle flows and mixing entropies.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 17:27:59 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Mayr", "Andreas", ""], ["Lehner", "Sebastian", ""], ["Mayrhofer", "Arno", ""], ["Kloss", "Christoph", ""], ["Hochreiter", "Sepp", ""], ["Brandstetter", "Johannes", ""]]}, {"id": "2105.01637", "submitter": "Quentin Bertrand", "authors": "Quentin Bertrand, Quentin Klopfenstein, Mathurin Massias, Mathieu\n  Blondel, Samuel Vaiter, Alexandre Gramfort, Joseph Salmon", "title": "Implicit differentiation for fast hyperparameter selection in non-smooth\n  convex learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the optimal hyperparameters of a model can be cast as a bilevel\noptimization problem, typically solved using zero-order techniques. In this\nwork we study first-order methods when the inner optimization problem is convex\nbut non-smooth. We show that the forward-mode differentiation of proximal\ngradient descent and proximal coordinate descent yield sequences of Jacobians\nconverging toward the exact Jacobian. Using implicit differentiation, we show\nit is possible to leverage the non-smoothness of the inner problem to speed up\nthe computation. Finally, we provide a bound on the error made on the\nhypergradient when the inner optimization problem is solved approximately.\nResults on regression and classification problems reveal computational benefits\nfor hyperparameter optimization, especially when multiple hyperparameters are\nrequired.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 17:31:28 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 13:07:28 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Bertrand", "Quentin", ""], ["Klopfenstein", "Quentin", ""], ["Massias", "Mathurin", ""], ["Blondel", "Mathieu", ""], ["Vaiter", "Samuel", ""], ["Gramfort", "Alexandre", ""], ["Salmon", "Joseph", ""]]}, {"id": "2105.01650", "submitter": "Stephan Wojtowytsch", "authors": "Stephan Wojtowytsch", "title": "Stochastic gradient descent with noise of machine learning type. Part I:\n  Discrete time analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is one of the most popular algorithms in\nmodern machine learning. The noise encountered in these applications is\ndifferent from that in many theoretical analyses of stochastic gradient\nalgorithms. In this article, we discuss some of the common properties of energy\nlandscapes and stochastic noise encountered in machine learning problems, and\nhow they affect SGD-based optimization.\n  In particular, we show that the learning rate in SGD with machine learning\nnoise can be chosen to be small, but uniformly positive for all times if the\nenergy landscape resembles that of overparametrized deep learning problems. If\nthe objective function satisfies a Lojasiewicz inequality, SGD converges to the\nglobal minimum exponentially fast, and even for functions which may have local\nminima, we establish almost sure convergence to the global minimum at an\nexponential rate from any finite energy initialization. The assumptions that we\nmake in this result concern the behavior where the objective function is either\nsmall or large and the nature of the gradient noise, but the energy landscape\nis fairly unconstrained on the domain where the objective function takes values\nin an intermediate regime.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 17:52:20 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Wojtowytsch", "Stephan", ""]]}, {"id": "2105.01706", "submitter": "Chiheb Daaloul", "authors": "Chiheb Daaloul (1), Thibaut Le Gouic (2), Jacques Liandrat (1), Magali\n  Tournus (1) ((1) Aix-Marseille Univ., CNRS, I2M, UMR7373, Centrale Marseille,\n  Marseille, France, (2) Massachusetts Institute of Technology, Department of\n  Mathematics, USA)", "title": "Sampling From the Wasserstein Barycenter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an algorithm to sample from the Wasserstein barycenter of\nabsolutely continuous measures. Our method is based on the gradient flow of the\nmultimarginal formulation of the Wasserstein barycenter, with an additive\npenalization to account for the marginal constraints. We prove that the minimum\nof this penalized multimarginal formulation is achieved for a coupling that is\nclose to the Wasserstein barycenter. The performances of the algorithm are\nshowcased in several settings.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 18:57:41 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Daaloul", "Chiheb", ""], ["Gouic", "Thibaut Le", ""], ["Liandrat", "Jacques", ""], ["Tournus", "Magali", ""]]}, {"id": "2105.01783", "submitter": "Chanwoo Lee", "authors": "Chanwoo Lee, Lexin Li, Hao Helen Zhang, and Miaoyan Wang", "title": "Nonparametric Trace Regression in High Dimensions via Sign Series\n  Representation", "comments": "66 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning of matrix-valued data has recently surged in a range of scientific\nand business applications. Trace regression is a widely used method to model\neffects of matrix predictors and has shown great success in matrix learning.\nHowever, nearly all existing trace regression solutions rely on two\nassumptions: (i) a known functional form of the conditional mean, and (ii) a\nglobal low-rank structure in the entire range of the regression function, both\nof which may be violated in practice. In this article, we relax these\nassumptions by developing a general framework for nonparametric trace\nregression models via structured sign series representations of high\ndimensional functions. The new model embraces both linear and nonlinear trace\neffects, and enjoys rank invariance to order-preserving transformations of the\nresponse. In the context of matrix completion, our framework leads to a\nsubstantially richer model based on what we coin as the \"sign rank\" of a\nmatrix. We show that the sign series can be statistically characterized by\nweighted classification tasks. Based on this connection, we propose a learning\nreduction approach to learn the regression model via a series of classifiers,\nand develop a parallelable computation algorithm to implement sign series\naggregations. We establish the excess risk bounds, estimation error rates, and\nsample complexities. Our proposal provides a broad nonparametric paradigm to\nmany important matrix learning problems, including matrix regression, matrix\ncompletion, multi-task learning, and compressed sensing. We demonstrate the\nadvantages of our method through simulations and two applications, one on brain\nconnectivity study and the other on high-rank image completion.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 22:20:00 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Lee", "Chanwoo", ""], ["Li", "Lexin", ""], ["Zhang", "Hao Helen", ""], ["Wang", "Miaoyan", ""]]}, {"id": "2105.01850", "submitter": "Kush Bhatia", "authors": "Kush Bhatia, Ashwin Pananjady, Peter L. Bartlett, Anca D. Dragan,\n  Martin J. Wainwright", "title": "Preference learning along multiple criteria: A game-theoretic\n  perspective", "comments": "47 pages; published as a conference paper at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The literature on ranking from ordinal data is vast, and there are several\nways to aggregate overall preferences from pairwise comparisons between\nobjects. In particular, it is well known that any Nash equilibrium of the zero\nsum game induced by the preference matrix defines a natural solution concept\n(winning distribution over objects) known as a von Neumann winner. Many\nreal-world problems, however, are inevitably multi-criteria, with different\npairwise preferences governing the different criteria. In this work, we\ngeneralize the notion of a von Neumann winner to the multi-criteria setting by\ntaking inspiration from Blackwell's approachability. Our framework allows for\nnon-linear aggregation of preferences across criteria, and generalizes the\nlinearization-based approach from multi-objective optimization.\n  From a theoretical standpoint, we show that the Blackwell winner of a\nmulti-criteria problem instance can be computed as the solution to a convex\noptimization problem. Furthermore, given random samples of pairwise\ncomparisons, we show that a simple plug-in estimator achieves near-optimal\nminimax sample complexity. Finally, we showcase the practical utility of our\nframework in a user study on autonomous driving, where we find that the\nBlackwell winner outperforms the von Neumann winner for the overall\npreferences.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 03:23:11 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Bhatia", "Kush", ""], ["Pananjady", "Ashwin", ""], ["Bartlett", "Peter L.", ""], ["Dragan", "Anca D.", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "2105.01867", "submitter": "Devansh Bisla", "authors": "Devansh Bisla, Apoorva Nandini Saridena, Anna Choromanska", "title": "A Theoretical-Empirical Approach to Estimating Sample Complexity of DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper focuses on understanding how the generalization error scales with\nthe amount of the training data for deep neural networks (DNNs). Existing\ntechniques in statistical learning require computation of capacity measures,\nsuch as VC dimension, to provably bound this error. It is however unclear how\nto extend these measures to DNNs and therefore the existing analyses are\napplicable to simple neural networks, which are not used in practice, e.g.,\nlinear or shallow ones or otherwise multi-layer perceptrons. Moreover, many\ntheoretical error bounds are not empirically verifiable. We derive estimates of\nthe generalization error that hold for deep networks and do not rely on\nunattainable capacity measures. The enabling technique in our approach hinges\non two major assumptions: i) the network achieves zero training error, ii) the\nprobability of making an error on a test point is proportional to the distance\nbetween this point and its nearest training point in the feature space and at a\ncertain maximal distance (that we call radius) it saturates. Based on these\nassumptions we estimate the generalization error of DNNs. The obtained estimate\nscales as O(1/(\\delta N^{1/d})), where N is the size of the training data and\nis parameterized by two quantities, the effective dimensionality of the data as\nperceived by the network (d) and the aforementioned radius (\\delta), both of\nwhich we find empirically. We show that our estimates match with the\nexperimentally obtained behavior of the error on multiple learning tasks using\nbenchmark data-sets and realistic models. Estimating training data requirements\nis essential for deployment of safety critical applications such as autonomous\ndriving etc. Furthermore, collecting and annotating training data requires a\nhuge amount of financial, computational and human resources. Our empirical\nestimates will help to efficiently allocate resources.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 05:14:08 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Bisla", "Devansh", ""], ["Saridena", "Apoorva Nandini", ""], ["Choromanska", "Anna", ""]]}, {"id": "2105.01874", "submitter": "Yunhua Xiang", "authors": "Yunhua Xiang, Tianyu Zhang, Xu Wang, Ali Shojaie, Noah Simon", "title": "On the Optimality of Nuclear-norm-based Matrix Completion for Problems\n  with Smooth Non-linear Structure", "comments": "47 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Originally developed for imputing missing entries in low rank, or\napproximately low rank matrices, matrix completion has proven widely effective\nin many problems where there is no reason to assume low-dimensional linear\nstructure in the underlying matrix, as would be imposed by rank constraints. In\nthis manuscript, we build some theoretical intuition for this behavior. We\nconsider matrices which are not necessarily low-rank, but lie in a\nlow-dimensional non-linear manifold. We show that nuclear-norm penalization is\nstill effective for recovering these matrices when observations are missing\ncompletely at random. In particular, we give upper bounds on the rate of\nconvergence as a function of the number of rows, columns, and observed entries\nin the matrix, as well as the smoothness and dimension of the non-linear\nembedding. We additionally give a minimax lower bound: This lower bound agrees\nwith our upper bound (up to a logarithmic factor), which shows that\nnuclear-norm penalization is (up to log terms) minimax rate optimal for these\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 05:34:32 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Xiang", "Yunhua", ""], ["Zhang", "Tianyu", ""], ["Wang", "Xu", ""], ["Shojaie", "Ali", ""], ["Simon", "Noah", ""]]}, {"id": "2105.02062", "submitter": "Chengli Tan", "authors": "Chengli Tan, Jiangshe Zhang, and Junmin Liu", "title": "Understanding Short-Range Memory Effects in Deep Neural Networks", "comments": "15pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) is of fundamental importance in deep\nlearning. Despite its simplicity, elucidating its efficacy remains challenging.\nConventionally, the success of SGD is ascribed to the stochastic gradient noise\n(SGN) incurred in the training process. Based on this consensus, SGD is\nfrequently treated and analyzed as the Euler-Maruyama discretization of\nstochastic differential equations (SDEs) driven by either Brownian or Levy\nstable motion. In this study, we argue that SGN is neither Gaussian nor Levy\nstable. Instead, inspired by the short-range correlation emerging in the SGN\nseries, we propose that SGD can be viewed as a discretization of an SDE driven\nby fractional Brownian motion (FBM). Accordingly, the different convergence\nbehavior of SGD dynamics is well-grounded. Moreover, the first passage time of\nan SDE driven by FBM is approximately derived. The result suggests a lower\nescaping rate for a larger Hurst parameter, and thus SGD stays longer in flat\nminima. This happens to coincide with the well-known phenomenon that SGD favors\nflat minima that generalize well. Extensive experiments are conducted to\nvalidate our conjecture, and it is demonstrated that short-range memory effects\npersist across various model architectures, datasets, and training strategies.\nOur study opens up a new perspective and may contribute to a better\nunderstanding of SGD.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 13:54:26 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 02:49:44 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 03:23:42 GMT"}, {"version": "v4", "created": "Mon, 28 Jun 2021 08:50:25 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Tan", "Chengli", ""], ["Zhang", "Jiangshe", ""], ["Liu", "Junmin", ""]]}, {"id": "2105.02083", "submitter": "Matthias L\\\"offler", "authors": "Geoffrey Chinot, Felix Kuchelmeister, Matthias L\\\"offler and Sara van\n  de Geer", "title": "AdaBoost and robust one-bit compressed sensing", "comments": "29 pages, 4 figures, code available at\n  https://github.com/Felix-127/Adaboost-and-robust-one-bit-compressed-sensing", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper studies binary classification in robust one-bit compressed sensing\nwith adversarial errors. It is assumed that the model is overparameterized and\nthat the parameter of interest is effectively sparse. AdaBoost is considered,\nand, through its relation to the max-$\\ell_1$-margin-classifier, risk bounds\nare derived. In particular, this provides an explanation why interpolating\nadversarial noise can be harmless for classification problems. Simulations\nillustrate the presented theory.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 14:29:49 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 12:30:10 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 07:35:42 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Chinot", "Geoffrey", ""], ["Kuchelmeister", "Felix", ""], ["L\u00f6ffler", "Matthias", ""], ["van de Geer", "Sara", ""]]}, {"id": "2105.02180", "submitter": "Oliver Feng", "authors": "Oliver Y. Feng, Ramji Venkataramanan, Cynthia Rush and Richard J.\n  Samworth", "title": "A unifying tutorial on Approximate Message Passing", "comments": "99 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the last decade or so, Approximate Message Passing (AMP) algorithms have\nbecome extremely popular in various structured high-dimensional statistical\nproblems. The fact that the origins of these techniques can be traced back to\nnotions of belief propagation in the statistical physics literature lends a\ncertain mystique to the area for many statisticians. Our goal in this work is\nto present the main ideas of AMP from a statistical perspective, to illustrate\nthe power and flexibility of the AMP framework. Along the way, we strengthen\nand unify many of the results in the existing literature.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 16:47:10 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Feng", "Oliver Y.", ""], ["Venkataramanan", "Ramji", ""], ["Rush", "Cynthia", ""], ["Samworth", "Richard J.", ""]]}, {"id": "2105.02221", "submitter": "Kurtland Chua", "authors": "Kurtland Chua, Qi Lei, Jason D. Lee", "title": "How Fine-Tuning Allows for Effective Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning has been widely studied in the context of\nmeta-learning, enabling rapid learning of new tasks through shared\nrepresentations. Recent works such as MAML have explored using\nfine-tuning-based metrics, which measure the ease by which fine-tuning can\nachieve good performance, as proxies for obtaining representations. We present\na theoretical framework for analyzing representations derived from a MAML-like\nalgorithm, assuming the available tasks use approximately the same underlying\nrepresentation. We then provide risk bounds on the best predictor found by\nfine-tuning via gradient descent, demonstrating that the algorithm can provably\nleverage the shared structure. The upper bound applies to general function\nclasses, which we demonstrate by instantiating the guarantees of our framework\nin the logistic regression and neural network settings. In contrast, we\nestablish the existence of settings where any algorithm, using a representation\ntrained with no consideration for task-specific fine-tuning, performs as well\nas a learner with no access to source tasks in the worst case. This separation\nresult underscores the benefit of fine-tuning-based methods, such as MAML, over\nmethods with \"frozen representation\" objectives in few-shot learning.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 17:56:00 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Chua", "Kurtland", ""], ["Lei", "Qi", ""], ["Lee", "Jason D.", ""]]}, {"id": "2105.02259", "submitter": "Mingao Yuan", "authors": "Mingao Yuan, Zuofeng Shang", "title": "Information Limits for Detecting a Subhypergraph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of recovering a subhypergraph based on an observed\nadjacency tensor corresponding to a uniform hypergraph. The uniform hypergraph\nis assumed to contain a subset of vertices called as subhypergraph. The edges\nrestricted to the subhypergraph are assumed to follow a different probability\ndistribution than other edges. We consider both weak recovery and exact\nrecovery of the subhypergraph, and establish information-theoretic limits in\neach case. Specifically, we establish sharp conditions for the possibility of\nweakly or exactly recovering the subhypergraph from an information-theoretic\npoint of view. These conditions are fundamentally different from their\ncounterparts derived in hypothesis testing literature.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 18:08:42 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Yuan", "Mingao", ""], ["Shang", "Zuofeng", ""]]}, {"id": "2105.02337", "submitter": "Yijun Zuo", "authors": "Yijun Zuo", "title": "Non-asymptotic analysis and inference for an outlyingness induced\n  winsorized mean", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust estimation of a mean vector, a topic regarded as obsolete in the\ntraditional robust statistics community, has recently surged in machine\nlearning literature in the last decade. The latest focus is on the sub-Gaussian\nperformance and computability of the estimators in a non-asymptotic setting.\nNumerous traditional robust estimators are computationally intractable, which\npartly contributes to the renewal of the interest in the robust mean\nestimation.\n  Robust centrality estimators, however, include the trimmed mean and the\nsample median. The latter has the best robustness but suffers a low-efficiency\ndrawback. Trimmed mean and median of means, %as robust alternatives to the\nsample mean, and achieving sub-Gaussian performance have been proposed and\nstudied in the literature.\n  This article investigates the robustness of leading sub-Gaussian estimators\nof mean and reveals that none of them can resist greater than $25\\%$\ncontamination in data and consequently introduces an outlyingness induced\nwinsorized mean which has the best possible robustness (can resist up to $50\\%$\ncontamination without breakdown) meanwhile achieving high efficiency.\nFurthermore, it has a sub-Gaussian performance for uncontaminated samples and a\nbounded estimation error for contaminated samples at a given confidence level\nin a finite sample setting. It can be computed in linear time.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 21:35:24 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Zuo", "Yijun", ""]]}, {"id": "2105.02344", "submitter": "Ruohan Zhan", "authors": "Ruohan Zhan, Zhimei Ren, Susan Athey, Zhengyuan Zhou", "title": "Policy Learning with Adaptively Collected Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning optimal policies from historical data enables the gains from\npersonalization to be realized in a wide variety of applications. The growing\npolicy learning literature focuses on a setting where the treatment assignment\npolicy does not adapt to the data. However, adaptive data collection is\nbecoming more common in practice, from two primary sources: 1) data collected\nfrom adaptive experiments that are designed to improve inferential efficiency;\n2) data collected from production systems that are adaptively evolving an\noperational policy to improve performance over time (e.g. contextual bandits).\nIn this paper, we aim to address the challenge of learning the optimal policy\nwith adaptively collected data and provide one of the first theoretical\ninquiries into this problem. We propose an algorithm based on generalized\naugmented inverse propensity weighted estimators and establish its\nfinite-sample regret bound. We complement this regret upper bound with a lower\nbound that characterizes the fundamental difficulty of policy learning with\nadaptive data. Finally, we demonstrate our algorithm's effectiveness using both\nsynthetic data and public benchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 22:03:10 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Zhan", "Ruohan", ""], ["Ren", "Zhimei", ""], ["Athey", "Susan", ""], ["Zhou", "Zhengyuan", ""]]}, {"id": "2105.02375", "submitter": "Qing Qu", "authors": "Zhihui Zhu, Tianyu Ding, Jinxin Zhou, Xiao Li, Chong You, Jeremias\n  Sulam, and Qing Qu", "title": "A Geometric Analysis of Neural Collapse with Unconstrained Features", "comments": "42 pages, 8 figures, 1 table; the first two authors contributed to\n  this work equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first global optimization landscape analysis of\n$Neural\\;Collapse$ -- an intriguing empirical phenomenon that arises in the\nlast-layer classifiers and features of neural networks during the terminal\nphase of training. As recently reported by Papyan et al., this phenomenon\nimplies that ($i$) the class means and the last-layer classifiers all collapse\nto the vertices of a Simplex Equiangular Tight Frame (ETF) up to scaling, and\n($ii$) cross-example within-class variability of last-layer activations\ncollapses to zero. We study the problem based on a simplified\n$unconstrained\\;feature\\;model$, which isolates the topmost layers from the\nclassifier of the neural network. In this context, we show that the classical\ncross-entropy loss with weight decay has a benign global landscape, in the\nsense that the only global minimizers are the Simplex ETFs while all other\ncritical points are strict saddles whose Hessian exhibit negative curvature\ndirections. In contrast to existing landscape analysis for deep neural networks\nwhich is often disconnected from practice, our analysis of the simplified model\nnot only does it explain what kind of features are learned in the last layer,\nbut it also shows why they can be efficiently optimized in the simplified\nsettings, matching the empirical observations in practical deep network\narchitectures. These findings could have profound implications for\noptimization, generalization, and robustness of broad interests. For example,\nour experiments demonstrate that one may set the feature dimension equal to the\nnumber of classes and fix the last-layer classifier to be a Simplex ETF for\nnetwork training, which reduces memory cost by over $20\\%$ on ResNet18 without\nsacrificing the generalization performance.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 00:00:50 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Zhu", "Zhihui", ""], ["Ding", "Tianyu", ""], ["Zhou", "Jinxin", ""], ["Li", "Xiao", ""], ["You", "Chong", ""], ["Sulam", "Jeremias", ""], ["Qu", "Qing", ""]]}, {"id": "2105.02470", "submitter": "Thomas M. Sutter", "authors": "Thomas M. Sutter and Imant Daunhawer, Julia E. Vogt", "title": "Generalized Multimodal ELBO", "comments": "2021 ICLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Multiple data types naturally co-occur when describing real-world phenomena\nand learning from them is a long-standing goal in machine learning research.\nHowever, existing self-supervised generative models approximating an ELBO are\nnot able to fulfill all desired requirements of multimodal models: their\nposterior approximation functions lead to a trade-off between the semantic\ncoherence and the ability to learn the joint data distribution. We propose a\nnew, generalized ELBO formulation for multimodal data that overcomes these\nlimitations. The new objective encompasses two previous methods as special\ncases and combines their benefits without compromises. In extensive\nexperiments, we demonstrate the advantage of the proposed method compared to\nstate-of-the-art models in self-supervised, generative learning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 07:05:00 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 08:09:04 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Sutter", "Thomas M.", ""], ["Daunhawer", "Imant", ""], ["Vogt", "Julia E.", ""]]}, {"id": "2105.02487", "submitter": "Boxin Zhao", "authors": "Boxin Zhao, Shengjun Zhai, Y. Samuel Wang, Mladen Kolar", "title": "High-dimensional Functional Graphical Model Structure Learning via\n  Neighborhood Selection Approach", "comments": "52 pages, 1 figure and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Undirected graphical models have been widely used to model the conditional\nindependence structure of high-dimensional random vector data for years. In\nmany modern applications such as EEG and fMRI data, the observations are\nmultivariate random functions rather than scalars. To model the conditional\nindependence of this type of data, functional graphical models are proposed and\nhave attracted an increasing attention in recent years. In this paper, we\npropose a neighborhood selection approach to estimate Gaussian functional\ngraphical models. We first estimate the neighborhood of all nodes via\nfunction-on-function regression, and then we can recover the whole graph\nstructure based on the neighborhood information. By estimating conditional\nstructure directly, we can circumvent the need of a well-defined precision\noperator which generally does not exist. Besides, we can better explore the\neffect of the choice of function basis for dimension reduction. We give a\ncriterion for choosing the best function basis and motivate two practically\nuseful choices, which we justified by both theory and experiments and show that\nthey are better than expanding each function onto its own FPCA basis as in\nprevious literature. In addition, the neighborhood selection approach is\ncomputationally more efficient than fglasso as it is more easy to do parallel\ncomputing. The statistical consistency of our proposed methods in\nhigh-dimensional setting are supported by both theory and experiment.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 07:38:50 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Zhao", "Boxin", ""], ["Zhai", "Shengjun", ""], ["Wang", "Y. Samuel", ""], ["Kolar", "Mladen", ""]]}, {"id": "2105.02522", "submitter": "Alexis Bellot", "authors": "Alexis Bellot, Kim Branson and Mihaela van der Schaar", "title": "Consistency of mechanistic causal discovery in continuous-time using\n  Neural ODEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery of causal mechanisms from time series data is a key problem in\nfields working with complex systems. Most identifiability results and learning\nalgorithms assume the underlying dynamics to be discrete in time. Comparatively\nfew, in contrast, explicitly define causal associations in infinitesimal\nintervals of time, independently of the scale of observation and of the\nregularity of sampling. In this paper, we consider causal discovery in\ncontinuous-time for the study of dynamical systems. We prove that for vector\nfields parameterized in a large class of neural networks, adaptive\nregularization schemes consistently recover causal graphs in systems of\nordinary differential equations (ODEs). Using this insight, we propose a causal\ndiscovery algorithm based on penalized Neural ODEs that we show to be\napplicable to the general setting of irregularly-sampled multivariate time\nseries and to strongly outperform the state of the art.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 08:48:02 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Bellot", "Alexis", ""], ["Branson", "Kim", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "2105.02551", "submitter": "Jary Pomponi", "authors": "Jary Pomponi, Simone Scardapane, and Aurelio Uncini", "title": "Structured Ensembles: an Approach to Reduce the Memory Footprint of\n  Ensemble Methods", "comments": "Preprint submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a novel ensembling technique for deep neural\nnetworks, which is able to drastically reduce the required memory compared to\nalternative approaches. In particular, we propose to extract multiple\nsub-networks from a single, untrained neural network by solving an end-to-end\noptimization task combining differentiable scaling over the original\narchitecture, with multiple regularization terms favouring the diversity of the\nensemble. Since our proposal aims to detect and extract sub-structures, we call\nit Structured Ensemble. On a large experimental evaluation, we show that our\nmethod can achieve higher or comparable accuracy to competing methods while\nrequiring significantly less storage. In addition, we evaluate our ensembles in\nterms of predictive calibration and uncertainty, showing they compare\nfavourably with the state-of-the-art. Finally, we draw a link with the\ncontinual learning literature, and we propose a modification of our framework\nto handle continuous streams of tasks with a sub-linear memory cost. We compare\nwith a number of alternative strategies to mitigate catastrophic forgetting,\nhighlighting advantages in terms of average accuracy and memory.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 09:56:01 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Pomponi", "Jary", ""], ["Scardapane", "Simone", ""], ["Uncini", "Aurelio", ""]]}, {"id": "2105.02569", "submitter": "Qingfeng Liu", "authors": "Qingfeng Liu and Yang Feng", "title": "Machine Collaboration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new ensemble framework for supervised learning, called machine\ncollaboration (MaC), using a collection of base machines for prediction tasks.\nUnlike bagging/stacking (a parallel & independent framework) and boosting (a\nsequential & top-down framework), MaC is a type of circular & interactive\nlearning framework. The circular & interactive feature helps the base machines\nto transfer information circularly and update their structures and parameters\naccordingly. The theoretical result on the risk bound of the estimator from MaC\nreveals that the circular & interactive feature can help MaC reduce risk via a\nparsimonious ensemble. We conduct extensive experiments on MaC using both\nsimulated data and 119 benchmark real datasets. The results demonstrate that in\nmost cases, MaC performs significantly better than several other\nstate-of-the-art methods, including classification and regression trees, neural\nnetworks, stacking, and boosting.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 10:27:03 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 04:29:34 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Liu", "Qingfeng", ""], ["Feng", "Yang", ""]]}, {"id": "2105.02597", "submitter": "Carlo Manzo", "authors": "Carlo Manzo", "title": "Extreme Learning Machine for the Characterization of Anomalous Diffusion\n  from Single Trajectories", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": "10.1088/1751-8121/ac13dd", "report-no": null, "categories": "physics.data-an physics.bio-ph q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of the dynamics of natural and artificial systems has provided\nseveral examples of deviations from Brownian behavior, generally defined as\nanomalous diffusion. The investigation of these dynamics can provide a better\nunderstanding of diffusing objects and their surrounding media, but a\nquantitative characterization from individual trajectories is often\nchallenging. Efforts devoted to improving anomalous diffusion detection using\nclassical statistics and machine learning have produced several new methods.\nRecently, the anomalous diffusion challenge (AnDi,\nhttps://www.andi-challenge.org) was launched to objectively assess these\napproaches on a common dataset, focusing on three aspects of anomalous\ndiffusion: the inference of the anomalous diffusion exponent; the\nclassification of the diffusion model; and the segmentation of trajectories. In\nthis article, I describe a simple approach to tackle the tasks of the AnDi\nchallenge by combining extreme learning machine and feature engineering\n(AnDi-ELM). The method reaches satisfactory performance while offering a\nstraightforward implementation and fast training time with limited computing\nresources, making a suitable tool for fast preliminary screening.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 11:56:27 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Manzo", "Carlo", ""]]}, {"id": "2105.02675", "submitter": "Ali Shojaie", "authors": "Ali Shojaie and Emily B. Fox", "title": "Granger Causality: A Review and Recent Advances", "comments": "40 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Introduced more than a half century ago, Granger causality has become a\npopular tool for analyzing time series data in many application domains, from\neconomics and finance to genomics and neuroscience. Despite this popularity,\nthe validity of this notion for inferring causal relationships among time\nseries has remained the topic of continuous debate. Moreover, while the\noriginal definition was general, limitations in computational tools have\nprimarily limited the applications of Granger causality to simple bivariate\nvector auto-regressive processes or pairwise relationships among a set of\nvariables. Starting with a review of early developments and debates, this paper\ndiscusses recent advances that address various shortcomings of the earlier\napproaches, from models for high-dimensional time series to more recent\ndevelopments that account for nonlinear and non-Gaussian observations and allow\nfor sub-sampled and mixed frequency time series.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 17:37:18 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 02:38:08 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Shojaie", "Ali", ""], ["Fox", "Emily B.", ""]]}, {"id": "2105.02702", "submitter": "Yohei Kawaguchi", "authors": "Ryo Tanabe, Harsh Purohit, Kota Dohi, Takashi Endo, Yuki Nikaido,\n  Toshiki Nakamura, and Yohei Kawaguchi", "title": "MIMII DUE: Sound Dataset for Malfunctioning Industrial Machine\n  Investigation and Inspection with Domain Shifts due to Changes in Operational\n  and Environmental Conditions", "comments": "5 pages, under review for WASPAA 2021, disambiguation (in 2.2, sound\n  proof room -> sound isolation booth, anechoic room -> anechoic chamber)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a new dataset for malfunctioning industrial\nmachine investigation and inspection with domain shifts due to changes in\noperational and environmental conditions (MIMII DUE). Conventional methods for\nanomalous sound detection face challenges in practice because the distribution\nof features changes between the training and operational phases (called domain\nshift) due to some real-world factors. To check the robustness against domain\nshifts, we need a dataset with domain shifts, but such a dataset does not exist\nso far. The new dataset consists of normal and abnormal operating sounds of\nindustrial machines of five different types under two different\noperational/environmental conditions (source domain and target domain)\nindependent of normal/abnormal, with domain shifts occurring between the two\ndomains. Experimental results show significant performance differences between\nthe source and target domains, and the dataset contains the domain shifts.\nThese results indicate that the dataset will be helpful to check the robustness\nagainst domain shifts. The dataset is a subset of the dataset for DCASE 2021\nChallenge Task 2 and freely available for download at\nhttps://zenodo.org/record/4740355\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 14:18:24 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 13:56:38 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Tanabe", "Ryo", ""], ["Purohit", "Harsh", ""], ["Dohi", "Kota", ""], ["Endo", "Takashi", ""], ["Nikaido", "Yuki", ""], ["Nakamura", "Toshiki", ""], ["Kawaguchi", "Yohei", ""]]}, {"id": "2105.02716", "submitter": "Hidenori Tanaka", "authors": "Hidenori Tanaka, Daniel Kunin", "title": "Noether's Learning Dynamics: The Role of Kinetic Symmetry Breaking in\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In nature, symmetry governs regularities, while symmetry breaking brings\ntexture. Here, we reveal a novel role of symmetry breaking behind efficiency\nand stability in learning, a critical issue in machine learning. Recent\nexperiments suggest that the symmetry of the loss function is closely related\nto the learning performance. This raises a fundamental question. Is such\nsymmetry beneficial, harmful, or irrelevant to the success of learning? Here,\nwe demystify this question and pose symmetry breaking as a new design principle\nby considering the symmetry of the learning rule in addition to the loss\nfunction. We model the discrete learning dynamics using a continuous-time\nLagrangian formulation, in which the learning rule corresponds to the kinetic\nenergy and the loss function corresponds to the potential energy. We identify\nkinetic asymmetry unique to learning systems, where the kinetic energy often\ndoes not have the same symmetry as the potential (loss) function reflecting the\nnon-physical symmetries of the loss function and the non-Euclidean metric used\nin learning rules. We generalize Noether's theorem known in physics to\nexplicitly take into account this kinetic asymmetry and derive the resulting\nmotion of the Noether charge. Finally, we apply our theory to modern deep\nnetworks with normalization layers and reveal a mechanism of implicit adaptive\noptimization induced by the kinetic symmetry breaking.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 14:36:10 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Tanaka", "Hidenori", ""], ["Kunin", "Daniel", ""]]}, {"id": "2105.02725", "submitter": "Ahmad Khajenezhad", "authors": "Ahmad Khajehnejad, Moein Khajehnejad, Mahmoudreza Babaei, Krishna P.\n  Gummadi, Adrian Weller, Baharan Mirzasoleiman", "title": "CrossWalk: Fairness-enhanced Node Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The potential for machine learning systems to amplify social inequities and\nunfairness is receiving increasing popular and academic attention. Much recent\nwork has focused on developing algorithmic tools to assess and mitigate such\nunfairness. However, there is little work on enhancing fairness in graph\nalgorithms. Here, we develop a simple, effective and general method, CrossWalk,\nthat enhances fairness of various graph algorithms, including influence\nmaximization, link prediction and node classification, applied to node\nembeddings. CrossWalk is applicable to any random walk based node\nrepresentation learning algorithm, such as DeepWalk and Node2Vec. The key idea\nis to bias random walks to cross group boundaries, by upweighting edges which\n(1) are closer to the groups' peripheries or (2) connect different groups in\nthe network. CrossWalk pulls nodes that are near groups' peripheries towards\ntheir neighbors from other groups in the embedding space, while preserving the\nnecessary structural information from the graph. Extensive experiments show the\neffectiveness of our algorithm to enhance fairness in various graph algorithms,\nincluding influence maximization, link prediction and node classification in\nsynthetic and real networks, with only a very small decrease in performance.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 14:45:34 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Khajehnejad", "Ahmad", ""], ["Khajehnejad", "Moein", ""], ["Babaei", "Mahmoudreza", ""], ["Gummadi", "Krishna P.", ""], ["Weller", "Adrian", ""], ["Mirzasoleiman", "Baharan", ""]]}, {"id": "2105.02761", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Petar Veli\\v{c}kovi\\'c, Charles Blundell", "title": "Neural Algorithmic Reasoning", "comments": "Accepted as an Opinion paper in Patterns. 7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms have been fundamental to recent global technological advances and,\nin particular, they have been the cornerstone of technical advances in one\nfield rapidly being applied to another. We argue that algorithms possess\nfundamentally different qualities to deep learning methods, and this strongly\nsuggests that, were deep learning methods better able to mimic algorithms,\ngeneralisation of the sort seen with algorithms would become possible with deep\nlearning -- something far out of the reach of current machine learning methods.\nFurthermore, by representing elements in a continuous space of learnt\nalgorithms, neural networks are able to adapt known algorithms more closely to\nreal-world problems, potentially finding more efficient and pragmatic solutions\nthan those proposed by human computer scientists.\n  Here we present neural algorithmic reasoning -- the art of building neural\nnetworks that are able to execute algorithmic computation -- and provide our\nopinion on its transformative potential for running classical algorithms on\ninputs previously considered inaccessible to them.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 15:33:57 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Veli\u010dkovi\u0107", "Petar", ""], ["Blundell", "Charles", ""]]}, {"id": "2105.02796", "submitter": "Christian Fiedler", "authors": "Christian Fiedler, Carsten W. Scherer, Sebastian Trimpe", "title": "Practical and Rigorous Uncertainty Bounds for Gaussian Process\n  Regression", "comments": "Contains supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Process Regression is a popular nonparametric regression method\nbased on Bayesian principles that provides uncertainty estimates for its\npredictions. However, these estimates are of a Bayesian nature, whereas for\nsome important applications, like learning-based control with safety\nguarantees, frequentist uncertainty bounds are required. Although such rigorous\nbounds are available for Gaussian Processes, they are too conservative to be\nuseful in applications. This often leads practitioners to replacing these\nbounds by heuristics, thus breaking all theoretical guarantees. To address this\nproblem, we introduce new uncertainty bounds that are rigorous, yet practically\nuseful at the same time. In particular, the bounds can be explicitly evaluated\nand are much less conservative than state of the art results. Furthermore, we\nshow that certain model misspecifications lead to only graceful degradation. We\ndemonstrate these advantages and the usefulness of our results for\nlearning-based control with numerical examples.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 16:41:04 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Fiedler", "Christian", ""], ["Scherer", "Carsten W.", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "2105.02816", "submitter": "Aria Nosratinia", "authors": "Mohammad Esmaeili and Hussein Metwaly Saad and Aria Nosratinia", "title": "Semidefinite Programming for Community Detection with Side Information", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG cs.SI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper produces an efficient Semidefinite Programming (SDP) solution for\ncommunity detection that incorporates non-graph data, which in this context is\nknown as side information. SDP is an efficient solution for standard community\ndetection on graphs. We formulate a semi-definite relaxation for the maximum\nlikelihood estimation of node labels, subject to observing both graph and\nnon-graph data. This formulation is distinct from the SDP solution of standard\ncommunity detection, but maintains its desirable properties. We calculate the\nexact recovery threshold for three types of non-graph information, which in\nthis paper are called side information: partially revealed labels, noisy\nlabels, as well as multiple observations (features) per node with arbitrary but\nfinite cardinality. We find that SDP has the same exact recovery threshold in\nthe presence of side information as maximum likelihood with side information.\nThus, the methods developed herein are computationally efficient as well as\nasymptotically accurate for the solution of community detection in the presence\nof side information. Simulations show that the asymptotic results of this paper\ncan also shed light on the performance of SDP for graphs of modest size.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 17:00:34 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Esmaeili", "Mohammad", ""], ["Saad", "Hussein Metwaly", ""], ["Nosratinia", "Aria", ""]]}, {"id": "2105.02831", "submitter": "Peter Hinz", "authors": "Peter Hinz", "title": "The layer-wise L1 Loss Landscape of Neural Nets is more complex around\n  local minima", "comments": "4 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For fixed training data and network parameters in the other layers the L1\nloss of a ReLU neural network as a function of the first layer's parameters is\na piece-wise affine function. We use the Deep ReLU Simplex algorithm to\niteratively minimize the loss monotonically on adjacent vertices and analyze\nthe trajectory of these vertex positions. We empirically observe that in a\nneighbourhood around a local minimum, the iterations behave differently such\nthat conclusions on loss level and proximity of the local minimum can be made\nbefore it has been found: Firstly the loss seems to decay exponentially slow at\niterated adjacent vertices such that the loss level at the local minimum can be\nestimated from the loss levels of subsequently iterated vertices, and secondly\nwe observe a strong increase of the vertex density around local minima. This\ncould have far-reaching consequences for the design of new gradient-descent\nalgorithms that might improve convergence rate by exploiting these facts.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 17:18:44 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Hinz", "Peter", ""]]}, {"id": "2105.02845", "submitter": "So Takao", "authors": "Alessandro Barp, So Takao, Michael Betancourt, Alexis Arnaudon, Mark\n  Girolami", "title": "A Unifying and Canonical Description of Measure-Preserving Diffusions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.DG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A complete recipe of measure-preserving diffusions in Euclidean space was\nrecently derived unifying several MCMC algorithms into a single framework. In\nthis paper, we develop a geometric theory that improves and generalises this\nconstruction to any manifold. We thereby demonstrate that the completeness\nresult is a direct consequence of the topology of the underlying manifold and\nthe geometry induced by the target measure $P$; there is no need to introduce\nother structures such as a Riemannian metric, local coordinates, or a reference\nmeasure. Instead, our framework relies on the intrinsic geometry of $P$ and in\nparticular its canonical derivative, the deRham rotationnel, which allows us to\nparametrise the Fokker--Planck currents of measure-preserving diffusions using\npotentials. The geometric formalism can easily incorporate constraints and\nsymmetries, and deliver new important insights, for example, a new complete\nrecipe of Langevin-like diffusions that are suited to the construction of\nsamplers. We also analyse the reversibility and dissipative properties of the\ndiffusions, the associated deterministic flow on the space of measures, and the\ngeometry of Langevin processes. Our article connects ideas from various\nliterature and frames the theory of measure-preserving diffusions in its\nappropriate mathematical context.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 17:36:55 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Barp", "Alessandro", ""], ["Takao", "So", ""], ["Betancourt", "Michael", ""], ["Arnaudon", "Alexis", ""], ["Girolami", "Mark", ""]]}, {"id": "2105.02873", "submitter": "Bj\\\"orn H Eriksson Mr.", "authors": "Bj\\\"orn H Eriksson", "title": "Contextual Bandits with Sparse Data in Web setting", "comments": "4 pages, 3 tables, review paper, scoping study", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper is a scoping study to identify current methods used in handling\nsparse data with contextual bandits in web settings. The area is highly current\nand state of the art methods are identified. The years 2017-2020 are\ninvestigated, and 19 method articles are identified, and two review articles.\nFive categories of methods are described, making it easy to choose how to\naddress sparse data using contextual bandits with a method available for\nmodification in the specific setting of concern. In addition, each method has\nmultiple techniques to choose from for future evaluation. The problem areas are\nalso mentioned that each article covers. An overall updated understanding of\nsparse data problems using contextual bandits in web settings is given. The\nidentified methods are policy evaluation (off-line and on-line) ,\nhybrid-method, model representation (clusters and deep neural networks),\ndimensionality reduction, and simulation.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 17:58:13 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Eriksson", "Bj\u00f6rn H", ""]]}, {"id": "2105.02936", "submitter": "Edward Raff", "authors": "Edward Raff", "title": "Exact Acceleration of K-Means++ and K-Means$\\|$", "comments": "to appear in the 30th International Joint Conference on Artificial\n  Intelligence (IJCAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-Means++ and its distributed variant K-Means$\\|$ have become de facto tools\nfor selecting the initial seeds of K-means. While alternatives have been\ndeveloped, the effectiveness, ease of implementation, and theoretical grounding\nof the K-means++ and $\\|$ methods have made them difficult to \"best\" from a\nholistic perspective. By considering the limited opportunities within seed\nselection to perform pruning, we develop specialized triangle inequality\npruning strategies and a dynamic priority queue to show the first acceleration\nof K-Means++ and K-Means$\\|$ that is faster in run-time while being\nalgorithmicly equivalent. For both algorithms we are able to reduce distance\ncomputations by over $500\\times$. For K-means++ this results in up to a\n17$\\times$ speedup in run-time and a $551\\times$ speedup for K-means$\\|$. We\nachieve this with simple, but carefully chosen, modifications to known\ntechniques which makes it easy to integrate our approach into existing\nimplementations of these algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 20:22:55 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Raff", "Edward", ""]]}, {"id": "2105.03058", "submitter": "Mehrnaz Najafi", "authors": "Mehrnaz Najafi and Lifang He and Philip S. Yu", "title": "Error-Robust Multi-View Clustering: Progress, Challenges and\n  Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent advances in data collection from multiple sources, multi-view\ndata has received significant attention. In multi-view data, each view\nrepresents a different perspective of data. Since label information is often\nexpensive to acquire, multi-view clustering has gained growing interest, which\naims to obtain better clustering solution by exploiting complementary and\nconsistent information across all views rather than only using an individual\nview. Due to inevitable sensor failures, data in each view may contain error.\nError often exhibits as noise or feature-specific corruptions or outliers.\nMulti-view data may contain any or combination of these error types. Blindly\nclustering multi-view data i.e., without considering possible error in view(s)\ncould significantly degrade the performance. The goal of error-robust\nmulti-view clustering is to obtain useful outcome even if the multi-view data\nis corrupted. Existing error-robust multi-view clustering approaches with\nexplicit error removal formulation can be structured into five broad research\ncategories - sparsity norm based approaches, graph based methods, subspace\nbased learning approaches, deep learning based methods and hybrid approaches,\nthis survey summarizes and reviews recent advances in error-robust clustering\nfor multi-view data. Finally, we highlight the challenges and provide future\nresearch opportunities.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 04:03:02 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Najafi", "Mehrnaz", ""], ["He", "Lifang", ""], ["Yu", "Philip S.", ""]]}, {"id": "2105.03067", "submitter": "Suyash Gupta", "authors": "Suyash Gupta and Dominik Rothenh\\\"ausler", "title": "The $s$-value: evaluating stability with respect to distributional\n  shifts", "comments": "43 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common statistical measures of uncertainty such as $p$-values and confidence\nintervals quantify the uncertainty due to sampling, that is, the uncertainty\ndue to not observing the full population. However, sampling is not the only\nsource of uncertainty. In practice, distributions change between locations and\nacross time. This makes it difficult to gather knowledge that transfers across\ndata sets. We propose a measure of uncertainty or instability that quantifies\nthe distributional instability of a statistical parameter with respect to\nKullback-Leibler divergence, that is, the sensitivity of the parameter under\ngeneral distributional perturbations within a Kullback-Leibler divergence ball.\nIn addition, we propose measures to elucidate the instability of parameters\nwith respect to directional or variable-specific shifts. Measuring instability\nwith respect to directional shifts can be used to detect the type of shifts a\nparameter is sensitive to. We discuss how such knowledge can inform data\ncollection for improved estimation of statistical parameters under shifted\ndistributions. We evaluate the performance of the proposed measure on real data\nand show that it can elucidate the distributional (in-)stability of a parameter\nwith respect to certain shifts and can be used to improve the accuracy of\nestimation under shifted distributions.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 05:18:12 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 00:39:28 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Gupta", "Suyash", ""], ["Rothenh\u00e4usler", "Dominik", ""]]}, {"id": "2105.03109", "submitter": "Marius Hobbhahn", "authors": "Marius Hobbhahn, Philipp Hennig", "title": "Laplace Matching for fast Approximate Inference in Generalized Linear\n  Models", "comments": "Currently under review at JMLR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian inference in generalized linear models (GLMs), i.e.~Gaussian\nregression with non-Gaussian likelihoods, is generally non-analytic and\nrequires computationally expensive approximations, such as sampling or\nvariational inference. We propose an approximate inference framework primarily\ndesigned to be computationally cheap while still achieving high approximation\nquality. The concept, which we call \\emph{Laplace Matching}, involves\nclosed-form, approximate, bi-directional transformations between the parameter\nspaces of exponential families. These are constructed from Laplace\napproximations under custom-designed basis transformations. The mappings can\nthen be leveraged to effectively turn a latent Gaussian distribution into a\nconjugate prior for a rich class of observable variables. This effectively\nturns inference in GLMs into conjugate inference (with small approximation\nerrors). We empirically evaluate the method in two different GLMs, showing\napproximation quality comparable to state-of-the-art approximate inference\ntechniques at a drastic reduction in computational cost. More specifically, our\nmethod has a cost comparable to the \\emph{very first} step of the iterative\noptimization usually employed in standard GLM inference.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 08:25:17 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Hobbhahn", "Marius", ""], ["Hennig", "Philipp", ""]]}, {"id": "2105.03153", "submitter": "Matth\\\"aus Kleindessner", "authors": "Matth\\\"aus Kleindessner, Samira Samadi, Muhammad Bilal Zafar,\n  Krishnaram Kenthapadi, Chris Russell", "title": "Pairwise Fairness for Ordinal Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate the study of fairness for ordinal regression, or ordinal\nclassification. We adapt two fairness notions previously considered in fair\nranking and propose a strategy for training a predictor that is approximately\nfair according to either notion. Our predictor consists of a threshold model,\ncomposed of a scoring function and a set of thresholds, and our strategy is\nbased on a reduction to fair binary classification for learning the scoring\nfunction and local search for choosing the thresholds. We can control the\nextent to which we care about the accuracy vs the fairness of the predictor via\na parameter. In extensive experiments we show that our strategy allows us to\neffectively explore the accuracy-vs-fairness trade-off and that it often\ncompares favorably to \"unfair\" state-of-the-art methods for ordinal regression\nin that it yields predictors that are only slightly less accurate, but\nsignificantly more fair.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 10:33:42 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Kleindessner", "Matth\u00e4us", ""], ["Samadi", "Samira", ""], ["Zafar", "Muhammad Bilal", ""], ["Kenthapadi", "Krishnaram", ""], ["Russell", "Chris", ""]]}, {"id": "2105.03172", "submitter": "Hlynur Dav{\\i}{\\dh} Hlynsson", "authors": "Hlynur Dav\\'i{\\dh} Hlynsson, Laurenz Wiskott", "title": "Reward prediction for representation learning and reward shaping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the fundamental challenges in reinforcement learning (RL) is the one\nof data efficiency: modern algorithms require a very large number of training\nsamples, especially compared to humans, for solving environments with\nhigh-dimensional observations. The severity of this problem is increased when\nthe reward signal is sparse. In this work, we propose learning a state\nrepresentation in a self-supervised manner for reward prediction. The reward\npredictor learns to estimate either a raw or a smoothed version of the true\nreward signal in environment with a single, terminating, goal state. We augment\nthe training of out-of-the-box RL agents by shaping the reward using our reward\npredictor during policy learning. Using our representation for preprocessing\nhigh-dimensional observations, as well as using the predictor for reward\nshaping, is shown to significantly enhance Actor Critic using\nKronecker-factored Trust Region and Proximal Policy Optimization in single-goal\nenvironments with visual inputs.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 11:29:32 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Hlynsson", "Hlynur Dav\u00ed\u00f0", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "2105.03173", "submitter": "Luigi Riso", "authors": "Luigi Riso", "title": "Use of High Dimensional Modeling for automatic variables selection: the\n  best path algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new algorithm for automatic variables selection. In\nparticular, using the Graphical Models properties it is possible to develop a\nmethod that can be used in the contest of large dataset. The advantage of this\nalgorithm is that can be combined with different forecasting models. In this\nresearch we have used the OLS method and we have compared the result with the\nLASSO method.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 11:33:06 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Riso", "Luigi", ""]]}, {"id": "2105.03248", "submitter": "David Heckerman", "authors": "Dan Geiger and David Heckerman", "title": "Parameter Priors for Directed Acyclic Graphical Models and the\n  Characterization of Several Probability Distributions", "comments": "This version has improved pointers to the literature. arXiv admin\n  note: substantial text overlap with arXiv:1301.6697", "journal-ref": "The Annals of Statistics, 30: 1412-1440, 2002", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop simple methods for constructing parameter priors for model choice\namong Directed Acyclic Graphical (DAG) models. In particular, we introduce\nseveral assumptions that permit the construction of parameter priors for a\nlarge number of DAG models from a small set of assessments. We then present a\nmethod for directly computing the marginal likelihood of every DAG model given\na random sample with no missing observations. We apply this methodology to\nGaussian DAG models which consist of a recursive set of linear regression\nmodels. We show that the only parameter prior for complete Gaussian DAG models\nthat satisfies our assumptions is the normal-Wishart distribution. Our analysis\nis based on the following new characterization of the Wishart distribution: let\n$W$ be an $n \\times n$, $n \\ge 3$, positive-definite symmetric matrix of random\nvariables and $f(W)$ be a pdf of $W$. Then, f$(W)$ is a Wishart distribution if\nand only if $W_{11} - W_{12} W_{22}^{-1} W'_{12}$ is independent of\n$\\{W_{12},W_{22}\\}$ for every block partitioning $W_{11},W_{12}, W'_{12},\nW_{22}$ of $W$. Similar characterizations of the normal and normal-Wishart\ndistributions are provided as well.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 18:01:11 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 19:44:37 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Geiger", "Dan", ""], ["Heckerman", "David", ""]]}, {"id": "2105.03308", "submitter": "Daniel Rudolf", "authors": "Viacheslav Natarovskii, Daniel Rudolf, Bj\\\"orn Sprungk", "title": "Geometric convergence of elliptical slice sampling", "comments": "13 pages, 2 figures, Accepted in the Proceedings of the 38th\n  International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For Bayesian learning, given likelihood function and Gaussian prior, the\nelliptical slice sampler, introduced by Murray, Adams and MacKay 2010, provides\na tool for the construction of a Markov chain for approximate sampling of the\nunderlying posterior distribution. Besides of its wide applicability and\nsimplicity its main feature is that no tuning is necessary. Under weak\nregularity assumptions on the posterior density we show that the corresponding\nMarkov chain is geometrically ergodic and therefore yield qualitative\nconvergence guarantees. We illustrate our result for Gaussian posteriors as\nthey appear in Gaussian process regression, as well as in a setting of a\nmulti-modal distribution. Remarkably, our numerical experiments indicate a\ndimension-independent performance of elliptical slice sampling even in\nsituations where our ergodicity result does not apply.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 15:00:30 GMT"}, {"version": "v2", "created": "Tue, 6 Jul 2021 07:55:37 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 19:13:43 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Natarovskii", "Viacheslav", ""], ["Rudolf", "Daniel", ""], ["Sprungk", "Bj\u00f6rn", ""]]}, {"id": "2105.03310", "submitter": "Yuan Pu", "authors": "Yuan Pu, Shaochen Wang, Xin Yao, Bin Li", "title": "Context-Based Soft Actor Critic for Environments with Non-stationary\n  Dynamics", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The performance of deep reinforcement learning methods prone to degenerate\nwhen applied to environments with non-stationary dynamics. In this paper, we\nutilize the latent context recurrent encoders motivated by recent Meta-RL\nmaterials, and propose the Latent Context-based Soft Actor Critic (LC-SAC)\nmethod to address aforementioned issues. By minimizing the contrastive\nprediction loss function, the learned context variables capture the information\nof the environment dynamics and the recent behavior of the agent. Then combined\nwith the soft policy iteration paradigm, the LC-SAC method alternates between\nsoft policy evaluation and soft policy improvement until it converges to the\noptimal policy. Experimental results show that the performance of LC-SAC is\nsignificantly better than the SAC algorithm on the MetaWorld ML1 tasks whose\ndynamics changes drasticly among different episodes, and is comparable to SAC\non the continuous control benchmark task MuJoCo whose dynamics changes slowly\nor doesn't change between different episodes. In addition, we also conduct\nrelevant experiments to determine the impact of different hyperparameter\nsettings on the performance of the LC-SAC algorithm and give the reasonable\nsuggestions of hyperparameter setting.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 15:00:59 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 09:25:53 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Pu", "Yuan", ""], ["Wang", "Shaochen", ""], ["Yao", "Xin", ""], ["Li", "Bin", ""]]}, {"id": "2105.03361", "submitter": "Rahul Parhi", "authors": "Rahul Parhi, Robert D. Nowak", "title": "What Kinds of Functions do Deep Neural Networks Learn? Insights from\n  Variational Spline Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a variational framework to understand the properties of functions\nlearned by deep neural networks with ReLU activation functions fit to data. We\npropose a new function space, which is reminiscent of classical bounded\nvariation spaces, that captures the compositional structure associated with\ndeep neural networks. We derive a representer theorem showing that deep ReLU\nnetworks are solutions to regularized data fitting problems in this function\nspace. The function space consists of compositions of functions from the\n(non-reflexive) Banach spaces of second-order bounded variation in the Radon\ndomain. These are Banach spaces with sparsity-promoting norms, giving insight\ninto the role of sparsity in deep neural networks. The neural network solutions\nhave skip connections and rank bounded weight matrices, providing new\ntheoretical support for these common architectural choices. The variational\nproblem we study can be recast as a finite-dimensional neural network training\nproblem with regularization schemes related to the notions of weight decay and\npath-norm regularization. Finally, our analysis builds on techniques from\nvariational spline theory, providing new connections between deep neural\nnetworks and splines.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 16:18:22 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 17:02:03 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Parhi", "Rahul", ""], ["Nowak", "Robert D.", ""]]}, {"id": "2105.03396", "submitter": "Dongbang Yuan", "authors": "Dongbang Yuan and Irina Gaynanova", "title": "Double-matched matrix decomposition for multi-view data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of extracting joint and individual signals from\nmulti-view data, that is data collected from different sources on matched\nsamples. While existing methods for multi-view data decomposition explore\nsingle matching of data by samples, we focus on double-matched multi-view data\n(matched by both samples and source features). Our motivating example is the\nmiRNA data collected from both primary tumor and normal tissues of the same\nsubjects; the measurements from two tissues are thus matched both by subjects\nand by miRNAs. Our proposed double-matched matrix decomposition allows to\nsimultaneously extract joint and individual signals across subjects, as well as\njoint and individual signals across miRNAs. Our estimation approach takes\nadvantage of double-matching by formulating a new type of optimization problem\nwith explicit row space and column space constraints, for which we develop an\nefficient iterative algorithm. Numerical studies indicate that taking advantage\nof double-matching leads to superior signal estimation performance compared to\nexisting multi-view data decomposition based on single-matching. We apply our\nmethod to miRNA data as well as data from the English Premier League soccer\nmatches, and find joint and individual multi-view signals that align with\ndomain specific knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 17:09:57 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Yuan", "Dongbang", ""], ["Gaynanova", "Irina", ""]]}, {"id": "2105.03397", "submitter": "Christian Fiedler", "authors": "Christian Fiedler, Carsten W. Scherer, Sebastian Trimpe", "title": "Learning-enhanced robust controller synthesis with rigorous statistical\n  and control-theoretic guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The combination of machine learning with control offers many opportunities,\nin particular for robust control. However, due to strong safety and reliability\nrequirements in many real-world applications, providing rigorous statistical\nand control-theoretic guarantees is of utmost importance, yet difficult to\nachieve for learning-based control schemes. We present a general framework for\nlearning-enhanced robust control that allows for systematic integration of\nprior engineering knowledge, is fully compatible with modern robust control and\nstill comes with rigorous and practically meaningful guarantees. Building on\nthe established Linear Fractional Representation and Integral Quadratic\nConstraints framework, we integrate Gaussian Process Regression as a learning\ncomponent and state-of-the-art robust controller synthesis. In a concrete\nrobust control example, our approach is demonstrated to yield improved\nperformance with more data, while guarantees are maintained throughout.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 17:11:33 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Fiedler", "Christian", ""], ["Scherer", "Carsten W.", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "2105.03418", "submitter": "Sam Foreman", "authors": "Sam Foreman, Xiao-Yong Jin, and James C. Osborn", "title": "Deep Learning Hamiltonian Monte Carlo", "comments": "8 pages, 7 figures, Published as a workshop paper at ICLR 2021 SimDL\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-lat cond-mat.stat-mech cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We generalize the Hamiltonian Monte Carlo algorithm with a stack of neural\nnetwork layers and evaluate its ability to sample from different topologies in\na two dimensional lattice gauge theory. We demonstrate that our model is able\nto successfully mix between modes of different topologies, significantly\nreducing the computational cost required to generated independent gauge field\nconfigurations. Our implementation is available at\nhttps://github.com/saforem2/l2hmc-qcd .\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 17:50:18 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Foreman", "Sam", ""], ["Jin", "Xiao-Yong", ""], ["Osborn", "James C.", ""]]}, {"id": "2105.03425", "submitter": "Xiuyuan Cheng", "authors": "Xiuyuan Cheng, Yao Xie", "title": "Kernel MMD Two-Sample Tests for Manifold Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present a study of kernel MMD two-sample test statistics in the manifold\nsetting, assuming the high-dimensional observations are close to a\nlow-dimensional manifold. We characterize the property of the test (level and\npower) in relation to the kernel bandwidth, the number of samples, and the\nintrinsic dimensionality of the manifold. Specifically, we show that when data\ndensities are supported on a $d$-dimensional sub-manifold $\\mathcal{M}$\nembedded in an $m$-dimensional space, the kernel MMD two-sample test for data\nsampled from a pair of distributions $(p, q)$ that are H\\\"older with order\n$\\beta$ is consistent and powerful when the number of samples $n$ is greater\nthan $\\delta_2(p,q)^{-2-d/\\beta}$ up to certain constant, where $\\delta_2$ is\nthe squared $\\ell_2$-divergence between two distributions on manifold.\nMoreover, to achieve testing consistency under this scaling of $n$, our theory\nsuggests that the kernel bandwidth $\\gamma$ scales with $n^{-1/(d+2\\beta)}$.\nThese results indicate that the kernel MMD two-sample test does not have a\ncurse-of-dimensionality when the data lie on the low-dimensional manifold. We\ndemonstrate the validity of our theory and the property of the MMD test for\nmanifold data using several numerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 17:56:45 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Cheng", "Xiuyuan", ""], ["Xie", "Yao", ""]]}, {"id": "2105.03491", "submitter": "Gregor Bachmann", "authors": "Gregor Bachmann, Seyed-Mohsen Moosavi-Dezfooli, Thomas Hofmann", "title": "Uniform Convergence, Adversarial Spheres and a Simple Remedy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has cast doubt on the general framework of uniform convergence\nand its ability to explain generalization in neural networks. By considering a\nspecific dataset, it was observed that a neural network completely\nmisclassifies a projection of the training data (adversarial set), rendering\nany existing generalization bound based on uniform convergence vacuous. We\nprovide an extensive theoretical investigation of the previously studied data\nsetting through the lens of infinitely-wide models. We prove that the Neural\nTangent Kernel (NTK) also suffers from the same phenomenon and we uncover its\norigin. We highlight the important role of the output bias and show\ntheoretically as well as empirically how a sensible choice completely mitigates\nthe problem. We identify sharp phase transitions in the accuracy on the\nadversarial set and study its dependency on the training sample size. As a\nresult, we are able to characterize critical sample sizes beyond which the\neffect disappears. Moreover, we study decompositions of a neural network into a\nclean and noisy part by considering its canonical decomposition into its\ndifferent eigenfunctions and show empirically that for too small bias the\nadversarial phenomenon still persists.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 20:23:01 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Bachmann", "Gregor", ""], ["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Hofmann", "Thomas", ""]]}, {"id": "2105.03527", "submitter": "Mingrui Zhang", "authors": "Mingrui Zhang", "title": "Scalable Projection-Free Optimization", "comments": "dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a projection-free algorithm, Frank-Wolfe (FW) method, also known as\nconditional gradient, has recently received considerable attention in the\nmachine learning community. In this dissertation, we study several topics on\nthe FW variants for scalable projection-free optimization.\n  We first propose 1-SFW, the first projection-free method that requires only\none sample per iteration to update the optimization variable and yet achieves\nthe best known complexity bounds for convex, non-convex, and monotone\nDR-submodular settings. Then we move forward to the distributed setting, and\ndevelop Quantized Frank-Wolfe (QFW), a general communication-efficient\ndistributed FW framework for both convex and non-convex objective functions. We\nstudy the performance of QFW in two widely recognized settings: 1) stochastic\noptimization and 2) finite-sum optimization. Finally, we propose Black-Box\nContinuous Greedy, a derivative-free and projection-free algorithm, that\nmaximizes a monotone continuous DR-submodular function over a bounded convex\nbody in Euclidean space.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 22:27:18 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhang", "Mingrui", ""]]}, {"id": "2105.03584", "submitter": "Alexander Scheinker", "authors": "Alexander Scheinker, Frederick Cropp, Sergio Paiagua, Daniele\n  Filippetto", "title": "Adaptive Latent Space Tuning for Non-Stationary Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.acc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Powerful deep learning tools, such as convolutional neural networks (CNN),\nare able to learn the input-output relationships of large complicated systems\ndirectly from data. Encoder-decoder deep CNNs are able to extract features\ndirectly from images, mix them with scalar inputs within a general\nlow-dimensional latent space, and then generate new complex 2D outputs which\nrepresent complex physical phenomenon. One important challenge faced by deep\nlearning methods is large non-stationary systems whose characteristics change\nquickly with time for which re-training is not feasible. In this paper we\npresent a method for adaptive tuning of the low-dimensional latent space of\ndeep encoder-decoder style CNNs based on real-time feedback to quickly\ncompensate for unknown and fast distribution shifts. We demonstrate our\napproach for predicting the properties of a time-varying charged particle beam\nin a particle accelerator whose components (accelerating electric fields and\nfocusing magnetic fields) are also quickly changing with time.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 03:50:45 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 05:02:00 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 13:03:11 GMT"}, {"version": "v4", "created": "Sun, 6 Jun 2021 16:45:26 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Scheinker", "Alexander", ""], ["Cropp", "Frederick", ""], ["Paiagua", "Sergio", ""], ["Filippetto", "Daniele", ""]]}, {"id": "2105.03594", "submitter": "Li-Yang Tan", "authors": "Guy Blanc and Jane Lange and Li-Yang Tan", "title": "Learning stochastic decision trees", "comments": "To appear in ICALP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a quasipolynomial-time algorithm for learning stochastic decision\ntrees that is optimally resilient to adversarial noise. Given an\n$\\eta$-corrupted set of uniform random samples labeled by a size-$s$ stochastic\ndecision tree, our algorithm runs in time\n$n^{O(\\log(s/\\varepsilon)/\\varepsilon^2)}$ and returns a hypothesis with error\nwithin an additive $2\\eta + \\varepsilon$ of the Bayes optimal. An additive\n$2\\eta$ is the information-theoretic minimum.\n  Previously no non-trivial algorithm with a guarantee of $O(\\eta) +\n\\varepsilon$ was known, even for weaker noise models. Our algorithm is\nfurthermore proper, returning a hypothesis that is itself a decision tree;\npreviously no such algorithm was known even in the noiseless setting.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 04:54:12 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Blanc", "Guy", ""], ["Lange", "Jane", ""], ["Tan", "Li-Yang", ""]]}, {"id": "2105.03603", "submitter": "Periyapattana Narayana Prasad Karthik", "authors": "P. N. Karthik and Rajesh Sundaresan", "title": "Learning to Detect an Odd Restless Markov Arm with a Trembling Hand", "comments": "49 pages. A shorter version of this manuscript has been accepted for\n  presentation at the 2021 IEEE International Symposium on Information Theory.\n  This manuscript contains the proofs of all the main results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper studies the problem of finding an anomalous arm in a multi-armed\nbandit when (a) each arm is a finite-state Markov process, and (b) the arms are\nrestless. Here, anomaly means that the transition probability matrix (TPM) of\none of the arms (the odd arm) is different from the common TPM of each of the\nnon-odd arms. The TPMs are unknown to a decision entity that wishes to find the\nindex of the odd arm as quickly as possible, subject to an upper bound on the\nerror probability. We derive a problem instance-specific asymptotic lower bound\non the expected time required to find the odd arm index, where the asymptotics\nis as the error probability vanishes. Further, we devise a policy based on the\nprinciple of certainty equivalence, and demonstrate that under a continuous\nselection assumption and a certain regularity assumption on the TPMs, the\npolicy achieves the lower bound arbitrarily closely. Thus, while the lower\nbound is shown for all problem instances, the upper bound is shown only for\nthose problem instances satisfying the continuous selection and the regularity\nassumptions. Our achievability analysis is based on resolving the\nidentifiability problem in the context of a certain lifted countable-state\ncontrolled Markov process.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 05:53:12 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 08:17:21 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Karthik", "P. N.", ""], ["Sundaresan", "Rajesh", ""]]}, {"id": "2105.03616", "submitter": "Ryuichi Kanoh", "authors": "Ryuichi Kanoh, Tomu Yanabe", "title": "Interpretable Mixture Density Estimation by use of Differentiable\n  Tree-module", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to develop reliable services using machine learning, it is important\nto understand the uncertainty of the model outputs. Often the probability\ndistribution that the prediction target follows has a complex shape, and a\nmixture distribution is assumed as a distribution that uncertainty follows.\nSince the output of mixture density estimation is complicated, its\ninterpretability becomes important when considering its use in real services.\nIn this paper, we propose a method for mixture density estimation that utilizes\nan interpretable tree structure. Further, a fast inference procedure based on\ntime-invariant information cache achieves both high speed and interpretability.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 07:29:58 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Kanoh", "Ryuichi", ""], ["Yanabe", "Tomu", ""]]}, {"id": "2105.03678", "submitter": "Fan Wu", "authors": "Fan Wu, Patrick Rebeschini", "title": "Nearly Minimax-Optimal Rates for Noisy Sparse Phase Retrieval via\n  Early-Stopped Mirror Descent", "comments": "arXiv admin note: text overlap with arXiv:2010.10168", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies early-stopped mirror descent applied to noisy sparse phase\nretrieval, which is the problem of recovering a $k$-sparse signal\n$\\mathbf{x}^\\star\\in\\mathbb{R}^n$ from a set of quadratic Gaussian measurements\ncorrupted by sub-exponential noise. We consider the (non-convex) unregularized\nempirical risk minimization problem and show that early-stopped mirror descent,\nwhen equipped with the hyperbolic entropy mirror map and proper initialization,\nachieves a nearly minimax-optimal rate of convergence, provided the sample size\nis at least of order $k^2$ (modulo logarithmic term) and the minimum (in\nmodulus) non-zero entry of the signal is on the order of\n$\\|\\mathbf{x}^\\star\\|_2/\\sqrt{k}$. Our theory leads to a simple algorithm that\ndoes not rely on explicit regularization or thresholding steps to promote\nsparsity. More generally, our results establish a connection between mirror\ndescent and sparsity in the non-convex problem of noisy sparse phase retrieval,\nadding to the literature on early stopping that has mostly focused on\nnon-sparse, Euclidean, and convex settings via gradient descent. Our proof\ncombines a potential-based analysis of mirror descent with a quantitative\ncontrol on a variational coherence property that we establish along the path of\nmirror descent, up to a prescribed stopping time.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 11:22:19 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Wu", "Fan", ""], ["Rebeschini", "Patrick", ""]]}, {"id": "2105.03692", "submitter": "Charles Jin", "authors": "Charles Jin, Melinda Sun, Martin Rinard", "title": "Provable Guarantees against Data Poisoning Using Self-Expansion and\n  Compatibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A recent line of work has shown that deep networks are highly susceptible to\nbackdoor data poisoning attacks. Specifically, by injecting a small amount of\nmalicious data into the training distribution, an adversary gains the ability\nto control the model's behavior during inference. In this work, we propose an\niterative training procedure for removing poisoned data from the training set.\nOur approach consists of two steps. We first train an ensemble of weak learners\nto automatically discover distinct subpopulations in the training set. We then\nleverage a boosting framework to recover the clean data. Empirically, our\nmethod successfully defends against several state-of-the-art backdoor attacks,\nincluding both clean and dirty label attacks. We also present results from an\nindependent third-party evaluation including a recent \\textit{adaptive}\npoisoning adversary. The results indicate our approach is competitive with\nexisting defenses against backdoor attacks on deep neural networks, and\nsignificantly outperforms the state-of-the-art in several scenarios.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 13:01:42 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Jin", "Charles", ""], ["Sun", "Melinda", ""], ["Rinard", "Martin", ""]]}, {"id": "2105.03705", "submitter": "Ding Liu", "authors": "Zhanghao Zhouyin, Ding Liu", "title": "Understanding Neural Networks with Logarithm Determinant Entropy\n  Estimator", "comments": "15pages,22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding the informative behaviour of deep neural networks is challenged\nby misused estimators and the complexity of network structure, which leads to\ninconsistent observations and diversified interpretation. Here we propose the\nLogDet estimator -- a reliable matrix-based entropy estimator that approximates\nShannon differential entropy. We construct informative measurements based on\nLogDet estimator, verify our method with comparable experiments and utilize it\nto analyse neural network behaviour. Our results demonstrate the LogDet\nestimator overcomes the drawbacks that emerge from highly diverse and\ndegenerated distribution thus is reliable to estimate entropy in neural\nnetworks. The Network analysis results also find a functional distinction\nbetween shallow and deeper layers, which can help understand the compression\nphenomenon in the Information bottleneck theory of neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 14:07:58 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhouyin", "Zhanghao", ""], ["Liu", "Ding", ""]]}, {"id": "2105.03714", "submitter": "Shubham Gupta", "authors": "Shubham Gupta and Ambedkar Dukkipati", "title": "Protecting Individual Interests across Clusters: Spectral Clustering\n  with Guarantees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies related to fairness in machine learning have recently gained traction\ndue to its ever-expanding role in high-stakes decision making. For example, it\nmay be desirable to ensure that all clusters discovered by an algorithm have\nhigh gender diversity. Previously, these problems have been studied under a\nsetting where sensitive attributes, with respect to which fairness conditions\nimpose diversity across clusters, are assumed to be observable; hence,\nprotected groups are readily available. Most often, this may not be true, and\ndiversity or individual interests can manifest as an intrinsic or latent\nfeature of a social network. For example, depending on latent sensitive\nattributes, individuals interact with each other and represent each other's\ninterests, resulting in a network, which we refer to as a representation graph.\nMotivated by this, we propose an individual fairness criterion for clustering a\ngraph $\\mathcal{G}$ that requires each cluster to contain an adequate number of\nmembers connected to the individual under a representation graph $\\mathcal{R}$.\nWe devise a spectral clustering algorithm to find fair clusters under a given\nrepresentation graph. We further propose a variant of the stochastic block\nmodel and establish our algorithm's weak consistency under this model. Finally,\nwe present experimental results to corroborate our theoretical findings.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 15:03:25 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Gupta", "Shubham", ""], ["Dukkipati", "Ambedkar", ""]]}, {"id": "2105.03746", "submitter": "Huangjie Zheng", "authors": "Huangjie Zheng, Xu Chen, Jiangchao Yao, Hongxia Yang, Chunyuan Li, Ya\n  Zhang, Hao Zhang, Ivor Tsang, Jingren Zhou, Mingyuan Zhou", "title": "Contrastive Attraction and Contrastive Repulsion for Representation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrastive learning (CL) is effective in learning data representations\nwithout label supervision, where the encoder needs to contrast each positive\nsample over multiple negative samples via a one-vs-many softmax cross-entropy\nloss. However, conventional CL is sensitive to how many negative samples are\nincluded and how they are selected. Proposed in this paper is a doubly CL\nstrategy that contrasts positive samples and negative ones within themselves\nseparately. We realize this strategy with contrastive attraction and\ncontrastive repulsion (CACR) makes the query not only exert a greater force to\nattract more distant positive samples but also do so to repel closer negative\nsamples. Theoretical analysis reveals the connection between CACR and CL from\nthe perspectives of both positive attraction and negative repulsion and shows\nthe benefits in both efficiency and robustness brought by separately\ncontrasting within the sampled positive and negative pairs. Extensive\nlarge-scale experiments on standard vision tasks show that CACR not only\nconsistently outperforms existing CL methods on benchmark datasets in\nrepresentation learning, but also provides interpretable contrastive weights,\ndemonstrating the efficacy of the proposed doubly contrastive strategy.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 17:25:08 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 04:12:54 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Zheng", "Huangjie", ""], ["Chen", "Xu", ""], ["Yao", "Jiangchao", ""], ["Yang", "Hongxia", ""], ["Li", "Chunyuan", ""], ["Zhang", "Ya", ""], ["Zhang", "Hao", ""], ["Tsang", "Ivor", ""], ["Zhou", "Jingren", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "2105.03800", "submitter": "Rafael Lima Goncalves de", "authors": "Rafael Lima", "title": "Fine-Grained $\\epsilon$-Margin Closed-Form Stabilization of Parametric\n  Hawkes Processes", "comments": "Presented as a RobustML workshop paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hawkes Processes have undergone increasing popularity as default tools for\nmodeling self- and mutually exciting interactions of discrete events in\ncontinuous-time event streams. A Maximum Likelihood Estimation (MLE)\nunconstrained optimization procedure over parametrically assumed forms of the\ntriggering kernels of the corresponding intensity function are a widespread\ncost-effective modeling strategy, particularly suitable for data with few\nand/or short sequences. However, the MLE optimization lacks guarantees, except\nfor strong assumptions on the parameters of the triggering kernels, and may\nlead to instability of the resulting parameters .In the present work, we show\nhow a simple stabilization procedure improves the performance of the MLE\noptimization without these overly restrictive assumptions.This stabilized\nversion of the MLE is shown to outperform traditional methods over sequences of\nseveral different lengths.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 23:49:09 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Lima", "Rafael", ""]]}, {"id": "2105.03810", "submitter": "Eric Auerbach", "authors": "Eric Auerbach and Max Tabord-Meehan", "title": "The Local Approach to Causal Inference under Network Interference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.ST stat.ME stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new unified framework for causal inference when outcomes depend\non how agents are linked in a social or economic network. Such network\ninterference describes a large literature on treatment spillovers, social\ninteractions, social learning, information diffusion, social capital formation,\nand more. Our approach works by first characterizing how an agent is linked in\nthe network using the configuration of other agents and connections nearby as\nmeasured by path distance. The impact of a policy or treatment assignment is\nthen learned by pooling outcome data across similarly configured agents. In the\npaper, we propose a new nonparametric modeling approach and consider two\napplications to causal inference. The first application is to testing policy\nirrelevance/no treatment effects. The second application is to estimating\npolicy effects/treatment response. We conclude by evaluating the finite-sample\nproperties of our estimation and inference procedures via simulation.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 01:27:05 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 23:37:06 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Auerbach", "Eric", ""], ["Tabord-Meehan", "Max", ""]]}, {"id": "2105.03855", "submitter": "Seung Jee Yang", "authors": "Seung Jee Yang, Kyung Joon Cha", "title": "GMOTE: Gaussian based minority oversampling technique for imbalanced\n  classification adapting tail probability of outliers", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classification of imbalanced data is one of the common problems in the recent\nfield of data mining. Imbalanced data substantially affects the performance of\nstandard classification models. Data-level approaches mainly use the\noversampling methods to solve the problem, such as synthetic minority\noversampling Technique (SMOTE). However, since the methods such as SMOTE\ngenerate instances by linear interpolation, synthetic data space may look like\na polygonal. Also, the oversampling methods generate outliers of the minority\nclass. In this paper, we proposed Gaussian based minority oversampling\ntechnique (GMOTE) with a statistical perspective for imbalanced datasets. To\navoid linear interpolation and to consider outliers, this proposed method\ngenerates instances by the Gaussian Mixture Model. Motivated by\nclustering-based multivariate Gaussian outlier score (CMGOS), we propose to\nadapt tail probability of instances through the Mahalanobis distance to\nconsider local outliers. The experiment was carried out on a representative set\nof benchmark datasets. The performance of the GMOTE is compared with other\nmethods such as SMOTE. When the GMOTE is combined with classification and\nregression tree (CART) or support vector machine (SVM), it shows better\naccuracy and F1-Score. Experimental results demonstrate the robust performance.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 07:04:37 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Yang", "Seung Jee", ""], ["Cha", "Kyung Joon", ""]]}, {"id": "2105.03863", "submitter": "Wenhao Yang", "authors": "Wenhao Yang, Zhihua Zhang", "title": "Non-asymptotic Performances of Robust Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the non-asymptotic performance of optimal policy on\nrobust value function with true transition dynamics. The optimal robust policy\nis solved from a generative model or offline dataset without access to true\ntransition dynamics. In particular, we consider three different uncertainty\nsets including the $L_1$, $\\chi^2$ and KL balls in both $(s,a)$-rectangular and\n$s$-rectangular assumptions. Our results show that when we assume\n$(s,a)$-rectangular on uncertainty sets, the sample complexity is about\n$\\widetilde{O}\\left(\\frac{|\\mathcal{S}|^2|\\mathcal{A}|}{\\varepsilon^2\\rho^2(1-\\gamma)^4}\\right)$\nin the generative model setting and\n$\\widetilde{O}\\left(\\frac{|\\mathcal{S}|}{\\nu_{\\min}\\varepsilon^2\\rho^2(1-\\gamma)^4}\\right)$\nin the offline dataset setting. While prior works on non-asymptotic\nperformances are restricted with the KL ball and $(s,a)$-rectangular\nassumption, we also extend our results to a more general $s$-rectangular\nassumption, which leads to a larger sample complexity than the\n$(s,a)$-rectangular assumption.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 07:40:45 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Yang", "Wenhao", ""], ["Zhang", "Zhihua", ""]]}, {"id": "2105.03875", "submitter": "Ganesh Del Grosso", "authors": "Ganesh Del Grosso, Georg Pichler, Catuscia Palamidessi, Pablo\n  Piantanida", "title": "Bounding Information Leakage in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine Learning services are being deployed in a large range of applications\nthat make it easy for an adversary, using the algorithm and/or the model, to\ngain access to sensitive data. This paper investigates fundamental bounds on\ninformation leakage. First, we identify and bound the success rate of the\nworst-case membership inference attack, connecting it to the generalization\nerror of the target model. Second, we study the question of how much sensitive\ninformation is stored by the algorithm about the training set and we derive\nbounds on the mutual information between the sensitive attributes and model\nparameters. Although our contributions are mostly of theoretical nature, the\nbounds and involved concepts are of practical relevance. Inspired by our\ntheoretical analysis, we study linear regression and DNN models to illustrate\nhow these bounds can be used to assess the privacy guarantees of ML models.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 08:49:14 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Del Grosso", "Ganesh", ""], ["Pichler", "Georg", ""], ["Palamidessi", "Catuscia", ""], ["Piantanida", "Pablo", ""]]}, {"id": "2105.03879", "submitter": "Dachao Lin", "authors": "Dachao Lin, Zhihua Zhang", "title": "Directional Convergence Analysis under Spherically Symmetric\n  Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the fundamental problem of learning linear predictors (i.e.,\nseparable datasets with zero margin) using neural networks with gradient flow\nor gradient descent. Under the assumption of spherically symmetric data\ndistribution, we show directional convergence guarantees with exact convergence\nrate for two-layer non-linear networks with only two hidden nodes, and (deep)\nlinear networks. Moreover, our discovery is built on dynamic from the\ninitialization without both initial loss and perfect classification constraint\nin contrast to previous works. We also point out and study the challenges in\nfurther strengthening and generalizing our results.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 08:59:58 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Lin", "Dachao", ""], ["Zhang", "Zhihua", ""]]}, {"id": "2105.03962", "submitter": "Arun Verma", "authors": "Arun Verma, Manjesh K. Hanawal", "title": "Stochastic Multi-Armed Bandits with Control Variates", "comments": "26 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper studies a new variant of the stochastic multi-armed bandits\nproblem, where the learner has access to auxiliary information about the arms.\nThe auxiliary information is correlated with the arm rewards, which we treat as\ncontrol variates. In many applications, the arm rewards are a function of some\nexogenous values, whose mean value is known a priori from historical data and\nhence can be used as control variates. We use the control variates to obtain\nmean estimates with smaller variance and tighter confidence bounds. We then\ndevelop an algorithm named UCB-CV that uses improved estimates. We characterize\nthe regret bounds in terms of the correlation between the rewards and control\nvariates. The experiments on synthetic data validate the performance guarantees\nof our proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 15:40:09 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Verma", "Arun", ""], ["Hanawal", "Manjesh K.", ""]]}, {"id": "2105.04001", "submitter": "Alessio Benavoli", "authors": "Alessio Benavoli and Cassio de Campos", "title": "Bayesian Kernelised Test of (In)dependence with Mixed-type Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental task in AI is to assess (in)dependence between mixed-type\nvariables (text, image, sound). We propose a Bayesian kernelised correlation\ntest of (in)dependence using a Dirichlet process model. The new measure of\n(in)dependence allows us to answer some fundamental questions: Based on data,\nare (mixed-type) variables independent? How likely is dependence/independence\nto hold? How high is the probability that two mixed-type variables are more\nthan just weakly dependent? We theoretically show the properties of the\napproach, as well as algorithms for fast computation with it. We empirically\ndemonstrate the effectiveness of the proposed method by analysing its\nperformance and by comparing it with other frequentist and Bayesian approaches\non a range of datasets and tasks with mixed-type variables.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 19:21:43 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Benavoli", "Alessio", ""], ["de Campos", "Cassio", ""]]}, {"id": "2105.04026", "submitter": "Julius Berner", "authors": "Julius Berner, Philipp Grohs, Gitta Kutyniok, Philipp Petersen", "title": "The Modern Mathematics of Deep Learning", "comments": "This review paper will appear as a book chapter in the book \"Theory\n  of Deep Learning\" by Cambridge University Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the new field of mathematical analysis of deep learning. This\nfield emerged around a list of research questions that were not answered within\nthe classical framework of learning theory. These questions concern: the\noutstanding generalization power of overparametrized neural networks, the role\nof depth in deep architectures, the apparent absence of the curse of\ndimensionality, the surprisingly successful optimization performance despite\nthe non-convexity of the problem, understanding what features are learned, why\ndeep architectures perform exceptionally well in physical problems, and which\nfine aspects of an architecture affect the behavior of a learning task in which\nway. We present an overview of modern approaches that yield partial answers to\nthese questions. For selected approaches, we describe the main ideas in more\ndetail.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 21:30:42 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Berner", "Julius", ""], ["Grohs", "Philipp", ""], ["Kutyniok", "Gitta", ""], ["Petersen", "Philipp", ""]]}, {"id": "2105.04046", "submitter": "Minwoo Chae", "authors": "Minwoo Chae, Dongha Kim, Yongdai Kim, Lizhen Lin", "title": "A likelihood approach to nonparametric estimation of a singular\n  distribution using deep generative models", "comments": "33 pages, 12 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We investigate statistical properties of a likelihood approach to\nnonparametric estimation of a singular distribution using deep generative\nmodels. More specifically, a deep generative model is used to model\nhigh-dimensional data that are assumed to concentrate around some\nlow-dimensional structure. Estimating the distribution supported on this\nlow-dimensional structure such as a low-dimensional manifold is challenging due\nto its singularity with respect to the Lebesgue measure in the ambient space.\nIn the considered model, a usual likelihood approach can fail to estimate the\ntarget distribution consistently due to the singularity. We prove that a novel\nand effective solution exists by perturbing the data with an instance noise\nwhich leads to consistent estimation of the underlying distribution with\ndesirable convergence rates. We also characterize the class of distributions\nthat can be efficiently estimated via deep generative models. This class is\nsufficiently general to contain various structured distributions such as\nproduct distributions, classically smooth distributions and distributions\nsupported on a low-dimensional manifold. Our analysis provides some insights on\nhow deep generative models can avoid the curse of dimensionality for\nnonparametric distribution estimation. We conduct thorough simulation study and\nreal data analysis to empirically demonstrate that the proposed data\nperturbation technique improves the estimation performance significantly.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 23:13:58 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Chae", "Minwoo", ""], ["Kim", "Dongha", ""], ["Kim", "Yongdai", ""], ["Lin", "Lizhen", ""]]}, {"id": "2105.04051", "submitter": "Changjian Shui", "authors": "Changjian Shui, Zijian Li, Jiaqi Li, Christian Gagn\\'e, Charles Ling,\n  Boyu Wang", "title": "Aggregating From Multiple Target-Shifted Sources", "comments": null, "journal-ref": "ICML2021", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-source domain adaptation aims at leveraging the knowledge from multiple\ntasks for predicting a related target domain. Hence, a crucial aspect is to\nproperly combine different sources based on their relations. In this paper, we\nanalyzed the problem for aggregating source domains with different label\ndistributions, where most recent source selection approaches fail. Our proposed\nalgorithm differs from previous approaches in two key ways: the model\naggregates multiple sources mainly through the similarity of semantic\nconditional distribution rather than marginal distribution; the model proposes\na \\emph{unified} framework to select relevant sources for three popular\nscenarios, i.e., domain adaptation with limited label on target domain,\nunsupervised domain adaptation and label partial unsupervised domain adaption.\nWe evaluate the proposed method through extensive experiments. The empirical\nresults significantly outperform the baselines.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 23:25:29 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 14:57:01 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Shui", "Changjian", ""], ["Li", "Zijian", ""], ["Li", "Jiaqi", ""], ["Gagn\u00e9", "Christian", ""], ["Ling", "Charles", ""], ["Wang", "Boyu", ""]]}, {"id": "2105.04062", "submitter": "Francois Meyer", "authors": "Daniel Ferguson and Fran\\c{c}ois G. Meyer", "title": "Approximate Fr\\'echet Mean for Data Sets of Sparse Graphs", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To characterize the location (mean, median) of a set of graphs, one needs a\nnotion of centrality that is adapted to metric spaces, since graph sets are not\nEuclidean spaces. A standard approach is to consider the Fr\\'echet mean. In\nthis work, we equip a set of graph with the pseudometric defined by the\n$\\ell_2$ norm between the eigenvalues of their respective adjacency matrix .\nUnlike the edit distance, this pseudometric reveals structural changes at\nmultiple scales, and is well adapted to studying various statistical problems\non sets of graphs. We describe an algorithm to compute an approximation to the\nFr\\'echet mean of a set of undirected unweighted graphs with a fixed size.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 01:13:25 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 00:48:10 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ferguson", "Daniel", ""], ["Meyer", "Fran\u00e7ois G.", ""]]}, {"id": "2105.04087", "submitter": "Pengcheng Ren", "authors": "Pengcheng Ren and Tongjiang Yan", "title": "Latency Analysis of Consortium Blockchained Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A decentralized federated learning architecture is proposed to apply to the\nBusinesses-to-Businesses scenarios by introducing the consortium blockchain in\nthis paper. We introduce a model verification mechanism to ensure the quality\nof local models trained by participators. To analyze the latency of the system,\na latency model is constructed by considering the work flow of the\narchitecture. Finally the experiment results show that our latency model does\nwell in quantifying the actual delays.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 03:14:52 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Ren", "Pengcheng", ""], ["Yan", "Tongjiang", ""]]}, {"id": "2105.04093", "submitter": "Abhishek Aich", "authors": "Abhishek Aich", "title": "Elastic Weight Consolidation (EWC): Nuts and Bolts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this report, we present a theoretical support of the continual learning\nmethod \\textbf{Elastic Weight Consolidation}, introduced in paper titled\n`Overcoming catastrophic forgetting in neural networks'. Being one of the most\ncited paper in regularized methods for continual learning, this report\ndisentangles the underlying concept of the proposed objective function. We\nassume that the reader is aware of the basic terminologies of continual\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 03:48:55 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Aich", "Abhishek", ""]]}, {"id": "2105.04100", "submitter": "Yuzhou Chen", "authors": "Yuzhou Chen, Ignacio Segovia-Dominguez, Yulia R. Gel", "title": "Z-GCNETs: Time Zigzags at Graph Convolutional Networks for Time Series\n  Forecasting", "comments": "Accepted at the International Conference on Machine Learning (ICML)\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There recently has been a surge of interest in developing a new class of deep\nlearning (DL) architectures that integrate an explicit time dimension as a\nfundamental building block of learning and representation mechanisms. In turn,\nmany recent results show that topological descriptors of the observed data,\nencoding information on the shape of the dataset in a topological space at\ndifferent scales, that is, persistent homology of the data, may contain\nimportant complementary information, improving both performance and robustness\nof DL. As convergence of these two emerging ideas, we propose to enhance DL\narchitectures with the most salient time-conditioned topological information of\nthe data and introduce the concept of zigzag persistence into time-aware graph\nconvolutional networks (GCNs). Zigzag persistence provides a systematic and\nmathematically rigorous framework to track the most important topological\nfeatures of the observed data that tend to manifest themselves over time. To\nintegrate the extracted time-conditioned topological descriptors into DL, we\ndevelop a new topological summary, zigzag persistence image, and derive its\ntheoretical stability guarantees. We validate the new GCNs with a time-aware\nzigzag topological layer (Z-GCNETs), in application to traffic forecasting and\nEthereum blockchain price prediction. Our results indicate that Z-GCNET\noutperforms 13 state-of-the-art methods on 4 time series datasets.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 04:01:04 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Chen", "Yuzhou", ""], ["Segovia-Dominguez", "Ignacio", ""], ["Gel", "Yulia R.", ""]]}, {"id": "2105.04130", "submitter": "Sujie Li", "authors": "Sujie Li, Feng Pan, Pengfei Zhou, Pan Zhang", "title": "Boltzmann machines as two-dimensional tensor networks", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.LG physics.comp-ph quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann machines (RBM) and deep Boltzmann machines (DBM) are\nimportant models in machine learning, and recently found numerous applications\nin quantum many-body physics. We show that there are fundamental connections\nbetween them and tensor networks. In particular, we demonstrate that any RBM\nand DBM can be exactly represented as a two-dimensional tensor network. This\nrepresentation gives an understanding of the expressive power of RBM and DBM\nusing entanglement structures of the tensor networks, also provides an\nefficient tensor network contraction algorithm for the computing partition\nfunction of RBM and DBM. Using numerical experiments, we demonstrate that the\nproposed algorithm is much more accurate than the state-of-the-art machine\nlearning methods in estimating the partition function of restricted Boltzmann\nmachines and deep Boltzmann machines, and have potential applications in\ntraining deep Boltzmann machines for general machine learning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 06:14:49 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Li", "Sujie", ""], ["Pan", "Feng", ""], ["Zhou", "Pengfei", ""], ["Zhang", "Pan", ""]]}, {"id": "2105.04143", "submitter": "Dandan Guo", "authors": "Dandan Guo, Ruiying Lu, Bo Chen, Zequn Zeng, Mingyuan Zhou", "title": "Matching Visual Features to Hierarchical Semantic Topics for Image\n  Paragraph Captioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observing a set of images and their corresponding paragraph-captions, a\nchallenging task is to learn how to produce a semantically coherent paragraph\nto describe the visual content of an image. Inspired by recent successes in\nintegrating semantic topics into this task, this paper develops a plug-and-play\nhierarchical-topic-guided image paragraph generation framework, which couples a\nvisual extractor with a deep topic model to guide the learning of a language\nmodel. To capture the correlations between the image and text at multiple\nlevels of abstraction and learn the semantic topics from images, we design a\nvariational inference network to build the mapping from image features to\ntextual captions. To guide the paragraph generation, the learned hierarchical\ntopics and visual features are integrated into the language model, including\nLong Short-Term Memory (LSTM) and Transformer, and jointly optimized.\nExperiments on public dataset demonstrate that the proposed models, which are\ncompetitive with many state-of-the-art approaches in terms of standard\nevaluation metrics, can be used to both distill interpretable multi-layer\ntopics and generate diverse and coherent captions.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 06:55:39 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Guo", "Dandan", ""], ["Lu", "Ruiying", ""], ["Chen", "Bo", ""], ["Zeng", "Zequn", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "2105.04211", "submitter": "Maud Lemercier", "authors": "Maud Lemercier, Cristopher Salvi, Thomas Cass, Edwin V. Bonilla,\n  Theodoros Damoulas, Terry Lyons", "title": "SigGPDE: Scaling Sparse Gaussian Processes on Sequential Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Making predictions and quantifying their uncertainty when the input data is\nsequential is a fundamental learning challenge, recently attracting increasing\nattention. We develop SigGPDE, a new scalable sparse variational inference\nframework for Gaussian Processes (GPs) on sequential data. Our contribution is\ntwofold. First, we construct inducing variables underpinning the sparse\napproximation so that the resulting evidence lower bound (ELBO) does not\nrequire any matrix inversion. Second, we show that the gradients of the GP\nsignature kernel are solutions of a hyperbolic partial differential equation\n(PDE). This theoretical insight allows us to build an efficient\nback-propagation algorithm to optimize the ELBO. We showcase the significant\ncomputational gains of SigGPDE compared to existing methods, while achieving\nstate-of-the-art performance for classification tasks on large datasets of up\nto 1 million multivariate time series.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 09:10:17 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Lemercier", "Maud", ""], ["Salvi", "Cristopher", ""], ["Cass", "Thomas", ""], ["Bonilla", "Edwin V.", ""], ["Damoulas", "Theodoros", ""], ["Lyons", "Terry", ""]]}, {"id": "2105.04240", "submitter": "Jun Lu", "authors": "Jun Lu", "title": "A rigorous introduction for linear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This note is meant to provide an introduction to linear models and the\ntheories behind them. Our goal is to give a rigorous introduction to the\nreaders with prior exposure to ordinary least squares. In machine learning, the\noutput is usually a nonlinear function of the input. Deep learning even aims to\nfind a nonlinear dependence with many layers which require a large amount of\ncomputation. However, most of these algorithms build upon simple linear models.\nWe then describe linear models from different views and find the properties and\ntheories behind the models. The linear model is the main technique in\nregression problems and the primary tool for it is the least squares\napproximation which minimizes a sum of squared errors. This is a natural choice\nwhen we're interested in finding the regression function which minimizes the\ncorresponding expected squared error. We first describe ordinary least squares\nfrom three different points of view upon which we disturb the model with random\nnoise and Gaussian noise. By Gaussian noise, the model gives rise to the\nlikelihood so that we introduce a maximum likelihood estimator. It also\ndevelops some distribution theories for it via this Gaussian disturbance. The\ndistribution theory of least squares will help us answer various questions and\nintroduce related applications. We then prove least squares is the best\nunbiased linear model in the sense of mean squared error and most importantly,\nit actually approaches the theoretical limit. We end up with linear models with\nthe Bayesian approach and beyond.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 10:12:28 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 12:47:29 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Lu", "Jun", ""]]}, {"id": "2105.04242", "submitter": "Mikolaj Wieczorek", "authors": "Barbara Rychalska, Mikolaj Wieczorek, Jacek Dabrowski", "title": "T-EMDE: Sketching-based global similarity for cross-modal retrieval", "comments": "10 pages,5 figures, 4 tables, 1 code snippet", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key challenge in cross-modal retrieval is to find similarities between\nobjects represented with different modalities, such as image and text. However,\neach modality embeddings stem from non-related feature spaces, which causes the\nnotorious 'heterogeneity gap'. Currently, many cross-modal systems try to\nbridge the gap with self-attention. However, self-attention has been widely\ncriticized for its quadratic complexity, which prevents many real-life\napplications. In response to this, we propose T-EMDE - a neural density\nestimator inspired by the recently introduced Efficient Manifold Density\nEstimator (EMDE) from the area of recommender systems. EMDE operates on\nsketches - representations especially suitable for multimodal operations.\nHowever, EMDE is non-differentiable and ingests precomputed, static embeddings.\nWith T-EMDE we introduce a trainable version of EMDE which allows full\nend-to-end training. In contrast to self-attention, the complexity of our\nsolution is linear to the number of tokens/segments. As such, T-EMDE is a\ndrop-in replacement for the self-attention module, with beneficial influence on\nboth speed and metric performance in cross-modal settings. It facilitates\ncommunication between modalities, as each global text/image representation is\nexpressed with a standardized sketch histogram which represents the same\nmanifold structures irrespective of the underlying modality. We evaluate T-EMDE\nby introducing it into two recent cross-modal SOTA models and achieving new\nstate-of-the-art results on multiple datasets and decreasing model latency by\nup to 20%.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 10:14:32 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Rychalska", "Barbara", ""], ["Wieczorek", "Mikolaj", ""], ["Dabrowski", "Jacek", ""]]}, {"id": "2105.04290", "submitter": "Xingchen Ma", "authors": "Xingchen Ma, Matthew B. Blaschko", "title": "Meta-Cal: Well-controlled Post-hoc Calibration by Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, it is desirable that a classifier not only makes\naccurate predictions, but also outputs calibrated posterior probabilities.\nHowever, many existing classifiers, especially deep neural network classifiers,\ntend to be uncalibrated. Post-hoc calibration is a technique to recalibrate a\nmodel by learning a calibration map. Existing approaches mostly focus on\nconstructing calibration maps with low calibration errors, however, this\nquality is inadequate for a calibrator being useful. In this paper, we\nintroduce two constraints that are worth consideration in designing a\ncalibration map for post-hoc calibration. Then we present Meta-Cal, which is\nbuilt from a base calibrator and a ranking model. Under some mild assumptions,\ntwo high-probability bounds are given with respect to these constraints.\nEmpirical results on CIFAR-10, CIFAR-100 and ImageNet and a range of popular\nnetwork architectures show our proposed method significantly outperforms the\ncurrent state of the art for post-hoc multi-class classification calibration.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 12:00:54 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 11:51:22 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Ma", "Xingchen", ""], ["Blaschko", "Matthew B.", ""]]}, {"id": "2105.04332", "submitter": "Hung Tran-The", "authors": "Hung Tran-The, Sunil Gupta, Santu Rana, Svetha Venkatesh", "title": "Bayesian Optimistic Optimisation with Exponentially Decaying Regret", "comments": "To appear at ICML 2021 (21 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian optimisation (BO) is a well-known efficient algorithm for finding\nthe global optimum of expensive, black-box functions. The current practical BO\nalgorithms have regret bounds ranging from $\\mathcal{O}(\\frac{logN}{\\sqrt{N}})$\nto $\\mathcal O(e^{-\\sqrt{N}})$, where $N$ is the number of evaluations. This\npaper explores the possibility of improving the regret bound in the noiseless\nsetting by intertwining concepts from BO and tree-based optimistic optimisation\nwhich are based on partitioning the search space. We propose the BOO algorithm,\na first practical approach which can achieve an exponential regret bound with\norder $\\mathcal O(N^{-\\sqrt{N}})$ under the assumption that the objective\nfunction is sampled from a Gaussian process with a Mat\\'ern kernel with\nsmoothness parameter $\\nu > 4 +\\frac{D}{2}$, where $D$ is the number of\ndimensions. We perform experiments on optimisation of various synthetic\nfunctions and machine learning hyperparameter tuning tasks and show that our\nalgorithm outperforms baselines.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 13:07:44 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Tran-The", "Hung", ""], ["Gupta", "Sunil", ""], ["Rana", "Santu", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "2105.04373", "submitter": "Jinhang Zuo", "authors": "Jinhang Zuo, Carlee Joe-Wong", "title": "Combinatorial Multi-armed Bandits for Resource Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the sequential resource allocation problem where a decision maker\nrepeatedly allocates budgets between resources. Motivating examples include\nallocating limited computing time or wireless spectrum bands to multiple users\n(i.e., resources). At each timestep, the decision maker should distribute its\navailable budgets among different resources to maximize the expected reward, or\nequivalently to minimize the cumulative regret. In doing so, the decision maker\nshould learn the value of the resources allocated for each user from feedback\non each user's received reward. For example, users may send messages of\ndifferent urgency over wireless spectrum bands; the reward generated by\nallocating spectrum to a user then depends on the message's urgency. We assume\neach user's reward follows a random process that is initially unknown. We\ndesign combinatorial multi-armed bandit algorithms to solve this problem with\ndiscrete or continuous budgets. We prove the proposed algorithms achieve\nlogarithmic regrets under semi-bandit feedback.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 13:55:30 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zuo", "Jinhang", ""], ["Joe-Wong", "Carlee", ""]]}, {"id": "2105.04379", "submitter": "Steven Kleinegesse", "authors": "Steven Kleinegesse and Michael U. Gutmann", "title": "Gradient-based Bayesian Experimental Design for Implicit Models using\n  Mutual Information Lower Bounds", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a framework for Bayesian experimental design (BED) with implicit\nmodels, where the data-generating distribution is intractable but sampling from\nit is still possible. In order to find optimal experimental designs for such\nmodels, our approach maximises mutual information lower bounds that are\nparametrised by neural networks. By training a neural network on sampled data,\nwe simultaneously update network parameters and designs using stochastic\ngradient-ascent. The framework enables experimental design with a variety of\nprominent lower bounds and can be applied to a wide range of scientific tasks,\nsuch as parameter estimation, model discrimination and improving future\npredictions. Using a set of intractable toy models, we provide a comprehensive\nempirical comparison of prominent lower bounds applied to the aforementioned\ntasks. We further validate our framework on a challenging system of stochastic\ndifferential equations from epidemiology.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 13:59:25 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Kleinegesse", "Steven", ""], ["Gutmann", "Michael U.", ""]]}, {"id": "2105.04399", "submitter": "Antonio Elias Fernandez", "authors": "Antonio El\\'ias (1) and Ra\\'ul Jim\\'enez (2) and Hanlin Shang (3) ((1)\n  OASYS group, Department of Applied Mathematics, Universidad de M\\'alaga,\n  M\\'alaga, Spain, (2) Department of Statistics, Universidad Carlos III de\n  Madrid, Madrid, Spain, (3) Department of Actuarial Studies and Business\n  Analytics, Macquarie University, Sydney, Australia)", "title": "On projection methods for functional time series forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Two nonparametric methods are presented for forecasting functional time\nseries (FTS). The FTS we observe is a curve at a discrete-time point. We\naddress both one-step-ahead forecasting and dynamic updating. Dynamic updating\nis a forward prediction of the unobserved segment of the most recent curve.\nAmong the two proposed methods, the first one is a straightforward adaptation\nto FTS of the $k$-nearest neighbors methods for univariate time series\nforecasting. The second one is based on a selection of curves, termed \\emph{the\ncurve envelope}, that aims to be representative in shape and magnitude of the\nmost recent functional observation, either a whole curve or the observed part\nof a partially observed curve. In a similar fashion to $k$-nearest neighbors\nand other projection methods successfully used for time series forecasting, we\n``project'' the $k$-nearest neighbors and the curves in the envelope for\nforecasting. In doing so, we keep track of the next period evolution of the\ncurves. The methods are applied to simulated data, daily electricity demand,\nand NOx emissions and provide competitive results with and often superior to\nseveral benchmark predictions. The approach offers a model-free alternative to\nstatistical methods based on FTS modeling to study the cyclic or seasonal\nbehavior of many FTS.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 14:24:38 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["El\u00edas", "Antonio", ""], ["Jim\u00e9nez", "Ra\u00fal", ""], ["Shang", "Hanlin", ""]]}, {"id": "2105.04404", "submitter": "Theo Lacombe", "authors": "Th\\'eo Lacombe (DATASHAPE), Yuichi Ike, Mathieu Carriere, Fr\\'ed\\'eric\n  Chazal, Marc Glisse, Yuhei Umeda", "title": "Topological Uncertainty: Monitoring trained neural networks through\n  persistence of activation graphs", "comments": null, "journal-ref": "2021 International Joint Conference on Artificial Intelligence,\n  Aug 2021, Montr{\\'e}al, Canada", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural networks are capable of reaching astonishing performances on\na wide variety of contexts, properly training networks on complicated tasks\nrequires expertise and can be expensive from a computational perspective. In\nindustrial applications, data coming from an open-world setting might widely\ndiffer from the benchmark datasets on which a network was trained. Being able\nto monitor the presence of such variations without retraining the network is of\ncrucial importance. In this article, we develop a method to monitor trained\nneural networks based on the topological properties of their activation graphs.\nTo each new observation, we assign a Topological Uncertainty, a score that aims\nto assess the reliability of the predictions by investigating the whole network\ninstead of its final layer only, as typically done by practitioners. Our\napproach entirely works at a post-training level and does not require any\nassumption on the network architecture, optimization scheme, nor the use of\ndata augmentation or auxiliary datasets; and can be faithfully applied on a\nlarge range of network architectures and data types. We showcase experimentally\nthe potential of Topological Uncertainty in the context of trained network\nselection, Out-Of-Distribution detection, and shift-detection, both on\nsynthetic and real datasets of images and graphs.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 14:16:03 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Lacombe", "Th\u00e9o", "", "DATASHAPE"], ["Ike", "Yuichi", ""], ["Carriere", "Mathieu", ""], ["Chazal", "Fr\u00e9d\u00e9ric", ""], ["Glisse", "Marc", ""], ["Umeda", "Yuhei", ""]]}, {"id": "2105.04448", "submitter": "Benjamin Nachman", "authors": "Anders Andreassen, Patrick T. Komiske, Eric M. Metodiev, Benjamin\n  Nachman, Adi Suresh, and Jesse Thaler", "title": "Scaffolding Simulations with Deep Learning for High-dimensional\n  Deconvolution", "comments": "6 pages, 1 figure, 1 table", "journal-ref": "ICLR simDL workshop 2021 (https://simdl.github.io/files/12.pdf)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG hep-ex hep-ph physics.data-an", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common setting for scientific inference is the ability to sample from a\nhigh-fidelity forward model (simulation) without having an explicit probability\ndensity of the data. We propose a simulation-based maximum likelihood\ndeconvolution approach in this setting called OmniFold. Deep learning enables\nthis approach to be naturally unbinned and (variable-, and) high-dimensional.\nIn contrast to model parameter estimation, the goal of deconvolution is to\nremove detector distortions in order to enable a variety of down-stream\ninference tasks. Our approach is the deep learning generalization of the common\nRichardson-Lucy approach that is also called Iterative Bayesian Unfolding in\nparticle physics. We show how OmniFold can not only remove detector\ndistortions, but it can also account for noise processes and acceptance\neffects.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 15:16:18 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Andreassen", "Anders", ""], ["Komiske", "Patrick T.", ""], ["Metodiev", "Eric M.", ""], ["Nachman", "Benjamin", ""], ["Suresh", "Adi", ""], ["Thaler", "Jesse", ""]]}, {"id": "2105.04471", "submitter": "Bertrand Charpentier", "authors": "Bertrand Charpentier, Oliver Borchert, Daniel Z\\\"ugner, Simon Geisler,\n  Stephan G\\\"unnemann", "title": "Natural Posterior Network: Deep Bayesian Predictive Uncertainty for\n  Exponential Family Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty awareness is crucial to develop reliable machine learning models.\nIn this work, we propose the Natural Posterior Network (NatPN) for fast and\nhigh-quality uncertainty estimation for any task where the target distribution\nbelongs to the exponential family. Thus, NatPN finds application for both\nclassification and general regression settings. Unlike many previous\napproaches, NatPN does not require out-of-distribution (OOD) data at training\ntime. Instead, it leverages Normalizing Flows to fit a single density on a\nlearned low-dimensional and task-dependent latent space. For any input sample,\nNatPN uses the predicted likelihood to perform a Bayesian update over the\ntarget distribution. Theoretically, NatPN assigns high uncertainty far away\nfrom training data. Empirically, our extensive experiments on calibration and\nOOD detection show that NatPN delivers highly competitive performance for\nclassification, regression and count prediction tasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 16:10:26 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Charpentier", "Bertrand", ""], ["Borchert", "Oliver", ""], ["Z\u00fcgner", "Daniel", ""], ["Geisler", "Simon", ""], ["G\u00fcnnemann", "Stephan", ""]]}, {"id": "2105.04504", "submitter": "Vincent Dutordoir", "authors": "Vincent Dutordoir, James Hensman, Mark van der Wilk, Carl Henrik Ek,\n  Zoubin Ghahramani, Nicolas Durrande", "title": "Deep Neural Networks as Point Estimates for Deep Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Gaussian processes (DGPs) have struggled for relevance in applications\ndue to the challenges and cost associated with Bayesian inference. In this\npaper we propose a sparse variational approximation for DGPs for which the\napproximate posterior mean has the same mathematical structure as a Deep Neural\nNetwork (DNN). We make the forward pass through a DGP equivalent to a ReLU DNN\nby finding an interdomain transformation that represents the GP posterior mean\nas a sum of ReLU basis functions. This unification enables the initialisation\nand training of the DGP as a neural network, leveraging the well established\npractice in the deep learning community, and so greatly aiding the inference\ntask. The experiments demonstrate improved accuracy and faster training\ncompared to current DGP methods, while retaining favourable predictive\nuncertainties.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 16:55:17 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Dutordoir", "Vincent", ""], ["Hensman", "James", ""], ["van der Wilk", "Mark", ""], ["Ek", "Carl Henrik", ""], ["Ghahramani", "Zoubin", ""], ["Durrande", "Nicolas", ""]]}, {"id": "2105.04522", "submitter": "Erik Englesson", "authors": "Erik Englesson, Hossein Azizpour", "title": "Generalized Jensen-Shannon Divergence Loss for Learning with Noisy\n  Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prior works have found it beneficial to combine provably noise-robust loss\nfunctions e.g., mean absolute error (MAE) with standard categorical loss\nfunction e.g. cross entropy (CE) to improve their learnability. Here, we\npropose to use Jensen-Shannon divergence as a noise-robust loss function and\nshow that it interestingly interpolate between CE and MAE with a controllable\nmixing parameter. Furthermore, we make a crucial observation that CE exhibit\nlower consistency around noisy data points. Based on this observation, we adopt\na generalized version of the Jensen-Shannon divergence for multiple\ndistributions to encourage consistency around data points. Using this loss\nfunction, we show state-of-the-art results on both synthetic (CIFAR), and\nreal-world (WebVision) noise with varying noise rates.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 17:19:38 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 12:07:03 GMT"}, {"version": "v3", "created": "Sat, 5 Jun 2021 08:57:58 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Englesson", "Erik", ""], ["Azizpour", "Hossein", ""]]}, {"id": "2105.04550", "submitter": "Keyulu Xu", "authors": "Keyulu Xu, Mozhi Zhang, Stefanie Jegelka, Kenji Kawaguchi", "title": "Optimization of Graph Neural Networks: Implicit Acceleration by Skip\n  Connections and More Depth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have been studied through the lens of expressive\npower and generalization. However, their optimization properties are less well\nunderstood. We take the first step towards analyzing GNN training by studying\nthe gradient dynamics of GNNs. First, we analyze linearized GNNs and prove that\ndespite the non-convexity of training, convergence to a global minimum at a\nlinear rate is guaranteed under mild assumptions that we validate on real-world\ngraphs. Second, we study what may affect the GNNs' training speed. Our results\nshow that the training of GNNs is implicitly accelerated by skip connections,\nmore depth, and/or a good label distribution. Empirical results confirm that\nour theoretical results for linearized GNNs align with the training behavior of\nnonlinear GNNs. Our results provide the first theoretical support for the\nsuccess of GNNs with skip connections in terms of optimization, and suggest\nthat deep GNNs with skip connections would be promising in practice.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 17:59:01 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 05:55:42 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Xu", "Keyulu", ""], ["Zhang", "Mozhi", ""], ["Jegelka", "Stefanie", ""], ["Kawaguchi", "Kenji", ""]]}, {"id": "2105.04554", "submitter": "Jan N. Fuhg", "authors": "Jan Niklas Fuhg, Michele Marino, Nikolaos Bouklas", "title": "Local approximate Gaussian process regression for data-driven\n  constitutive laws: Development and comparison with neural networks", "comments": "22 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Hierarchical computational methods for multiscale mechanics such as the\nFE$^2$ and FE-FFT methods are generally accompanied by high computational\ncosts. Data-driven approaches are able to speed the process up significantly by\nenabling to incorporate the effective micromechanical response in macroscale\nsimulations without the need of performing additional computations at each\nGauss point explicitly. Traditionally artificial neural networks (ANNs) have\nbeen the surrogate modeling technique of choice in the solid mechanics\ncommunity. However they suffer from severe drawbacks due to their parametric\nnature and suboptimal training and inference properties for the investigated\ndatasets in a three dimensional setting. These problems can be avoided using\nlocal approximate Gaussian process regression (laGPR). This method can allow\nthe prediction of stress outputs at particular strain space locations by\ntraining local regression models based on Gaussian processes, using only a\nsubset of the data for each local model, offering better and more reliable\naccuracy than ANNs. A modified Newton-Raphson approach is proposed to\naccommodate for the local nature of the laGPR approximation when solving the\nglobal structural problem in a FE setting. Hence, the presented work offers a\ncomplete and general framework enabling multiscale calculations combining a\ndata-driven constitutive prediction using laGPR, and macroscopic calculations\nusing an FE scheme that we test for finite-strain three-dimensional\nhyperelastic problems.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 14:49:28 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Fuhg", "Jan Niklas", ""], ["Marino", "Michele", ""], ["Bouklas", "Nikolaos", ""]]}, {"id": "2105.04646", "submitter": "Chengchun Shi", "authors": "Chengchun Shi and Runzhe Wan and Victor Chernozhukov and Rui Song", "title": "Deeply-Debiased Off-Policy Interval Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation learns a target policy's value with a historical\ndataset generated by a different behavior policy. In addition to a point\nestimate, many applications would benefit significantly from having a\nconfidence interval (CI) that quantifies the uncertainty of the point estimate.\nIn this paper, we propose a novel deeply-debiasing procedure to construct an\nefficient, robust, and flexible CI on a target policy's value. Our method is\njustified by theoretical results and numerical experiments. A Python\nimplementation of the proposed procedure is available at\nhttps://github.com/RunzheStat/D2OPE.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 20:00:08 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 20:14:34 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Shi", "Chengchun", ""], ["Wan", "Runzhe", ""], ["Chernozhukov", "Victor", ""], ["Song", "Rui", ""]]}, {"id": "2105.04656", "submitter": "Chirag Gupta", "authors": "Chirag Gupta, Aaditya K. Ramdas", "title": "Distribution-free calibration guarantees for histogram binning without\n  sample splitting", "comments": "Appears at ICML 2021\n  (http://proceedings.mlr.press/v139/gupta21b.html)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove calibration guarantees for the popular histogram binning (also\ncalled uniform-mass binning) method of Zadrozny and Elkan [2001]. Histogram\nbinning has displayed strong practical performance, but theoretical guarantees\nhave only been shown for sample split versions that avoid 'double dipping' the\ndata. We demonstrate that the statistical cost of sample splitting is\npractically significant on a credit default dataset. We then prove calibration\nguarantees for the original method that double dips the data, using a certain\nMarkov property of order statistics. Based on our results, we make practical\nrecommendations for choosing the number of bins in histogram binning. In our\nillustrative simulations, we propose a new tool for assessing calibration --\nvalidity plots -- which provide more information than an ECE estimate. Code for\nthis work will be made publicly available at\nhttps://github.com/aigen/df-posthoc-calibration.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 20:26:26 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 20:09:35 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Gupta", "Chirag", ""], ["Ramdas", "Aaditya K.", ""]]}, {"id": "2105.04683", "submitter": "Mattia Rigotti", "authors": "Mattia Rigotti, Rong Zhu", "title": "Deep Bandits Show-Off: Simple and Efficient Exploration with Deep\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing efficient exploration is central to Reinforcement Learning due to\nthe fundamental problem posed by the exploration-exploitation dilemma. Bayesian\nexploration strategies like Thompson Sampling resolve this trade-off in a\nprincipled way by modeling and updating the distribution of the parameters of\nthe the action-value function, the outcome model of the environment. However,\nthis technique becomes infeasible for complex environments due to the\ndifficulty of representing and updating probability distributions over\nparameters of outcome models of corresponding complexity. Moreover, the\napproximation techniques introduced to mitigate this issue typically result in\npoor exploration-exploitation trade-offs, as observed in the case of deep\nneural network models with approximate posterior methods that have been shown\nto underperform in the deep bandit scenario.\n  In this paper we introduce Sample Average Uncertainty (SAU), a simple and\nefficient uncertainty measure for contextual bandits. While Bayesian approaches\nlike Thompson Sampling estimate outcomes uncertainty indirectly by first\nquantifying the variability over the parameters of the outcome model, SAU is a\nfrequentist approach that directly estimates the uncertainty of the outcomes\nbased on the value predictions. Importantly, we show theoretically that the\nuncertainty measure estimated by SAU asymptotically matches the uncertainty\nprovided by Thompson Sampling, as well as its regret bounds. Because of its\nsimplicity SAU can be seamlessly applied to deep contextual bandits as a very\nscalable drop-in replacement for epsilon-greedy exploration. Finally, we\nempirically confirm our theory by showing that SAU-based exploration\noutperforms current state-of-the-art deep Bayesian bandit methods on several\nreal-world datasets at modest computation cost.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 21:45:01 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Rigotti", "Mattia", ""], ["Zhu", "Rong", ""]]}, {"id": "2105.04770", "submitter": "Qiaosheng Zhang", "authors": "Qiaosheng Zhang, Vincent Y. F. Tan", "title": "Exact Recovery in the General Hypergraph Stochastic Block Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT math.ST stat.ML stat.TH", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  This paper investigates fundamental limits of exact recovery in the general\nd-uniform hypergraph stochastic block model (d-HSBM), wherein n nodes are\npartitioned into k disjoint communities with relative sizes (p1,..., pk). Each\nsubset of nodes with cardinality d is generated independently as an order-d\nhyperedge with a certain probability that depends on the ground-truth\ncommunities that the d nodes belong to. The goal is to exactly recover the k\nhidden communities based on the observed hypergraph. We show that there exists\na sharp threshold such that exact recovery is achievable above the threshold\nand impossible below the threshold (apart from a small regime of parameters\nthat will be specified precisely). This threshold is represented in terms of a\nquantity which we term as the generalized Chernoff-Hellinger divergence between\ncommunities. Our result for this general model recovers prior results for the\nstandard SBM and d-HSBM with two symmetric communities as special cases. En\nroute to proving our achievability results, we develop a polynomial-time\ntwo-stage algorithm that meets the threshold. The first stage adopts a certain\nhypergraph spectral clustering method to obtain a coarse estimate of\ncommunities, and the second stage refines each node individually via local\nrefinement steps to ensure exact recovery.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 03:39:08 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Zhang", "Qiaosheng", ""], ["Tan", "Vincent Y. F.", ""]]}, {"id": "2105.04816", "submitter": "Matthew J. Holland", "authors": "Matthew J. Holland, El Mehdi Haress", "title": "Spectral risk-based learning using unbounded losses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the setting of learning problems under a wide class\nof spectral risk (or \"L-risk\") functions, where a Lipschitz-continuous spectral\ndensity is used to flexibly assign weight to extreme loss values. We obtain\nexcess risk guarantees for a derivative-free learning procedure under unbounded\nheavy-tailed loss distributions, and propose a computationally efficient\nimplementation which empirically outperforms traditional risk minimizers in\nterms of balancing spectral risk and misclassification error.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 07:08:10 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Holland", "Matthew J.", ""], ["Haress", "El Mehdi", ""]]}, {"id": "2105.04852", "submitter": "Theo Lacombe", "authors": "Vincent Divol (DATASHAPE, LMO), Th\\'eo Lacombe (DATASHAPE)", "title": "Estimation and Quantization of Expected Persistence Diagrams", "comments": null, "journal-ref": "International Conference on Machine Learning, Jul 2021, Virtual\n  Conference, France", "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistence diagrams (PDs) are the most common descriptors used to encode the\ntopology of structured data appearing in challenging learning tasks; think e.g.\nof graphs, time series or point clouds sampled close to a manifold. Given\nrandom objects and the corresponding distribution of PDs, one may want to build\na statistical summary-such as a mean-of these random PDs, which is however not\na trivial task as the natural geometry of the space of PDs is not linear. In\nthis article, we study two such summaries, the Expected Persistence Diagram\n(EPD), and its quantization. The EPD is a measure supported on R 2 , which may\nbe approximated by its empirical counterpart. We prove that this estimator is\noptimal from a minimax standpoint on a large class of models with a parametric\nrate of convergence. The empirical EPD is simple and efficient to compute, but\npossibly has a very large support, hindering its use in practice. To overcome\nthis issue, we propose an algorithm to compute a quantization of the empirical\nEPD, a measure with small support which is shown to approximate with\nnear-optimal rates a quantization of the theoretical EPD.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 08:12:18 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Divol", "Vincent", "", "DATASHAPE, LMO"], ["Lacombe", "Th\u00e9o", "", "DATASHAPE"]]}, {"id": "2105.04854", "submitter": "Ryan Henderson", "authors": "Ryan Henderson, Djork-Arn\\'e Clevert, Floriane Montanari", "title": "Improving Molecular Graph Neural Network Explainability with\n  Orthonormalization and Induced Sparsity", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rationalizing which parts of a molecule drive the predictions of a molecular\ngraph convolutional neural network (GCNN) can be difficult. To help, we propose\ntwo simple regularization techniques to apply during the training of GCNNs:\nBatch Representation Orthonormalization (BRO) and Gini regularization. BRO,\ninspired by molecular orbital theory, encourages graph convolution operations\nto generate orthonormal node embeddings. Gini regularization is applied to the\nweights of the output layer and constrains the number of dimensions the model\ncan use to make predictions. We show that Gini and BRO regularization can\nimprove the accuracy of state-of-the-art GCNN attribution methods on artificial\nbenchmark datasets. In a real-world setting, we demonstrate that medicinal\nchemists significantly prefer explanations extracted from regularized models.\nWhile we only study these regularizers in the context of GCNNs, both can be\napplied to other types of neural networks\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 08:13:34 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 12:07:30 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Henderson", "Ryan", ""], ["Clevert", "Djork-Arn\u00e9", ""], ["Montanari", "Floriane", ""]]}, {"id": "2105.04857", "submitter": "Eric Wong", "authors": "Eric Wong, Shibani Santurkar, Aleksander M\\k{a}dry", "title": "Leveraging Sparse Linear Layers for Debuggable Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how fitting sparse linear models over learned deep feature\nrepresentations can lead to more debuggable neural networks. These networks\nremain highly accurate while also being more amenable to human interpretation,\nas we demonstrate quantiatively via numerical and human experiments. We further\nillustrate how the resulting sparse explanations can help to identify spurious\ncorrelations, explain misclassifications, and diagnose model biases in vision\nand language tasks. The code for our toolkit can be found at\nhttps://github.com/madrylab/debuggabledeepnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 08:15:25 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Wong", "Eric", ""], ["Santurkar", "Shibani", ""], ["M\u0105dry", "Aleksander", ""]]}, {"id": "2105.04876", "submitter": "Matthias A{\\ss}enmacher", "authors": "M. A{\\ss}enmacher, P. Schulze, C. Heumann", "title": "Benchmarking down-scaled (not so large) pre-trained language models", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large Transformer-based language models are pre-trained on corpora of varying\nsizes, for a different number of steps and with different batch sizes. At the\nsame time, more fundamental components, such as the pre-training objective or\narchitectural hyperparameters, are modified. In total, it is therefore\ndifficult to ascribe changes in performance to specific factors. Since\nsearching the hyperparameter space over the full systems is too costly, we\npre-train down-scaled versions of several popular Transformer-based\narchitectures on a common pre-training corpus and benchmark them on a subset of\nthe GLUE tasks (Wang et al., 2018). Specifically, we systematically compare\nthree pre-training objectives for different shape parameters and model sizes,\nwhile also varying the number of pre-training steps and the batch size. In our\nexperiments MLM + NSP (BERT-style) consistently outperforms MLM (RoBERTa-style)\nas well as the standard LM objective. Furthermore, we find that additional\ncompute should be mainly allocated to an increased model size, while training\nfor more steps is inefficient. Based on these observations, as a final step we\nattempt to scale up several systems using compound scaling (Tan and Le, 2019)\nadapted to Transformer-based language models.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 09:01:04 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["A\u00dfenmacher", "M.", ""], ["Schulze", "P.", ""], ["Heumann", "C.", ""]]}, {"id": "2105.04920", "submitter": "Vo Nguyen Le Duy", "authors": "Vo Nguyen Le Duy, Ichiro Takeuchi", "title": "More Powerful Conditional Selective Inference for Generalized Lasso by\n  Parametric Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional selective inference (SI) has been studied intensively as a new\nstatistical inference framework for data-driven hypotheses. The basic concept\nof conditional SI is to make the inference conditional on the selection event,\nwhich enables an exact and valid statistical inference to be conducted even\nwhen the hypothesis is selected based on the data. Conditional SI has mainly\nbeen studied in the context of model selection, such as vanilla lasso or\ngeneralized lasso. The main limitation of existing approaches is the low\nstatistical power owing to over-conditioning, which is required for\ncomputational tractability. In this study, we propose a more powerful and\ngeneral conditional SI method for a class of problems that can be converted\ninto quadratic parametric programming, which includes generalized lasso. The\nkey concept is to compute the continuum path of the optimal solution in the\ndirection of the selected test statistic and to identify the subset of the data\nspace that corresponds to the model selection event by following the solution\npath. The proposed parametric programming-based method not only avoids the\naforementioned major drawback of over-conditioning, but also improves the\nperformance and practicality of SI in various respects. We conducted several\nexperiments to demonstrate the effectiveness and efficiency of our proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 10:12:00 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Duy", "Vo Nguyen Le", ""], ["Takeuchi", "Ichiro", ""]]}, {"id": "2105.04979", "submitter": "Souvik Chakraborty", "authors": "Navaneeth N. and Souvik Chakraborty", "title": "Surrogate assisted active subspace and active subspace assisted\n  surrogate -- A new paradigm for high dimensional structural reliability\n  analysis", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing reliability analysis on complex systems is often computationally\nexpensive. In particular, when dealing with systems having high input\ndimensionality, reliability estimation becomes a daunting task. A popular\napproach to overcome the problem associated with time-consuming and expensive\nevaluations is building a surrogate model. However, these computationally\nefficient models often suffer from the curse of dimensionality. Hence, training\na surrogate model for high-dimensional problems is not straightforward.\nHenceforth, this paper presents a framework for solving high-dimensional\nreliability analysis problems. The basic premise is to train the surrogate\nmodel on a low-dimensional manifold, discovered using the active subspace\nalgorithm. However, learning the low-dimensional manifold using active subspace\nis non-trivial as it requires information on the gradient of the response\nvariable. To address this issue, we propose using sparse learning algorithms in\nconjunction with the active subspace algorithm; the resulting algorithm is\nreferred to as the sparse active subspace (SAS) algorithm. We project the\nhigh-dimensional inputs onto the identified low-dimensional manifold identified\nusing SAS. A high-fidelity surrogate model is used to map the inputs on the\nlow-dimensional manifolds to the output response. We illustrate the efficacy of\nthe proposed framework by using three benchmark reliability analysis problems\nfrom the literature. The results obtained indicate the accuracy and efficiency\nof the proposed approach compared to already established reliability analysis\nmethods in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 12:29:01 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 14:14:40 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["N.", "Navaneeth", ""], ["Chakraborty", "Souvik", ""]]}, {"id": "2105.04999", "submitter": "Said Ouala", "authors": "Said Ouala, Laurent Debreu, Ananda Pascual, Bertrand Chapron, Fabrice\n  Collard, Lucile Gaultier and Ronan Fablet", "title": "Learning Runge-Kutta Integration Schemes for ODE Simulation and\n  Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deriving analytical solutions of ordinary differential equations is usually\nrestricted to a small subset of problems and numerical techniques are\nconsidered. Inevitably, a numerical simulation of a differential equation will\nthen always be distinct from a true analytical solution. An efficient\nintegration scheme shall further not only provide a trajectory throughout a\ngiven state, but also be derived to ensure the generated simulation to be close\nto the analytical one. Consequently, several integration schemes were developed\nfor different classes of differential equations. Unfortunately, when\nconsidering the integration of complex non-linear systems, as well as the\nidentification of non-linear equations from data, this choice of the\nintegration scheme is often far from being trivial. In this paper, we propose a\nnovel framework to learn integration schemes that minimize an\nintegration-related cost function. We demonstrate the relevance of the proposed\nlearning-based approach for non-linear equations and include a quantitative\nanalysis w.r.t. classical state-of-the-art integration techniques, especially\nwhere the latter may not apply.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 13:02:20 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Ouala", "Said", ""], ["Debreu", "Laurent", ""], ["Pascual", "Ananda", ""], ["Chapron", "Bertrand", ""], ["Collard", "Fabrice", ""], ["Gaultier", "Lucile", ""], ["Fablet", "Ronan", ""]]}, {"id": "2105.05001", "submitter": "Zhao Song", "authors": "Baihe Huang, Xiaoxiao Li, Zhao Song, Xin Yang", "title": "FL-NTK: A Neural Tangent Kernel-based Framework for Federated Learning\n  Convergence Analysis", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Federated Learning (FL) is an emerging learning scheme that allows different\ndistributed clients to train deep neural networks together without data\nsharing. Neural networks have become popular due to their unprecedented\nsuccess. To the best of our knowledge, the theoretical guarantees of FL\nconcerning neural networks with explicit forms and multi-step updates are\nunexplored. Nevertheless, training analysis of neural networks in FL is\nnon-trivial for two reasons: first, the objective loss function we are\noptimizing is non-smooth and non-convex, and second, we are even not updating\nin the gradient direction. Existing convergence results for gradient\ndescent-based methods heavily rely on the fact that the gradient direction is\nused for updating. This paper presents a new class of convergence analysis for\nFL, Federated Learning Neural Tangent Kernel (FL-NTK), which corresponds to\noverparamterized ReLU neural networks trained by gradient descent in FL and is\ninspired by the analysis in Neural Tangent Kernel (NTK). Theoretically, FL-NTK\nconverges to a global-optimal solution at a linear rate with properly tuned\nlearning parameters. Furthermore, with proper distributional assumptions,\nFL-NTK can also achieve good generalization.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 13:05:53 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Huang", "Baihe", ""], ["Li", "Xiaoxiao", ""], ["Song", "Zhao", ""], ["Yang", "Xin", ""]]}, {"id": "2105.05026", "submitter": "Chongxuan Li", "authors": "Guoqiang Wu, Chongxuan Li, Kun Xu, Jun Zhu", "title": "Rethinking and Reweighting the Univariate Losses for Multi-Label\n  Ranking: Consistency and Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (Partial) ranking loss is a commonly used evaluation measure for multi-label\nclassification, which is usually optimized with convex surrogates for\ncomputational efficiency. Prior theoretical work on multi-label ranking mainly\nfocuses on (Fisher) consistency analyses. However, there is a gap between\nexisting theory and practice -- some pairwise losses can lead to promising\nperformance but lack consistency, while some univariate losses are consistent\nbut usually have no clear superiority in practice. In this paper, we attempt to\nfill this gap through a systematic study from two complementary perspectives of\nconsistency and generalization error bounds of learning algorithms. Our results\nshow that learning algorithms with the consistent univariate loss have an error\nbound of $O(c)$ ($c$ is the number of labels), while algorithms with the\ninconsistent pairwise loss depend on $O(\\sqrt{c})$ as shown in prior work. This\nexplains that the latter can achieve better performance than the former in\npractice. Moreover, we present an inconsistent reweighted univariate loss-based\nlearning algorithm that enjoys an error bound of $O(\\sqrt{c})$ for promising\nperformance as well as the computational efficiency of univariate losses.\nFinally, experimental results validate our theoretical analyses.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 09:23:27 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Wu", "Guoqiang", ""], ["Li", "Chongxuan", ""], ["Xu", "Kun", ""], ["Zhu", "Jun", ""]]}, {"id": "2105.05031", "submitter": "Kyriakos Flouris", "authors": "Kyriakos Flouris, Anna Volokitin, Gustav Bredell, Ender Konukoglu", "title": "Gradient flow encoding with distance optimization adaptive step size", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The autoencoder model uses an encoder to map data samples to a lower\ndimensional latent space and then a decoder to map the latent space\nrepresentations back to the data space. Implicitly, it relies on the encoder to\napproximate the inverse of the decoder network, so that samples can be mapped\nto and back from the latent space faithfully. This approximation may lead to\nsub-optimal latent space representations. In this work, we investigate a\ndecoder-only method that uses gradient flow to encode data samples in the\nlatent space. The gradient flow is defined based on a given decoder and aims to\nfind the optimal latent space representation for any given sample through\noptimisation, eliminating the need of an approximate inversion through an\nencoder. Implementing gradient flow through ordinary differential equations\n(ODE), we leverage the adjoint method to train a given decoder. We further show\nempirically that the costly integrals in the adjoint method may not be entirely\nnecessary. Additionally, we propose a $2^{nd}$ order ODE variant to the method,\nwhich approximates Nesterov's accelerated gradient descent, with faster\nconvergence per iteration. Commonly used ODE solvers can be quite sensitive to\nthe integration step-size depending on the stiffness of the ODE. To overcome\nthe sensitivity for gradient flow encoding, we use an adaptive solver that\nprioritises minimising loss at each integration step. We assess the proposed\nmethod in comparison to the autoencoding model. In our experiments, GFE showed\na much higher data-efficiency than the autoencoding model, which can be crucial\nfor data scarce applications.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 13:38:23 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Flouris", "Kyriakos", ""], ["Volokitin", "Anna", ""], ["Bredell", "Gustav", ""], ["Konukoglu", "Ender", ""]]}, {"id": "2105.05115", "submitter": "Dominik Schr\\\"oder", "authors": "Vanessa Piccolo and Dominik Schr\\\"oder", "title": "Analysis of One-Hidden-Layer Neural Networks via the Resolvent Method", "comments": "24 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compute the asymptotic empirical spectral distribution of a non-linear\nrandom matrix model by using the resolvent method. Motivated by random neural\nnetworks, we consider the random matrix $M = Y Y^\\ast$ with $Y = f(WX)$, where\n$W$ and $X$ are random rectangular matrices with i.i.d. centred entries and $f$\nis a non-linear smooth function which is applied entry-wise. We prove that the\nStieltjes transform of the limiting spectral distribution satisfies a quartic\nself-consistent equation up to some error terms, which is exactly the equation\nobtained by [Pennington, Worah] and [Benigni, P\\'{e}ch\\'{e}] with the moment\nmethod approach. In addition, we extend the previous results to the case of\nadditive bias $Y=f(WX+B)$ with $B$ being an independent rank-one Gaussian\nrandom matrix, closer modelling the neural network infrastructures encountering\nin practice. Our approach following the \\emph{resolvent method} is more robust\nthan the moment method and is expected to provide insights also for models\nwhere the combinatorics of the latter become intractable.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 15:17:39 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Piccolo", "Vanessa", ""], ["Schr\u00f6der", "Dominik", ""]]}, {"id": "2105.05146", "submitter": "Mouloud Belbahri", "authors": "Mouloud Belbahri, Olivier Gandouet, Alejandro Murua and Vahid Partovi\n  Nia", "title": "A Twin Neural Model for Uplift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Uplift is a particular case of conditional treatment effect modeling. Such\nmodels deal with cause-and-effect inference for a specific factor, such as a\nmarketing intervention or a medical treatment. In practice, these models are\nbuilt on individual data from randomized clinical trials where the goal is to\npartition the participants into heterogeneous groups depending on the uplift.\nMost existing approaches are adaptations of random forests for the uplift case.\nSeveral split criteria have been proposed in the literature, all relying on\nmaximizing heterogeneity. However, in practice, these approaches are prone to\noverfitting. In this work, we bring a new vision to uplift modeling. We propose\na new loss function defined by leveraging a connection with the Bayesian\ninterpretation of the relative risk. Our solution is developed for a specific\ntwin neural network architecture allowing to jointly optimize the marginal\nprobabilities of success for treated and control individuals. We show that this\nmodel is a generalization of the uplift logistic interaction model. We modify\nthe stochastic gradient descent algorithm to allow for structured sparse\nsolutions. This helps training our uplift models to a great extent. We show our\nproposed method is competitive with the state-of-the-art in simulation setting\nand on real data from large scale randomized experiments.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 16:02:39 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Belbahri", "Mouloud", ""], ["Gandouet", "Olivier", ""], ["Murua", "Alejandro", ""], ["Nia", "Vahid Partovi", ""]]}, {"id": "2105.05181", "submitter": "Anthony LaTorre", "authors": "Anthony LaTorre", "title": "Factoring Multidimensional Data to Create a Sophisticated Bayes\n  Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we derive an explicit formula for calculating the marginal\nlikelihood of a given factorization of a categorical dataset. Since the\nmarginal likelihood is proportional to the posterior probability of the\nfactorization, these likelihoods can be used to order all possible\nfactorizations and select the \"best\" way to factor the overall distribution\nfrom which the dataset is drawn. The best factorization can then be used to\nconstruct a Bayes classifier which benefits from factoring out mutually\nindependent sets of variables.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 16:34:12 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 16:29:10 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["LaTorre", "Anthony", ""]]}, {"id": "2105.05228", "submitter": "Huy Tuan Pham", "authors": "Huy Tuan Pham, Phan-Minh Nguyen", "title": "Global Convergence of Three-layer Neural Networks in the Mean Field\n  Regime", "comments": "Appear in ICLR 2021. This is the conference version of\n  arXiv:2001.11443 (which contains treatment of the multilayer neural nets and\n  their global convergence)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the mean field regime, neural networks are appropriately scaled so that as\nthe width tends to infinity, the learning dynamics tends to a nonlinear and\nnontrivial dynamical limit, known as the mean field limit. This lends a way to\nstudy large-width neural networks via analyzing the mean field limit. Recent\nworks have successfully applied such analysis to two-layer networks and\nprovided global convergence guarantees. The extension to multilayer ones\nhowever has been a highly challenging puzzle, and little is known about the\noptimization efficiency in the mean field regime when there are more than two\nlayers.\n  In this work, we prove a global convergence result for unregularized\nfeedforward three-layer networks in the mean field regime. We first develop a\nrigorous framework to establish the mean field limit of three-layer networks\nunder stochastic gradient descent training. To that end, we propose the idea of\na \\textit{neuronal embedding}, which comprises of a fixed probability space\nthat encapsulates neural networks of arbitrary sizes. The identified mean field\nlimit is then used to prove a global convergence guarantee under suitable\nregularity and convergence mode assumptions, which -- unlike previous works on\ntwo-layer networks -- does not rely critically on convexity. Underlying the\nresult is a universal approximation property, natural of neural networks, which\nimportantly is shown to hold at \\textit{any} finite training time (not\nnecessarily at convergence) via an algebraic topology argument.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 17:45:42 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Pham", "Huy Tuan", ""], ["Nguyen", "Phan-Minh", ""]]}, {"id": "2105.05231", "submitter": "Animesh Sakorikar", "authors": "Animesh Sakorikar and Lele Wang", "title": "Variants on Block Design Based Gradient Codes for Adversarial Stragglers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gradient coding is a coding theoretic framework to provide robustness against\nslow or unresponsive machines, known as stragglers, in distributed machine\nlearning applications. Recently, Kadhe et al. proposed a gradient code based on\na combinatorial design, called balanced incomplete block design (BIBD), which\nis shown to outperform many existing gradient codes in worst-case adversarial\nstraggling scenarios. However, parameters for which such BIBD constructions\nexist are very limited. In this paper, we aim to overcome such limitations and\nconstruct gradient codes which exist for a wide range of parameters while\nretaining the superior performance of BIBD gradient codes. Two such\nconstructions are proposed, one based on a probabilistic construction that\nrelax the stringent BIBD gradient code constraints, and the other based on\ntaking the Kronecker product of existing gradient codes. Theoretical error\nbounds for worst-case adversarial straggling scenarios are derived. Simulations\nshow that the proposed constructions can outperform existing gradient codes\nwith similar redundancy per data piece.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 17:49:05 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Sakorikar", "Animesh", ""], ["Wang", "Lele", ""]]}, {"id": "2105.05233", "submitter": "Prafulla Dhariwal", "authors": "Prafulla Dhariwal, Alex Nichol", "title": "Diffusion Models Beat GANs on Image Synthesis", "comments": "Added compute requirements, ImageNet 256$\\times$256 upsampling FID\n  and samples, DDIM guided sampler, fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that diffusion models can achieve image sample quality superior to\nthe current state-of-the-art generative models. We achieve this on\nunconditional image synthesis by finding a better architecture through a series\nof ablations. For conditional image synthesis, we further improve sample\nquality with classifier guidance: a simple, compute-efficient method for\ntrading off diversity for fidelity using gradients from a classifier. We\nachieve an FID of 2.97 on ImageNet 128$\\times$128, 4.59 on ImageNet\n256$\\times$256, and 7.72 on ImageNet 512$\\times$512, and we match BigGAN-deep\neven with as few as 25 forward passes per sample, all while maintaining better\ncoverage of the distribution. Finally, we find that classifier guidance\ncombines well with upsampling diffusion models, further improving FID to 3.94\non ImageNet 256$\\times$256 and 3.85 on ImageNet 512$\\times$512. We release our\ncode at https://github.com/openai/guided-diffusion\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 17:50:24 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 17:57:59 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 17:57:08 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 17:49:49 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Dhariwal", "Prafulla", ""], ["Nichol", "Alex", ""]]}, {"id": "2105.05328", "submitter": "Jack Dunn", "authors": "Jack Dunn, Luca Mingardi, Ying Daisy Zhuo", "title": "Comparing interpretability and explainability for feature selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common approach for feature selection is to examine the variable importance\nscores for a machine learning model, as a way to understand which features are\nthe most relevant for making predictions. Given the significance of feature\nselection, it is crucial for the calculated importance scores to reflect\nreality. Falsely overestimating the importance of irrelevant features can lead\nto false discoveries, while underestimating importance of relevant features may\nlead us to discard important features, resulting in poor model performance.\nAdditionally, black-box models like XGBoost provide state-of-the art predictive\nperformance, but cannot be easily understood by humans, and thus we rely on\nvariable importance scores or methods for explainability like SHAP to offer\ninsight into their behavior.\n  In this paper, we investigate the performance of variable importance as a\nfeature selection method across various black-box and interpretable machine\nlearning methods. We compare the ability of CART, Optimal Trees, XGBoost and\nSHAP to correctly identify the relevant subset of variables across a number of\nexperiments. The results show that regardless of whether we use the native\nvariable importance method or SHAP, XGBoost fails to clearly distinguish\nbetween relevant and irrelevant features. On the other hand, the interpretable\nmethods are able to correctly and efficiently identify irrelevant features, and\nthus offer significantly better performance for feature selection.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 20:01:23 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Dunn", "Jack", ""], ["Mingardi", "Luca", ""], ["Zhuo", "Ying Daisy", ""]]}, {"id": "2105.05347", "submitter": "Tom Schaul", "authors": "Tom Schaul, Georg Ostrovski, Iurii Kemaev, Diana Borsa", "title": "Return-based Scaling: Yet Another Normalisation Trick for Deep RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scaling issues are mundane yet irritating for practitioners of reinforcement\nlearning. Error scales vary across domains, tasks, and stages of learning;\nsometimes by many orders of magnitude. This can be detrimental to learning\nspeed and stability, create interference between learning tasks, and\nnecessitate substantial tuning. We revisit this topic for agents based on\ntemporal-difference learning, sketch out some desiderata and investigate\nscenarios where simple fixes fall short. The mechanism we propose requires\nneither tuning, clipping, nor adaptation. We validate its effectiveness and\nrobustness on the suite of Atari games. Our scaling method turns out to be\nparticularly helpful at mitigating interference, when training a shared neural\nnetwork on multiple targets that differ in reward scale or discounting.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 21:31:02 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Schaul", "Tom", ""], ["Ostrovski", "Georg", ""], ["Kemaev", "Iurii", ""], ["Borsa", "Diana", ""]]}, {"id": "2105.05360", "submitter": "Alexandra Koulouri", "authors": "Alexandra Koulouri", "title": "Real-time Ionospheric Imaging of S4 Scintillation from Limited Data with\n  Parallel Kalman Filters and Smoothness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ao-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a Bayesian framework to create two dimensional\nionospheric images of high spatio-temporal resolution to monitor ionospheric\nirregularities as measured by the S4 index. Here, we recast the standard\nBayesian recursive filtering for a linear Gaussian state-space model, also\nreferred to as the Kalman filter, first by augmenting the (pierce point)\nobservation model with connectivity information stemming from the insight and\nassumptions/standard modeling about the spatial distribution of the\nscintillation activity on the ionospheric shell at 350 km altitude. Thus, we\nachieve to handle the limited spatio-temporal observations. Then, by\nintroducing a set of Kalman filters running in parallel, we mitigate the\nuncertainty related to a tuning parameter of the proposed augmented model. The\noutput images are a weighted average of the state estimates of the individual\nfilters. We demonstrate our approach by rendering two dimensional real-time\nionospheric images of S4 amplitude scintillation at 350 km over South America\nwith temporal resolution of one minute. Furthermore, we employ extra S4 data\nthat was not used in producing these ionospheric images, to check and verify\nthe ability of our images to predict this extra data in particular ionospheric\npierce points. Our results show that in areas with a network of ground\nreceivers with a relatively good coverage (e.g. within a couple of kilometers\ndistance) the produced images can provide reliable real-time results. Our\nproposed algorithmic framework can be readily used to visualize real-time\nionospheric images taking as inputs the available scintillation data provided\nfrom freely available web-servers.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 23:09:14 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Koulouri", "Alexandra", ""]]}, {"id": "2105.05373", "submitter": "Yue You", "authors": "Yue You, Mark van der Laan, Philip Collender, Qu Cheng, Alan Hubbard,\n  Nicholas P Jewell, Zhiyue Tom Hu, Robin Mejia and Justin Remais", "title": "Estimation of population size based on capture recapture designs and\n  evaluation of the estimation reliability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a modern method to estimate population size based on\ncapture-recapture designs of K samples. The observed data is formulated as a\nsample of n i.i.d. K-dimensional vectors of binary indicators, where the k-th\ncomponent of each vector indicates the subject being caught by the k-th sample,\nsuch that only subjects with nonzero capture vectors are observed. The target\nquantity is the unconditional probability of the vector being nonzero across\nboth observed and unobserved subjects. We cover models assuming a single\nconstraint (identification assumption) on the K-dimensional distribution such\nthat the target quantity is identified and the statistical model is\nunrestricted. We present solutions for linear and non-linear constraints\ncommonly assumed to identify capture-recapture models, including no K-way\ninteraction in linear and log-linear models, independence or conditional\nindependence. We demonstrate that the choice of constraint has a dramatic\nimpact on the value of the estimand, showing that it is crucial that the\nconstraint is known to hold by design. For the commonly assumed constraint of\nno K-way interaction in a log-linear model, the statistical target parameter is\nonly defined when each of the $2^K - 1$ observable capture patterns is present,\nand therefore suffers from the curse of dimensionality. We propose a targeted\nMLE based on undersmoothed lasso model to smooth across the cells while\ntargeting the fit towards the single valued target parameter of interest. For\neach identification assumption, we provide simulated inference and confidence\nintervals to assess the performance on the estimator under correct and\nincorrect identifying assumptions. We apply the proposed method, alongside\nexisting estimators, to estimate prevalence of a parasitic infection using\nmulti-source surveillance data from a region in southwestern China, under the\nfour identification assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 00:12:13 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["You", "Yue", ""], ["van der Laan", "Mark", ""], ["Collender", "Philip", ""], ["Cheng", "Qu", ""], ["Hubbard", "Alan", ""], ["Jewell", "Nicholas P", ""], ["Hu", "Zhiyue Tom", ""], ["Mejia", "Robin", ""], ["Remais", "Justin", ""]]}, {"id": "2105.05400", "submitter": "Jimmy Aronsson", "authors": "Jimmy Aronsson", "title": "Homogeneous vector bundles and $G$-equivariant convolutional neural\n  networks", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.RT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  $G$-equivariant convolutional neural networks (GCNNs) is a geometric deep\nlearning model for data defined on a homogeneous $G$-space $\\mathcal{M}$. GCNNs\nare designed to respect the global symmetry in $\\mathcal{M}$, thereby\nfacilitating learning. In this paper, we analyze GCNNs on homogeneous spaces\n$\\mathcal{M} = G/K$ in the case of unimodular Lie groups $G$ and compact\nsubgroups $K \\leq G$. We demonstrate that homogeneous vector bundles is the\nnatural setting for GCNNs. We also use reproducing kernel Hilbert spaces to\nobtain a precise criterion for expressing $G$-equivariant layers as\nconvolutional layers. This criterion is then rephrased as a bandwidth\ncriterion, leading to even stronger results for some groups.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 02:06:04 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Aronsson", "Jimmy", ""]]}, {"id": "2105.05449", "submitter": "Amir Ahooye Atashin", "authors": "Majid Mohammadi, Amir Ahooye Atashin, Damian A. Tamburri", "title": "An efficient projection neural network for $\\ell_1$-regularized logistic\n  regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\ell_1$ regularization has been used for logistic regression to circumvent\nthe overfitting and use the estimated sparse coefficient for feature selection.\nHowever, the challenge of such a regularization is that the $\\ell_1$ norm is\nnot differentiable, making the standard algorithms for convex optimization not\napplicable to this problem. This paper presents a simple projection neural\nnetwork for $\\ell_1$-regularized logistics regression. In contrast to many\navailable solvers in the literature, the proposed neural network does not\nrequire any extra auxiliary variable nor any smooth approximation, and its\ncomplexity is almost identical to that of the gradient descent for logistic\nregression without $\\ell_1$ regularization, thanks to the projection operator.\nWe also investigate the convergence of the proposed neural network by using the\nLyapunov theory and show that it converges to a solution of the problem with\nany arbitrary initial value. The proposed neural solution significantly\noutperforms state-of-the-art methods with respect to the execution time and is\ncompetitive in terms of accuracy and AUROC.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 06:13:44 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Mohammadi", "Majid", ""], ["Atashin", "Amir Ahooye", ""], ["Tamburri", "Damian A.", ""]]}, {"id": "2105.05489", "submitter": "Shumao Zhang", "authors": "Shumao Zhang, Pengchuan Zhang, Thomas Y. Hou", "title": "Multiscale Invertible Generative Networks for High-Dimensional Bayesian\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Multiscale Invertible Generative Network (MsIGN) and associated\ntraining algorithm that leverages multiscale structure to solve\nhigh-dimensional Bayesian inference. To address the curse of dimensionality,\nMsIGN exploits the low-dimensional nature of the posterior, and generates\nsamples from coarse to fine scale (low to high dimension) by iteratively\nupsampling and refining samples. MsIGN is trained in a multi-stage manner to\nminimize the Jeffreys divergence, which avoids mode dropping in\nhigh-dimensional cases. On two high-dimensional Bayesian inverse problems, we\nshow superior performance of MsIGN over previous approaches in posterior\napproximation and multiple mode capture. On the natural image synthesis task,\nMsIGN achieves superior performance in bits-per-dimension over baseline models\nand yields great interpret-ability of its neurons in intermediate layers.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 07:51:47 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Zhang", "Shumao", ""], ["Zhang", "Pengchuan", ""], ["Hou", "Thomas Y.", ""]]}, {"id": "2105.05555", "submitter": "Honghao Lin", "authors": "Yu Cheng and Honghao Lin", "title": "Robust Learning of Fixed-Structure Bayesian Networks in Nearly-Linear\n  Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning Bayesian networks where an\n$\\epsilon$-fraction of the samples are adversarially corrupted. We focus on the\nfully-observable case where the underlying graph structure is known. In this\nwork, we present the first nearly-linear time algorithm for this problem with a\ndimension-independent error guarantee. Previous robust algorithms with\ncomparable error guarantees are slower by at least a factor of $(d/\\epsilon)$,\nwhere $d$ is the number of variables in the Bayesian network and $\\epsilon$ is\nthe fraction of corrupted samples.\n  Our algorithm and analysis are considerably simpler than those in previous\nwork. We achieve this by establishing a direct connection between robust\nlearning of Bayesian networks and robust mean estimation. As a subroutine in\nour algorithm, we develop a robust mean estimation algorithm whose runtime is\nnearly-linear in the number of nonzeros in the input samples, which may be of\nindependent interest.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 10:11:32 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Cheng", "Yu", ""], ["Lin", "Honghao", ""]]}, {"id": "2105.05622", "submitter": "Aidan Hughes", "authors": "A.J. Hughes, L.A. Bull, P. Gardner, R.J. Barthorpe, N. Dervilis, K.\n  Worden", "title": "On risk-based active learning for structural health monitoring", "comments": "28 pages. 23 figures. Under review, preprint submitted to Mechanical\n  Systems and Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A primary motivation for the development and implementation of structural\nhealth monitoring systems, is the prospect of gaining the ability to make\ninformed decisions regarding the operation and maintenance of structures and\ninfrastructure. Unfortunately, descriptive labels for measured data\ncorresponding to health-state information for the structure of interest are\nseldom available prior to the implementation of a monitoring system. This issue\nlimits the applicability of the traditional supervised and unsupervised\napproaches to machine learning in the development of statistical classifiers\nfor decision-supporting SHM systems.\n  The current paper presents a risk-based formulation of active learning, in\nwhich the querying of class-label information is guided by the expected value\nof said information for each incipient data point. When applied to structural\nhealth monitoring, the querying of class labels can be mapped onto the\ninspection of a structure of interest in order to determine its health state.\nIn the current paper, the risk-based active learning process is explained and\nvisualised via a representative numerical example and subsequently applied to\nthe Z24 Bridge benchmark. The results of the case studies indicate that a\ndecision-maker's performance can be improved via the risk-based active learning\nof a statistical classifier, such that the decision process itself is taken\ninto account.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 12:34:03 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Hughes", "A. J.", ""], ["Bull", "L. A.", ""], ["Gardner", "P.", ""], ["Barthorpe", "R. J.", ""], ["Dervilis", "N.", ""], ["Worden", "K.", ""]]}, {"id": "2105.05648", "submitter": "Johan Larsson", "authors": "Johan Larsson", "title": "Look-Ahead Screening Rules for the Lasso", "comments": "EYSM 2021 short paper; 6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lasso is a popular method to induce shrinkage and sparsity in the\nsolution vector (coefficients) of regression problems, particularly when there\nare many predictors relative to the number of observations. Solving the lasso\nin this high-dimensional setting can, however, be computationally demanding.\nFortunately, this demand can be alleviated via the use of screening rules that\ndiscard predictors prior to fitting the model, leading to a reduced problem to\nbe solved. In this paper, we present a new screening strategy: look-ahead\nscreening. Our method uses safe screening rules to find a range of penalty\nvalues for which a given predictor cannot enter the model, thereby screening\npredictors along the remainder of the path. In experiments we show that these\nlook-ahead screening rules outperform the active warm-start version of the Gap\nSafe rules.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 13:27:40 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 10:05:19 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Larsson", "Johan", ""]]}, {"id": "2105.05650", "submitter": "Dian Wu", "authors": "Dian Wu, Riccardo Rossi, Giuseppe Carleo", "title": "Unbiased Monte Carlo Cluster Updates with Autoregressive Neural Networks", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficient sampling of complex high-dimensional probability densities is a\ncentral task in computational science. Machine Learning techniques based on\nautoregressive neural networks have been recently shown to provide good\napproximations of probability distributions of interest in physics. In this\nwork, we propose a systematic way to remove the intrinsic bias associated with\nthese variational approximations, combining it with Markov-chain Monte Carlo in\nan automatic scheme to efficiently generate cluster updates, which is\nparticularly useful for models for which no efficient cluster update scheme is\nknown. Our approach is based on symmetry-enforced cluster updates building on\nthe neural-network representation of conditional probabilities. We demonstrate\nthat such finite-cluster updates are crucial to circumvent ergodicity problems\nassociated with global neural updates. We test our method for first- and\nsecond-order phase transitions in classical spin systems, proving in particular\nits viability for critical systems, or in the presence of metastable states.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 13:31:12 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Wu", "Dian", ""], ["Rossi", "Riccardo", ""], ["Carleo", "Giuseppe", ""]]}, {"id": "2105.05721", "submitter": "Rafael Chaves", "authors": "Rafael Chaves, George Moreno, Emanuele Polino, Davide Poderini, Iris\n  Agresti, Alessia Suprano, Mariana R. Barros, Gonzalo Carvacho, Elie Wolfe,\n  Askery Canabarro, Robert W. Spekkens, Fabio Sciarrino", "title": "Causal networks and freedom of choice in Bell's theorem", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bell's theorem is typically understood as the proof that quantum theory is\nincompatible with local hidden variable models. More generally, we can see the\nviolation of a Bell inequality as witnessing the impossibility of explaining\nquantum correlations with classical causal models. The violation of a Bell\ninequality, however, does not exclude classical models where some level of\nmeasurement dependence is allowed, that is, the choice made by observers can be\ncorrelated with the source generating the systems to be measured. Here we show\nthat the level of measurement dependence can be quantitatively upper bounded if\nwe arrange the Bell test within a network. Furthermore, we also prove that\nthese results can be adapted in order to derive non-linear Bell inequalities\nfor a large class of causal networks and to identify quantumly realizable\ncorrelations which violate them.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 15:14:17 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Chaves", "Rafael", ""], ["Moreno", "George", ""], ["Polino", "Emanuele", ""], ["Poderini", "Davide", ""], ["Agresti", "Iris", ""], ["Suprano", "Alessia", ""], ["Barros", "Mariana R.", ""], ["Carvacho", "Gonzalo", ""], ["Wolfe", "Elie", ""], ["Canabarro", "Askery", ""], ["Spekkens", "Robert W.", ""], ["Sciarrino", "Fabio", ""]]}, {"id": "2105.05728", "submitter": "Matthias H\\\"user", "authors": "Matthias H\\\"user, Martin Faltys, Xinrui Lyu, Chris Barber, Stephanie\n  L. Hyland, Tobias M. Merz, Gunnar R\\\"atsch", "title": "Early prediction of respiratory failure in the intensive care unit", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of respiratory failure is common among patients in intensive\ncare units (ICU). Large data quantities from ICU patient monitoring systems\nmake timely and comprehensive analysis by clinicians difficult but are ideal\nfor automatic processing by machine learning algorithms. Early prediction of\nrespiratory system failure could alert clinicians to patients at risk of\nrespiratory failure and allow for early patient reassessment and treatment\nadjustment. We propose an early warning system that predicts moderate/severe\nrespiratory failure up to 8 hours in advance. Our system was trained on\nHiRID-II, a data-set containing more than 60,000 admissions to a tertiary care\nICU. An alarm is typically triggered several hours before the beginning of\nrespiratory failure. Our system outperforms a clinical baseline mimicking\ntraditional clinical decision-making based on pulse-oximetric oxygen saturation\nand the fraction of inspired oxygen. To provide model introspection and\ndiagnostics, we developed an easy-to-use web browser-based system to explore\nmodel input data and predictions visually.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 15:20:09 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["H\u00fcser", "Matthias", ""], ["Faltys", "Martin", ""], ["Lyu", "Xinrui", ""], ["Barber", "Chris", ""], ["Hyland", "Stephanie L.", ""], ["Merz", "Tobias M.", ""], ["R\u00e4tsch", "Gunnar", ""]]}, {"id": "2105.05736", "submitter": "Ankit Singh Rawat", "authors": "Ankit Singh Rawat, Aditya Krishna Menon, Wittawat Jitkrittum, Sadeep\n  Jayasumana, Felix X. Yu, Sashank Reddi, Sanjiv Kumar", "title": "Disentangling Sampling and Labeling Bias for Learning in Large-Output\n  Spaces", "comments": "To appear in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Negative sampling schemes enable efficient training given a large number of\nclasses, by offering a means to approximate a computationally expensive loss\nfunction that takes all labels into account. In this paper, we present a new\nconnection between these schemes and loss modification techniques for\ncountering label imbalance. We show that different negative sampling schemes\nimplicitly trade-off performance on dominant versus rare labels. Further, we\nprovide a unified means to explicitly tackle both sampling bias, arising from\nworking with a subset of all labels, and labeling bias, which is inherent to\nthe data due to label imbalance. We empirically verify our findings on\nlong-tail classification and retrieval benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 15:40:13 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Rawat", "Ankit Singh", ""], ["Menon", "Aditya Krishna", ""], ["Jitkrittum", "Wittawat", ""], ["Jayasumana", "Sadeep", ""], ["Yu", "Felix X.", ""], ["Reddi", "Sashank", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "2105.05757", "submitter": "Thomas Goerttler", "authors": "Thomas Goerttler and Klaus Obermayer", "title": "Exploring the Similarity of Representations in Model-Agnostic\n  Meta-Learning", "comments": "Learning to Learn workshop at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In past years model-agnostic meta-learning (MAML) has been one of the most\npromising approaches in meta-learning. It can be applied to different kinds of\nproblems, e.g., reinforcement learning, but also shows good results on few-shot\nlearning tasks. Besides their tremendous success in these tasks, it has still\nnot been fully revealed yet, why it works so well. Recent work proposes that\nMAML rather reuses features than rapidly learns. In this paper, we want to\ninspire a deeper understanding of this question by analyzing MAML's\nrepresentation. We apply representation similarity analysis (RSA), a\nwell-established method in neuroscience, to the few-shot learning instantiation\nof MAML. Although some part of our analysis supports their general results that\nfeature reuse is predominant, we also reveal arguments against their\nconclusion. The similarity-increase of layers closer to the input layers arises\nfrom the learning task itself and not from the model. In addition, the\nrepresentations after inner gradient steps make a broader change to the\nrepresentation than the changes during meta-training.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 16:20:40 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Goerttler", "Thomas", ""], ["Obermayer", "Klaus", ""]]}, {"id": "2105.05782", "submitter": "Sainyam Galhotra", "authors": "Raghavendra Addanki, Sainyam Galhotra, Barna Saha", "title": "How to Design Robust Algorithms using Noisy Comparison Oracle", "comments": "PVLDB 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Metric based comparison operations such as finding maximum, nearest and\nfarthest neighbor are fundamental to studying various clustering techniques\nsuch as $k$-center clustering and agglomerative hierarchical clustering. These\ntechniques crucially rely on accurate estimation of pairwise distance between\nrecords. However, computing exact features of the records, and their pairwise\ndistances is often challenging, and sometimes not possible. We circumvent this\nchallenge by leveraging weak supervision in the form of a comparison oracle\nthat compares the relative distance between the queried points such as `Is\npoint u closer to v or w closer to x?'.\n  However, it is possible that some queries are easier to answer than others\nusing a comparison oracle. We capture this by introducing two different noise\nmodels called adversarial and probabilistic noise. In this paper, we study\nvarious problems that include finding maximum, nearest/farthest neighbor search\nunder these noise models. Building upon the techniques we develop for these\ncomparison operations, we give robust algorithms for k-center clustering and\nagglomerative hierarchical clustering. We prove that our algorithms achieve\ngood approximation guarantees with a high probability and analyze their query\ncomplexity. We evaluate the effectiveness and efficiency of our techniques\nempirically on various real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 16:58:09 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Addanki", "Raghavendra", ""], ["Galhotra", "Sainyam", ""], ["Saha", "Barna", ""]]}, {"id": "2105.05842", "submitter": "Raaz Dwivedi", "authors": "Raaz Dwivedi, Lester Mackey", "title": "Kernel Thinning", "comments": "Accepted for presentation as an extended abstract at the Conference\n  on Learning Theory (COLT) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.CO stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce kernel thinning, a new procedure for compressing a distribution\n$\\mathbb{P}$ more effectively than i.i.d. sampling or standard thinning. Given\na suitable reproducing kernel $\\mathbf{k}$ and $\\mathcal{O}(n^2)$ time, kernel\nthinning compresses an $n$-point approximation to $\\mathbb{P}$ into a\n$\\sqrt{n}$-point approximation with comparable worst-case integration error in\nthe associated reproducing kernel Hilbert space. With high probability, the\nmaximum discrepancy in integration error is\n$\\mathcal{O}_d(n^{-\\frac{1}{2}}\\sqrt{\\log n})$ for compactly supported\n$\\mathbb{P}$ and $\\mathcal{O}_d(n^{-\\frac{1}{2}} \\sqrt{(\\log n)^{d+1}\\log\\log\nn})$ for sub-exponential $\\mathbb{P}$ on $\\mathbb{R}^d$. In contrast, an\nequal-sized i.i.d. sample from $\\mathbb{P}$ suffers $\\Omega(n^{-\\frac14})$\nintegration error. Our sub-exponential guarantees resemble the classical\nquasi-Monte Carlo error rates for uniform $\\mathbb{P}$ on $[0,1]^d$ but apply\nto general distributions on $\\mathbb{R}^d$ and a wide range of common kernels.\nWe use our results to derive explicit non-asymptotic maximum mean discrepancy\nbounds for Gaussian, Mat\\'ern, and B-spline kernels and present two vignettes\nillustrating the practical benefits of kernel thinning over i.i.d. sampling and\nstandard Markov chain Monte Carlo thinning.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 17:56:42 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 17:59:23 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 20:57:55 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Dwivedi", "Raaz", ""], ["Mackey", "Lester", ""]]}, {"id": "2105.05947", "submitter": "Ryan Cory-Wright", "authors": "Dimitris Bertsimas, Ryan Cory-Wright, Jean Pauphilet", "title": "A new perspective on low-rank optimization", "comments": "Submitted to Mathematical Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key question in many low-rank problems throughout optimization, machine\nlearning, and statistics is to characterize the convex hulls of simple low-rank\nsets and judiciously apply these convex hulls to obtain strong yet\ncomputationally tractable convex relaxations. We invoke the matrix perspective\nfunction - the matrix analog of the perspective function-and characterize\nexplicitly the convex hull of epigraphs of convex quadratic, matrix\nexponential, and matrix power functions under low-rank constraints. Further, we\nexploit these characterizations to develop strong relaxations for a variety of\nlow-rank problems including reduced rank regression, non-negative matrix\nfactorization, and factor analysis. We establish that these relaxations can be\nmodeled via semidefinite and matrix power cone constraints, and thus optimized\nover tractably. The proposed approach parallels and generalizes the perspective\nreformulation technique in mixed-integer optimization, and leads to new\nrelaxations for a broad class of problems.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 20:22:21 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Cory-Wright", "Ryan", ""], ["Pauphilet", "Jean", ""]]}, {"id": "2105.05953", "submitter": "Babak Barazandeh", "authors": "Babak Barazandeh, Ali Ghafelebashi, Meisam Razaviyayn, Ram Sriharsha", "title": "Efficient Algorithms for Estimating the Parameters of Mixed Linear\n  Regression Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixed linear regression (MLR) model is among the most exemplary statistical\ntools for modeling non-linear distributions using a mixture of linear models.\nWhen the additive noise in MLR model is Gaussian, Expectation-Maximization (EM)\nalgorithm is a widely-used algorithm for maximum likelihood estimation of MLR\nparameters. However, when noise is non-Gaussian, the steps of EM algorithm may\nnot have closed-form update rules, which makes EM algorithm impractical. In\nthis work, we study the maximum likelihood estimation of the parameters of MLR\nmodel when the additive noise has non-Gaussian distribution. In particular, we\nconsider the case that noise has Laplacian distribution and we first show that\nunlike the the Gaussian case, the resulting sub-problems of EM algorithm in\nthis case does not have closed-form update rule, thus preventing us from using\nEM in this case. To overcome this issue, we propose a new algorithm based on\ncombining the alternating direction method of multipliers (ADMM) with EM\nalgorithm idea. Our numerical experiments show that our method outperforms the\nEM algorithm in statistical accuracy and computational time in non-Gaussian\nnoise case.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 20:29:03 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Barazandeh", "Babak", ""], ["Ghafelebashi", "Ali", ""], ["Razaviyayn", "Meisam", ""], ["Sriharsha", "Ram", ""]]}, {"id": "2105.05989", "submitter": "Wolfgang Stummer", "authors": "Wolfgang Stummer", "title": "Optimal transport with some directed distances", "comments": "9 pages", "journal-ref": "in: F. Nielsen and F. Barbaresco (Eds.): Geometric Science of\n  Information GSI 2021, LNCS 12829, pp. 829-840, 2021", "doi": "10.1007/978-3-030-80209-7_89", "report-no": null, "categories": "cs.IT math.IT math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a toolkit of directed distances between quantile functions. By\nemploying this, we solve some new optimal transport (OT) problems which e.g.\nconsiderably flexibilize some prominent OTs expressed through Wasserstein\ndistances.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 22:17:32 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Stummer", "Wolfgang", ""]]}, {"id": "2105.06018", "submitter": "Bin Liu", "authors": "Bin Liu", "title": "Robust Dynamic Multi-Modal Data Fusion: A Model Uncertainty Perspective", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper is concerned with multi-modal data fusion (MMDF) under unexpected\nmodality failures in nonlinear non-Gaussian dynamic processes. An efficient\nframework to tackle this problem is proposed. In particular, a notion termed\nmodality \"\\emph{usefulness}\", which takes a value of 1 or 0, is used for\nindicating whether the observation of this modality is useful or not. For $n$\nmodalities involved, $2^n$ combinations of their \"\\emph{usefulness}\" values\nexist. Each combination defines one hypothetical model of the true data\ngenerative process. Then the problem of concern is formalized as a task of\nnonlinear non-Gaussian state filtering under model uncertainty, which is\naddressed by a dynamic model averaging (DMA) based particle filter (PF)\nalgorithm. This DMA algorithm employs $2^n$ models, while all models share the\nsame state-transition function and a unique set of particle values. That makes\nthe computational complexity of this algorithm only slightly larger than a\nsingle model based PF algorithm, especially for scenarios in which $n$ is\nsmall. Experimental results show that the proposed solution outperforms\nremarkably state-of-the-art methods. Code and data are available at\nhttps://github.com/robinlau1981/fusion.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 01:08:34 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 13:15:36 GMT"}, {"version": "v3", "created": "Thu, 8 Jul 2021 01:42:41 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Liu", "Bin", ""]]}, {"id": "2105.06029", "submitter": "Ming Yin", "authors": "Ming Yin, Yu-Xiang Wang", "title": "Optimal Uniform OPE and Model-based Offline Reinforcement Learning in\n  Time-Homogeneous, Reward-Free and Task-Agnostic Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the statistical limits of uniform convergence for offline\npolicy evaluation (OPE) problems with model-based methods (for episodic MDP)\nand provides a unified framework towards optimal learning for several\nwell-motivated offline tasks. Uniform OPE\n$\\sup_\\Pi|Q^\\pi-\\hat{Q}^\\pi|<\\epsilon$ is a stronger measure than the\npoint-wise OPE and ensures offline learning when $\\Pi$ contains all policies\n(the global class). In this paper, we establish an $\\Omega(H^2\nS/d_m\\epsilon^2)$ lower bound (over model-based family) for the global uniform\nOPE and our main result establishes an upper bound of\n$\\tilde{O}(H^2/d_m\\epsilon^2)$ for the \\emph{local} uniform convergence that\napplies to all \\emph{near-empirically optimal} policies for the MDPs with\n\\emph{stationary} transition. Here $d_m$ is the minimal marginal state-action\nprobability. Critically, the highlight in achieving the optimal rate\n$\\tilde{O}(H^2/d_m\\epsilon^2)$ is our design of \\emph{singleton absorbing MDP},\nwhich is a new sharp analysis tool that works with the model-based approach. We\ngeneralize such a model-based framework to the new settings: offline\ntask-agnostic and the offline reward-free with optimal complexity\n$\\tilde{O}(H^2\\log(K)/d_m\\epsilon^2)$ ($K$ is the number of tasks) and\n$\\tilde{O}(H^2S/d_m\\epsilon^2)$ respectively. These results provide a unified\nsolution for simultaneously solving different offline RL problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 01:36:34 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 04:32:16 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 07:01:53 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Yin", "Ming", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "2105.06031", "submitter": "Yifeng Fan", "authors": "Yifeng Fan, Yuehaw Khoo and Zhizhen Zhao", "title": "Joint Community Detection and Rotational Synchronization via\n  Semidefinite Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the presence of heterogeneous data, where randomly rotated objects fall\ninto multiple underlying categories, it is challenging to simultaneously\nclassify them into clusters and synchronize them based on pairwise relations.\nThis gives rise to the joint problem of community detection and\nsynchronization. We propose a series of semidefinite relaxations, and prove\ntheir exact recovery when extending the celebrated stochastic block model to\nthis new setting where both rotations and cluster identities are to be\ndetermined. Numerical experiments demonstrate the efficacy of our proposed\nalgorithms and confirm our theoretical result which indicates a sharp phase\ntransition for exact recovery.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 01:40:20 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Fan", "Yifeng", ""], ["Khoo", "Yuehaw", ""], ["Zhao", "Zhizhen", ""]]}, {"id": "2105.06060", "submitter": "Hoormazd Rezaei", "authors": "Sina Jandaghi Semnani, Hoormazd Rezaei", "title": "House Price Prediction using Satellite Imagery", "comments": "Stanford CS230 Deep Learning, Winter 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show how using satellite images can improve the accuracy of\nhousing price estimation models. Using Los Angeles County's property assessment\ndataset, by transferring learning from an Inception-v3 model pretrained on\nImageNet, we could achieve an improvement of ~10% in R-squared score compared\nto two baseline models that only use non-image features of the house.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 03:25:32 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Semnani", "Sina Jandaghi", ""], ["Rezaei", "Hoormazd", ""]]}, {"id": "2105.06241", "submitter": "David Heckerman", "authors": "David Heckerman and Dan Geiger", "title": "Likelihoods and Parameter Priors for Bayesian Networks", "comments": "This version has improved pointers to the literature", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop simple methods for constructing likelihoods and parameter priors\nfor learning about the parameters and structure of a Bayesian network. In\nparticular, we introduce several assumptions that permit the construction of\nlikelihoods and parameter priors for a large number of Bayesian-network\nstructures from a small set of assessments. The most notable assumption is that\nof likelihood equivalence, which says that data can not help to discriminate\nnetwork structures that encode the same assertions of conditional independence.\nWe describe the constructions that follow from these assumptions, and also\npresent a method for directly computing the marginal likelihood of a random\nsample with no missing observations. Also, we show how these assumptions lead\nto a general framework for characterizing parameter priors of multivariate\ndistributions.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 12:45:44 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 19:42:53 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Heckerman", "David", ""], ["Geiger", "Dan", ""]]}, {"id": "2105.06251", "submitter": "Eike Stadtl\\\"ander", "authors": "Eike Stadtl\\\"ander, Tam\\'as Horv\\'ath, Stefan Wrobel", "title": "Learning Weakly Convex Sets in Metric Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of weak convexity in metric spaces, a generalization\nof ordinary convexity commonly used in machine learning. It is shown that\nweakly convex sets can be characterized by a closure operator and have a unique\ndecomposition into a set of pairwise disjoint connected blocks. We give two\ngeneric efficient algorithms, an extensional and an intensional one for\nlearning weakly convex concepts and study their formal properties. Our\nexperimental results concerning vertex classification clearly demonstrate the\nexcellent predictive performance of the extensional algorithm. Two non-trivial\napplications of the intensional algorithm to polynomial PAC-learnability are\npresented. The first one deals with learning $k$-convex Boolean functions,\nwhich are already known to be efficiently PAC-learnable. It is shown how to\nderive this positive result in a fairly easy way by the generic intensional\nalgorithm. The second one is concerned with the Euclidean space equipped with\nthe Manhattan distance. For this metric space, weakly convex sets are a union\nof pairwise disjoint axis-aligned hyperrectangles. We show that a weakly convex\nset that is consistent with a set of examples and contains a minimum number of\nhyperrectangles can be found in polynomial time. In contrast, this problem is\nknown to be NP-complete if the hyperrectangles may be overlapping.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 23:00:02 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Stadtl\u00e4nder", "Eike", ""], ["Horv\u00e1th", "Tam\u00e1s", ""], ["Wrobel", "Stefan", ""]]}, {"id": "2105.06337", "submitter": "Mikhail Kudinov", "authors": "Vadim Popov, Ivan Vovk, Vladimir Gogoryan, Tasnima Sadekova, Mikhail\n  Kudinov", "title": "Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, denoising diffusion probabilistic models and generative score\nmatching have shown high potential in modelling complex data distributions\nwhile stochastic calculus has provided a unified point of view on these\ntechniques allowing for flexible inference schemes. In this paper we introduce\nGrad-TTS, a novel text-to-speech model with score-based decoder producing\nmel-spectrograms by gradually transforming noise predicted by encoder and\naligned with text input by means of Monotonic Alignment Search. The framework\nof stochastic differential equations helps us to generalize conventional\ndiffusion probabilistic models to the case of reconstructing data from noise\nwith different parameters and allows to make this reconstruction flexible by\nexplicitly controlling trade-off between sound quality and inference speed.\nSubjective human evaluation shows that Grad-TTS is competitive with\nstate-of-the-art text-to-speech approaches in terms of Mean Opinion Score. We\nwill make the code publicly available shortly.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 14:47:44 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Popov", "Vadim", ""], ["Vovk", "Ivan", ""], ["Gogoryan", "Vladimir", ""], ["Sadekova", "Tasnima", ""], ["Kudinov", "Mikhail", ""]]}, {"id": "2105.06347", "submitter": "Sela Fried", "authors": "Sela Fried and Geoffrey Wolfer", "title": "Identity testing of reversible Markov chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of identity testing of Markov chains based on a\nsingle trajectory of observations under the distance notion introduced by\nDaskalakis et al. [2018a] and further analyzed by Cherapanamjeri and Bartlett\n[2019]. Both works made the restrictive assumption that the Markov chains under\nconsideration are symmetric. In this work we relax the symmetry assumption to\nthe more natural assumption of reversibility, still assuming that both the\nreference and the unknown Markov chains share the same stationary distribution.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 15:03:27 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Fried", "Sela", ""], ["Wolfer", "Geoffrey", ""]]}, {"id": "2105.06371", "submitter": "Chinmay Hegde", "authors": "Viraj Shah, Rakib Hyder, M. Salman Asif, Chinmay Hegde", "title": "Provably Convergent Algorithms for Solving Inverse Problems Using\n  Generative Models", "comments": "arXiv admin note: text overlap with arXiv:1810.03587,\n  arXiv:1802.08406", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The traditional approach of hand-crafting priors (such as sparsity) for\nsolving inverse problems is slowly being replaced by the use of richer learned\npriors (such as those modeled by deep generative networks). In this work, we\nstudy the algorithmic aspects of such a learning-based approach from a\ntheoretical perspective. For certain generative network architectures, we\nestablish a simple non-convex algorithmic approach that (a) theoretically\nenjoys linear convergence guarantees for certain linear and nonlinear inverse\nproblems, and (b) empirically improves upon conventional techniques such as\nback-propagation. We support our claims with the experimental results for\nsolving various inverse problems. We also propose an extension of our approach\nthat can handle model mismatch (i.e., situations where the generative network\nprior is not exactly applicable). Together, our contributions serve as building\nblocks towards a principled use of generative models in inverse problems with\nmore complete algorithmic understanding.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 15:58:27 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Shah", "Viraj", ""], ["Hyder", "Rakib", ""], ["Asif", "M. Salman", ""], ["Hegde", "Chinmay", ""]]}, {"id": "2105.06499", "submitter": "Julian Katz-Samuels", "authors": "Julian Katz-Samuels, Jifan Zhang, Lalit Jain, Kevin Jamieson", "title": "Improved Algorithms for Agnostic Pool-based Active Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider active learning for binary classification in the agnostic\npool-based setting. The vast majority of works in active learning in the\nagnostic setting are inspired by the CAL algorithm where each query is\nuniformly sampled from the disagreement region of the current version space.\nThe sample complexity of such algorithms is described by a quantity known as\nthe disagreement coefficient which captures both the geometry of the hypothesis\nspace as well as the underlying probability space. To date, the disagreement\ncoefficient has been justified by minimax lower bounds only, leaving the door\nopen for superior instance dependent sample complexities. In this work we\npropose an algorithm that, in contrast to uniform sampling over the\ndisagreement region, solves an experimental design problem to determine a\ndistribution over examples from which to request labels. We show that the new\napproach achieves sample complexity bounds that are never worse than the best\ndisagreement coefficient-based bounds, but in specific cases can be\ndramatically smaller. From a practical perspective, the proposed algorithm\nrequires no hyperparameters to tune (e.g., to control the aggressiveness of\nsampling), and is computationally efficient by means of assuming access to an\nempirical risk minimization oracle (without any constraints). Empirically, we\ndemonstrate that our algorithm is superior to state of the art agnostic active\nlearning algorithms on image classification datasets.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 18:24:30 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Katz-Samuels", "Julian", ""], ["Zhang", "Jifan", ""], ["Jain", "Lalit", ""], ["Jamieson", "Kevin", ""]]}, {"id": "2105.06558", "submitter": "Nengfeng Zhou", "authors": "Nengfeng Zhou, Zach Zhang, Vijayan N. Nair, Harsh Singhal, Jie Chen,\n  and Agus Sudjianto", "title": "Bias, Fairness, and Accountability with AI and ML Algorithms", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of AI and ML algorithms has led to opportunities as well as\nchallenges. In this paper, we provide an overview of bias and fairness issues\nthat arise with the use of ML algorithms. We describe the types and sources of\ndata bias, and discuss the nature of algorithmic unfairness. This is followed\nby a review of fairness metrics in the literature, discussion of their\nlimitations, and a description of de-biasing (or mitigation) techniques in the\nmodel life cycle.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 21:12:04 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Zhou", "Nengfeng", ""], ["Zhang", "Zach", ""], ["Nair", "Vijayan N.", ""], ["Singhal", "Harsh", ""], ["Chen", "Jie", ""], ["Sudjianto", "Agus", ""]]}, {"id": "2105.06559", "submitter": "Theodore Huang", "authors": "Theodore Huang, Gregory Idos, Christine Hong, Stephen Gruber, Giovanni\n  Parmigiani, Danielle Braun", "title": "Extending Models Via Gradient Boosting: An Application to Mendelian\n  Models", "comments": "46 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving existing widely-adopted prediction models is often a more efficient\nand robust way towards progress than training new models from scratch. Existing\nmodels may (a) incorporate complex mechanistic knowledge, (b) leverage\nproprietary information and, (c) have surmounted barriers to adoption. Compared\nto model training, model improvement and modification receive little attention.\nIn this paper we propose a general approach to model improvement: we combine\ngradient boosting with any previously developed model to improve model\nperformance while retaining important existing characteristics. To exemplify,\nwe consider the context of Mendelian models, which estimate the probability of\ncarrying genetic mutations that confer susceptibility to disease by using\nfamily pedigrees and health histories of family members. Via simulations we\nshow that integration of gradient boosting with an existing Mendelian model can\nproduce an improved model that outperforms both that model and the model built\nusing gradient boosting alone. We illustrate the approach on genetic testing\ndata from the USC-Stanford Cancer Genetics Hereditary Cancer Panel (HCP) study.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 21:21:05 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Huang", "Theodore", ""], ["Idos", "Gregory", ""], ["Hong", "Christine", ""], ["Gruber", "Stephen", ""], ["Parmigiani", "Giovanni", ""], ["Braun", "Danielle", ""]]}, {"id": "2105.06587", "submitter": "Tomas Geffner", "authors": "Tomas Geffner and Justin Domke", "title": "Empirical Evaluation of Biased Methods for Alpha Divergence Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we empirically evaluate biased methods for alpha-divergence\nminimization. In particular, we focus on how the bias affects the final\nsolutions found, and how this depends on the dimensionality of the problem. We\nfind that (i) solutions returned by these methods appear to be strongly biased\ntowards minimizers of the traditional \"exclusive\" KL-divergence, KL(q||p), and\n(ii) in high dimensions, an impractically large amount of computation is needed\nto mitigate this bias and obtain solutions that actually minimize the\nalpha-divergence of interest.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 23:16:54 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Geffner", "Tomas", ""], ["Domke", "Justin", ""]]}, {"id": "2105.06600", "submitter": "Ke Wang", "authors": "Ke Wang, Alexander Franks, Sang-Yun Oh", "title": "Learning Gaussian Graphical Models with Latent Confounders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gaussian Graphical models (GGM) are widely used to estimate the network\nstructures in many applications ranging from biology to finance. In practice,\ndata is often corrupted by latent confounders which biases inference of the\nunderlying true graphical structure. In this paper, we compare and contrast two\nstrategies for inference in graphical models with latent confounders: Gaussian\ngraphical models with latent variables (LVGGM) and PCA-based removal of\nconfounding (PCA+GGM). While these two approaches have similar goals, they are\nmotivated by different assumptions about confounding. In this paper, we explore\nthe connection between these two approaches and propose a new method, which\ncombines the strengths of these two approaches. We prove the consistency and\nconvergence rate for the PCA-based method and use these results to provide\nguidance about when to use each method. We demonstrate the effectiveness of our\nmethodology using both simulations and in two real-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 00:53:03 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Wang", "Ke", ""], ["Franks", "Alexander", ""], ["Oh", "Sang-Yun", ""]]}, {"id": "2105.06643", "submitter": "Rakshitha Godahewa", "authors": "Rakshitha Godahewa, Christoph Bergmeir, Geoffrey I. Webb, Rob J.\n  Hyndman, Pablo Montero-Manso", "title": "Monash Time Series Forecasting Archive", "comments": "33 pages, 3 figures, 15 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many businesses and industries nowadays rely on large quantities of time\nseries data making time series forecasting an important research area. Global\nforecasting models that are trained across sets of time series have shown a\nhuge potential in providing accurate forecasts compared with the traditional\nunivariate forecasting models that work on isolated series. However, there are\ncurrently no comprehensive time series archives for forecasting that contain\ndatasets of time series from similar sources available for the research\ncommunity to evaluate the performance of new global forecasting algorithms over\na wide variety of datasets. In this paper, we present such a comprehensive time\nseries forecasting archive containing 20 publicly available time series\ndatasets from varied domains, with different characteristics in terms of\nfrequency, series lengths, and inclusion of missing values. We also\ncharacterise the datasets, and identify similarities and differences among\nthem, by conducting a feature analysis. Furthermore, we present the performance\nof a set of standard baseline forecasting methods over all datasets across\neight error metrics, for the benefit of researchers using the archive to\nbenchmark their forecasting algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 04:49:58 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Godahewa", "Rakshitha", ""], ["Bergmeir", "Christoph", ""], ["Webb", "Geoffrey I.", ""], ["Hyndman", "Rob J.", ""], ["Montero-Manso", "Pablo", ""]]}, {"id": "2105.06715", "submitter": "Xiaolong Fan", "authors": "Xiaolong Fan, Maoguo Gong, Yue Wu, Hao Li", "title": "Maximizing Mutual Information Across Feature and Topology Views for\n  Learning Graph Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, maximizing mutual information has emerged as a powerful method for\nunsupervised graph representation learning. The existing methods are typically\neffective to capture information from the topology view but ignore the feature\nview. To circumvent this issue, we propose a novel approach by exploiting\nmutual information maximization across feature and topology views.\nSpecifically, we first utilize a multi-view representation learning module to\nbetter capture both local and global information content across feature and\ntopology views on graphs. To model the information shared by the feature and\ntopology spaces, we then develop a common representation learning module using\nmutual information maximization and reconstruction loss minimization. To\nexplicitly encourage diversity between graph representations from the same\nview, we also introduce a disagreement regularization to enlarge the distance\nbetween representations from the same view. Experiments on synthetic and\nreal-world datasets demonstrate the effectiveness of integrating feature and\ntopology views. In particular, compared with the previous supervised methods,\nour proposed method can achieve comparable or even better performance under the\nunsupervised representation and linear evaluation protocol.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 08:49:40 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Fan", "Xiaolong", ""], ["Gong", "Maoguo", ""], ["Wu", "Yue", ""], ["Li", "Hao", ""]]}, {"id": "2105.06742", "submitter": "Nathaniel Bastian PhD", "authors": "David A. Bierbrauer and Alexander Chang and Will Kritzer and Nathaniel\n  D. Bastian", "title": "Anomaly Detection in Cybersecurity: Unsupervised, Graph-Based and\n  Supervised Learning Methods in Adversarial Environments", "comments": "6 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning for anomaly detection has become a widely researched field\nin cybersecurity. Inherent to today's operating environment is the practice of\nadversarial machine learning, which attempts to circumvent machine learning\nmodels. In this work, we examine the feasibility of unsupervised learning and\ngraph-based methods for anomaly detection in the network intrusion detection\nsystem setting, as well as leverage an ensemble approach to supervised learning\nof the anomaly detection problem. We incorporate a realistic adversarial\ntraining mechanism when training our supervised models to enable strong\nclassification performance in adversarial environments. Our results indicate\nthat the unsupervised and graph-based methods were outperformed in detecting\nanomalies (malicious activity) by the supervised stacking ensemble method with\ntwo levels. This model consists of three different classifiers in the first\nlevel, followed by either a Naive Bayes or Decision Tree classifier for the\nsecond level. We see that our model maintains an F1-score above 0.97 for\nmalicious samples across all tested level two classifiers. Notably, Naive Bayes\nis the fastest level two classifier averaging 1.12 seconds while Decision Tree\nmaintains the highest AUC score of 0.98.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 10:05:10 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Bierbrauer", "David A.", ""], ["Chang", "Alexander", ""], ["Kritzer", "Will", ""], ["Bastian", "Nathaniel D.", ""]]}, {"id": "2105.06868", "submitter": "Vincent Fortuin", "authors": "Vincent Fortuin", "title": "Priors in Bayesian Deep Learning: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the choice of prior is one of the most critical parts of the Bayesian\ninference workflow, recent Bayesian deep learning models have often fallen back\non vague priors, such as standard Gaussians. In this review, we highlight the\nimportance of prior choices for Bayesian deep learning and present an overview\nof different priors that have been proposed for (deep) Gaussian processes,\nvariational autoencoders, and Bayesian neural networks. We also outline\ndifferent methods of learning priors for these models from data. We hope to\nmotivate practitioners in Bayesian deep learning to think more carefully about\nthe prior specification for their models and to provide them with some\ninspiration in this regard.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 14:53:30 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 17:48:55 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Fortuin", "Vincent", ""]]}, {"id": "2105.06903", "submitter": "Weipeng Huang", "authors": "Weipeng Huang, Tin Lok James Ng, Nishma Laitonjam, Neil J. Hurley", "title": "Posterior Regularisation on Bayesian Hierarchical Mixture Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a recent inferential framework, named posterior regularisation, on\nthe Bayesian hierarchical mixture clustering (BHMC) model. This framework\nfacilitates a simple way to impose extra constraints on a Bayesian model to\novercome some weakness of the original model. It narrows the search space of\nthe parameters of the Bayesian model through a formalism that imposes certain\nconstraints on the features of the found solutions. In this paper, in order to\nenhance the separation of clusters, we apply posterior regularisation to impose\nmax-margin constraints on the nodes at every level of the hierarchy. This paper\nshows how the framework integrates with BHMC and achieves the expected\nimprovements over the original Bayesian model.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 15:41:15 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 17:03:57 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Huang", "Weipeng", ""], ["Ng", "Tin Lok James", ""], ["Laitonjam", "Nishma", ""], ["Hurley", "Neil J.", ""]]}, {"id": "2105.06907", "submitter": "Kiana Farhadyar", "authors": "Kiana Farhadyar, Federico Bonofiglio, Daniela Zoeller and Harald\n  Binder", "title": "Adapting deep generative approaches for getting synthetic data with\n  realistic marginal distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic data generation is of great interest in diverse applications, such\nas for privacy protection. Deep generative models, such as variational\nautoencoders (VAEs), are a popular approach for creating such synthetic\ndatasets from original data. Despite the success of VAEs, there are limitations\nwhen it comes to the bimodal and skewed marginal distributions. These deviate\nfrom the unimodal symmetric distributions that are encouraged by the normality\nassumption typically used for the latent representations in VAEs. While there\nare extensions that assume other distributions for the latent space, this does\nnot generally increase flexibility for data with many different distributions.\nTherefore, we propose a novel method, pre-transformation variational\nautoencoders (PTVAEs), to specifically address bimodal and skewed data, by\nemploying pre-transformations at the level of original variables. Two types of\ntransformations are used to bring the data close to a normal distribution by a\nseparate parameter optimization for each variable in a dataset. We compare the\nperformance of our method with other state-of-the-art methods for synthetic\ndata generation. In addition to the visual comparison, we use a utility\nmeasurement for a quantitative evaluation. The results show that the PTVAE\napproach can outperform others in both bimodal and skewed data generation.\nFurthermore, the simplicity of the approach makes it usable in combination with\nother extensions of VAE.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 15:47:20 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Farhadyar", "Kiana", ""], ["Bonofiglio", "Federico", ""], ["Zoeller", "Daniela", ""], ["Binder", "Harald", ""]]}, {"id": "2105.06960", "submitter": "Ming Liang Ang", "authors": "Ming Liang Ang, Eloise Y. Y. Lim, Joel Q. L. Chang", "title": "Thompson Sampling for Gaussian Entropic Risk Bandits", "comments": "arXiv admin note: text overlap with arXiv:2011.08046", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The multi-armed bandit (MAB) problem is a ubiquitous decision-making problem\nthat exemplifies exploration-exploitation tradeoff. Standard formulations\nexclude risk in decision making. Risknotably complicates the basic\nreward-maximising objectives, in part because there is no universally agreed\ndefinition of it. In this paper, we consider an entropic risk (ER) measure and\nexplore the performance of a Thompson sampling-based algorithm ERTS under this\nrisk measure by providing regret bounds for ERTS and corresponding instance\ndependent lower bounds.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 17:01:02 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Ang", "Ming Liang", ""], ["Lim", "Eloise Y. Y.", ""], ["Chang", "Joel Q. L.", ""]]}, {"id": "2105.06964", "submitter": "Vincent Fortuin", "authors": "Vincent Fortuin, Adri\\`a Garriga-Alonso, Mark van der Wilk, Laurence\n  Aitchison", "title": "BNNpriors: A library for Bayesian neural network inference with\n  different prior distributions", "comments": "Accepted for publication at Software Impacts", "journal-ref": null, "doi": "10.1016/j.simpa.2021.100079", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks have shown great promise in many applications where\ncalibrated uncertainty estimates are crucial and can often also lead to a\nhigher predictive performance. However, it remains challenging to choose a good\nprior distribution over their weights. While isotropic Gaussian priors are\noften chosen in practice due to their simplicity, they do not reflect our true\nprior beliefs well and can lead to suboptimal performance. Our new library,\nBNNpriors, enables state-of-the-art Markov Chain Monte Carlo inference on\nBayesian neural networks with a wide range of predefined priors, including\nheavy-tailed ones, hierarchical ones, and mixture priors. Moreover, it follows\na modular approach that eases the design and implementation of new custom\npriors. It has facilitated foundational discoveries on the nature of the cold\nposterior effect in Bayesian neural networks and will hopefully catalyze future\nresearch as well as practical applications in this area.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 17:11:04 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Fortuin", "Vincent", ""], ["Garriga-Alonso", "Adri\u00e0", ""], ["van der Wilk", "Mark", ""], ["Aitchison", "Laurence", ""]]}, {"id": "2105.06987", "submitter": "Andrey Malinin Dr.", "authors": "Max Ryabinin, Andrey Malinin, Mark Gales", "title": "Scaling Ensemble Distribution Distillation to Many Classes with Proxy\n  Targets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles of machine learning models yield improved system performance as\nwell as robust and interpretable uncertainty estimates; however, their\ninference costs may often be prohibitively high. \\emph{Ensemble Distribution\nDistillation} is an approach that allows a single model to efficiently capture\nboth the predictive performance and uncertainty estimates of an ensemble. For\nclassification, this is achieved by training a Dirichlet distribution over the\nensemble members' output distributions via the maximum likelihood criterion.\nAlthough theoretically principled, this criterion exhibits poor convergence\nwhen applied to large-scale tasks where the number of classes is very high. In\nour work, we analyze this effect and show that the Dirichlet log-likelihood\ncriterion classes with low probability induce larger gradients than\nhigh-probability classes. This forces the model to focus on the distribution of\nthe ensemble tail-class probabilities. We propose a new training objective that\nminimizes the reverse KL-divergence to a \\emph{Proxy-Dirichlet} target derived\nfrom the ensemble. This loss resolves the gradient issues of Ensemble\nDistribution Distillation, as we demonstrate both theoretically and empirically\non the ImageNet and WMT17 En-De datasets containing 1000 and 40,000 classes,\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 17:50:14 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Ryabinin", "Max", ""], ["Malinin", "Andrey", ""], ["Gales", "Mark", ""]]}, {"id": "2105.07025", "submitter": "Lu Li", "authors": "Lu Li, Connor Thompson, Gregory Henselman-Petrusek, Chad Giusti, Lori\n  Ziegelmeier", "title": "Minimal Cycle Representatives in Persistent Homology using Linear\n  Programming: an Empirical Study with User's Guide", "comments": null, "journal-ref": null, "doi": "10.3389/frai.2021.681117", "report-no": null, "categories": "math.AT cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cycle representatives of persistent homology classes can be used to provide\ndescriptions of topological features in data. However, the non-uniqueness of\nthese representatives creates ambiguity and can lead to many different\ninterpretations of the same set of classes. One approach to solving this\nproblem is to optimize the choice of representative against some measure that\nis meaningful in the context of the data. In this work, we provide a study of\nthe effectiveness and computational cost of several $\\ell_1$-minimization\noptimization procedures for constructing homological cycle bases for persistent\nhomology with rational coefficients in dimension one, including\nuniform-weighted and length-weighted edge-loss algorithms as well as\nuniform-weighted and area-weighted triangle-loss algorithms. We conduct these\noptimizations via standard linear programming methods, applying general-purpose\nsolvers to optimize over column bases of simplicial boundary matrices.\n  Our key findings are: (i) optimization is effective in reducing the size of\ncycle representatives, (ii) the computational cost of optimizing a basis of\ncycle representatives exceeds the cost of computing such a basis in most data\nsets we consider, (iii) the choice of linear solvers matters a lot to the\ncomputation time of optimizing cycles, (iv) the computation time of solving an\ninteger program is not significantly longer than the computation time of\nsolving a linear program for most of the cycle representatives, using the\nGurobi linear solver, (v) strikingly, whether requiring integer solutions or\nnot, we almost always obtain a solution with the same cost and almost all\nsolutions found have entries in {-1, 0, 1} and therefore, are also solutions to\na restricted $\\ell_0$ optimization problem, and (vi) we obtain qualitatively\ndifferent results for generators in Erd\\H{o}s-R\\'enyi random clique complexes.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 18:38:48 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 23:39:25 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Li", "Lu", ""], ["Thompson", "Connor", ""], ["Henselman-Petrusek", "Gregory", ""], ["Giusti", "Chad", ""], ["Ziegelmeier", "Lori", ""]]}, {"id": "2105.07168", "submitter": "Masayoshi Mase", "authors": "Masayoshi Mase, Art B. Owen, Benjamin B. Seiler", "title": "Cohort Shapley value for algorithmic fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cohort Shapley value is a model-free method of variable importance grounded\nin game theory that does not use any unobserved and potentially impossible\nfeature combinations. We use it to evaluate algorithmic fairness, using the\nwell known COMPAS recidivism data as our example. This approach allows one to\nidentify for each individual in a data set the extent to which they were\nadversely or beneficially affected by their value of a protected attribute such\nas their race. The method can do this even if race was not one of the original\npredictors and even if it does not have access to a proprietary algorithm that\nhas made the predictions. The grounding in game theory lets us define aggregate\nvariable importance for a data set consistently with its per subject\ndefinitions. We can investigate variable importance for multiple quantities of\ninterest in the fairness literature including false positive predictions.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 08:02:18 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Mase", "Masayoshi", ""], ["Owen", "Art B.", ""], ["Seiler", "Benjamin B.", ""]]}, {"id": "2105.07222", "submitter": "Zhiyi Zhang", "authors": "Zhang Zhiyi, Liu Ziyin", "title": "On the Distributional Properties of Adaptive Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive gradient methods have achieved remarkable success in training deep\nneural networks on a wide variety of tasks. However, not much is known about\nthe mathematical and statistical properties of this family of methods. This\nwork aims at providing a series of theoretical analyses of its statistical\nproperties justified by experiments. In particular, we show that when the\nunderlying gradient obeys a normal distribution, the variance of the magnitude\nof the \\textit{update} is an increasing and bounded function of time and does\nnot diverge. This work suggests that the divergence of variance is not the\ncause of the need for warm up of the Adam optimizer, contrary to what is\nbelieved in the current literature.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 13:45:16 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Zhiyi", "Zhang", ""], ["Ziyin", "Liu", ""]]}, {"id": "2105.07283", "submitter": "Dirk Tasche", "authors": "Dirk Tasche", "title": "Calibrating sufficiently", "comments": "26 pages, 2 figures, appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When probabilistic classifiers are trained and calibrated, the so-called\ngrouping loss component of the calibration loss can easily be overlooked.\nGrouping loss refers to the gap between observable information and information\nactually exploited in the calibration exercise. We investigate the relation\nbetween grouping loss and the concept of sufficiency, identifying\ncomonotonicity as a useful criterion for sufficiency. We revisit the probing\nreduction approach of Langford & Zadrozny (2005) and find that it produces an\nestimator of probabilistic classifiers that reduces grouping loss. Finally, we\ndiscuss Brier curves as tools to support training and 'sufficient' calibration\nof probabilistic classifiers.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 19:48:28 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 18:36:00 GMT"}, {"version": "v3", "created": "Sat, 29 May 2021 13:02:08 GMT"}, {"version": "v4", "created": "Sun, 25 Jul 2021 12:41:41 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tasche", "Dirk", ""]]}, {"id": "2105.07320", "submitter": "Vipul Gupta", "authors": "Vipul Gupta, Avishek Ghosh, Michal Derezinski, Rajiv Khanna, Kannan\n  Ramchandran, Michael Mahoney", "title": "LocalNewton: Reducing Communication Bottleneck for Distributed Learning", "comments": "To be published in Uncertainty in Artificial Intelligence (UAI) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address the communication bottleneck problem in distributed optimization\nwithin a master-worker framework, we propose LocalNewton, a distributed\nsecond-order algorithm with local averaging. In LocalNewton, the worker\nmachines update their model in every iteration by finding a suitable\nsecond-order descent direction using only the data and model stored in their\nown local memory. We let the workers run multiple such iterations locally and\ncommunicate the models to the master node only once every few (say L)\niterations. LocalNewton is highly practical since it requires only one\nhyperparameter, the number L of local iterations. We use novel matrix\nconcentration-based techniques to obtain theoretical guarantees for\nLocalNewton, and we validate them with detailed empirical evaluation. To\nenhance practicability, we devise an adaptive scheme to choose L, and we show\nthat this reduces the number of local iterations in worker machines between two\nmodel synchronizations as the training proceeds, successively refining the\nmodel quality at the master. Via extensive experiments using several real-world\ndatasets with AWS Lambda workers and an AWS EC2 master, we show that\nLocalNewton requires fewer than 60% of the communication rounds (between master\nand workers) and less than 40% of the end-to-end running time, compared to\nstate-of-the-art algorithms, to reach the same training~loss.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 00:15:08 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Gupta", "Vipul", ""], ["Ghosh", "Avishek", ""], ["Derezinski", "Michal", ""], ["Khanna", "Rajiv", ""], ["Ramchandran", "Kannan", ""], ["Mahoney", "Michael", ""]]}, {"id": "2105.07338", "submitter": "Ming-Kun Xie", "authors": "Ming-Kun Xie and Sheng-Jun Huang", "title": "CCMN: A General Framework for Learning with Class-Conditional\n  Multi-Label Noise", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class-conditional noise commonly exists in machine learning tasks, where the\nclass label is corrupted with a probability depending on its ground-truth. Many\nresearch efforts have been made to improve the model robustness against the\nclass-conditional noise. However, they typically focus on the single label case\nby assuming that only one label is corrupted. In real applications, an instance\nis usually associated with multiple labels, which could be corrupted\nsimultaneously with their respective conditional probabilities. In this paper,\nwe formalize this problem as a general framework of learning with\nClass-Conditional Multi-label Noise (CCMN for short). We establish two unbiased\nestimators with error bounds for solving the CCMN problems, and further prove\nthat they are consistent with commonly used multi-label loss functions.\nFinally, a new method for partial multi-label learning is implemented with\nunbiased estimator under the CCMN framework. Empirical studies on multiple\ndatasets and various evaluation metrics validate the effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 03:24:15 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Xie", "Ming-Kun", ""], ["Huang", "Sheng-Jun", ""]]}, {"id": "2105.07385", "submitter": "Haruka Asanuma", "authors": "Haruka Asanuma, Shiro Takagi, Yoshihiro Nagano, Yuki Yoshida, Yasuhiko\n  Igarashi, and Masato Okada", "title": "Statistical Mechanical Analysis of Catastrophic Forgetting in Continual\n  Learning with Teacher and Student Networks", "comments": "22 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a computational system continuously learns from an ever-changing\nenvironment, it rapidly forgets its past experiences. This phenomenon is called\ncatastrophic forgetting. While a line of studies has been proposed with respect\nto avoiding catastrophic forgetting, most of the methods are based on intuitive\ninsights into the phenomenon, and their performances have been evaluated by\nnumerical experiments using benchmark datasets. Therefore, in this study, we\nprovide the theoretical framework for analyzing catastrophic forgetting by\nusing teacher-student learning. Teacher-student learning is a framework in\nwhich we introduce two neural networks: one neural network is a target function\nin supervised learning, and the other is a learning neural network. To analyze\ncontinual learning in the teacher-student framework, we introduce the\nsimilarity of the input distribution and the input-output relationship of the\ntarget functions as the similarity of tasks. In this theoretical framework, we\nalso provide a qualitative understanding of how a single-layer linear learning\nneural network forgets tasks. Based on the analysis, we find that the network\ncan avoid catastrophic forgetting when the similarity among input distributions\nis small and that of the input-output relationship of the target functions is\nlarge. The analysis also suggests that a system often exhibits a characteristic\nphenomenon called overshoot, which means that even if the learning network has\nonce undergone catastrophic forgetting, it is possible that the network may\nperform reasonably well after further learning of the current task.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 09:02:48 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Asanuma", "Haruka", ""], ["Takagi", "Shiro", ""], ["Nagano", "Yoshihiro", ""], ["Yoshida", "Yuki", ""], ["Igarashi", "Yasuhiko", ""], ["Okada", "Masato", ""]]}, {"id": "2105.07416", "submitter": "Sebastian Goldt", "authors": "Sebastian Goldt, Florent Krzakala, Lenka Zdeborov\\'a, Nicolas Brunel", "title": "Bayesian reconstruction of memories stored in neural networks from their\n  connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of comprehensive synaptic wiring diagrams of large neural circuits\nhas created the field of connectomics and given rise to a number of open\nresearch questions. One such question is whether it is possible to reconstruct\nthe information stored in a recurrent network of neurons, given its synaptic\nconnectivity matrix. Here, we address this question by determining when solving\nsuch an inference problem is theoretically possible in specific attractor\nnetwork models and by providing a practical algorithm to do so. The algorithm\nbuilds on ideas from statistical physics to perform approximate Bayesian\ninference and is amenable to exact analysis. We study its performance on three\ndifferent models and explore the limitations of reconstructing stored patterns\nfrom synaptic connectivity.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 12:05:10 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Goldt", "Sebastian", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""], ["Brunel", "Nicolas", ""]]}, {"id": "2105.07446", "submitter": "Prem Talwai", "authors": "Prem Talwai, Ali Shameli, David Simchi-Levi", "title": "Sobolev Norm Learning Rates for Conditional Mean Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop novel learning rates for conditional mean embeddings by applying\nthe theory of interpolation for reproducing kernel Hilbert spaces (RKHS). We\nderive explicit, adaptive convergence rates for the sample estimator under the\nmisspecifed setting, where the target operator is not Hilbert-Schmidt or\nbounded with respect to the input/output RKHSs. We demonstrate that in certain\nparameter regimes, we can achieve uniform convergence rates in the output RKHS.\nWe hope our analyses will allow the much broader application of conditional\nmean embeddings to more complex ML/RL settings involving infinite dimensional\nRKHSs and continuous state spaces.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 14:43:54 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 07:33:28 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Talwai", "Prem", ""], ["Shameli", "Ali", ""], ["Simchi-Levi", "David", ""]]}, {"id": "2105.07536", "submitter": "Rong Ma", "authors": "T. Tony Cai and Rong Ma", "title": "Theoretical Foundations of t-SNE for Visualizing High-Dimensional\n  Clustered Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This study investigates the theoretical foundations of t-distributed\nstochastic neighbor embedding (t-SNE), a popular nonlinear dimension reduction\nand data visualization method. A novel theoretical framework for the analysis\nof t-SNE based on the gradient descent approach is presented. For the early\nexaggeration stage of t-SNE, we show its asymptotic equivalence to a power\niteration based on the underlying graph Laplacian, characterize its limiting\nbehavior, and uncover its deep connection to Laplacian spectral clustering, and\nfundamental principles including early stopping as implicit regularization. The\nresults explain the intrinsic mechanism and the empirical benefits of such a\ncomputational strategy. For the embedding stage of t-SNE, we characterize the\nkinematics of the low-dimensional map throughout the iterations, and identify\nan amplification phase, featuring the intercluster repulsion and the expansive\nbehavior of the low-dimensional map. The general theory explains the fast\nconvergence rate and the exceptional empirical performance of t-SNE for\nvisualizing clustered data, brings forth the interpretations of the t-SNE\noutput, and provides theoretical guidance for selecting tuning parameters in\nvarious applications.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 22:43:20 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 01:04:30 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Cai", "T. Tony", ""], ["Ma", "Rong", ""]]}, {"id": "2105.07593", "submitter": "Peter Karkus", "authors": "Peter Karkus, Shaojun Cai, David Hsu", "title": "Differentiable SLAM-net: Learning Particle SLAM for Visual Navigation", "comments": "CVPR 2021, extended results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simultaneous localization and mapping (SLAM) remains challenging for a number\nof downstream applications, such as visual robot navigation, because of rapid\nturns, featureless walls, and poor camera quality. We introduce the\nDifferentiable SLAM Network (SLAM-net) along with a navigation architecture to\nenable planar robot navigation in previously unseen indoor environments.\nSLAM-net encodes a particle filter based SLAM algorithm in a differentiable\ncomputation graph, and learns task-oriented neural network components by\nbackpropagating through the SLAM algorithm. Because it can optimize all model\ncomponents jointly for the end-objective, SLAM-net learns to be robust in\nchallenging conditions. We run experiments in the Habitat platform with\ndifferent real-world RGB and RGB-D datasets. SLAM-net significantly outperforms\nthe widely adapted ORB-SLAM in noisy conditions. Our navigation architecture\nwith SLAM-net improves the state-of-the-art for the Habitat Challenge 2020\nPointNav task by a large margin (37% to 64% success). Project website:\nhttp://sites.google.com/view/slamnet\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 03:54:34 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 14:12:02 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Karkus", "Peter", ""], ["Cai", "Shaojun", ""], ["Hsu", "David", ""]]}, {"id": "2105.07610", "submitter": "Maya Ramchandran", "authors": "Maya Ramchandran, Rajarshi Mukherjee, and Giovanni Parmigiani", "title": "Cross-Cluster Weighted Forests", "comments": "20 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adapting machine learning algorithms to better handle the presence of natural\nclustering or batch effects within training datasets is imperative across a\nwide variety of biological applications. This article considers the effect of\nensembling Random Forest learners trained on clusters within a single dataset\nwith heterogeneity in the distribution of the features. We find that\nconstructing ensembles of forests trained on clusters determined by algorithms\nsuch as k-means results in significant improvements in accuracy and\ngeneralizability over the traditional Random Forest algorithm. We denote our\nnovel approach as the Cross-Cluster Weighted Forest, and examine its robustness\nto various data-generating scenarios and outcome models. Furthermore, we\nexplore the influence of the data-partitioning and ensemble weighting\nstrategies on conferring the benefits of our method over the existing paradigm.\nFinally, we apply our approach to cancer molecular profiling and gene\nexpression datasets that are naturally divisible into clusters and illustrate\nthat our approach outperforms classic Random Forest. Code and supplementary\nmaterial are available at https://github.com/m-ramchandran/cross-cluster.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 04:58:29 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Ramchandran", "Maya", ""], ["Mukherjee", "Rajarshi", ""], ["Parmigiani", "Giovanni", ""]]}, {"id": "2105.07634", "submitter": "Sunil Kumar Maurya", "authors": "Sunil Kumar Maurya, Xin Liu and Tsuyoshi Murata", "title": "Improving Graph Neural Networks with Simple Architecture Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks have emerged as a useful tool to learn on the data by\napplying additional constraints based on the graph structure. These graphs are\noften created with assumed intrinsic relations between the entities. In recent\nyears, there have been tremendous improvements in the architecture design,\npushing the performance up in various prediction tasks. In general, these\nneural architectures combine layer depth and node feature aggregation steps.\nThis makes it challenging to analyze the importance of features at various hops\nand the expressiveness of the neural network layers. As different graph\ndatasets show varying levels of homophily and heterophily in features and class\nlabel distribution, it becomes essential to understand which features are\nimportant for the prediction tasks without any prior information. In this work,\nwe decouple the node feature aggregation step and depth of graph neural network\nand introduce several key design strategies for graph neural networks. More\nspecifically, we propose to use softmax as a regularizer and \"Soft-Selector\" of\nfeatures aggregated from neighbors at different hop distances; and\n\"Hop-Normalization\" over GNN layers. Combining these techniques, we present a\nsimple and shallow model, Feature Selection Graph Neural Network (FSGNN), and\nshow empirically that the proposed model outperforms other state of the art GNN\nmodels and achieves up to 64% improvements in accuracy on node classification\ntasks. Moreover, analyzing the learned soft-selection parameters of the model\nprovides a simple way to study the importance of features in the prediction\ntasks. Finally, we demonstrate with experiments that the model is scalable for\nlarge graphs with millions of nodes and billions of edges.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 06:46:01 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Maurya", "Sunil Kumar", ""], ["Liu", "Xin", ""], ["Murata", "Tsuyoshi", ""]]}, {"id": "2105.07636", "submitter": "Sauptik Dhar", "authors": "Sauptik Dhar, Bernardo Gonzalez Torres", "title": "DOC3-Deep One Class Classification using Contradictions", "comments": "Deep Learning, Anomaly Detection, Visual Inspection, Learning from\n  Contradictions, Outlier Exposure, 18 pages, 14 tables, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper introduces the notion of learning from contradictions (a.k.a\nUniversum learning) for deep one class classification problems. We formalize\nthis notion for the widely adopted one class large-margin loss, and propose the\nDeep One Class Classification using Contradictions (DOC3) algorithm. We show\nthat learning from contradictions incurs lower generalization error by\ncomparing the Empirical Radamacher Complexity (ERC) of DOC3 against its\ntraditional inductive learning counterpart. Our empirical results demonstrate\nthe efficacy of DOC3 algorithm achieving > 30% for CIFAR-10 and >50% for MV-Tec\nAD data sets in test AUCs compared to its inductive learning counterpart and in\nmany cases improving the state-of-the-art in anomaly detection.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 06:48:25 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Dhar", "Sauptik", ""], ["Torres", "Bernardo Gonzalez", ""]]}, {"id": "2105.07671", "submitter": "Petra Posedel \\v{S}imovi\\'c", "authors": "Petra Posedel \\v{S}imovi\\'c, Davor Horvatic, Edward W. Sun", "title": "Classifying variety of customer's online engagement for churn prediction\n  with mixed-penalty logistic regression", "comments": "This version is not sufficiently exhaustive; a wrong version of\n  validation results has been released (using a wrong part of a dataset for\n  validation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using big data to analyze consumer behavior can provide effective\ndecision-making tools for preventing customer attrition (churn) in customer\nrelationship management (CRM). Focusing on a CRM dataset with several different\ncategories of factors that impact customer heterogeneity (i.e., usage of\nself-care service channels, duration of service, and responsiveness to\nmarketing actions), we provide new predictive analytics of customer churn rate\nbased on a machine learning method that enhances the classification of logistic\nregression by adding a mixed penalty term. The proposed penalized logistic\nregression can prevent overfitting when dealing with big data and minimize the\nloss function when balancing the cost from the median (absolute value) and mean\n(squared value) regularization. We show the analytical properties of the\nproposed method and its computational advantage in this research. In addition,\nwe investigate the performance of the proposed method with a CRM data set (that\nhas a large number of features) under different settings by efficiently\neliminating the disturbance of (1) least important features and (2) sensitivity\nfrom the minority (churn) class. Our empirical results confirm the expected\nperformance of the proposed method in full compliance with the common\nclassification criteria (i.e., accuracy, precision, and recall) for evaluating\nmachine learning methods.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 08:40:34 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 15:25:20 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["\u0160imovi\u0107", "Petra Posedel", ""], ["Horvatic", "Davor", ""], ["Sun", "Edward W.", ""]]}, {"id": "2105.07729", "submitter": "Vinicius Luiz Santos Silva", "authors": "Vinicius L. S. Silva, Claire E. Heaney, Yaqi Li, Christopher C. Pain", "title": "Data Assimilation Predictive GAN (DA-PredGAN): applied to determine the\n  spread of COVID-19", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the novel use of a generative adversarial network (GAN) (i) to\nmake predictions in time (PredGAN) and (ii) to assimilate measurements\n(DA-PredGAN). In the latter case, we take advantage of the natural adjoint-like\nproperties of generative models and the ability to simulate forwards and\nbackwards in time. GANs have received much attention recently, after achieving\nexcellent results for their generation of realistic-looking images. We wish to\nexplore how this property translates to new applications in computational\nmodelling and to exploit the adjoint-like properties for efficient data\nassimilation. To predict the spread of COVID-19 in an idealised town, we apply\nthese methods to a compartmental model in epidemiology that is able to model\nspace and time variations. To do this, the GAN is set within a reduced-order\nmodel (ROM), which uses a low-dimensional space for the spatial distribution of\nthe simulation states. Then the GAN learns the evolution of the low-dimensional\nstates over time. The results show that the proposed methods can accurately\npredict the evolution of the high-fidelity numerical simulation, and can\nefficiently assimilate observed data and determine the corresponding model\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 10:56:53 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 14:55:29 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Silva", "Vinicius L. S.", ""], ["Heaney", "Claire E.", ""], ["Li", "Yaqi", ""], ["Pain", "Christopher C.", ""]]}, {"id": "2105.07743", "submitter": "Anastasis Kratsios", "authors": "Anastasis Kratsios", "title": "Universal Regular Conditional Distributions", "comments": "Keywords: Universal Regular Conditional Distributions, Geometric Deep\n  Learning, Measure-Valued Neural Networks, Conditional Expectation,\n  Uncertainty Quantification. Additional Information: 27 Pages + 22 Page\n  Appendix, 7 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE math.MG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a general framework for approximating regular conditional\ndistributions (RCDs). Our approximations of these RCDs are implemented by a new\nclass of geometric deep learning models with inputs in $\\mathbb{R}^d$ and\noutputs in the Wasserstein-$1$ space $\\mathcal{P}_1(\\mathbb{R}^D)$. We find\nthat the models built using our framework can approximate any continuous\nfunctions from $\\mathbb{R}^d$ to $\\mathcal{P}_1(\\mathbb{R}^D)$ uniformly on\ncompacts, and quantitative rates are obtained. We identify two methods for\navoiding the \"curse of dimensionality\"; i.e.: the number of parameters\ndetermining the approximating neural network depends only polynomially on the\ninvolved dimension and the approximation error. The first solution describes\nfunctions in $C(\\mathbb{R}^d,\\mathcal{P}_1(\\mathbb{R}^D))$ which can be\nefficiently approximated on any compact subset of $\\mathbb{R}^d$. Conversely,\nthe second approach describes sets in $\\mathbb{R}^d$, on which any function in\n$C(\\mathbb{R}^d,\\mathcal{P}_1(\\mathbb{R}^D))$ can be efficiently approximated.\nOur framework is used to obtain an affirmative answer to the open conjecture of\nBishop (1994); namely: mixture density networks are universal regular\nconditional distributions. The predictive performance of the proposed models is\nevaluated against comparable learning models on various probabilistic\npredictions tasks in the context of ELMs, model uncertainty, and\nheteroscedastic regression. All the results are obtained for more general input\nand output spaces and thus apply to geometric deep learning contexts.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 11:34:09 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 17:51:20 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Kratsios", "Anastasis", ""]]}, {"id": "2105.07829", "submitter": "Yuchen Zhong", "authors": "Yuchen Zhong, Cong Xie, Shuai Zheng, Haibin Lin", "title": "Compressed Communication for Distributed Training: Adaptive Methods and\n  System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication overhead severely hinders the scalability of distributed\nmachine learning systems. Recently, there has been a growing interest in using\ngradient compression to reduce the communication overhead of the distributed\ntraining. However, there is little understanding of applying gradient\ncompression to adaptive gradient methods. Moreover, its performance benefits\nare often limited by the non-negligible compression overhead. In this paper, we\nfirst introduce a novel adaptive gradient method with gradient compression. We\nshow that the proposed method has a convergence rate of\n$\\mathcal{O}(1/\\sqrt{T})$ for non-convex problems. In addition, we develop a\nscalable system called BytePS-Compress for two-way compression, where the\ngradients are compressed in both directions between workers and parameter\nservers. BytePS-Compress pipelines the compression and decompression on CPUs\nand achieves a high degree of parallelism. Empirical evaluations show that we\nimprove the training time of ResNet50, VGG16, and BERT-base by 5.0%, 58.1%,\n23.3%, respectively, without any accuracy loss with 25 Gb/s networking.\nFurthermore, for training the BERT models, we achieve a compression rate of\n333x compared to the mixed-precision training.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 13:41:47 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Zhong", "Yuchen", ""], ["Xie", "Cong", ""], ["Zheng", "Shuai", ""], ["Lin", "Haibin", ""]]}, {"id": "2105.07882", "submitter": "Max Hahn-Klimroth", "authors": "AminCoja-Oghlan, Max Hahn-Klimroth, Philipp Loick, Manuel Penschuck", "title": "Efficient and accurate group testing via Belief Propagation: an\n  empirical study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The group testing problem asks for efficient pooling schemes and algorithms\nthat allow to screen moderately large numbers of samples for rare infections.\nThe goal is to accurately identify the infected samples while conducting the\nleast possible number of tests. Exploring the use of techniques centred around\nthe Belief Propagation message passing algorithm, we suggest a new test design\nthat significantly increases the accuracy of the results. The new design comes\nwith Belief Propagation as an efficient inference algorithm. Aiming for results\non practical rather than asymptotic problem sizes, we conduct an experimental\nstudy.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 10:52:46 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["AminCoja-Oghlan", "", ""], ["Hahn-Klimroth", "Max", ""], ["Loick", "Philipp", ""], ["Penschuck", "Manuel", ""]]}, {"id": "2105.07900", "submitter": "Kazuma Tsuji", "authors": "Kazuma Tsuji and Ken'ichiro Tanaka", "title": "Acceleration of the kernel herding algorithm by improved gradient\n  approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel herding is a method used to construct quadrature formulas in a\nreproducing kernel Hilbert space. Although there are some advantages of kernel\nherding, such as numerical stability of quadrature and effective outputs of\nnodes and weights, the convergence speed of worst-case integration error is\nslow in comparison to other quadrature methods. To address this problem, we\npropose two improved versions of the kernel herding algorithm. The fundamental\nconcept of both algorithms involves approximating negative gradients with a\npositive linear combination of vertex directions. We analyzed the convergence\nand validity of both algorithms theoretically; in particular, we showed that\nthe approximation of negative gradients directly influences the convergence\nspeed. In addition, we confirmed the accelerated convergence of the worst-case\nintegration error with respect to the number of nodes and computational time\nthrough numerical experiments.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 14:32:45 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Tsuji", "Kazuma", ""], ["Tanaka", "Ken'ichiro", ""]]}, {"id": "2105.07911", "submitter": "Kuan Xu", "authors": "Kuan Xuan, Yongbo Wang, Yongliang Wang, Zujie Wen, Yang Dong", "title": "SeaD: End-to-end Text-to-SQL Generation with Schema-aware Denoising", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In text-to-SQL task, seq-to-seq models often lead to sub-optimal performance\ndue to limitations in their architecture. In this paper, we present a simple\nyet effective approach that adapts transformer-based seq-to-seq model to robust\ntext-to-SQL generation. Instead of inducing constraint to decoder or reformat\nthe task as slot-filling, we propose to train seq-to-seq model with Schema\naware Denoising (SeaD), which consists of two denoising objectives that train\nmodel to either recover input or predict output from two novel erosion and\nshuffle noises. These denoising objectives acts as the auxiliary tasks for\nbetter modeling the structural data in S2S generation. In addition, we improve\nand propose a clause-sensitive execution guided (EG) decoding strategy to\novercome the limitation of EG decoding for generative model. The experiments\nshow that the proposed method improves the performance of seq-to-seq model in\nboth schema linking and grammar correctness and establishes new\nstate-of-the-art on WikiSQL benchmark. The results indicate that the capacity\nof vanilla seq-to-seq architecture for text-to-SQL may have been\nunder-estimated.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 14:49:54 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Xuan", "Kuan", ""], ["Wang", "Yongbo", ""], ["Wang", "Yongliang", ""], ["Wen", "Zujie", ""], ["Dong", "Yang", ""]]}, {"id": "2105.07957", "submitter": "Daniel Tanneberg", "authors": "Daniel Tanneberg, Elmar Rueckert, Jan Peters", "title": "Evolutionary Training and Abstraction Yields Algorithmic Generalization\n  of Neural Computers", "comments": "Nature Machine Intelligence", "journal-ref": "Nature Machine Intelligence, Vol. 2, December 2020, 753-763", "doi": "10.1038/s42256-020-00255-1", "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key feature of intelligent behaviour is the ability to learn abstract\nstrategies that scale and transfer to unfamiliar problems. An abstract strategy\nsolves every sample from a problem class, no matter its representation or\ncomplexity -- like algorithms in computer science. Neural networks are powerful\nmodels for processing sensory data, discovering hidden patterns, and learning\ncomplex functions, but they struggle to learn such iterative, sequential or\nhierarchical algorithmic strategies. Extending neural networks with external\nmemories has increased their capacities in learning such strategies, but they\nare still prone to data variations, struggle to learn scalable and transferable\nsolutions, and require massive training data. We present the Neural Harvard\nComputer (NHC), a memory-augmented network based architecture, that employs\nabstraction by decoupling algorithmic operations from data manipulations,\nrealized by splitting the information flow and separated modules. This\nabstraction mechanism and evolutionary training enable the learning of robust\nand scalable algorithmic solutions. On a diverse set of 11 algorithms with\nvarying complexities, we show that the NHC reliably learns algorithmic\nsolutions with strong generalization and abstraction: perfect generalization\nand scaling to arbitrary task configurations and complexities far beyond seen\nduring training, and being independent of the data representation and the task\ndomain.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 15:37:32 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Tanneberg", "Daniel", ""], ["Rueckert", "Elmar", ""], ["Peters", "Jan", ""]]}, {"id": "2105.08005", "submitter": "Ainesh Bakshi", "authors": "Ainesh Bakshi, Chiranjib Bhattacharyya, Ravi Kannan, David P. Woodruff\n  and Samson Zhou", "title": "Learning a Latent Simplex in Input-Sparsity Time", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of learning a latent $k$-vertex simplex\n$K\\subset\\mathbb{R}^d$, given access to $A\\in\\mathbb{R}^{d\\times n}$, which can\nbe viewed as a data matrix with $n$ points that are obtained by randomly\nperturbing latent points in the simplex $K$ (potentially beyond $K$). A large\nclass of latent variable models, such as adversarial clustering, mixed\nmembership stochastic block models, and topic models can be cast as learning a\nlatent simplex. Bhattacharyya and Kannan (SODA, 2020) give an algorithm for\nlearning such a latent simplex in time roughly $O(k\\cdot\\textrm{nnz}(A))$,\nwhere $\\textrm{nnz}(A)$ is the number of non-zeros in $A$. We show that the\ndependence on $k$ in the running time is unnecessary given a natural assumption\nabout the mass of the top $k$ singular values of $A$, which holds in many of\nthese applications. Further, we show this assumption is necessary, as otherwise\nan algorithm for learning a latent simplex would imply an algorithmic\nbreakthrough for spectral low rank approximation.\n  At a high level, Bhattacharyya and Kannan provide an adaptive algorithm that\nmakes $k$ matrix-vector product queries to $A$ and each query is a function of\nall queries preceding it. Since each matrix-vector product requires\n$\\textrm{nnz}(A)$ time, their overall running time appears unavoidable.\nInstead, we obtain a low-rank approximation to $A$ in input-sparsity time and\nshow that the column space thus obtained has small $\\sin\\Theta$ (angular)\ndistance to the right top-$k$ singular space of $A$. Our algorithm then selects\n$k$ points in the low-rank subspace with the largest inner product with $k$\ncarefully chosen random vectors. By working in the low-rank subspace, we avoid\nreading the entire matrix in each iteration and thus circumvent the\n$\\Theta(k\\cdot\\textrm{nnz}(A))$ running time.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 16:40:48 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Bakshi", "Ainesh", ""], ["Bhattacharyya", "Chiranjib", ""], ["Kannan", "Ravi", ""], ["Woodruff", "David P.", ""], ["Zhou", "Samson", ""]]}, {"id": "2105.08013", "submitter": "Benjamin Seiler", "authors": "Benjamin B. Seiler, Masayoshi Mase, Art B. Owen", "title": "What makes you unique?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes a uniqueness Shapley measure to compare the extent to\nwhich different variables are able to identify a subject. Revealing the value\nof a variable on subject $t$ shrinks the set of possible subjects that $t$\ncould be. The extent of the shrinkage depends on which other variables have\nalso been revealed. We use Shapley value to combine all of the reductions in\nlog cardinality due to revealing a variable after some subset of the other\nvariables has been revealed. This uniqueness Shapley measure can be aggregated\nover subjects where it becomes a weighted sum of conditional entropies.\nAggregation over subsets of subjects can address questions like how identifying\nis age for people of a given zip code. Such aggregates have a corresponding\nexpression in terms of cross entropies. We use uniqueness Shapley to\ninvestigate the differential effects of revealing variables from the North\nCarolina voter registration rolls and in identifying anomalous solar flares. An\nenormous speedup (approaching 2000 fold in one example) is obtained by using\nthe all dimension trees of Moore and Lee (1998) to store the cardinalities we\nneed.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 16:53:16 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Seiler", "Benjamin B.", ""], ["Mase", "Masayoshi", ""], ["Owen", "Art B.", ""]]}, {"id": "2105.08024", "submitter": "Yuting Wei", "authors": "Gen Li, Yuxin Chen, Yuejie Chi, Yuantao Gu, Yuting Wei", "title": "Sample-Efficient Reinforcement Learning Is Feasible for Linearly\n  Realizable MDPs with Limited Revisiting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Low-complexity models such as linear function representation play a pivotal\nrole in enabling sample-efficient reinforcement learning (RL). The current\npaper pertains to a scenario with value-based linear representation, which\npostulates the linear realizability of the optimal Q-function (also called the\n\"linear $Q^{\\star}$ problem\"). While linear realizability alone does not allow\nfor sample-efficient solutions in general, the presence of a large\nsub-optimality gap is a potential game changer, depending on the sampling\nmechanism in use. Informally, sample efficiency is achievable with a large\nsub-optimality gap when a generative model is available but is unfortunately\ninfeasible when we turn to standard online RL settings.\n  In this paper, we make progress towards understanding this linear $Q^{\\star}$\nproblem by investigating a new sampling protocol, which draws samples in an\nonline/exploratory fashion but allows one to backtrack and revisit previous\nstates in a controlled and infrequent manner. This protocol is more flexible\nthan the standard online RL setting, while being practically relevant and far\nmore restrictive than the generative model. We develop an algorithm tailored to\nthis setting, achieving a sample complexity that scales polynomially with the\nfeature dimension, the horizon, and the inverse sub-optimality gap, but not the\nsize of the state/action space. Our findings underscore the fundamental\ninterplay between sampling protocols and low-complexity structural\nrepresentation in RL.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 17:22:07 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Li", "Gen", ""], ["Chen", "Yuxin", ""], ["Chi", "Yuejie", ""], ["Gu", "Yuantao", ""], ["Wei", "Yuting", ""]]}, {"id": "2105.08164", "submitter": "John Thickstun", "authors": "Vivek Jayaram, John Thickstun", "title": "Parallel and Flexible Sampling from Autoregressive Models via Langevin\n  Dynamics", "comments": "16 pages, 8 figures, to appear in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an alternative approach to sampling from autoregressive\nmodels. Autoregressive models are typically sampled sequentially, according to\nthe transition dynamics defined by the model. Instead, we propose a sampling\nprocedure that initializes a sequence with white noise and follows a Markov\nchain defined by Langevin dynamics on the global log-likelihood of the\nsequence. This approach parallelizes the sampling process and generalizes to\nconditional sampling. Using an autoregressive model as a Bayesian prior, we can\nsteer the output of a generative model using a conditional likelihood or\nconstraints. We apply these techniques to autoregressive models in the visual\nand audio domains, with competitive results for audio source separation,\nsuper-resolution, and inpainting.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 21:07:02 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Jayaram", "Vivek", ""], ["Thickstun", "John", ""]]}, {"id": "2105.08195", "submitter": "Samuel Daulton", "authors": "Samuel Daulton, Maximilian Balandat, Eytan Bakshy", "title": "Parallel Bayesian Optimization of Multiple Noisy Objectives with\n  Expected Hypervolume Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing multiple competing black-box objectives is a challenging problem\nin many fields, including science, engineering, and machine learning.\nMulti-objective Bayesian optimization is a powerful approach for identifying\nthe optimal trade-offs between the objectives with very few function\nevaluations. However, existing methods tend to perform poorly when observations\nare corrupted by noise, as they do not take into account uncertainty in the\ntrue Pareto frontier over the previously evaluated designs. We propose a novel\nacquisition function, NEHVI, that overcomes this important practical limitation\nby applying a Bayesian treatment to the popular expected hypervolume\nimprovement criterion to integrate over this uncertainty in the Pareto\nfrontier. We further argue that, even in the noiseless setting, the problem of\ngenerating multiple candidates in parallel reduces that of handling uncertainty\nin the Pareto frontier. Through this lens, we derive a natural parallel variant\nof NEHVI that can efficiently generate large batches of candidates. We provide\na theoretical convergence guarantee for optimizing a Monte Carlo estimator of\nNEHVI using exact sample-path gradients. Empirically, we show that NEHVI\nachieves state-of-the-art performance in noisy and large-batch environments.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 23:31:42 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Daulton", "Samuel", ""], ["Balandat", "Maximilian", ""], ["Bakshy", "Eytan", ""]]}, {"id": "2105.08232", "submitter": "Ziye Ma", "authors": "Ziye Ma, Yingjie Bi, Javad Lavaei, Somayeh Sojoudi", "title": "Sharp Restricted Isometry Property Bounds for Low-rank Matrix Recovery\n  Problems with Corrupted Measurements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a general low-rank matrix recovery problem with\nlinear measurements corrupted by some noise. The objective is to understand\nunder what conditions on the restricted isometry property (RIP) of the problem\nlocal search methods can find the ground truth with a small error. By analyzing\nthe landscape of the non-convex problem, we first propose a global guarantee on\nthe maximum distance between an arbitrary local minimizer and the ground truth\nunder the assumption that the RIP constant is smaller than 1/2. We show that\nthis distance shrinks to zero as the intensity of the noise reduces. Our new\nguarantee is sharp in terms of the RIP constant and is much stronger than the\nexisting results. We then present a local guarantee for problems with an\narbitrary RIP constant, which states that any local minimizer is either\nconsiderably close to the ground truth or far away from it. The developed\nresults demonstrate how the noise intensity and the RIP constant of the problem\naffect the locations of the local minima relative to the true solution.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 02:17:59 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Ma", "Ziye", ""], ["Bi", "Yingjie", ""], ["Lavaei", "Javad", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "2105.08233", "submitter": "Gang Qiao", "authors": "Gang Qiao, Weijie J. Su, Li Zhang", "title": "Oneshot Differentially Private Top-k Selection", "comments": "Accepted to ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Being able to efficiently and accurately select the top-$k$ elements with\ndifferential privacy is an integral component of various private data analysis\ntasks. In this paper, we present the oneshot Laplace mechanism, which\ngeneralizes the well-known Report Noisy Max mechanism to reporting noisy\ntop-$k$ elements. We show that the oneshot Laplace mechanism with a noise level\nof $\\widetilde{O}(\\sqrt{k}/\\eps)$ is approximately differentially private.\nCompared to the previous peeling approach of running Report Noisy Max $k$\ntimes, the oneshot Laplace mechanism only adds noises and computes the top $k$\nelements once, hence much more efficient for large $k$. In addition, our proof\nof privacy relies on a novel coupling technique that bypasses the use of\ncomposition theorems. Finally, we present a novel application of efficient\ntop-$k$ selection in the classical problem of ranking from pairwise\ncomparisons.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 02:18:01 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 17:32:13 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Qiao", "Gang", ""], ["Su", "Weijie J.", ""], ["Zhang", "Li", ""]]}, {"id": "2105.08285", "submitter": "Zhaozhuo Xu", "authors": "Anshumali Shrivastava, Zhao Song, Zhaozhuo Xu", "title": "Sublinear Least-Squares Value Iteration via Locality Sensitive Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present the first provable Least-Squares Value Iteration (LSVI) algorithms\nthat have runtime complexity sublinear in the number of actions. We formulate\nthe value function estimation procedure in value iteration as an approximate\nmaximum inner product search problem and propose a locality sensitive hashing\n(LSH) [Indyk and Motwani STOC'98, Andoni and Razenshteyn STOC'15, Andoni,\nLaarhoven, Razenshteyn and Waingarten SODA'17] type data structure to solve\nthis problem with sublinear time complexity. Moreover, we build the connections\nbetween the theory of approximate maximum inner product search and the regret\nanalysis of reinforcement learning. We prove that, with our choice of\napproximation factor, our Sublinear LSVI algorithms maintain the same regret as\nthe original LSVI algorithms while reducing the runtime complexity to sublinear\nin the number of actions. To the best of our knowledge, this is the first work\nthat combines LSH with reinforcement learning resulting in provable\nimprovements. We hope that our novel way of combining data-structures and\niterative algorithm will open the door for further study into cost reduction in\noptimization.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 05:23:53 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 16:45:58 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Shrivastava", "Anshumali", ""], ["Song", "Zhao", ""], ["Xu", "Zhaozhuo", ""]]}, {"id": "2105.08304", "submitter": "Jesus Cerquides", "authors": "Jesus Cerquides", "title": "Parametrization invariant interpretation of priors and posteriors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we leverage on probability over Riemannian manifolds to rethink\nthe interpretation of priors and posteriors in Bayesian inference. The main\nmindshift is to move away from the idea that \"a prior distribution establishes\na probability distribution over the parameters of our model\" to the idea that\n\"a prior distribution establishes a probability distribution over probability\ndistributions\". To do that we assume that our probabilistic model is a\nRiemannian manifold with the Fisher metric. Under this mindset, any\ndistribution over probability distributions should be \"intrinsic\", that is,\ninvariant to the specific parametrization which is selected for the manifold.\nWe exemplify our ideas through a simple analysis of distributions over the\nmanifold of Bernoulli distributions. One of the major shortcomings of maximum a\nposteriori estimates is that they depend on the parametrization. Based on the\nunderstanding developed here, we can define the maximum a posteriori estimate\nwhich is independent of the parametrization.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 06:45:05 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 20:11:27 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Cerquides", "Jesus", ""]]}, {"id": "2105.08306", "submitter": "Kiran Koshy Thekumparampil", "authors": "Kiran Koshy Thekumparampil, Prateek Jain, Praneeth Netrapalli, Sewoong\n  Oh", "title": "Sample Efficient Linear Meta-Learning by Alternating Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning synthesizes and leverages the knowledge from a given set of\ntasks to rapidly learn new tasks using very little data. Meta-learning of\nlinear regression tasks, where the regressors lie in a low-dimensional\nsubspace, is an extensively-studied fundamental problem in this domain.\nHowever, existing results either guarantee highly suboptimal estimation errors,\nor require $\\Omega(d)$ samples per task (where $d$ is the data dimensionality)\nthus providing little gain over separately learning each task. In this work, we\nstudy a simple alternating minimization method (MLLAM), which alternately\nlearns the low-dimensional subspace and the regressors. We show that, for a\nconstant subspace dimension MLLAM obtains nearly-optimal estimation error,\ndespite requiring only $\\Omega(\\log d)$ samples per task. However, the number\nof samples required per task grows logarithmically with the number of tasks. To\nremedy this in the low-noise regime, we propose a novel task subset selection\nscheme that ensures the same strong statistical guarantee as MLLAM, even with\nbounded number of samples per task for arbitrarily large number of tasks.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 06:46:48 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Thekumparampil", "Kiran Koshy", ""], ["Jain", "Prateek", ""], ["Netrapalli", "Praneeth", ""], ["Oh", "Sewoong", ""]]}, {"id": "2105.08310", "submitter": "Dave Cliff", "authors": "Dave Cliff", "title": "BBE: Simulating the Microstructural Dynamics of an In-Play Betting\n  Exchange via Agent-Based Modelling", "comments": "47 pages, 9 figures, 120 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CE q-fin.CP q-fin.TR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I describe the rationale for, and design of, an agent-based simulation model\nof a contemporary online sports-betting exchange: such exchanges, closely\nrelated to the exchange mechanisms at the heart of major financial markets,\nhave revolutionized the gambling industry in the past 20 years, but gathering\nsufficiently large quantities of rich and temporally high-resolution data from\nreal exchanges - i.e., the sort of data that is needed in large quantities for\nDeep Learning - is often very expensive, and sometimes simply impossible; this\ncreates a need for a plausibly realistic synthetic data generator, which is\nwhat this simulation now provides. The simulator, named the \"Bristol Betting\nExchange\" (BBE), is intended as a common platform, a data-source and\nexperimental test-bed, for researchers studying the application of AI and\nmachine learning (ML) techniques to issues arising in betting exchanges; and,\nas far as I have been able to determine, BBE is the first of its kind: a free\nopen-source agent-based simulation model consisting not only of a\nsports-betting exchange, but also a minimal simulation model of racetrack\nsporting events (e.g., horse-races or car-races) about which bets may be made,\nand a population of simulated bettors who each form their own private\nevaluation of odds and place bets on the exchange before and - crucially -\nduring the race itself (i.e., so-called \"in-play\" betting) and whose betting\nopinions change second-by-second as each race event unfolds. BBE is offered as\na proof-of-concept system that enables the generation of large high-resolution\ndata-sets for automated discovery or improvement of profitable strategies for\nbetting on sporting events via the application of AI/ML and advanced data\nanalytics techniques. This paper offers an extensive survey of relevant\nliterature and explains the motivation and design of BBE, and presents brief\nillustrative results.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 06:52:08 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Cliff", "Dave", ""]]}, {"id": "2105.08348", "submitter": "Canh Hao Nguyen", "authors": "Canh Hao Nguyen, Hiroshi Mamitsuka", "title": "On Convex Clustering Solutions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Convex clustering is an attractive clustering algorithm with favorable\nproperties such as efficiency and optimality owing to its convex formulation.\nIt is thought to generalize both k-means clustering and agglomerative\nclustering. However, it is not known whether convex clustering preserves\ndesirable properties of these algorithms. A common expectation is that convex\nclustering may learn difficult cluster types such as non-convex ones. Current\nunderstanding of convex clustering is limited to only consistency results on\nwell-separated clusters. We show new understanding of its solutions. We prove\nthat convex clustering can only learn convex clusters. We then show that the\nclusters have disjoint bounding balls with significant gaps. We further\ncharacterize the solutions, regularization hyperparameters, inclusterable cases\nand consistency.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 08:19:29 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Nguyen", "Canh Hao", ""], ["Mamitsuka", "Hiroshi", ""]]}, {"id": "2105.08399", "submitter": "Ond\\v{r}ej C\\'ifka", "authors": "Antoine Liutkus, Ond\\v{r}ej C\\'ifka, Shih-Lun Wu, Umut\n  \\c{S}im\\c{s}ekli, Yi-Hsuan Yang, Ga\\\"el Richard", "title": "Relative Positional Encoding for Transformers with Linear Complexity", "comments": "ICML 2021 (long talk) camera-ready. 24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Transformer models allow for unprecedented sequence\nlengths, due to linear space and time complexity. In the meantime, relative\npositional encoding (RPE) was proposed as beneficial for classical Transformers\nand consists in exploiting lags instead of absolute positions for inference.\nStill, RPE is not available for the recent linear-variants of the Transformer,\nbecause it requires the explicit computation of the attention matrix, which is\nprecisely what is avoided by such methods. In this paper, we bridge this gap\nand present Stochastic Positional Encoding as a way to generate PE that can be\nused as a replacement to the classical additive (sinusoidal) PE and provably\nbehaves like RPE. The main theoretical contribution is to make a connection\nbetween positional encoding and cross-covariance structures of correlated\nGaussian processes. We illustrate the performance of our approach on the\nLong-Range Arena benchmark and on music generation.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 09:52:32 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 08:55:58 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Liutkus", "Antoine", ""], ["C\u00edfka", "Ond\u0159ej", ""], ["Wu", "Shih-Lun", ""], ["\u015eim\u015fekli", "Umut", ""], ["Yang", "Yi-Hsuan", ""], ["Richard", "Ga\u00ebl", ""]]}, {"id": "2105.08532", "submitter": "Muhammad Osama", "authors": "Muhammad Osama, Dave Zachariah, Petre Stoica", "title": "Distributionally Robust Learning in Heterogeneous Contexts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning from training data obtained in different\ncontexts, where the test data is subject to distributional shifts. We develop a\ndistributionally robust method that focuses on excess risks and achieves a more\nappropriate trade-off between performance and robustness than the conventional\nand overly conservative minimax approach. The proposed method is\ncomputationally feasible and provides statistical guarantees. We demonstrate\nits performance using both real and synthetic data.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 14:00:34 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Osama", "Muhammad", ""], ["Zachariah", "Dave", ""], ["Stoica", "Petre", ""]]}, {"id": "2105.08620", "submitter": "Yao Li", "authors": "Yao Li, Tongyi Tang, Cho-Jui Hsieh, Thomas C. M. Lee", "title": "Detecting Adversarial Examples with Bayesian Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a new framework to detect adversarial examples\nmotivated by the observations that random components can improve the smoothness\nof predictors and make it easier to simulate output distribution of deep neural\nnetwork. With these observations, we propose a novel Bayesian adversarial\nexample detector, short for BATer, to improve the performance of adversarial\nexample detection. In specific, we study the distributional difference of\nhidden layer output between natural and adversarial examples, and propose to\nuse the randomness of Bayesian neural network (BNN) to simulate hidden layer\noutput distribution and leverage the distribution dispersion to detect\nadversarial examples. The advantage of BNN is that the output is stochastic\nwhile neural networks without random components do not have such\ncharacteristics. Empirical results on several benchmark datasets against\npopular attacks show that the proposed BATer outperforms the state-of-the-art\ndetectors in adversarial example detection.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 15:51:24 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 20:04:48 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Li", "Yao", ""], ["Tang", "Tongyi", ""], ["Hsieh", "Cho-Jui", ""], ["Lee", "Thomas C. M.", ""]]}, {"id": "2105.08675", "submitter": "Christoph Hertrich", "authors": "Vincent Froese, Christoph Hertrich, Rolf Niedermeier", "title": "The Computational Complexity of ReLU Network Training Parameterized by\n  Data Dimensionality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC cs.DS cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the computational complexity of training simple neural networks\nwith rectified linear units (ReLUs) has recently been a subject of intensive\nresearch. Closing gaps and complementing results from the literature, we\npresent several results on the parameterized complexity of training two-layer\nReLU networks with respect to various loss functions. After a brief discussion\nof other parameters, we focus on analyzing the influence of the dimension $d$\nof the training data on the computational complexity. We provide running time\nlower bounds in terms of W[1]-hardness for parameter $d$ and prove that known\nbrute-force strategies are essentially optimal (assuming the Exponential Time\nHypothesis). In comparison with previous work, our results hold for a broad(er)\nrange of loss functions, including $\\ell^p$-loss for all $p\\in[0,\\infty]$. In\nparticular, we extend a known polynomial-time algorithm for constant $d$ and\nconvex loss functions to a more general class of loss functions, matching our\nrunning time lower bounds also in these cases.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:05:26 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 08:32:12 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Froese", "Vincent", ""], ["Hertrich", "Christoph", ""], ["Niedermeier", "Rolf", ""]]}, {"id": "2105.08678", "submitter": "Krishnakumar Balasubramanian", "authors": "Krishnakumar Balasubramanian", "title": "Nonparametric Modeling of Higher-Order Interactions via Hypergraphons", "comments": "To appear in Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We study statistical and algorithmic aspects of using hypergraphons, that are\nlimits of large hypergraphs, for modeling higher-order interactions. Although\nhypergraphons are extremely powerful from a modeling perspective, we consider a\nrestricted class of Simple Lipschitz Hypergraphons (SLH), that are amenable to\npractically efficient estimation. We also provide rates of convergence for our\nestimator that are optimal for the class of SLH. Simulation results are\nprovided to corroborate the theory.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:08:29 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Balasubramanian", "Krishnakumar", ""]]}, {"id": "2105.08717", "submitter": "Michele Ceriotti", "authors": "Alexander Goscinski, F\\'elix Musil, Sergey Pozdnyakov, and Michele\n  Ceriotti", "title": "Optimal radial basis for density-based atomic representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The input of almost every machine learning algorithm targeting the properties\nof matter at the atomic scale involves a transformation of the list of\nCartesian atomic coordinates into a more symmetric representation. Many of\nthese most popular representations can be seen as an expansion of the\nsymmetrized correlations of the atom density, and differ mainly by the choice\nof basis. Here we discuss how to build an adaptive, optimal numerical basis\nthat is chosen to represent most efficiently the structural diversity of the\ndataset at hand. For each training dataset, this optimal basis is unique, and\ncan be computed at no additional cost with respect to the primitive basis by\napproximating it with splines. We demonstrate that this construction yields\nrepresentations that are accurate and computationally efficient, presenting\nexamples that involve both molecular and condensed-phase machine-learning\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:57:08 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Goscinski", "Alexander", ""], ["Musil", "F\u00e9lix", ""], ["Pozdnyakov", "Sergey", ""], ["Ceriotti", "Michele", ""]]}, {"id": "2105.08747", "submitter": "Matteo Sesia", "authors": "Matteo Sesia, Yaniv Romano", "title": "Conformal histogram regression", "comments": "11 pages, 4 figures. Supplement: 13 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a conformal method to compute prediction intervals for\nnon-parametric regression that can automatically adapt to skewed data.\nLeveraging black-box machine learning algorithms to estimate the conditional\ndistribution of the outcome using histograms, it translates their output into\nthe shortest prediction intervals with approximate conditional coverage. The\nresulting prediction intervals provably have marginal coverage in finite\nsamples, while asymptotically achieving conditional coverage and optimal length\nif the black-box model is consistent. Numerical experiments with simulated and\nreal data demonstrate improved performance compared to state-of-the-art\nalternatives, including conformalized quantile regression and other\ndistributional conformal prediction approaches.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 18:05:02 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Sesia", "Matteo", ""], ["Romano", "Yaniv", ""]]}, {"id": "2105.08866", "submitter": "Suhas Vijaykumar", "authors": "Suhas Vijaykumar", "title": "Localization, Convexity, and Star Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Offset Rademacher complexities have been shown to imply sharp, data-dependent\nupper bounds for the square loss in a broad class of problems including\nimproper statistical learning and online learning. We show that in the\nstatistical setting, the offset complexity upper bound can be generalized to\nany loss satisfying a certain uniform convexity condition. Amazingly, this\ncondition is shown to also capture exponential concavity and self-concordance,\nuniting several apparently disparate results. By a unified geometric argument,\nthese bounds translate directly to improper learning in a non-convex class\nusing Audibert's \"star algorithm.\" As applications, we recover the optimal\nrates for proper and improper learning with the $p$-loss, $1 < p < \\infty$ and\nshow that improper variants of empirical risk minimization can attain fast\nrates for logistic regression and other generalized linear models.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 00:47:59 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 15:36:56 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Vijaykumar", "Suhas", ""]]}, {"id": "2105.08869", "submitter": "Tianchen Zhou", "authors": "Tianchen Zhou, Jia Liu, Chaosheng Dong, Jingyuan Deng", "title": "Incentivized Bandit Learning with Self-Reinforcing User Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate a new multi-armed bandit (MAB) online learning\nmodel that considers real-world phenomena in many recommender systems: (i) the\nlearning agent cannot pull the arms by itself and thus has to offer rewards to\nusers to incentivize arm-pulling indirectly; and (ii) if users with specific\narm preferences are well rewarded, they induce a \"self-reinforcing\" effect in\nthe sense that they will attract more users of similar arm preferences. Besides\naddressing the tradeoff of exploration and exploitation, another key feature of\nthis new MAB model is to balance reward and incentivizing payment. The goal of\nthe agent is to maximize the total reward over a fixed time horizon $T$ with a\nlow total payment. Our contributions in this paper are two-fold: (i) We propose\na new MAB model with random arm selection that considers the relationship of\nusers' self-reinforcing preferences and incentives; and (ii) We leverage the\nproperties of a multi-color Polya urn with nonlinear feedback model to propose\ntwo MAB policies termed \"At-Least-$n$ Explore-Then-Commit\" and \"UCB-List\". We\nprove that both policies achieve $O(log T)$ expected regret with $O(log T)$\nexpected payment over a time horizon $T$. We conduct numerical simulations to\ndemonstrate and verify the performances of these two policies and study their\nrobustness under various settings.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 01:06:32 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 05:44:36 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 03:15:05 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhou", "Tianchen", ""], ["Liu", "Jia", ""], ["Dong", "Chaosheng", ""], ["Deng", "Jingyuan", ""]]}, {"id": "2105.08875", "submitter": "Nicholas Sterge", "authors": "Nicholas Sterge, Bharath Sriperumbudur", "title": "Statistical Optimality and Computational Efficiency of Nystr\\\"om Kernel\n  PCA", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Kernel methods provide an elegant framework for developing nonlinear learning\nalgorithms from simple linear methods. Though these methods have superior\nempirical performance in several real data applications, their usefulness is\ninhibited by the significant computational burden incurred in large sample\nsituations. Various approximation schemes have been proposed in the literature\nto alleviate these computational issues, and the approximate kernel machines\nare shown to retain the empirical performance. However, the theoretical\nproperties of these approximate kernel machines are less well understood. In\nthis work, we theoretically study the trade-off between computational\ncomplexity and statistical accuracy in Nystr\\\"om approximate kernel principal\ncomponent analysis (KPCA), wherein we show that the Nystr\\\"om approximate KPCA\nmatches the statistical performance of (non-approximate) KPCA while remaining\ncomputationally beneficial. Additionally, we show that Nystr\\\"om approximate\nKPCA outperforms the statistical behavior of another popular approximation\nscheme, the random feature approximation, when applied to KPCA.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 01:49:35 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Sterge", "Nicholas", ""], ["Sriperumbudur", "Bharath", ""]]}, {"id": "2105.08966", "submitter": "Fabio Sigrist", "authors": "Fabio Sigrist", "title": "Latent Gaussian Model Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Gaussian models and boosting are widely used techniques in statistics\nand machine learning. Tree-boosting shows excellent predictive accuracy on many\ndata sets, but potential drawbacks are that it assumes conditional independence\nof samples, produces discontinuous predictions for, e.g., spatial data, and it\ncan have difficulty with high-cardinality categorical variables. Latent\nGaussian models, such as Gaussian process and grouped random effects models,\nare flexible prior models that allow for making probabilistic predictions.\nHowever, existing latent Gaussian models usually assume either a zero or a\nlinear prior mean function which can be an unrealistic assumption. This article\nintroduces a novel approach that combines boosting and latent Gaussian models\nin order to remedy the above-mentioned drawbacks and to leverage the advantages\nof both techniques. We obtain increased predictive accuracy compared to\nexisting approaches in both simulated and real-world data experiments.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 07:36:30 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 13:42:12 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Sigrist", "Fabio", ""]]}, {"id": "2105.09016", "submitter": "Emiel Hoogeboom", "authors": "Victor Garcia Satorras, Emiel Hoogeboom, Fabian B. Fuchs, Ingmar\n  Posner, Max Welling", "title": "E(n) Equivariant Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a generative model equivariant to Euclidean symmetries:\nE(n) Equivariant Normalizing Flows (E-NFs). To construct E-NFs, we take the\ndiscriminative E(n) graph neural networks and integrate them as a differential\nequation to obtain an invertible equivariant function: a continuous-time\nnormalizing flow. We demonstrate that E-NFs considerably outperform baselines\nand existing methods from the literature on particle systems such as DW4 and\nLJ13, and on molecules from QM9 in terms of log-likelihood. To the best of our\nknowledge, this is the first flow that jointly generates molecule features and\npositions in 3D.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 09:28:54 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 12:17:00 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Satorras", "Victor Garcia", ""], ["Hoogeboom", "Emiel", ""], ["Fuchs", "Fabian B.", ""], ["Posner", "Ingmar", ""], ["Welling", "Max", ""]]}, {"id": "2105.09095", "submitter": "J\\\"org Martin", "authors": "J\\\"org Martin and Clemens Elster", "title": "Errors-in-Variables for deep learning: rethinking aleatoric uncertainty", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a Bayesian treatment for deep regression using an\nErrors-in-Variables model which accounts for the uncertainty associated with\nthe input to the employed neural network. It is shown how the treatment can be\ncombined with already existing approaches for uncertainty quantification that\nare based on variational inference. Our approach yields a decomposition of the\npredictive uncertainty into an aleatoric and epistemic part that is more\ncomplete and, in many cases, more consistent from a statistical perspective. We\nillustrate and discuss the approach along various toy and real world examples.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 12:37:02 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 08:51:07 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Martin", "J\u00f6rg", ""], ["Elster", "Clemens", ""]]}, {"id": "2105.09107", "submitter": "Tomas Pevny", "authors": "Simon Mandlik, Matej Racinsky, Viliam Lisy, Tomas Pevny", "title": "Mill.jl and JsonGrinder.jl: automated differentiable feature extraction\n  for learning from raw JSON data", "comments": "5 pages, 2 figures, 1 table, submitted to section on one-source\n  software of Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.MS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Learning from raw data input, thus limiting the need for manual feature\nengineering, is one of the key components of many successful applications of\nmachine learning methods. While machine learning problems are often formulated\non data that naturally translate into a vector representation suitable for\nclassifiers, there are data sources, for example in cybersecurity, that are\nnaturally represented in diverse files with a unifying hierarchical structure,\nsuch as XML, JSON, and Protocol Buffers. Converting this data to vector\n(tensor) representation is generally done by manual feature engineering, which\nis laborious, lossy, and prone to human bias about the importance of particular\nfeatures.\n  Mill and JsonGrinder is a tandem of libraries, which fully automates the\nconversion. Starting with an arbitrary set of JSON samples, they create a\ndifferentiable machine learning model capable of infer from further JSON\nsamples in their raw form.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 13:02:10 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Mandlik", "Simon", ""], ["Racinsky", "Matej", ""], ["Lisy", "Viliam", ""], ["Pevny", "Tomas", ""]]}, {"id": "2105.09240", "submitter": "Gideon Dresdner", "authors": "Gideon Dresdner, Saurav Shekhar, Fabian Pedregosa, Francesco\n  Locatello, Gunnar R\\\"atsch", "title": "Boosting Variational Inference With Locally Adaptive Step-Sizes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Variational Inference makes a trade-off between the capacity of the\nvariational family and the tractability of finding an approximate posterior\ndistribution. Instead, Boosting Variational Inference allows practitioners to\nobtain increasingly good posterior approximations by spending more compute. The\nmain obstacle to widespread adoption of Boosting Variational Inference is the\namount of resources necessary to improve over a strong Variational Inference\nbaseline. In our work, we trace this limitation back to the global curvature of\nthe KL-divergence. We characterize how the global curvature impacts time and\nmemory consumption, address the problem with the notion of local curvature, and\nprovide a novel approximate backtracking algorithm for estimating local\ncurvature. We give new theoretical convergence rates for our algorithms and\nprovide experimental validation on synthetic and real-world datasets.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 16:41:33 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Dresdner", "Gideon", ""], ["Shekhar", "Saurav", ""], ["Pedregosa", "Fabian", ""], ["Locatello", "Francesco", ""], ["R\u00e4tsch", "Gunnar", ""]]}, {"id": "2105.09254", "submitter": "AmirEmad Ghassami", "authors": "AmirEmad Ghassami, Numair Sani, Yizhen Xu, Ilya Shpitser", "title": "Multiply Robust Causal Mediation Analysis with Continuous Treatments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG econ.EM stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many applications, researchers are interested in the direct and indirect\ncausal effects of an intervention on an outcome of interest. Mediation analysis\noffers a rigorous framework for the identification and estimation of such\ncausal quantities. In the case of binary treatment, efficient estimators for\nthe direct and indirect effects are derived by Tchetgen Tchetgen and Shpitser\n(2012). These estimators are based on influence functions and possess desirable\nmultiple robustness properties. However, they are not readily applicable when\ntreatments are continuous, which is the case in several settings, such as drug\ndosage in medical applications. In this work, we extend the influence\nfunction-based estimator of Tchetgen Tchetgen and Shpitser (2012) to deal with\ncontinuous treatments by utilizing a kernel smoothing approach. We first\ndemonstrate that our proposed estimator preserves the multiple robustness\nproperty of the estimator in Tchetgen Tchetgen and Shpitser (2012). Then we\nshow that under certain mild regularity conditions, our estimator is\nasymptotically normal. Our estimation scheme allows for high-dimensional\nnuisance parameters that can be estimated at slower rates than the target\nparameter. Additionally, we utilize cross-fitting, which allows for weaker\nsmoothness requirements for the nuisance functions.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 16:58:57 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Ghassami", "AmirEmad", ""], ["Sani", "Numair", ""], ["Xu", "Yizhen", ""], ["Shpitser", "Ilya", ""]]}, {"id": "2105.09261", "submitter": "Rapha\\\"el d'Andrimont", "authors": "Rapha\\\"el d'Andrimont and Astrid Verhegghen and Guido Lemoine and\n  Pieter Kempeneers and Michele Meroni and Marijn van der Velde", "title": "From parcel to continental scale -- A first European crop type map based\n  on Sentinel-1 and LUCAS Copernicus in-situ observations", "comments": "19 pages, 11 Figures, 5 Tables (without appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detailed parcel-level crop type mapping for the whole European Union (EU) is\nnecessary for the evaluation of agricultural policies. The Copernicus program,\nand Sentinel-1 (S1) in particular, offers the opportunity to monitor\nagricultural land at a continental scale and in a timely manner. However, so\nfar the potential of S1 has not been explored at such a scale. Capitalizing on\nthe unique LUCAS 2018 Copernicus in-situ survey, we present the first\ncontinental crop type map at 10-m spatial resolution for the EU based on S1A\nand S1B Synthetic Aperture Radar observations for the year 2018. Random forest\nclassification algorithms are tuned to detect 19 different crop types. We\nassess the accuracy of this EU crop map with three approaches. First, the\naccuracy is assessed with independent LUCAS core in-situ observations over the\ncontinent. Second, an accuracy assessment is done specifically for main crop\ntypes from farmers declarations from 6 EU member countries or regions totaling\n>3M parcels and 8.21 Mha. Finally, the crop areas derived by classification are\ncompared to the subnational (NUTS 2) area statistics reported by Eurostat. The\noverall accuracy for the map is reported as 80.3% when grouping main crop\nclasses and 76% when considering all 19 crop type classes separately. Highest\naccuracies are obtained for rape and turnip rape with user and produced\naccuracies higher than 96%. The correlation between the remotely sensed\nestimated and Eurostat reported crop area ranges from 0.93 (potatoes) to 0.99\n(rape and turnip rape). Finally, we discuss how the framework presented here\ncan underpin the operational delivery of in-season high-resolution based crop\nmapping.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 17:17:45 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 13:43:03 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["d'Andrimont", "Rapha\u00ebl", ""], ["Verhegghen", "Astrid", ""], ["Lemoine", "Guido", ""], ["Kempeneers", "Pieter", ""], ["Meroni", "Michele", ""], ["van der Velde", "Marijn", ""]]}, {"id": "2105.09433", "submitter": "Aditya Parulekar", "authors": "Aditya Parulekar, Advait Parulekar, Eric Price", "title": "L1 Regression with Lewis Weights Subsampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem of finding an approximate solution to $\\ell_1$\nregression while only observing a small number of labels. Given an $n \\times d$\nunlabeled data matrix $X$, we must choose a small set of $m \\ll n$ rows to\nobserve the labels of, then output an estimate $\\widehat{\\beta}$ whose error on\nthe original problem is within a $1 + \\varepsilon$ factor of optimal. We show\nthat sampling from $X$ according to its Lewis weights and outputting the\nempirical minimizer succeeds with probability $1-\\delta$ for $m >\nO(\\frac{1}{\\varepsilon^2} d \\log \\frac{d}{\\varepsilon \\delta})$. This is\nanalogous to the performance of sampling according to leverage scores for\n$\\ell_2$ regression, but with exponentially better dependence on $\\delta$. We\nalso give a corresponding lower bound of $\\Omega(\\frac{d}{\\varepsilon^2} + (d +\n\\frac{1}{\\varepsilon^2}) \\log\\frac{1}{\\delta})$.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 23:15:00 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Parulekar", "Aditya", ""], ["Parulekar", "Advait", ""], ["Price", "Eric", ""]]}, {"id": "2105.09536", "submitter": "Sela Fried", "authors": "Sela Fried, Geoffrey Wolfer", "title": "On the $\\alpha$-lazy version of Markov chains in estimation and testing\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate extendibility of the minimax one-trajectory length of several\nstatistical Markov chains inference problems and give sufficient conditions for\nboth the possibility and impossibility of such extensions. We follow up and\napply this framework to recently published results on learning and identity\ntesting of ergodic Markov chains. In particular, we show that for some of the\naforementioned results, we can omit the aperiodicity requirement by simulating\nan $\\alpha$-lazy version of the original process, and quantify the incurred\ncost of removing this assumption.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 06:26:13 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Fried", "Sela", ""], ["Wolfer", "Geoffrey", ""]]}, {"id": "2105.09557", "submitter": "Takashi Mori", "authors": "Takashi Mori, Liu Ziyin, Kangqiao Liu, Masahito Ueda", "title": "Logarithmic landscape and power-law escape rate of SGD", "comments": "15+6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) undergoes complicated multiplicative noise\nfor the mean-square loss. We use this property of the SGD noise to derive a\nstochastic differential equation (SDE) with simpler additive noise by\nperforming a non-uniform transformation of the time variable. In the SDE, the\ngradient of the loss is replaced by that of the logarithmized loss.\nConsequently, we show that, near a local or global minimum, the stationary\ndistribution $P_\\mathrm{ss}(\\theta)$ of the network parameters $\\theta$ follows\na power-law with respect to the loss function $L(\\theta)$, i.e.\n$P_\\mathrm{ss}(\\theta)\\propto L(\\theta)^{-\\phi}$ with the exponent $\\phi$\nspecified by the mini-batch size, the learning rate, and the Hessian at the\nminimum. We obtain the escape rate formula from a local minimum, which is\ndetermined not by the loss barrier height $\\Delta L=L(\\theta^s)-L(\\theta^*)$\nbetween a minimum $\\theta^*$ and a saddle $\\theta^s$ but by the logarithmized\nloss barrier height $\\Delta\\log L=\\log[L(\\theta^s)/L(\\theta^*)]$. Our\nescape-rate formula explains an empirical fact that SGD prefers flat minima\nwith low effective dimensions.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 07:25:07 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Mori", "Takashi", ""], ["Ziyin", "Liu", ""], ["Liu", "Kangqiao", ""], ["Ueda", "Masahito", ""]]}, {"id": "2105.09579", "submitter": "Daisuke Moriwaki", "authors": "Takamichi Toda, Daisuke Moriwaki, Kazuhiro Ota", "title": "Aggregate Learning for Mixed Frequency Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large and acute economic shocks such as the 2007-2009 financial crisis and\nthe current COVID-19 infections rapidly change the economic environment. In\nsuch a situation, the importance of real-time economic analysis using\nalternative datais emerging. Alternative data such as search query and location\ndata are closer to real-time and richer than official statistics that are\ntypically released once a month in an aggregated form. We take advantage of\nspatio-temporal granularity of alternative data and propose a\nmixed-FrequencyAggregate Learning (MF-AGL)model that predicts economic\nindicators for the smaller areas in real-time. We apply the model for the\nreal-world problem; prediction of the number of job applicants which is closely\nrelated to the unemployment rates. We find that the proposed model predicts (i)\nthe regional heterogeneity of the labor market condition and (ii) the rapidly\nchanging economic status. The model can be applied to various tasks, especially\neconomic analysis\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 08:12:43 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Toda", "Takamichi", ""], ["Moriwaki", "Daisuke", ""], ["Ota", "Kazuhiro", ""]]}, {"id": "2105.09580", "submitter": "Nanqing Dong", "authors": "Nanqing Dong, Michael Kampffmeyer, Irina Voiculescu, Eric Xing", "title": "Negational Symmetry of Quantum Neural Networks for Binary Pattern\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Entanglement is a physical phenomenon, which has fueled recent successes of\nquantum algorithms. Although quantum neural networks (QNNs) have shown\npromising results in solving simple machine learning tasks recently, for the\ntime being, the effect of entanglement in QNNs and the behavior of QNNs in\nbinary pattern classification are still underexplored. In this work, we provide\nsome theoretical insight into the properties of QNNs by presenting and\nanalyzing a new form of invariance embedded in QNNs for both quantum binary\nclassification and quantum representation learning, which we term negational\nsymmetry. Given a quantum binary signal and its negational counterpart where a\nbitwise NOT operation is applied to each quantum bit of the binary signal, a\nQNN outputs the same logits. That is to say, QNNs cannot differentiate a\nquantum binary signal and its negational counterpart in a binary classification\ntask. We further empirically evaluate the negational symmetry of QNNs in binary\npattern classification tasks using Google's quantum computing framework. The\ntheoretical and experimental results suggest that negational symmetry is a\nfundamental property of QNNs, which is not shared by classical models. Our\nfindings also imply that negational symmetry is a double-edged sword in\npractical quantum applications.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 08:13:38 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Dong", "Nanqing", ""], ["Kampffmeyer", "Michael", ""], ["Voiculescu", "Irina", ""], ["Xing", "Eric", ""]]}, {"id": "2105.09618", "submitter": "Noa Malem-Shinitski", "authors": "Noa Malem-Shinitski, Cesar Ojeda and Manfred Opper", "title": "Nonlinear Hawkes Process with Gaussian Process Self Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditionally, Hawkes processes are used to model time--continuous point\nprocesses with history dependence. Here we propose an extended model where the\nself--effects are of both excitatory and inhibitory type and follow a Gaussian\nProcess. Whereas previous work either relies on a less flexible\nparameterization of the model, or requires a large amount of data, our\nformulation allows for both a flexible model and learning when data are scarce.\nWe continue the line of work of Bayesian inference for Hawkes processes, and\nour approach dispenses with the necessity of estimating a branching structure\nfor the posterior, as we perform inference on an aggregated sum of Gaussian\nProcesses. Efficient approximate Bayesian inference is achieved via data\naugmentation, and we describe a mean--field variational inference approach to\nlearn the model parameters. To demonstrate the flexibility of the model we\napply our methodology on data from three different domains and compare it to\npreviously reported results.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 09:20:35 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Malem-Shinitski", "Noa", ""], ["Ojeda", "Cesar", ""], ["Opper", "Manfred", ""]]}, {"id": "2105.09670", "submitter": "Jingyi Zhang", "authors": "Jingyi Zhang, Huolan Zhu, Yongkai Chen, Chenguang Yang, Huimin Cheng,\n  Yi Li, Wenxuan Zhong, Fang Wang", "title": "Ensemble machine learning approach for screening of coronary heart\n  disease based on echocardiography and risk factors", "comments": "30 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Extensive clinical evidence suggests that a preventive screening\nof coronary heart disease (CHD) at an earlier stage can greatly reduce the\nmortality rate. We use 64 two-dimensional speckle tracking echocardiography\n(2D-STE) features and seven clinical features to predict whether one has CHD.\nMethods: We develop a machine learning approach that integrates a number of\npopular classification methods together by model stacking, and generalize the\ntraditional stacking method to a two-step stacking method to improve the\ndiagnostic performance. Results: By borrowing strengths from multiple\nclassification models through the proposed method, we improve the CHD\nclassification accuracy from around 70% to 87.7% on the testing set. The\nsensitivity of the proposed method is 0.903 and the specificity is 0.843, with\nan AUC of 0.904, which is significantly higher than those of the individual\nclassification models. Conclusions: Our work lays a foundation for the\ndeployment of speckle tracking echocardiography-based screening tools for\ncoronary heart disease.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 11:04:58 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Zhang", "Jingyi", ""], ["Zhu", "Huolan", ""], ["Chen", "Yongkai", ""], ["Yang", "Chenguang", ""], ["Cheng", "Huimin", ""], ["Li", "Yi", ""], ["Zhong", "Wenxuan", ""], ["Wang", "Fang", ""]]}, {"id": "2105.09679", "submitter": "Koujin Takeda", "authors": "Shun Kimura, Keisuke Ota, Koujin Takeda", "title": "Improved Neuronal Ensemble Inference with Generative Model and MCMC", "comments": "23 pages, 8 figures, partially overlapped with arXiv:1911.06509", "journal-ref": "J. Stat. Mech. (2021) 063501", "doi": "10.1088/1742-5468/abffd5", "report-no": null, "categories": "cond-mat.dis-nn cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal ensemble inference is a significant problem in the study of\nbiological neural networks. Various methods have been proposed for ensemble\ninference from experimental data of neuronal activity. Among them, Bayesian\ninference approach with generative model was proposed recently. However, this\nmethod requires large computational cost for appropriate inference. In this\nwork, we give an improved Bayesian inference algorithm by modifying update rule\nin Markov chain Monte Carlo method and introducing the idea of simulated\nannealing for hyperparameter control. We compare the performance of ensemble\ninference between our algorithm and the original one, and discuss the advantage\nof our method.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 11:37:38 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Kimura", "Shun", ""], ["Ota", "Keisuke", ""], ["Takeda", "Koujin", ""]]}, {"id": "2105.09695", "submitter": "Zheng Zhao", "authors": "Zheng Zhao, Rui Gao, Simo S\\\"arkk\\\"a", "title": "Hierarchical Non-Stationary Temporal Gaussian Processes With\n  $L^1$-Regularization", "comments": "20 pages. Submitted to Statistics and Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with regularized extensions of hierarchical\nnon-stationary temporal Gaussian processes (NSGPs) in which the parameters\n(e.g., length-scale) are modeled as GPs. In particular, we consider two\ncommonly used NSGP constructions which are based on explicitly constructed\nnon-stationary covariance functions and stochastic differential equations,\nrespectively. We extend these NSGPs by including $L^1$-regularization on the\nprocesses in order to induce sparseness. To solve the resulting regularized\nNSGP (R-NSGP) regression problem we develop a method based on the alternating\ndirection method of multipliers (ADMM) and we also analyze its convergence\nproperties theoretically. We also evaluate the performance of the proposed\nmethods in simulated and real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 12:15:33 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Zhao", "Zheng", ""], ["Gao", "Rui", ""], ["S\u00e4rkk\u00e4", "Simo", ""]]}, {"id": "2105.09788", "submitter": "Ruiqi Liu", "authors": "Ruiqi Liu, Ganggang Xu, Zuofeng Shang", "title": "Distributed Adaptive Nearest Neighbor Classifier: Algorithm and Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When data is of an extraordinarily large size or physically stored in\ndifferent locations, the distributed nearest neighbor (NN) classifier is an\nattractive tool for classification. We propose a novel distributed adaptive NN\nclassifier for which the number of nearest neighbors is a tuning parameter\nstochastically chosen by a data-driven criterion. An early stopping rule is\nproposed when searching for the optimal tuning parameter, which not only speeds\nup the computation but also improves the finite sample performance of the\nproposed Algorithm. Convergence rate of excess risk of the distributed adaptive\nNN classifier is investigated under various sub-sample size compositions. In\nparticular, we show that when the sub-sample sizes are sufficiently large, the\nproposed classifier achieves the nearly optimal convergence rate. Effectiveness\nof the proposed approach is demonstrated through simulation studies as well as\nan empirical application to a real-world dataset.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 14:38:41 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Liu", "Ruiqi", ""], ["Xu", "Ganggang", ""], ["Shang", "Zuofeng", ""]]}, {"id": "2105.09801", "submitter": "Shuangshuang Chen", "authors": "Shuangshuang Chen, Sihao Ding, Yiannis Karayiannidis, M{\\aa}rten\n  Bj\\\"orkman", "title": "Monte Carlo Filtering Objectives: A New Family of Variational Objectives\n  to Learn Generative Model and Neural Adaptive Proposal for Time Series", "comments": "A complete version of manuscript accepted by IJCAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning generative models and inferring latent trajectories have shown to be\nchallenging for time series due to the intractable marginal likelihoods of\nflexible generative models. It can be addressed by surrogate objectives for\noptimization. We propose Monte Carlo filtering objectives (MCFOs), a family of\nvariational objectives for jointly learning parametric generative models and\namortized adaptive importance proposals of time series. MCFOs extend the\nchoices of likelihood estimators beyond Sequential Monte Carlo in\nstate-of-the-art objectives, possess important properties revealing the factors\nfor the tightness of objectives, and allow for less biased and variant gradient\nestimates. We demonstrate that the proposed MCFOs and gradient estimations lead\nto efficient and stable model learning, and learned generative models well\nexplain data and importance proposals are more sample efficient on various\nkinds of time series data.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 14:56:30 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Chen", "Shuangshuang", ""], ["Ding", "Sihao", ""], ["Karayiannidis", "Yiannis", ""], ["Bj\u00f6rkman", "M\u00e5rten", ""]]}, {"id": "2105.09872", "submitter": "Seyoung Kim", "authors": "Jun Ho Yoon and Seyoung Kim", "title": "EiGLasso for Scalable Sparse Kronecker-Sum Inverse Covariance Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world problems, complex dependencies are present both among\nsamples and among features. The Kronecker sum or the Cartesian product of two\ngraphs, each modeling dependencies across features and across samples, has been\nused as an inverse covariance matrix for a matrix-variate Gaussian\ndistribution, as an alternative to a Kronecker-product inverse covariance\nmatrix, due to its more intuitive sparse structure. However, the existing\nmethods for sparse Kronecker-sum inverse covariance estimation are limited in\nthat they do not scale to more than a few hundred features and samples and that\nthe unidentifiable parameters pose challenges in estimation. In this paper, we\nintroduce EiGLasso, a highly scalable method for sparse Kronecker-sum inverse\ncovariance estimation, based on Newton's method combined with\neigendecomposition of the two graphs for exploiting the structure of Kronecker\nsum. EiGLasso further reduces computation time by approximating the Hessian\nbased on the eigendecomposition of the sample and feature graphs. EiGLasso\nachieves quadratic convergence with the exact Hessian and linear convergence\nwith the approximate Hessian. We describe a simple new approach to estimating\nthe unidentifiable parameters that generalizes the existing methods. On\nsimulated and real-world data, we demonstrate that EiGLasso achieves two to\nthree orders-of-magnitude speed-up compared to the existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 16:22:50 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Yoon", "Jun Ho", ""], ["Kim", "Seyoung", ""]]}, {"id": "2105.09917", "submitter": "Aleksandr Beknazaryan", "authors": "Aleksandr Beknazaryan", "title": "Neural networks with superexpressive activations and integer weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An example of an activation function $\\sigma$ is given such that networks\nwith activations $\\{\\sigma, \\lfloor\\cdot\\rfloor\\}$, integer weights and a fixed\narchitecture depending on $d$ approximate continuous functions on $[0,1]^d$.\nThe range of integer weights required for $\\varepsilon$-approximation of\nH\\\"older continuous functions is derived, which leads to a convergence rate of\norder $n^{\\frac{-2\\beta}{2\\beta+d}}\\log_2n$ for neural network regression\nestimation of unknown $\\beta$-H\\\"older continuous function with given $n$\nsamples.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 17:29:08 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 06:40:28 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Beknazaryan", "Aleksandr", ""]]}, {"id": "2105.09980", "submitter": "Nikolaos Napoleon Vlassis", "authors": "Xiao Sun, Bahador Bahmani, Nikolaos N. Vlassis, WaiChing Sun, Yanxun\n  Xu", "title": "Data-driven discovery of interpretable causal relations for deep\n  learning material laws with uncertainty propagation", "comments": "43 pages, 27 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a computational framework that generates ensemble\npredictive mechanics models with uncertainty quantification (UQ). We first\ndevelop a causal discovery algorithm to infer causal relations among\ntime-history data measured during each representative volume element (RVE)\nsimulation through a directed acyclic graph (DAG). With multiple plausible sets\nof causal relationships estimated from multiple RVE simulations, the\npredictions are propagated in the derived causal graph while using a deep\nneural network equipped with dropout layers as a Bayesian approximation for\nuncertainty quantification. We select two representative numerical examples\n(traction-separation laws for frictional interfaces, elastoplasticity models\nfor granular assembles) to examine the accuracy and robustness of the proposed\ncausal discovery method for the common material law predictions in civil\nengineering applications.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 18:25:43 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Sun", "Xiao", ""], ["Bahmani", "Bahador", ""], ["Vlassis", "Nikolaos N.", ""], ["Sun", "WaiChing", ""], ["Xu", "Yanxun", ""]]}, {"id": "2105.09985", "submitter": "Pranjal Awasthi", "authors": "Flavien Prost, Pranjal Awasthi, Nick Blumm, Aditee Kumthekar, Trevor\n  Potter, Li Wei, Xuezhi Wang, Ed H. Chi, Jilin Chen, Alex Beutel", "title": "Measuring Model Fairness under Noisy Covariates: A Theoretical\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we study the problem of measuring the fairness of a machine\nlearning model under noisy information. Focusing on group fairness metrics, we\ninvestigate the particular but common situation when the evaluation requires\ncontrolling for the confounding effect of covariate variables. In a practical\nsetting, we might not be able to jointly observe the covariate and group\ninformation, and a standard workaround is to then use proxies for one or more\nof these variables. Prior works have demonstrated the challenges with using a\nproxy for sensitive attributes, and strong independence assumptions are needed\nto provide guarantees on the accuracy of the noisy estimates. In contrast, in\nthis work we study using a proxy for the covariate variable and present a\ntheoretical analysis that aims to characterize weaker conditions under which\naccurate fairness evaluation is possible.\n  Furthermore, our theory identifies potential sources of errors and decouples\nthem into two interpretable parts $\\gamma$ and $\\epsilon$. The first part\n$\\gamma$ depends solely on the performance of the proxy such as precision and\nrecall, whereas the second part $\\epsilon$ captures correlations between all\nthe variables of interest. We show that in many scenarios the error in the\nestimates is dominated by $\\gamma$ via a linear dependence, whereas the\ndependence on the correlations $\\epsilon$ only constitutes a lower order term.\nAs a result we expand the understanding of scenarios where measuring model\nfairness via proxies can be an effective approach. Finally, we compare, via\nsimulations, the theoretical upper-bounds to the distribution of simulated\nestimation errors and show that assuming some structure on the data, even weak,\nis key to significantly improve both theoretical guarantees and empirical\nresults.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 18:36:28 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Prost", "Flavien", ""], ["Awasthi", "Pranjal", ""], ["Blumm", "Nick", ""], ["Kumthekar", "Aditee", ""], ["Potter", "Trevor", ""], ["Wei", "Li", ""], ["Wang", "Xuezhi", ""], ["Chi", "Ed H.", ""], ["Chen", "Jilin", ""], ["Beutel", "Alex", ""]]}, {"id": "2105.09994", "submitter": "Anna Korba", "authors": "Anna Korba, Pierre-Cyril Aubin-Frankowski, Szymon Majewski, Pierre\n  Ablin", "title": "Kernel Stein Discrepancy Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Among dissimilarities between probability distributions, the Kernel Stein\nDiscrepancy (KSD) has received much interest recently. We investigate the\nproperties of its Wasserstein gradient flow to approximate a target probability\ndistribution $\\pi$ on $\\mathbb{R}^d$, known up to a normalization constant.\nThis leads to a straightforwardly implementable, deterministic score-based\nmethod to sample from $\\pi$, named KSD Descent, which uses a set of particles\nto approximate $\\pi$. Remarkably, owing to a tractable loss function, KSD\nDescent can leverage robust parameter-free optimization schemes such as L-BFGS;\nthis contrasts with other popular particle-based schemes such as the Stein\nVariational Gradient Descent algorithm. We study the convergence properties of\nKSD Descent and demonstrate its practical relevance. However, we also highlight\nfailure cases by showing that the algorithm can get stuck in spurious local\nminima.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 19:05:23 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Korba", "Anna", ""], ["Aubin-Frankowski", "Pierre-Cyril", ""], ["Majewski", "Szymon", ""], ["Ablin", "Pierre", ""]]}, {"id": "2105.10017", "submitter": "Abhishek Kaul", "authors": "Abhishek Kaul", "title": "Segmentation of high dimensional means over multi-dimensional change\n  points and connections to regression trees", "comments": "All implementations carried out in R (code available upon request)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This article is motivated by the objective of providing a new analytically\ntractable and fully frequentist framework to characterize and implement\nregression trees while also allowing a multivariate (potentially high\ndimensional) response. The connection to regression trees is made by a high\ndimensional model with dynamic mean vectors over multi-dimensional change axes.\nOur theoretical analysis is carried out under a single two dimensional change\npoint setting. An optimal rate of convergence of the proposed estimator is\nobtained, which in turn allows existence of limiting distributions.\nDistributional behavior of change point estimates are split into two distinct\nregimes, the limiting distributions under each regime is then characterized, in\nturn allowing construction of asymptotically valid confidence intervals for\n$2d$-location of change. All results are obtained under a high dimensional\nscaling $s\\log^2 p=o(T_wT_h),$ where $p$ is the response dimension, $s$ is a\nsparsity parameter, and $T_w,T_h$ are sampling periods along change axes. We\ncharacterize full regression trees by defining a multiple multi-dimensional\nchange point model. Natural extensions of the single $2d$-change point\nestimation methodology are provided. Two applications, first on segmentation of\n{\\it Infra-red astronomy satellite (IRAS)} data and second to segmentation of\ndigital images are provided. Methodology and theoretical results are supported\nwith monte-carlo simulations.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 20:29:48 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Kaul", "Abhishek", ""]]}, {"id": "2105.10090", "submitter": "Dmitrii Avdiukhin", "authors": "Dmitrii Avdiukhin, Grigory Yaroslavtsev", "title": "Escaping Saddle Points with Compressed SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic gradient descent (SGD) is a prevalent optimization technique for\nlarge-scale distributed machine learning. While SGD computation can be\nefficiently divided between multiple machines, communication typically becomes\na bottleneck in the distributed setting. Gradient compression methods can be\nused to alleviate this problem, and a recent line of work shows that SGD\naugmented with gradient compression converges to an $\\varepsilon$-first-order\nstationary point. In this paper we extend these results to convergence to an\n$\\varepsilon$-second-order stationary point ($\\varepsilon$-SOSP), which is to\nthe best of our knowledge the first result of this type. In addition, we show\nthat, when the stochastic gradient is not Lipschitz, compressed SGD with\nRandomK compressor converges to an $\\varepsilon$-SOSP with the same number of\niterations as uncompressed SGD [Jin et al.,2021] (JACM), while improving the\ntotal communication by a factor of $\\tilde \\Theta(\\sqrt{d}\n\\varepsilon^{-3/4})$, where $d$ is the dimension of the optimization problem.\nWe present additional results for the cases when the compressor is arbitrary\nand when the stochastic gradient is Lipschitz.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 01:56:43 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Avdiukhin", "Dmitrii", ""], ["Yaroslavtsev", "Grigory", ""]]}, {"id": "2105.10148", "submitter": "Yutian Chen", "authors": "Yutian Chen, Liyuan Xu, Caglar Gulcehre, Tom Le Paine, Arthur Gretton,\n  Nando de Freitas, Arnaud Doucet", "title": "On Instrumental Variable Regression for Deep Offline Policy Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show that the popular reinforcement learning (RL) strategy of estimating\nthe state-action value (Q-function) by minimizing the mean squared Bellman\nerror leads to a regression problem with confounding, the inputs and output\nnoise being correlated. Hence, direct minimization of the Bellman error can\nresult in significantly biased Q-function estimates. We explain why fixing the\ntarget Q-network in Deep Q-Networks and Fitted Q Evaluation provides a way of\novercoming this confounding, thus shedding new light on this popular but not\nwell understood trick in the deep RL literature. An alternative approach to\naddress confounding is to leverage techniques developed in the causality\nliterature, notably instrumental variables (IV). We bring together here the\nliterature on IV and RL by investigating whether IV approaches can lead to\nimproved Q-function estimates. This paper analyzes and compares a wide range of\nrecent IV methods in the context of offline policy evaluation (OPE), where the\ngoal is to estimate the value of a policy using logged data only. By applying\ndifferent IV techniques to OPE, we are not only able to recover previously\nproposed OPE methods such as model-based techniques but also to obtain\ncompetitive new techniques. We find empirically that state-of-the-art OPE\nmethods are closely matched in performance by some IV methods such as AGMM,\nwhich were not developed for OPE. We open-source all our code and datasets at\nhttps://github.com/liyuan9988/IVOPEwithACME.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 06:22:34 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Chen", "Yutian", ""], ["Xu", "Liyuan", ""], ["Gulcehre", "Caglar", ""], ["Paine", "Tom Le", ""], ["Gretton", "Arthur", ""], ["de Freitas", "Nando", ""], ["Doucet", "Arnaud", ""]]}, {"id": "2105.10190", "submitter": "Juan M Haut", "authors": "S.K. Roy, M.E. Paoletti, J.M. Haut, S.R. Dubey, P. Kar, A. Plaza, B.B.\n  Chaudhuri", "title": "AngularGrad: A New Optimization Technique for Angular Convergence of\n  Convolutional Neural Networks", "comments": "Submitted in IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are trained using stochastic gradient\ndescent (SGD)-based optimizers. Recently, the adaptive moment estimation (Adam)\noptimizer has become very popular due to its adaptive momentum, which tackles\nthe dying gradient problem of SGD. Nevertheless, existing optimizers are still\nunable to exploit the optimization curvature information efficiently. This\npaper proposes a new AngularGrad optimizer that considers the behavior of the\ndirection/angle of consecutive gradients. This is the first attempt in the\nliterature to exploit the gradient angular information apart from its\nmagnitude. The proposed AngularGrad generates a score to control the step size\nbased on the gradient angular information of previous iterations. Thus, the\noptimization steps become smoother as a more accurate step size of immediate\npast gradients is captured through the angular information. Two variants of\nAngularGrad are developed based on the use of Tangent or Cosine functions for\ncomputing the gradient angular information. Theoretically, AngularGrad exhibits\nthe same regret bound as Adam for convergence purposes. Nevertheless, extensive\nexperiments conducted on benchmark data sets against state-of-the-art methods\nreveal a superior performance of AngularGrad. The source code will be made\npublicly available at: https://github.com/mhaut/AngularGrad.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 08:00:53 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Roy", "S. K.", ""], ["Paoletti", "M. E.", ""], ["Haut", "J. M.", ""], ["Dubey", "S. R.", ""], ["Kar", "P.", ""], ["Plaza", "A.", ""], ["Chaudhuri", "B. B.", ""]]}, {"id": "2105.10305", "submitter": "Mark Collier", "authors": "Mark Collier, Basil Mustafa, Efi Kokiopoulou, Rodolphe Jenatton and\n  Jesse Berent", "title": "Correlated Input-Dependent Label Noise in Large-Scale Image\n  Classification", "comments": "Accepted as Oral at CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale image classification datasets often contain noisy labels. We take\na principled probabilistic approach to modelling input-dependent, also known as\nheteroscedastic, label noise in these datasets. We place a multivariate Normal\ndistributed latent variable on the final hidden layer of a neural network\nclassifier. The covariance matrix of this latent variable, models the aleatoric\nuncertainty due to label noise. We demonstrate that the learned covariance\nstructure captures known sources of label noise between semantically similar\nand co-occurring classes. Compared to standard neural network training and\nother baselines, we show significantly improved accuracy on Imagenet ILSVRC\n2012 79.3% (+2.6%), Imagenet-21k 47.0% (+1.1%) and JFT 64.7% (+1.6%). We set a\nnew state-of-the-art result on WebVision 1.0 with 76.6% top-1 accuracy. These\ndatasets range from over 1M to over 300M training examples and from 1k classes\nto more than 21k classes. Our method is simple to use, and we provide an\nimplementation that is a drop-in replacement for the final fully-connected\nlayer in a deep classifier.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 17:30:59 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Collier", "Mark", ""], ["Mustafa", "Basil", ""], ["Kokiopoulou", "Efi", ""], ["Jenatton", "Rodolphe", ""], ["Berent", "Jesse", ""]]}, {"id": "2105.10315", "submitter": "Ruiqi Liu", "authors": "Ruiqi Liu, Mingao Yuan, Zuofeng Shang", "title": "Online Statistical Inference for Parameters Estimation with\n  Linear-Equality Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) and projected stochastic gradient descent\n(PSGD) are scalable algorithms to compute model parameters in unconstrained and\nconstrained optimization problems. In comparison with stochastic gradient\ndescent (SGD), PSGD forces its iterative values into the constrained parameter\nspace via projection. The convergence rate of PSGD-type estimates has been\nexhaustedly studied, while statistical properties such as asymptotic\ndistribution remain less explored. From a purely statistical point of view,\nthis paper studies the limiting distribution of PSGD-based estimate when the\ntrue parameters satisfying some linear-equality constraints. Our theoretical\nfindings reveal the role of projection played in the uncertainty of the PSGD\nestimate. As a byproduct, we propose an online hypothesis testing procedure to\ntest the linear-equality constraints. Simulation studies on synthetic data and\nan application to a real-world dataset confirm our theory.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 12:39:53 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Liu", "Ruiqi", ""], ["Yuan", "Mingao", ""], ["Shang", "Zuofeng", ""]]}, {"id": "2105.10347", "submitter": "Inass Sekkat", "authors": "Inass Sekkat, Gabriel Stoltz", "title": "Removing the mini-batching error in Bayesian inference using Adaptive\n  Langevin dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational cost of usual Monte Carlo methods for sampling a posteriori\nlaws in Bayesian inference scales linearly with the number of data points. One\noption to reduce it to a fraction of this cost is to resort to mini-batching in\nconjunction with unadjusted discretizations of Langevin dynamics, in which case\nonly a random fraction of the data is used to estimate the gradient. However,\nthis leads to an additional noise in the dynamics and hence a bias on the\ninvariant measure which is sampled by the Markov chain. We advocate using the\nso-called Adaptive Langevin dynamics, which is a modification of standard\ninertial Langevin dynamics with a dynamical friction which automatically\ncorrects for the increased noise arising from mini-batching. We investigate the\npractical relevance of the assumptions underpinning Adaptive Langevin (constant\ncovariance for the estimation of the gradient), which are not satisfied in\ntypical models of Bayesian inference; and show how to extend the approach to\nmore general situations.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 13:39:39 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Sekkat", "Inass", ""], ["Stoltz", "Gabriel", ""]]}, {"id": "2105.10360", "submitter": "Doudou Zhou", "authors": "Doudou Zhou, and Tianxi Cai, and Junwei Lu", "title": "BELT: Block-wise Missing Embedding Learning Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion has attracted attention in many fields, including\nstatistics, applied mathematics, and electrical engineering. Most of the works\nfocus on the independent sampling models under which the observed entries are\nsampled independently. Motivated by applications in the integration of multiple\nElectronic Health Record (EHR) datasets, we propose the method {\\bf B}lock-wise\nmissing {\\bf E}mbedding {\\bf L}earning {\\bf T}ransformer (BELT) to treat\nrow-wise/column-wise missingness. Specifically, BELT can recover block-wise\nmissing matrices efficiently when every pair of matrices has an overlap. Our\nidea is to exploit the orthogonal Procrustes problem to align the eigenspace of\nthe two sub-matrices using their overlap, then complete the missing blocks by\nthe inner product of the two low-rank components. Besides, we prove the\nstatistical rate for the eigenspace of the underlying matrix, which is\ncomparable to the rate under the independently missing assumption. Simulation\nstudies show that the method performs well under a variety of configurations.\nIn the real data analysis, the method is applied to two tasks: (i) the\nintegrating of several point-wise mutual information matrices built by English\nEHR and Chinese medical text data, and (ii) the machine translation between\nEnglish and Chinese medical concepts. Our method shows an advantage over\nexisting methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 13:55:30 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 12:20:03 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Zhou", "Doudou", ""], ["Cai", "Tianxi", ""], ["Lu", "Junwei", ""]]}, {"id": "2105.10392", "submitter": "Tim Verdonck", "authors": "Robin Van Oirbeek and Jolien Ponnet and Tim Verdonck", "title": "Computational Efficient Approximations of the Concordance Probability in\n  a Big Data Setting", "comments": "40 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance measurement is an essential task once a statistical model is\ncreated. The Area Under the receiving operating characteristics Curve (AUC) is\nthe most popular measure for evaluating the quality of a binary classifier. In\nthis case, AUC is equal to the concordance probability, a frequently used\nmeasure to evaluate the discriminatory power of the model. Contrary to AUC, the\nconcordance probability can also be extended to the situation with a continuous\nresponse variable. Due to the staggering size of data sets nowadays,\ndetermining this discriminatory measure requires a tremendous amount of costly\ncomputations and is hence immensely time consuming, certainly in case of a\ncontinuous response variable. Therefore, we propose two estimation methods that\ncalculate the concordance probability in a fast and accurate way and that can\nbe applied to both the discrete and continuous setting. Extensive simulation\nstudies show the excellent performance and fast computing times of both\nestimators. Finally, experiments on two real-life data sets confirm the\nconclusions of the artificial simulations.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 15:09:53 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Van Oirbeek", "Robin", ""], ["Ponnet", "Jolien", ""], ["Verdonck", "Tim", ""]]}, {"id": "2105.10439", "submitter": "Alexander Lin", "authors": "Alexander Lin, Andrew H. Song, Berkin Bilgic, and Demba Ba", "title": "Covariance-Free Sparse Bayesian Learning", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sparse Bayesian learning (SBL) is a powerful framework for tackling the\nsparse coding problem while also providing uncertainty quantification. However,\nthe most popular inference algorithms for SBL become too expensive for\nhigh-dimensional problems due to the need to maintain a large covariance\nmatrix. To resolve this issue, we introduce a new SBL inference algorithm that\navoids explicit computation of the covariance matrix, thereby saving\nsignificant time and space. Instead of performing costly matrix inversions, our\ncovariance-free method solves multiple linear systems to obtain provably\nunbiased estimates of the posterior statistics needed by SBL. These systems can\nbe solved in parallel, enabling further acceleration of the algorithm via\ngraphics processing units. In practice, our method can be up to thousands of\ntimes faster than existing baselines, reducing hours of computation time to\nseconds. We showcase how our new algorithm enables SBL to tractably tackle\nhigh-dimensional signal recovery problems, such as deconvolution of calcium\nimaging data and multi-contrast reconstruction of magnetic resonance images.\nFinally, we open-source a toolbox containing all of our implementations to\ndrive future research in SBL.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 16:20:07 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Lin", "Alexander", ""], ["Song", "Andrew H.", ""], ["Bilgic", "Berkin", ""], ["Ba", "Demba", ""]]}, {"id": "2105.10446", "submitter": "Yaodong Yu", "authors": "Kwan Ho Ryan Chan, Yaodong Yu, Chong You, Haozhi Qi, John Wright, Yi\n  Ma", "title": "ReduNet: A White-box Deep Network from the Principle of Maximizing Rate\n  Reduction", "comments": "This paper integrates previous two manuscripts: arXiv:2006.08558 and\n  arXiv:2010.14765, with significantly improved organization, presentation, and\n  new results; V2 polishes writing and adds citation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work attempts to provide a plausible theoretical framework that aims to\ninterpret modern deep (convolutional) networks from the principles of data\ncompression and discriminative representation. We argue that for\nhigh-dimensional multi-class data, the optimal linear discriminative\nrepresentation maximizes the coding rate difference between the whole dataset\nand the average of all the subsets. We show that the basic iterative gradient\nascent scheme for optimizing the rate reduction objective naturally leads to a\nmulti-layer deep network, named ReduNet, which shares common characteristics of\nmodern deep networks. The deep layered architectures, linear and nonlinear\noperators, and even parameters of the network are all explicitly constructed\nlayer-by-layer via forward propagation, although they are amenable to\nfine-tuning via back propagation. All components of so-obtained ``white-box''\nnetwork have precise optimization, statistical, and geometric interpretation.\nMoreover, all linear operators of the so-derived network naturally become\nmulti-channel convolutions when we enforce classification to be rigorously\nshift-invariant. The derivation in the invariant setting suggests a trade-off\nbetween sparsity and invariance, and also indicates that such a deep\nconvolution network is significantly more efficient to construct and learn in\nthe spectral domain. Our preliminary simulations and experiments clearly verify\nthe effectiveness of both the rate reduction objective and the associated\nReduNet. All code and data are available at https://github.com/Ma-Lab-Berkeley.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 16:29:57 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 22:09:24 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Chan", "Kwan Ho Ryan", ""], ["Yu", "Yaodong", ""], ["You", "Chong", ""], ["Qi", "Haozhi", ""], ["Wright", "John", ""], ["Ma", "Yi", ""]]}, {"id": "2105.10470", "submitter": "Philipp Frank", "authors": "Philipp Frank, Reimar Leike, and Torsten A. En{\\ss}lin", "title": "Geometric variational inference", "comments": "42 pages, 18 figures, accepted by Entropy", "journal-ref": null, "doi": "10.3390/e23070853", "report-no": null, "categories": "stat.ME astro-ph.IM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficiently accessing the information contained in non-linear and high\ndimensional probability distributions remains a core challenge in modern\nstatistics. Traditionally, estimators that go beyond point estimates are either\ncategorized as Variational Inference (VI) or Markov-Chain Monte-Carlo (MCMC)\ntechniques. While MCMC methods that utilize the geometric properties of\ncontinuous probability distributions to increase their efficiency have been\nproposed, VI methods rarely use the geometry. This work aims to fill this gap\nand proposes geometric Variational Inference (geoVI), a method based on\nRiemannian geometry and the Fisher information metric. It is used to construct\na coordinate transformation that relates the Riemannian manifold associated\nwith the metric to Euclidean space. The distribution, expressed in the\ncoordinate system induced by the transformation, takes a particularly simple\nform that allows for an accurate variational approximation by a normal\ndistribution. Furthermore, the algorithmic structure allows for an efficient\nimplementation of geoVI which is demonstrated on multiple examples, ranging\nfrom low-dimensional illustrative ones to non-linear, hierarchical Bayesian\ninverse problems in thousands of dimensions.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 17:18:50 GMT"}, {"version": "v2", "created": "Fri, 2 Jul 2021 07:41:31 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Frank", "Philipp", ""], ["Leike", "Reimar", ""], ["En\u00dflin", "Torsten A.", ""]]}, {"id": "2105.10590", "submitter": "Nilesh Tripuraneni", "authors": "Jeffrey Chan, Aldo Pacchiano, Nilesh Tripuraneni, Yun S. Song, Peter\n  Bartlett, Michael I. Jordan", "title": "Parallelizing Contextual Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.BM q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Standard approaches to decision-making under uncertainty focus on sequential\nexploration of the space of decisions. However, \\textit{simultaneously}\nproposing a batch of decisions, which leverages available resources for\nparallel experimentation, has the potential to rapidly accelerate exploration.\nWe present a family of (parallel) contextual linear bandit algorithms, whose\nregret is nearly identical to their perfectly sequential counterparts -- given\naccess to the same total number of oracle queries -- up to a lower-order\n\"burn-in\" term that is dependent on the context-set geometry. We provide\nmatching information-theoretic lower bounds on parallel regret performance to\nestablish our algorithms are asymptotically optimal in the time horizon.\nFinally, we also present an empirical evaluation of these parallel algorithms\nin several domains, including materials discovery and biological sequence\ndesign problems, to demonstrate the utility of parallelized bandits in\npractical settings.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 22:22:02 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Chan", "Jeffrey", ""], ["Pacchiano", "Aldo", ""], ["Tripuraneni", "Nilesh", ""], ["Song", "Yun S.", ""], ["Bartlett", "Peter", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2105.10635", "submitter": "Bo Wang", "authors": "Jiabin Liu, Bo Wang, Xin Shen, Zhiquan Qi, Yingjie Tian", "title": "Two-stage Training for Learning from Label Proportions", "comments": "10 pages, 4 figures, 5 tables, accepted by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning from label proportions (LLP) aims at learning an instance-level\nclassifier with label proportions in grouped training data. Existing deep\nlearning based LLP methods utilize end-to-end pipelines to obtain the\nproportional loss with Kullback-Leibler divergence between the bag-level prior\nand posterior class distributions. However, the unconstrained optimization on\nthis objective can hardly reach a solution in accordance with the given\nproportions. Besides, concerning the probabilistic classifier, this strategy\nunavoidably results in high-entropy conditional class distributions at the\ninstance level. These issues further degrade the performance of the\ninstance-level classification. In this paper, we regard these problems as noisy\npseudo labeling, and instead impose the strict proportion consistency on the\nclassifier with a constrained optimization as a continuous training stage for\nexisting LLP classifiers. In addition, we introduce the mixup strategy and\nsymmetric crossentropy to further reduce the label noise. Our framework is\nmodel-agnostic, and demonstrates compelling performance improvement in\nextensive experiments, when incorporated into other deep LLP models as a\npost-hoc phase.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 03:55:35 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Liu", "Jiabin", ""], ["Wang", "Bo", ""], ["Shen", "Xin", ""], ["Qi", "Zhiquan", ""], ["Tian", "Yingjie", ""]]}, {"id": "2105.10721", "submitter": "Anand Kalvit", "authors": "Anand Kalvit and Assaf Zeevi", "title": "From Finite to Countable-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a stochastic bandit problem with countably many arms that belong\nto a finite set of types, each characterized by a unique mean reward. In\naddition, there is a fixed distribution over types which sets the proportion of\neach type in the population of arms. The decision maker is oblivious to the\ntype of any arm and to the aforementioned distribution over types, but\nperfectly knows the total number of types occurring in the population of arms.\nWe propose a fully adaptive online learning algorithm that achieves O(log n)\ndistribution-dependent expected cumulative regret after any number of plays n,\nand show that this order of regret is best possible. The analysis of our\nalgorithm relies on newly discovered concentration and convergence properties\nof optimism-based policies like UCB in finite-armed bandit problems with \"zero\ngap,\" which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 13:09:50 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Kalvit", "Anand", ""], ["Zeevi", "Assaf", ""]]}, {"id": "2105.10832", "submitter": "Takashi Furuya", "authors": "Takashi Furuya, Kazuma Suetake, Koichi Taniguchi, Hiroyuki Kusumoto,\n  Ryuji Saiin, Tomohiro Daimon", "title": "Spectral Pruning for Recurrent Neural Networks", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning techniques for neural networks with a recurrent architecture, such as\nthe recurrent neural network (RNN), are strongly desired for their application\nto edge-computing devices. However, the recurrent architecture is generally not\nrobust to pruning because even small pruning causes accumulation error and the\ntotal error increases significantly over time. In this paper, we propose an\nappropriate pruning algorithm for RNNs inspired by \"spectral pruning\", and\nprovide the generalization error bounds for compressed RNNs. We also provide\nnumerical experiments to demonstrate our theoretical results and show the\neffectiveness of our pruning method compared with existing methods.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 00:30:59 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Furuya", "Takashi", ""], ["Suetake", "Kazuma", ""], ["Taniguchi", "Koichi", ""], ["Kusumoto", "Hiroyuki", ""], ["Saiin", "Ryuji", ""], ["Daimon", "Tomohiro", ""]]}, {"id": "2105.10838", "submitter": "Xinjie Du", "authors": "Xinjie Du, Minh Tang", "title": "Hypothesis Testing for Equality of Latent Positions in Random Graphs", "comments": "67 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the hypothesis testing problem that two vertices $i$ and $j$ of a\ngeneralized random dot product graph have the same latent positions, possibly\nup to scaling. Special cases of this hypotheses test include testing whether\ntwo vertices in a stochastic block model or degree-corrected stochastic block\nmodel graph have the same block membership vectors. We propose several test\nstatistics based on the empirical Mahalanobis distances between the $i$th and\n$j$th rows of either the adjacency or the normalized Laplacian spectral\nembedding of the graph. We show that, under mild conditions, these test\nstatistics have limiting chi-square distributions under both the null and local\nalternative hypothesis, and we derived explicit expressions for the\nnon-centrality parameters under the local alternative. Using these limit\nresults, we address the model selection problem of choosing between the\nstandard stochastic block model and its degree-corrected variant. The\neffectiveness of our proposed tests are illustrated via both simulation studies\nand real data applications.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 01:27:23 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Du", "Xinjie", ""], ["Tang", "Minh", ""]]}, {"id": "2105.10867", "submitter": "SeungHwan An", "authors": "SeungHwan An, Hosik Choi, Jong-June Jeon", "title": "EXoN: EXplainable encoder Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new semi-supervised learning method of Variational AutoEncoder\n(VAE) which yields an explainable latent space by EXplainable encoder Network\n(EXoN). The EXoN provides two useful tools for implementing VAE. First, we can\nfreely assign a conceptual center of the latent distribution for a specific\nlabel. The latent space of VAE is separated with the multi-modal property of\nthe Gaussian mixture distribution according to the labels of observations.\nNext, we can easily investigate the latent subspace by a simple statistics\nobtained from the EXoN. We found that both the negative cross-entropy and the\nKullback-Leibler divergence play a crucial role in constructing explainable\nlatent space and the variability of generated samples from our proposed model\ndepends on a specific subspace, called `activated latent subspace'. With MNIST\nand CIFAR-10 dataset, we show that the EXoN can produce an explainable latent\nspace that effectively represents the labels and characteristics of the images.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 07:04:30 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 13:45:31 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["An", "SeungHwan", ""], ["Choi", "Hosik", ""], ["Jeon", "Jong-June", ""]]}, {"id": "2105.10915", "submitter": "Daniel Wilke", "authors": "Younghwan Chae, Daniel N. Wilke, Dominic Kafka", "title": "GOALS: Gradient-Only Approximations for Line Searches Towards Robust and\n  Consistent Training of Deep Neural Networks", "comments": "26 pages, 8 figures and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mini-batch sub-sampling (MBSS) is favored in deep neural network training to\nreduce the computational cost. Still, it introduces an inherent sampling error,\nmaking the selection of appropriate learning rates challenging. The sampling\nerrors can manifest either as a bias or variances in a line search. Dynamic\nMBSS re-samples a mini-batch at every function evaluation. Hence, dynamic MBSS\nresults in point-wise discontinuous loss functions with smaller bias but larger\nvariance than static sampled loss functions. However, dynamic MBSS has the\nadvantage of having larger data throughput during training but requires the\ncomplexity regarding discontinuities to be resolved. This study extends the\ngradient-only surrogate (GOS), a line search method using quadratic\napproximation models built with only directional derivative information, for\ndynamic MBSS loss functions. We propose a gradient-only approximation line\nsearch (GOALS) with strong convergence characteristics with defined optimality\ncriterion. We investigate GOALS's performance by applying it on various\noptimizers that include SGD, RMSprop and Adam on ResNet-18 and EfficientNetB0.\nWe also compare GOALS's against the other existing learning rate methods. We\nquantify both the best performing and most robust algorithms. For the latter,\nwe introduce a relative robust criterion that allows us to quantify the\ndifference between an algorithm and the best performing algorithm for a given\nproblem. The results show that training a model with the recommended learning\nrate for a class of search directions helps to reduce the model errors in\nmultimodal cases.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 11:21:01 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Chae", "Younghwan", ""], ["Wilke", "Daniel N.", ""], ["Kafka", "Dominic", ""]]}, {"id": "2105.10948", "submitter": "Javier Carnerero-Cano", "authors": "Javier Carnerero-Cano, Luis Mu\\~noz-Gonz\\'alez, Phillippa Spencer,\n  Emil C. Lupu", "title": "Regularization Can Help Mitigate Poisoning Attacks... with the Right\n  Hyperparameters", "comments": "Published at ICLR 2021 Workshop on Security and Safety in Machine\n  Learning Systems. arXiv admin note: text overlap with arXiv:2003.00040", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning algorithms are vulnerable to poisoning attacks, where a\nfraction of the training data is manipulated to degrade the algorithms'\nperformance. We show that current approaches, which typically assume that\nregularization hyperparameters remain constant, lead to an overly pessimistic\nview of the algorithms' robustness and of the impact of regularization. We\npropose a novel optimal attack formulation that considers the effect of the\nattack on the hyperparameters, modelling the attack as a \\emph{minimax bilevel\noptimization problem}. This allows to formulate optimal attacks, select\nhyperparameters and evaluate robustness under worst case conditions. We apply\nthis formulation to logistic regression using $L_2$ regularization, empirically\nshow the limitations of previous strategies and evidence the benefits of using\n$L_2$ regularization to dampen the effect of poisoning attacks.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 14:34:47 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Carnerero-Cano", "Javier", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Spencer", "Phillippa", ""], ["Lupu", "Emil C.", ""]]}, {"id": "2105.11004", "submitter": "Aleksandros Sobczyk", "authors": "Aleksandros Sobczyk (1) and Efstratios Gallopoulos (2) ((1) IBM\n  Research Europe, Zurich, Switzerland (2) Computer Engineering and Informatics\n  Department, University of Patras, Greece)", "title": "Estimating leverage scores via rank revealing methods and randomization", "comments": "To appear in SIAM Journal on Matrix Analysis and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG cs.NA math.NA stat.CO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We study algorithms for estimating the statistical leverage scores of\nrectangular dense or sparse matrices of arbitrary rank. Our approach is based\non combining rank revealing methods with compositions of dense and sparse\nrandomized dimensionality reduction transforms. We first develop a set of fast\nnovel algorithms for rank estimation, column subset selection and least squares\npreconditioning. We then describe the design and implementation of leverage\nscore estimators based on these primitives. These estimators are also effective\nfor rank deficient input, which is frequently the case in data analytics\napplications. We provide detailed complexity analyses for all algorithms as\nwell as meaningful approximation bounds and comparisons with the\nstate-of-the-art. We conduct extensive numerical experiments to evaluate our\nalgorithms and to illustrate their properties and performance using synthetic\nand real world data sets.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 19:21:55 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Sobczyk", "Aleksandros", ""], ["Gallopoulos", "Efstratios", ""]]}, {"id": "2105.11025", "submitter": "John Shin", "authors": "John Y. Shin", "title": "Compressing Heavy-Tailed Weight Matrices for Non-Vacuous Generalization\n  Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heavy-tailed distributions have been studied in statistics, random matrix\ntheory, physics, and econometrics as models of correlated systems, among other\ndomains. Further, heavy-tail distributed eigenvalues of the covariance matrix\nof the weight matrices in neural networks have been shown to empirically\ncorrelate with test set accuracy in several works (e.g. arXiv:1901.08276), but\na formal relationship between heavy-tail distributed parameters and\ngeneralization bounds was yet to be demonstrated. In this work, the compression\nframework of arXiv:1802.05296 is utilized to show that matrices with heavy-tail\ndistributed matrix elements can be compressed, resulting in networks with\nsparse weight matrices. Since the parameter count has been reduced to a sum of\nthe non-zero elements of sparse matrices, the compression framework allows us\nto bound the generalization gap of the resulting compressed network with a\nnon-vacuous generalization bound. Further, the action of these matrices on a\nvector is discussed, and how they may relate to compression and resilient\nclassification is analyzed.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 21:36:33 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Shin", "John Y.", ""]]}, {"id": "2105.11045", "submitter": "Yuankai Teng", "authors": "Yuankai Teng, Xiaoping Zhang, Zhu Wang, Lili Ju", "title": "Learning Green's Functions of Linear Reaction-Diffusion Equations with\n  Application to Fast Numerical Solver", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial differential equations are often used to model various physical\nphenomena, such as heat diffusion, wave propagation, fluid dynamics,\nelasticity, electrodynamics and image processing, and many analytic approaches\nor traditional numerical methods have been developed and widely used for their\nsolutions. Inspired by rapidly growing impact of deep learning on scientific\nand engineering research, in this paper we propose a novel neural network,\nGF-Net, for learning the Green's functions of linear reaction-diffusion\nequations in an unsupervised fashion. The proposed method overcomes the\nchallenges for finding the Green's functions of the equations on arbitrary\ndomains by utilizing physics-informed approach and the symmetry of the Green's\nfunction. As a consequence, it particularly leads to an efficient way for\nsolving the target equations under different boundary conditions and sources.\nWe also demonstrate the effectiveness of the proposed approach by experiments\nin square, annular and L-shape domains.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 23:36:46 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Teng", "Yuankai", ""], ["Zhang", "Xiaoping", ""], ["Wang", "Zhu", ""], ["Ju", "Lili", ""]]}, {"id": "2105.11053", "submitter": "Sheng (Victor) Wang", "authors": "Samuel N. Cohen and Christoph Reisinger and Sheng Wang", "title": "Arbitrage-free neural-SDE market models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP math.PR q-fin.RM q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling joint dynamics of liquid vanilla options is crucial for\narbitrage-free pricing of illiquid derivatives and managing risks of option\ntrade books. This paper develops a nonparametric model for the European options\nbook respecting underlying financial constraints and while being practically\nimplementable. We derive a state space for prices which are free from static\n(or model-independent) arbitrage and study the inference problem where a model\nis learnt from discrete time series data of stock and option prices. We use\nneural networks as function approximators for the drift and diffusion of the\nmodelled SDE system, and impose constraints on the neural nets such that\nno-arbitrage conditions are preserved. In particular, we give methods to\ncalibrate \\textit{neural SDE} models which are guaranteed to satisfy a set of\nlinear inequalities. We validate our approach with numerical experiments using\ndata generated from a Heston stochastic local volatility model.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 00:53:10 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Cohen", "Samuel N.", ""], ["Reisinger", "Christoph", ""], ["Wang", "Sheng", ""]]}, {"id": "2105.11066", "submitter": "Shicong Cen", "authors": "Wenhao Zhan, Shicong Cen, Baihe Huang, Yuxin Chen, Jason D. Lee,\n  Yuejie Chi", "title": "Policy Mirror Descent for Regularized Reinforcement Learning: A\n  Generalized Framework with Linear Convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy optimization, which learns the policy of interest by maximizing the\nvalue function via large-scale optimization techniques, lies at the heart of\nmodern reinforcement learning (RL). In addition to value maximization, other\npractical considerations arise commonly as well, including the need of\nencouraging exploration, and that of ensuring certain structural properties of\nthe learned policy due to safety, resource and operational constraints. These\nconsiderations can often be accounted for by resorting to regularized RL, which\naugments the target value function with a structure-promoting regularization\nterm.\n  Focusing on an infinite-horizon discounted Markov decision process, this\npaper proposes a generalized policy mirror descent (GPMD) algorithm for solving\nregularized RL. As a generalization of policy mirror descent Lan (2021), the\nproposed algorithm accommodates a general class of convex regularizers as well\nas a broad family of Bregman divergence in cognizant of the regularizer in use.\nWe demonstrate that our algorithm converges linearly over an entire range of\nlearning rates, in a dimension-free fashion, to the global solution, even when\nthe regularizer lacks strong convexity and smoothness. In addition, this linear\nconvergence feature is provably stable in the face of inexact policy evaluation\nand imperfect policy updates. Numerical experiments are provided to corroborate\nthe applicability and appealing performance of GPMD.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 02:21:34 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Zhan", "Wenhao", ""], ["Cen", "Shicong", ""], ["Huang", "Baihe", ""], ["Chen", "Yuxin", ""], ["Lee", "Jason D.", ""], ["Chi", "Yuejie", ""]]}, {"id": "2105.11069", "submitter": "Jian Kang", "authors": "Jian Kang, Tiankai Xie, Xintao Wu, Ross Maciejewski, Hanghang Tong", "title": "MultiFair: Multi-Group Fairness in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Algorithmic fairness is becoming increasingly important in data mining and\nmachine learning, and one of the most fundamental notions is group fairness.\nThe vast majority of the existing works on group fairness, with a few\nexceptions, primarily focus on debiasing with respect to a single sensitive\nattribute, despite the fact that the co-existence of multiple sensitive\nattributes (e.g., gender, race, marital status, etc.) in the real-world is\ncommonplace. As such, methods that can ensure a fair learning outcome with\nrespect to all sensitive attributes of concern simultaneously need to be\ndeveloped. In this paper, we study multi-group fairness in machine learning\n(MultiFair), where statistical parity, a representative group fairness measure,\nis guaranteed among demographic groups formed by multiple sensitive attributes\nof interest. We formulate it as a mutual information minimization problem and\npropose a generic end-to-end algorithmic framework to solve it. The key idea is\nto leverage a variational representation of mutual information, which considers\nthe variational distribution between learning outcomes and sensitive\nattributes, as well as the density ratio between the variational and the\noriginal distributions. Our proposed framework is generalizable to many\ndifferent settings, including other statistical notions of fairness, and could\nhandle any type of learning task equipped with a gradient-based optimizer.\nEmpirical evaluations in the fair classification task on three real-world\ndatasets demonstrate that our proposed framework can effectively debias the\nclassification results with minimal impact to the classification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 02:30:22 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Kang", "Jian", ""], ["Xie", "Tiankai", ""], ["Wu", "Xintao", ""], ["Maciejewski", "Ross", ""], ["Tong", "Hanghang", ""]]}, {"id": "2105.11135", "submitter": "Matthew J. Holland", "authors": "Matthew J. Holland", "title": "Robust learning with anytime-guaranteed feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under data distributions which may be heavy-tailed, many stochastic\ngradient-based learning algorithms are driven by feedback queried at points\nwith almost no performance guarantees on their own. Here we explore a modified\n\"anytime online-to-batch\" mechanism which for smooth objectives admits\nhigh-probability error bounds while requiring only lower-order moment bounds on\nthe stochastic gradients. Using this conversion, we can derive a wide variety\nof \"anytime robust\" procedures, for which the task of performance analysis can\nbe effectively reduced to regret control, meaning that existing regret bounds\n(for the bounded gradient case) can be robustified and leveraged in a\nstraightforward manner. As a direct takeaway, we obtain an easily implemented\nstochastic gradient-based algorithm for which all queried points formally enjoy\nsub-Gaussian error bounds, and in practice show noteworthy gains on real-world\ndata applications.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 07:31:52 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Holland", "Matthew J.", ""]]}, {"id": "2105.11357", "submitter": "Austin Cole", "authors": "D. Austin Cole, Robert B. Gramacy, James E. Warner, Geoffrey F.\n  Bomarito, Patrick E. Leser, William P. Leser", "title": "Entropy-based adaptive design for contour finding and estimating\n  reliability", "comments": "41 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reliability analysis, methods used to estimate failure probability are\noften limited by the costs associated with model evaluations. Many of these\nmethods, such as multifidelity importance sampling (MFIS), rely upon a\ncomputationally efficient, surrogate model like a Gaussian process (GP) to\nquickly generate predictions. The quality of the GP fit, particularly in the\nvicinity of the failure region(s), is instrumental in supplying accurately\npredicted failures for such strategies. We introduce an entropy-based GP\nadaptive design that, when paired with MFIS, provides more accurate failure\nprobability estimates and with higher confidence. We show that our greedy data\nacquisition strategy better identifies multiple failure regions compared to\nexisting contour-finding schemes. We then extend the method to batch selection,\nwithout sacrificing accuracy. Illustrative examples are provided on benchmark\ndata as well as an application to an impact damage simulator for National\nAeronautics and Space Administration (NASA) spacesuits.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 15:41:15 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Cole", "D. Austin", ""], ["Gramacy", "Robert B.", ""], ["Warner", "James E.", ""], ["Bomarito", "Geoffrey F.", ""], ["Leser", "Patrick E.", ""], ["Leser", "William P.", ""]]}, {"id": "2105.11425", "submitter": "Valeriy Avanesov", "authors": "Valeriy Avanesov", "title": "Uncertainty quantification for distributed regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-growing size of the datasets renders well-studied learning\ntechniques, such as Kernel Ridge Regression, inapplicable, posing a serious\ncomputational challenge. Divide-and-conquer is a common remedy, suggesting to\nsplit the dataset into disjoint partitions, obtain the local estimates and\naverage them, it allows to scale-up an otherwise ineffective base approach. In\nthe current study we suggest a fully data-driven approach to quantify\nuncertainty of the averaged estimator. Namely, we construct simultaneous\nelement-wise confidence bands for the predictions yielded by the averaged\nestimator on a given deterministic prediction set. The novel approach features\nrigorous theoretical guaranties for a wide class of base learners with Kernel\nRidge regression being a special case. As a by-product of our analysis we also\nobtain a sup-norm consistency result for the divide-and-conquer Kernel Ridge\nRegression. The simulation study supports the theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 17:33:19 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Avanesov", "Valeriy", ""]]}, {"id": "2105.11447", "submitter": "Ethan Perez", "authors": "Ethan Perez, Douwe Kiela, Kyunghyun Cho", "title": "True Few-Shot Learning with Language Models", "comments": "Code at https://github.com/ethanjperez/true_few_shot", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pretrained language models (LMs) perform well on many tasks even when\nlearning from a few examples, but prior work uses many held-out examples to\ntune various aspects of learning, such as hyperparameters, training objectives,\nand natural language templates (\"prompts\"). Here, we evaluate the few-shot\nability of LMs when such held-out examples are unavailable, a setting we call\ntrue few-shot learning. We test two model selection criteria, cross-validation\nand minimum description length, for choosing LM prompts and hyperparameters in\nthe true few-shot setting. On average, both marginally outperform random\nselection and greatly underperform selection based on held-out examples.\nMoreover, selection criteria often prefer models that perform significantly\nworse than randomly-selected ones. We find similar results even when taking\ninto account our uncertainty in a model's true performance during selection, as\nwell as when varying the amount of computation and number of examples used for\nselection. Overall, our findings suggest that prior work significantly\noverestimated the true few-shot ability of LMs given the difficulty of few-shot\nmodel selection.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 17:55:51 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Perez", "Ethan", ""], ["Kiela", "Douwe", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "2105.11522", "submitter": "Marco Ballesio", "authors": "Marco Ballesio and Ajay Jasra", "title": "Unbiased Estimation of the Gradient of the Log-Likelihood for a Class of\n  Continuous-Time State-Space Models", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider static parameter estimation for a class of\ncontinuous-time state-space models. Our goal is to obtain an unbiased estimate\nof the gradient of the log-likelihood (score function), which is an estimate\nthat is unbiased even if the stochastic processes involved in the model must be\ndiscretized in time. To achieve this goal, we apply a doubly randomized scheme,\nthat involves a novel coupled conditional particle filter (CCPF) on the second\nlevel of randomization. Our novel estimate helps facilitate the application of\ngradient-based estimation algorithms, such as stochastic-gradient Langevin\ndescent. We illustrate our methodology in the context of stochastic gradient\ndescent (SGD) in several numerical examples and compare with the Rhee & Glynn\nestimator.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 20:31:48 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 20:56:49 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ballesio", "Marco", ""], ["Jasra", "Ajay", ""]]}, {"id": "2105.11535", "submitter": "Martin Jankowiak", "authors": "Martin Jankowiak, Geoff Pleiss", "title": "Scalable Cross Validation Losses for Gaussian Process Models", "comments": "19 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple and scalable method for training Gaussian process (GP)\nmodels that exploits cross-validation and nearest neighbor truncation. To\naccommodate binary and multi-class classification we leverage P\\`olya-Gamma\nauxiliary variables and variational inference. In an extensive empirical\ncomparison with a number of alternative methods for scalable GP regression and\nclassification, we find that our method offers fast training and excellent\npredictive performance. We argue that the good predictive performance can be\ntraced to the non-parametric nature of the resulting predictive distributions\nas well as to the cross-validation loss, which provides robustness against\nmodel mis-specification.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 21:01:47 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Jankowiak", "Martin", ""], ["Pleiss", "Geoff", ""]]}, {"id": "2105.11558", "submitter": "Suhas S Kowshik", "authors": "Prateek Jain, Suhas S Kowshik, Dheeraj Nagaraj, Praneeth Netrapalli", "title": "Near-optimal Offline and Streaming Algorithms for Learning Non-Linear\n  Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the setting of vector valued non-linear dynamical systems\n$X_{t+1} = \\phi(A^* X_t) + \\eta_t$, where $\\eta_t$ is unbiased noise and $\\phi\n: \\mathbb{R} \\to \\mathbb{R}$ is a known link function that satisfies certain\n{\\em expansivity property}. The goal is to learn $A^*$ from a single trajectory\n$X_1,\\cdots,X_T$ of {\\em dependent or correlated} samples. While the problem is\nwell-studied in the linear case, where $\\phi$ is identity, with optimal error\nrates even for non-mixing systems, existing results in the non-linear case hold\nonly for mixing systems. In this work, we improve existing results for learning\nnonlinear systems in a number of ways: a) we provide the first offline\nalgorithm that can learn non-linear dynamical systems without the mixing\nassumption, b) we significantly improve upon the sample complexity of existing\nresults for mixing systems, c) in the much harder one-pass, streaming setting\nwe study a SGD with Reverse Experience Replay ($\\mathsf{SGD-RER}$) method, and\ndemonstrate that for mixing systems, it achieves the same sample complexity as\nour offline algorithm, d) we justify the expansivity assumption by showing that\nfor the popular ReLU link function -- a non-expansive but easy to learn link\nfunction with i.i.d. samples -- any method would require exponentially many\nsamples (with respect to dimension of $X_t$) from the dynamical system. We\nvalidate our results via. simulations and demonstrate that a naive application\nof SGD can be highly sub-optimal. Indeed, our work demonstrates that for\ncorrelated data, specialized methods designed for the dependency structure in\ndata can significantly outperform standard SGD based methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 22:14:26 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 16:48:00 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Jain", "Prateek", ""], ["Kowshik", "Suhas S", ""], ["Nagaraj", "Dheeraj", ""], ["Netrapalli", "Praneeth", ""]]}, {"id": "2105.11724", "submitter": "Clement Benard", "authors": "Cl\\'ement B\\'enard (LPSM), G\\'erard Biau (LPSM), S\\'ebastien da Veiga,\n  Erwan Scornet (CMAP)", "title": "SHAFF: Fast and consistent SHApley eFfect estimates via random Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability of learning algorithms is crucial for applications involving\ncritical decisions, and variable importance is one of the main interpretation\ntools. Shapley effects are now widely used to interpret both tree ensembles and\nneural networks, as they can efficiently handle dependence and interactions in\nthe data, as opposed to most other variable importance measures. However,\nestimating Shapley effects is a challenging task, because of the computational\ncomplexity and the conditional expectation estimates. Accordingly, existing\nShapley algorithms have flaws: a costly running time, or a bias when input\nvariables are dependent. Therefore, we introduce SHAFF, SHApley eFfects via\nrandom Forests, a fast and accurate Shapley effect estimate, even when input\nvariables are dependent. We show SHAFF efficiency through both a theoretical\nanalysis of its consistency, and the practical performance improvements over\ncompetitors with extensive experiments. An implementation of SHAFF in C++ and R\nis available online.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 07:48:07 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["B\u00e9nard", "Cl\u00e9ment", "", "LPSM"], ["Biau", "G\u00e9rard", "", "LPSM"], ["da Veiga", "S\u00e9bastien", "", "CMAP"], ["Scornet", "Erwan", "", "CMAP"]]}, {"id": "2105.11802", "submitter": "Johannes Kirschner", "authors": "Johannes Kirschner and Andreas Krause", "title": "Bias-Robust Bayesian Optimization via Dueling Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Bayesian optimization in settings where observations can be\nadversarially biased, for example by an uncontrolled hidden confounder. Our\nfirst contribution is a reduction of the confounded setting to the dueling\nbandit model. Then we propose a novel approach for dueling bandits based on\ninformation-directed sampling (IDS). Thereby, we obtain the first efficient\nkernelized algorithm for dueling bandits that comes with cumulative regret\nguarantees. Our analysis further generalizes a previously proposed\nsemi-parametric linear bandit model to non-linear reward functions, and\nuncovers interesting links to doubly-robust estimation.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 10:08:41 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 07:04:02 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Kirschner", "Johannes", ""], ["Krause", "Andreas", ""]]}, {"id": "2105.11815", "submitter": "Zhen Shao", "authors": "Coralia Cartis, Jan Fiala and Zhen Shao", "title": "Hashing embeddings of optimal dimension, with applications to linear\n  least squares", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA math.OC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The aim of this paper is two-fold: firstly, to present subspace embedding\nproperties for $s$-hashing sketching matrices, with $s\\geq 1$, that are optimal\nin the projection dimension $m$ of the sketch, namely, $m=\\mathcal{O}(d)$,\nwhere $d$ is the dimension of the subspace. A diverse set of results are\npresented that address the case when the input matrix has sufficiently low\ncoherence (thus removing the $\\log^2 d$ factor dependence in $m$, in the\nlow-coherence result of Bourgain et al (2015) at the expense of a smaller\ncoherence requirement); how this coherence changes with the number $s$ of\ncolumn nonzeros (allowing a scaling of $\\sqrt{s}$ of the coherence bound), or\nis reduced through suitable transformations (when considering hashed -- instead\nof subsampled -- coherence reducing transformations such as randomised\nHadamard). Secondly, we apply these general hashing sketching results to the\nspecial case of Linear Least Squares (LLS), and develop Ski-LLS, a generic\nsoftware package for these problems, that builds upon and improves the\nBlendenpik solver on dense input and the (sequential) LSRN performance on\nsparse problems. In addition to the hashing sketching improvements, we add\nsuitable linear algebra tools for rank-deficient and for sparse problems that\nlead Ski-LLS to outperform not only sketching-based routines on randomly\ngenerated input, but also state of the art direct solver SPQR and iterative\ncode HSL on certain subsets of the sparse Florida matrix collection; namely, on\nleast squares problems that are significantly overdetermined, or moderately\nsparse, or difficult.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 10:35:13 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Cartis", "Coralia", ""], ["Fiala", "Jan", ""], ["Shao", "Zhen", ""]]}, {"id": "2105.11818", "submitter": "Remi Leluc", "authors": "R\\'emi Leluc and Fran\\c{c}ois Portier", "title": "SGD with Coordinate Sampling: Theory and Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While classical forms of stochastic gradient descent algorithm treat the\ndifferent coordinates in the same way, a framework allowing for adaptive (non\nuniform) coordinate sampling is developed to leverage structure in data. In a\nnon-convex setting and including zeroth order gradient estimate, almost sure\nconvergence as well as non-asymptotic bounds are established. Within the\nproposed framework, we develop an algorithm, MUSKETEER, based on a\nreinforcement strategy: after collecting information on the noisy gradients, it\nsamples the most promising coordinate (all for one); then it moves along the\none direction yielding an important decrease of the objective (one for all).\nNumerical experiments on both synthetic and real data examples confirm the\neffectiveness of MUSKETEER in large scale problems.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 10:37:50 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Leluc", "R\u00e9mi", ""], ["Portier", "Fran\u00e7ois", ""]]}, {"id": "2105.11839", "submitter": "Lars Lorch", "authors": "Lars Lorch, Jonas Rothfuss, Bernhard Sch\\\"olkopf, Andreas Krause", "title": "DiBS: Differentiable Bayesian Structure Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian structure learning allows inferring Bayesian network structure from\ndata while reasoning about the epistemic uncertainty -- a key element towards\nenabling active causal discovery and designing interventions in real world\nsystems. In this work, we propose a general, fully differentiable framework for\nBayesian structure learning (DiBS) that operates in the continuous space of a\nlatent probabilistic graph representation. Building on recent advances in\nvariational inference, we use DiBS to devise an efficient method for\napproximating posteriors over structural models. Contrary to existing work,\nDiBS is agnostic to the form of the local conditional distributions and allows\nfor joint posterior inference of both the graph structure and the conditional\ndistribution parameters. This makes our method directly applicable to posterior\ninference of nonstandard Bayesian network models, e.g., with nonlinear\ndependencies encoded by neural networks. In evaluations on simulated and\nreal-world data, DiBS significantly outperforms related approaches to joint\nposterior inference.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 11:23:08 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Lorch", "Lars", ""], ["Rothfuss", "Jonas", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Krause", "Andreas", ""]]}, {"id": "2105.11886", "submitter": "Chen Xu", "authors": "Chen Xu, Yao Xie", "title": "Conformal Anomaly Detection on Spatio-Temporal Observations with Missing\n  Data", "comments": "Submitted to ICML 2021 Workshop--Distribution-free Uncertainty\n  Quantification", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop a distribution-free, unsupervised anomaly detection method called\nECAD, which wraps around any regression algorithm and sequentially detects\nanomalies. Rooted in conformal prediction, ECAD does not require data\nexchangeability but approximately controls the Type-I error when data are\nnormal. Computationally, it involves no data-splitting and efficiently trains\nensemble predictors to increase statistical power. We demonstrate the superior\nperformance of ECAD on detecting anomalous spatio-temporal traffic flow.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 12:44:14 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 02:49:29 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Xu", "Chen", ""], ["Xie", "Yao", ""]]}, {"id": "2105.11964", "submitter": "Martin Hellkvist", "authors": "Martin Hellkvist, Ay\\c{c}a \\\"Oz\\c{c}elikkale", "title": "Model Mismatch Trade-offs in LMMSE Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a linear minimum mean squared error (LMMSE) estimation framework\nwith model mismatch where the assumed model order is smaller than that of the\nunderlying linear system which generates the data used in the estimation\nprocess. By modelling the regressors of the underlying system as random\nvariables, we analyze the average behaviour of the mean squared error (MSE).\nOur results quantify how the MSE depends on the interplay between the number of\nsamples and the number of parameters in the underlying system and in the\nassumed model. In particular, if the number of samples is not sufficiently\nlarge, neither increasing the number of samples nor the assumed model\ncomplexity is sufficient to guarantee a performance improvement.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 14:16:45 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Hellkvist", "Martin", ""], ["\u00d6z\u00e7elikkale", "Ay\u00e7a", ""]]}, {"id": "2105.11982", "submitter": "Xinyue Xiong", "authors": "Dongxia Wu, Liyao Gao, Xinyue Xiong, Matteo Chinazzi, Alessandro\n  Vespignani, Yi-An Ma, Rose Yu", "title": "Quantifying Uncertainty in Deep Spatiotemporal Forecasting", "comments": "arXiv admin note: text overlap with arXiv:2102.06684", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is gaining increasing popularity for spatiotemporal\nforecasting. However, prior works have mostly focused on point estimates\nwithout quantifying the uncertainty of the predictions. In high stakes domains,\nbeing able to generate probabilistic forecasts with confidence intervals is\ncritical to risk assessment and decision making. Hence, a systematic study of\nuncertainty quantification (UQ) methods for spatiotemporal forecasting is\nmissing in the community. In this paper, we describe two types of\nspatiotemporal forecasting problems: regular grid-based and graph-based. Then\nwe analyze UQ methods from both the Bayesian and the frequentist point of view,\ncasting in a unified framework via statistical decision theory. Through\nextensive experiments on real-world road network traffic, epidemics, and air\nquality forecasting tasks, we reveal the statistical and computational\ntrade-offs for different UQ methods: Bayesian methods are typically more robust\nin mean prediction, while confidence levels obtained from frequentist methods\nprovide more extensive coverage over data variations. Computationally, quantile\nregression type methods are cheaper for a single confidence interval but\nrequire re-training for different intervals. Sampling based methods generate\nsamples that can form multiple confidence intervals, albeit at a higher\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 14:35:46 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 12:59:06 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Wu", "Dongxia", ""], ["Gao", "Liyao", ""], ["Xiong", "Xinyue", ""], ["Chinazzi", "Matteo", ""], ["Vespignani", "Alessandro", ""], ["Ma", "Yi-An", ""], ["Yu", "Rose", ""]]}, {"id": "2105.12005", "submitter": "Parisa Abdolrahim Poorheravi", "authors": "Parisa Abdolrahim Poorheravi and Vincent Gaudet", "title": "Hierarchical Subspace Learning for Dimensionality Reduction to Improve\n  Classification Accuracy in Large Data Sets", "comments": "6 pages with 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold learning is used for dimensionality reduction, with the goal of\nfinding a projection subspace to increase and decrease the inter- and\nintraclass variances, respectively. However, a bottleneck for subspace learning\nmethods often arises from the high dimensionality of datasets. In this paper, a\nhierarchical approach is proposed to scale subspace learning methods, with the\ngoal of improving classification in large datasets by a range of 3% to 10%.\nDifferent combinations of methods are studied. We assess the proposed method on\nfive publicly available large datasets, for different eigen-value based\nsubspace learning methods such as linear discriminant analysis, principal\ncomponent analysis, generalized discriminant analysis, and reconstruction\nindependent component analysis. To further examine the effect of the proposed\nmethod on various classification methods, we fed the generated result to linear\ndiscriminant analysis, quadratic linear analysis, k-nearest neighbor, and\nrandom forest classifiers. The resulting classification accuracies are compared\nto show the effectiveness of the hierarchical approach, reporting results of an\naverage of 5% increase in classification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 15:15:12 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Poorheravi", "Parisa Abdolrahim", ""], ["Gaudet", "Vincent", ""]]}, {"id": "2105.12022", "submitter": "Robbie Vreugdenhil", "authors": "Robbie Vreugdenhil, Viet Anh Nguyen, Armin Eftekhari, Peyman Mohajerin\n  Esfahani", "title": "Principal Component Hierarchy for Sparse Quadratic Programs", "comments": null, "journal-ref": "ICML 2021", "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel approximation hierarchy for cardinality-constrained,\nconvex quadratic programs that exploits the rank-dominating eigenvectors of the\nquadratic matrix. Each level of approximation admits a min-max characterization\nwhose objective function can be optimized over the binary variables\nanalytically, while preserving convexity in the continuous variables.\nExploiting this property, we propose two scalable optimization algorithms,\ncoined as the \"best response\" and the \"dual program\", that can efficiently\nscreen the potential indices of the nonzero elements of the original program.\nWe show that the proposed methods are competitive with the existing screening\nmethods in the current sparse regression literature, and it is particularly\nfast on instances with high number of measurements in experiments with both\nsynthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 15:45:16 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Vreugdenhil", "Robbie", ""], ["Nguyen", "Viet Anh", ""], ["Eftekhari", "Armin", ""], ["Esfahani", "Peyman Mohajerin", ""]]}, {"id": "2105.12033", "submitter": "Van Hai Nguyen", "authors": "Hai V. Nguyen, Tan Bui-Thanh", "title": "Model-Constrained Deep Learning Approaches for Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL), in particular deep neural networks (DNN), by design is\npurely data-driven and in general does not require physics. This is the\nstrength of DL but also one of its key limitations when applied to science and\nengineering problems in which underlying physical properties (such as\nstability, conservation, and positivity) and desired accuracy need to be\nachieved. DL methods in their original forms are not capable of respecting the\nunderlying mathematical models or achieving desired accuracy even in big-data\nregimes. On the other hand, many data-driven science and engineering problems,\nsuch as inverse problems, typically have limited experimental or observational\ndata, and DL would overfit the data in this case. Leveraging information\nencoded in the underlying mathematical models, we argue, not only compensates\nmissing information in low data regimes but also provides opportunities to\nequip DL methods with the underlying physics and hence obtaining higher\naccuracy. This short communication introduces several model-constrained DL\napproaches (including both feed-forward DNN and autoencoders) that are capable\nof learning not only information hidden in the training data but also in the\nunderlying mathematical models to solve inverse problems. We present and\nprovide intuitions for our formulations for general nonlinear problems. For\nlinear inverse problems and linear networks, the first order optimality\nconditions show that our model-constrained DL approaches can learn information\nencoded in the underlying mathematical models, and thus can produce consistent\nor equivalent inverse solutions, while naive purely data-based counterparts\ncannot.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 16:12:39 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 22:18:15 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Nguyen", "Hai V.", ""], ["Bui-Thanh", "Tan", ""]]}, {"id": "2105.12062", "submitter": "Kaiwen Zhou", "authors": "Kaiwen Zhou, Lai Tian, Anthony Man-Cho So, James Cheng", "title": "Practical Schemes for Finding Near-Stationary Points of Convex\n  Finite-Sums", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of finding near-stationary points in convex optimization has not\nbeen adequately studied yet, unlike other optimality measures such as\nminimizing function value. Even in the deterministic case, the optimal method\n(OGM-G, due to Kim and Fessler (2021)) has just been discovered recently. In\nthis work, we conduct a systematic study of the algorithmic techniques in\nfinding near-stationary points of convex finite-sums. Our main contributions\nare several algorithmic discoveries: (1) we discover a memory-saving variant of\nOGM-G based on the performance estimation problem approach (Drori and Teboulle,\n2014); (2) we design a new accelerated SVRG variant that can simultaneously\nachieve fast rates for both minimizing gradient norm and function value; (3) we\npropose an adaptively regularized accelerated SVRG variant, which does not\nrequire the knowledge of some unknown initial constants and achieves\nnear-optimal complexities. We put an emphasis on the simplicity and\npracticality of the new schemes, which could facilitate future developments.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 16:46:35 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Zhou", "Kaiwen", ""], ["Tian", "Lai", ""], ["So", "Anthony Man-Cho", ""], ["Cheng", "James", ""]]}, {"id": "2105.12081", "submitter": "Ryan Thompson", "authors": "Ryan Thompson and Farshid Vahid", "title": "Group selection and shrinkage with application to sparse semiparametric\n  modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse regression and classification estimators capable of group selection\nhave application to an assortment of statistical problems, from multitask\nlearning to sparse additive modeling to hierarchical selection. This work\nintroduces a class of group-sparse estimators that combine group subset\nselection with group lasso or ridge shrinkage. We develop an optimization\nframework for fitting the nonconvex regularization surface and present\nfinite-sample error bounds for estimation of the regression function. Our\nmethods and analyses accommodate the general setting where groups overlap. As\nan application of group selection, we study sparse semiparametric modeling, a\nprocedure that allows the effect of each predictor to be zero, linear, or\nnonlinear. For this task, the new estimators improve across several metrics on\nsynthetic data compared to alternatives. Finally, we demonstrate their efficacy\nin modeling supermarket foot traffic and economic recessions using many\npredictors. All of our proposals are made available in the scalable\nimplementation grpsel.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 17:00:25 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Thompson", "Ryan", ""], ["Vahid", "Farshid", ""]]}, {"id": "2105.12089", "submitter": "Piyush Sharma", "authors": "Piyush K. Sharma, Gary Holness, and Poopalasingam Sivakumar, Yuri\n  Markushin, Noureddine Melikechi", "title": "Investigating Manifold Neighborhood size for Nonlinear Analysis of LIBS\n  Amino Acid Spectra", "comments": "In ISCA 24th International Conference on Software Engineering and\n  Data Engineering (SEDE 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification and identification of amino acids in aqueous solutions is\nimportant in the study of biomacromolecules. Laser Induced Breakdown\nSpectroscopy (LIBS) uses high energy laser-pulses for ablation of chemical\ncompounds whose radiated spectra are captured and recorded to reveal molecular\nstructure. Spectral peaks and noise from LIBS are impacted by experimental\nprotocols. Current methods for LIBS spectral analysis achieves promising\nresults using PCA, a linear method. It is well-known that the underlying\nphysical processes behind LIBS are highly nonlinear. Our work set out to\nunderstand the impact of LIBS spectra on suitable neighborhood size over which\nto consider pattern phenomena, if nonlinear methods capture pattern phenomena\nwith increased efficacy, and how they improve classification and identification\nof compounds. We analyzed four amino acids, polysaccharide, and a control\ngroup, water. We developed an information theoretic method for measurement of\nLIBS energy spectra, implemented manifold methods for nonlinear dimensionality\nreduction, and found while clustering results were not statistically\nsignificantly different, nonlinear methods lead to increased classification\naccuracy. Moreover, our approach uncovered the contribution of micro-wells\n(experimental protocol) in LIBS spectra. To the best of our knowledge, ours is\nthe first application of Manifold methods to LIBS amino-acid analysis in the\nresearch literature.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 17:17:00 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Sharma", "Piyush K.", ""], ["Holness", "Gary", ""], ["Sivakumar", "Poopalasingam", ""], ["Markushin", "Yuri", ""], ["Melikechi", "Noureddine", ""]]}, {"id": "2105.12092", "submitter": "Anselmo Pitombeira-Neto", "authors": "Anselmo R. Pitombeira-Neto, Helano P. Santos, Ticiana L. Coelho da\n  Silva, Jos\\'e Antonio F. de Macedo", "title": "Trajectory Modeling via Random Utility Inverse Reinforcement Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of modeling trajectories of drivers in a road network\nfrom the perspective of inverse reinforcement learning. As rational agents,\ndrivers are trying to maximize some reward function unknown to an external\nobserver as they make up their trajectories. We apply the concept of random\nutility from microeconomic theory to model the unknown reward function as a\nfunction of observable features plus an error term which represents features\nknown only to the driver. We develop a parameterized generative model for the\ntrajectories based on a random utility Markov decision process formulation of\ndrivers decisions. We show that maximum entropy inverse reinforcement learning\nis a particular case of our proposed formulation when we assume a Gumbel\ndensity function for the unobserved reward error terms. We illustrate Bayesian\ninference on model parameters through a case study with real trajectory data\nfrom a large city obtained from sensors placed on sparsely distributed points\non the street network.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 17:19:09 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Pitombeira-Neto", "Anselmo R.", ""], ["Santos", "Helano P.", ""], ["da Silva", "Ticiana L. Coelho", ""], ["de Macedo", "Jos\u00e9 Antonio F.", ""]]}, {"id": "2105.12152", "submitter": "Christian Horvat", "authors": "Christian Horvat, Jean-Pascal Pfister", "title": "Density estimation on low-dimensional manifolds: an inflation-deflation\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Normalizing Flows (NFs) are universal density estimators based on Neuronal\nNetworks. However, this universality is limited: the density's support needs to\nbe diffeomorphic to a Euclidean space. In this paper, we propose a novel method\nto overcome this limitation without sacrificing universality. The proposed\nmethod inflates the data manifold by adding noise in the normal space, trains\nan NF on this inflated manifold, and, finally, deflates the learned density.\nOur main result provides sufficient conditions on the manifold and the specific\nchoice of noise under which the corresponding estimator is exact. Our method\nhas the same computational complexity as NFs and does not require computing an\ninverse flow. We also show that, if the embedding dimension is much larger than\nthe manifold dimension, noise in the normal space can be well approximated by\nGaussian noise. This allows to use our method for approximating arbitrary\ndensities on non-flat manifolds provided that the manifold dimension is known.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 18:08:09 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 12:42:45 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Horvat", "Christian", ""], ["Pfister", "Jean-Pascal", ""]]}, {"id": "2105.12237", "submitter": "Yatong Bai", "authors": "Yatong Bai, Tanmay Gautam, Yu Gai, Somayeh Sojoudi", "title": "Practical Convex Formulation of Robust One-hidden-layer Neural Network\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has shown that the training of a one-hidden-layer, scalar-output\nfully-connected ReLU neural network can be reformulated as a finite-dimensional\nconvex program. Unfortunately, the scale of such a convex program grows\nexponentially in data size. In this work, we prove that a stochastic procedure\nwith a linear complexity well approximates the exact formulation. Moreover, we\nderive a convex optimization approach to efficiently solve the \"adversarial\ntraining\" problem, which trains neural networks that are robust to adversarial\ninput perturbations. Our method can be applied to binary classification and\nregression, and provides an alternative to the current adversarial training\nmethods, such as Fast Gradient Sign Method (FGSM) and Projected Gradient\nDescent (PGD). We demonstrate in experiments that the proposed method achieves\na noticeably better adversarial robustness and performance than the existing\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 22:06:27 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Bai", "Yatong", ""], ["Gautam", "Tanmay", ""], ["Gai", "Yu", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "2105.12245", "submitter": "Alain Rossier", "authors": "Alain-Sam Cohen, Rama Cont, Alain Rossier, Renyuan Xu", "title": "Scaling Properties of Deep Residual Networks", "comments": "Published at ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA cs.NE math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residual networks (ResNets) have displayed impressive results in pattern\nrecognition and, recently, have garnered considerable theoretical interest due\nto a perceived link with neural ordinary differential equations (neural ODEs).\nThis link relies on the convergence of network weights to a smooth function as\nthe number of layers increases. We investigate the properties of weights\ntrained by stochastic gradient descent and their scaling with network depth\nthrough detailed numerical experiments. We observe the existence of scaling\nregimes markedly different from those assumed in neural ODE literature.\nDepending on certain features of the network architecture, such as the\nsmoothness of the activation function, one may obtain an alternative ODE limit,\na stochastic differential equation or neither of these. These findings cast\ndoubts on the validity of the neural ODE model as an adequate asymptotic\ndescription of deep ResNets and point to an alternative class of differential\nequations as a better description of the deep network limit.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 22:31:30 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 13:46:14 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Cohen", "Alain-Sam", ""], ["Cont", "Rama", ""], ["Rossier", "Alain", ""], ["Xu", "Renyuan", ""]]}, {"id": "2105.12247", "submitter": "Sayan Nag", "authors": "Sayan Nag", "title": "Graph Self Supervised Learning: the BT, the HSIC, and the VICReg", "comments": "Paper Accepted in the Weakly Supervised Representation Learning\n  Workshop, IJCAI 2021 (IJCAI2021-WSRL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised learning and pre-training strategies have developed over the\nlast few years especially for Convolutional Neural Networks (CNNs). Recently\napplication of such methods can also be noticed for Graph Neural Networks\n(GNNs) . In this paper, we have used a graph based self-supervised learning\nstrategy with different loss functions (Barlow Twins[Zbontar et al., 2021],\nHSIC[Tsai et al., 2021], VICReg[Bardes et al., 2021]) which have shown\npromising results when applied with CNNs previously. We have also proposed a\nhybrid loss function combining the advantages of VICReg and HSIC and called it\nas VICRegHSIC. The performance of these aforementioned methods have been\ncompared when applied to different datasets such as MUTAG, PROTEINS and\nIMDB-Binary. Moreover, the impact of different batch sizes, projector\ndimensions and data augmentation strategies have also been explored\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 22:34:19 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 04:51:26 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 03:18:43 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Nag", "Sayan", ""]]}, {"id": "2105.12257", "submitter": "Antoine Bodin", "authors": "Antoine Bodin, Nicolas Macris", "title": "Rank-one matrix estimation: analytic time evolution of gradient descent\n  dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a rank-one symmetric matrix corrupted by additive noise. The\nrank-one matrix is formed by an $n$-component unknown vector on the sphere of\nradius $\\sqrt{n}$, and we consider the problem of estimating this vector from\nthe corrupted matrix in the high dimensional limit of $n$ large, by gradient\ndescent for a quadratic cost function on the sphere. Explicit formulas for the\nwhole time evolution of the overlap between the estimator and unknown vector,\nas well as the cost, are rigorously derived. In the long time limit we recover\nthe well known spectral phase transition, as a function of the signal-to-noise\nratio. The explicit formulas also allow to point out interesting transient\nfeatures of the time evolution. Our analysis technique is based on recent\nprogress in random matrix theory and uses local versions of the semi-circle\nlaw.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 23:31:08 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Bodin", "Antoine", ""], ["Macris", "Nicolas", ""]]}, {"id": "2105.12271", "submitter": "Yu Wang", "authors": "Yu Wang and Alfred Hero", "title": "SG-PALM: a Fast Physically Interpretable Tensor Graphical Model", "comments": "Accepted in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new graphical model inference procedure, called SG-PALM, for\nlearning conditional dependency structure of high-dimensional tensor-variate\ndata. Unlike most other tensor graphical models the proposed model is\ninterpretable and computationally scalable to high dimension. Physical\ninterpretability follows from the Sylvester generative (SG) model on which\nSG-PALM is based: the model is exact for any observation process that is a\nsolution of a partial differential equation of Poisson type. Scalability\nfollows from the fast proximal alternating linearized minimization (PALM)\nprocedure that SG-PALM uses during training. We establish that SG-PALM\nconverges linearly (i.e., geometric convergence rate) to a global optimum of\nits objective function. We demonstrate the scalability and accuracy of SG-PALM\nfor an important but challenging climate prediction problem: spatio-temporal\nforecasting of solar flares from multimodal imaging data.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 00:24:25 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Wang", "Yu", ""], ["Hero", "Alfred", ""]]}, {"id": "2105.12286", "submitter": "Amadou Barry", "authors": "Amadou Barry, Nikhil Bhagwat, Bratislav Misic, Jean-Baptiste Poline\n  and Celia M. T. Greenwood", "title": "An algorithm-based multiple detection influence measure for high\n  dimensional regression using expectile", "comments": "38 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of influential observations is an important part of data\nanalysis that can prevent erroneous conclusions drawn from biased estimators.\nHowever, in high dimensional data, this identification is challenging.\nClassical and recently-developed methods often perform poorly when there are\nmultiple influential observations in the same dataset. In particular, current\nmethods can fail when there is masking several influential observations with\nsimilar characteristics, or swamping when the influential observations are near\nthe boundary of the space spanned by well-behaved observations. Therefore, we\npropose an algorithm-based, multi-step, multiple detection procedure to\nidentify influential observations that addresses current limitations. Our\nthree-step algorithm to identify and capture undesirable variability in the\ndata, $\\asymMIP,$ is based on two complementary statistics, inspired by\nasymmetric correlations, and built on expectiles. Simulations demonstrate\nhigher detection power than competing methods. Use of the resulting asymptotic\ndistribution leads to detection of influential observations without the need\nfor computationally demanding procedures such as the bootstrap. The application\nof our method to the Autism Brain Imaging Data Exchange neuroimaging dataset\nresulted in a more balanced and accurate prediction of brain maturity based on\ncortical thickness. See our GitHub for a free R package that implements our\nalgorithm: \\texttt{asymMIP} (\\url{github.com/AmBarry/hidetify}).\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 01:16:24 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Barry", "Amadou", ""], ["Bhagwat", "Nikhil", ""], ["Misic", "Bratislav", ""], ["Poline", "Jean-Baptiste", ""], ["Greenwood", "Celia M. T.", ""]]}, {"id": "2105.12290", "submitter": "Benjamin Leinwand", "authors": "Benjamin Leinwand, Vladas Pipiras", "title": "Block Dense Weighted Networks with Augmented Degree Correction", "comments": "43 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dense networks with weighted connections often exhibit a community like\nstructure, where although most nodes are connected to each other, different\npatterns of edge weights may emerge depending on each node's community\nmembership. We propose a new framework for generating and estimating dense\nweighted networks with potentially different connectivity patterns across\ndifferent communities. The proposed model relies on a particular class of\nfunctions which map individual node characteristics to the edges connecting\nthose nodes, allowing for flexibility while requiring a small number of\nparameters relative to the number of edges. By leveraging the estimation\ntechniques, we also develop a bootstrap methodology for generating new networks\non the same set of vertices, which may be useful in circumstances where\nmultiple data sets cannot be collected. Performance of these methods are\nanalyzed in theory, simulations, and real data.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 01:25:07 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Leinwand", "Benjamin", ""], ["Pipiras", "Vladas", ""]]}, {"id": "2105.12342", "submitter": "Andrew Lim", "authors": "Jun-ya Gotoh, Michael Jong Kim, Andrew E.B. Lim", "title": "A data-driven approach to beating SAA out-of-sample", "comments": "20 pages, 2 Figures, 2 page Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.SY econ.EM eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While solutions of Distributionally Robust Optimization (DRO) problems can\nsometimes have a higher out-of-sample expected reward than the Sample Average\nApproximation (SAA), there is no guarantee. In this paper, we introduce the\nclass of Distributionally Optimistic Optimization (DOO) models, and show that\nit is always possible to \"beat\" SAA out-of-sample if we consider not just\nworst-case (DRO) models but also best-case (DOO) ones. We also show, however,\nthat this comes at a cost: Optimistic solutions are more sensitive to model\nerror than either worst-case or SAA optimizers, and hence are less robust.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 06:10:12 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 11:49:24 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Gotoh", "Jun-ya", ""], ["Kim", "Michael Jong", ""], ["Lim", "Andrew E. B.", ""]]}, {"id": "2105.12356", "submitter": "Michelangelo Conserva", "authors": "Michelangelo Conserva, Marc Peter Deisenroth, K S Sesh Kumar", "title": "Submodular Kernels for Efficient Rankings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Many algorithms for ranked data become computationally intractable as the\nnumber of objects grows due to complex geometric structure induced by rankings.\nAn additional challenge is posed by partial rankings, i.e. rankings in which\nthe preference is only known for a subset of all objects. For these reasons,\nstate-of-the-art methods cannot scale to real-world applications, such as\nrecommender systems. We address this challenge by exploiting geometric\nstructure of ranked data and additional available information about the objects\nto derive a submodular kernel for ranking. The submodular kernel combines the\nefficiency of submodular optimization with the theoretical properties of\nkernel-based methods. We demonstrate that the submodular kernel drastically\nreduces the computational cost compared to state-of-the-art kernels and scales\nwell to large datasets while attaining good empirical performance.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 06:42:06 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Conserva", "Michelangelo", ""], ["Deisenroth", "Marc Peter", ""], ["Kumar", "K S Sesh", ""]]}, {"id": "2105.12478", "submitter": "Tyler McCormick", "authors": "Tyler McCormick", "title": "The \"given data\" paradigm undermines both cultures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Breiman organizes \"Statistical modeling: The two cultures\" around a simple\nvisual. Data, to the far right, are compelled into a \"black box\" with an arrow\nand then catapulted left by a second arrow, having been transformed into an\noutput. Breiman then posits two interpretations of this visual as encapsulating\na distinction between two cultures in statistics. The divide, he argues is\nabout what happens in the \"black box.\" In this comment, I argue for a broader\nperspective on statistics and, in doing so, elevate questions from \"before\" and\n\"after\" the box as fruitful areas for statistical innovation and practice.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 11:22:06 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["McCormick", "Tyler", ""]]}, {"id": "2105.12639", "submitter": "Namuk Park", "authors": "Namuk Park, Songkuk Kim", "title": "Blurs Make Results Clearer: Spatial Smoothings to Improve Accuracy,\n  Uncertainty, and Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian neural networks (BNNs) have shown success in the areas of\nuncertainty estimation and robustness. However, a crucial challenge prohibits\ntheir use in practice: Bayesian NNs require a large number of predictions to\nproduce reliable results, leading to a significant increase in computational\ncost. To alleviate this issue, we propose spatial smoothing, a method that\nensembles neighboring feature map points of CNNs. By simply adding a few blur\nlayers to the models, we empirically show that the spatial smoothing improves\naccuracy, uncertainty estimation, and robustness of BNNs across a whole range\nof ensemble sizes. In particular, BNNs incorporating the spatial smoothing\nachieve high predictive performance merely with a handful of ensembles.\nMoreover, this method also can be applied to canonical deterministic neural\nnetworks to improve the performances. A number of evidences suggest that the\nimprovements can be attributed to the smoothing and flattening of the loss\nlandscape. In addition, we provide a fundamental explanation for prior works -\nnamely, global average pooling, pre-activation, and ReLU6 - by addressing to\nthem as special cases of the spatial smoothing. These not only enhance\naccuracy, but also improve uncertainty estimation and robustness by making the\nloss landscape smoother in the same manner as the spatial smoothing. The code\nis available at https://github.com/xxxnell/spatial-smoothing.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 15:58:11 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Park", "Namuk", ""], ["Kim", "Songkuk", ""]]}, {"id": "2105.12769", "submitter": "Alexander Jung", "authors": "Yasmin SarcheshmehPour, Yu Tian, Linli Zhang, Alexander Jung", "title": "Networked Federated Multi-Task Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many important application domains generate distributed collections of\nheterogeneous local datasets. These local datasets are often related via an\nintrinsic network structure that arises from domain-specific notions of\nsimilarity between local datasets. Different notions of similarity are induced\nby spatiotemporal proximity, statistical dependencies, or functional relations.\nWe use this network structure to adaptively pool similar local datasets into\nnearly homogenous training sets for learning tailored models. Our main\nconceptual contribution is to formulate networked federated learning using the\nconcept of generalized total variation (GTV) minimization as a regularizer.\nThis formulation is highly flexible and can be combined with almost any\nparametric model including Lasso or deep neural networks. We unify and\nconsiderably extend some well-known approaches to federated multi-task\nlearning. Our main algorithmic contribution is a novel federated learning\nalgorithm that is well suited for distributed computing environments such as\nedge computing over wireless networks. This algorithm is robust against model\nmisspecification and numerical errors arising from limited computational\nresources including processing time or wireless channel bandwidth. As our main\ntechnical contribution, we offer precise conditions on the local models as well\non their network structure such that our algorithm learns nearly optimal local\nmodels. Our analysis reveals an interesting interplay between the\n(information-) geometry of local models and the (cluster-) geometry of their\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 18:07:19 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["SarcheshmehPour", "Yasmin", ""], ["Tian", "Yu", ""], ["Zhang", "Linli", ""], ["Jung", "Alexander", ""]]}, {"id": "2105.12778", "submitter": "George Wynne", "authors": "George Wynne and Stanislav Nagy", "title": "Statistical Depth Meets Machine Learning: Kernel Mean Embeddings and\n  Depth in Functional Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Statistical depth is the act of gauging how representative a point is\ncompared to a reference probability measure. The depth allows introducing\nrankings and orderings to data living in multivariate, or function spaces.\nThough widely applied and with much experimental success, little theoretical\nprogress has been made in analysing functional depths. This article highlights\nhow the common $h$-depth and related statistical depths for functional data can\nbe viewed as a kernel mean embedding, a technique used widely in statistical\nmachine learning. This connection facilitates answers to open questions\nregarding statistical properties of functional depths, as well as it provides a\nlink between the depth and empirical characteristic function based procedures\nfor functional data.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 18:22:33 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Wynne", "George", ""], ["Nagy", "Stanislav", ""]]}, {"id": "2105.12806", "submitter": "Mark Sellke", "authors": "S\\'ebastien Bubeck, Mark Sellke", "title": "A Universal Law of Robustness via Isoperimetry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classically, data interpolation with a parametrized model class is possible\nas long as the number of parameters is larger than the number of equations to\nbe satisfied. A puzzling phenomenon in deep learning is that models are trained\nwith many more parameters than what this classical theory would suggest. We\npropose a theoretical explanation for this phenomenon. We prove that for a\nbroad class of data distributions and model classes, overparametrization is\nnecessary if one wants to interpolate the data smoothly. Namely we show that\nsmooth interpolation requires $d$ times more parameters than mere\ninterpolation, where $d$ is the ambient data dimension. We prove this universal\nlaw of robustness for any smoothly parametrized function class with polynomial\nsize weights, and any covariate distribution verifying isoperimetry. In the\ncase of two-layers neural networks and Gaussian covariates, this law was\nconjectured in prior work by Bubeck, Li and Nagaraj. We also give an\ninterpretation of our result as an improved generalization bound for model\nclasses consisting of smooth functions.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 19:49:47 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 21:10:50 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Bubeck", "S\u00e9bastien", ""], ["Sellke", "Mark", ""]]}, {"id": "2105.12837", "submitter": "Hubert Baniecki", "authors": "Hubert Baniecki, Wojciech Kretowicz, Przemyslaw Biecek", "title": "Fooling Partial Dependence via Data Poisoning", "comments": "Code for this work is available at\n  https://github.com/MI2DataLab/fooling-partial-dependence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many methods have been developed to understand complex predictive models and\nhigh expectations are placed on post-hoc model explainability. It turns out\nthat such explanations are not robust nor trustworthy, and they can be fooled.\nThis paper presents techniques for attacking Partial Dependence (plots,\nprofiles, PDP), which are among the most popular methods of explaining any\npredictive model trained on tabular data. We showcase that PD can be\nmanipulated in an adversarial manner, which is alarming, especially in\nfinancial or medical applications where auditability became a must-have trait\nsupporting black-box models. The fooling is performed via poisoning the data to\nbend and shift explanations in the desired direction using genetic and gradient\nalgorithms. To the best of our knowledge, this is the first work performing\nattacks on variable dependence explanations. The novel approach of using a\ngenetic algorithm for doing so is highly transferable as it generalizes both\nways: in a model-agnostic and an explanation-agnostic manner.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 20:58:04 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 17:10:23 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Baniecki", "Hubert", ""], ["Kretowicz", "Wojciech", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "2105.12866", "submitter": "Xiaoliang Wan", "authors": "Xiaoliang Wan and Kejun Tang", "title": "Augmented KRnet for density estimation and approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we have proposed augmented KRnets including both discrete and\ncontinuous models. One difficulty in flow-based generative modeling is to\nmaintain the invertibility of the transport map, which is often a trade-off\nbetween effectiveness and robustness. The exact invertibility has been achieved\nin the real NVP using a specific pattern to exchange information between two\nseparated groups of dimensions. KRnet has been developed to enhance the\ninformation exchange among data dimensions by incorporating the\nKnothe-Rosenblatt rearrangement into the structure of the transport map. Due to\nthe maintenance of exact invertibility, a full nonlinear update of all data\ndimensions needs three iterations in KRnet. To alleviate this issue, we will\nadd augmented dimensions that act as a channel for communications among the\ndata dimensions. In the augmented KRnet, a fully nonlinear update is achieved\nin two iterations. We also show that the augmented KRnet can be reformulated as\nthe discretization of a neural ODE, where the exact invertibility is kept such\nthat the adjoint method can be formulated with respect to the discretized ODE\nto obtain the exact gradient. Numerical experiments have been implemented to\ndemonstrate the effectiveness of our models.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 22:20:16 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 00:08:27 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Wan", "Xiaoliang", ""], ["Tang", "Kejun", ""]]}, {"id": "2105.12894", "submitter": "Chaofan Huang", "authors": "Chaofan Huang, Simin Ma, Shihao Yang", "title": "MAGI-X: Manifold-Constrained Gaussian Process Inference for Unknown\n  System Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinary differential equations (ODEs), commonly used to characterize the\ndynamic systems, are difficult to propose in closed-form for many complicated\nscientific applications, even with the help of domain expert. We propose a fast\nand accurate data-driven method, MAGI-X, to learn the unknown dynamic from the\nobservation data in a non-parametric fashion, without the need of any domain\nknowledge. Unlike the existing methods that mainly rely on the costly numerical\nintegration, MAGI-X utilizes the powerful functional approximator of neural\nnetwork to learn the unknown nonlinear dynamic within the MAnifold-constrained\nGaussian process Inference (MAGI) framework that completely circumvents the\nnumerical integration. Comparing against the state-of-the-art methods on three\nrealistic examples, MAGI-X achieves competitive accuracy in both fitting and\nforecasting while only taking a fraction of computational time. Moreover,\nMAGI-X provides practical solution for the inference of partial observed\nsystems, which no previous method is able to handle.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 01:01:40 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 03:28:33 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Huang", "Chaofan", ""], ["Ma", "Simin", ""], ["Yang", "Shihao", ""]]}, {"id": "2105.12898", "submitter": "Duong Dung", "authors": "Tri Dung Duong, Qian Li, Guandong Xu", "title": "Stochastic Intervention for Causal Effect Estimation", "comments": "Accepted in IJCNN 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal inference methods are widely applied in various decision-making\ndomains such as precision medicine, optimal policy and economics. Central to\nthese applications is the treatment effect estimation of intervention\nstrategies. Current estimation methods are mostly restricted to the\ndeterministic treatment, which however, is unable to address the stochastic\nspace treatment policies. Moreover, previous methods can only make binary\nyes-or-no decisions based on the treatment effect, lacking the capability of\nproviding fine-grained effect estimation degree to explain the process of\ndecision making. In our study, we therefore advance the causal inference\nresearch to estimate stochastic intervention effect by devising a new\nstochastic propensity score and stochastic intervention effect estimator (SIE).\nMeanwhile, we design a customized genetic algorithm specific to stochastic\nintervention effect (Ge-SIO) with the aim of providing causal evidence for\ndecision making. We provide the theoretical analysis and conduct an empirical\nstudy to justify that our proposed measures and algorithms can achieve a\nsignificant performance lift in comparison with state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 01:12:03 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Duong", "Tri Dung", ""], ["Li", "Qian", ""], ["Xu", "Guandong", ""]]}, {"id": "2105.12909", "submitter": "Shahine Bouabid", "authors": "Siu Lun Chau, Shahine Bouabid, Dino Sejdinovic", "title": "Deconditional Downscaling with Gaussian Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Refining low-resolution (LR) spatial fields with high-resolution (HR)\ninformation is challenging as the diversity of spatial datasets often prevents\ndirect matching of observations. Yet, when LR samples are modeled as aggregate\nconditional means of HR samples with respect to a mediating variable that is\nglobally observed, the recovery of the underlying fine-grained field can be\nframed as taking an \"inverse\" of the conditional expectation, namely a\ndeconditioning problem. In this work, we introduce conditional mean processes\n(CMP), a new class of Gaussian Processes describing conditional means. By\ntreating CMPs as inter-domain features of the underlying field, a posterior for\nthe latent field can be established as a solution to the deconditioning\nproblem. Furthermore, we show that this solution can be viewed as a two-staged\nvector-valued kernel ridge regressor and show that it has a minimax optimal\nconvergence rate under mild assumptions. Lastly, we demonstrate its proficiency\nin a synthetic and a real-world atmospheric field downscaling problem, showing\nsubstantial improvements over existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 02:10:22 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 19:32:40 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chau", "Siu Lun", ""], ["Bouabid", "Shahine", ""], ["Sejdinovic", "Dino", ""]]}, {"id": "2105.12916", "submitter": "Hubert Banville", "authors": "Hubert Banville, Sean U.N. Wood, Chris Aimone, Denis-Alexander\n  Engemann and Alexandre Gramfort", "title": "Robust learning from corrupted EEG with dynamic spatial filtering", "comments": "42 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP q-bio.NC q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building machine learning models using EEG recorded outside of the laboratory\nsetting requires methods robust to noisy data and randomly missing channels.\nThis need is particularly great when working with sparse EEG montages (1-6\nchannels), often encountered in consumer-grade or mobile EEG devices. Neither\nclassical machine learning models nor deep neural networks trained end-to-end\non EEG are typically designed or tested for robustness to corruption, and\nespecially to randomly missing channels. While some studies have proposed\nstrategies for using data with missing channels, these approaches are not\npractical when sparse montages are used and computing power is limited (e.g.,\nwearables, cell phones). To tackle this problem, we propose dynamic spatial\nfiltering (DSF), a multi-head attention module that can be plugged in before\nthe first layer of a neural network to handle missing EEG channels by learning\nto focus on good channels and to ignore bad ones. We tested DSF on public EEG\ndata encompassing ~4,000 recordings with simulated channel corruption and on a\nprivate dataset of ~100 at-home recordings of mobile EEG with natural\ncorruption. Our proposed approach achieves the same performance as baseline\nmodels when no noise is applied, but outperforms baselines by as much as 29.4%\naccuracy when significant channel corruption is present. Moreover, DSF outputs\nare interpretable, making it possible to monitor channel importance in\nreal-time. This approach has the potential to enable the analysis of EEG in\nchallenging settings where channel corruption hampers the reading of brain\nsignals.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 02:33:16 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Banville", "Hubert", ""], ["Wood", "Sean U. N.", ""], ["Aimone", "Chris", ""], ["Engemann", "Denis-Alexander", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "2105.12937", "submitter": "Dong Li", "authors": "Ruoming Jin and Dong Li and Jing Gao and Zhi Liu and Li Chen and Yang\n  Zhou", "title": "Towards a Better Understanding of Linear Models for Recommendation", "comments": null, "journal-ref": null, "doi": "10.1145/3447548.3467428", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, linear regression models, such as EASE and SLIM, have shown to\noften produce rather competitive results against more sophisticated deep\nlearning models. On the other side, the (weighted) matrix factorization\napproaches have been popular choices for recommendation in the past and widely\nadopted in the industry. In this work, we aim to theoretically understand the\nrelationship between these two approaches, which are the cornerstones of\nmodel-based recommendations. Through the derivation and analysis of the\nclosed-form solutions for two basic regression and matrix factorization\napproaches, we found these two approaches are indeed inherently related but\nalso diverge in how they \"scale-down\" the singular values of the original\nuser-item interaction matrix. This analysis also helps resolve the questions\nrelated to the regularization parameter range and model complexities. We\nfurther introduce a new learning algorithm in searching (hyper)parameters for\nthe closed-form solution and utilize it to discover the nearby models of the\nexisting solutions. The experimental results demonstrate that the basic models\nand their closed-form solutions are indeed quite competitive against the\nstate-of-the-art models, thus, confirming the validity of studying the basic\nmodels. The effectiveness of exploring the nearby models are also\nexperimentally validated.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 04:17:04 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 03:38:09 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Jin", "Ruoming", ""], ["Li", "Dong", ""], ["Gao", "Jing", ""], ["Liu", "Zhi", ""], ["Chen", "Li", ""], ["Zhou", "Yang", ""]]}, {"id": "2105.12941", "submitter": "Jilei Yang", "authors": "Jilei Yang, Diana Negoescu, Parvez Ahammad", "title": "Intellige: A User-Facing Model Explainer for Narrative Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predictive machine learning models often lack interpretability, resulting in\nlow trust from model end users despite having high predictive performance.\nWhile many model interpretation approaches return top important features to\nhelp interpret model predictions, these top features may not be well-organized\nor intuitive to end users, which limits model adoption rates. In this paper, we\npropose Intellige, a user-facing model explainer that creates user-digestible\ninterpretations and insights reflecting the rationale behind model predictions.\nIntellige builds an end-to-end pipeline from machine learning platforms to end\nuser platforms, and provides users with an interface for implementing model\ninterpretation approaches and for customizing narrative insights. Intellige is\na platform consisting of four components: Model Importer, Model Interpreter,\nNarrative Generator, and Narrative Exporter. We describe these components, and\nthen demonstrate the effectiveness of Intellige through use cases at LinkedIn.\nQuantitative performance analyses indicate that Intellige's narrative insights\nlead to lifts in adoption rates of predictive model recommendations, as well as\nto increases in downstream key metrics such as revenue when compared to\nprevious approaches, while qualitative analyses indicate positive feedback from\nend users.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 05:11:47 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Yang", "Jilei", ""], ["Negoescu", "Diana", ""], ["Ahammad", "Parvez", ""]]}, {"id": "2105.12978", "submitter": "Antoine Barrier", "authors": "Antoine Barrier (UMPA-ENSL, LMO), Aur\\'elien Garivier (UMPA-ENSL),\n  Tom\\'a\\v{s} Koc\\'ak (UMPA-ENSL)", "title": "A Non-asymptotic Approach to Best-Arm Identification for Gaussian\n  Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new strategy for best-arm identification with fixed confidence\nof Gaussian variables with bounded means and unit variance. This strategy\ncalled Exploration-Biased Sampling is not only asymptotically optimal: we also\nprove non-asymptotic bounds occurring with high probability. To the best of our\nknowledge, this is the first strategy with such guarantees. But the main\nadvantage over other algorithms like Track-and-Stop is an improved behavior\nregarding exploration: Exploration-Biased Sampling is slightly biased in favor\nof exploration in a subtle but natural way that makes it more stable and\ninterpretable. These improvements are allowed by a new analysis of the sample\ncomplexity optimization problem, which yields a faster numerical resolution\nscheme and several quantitative regularity results that we believe of high\nindependent interest.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 07:42:49 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Barrier", "Antoine", "", "UMPA-ENSL, LMO"], ["Garivier", "Aur\u00e9lien", "", "UMPA-ENSL"], ["Koc\u00e1k", "Tom\u00e1\u0161", "", "UMPA-ENSL"]]}, {"id": "2105.13010", "submitter": "Yunfei Yang", "authors": "Jian Huang, Yuling Jiao, Zhen Li, Shiao Liu, Yang Wang, Yunfei Yang", "title": "An error analysis of generative adversarial networks for learning\n  distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies how well generative adversarial networks (GANs) learn\nprobability distributions from finite samples. Our main results establish the\nconvergence rates of GANs under a collection of integral probability metrics\ndefined through H\\\"older classes, including the Wasserstein distance as a\nspecial case. We also show that GANs are able to adaptively learn data\ndistributions with low-dimensional structures or have H\\\"older densities, when\nthe network architectures are chosen properly. In particular, for distributions\nconcentrated around a low-dimensional set, we show that the learning rates of\nGANs do not depend on the high ambient dimension, but on the lower intrinsic\ndimension. Our analysis is based on a new oracle inequality decomposing the\nestimation error into the generator and discriminator approximation error and\nthe statistical error, which may be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 08:55:19 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 07:28:00 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 02:19:06 GMT"}, {"version": "v4", "created": "Thu, 1 Jul 2021 03:03:30 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Huang", "Jian", ""], ["Jiao", "Yuling", ""], ["Li", "Zhen", ""], ["Liu", "Shiao", ""], ["Wang", "Yang", ""], ["Yang", "Yunfei", ""]]}, {"id": "2105.13011", "submitter": "Subhayan De", "authors": "Subhayan De and Alireza Doostan", "title": "Neural Network Training Using $\\ell_1$-Regularization and Bi-fidelity\n  Data", "comments": "28 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the capability of accurately representing a functional relationship\nbetween the inputs of a physical system's model and output quantities of\ninterest, neural networks have become popular for surrogate modeling in\nscientific applications. However, as these networks are over-parameterized,\ntheir training often requires a large amount of data. To prevent overfitting\nand improve generalization error, regularization based on, e.g., $\\ell_1$- and\n$\\ell_2$-norms of the parameters is applied. Similarly, multiple connections of\nthe network may be pruned to increase sparsity in the network parameters. In\nthis paper, we explore the effects of sparsity promoting\n$\\ell_1$-regularization on training neural networks when only a small training\ndataset from a high-fidelity model is available. As opposed to standard\n$\\ell_1$-regularization that is known to be inadequate, we consider two\nvariants of $\\ell_1$-regularization informed by the parameters of an identical\nnetwork trained using data from lower-fidelity models of the problem at hand.\nThese bi-fidelity strategies are generalizations of transfer learning of neural\nnetworks that uses the parameters learned from a large low-fidelity dataset to\nefficiently train networks for a small high-fidelity dataset. We also compare\nthe bi-fidelity strategies with two $\\ell_1$-regularization methods that only\nuse the high-fidelity dataset. Three numerical examples for propagating\nuncertainty through physical systems are used to show that the proposed\nbi-fidelity $\\ell_1$-regularization strategies produce errors that are one\norder of magnitude smaller than those of networks trained only using datasets\nfrom the high-fidelity models.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 08:56:17 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 19:54:39 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["De", "Subhayan", ""], ["Doostan", "Alireza", ""]]}, {"id": "2105.13052", "submitter": "Nicolas Boull\\'e", "authors": "Nicolas Boull\\'e, Alex Townsend", "title": "A generalization of the randomized singular value decomposition", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The randomized singular value decomposition (SVD) is a popular and effective\nalgorithm for computing a near-best rank $k$ approximation of a matrix $A$\nusing matrix-vector products with standard Gaussian vectors. Here, we\ngeneralize the theory of randomized SVD to multivariable Gaussian vectors,\nallowing one to incorporate prior knowledge of $A$ into the algorithm. This\nenables us to explore the continuous analogue of the randomized SVD for\nHilbert--Schmidt (HS) operators using operator-function products with functions\ndrawn from a Gaussian process (GP). We then construct a new covariance kernel\nfor GPs, based on weighted Jacobi polynomials, which allows us to rapidly\nsample the GP and control the smoothness of the randomly generated functions.\nNumerical examples on matrices and HS operators demonstrate the applicability\nof the algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 10:39:37 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Boull\u00e9", "Nicolas", ""], ["Townsend", "Alex", ""]]}, {"id": "2105.13059", "submitter": "Jeremie Coullon", "authors": "Jeremie Coullon, Leah South, Christopher Nemeth", "title": "Stochastic Gradient MCMC with Multi-Armed Bandit Tuning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic gradient Markov chain Monte Carlo (SGMCMC) is a popular class of\nalgorithms for scalable Bayesian inference. However, these algorithms include\nhyperparameters such as step size or batch size that influence the accuracy of\nestimators based on the obtained samples. As a result, these hyperparameters\nmust be tuned by the practitioner and currently no principled and automated way\nto tune them exists. Standard MCMC tuning methods based on acceptance rates\ncannot be used for SGMCMC, thus requiring alternative tools and diagnostics. We\npropose a novel bandit-based algorithm that tunes SGMCMC hyperparameters to\nmaximize the accuracy of the posterior approximation by minimizing the kernel\nStein discrepancy (KSD). We provide theoretical results supporting this\napproach and assess alternative metrics to KSD. We support our results with\nexperiments on both simulated and real datasets, and find that this method is\npractical for a wide range of application areas.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 11:00:31 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 13:49:38 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Coullon", "Jeremie", ""], ["South", "Leah", ""], ["Nemeth", "Christopher", ""]]}, {"id": "2105.13093", "submitter": "Mary Phuong", "authors": "Mary Phuong, Christoph H. Lampert", "title": "Towards Understanding Knowledge Distillation", "comments": "ICML'19. Post-edited to add related work. arXiv admin note: text\n  overlap with arXiv:2003.13438 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge distillation, i.e., one classifier being trained on the outputs of\nanother classifier, is an empirically very successful technique for knowledge\ntransfer between classifiers. It has even been observed that classifiers learn\nmuch faster and more reliably if trained with the outputs of another classifier\nas soft labels, instead of from ground truth data. So far, however, there is no\nsatisfactory theoretical explanation of this phenomenon. In this work, we\nprovide the first insights into the working mechanisms of distillation by\nstudying the special case of linear and deep linear classifiers. Specifically,\nwe prove a generalization bound that establishes fast convergence of the\nexpected risk of a distillation-trained linear classifier. From the bound and\nits proof we extract three key factors that determine the success of\ndistillation: * data geometry -- geometric properties of the data distribution,\nin particular class separation, has a direct influence on the convergence speed\nof the risk; * optimization bias -- gradient descent optimization finds a very\nfavorable minimum of the distillation objective; and * strong monotonicity --\nthe expected risk of the student classifier always decreases when the size of\nthe training set grows.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 12:45:08 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Phuong", "Mary", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "2105.13099", "submitter": "Nicolas Keriven", "authors": "Nicolas Keriven, Alberto Bietti, Samuel Vaiter", "title": "On the Universality of Graph Neural Networks on Large Random Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximation power of Graph Neural Networks (GNNs) on latent\nposition random graphs. In the large graph limit, GNNs are known to converge to\ncertain \"continuous\" models known as c-GNNs, which directly enables a study of\ntheir approximation power on random graph models. In the absence of input node\nfeatures however, just as GNNs are limited by the Weisfeiler-Lehman isomorphism\ntest, c-GNNs will be severely limited on simple random graph models. For\ninstance, they will fail to distinguish the communities of a well-separated\nStochastic Block Model (SBM) with constant degree function. Thus, we consider\nrecently proposed architectures that augment GNNs with unique node identifiers,\nreferred to as Structural GNNs here (SGNNs). We study the convergence of SGNNs\nto their continuous counterpart (c-SGNNs) in the large random graph limit,\nunder new conditions on the node identifiers. We then show that c-SGNNs are\nstrictly more powerful than c-GNNs in the continuous limit, and prove their\nuniversality on several random graph models of interest, including most SBMs\nand a large class of random geometric graphs. Our results cover both\npermutation-invariant and permutation-equivariant architectures.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 12:52:36 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 20:23:31 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Keriven", "Nicolas", ""], ["Bietti", "Alberto", ""], ["Vaiter", "Samuel", ""]]}, {"id": "2105.13189", "submitter": "Zhiyong Zhou", "authors": "Zhiyong Zhou", "title": "Sparse recovery based on the generalized error function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a novel sparse recovery method based on the\ngeneralized error function. The penalty function introduced involves both the\nshape and the scale parameters, making it very flexible. The theoretical\nanalysis results in terms of the null space property, the spherical section\nproperty and the restricted invertibility factor are established for both\nconstrained and unconstrained models. The practical algorithms via both the\niteratively reweighted $\\ell_1$ and the difference of convex functions\nalgorithms are presented. Numerical experiments are conducted to illustrate the\nimprovement provided by the proposed approach in various scenarios. Its\npractical application in magnetic resonance imaging (MRI) reconstruction is\nstudied as well.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 11:36:01 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 01:57:48 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zhou", "Zhiyong", ""]]}, {"id": "2105.13245", "submitter": "Juan Ungredda", "authors": "Juan Ungredda and Juergen Branke", "title": "Bayesian Optimisation for Constrained Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world optimisation problems such as hyperparameter tuning in\nmachine learning or simulation-based optimisation can be formulated as\nexpensive-to-evaluate black-box functions. A popular approach to tackle such\nproblems is Bayesian optimisation (BO), which builds a response surface model\nbased on the data collected so far, and uses the mean and uncertainty predicted\nby the model to decide what information to collect next. In this paper, we\npropose a novel variant of the well-known Knowledge Gradient acquisition\nfunction that allows it to handle constraints. We empirically compare the new\nalgorithm with four other state-of-the-art constrained Bayesian optimisation\nalgorithms and demonstrate its superior performance. We also prove theoretical\nconvergence in the infinite budget limit.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 15:43:09 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Ungredda", "Juan", ""], ["Branke", "Juergen", ""]]}, {"id": "2105.13251", "submitter": "T. Mitchell Roddenberry", "authors": "T. Mitchell Roddenberry, Yu Zhu, Santiago Segarra", "title": "An Impossibility Theorem for Node Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing popularity of graph-based methods for dimensionality\nreduction and representation learning, node embedding functions have become\nimportant objects of study in the literature. In this paper, we take an\naxiomatic approach to understanding node embedding methods, first stating three\nproperties for embedding dissimilarity networks, then proving that all three\ncannot be satisfied simultaneously by any node embedding method. Similar to\nexisting results on the impossibility of clustering under certain axiomatic\nassumptions, this points to fundamental difficulties inherent to node embedding\ntasks. Once these difficulties are identified, we then relax these axioms to\nallow for certain node embedding methods to be admissible in our framework.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 15:48:41 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Roddenberry", "T. Mitchell", ""], ["Zhu", "Yu", ""], ["Segarra", "Santiago", ""]]}, {"id": "2105.13283", "submitter": "Lara Hoffmann", "authors": "Lara Hoffmann and Clemens Elster", "title": "Deep Ensembles from a Bayesian Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep ensembles can be seen as the current state-of-the-art for uncertainty\nquantification in deep learning. While the approach was originally proposed as\nan non-Bayesian technique, arguments towards its Bayesian footing have been put\nforward as well. We show that deep ensembles can be viewed as an approximate\nBayesian method by specifying the corresponding assumptions. Our finding leads\nto an improved approximation which results in an increased epistemic part of\nthe uncertainty. Numerical examples suggest that the improved approximation can\nlead to more reliable uncertainties. Analytical derivations ensure easy\ncalculation of results.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 16:30:52 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Hoffmann", "Lara", ""], ["Elster", "Clemens", ""]]}, {"id": "2105.13302", "submitter": "Zhiqi Bu", "authors": "Zhiqi Bu, Jason Klusowski, Cynthia Rush, Weijie J. Su", "title": "Characterizing the SLOPE Trade-off: A Variational Perspective and the\n  Donoho-Tanner Limit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG eess.SP math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sorted l1 regularization has been incorporated into many methods for solving\nhigh-dimensional statistical estimation problems, including the SLOPE estimator\nin linear regression. In this paper, we study how this relatively new\nregularization technique improves variable selection by characterizing the\noptimal SLOPE trade-off between the false discovery proportion (FDP) and true\npositive proportion (TPP) or, equivalently, between measures of type I error\nand power. Assuming a regime of linear sparsity and working under Gaussian\nrandom designs, we obtain an upper bound on the optimal trade-off for SLOPE,\nshowing its capability of breaking the Donoho-Tanner power limit. To put it\ninto perspective, this limit is the highest possible power that the Lasso,\nwhich is perhaps the most popular l1-based method, can achieve even with\narbitrarily strong effect sizes. Next, we derive a tight lower bound that\ndelineates the fundamental limit of sorted l1 regularization in optimally\ntrading the FDP off for the TPP. Finally, we show that on any problem instance,\nSLOPE with a certain regularization sequence outperforms the Lasso, in the\nsense of having a smaller FDP, larger TPP and smaller l2 estimation risk\nsimultaneously. Our proofs are based on a novel technique that reduces a\nvariational calculus problem to a class of infinite-dimensional convex\noptimization problems and a very recent result from approximate message passing\ntheory.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 16:56:42 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Bu", "Zhiqi", ""], ["Klusowski", "Jason", ""], ["Rush", "Cynthia", ""], ["Su", "Weijie J.", ""]]}, {"id": "2105.13420", "submitter": "Zhenwen Dai", "authors": "Zhenwen Dai, Praveen Chandar, Ghazal Fazelnia, Ben Carterette, Mounia\n  Lalmas-Roelleke", "title": "Model Selection for Production System via Automated Online Experiments", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A challenge that machine learning practitioners in the industry face is the\ntask of selecting the best model to deploy in production. As a model is often\nan intermediate component of a production system, online controlled experiments\nsuch as A/B tests yield the most reliable estimation of the effectiveness of\nthe whole system, but can only compare two or a few models due to budget\nconstraints. We propose an automated online experimentation mechanism that can\nefficiently perform model selection from a large pool of models with a small\nnumber of online experiments. We derive the probability distribution of the\nmetric of interest that contains the model uncertainty from our Bayesian\nsurrogate model trained using historical logs. Our method efficiently\nidentifies the best model by sequentially selecting and deploying a list of\nmodels from the candidate set that balance exploration-exploitation. Using\nsimulations based on real data, we demonstrate the effectiveness of our method\non two different tasks.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 19:48:23 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Dai", "Zhenwen", ""], ["Chandar", "Praveen", ""], ["Fazelnia", "Ghazal", ""], ["Carterette", "Ben", ""], ["Lalmas-Roelleke", "Mounia", ""]]}, {"id": "2105.13440", "submitter": "Peter Carbonetto", "authors": "Peter Carbonetto, Abhishek Sarkar, Zihao Wang and Matthew Stephens", "title": "Non-negative matrix factorization algorithms greatly improve topic model\n  fits", "comments": "Submitted to Advances in Neural Information Processing Systems 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We report on the potential for using algorithms for non-negative matrix\nfactorization (NMF) to improve parameter estimation in topic models. While\nseveral papers have studied connections between NMF and topic models, none have\nsuggested leveraging these connections to develop new algorithms for fitting\ntopic models. Importantly, NMF avoids the \"sum-to-one\" constraints on the topic\nmodel parameters, resulting in an optimization problem with simpler structure\nand more efficient computations. Building on recent advances in optimization\nalgorithms for NMF, we show that first solving the NMF problem then recovering\nthe topic model fit can produce remarkably better fits, and in less time, than\nstandard algorithms for topic models. While we focus primarily on maximum\nlikelihood estimation, we show that this approach also has the potential to\nimprove variational inference for topic models. Our methods are implemented in\nthe R package fastTopics.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 20:34:46 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Carbonetto", "Peter", ""], ["Sarkar", "Abhishek", ""], ["Wang", "Zihao", ""], ["Stephens", "Matthew", ""]]}, {"id": "2105.13483", "submitter": "Matteo Guardiani", "authors": "Matteo Guardiani, Philipp Frank, Andrija Kosti\\'c, Gordian Edenhofer,\n  Jakob Roth, Berit Uhlmann, Torsten En{\\ss}lin", "title": "Non-parametric Bayesian Causal Modeling of the SARS-CoV-2 Viral Load\n  Distribution vs. Patient's Age", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The viral load of patients infected with SARS-CoV-2 varies on logarithmic\nscales and possibly with age. Controversial claims have been made in the\nliterature regarding whether the viral load distribution actually depends on\nthe age of the patients. Such a dependence would have implications for the\nCOVID-19 spreading mechanism, the age-dependent immune system reaction, and\nthus for policymaking. We hereby develop a method to analyze viral-load\ndistribution data as a function of the patients' age within a flexible,\nnon-parametric, hierarchical, Bayesian, and causal model. This method can be\napplied to other contexts as well, and for this purpose, it is made freely\navailable. The developed reconstruction method also allows testing for bias in\nthe data. This could be due to, e.g., bias in patient-testing and data\ncollection or systematic errors in the measurement of the viral load. We\nperform these tests by calculating the Bayesian evidence for each implied\npossible causal direction. When applying these tests to publicly available age\nand SARS-CoV-2 viral load data, we find a statistically significant increase in\nthe viral load with age, but only for one of the two analyzed datasets. If we\nconsider this dataset, and based on the current understanding of viral load's\nimpact on patients' infectivity, we expect a non-negligible difference in the\ninfectivity of different age groups. This difference is nonetheless too small\nto justify considering any age group as noninfectious.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 22:35:02 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Guardiani", "Matteo", ""], ["Frank", "Philipp", ""], ["Kosti\u0107", "Andrija", ""], ["Edenhofer", "Gordian", ""], ["Roth", "Jakob", ""], ["Uhlmann", "Berit", ""], ["En\u00dflin", "Torsten", ""]]}, {"id": "2105.13493", "submitter": "Patrick Kidger", "authors": "Patrick Kidger and James Foster and Xuechen Li and Terry Lyons", "title": "Efficient and Accurate Gradients for Neural SDEs", "comments": "Submitted to NeurIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural SDEs combine many of the best qualities of both RNNs and SDEs: memory\nefficient training, high-capacity function approximation, and strong priors on\nmodel space. This makes them a natural choice for modelling many types of\ntemporal dynamics. Training a Neural SDE (either as a VAE or as a GAN) requires\nbackpropagating through an SDE solve. This may be done by solving a\nbackwards-in-time SDE whose solution is the desired parameter gradients.\nHowever, this has previously suffered from severe speed and accuracy issues,\ndue to high computational cost and numerical truncation errors. Here, we\novercome these issues through several technical innovations. First, we\nintroduce the \\textit{reversible Heun method}. This is a new SDE solver that is\n\\textit{algebraically reversible}: eliminating numerical gradient errors, and\nthe first such solver of which we are aware. Moreover it requires half as many\nfunction evaluations as comparable solvers, giving up to a $1.98\\times$\nspeedup. Second, we introduce the \\textit{Brownian Interval}: a new, fast,\nmemory efficient, and exact way of sampling \\textit{and reconstructing}\nBrownian motion. With this we obtain up to a $10.6\\times$ speed improvement\nover previous techniques, which in contrast are both approximate and relatively\nslow. Third, when specifically training Neural SDEs as GANs (Kidger et al.\n2021), we demonstrate how SDE-GANs may be trained through careful weight\nclipping and choice of activation function. This reduces computational cost\n(giving up to a $1.87\\times$ speedup) and removes the numerical truncation\nerrors associated with gradient penalty. Altogether, we outperform the\nstate-of-the-art by substantial margins, with respect to training speed, and\nwith respect to classification, prediction, and MMD test metrics. We have\ncontributed implementations of all of our techniques to the torchsde library to\nhelp facilitate their adoption.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 22:59:36 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 17:34:54 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Kidger", "Patrick", ""], ["Foster", "James", ""], ["Li", "Xuechen", ""], ["Lyons", "Terry", ""]]}, {"id": "2105.13504", "submitter": "Oscar Hernan Madrid Padilla", "authors": "Oscar Hernan Madrid Padilla, Yi Yu, Alessandro Rinaldo", "title": "Lattice partition recovery with dyadic CART", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study piece-wise constant signals corrupted by additive Gaussian noise\nover a $d$-dimensional lattice. Data of this form naturally arise in a host of\napplications, and the tasks of signal detection or testing, de-noising and\nestimation have been studied extensively in the statistical and signal\nprocessing literature. In this paper we consider instead the problem of\npartition recovery, i.e.~of estimating the partition of the lattice induced by\nthe constancy regions of the unknown signal, using the\ncomputationally-efficient dyadic classification and regression tree (DCART)\nmethodology proposed by \\citep{donoho1997cart}. We prove that, under\nappropriate regularity conditions on the shape of the partition elements, a\nDCART-based procedure consistently estimates the underlying partition at a rate\nof order $\\sigma^2 k^* \\log (N)/\\kappa^2$, where $k^*$ is the minimal number of\nrectangular sub-graphs obtained using recursive dyadic partitions supporting\nthe signal partition, $\\sigma^2$ is the noise variance, $\\kappa$ is the minimal\nmagnitude of the signal difference among contiguous elements of the partition\nand $N$ is the size of the lattice. Furthermore, under stronger assumptions,\nour method attains a sharper estimation error of order\n$\\sigma^2\\log(N)/\\kappa^2$, independent of $ k^*$, which we show to be minimax\nrate optimal. Our theoretical guarantees further extend to the partition\nestimator based on the optimal regression tree estimator (ORT) of\n\\cite{chatterjee2019adaptive} and to the one obtained through an NP-hard\nexhaustive search method. We corroborate our theoretical findings and the\neffectiveness of DCART for partition recovery in simulations.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 23:41:01 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Padilla", "Oscar Hernan Madrid", ""], ["Yu", "Yi", ""], ["Rinaldo", "Alessandro", ""]]}, {"id": "2105.13655", "submitter": "Dabeen Lee", "authors": "Dabeen Lee, Milan Vojnovic", "title": "Learning to Schedule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a learning and scheduling algorithm to minimize the\nexpected cumulative holding cost incurred by jobs, where statistical parameters\ndefining their individual holding costs are unknown a priori. In each time\nslot, the server can process a job while receiving the realized random holding\ncosts of the jobs remaining in the system. Our algorithm is a learning-based\nvariant of the $c\\mu$ rule for scheduling: it starts with a preemption period\nof fixed length which serves as a learning phase, and after accumulating enough\ndata about individual jobs, it switches to nonpreemptive scheduling mode. The\nalgorithm is designed to handle instances with large or small gaps in jobs'\nparameters and achieves near-optimal performance guarantees. The performance of\nour algorithm is captured by its regret, where the benchmark is the minimum\npossible cost attained when the statistical parameters of jobs are fully known.\nWe prove upper bounds on the regret of our algorithm, and we derive a regret\nlower bound that is almost matching the proposed upper bounds. Our numerical\nresults demonstrate the effectiveness of our algorithm and show that our\ntheoretical regret analysis is nearly tight.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 08:04:06 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Lee", "Dabeen", ""], ["Vojnovic", "Milan", ""]]}, {"id": "2105.13669", "submitter": "Bernt Ivar Utst{\\o}l N{\\o}dland", "authors": "Bernt Ivar Utst{\\o}l N{\\o}dland", "title": "Measuring global properties of neural generative model outputs via\n  generating mathematical objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train deep generative models on datasets of reflexive polytopes. This\nenables us to compare how well the models have picked up on various global\nproperties of generated samples. Our datasets are complete in the sense that\nevery single example, up to changes of coordinate, is included in the dataset.\nUsing this property we also perform tests checking to what extent the models\nare merely memorizing the data. We also train models on the same dataset\nrepresented in two different ways, enabling us to measure which form is easiest\nto learn from. We use these experiments to show that deep generative models can\nlearn to generate geometric objects with non-trivial global properties, and\nthat the models learn some underlying properties of the objects rather than\nsimply memorizing the data.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 08:38:18 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["N\u00f8dland", "Bernt Ivar Utst\u00f8l", ""]]}, {"id": "2105.13727", "submitter": "Kieran Wood", "authors": "Kieran Wood, Stephen Roberts, Stefan Zohren", "title": "Slow Momentum with Fast Reversion: A Trading Strategy Using Deep\n  Learning and Changepoint Detection", "comments": "minor corrections, strategy comparison for 2015-2020 made more robust\n  by repeated trials", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Momentum strategies are an important part of alternative investments and are\nat the heart of commodity trading advisors (CTAs). These strategies have\nhowever been found to have difficulties adjusting to rapid changes in market\nconditions, such as during the 2020 market crash. In particular, immediately\nafter momentum turning points, where a trend reverses from an uptrend\n(downtrend) to a downtrend (uptrend), time-series momentum (TSMOM) strategies\nare prone to making bad bets. To improve the response to regime change, we\nintroduce a novel approach, where we insert an online change-point detection\n(CPD) module into a Deep Momentum Network (DMN) [1904.04912] pipeline, which\nuses an LSTM deep-learning architecture to simultaneously learn both trend\nestimation and position sizing. Furthermore, our model is able to optimise the\nway in which it balances 1) a slow momentum strategy which exploits persisting\ntrends, but does not overreact to localised price moves, and 2) a fast\nmean-reversion strategy regime by quickly flipping its position, then swapping\nit back again to exploit localised price moves. Our CPD module outputs a\nchangepoint location and severity score, allowing our model to learn to respond\nto varying degrees of disequilibrium, or smaller and more localised\nchangepoints, in a data driven manner. Using a portfolio of 50, liquid,\ncontinuous futures contracts over the period 1990-2020, the addition of the CPD\nmodule leads to an improvement in Sharpe ratio of one-third. Even more notably,\nthis module is especially beneficial in periods of significant nonstationarity,\nand in particular, over the most recent years tested (2015-2020) the\nperformance boost is approximately two-thirds. This is especially interesting\nas traditional momentum strategies have been underperforming in this period.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 10:46:53 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 12:51:25 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Wood", "Kieran", ""], ["Roberts", "Stephen", ""], ["Zohren", "Stefan", ""]]}, {"id": "2105.13745", "submitter": "Yaowei Zheng", "authors": "Xiaohui Guo, Richong Zhang, Yaowei Zheng, Yongyi Mao", "title": "Robust Regularization with Adversarial Labelling of Perturbed Samples", "comments": "Accepted to IJCAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent researches have suggested that the predictive accuracy of neural\nnetwork may contend with its adversarial robustness. This presents challenges\nin designing effective regularization schemes that also provide strong\nadversarial robustness. Revisiting Vicinal Risk Minimization (VRM) as a\nunifying regularization principle, we propose Adversarial Labelling of\nPerturbed Samples (ALPS) as a regularization scheme that aims at improving the\ngeneralization ability and adversarial robustness of the trained model. ALPS\ntrains neural networks with synthetic samples formed by perturbing each\nauthentic input sample towards another one along with an adversarially assigned\nlabel. The ALPS regularization objective is formulated as a min-max problem, in\nwhich the outer problem is minimizing an upper-bound of the VRM loss, and the\ninner problem is L$_1$-ball constrained adversarial labelling on perturbed\nsample. The analytic solution to the induced inner maximization problem is\nelegantly derived, which enables computational efficiency. Experiments on the\nSVHN, CIFAR-10, CIFAR-100 and Tiny-ImageNet datasets show that the ALPS has a\nstate-of-the-art regularization performance while also serving as an effective\nadversarial training scheme.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 11:26:49 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Guo", "Xiaohui", ""], ["Zhang", "Richong", ""], ["Zheng", "Yaowei", ""], ["Mao", "Yongyi", ""]]}, {"id": "2105.13810", "submitter": "Benjamin Maschler", "authors": "Benjamin Lindemann, Benjamin Maschler, Nada Sahlab, and Michael\n  Weyrich", "title": "A Survey on Anomaly Detection for Technical Systems using LSTM Networks", "comments": "14 pages, 6 figures, 4 tables. Accepted for publication by Computers\n  in Industry", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Anomalies represent deviations from the intended system operation and can\nlead to decreased efficiency as well as partial or complete system failure. As\nthe causes of anomalies are often unknown due to complex system dynamics,\nefficient anomaly detection is necessary. Conventional detection approaches\nrely on statistical and time-invariant methods that fail to address the complex\nand dynamic nature of anomalies. With advances in artificial intelligence and\nincreasing importance for anomaly detection and prevention in various domains,\nartificial neural network approaches enable the detection of more complex\nanomaly types while considering temporal and contextual characteristics. In\nthis article, a survey on state-of-the-art anomaly detection using deep neural\nand especially long short-term memory networks is conducted. The investigated\napproaches are evaluated based on the application scenario, data and anomaly\ntypes as well as further metrics. To highlight the potential of upcoming\nanomaly detection techniques, graph-based and transfer learning approaches are\nalso included in the survey, enabling the analysis of heterogeneous data as\nwell as compensating for its shortage and improving the handling of dynamic\nprocesses.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 13:24:40 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Lindemann", "Benjamin", ""], ["Maschler", "Benjamin", ""], ["Sahlab", "Nada", ""], ["Weyrich", "Michael", ""]]}, {"id": "2105.13831", "submitter": "Fan Wu", "authors": "Fan Wu and Patrick Rebeschini", "title": "Implicit Regularization in Matrix Sensing via Mirror Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study discrete-time mirror descent applied to the unregularized empirical\nrisk in matrix sensing. In both the general case of rectangular matrices and\nthe particular case of positive semidefinite matrices, a simple potential-based\nanalysis in terms of the Bregman divergence allows us to establish convergence\nof mirror descent -- with different choices of the mirror maps -- to a matrix\nthat, among all global minimizers of the empirical risk, minimizes a quantity\nexplicitly related to the nuclear norm, the Frobenius norm, and the von Neumann\nentropy. In both cases, this characterization implies that mirror descent, a\nfirst-order algorithm minimizing the unregularized empirical risk, recovers\nlow-rank matrices under the same set of assumptions that are sufficient to\nguarantee recovery for nuclear-norm minimization. When the sensing matrices are\nsymmetric and commute, we show that gradient descent with full-rank factorized\nparametrization is a first-order approximation to mirror descent, in which case\nwe obtain an explicit characterization of the implicit bias of gradient flow as\na by-product.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 13:46:47 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Wu", "Fan", ""], ["Rebeschini", "Patrick", ""]]}, {"id": "2105.13841", "submitter": "Huiqi Deng", "authors": "Huiqi Deng, Na Zou, Mengnan Du, Weifu Chen, Guocan Feng, Xia Hu", "title": "A General Taylor Framework for Unifying and Revisiting Attribution\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribution methods provide an insight into the decision-making process of\nmachine learning models, especially deep neural networks, by assigning\ncontribution scores to each individual feature. However, the attribution\nproblem has not been well-defined, which lacks a unified guideline to the\ncontribution assignment process. Furthermore, existing attribution methods\noften built upon various empirical intuitions and heuristics. There still lacks\na general theoretical framework that not only can offer a good description of\nthe attribution problem, but also can be applied to unifying and revisiting\nexisting attribution methods. To bridge the gap, in this paper, we propose a\nTaylor attribution framework, which models the attribution problem as how to\ndecide individual payoffs in a coalition. Then, we reformulate fourteen\nmainstream attribution methods into the Taylor framework and analyze these\nattribution methods in terms of rationale, fidelity, and limitation in the\nframework. Moreover, we establish three principles for a good attribution in\nthe Taylor attribution framework, i.e., low approximation error, correct Taylor\ncontribution assignment, and unbiased baseline selection. Finally, we\nempirically validate the Taylor reformulations and reveal a positive\ncorrelation between the attribution performance and the number of principles\nfollowed by the attribution method via benchmarking on real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 13:57:16 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Deng", "Huiqi", ""], ["Zou", "Na", ""], ["Du", "Mengnan", ""], ["Chen", "Weifu", ""], ["Feng", "Guocan", ""], ["Hu", "Xia", ""]]}, {"id": "2105.13850", "submitter": "Michael Kirchhof", "authors": "Michael Kirchhof and Lena Schmid and Christopher Reining and Michael\n  ten Hompel and Markus Pauly", "title": "pRSL: Interpretable Multi-label Stacking by Learning Probabilistic Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A key task in multi-label classification is modeling the structure between\nthe involved classes. Modeling this structure by probabilistic and\ninterpretable means enables application in a broad variety of tasks such as\nzero-shot learning or learning from incomplete data. In this paper, we present\nthe probabilistic rule stacking learner (pRSL) which uses probabilistic\npropositional logic rules and belief propagation to combine the predictions of\nseveral underlying classifiers. We derive algorithms for exact and approximate\ninference and learning, and show that pRSL reaches state-of-the-art performance\non various benchmark datasets.\n  In the process, we introduce a novel multicategorical generalization of the\nnoisy-or gate. Additionally, we report simulation results on the quality of\nloopy belief propagation algorithms for approximate inference in bipartite\nnoisy-or networks.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 14:06:21 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Kirchhof", "Michael", ""], ["Schmid", "Lena", ""], ["Reining", "Christopher", ""], ["Hompel", "Michael ten", ""], ["Pauly", "Markus", ""]]}, {"id": "2105.13859", "submitter": "Vinicius Luiz Santos Silva", "authors": "Vinicius L. S. Silva, Claire E. Heaney, Christopher C. Pain", "title": "GAN for time series prediction, data assimilation and uncertainty\n  quantification", "comments": "arXiv admin note: text overlap with arXiv:2105.07729", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method in which a generative adversarial network (GAN) is\nused to quantify the uncertainty of forward simulations in the presence of\nobserved data. Previously, a method has been developed which enables GANs to\nmake time series predictions and data assimilation by training a GAN with\nunconditional simulations of a high-fidelity numerical model. After training,\nthe GAN can be used to predict the evolution of the spatial distribution of the\nsimulation states and observed data is assimilated. In this paper, we describe\nthe process required in order to quantify uncertainty, during which no\nadditional simulations of the high-fidelity numerical model are required. These\nmethods take advantage of the adjoint-like capabilities of generative models\nand the ability to simulate forwards and backwards in time. Set within a\nreduced-order model framework for efficiency, we apply these methods to a\ncompartmental model in epidemiology to predict the spread of COVID-19 in an\nidealised town. The results show that the proposed method can efficiently\nquantify uncertainty in the presence of measurements using only unconditional\nsimulations of the high-fidelity numerical model.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 14:12:45 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 15:05:18 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Silva", "Vinicius L. S.", ""], ["Heaney", "Claire E.", ""], ["Pain", "Christopher C.", ""]]}, {"id": "2105.13913", "submitter": "Mathieu Besan\\c{c}on", "authors": "Alejandro Carderera and Mathieu Besan\\c{c}on and Sebastian Pokutta", "title": "Simple steps are all you need: Frank-Wolfe and generalized\n  self-concordant functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized self-concordance is a key property present in the objective\nfunction of many important learning problems. We establish the convergence rate\nof a simple Frank-Wolfe variant that uses the open-loop step size strategy\n$\\gamma_t = 2/(t+2)$, obtaining a $\\mathcal{O}(1/t)$ convergence rate for this\nclass of functions in terms of primal gap and Frank-Wolfe gap, where $t$ is the\niteration count. This avoids the use of second-order information or the need to\nestimate local smoothness parameters of previous work. We also show improved\nconvergence rates for various common cases, e.g., when the feasible region\nunder consideration is uniformly convex or polyhedral.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 15:26:36 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 07:18:01 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Carderera", "Alejandro", ""], ["Besan\u00e7on", "Mathieu", ""], ["Pokutta", "Sebastian", ""]]}, {"id": "2105.13922", "submitter": "Mihaela Rosca", "authors": "Mihaela Rosca and Yan Wu and Benoit Dherin and David G. T. Barrett", "title": "Discretization Drift in Two-Player Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Gradient-based methods for two-player games produce rich dynamics that can\nsolve challenging problems, yet can be difficult to stabilize and understand.\nPart of this complexity originates from the discrete update steps given by\nsimultaneous or alternating gradient descent, which causes each player to drift\naway from the continuous gradient flow -- a phenomenon we call discretization\ndrift. Using backward error analysis, we derive modified continuous dynamical\nsystems that closely follow the discrete dynamics. These modified dynamics\nprovide an insight into the notorious challenges associated with zero-sum\ngames, including Generative Adversarial Networks. In particular, we identify\ndistinct components of the discretization drift that can alter performance and\nin some cases destabilize the game. Finally, quantifying discretization drift\nallows us to identify regularizers that explicitly cancel harmful forms of\ndrift or strengthen beneficial forms of drift, and thus improve performance of\nGAN training.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 15:38:34 GMT"}, {"version": "v2", "created": "Thu, 1 Jul 2021 18:26:15 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Rosca", "Mihaela", ""], ["Wu", "Yan", ""], ["Dherin", "Benoit", ""], ["Barrett", "David G. T.", ""]]}, {"id": "2105.13937", "submitter": "Sotirios Sabanis", "authors": "Dong-Young Lim and Sotirios Sabanis", "title": "Polygonal Unadjusted Langevin Algorithms: Creating stable and efficient\n  adaptive algorithms for neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new class of adaptive stochastic optimization algorithms, which\novercomes many of the known shortcomings of popular adaptive optimizers that\nare currently used for the fine tuning of artificial neural networks (ANNs).\nIts underpinning theory relies on advances of Euler's polygonal approximations\nfor stochastic differential equations (SDEs) with monotone coefficients. As a\nresult, it inherits the stability properties of tamed algorithms, while it\naddresses other known issues, e.g. vanishing gradients in ANNs. In particular,\nwe provide an nonasymptotic analysis and full theoretical guarantees for the\nconvergence properties of an algorithm of this novel class, which we named\nTH$\\varepsilon$O POULA (or, simply, TheoPouLa). Finally, several experiments\nare presented with different types of ANNs, which show the superior performance\nof TheoPouLa over many popular adaptive optimization algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 15:58:48 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Lim", "Dong-Young", ""], ["Sabanis", "Sotirios", ""]]}, {"id": "2105.13939", "submitter": "Christophe Roux", "authors": "Christophe Roux, Elias Wirth, Sebastian Pokutta, Thomas Kerdreux", "title": "Efficient Online-Bandit Strategies for Minimax Learning Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several learning problems involve solving min-max problems, e.g., empirical\ndistributional robust learning or learning with non-standard aggregated losses.\nMore specifically, these problems are convex-linear problems where the\nminimization is carried out over the model parameters $w\\in\\mathcal{W}$ and the\nmaximization over the empirical distribution $p\\in\\mathcal{K}$ of the training\nset indexes, where $\\mathcal{K}$ is the simplex or a subset of it. To design\nefficient methods, we let an online learning algorithm play against a\n(combinatorial) bandit algorithm. We argue that the efficiency of such\napproaches critically depends on the structure of $\\mathcal{K}$ and propose two\nproperties of $\\mathcal{K}$ that facilitate designing efficient algorithms. We\nfocus on a specific family of sets $\\mathcal{S}_{n,k}$ encompassing various\nlearning applications and provide high-probability convergence guarantees to\nthe minimax values.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 16:01:42 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 14:38:53 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Roux", "Christophe", ""], ["Wirth", "Elias", ""], ["Pokutta", "Sebastian", ""], ["Kerdreux", "Thomas", ""]]}, {"id": "2105.13942", "submitter": "Joachim Schreurs", "authors": "Joachim Schreurs, Micha\\\"el Fanuel and Johan A.K. Suykens", "title": "Towards Deterministic Diverse Subset Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determinantal point processes (DPPs) are well known models for diverse subset\nselection problems, including recommendation tasks, document summarization and\nimage search. In this paper, we discuss a greedy deterministic adaptation of\nk-DPP. Deterministic algorithms are interesting for many applications, as they\nprovide interpretability to the user by having no failure probability and\nalways returning the same results. First, the ability of the method to yield\nlow-rank approximations of kernel matrices is evaluated by comparing the\naccuracy of the Nystr\\\"om approximation on multiple datasets. Afterwards, we\ndemonstrate the usefulness of the model on an image search task.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 16:05:58 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Schreurs", "Joachim", ""], ["Fanuel", "Micha\u00ebl", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2105.13949", "submitter": "Joachim Schreurs", "authors": "David Winant, Joachim Schreurs and Johan A.K. Suykens", "title": "Latent Space Exploration Using Generative Kernel PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel PCA is a powerful feature extractor which recently has seen a\nreformulation in the context of Restricted Kernel Machines (RKMs). These RKMs\nallow for a representation of kernel PCA in terms of hidden and visible units\nsimilar to Restricted Boltzmann Machines. This connection has led to insights\non how to use kernel PCA in a generative procedure, called generative kernel\nPCA. In this paper, the use of generative kernel PCA for exploring latent\nspaces of datasets is investigated. New points can be generated by gradually\nmoving in the latent space, which allows for an interpretation of the\ncomponents. Firstly, examples of this feature space exploration on three\ndatasets are shown with one of them leading to an interpretable representation\nof ECG signals. Afterwards, the use of the tool in combination with novelty\ndetection is shown, where the latent space around novel patterns in the data is\nexplored. This helps in the interpretation of why certain points are considered\nas novel.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 16:17:37 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Winant", "David", ""], ["Schreurs", "Joachim", ""], ["Suykens", "Johan A. K.", ""]]}, {"id": "2105.13975", "submitter": "Veronika Thost", "authors": "Arthur Feeney and Rishabh Gupta and Veronika Thost and Rico Angell and\n  Gayathri Chandu and Yash Adhikari and Tengfei Ma", "title": "Relation Matters in Sampling: A Scalable Multi-Relational Graph Neural\n  Network for Drug-Drug Interaction Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling is an established technique to scale graph neural networks to large\ngraphs. Current approaches however assume the graphs to be homogeneous in terms\nof relations and ignore relation types, critically important in biomedical\ngraphs. Multi-relational graphs contain various types of relations that usually\ncome with variable frequency and have different importance for the problem at\nhand. We propose an approach to modeling the importance of relation types for\nneighborhood sampling in graph neural networks and show that we can learn the\nright balance: relation-type probabilities that reflect both frequency and\nimportance. Our experiments on drug-drug interaction prediction show that\nstate-of-the-art graph neural networks profit from relation-dependent sampling\nin terms of both accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 16:55:09 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Feeney", "Arthur", ""], ["Gupta", "Rishabh", ""], ["Thost", "Veronika", ""], ["Angell", "Rico", ""], ["Chandu", "Gayathri", ""], ["Adhikari", "Yash", ""], ["Ma", "Tengfei", ""]]}, {"id": "2105.14016", "submitter": "Bingyan Wang", "authors": "Bingyan Wang, Yuling Yan, Jianqing Fan", "title": "Sample-Efficient Reinforcement Learning for Linearly-Parameterized MDPs\n  with a Generative Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The curse of dimensionality is a widely known issue in reinforcement learning\n(RL). In the tabular setting where the state space $\\mathcal{S}$ and the action\nspace $\\mathcal{A}$ are both finite, to obtain a nearly optimal policy with\nsampling access to a generative model, the minimax optimal sample complexity\nscales linearly with $|\\mathcal{S}|\\times|\\mathcal{A}|$, which can be\nprohibitively large when $\\mathcal{S}$ or $\\mathcal{A}$ is large. This paper\nconsiders a Markov decision process (MDP) that admits a set of state-action\nfeatures, which can linearly express (or approximate) its probability\ntransition kernel. We show that a model-based approach (resp.$~$Q-learning)\nprovably learns an $\\varepsilon$-optimal policy (resp.$~$Q-function) with high\nprobability as soon as the sample size exceeds the order of\n$\\frac{K}{(1-\\gamma)^{3}\\varepsilon^{2}}$\n(resp.$~$$\\frac{K}{(1-\\gamma)^{4}\\varepsilon^{2}}$), up to some logarithmic\nfactor. Here $K$ is the feature dimension and $\\gamma\\in(0,1)$ is the discount\nfactor of the MDP. Both sample complexity bounds are provably tight, and our\nresult for the model-based approach matches the minimax lower bound. Our\nresults show that for arbitrarily large-scale MDP, both the model-based\napproach and Q-learning are sample-efficient when $K$ is relatively small, and\nhence the title of this paper.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 17:49:39 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Wang", "Bingyan", ""], ["Yan", "Yuling", ""], ["Fan", "Jianqing", ""]]}, {"id": "2105.14027", "submitter": "Bryan Ostdiek", "authors": "T. Aarrestad, M. van Beekveld, M. Bona, A. Boveia, S. Caron, J.\n  Davies, A. De Simone, C. Doglioni, J.M. Duarte, A. Farbin, H. Gupta, L.\n  Hendriks, L. Heinrich, J. Howarth, P. Jawahar, A. Jueid, J. Lastow, A.\n  Leinweber, J. Mamuzic, E. Mer\\'enyi, A. Morandini, P. Moskvitina, C. Nellist,\n  J. Ngadiuba, B. Ostdiek, M. Pierini, B. Ravina, R. Ruiz de Austri, S. Sekmen,\n  M. Touranakou, M. Va\\v{s}kevi\\v{c}i\\=ute, R. Vilalta, J.R. Vlimant, R.\n  Verheyen, M. White, E. Wulff, E. Wallin, K.A. Wozniak, Z. Zhang", "title": "The Dark Machines Anomaly Score Challenge: Benchmark Data and Model\n  Independent Event Classification for the Large Hadron Collider", "comments": "54 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph hep-ex physics.data-an stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe the outcome of a data challenge conducted as part of the Dark\nMachines Initiative and the Les Houches 2019 workshop on Physics at TeV\ncolliders. The challenged aims at detecting signals of new physics at the LHC\nusing unsupervised machine learning algorithms. First, we propose how an\nanomaly score could be implemented to define model-independent signal regions\nin LHC searches. We define and describe a large benchmark dataset, consisting\nof >1 Billion simulated LHC events corresponding to $10~\\rm{fb}^{-1}$ of\nproton-proton collisions at a center-of-mass energy of 13 TeV. We then review a\nwide range of anomaly detection and density estimation algorithms, developed in\nthe context of the data challenge, and we measure their performance in a set of\nrealistic analysis environments. We draw a number of useful conclusions that\nwill aid the development of unsupervised new physics searches during the third\nrun of the LHC, and provide our benchmark dataset for future studies at\nhttps://www.phenoMLdata.org. Code to reproduce the analysis is provided at\nhttps://github.com/bostdiek/DarkMachines-UnsupervisedChallenge.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 18:00:02 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Aarrestad", "T.", ""], ["van Beekveld", "M.", ""], ["Bona", "M.", ""], ["Boveia", "A.", ""], ["Caron", "S.", ""], ["Davies", "J.", ""], ["De Simone", "A.", ""], ["Doglioni", "C.", ""], ["Duarte", "J. M.", ""], ["Farbin", "A.", ""], ["Gupta", "H.", ""], ["Hendriks", "L.", ""], ["Heinrich", "L.", ""], ["Howarth", "J.", ""], ["Jawahar", "P.", ""], ["Jueid", "A.", ""], ["Lastow", "J.", ""], ["Leinweber", "A.", ""], ["Mamuzic", "J.", ""], ["Mer\u00e9nyi", "E.", ""], ["Morandini", "A.", ""], ["Moskvitina", "P.", ""], ["Nellist", "C.", ""], ["Ngadiuba", "J.", ""], ["Ostdiek", "B.", ""], ["Pierini", "M.", ""], ["Ravina", "B.", ""], ["de Austri", "R. Ruiz", ""], ["Sekmen", "S.", ""], ["Touranakou", "M.", ""], ["Va\u0161kevi\u010di\u016bte", "M.", ""], ["Vilalta", "R.", ""], ["Vlimant", "J. R.", ""], ["Verheyen", "R.", ""], ["White", "M.", ""], ["Wulff", "E.", ""], ["Wallin", "E.", ""], ["Wozniak", "K. A.", ""], ["Zhang", "Z.", ""]]}, {"id": "2105.14035", "submitter": "Shih-Ting Huang", "authors": "Shih-Ting Huang and Johannes Lederer", "title": "DeepMoM: Robust Deep Learning With Median-of-Means", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data used in deep learning is notoriously problematic. For example, data are\nusually combined from diverse sources, rarely cleaned and vetted thoroughly,\nand sometimes corrupted on purpose. Intentional corruption that targets the\nweak spots of algorithms has been studied extensively under the label of\n\"adversarial attacks.\" In contrast, the arguably much more common case of\ncorruption that reflects the limited quality of data has been studied much\nless. Such \"random\" corruptions are due to measurement errors, unreliable\nsources, convenience sampling, and so forth. These kinds of corruption are\ncommon in deep learning, because data are rarely collected according to strict\nprotocols -- in strong contrast to the formalized data collection in some parts\nof classical statistics. This paper concerns such corruption. We introduce an\napproach motivated by very recent insights into median-of-means and Le Cam's\nprinciple, we show that the approach can be readily implemented, and we\ndemonstrate that it performs very well in practice. In conclusion, we believe\nthat our approach is a very promising alternative to standard parameter\ntraining based on least-squares and cross-entropy loss.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 18:07:32 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Huang", "Shih-Ting", ""], ["Lederer", "Johannes", ""]]}, {"id": "2105.14080", "submitter": "Alexia Jolicoeur-Martineau", "authors": "Alexia Jolicoeur-Martineau, Ke Li, R\\'emi Pich\\'e-Taillefer, Tal\n  Kachman, Ioannis Mitliagkas", "title": "Gotta Go Fast When Generating Data with Score-Based Models", "comments": "Code is available on\n  https://github.com/AlexiaJM/score_sde_fast_sampling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Score-based (denoising diffusion) generative models have recently gained a\nlot of success in generating realistic and diverse data. These approaches\ndefine a forward diffusion process for transforming data to noise and generate\ndata by reversing it (thereby going from noise to data). Unfortunately, current\nscore-based models generate data very slowly due to the sheer number of score\nnetwork evaluations required by numerical SDE solvers.\n  In this work, we aim to accelerate this process by devising a more efficient\nSDE solver. Existing approaches rely on the Euler-Maruyama (EM) solver, which\nuses a fixed step size. We found that naively replacing it with other SDE\nsolvers fares poorly - they either result in low-quality samples or become\nslower than EM. To get around this issue, we carefully devise an SDE solver\nwith adaptive step sizes tailored to score-based generative models piece by\npiece. Our solver requires only two score function evaluations, rarely rejects\nsamples, and leads to high-quality samples. Our approach generates data 2 to 10\ntimes faster than EM while achieving better or equal sample quality. For\nhigh-resolution images, our method leads to significantly higher quality\nsamples than all other methods tested. Our SDE solver has the benefit of\nrequiring no step size tuning.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 19:48:51 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Jolicoeur-Martineau", "Alexia", ""], ["Li", "Ke", ""], ["Pich\u00e9-Taillefer", "R\u00e9mi", ""], ["Kachman", "Tal", ""], ["Mitliagkas", "Ioannis", ""]]}, {"id": "2105.14083", "submitter": "Glenn Dawson", "authors": "Glenn Dawson, Robi Polikar", "title": "Rethinking Noisy Label Models: Labeler-Dependent Noise with Adversarial\n  Awareness", "comments": "9 pages, 3 figures, 3 algorithms. Currently under blind review at\n  NeurIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most studies on learning from noisy labels rely on unrealistic models of\ni.i.d. label noise, such as class-conditional transition matrices. More recent\nwork on instance-dependent noise models are more realistic, but assume a single\ngenerative process for label noise across the entire dataset. We propose a more\nprincipled model of label noise that generalizes instance-dependent noise to\nmultiple labelers, based on the observation that modern datasets are typically\nannotated using distributed crowdsourcing methods. Under our labeler-dependent\nmodel, label noise manifests itself under two modalities: natural error of\ngood-faith labelers, and adversarial labels provided by malicious actors. We\npresent two adversarial attack vectors that more accurately reflect the label\nnoise that may be encountered in real-world settings, and demonstrate that\nunder our multimodal noisy labels model, state-of-the-art approaches for\nlearning from noisy labels are defeated by adversarial label attacks. Finally,\nwe propose a multi-stage, labeler-aware, model-agnostic framework that reliably\nfilters noisy labels by leveraging knowledge about which data partitions were\nlabeled by which labeler, and show that our proposed framework remains robust\neven in the presence of extreme adversarial label noise.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 19:58:18 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 01:40:37 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Dawson", "Glenn", ""], ["Polikar", "Robi", ""]]}, {"id": "2105.14084", "submitter": "Clayton Sanford", "authors": "Navid Ardeshir, Clayton Sanford, Daniel Hsu", "title": "Support vector machines and linear regression coincide with very\n  high-dimensional features", "comments": "32 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The support vector machine (SVM) and minimum Euclidean norm least squares\nregression are two fundamentally different approaches to fitting linear models,\nbut they have recently been connected in models for very high-dimensional data\nthrough a phenomenon of support vector proliferation, where every training\nexample used to fit an SVM becomes a support vector. In this paper, we explore\nthe generality of this phenomenon and make the following contributions. First,\nwe prove a super-linear lower bound on the dimension (in terms of sample size)\nrequired for support vector proliferation in independent feature models,\nmatching the upper bounds from previous works. We further identify a sharp\nphase transition in Gaussian feature models, bound the width of this\ntransition, and give experimental support for its universality. Finally, we\nhypothesize that this phase transition occurs only in much higher-dimensional\nsettings in the $\\ell_1$ variant of the SVM, and we present a new geometric\ncharacterization of the problem that may elucidate this phenomenon for the\ngeneral $\\ell_p$ case.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 20:06:21 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Ardeshir", "Navid", ""], ["Sanford", "Clayton", ""], ["Hsu", "Daniel", ""]]}, {"id": "2105.14095", "submitter": "Shuxiao Chen", "authors": "Shuxiao Chen, Koby Crammer, Hangfeng He, Dan Roth, Weijie J. Su", "title": "Weighted Training for Cross-Task Learning", "comments": "21 pages, 3 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce Target-Aware Weighted Training (TAWT), a weighted\ntraining algorithm for cross-task learning based on minimizing a\nrepresentation-based task distance between the source and target tasks. We show\nthat TAWT is easy to implement, is computationally efficient, requires little\nhyperparameter tuning, and enjoys non-asymptotic learning-theoretic guarantees.\nThe effectiveness of TAWT is corroborated through extensive experiments with\nBERT on four sequence tagging tasks in natural language processing (NLP),\nincluding part-of-speech (PoS) tagging, chunking, predicate detection, and\nnamed entity recognition (NER). As a byproduct, the proposed\nrepresentation-based task distance allows one to reason in a theoretically\nprincipled way about several critical aspects of cross-task learning, such as\nthe choice of the source data and the impact of fine-tuning\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 20:27:02 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chen", "Shuxiao", ""], ["Crammer", "Koby", ""], ["He", "Hangfeng", ""], ["Roth", "Dan", ""], ["Su", "Weijie J.", ""]]}, {"id": "2105.14099", "submitter": "Nan Ding", "authors": "Nan Ding, Xi Chen, Tomer Levinboim, Sebastian Goodman, Radu Soricut", "title": "Bridging the Gap Between Practice and PAC-Bayes Theory in Few-Shot\n  Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite recent advances in its theoretical understanding, there still remains\na significant gap in the ability of existing PAC-Bayesian theories on\nmeta-learning to explain performance improvements in the few-shot learning\nsetting, where the number of training examples in the target tasks is severely\nlimited. This gap originates from an assumption in the existing theories which\nsupposes that the number of training examples in the observed tasks and the\nnumber of training examples in the target tasks follow the same distribution,\nan assumption that rarely holds in practice. By relaxing this assumption, we\ndevelop two PAC-Bayesian bounds tailored for the few-shot learning setting and\nshow that two existing meta-learning algorithms (MAML and Reptile) can be\nderived from our bounds, thereby bridging the gap between practice and\nPAC-Bayesian theories. Furthermore, we derive a new computationally-efficient\nPACMAML algorithm, and show it outperforms existing meta-learning algorithms on\nseveral few-shot benchmark datasets.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 20:40:40 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ding", "Nan", ""], ["Chen", "Xi", ""], ["Levinboim", "Tomer", ""], ["Goodman", "Sebastian", ""], ["Soricut", "Radu", ""]]}, {"id": "2105.14114", "submitter": "Matias M\\\"uller", "authors": "Matias I. M\\\"uller and Cristian R. Rojas", "title": "Asymptotically Optimal Bandits under Weighted Information", "comments": "9 content pages, 3 references pages, 22 appendix pages, 4 figures, 34\n  total pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We study the problem of regret minimization in a multi-armed bandit setup\nwhere the agent is allowed to play multiple arms at each round by spreading the\nresources usually allocated to only one arm. At each iteration the agent\nselects a normalized power profile and receives a Gaussian vector as outcome,\nwhere the unknown variance of each sample is inversely proportional to the\npower allocated to that arm. The reward corresponds to a linear combination of\nthe power profile and the outcomes, resembling a linear bandit. By spreading\nthe power, the agent can choose to collect information much faster than in a\ntraditional multi-armed bandit at the price of reducing the accuracy of the\nsamples. This setup is fundamentally different from that of a linear bandit --\nthe regret is known to scale as $\\Theta(\\sqrt{T})$ for linear bandits, while in\nthis setup the agent receives a much more detailed feedback, for which we\nderive a tight $\\log(T)$ problem-dependent lower-bound. We propose a\nThompson-Sampling-based strategy, called Weighted Thompson Sampling (\\WTS),\nthat designs the power profile as its posterior belief of each arm being the\nbest arm, and show that its upper bound matches the derived logarithmic lower\nbound. Finally, we apply this strategy to a problem of control and system\nidentification, where the goal is to estimate the maximum gain (also called\n$\\mathcal{H}_\\infty$-norm) of a linear dynamical system based on batches of\ninput-output samples.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 21:28:44 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["M\u00fcller", "Matias I.", ""], ["Rojas", "Cristian R.", ""]]}, {"id": "2105.14119", "submitter": "Adam Kalai", "authors": "Adam Tauman Kalai, Varun Kanade", "title": "Towards optimally abstaining from prediction", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common challenge across all areas of machine learning is that training data\nis not distributed like test data, due to natural shifts, \"blind spots,\" or\nadversarial examples. We consider a model where one may abstain from\npredicting, at a fixed cost. In particular, our transductive abstention\nalgorithm takes labeled training examples and unlabeled test examples as input,\nand provides predictions with optimal prediction loss guarantees. The loss\nbounds match standard generalization bounds when test examples are i.i.d. from\nthe training distribution, but add an additional term that is the cost of\nabstaining times the statistical distance between the train and test\ndistribution (or the fraction of adversarial examples). For linear regression,\nwe give a polynomial-time algorithm based on Celis-Dennis-Tapia optimization\nalgorithms. For binary classification, we show how to efficiently implement it\nusing a proper agnostic learner (i.e., an Empirical Risk Minimizer) for the\nclass of interest. Our work builds on a recent abstention algorithm of\nGoldwasser, Kalais, and Montasser (2020) for transductive binary\nclassification.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 21:44:48 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Kalai", "Adam Tauman", ""], ["Kanade", "Varun", ""]]}, {"id": "2105.14141", "submitter": "Alek Dimitriev", "authors": "Alek Dimitriev and Mingyuan Zhou", "title": "ARMS: Antithetic-REINFORCE-Multi-Sample Gradient for Binary Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the gradients for binary variables is a task that arises\nfrequently in various domains, such as training discrete latent variable\nmodels. What has been commonly used is a REINFORCE based Monte Carlo estimation\nmethod that uses either independent samples or pairs of negatively correlated\nsamples. To better utilize more than two samples, we propose ARMS, an\nAntithetic REINFORCE-based Multi-Sample gradient estimator. ARMS uses a copula\nto generate any number of mutually antithetic samples. It is unbiased, has low\nvariance, and generalizes both DisARM, which we show to be ARMS with two\nsamples, and the leave-one-out REINFORCE (LOORF) estimator, which is ARMS with\nuncorrelated samples. We evaluate ARMS on several datasets for training\ngenerative models, and our experimental results show that it outperforms\ncompeting methods. We also develop a version of ARMS for optimizing the\nmulti-sample variational bound, and show that it outperforms both VIMCO and\nDisARM. The code is publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 23:19:54 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Dimitriev", "Alek", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "2105.14146", "submitter": "Hongjing Zhang", "authors": "Hongjing Zhang, Ian Davidson", "title": "Deep Fair Discriminative Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep clustering has the potential to learn a strong representation and hence\nbetter clustering performance compared to traditional clustering methods such\nas $k$-means and spectral clustering. However, this strong representation\nlearning ability may make the clustering unfair by discovering surrogates for\nprotected information which we empirically show in our experiments. In this\nwork, we study a general notion of group-level fairness for both binary and\nmulti-state protected status variables (PSVs). We begin by formulating the\ngroup-level fairness problem as an integer linear programming formulation whose\ntotally unimodular constraint matrix means it can be efficiently solved via\nlinear programming. We then show how to inject this solver into a\ndiscriminative deep clustering backbone and hence propose a refinement learning\nalgorithm to combine the clustering goal with the fairness objective to learn\nfair clusters adaptively. Experimental results on real-world datasets\ndemonstrate that our model consistently outperforms state-of-the-art fair\nclustering algorithms. Our framework shows promising results for novel\nclustering tasks including flexible fairness constraints, multi-state PSVs and\npredictive clustering.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 23:50:48 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhang", "Hongjing", ""], ["Davidson", "Ian", ""]]}, {"id": "2105.14166", "submitter": "Sinho Chewi", "authors": "Sinho Chewi, Patrik Gerber, Chen Lu, Thibaut Le Gouic, Philippe\n  Rigollet", "title": "Rejection sampling from shape-constrained distributions in sublinear\n  time", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of generating exact samples from a target distribution,\nknown up to normalization, over a finite alphabet. The classical algorithm for\nthis task is rejection sampling, and although it has been used in practice for\ndecades, there is surprisingly little study of its fundamental limitations. In\nthis work, we study the query complexity of rejection sampling in a minimax\nframework for various classes of discrete distributions. Our results provide\nnew algorithms for sampling whose complexity scales sublinearly with the\nalphabet size. When applied to adversarial bandits, we show that a slight\nmodification of the Exp3 algorithm reduces the per-iteration complexity from\n$\\mathcal O(K)$ to $\\mathcal O(\\log^2 K)$, where $K$ is the number of arms.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 01:00:42 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chewi", "Sinho", ""], ["Gerber", "Patrik", ""], ["Lu", "Chen", ""], ["Gouic", "Thibaut Le", ""], ["Rigollet", "Philippe", ""]]}, {"id": "2105.14172", "submitter": "Suyun Liu", "authors": "Suyun Liu, Luis Nunes Vicente", "title": "A Stochastic Alternating Balance $k$-Means Algorithm for Fair Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the application of data clustering to human-centric decision-making\nsystems, such as loan applications and advertisement recommendations, the\nclustering outcome might discriminate against people across different\ndemographic groups, leading to unfairness. A natural conflict occurs between\nthe cost of clustering (in terms of distance to cluster centers) and the\nbalance representation of all demographic groups across the clusters, leading\nto a bi-objective optimization problem that is nonconvex and nonsmooth. To\ndetermine the complete trade-off between these two competing goals, we design a\nnovel stochastic alternating balance fair $k$-means (SAfairKM) algorithm, which\nconsists of alternating classical mini-batch $k$-means updates and group swap\nupdates. The number of $k$-means updates and the number of swap updates\nessentially parameterize the weight put on optimizing each objective function.\nOur numerical experiments show that the proposed SAfairKM algorithm is robust\nand computationally efficient in constructing well-spread and high-quality\nPareto fronts both on synthetic and real datasets. Moreover, we propose a novel\ncompanion algorithm, the stochastic alternating bi-objective gradient descent\n(SA2GD) algorithm, which can handle a smooth version of the considered\nbi-objective fair $k$-means problem, more amenable for analysis. A sublinear\nconvergence rate of $\\mathcal{O}(1/T)$ is established under strong convexity\nfor the determination of a stationary point of a weighted sum of the two\nfunctions parameterized by the number of steps or updates on each function.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 01:47:15 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Liu", "Suyun", ""], ["Vicente", "Luis Nunes", ""]]}, {"id": "2105.14203", "submitter": "Zhifeng Kong", "authors": "Zhifeng Kong, Kamalika Chaudhuri", "title": "Understanding Instance-based Interpretability of Variational\n  Auto-Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instance-based interpretation methods have been widely studied for supervised\nlearning methods as they help explain how black box neural networks predict.\nHowever, instance-based interpretations remain ill-understood in the context of\nunsupervised learning. In this paper, we investigate influence functions [20],\na popular instance-based interpretation method, for a class of deep generative\nmodels called variational auto-encoders (VAE). We formally frame the\ncounter-factual question answered by influence functions in this setting, and\nthrough theoretical analysis, examine what they reveal about the impact of\ntraining samples on classical unsupervised learning methods. We then introduce\nVAE-TracIn, a computationally efficient and theoretically sound solution based\non Pruthi et al. [28], for VAEs. Finally, we evaluate VAE-TracIn on several\nreal world datasets with extensive quantitative and qualitative analysis.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 04:03:09 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Kong", "Zhifeng", ""], ["Chaudhuri", "Kamalika", ""]]}, {"id": "2105.14244", "submitter": "Hongteng Xu", "authors": "Hongteng Xu, Peilin Zhao, Junzhou Huang, Dixin Luo", "title": "Learning Graphon Autoencoders for Generative Graph Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graphon is a nonparametric model that generates graphs with arbitrary sizes\nand can be induced from graphs easily. Based on this model, we propose a novel\nalgorithmic framework called \\textit{graphon autoencoder} to build an\ninterpretable and scalable graph generative model. This framework treats\nobserved graphs as induced graphons in functional space and derives their\nlatent representations by an encoder that aggregates Chebshev graphon filters.\nA linear graphon factorization model works as a decoder, leveraging the latent\nrepresentations to reconstruct the induced graphons (and the corresponding\nobserved graphs). We develop an efficient learning algorithm to learn the\nencoder and the decoder, minimizing the Wasserstein distance between the model\nand data distributions. This algorithm takes the KL divergence of the graph\ndistributions conditioned on different graphons as the underlying distance and\nleads to a reward-augmented maximum likelihood estimation. The graphon\nautoencoder provides a new paradigm to represent and generate graphs, which has\ngood generalizability and transferability.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 08:11:40 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Xu", "Hongteng", ""], ["Zhao", "Peilin", ""], ["Huang", "Junzhou", ""], ["Luo", "Dixin", ""]]}, {"id": "2105.14260", "submitter": "Houshuang Chen", "authors": "Houshuang Chen (1), Zengfeng Huang (2), Shuai Li (1) and Chihao Zhang\n  (1) ((1) Shanghai Jiao Tong University, (2) Fudan University)", "title": "Understanding Bandits with Graph Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bandit problem with graph feedback, proposed in [Mannor and Shamir,\nNeurIPS 2011], is modeled by a directed graph $G=(V,E)$ where $V$ is the\ncollection of bandit arms, and once an arm is triggered, all its incident arms\nare observed. A fundamental question is how the structure of the graph affects\nthe min-max regret. We propose the notions of the fractional weak domination\nnumber $\\delta^*$ and the $k$-packing independence number capturing upper bound\nand lower bound for the regret respectively. We show that the two notions are\ninherently connected via aligning them with the linear program of the weakly\ndominating set and its dual -- the fractional vertex packing set respectively.\nBased on this connection, we utilize the strong duality theorem to prove a\ngeneral regret upper bound $O\\left(\\left( \\delta^*\\log\n|V|\\right)^{\\frac{1}{3}}T^{\\frac{2}{3}}\\right)$ and a lower bound\n$\\Omega\\left(\\left(\\delta^*/\\alpha\\right)^{\\frac{1}{3}}T^{\\frac{2}{3}}\\right)$\nwhere $\\alpha$ is the integrality gap of the dual linear program. Therefore,\nour bounds are tight up to a $\\left(\\log |V|\\right)^{\\frac{1}{3}}$ factor on\ngraphs with bounded integrality gap for the vertex packing problem including\ntrees and graphs with bounded degree. Moreover, we show that for several\nspecial families of graphs, we can get rid of the $\\left(\\log\n|V|\\right)^{\\frac{1}{3}}$ factor and establish optimal regret.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 09:35:28 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chen", "Houshuang", "", "Shanghai Jiao Tong University"], ["Huang", "Zengfeng", "", "Fudan University"], ["Li", "Shuai", "", "Shanghai Jiao Tong University"], ["Zhang", "Chihao", "", "Shanghai Jiao Tong University"]]}, {"id": "2105.14267", "submitter": "Botao Hao", "authors": "Botao Hao, Tor Lattimore, Wei Deng", "title": "Information Directed Sampling for Sparse Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic sparse linear bandits offer a practical model for high-dimensional\nonline decision-making problems and have a rich information-regret structure.\nIn this work we explore the use of information-directed sampling (IDS), which\nnaturally balances the information-regret trade-off. We develop a class of\ninformation-theoretic Bayesian regret bounds that nearly match existing lower\nbounds on a variety of problem instances, demonstrating the adaptivity of IDS.\nTo efficiently implement sparse IDS, we propose an empirical Bayesian approach\nfor sparse posterior sampling using a spike-and-slab Gaussian-Laplace prior.\nNumerical results demonstrate significant regret reductions by sparse IDS\nrelative to several baselines.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 10:26:23 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Hao", "Botao", ""], ["Lattimore", "Tor", ""], ["Deng", "Wei", ""]]}, {"id": "2105.14301", "submitter": "Haozhe Shan", "authors": "Haozhe Shan and Blake Bordelon", "title": "Rapid Feature Evolution Accelerates Learning in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural network (NN) training and generalization in the infinite-width limit\nare well-characterized by kernel methods with a neural tangent kernel (NTK)\nthat is stationary in time. However, finite-width NNs consistently outperform\ncorresponding kernel methods, suggesting the importance of feature learning,\nwhich manifests as the time evolution of NTKs. Here, we analyze the phenomenon\nof kernel alignment of the NTK with the target functions during gradient\ndescent. We first provide a mechanistic explanation for why alignment between\ntask and kernel occurs in deep linear networks. We then show that this behavior\noccurs more generally if one optimizes the feature map over time to accelerate\nlearning while constraining how quickly the features evolve. Empirically,\ngradient descent undergoes a feature learning phase, during which top\neigenfunctions of the NTK quickly align with the target function and the loss\ndecreases faster than power law in time; it then enters a kernel gradient\ndescent (KGD) phase where the alignment does not improve significantly and the\ntraining loss decreases in power law. We show that feature evolution is faster\nand more dramatic in deeper networks. We also found that networks with multiple\noutput nodes develop separate, specialized kernels for each output channel, a\nphenomenon we termed kernel specialization. We show that this class-specific\nalignment is does not occur in linear networks.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 13:50:03 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Shan", "Haozhe", ""], ["Bordelon", "Blake", ""]]}, {"id": "2105.14328", "submitter": "Ye Tian", "authors": "Ye Tian and Yang Feng", "title": "Transfer Learning under High-dimensional Generalized Linear Models", "comments": "52 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the transfer learning problem under high-dimensional\ngeneralized linear models (GLMs), which aim to improve the fit on target data\nby borrowing information from useful source data. Given which sources to\ntransfer, we propose an oracle algorithm and derive its $\\ell_2$-estimation\nerror bounds. The theoretical analysis shows that under certain conditions,\nwhen the target and source are sufficiently close to each other, the estimation\nerror bound could be improved over that of the classical penalized estimator\nusing only target data. When we don't know which sources to transfer, an\nalgorithm-free transferable source detection approach is introduced to detect\ninformative sources. The detection consistency is proved under the\nhigh-dimensional GLM transfer learning setting. Extensive simulations and a\nreal-data experiment verify the effectiveness of our algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 15:39:43 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Tian", "Ye", ""], ["Feng", "Yang", ""]]}, {"id": "2105.14337", "submitter": "Diego Gonz\\'alez-S\\'anchez", "authors": "D\\'avid Terj\\'ek (1) and Diego Gonz\\'alez-S\\'anchez (1) ((1) Alfr\\'ed\n  R\\'enyi Institute of Mathematics)", "title": "Optimal transport with $f$-divergence regularization and generalized\n  Sinkhorn algorithm", "comments": "30 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.FA math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropic regularization provides a generalization of the original optimal\ntransport problem. It introduces a penalty term defined by the Kullback-Leibler\ndivergence, making the problem more tractable via the celebrated Sinkhorn\nalgorithm. Replacing the Kullback-Leibler divergence with a general\n$f$-divergence leads to a natural generalization. Using convex analysis, we\nextend the theory developed so far to include $f$-divergences defined by\nfunctions of Legendre type, and prove that under some mild conditions, strong\nduality holds, optimums in both the primal and dual problems are attained, the\ngeneralization of the $c$-transform is well-defined, and we give sufficient\nconditions for the generalized Sinkhorn algorithm to converge to an optimal\nsolution. We propose a practical algorithm for computing the regularized\noptimal transport cost and its gradient via the generalized Sinkhorn algorithm.\nFinally, we present experimental results on synthetic 2-dimensional data,\ndemonstrating the effects of using different $f$-divergences for\nregularization, which influences convergence speed, numerical stability and\nsparsity of the optimal coupling.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 16:37:31 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Terj\u00e9k", "D\u00e1vid", ""], ["Gonz\u00e1lez-S\u00e1nchez", "Diego", ""]]}, {"id": "2105.14363", "submitter": "Niladri Chatterji", "authors": "Niladri S. Chatterji, Aldo Pacchiano, Peter L. Bartlett, Michael I.\n  Jordan", "title": "On the Theory of Reinforcement Learning with Once-per-Episode Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a theory of reinforcement learning (RL) in which the learner\nreceives binary feedback only once at the end of an episode. While this is an\nextreme test case for theory, it is also arguably more representative of\nreal-world applications than the traditional requirement in RL practice that\nthe learner receive feedback at every time step. Indeed, in many real-world\napplications of reinforcement learning, such as self-driving cars and robotics,\nit is easier to evaluate whether a learner's complete trajectory was either\n\"good\" or \"bad,\" but harder to provide a reward signal at each step. To show\nthat learning is possible in this more challenging setting, we study the case\nwhere trajectory labels are generated by an unknown parametric model, and\nprovide a statistically and computationally efficient algorithm that achieves\nsub-linear regret.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 19:48:51 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 05:16:09 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chatterji", "Niladri S.", ""], ["Pacchiano", "Aldo", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2105.14367", "submitter": "Mazharul Islam", "authors": "Bing Chen, Mazharul Islam, Lin Wang, Jisuo Gao and Jeff Orchard", "title": "Deconvolutional Density Network: Free-Form Conditional Density\n  Estimation", "comments": "11 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional density estimation is the task of estimating the probability of\nan event, conditioned on some inputs. A neural network can be used to compute\nthe output distribution explicitly. For such a task, there are many ways to\nrepresent a continuous-domain distribution using the output of a neural\nnetwork, but each comes with its own limitations for what distributions it can\naccurately render. If the family of functions is too restrictive, it will not\nbe appropriate for many datasets. In this paper, we demonstrate the benefits of\nmodeling free-form distributions using deconvolution. It has the advantage of\nbeing flexible, but also takes advantage of the topological smoothness offered\nby the deconvolution layers. We compare our method to a number of other\ndensity-estimation approaches, and show that our Deconvolutional Density\nNetwork (DDN) outperforms the competing methods on many artificial and real\ntasks, without committing to a restrictive parametric model.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 20:09:25 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chen", "Bing", ""], ["Islam", "Mazharul", ""], ["Wang", "Lin", ""], ["Gao", "Jisuo", ""], ["Orchard", "Jeff", ""]]}, {"id": "2105.14368", "submitter": "Mikhail Belkin", "authors": "Mikhail Belkin", "title": "Fit without fear: remarkable mathematical phenomena of deep learning\n  through the prism of interpolation", "comments": "A version of this paper will appear in Acta Numerica", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past decade the mathematical theory of machine learning has lagged far\nbehind the triumphs of deep neural networks on practical challenges. However,\nthe gap between theory and practice is gradually starting to close. In this\npaper I will attempt to assemble some pieces of the remarkable and still\nincomplete mathematical mosaic emerging from the efforts to understand the\nfoundations of deep learning. The two key themes will be interpolation, and its\nsibling, over-parameterization. Interpolation corresponds to fitting data, even\nnoisy data, exactly. Over-parameterization enables interpolation and provides\nflexibility to select a right interpolating model.\n  As we will see, just as a physical prism separates colors mixed within a ray\nof light, the figurative prism of interpolation helps to disentangle\ngeneralization and optimization properties within the complex picture of modern\nMachine Learning. This article is written with belief and hope that clearer\nunderstanding of these issues brings us a step closer toward a general theory\nof deep learning and machine learning.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 20:15:53 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Belkin", "Mikhail", ""]]}, {"id": "2105.14397", "submitter": "Francois Meyer", "authors": "Daniel Ferguson, Francois G. Meyer", "title": "The Sample Fr\\'echet Mean (or Median) Graph of Sparse Graphs is Sparse", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.SI physics.data-an stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To characterize the \"average\" of a sample of graphs, one can compute the\nsample Frechet mean (or median) graph, which provides an interpretable summary\nof the graph sample. In this paper, we address the following foundational\nquestion: does the mean or median graph inherit the structural properties of\nthe graphs in the sample? An important graph property is the edge density.\nBecause sparse graphs provide prototypical models for real networks, one would\nlike to guarantee that the edge density be preserved when computing the sample\nmean (or median). In this paper, we prove that the edge density is an\nhereditary property, which can be transmitted from a graph sample to its sample\nFrechet mean (or median), irrespective of the method used to estimate the mean\nor the median. Specifically, we prove the following result: the number of edges\nof the Frechet mean (or median) graph of a set of graphs is bounded by the\nmaximal number of edges amongst all the graphs in the sample. We prove the\nresult for the graph Hamming distance, and the spectral adjacency pseudometric,\nusing very different arguments.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 00:40:43 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 02:52:21 GMT"}, {"version": "v3", "created": "Thu, 29 Jul 2021 00:39:09 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Ferguson", "Daniel", ""], ["Meyer", "Francois G.", ""]]}, {"id": "2105.14417", "submitter": "Zhiyan Ding", "authors": "Zhiyan Ding and Shi Chen and Qin Li and Stephen Wright", "title": "Overparameterization of deep ResNet: zero loss and mean-field analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finding parameters in a deep neural network (NN) that fit training data is a\nnonconvex optimization problem, but a basic first-order optimization method\n(gradient descent) finds a global solution with perfect fit in many practical\nsituations. We examine this phenomenon for the case of Residual Neural Networks\n(ResNet) with smooth activation functions in a limiting regime in which both\nthe number of layers (depth) and the number of neurons in each layer (width) go\nto infinity. First, we use a mean-field-limit argument to prove that the\ngradient descent for parameter training becomes a partial differential equation\n(PDE) that characterizes gradient flow for a probability distribution in the\nlarge-NN limit. Next, we show that the solution to the PDE converges in the\ntraining time to a zero-loss solution. Together, these results imply that\ntraining of the ResNet also gives a near-zero loss if the Resnet is large\nenough. We give estimates of the depth and width needed to reduce the loss\nbelow a given threshold, with high probability.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 02:46:09 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 18:57:16 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Ding", "Zhiyan", ""], ["Chen", "Shi", ""], ["Li", "Qin", ""], ["Wright", "Stephen", ""]]}, {"id": "2105.14524", "submitter": "Jiwei Li", "authors": "Chun Fan, Yuxian Meng, Xiaofei Sun, Fei Wu, Tianwei Zhang, Jiwei Li", "title": "Parameter Estimation for the SEIR Model Using Recurrent Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The standard way to estimate the parameters $\\Theta_\\text{SEIR}$ (e.g., the\ntransmission rate $\\beta$) of an SEIR model is to use grid search, where\nsimulations are performed on each set of parameters, and the parameter set\nleading to the least $L_2$ distance between predicted number of infections and\nobserved infections is selected. This brute-force strategy is not only time\nconsuming, as simulations are slow when the population is large, but also\ninaccurate, since it is impossible to enumerate all parameter combinations. To\naddress these issues, in this paper, we propose to transform the\nnon-differentiable problem of finding optimal $\\Theta_\\text{SEIR}$ to a\ndifferentiable one, where we first train a recurrent net to fit a small number\nof simulation data. Next, based on this recurrent net that is able to\ngeneralize SEIR simulations, we are able to transform the objective to a\ndifferentiable one with respect to $\\Theta_\\text{SEIR}$, and straightforwardly\nobtain its optimal value. The proposed strategy is both time efficient as it\nonly relies on a small number of SEIR simulations, and accurate as we are able\nto find the optimal $\\Theta_\\text{SEIR}$ based on the differentiable objective.\nOn two COVID-19 datasets, we observe that the proposed strategy leads to\nsignificantly better parameter estimations with a smaller number of\nsimulations.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 12:51:45 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Fan", "Chun", ""], ["Meng", "Yuxian", ""], ["Sun", "Xiaofei", ""], ["Wu", "Fei", ""], ["Zhang", "Tianwei", ""], ["Li", "Jiwei", ""]]}, {"id": "2105.14529", "submitter": "Changjian Shui", "authors": "Changjian Shui, Boyu Wang, Christian Gagn\\'e", "title": "On the benefits of representation regularization in invariance based\n  domain generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A crucial aspect in reliable machine learning is to design a deployable\nsystem in generalizing new related but unobserved environments. Domain\ngeneralization aims to alleviate such a prediction gap between the observed and\nunseen environments. Previous approaches commonly incorporated learning\ninvariant representation for achieving good empirical performance. In this\npaper, we reveal that merely learning invariant representation is vulnerable to\nthe unseen environment. To this end, we derive novel theoretical analysis to\ncontrol the unseen test environment error in the representation learning, which\nhighlights the importance of controlling the smoothness of representation. In\npractice, our analysis further inspires an efficient regularization method to\nimprove the robustness in domain generalization. Our regularization is\northogonal to and can be straightforwardly adopted in existing domain\ngeneralization algorithms for invariant representation learning. Empirical\nresults show that our algorithm outperforms the base versions in various\ndataset and invariance criteria.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 13:13:55 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Shui", "Changjian", ""], ["Wang", "Boyu", ""], ["Gagn\u00e9", "Christian", ""]]}, {"id": "2105.14559", "submitter": "Jae Oh Woo", "authors": "Jae Oh Woo", "title": "BABA: Beta Approximation for Bayesian Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper introduces a new acquisition function under the Bayesian active\nlearning framework, namely BABA. It is motivated by previously well-established\nworks BALD, and BatchBALD which capture the mutual information between the\nmodel parameters and the predictive outputs of the data. Our proposed measure,\nBABA, endeavors to quantify the normalized mutual information by approximating\nthe stochasticity of predictive probabilities using Beta distributions. BABA\noutperforms the well-known family of acquisition functions, including BALD and\nBatchBALD. We demonstrate this by showing extensive experimental results\nobtained from MNIST and EMNIST datasets.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 14:49:10 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Woo", "Jae Oh", ""]]}, {"id": "2105.14573", "submitter": "Zhongwang Zhang", "authors": "Yaoyu Zhang, Zhongwang Zhang, Tao Luo, Zhi-Qin John Xu", "title": "Embedding Principle of Loss Landscape of Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the structure of loss landscape of deep neural networks\n(DNNs)is obviously important. In this work, we prove an embedding principle\nthat the loss landscape of a DNN \"contains\" all the critical points of all the\nnarrower DNNs. More precisely, we propose a critical embedding such that any\ncritical point, e.g., local or global minima, of a narrower DNN can be embedded\nto a critical point/hyperplane of the target DNN with higher degeneracy and\npreserving the DNN output function. The embedding structure of critical points\nis independent of loss function and training data, showing a stark difference\nfrom other nonconvex problems such as protein-folding. Empirically, we find\nthat a wide DNN is often attracted by highly-degenerate critical points that\nare embedded from narrow DNNs. The embedding principle provides an explanation\nfor the general easy optimization of wide DNNs and unravels a potential\nimplicit low-complexity regularization during the training. Overall, our work\nprovides a skeleton for the study of loss landscape of DNNs and its\nimplication, by which a more exact and comprehensive understanding can be\nanticipated in the near\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 15:32:32 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhang", "Yaoyu", ""], ["Zhang", "Zhongwang", ""], ["Luo", "Tao", ""], ["Xu", "Zhi-Qin John", ""]]}, {"id": "2105.14574", "submitter": "Aristeidis Panos", "authors": "Aristeidis Panos, Ioannis Kosmidis, Petros Dellaportas", "title": "Scalable and Interpretable Marked Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a novel inferential framework for marked point processes that\nenjoys both scalability and interpretability. The framework is based on\nvariational inference and it aims to speed up inference for a flexible family\nof marked point processes where the joint distribution of times and marks can\nbe specified in terms of the conditional distribution of times given the\nprocess filtration, and of the conditional distribution of marks given the\nprocess filtration and the current time. We assess the predictive ability of\nour proposed method over four real-world datasets where results show its\ncompetitive performance against other baselines. The attractiveness of our\nframework for the modelling of marked point processes is illustrated through a\ncase study of association football data where scalability and interpretability\nare exploited for extracting useful informative patterns.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 15:37:57 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Panos", "Aristeidis", ""], ["Kosmidis", "Ioannis", ""], ["Dellaportas", "Petros", ""]]}, {"id": "2105.14586", "submitter": "Hardhik Mohanty", "authors": "Gourab Ghatak, Hardhik Mohanty, Aniq Ur Rahman", "title": "Kolmogorov-Smirnov Test-Based Actively-Adaptive Thompson Sampling for\n  Non-Stationary Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the non-stationary multi-armed bandit (MAB) framework and propose\na Kolmogorov-Smirnov (KS) test based Thompson Sampling (TS) algorithm named\nTS-KS, that actively detects change points and resets the TS parameters once a\nchange is detected. In particular, for the two-armed bandit case, we derive\nbounds on the number of samples of the reward distribution to detect the change\nonce it occurs. Consequently, we show that the proposed algorithm has\nsub-linear regret. Contrary to existing works, our algorithm is able to detect\na change when the underlying reward distribution changes even though the mean\nreward remains the same. Finally, to test the efficacy of the proposed\nalgorithm, we employ it in two case-studies: i) task-offloading scenario in\nwireless edge-computing, and ii) portfolio optimization. Our results show that\nthe proposed TS-KS algorithm outperforms not only the static TS algorithm but\nalso it performs better than other bandit algorithms designed for\nnon-stationary environments. Moreover, the performance of TS-KS is at par with\nthe state-of-the-art forecasting algorithms such as Facebook-PROPHET and ARIMA.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 17:28:41 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ghatak", "Gourab", ""], ["Mohanty", "Hardhik", ""], ["Rahman", "Aniq Ur", ""]]}, {"id": "2105.14594", "submitter": "Yingzhen Li", "authors": "Hippolyt Ritter, Martin Kukla, Cheng Zhang, Yingzhen Li", "title": "Sparse Uncertainty Representation in Deep Learning with Inducing Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian neural networks and deep ensembles represent two modern paradigms of\nuncertainty quantification in deep learning. Yet these approaches struggle to\nscale mainly due to memory inefficiency issues, since they require parameter\nstorage several times higher than their deterministic counterparts. To address\nthis, we augment the weight matrix of each layer with a small number of\ninducing weights, thereby projecting the uncertainty quantification into such\nlow dimensional spaces. We further extend Matheron's conditional Gaussian\nsampling rule to enable fast weight sampling, which enables our inference\nmethod to maintain reasonable run-time as compared with ensembles. Importantly,\nour approach achieves competitive performance to the state-of-the-art in\nprediction and uncertainty estimation tasks with fully connected neural\nnetworks and ResNets, while reducing the parameter size to $\\leq 24.3\\%$ of\nthat of a $single$ neural network.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 18:17:47 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ritter", "Hippolyt", ""], ["Kukla", "Martin", ""], ["Zhang", "Cheng", ""], ["Li", "Yingzhen", ""]]}, {"id": "2105.14602", "submitter": "SueYeon Chung", "authors": "Cory Stephenson, Suchismita Padhy, Abhinav Ganesh, Yue Hui, Hanlin\n  Tang and SueYeon Chung", "title": "On the geometry of generalization and memorization in deep neural\n  networks", "comments": "ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how large neural networks avoid memorizing training data is key\nto explaining their high generalization performance. To examine the structure\nof when and where memorization occurs in a deep network, we use a recently\ndeveloped replica-based mean field theoretic geometric analysis method. We find\nthat all layers preferentially learn from examples which share features, and\nlink this behavior to generalization performance. Memorization predominately\noccurs in the deeper layers, due to decreasing object manifolds' radius and\ndimension, whereas early layers are minimally affected. This predicts that\ngeneralization can be restored by reverting the final few layer weights to\nearlier epochs before significant memorization occurred, which is confirmed by\nthe experiments. Additionally, by studying generalization under different model\nsizes, we reveal the connection between the double descent phenomenon and the\nunderlying model geometry. Finally, analytical analysis shows that networks\navoid memorization early in training because close to initialization, the\ngradient contribution from permuted examples are small. These findings provide\nquantitative evidence for the structure of memorization across layers of a deep\nneural network, the drivers for such structure, and its connection to manifold\ngeometric properties.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 19:07:33 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Stephenson", "Cory", ""], ["Padhy", "Suchismita", ""], ["Ganesh", "Abhinav", ""], ["Hui", "Yue", ""], ["Tang", "Hanlin", ""], ["Chung", "SueYeon", ""]]}, {"id": "2105.14648", "submitter": "Jesse Geneson", "authors": "Jesse Geneson", "title": "Sharper bounds for online learning of smooth functions of a single\n  variable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the generalization of the mistake-bound model to continuous\nreal-valued single variable functions. Let $\\mathcal{F}_q$ be the class of\nabsolutely continuous functions $f: [0, 1] \\rightarrow \\mathbb{R}$ with\n$||f'||_q \\le 1$, and define $opt_p(\\mathcal{F}_q)$ as the best possible bound\non the worst-case sum of the $p^{th}$ powers of the absolute prediction errors\nover any number of trials. Kimber and Long (Theoretical Computer Science, 1995)\nproved for $q \\ge 2$ that $opt_p(\\mathcal{F}_q) = 1$ when $p \\ge 2$ and\n$opt_p(\\mathcal{F}_q) = \\infty$ when $p = 1$. For $1 < p < 2$ with $p =\n1+\\epsilon$, the only known bound was $opt_p(\\mathcal{F}_{q}) =\nO(\\epsilon^{-1})$ from the same paper. We show for all $\\epsilon \\in (0, 1)$\nand $q \\ge 2$ that $opt_{1+\\epsilon}(\\mathcal{F}_q) =\n\\Theta(\\epsilon^{-\\frac{1}{2}})$, where the constants in the bound do not\ndepend on $q$. We also show that $opt_{1+\\epsilon}(\\mathcal{F}_{\\infty}) =\n\\Theta(\\epsilon^{-\\frac{1}{2}})$.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 23:06:21 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Geneson", "Jesse", ""]]}, {"id": "2105.14673", "submitter": "Waheed Bajwa", "authors": "Batoul Taki, Mohsen Ghassemi, Anand D. Sarwate, and Waheed U. Bajwa", "title": "A Minimax Lower Bound for Low-Rank Matrix-Variate Logistic Regression", "comments": "8 pages; preprint of a conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of matrix-variate logistic regression. The\nfundamental error threshold on estimating coefficient matrices in the logistic\nregression problem is found by deriving a lower bound on the minimax risk. The\nfocus of this paper is on derivation of a minimax risk lower bound for low-rank\ncoefficient matrices. The bound depends explicitly on the dimensions and\ndistribution of the covariates, the rank and energy of the coefficient matrix,\nand the number of samples. The resulting bound is proportional to the intrinsic\ndegrees of freedom in the problem, which suggests the sample complexity of the\nlow-rank matrix logistic regression problem can be lower than that for\nvectorized logistic regression. \\color{red}\\color{black} The proof techniques\nutilized in this work also set the stage for development of minimax lower\nbounds for tensor-variate logistic regression problems.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 02:06:34 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Taki", "Batoul", ""], ["Ghassemi", "Mohsen", ""], ["Sarwate", "Anand D.", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "2105.14710", "submitter": "Ameya Patil", "authors": "Ameya D. Patil, Michael Tuttle, Alexander G. Schwing, Naresh R.\n  Shanbhag", "title": "Robustifying $\\ell_\\infty$ Adversarial Training to the Union of\n  Perturbation Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classical adversarial training (AT) frameworks are designed to achieve high\nadversarial accuracy against a single attack type, typically $\\ell_\\infty$\nnorm-bounded perturbations. Recent extensions in AT have focused on defending\nagainst the union of multiple perturbations but this benefit is obtained at the\nexpense of a significant (up to $10\\times$) increase in training complexity\nover single-attack $\\ell_\\infty$ AT. In this work, we expand the capabilities\nof widely popular single-attack $\\ell_\\infty$ AT frameworks to provide\nrobustness to the union of ($\\ell_\\infty, \\ell_2, \\ell_1$) perturbations while\npreserving their training efficiency. Our technique, referred to as Shaped\nNoise Augmented Processing (SNAP), exploits a well-established byproduct of\nsingle-attack AT frameworks -- the reduction in the curvature of the decision\nboundary of networks. SNAP prepends a given deep net with a shaped noise\naugmentation layer whose distribution is learned along with network parameters\nusing any standard single-attack AT. As a result, SNAP enhances adversarial\naccuracy of ResNet-18 on CIFAR-10 against the union of ($\\ell_\\infty, \\ell_2,\n\\ell_1$) perturbations by 14%-to-20% for four state-of-the-art (SOTA)\nsingle-attack $\\ell_\\infty$ AT frameworks, and, for the first time, establishes\na benchmark for ResNet-50 and ResNet-101 on ImageNet.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 05:18:42 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 23:12:47 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 22:36:08 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Patil", "Ameya D.", ""], ["Tuttle", "Michael", ""], ["Schwing", "Alexander G.", ""], ["Shanbhag", "Naresh R.", ""]]}, {"id": "2105.14742", "submitter": "Dominik Linzner", "authors": "Dominik Linzner and Heinz Koeppl", "title": "Active Learning of Continuous-time Bayesian Networks through\n  Interventions", "comments": "Accepted at ICML2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning structures and parameters of\nContinuous-time Bayesian Networks (CTBNs) from time-course data under minimal\nexperimental resources. In practice, the cost of generating experimental data\nposes a bottleneck, especially in the natural and social sciences. A popular\napproach to overcome this is Bayesian optimal experimental design (BOED).\nHowever, BOED becomes infeasible in high-dimensional settings, as it involves\nintegration over all possible experimental outcomes. We propose a novel\ncriterion for experimental design based on a variational approximation of the\nexpected information gain. We show that for CTBNs, a semi-analytical expression\nfor this criterion can be calculated for structure and parameter learning. By\ndoing so, we can replace sampling over experimental outcomes by solving the\nCTBNs master-equation, for which scalable approximations exist. This alleviates\nthe computational burden of sampling possible experimental outcomes in\nhigh-dimensions. We employ this framework in order to recommend interventional\nsequences. In this context, we extend the CTBN model to conditional CTBNs in\norder to incorporate interventions. We demonstrate the performance of our\ncriterion on synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 07:13:50 GMT"}, {"version": "v2", "created": "Fri, 11 Jun 2021 06:10:06 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Linzner", "Dominik", ""], ["Koeppl", "Heinz", ""]]}, {"id": "2105.14835", "submitter": "Christoph Hertrich", "authors": "Christoph Hertrich, Amitabh Basu, Marco Di Summa, Martin Skutella", "title": "Towards Lower Bounds on the Depth of ReLU Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DM cs.NE math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We contribute to a better understanding of the class of functions that is\nrepresented by a neural network with ReLU activations and a given architecture.\nUsing techniques from mixed-integer optimization, polyhedral theory, and\ntropical geometry, we provide a mathematical counterbalance to the universal\napproximation theorems which suggest that a single hidden layer is sufficient\nfor learning tasks. In particular, we investigate whether the class of exactly\nrepresentable functions strictly increases by adding more layers (with no\nrestrictions on size). This problem has potential impact on algorithmic and\nstatistical aspects because of the insight it provides into the class of\nfunctions represented by neural hypothesis classes. However, to the best of our\nknowledge, this question has not been investigated in the neural network\nliterature. We also present upper bounds on the sizes of neural networks\nrequired to represent functions in these neural hypothesis classes.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 09:49:14 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Hertrich", "Christoph", ""], ["Basu", "Amitabh", ""], ["Di Summa", "Marco", ""], ["Skutella", "Martin", ""]]}, {"id": "2105.14866", "submitter": "Alexander Camuto", "authors": "Alexander Camuto, Matthew Willetts", "title": "Variational Autoencoders: A Harmonic Perspective", "comments": "18 pages including Appendix, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we study Variational Autoencoders (VAEs) from the perspective of\nharmonic analysis. By viewing a VAE's latent space as a Gaussian Space, a\nvariety of measure space, we derive a series of results that show that the\nencoder variance of a VAE controls the frequency content of the functions\nparameterised by the VAE encoder and decoder neural networks. In particular we\ndemonstrate that larger encoder variances reduce the high frequency content of\nthese functions. Our analysis allows us to show that increasing this variance\neffectively induces a soft Lipschitz constraint on the decoder network of a\nVAE, which is a core contributor to the adversarial robustness of VAEs. We\nfurther demonstrate that adding Gaussian noise to the input of a VAE allows us\nto more finely control the frequency content and the Lipschitz constant of the\nVAE encoder networks. To support our theoretical analysis we run experiments\nwith VAEs with small fully-connected neural networks and with larger\nconvolutional networks, demonstrating empirically that our theory holds for a\nvariety of neural network architectures.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 10:39:25 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 08:59:58 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 19:09:44 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Camuto", "Alexander", ""], ["Willetts", "Matthew", ""]]}, {"id": "2105.14876", "submitter": "Nestor Cabello", "authors": "Nestor Cabello, Elham Naghizade, Jianzhong Qi, Lars Kulik", "title": "Fast, Accurate and Interpretable Time Series Classification Through\n  Randomization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series classification (TSC) aims to predict the class label of a given\ntime series, which is critical to a rich set of application areas such as\neconomics and medicine. State-of-the-art TSC methods have mostly focused on\nclassification accuracy and efficiency, without considering the\ninterpretability of their classifications, which is an important property\nrequired by modern applications such as appliance modeling and legislation such\nas the European General Data Protection Regulation. To address this gap, we\npropose a novel TSC method - the Randomized-Supervised Time Series Forest\n(r-STSF). r-STSF is highly efficient, achieves state-of-the-art classification\naccuracy and enables interpretability. r-STSF takes an efficient interval-based\napproach to classify time series according to aggregate values of\ndiscriminatory sub-series (intervals). To achieve state-of-the-art accuracy,\nr-STSF builds an ensemble of randomized trees using the discriminatory\nsub-series. It uses four time series representations, nine aggregation\nfunctions and a supervised binary-inspired search combined with a feature\nranking metric to identify highly discriminatory sub-series. The discriminatory\nsub-series enable interpretable classifications. Experiments on extensive\ndatasets show that r-STSF achieves state-of-the-art accuracy while being orders\nof magnitude faster than most existing TSC methods. It is the only classifier\nfrom the state-of-the-art group that enables interpretability. Our findings\nalso highlight that r-STSF is the best TSC method when classifying complex time\nseries datasets.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 10:59:11 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Cabello", "Nestor", ""], ["Naghizade", "Elham", ""], ["Qi", "Jianzhong", ""], ["Kulik", "Lars", ""]]}, {"id": "2105.14890", "submitter": "Kulin Shah", "authors": "Kulin Shah, Pooja Gupta, Amit Deshpande, Chiranjib Bhattacharyya", "title": "Rawlsian Fair Adaptation of Deep Learning Classifiers", "comments": "24 figures, 19 figures", "journal-ref": null, "doi": "10.1145/3461702.3462592", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Group-fairness in classification aims for equality of a predictive utility\nacross different sensitive sub-populations, e.g., race or gender. Equality or\nnear-equality constraints in group-fairness often worsen not only the aggregate\nutility but also the utility for the least advantaged sub-population. In this\npaper, we apply the principles of Pareto-efficiency and least-difference to the\nutility being accuracy, as an illustrative example, and arrive at the Rawls\nclassifier that minimizes the error rate on the worst-off sensitive\nsub-population. Our mathematical characterization shows that the Rawls\nclassifier uniformly applies a threshold to an ideal score of features, in the\nspirit of fair equality of opportunity. In practice, such a score or a feature\nrepresentation is often computed by a black-box model that has been useful but\nunfair. Our second contribution is practical Rawlsian fair adaptation of any\ngiven black-box deep learning model, without changing the score or feature\nrepresentation it computes. Given any score function or feature representation\nand only its second-order statistics on the sensitive sub-populations, we seek\na threshold classifier on the given score or a linear threshold classifier on\nthe given feature representation that achieves the Rawls error rate restricted\nto this hypothesis class. Our technical contribution is to formulate the above\nproblems using ambiguous chance constraints, and to provide efficient\nalgorithms for Rawlsian fair adaptation, along with provable upper bounds on\nthe Rawls error rate. Our empirical results show significant improvement over\nstate-of-the-art group-fair algorithms, even without retraining for fairness.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 11:31:30 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Shah", "Kulin", ""], ["Gupta", "Pooja", ""], ["Deshpande", "Amit", ""], ["Bhattacharyya", "Chiranjib", ""]]}, {"id": "2105.14900", "submitter": "Paavo Parmas", "authors": "Paavo Parmas and Masashi Sugiyama", "title": "A unified view of likelihood ratio and reparameterization gradients", "comments": "AISTATS2021; Earlier paper was split in two (arXiv:1910.06419). Refer\n  to the current paper for the unified view, but see the earlier paper for\n  discussion on an importance sampling technique", "journal-ref": "In International Conference on Artificial Intelligence and\n  Statistics (pp. 4078-4086). PMLR (2021, March)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Reparameterization (RP) and likelihood ratio (LR) gradient estimators are\nused to estimate gradients of expectations throughout machine learning and\nreinforcement learning; however, they are usually explained as simple\nmathematical tricks, with no insight into their nature. We use a first\nprinciples approach to explain that LR and RP are alternative methods of\nkeeping track of the movement of probability mass, and the two are connected\nvia the divergence theorem. Moreover, we show that the space of all possible\nestimators combining LR and RP can be completely parameterized by a flow field\n$u(x)$ and an importance sampling distribution $q(x)$. We prove that there\ncannot exist a single-sample estimator of this type outside our characterized\nspace, thus, clarifying where we should be searching for better Monte Carlo\ngradient estimators.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 11:53:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Parmas", "Paavo", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2105.14957", "submitter": "Chancellor Johnstone", "authors": "Chancellor Johnstone", "title": "Conformal Uncertainty Sets for Robust Optimization", "comments": "20 pages, 8 figures, submitted to COPA 2021, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-making under uncertainty is hugely important for any decisions\nsensitive to perturbations in observed data. One method of incorporating\nuncertainty into making optimal decisions is through robust optimization, which\nminimizes the worst-case scenario over some uncertainty set. We explore\nMahalanobis distance as a novel function for multi-target regression and the\nconstruction of joint prediction regions. We also connect conformal prediction\nregions to robust optimization, providing finite sample valid and conservative\nuncertainty sets, aptly named conformal uncertainty sets. We compare the\ncoverage and efficiency of the conformal prediction regions generated with\nMahalanobis distance to other conformal prediction regions. We also construct a\nsmall robust optimization example to compare conformal uncertainty sets to\nthose constructed under the assumption of normality.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 13:42:24 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Johnstone", "Chancellor", ""]]}, {"id": "2105.14989", "submitter": "Ziping Xu", "authors": "Ziping Xu and Ambuj Tewari", "title": "Representation Learning Beyond Linear Prediction Functions", "comments": "1 Figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent papers on the theory of representation learning has shown the\nimportance of a quantity called diversity when generalizing from a set of\nsource tasks to a target task. Most of these papers assume that the function\nmapping shared representations to predictions is linear, for both source and\ntarget tasks. In practice, researchers in deep learning use different numbers\nof extra layers following the pretrained model based on the difficulty of the\nnew task. This motivates us to ask whether diversity can be achieved when\nsource tasks and the target task use different prediction function spaces\nbeyond linear functions. We show that diversity holds even if the target task\nuses a neural network with multiple layers, as long as source tasks use linear\nfunctions. If source tasks use nonlinear prediction functions, we provide a\nnegative result by showing that depth-1 neural networks with ReLu activation\nfunction need exponentially many source tasks to achieve diversity. For a\ngeneral function class, we find that eluder dimension gives a lower bound on\nthe number of tasks required for diversity. Our theoretical results imply that\nsimpler tasks generalize better. Though our theoretical results are shown for\nthe global minimizer of empirical risks, their qualitative predictions still\nhold true for gradient-based optimization algorithms as verified by our\nsimulations on deep neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 14:21:52 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Xu", "Ziping", ""], ["Tewari", "Ambuj", ""]]}, {"id": "2105.15004", "submitter": "Florent Krzakala", "authors": "Hugo Cui, Bruno Loureiro, Florent Krzakala, Lenka Zdeborov\\'a", "title": "Generalization Error Rates in Kernel Regression: The Crossover from the\n  Noiseless to Noisy Regime", "comments": "22 pages, 10 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this manuscript we consider Kernel Ridge Regression (KRR) under the\nGaussian design. Exponents for the decay of the excess generalization error of\nKRR have been reported in various works under the assumption of power-law decay\nof eigenvalues of the features co-variance. These decays were, however,\nprovided for sizeably different setups, namely in the noiseless case with\nconstant regularization and in the noisy optimally regularized case.\nIntermediary settings have been left substantially uncharted. In this work, we\nunify and extend this line of work, providing characterization of all regimes\nand excess error decay rates that can be observed in terms of the interplay of\nnoise and regularization. In particular, we show the existence of a transition\nin the noisy setting between the noiseless exponents to its noisy values as the\nsample complexity is increased. Finally, we illustrate how this crossover can\nalso be observed on real data sets.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 14:39:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Cui", "Hugo", ""], ["Loureiro", "Bruno", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "2105.15069", "submitter": "Alex Nowak-Vila", "authors": "Alex Nowak-Vila, Alessandro Rudi, Francis Bach", "title": "Max-Margin is Dead, Long Live Max-Margin!", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The foundational concept of Max-Margin in machine learning is ill-posed for\noutput spaces with more than two labels such as in structured prediction. In\nthis paper, we show that the Max-Margin loss can only be consistent to the\nclassification task under highly restrictive assumptions on the discrete loss\nmeasuring the error between outputs. These conditions are satisfied by\ndistances defined in tree graphs, for which we prove consistency, thus being\nthe first losses shown to be consistent for Max-Margin beyond the binary\nsetting. We finally address these limitations by correcting the concept of\nMax-Margin and introducing the Restricted-Max-Margin, where the maximization of\nthe loss-augmented scores is maintained, but performed over a subset of the\noriginal domain. The resulting loss is also a generalization of the binary\nsupport vector machine and it is consistent under milder conditions on the\ndiscrete loss.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 15:55:52 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 07:52:27 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Nowak-Vila", "Alex", ""], ["Rudi", "Alessandro", ""], ["Bach", "Francis", ""]]}, {"id": "2105.15081", "submitter": "Alexander Wein", "authors": "Cheng Mao, Alexander S. Wein", "title": "Optimal Spectral Recovery of a Planted Vector in a Subspace", "comments": "47 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovering a planted vector $v$ in an $n$-dimensional random subspace of\n$\\mathbb{R}^N$ is a generic task related to many problems in machine learning\nand statistics, such as dictionary learning, subspace recovery, and principal\ncomponent analysis. In this work, we study computationally efficient estimation\nand detection of a planted vector $v$ whose $\\ell_4$ norm differs from that of\na Gaussian vector with the same $\\ell_2$ norm. For instance, in the special\ncase of an $N \\rho$-sparse vector $v$ with Rademacher nonzero entries, our\nresults include the following:\n  (1) We give an improved analysis of (a slight variant of) the spectral method\nproposed by Hopkins, Schramm, Shi, and Steurer, showing that it approximately\nrecovers $v$ with high probability in the regime $n \\rho \\ll \\sqrt{N}$. In\ncontrast, previous work required either $\\rho \\ll 1/\\sqrt{n}$ or $n \\sqrt{\\rho}\n\\lesssim \\sqrt{N}$ for polynomial-time recovery. Our result subsumes both of\nthese conditions (up to logarithmic factors) and also treats the dense case\n$\\rho = 1$ which was not previously considered.\n  (2) Akin to $\\ell_\\infty$ bounds for eigenvector perturbation, we establish\nan entrywise error bound for the spectral estimator via a leave-one-out\nanalysis, from which it follows that thresholding recovers $v$ exactly.\n  (3) We study the associated detection problem and show that in the regime $n\n\\rho \\gg \\sqrt{N}$, any spectral method from a large class (and more generally,\nany low-degree polynomial of the input) fails to detect the planted vector.\nThis establishes optimality of our upper bounds and offers evidence that no\npolynomial-time algorithm can succeed when $n \\rho \\gg \\sqrt{N}$.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 16:10:49 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Mao", "Cheng", ""], ["Wein", "Alexander S.", ""]]}, {"id": "2105.15134", "submitter": "Zixin Wen", "authors": "Zixin Wen, Yuanzhi Li", "title": "Toward Understanding the Feature Learning Process of Self-supervised\n  Contrastive Learning", "comments": "V3 corrected related works. Accepted to ICML2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can neural networks trained by contrastive learning extract features from\nthe unlabeled data? Why does contrastive learning usually need much stronger\ndata augmentations than supervised learning to ensure good representations?\nThese questions involve both the optimization and statistical aspects of deep\nlearning, but can hardly be answered by analyzing supervised learning, where\nthe target functions are the highest pursuit. Indeed, in self-supervised\nlearning, it is inevitable to relate to the optimization/generalization of\nneural networks to how they can encode the latent structures in the data, which\nwe refer to as the feature learning process.\n  In this work, we formally study how contrastive learning learns the feature\nrepresentations for neural networks by analyzing its feature learning process.\nWe consider the case where our data are comprised of two types of features: the\nmore semantically aligned sparse features which we want to learn from, and the\nother dense features we want to avoid. Theoretically, we prove that contrastive\nlearning using $\\mathbf{ReLU}$ networks provably learns the desired sparse\nfeatures if proper augmentations are adopted. We present an underlying\nprinciple called $\\textbf{feature decoupling}$ to explain the effects of\naugmentations, where we theoretically characterize how augmentations can reduce\nthe correlations of dense features between positive samples while keeping the\ncorrelations of sparse features intact, thereby forcing the neural networks to\nlearn from the self-supervision of sparse features. Empirically, we verified\nthat the feature decoupling principle matches the underlying mechanism of\ncontrastive learning in practice.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 16:42:09 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 10:05:33 GMT"}, {"version": "v3", "created": "Mon, 5 Jul 2021 17:48:01 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Wen", "Zixin", ""], ["Li", "Yuanzhi", ""]]}, {"id": "2105.15183", "submitter": "Mathieu Blondel", "authors": "Mathieu Blondel, Quentin Berthet, Marco Cuturi, Roy Frostig, Stephan\n  Hoyer, Felipe Llinares-L\\'opez, Fabian Pedregosa, Jean-Philippe Vert", "title": "Efficient and Modular Implicit Differentiation", "comments": "V2: some corrections and link to software", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic differentiation (autodiff) has revolutionized machine learning. It\nallows expressing complex computations by composing elementary ones in creative\nways and removes the burden of computing their derivatives by hand. More\nrecently, differentiation of optimization problem solutions has attracted\nwidespread attention with applications such as optimization as a layer, and in\nbi-level problems such as hyper-parameter optimization and meta-learning.\nHowever, the formulas for these derivatives often involve case-by-case tedious\nmathematical derivations. In this paper, we propose a unified, efficient and\nmodular approach for implicit differentiation of optimization problems. In our\napproach, the user defines (in Python in the case of our implementation) a\nfunction $F$ capturing the optimality conditions of the problem to be\ndifferentiated. Once this is done, we leverage autodiff of $F$ and implicit\ndifferentiation to automatically differentiate the optimization problem. Our\napproach thus combines the benefits of implicit differentiation and autodiff.\nIt is efficient as it can be added on top of any state-of-the-art solver and\nmodular as the optimality condition specification is decoupled from the\nimplicit differentiation mechanism. We show that seemingly simple principles\nallow to recover many recently proposed implicit differentiation methods and\ncreate new ones easily. We demonstrate the ease of formulating and solving\nbi-level optimization problems using our framework. We also showcase an\napplication to the sensitivity analysis of molecular dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 17:45:58 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 21:40:01 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Blondel", "Mathieu", ""], ["Berthet", "Quentin", ""], ["Cuturi", "Marco", ""], ["Frostig", "Roy", ""], ["Hoyer", "Stephan", ""], ["Llinares-L\u00f3pez", "Felipe", ""], ["Pedregosa", "Fabian", ""], ["Vert", "Jean-Philippe", ""]]}, {"id": "2105.15197", "submitter": "Rahul Singh", "authors": "Victor Chernozhukov, Whitney K. Newey, Rahul Singh", "title": "A Simple and General Debiased Machine Learning Theorem with Finite\n  Sample Guarantees", "comments": "25 pages. arXiv admin note: text overlap with arXiv:2102.11076", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Debiased machine learning is a meta algorithm based on bias correction and\nsample splitting to calculate confidence intervals for functionals (i.e. scalar\nsummaries) of machine learning algorithms. For example, an analyst may desire\nthe confidence interval for a treatment effect estimated with a neural network.\nWe provide a nonasymptotic debiased machine learning theorem that encompasses\nany global or local functional of any machine learning algorithm that satisfies\na few simple, interpretable conditions. Formally, we prove consistency,\nGaussian approximation, and semiparametric efficiency by finite sample\narguments. The rate of convergence is root-n for global functionals, and it\ndegrades gracefully for local functionals. Our results culminate in a simple\nset of conditions that an analyst can use to translate modern learning theory\nrates into traditional statistical inference. The conditions reveal a new\ndouble robustness property for ill posed inverse problems.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 17:57:02 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chernozhukov", "Victor", ""], ["Newey", "Whitney K.", ""], ["Singh", "Rahul", ""]]}]