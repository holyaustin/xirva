[{"id": "1907.00020", "submitter": "Mikhail Yurochkin", "authors": "Mikhail Yurochkin, Amanda Bower and Yuekai Sun", "title": "Training individually fair ML models with Sensitive Subspace Robustness", "comments": "ICLR 2020 (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider training machine learning models that are fair in the sense that\ntheir performance is invariant under certain sensitive perturbations to the\ninputs. For example, the performance of a resume screening system should be\ninvariant under changes to the gender and/or ethnicity of the applicant. We\nformalize this notion of algorithmic fairness as a variant of individual\nfairness and develop a distributionally robust optimization approach to enforce\nit during training. We also demonstrate the effectiveness of the approach on\ntwo ML tasks that are susceptible to gender and racial biases.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 18:11:25 GMT"}, {"version": "v2", "created": "Fri, 13 Mar 2020 05:25:24 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Yurochkin", "Mikhail", ""], ["Bower", "Amanda", ""], ["Sun", "Yuekai", ""]]}, {"id": "1907.00025", "submitter": "Carlo Vittorio Cannistraci", "authors": "Alessandro Muscoloni and Carlo Vittorio Cannistraci", "title": "Angular separability of data clusters or network communities in\n  geometrical space and its relevance to hyperbolic embedding", "comments": "arXiv admin note: text overlap with arXiv:1802.01183", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of 'big data' characterized by high-dimensionality such as word\nvectors and complex networks requires often their representation in a\ngeometrical space by embedding. Recent developments in machine learning and\nnetwork geometry have pointed out the hyperbolic space as a useful framework\nfor the representation of this data derived by real complex physical systems.\nIn the hyperbolic space, the radial coordinate of the nodes characterizes their\nhierarchy, whereas the angular distance between them represents their\nsimilarity. Several studies have highlighted the relationship between the\nangular coordinates of the nodes embedded in the hyperbolic space and the\ncommunity metadata available. However, such analyses have been often limited to\na visual or qualitative assessment. Here, we introduce the angular separation\nindex (ASI), to quantitatively evaluate the separation of node network\ncommunities or data clusters over the angular coordinates of a geometrical\nspace. ASI is particularly useful in the hyperbolic space - where it is\nextensively tested along this study - but can be used in general for any\nassessment of angular separation regardless of the adopted geometry. ASI is\nproposed together with an exact test statistic based on a uniformly random null\nmodel to assess the statistical significance of the separation. We show that\nASI allows to discover two significant phenomena in network geometry. The first\nis that the increase of temperature in 2D hyperbolic network generative models,\nnot only reduces the network clustering but also induces a 'dimensionality\njump' of the network to dimensions higher than two. The second is that ASI can\nbe successfully applied to detect the intrinsic dimensionality of network\nstructures that grow in a hidden geometrical space.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 18:23:30 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Muscoloni", "Alessandro", ""], ["Cannistraci", "Carlo Vittorio", ""]]}, {"id": "1907.00030", "submitter": "Rares-Darius Buhai", "authors": "Rares-Darius Buhai, Yoni Halpern, Yoon Kim, Andrej Risteski, David\n  Sontag", "title": "Empirical Study of the Benefits of Overparameterization in Learning\n  Latent Variable Models", "comments": "22 pages, to appear at ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most surprising and exciting discoveries in supervised learning\nwas the benefit of overparameterization (i.e. training a very large model) to\nimproving the optimization landscape of a problem, with minimal effect on\nstatistical performance (i.e. generalization). In contrast, unsupervised\nsettings have been under-explored, despite the fact that it was observed that\noverparameterization can be helpful as early as Dasgupta & Schulman (2007). We\nperform an empirical study of different aspects of overparameterization in\nunsupervised learning of latent variable models via synthetic and\nsemi-synthetic experiments. We discuss benefits to different metrics of success\n(recovering the parameters of the ground-truth model, held-out log-likelihood),\nsensitivity to variations of the training algorithm, and behavior as the amount\nof overparameterization increases. We find that across a variety of models\n(noisy-OR networks, sparse coding, probabilistic context-free grammars) and\ntraining algorithms (variational inference, alternating minimization,\nexpectation-maximization), overparameterization can significantly increase the\nnumber of ground truth latent variables recovered.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 18:31:52 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 13:41:15 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 06:43:28 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Buhai", "Rares-Darius", ""], ["Halpern", "Yoni", ""], ["Kim", "Yoon", ""], ["Risteski", "Andrej", ""], ["Sontag", "David", ""]]}, {"id": "1907.00031", "submitter": "Vaden Masrani", "authors": "Vaden Masrani, Tuan Anh Le and Frank Wood", "title": "The Thermodynamic Variational Objective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the thermodynamic variational objective (TVO) for learning in\nboth continuous and discrete deep generative models. The TVO arises from a key\nconnection between variational inference and thermodynamic integration that\nresults in a tighter lower bound to the log marginal likelihood than the\nstandard variational variational evidence lower bound (ELBO) while remaining as\nbroadly applicable. We provide a computationally efficient gradient estimator\nfor the TVO that applies to continuous, discrete, and non-reparameterizable\ndistributions and show that the objective functions used in variational\ninference, variational autoencoders, wake sleep, and inference compilation are\nall special cases of the TVO. We use the TVO to learn both discrete and\ncontinuous deep generative models and empirically demonstrate state of the art\nmodel and inference network learning.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 18:33:05 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 18:45:23 GMT"}, {"version": "v3", "created": "Thu, 31 Oct 2019 16:43:05 GMT"}, {"version": "v4", "created": "Tue, 26 Nov 2019 21:13:25 GMT"}, {"version": "v5", "created": "Wed, 7 Apr 2021 19:25:48 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Masrani", "Vaden", ""], ["Le", "Tuan Anh", ""], ["Wood", "Frank", ""]]}, {"id": "1907.00032", "submitter": "Jos\\'e Camacho", "authors": "Jos\\'e Camacho, Evrim Acar, Morten A. Rasmussen, Rasmus Bro", "title": "Cross-product Penalized Component Analysis (XCAN)", "comments": null, "journal-ref": "Chemometrics and Intelligent Laboratory Systems, 2020, 203:\n  104038-", "doi": "10.1016/j.chemolab.2020.104038.", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization methods are extensively employed to understand complex\ndata. In this paper, we introduce the cross-product penalized component\nanalysis (XCAN), a sparse matrix factorization based on the optimization of a\nloss function that allows a trade-off between variance maximization and\nstructural preservation. The approach is based on previous developments,\nnotably (i) the Sparse Principal Component Analysis (SPCA) framework based on\nthe LASSO, (ii) extensions of SPCA to constrain both modes of the\nfactorization, like co-clustering or the Penalized Matrix Decomposition (PMD),\nand (iii) the Group-wise Principal Component Analysis (GPCA) method. The result\nis a flexible modeling approach that can be used for data exploration in a\nlarge variety of problems. We demonstrate its use with applications from\ndifferent disciplines.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 18:33:43 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Camacho", "Jos\u00e9", ""], ["Acar", "Evrim", ""], ["Rasmussen", "Morten A.", ""], ["Bro", "Rasmus", ""]]}, {"id": "1907.00038", "submitter": "Afshin Rostamizadeh", "authors": "Jean-Fran\\c{c}ois Kagy, Tolga Kayadelen, Ji Ma, Afshin Rostamizadeh,\n  Jana Strnadova", "title": "The Practical Challenges of Active Learning: Lessons Learned from Live\n  Experimentation", "comments": "Presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We tested in a live setting the use of active learning for selecting text\nsentences for human annotations used in training a Thai segmentation machine\nlearning model. In our study, two concurrent annotated samples were\nconstructed, one through random sampling of sentences from a text corpus, and\nthe other through model-based scoring and ranking of sentences from the same\ncorpus. In the course of the experiment, we observed the effect of significant\nchanges to the learning environment which are likely to occur in real-world\nlearning tasks. We describe how our active learning strategy interacted with\nthese events and discuss other practical challenges encountered in using active\nlearning in the live setting.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 18:56:20 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Kagy", "Jean-Fran\u00e7ois", ""], ["Kayadelen", "Tolga", ""], ["Ma", "Ji", ""], ["Rostamizadeh", "Afshin", ""], ["Strnadova", "Jana", ""]]}, {"id": "1907.00063", "submitter": "Tammo Rukat", "authors": "Tammo Rukat, Christopher Yau", "title": "Bayesian Nonparametric Boolean Factor Models", "comments": "Presented at the 2018 NeurIPS Workshop on Bayesian Nonparametrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build upon probabilistic models for Boolean Matrix and Boolean Tensor\nfactorisation that have recently been shown to solve these problems with\nunprecedented accuracy and to enable posterior inference to scale to Billions\nof observation. Here, we lift the restriction of a pre-specified number of\nlatent dimensions by introducing an Indian Buffet Process prior over factor\nmatrices. Not only does the full factor-conditional take a computationally\nconvenient form due to the logical dependencies in the model, but also the\nposterior over the number of non-zero latent dimensions is remarkably simple.\nIt amounts to counting the number false and true negative predictions, whereas\npositive predictions can be ignored. This constitutes a very transparent\nexample of sampling-based posterior inference with an IBP prior and,\nimportantly, lets us maintain extremely efficient inference. We discuss\napplications to simulated data, as well as to a real world data matrix with 6\nMillion entries.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 20:28:18 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Rukat", "Tammo", ""], ["Yau", "Christopher", ""]]}, {"id": "1907.00089", "submitter": "Ramin Mohammadi", "authors": "Ramin Mohammadi, Sarthak Jain, Stephen Agboola, Ramya Palacholla,\n  Sagar Kamarthi, Byron C. Wallace", "title": "Learning to Identify Patients at Risk of Uncontrolled Hypertension Using\n  Electronic Health Records Data", "comments": "Accepted at The AMIA informatics summit 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypertension is a major risk factor for stroke, cardiovascular disease, and\nend-stage renal disease, and its prevalence is expected to rise dramatically.\nEffective hypertension management is thus critical. A particular priority is\ndecreasing the incidence of uncontrolled hypertension. Early identification of\npatients at risk for uncontrolled hypertension would allow targeted use of\npersonalized, proactive treatments. We develop machine learning models\n(logistic regression and recurrent neural networks) to stratify patients with\nrespect to the risk of exhibiting uncontrolled hypertension within the coming\nthree-month period. We trained and tested models using EHR data from 14,407 and\n3,009 patients, respectively. The best model achieved an AUROC of 0.719,\noutperforming the simple, competitive baseline of relying prediction based on\nthe last BP measure alone (0.634). Perhaps surprisingly, recurrent neural\nnetworks did not outperform a simple logistic regression for this task,\nsuggesting that linear models should be included as strong baselines for\npredictive tasks using EHR\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 21:33:40 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Mohammadi", "Ramin", ""], ["Jain", "Sarthak", ""], ["Agboola", "Stephen", ""], ["Palacholla", "Ramya", ""], ["Kamarthi", "Sagar", ""], ["Wallace", "Byron C.", ""]]}, {"id": "1907.00103", "submitter": "Matthew Streeter", "authors": "Matthew Streeter", "title": "Learning Effective Loss Functions Efficiently", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a loss function which, when minimized\nover a training dataset, yields a model that approximately minimizes a\nvalidation error metric. Though learning an optimal loss function is NP-hard,\nwe present an anytime algorithm that is asymptotically optimal in the worst\ncase, and is provably efficient in an idealized \"easy\" case. Experimentally, we\nshow that this algorithm can be used to tune loss function hyperparameters\norders of magnitude faster than state-of-the-art alternatives. We also show\nthat our algorithm can be used to learn novel and effective loss functions\non-the-fly during training.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 22:35:17 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Streeter", "Matthew", ""]]}, {"id": "1907.00107", "submitter": "Ahmadreza Momeni", "authors": "Yonatan Gur and Ahmadreza Momeni", "title": "Adaptive Sequential Experiments with Unknown Information Arrival\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential experiments are often characterized by an exploration-exploitation\ntradeoff that is captured by the multi-armed bandit (MAB) framework. This\nframework has been studied and applied, typically when at each time period\nfeedback is received only on the action that was selected at that period.\nHowever, in many practical settings additional data may become available\nbetween decision epochs. We introduce a generalized MAB formulation, which\nconsiders a broad class of distributions that are informative about mean\nrewards, and allows observations from these distributions to arrive according\nto an arbitrary and a priori unknown arrival process. When it is known how to\nmap auxiliary data to reward estimates, by obtaining matching lower and upper\nbounds we characterize a spectrum of minimax complexities for this class of\nproblems as a function of the information arrival process, which captures how\nsalient characteristics of this process impact achievable performance. In terms\nof achieving optimal performance, we establish that upper confidence bound and\nposterior sampling policies possess natural robustness with respect to the\ninformation arrival process without any adjustments, which uncovers a novel\nproperty of these popular policies and further lends credence to their appeal.\nWhen the mappings connecting auxiliary data and rewards are a priori unknown,\nwe characterize necessary and sufficient conditions under which auxiliary\ninformation allows performance improvement. We devise a new policy that is\nbased on two different upper confidence bounds (one that accounts for auxiliary\nobservation and one that does not) and establish the near-optimality of this\npolicy. We use data from a large media site to analyze the value that may be\ncaptured in practice by leveraging auxiliary data for designing content\nrecommendations.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 22:40:47 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 00:57:48 GMT"}, {"version": "v3", "created": "Thu, 9 Apr 2020 21:29:46 GMT"}, {"version": "v4", "created": "Wed, 11 Nov 2020 07:18:43 GMT"}, {"version": "v5", "created": "Fri, 13 Nov 2020 22:39:03 GMT"}, {"version": "v6", "created": "Fri, 18 Dec 2020 19:13:30 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Gur", "Yonatan", ""], ["Momeni", "Ahmadreza", ""]]}, {"id": "1907.00109", "submitter": "Alessandro Ferrero Mr.", "authors": "Alessandro Ferrero, Shireen Elhabian, Ross Whitaker", "title": "SetGAN: Improving the stability and diversity of generative models\n  through a permutation invariant architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) have proven effective in modeling\ndistributions of high-dimensional data. However, their training instability is\na well-known hindrance to convergence, which results in practical challenges in\ntheir applications to novel data. Furthermore, even when convergence is\nreached, GANs can be affected by mode collapse, a phenomenon for which the\ngenerator learns to model only a small part of the target distribution,\ndisregarding the vast majority of the data manifold or distribution. This paper\naddresses these challenges by introducing SetGAN, an adversarial architecture\nthat processes sets of generated and real samples, and discriminates between\nthe origins of these sets (i.e., training versus generated data) in a flexible,\npermutation invariant manner. We also propose a new metric to quantitatively\nevaluate GANs that does not require previous knowledge of the application,\napart from the data itself. Using the new metric, in conjunction with the\nstate-of-the-art evaluation methods, we show that the proposed architecture,\nwhen compared with GAN variants stemming from similar strategies, produces more\naccurate models of the input data in a way that is also less sensitive to\nhyperparameter settings.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 22:43:02 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 21:36:56 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Ferrero", "Alessandro", ""], ["Elhabian", "Shireen", ""], ["Whitaker", "Ross", ""]]}, {"id": "1907.00113", "submitter": "Ziwei Zhu", "authors": "Ziwei Zhu, Xudong Li, Mengdi Wang, Anru Zhang", "title": "Learning Markov models via low-rank optimization", "comments": "52 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:1804.00795", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling unknown systems from data is a precursor of system optimization and\nsequential decision making. In this paper, we focus on learning a Markov model\nfrom a single trajectory of states. Suppose that the transition model has a\nsmall rank despite of having a large state space, meaning that the system\nadmits a low-dimensional latent structure. We show that one can estimate the\nfull transition model accurately using a trajectory of length that is\nproportional to the total number of states. We propose two maximum likelihood\nestimation methods: a convex approach with nuclear-norm regularization and a\nnonconvex approach with rank constraint. We explicitly derive the statistical\nrates of both estimators in terms of the Kullback-Leiber divergence and the\n$\\ell_2$ error and also establish a minimax lower bound to assess the tightness\nof these rates. For computing the nonconvex estimator, we develop a novel DC\n(difference of convex function) programming algorithm that starts with the\nconvex M-estimator and then successively refines the solution till convergence.\nEmpirical experiments demonstrate consistent superiority of the nonconvex\nestimator over the convex one.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 22:58:26 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 05:52:34 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Zhu", "Ziwei", ""], ["Li", "Xudong", ""], ["Wang", "Mengdi", ""], ["Zhang", "Anru", ""]]}, {"id": "1907.00139", "submitter": "Anthony Degleris", "authors": "Anthony Degleris and Ben Antin and Surya Ganguli and Alex H Williams", "title": "Fast Convolutive Nonnegative Matrix Factorization Through Coordinate and\n  Block Coordinate Updates", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying recurring patterns in high-dimensional time series data is an\nimportant problem in many scientific domains. A popular model to achieve this\nis convolutive nonnegative matrix factorization (CNMF), which extends classic\nnonnegative matrix factorization (NMF) to extract short-lived temporal motifs\nfrom a long time series. Prior work has typically fit this model by\nmultiplicative parameter updates---an approach widely considered to be\nsuboptimal for NMF, especially in large-scale data applications. Here, we\ndescribe how to extend two popular and computationally scalable NMF\nalgorithms---Hierarchical Alternating Least Squares (HALS) and Alternatining\nNonnegative Least Squares (ANLS)---for the CNMF model. Both methods demonstrate\nperformance advantages over multiplicative updates on large-scale synthetic and\nreal world data.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 03:53:09 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Degleris", "Anthony", ""], ["Antin", "Ben", ""], ["Ganguli", "Surya", ""], ["Williams", "Alex H", ""]]}, {"id": "1907.00141", "submitter": "Alireza Heidari", "authors": "Alireza Heidari, Ihab F. Ilyas, Theodoros Rekatsinas", "title": "Approximate Inference in Structured Instances with Noisy Categorical\n  Observations", "comments": "UAI 2019, 33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of recovering the latent ground truth labeling of a\nstructured instance with categorical random variables in the presence of noisy\nobservations. We present a new approximate algorithm for graphs with\ncategorical variables that achieves low Hamming error in the presence of noisy\nvertex and edge observations. Our main result shows a logarithmic dependency of\nthe Hamming error to the number of categories of the random variables. Our\napproach draws connections to correlation clustering with a fixed number of\nclusters. Our results generalize the works of Globerson et al. (2015) and\nFoster et al. (2018), who study the hardness of structured prediction under\nbinary labels, to the case of categorical labels.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 04:15:33 GMT"}, {"version": "v2", "created": "Sat, 6 Jul 2019 02:30:56 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Heidari", "Alireza", ""], ["Ilyas", "Ihab F.", ""], ["Rekatsinas", "Theodoros", ""]]}, {"id": "1907.00164", "submitter": "Martin Strobel", "authors": "Reza Shokri, Martin Strobel, Yair Zick", "title": "On the Privacy Risks of Model Explanations", "comments": "19 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy and transparency are two key foundations of trustworthy machine\nlearning. Model explanations offer insights into a model's decisions on input\ndata, whereas privacy is primarily concerned with protecting information about\nthe training data. We analyze connections between model explanations and the\nleakage of sensitive information about the model's training set. We investigate\nthe privacy risks of feature-based model explanations using membership\ninference attacks: quantifying how much model predictions plus their\nexplanations leak information about the presence of a datapoint in the training\nset of a model. We extensively evaluate membership inference attacks based on\nfeature-based model explanations, over a variety of datasets. We show that\nbackpropagation-based explanations can leak a significant amount of information\nabout individual training datapoints. This is because they reveal statistical\ninformation about the decision boundaries of the model about an input, which\ncan reveal its membership. We also empirically investigate the trade-off\nbetween privacy and explanation quality, by studying the perturbation-based\nmodel explanations.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 07:59:34 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 08:10:38 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 11:01:43 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 06:51:27 GMT"}, {"version": "v5", "created": "Tue, 14 Jul 2020 09:08:57 GMT"}, {"version": "v6", "created": "Fri, 5 Feb 2021 05:04:17 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Shokri", "Reza", ""], ["Strobel", "Martin", ""], ["Zick", "Yair", ""]]}, {"id": "1907.00208", "submitter": "Ziyin Liu", "authors": "Liu Ziyin, Zhikang Wang, Paul Pu Liang, Ruslan Salakhutdinov,\n  Louis-Philippe Morency, Masahito Ueda", "title": "Deep Gamblers: Learning to Abstain with Portfolio Theory", "comments": "Camera-Ready version for NeurIPS2019. Link to our code updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We deal with the \\textit{selective classification} problem\n(supervised-learning problem with a rejection option), where we want to achieve\nthe best performance at a certain level of coverage of the data. We transform\nthe original $m$-class classification problem to $(m+1)$-class where the\n$(m+1)$-th class represents the model abstaining from making a prediction due\nto disconfidence. Inspired by portfolio theory, we propose a loss function for\nthe selective classification problem based on the doubling rate of gambling.\nMinimizing this loss function corresponds naturally to maximizing the return of\na \\textit{horse race}, where a player aims to balance between betting on an\noutcome (making a prediction) when confident and reserving one's winnings\n(abstaining) when not confident. This loss function allows us to train neural\nnetworks and characterize the disconfidence of prediction in an end-to-end\nfashion. In comparison with previous methods, our method requires almost no\nmodification to the model inference algorithm or model architecture.\nExperiments show that our method can identify uncertainty in data points, and\nachieves strong results on SVHN and CIFAR10 at various coverages of the data.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 14:04:36 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 08:57:03 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Ziyin", "Liu", ""], ["Wang", "Zhikang", ""], ["Liang", "Paul Pu", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""], ["Ueda", "Masahito", ""]]}, {"id": "1907.00211", "submitter": "Zheng Wang", "authors": "Feiping Nie, Hua Wang, Zheng Wang, Heng Huang", "title": "Robust Linear Discriminant Analysis Using Ratio Minimization of\n  L1,2-Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the most popular linear subspace learning methods, the Linear\nDiscriminant Analysis (LDA) method has been widely studied in machine learning\ncommunity and applied to many scientific applications. Traditional LDA\nminimizes the ratio of squared L2-norms, which is sensitive to outliers. In\nrecent research, many L1-norm based robust Principle Component Analysis methods\nwere proposed to improve the robustness to outliers. However, due to the\ndifficulty of L1-norm ratio optimization, so far there is no existing work to\nutilize sparsity-inducing norms for LDA objective. In this paper, we propose a\nnovel robust linear discriminant analysis method based on the L1,2-norm ratio\nminimization. Minimizing the L1,2-norm ratio is a much more challenging problem\nthan the traditional methods, and there is no existing optimization algorithm\nto solve such non-smooth terms ratio problem. We derive a new efficient\nalgorithm to solve this challenging problem, and provide a theoretical analysis\non the convergence of our algorithm. The proposed algorithm is easy to\nimplement, and converges fast in practice. Extensive experiments on both\nsynthetic data and nine real benchmark data sets show the effectiveness of the\nproposed robust LDA method.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 14:39:27 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Nie", "Feiping", ""], ["Wang", "Hua", ""], ["Wang", "Zheng", ""], ["Huang", "Heng", ""]]}, {"id": "1907.00221", "submitter": "Rohit Bhattacharya", "authors": "Rohit Bhattacharya, Daniel Malinsky, Ilya Shpitser", "title": "Causal Inference Under Interference And Network Uncertainty", "comments": "16 pages, published in proceedings of 35th Conference on Uncertainty\n  in Artificial Intelligence (UAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical causal and statistical inference methods typically assume the\nobserved data consists of independent realizations. However, in many\napplications this assumption is inappropriate due to a network of dependences\nbetween units in the data. Methods for estimating causal effects have been\ndeveloped in the setting where the structure of dependence between units is\nknown exactly, but in practice there is often substantial uncertainty about the\nprecise network structure. This is true, for example, in trial data drawn from\nvulnerable communities where social ties are difficult to query directly. In\nthis paper we combine techniques from the structure learning and interference\nliteratures in causal inference, proposing a general method for estimating\ncausal effects under data dependence when the structure of this dependence is\nnot known a priori. We demonstrate the utility of our method on synthetic\ndatasets which exhibit network dependence.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 15:25:53 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Bhattacharya", "Rohit", ""], ["Malinsky", "Daniel", ""], ["Shpitser", "Ilya", ""]]}, {"id": "1907.00235", "submitter": "Xiyou Zhou", "authors": "Shiyang Li, Xiaoyong Jin, Yao Xuan, Xiyou Zhou, Wenhu Chen, Yu-Xiang\n  Wang and Xifeng Yan", "title": "Enhancing the Locality and Breaking the Memory Bottleneck of Transformer\n  on Time Series Forecasting", "comments": "To appear in the proceeding of NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series forecasting is an important problem across many domains,\nincluding predictions of solar plant energy output, electricity consumption,\nand traffic jam situation. In this paper, we propose to tackle such forecasting\nproblem with Transformer [1]. Although impressed by its performance in our\npreliminary study, we found its two major weaknesses: (1) locality-agnostics:\nthe point-wise dot-product self-attention in canonical Transformer architecture\nis insensitive to local context, which can make the model prone to anomalies in\ntime series; (2) memory bottleneck: space complexity of canonical Transformer\ngrows quadratically with sequence length $L$, making directly modeling long\ntime series infeasible. In order to solve these two issues, we first propose\nconvolutional self-attention by producing queries and keys with causal\nconvolution so that local context can be better incorporated into attention\nmechanism. Then, we propose LogSparse Transformer with only $O(L(\\log L)^{2})$\nmemory cost, improving forecasting accuracy for time series with fine\ngranularity and strong long-term dependencies under constrained memory budget.\nOur experiments on both synthetic data and real-world datasets show that it\ncompares favorably to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 16:36:04 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 07:51:31 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 05:10:50 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Li", "Shiyang", ""], ["Jin", "Xiaoyong", ""], ["Xuan", "Yao", ""], ["Zhou", "Xiyou", ""], ["Chen", "Wenhu", ""], ["Wang", "Yu-Xiang", ""], ["Yan", "Xifeng", ""]]}, {"id": "1907.00241", "submitter": "Rohit Bhattacharya", "authors": "Rohit Bhattacharya, Razieh Nabi, Ilya Shpitser, James M. Robins", "title": "Identification In Missing Data Models Represented By Directed Acyclic\n  Graphs", "comments": "16 pages, published in proceedings of 35th Conference on Uncertainty\n  in Artificial Intelligence (UAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Missing data is a pervasive problem in data analyses, resulting in datasets\nthat contain censored realizations of a target distribution. Many approaches to\ninference on the target distribution using censored observed data, rely on\nmissing data models represented as a factorization with respect to a directed\nacyclic graph. In this paper we consider the identifiability of the target\ndistribution within this class of models, and show that the most general\nidentification strategies proposed so far retain a significant gap in that they\nfail to identify a wide class of identifiable distributions. To address this\ngap, we propose a new algorithm that significantly generalizes the types of\nmanipulations used in the ID algorithm, developed in the context of causal\ninference, in order to obtain identification.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 17:17:52 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Bhattacharya", "Rohit", ""], ["Nabi", "Razieh", ""], ["Shpitser", "Ilya", ""], ["Robins", "James M.", ""]]}, {"id": "1907.00262", "submitter": "Jonathan Frankle", "authors": "Jonathan Frankle and David Bau", "title": "Dissecting Pruned Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pruning is a standard technique for removing unnecessary structure from a\nneural network to reduce its storage footprint, computational demands, or\nenergy consumption. Pruning can reduce the parameter-counts of many\nstate-of-the-art neural networks by an order of magnitude without compromising\naccuracy, meaning these networks contain a vast amount of unnecessary\nstructure. In this paper, we study the relationship between pruning and\ninterpretability. Namely, we consider the effect of removing unnecessary\nstructure on the number of hidden units that learn disentangled representations\nof human-recognizable concepts as identified by network dissection. We aim to\nevaluate how the interpretability of pruned neural networks changes as they are\ncompressed. We find that pruning has no detrimental effect on this measure of\ninterpretability until so few parameters remain that accuracy beings to drop.\nResnet-50 models trained on ImageNet maintain the same number of interpretable\nconcepts and units until more than 90% of parameters have been pruned.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 19:27:57 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Frankle", "Jonathan", ""], ["Bau", "David", ""]]}, {"id": "1907.00267", "submitter": "Dawei Yang", "authors": "Dawei Yang, Jia Deng", "title": "Learning to Generate Synthetic 3D Training Data through Hybrid Gradient", "comments": "Accepted to CVPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic images rendered by graphics engines are a promising source for\ntraining deep networks. However, it is challenging to ensure that they can help\ntrain a network to perform well on real images, because a graphics-based\ngeneration pipeline requires numerous design decisions such as the selection of\n3D shapes and the placement of the camera. In this work, we propose a new\nmethod that optimizes the generation of 3D training data based on what we call\n\"hybrid gradient\". We parametrize the design decisions as a real vector, and\ncombine the approximate gradient and the analytical gradient to obtain the\nhybrid gradient of the network performance with respect to this vector. We\nevaluate our approach on the task of estimating surface normal, depth or\nintrinsic decomposition from a single image. Experiments on standard benchmarks\nshow that our approach can outperform the prior state of the art on optimizing\nthe generation of 3D training data, particularly in terms of computational\nefficiency.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 19:34:19 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 18:42:03 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Yang", "Dawei", ""], ["Deng", "Jia", ""]]}, {"id": "1907.00270", "submitter": "Guillaume Derval", "authors": "Guillaume Derval, Fr\\'ed\\'eric Docquier and Pierre Schaus", "title": "An aggregate learning approach for interpretable semi-supervised\n  population prediction and disaggregation using ancillary data", "comments": "Accepted at ECML-PKDD 2019 Data on Zenodo:\n  https://zenodo.org/record/3260713", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Census data provide detailed information about population characteristics at\na coarse resolution. Nevertheless, fine-grained, high-resolution mappings of\npopulation counts are increasingly needed to characterize population dynamics\nand to assess the consequences of climate shocks, natural disasters,\ninvestments in infrastructure, development policies, etc. Dissagregating these\ncensus is a complex machine learning, and multiple solutions have been proposed\nin past research. We propose in this paper to view the problem in the context\nof the aggregate learning paradigm, where the output value for all training\npoints is not known, but where it is only known for aggregates of the points\n(i.e. in this context, for regions of pixels where a census is available). We\ndemonstrate with a very simple and interpretable model that this method is on\npar, and even outperforms on some metrics, the state-of-the-art, despite its\nsimplicity.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 19:53:11 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Derval", "Guillaume", ""], ["Docquier", "Fr\u00e9d\u00e9ric", ""], ["Schaus", "Pierre", ""]]}, {"id": "1907.00275", "submitter": "Oleksandr Zadorozhnyi", "authors": "Leonidas Lefakis, Oleksandr Zadorozhnyi, Gilles Blanchard", "title": "Efficient Regularized Piecewise-Linear Regression Trees", "comments": "32 pages,6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a detailed analysis of the class of regression decision tree\nalgorithms which employ a regulized piecewise-linear node-splitting criterion\nand have regularized linear models at the leaves. From a theoretic standpoint,\nbased on Rademacher complexity framework, we present new high-probability upper\nbounds for the generalization error for the proposed classes of regularized\nregression decision tree algorithms, including LASSO-type, and $\\ell_{2}$\nregularization for linear models at the leaves. Theoretical result are further\nextended by considering a general type of variable selection procedure.\nFurthermore, in our work we demonstrate that the class of piecewise-linear\nregression trees is not only numerically stable but can be made tractable via\nan algorithmic implementation, presented herein, as well as with the help of\nmodern GPU technology. Empirically, we present results on multiple datasets\nwhich highlight the strengths and potential pitfalls, of the proposed tree\nalgorithms compared to baselines which grow trees based on piecewise constant\nmodels.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 20:34:06 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Lefakis", "Leonidas", ""], ["Zadorozhnyi", "Oleksandr", ""], ["Blanchard", "Gilles", ""]]}, {"id": "1907.00287", "submitter": "Jelena Bradic", "authors": "Jue Hou and Jelena Bradic and Ronghui Xu", "title": "Estimating Treatment Effect under Additive Hazards Models with\n  High-dimensional Covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.QM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating causal effects for survival outcomes in the high-dimensional\nsetting is an extremely important topic for many biomedical applications as\nwell as areas of social sciences. We propose a new orthogonal score method for\ntreatment effect estimation and inference that results in asymptotically valid\nconfidence intervals assuming only good estimation properties of the hazard\noutcome model and the conditional probability of treatment. This guarantee\nallows us to provide valid inference for the conditional treatment effect under\nthe high-dimensional additive hazards model under considerably more generality\nthan existing approaches. In addition, we develop a new Hazards Difference\n(HDi), estimator. We showcase that our approach has double-robustness\nproperties in high dimensions: with cross-fitting, the HDi estimate is\nconsistent under a wide variety of treatment assignment models; the HDi\nestimate is also consistent when the hazards model is misspecified and instead\nthe true data generating mechanism follows a partially linear additive hazards\nmodel. We further develop a novel sparsity doubly robust result, where either\nthe outcome or the treatment model can be a fully dense high-dimensional model.\nWe apply our methods to study the treatment effect of radical prostatectomy\nversus conservative management for prostate cancer patients using the\nSEER-Medicare Linked Data.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 22:15:59 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Hou", "Jue", ""], ["Bradic", "Jelena", ""], ["Xu", "Ronghui", ""]]}, {"id": "1907.00288", "submitter": "Tomohiro Nishiyama", "authors": "Tomohiro Nishiyama", "title": "A New Lower Bound for Kullback-Leibler Divergence Based on\n  Hammersley-Chapman-Robbins Bound", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive a useful lower bound for the Kullback-Leibler\ndivergence (KL-divergence) based on the Hammersley-Chapman-Robbins bound\n(HCRB). The HCRB states that the variance of an estimator is bounded from below\nby the Chi-square divergence and the expectation value of the estimator. By\nusing the relation between the KL-divergence and the Chi-square divergence, we\nshow that the lower bound for the KL-divergence which only depends on the\nexpectation value and the variance of a function we choose. This lower bound\ncan also be derived from an information geometric approach. Furthermore, we\nshow that the equality holds for the Bernoulli distributions and show that the\ninequality converges to the Cram\\'{e}r-Rao bound when two distributions are\nvery close. We also describe application examples and examples of numerical\ncalculation.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 22:30:03 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 13:17:58 GMT"}, {"version": "v3", "created": "Sat, 2 Nov 2019 05:57:28 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Nishiyama", "Tomohiro", ""]]}, {"id": "1907.00289", "submitter": "Jelena Diakonikolas", "authors": "Jelena Diakonikolas and Lorenzo Orecchia", "title": "Conjugate Gradients and Accelerated Methods Unified: The Approximate\n  Duality Gap View", "comments": "8 pages. v1 -> v2: corrected a reference to the paper with Nemirovski\n  acceleration with line search. v2 -> v3: updated affiliations, corrected a\n  few typos on p.7 and added an acknowledgement", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note provides a novel, simple analysis of the method of conjugate\ngradients for the minimization of convex quadratic functions. In contrast with\nstandard arguments, our proof is entirely self-contained and does not rely on\nthe existence of Chebyshev polynomials. Another advantage of our development is\nthat it clarifies the relation between the method of conjugate gradients and\ngeneral accelerated methods for smooth minimization by unifying their analyses\nwithin the framework of the Approximate Duality Gap Technique that was\nintroduced by the authors.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 22:40:35 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 22:39:23 GMT"}, {"version": "v3", "created": "Sun, 9 Feb 2020 18:06:44 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Diakonikolas", "Jelena", ""], ["Orecchia", "Lorenzo", ""]]}, {"id": "1907.00296", "submitter": "Didong Li", "authors": "Didong Li and David B Dunson", "title": "Geodesic Distance Estimation with Spherelets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many statistical and machine learning approaches rely on pairwise distances\nbetween data points. The choice of distance metric has a fundamental impact on\nperformance of these procedures, raising questions about how to appropriately\ncalculate distances. When data points are real-valued vectors, by far the most\ncommon choice is the Euclidean distance. This article is focused on the problem\nof how to better calculate distances taking into account the intrinsic geometry\nof the data, assuming data are concentrated near an unknown subspace or\nmanifold. The appropriate geometric distance corresponds to the length of the\nshortest path along the manifold, which is the geodesic distance. When the\nmanifold is unknown, it is challenging to accurately approximate the geodesic\ndistance. Current algorithms are either highly complex, and hence often\nimpractical to implement, or based on simple local linear approximations and\nshortest path algorithms that may have inadequate accuracy. We propose a simple\nand general alternative, which uses pieces of spheres, or spherelets, to\nlocally approximate the unknown subspace and thereby estimate the geodesic\ndistance through paths over spheres. Theory is developed showing lower error\nfor many manifolds, with applications in clustering, conditional density\nestimation and mean regression. The conclusion is supported through multiple\nsimulation examples and real data sets.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 23:37:02 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 06:08:35 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Li", "Didong", ""], ["Dunson", "David B", ""]]}, {"id": "1907.00300", "submitter": "Heyi Li", "authors": "Heyi Li, Dongdong Chen, William H. Nailon, Mike E. Davies and David I.\n  Laurenson", "title": "Signed Laplacian Deep Learning with Adversarial Augmentation for\n  Improved Mammography Diagnosis", "comments": "To appear in MICCAI October 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer-aided breast cancer diagnosis in mammography is limited by\ninadequate data and the similarity between benign and cancerous masses. To\naddress this, we propose a signed graph regularized deep neural network with\nadversarial augmentation, named \\textsc{DiagNet}. Firstly, we use adversarial\nlearning to generate positive and negative mass-contained mammograms for each\nmass class. After that, a signed similarity graph is built upon the expanded\ndata to further highlight the discrimination. Finally, a deep convolutional\nneural network is trained by jointly optimizing the signed graph regularization\nand classification loss. Experiments show that the \\textsc{DiagNet} framework\noutperforms the state-of-the-art in breast mass diagnosis in mammography.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 00:34:27 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 16:10:48 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Li", "Heyi", ""], ["Chen", "Dongdong", ""], ["Nailon", "William H.", ""], ["Davies", "Mike E.", ""], ["Laurenson", "David I.", ""]]}, {"id": "1907.00312", "submitter": "Omid Sadeghi", "authors": "Omid Sadeghi, Reza Eghbali and Maryam Fazel", "title": "Competitive Algorithms for Online Budget-Constrained Continuous\n  DR-Submodular Problems", "comments": "Submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a certain class of online optimization problems,\nwhere the goal is to maximize a function that is not necessarily concave and\nsatisfies the Diminishing Returns (DR) property under budget constraints. We\nanalyze a primal-dual algorithm, called the Generalized Sequential algorithm,\nand we obtain the first bound on the competitive ratio of online monotone\nDR-submodular function maximization subject to linear packing constraints which\nmatches the known tight bound in the special case of linear objective function.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 03:33:52 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Sadeghi", "Omid", ""], ["Eghbali", "Reza", ""], ["Fazel", "Maryam", ""]]}, {"id": "1907.00316", "submitter": "Omid Sadeghi", "authors": "Omid Sadeghi and Maryam Fazel", "title": "Online Continuous DR-Submodular Maximization with Long-Term Budget\n  Constraints", "comments": "Submitted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a class of online optimization problems with\nlong-term budget constraints where the objective functions are not necessarily\nconcave (nor convex) but they instead satisfy the Diminishing Returns (DR)\nproperty. Specifically, a sequence of monotone DR-submodular objective\nfunctions $\\{f_t(x)\\}_{t=1}^T$ and monotone linear budget functions $\\{\\langle\np_t,x \\rangle \\}_{t=1}^T$ arrive over time and assuming a total targeted budget\n$B_T$, the goal is to choose points $x_t$ at each time $t\\in\\{1,\\dots,T\\}$,\nwithout knowing $f_t$ and $p_t$ on that step, to achieve sub-linear regret\nbound while the total budget violation $\\sum_{t=1}^T \\langle p_t,x_t \\rangle\n-B_T$ is sub-linear as well. Prior work has shown that achieving sub-linear\nregret is impossible if the budget functions are chosen adversarially.\nTherefore, we modify the notion of regret by comparing the agent against a\n$(1-\\frac{1}{e})$-approximation to the best fixed decision in hindsight which\nsatisfies the budget constraint proportionally over any window of length $W$.\nWe propose the Online Saddle Point Hybrid Gradient (OSPHG) algorithm to solve\nthis class of online problems. For $W=T$, we recover the aforementioned\nimpossibility result. However, when $W=o(T)$, we show that it is possible to\nobtain sub-linear bounds for both the $(1-\\frac{1}{e})$-regret and the total\nbudget violation.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 04:01:32 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Sadeghi", "Omid", ""], ["Fazel", "Maryam", ""]]}, {"id": "1907.00325", "submitter": "Richard Guo", "authors": "Ronak Mehta, Richard Guo, Jesus Arroyo, Mike Powell, Hayden Helm,\n  Cencheng Shen, Joshua T. Vogelstein", "title": "Estimating Information-Theoretic Quantities with Uncertainty Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information-theoretic quantities, such as conditional entropy and mutual\ninformation, are critical data summaries for quantifying uncertainty. Existing\nestimators for these quantities either have strong theoretical guarantees or\neffective performance in high-dimensional data, but not both. We propose a\ndecision forest method, Uncertainty Forests (UF), which combines quantile\nregression forests, honest sampling, and a finite sample correction. We prove\nUF provides consistent estimates for these information-theoretic quantities,\nincluding in multivariate settings. Empirically, UF reduces finite sample bias\nand variance in a range of both low- and high-dimensional simulated settings\nfor estimating posterior probabilities, conditional entropies, and mutual\ninformation. In a real-world connectome application, UF quantifies the\nuncertainty about neuron type given various cellular features in the Drosophila\nlarva mushroom body, a key challenge for modern neuroscience.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 05:59:50 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 16:49:44 GMT"}, {"version": "v3", "created": "Thu, 28 Nov 2019 07:12:15 GMT"}, {"version": "v4", "created": "Wed, 27 May 2020 21:21:09 GMT"}, {"version": "v5", "created": "Tue, 25 Aug 2020 04:39:25 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Mehta", "Ronak", ""], ["Guo", "Richard", ""], ["Arroyo", "Jesus", ""], ["Powell", "Mike", ""], ["Helm", "Hayden", ""], ["Shen", "Cencheng", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1907.00366", "submitter": "Song-Kyoo Amang Kim Ph.D.", "authors": "Ebrahim Al Alkeem, Song-Kyoo Kim, Chan Yeob Yeun, M. Jamal Zemerly,\n  Kin Poon, Paul D. Yoo", "title": "An Enhanced Electrocardiogram Biometric Authentication System Using\n  Machine Learning", "comments": "This paper has been published in the IEEE Access", "journal-ref": "IEEE Access 7 (2019), pp. 123069-123075", "doi": "10.1109/ACCESS.2019.2937357", "report-no": null, "categories": "cs.CR cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional authentication systems use alphanumeric or graphical passwords,\nor token-based techniques that require \"something you know and something you\nhave\". The disadvantages of these systems include the risks of forgetfulness,\nloss, and theft. To address these shortcomings, biometric authentication is\nrapidly replacing traditional authentication methods and is becoming a part of\neveryday life. The electrocardiogram (ECG) is one of the most recent traits\nconsidered for biometric purposes. In this work we describe an ECG-based\nauthentication system suitable for security checks and hospital environments.\nThe proposed system will help investigators studying ECG-based biometric\nauthentication techniques to define dataset boundaries and to acquire\nhigh-quality training data. We evaluated the performance of the proposed system\nand found that it could achieve up to the 92 percent identification accuracy.\nIn addition, by applying the Amang ECG (amgecg) toolbox within MATLAB, we\ninvestigated the two parameters that directly affect the accuracy of\nauthentication: the ECG slicing time (sliding window) and the sampling time\nperiod, and found their optimal values.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 11:10:35 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 10:47:03 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Alkeem", "Ebrahim Al", ""], ["Kim", "Song-Kyoo", ""], ["Yeun", "Chan Yeob", ""], ["Zemerly", "M. Jamal", ""], ["Poon", "Kin", ""], ["Yoo", "Paul D.", ""]]}, {"id": "1907.00378", "submitter": "Ye Zhu PhD", "authors": "Xiaoyu Qin, Kai Ming Ting, Ye Zhu, Vincent CS Lee", "title": "Nearest-Neighbour-Induced Isolation Similarity and its Impact on\n  Density-Based Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent proposal of data dependent similarity called Isolation\nKernel/Similarity has enabled SVM to produce better classification accuracy. We\nidentify shortcomings of using a tree method to implement Isolation Similarity;\nand propose a nearest neighbour method instead. We formally prove the\ncharacteristic of Isolation Similarity with the use of the proposed method. The\nimpact of Isolation Similarity on density-based clustering is studied here. We\nshow for the first time that the clustering performance of the classic\ndensity-based clustering algorithm DBSCAN can be significantly uplifted to\nsurpass that of the recent density-peak clustering algorithm DP. This is\nachieved by simply replacing the distance measure with the proposed\nnearest-neighbour-induced Isolation Similarity in DBSCAN, leaving the rest of\nthe procedure unchanged. A new type of clusters called mass-connected clusters\nis formally defined. We show that DBSCAN, which detects density-connected\nclusters, becomes one which detects mass-connected clusters, when the distance\nmeasure is replaced with the proposed similarity. We also provide the condition\nunder which mass-connected clusters can be detected, while density-connected\nclusters cannot.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 13:06:26 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Qin", "Xiaoyu", ""], ["Ting", "Kai Ming", ""], ["Zhu", "Ye", ""], ["Lee", "Vincent CS", ""]]}, {"id": "1907.00389", "submitter": "Alessio Spantini", "authors": "Alessio Spantini, Ricardo Baptista, Youssef Marzouk", "title": "Coupling techniques for nonlinear ensemble filtering", "comments": "43 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider filtering in high-dimensional non-Gaussian state-space models\nwith intractable transition kernels, nonlinear and possibly chaotic dynamics,\nand sparse observations in space and time. We propose a novel filtering\nmethodology that harnesses transportation of measures, convex optimization, and\nideas from probabilistic graphical models to yield robust ensemble\napproximations of the filtering distribution in high dimensions. Our approach\ncan be understood as the natural generalization of the ensemble Kalman filter\n(EnKF) to nonlinear updates, using stochastic or deterministic couplings. The\nuse of nonlinear updates can reduce the intrinsic bias of the EnKF at a\nmarginal increase in computational cost. We avoid any form of importance\nsampling and introduce non-Gaussian localization approaches for dimension\nscalability. Our framework achieves state-of-the-art tracking performance on\nchallenging configurations of the Lorenz-96 model in the chaotic regime.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 14:51:05 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Spantini", "Alessio", ""], ["Baptista", "Ricardo", ""], ["Marzouk", "Youssef", ""]]}, {"id": "1907.00397", "submitter": "Samuel Yen-Chi Chen", "authors": "Samuel Yen-Chi Chen, Chao-Han Huck Yang, Jun Qi, Pin-Yu Chen, Xiaoli\n  Ma, Hsi-Sheng Goan", "title": "Variational Quantum Circuits for Deep Reinforcement Learning", "comments": "Accepted for publication by IEEE Access", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI quant-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The state-of-the-art machine learning approaches are based on classical von\nNeumann computing architectures and have been widely used in many industrial\nand academic domains. With the recent development of quantum computing,\nresearchers and tech-giants have attempted new quantum circuits for machine\nlearning tasks. However, the existing quantum computing platforms are hard to\nsimulate classical deep learning models or problems because of the\nintractability of deep quantum circuits. Thus, it is necessary to design\nfeasible quantum algorithms for quantum machine learning for noisy intermediate\nscale quantum (NISQ) devices. This work explores variational quantum circuits\nfor deep reinforcement learning. Specifically, we reshape classical deep\nreinforcement learning algorithms like experience replay and target network\ninto a representation of variational quantum circuits. Moreover, we use a\nquantum information encoding scheme to reduce the number of model parameters\ncompared to classical neural networks. To the best of our knowledge, this work\nis the first proof-of-principle demonstration of variational quantum circuits\nto approximate the deep $Q$-value function for decision-making and\npolicy-selection reinforcement learning with experience replay and target\nnetwork. Besides, our variational quantum circuits can be deployed in many\nnear-term NISQ machines.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 15:35:07 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 03:56:39 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 13:47:07 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Chen", "Samuel Yen-Chi", ""], ["Yang", "Chao-Han Huck", ""], ["Qi", "Jun", ""], ["Chen", "Pin-Yu", ""], ["Ma", "Xiaoli", ""], ["Goan", "Hsi-Sheng", ""]]}, {"id": "1907.00420", "submitter": "Artit Wangperawong", "authors": "Pasawee Wirojwatanakul and Artit Wangperawong", "title": "Multi-Label Product Categorization Using Multi-Modal Fusion Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we investigated multi-modal approaches using images,\ndescriptions, and titles to categorize e-commerce products on Amazon.\nSpecifically, we examined late fusion models, where the modalities are fused at\nthe decision level. Products were each assigned multiple labels, and the\nhierarchy in the labels were flattened and filtered. For our individual\nbaseline models, we modified a CNN architecture to classify the description and\ntitle, and then modified Keras' ResNet-50 to classify the images, achieving\n$F_1$ scores of 77.0%, 82.7%, and 61.0%, respectively. In comparison, our\ntri-modal late fusion model can classify products more effectively than single\nmodal models can, improving the $F_1$ score to 88.2%. Each modality\ncomplemented the shortcomings of the other modalities, demonstrating that\nincreasing the number of modalities can be an effective method for improving\nthe performance of multi-label classification problems.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 17:10:21 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 02:54:31 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Wirojwatanakul", "Pasawee", ""], ["Wangperawong", "Artit", ""]]}, {"id": "1907.00429", "submitter": "He Fang", "authors": "He Fang, Xianbin Wang, and Stefano Tomasin", "title": "Machine Learning for Intelligent Authentication in 5G-and-Beyond\n  Wireless Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fifth generation (5G) and beyond wireless networks are critical to\nsupport diverse vertical applications by connecting heterogeneous devices and\nmachines, which directly increase vulnerability for various spoofing attacks.\nConventional cryptographic and physical layer authentication techniques are\nfacing some challenges in complex dynamic wireless environments, including\nsignificant security overhead, low reliability, as well as difficulty in\npre-designing authentication model, providing continuous protections, and\nlearning time-varying attributes. In this article, we envision new\nauthentication approaches based on machine learning techniques by\nopportunistically leveraging physical layer attributes, and introduce\nintelligence to authentication for more efficient security provisioning.\nMachine learning paradigms for intelligent authentication design are presented,\nnamely for parametric/non-parametric and supervised/unsupervised/reinforcement\nlearning algorithms. In a nutshell, the machine learning-based intelligent\nauthentication approaches utilize specific features in the multi-dimensional\ndomain for achieving cost-effective, more reliable, model-free, continuous and\nsituation-aware device validation under unknown network conditions and\nunpredictable dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 18:36:26 GMT"}, {"version": "v2", "created": "Sun, 28 Jul 2019 00:25:21 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Fang", "He", ""], ["Wang", "Xianbin", ""], ["Tomasin", "Stefano", ""]]}, {"id": "1907.00437", "submitter": "Rodney LaLonde Iii", "authors": "Rodney LaLonde, Irene Tanner, Katerina Nikiforaki, Georgios Z.\n  Papadakis, Pujan Kandel, Candice W. Bolan, Michael B. Wallace, Ulas Bagci", "title": "INN: Inflated Neural Networks for IPMN Diagnosis", "comments": "Accepted for publication at MICCAI 2019 (22nd International\n  Conference on Medical Image Computing and Computer Assisted Intervention).\n  Code is publicly available at\n  https://github.com/lalonderodney/INN-Inflated-Neural-Nets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intraductal papillary mucinous neoplasm (IPMN) is a precursor to pancreatic\nductal adenocarcinoma. While over half of patients are diagnosed with\npancreatic cancer at a distant stage, patients who are diagnosed early enjoy a\nmuch higher 5-year survival rate of $34\\%$ compared to $3\\%$ in the former;\nhence, early diagnosis is key. Unique challenges in the medical imaging domain\nsuch as extremely limited annotated data sets and typically large 3D volumetric\ndata have made it difficult for deep learning to secure a strong foothold. In\nthis work, we construct two novel \"inflated\" deep network architectures,\n$\\textit{InceptINN}$ and $\\textit{DenseINN}$, for the task of diagnosing IPMN\nfrom multisequence (T1 and T2) MRI. These networks inflate their 2D layers to\n3D and bootstrap weights from their 2D counterparts (Inceptionv3 and\nDenseNet121 respectively) trained on ImageNet to the new 3D kernels. We also\nextend the inflation process by further expanding the pre-trained kernels to\nhandle any number of input modalities and different fusion strategies. This is\none of the first studies to train an end-to-end deep network on multisequence\nMRI for IPMN diagnosis, and shows that our proposed novel inflated network\narchitectures are able to handle the extremely limited training data (139 MRI\nscans), while providing an absolute improvement of $8.76\\%$ in accuracy for\ndiagnosing IPMN over the current state-of-the-art. Code is publicly available\nat https://github.com/lalonderodney/INN-Inflated-Neural-Nets.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 19:24:41 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["LaLonde", "Rodney", ""], ["Tanner", "Irene", ""], ["Nikiforaki", "Katerina", ""], ["Papadakis", "Georgios Z.", ""], ["Kandel", "Pujan", ""], ["Bolan", "Candice W.", ""], ["Wallace", "Michael B.", ""], ["Bagci", "Ulas", ""]]}, {"id": "1907.00441", "submitter": "Marcio Fonseca", "authors": "Marcio Fonseca", "title": "Unsupervised predictive coding models may explain visual brain\n  representation", "comments": "4 pages, 1 figure, Algonauts Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep predictive coding networks are neuroscience-inspired unsupervised\nlearning models that learn to predict future sensory states. We build upon the\nPredNet implementation by Lotter, Kreiman, and Cox (2016) to investigate if\npredictive coding representations are useful to predict brain activity in the\nvisual cortex. We use representational similarity analysis (RSA) to compare\nPredNet representations to functional magnetic resonance imaging (fMRI) and\nmagnetoencephalography (MEG) data from the Algonauts Project. In contrast to\nprevious findings in the literature (Khaligh-Razavi &Kriegeskorte, 2014), we\nreport empirical data suggesting that unsupervised models trained to predict\nframes of videos may outperform supervised image classification baselines. Our\nbest submission achieves an average noise normalized score of 16.67% and 27.67%\non the fMRI and MEG tracks of the Algonauts Challenge.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 19:53:32 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Fonseca", "Marcio", ""]]}, {"id": "1907.00452", "submitter": "David Lindner", "authors": "Jason Mancuso, Tomasz Kisielewski, David Lindner, Alok Singh", "title": "Detecting Spiky Corruption in Markov Decision Processes", "comments": "paper accepted to the AI Safety Workshop at IJCAI-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current reinforcement learning methods fail if the reward function is\nimperfect, i.e. if the agent observes reward different from what it actually\nreceives. We study this problem within the formalism of Corrupt Reward Markov\nDecision Processes (CRMDPs). We show that if the reward corruption in a CRMDP\nis sufficiently \"spiky\", the environment is solvable. We fully characterize the\nregret bound of a Spiky CRMDP, and introduce an algorithm that is able to\ndetect its corrupt states. We show that this algorithm can be used to learn the\noptimal policy with any common reinforcement learning algorithm. Finally, we\ninvestigate our algorithm in a pair of simple gridworld environments, finding\nthat our algorithm can detect the corrupt states and learn the optimal policy\ndespite the corruption.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 20:30:05 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Mancuso", "Jason", ""], ["Kisielewski", "Tomasz", ""], ["Lindner", "David", ""], ["Singh", "Alok", ""]]}, {"id": "1907.00455", "submitter": "Marie-Jean Meurs", "authors": "Diego Maupom\\'e and Marie-Jean Meurs", "title": "Multiplicative Models for Recurrent Language Modeling", "comments": "10 pages, pre-print from Proceedings of CICLing 2019: 20th\n  International Conference on Computational Linguistics and Intelligent Text\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there has been interest in multiplicative recurrent neural networks\nfor language modeling. Indeed, simple Recurrent Neural Networks (RNNs)\nencounter difficulties recovering from past mistakes when generating sequences\ndue to high correlation between hidden states. These challenges can be\nmitigated by integrating second-order terms in the hidden-state update. One\nsuch model, multiplicative Long Short-Term Memory (mLSTM) is particularly\ninteresting in its original formulation because of the sharing of its\nsecond-order term, referred to as the intermediate state. We explore these\narchitectural improvements by introducing new models and testing them on\ncharacter-level language modeling tasks. This allows us to establish the\nrelevance of shared parametrization in recurrent language modeling.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 20:51:43 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Maupom\u00e9", "Diego", ""], ["Meurs", "Marie-Jean", ""]]}, {"id": "1907.00456", "submitter": "Natasha Jaques", "authors": "Natasha Jaques, Asma Ghandeharioun, Judy Hanwen Shen, Craig Ferguson,\n  Agata Lapedriza, Noah Jones, Shixiang Gu, Rosalind Picard", "title": "Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human\n  Preferences in Dialog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most deep reinforcement learning (RL) systems are not able to learn\neffectively from off-policy data, especially if they cannot explore online in\nthe environment. These are critical shortcomings for applying RL to real-world\nproblems where collecting data is expensive, and models must be tested offline\nbefore being deployed to interact with the environment -- e.g. systems that\nlearn from human interaction. Thus, we develop a novel class of off-policy\nbatch RL algorithms, which are able to effectively learn offline, without\nexploring, from a fixed batch of human interaction data. We leverage models\npre-trained on data as a strong prior, and use KL-control to penalize\ndivergence from this prior during RL training. We also use dropout-based\nuncertainty estimates to lower bound the target Q-values as a more efficient\nalternative to Double Q-Learning. The algorithms are tested on the problem of\nopen-domain dialog generation -- a challenging reinforcement learning problem\nwith a 20,000-dimensional action space. Using our Way Off-Policy algorithm, we\ncan extract multiple different reward functions post-hoc from collected human\ninteraction data, and learn effectively from all of these. We test the\nreal-world generalization of these systems by deploying them live to converse\nwith humans in an open-domain setting, and demonstrate that our algorithm\nachieves significant improvements over prior methods in off-policy batch RL.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 20:53:19 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 17:21:46 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Jaques", "Natasha", ""], ["Ghandeharioun", "Asma", ""], ["Shen", "Judy Hanwen", ""], ["Ferguson", "Craig", ""], ["Lapedriza", "Agata", ""], ["Jones", "Noah", ""], ["Gu", "Shixiang", ""], ["Picard", "Rosalind", ""]]}, {"id": "1907.00481", "submitter": "Filippo Maria Bianchi", "authors": "Filippo Maria Bianchi, Daniele Grattarola, Cesare Alippi", "title": "Spectral Clustering with Graph Neural Networks for Graph Pooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering (SC) is a popular clustering technique to find strongly\nconnected communities on a graph. SC can be used in Graph Neural Networks\n(GNNs) to implement pooling operations that aggregate nodes belonging to the\nsame cluster. However, the eigendecomposition of the Laplacian is expensive\nand, since clustering results are graph-specific, pooling methods based on SC\nmust perform a new optimization for each new sample. In this paper, we propose\na graph clustering approach that addresses these limitations of SC. We\nformulate a continuous relaxation of the normalized minCUT problem and train a\nGNN to compute cluster assignments that minimize this objective. Our GNN-based\nimplementation is differentiable, does not require to compute the spectral\ndecomposition, and learns a clustering function that can be quickly evaluated\non out-of-sample graphs. From the proposed clustering method, we design a graph\npooling operator that overcomes some important limitations of state-of-the-art\ngraph pooling techniques and achieves the best performance in several\nsupervised and unsupervised tasks.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 22:08:16 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 14:26:02 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 16:07:45 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2020 09:46:10 GMT"}, {"version": "v5", "created": "Mon, 14 Dec 2020 13:39:00 GMT"}, {"version": "v6", "created": "Tue, 29 Dec 2020 08:32:54 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Bianchi", "Filippo Maria", ""], ["Grattarola", "Daniele", ""], ["Alippi", "Cesare", ""]]}, {"id": "1907.00485", "submitter": "Massimo Fornasier", "authors": "Massimo Fornasier, Timo Klock, Michael Rauchensteiner", "title": "Robust and Resource Efficient Identification of Two Hidden Layer Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the structure identification and the uniform approximation of two\nfully nonlinear layer neural networks of the type $f(x)=1^T h(B^T g(A^T x))$ on\n$\\mathbb R^d$ from a small number of query samples. We approach the problem by\nsampling actively finite difference approximations to Hessians of the network.\nGathering several approximate Hessians allows reliably to approximate the\nmatrix subspace $\\mathcal W$ spanned by symmetric tensors $a_1 \\otimes a_1\n,\\dots,a_{m_0}\\otimes a_{m_0}$ formed by weights of the first layer together\nwith the entangled symmetric tensors $v_1 \\otimes v_1 ,\\dots,v_{m_1}\\otimes\nv_{m_1}$, formed by suitable combinations of the weights of the first and\nsecond layer as $v_\\ell=A G_0 b_\\ell/\\|A G_0 b_\\ell\\|_2$, $\\ell \\in [m_1]$, for\na diagonal matrix $G_0$ depending on the activation functions of the first\nlayer. The identification of the 1-rank symmetric tensors within $\\mathcal W$\nis then performed by the solution of a robust nonlinear program. We provide\nguarantees of stable recovery under a posteriori verifiable conditions. We\nfurther address the correct attribution of approximate weights to the first or\nsecond layer. By using a suitably adapted gradient descent iteration, it is\npossible then to estimate, up to intrinsic symmetries, the shifts of the\nactivations functions of the first layer and compute exactly the matrix $G_0$.\nOur method of identification of the weights of the network is fully\nconstructive, with quantifiable sample complexity, and therefore contributes to\ndwindle the black-box nature of the network training phase. We corroborate our\ntheoretical results by extensive numerical experiments.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 22:27:13 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Fornasier", "Massimo", ""], ["Klock", "Timo", ""], ["Rauchensteiner", "Michael", ""]]}, {"id": "1907.00489", "submitter": "Maximilian Du", "authors": "Maximilian Du", "title": "Improving LSTM Neural Networks for Better Short-Term Wind Power\n  Predictions", "comments": "5 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper improves wind power prediction via weather forecast-contextualized\nLong Short-Term Memory Neural Network (LSTM) models. Initially, only wind power\ndata was fed to a generic LSTM, but this model performed poorly, with erratic\nand naive behavior observed on even low-variance data sections. To address this\nissue, weather forecast data was added to better contextualize the power data,\nand LSTM modifications were made to address specific model shortcomings. These\nmodels were tested through both a Normalized Mean Absolute Error and the Naive\nRatio (NR), which is a score introduced by this paper to quantify the unwanted\npresence of naive character in trained models. Results showed an increased\naccuracy with the addition of weather forecast data on the modified models, as\nwell as a decrease in naive character. Key contributions include making\nimproved LSTM variants, usage of weather forecast data, and the introduction of\na new model performance index.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 22:43:18 GMT"}, {"version": "v2", "created": "Sat, 3 Aug 2019 21:08:32 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Du", "Maximilian", ""]]}, {"id": "1907.00503", "submitter": "Lei Xu", "authors": "Lei Xu, Maria Skoularidou, Alfredo Cuesta-Infante, Kalyan\n  Veeramachaneni", "title": "Modeling Tabular data using Conditional GAN", "comments": "Accepted to NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling the probability distribution of rows in tabular data and generating\nrealistic synthetic data is a non-trivial task. Tabular data usually contains a\nmix of discrete and continuous columns. Continuous columns may have multiple\nmodes whereas discrete columns are sometimes imbalanced making the modeling\ndifficult. Existing statistical and deep neural network models fail to properly\nmodel this type of data. We design TGAN, which uses a conditional generative\nadversarial network to address these challenges. To aid in a fair and thorough\ncomparison, we design a benchmark with 7 simulated and 8 real datasets and\nseveral Bayesian network baselines. TGAN outperforms Bayesian methods on most\nof the real datasets whereas other deep learning methods could not.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 00:11:32 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 02:13:06 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Xu", "Lei", ""], ["Skoularidou", "Maria", ""], ["Cuesta-Infante", "Alfredo", ""], ["Veeramachaneni", "Kalyan", ""]]}, {"id": "1907.00526", "submitter": "Longxiang Shi", "authors": "Longxiang Shi, Shijian Li, Longbing Cao, Long Yang, Gang Zheng, Gang\n  Pan", "title": "FiDi-RL: Incorporating Deep Reinforcement Learning with\n  Finite-Difference Policy Search for Efficient Learning of Continuous Control", "comments": "I found some theoretical errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years significant progress has been made in dealing with\nchallenging problems using reinforcement learning.Despite its great success,\nreinforcement learning still faces challenge in continuous control tasks.\nConventional methods always compute the derivatives of the optimal goal with a\ncostly computation resources, and are inefficient, unstable and lack of\nrobust-ness when dealing with such tasks. Alternatively, derivative-based\nmethods treat the optimization process as a blackbox and show robustness and\nstability in learning continuous control tasks, but not data efficient in\nlearning. The combination of both methods so as to get the best of the both has\nraised attention. However, most of the existing combination works adopt complex\nneural networks (NNs) as the policy for control. The double-edged sword of deep\nNNs can yield better performance, but also makes it difficult for parameter\ntuning and computation. To this end, in this paper we presents a novel method\ncalled FiDi-RL, which incorporates deep RL with Finite-Difference (FiDi) policy\nsearch.FiDi-RL combines Deep Deterministic Policy Gradients (DDPG)with Augment\nRandom Search (ARS) and aims at improving the data efficiency of ARS. The\nempirical results show that FiDi-RL can improves the performance and stability\nof ARS, and provide competitive results against some existing deep\nreinforcement learning methods\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 03:21:19 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 03:29:40 GMT"}, {"version": "v3", "created": "Sat, 1 Feb 2020 03:22:47 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Shi", "Longxiang", ""], ["Li", "Shijian", ""], ["Cao", "Longbing", ""], ["Yang", "Long", ""], ["Zheng", "Gang", ""], ["Pan", "Gang", ""]]}, {"id": "1907.00542", "submitter": "Hee-Soo Heo", "authors": "Hee-Soo Heo, Jee-weon Jung, Hye-jin Shim, IL-Ho Yang, Ha-Jin Yu", "title": "Cosine similarity-based adversarial process", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An adversarial process between two deep neural networks is a promising\napproach to train a robust model. In this paper, we propose an adversarial\nprocess using cosine similarity, whereas conventional adversarial processes are\nbased on inverted categorical cross entropy (CCE). When used for training an\nidentification model, the adversarial process induces the competition of two\ndiscriminative models; one for a primary task such as speaker identification or\nimage recognition, the other one for a subsidiary task such as channel\nidentification or domain identification. In particular, the adversarial process\ndegrades the performance of the subsidiary model by eliminating the subsidiary\ninformation in the input which, in assumption, may degrade the performance of\nthe primary model. The conventional adversarial processes maximize the CCE of\nthe subsidiary model to degrade the performance. We have studied a framework\nfor training robust discriminative models by eliminating channel or domain\ninformation (subsidiary information) by applying such an adversarial process.\nHowever, we found through experiments that using the process of maximizing the\nCCE does not guarantee the performance degradation of the subsidiary model. In\nthe proposed adversarial process using cosine similarity, on the contrary, the\nperformance of the subsidiary model can be degraded more efficiently by\nsearching feature space orthogonal to the subsidiary model. The experiments on\nspeaker identification and image recognition show that we found features that\nmake the outputs of the subsidiary models independent of the input, and the\nperformances of the primary models are improved.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 04:44:35 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Heo", "Hee-Soo", ""], ["Jung", "Jee-weon", ""], ["Shim", "Hye-jin", ""], ["Yang", "IL-Ho", ""], ["Yu", "Ha-Jin", ""]]}, {"id": "1907.00558", "submitter": "Maria Glenski", "authors": "Maria Glenski, Tim Weninger, and Svitlana Volkova", "title": "Improved Forecasting of Cryptocurrency Price using Social Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social media signals have been successfully used to develop large-scale\npredictive and anticipatory analytics. For example, forecasting stock market\nprices and influenza outbreaks. Recently, social data has been explored to\nforecast price fluctuations of cryptocurrencies, which are a novel disruptive\ntechnology with significant political and economic implications. In this paper\nwe leverage and contrast the predictive power of social signals, specifically\nuser behavior and communication patterns, from multiple social platforms GitHub\nand Reddit to forecast prices for three cyptocurrencies with high developer and\ncommunity interest - Bitcoin, Ethereum, and Monero. We evaluate the performance\nof neural network models that rely on long short-term memory units (LSTMs)\ntrained on historical price data and social data against price only LSTMs and\nbaseline autoregressive integrated moving average (ARIMA) models, commonly used\nto predict stock prices. Our results not only demonstrate that social signals\nreduce error when forecasting daily coin price, but also show that the language\nused in comments within the official communities on Reddit (r/Bitcoin,\nr/Ethereum, and r/Monero) are the best predictors overall. We observe that\nmodels are more accurate in forecasting price one day ahead for Bitcoin (4%\nroot mean squared percent error) compared to Ethereum (7%) and Monero (8%).\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 05:51:05 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Glenski", "Maria", ""], ["Weninger", "Tim", ""], ["Volkova", "Svitlana", ""]]}, {"id": "1907.00560", "submitter": "Ido Nachum", "authors": "Ido Nachum and Amir Yehudayoff", "title": "On Symmetry and Initialization for Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work provides an additional step in the theoretical understanding of\nneural networks. We consider neural networks with one hidden layer and show\nthat when learning symmetric functions, one can choose initial conditions so\nthat standard SGD training efficiently produces generalization guarantees. We\nempirically verify this and show that this does not hold when the initial\nconditions are chosen at random. The proof of convergence investigates the\ninteraction between the two layers of the network. Our results highlight the\nimportance of using symmetry in the design of neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 06:03:05 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Nachum", "Ido", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "1907.00586", "submitter": "Heishiro Kanagawa", "authors": "Heishiro Kanagawa and Wittawat Jitkrittum and Lester Mackey and Kenji\n  Fukumizu and Arthur Gretton", "title": "A Kernel Stein Test for Comparing Latent Variable Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a kernel-based nonparametric test of relative goodness of fit,\nwhere the goal is to compare two models, both of which may have unobserved\nlatent variables, such that the marginal distribution of the observed variables\nis intractable. The proposed test generalises the recently proposed kernel\nStein discrepancy (KSD) tests (Liu et al., 2016, Chwialkowski et al., 2016,\nYang et al., 2018) to the case of latent variable models, a much more general\nclass than the fully observed models treated previously. As our main\ntheoretical contribution, we prove that the new test, with a properly\ncalibrated threshold, has a well-controlled type-I error. In the case of models\nwith low-dimensional latent structure and high-dimensional observations, our\ntest significantly outperforms the relative Maximum Mean Discrepancy test,\nwhich is based on samples from the models and does not exploit the latent\nstructure.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 07:46:16 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 09:52:22 GMT"}, {"version": "v3", "created": "Wed, 5 May 2021 11:56:30 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Kanagawa", "Heishiro", ""], ["Jitkrittum", "Wittawat", ""], ["Mackey", "Lester", ""], ["Fukumizu", "Kenji", ""], ["Gretton", "Arthur", ""]]}, {"id": "1907.00593", "submitter": "Wen-Pu Cai", "authors": "Wen-Pu Cai and Wu-Jun Li", "title": "Weight Normalization based Quantization for Deep Neural Network\n  Compression", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the development of deep neural networks, the size of network models\nbecomes larger and larger. Model compression has become an urgent need for\ndeploying these network models to mobile or embedded devices. Model\nquantization is a representative model compression technique. Although a lot of\nquantization methods have been proposed, many of them suffer from a high\nquantization error caused by a long-tail distribution of network weights. In\nthis paper, we propose a novel quantization method, called weight normalization\nbased quantization (WNQ), for model compression. WNQ adopts weight\nnormalization to avoid the long-tail distribution of network weights and\nsubsequently reduces the quantization error. Experiments on CIFAR-100 and\nImageNet show that WNQ can outperform other baselines to achieve\nstate-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 07:59:39 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Cai", "Wen-Pu", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1907.00624", "submitter": "Georgios Leontidis", "authors": "Bashar Alhnaity, Simon Pearson, Georgios Leontidis and Stefanos\n  Kollias", "title": "Using Deep Learning to Predict Plant Growth and Yield in Greenhouse\n  Environments", "comments": "8 pages, 2 figures, 1 table. arXiv admin note: text overlap with\n  arXiv:1807.11809, arXiv:1707.00666 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective plant growth and yield prediction is an essential task for\ngreenhouse growers and for agriculture in general. Developing models which can\neffectively model growth and yield can help growers improve the environmental\ncontrol for better production, match supply and market demand and lower costs.\nRecent developments in Machine Learning (ML) and, in particular, Deep Learning\n(DL) can provide powerful new analytical tools. The proposed study utilises ML\nand DL techniques to predict yield and plant growth variation across two\ndifferent scenarios, tomato yield forecasting and Ficus benjamina stem growth,\nin controlled greenhouse environments. We deploy a new deep recurrent neural\nnetwork (RNN), using the Long Short-Term Memory (LSTM) neuron model, in the\nprediction formulations. Both the former yield, growth and stem diameter\nvalues, as well as the microclimate conditions, are used by the RNN\narchitecture to model the targeted growth parameters. A comparative study is\npresented, using ML methods, such as support vector regression and random\nforest regression, utilising the mean square error criterion, in order to\nevaluate the performance achieved by the different methods. Very promising\nresults, based on data that have been obtained from two greenhouses, in Belgium\nand the UK, in the framework of the EU Interreg SMARTGREEN project (2017-2021),\nare presented.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 09:36:06 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Alhnaity", "Bashar", ""], ["Pearson", "Simon", ""], ["Leontidis", "Georgios", ""], ["Kollias", "Stefanos", ""]]}, {"id": "1907.00650", "submitter": "Qi She", "authors": "Qi She, Anqi Wu", "title": "Neural Dynamics Discovery via Gaussian Process Recurrent Neural Networks", "comments": "11 pages, 3 figures, 7 Tables, accepted to The Conference on\n  Uncertainty in Artificial Intelligence (UAI), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent dynamics discovery is challenging in extracting complex dynamics from\nhigh-dimensional noisy neural data. Many dimensionality reduction methods have\nbeen widely adopted to extract low-dimensional, smooth and time-evolving latent\ntrajectories. However, simple state transition structures, linear embedding\nassumptions, or inflexible inference networks impede the accurate recovery of\ndynamic portraits. In this paper, we propose a novel latent dynamic model that\nis capable of capturing nonlinear, non-Markovian, long short-term\ntime-dependent dynamics via recurrent neural networks and tackling complex\nnonlinear embedding via non-parametric Gaussian process. Due to the complexity\nand intractability of the model and its inference, we also provide a powerful\ninference network with bi-directional long short-term memory networks that\nencode both past and future information into posterior distributions. In the\nexperiment, we show that our model outperforms other state-of-the-art methods\nin reconstructing insightful latent dynamics from both simulated and\nexperimental neural datasets with either Gaussian or Poisson observations,\nespecially in the low-sample scenario. Our codes and additional materials are\navailable at https://github.com/sheqi/GP-RNN_UAI2019.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 10:51:38 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["She", "Qi", ""], ["Wu", "Anqi", ""]]}, {"id": "1907.00652", "submitter": "Ashley Gritzman", "authors": "Ashley Daniel Gritzman", "title": "Avoiding Implementation Pitfalls of \"Matrix Capsules with EM Routing\" by\n  Hinton et al", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent progress on capsule networks by Hinton et al. has generated\nconsiderable excitement in the machine learning community. The idea behind a\ncapsule is inspired by a cortical minicolumn in the brain, whereby a vertically\norganised group of around 100 neurons receive common inputs, have common\noutputs, are interconnected, and may well constitute a fundamental computation\nunit of the cerebral cortex. However, Hinton's paper on \"Matrix Capsule with EM\nRouting'\" was unfortunately not accompanied by a release of source code, which\nleft interested researchers attempting to implement the architecture and\nreproduce the benchmarks on their own. This has certainly slowed the progress\nof research building on this work. While writing our own implementation, we\nnoticed several common mistakes in other open source implementations that we\ncame across. In this paper we share some of these learnings, specifically\nfocusing on three implementation pitfalls and how to avoid them: (1) parent\ncapsules with only one child; (2) normalising the amount of data assigned to\nparent capsules; (3) parent capsules at different positions compete for child\ncapsules. While our implementation is a considerable improvement over currently\navailable implementations, it still falls slightly short of the performance\nreported by Hinton et al. (2018). The source code for this implementation is\navailable on GitHub at the following URL:\nhttps://github.com/IBM/matrix-capsules-with-em-routing.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 10:51:58 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Gritzman", "Ashley Daniel", ""]]}, {"id": "1907.00664", "submitter": "Wenling Shang", "authors": "Wenling Shang, Alex Trott, Stephan Zheng, Caiming Xiong, Richard\n  Socher", "title": "Learning World Graphs to Accelerate Hierarchical Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world scenarios, an autonomous agent often encounters various\ntasks within a single complex environment. We propose to build a graph\nabstraction over the environment structure to accelerate the learning of these\ntasks. Here, nodes are important points of interest (pivotal states) and edges\nrepresent feasible traversals between them. Our approach has two stages. First,\nwe jointly train a latent pivotal state model and a curiosity-driven\ngoal-conditioned policy in a task-agnostic manner. Second, provided with the\ninformation from the world graph, a high-level Manager quickly finds solution\nto new tasks and expresses subgoals in reference to pivotal states to a\nlow-level Worker. The Worker can then also leverage the graph to easily\ntraverse to the pivotal states of interest, even across long distance, and\nexplore non-locally. We perform a thorough ablation study to evaluate our\napproach on a suite of challenging maze tasks, demonstrating significant\nadvantages from the proposed framework over baselines that lack world graph\nknowledge in terms of performance and efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 11:22:52 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Shang", "Wenling", ""], ["Trott", "Alex", ""], ["Zheng", "Stephan", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1907.00680", "submitter": "Sibylle Hess", "authors": "Sibylle Hess, Wouter Duivesteijn, Philipp Honysz, Katharina Morik", "title": "The SpectACl of Nonconvex Clustering: A Spectral Approach to\n  Density-Based Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When it comes to clustering nonconvex shapes, two paradigms are used to find\nthe most suitable clustering: minimum cut and maximum density. The most popular\nalgorithms incorporating these paradigms are Spectral Clustering and DBSCAN.\nBoth paradigms have their pros and cons. While minimum cut clusterings are\nsensitive to noise, density-based clusterings have trouble handling clusters\nwith varying densities. In this paper, we propose \\textsc{SpectACl}: a method\ncombining the advantages of both approaches, while solving the two mentioned\ndrawbacks. Our method is easy to implement, such as spectral clustering, and\ntheoretically founded to optimize a proposed density criterion of clusterings.\nThrough experiments on synthetic and real-world data, we demonstrate that our\napproach provides robust and reliable clusterings.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 12:08:58 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Hess", "Sibylle", ""], ["Duivesteijn", "Wouter", ""], ["Honysz", "Philipp", ""], ["Morik", "Katharina", ""]]}, {"id": "1907.00686", "submitter": "Nicolas Meyer", "authors": "Meyer Nicolas (LPSM (UMR\\_8001)), Olivier Wintenberger (LPSM\n  (UMR\\_8001))", "title": "Sparse regular variation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regular variation provides a convenient theoretical framework to study large\nevents. In the multivariate setting, the dependence structure of the positive\nextremes is characterized by a measure - the spectral measure - defined on the\npositive orthant of the unit sphere. This measure gathers information on the\nlocalization of extreme events and has often a sparse support since severe\nevents do not simultaneously occur in all directions. However, it is defined\nthrough weak convergence which does not provide a natural way to capture this\nsparsity structure.In this paper, we introduce the notion of sparse regular\nvariation which allows to better learn the dependence structure of extreme\nevents. This concept is based on the Euclidean projection onto the simplex for\nwhich efficient algorithms are known. We prove that under mild assumptions\nsparse regular variation and regular variation are two equivalent notions and\nwe establish several results for sparsely regularly varying random vectors.\nFinally, we illustrate on numerical examples how this new concept allows one to\ndetect extremal directions.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 12:11:57 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 09:55:28 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 18:43:38 GMT"}, {"version": "v4", "created": "Fri, 27 Nov 2020 15:52:29 GMT"}, {"version": "v5", "created": "Tue, 23 Feb 2021 08:33:40 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Nicolas", "Meyer", "", "LPSM"], ["Wintenberger", "Olivier", "", "LPSM"]]}, {"id": "1907.00693", "submitter": "Seiichi Uchida", "authors": "Toshiki Nakamura, Anna Zhu, and Seiichi Uchida", "title": "Scene Text Magnifier", "comments": "to appear at the International Conference on Document Analysis and\n  Recognition (ICDAR) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene text magnifier aims to magnify text in natural scene images without\nrecognition. It could help the special groups, who have myopia or dyslexia to\nbetter understand the scene. In this paper, we design the scene text magnifier\nthrough interacted four CNN-based networks: character erasing, character\nextraction, character magnify, and image synthesis. The architecture of the\nnetworks are extended based on the hourglass encoder-decoders. It inputs the\noriginal scene text image and outputs the text magnified image while keeps the\nbackground unchange. Intermediately, we can get the side-output results of text\nerasing and text extraction. The four sub-networks are first trained\nindependently and fine-tuned in end-to-end mode. The training samples for each\nstage are processed through a flow with original image and text annotation in\nICDAR2013 and Flickr dataset as input, and corresponding text erased image,\nmagnified text annotation, and text magnified scene image as output. To\nevaluate the performance of text magnifier, the Structural Similarity is used\nto measure the regional changes in each character region. The experimental\nresults demonstrate our method can magnify scene text effectively without\neffecting the background.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 03:14:08 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 09:16:02 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Nakamura", "Toshiki", ""], ["Zhu", "Anna", ""], ["Uchida", "Seiichi", ""]]}, {"id": "1907.00697", "submitter": "Sibylle Hess", "authors": "Sibylle Hess, Nico Piatkowski, Katharina Morik", "title": "The Trustworthy Pal: Controlling the False Discovery Rate in Boolean\n  Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean matrix factorization (BMF) is a popular and powerful technique for\ninferring knowledge from data. The mining result is the Boolean product of two\nmatrices, approximating the input dataset. The Boolean product is a disjunction\nof rank-1 binary matrices, each describing a feature-relation, called pattern,\nfor a group of samples. Yet, there are no guarantees that any of the returned\npatterns do not actually arise from noise, i.e., are false discoveries. In this\npaper, we propose and discuss the usage of the false discovery rate in the\nunsupervised BMF setting. We prove two bounds on the probability that a found\npattern is constituted of random Bernoulli-distributed noise. Each bound\nexploits a specific property of the factorization which minimizes the\napproximation error---yielding new insights on the minimizers of Boolean matrix\nfactorization. This leads to improved BMF algorithms by replacing heuristic\nrank selection techniques with a theoretically well-based approach. Our\nempirical demonstration shows that both bounds deliver excellent results in\nvarious practical settings.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 12:23:49 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Hess", "Sibylle", ""], ["Piatkowski", "Nico", ""], ["Morik", "Katharina", ""]]}, {"id": "1907.00700", "submitter": "Yingyang Chen", "authors": "Chunkai Zhang and Yingyang Chen and Ao Yin and Zhen Qin and Xing Zhang\n  and Keli Zhang and Zoe L. Jiang", "title": "An Improvement of PAA on Trend-Based Approximation for Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Piecewise Aggregate Approximation (PAA) is a competitive basic dimension\nreduction method for high-dimensional time series mining. When deployed,\nhowever, the limitations are obvious that some important information will be\nmissed, especially the trend. In this paper, we propose two new approaches for\ntime series that utilize approximate trend feature information. Our first\nmethod is based on relative mean value of each segment to record the trend,\nwhich divide each segment into two parts and use the numerical average\nrespectively to represent the trend. We proved that this method satisfies lower\nbound which guarantee no false dismissals. Our second method uses a binary\nstring to record the trend which is also relative to mean in each segment. Our\nmethods are applied on similarity measurement in classification and anomaly\ndetection, the experimental results show the improvement of accuracy and\neffectiveness by extracting the trend feature suitably.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 06:45:07 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Zhang", "Chunkai", ""], ["Chen", "Yingyang", ""], ["Yin", "Ao", ""], ["Qin", "Zhen", ""], ["Zhang", "Xing", ""], ["Zhang", "Keli", ""], ["Jiang", "Zoe L.", ""]]}, {"id": "1907.00708", "submitter": "Dominic Danks", "authors": "Fran\\c{c}ois-Xavier Aubet, Dominic Danks, Yuchen Zhu", "title": "EQuANt (Enhanced Question Answer Network)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Reading Comprehension (MRC) is an important topic in the domain of\nautomated question answering and in natural language processing more generally.\nSince the release of the SQuAD 1.1 and SQuAD 2 datasets, progress in the field\nhas been particularly significant, with current state-of-the-art models now\nexhibiting near-human performance at both answering well-posed questions and\ndetecting questions which are unanswerable given a corresponding context. In\nthis work, we present Enhanced Question Answer Network (EQuANt), an MRC model\nwhich extends the successful QANet architecture of Yu et al. to cope with\nunanswerable questions. By training and evaluating EQuANt on SQuAD 2, we show\nthat it is indeed possible to extend QANet to the unanswerable domain. We\nachieve results which are close to 2 times better than our chosen baseline\nobtained by evaluating a lightweight version of the original QANet architecture\non SQuAD 2. In addition, we report that the performance of EQuANt on SQuAD 1.1\nafter being trained on SQuAD2 exceeds that of our lightweight QANet\narchitecture trained and evaluated on SQuAD 1.1, demonstrating the utility of\nmulti-task learning in the MRC context.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 08:13:45 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 21:03:37 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Aubet", "Fran\u00e7ois-Xavier", ""], ["Danks", "Dominic", ""], ["Zhu", "Yuchen", ""]]}, {"id": "1907.00749", "submitter": "Vidyasagar Sadhu", "authors": "Vidyasagar Sadhu, Teruhisa Misu, Dario Pompili", "title": "Deep Multi-Task Learning for Anomalous Driving Detection Using CAN Bus\n  Scalar Sensor Data", "comments": "IROS 2019, 8 pages", "journal-ref": "2019 IEEE/RSJ International Conference on Intelligent Robots and\n  Systems (IROS), pp. 1-8", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corner cases are the main bottlenecks when applying Artificial Intelligence\n(AI) systems to safety-critical applications. An AI system should be\nintelligent enough to detect such situations so that system developers can\nprepare for subsequent planning. In this paper, we propose semi-supervised\nanomaly detection considering the imbalance of normal situations. In\nparticular, driving data consists of multiple positive/normal situations (e.g.,\nright turn, going straight), some of which (e.g., U-turn) could be as rare as\nanomalous situations. Existing machine learning based anomaly detection\napproaches do not fare sufficiently well when applied to such imbalanced data.\nIn this paper, we present a novel multi-task learning based approach that\nleverages domain-knowledge (maneuver labels) for anomaly detection in driving\ndata. We evaluate the proposed approach both quantitatively and qualitatively\non 150 hours of real-world driving data and show improved performance over\nbaseline approaches.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 04:36:47 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Sadhu", "Vidyasagar", ""], ["Misu", "Teruhisa", ""], ["Pompili", "Dario", ""]]}, {"id": "1907.00762", "submitter": "Blake Woodworth", "authors": "Blake Woodworth and Nathan Srebro", "title": "Open Problem: The Oracle Complexity of Convex Optimization with Limited\n  Memory", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We note that known methods achieving the optimal oracle complexity for first\norder convex optimization require quadratic memory, and ask whether this is\nnecessary, and more broadly seek to characterize the minimax number of first\norder queries required to optimize a convex Lipschitz function subject to a\nmemory constraint.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 13:37:34 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Woodworth", "Blake", ""], ["Srebro", "Nathan", ""]]}, {"id": "1907.00770", "submitter": "Artur Speiser", "authors": "Artur Speiser, Lucas-Raphael M\\\"uller, Ulf Matti, Christopher J.\n  Obara, Wesley R. Legant, Jonas Ries, Jakob H. Macke, Srinivas C. Turaga", "title": "Teaching deep neural networks to localize single molecules for\n  super-resolution microscopy", "comments": "Significant improvements of the algorithm, including a novel loss\n  function. Evaluations on multiple real data sets", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-molecule localization fluorescence microscopy constructs\nsuper-resolution images by sequential imaging and computational localization of\nsparsely activated fluorophores. Accurate and efficient fluorophore\nlocalization algorithms are key to the success of this computational microscopy\nmethod. We present a novel localization algorithm based on deep learning which\nsignificantly improves upon the state of the art. Our contributions are a novel\nnetwork architecture for simultaneous detection and localization, and new loss\nfunction which phrases detection and localization as a Bayesian inference\nproblem, and thus allows the network to provide uncertainty-estimates. In\ncontrast to standard methods which independently process imaging frames, our\nnetwork architecture uses temporal context from multiple sequentially imaged\nframes to detect and localize molecules. We demonstrate the power of our method\nacross a variety of datasets, imaging modalities, signal to noise ratios, and\nfluorophore densities. While existing localization algorithms can achieve\noptimal localization accuracy at low fluorophore densities, they are confounded\nby high densities. Our method is the first deep-learning based approach which\nachieves state-of-the-art on the SMLM2016 challenge. It achieves the best\nscores on 12 out of 12 data-sets when comparing both detection accuracy and\nprecision, and excels at high densities. Finally, we investigate how\nunsupervised learning can be used to make the network robust against mismatch\nbetween simulated and real data. The lessons learned here are more generally\nrelevant for the training of deep networks to solve challenging Bayesian\ninverse problems on spatially extended domains in biology and physics.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 22:27:17 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 14:28:35 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Speiser", "Artur", ""], ["M\u00fcller", "Lucas-Raphael", ""], ["Matti", "Ulf", ""], ["Obara", "Christopher J.", ""], ["Legant", "Wesley R.", ""], ["Ries", "Jonas", ""], ["Macke", "Jakob H.", ""], ["Turaga", "Srinivas C.", ""]]}, {"id": "1907.00783", "submitter": "Cem Tekin", "authors": "Eralp Turgay, Cem Bulucu, Cem Tekin", "title": "Exploiting Relevance for Online Decision-Making in High-Dimensions", "comments": "Accepted for publication in IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many sequential decision-making tasks require choosing at each decision step\nthe right action out of the vast set of possibilities by extracting actionable\nintelligence from high-dimensional data streams. Most of the times, the\nhigh-dimensionality of actions and data makes learning of the optimal actions\nby traditional learning methods impracticable. In this work, we investigate how\nto discover and leverage sparsity in actions and data to enable fast learning.\nAs our learning model, we consider a structured contextual multi-armed bandit\n(CMAB) with high-dimensional arm (action) and context (data) sets, where the\nrewards depend only on a few relevant dimensions of the joint context-arm set,\npossibly in a non-linear way. We depart from the prior work by assuming a\nhigh-dimensional, continuum set of arms, and allow relevant context dimensions\nto vary for each arm. We propose a new online learning algorithm called {\\em\nCMAB with Relevance Learning} (CMAB-RL) and prove that its time-averaged regret\nasymptotically goes to zero when the expected reward varies smoothly in\ncontexts and arms. CMAB-RL enjoys a substantially improved regret bound\ncompared to classical CMAB algorithms whose regrets depend on dimensions $d_x$\nand $d_a$ of the context and arm sets. Importantly, we show that when the\nlearner has prior knowledge on sparsity, given in terms of upper bounds\n$\\overline{d}_x$ and $\\overline{d}_a$ on the number of relevant dimensions,\nthen CMAB-RL achieves $\\tilde{O}(T^{1-1/(2+2\\overline{d}_x +\\overline{d}_a)})$\nregret. Finally, we illustrate how CMAB algorithms can be used for optimal\npersonalized blood glucose control in type 1 diabetes mellitus patients, and\nshow that CMAB-RL outperforms other contextual MAB algorithms in this task.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 13:52:11 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 13:26:00 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Turgay", "Eralp", ""], ["Bulucu", "Cem", ""], ["Tekin", "Cem", ""]]}, {"id": "1907.00787", "submitter": "Larissa Triess", "authors": "Larissa T. Triess, David Peter, Christoph B. Rist, Markus Enzweiler,\n  J. Marius Z\\\"ollner", "title": "CNN-based synthesis of realistic high-resolution LiDAR data", "comments": "2019 IEEE Intelligent Vehicles Symposium (IV)", "journal-ref": null, "doi": "10.1109/IVS.2019.8813771", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel CNN-based approach for synthesizing\nhigh-resolution LiDAR point cloud data. Our approach generates semantically and\nperceptually realistic results with guidance from specialized loss-functions.\nFirst, we utilize a modified per-point loss that addresses missing LiDAR point\nmeasurements. Second, we align the quality of our generated output with\nreal-world sensor data by applying a perceptual loss. In large-scale\nexperiments on real-world datasets, we evaluate both the geometric accuracy and\nsemantic segmentation performance using our generated data vs. ground truth. In\na mean opinion score testing we further assess the perceptual quality of our\ngenerated point clouds. Our results demonstrate a significant quantitative and\nqualitative improvement in both geometry and semantics over traditional non\nCNN-based up-sampling methods.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 12:36:18 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Triess", "Larissa T.", ""], ["Peter", "David", ""], ["Rist", "Christoph B.", ""], ["Enzweiler", "Markus", ""], ["Z\u00f6llner", "J. Marius", ""]]}, {"id": "1907.00806", "submitter": "Sijing Li", "authors": "Sijing Li, Zhiwen Zhang, Hongkai Zhao", "title": "A data-driven approach for multiscale elliptic PDEs with random\n  coefficients based on intrinsic dimension reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-driven approach to solve multiscale elliptic PDEs with\nrandom coefficients based on the intrinsic low dimension structure of the\nunderlying elliptic differential operators. Our method consists of offline and\nonline stages. At the offline stage, a low dimension space and its basis are\nextracted from the data to achieve significant dimension reduction in the\nsolution space. At the online stage, the extracted basis will be used to solve\na new multiscale elliptic PDE efficiently. The existence of low dimension\nstructure is established by showing the high separability of the underlying\nGreen's functions. Different online construction methods are proposed depending\non the problem setup. We provide error analysis based on the sampling error and\nthe truncation threshold in building the data-driven basis. Finally, we present\nnumerical examples to demonstrate the accuracy and efficiency of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:12:27 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Li", "Sijing", ""], ["Zhang", "Zhiwen", ""], ["Zhao", "Hongkai", ""]]}, {"id": "1907.00811", "submitter": "Xiaoyang Wang", "authors": "Xiaoyang Wang, Ioannis Mavromatis, Andrea Tassi, Raul\n  Santos-Rodriguez, Robert J. Piechocki", "title": "Location Anomalies Detection for Connected and Autonomous Vehicles", "comments": "Accepted to IEEE CAVS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future Connected and Automated Vehicles (CAV), and more generally ITS, will\nform a highly interconnected system. Such a paradigm is referred to as the\nInternet of Vehicles (herein Internet of CAVs) and is a prerequisite to\norchestrate traffic flows in cities. For optimal decision making and\nsupervision, traffic centres will have access to suitably anonymized CAV\nmobility information. Safe and secure operations will then be contingent on\nearly detection of anomalies. In this paper, a novel unsupervised learning\nmodel based on deep autoencoder is proposed to detect the self-reported\nlocation anomaly in CAVs, using vehicle locations and the Received Signal\nStrength Indicator (RSSI) as features. Quantitative experiments on simulation\ndatasets show that the proposed approach is effective and robust in detecting\nself-reported location anomalies.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:16:54 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Wang", "Xiaoyang", ""], ["Mavromatis", "Ioannis", ""], ["Tassi", "Andrea", ""], ["Santos-Rodriguez", "Raul", ""], ["Piechocki", "Robert J.", ""]]}, {"id": "1907.00813", "submitter": "Matthew Joseph", "authors": "Matthew Joseph, Jieming Mao, Aaron Roth", "title": "Exponential Separations in Local Differential Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a general connection between the communication complexity of\ntwo-player games and the sample complexity of their multi-player locally\nprivate analogues. We use this connection to prove sample complexity lower\nbounds for locally differentially private protocols as straightforward\ncorollaries of results from communication complexity. In particular, we 1) use\na communication lower bound for the hidden layers problem to prove an\nexponential sample complexity separation between sequentially and fully\ninteractive locally private protocols, and 2) use a communication lower bound\nfor the pointer chasing problem to prove an exponential sample complexity\nseparation between $k$ round and $k+1$ round sequentially interactive locally\nprivate protocols, for every $k$.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:18:39 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 15:28:35 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 14:10:49 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Joseph", "Matthew", ""], ["Mao", "Jieming", ""], ["Roth", "Aaron", ""]]}, {"id": "1907.00821", "submitter": "Nikola Simidjievski", "authors": "Nikola Simidjievski, Ljup\\v{c}o Todorovski, Ju\\v{s} Kocijan, Sa\\v{s}o\n  D\\v{z}eroski", "title": "Equation Discovery for Nonlinear System Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Equation discovery methods enable modelers to combine domain-specific\nknowledge and system identification to construct models most suitable for a\nselected modeling task. The method described and evaluated in this paper can be\nused as a nonlinear system identification method for gray-box modeling. It\nconsists of two interlaced parts of modeling that are computer-aided. The first\nperforms computer-aided identification of a model structure composed of\nelements selected from user-specified domain-specific modeling knowledge, while\nthe second part performs parameter estimation. In this paper, recent\ndevelopments of the equation discovery method called process-based modeling,\nsuited for nonlinear system identification, are elaborated and illustrated on\ntwo continuous-time case studies. The first case study illustrates the use of\nthe process-based modeling on synthetic data while the second case-study\nevaluates on measured data for a standard system-identification benchmark. The\nexperimental results clearly demonstrate the ability of process-based modeling\nto reconstruct both model structure and parameters from measured data.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:28:40 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Simidjievski", "Nikola", ""], ["Todorovski", "Ljup\u010do", ""], ["Kocijan", "Ju\u0161", ""], ["D\u017eeroski", "Sa\u0161o", ""]]}, {"id": "1907.00825", "submitter": "H{\\aa}vard Kvamme", "authors": "H{\\aa}vard Kvamme, {\\O}rnulf Borgan, Ida Scheel", "title": "Time-to-Event Prediction with Neural Networks and Cox Regression", "comments": null, "journal-ref": "Journal of Machine Learning Research, 20(129):1-30, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  New methods for time-to-event prediction are proposed by extending the Cox\nproportional hazards model with neural networks. Building on methodology from\nnested case-control studies, we propose a loss function that scales well to\nlarge data sets, and enables fitting of both proportional and non-proportional\nextensions of the Cox model. Through simulation studies, the proposed loss\nfunction is verified to be a good approximation for the Cox partial\nlog-likelihood. The proposed methodology is compared to existing methodologies\non real-world data sets, and is found to be highly competitive, typically\nyielding the best performance in terms of Brier score and binomial\nlog-likelihood. A python package for the proposed methods is available at\nhttps://github.com/havakv/pycox.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:34:03 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 10:32:24 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Kvamme", "H\u00e5vard", ""], ["Borgan", "\u00d8rnulf", ""], ["Scheel", "Ida", ""]]}, {"id": "1907.00832", "submitter": "Xing Gao", "authors": "Xing Gao, Hongkai Xiong, Pascal Frossard", "title": "iPool -- Information-based Pooling in Hierarchical Graph Neural Networks", "comments": "Typos corrected and one reference added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of data science, the analysis of network or graph data has\nbecome a very timely research problem. A variety of recent works have been\nproposed to generalize neural networks to graphs, either from a spectral graph\ntheory or a spatial perspective. The majority of these works however focus on\nadapting the convolution operator to graph representation. At the same time,\nthe pooling operator also plays an important role in distilling multiscale and\nhierarchical representations but it has been mostly overlooked so far. In this\npaper, we propose a parameter-free pooling operator, called iPool, that permits\nto retain the most informative features in arbitrary graphs. With the argument\nthat informative nodes dominantly characterize graph signals, we propose a\ncriterion to evaluate the amount of information of each node given its\nneighbors, and theoretically demonstrate its relationship to neighborhood\nconditional entropy. This new criterion determines how nodes are selected and\ncoarsened graphs are constructed in the pooling layer. The resulting\nhierarchical structure yields an effective isomorphism-invariant representation\nof networked data in arbitrary topologies. The proposed strategy is evaluated\nin terms of graph classification on a collection of public graph datasets,\nincluding bioinformatics and social networks, and achieves state-of-the-art\nperformance on most of the datasets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:48:49 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 06:55:29 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Gao", "Xing", ""], ["Xiong", "Hongkai", ""], ["Frossard", "Pascal", ""]]}, {"id": "1907.00865", "submitter": "Sebastian Farquhar", "authors": "Sebastian Farquhar, Michael Osborne, Yarin Gal", "title": "Radial Bayesian Neural Networks: Beyond Discrete Support In Large-Scale\n  Bayesian Deep Learning", "comments": null, "journal-ref": "AI Stats, PMLR 108:1352-1362, 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Radial Bayesian Neural Networks (BNNs): a variational approximate\nposterior for BNNs which scales well to large models while maintaining a\ndistribution over weight-space with full support. Other scalable Bayesian deep\nlearning methods, like MC dropout or deep ensembles, have discrete support-they\nassign zero probability to almost all of the weight-space. Unlike these\ndiscrete support methods, Radial BNNs' full support makes them suitable for use\nas a prior for sequential inference. In addition, they solve the conceptual\nchallenges with the a priori implausibility of weight distributions with\ndiscrete support. The Radial BNN is motivated by avoiding a sampling problem in\n'mean-field' variational inference (MFVI) caused by the so-called 'soap-bubble'\npathology of multivariate Gaussians. We show that, unlike MFVI, Radial BNNs are\nrobust to hyperparameters and can be efficiently applied to a challenging\nreal-world medical application without needing ad-hoc tweaks and intensive\ntuning. In fact, in this setting Radial BNNs out-perform discrete-support\nmethods like MC dropout. Lastly, by using Radial BNNs as a theoretically\nprincipled, robust alternative to MFVI we make significant strides in a\nBayesian continual learning evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:25:50 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 09:22:38 GMT"}, {"version": "v3", "created": "Tue, 7 Apr 2020 10:38:39 GMT"}, {"version": "v4", "created": "Mon, 31 May 2021 11:12:44 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Farquhar", "Sebastian", ""], ["Osborne", "Michael", ""], ["Gal", "Yarin", ""]]}, {"id": "1907.00868", "submitter": "Lucas Beyer", "authors": "Lucas Beyer, Damien Vincent, Olivier Teboul, Sylvain Gelly, Matthieu\n  Geist, Olivier Pietquin", "title": "MULEX: Disentangling Exploitation from Exploration in Deep RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An agent learning through interactions should balance its action selection\nprocess between probing the environment to discover new rewards and using the\ninformation acquired in the past to adopt useful behaviour. This trade-off is\nusually obtained by perturbing either the agent's actions (e.g., e-greedy or\nGibbs sampling) or the agent's parameters (e.g., NoisyNet), or by modifying the\nreward it receives (e.g., exploration bonus, intrinsic motivation, or\nhand-shaped rewards). Here, we adopt a disruptive but simple and generic\nperspective, where we explicitly disentangle exploration and exploitation.\nDifferent losses are optimized in parallel, one of them coming from the true\nobjective (maximizing cumulative rewards from the environment) and others being\nrelated to exploration. Every loss is used in turn to learn a policy that\ngenerates transitions, all shared in a single replay buffer. Off-policy methods\nare then applied to these transitions to optimize each loss. We showcase our\napproach on a hard-exploration environment, show its sample-efficiency and\nrobustness, and discuss further implications.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:28:02 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Beyer", "Lucas", ""], ["Vincent", "Damien", ""], ["Teboul", "Olivier", ""], ["Gelly", "Sylvain", ""], ["Geist", "Matthieu", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1907.00878", "submitter": "Jan Niclas Reimann", "authors": "Jan Niclas Reimann, Andreas Schwung", "title": "Neural Logic Rule Layers", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.10091.59687", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite their great success in recent years, deep neural networks (DNN) are\nmainly black boxes where the results obtained by running through the network\nare difficult to understand and interpret. Compared to e.g. decision trees or\nbayesian classifiers, DNN suffer from bad interpretability where we understand\nby interpretability, that a human can easily derive the relations modeled by\nthe network. A reasonable way to provide interpretability for humans are\nlogical rules. In this paper we propose neural logic rule layers (NLRL) which\nare able to represent arbitrary logic rules in terms of their conjunctive and\ndisjunctive normal forms. Using various NLRL within one layer and\ncorrespondingly stacking various layers, we are able to represent arbitrary\ncomplex rules by the resulting neural network architecture. The NLRL are\nend-to-end trainable allowing to learn logic rules directly from available data\nsets. Experiments show that NLRL-enhanced neural networks can learn to model\narbitrary complex logic and perform arithmetic operation over the input values.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:49:06 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Reimann", "Jan Niclas", ""], ["Schwung", "Andreas", ""]]}, {"id": "1907.00880", "submitter": "Lei Yang", "authors": "Lei Yang, Xiaojun Chen, Shuhuang Xiang", "title": "Sparse Solutions of a Class of Constrained Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a well-known sparse optimization problem that aims\nto find a sparse solution of a possibly noisy underdetermined system of linear\nequations. Mathematically, it can be modeled in a unified manner by minimizing\n$\\|\\bf{x}\\|_p^p$ subject to $\\|A\\bf{x}-\\bf{b}\\|_q\\leq\\sigma$ for given $A \\in\n\\mathbb{R}^{m \\times n}$, $\\bf{b}\\in\\mathbb{R}^m$, $\\sigma \\geq0$, $0\\leq p\\leq\n1$ and $q \\geq 1$. We then study various properties of the optimal solutions of\nthis problem. Specifically, without any condition on the matrix $A$, we provide\nupper bounds in cardinality and infinity norm for the optimal solutions, and\nshow that all optimal solutions must be on the boundary of the feasible set\nwhen $0<p<1$. Moreover, for $q \\in \\{1,\\infty\\}$, we show that the problem with\n$0<p<1$ has a finite number of optimal solutions and prove that there exists\n$0<p^*<1$ such that the solution set of the problem with any $0<p<p^*$ is\ncontained in the solution set of the problem with $p=0$ and there further\nexists $0<\\bar{p}<p^*$ such that the solution set of the problem with any\n$0<p\\leq\\bar{p}$ remains unchanged. An estimation of such $p^*$ is also\nprovided. In addition, to solve the constrained nonconvex non-Lipschitz\n$L_p$-$L_1$ problem ($0<p<1$ and $q=1$), we propose a smoothing penalty method\nand show that, under some mild conditions, any cluster point of the sequence\ngenerated is a KKT point of our problem. Some numerical examples are given to\nimplicitly illustrate the theoretical results and show the efficiency of the\nproposed algorithm for the constrained $L_p$-$L_1$ problem under different\nnoises.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:53:27 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 11:25:13 GMT"}, {"version": "v3", "created": "Mon, 19 Oct 2020 04:39:19 GMT"}, {"version": "v4", "created": "Mon, 9 Nov 2020 03:18:39 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Yang", "Lei", ""], ["Chen", "Xiaojun", ""], ["Xiang", "Shuhuang", ""]]}, {"id": "1907.00884", "submitter": "Nicholas Denis", "authors": "Nick Denis", "title": "On mechanisms for transfer using landmark value functions in multi-task\n  lifelong reinforcement learning", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning across different reinforcement learning (RL) tasks is\nbecoming an increasingly valuable area of research. We consider a goal-based\nmulti-task RL framework and mechanisms by which previously solved tasks can\nreduce sample complexity and regret when the agent is faced with a new task.\nSpecifically, we introduce two metrics on the state space that encode notions\nof traversibility of the state space for an agent. Using these metrics a\ntopological covering is constructed by way of a set of landmark states in a\nfully self-supervised manner. We show that these landmark coverings confer\ntheoretical advantages for transfer learning within the goal-based multi-task\nRL setting. Specifically, we demonstrate three mechanisms by which landmark\ncoverings can be used for successful transfer learning. First, we extend the\nLandmark Options Via Reflection (LOVR) framework to this new topological\ncovering; second, we use the landmark-centric value functions themselves as\nfeatures and define a greedy zombie policy that achieves near oracle\nperformance on a sequence of zero-shot transfer tasks; finally, motivated by\nthe second transfer mechanism, we introduce a learned reward function that\nprovides a more dense reward signal for goal-based RL. Our novel topological\nlandmark covering confers beneficial theoretical results, bounding the Q values\nat each state-action pair. In doing so, we introduce a mechanism that performs\naction-pruning at infeasible actions which cannot possibly be part of an\noptimal policy for the current goal.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:56:24 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Denis", "Nick", ""]]}, {"id": "1907.00895", "submitter": "Roland S. Zimmermann", "authors": "Roland S. Zimmermann", "title": "Comment on \"Adv-BNN: Improved Adversarial Defense through Robust\n  Bayesian Neural Network\"", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A recent paper by Liu et al. combines the topics of adversarial training and\nBayesian Neural Networks (BNN) and suggests that adversarially trained BNNs are\nmore robust against adversarial attacks than their non-Bayesian counterparts.\nHere, I analyze the proposed defense and suggest that one needs to adjust the\nadversarial attack to incorporate the stochastic nature of a Bayesian network\nto perform an accurate evaluation of its robustness. Using this new type of\nattack I show that there appears to be no strong evidence for higher robustness\nof the adversarially trained BNNs.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 16:11:28 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Zimmermann", "Roland S.", ""]]}, {"id": "1907.00909", "submitter": "Pieter Gijsbers", "authors": "Pieter Gijsbers, Erin LeDell, Janek Thomas, S\\'ebastien Poirier, Bernd\n  Bischl, Joaquin Vanschoren", "title": "An Open Source AutoML Benchmark", "comments": "Accepted paper at the AutoML Workshop at ICML 2019. Code:\n  https://github.com/openml/automlbenchmark/ Accompanying website:\n  https://openml.github.io/automlbenchmark/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, an active field of research has developed around automated\nmachine learning (AutoML). Unfortunately, comparing different AutoML systems is\nhard and often done incorrectly. We introduce an open, ongoing, and extensible\nbenchmark framework which follows best practices and avoids common mistakes.\nThe framework is open-source, uses public datasets and has a website with\nup-to-date results. We use the framework to conduct a thorough comparison of 4\nAutoML systems across 39 datasets and analyze the results.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 16:28:11 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Gijsbers", "Pieter", ""], ["LeDell", "Erin", ""], ["Thomas", "Janek", ""], ["Poirier", "S\u00e9bastien", ""], ["Bischl", "Bernd", ""], ["Vanschoren", "Joaquin", ""]]}, {"id": "1907.00921", "submitter": "Kalesha Bullard", "authors": "Kalesha Bullard, Yannick Schroecker, Sonia Chernova", "title": "Active Learning within Constrained Environments through Imitation of an\n  Expert Questioner", "comments": "In Conference Proceedings for IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning agents typically employ a query selection algorithm which\nsolely considers the agent's learning objectives. However, this may be\ninsufficient in more realistic human domains. This work uses imitation learning\nto enable an agent in a constrained environment to concurrently reason about\nboth its internal learning goals and environmental constraints externally\nimposed, all within its objective function. Experiments are conducted on a\nconcept learning task to test generalization of the proposed algorithm to\ndifferent environmental conditions and analyze how time and resource\nconstraints impact efficacy of solving the learning problem. Our findings show\nthe environmentally-aware learning agent is able to statistically outperform\nall other active learners explored under most of the constrained conditions. A\nkey implication is adaptation for active learning agents to more realistic\nhuman environments, where constraints are often externally imposed on the\nlearner.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 16:53:47 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Bullard", "Kalesha", ""], ["Schroecker", "Yannick", ""], ["Chernova", "Sonia", ""]]}, {"id": "1907.00924", "submitter": "Giorgia Franchini", "authors": "Giorgia Franchini, Mathilde Galinier, Micaela Verucchi", "title": "Mise en abyme with artificial intelligence: how to predict the accuracy\n  of NN, applied to hyper-parameter tuning", "comments": "The research leading to these results has received funding from the\n  European Union's Horizon 2020 Programme under the CLASS Project\n  (https://class-project.eu/), grant agreement n 780622", "journal-ref": "INNS Big Data and Deep Learning conference, 286-295, Springer,\n  2018", "doi": "10.1007/978-3-030-16841-4_30", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of deep learning, the costliest phase from a computational\npoint of view is the full training of the learning algorithm. However, this\nprocess is to be used a significant number of times during the design of a new\nartificial neural network, leading therefore to extremely expensive operations.\nHere, we propose a low-cost strategy to predict the accuracy of the algorithm,\nbased only on its initial behaviour. To do so, we train the network of interest\nup to convergence several times, modifying its characteristics at each\ntraining. The initial and final accuracies observed during this beforehand\nprocess are stored in a database. We then make use of both curve fitting and\nSupport Vector Machines techniques, the latter being trained on the created\ndatabase, to predict the accuracy of the network, given its accuracy on the\nprimary iterations of its learning. This approach can be of particular interest\nwhen the space of the characteristics of the network is notably large or when\nits full training is highly time-consuming. The results we obtained are\npromising and encouraged us to apply this strategy to a topical issue:\nhyper-parameter optimisation (HO). In particular, we focused on the HO of a\nconvolutional neural network for the classification of the databases MNIST and\nCIFAR-10. By using our method of prediction, and an algorithm implemented by us\nfor a probabilistic exploration of the hyper-parameter space, we were able to\nfind the hyper-parameter settings corresponding to the optimal accuracies\nalready known in literature, at a quite low-cost.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 14:38:39 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Franchini", "Giorgia", ""], ["Galinier", "Mathilde", ""], ["Verucchi", "Micaela", ""]]}, {"id": "1907.00927", "submitter": "Adarsh Prasad", "authors": "Adarsh Prasad, Sivaraman Balakrishnan, Pradeep Ravikumar", "title": "A Unified Approach to Robust Mean Estimation", "comments": "51 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop connections between two seemingly disparate, but\ncentral, models in robust statistics: Huber's epsilon-contamination model and\nthe heavy-tailed noise model. We provide conditions under which this connection\nprovides near-statistically-optimal estimators. Building on this connection, we\nprovide a simple variant of recent computationally-efficient algorithms for\nmean estimation in Huber's model, which given our connection entails that the\nsame efficient sample-pruning based estimators is simultaneously robust to\nheavy-tailed noise and Huber contamination. Furthermore, we complement our\nefficient algorithms with statistically-optimal albeit computationally\nintractable estimators, which are simultaneously optimally robust in both\nmodels. We study the empirical performance of our proposed estimators on\nsynthetic datasets, and find that our methods convincingly outperform a variety\nof practical baselines.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:03:11 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Prasad", "Adarsh", ""], ["Balakrishnan", "Sivaraman", ""], ["Ravikumar", "Pradeep", ""]]}, {"id": "1907.00941", "submitter": "Yi Liu", "authors": "Yi Liu, Hao Yuan, Zhengyang Wang, Shuiwang Ji", "title": "Global Pixel Transformers for Virtual Staining of Microscopy Images", "comments": "10 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualizing the details of different cellular structures is of great\nimportance to elucidate cellular functions. However, it is challenging to\nobtain high quality images of different structures directly due to complex\ncellular environments. Fluorescence staining is a popular technique to label\ndifferent structures but has several drawbacks. In particular, label staining\nis time consuming and may affect cell morphology, and simultaneous labels are\ninherently limited. This raises the need of building computational models to\nlearn relationships between unlabeled microscopy images and labeled\nfluorescence images, and to infer fluorescence labels of other microscopy\nimages excluding the physical staining process. We propose to develop a novel\ndeep model for virtual staining of unlabeled microscopy images. We first\npropose a novel network layer, known as the global pixel transformer layer,\nthat fuses global information from inputs effectively. The proposed global\npixel transformer layer can generate outputs with arbitrary dimensions, and can\nbe employed for all the regular, down-sampling, and up-sampling operators. We\nthen incorporate our proposed global pixel transformer layers and dense blocks\nto build an U-Net like network. We believe such a design can promote feature\nreusing between layers. In addition, we propose a multi-scale input strategy to\nencourage networks to capture features at different scales. We conduct\nevaluations across various fluorescence image prediction tasks to demonstrate\nthe effectiveness of our approach. Both quantitative and qualitative results\nshow that our method outperforms the state-of-the-art approach significantly.\nIt is also shown that our proposed global pixel transformer layer is useful to\nimprove the fluorescence image prediction results.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:28:08 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 02:42:32 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 16:13:19 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Liu", "Yi", ""], ["Yuan", "Hao", ""], ["Wang", "Zhengyang", ""], ["Ji", "Shuiwang", ""]]}, {"id": "1907.00953", "submitter": "Alex Lee", "authors": "Alex X. Lee, Anusha Nagabandi, Pieter Abbeel, Sergey Levine", "title": "Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a\n  Latent Variable Model", "comments": "Project website: https://alexlee-gk.github.io/slac/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) algorithms can use high-capacity deep\nnetworks to learn directly from image observations. However, these\nhigh-dimensional observation spaces present a number of challenges in practice,\nsince the policy must now solve two problems: representation learning and task\nlearning. In this work, we tackle these two problems separately, by explicitly\nlearning latent representations that can accelerate reinforcement learning from\nimages. We propose the stochastic latent actor-critic (SLAC) algorithm: a\nsample-efficient and high-performing RL algorithm for learning policies for\ncomplex continuous control tasks directly from high-dimensional image inputs.\nSLAC provides a novel and principled approach for unifying stochastic\nsequential models and RL into a single method, by learning a compact latent\nrepresentation and then performing RL in the model's learned latent space. Our\nexperimental evaluation demonstrates that our method outperforms both\nmodel-free and model-based alternatives in terms of final performance and\nsample efficiency, on a range of difficult image-based control tasks. Our code\nand videos of our results are available at our website.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:45:09 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 15:07:43 GMT"}, {"version": "v3", "created": "Tue, 11 Aug 2020 16:02:04 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 12:21:51 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Lee", "Alex X.", ""], ["Nagabandi", "Anusha", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1907.00959", "submitter": "Dimitrios Stamoulis", "authors": "Dimitrios Stamoulis, Ruizhou Ding, Di Wang, Dimitrios Lymberopoulos,\n  Bodhi Priyantha, Jie Liu, Diana Marculescu", "title": "Single-Path Mobile AutoML: Efficient ConvNet Design and NAS\n  Hyperparameter Optimization", "comments": "Detailed extension (journal) of the Single-Path NAS ECMLPKDD'19 paper\n  (arXiv:1904.02877)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we reduce the search cost of Neural Architecture Search (NAS) from days\ndown to only few hours? NAS methods automate the design of Convolutional\nNetworks (ConvNets) under hardware constraints and they have emerged as key\ncomponents of AutoML frameworks. However, the NAS problem remains challenging\ndue to the combinatorially large design space and the significant search time\n(at least 200 GPU-hours). In this work, we alleviate the NAS search cost down\nto less than 3 hours, while achieving state-of-the-art image classification\nresults under mobile latency constraints. We propose a novel differentiable NAS\nformulation, namely Single-Path NAS, that uses one single-path\nover-parameterized ConvNet to encode all architectural decisions based on\nshared convolutional kernel parameters, hence drastically decreasing the search\noverhead. Single-Path NAS achieves state-of-the-art top-1 ImageNet accuracy\n(75.62%), hence outperforming existing mobile NAS methods in similar latency\nsettings (~80ms). In particular, we enhance the accuracy-runtime trade-off in\ndifferentiable NAS by treating the Squeeze-and-Excitation path as a fully\nsearchable operation with our novel single-path encoding. Our method has an\noverall cost of only 8 epochs (24 TPU-hours), which is up to 5,000x faster\ncompared to prior work. Moreover, we study how different NAS formulation\nchoices affect the performance of the designed ConvNets. Furthermore, we\nexploit the efficiency of our method to answer an interesting question: instead\nof empirically tuning the hyperparameters of the NAS solver (as in prior work),\ncan we automatically find the hyperparameter values that yield the desired\naccuracy-runtime trade-off? We open-source our entire codebase at:\nhttps://github.com/dstamoulis/single-path-nas.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:52:55 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Stamoulis", "Dimitrios", ""], ["Ding", "Ruizhou", ""], ["Wang", "Di", ""], ["Lymberopoulos", "Dimitrios", ""], ["Priyantha", "Bodhi", ""], ["Liu", "Jie", ""], ["Marculescu", "Diana", ""]]}, {"id": "1907.00971", "submitter": "Philippe Esling", "authors": "Philippe Esling, Naotake Masuda, Adrien Bardet, Romeo Despres, Axel\n  Chemla--Romeu-Santos", "title": "Universal audio synthesizer control with normalizing flows", "comments": "DaFX 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.MM cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ubiquity of sound synthesizers has reshaped music production and even\nentirely defined new music genres. However, the increasing complexity and\nnumber of parameters in modern synthesizers make them harder to master. Hence,\nthe development of methods allowing to easily create and explore with\nsynthesizers is a crucial need. Here, we introduce a novel formulation of audio\nsynthesizer control. We formalize it as finding an organized latent audio space\nthat represents the capabilities of a synthesizer, while constructing an\ninvertible mapping to the space of its parameters. By using this formulation,\nwe show that we can address simultaneously automatic parameter inference,\nmacro-control learning and audio-based preset exploration within a single\nmodel. To solve this new formulation, we rely on Variational Auto-Encoders\n(VAE) and Normalizing Flows (NF) to organize and map the respective auditory\nand parameter spaces. We introduce the disentangling flows, which allow to\nperform the invertible mapping between separate latent spaces, while steering\nthe organization of some latent dimensions to match target variation factors by\nsplitting the objective as partial density evaluation. We evaluate our proposal\nagainst a large set of baseline models and show its superiority in both\nparameter inference and audio reconstruction. We also show that the model\ndisentangles the major factors of audio variations as latent dimensions, that\ncan be directly used as macro-parameters. We also show that our model is able\nto learn semantic controls of a synthesizer by smoothly mapping to its\nparameters. Finally, we discuss the use of our model in creative applications\nand its real-time implementation in Ableton Live\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:49:07 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Esling", "Philippe", ""], ["Masuda", "Naotake", ""], ["Bardet", "Adrien", ""], ["Despres", "Romeo", ""], ["Chemla--Romeu-Santos", "Axel", ""]]}, {"id": "1907.00973", "submitter": "Ivan Ezhov", "authors": "Ivan Ezhov, Jana Lipkova, Suprosanna Shit, Florian Kofler, Nore\n  Collomb, Benjamin Lemasson, Emmanuel Barbier, Bjoern Menze", "title": "Neural parameters estimation for brain tumor growth modeling", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-32245-8_87", "report-no": null, "categories": "q-bio.QM cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the dynamics of brain tumor progression is essential for\noptimal treatment planning. Cast in a mathematical formulation, it is typically\nviewed as evaluation of a system of partial differential equations, wherein the\nphysiological processes that govern the growth of the tumor are considered. To\npersonalize the model, i.e. find a relevant set of parameters, with respect to\nthe tumor dynamics of a particular patient, the model is informed from\nempirical data, e.g., medical images obtained from diagnostic modalities, such\nas magnetic-resonance imaging. Existing model-observation coupling schemes\nrequire a large number of forward integrations of the biophysical model and\nrely on simplifying assumption on the functional form, linking the output of\nthe model with the image information. In this work, we propose a learning-based\ntechnique for the estimation of tumor growth model parameters from medical\nscans. The technique allows for explicit evaluation of the posterior\ndistribution of the parameters by sequentially training a mixture-density\nnetwork, relaxing the constraint on the functional form and reducing the number\nof samples necessary to propagate through the forward model for the estimation.\nWe test the method on synthetic and real scans of rats injected with brain\ntumors to calibrate the model and to predict tumor progression.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:57:14 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 19:04:45 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Ezhov", "Ivan", ""], ["Lipkova", "Jana", ""], ["Shit", "Suprosanna", ""], ["Kofler", "Florian", ""], ["Collomb", "Nore", ""], ["Lemasson", "Benjamin", ""], ["Barbier", "Emmanuel", ""], ["Menze", "Bjoern", ""]]}, {"id": "1907.01003", "submitter": "Wieland Brendel", "authors": "Wieland Brendel, Jonas Rauber, Matthias K\\\"ummerer, Ivan\n  Ustyuzhaninov, Matthias Bethge", "title": "Accurate, reliable and fast robustness evaluation", "comments": "Accepted at the 2019 Conference on Neural Information Processing\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Throughout the past five years, the susceptibility of neural networks to\nminimal adversarial perturbations has moved from a peculiar phenomenon to a\ncore issue in Deep Learning. Despite much attention, however, progress towards\nmore robust models is significantly impaired by the difficulty of evaluating\nthe robustness of neural network models. Today's methods are either fast but\nbrittle (gradient-based attacks), or they are fairly reliable but slow (score-\nand decision-based attacks). We here develop a new set of gradient-based\nadversarial attacks which (a) are more reliable in the face of gradient-masking\nthan other gradient-based attacks, (b) perform better and are more query\nefficient than current state-of-the-art gradient-based attacks, (c) can be\nflexibly adapted to a wide range of adversarial criteria and (d) require\nvirtually no hyperparameter tuning. These findings are carefully validated\nacross a diverse set of six different models and hold for L0, L1, L2 and Linf\nin both targeted as well as untargeted scenarios. Implementations will soon be\navailable in all major toolboxes (Foolbox, CleverHans and ART). We hope that\nthis class of attacks will make robustness evaluations easier and more\nreliable, thus contributing to more signal in the search for more robust\nmachine learning models.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 18:18:10 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 18:32:51 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Brendel", "Wieland", ""], ["Rauber", "Jonas", ""], ["K\u00fcmmerer", "Matthias", ""], ["Ustyuzhaninov", "Ivan", ""], ["Bethge", "Matthias", ""]]}, {"id": "1907.01011", "submitter": "Zhun Liu", "authors": "Paul Pu Liang, Zhun Liu, Yao-Hung Hubert Tsai, Qibin Zhao, Ruslan\n  Salakhutdinov, Louis-Philippe Morency", "title": "Learning Representations from Imperfect Time Series Data via Tensor Rank\n  Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increased interest in multimodal language processing\nincluding multimodal dialog, question answering, sentiment analysis, and speech\nrecognition. However, naturally occurring multimodal data is often imperfect as\na result of imperfect modalities, missing entries or noise corruption. To\naddress these concerns, we present a regularization method based on tensor rank\nminimization. Our method is based on the observation that high-dimensional\nmultimodal time series data often exhibit correlations across time and\nmodalities which leads to low-rank tensor representations. However, the\npresence of noise or incomplete values breaks these correlations and results in\ntensor representations of higher rank. We design a model to learn such tensor\nrepresentations and effectively regularize their rank. Experiments on\nmultimodal language data show that our model achieves good results across\nvarious levels of imperfection.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 18:40:52 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Liang", "Paul Pu", ""], ["Liu", "Zhun", ""], ["Tsai", "Yao-Hung Hubert", ""], ["Zhao", "Qibin", ""], ["Salakhutdinov", "Ruslan", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1907.01022", "submitter": "Yunlong Wang", "authors": "Kezi Yu, Yunlong Wang, Yong Cai, Cao Xiao, Emily Zhao, Lucas Glass,\n  Jimeng Sun", "title": "Rare Disease Detection by Sequence Modeling with Generative Adversarial\n  Networks", "comments": "International Conference on Machine Learning (ICML) 2019 time series\n  workshop accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rare diseases affecting 350 million individuals are commonly associated with\ndelay in diagnosis or misdiagnosis. To improve those patients' outcome, rare\ndisease detection is an important task for identifying patients with rare\nconditions based on longitudinal medical claims. In this paper, we present a\ndeep learning method for detecting patients with exocrine pancreatic\ninsufficiency (EPI) (a rare disease). The contribution includes 1) a large\nlongitudinal study using 7 years medical claims from 1.8 million patients\nincluding 29,149 EPI patients, 2) a new deep learning model using generative\nadversarial networks (GANs) to boost rare disease class, and also leveraging\nrecurrent neural networks to model patient sequence data, 3) an accurate\nprediction with 0.56 PR-AUC which outperformed benchmark models in terms of\nprecision and recall.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 19:18:31 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Yu", "Kezi", ""], ["Wang", "Yunlong", ""], ["Cai", "Yong", ""], ["Xiao", "Cao", ""], ["Zhao", "Emily", ""], ["Glass", "Lucas", ""], ["Sun", "Jimeng", ""]]}, {"id": "1907.01030", "submitter": "Wei Zhou", "authors": "Eugen Beck, Wei Zhou, Ralf Schl\\\"uter, Hermann Ney", "title": "LSTM Language Models for LVCSR in First-Pass Decoding and\n  Lattice-Rescoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  LSTM based language models are an important part of modern LVCSR systems as\nthey significantly improve performance over traditional backoff language\nmodels. Incorporating them efficiently into decoding has been notoriously\ndifficult. In this paper we present an approach based on a combination of\none-pass decoding and lattice rescoring. We perform decoding with the LSTM-LM\nin the first pass but recombine hypothesis that share the last two words,\nafterwards we rescore the resulting lattice. We run our systems on GPGPU\nequipped machines and are able to produce competitive results on the Hub5'00\nand Librispeech evaluation corpora with a runtime better than real-time. In\naddition we shortly investigate the possibility to carry out the full sum over\nall state-sequences belonging to a given word-hypothesis during decoding\nwithout recombination.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 19:29:04 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Beck", "Eugen", ""], ["Zhou", "Wei", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1907.01040", "submitter": "Niki Kilbertus", "authors": "Niki Kilbertus, Philip J. Ball, Matt J. Kusner, Adrian Weller, Ricardo\n  Silva", "title": "The Sensitivity of Counterfactual Fairness to Unmeasured Confounding", "comments": "published at UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal approaches to fairness have seen substantial recent interest, both\nfrom the machine learning community and from wider parties interested in\nethical prediction algorithms. In no small part, this has been due to the fact\nthat causal models allow one to simultaneously leverage data and expert\nknowledge to remove discriminatory effects from predictions. However, one of\nthe primary assumptions in causal modeling is that you know the causal graph.\nThis introduces a new opportunity for bias, caused by misspecifying the causal\nmodel. One common way for misspecification to occur is via unmeasured\nconfounding: the true causal effect between variables is partially described by\nunobserved quantities. In this work we design tools to assess the sensitivity\nof fairness measures to this confounding for the popular class of non-linear\nadditive noise models (ANMs). Specifically, we give a procedure for computing\nthe maximum difference between two counterfactually fair predictors, where one\nhas become biased due to confounding. For the case of bivariate confounding our\ntechnique can be swiftly computed via a sequence of closed-form updates. For\nmultivariate confounding we give an algorithm that can be efficiently solved\nvia automatic differentiation. We demonstrate our new sensitivity analysis\ntools in real-world fairness scenarios to assess the bias arising from\nconfounding.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 19:47:40 GMT"}], "update_date": "2019-08-17", "authors_parsed": [["Kilbertus", "Niki", ""], ["Ball", "Philip J.", ""], ["Kusner", "Matt J.", ""], ["Weller", "Adrian", ""], ["Silva", "Ricardo", ""]]}, {"id": "1907.01051", "submitter": "Saurabh Jha", "authors": "Saurabh Jha, Subho S. Banerjee, Timothy Tsai, Siva K. S. Hari, Michael\n  B. Sullivan, Zbigniew T. Kalbarczyk, Stephen W. Keckler, Ravishankar K. Iyer", "title": "ML-based Fault Injection for Autonomous Vehicles: A Case for Bayesian\n  Fault Injection", "comments": "Accepted at 2019 49th Annual IEEE/IFIP International Conference on\n  Dependable Systems and Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The safety and resilience of fully autonomous vehicles (AVs) are of\nsignificant concern, as exemplified by several headline-making accidents. While\nAV development today involves verification, validation, and testing, end-to-end\nassessment of AV systems under accidental faults in realistic driving scenarios\nhas been largely unexplored. This paper presents DriveFI, a machine\nlearning-based fault injection engine, which can mine situations and faults\nthat maximally impact AV safety, as demonstrated on two industry-grade AV\ntechnology stacks (from NVIDIA and Baidu). For example, DriveFI found 561\nsafety-critical faults in less than 4 hours. In comparison, random injection\nexperiments executed over several weeks could not find any safety-critical\nfaults\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 20:16:26 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Jha", "Saurabh", ""], ["Banerjee", "Subho S.", ""], ["Tsai", "Timothy", ""], ["Hari", "Siva K. S.", ""], ["Sullivan", "Michael B.", ""], ["Kalbarczyk", "Zbigniew T.", ""], ["Keckler", "Stephen W.", ""], ["Iyer", "Ravishankar K.", ""]]}, {"id": "1907.01068", "submitter": "Robert Bamler", "authors": "Robert Bamler, Farnood Salehi, and Stephan Mandt", "title": "Augmenting and Tuning Knowledge Graph Embeddings", "comments": "Published version, Conference on Uncertainty in Artificial\n  Intelligence (UAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graph embeddings rank among the most successful methods for link\nprediction in knowledge graphs, i.e., the task of completing an incomplete\ncollection of relational facts. A downside of these models is their strong\nsensitivity to model hyperparameters, in particular regularizers, which have to\nbe extensively tuned to reach good performance [Kadlec et al., 2017]. We\npropose an efficient method for large scale hyperparameter tuning by\ninterpreting these models in a probabilistic framework. After a model\naugmentation that introduces per-entity hyperparameters, we use a variational\nexpectation-maximization approach to tune thousands of such hyperparameters\nwith minimal additional cost. Our approach is agnostic to details of the model\nand results in a new state of the art in link prediction on standard benchmark\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 20:40:37 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Bamler", "Robert", ""], ["Salehi", "Farnood", ""], ["Mandt", "Stephan", ""]]}, {"id": "1907.01070", "submitter": "Pedro Braga", "authors": "Pedro H. M. Braga and Hansenclever F. Bassani", "title": "A Semi-Supervised Self-Organizing Map for Clustering and Classification", "comments": null, "journal-ref": "2018 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN.2018.8489675", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There has been an increasing interest in semi-supervised learning in the\nrecent years because of the great number of datasets with a large number of\nunlabeled data but only a few labeled samples. Semi-supervised learning\nalgorithms can work with both types of data, combining them to obtain better\nperformance for both clustering and classification. Also, these datasets\ncommonly have a high number of dimensions. This article presents a new\nsemi-supervised method based on self-organizing maps (SOMs) for clustering and\nclassification, called Semi-Supervised Self-Organizing Map (SS-SOM). The method\ncan dynamically switch between supervised and unsupervised learning during the\ntraining according to the availability of the class labels for each pattern.\nOur results show that the SS-SOM outperforms other semi-supervised methods in\nconditions in which there is a low amount of labeled samples, also achieving\ngood results when all samples are labeled.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 20:45:01 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Braga", "Pedro H. M.", ""], ["Bassani", "Hansenclever F.", ""]]}, {"id": "1907.01086", "submitter": "Pedro Braga", "authors": "Pedro H. M. Braga and Hansenclever F. Bassani", "title": "A Semi-Supervised Self-Organizing Map with Adaptive Local Thresholds", "comments": null, "journal-ref": "2019 International Joint Conference on Neural Networks (IJCNN)", "doi": "10.1109/IJCNN.2019.8851839", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the recent years, there is a growing interest in semi-supervised learning,\nsince, in many learning tasks, there is a plentiful supply of unlabeled data,\nbut insufficient labeled ones. Hence, Semi-Supervised learning models can\nbenefit from both types of data to improve the obtained performance. Also, it\nis important to develop methods that are easy to parameterize in a way that is\nrobust to the different characteristics of the data at hand. This article\npresents a new method based on Self-Organizing Map (SOM) for clustering and\nclassification, called Adaptive Local Thresholds Semi-Supervised\nSelf-Organizing Map (ALTSS-SOM). It can dynamically switch between two forms of\nlearning at training time, according to the availability of labels, as in\nprevious models, and can automatically adjust itself to the local variance\nobserved in each data cluster. The results show that the ALTSS-SOM surpass the\nperformance of other semi-supervised methods in terms of classification, and\nother pure clustering methods when there are no labels available, being also\nless sensitive than previous methods to the parameters values.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 22:02:47 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 01:26:54 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Braga", "Pedro H. M.", ""], ["Bassani", "Hansenclever F.", ""]]}, {"id": "1907.01099", "submitter": "Tong Wu", "authors": "Fan Zhang, Tong Wu, Yunlong Wang, Yong Cai, Cao Xiao, Emily Zhao,\n  Lucas Glass, Jimeng Sun", "title": "Predicting Treatment Initiation from Clinical Time Series Data via\n  Graph-Augmented Time-Sensitive Model", "comments": "5 pages, 3 figures, accepted by ICML 2019 Time Series Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many computational models were proposed to extract temporal patterns from\nclinical time series for each patient and among patient group for predictive\nhealthcare. However, the common relations among patients (e.g., share the same\ndoctor) were rarely considered. In this paper, we represent patients and\nclinicians relations by bipartite graphs addressing for example from whom a\npatient get a diagnosis. We then solve for the top eigenvectors of the graph\nLaplacian, and include the eigenvectors as latent representations of the\nsimilarity between patient-clinician pairs into a time-sensitive prediction\nmodel. We conducted experiments using real-world data to predict the initiation\nof first-line treatment for Chronic Lymphocytic Leukemia (CLL) patients.\nResults show that relational similarity can improve prediction over multiple\nbaselines, for example a 5% incremental over long-short term memory baseline in\nterms of area under precision-recall curve.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 23:22:45 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Zhang", "Fan", ""], ["Wu", "Tong", ""], ["Wang", "Yunlong", ""], ["Cai", "Yong", ""], ["Xiao", "Cao", ""], ["Zhao", "Emily", ""], ["Glass", "Lucas", ""], ["Sun", "Jimeng", ""]]}, {"id": "1907.01103", "submitter": "Masahito Ohue", "authors": "Masahito Ohue, Ryota Ii, Keisuke Yanagisawa, Yutaka Akiyama", "title": "Molecular activity prediction using graph convolutional deep neural\n  network considering distance on a molecular graph", "comments": "7 pages", "journal-ref": "In Proceedings of the 2019 International Conference on Parallel\n  and Distributed Processing Techniques & Applications (PDPTA'19), 122-128,\n  2019", "doi": null, "report-no": null, "categories": "q-bio.BM cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is often used in virtual screening to find compounds that\nare pharmacologically active on a target protein. The weave module is a type of\ngraph convolutional deep neural network that uses not only features focusing on\natoms alone (atom features) but also features focusing on atom pairs (pair\nfeatures); thus, it can consider information of nonadjacent atoms. However, the\ncorrelation between the distance on the graph and the three-dimensional\ncoordinate distance is uncertain. In this paper, we propose three improvements\nfor modifying the weave module. First, the distances between ring atoms on the\ngraph were modified to bring the distances on the graph closer to the\ncoordinate distance. Second, different weight matrices were used depending on\nthe distance on the graph in the convolution layers of the pair features.\nFinally, a weighted sum, by distance, was used when converting pair features to\natom features. The experimental results show that the performance of the\nproposed method is slightly better than that of the weave module, and the\nimprovement in the distance representation might be useful for compound\nactivity prediction.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 00:23:42 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 14:29:01 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ohue", "Masahito", ""], ["Ii", "Ryota", ""], ["Yanagisawa", "Keisuke", ""], ["Akiyama", "Yutaka", ""]]}, {"id": "1907.01104", "submitter": "Jonathan Wells", "authors": "Kai Ming Ting and Jonathan R. Wells and Takashi Washio", "title": "Isolation Kernel: The X Factor in Efficient and Effective Large Scale\n  Online Kernel Learning", "comments": "Textural updates. Restructured section 8.4 including additional\n  experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale online kernel learning aims to build an efficient and scalable\nkernel-based predictive model incrementally from a sequence of potentially\ninfinite data points. A current key approach focuses on ways to produce an\napproximate finite-dimensional feature map, assuming that the kernel used has a\nfeature map with intractable dimensionality---an assumption traditionally held\nin kernel-based methods. While this approach can deal with large scale datasets\nefficiently, this outcome is achieved by compromising predictive accuracy\nbecause of the approximation. We offer an alternative approach which overrides\nthe assumption and puts the kernel used at the heart of the approach. It\nfocuses on creating an exact, sparse and finite-dimensional feature map of a\nkernel called Isolation Kernel. Using this new approach, to achieve the above\naim of large scale online kernel learning becomes extremely simple---simply use\nIsolation Kernel instead of a kernel having a feature map with intractable\ndimensionality. We show that, using Isolation Kernel, large scale online kernel\nlearning can be achieved efficiently without sacrificing accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 00:23:43 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 05:34:59 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Ting", "Kai Ming", ""], ["Wells", "Jonathan R.", ""], ["Washio", "Takashi", ""]]}, {"id": "1907.01113", "submitter": "Xiongjun Zhang", "authors": "Guangjing Song, Michael K. Ng, and Xiongjun Zhang", "title": "Robust Tensor Completion Using Transformed Tensor SVD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study robust tensor completion by using transformed tensor\nsingular value decomposition (SVD), which employs unitary transform matrices\ninstead of discrete Fourier transform matrix that is used in the traditional\ntensor SVD. The main motivation is that a lower tubal rank tensor can be\nobtained by using other unitary transform matrices than that by using discrete\nFourier transform matrix. This would be more effective for robust tensor\ncompletion. Experimental results for hyperspectral, video and face datasets\nhave shown that the recovery performance for the robust tensor completion\nproblem by using transformed tensor SVD is better in PSNR than that by using\nFourier transform and other robust tensor completion methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 00:50:31 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Song", "Guangjing", ""], ["Ng", "Michael K.", ""], ["Zhang", "Xiongjun", ""]]}, {"id": "1907.01121", "submitter": "Zhanxuan Hu", "authors": "Feiping Nie, Zhanxuan Hu, Xiaoqian Wang, Rong Wang, Xuelong Li, Heng\n  Huang", "title": "An Iteratively Re-weighted Method for Problems with Sparsity-Inducing\n  Norms", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work aims at solving the problems with intractable sparsity-inducing\nnorms that are often encountered in various machine learning tasks, such as\nmulti-task learning, subspace clustering, feature selection, robust principal\ncomponent analysis, and so on. Specifically, an Iteratively Re-Weighted method\n(IRW) with solid convergence guarantee is provided. We investigate its\nconvergence speed via numerous experiments on real data. Furthermore, in order\nto validate the practicality of IRW, we use it to solve a concrete robust\nfeature selection model with complicated objective function. The experimental\nresults show that the model coupled with proposed optimization method\noutperforms alternative methods significantly.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 01:36:52 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Nie", "Feiping", ""], ["Hu", "Zhanxuan", ""], ["Wang", "Xiaoqian", ""], ["Wang", "Rong", ""], ["Li", "Xuelong", ""], ["Huang", "Heng", ""]]}, {"id": "1907.01127", "submitter": "Jonathan Lee", "authors": "Jonathan N. Lee, Aldo Pacchiano, Michael I. Jordan", "title": "Convergence Rates of Smooth Message Passing with Rounding in\n  Entropy-Regularized MAP Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum a posteriori (MAP) inference is a fundamental computational paradigm\nfor statistical inference. In the setting of graphical models, MAP inference\nentails solving a combinatorial optimization problem to find the most likely\nconfiguration of the discrete-valued model. Linear programming (LP) relaxations\nin the Sherali-Adams hierarchy are widely used to attempt to solve this\nproblem, and smooth message passing algorithms have been proposed to solve\nregularized versions of these LPs with great success. This paper leverages\nrecent work in entropy-regularized LPs to analyze convergence rates of a class\nof edge-based smooth message passing algorithms to $\\epsilon$-optimality in the\nrelaxation. With an appropriately chosen regularization constant, we present a\ntheoretical guarantee on the number of iterations sufficient to recover the\ntrue integral MAP solution when the LP is tight and the solution is unique.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 02:21:44 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 02:59:30 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Lee", "Jonathan N.", ""], ["Pacchiano", "Aldo", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1907.01132", "submitter": "Moming Duan", "authors": "Moming Duan, Duo Liu, Xianzhang Chen, Yujuan Tan, Jinting Ren, Lei\n  Qiao, Liang Liang", "title": "Astraea: Self-balancing Federated Learning for Improving Classification\n  Accuracy of Mobile Deep Learning Applications", "comments": "Published as a conference paper at IEEE 37th International Conference\n  on Computer Design (ICCD) 2019", "journal-ref": null, "doi": "10.1109/ICCD46524.2019.00038", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a distributed deep learning method which enables\nmultiple participants, such as mobile phones and IoT devices, to contribute a\nneural network model while their private training data remains in local\ndevices. This distributed approach is promising in the edge computing system\nwhere have a large corpus of decentralized data and require high privacy.\nHowever, unlike the common training dataset, the data distribution of the edge\ncomputing system is imbalanced which will introduce biases in the model\ntraining and cause a decrease in accuracy of federated learning applications.\nIn this paper, we demonstrate that the imbalanced distributed training data\nwill cause accuracy degradation in FL. To counter this problem, we build a\nself-balancing federated learning framework call Astraea, which alleviates the\nimbalances by 1) Global data distribution based data augmentation, and 2)\nMediator based multi-client rescheduling. The proposed framework relieves\nglobal imbalance by runtime data augmentation, and for averaging the local\nimbalance, it creates the mediator to reschedule the training of clients based\non Kullback-Leibler divergence (KLD) of their data distribution. Compared with\nFedAvg, the state-of-the-art FL algorithm, Astraea shows +5.59% and +5.89%\nimprovement of top-1 accuracy on the imbalanced EMNIST and imbalanced CINIC-10\ndatasets, respectively. Meanwhile, the communication traffic of Astraea can be\n82% lower than that of FedAvg.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 02:44:36 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 07:01:56 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Duan", "Moming", ""], ["Liu", "Duo", ""], ["Chen", "Xianzhang", ""], ["Tan", "Yujuan", ""], ["Ren", "Jinting", ""], ["Qiao", "Lei", ""], ["Liang", "Liang", ""]]}, {"id": "1907.01136", "submitter": "Paul McNicholas", "authors": "Katharine M. Clark and Paul D. McNicholas", "title": "Using Subset Log-Likelihoods to Trim Outliers in Gaussian Mixture Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixtures of Gaussian distributions are a popular choice in model-based\nclustering. Outliers can affect parameters estimation and, as such, must be\naccounted for. Predicting the proportion of outliers correctly is paramount as\nit minimizes misclassification error. It is proved that, for a finite Gaussian\nmixture model, the log-likelihoods of the subset models are distributed\naccording to a mixture of beta distributions. An algorithm is then proposed\nthat predicts the proportion of outliers by measuring the adherence of a set of\nsubset log-likelihoods to a beta mixture reference distribution. This algorithm\nremoves the least likely points, which are deemed outliers, until model\nassumptions are met.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 03:02:20 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 19:44:17 GMT"}, {"version": "v3", "created": "Fri, 11 Oct 2019 01:11:26 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Clark", "Katharine M.", ""], ["McNicholas", "Paul D.", ""]]}, {"id": "1907.01160", "submitter": "Jonathan Le Roux", "authors": "Gordon Wichern, Joe Antognini, Michael Flynn, Licheng Richard Zhu,\n  Emmett McQuinn, Dwight Crow, Ethan Manilow, Jonathan Le Roux", "title": "WHAM!: Extending Speech Separation to Noisy Environments", "comments": "Accepted for publication at Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in separating the speech signals from multiple overlapping\nspeakers using a single audio channel has brought us closer to solving the\ncocktail party problem. However, most studies in this area use a constrained\nproblem setup, comparing performance when speakers overlap almost completely,\nat artificially low sampling rates, and with no external background noise. In\nthis paper, we strive to move the field towards more realistic and challenging\nscenarios. To that end, we created the WSJ0 Hipster Ambient Mixtures (WHAM!)\ndataset, consisting of two speaker mixtures from the wsj0-2mix dataset combined\nwith real ambient noise samples. The samples were collected in coffee shops,\nrestaurants, and bars in the San Francisco Bay Area, and are made publicly\navailable. We benchmark various speech separation architectures and objective\nfunctions to evaluate their robustness to noise. While separation performance\ndecreases as a result of noise, we still observe substantial gains relative to\nthe noisy signals for most approaches.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 04:27:55 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Wichern", "Gordon", ""], ["Antognini", "Joe", ""], ["Flynn", "Michael", ""], ["Zhu", "Licheng Richard", ""], ["McQuinn", "Emmett", ""], ["Crow", "Dwight", ""], ["Manilow", "Ethan", ""], ["Roux", "Jonathan Le", ""]]}, {"id": "1907.01162", "submitter": "Zhibin Li", "authors": "Zhibin Li, Jian Zhang, Qiang Wu, Yongshun Gong, Jinfeng Yi, Christina\n  Kirsch", "title": "Sample Adaptive Multiple Kernel Learning for Failure Prediction of\n  Railway Points", "comments": "Accepted by KDD2019 Applied Data Science track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Railway points are among the key components of railway infrastructure. As a\npart of signal equipment, points control the routes of trains at railway\njunctions, having a significant impact on the reliability, capacity, and\npunctuality of rail transport. Traditionally, maintenance of points is based on\na fixed time interval or raised after the equipment failures. Instead, it would\nbe of great value if we could forecast points' failures and take action\nbeforehand, minimising any negative effect. To date, most of the existing\nprediction methods are either lab-based or relying on specially installed\nsensors which makes them infeasible for large-scale implementation. Besides,\nthey often use data from only one source. We, therefore, explore a new way that\nintegrates multi-source data which are ready to hand to fulfil this task. We\nconducted our case study based on Sydney Trains rail network which is an\nextensive network of passenger and freight railways. Unfortunately, the\nreal-world data are usually incomplete due to various reasons, e.g., faults in\nthe database, operational errors or transmission faults. Besides, railway\npoints differ in their locations, types and some other properties, which means\nit is hard to use a unified model to predict their failures. Aiming at this\nchallenging task, we firstly constructed a dataset from multiple sources and\nselected key features with the help of domain experts. In this paper, we\nformulate our prediction task as a multiple kernel learning problem with\nmissing kernels. We present a robust multiple kernel learning algorithm for\npredicting points failures. Our model takes into account the missing pattern of\ndata as well as the inherent variance on different sets of railway points.\nExtensive experiments demonstrate the superiority of our algorithm compared\nwith other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 04:36:38 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Li", "Zhibin", ""], ["Zhang", "Jian", ""], ["Wu", "Qiang", ""], ["Gong", "Yongshun", ""], ["Yi", "Jinfeng", ""], ["Kirsch", "Christina", ""]]}, {"id": "1907.01164", "submitter": "Ashis Pati", "authors": "Ashis Pati, Alexander Lerch, Ga\\\"etan Hadjeres", "title": "Learning to Traverse Latent Spaces for Musical Score Inpainting", "comments": "20th International Society for Music Information Retrieval Conference\n  (ISMIR), 2019, Delft, The Netherlands; 6 pages, 8 figures", "journal-ref": "20th International Society for Music Information Retrieval\n  Conference (ISMIR), 2019, Delft, The Netherlands", "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Music Inpainting is the task of filling in missing or lost information in a\npiece of music. We investigate this task from an interactive music creation\nperspective. To this end, a novel deep learning-based approach for musical\nscore inpainting is proposed. The designed model takes both past and future\nmusical context into account and is capable of suggesting ways to connect them\nin a musically meaningful manner. To achieve this, we leverage the\nrepresentational power of the latent space of a Variational Auto-Encoder and\ntrain a Recurrent Neural Network which learns to traverse this latent space\nconditioned on the past and future musical contexts. Consequently, the designed\nmodel is capable of generating several measures of music to connect two musical\nexcerpts. The capabilities and performance of the model are showcased by\ncomparison with competitive baselines using several objective and subjective\nevaluation methods. The results show that the model generates meaningful\ninpaintings and can be used in interactive music creation applications.\nOverall, the method demonstrates the merit of learning complex trajectories in\nthe latent spaces of deep generative models.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 04:39:05 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Pati", "Ashis", ""], ["Lerch", "Alexander", ""], ["Hadjeres", "Ga\u00ebtan", ""]]}, {"id": "1907.01184", "submitter": "Linh Nguyen PhD", "authors": "Linh Nguyen, Jaime Valls Miro, Lei Shi and Teresa Vidal-Calleja", "title": "Gaussian Mixture Marginal Distributions for Modelling Remaining Pipe\n  Wall Thickness of Critical Water Mains in Non-Destructive Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapidly estimating the remaining wall thickness (RWT) is paramount for the\nnon-destructive condition assessment evaluation of large critical metallic\npipelines. A robotic vehicle with embedded magnetism-based sensors has been\ndeveloped to traverse the inside of a pipeline and conduct inspections at the\nlocation of a break. However its sensing speed is constrained by the magnetic\nprinciple of operation, thus slowing down the overall operation in seeking\ndense RWT mapping. To ameliorate this drawback, this work proposes the partial\nscanning of the pipe and then employing Gaussian Processes (GPs) to infer RWT\nat the unseen pipe sections. Since GP prediction assumes to have normally\ndistributed input data - which does correspond with real RWT measurements -\nGaussian mixture (GM) models are proven in this work as fitting marginal\ndistributions to effectively capture the probability of any RWT value in the\ninspected data. The effectiveness of the proposed approach is extensively\nvalidated from real-world data collected in collaboration with a water utility\nfrom a cast iron water main pipeline in Sydney, Australia.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 06:07:12 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Nguyen", "Linh", ""], ["Miro", "Jaime Valls", ""], ["Shi", "Lei", ""], ["Vidal-Calleja", "Teresa", ""]]}, {"id": "1907.01197", "submitter": "Claudio Lucchese", "authors": "Stefano Calzavara, Claudio Lucchese, Gabriele Tolomei, Seyum Assefa\n  Abebe and Salvatore Orlando", "title": "Treant: Training Evasion-Aware Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite its success and popularity, machine learning is now recognized as\nvulnerable to evasion attacks, i.e., carefully crafted perturbations of test\ninputs designed to force prediction errors. In this paper we focus on evasion\nattacks against decision tree ensembles, which are among the most successful\npredictive models for dealing with non-perceptual problems. Even though they\nare powerful and interpretable, decision tree ensembles have received only\nlimited attention by the security and machine learning communities so far,\nleading to a sub-optimal state of the art for adversarial learning techniques.\nWe thus propose Treant, a novel decision tree learning algorithm that, on the\nbasis of a formal threat model, minimizes an evasion-aware loss function at\neach step of the tree construction. Treant is based on two key technical\ningredients: robust splitting and attack invariance, which jointly guarantee\nthe soundness of the learning process. Experimental results on three publicly\navailable datasets show that Treant is able to generate decision tree ensembles\nthat are at the same time accurate and nearly insensitive to evasion attacks,\noutperforming state-of-the-art adversarial learning techniques.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 06:59:15 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 13:39:30 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Calzavara", "Stefano", ""], ["Lucchese", "Claudio", ""], ["Tolomei", "Gabriele", ""], ["Abebe", "Seyum Assefa", ""], ["Orlando", "Salvatore", ""]]}, {"id": "1907.01253", "submitter": "Erdi Calli", "authors": "Erdi \\c{C}all{\\i}, Keelin Murphy, Ecem Sogancioglu, Bram van Ginneken", "title": "FRODO: Free rejection of out-of-distribution samples: application to\n  chest x-ray analysis", "comments": "MIDL 2019 [arXiv:1907.08612]", "journal-ref": null, "doi": null, "report-no": "MIDL/2019/ExtendedAbstract/H1e7kWD794", "categories": "cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we propose a method to reject out-of-distribution samples which\ncan be adapted to any network architecture and requires no additional training\ndata. Publicly available chest x-ray data (38,353 images) is used to train a\nstandard ResNet-50 model to detect emphysema. Feature activations of\nintermediate layers are used as descriptors defining the training data\ndistribution. A novel metric, FRODO, is measured by using the Mahalanobis\ndistance of a new test sample to the training data distribution. The method is\ntested using a held-out test dataset of 21,176 chest x-rays (in-distribution)\nand a set of 14,821 out-of-distribution x-ray images of incorrect orientation\nor anatomy. In classifying test samples as in or out-of distribution, our\nmethod achieves an AUC score of 0.99.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 09:28:58 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["\u00c7all\u0131", "Erdi", ""], ["Murphy", "Keelin", ""], ["Sogancioglu", "Ecem", ""], ["van Ginneken", "Bram", ""]]}, {"id": "1907.01287", "submitter": "Ping-Chun Hsieh", "authors": "Xi Liu, Ping-Chun Hsieh, Anirban Bhattacharya, P. R. Kumar", "title": "Exploration Through Reward Biasing: Reward-Biased Maximum Likelihood\n  Estimation for Stochastic Multi-Armed Bandits", "comments": "ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the Reward-Biased Maximum Likelihood Estimate method of adaptive\ncontrol, we propose RBMLE -- a novel family of learning algorithms for\nstochastic multi-armed bandits (SMABs). For a broad range of SMABs including\nboth the parametric Exponential Family as well as the non-parametric\nsub-Gaussian/Exponential family, we show that RBMLE yields an index policy. To\nchoose the bias-growth rate $\\alpha(t)$ in RBMLE, we reveal the nontrivial\ninterplay between $\\alpha(t)$ and the regret bound that generally applies in\nboth the Exponential Family as well as the sub-Gaussian/Exponential family\nbandits. To quantify the finite-time performance, we prove that RBMLE attains\norder-optimality by adaptively estimating the unknown constants in the\nexpression of $\\alpha(t)$ for Gaussian and sub-Gaussian bandits. Extensive\nexperiments demonstrate that the proposed RBMLE achieves empirical regret\nperformance competitive with the state-of-the-art methods, while being more\ncomputationally efficient and scalable in comparison to the best-performing\nones among them.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 10:34:53 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 23:45:00 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 15:22:26 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Liu", "Xi", ""], ["Hsieh", "Ping-Chun", ""], ["Bhattacharya", "Anirban", ""], ["Kumar", "P. R.", ""]]}, {"id": "1907.01288", "submitter": "Ahmed ELGazzar", "authors": "Ahmed El Gazzar, Leonardo Cerliani, Guido van Wingen, Rajat Mani\n  Thomas", "title": "Simple 1-D Convolutional Networks for Resting-State fMRI Based\n  Classification in Autism", "comments": "accepted for publication in IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods are increasingly being used with neuroimaging data like\nstructural and function magnetic resonance imaging (MRI) to predict the\ndiagnosis of neuropsychiatric and neurological disorders. For psychiatric\ndisorders in particular, it is believed that one of the most promising modality\nis the resting-state functional MRI (rsfMRI), which captures the intrinsic\nconnectivity between regions in the brain. Because rsfMRI data points are\ninherently high-dimensional (~1M), it is impossible to process the entire input\nin its raw form. In this paper, we propose a very simple transformation of the\nrsfMRI images that captures all of the temporal dynamics of the signal but\nsub-samples its spatial extent. As a result, we use a very simple 1-D\nconvolutional network which is fast to train, requires minimal preprocessing\nand performs at par with the state-of-the-art on the classification of Autism\nspectrum disorders.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 10:35:25 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Gazzar", "Ahmed El", ""], ["Cerliani", "Leonardo", ""], ["van Wingen", "Guido", ""], ["Thomas", "Rajat Mani", ""]]}, {"id": "1907.01298", "submitter": "Matthieu Geist", "authors": "Erinc Merdivan, Sten Hanke and Matthieu Geist", "title": "Modified Actor-Critics", "comments": "Long version of AAMAS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent successful deep reinforcement learning algorithms, such as Trust\nRegion Policy Optimization (TRPO) or Proximal Policy Optimization (PPO), are\nfundamentally variations of conservative policy iteration (CPI). These\nalgorithms iterate policy evaluation followed by a softened policy improvement\nstep. As so, they are naturally on-policy. In this paper, we propose to combine\n(any kind of) soft greediness with Modified Policy Iteration (MPI). The\nproposed abstract framework applies repeatedly: (i) a partial policy evaluation\nstep that allows off-policy learning and (ii) any softened greedy step. Our\ncontribution can be seen as a new generic tool for the deep reinforcement\nlearning toolbox. As a proof of concept, we instantiate this framework with the\nPPO greediness. Comparison to the original PPO shows that our algorithm is much\nmore sample efficient. We also show that it is competitive with the\nstate-of-art off-policy algorithm Soft Actor Critic (SAC).\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 11:22:56 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2020 10:08:28 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Merdivan", "Erinc", ""], ["Hanke", "Sten", ""], ["Geist", "Matthieu", ""]]}, {"id": "1907.01319", "submitter": "Jong Chul Ye", "authors": "Boah Kim, Jieun Kim, June-Goo Lee, Dong Hwan Kim, Seong Ho Park, Jong\n  Chul Ye", "title": "Unsupervised Deformable Image Registration Using Cycle-Consistent CNN", "comments": "accepted for MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical image registration is one of the key processing steps for biomedical\nimage analysis such as cancer diagnosis. Recently, deep learning based\nsupervised and unsupervised image registration methods have been extensively\nstudied due to its excellent performance in spite of ultra-fast computational\ntime compared to the classical approaches. In this paper, we present a novel\nunsupervised medical image registration method that trains deep neural network\nfor deformable registration of 3D volumes using a cycle-consistency. Thanks to\nthe cycle consistency, the proposed deep neural networks can take diverse pair\nof image data with severe deformation for accurate registration. Experimental\nresults using multiphase liver CT images demonstrate that our method provides\nvery precise 3D image registration within a few seconds, resulting in more\naccurate cancer size estimation.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 12:29:02 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Kim", "Boah", ""], ["Kim", "Jieun", ""], ["Lee", "June-Goo", ""], ["Kim", "Dong Hwan", ""], ["Park", "Seong Ho", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1907.01329", "submitter": "Erik Daxberger", "authors": "Erik Daxberger, Anastasia Makarova, Matteo Turchetta, Andreas Krause", "title": "Mixed-Variable Bayesian Optimization", "comments": "IJCAI 2020 camera-ready; 17 pages, extended version with\n  supplementary material", "journal-ref": "Proceedings of the Twenty-Ninth International Joint Conference on\n  Artificial Intelligence (IJCAI-20), 2020, pages 2633-2639", "doi": "10.24963/ijcai.2020/365", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimization of expensive to evaluate, black-box, mixed-variable\nfunctions, i.e. functions that have continuous and discrete inputs, is a\ndifficult and yet pervasive problem in science and engineering. In Bayesian\noptimization (BO), special cases of this problem that consider fully continuous\nor fully discrete domains have been widely studied. However, few methods exist\nfor mixed-variable domains and none of them can handle discrete constraints\nthat arise in many real-world applications. In this paper, we introduce MiVaBo,\na novel BO algorithm for the efficient optimization of mixed-variable functions\ncombining a linear surrogate model based on expressive feature representations\nwith Thompson sampling. We propose an effective method to optimize its\nacquisition function, a challenging problem for mixed-variable domains, making\nMiVaBo the first BO method that can handle complex constraints over the\ndiscrete variables. Moreover, we provide the first convergence analysis of a\nmixed-variable BO algorithm. Finally, we show that MiVaBo is significantly more\nsample efficient than state-of-the-art mixed-variable BO algorithms on several\nhyperparameter tuning tasks, including the tuning of deep generative models.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 12:46:43 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 09:57:58 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 11:36:04 GMT"}, {"version": "v4", "created": "Tue, 4 Aug 2020 08:35:25 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Daxberger", "Erik", ""], ["Makarova", "Anastasia", ""], ["Turchetta", "Matteo", ""], ["Krause", "Andreas", ""]]}, {"id": "1907.01332", "submitter": "Coert Van Gemeren", "authors": "Axel Uran, Coert van Gemeren, Rosanne van Diepen, Ricardo Chavarriaga,\n  Jos\\'e del R. Mill\\'an", "title": "Applying Transfer Learning To Deep Learned Models For EEG Analysis", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The introduction of deep learning and transfer learning techniques in fields\nsuch as computer vision allowed a leap forward in the accuracy of image\nclassification tasks. Currently there is only limited use of such techniques in\nneuroscience. The challenge of using deep learning methods to successfully\ntrain models in neuroscience, lies in the complexity of the information that is\nprocessed, the availability of data and the cost of producing sufficient high\nquality annotations. Inspired by its application in computer vision, we\nintroduce transfer learning on electrophysiological data to enable training a\nmodel with limited amounts of data. Our method was tested on the dataset of the\nBCI competition IV 2a and compared to the top results that were obtained using\ntraditional machine learning techniques. Using our DL model we outperform the\ntop result of the competition by 33%. We also explore transferability of\nknowledge between trained models over different experiments, called\ninter-experimental transfer learning. This reduces the amount of required data\neven further and is especially useful when few subjects are available. This\nmethod is able to outperform the standard deep learning methods used in the BCI\ncompetition IV 2b approaches by 18%. In this project we propose a method that\ncan produce reliable electroencephalography (EEG) signal classification, based\non modest amounts of training data through the use of transfer learning.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 12:51:26 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Uran", "Axel", ""], ["van Gemeren", "Coert", ""], ["van Diepen", "Rosanne", ""], ["Chavarriaga", "Ricardo", ""], ["Mill\u00e1n", "Jos\u00e9 del R.", ""]]}, {"id": "1907.01343", "submitter": "Christoph Raab", "authors": "Christoph Raab and Frank-Michael Schleif", "title": "Low-Rank Subspace Override for Unsupervised Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current supervised learning models cannot generalize well across domain\nboundaries, which is a known problem in many applications, such as robotics or\nvisual classification. Domain adaptation methods are used to improve these\ngeneralization properties. However, these techniques suffer either from being\nrestricted to a particular task, such as visual adaptation, require a lot of\ncomputational time and data, which is not always guaranteed, have complex\nparameterization, or expensive optimization procedures. In this work, we\npresent an approach that requires only a well-chosen snapshot of data to find a\nsingle domain invariant subspace. The subspace is calculated in closed form and\noverrides domain structures, which makes it fast and stable in\nparameterization. By employing low-rank techniques, we emphasize on descriptive\ncharacteristics of data. The presented idea is evaluated on various domain\nadaptation tasks such as text and image classification against state of the art\ndomain adaptation approaches and achieves remarkable performance across all\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 13:19:29 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 10:02:00 GMT"}, {"version": "v3", "created": "Wed, 8 Jul 2020 12:48:25 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Raab", "Christoph", ""], ["Schleif", "Frank-Michael", ""]]}, {"id": "1907.01367", "submitter": "Rajiv Ratn Shah", "authors": "Yaman Kumar, Rohit Jain, Khwaja Mohd. Salik, Rajiv Ratn Shah, Yifang\n  yin, Roger Zimmermann", "title": "Lipper: Synthesizing Thy Speech using Multi-View Lipreading", "comments": "Accepted at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Lipreading has a lot of potential applications such as in the domain of\nsurveillance and video conferencing. Despite this, most of the work in building\nlipreading systems has been limited to classifying silent videos into classes\nrepresenting text phrases. However, there are multiple problems associated with\nmaking lipreading a text-based classification task like its dependence on a\nparticular language and vocabulary mapping. Thus, in this paper we propose a\nmulti-view lipreading to audio system, namely Lipper, which models it as a\nregression task. The model takes silent videos as input and produces speech as\nthe output. With multi-view silent videos, we observe an improvement over\nsingle-view speech reconstruction results. We show this by presenting an\nexhaustive set of experiments for speaker-dependent, out-of-vocabulary and\nspeaker-independent settings. Further, we compare the delay values of Lipper\nwith other speechreading systems in order to show the real-time nature of audio\nproduced. We also perform a user study for the audios produced in order to\nunderstand the level of comprehensibility of audios produced using Lipper.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 10:26:23 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Kumar", "Yaman", ""], ["Jain", "Rohit", ""], ["Salik", "Khwaja Mohd.", ""], ["Shah", "Rajiv Ratn", ""], ["yin", "Yifang", ""], ["Zimmermann", "Roger", ""]]}, {"id": "1907.01372", "submitter": "Cal Peyser`", "authors": "Cal Peyser, Hao Zhang, Tara N. Sainath, Zelin Wu", "title": "Improving Performance of End-to-End ASR on Numeric Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recognizing written domain numeric utterances (e.g. I need $1.25.) can be\nchallenging for ASR systems, particularly when numeric sequences are not seen\nduring training. This out-of-vocabulary (OOV) issue is addressed in\nconventional ASR systems by training part of the model on spoken domain\nutterances (e.g. I need one dollar and twenty five cents.), for which numeric\nsequences are composed of in-vocabulary numbers, and then using an FST\nverbalizer to denormalize the result. Unfortunately, conventional ASR models\nare not suitable for the low memory setting of on-device speech recognition.\nE2E models such as RNN-T are attractive for on-device ASR, as they fold the AM,\nPM and LM of a conventional model into one neural network. However, in the\non-device setting the large memory footprint of an FST denormer makes spoken\ndomain training more difficult. In this paper, we investigate techniques to\nimprove E2E model performance on numeric data. We find that using a\ntext-to-speech system to generate additional numeric training data, as well as\nusing a small-footprint neural network to perform spoken-to-written domain\ndenorming, yields improvement in several numeric classes. In the case of the\nlongest numeric sequences, we see reduction of WER by up to a factor of 8.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:21:09 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Peyser", "Cal", ""], ["Zhang", "Hao", ""], ["Sainath", "Tara N.", ""], ["Wu", "Zelin", ""]]}, {"id": "1907.01385", "submitter": "Yue Xu", "authors": "Yue Xu, Zengde Deng, Mengdi Wang, Wenjun Xu, Anthony Man-Cho So,\n  Shuguang Cui", "title": "Voting-Based Multi-Agent Reinforcement Learning for Intelligent IoT", "comments": "Published at IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of single-agent reinforcement learning (RL) in Internet of\nthings (IoT) systems motivates the study of multi-agent reinforcement learning\n(MARL), which is more challenging but more useful in large-scale IoT. In this\npaper, we consider a voting-based MARL problem, in which the agents vote to\nmake group decisions and the goal is to maximize the globally averaged returns.\nTo this end, we formulate the MARL problem based on the linear programming form\nof the policy optimization problem and propose a distributed primal-dual\nalgorithm to obtain the optimal solution. We also propose a voting mechanism\nthrough which the distributed learning achieves the same sublinear convergence\nrate as centralized learning. In other words, the distributed decision making\ndoes not slow down the process of achieving global consensus on optimality.\nLastly, we verify the convergence of our proposed algorithm with numerical\nsimulations and conduct case studies in practical multi-agent IoT systems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 14:12:51 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 09:52:36 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 09:37:42 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Xu", "Yue", ""], ["Deng", "Zengde", ""], ["Wang", "Mengdi", ""], ["Xu", "Wenjun", ""], ["So", "Anthony Man-Cho", ""], ["Cui", "Shuguang", ""]]}, {"id": "1907.01399", "submitter": "Santiago L\\'opez-Tapia", "authors": "Santiago L\\'opez-Tapia and Alice Lucas and Rafael Molina and Aggelos\n  K. Katsaggelos", "title": "A Single Video Super-Resolution GAN for Multiple Downsampling Operators\n  based on Pseudo-Inverse Image Formation Models", "comments": null, "journal-ref": null, "doi": "10.1016/j.dsp.2020.102801", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popularity of high and ultra-high definition displays has led to the need\nfor methods to improve the quality of videos already obtained at much lower\nresolutions. Current Video Super-Resolution methods are not robust to mismatch\nbetween training and testing degradation models since they are trained against\na single degradation model (usually bicubic downsampling). This causes their\nperformance to deteriorate in real-life applications. At the same time, the use\nof only the Mean Squared Error during learning causes the resulting images to\nbe too smooth. In this work we propose a new Convolutional Neural Network for\nvideo super resolution which is robust to multiple degradation models. During\ntraining, which is performed on a large dataset of scenes with slow and fast\nmotions, it uses the pseudo-inverse image formation model as part of the\nnetwork architecture in conjunction with perceptual losses, in addition to a\nsmoothness constraint that eliminates the artifacts originating from these\nperceptual losses. The experimental validation shows that our approach\noutperforms current state-of-the-art methods and is robust to multiple\ndegradations.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 14:28:27 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["L\u00f3pez-Tapia", "Santiago", ""], ["Lucas", "Alice", ""], ["Molina", "Rafael", ""], ["Katsaggelos", "Aggelos K.", ""]]}, {"id": "1907.01406", "submitter": "Jwala Dhamala", "authors": "Jwala Dhamala, Sandesh Ghimire, John L. Sapp, B. Milan Horacek, Linwei\n  Wang", "title": "Bayesian Optimization on Large Graphs via a Graph Convolutional\n  Generative Model: Application in Cardiac Model Personalization", "comments": "9 pages, 5 figures, MICCAI", "journal-ref": null, "doi": "10.1007/978-3-030-32245-8_51", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalization of cardiac models involves the optimization of organ tissue\nproperties that vary spatially over the non-Euclidean geometry model of the\nheart. To represent the high-dimensional (HD) unknown of tissue properties,\nmost existing works rely on a low-dimensional (LD) partitioning of the\ngeometrical model. While this exploits the geometry of the heart, it is of\nlimited expressiveness to allow partitioning that is small enough for effective\noptimization. Recently, a variational auto-encoder (VAE) was utilized as a more\nexpressive generative model to embed the HD optimization into the LD latent\nspace. Its Euclidean nature, however, neglects the rich geometrical information\nin the heart. In this paper, we present a novel graph convolutional VAE to\nallow generative modeling of non-Euclidean data, and utilize it to embed\nBayesian optimization of large graphs into a small latent space. This approach\nbridges the gap of previous works by introducing an expressive generative model\nthat is able to incorporate the knowledge of spatial proximity and hierarchical\ncompositionality of the underlying geometry. It further allows transferring of\nthe learned features across different geometries, which was not possible with a\nregular VAE. We demonstrate these benefits of the presented method in synthetic\nand real data experiments of estimating tissue excitability in a cardiac\nelectrophysiological model.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:47:21 GMT"}, {"version": "v2", "created": "Mon, 18 May 2020 16:01:35 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Dhamala", "Jwala", ""], ["Ghimire", "Sandesh", ""], ["Sapp", "John L.", ""], ["Horacek", "B. Milan", ""], ["Wang", "Linwei", ""]]}, {"id": "1907.01409", "submitter": "Wilfried Michel", "authors": "Wilfried Michel, Ralf Schl\\\"uter, Hermann Ney", "title": "Comparison of Lattice-Free and Lattice-Based Sequence Discriminative\n  Training Criteria for LVCSR", "comments": "Submitted to Interspeech 2019", "journal-ref": "Interspeech 2019, 20th Annual Conference of the International\n  Speech Communication Association, Graz, Austria, 15-19 September 2019, pp.\n  1601--1605", "doi": "10.21437/Interspeech.2019-2254", "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence discriminative training criteria have long been a standard tool in\nautomatic speech recognition for improving the performance of acoustic models\nover their maximum likelihood / cross entropy trained counterparts. While\npreviously a lattice approximation of the search space has been necessary to\nreduce computational complexity, recently proposed methods use other\napproximations to dispense of the need for the computationally expensive step\nof separate lattice creation.\n  In this work we present a memory efficient implementation of the\nforward-backward computation that allows us to use uni-gram word-level language\nmodels in the denominator calculation while still doing a full summation on\nGPU. This allows for a direct comparison of lattice-based and lattice-free\nsequence discriminative training criteria such as MMI and sMBR, both using the\nsame language model during training.\n  We compared performance, speed of convergence, and stability on large\nvocabulary continuous speech recognition tasks like Switchboard and Quaero. We\nfound that silence modeling seriously impacts the performance in the\nlattice-free case and needs special treatment. In our experiments lattice-free\nMMI comes on par with its lattice-based counterpart. Lattice-based sMBR still\noutperforms all lattice-free training criteria.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:16:04 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Michel", "Wilfried", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "1907.01433", "submitter": "Alaa Maalouf", "authors": "Alaa Maalouf, Adiel Statman, Dan Feldman", "title": "Tight Sensitivity Bounds For Smaller Coresets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An $\\varepsilon$-coreset for Least-Mean-Squares (LMS) of a matrix\n$A\\in{\\mathbb{R}}^{n\\times d}$ is a small weighted subset of its rows that\napproximates the sum of squared distances from its rows to every affine\n$k$-dimensional subspace of ${\\mathbb{R}}^d$, up to a factor of\n$1\\pm\\varepsilon$.\n  Such coresets are useful for hyper-parameter tuning and solving many\nleast-mean-squares problems such as low-rank approximation ($k$-SVD), $k$-PCA,\nLassso/Ridge/Linear regression and many more. Coresets are also useful for\nhandling streaming, dynamic and distributed big data in parallel. With high\nprobability, non-uniform sampling based on upper bounds on what is known as\nimportance or sensitivity of each row in $A$ yields a coreset. The size of the\n(sampled) coreset is then near-linear in the total sum of these sensitivity\nbounds.\n  We provide algorithms that compute provably \\emph{tight} bounds for the\nsensitivity of each input row.\n  It is based on two ingredients: (i) iterative algorithm that computes the\nexact sensitivity of each point up to arbitrary small precision for\n(non-affine) $k$-subspaces, and (ii) a general reduction of independent\ninterest from computing sensitivity for the family of affine $k$-subspaces in\n${\\mathbb{R}}^d$ to (non-affine) $(k+1)$- subspaces in ${\\mathbb{R}}^{d+1}$.\n  Experimental results on real-world datasets, including the English Wikipedia\ndocuments-term matrix, show that our bounds provide significantly smaller and\ndata-dependent coresets also in practice. Full open source is also provided.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 15:19:37 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Maalouf", "Alaa", ""], ["Statman", "Adiel", ""], ["Feldman", "Dan", ""]]}, {"id": "1907.01439", "submitter": "Preethi Lahoti", "authors": "Preethi Lahoti, Krishna P. Gummadi, and Gerhard Weikum", "title": "Operationalizing Individual Fairness with Pairwise Fair Representations", "comments": "To be published in the proceedings of the VLDB Endowment, Vol. 13,\n  Issue. 4", "journal-ref": null, "doi": "10.14778/3372716.3372723", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the notion of individual fairness proposed by Dwork et al. A\ncentral challenge in operationalizing their approach is the difficulty in\neliciting a human specification of a similarity metric. In this paper, we\npropose an operationalization of individual fairness that does not rely on a\nhuman specification of a distance metric. Instead, we propose novel approaches\nto elicit and leverage side-information on equally deserving individuals to\ncounter subordination between social groups. We model this knowledge as a\nfairness graph, and learn a unified Pairwise Fair Representation (PFR) of the\ndata that captures both data-driven similarity between individuals and the\npairwise side-information in fairness graph. We elicit fairness judgments from\na variety of sources, including human judgments for two real-world datasets on\nrecidivism prediction (COMPAS) and violent neighborhood prediction (Crime &\nCommunities). Our experiments show that the PFR model for operationalizing\nindividual fairness is practically viable.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 15:23:01 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 03:59:45 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Lahoti", "Preethi", ""], ["Gummadi", "Krishna P.", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1907.01463", "submitter": "Matthew McDermott", "authors": "Matthew B.A. McDermott (1), Shirly Wang (2), Nikki Marinsek (3),\n  Rajesh Ranganath (4), Marzyeh Ghassemi (2 and 5), Luca Foschini (3) ((1)\n  Massachusetts Institute of Technology, (2) University of Toronto, (3)\n  Evidation Health, Inc., (4) New York University, (5) Vector Institute)", "title": "Reproducibility in Machine Learning for Health", "comments": "Presented at the ICLR 2019 Reproducibility in Machine Learning\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms designed to characterize, monitor, and intervene\non human health (ML4H) are expected to perform safely and reliably when\noperating at scale, potentially outside strict human supervision. This\nrequirement warrants a stricter attention to issues of reproducibility than\nother fields of machine learning.\n  In this work, we conduct a systematic evaluation of over 100 recently\npublished ML4H research papers along several dimensions related to\nreproducibility. We find that the field of ML4H compares poorly to more\nestablished machine learning fields, particularly concerning data and code\naccessibility. Finally, drawing from success in other fields of science, we\npropose recommendations to data providers, academic publishers, and the ML4H\nresearch community in order to promote reproducible research moving forward.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 15:46:46 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["McDermott", "Matthew B. A.", "", "2 and 5"], ["Wang", "Shirly", "", "2 and 5"], ["Marinsek", "Nikki", "", "2 and 5"], ["Ranganath", "Rajesh", "", "2 and 5"], ["Ghassemi", "Marzyeh", "", "2 and 5"], ["Foschini", "Luca", ""]]}, {"id": "1907.01470", "submitter": "Sainbayar Sukhbaatar", "authors": "Sainbayar Sukhbaatar, Edouard Grave, Guillaume Lample, Herve Jegou,\n  Armand Joulin", "title": "Augmenting Self-attention with Persistent Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer networks have lead to important progress in language modeling and\nmachine translation. These models include two consecutive modules, a\nfeed-forward layer and a self-attention layer. The latter allows the network to\ncapture long term dependencies and are often regarded as the key ingredient in\nthe success of Transformers. Building upon this intuition, we propose a new\nmodel that solely consists of attention layers. More precisely, we augment the\nself-attention layers with persistent memory vectors that play a similar role\nas the feed-forward layer. Thanks to these vectors, we can remove the\nfeed-forward layer without degrading the performance of a transformer. Our\nevaluation shows the benefits brought by our model on standard character and\nword level language modeling benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 15:56:20 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Sukhbaatar", "Sainbayar", ""], ["Grave", "Edouard", ""], ["Lample", "Guillaume", ""], ["Jegou", "Herve", ""], ["Joulin", "Armand", ""]]}, {"id": "1907.01475", "submitter": "Zachary Kenton", "authors": "Zachary Kenton, Angelos Filos, Owain Evans, Yarin Gal", "title": "Generalizing from a few environments in safety-critical reinforcement\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Before deploying autonomous agents in the real world, we need to be confident\nthey will perform safely in novel situations. Ideally, we would expose agents\nto a very wide range of situations during training, allowing them to learn\nabout every possible danger, but this is often impractical. This paper\ninvestigates safety and generalization from a limited number of training\nenvironments in deep reinforcement learning (RL). We find RL algorithms can\nfail dangerously on unseen test environments even when performing perfectly on\ntraining environments. Firstly, in a gridworld setting, we show that\ncatastrophes can be significantly reduced with simple modifications, including\nensemble model averaging and the use of a blocking classifier. In the more\nchallenging CoinRun environment we find similar methods do not significantly\nreduce catastrophes. However, we do find that the uncertainty information from\nthe ensemble is useful for predicting whether a catastrophe will occur within a\nfew steps and hence whether human intervention should be requested.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 16:12:34 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Kenton", "Zachary", ""], ["Filos", "Angelos", ""], ["Evans", "Owain", ""], ["Gal", "Yarin", ""]]}, {"id": "1907.01490", "submitter": "Jan N. Fuhg", "authors": "Jan N. Fuhg and Amelie Fau", "title": "An innovative adaptive kriging approach for efficient binary\n  classification of mechanical problems", "comments": "62 pages, 26 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kriging is an efficient machine-learning tool, which allows to obtain an\napproximate response of an investigated phenomenon on the whole parametric\nspace. Adaptive schemes provide a the ability to guide the experiment yielding\nnew sample point positions to enrich the metamodel. Herein a novel adaptive\nscheme called Monte Carlo-intersite Voronoi (MiVor) is proposed to efficiently\nidentify binary decision regions on the basis of a regression surrogate model.\nThe performance of the innovative approach is tested for analytical functions\nas well as some mechanical problems and is furthermore compared to two\nregression-based adaptive schemes. For smooth problems, all three methods have\ncomparable performances. For highly fluctuating response surface as encountered\ne.g. for dynamics or damage problems, the innovative MiVor algorithm performs\nvery well and provides accurate binary classification with only a few\nobservation points.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 16:51:40 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Fuhg", "Jan N.", ""], ["Fau", "Amelie", ""]]}, {"id": "1907.01507", "submitter": "Lek-Heng Lim", "authors": "Lek-Heng Lim, Mateusz Michalek, Yang Qi", "title": "Best k-layer neural network approximations", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the empirical risk minimization (ERM) problem for neural\nnetworks has no solution in general. Given a training set $s_1, \\dots, s_n \\in\n\\mathbb{R}^p$ with corresponding responses $t_1,\\dots,t_n \\in \\mathbb{R}^q$,\nfitting a $k$-layer neural network $\\nu_\\theta : \\mathbb{R}^p \\to \\mathbb{R}^q$\ninvolves estimation of the weights $\\theta \\in \\mathbb{R}^m$ via an ERM: \\[\n\\inf_{\\theta \\in \\mathbb{R}^m} \\; \\sum_{i=1}^n \\lVert t_i - \\nu_\\theta(s_i)\n\\rVert_2^2. \\] We show that even for $k = 2$, this infimum is not attainable in\ngeneral for common activations like ReLU, hyperbolic tangent, and sigmoid\nfunctions. A high-level explanation is like that for the nonexistence of best\nrank-$r$ approximations of higher-order tensors --- the set of parameters is\nnot a closed set --- but the geometry involved for best $k$-layer neural\nnetworks approximations is more subtle. In addition, we show that for smooth\nactivations $\\sigma(x)= 1/\\bigl(1 + \\exp(-x)\\bigr)$ and $\\sigma(x)=\\tanh(x)$,\nsuch failure to attain an infimum can happen on a positive-measured subset of\nresponses. For the ReLU activation $\\sigma(x)=\\max(0,x)$, we completely\nclassifying cases where the ERM for a best two-layer neural network\napproximation attains its infimum. As an aside, we obtain a precise description\nof the geometry of the space of two-layer neural networks with $d$ neurons in\nthe hidden layer: it is the join locus of a line and the $d$-secant locus of a\ncone.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 17:16:54 GMT"}, {"version": "v2", "created": "Wed, 11 Dec 2019 20:23:21 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Lim", "Lek-Heng", ""], ["Michalek", "Mateusz", ""], ["Qi", "Yang", ""]]}, {"id": "1907.01515", "submitter": "Yasith Jayawardana", "authors": "Yasith Jayawardana, Mark Jaime, Sashi Thapaliya, Sampath Jayarathna", "title": "Electroencephalogram (EEG) for Delineating Objective Measure of Autism\n  Spectrum Disorder (ASD) (Extended Version)", "comments": null, "journal-ref": null, "doi": "10.4018/978-1-5225-7467-5.ch002", "report-no": null, "categories": "eess.SP cs.IR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autism Spectrum Disorder (ASD) is a developmental disorder that often impairs\na child's normal development of the brain. According to CDC, it is estimated\nthat 1 in 6 children in the US suffer from development disorders, and 1 in 68\nchildren in the US suffer from ASD. This condition has a negative impact on a\nperson's ability to hear, socialize and communicate. Overall, ASD has a broad\nrange of symptoms and severity; hence the term spectrum is used. One of the\nmain contributors to ASD is known to be genetics. Up to date, no suitable cure\nfor ASD has been found. Early diagnosis is crucial for the long-term treatment\nof ASD, but this is challenging due to the lack of a proper objective measures.\nSubjective measures often take more time, resources, and have false positives\nor false negatives. There is a need for efficient objective measures that can\nhelp in diagnosing this disease early as possible with less effort.\n  EEG measures the electric signals of the brain via electrodes placed on\nvarious places on the scalp. These signals can be used to study complex\nneuropsychiatric issues. Studies have shown that EEG has the potential to be\nused as a biomarker for various neurological conditions including ASD. This\nchapter will outline the usage of EEG measurement for the classification of ASD\nusing machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 01:13:21 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Jayawardana", "Yasith", ""], ["Jaime", "Mark", ""], ["Thapaliya", "Sashi", ""], ["Jayarathna", "Sampath", ""]]}, {"id": "1907.01543", "submitter": "Kiran Koshy Thekumparampil", "authors": "Kiran Koshy Thekumparampil, Prateek Jain, Praneeth Netrapalli, Sewoong\n  Oh", "title": "Efficient Algorithms for Smooth Minimax Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies first order methods for solving smooth minimax\noptimization problems $\\min_x \\max_y g(x,y)$ where $g(\\cdot,\\cdot)$ is smooth\nand $g(x,\\cdot)$ is concave for each $x$. In terms of $g(\\cdot,y)$, we consider\ntwo settings -- strongly convex and nonconvex -- and improve upon the best\nknown rates in both. For strongly-convex $g(\\cdot, y),\\ \\forall y$, we propose\na new algorithm combining Mirror-Prox and Nesterov's AGD, and show that it can\nfind global optimum in $\\tilde{O}(1/k^2)$ iterations, improving over current\nstate-of-the-art rate of $O(1/k)$. We use this result along with an inexact\nproximal point method to provide $\\tilde{O}(1/k^{1/3})$ rate for finding\nstationary points in the nonconvex setting where $g(\\cdot, y)$ can be\nnonconvex. This improves over current best-known rate of $O(1/k^{1/5})$.\nFinally, we instantiate our result for finite nonconvex minimax problems, i.e.,\n$\\min_x \\max_{1\\leq i\\leq m} f_i(x)$, with nonconvex $f_i(\\cdot)$, to obtain\nconvergence rate of $O(m(\\log m)^{3/2}/k^{1/3})$ total gradient evaluations for\nfinding a stationary point.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 17:50:34 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Thekumparampil", "Kiran Koshy", ""], ["Jain", "Prateek", ""], ["Netrapalli", "Praneeth", ""], ["Oh", "Sewoong", ""]]}, {"id": "1907.01549", "submitter": "Siddhartha Devapujula", "authors": "Siddhartha Devapujula, Sagar Arora, Sumit Borar", "title": "Learning to Rank Broad and Narrow Queries in E-Commerce", "comments": "7+1 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search is a prominent channel for discovering products on an e-commerce\nplatform. Ranking products retrieved from search becomes crucial to address\ncustomer's need and optimize for business metrics. While learning to Rank\n(LETOR) models have been extensively studied and have demonstrated efficacy in\nthe context of web search; it is a relatively new research area to be explored\nin the e-commerce. In this paper, we present a framework for building LETOR\nmodel for an e-commerce platform. We analyze user queries and propose a\nmechanism to segment queries between broad and narrow based on user's intent.\nWe discuss different types of features - query, product and query-product and\ndiscuss challenges in using them. We show that sparsity in product features can\nbe tackled through a denoising auto-encoder while skip-gram based word\nembeddings help solve the query-product sparsity issues. We also present\nvarious target metrics that can be employed for evaluating search results and\ncompare their robustness. Further, we build and compare performances of both\npointwise and pairwise LETOR models on fashion category data set. We also build\nand compare distinct models for broad and narrow queries, analyze feature\nimportance across these and show that these specialized models perform better\nthan a combined model in the fashion world.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 18:30:38 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 09:17:51 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Devapujula", "Siddhartha", ""], ["Arora", "Sagar", ""], ["Borar", "Sumit", ""]]}, {"id": "1907.01552", "submitter": "Shunya Okuno", "authors": "Shunya Okuno, Kazuyuki Aihara, Yoshito Hirata", "title": "Forecasting high-dimensional dynamics exploiting suboptimal embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delay embedding---a method for reconstructing dynamical systems by delay\ncoordinates---is widely used to forecast nonlinear time series as a model-free\napproach. When multivariate time series are observed, several existing\nframeworks can be applied to yield a single forecast combining multiple\nforecasts derived from various embeddings. However, the performance of these\nframeworks is not always satisfactory because they randomly select embeddings\nor use brute force and do not consider the diversity of the embeddings to\ncombine. Herein, we develop a forecasting framework that overcomes these\nexisting problems. The framework exploits various \"suboptimal embeddings\"\nobtained by minimizing the in-sample error via combinatorial optimization. The\nframework achieves the best results among existing frameworks for sample toy\ndatasets and a real-world flood dataset. We show that the framework is\napplicable to a wide range of data lengths and dimensions. Therefore, the\nframework can be applied to various fields such as neuroscience, ecology,\nfinance, fluid dynamics, weather, and disaster prevention.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 02:14:22 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Okuno", "Shunya", ""], ["Aihara", "Kazuyuki", ""], ["Hirata", "Yoshito", ""]]}, {"id": "1907.01632", "submitter": "Daniel Schwalbe-Koda", "authors": "Daniel Schwalbe-Koda, Rafael G\\'omez-Bombarelli", "title": "Generative Models for Automatic Chemical Design", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-40245-7_21", "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Materials discovery is decisive for tackling urgent challenges related to\nenergy, the environment, health care and many others. In chemistry,\nconventional methodologies for innovation usually rely on expensive and\nincremental strategies to optimize properties from molecular structures. On the\nother hand, inverse approaches map properties to structures, thus expediting\nthe design of novel useful compounds. In this chapter, we examine the way in\nwhich current deep generative models are addressing the inverse chemical\ndiscovery paradigm. We begin by revisiting early inverse design algorithms.\nThen, we introduce generative models for molecular systems and categorize them\naccording to their architecture and molecular representation. Using this\nclassification, we review the evolution and performance of important molecular\ngeneration schemes reported in the literature. Finally, we conclude\nhighlighting the prospects and challenges of generative models as cutting edge\ntools in materials discovery.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 20:57:23 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Schwalbe-Koda", "Daniel", ""], ["G\u00f3mez-Bombarelli", "Rafael", ""]]}, {"id": "1907.01636", "submitter": "Clint Pazhayidam George", "authors": "Clint P. George, Wei Xia, George Michailidis", "title": "Analyses of Multi-collection Corpora via Compound Topic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As electronically stored data grow in daily life, obtaining novel and\nrelevant information becomes challenging in text mining. Thus people have\nsought statistical methods based on term frequency, matrix algebra, or topic\nmodeling for text mining. Popular topic models have centered on one single text\ncollection, which is deficient for comparative text analyses. We consider a\nsetting where one can partition the corpus into subcollections. Each\nsubcollection shares a common set of topics, but there exists relative\nvariation in topic proportions among collections. Including any prior knowledge\nabout the corpus (e.g. organization structure), we propose the compound latent\nDirichlet allocation (cLDA) model, improving on previous work, encouraging\ngeneralizability, and depending less on user-input parameters. To identify the\nparameters of interest in cLDA, we study Markov chain Monte Carlo (MCMC) and\nvariational inference approaches extensively, and suggest an efficient MCMC\nmethod. We evaluate cLDA qualitatively and quantitatively using both synthetic\nand real-world corpora. The usability study on some real-world corpora\nillustrates the superiority of cLDA to explore the underlying topics\nautomatically but also model their connections and variations across multiple\ncollections.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 06:59:25 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["George", "Clint P.", ""], ["Xia", "Wei", ""], ["Michailidis", "George", ""]]}, {"id": "1907.01637", "submitter": "Syrine Krichene", "authors": "Syrine Krichene and Mike Gartrell and Clement Calauzenes", "title": "Embedding models for recommendation under contextual constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding models, which learn latent representations of users and items based\non user-item interaction patterns, are a key component of recommendation\nsystems. In many applications, contextual constraints need to be applied to\nrefine recommendations, e.g. when a user specifies a price range or product\ncategory filter. The conventional approach, for both context-aware and standard\nmodels, is to retrieve items and apply the constraints as independent\noperations. The order in which these two steps are executed can induce\nsignificant problems. For example, applying constraints a posteriori can result\nin incomplete recommendations or low-quality results for the tail of the\ndistribution (i.e., less popular items). As a result, the additional\ninformation that the constraint brings about user intent may not be accurately\ncaptured.\n  In this paper we propose integrating the information provided by the\ncontextual constraint into the similarity computation, by merging constraint\napplication and retrieval into one operation in the embedding space. This\ntechnique allows us to generate high-quality recommendations for the specified\nconstraint. Our approach learns constraints representations jointly with the\nuser and item embeddings. We incorporate our methods into a matrix\nfactorization model, and perform an experimental evaluation on one internal and\ntwo real-world datasets. Our results show significant improvements in\npredictive performance compared to context-aware and standard models.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 07:59:38 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Krichene", "Syrine", ""], ["Gartrell", "Mike", ""], ["Calauzenes", "Clement", ""]]}, {"id": "1907.01640", "submitter": "Khalil Damak", "authors": "Khalil Damak, Olfa Nasraoui", "title": "SeER: An Explainable Deep Learning MIDI-based Hybrid Song Recommender\n  System", "comments": "8 pages, 6 figures; added offline validation of explainability method", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art music recommender systems mainly rely on either matrix\nfactorization-based collaborative filtering approaches or deep learning\narchitectures. Deep learning models usually use metadata for content-based\nfiltering or predict the next user interaction by learning from temporal\nsequences of user actions. Despite advances in deep learning for song\nrecommendation, none has taken advantage of the sequential nature of songs by\nlearning sequence models that are based on content. Aside from the importance\nof prediction accuracy, other significant aspects are important, such as\nexplainability and solving the cold start problem. In this work, we propose a\nhybrid deep learning model, called \"SeER\", that uses collaborative filtering\n(CF) and deep learning sequence models on the MIDI content of songs for\nrecommendation in order to provide more accurate personalized recommendations;\nsolve the item cold start problem; and generate a relevant explanation for a\nsong recommendation. Our evaluation experiments show promising results compared\nto state of the art baseline and hybrid song recommender systems in terms of\nranking evaluation. Moreover, based on proposed tests for offline validation,\nwe show that our personalized explanations capture properties that are in\naccordance with the user's preferences.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 18:23:37 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 07:01:35 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Damak", "Khalil", ""], ["Nasraoui", "Olfa", ""]]}, {"id": "1907.01641", "submitter": "Hirotada Honda", "authors": "Hirotada Honda", "title": "Sensitivity of quantum PageRank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss the sensitivity of quantum PageRank. By using the\nfinite dimensional perturbation theory, we estimate the change of the quantum\nPageRank under a small analytical perturbation on the Google matrix. In\naddition, we will show the way to estimate the lower bound of the convergence\nradius as well as the error bound of the finite sum in the expansion of the\nperturbed PageRank.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 05:02:04 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Honda", "Hirotada", ""]]}, {"id": "1907.01643", "submitter": "Hemant Pugaliya", "authors": "Hemant Pugaliya, Karan Saxena, Shefali Garg, Sheetal Shalini, Prashant\n  Gupta, Eric Nyberg, Teruko Mitamura", "title": "Pentagon at MEDIQA 2019: Multi-task Learning for Filtering and\n  Re-ranking Answers using Language Inference and Question Entailment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel deep learning architectures like fine-tuned BERT and MT-DNN, have\nquickly become the state of the art, bypassing previous deep and shallow\nlearning methods by a large margin. More recently, pre-trained models from\nlarge related datasets have been able to perform well on many downstream tasks\nby just fine-tuning on domain-specific datasets . However, using powerful\nmodels on non-trivial tasks, such as ranking and large document classification,\nstill remains a challenge due to input size limitations of parallel\narchitecture and extremely small datasets (insufficient for fine-tuning). In\nthis work, we introduce an end-to-end system, trained in a multi-task setting,\nto filter and re-rank answers in the medical domain. We use task-specific\npre-trained models as deep feature extractors. Our model achieves the highest\nSpearman's Rho and Mean Reciprocal Rank of 0.338 and 0.9622 respectively, on\nthe ACL-BioNLP workshop MediQA Question Answering shared-task.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:48:40 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Pugaliya", "Hemant", ""], ["Saxena", "Karan", ""], ["Garg", "Shefali", ""], ["Shalini", "Sheetal", ""], ["Gupta", "Prashant", ""], ["Nyberg", "Eric", ""], ["Mitamura", "Teruko", ""]]}, {"id": "1907.01644", "submitter": "Dimitrios Rafailidis Dr", "authors": "Dimitrios Rafailidis and Gerhard Weiss", "title": "A Neural Attention Model for Adaptive Learning of Social Friends'\n  Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social-based recommendation systems exploit the selections of friends to\ncombat the data sparsity on user preferences, and improve the recommendation\naccuracy of the collaborative filtering strategy. The main challenge is to\ncapture and weigh friends' preferences, as in practice they do necessarily\nmatch. In this paper, we propose a Neural Attention mechanism for Social\ncollaborative filtering, namely NAS. We design a neural architecture, to\ncarefully compute the non-linearity in friends' preferences by taking into\naccount the social latent effects of friends on user behavior. In addition, we\nintroduce a social behavioral attention mechanism to adaptively weigh the\ninfluence of friends on user preferences and consequently generate accurate\nrecommendations. Our experiments on publicly available datasets demonstrate the\neffectiveness of the proposed NAS model over other state-of-the-art methods.\nFurthermore, we study the effect of the proposed social behavioral attention\nmechanism and show that it is a key factor to our model's performance.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 15:59:28 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Rafailidis", "Dimitrios", ""], ["Weiss", "Gerhard", ""]]}, {"id": "1907.01645", "submitter": "Dimitrios Rafailidis Dr", "authors": "Dimitrios Rafailidis and Gerhard Weiss", "title": "Adaptive Deep Learning of Cross-Domain Loss in Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, users open multiple accounts on social media platforms and\ne-commerce sites, expressing their personal preferences on different domains.\nHowever, users' behaviors change across domains, depending on the content that\nusers interact with, such as movies, music, clothing and retail products. In\nthis paper, we propose an adaptive deep learning strategy for cross-domain\nrecommendation, referred to as ADC. We design a neural architecture and\nformulate a cross-domain loss function, to compute the non-linearity in user\npreferences across domains and transfer the knowledge of users' multiple\nbehaviors, accordingly. In addition, we introduce an efficient algorithm for\ncross-domain loss balancing which directly tunes gradient magnitudes and adapts\nthe learning rates based on the domains' complexities/scales when training the\nmodel via backpropagation. In doing so, ADC controls and adjusts the\ncontribution of each domain when optimizing the model parameters. Our\nexperiments on six publicly available cross-domain recommendation tasks\ndemonstrate the effectiveness of the proposed ADC model over other\nstate-of-the-art methods. Furthermore, we study the effect of the proposed\nadaptive deep learning strategy and show that ADC can well balance the impact\nof the domains with different complexities.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 16:03:44 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Rafailidis", "Dimitrios", ""], ["Weiss", "Gerhard", ""]]}, {"id": "1907.01647", "submitter": "Yong Liu Stephen", "authors": "Yong Liu, Yingtai Xiao, Qiong Wu, Chunyan Miao, Juyong Zhang", "title": "Bandit Learning for Diversified Interactive Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive recommender systems that enable the interactions between users\nand the recommender system have attracted increasing research attentions.\nPrevious methods mainly focus on optimizing recommendation accuracy. However,\nthey usually ignore the diversity of the recommendation results, thus usually\nresults in unsatisfying user experiences. In this paper, we propose a novel\ndiversified recommendation model, named Diversified Contextual Combinatorial\nBandit (DC$^2$B), for interactive recommendation with users' implicit feedback.\nSpecifically, DC$^2$B employs determinantal point process in the recommendation\nprocedure to promote diversity of the recommendation results. To learn the\nmodel parameters, a Thompson sampling-type algorithm based on variational\nBayesian inference is proposed. In addition, theoretical regret analysis is\nalso provided to guarantee the performance of DC$^2$B. Extensive experiments on\nreal datasets are performed to demonstrate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 03:52:55 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Liu", "Yong", ""], ["Xiao", "Yingtai", ""], ["Wu", "Qiong", ""], ["Miao", "Chunyan", ""], ["Zhang", "Juyong", ""]]}, {"id": "1907.01650", "submitter": "Andr\\'as Horv\\'ath", "authors": "K\\'alm\\'an Szentannai, Jalal Al-Afandi, Andr\\'as Horv\\'ath", "title": "MimosaNet: An Unrobust Neural Network Preventing Model Stealing", "comments": "Presented at CVPR workshop: Adversarial Machine Learning in\n  Real-World Computer Vision Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks are robust to minor perturbations of the learned network\nparameters and their minor modifications do not change the overall network\nresponse significantly. This allows space for model stealing, where a\nmalevolent attacker can steal an already trained network, modify the weights\nand claim the new network his own intellectual property. In certain cases this\ncan prevent the free distribution and application of networks in the embedded\ndomain. In this paper, we propose a method for creating an equivalent version\nof an already trained fully connected deep neural network that can prevent\nnetwork stealing: namely, it produces the same responses and classification\naccuracy, but it is extremely sensitive to weight changes.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 21:13:02 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Szentannai", "K\u00e1lm\u00e1n", ""], ["Al-Afandi", "Jalal", ""], ["Horv\u00e1th", "Andr\u00e1s", ""]]}, {"id": "1907.01651", "submitter": "Yu-Chia Chen", "authors": "Yu-Chia Chen and Marina Meil\\u{a}", "title": "Selecting the independent coordinates of manifolds with large aspect\n  ratios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many manifold embedding algorithms fail apparently when the data manifold has\na large aspect ratio (such as a long, thin strip). Here, we formulate success\nand failure in terms of finding a smooth embedding, showing also that the\nproblem is pervasive and more complex than previously recognized.\nMathematically, success is possible under very broad conditions, provided that\nembedding is done by carefully selected eigenfunctions of the Laplace-Beltrami\noperator $\\Delta$. Hence, we propose a bicriterial Independent Eigencoordinate\nSelection (IES) algorithm that selects smooth embeddings with few eigenvectors.\nThe algorithm is grounded in theory, has low computational overhead, and is\nsuccessful on synthetic and large real data.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 21:14:07 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 09:07:23 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Chen", "Yu-Chia", ""], ["Meil\u0103", "Marina", ""]]}, {"id": "1907.01654", "submitter": "Mojdeh Saadati", "authors": "Mojdeh Saadati, Jin Tian", "title": "Adjustment Criteria for Recovering Causal Effects from Missing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Confounding bias, missing data, and selection bias are three common obstacles\nto valid causal inference in the data sciences. Covariate adjustment is the\nmost pervasive technique for recovering casual effects from confounding bias.\nIn this paper, we introduce a covariate adjustment formulation for controlling\nconfounding bias in the presence of missing-not-at-random data and develop a\nnecessary and sufficient condition for recovering causal effects using the\nadjustment. We also introduce an adjustment formulation for controlling both\nconfounding and selection biases in the presence of missing data and develop a\nnecessary and sufficient condition for valid adjustment. Furthermore, we\npresent an algorithm that lists all valid adjustment sets and an algorithm that\nfinds a valid adjustment set containing the minimum number of variables, which\nare useful for researchers interested in selecting adjustment sets with desired\nproperties.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 21:26:28 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 01:29:12 GMT"}, {"version": "v3", "created": "Sun, 15 Sep 2019 06:02:49 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Saadati", "Mojdeh", ""], ["Tian", "Jin", ""]]}, {"id": "1907.01657", "submitter": "Archit Sharma", "authors": "Archit Sharma, Shixiang Gu, Sergey Levine, Vikash Kumar, Karol Hausman", "title": "Dynamics-Aware Unsupervised Discovery of Skills", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventionally, model-based reinforcement learning (MBRL) aims to learn a\nglobal model for the dynamics of the environment. A good model can potentially\nenable planning algorithms to generate a large variety of behaviors and solve\ndiverse tasks. However, learning an accurate model for complex dynamical\nsystems is difficult, and even then, the model might not generalize well\noutside the distribution of states on which it was trained. In this work, we\ncombine model-based learning with model-free learning of primitives that make\nmodel-based planning easy. To that end, we aim to answer the question: how can\nwe discover skills whose outcomes are easy to predict? We propose an\nunsupervised learning algorithm, Dynamics-Aware Discovery of Skills (DADS),\nwhich simultaneously discovers predictable behaviors and learns their dynamics.\nOur method can leverage continuous skill spaces, theoretically, allowing us to\nlearn infinitely many behaviors even for high-dimensional state-spaces. We\ndemonstrate that zero-shot planning in the learned latent space significantly\noutperforms standard MBRL and model-free goal-conditioned RL, can handle\nsparse-reward tasks, and substantially improves over prior hierarchical RL\nmethods for unsupervised skill discovery.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 21:32:19 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 23:20:43 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Sharma", "Archit", ""], ["Gu", "Shixiang", ""], ["Levine", "Sergey", ""], ["Kumar", "Vikash", ""], ["Hausman", "Karol", ""]]}, {"id": "1907.01660", "submitter": "Frederic Pascal", "authors": "Violeta Roizman and Matthieu Jonckheere and Fr\\'ed\\'eric Pascal", "title": "A flexible EM-like clustering algorithm for noisy data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though very popular, it is well known that the EM for GMM algorithm suffers\nfrom non-Gaussian distribution shapes, outliers and high-dimensionality. In\nthis paper, we design a new robust clustering algorithm that can efficiently\ndeal with noise and outliers in diverse data sets. As an EM-like algorithm, it\nis based on both estimations of clusters centers and covariances. In addition,\nusing a semi-parametric paradigm, the method estimates an unknown scale\nparameter per data-point. This allows the algorithm to accommodate for heavier\ntails distributions and outliers without significantly loosing efficiency in\nvarious classical scenarios. We first derive and analyze the proposed algorithm\nin the context of elliptical distributions, showing in particular important\ninsensitivity properties to the underlying data distributions. We then study\nthe convergence and accuracy of the algorithm by considering first synthetic\ndata. Then, we show that the proposed algorithm outperforms other classical\nunsupervised methods of the literature such as k-means, the EM for Gaussian\nmixture models and its recent modifications or spectral clustering when applied\nto real data sets as MNIST, NORB, and 20newsgroups.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 21:36:30 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 14:21:55 GMT"}, {"version": "v3", "created": "Wed, 30 Sep 2020 07:51:28 GMT"}, {"version": "v4", "created": "Mon, 5 Oct 2020 11:28:26 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Roizman", "Violeta", ""], ["Jonckheere", "Matthieu", ""], ["Pascal", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1907.01661", "submitter": "Xiaoxiao Li", "authors": "Xiaoxiao Li, Nicha C. Dvornek, Yuan Zhou, Juntang Zhuang, Pamela\n  Ventola and James S. Duncan", "title": "Graph Neural Network for Interpreting Task-fMRI Biomarkers", "comments": null, "journal-ref": "Medical Image Computing and Computer-Assisted Intervention 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the biomarkers associated with ASD is helpful for understanding the\nunderlying roots of the disorder and can lead to earlier diagnosis and more\ntargeted treatment. A promising approach to identify biomarkers is using Graph\nNeural Networks (GNNs), which can be used to analyze graph structured data,\ni.e. brain networks constructed by fMRI. One way to interpret important\nfeatures is through looking at how the classification probability changes if\nthe features are occluded or replaced. The major limitation of this approach is\nthat replacing values may change the distribution of the data and lead to\nserious errors. Therefore, we develop a 2-stage pipeline to eliminate the need\nto replace features for reliable biomarker interpretation. Specifically, we\npropose an inductive GNN to embed the graphs containing different properties of\ntask-fMRI for identifying ASD and then discover the brain regions/sub-graphs\nused as evidence for the GNN classifier. We first show GNN can achieve high\naccuracy in identifying ASD. Next, we calculate the feature importance scores\nusing GNN and compare the interpretation ability with Random Forest. Finally,\nwe run with different atlases and parameters, proving the robustness of the\nproposed method. The detected biomarkers reveal their association with social\nbehaviors. We also show the potential of discovering new informative\nbiomarkers. Our pipeline can be generalized to other graph feature importance\ninterpretation problems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 21:43:43 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2019 02:40:08 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Li", "Xiaoxiao", ""], ["Dvornek", "Nicha C.", ""], ["Zhou", "Yuan", ""], ["Zhuang", "Juntang", ""], ["Ventola", "Pamela", ""], ["Duncan", "James S.", ""]]}, {"id": "1907.01662", "submitter": "Hatem Hajri", "authors": "Thomas Gerald, Hadi Zaatiti, Hatem Hajri, Nicolas Baskiotis, Olivier\n  Schwander", "title": "From Node Embedding To Community Embedding : A Hyperbolic Approach", "comments": "This version replaces the previous one. The package generating the\n  experimental results will be made public in the near future", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting communities on graphs has received significant interest in recent\nliterature. Current state-of-the-art community embedding approach called\n\\textit{ComE} tackles this problem by coupling graph embedding with community\ndetection. Considering the success of hyperbolic representations of\ngraph-structured data in last years, an ongoing challenge is to set up a\nhyperbolic approach for the community detection problem. The present paper\nmeets this challenge by introducing a Riemannian equivalent of \\textit{ComE}.\nOur proposed approach combines hyperbolic embeddings with Riemannian K-means or\nRiemannian mixture models to perform community detection. We illustrate the\nusefulness of this framework through several experiments on real-world social\nnetworks and comparisons with \\textit{ComE} and recent hyperbolic-based\nclassification approaches.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 21:45:22 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 12:23:50 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Gerald", "Thomas", ""], ["Zaatiti", "Hadi", ""], ["Hajri", "Hatem", ""], ["Baskiotis", "Nicolas", ""], ["Schwander", "Olivier", ""]]}, {"id": "1907.01674", "submitter": "Manisha Panta", "authors": "Manisha Panta, Avdesh Mishra, Md Tamjidul Hoque, Joel Atallah", "title": "Machine Learning based Prediction of Hierarchical Classification of\n  Transposable Elements", "comments": "9 pages, 7 figures, 5 tables, BIOKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Transposable Elements (TEs) or jumping genes are the DNA sequences that have\nan intrinsic capability to move within a host genome from one genomic location\nto another. Studies show that the presence of a TE within or adjacent to a\nfunctional gene may alter its expression. TEs can also cause an increase in the\nrate of mutation and can even mediate duplications and large insertions and\ndeletions in the genome, promoting gross genetic rearrangements. Thus, the\nproper classification of the identified jumping genes is essential to\nunderstand their genetic and evolutionary effects in the genome. While\ncomputational methods have been developed that perform either binary\nclassification or multi-label classification of TEs, few studies have focused\non their hierarchical classification. The state-of-the-art machine learning\nclassification method utilizes a Multi-Layer Perceptron (MLP), a class of\nneural network, for hierarchical classification of TEs. However, the existing\nmethods have limited accuracy in classifying TEs. A more effective classifier,\nwhich can explain the role of TEs in germline and somatic evolution, is needed.\nIn this study, we examine the performance of a variety of machine learning (ML)\nmethods. And eventually, propose a robust approach for the hierarchical\nclassification of TEs, with higher accuracy, using Support Vector Machines\n(SVM).\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 23:09:57 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 00:21:38 GMT"}, {"version": "v3", "created": "Mon, 26 Aug 2019 17:31:50 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Panta", "Manisha", ""], ["Mishra", "Avdesh", ""], ["Hoque", "Md Tamjidul", ""], ["Atallah", "Joel", ""]]}, {"id": "1907.01678", "submitter": "Antonio Orvieto", "authors": "Antonio Orvieto, Jonas Kohler and Aurelien Lucchi", "title": "The Role of Memory in Stochastic Optimization", "comments": "Accepted paper at the 35th Conference on Uncertainty in Artificial\n  Intelligence (UAI), Tel Aviv, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of how to retain information about past gradients dramatically\naffects the convergence properties of state-of-the-art stochastic optimization\nmethods, such as Heavy-ball, Nesterov's momentum, RMSprop and Adam. Building on\nthis observation, we use stochastic differential equations (SDEs) to explicitly\nstudy the role of memory in gradient-based algorithms. We first derive a\ngeneral continuous-time model that can incorporate arbitrary types of memory,\nfor both deterministic and stochastic settings. We provide convergence\nguarantees for this SDE for weakly-quasi-convex and quadratically growing\nfunctions. We then demonstrate how to discretize this SDE to get a flexible\ndiscrete-time algorithm that can implement a board spectrum of memories ranging\nfrom short- to long-term. Not only does this algorithm increase the degrees of\nfreedom in algorithmic choice for practitioners but it also comes with better\nstability properties than classical momentum in the convex stochastic setting.\nIn particular, no iterate averaging is needed for convergence. Interestingly,\nour analysis also provides a novel interpretation of Nesterov's momentum as\nstable gradient amplification and highlights a possible reason for its unstable\nbehavior in the (convex) stochastic setting. Furthermore, we discuss the use of\nlong term memory for second-moment estimation in adaptive methods, such as Adam\nand RMSprop. Finally, we provide an extensive experimental study of the effect\nof different types of memory in both convex and nonconvex settings.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 23:30:18 GMT"}, {"version": "v2", "created": "Wed, 11 Mar 2020 23:19:05 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Orvieto", "Antonio", ""], ["Kohler", "Jonas", ""], ["Lucchi", "Aurelien", ""]]}, {"id": "1907.01693", "submitter": "Dongrui Wu", "authors": "Chenfeng Guo, Dongrui Wu", "title": "Canonical Correlation Analysis (CCA) Based Multi-View Learning: An\n  Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view learning (MVL) is a strategy for fusing data from different\nsources or subsets. Canonical correlation analysis (CCA) is very important in\nMVL, whose main idea is to map data from different views onto a common space\nwith maximum correlation. Traditional CCA can only be used to calculate the\nlinear correlation of two views. Besides, it is unsupervised and the label\ninformation is wasted. Many nonlinear, supervised, or generalized extensions\nhave been proposed to overcome these limitations. However, to our knowledge,\nthere is no overview for these approaches. This paper provides an overview of\nmany representative CCA-based MVL approaches.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 00:53:32 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 00:08:54 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Guo", "Chenfeng", ""], ["Wu", "Dongrui", ""]]}, {"id": "1907.01698", "submitter": "S\\'ebastien Le Digabel", "authors": "Dounia Lakhmiri and S\\'ebastien Le Digabel and Christophe Tribes", "title": "HyperNOMAD: Hyperparameter optimization of deep neural networks using\n  mesh adaptive direct search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of deep neural networks is highly sensitive to the choice of\nthe hyperparameters that define the structure of the network and the learning\nprocess. When facing a new application, tuning a deep neural network is a\ntedious and time consuming process that is often described as a \"dark art\".\nThis explains the necessity of automating the calibration of these\nhyperparameters. Derivative-free optimization is a field that develops methods\ndesigned to optimize time consuming functions without relying on derivatives.\nThis work introduces the HyperNOMAD package, an extension of the NOMAD software\nthat applies the MADS algorithm [7] to simultaneously tune the hyperparameters\nresponsible for both the architecture and the learning process of a deep neural\nnetwork (DNN), and that allows for an important flexibility in the exploration\nof the search space by taking advantage of categorical variables. This new\napproach is tested on the MNIST and CIFAR-10 data sets and achieves results\ncomparable to the current state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 01:36:29 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Lakhmiri", "Dounia", ""], ["Digabel", "S\u00e9bastien Le", ""], ["Tribes", "Christophe", ""]]}, {"id": "1907.01702", "submitter": "Yingyang Chen", "authors": "Chunkai Zhang, Shaocong Li, Hongye Zhang, and Yingyang Chen", "title": "VELC: A New Variational AutoEncoder Based Model for Time Series Anomaly\n  Detection", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is a classical but worthwhile problem, and many deep\nlearning-based anomaly detection algorithms have been proposed, which can\nusually achieve better detection results than traditional methods. In view of\nreconstruct ability of the model and the calculation of anomaly score, this\npaper proposes a time series anomaly detection method based on Variational\nAutoEncoder model(VAE) with re-Encoder and Latent Constraint network(VELC). In\norder to modify reconstruct ability of the model to prevent it from\nreconstructing abnormal samples well, we add a constraint network in the latent\nspace of the VAE to force it generate new latent variables that are similar\nwith that of training samples. To be able to calculate anomaly score in two\nfeature spaces, we train a re-encoder to transform the generated data to a new\nlatent space. For better handling the time series, we use the LSTM as the\nencoder and decoder part of the VAE framework. Experimental results of several\nbenchmarks show that our method outperforms state-of-the-art anomaly detection\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 02:00:52 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2020 08:07:35 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Zhang", "Chunkai", ""], ["Li", "Shaocong", ""], ["Zhang", "Hongye", ""], ["Chen", "Yingyang", ""]]}, {"id": "1907.01703", "submitter": "Sidharth Gupta", "authors": "Sidharth Gupta, R\\'emi Gribonval, Laurent Daudet and Ivan Dokmani\\'c", "title": "Don't take it lightly: Phasing optical random projections with unknown\n  operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.ET eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we tackle the problem of recovering the phase of complex linear\nmeasurements when only magnitude information is available and we control the\ninput. We are motivated by the recent development of dedicated optics-based\nhardware for rapid random projections which leverages the propagation of light\nin random media. A signal of interest $\\mathbf{\\xi} \\in \\mathbb{R}^N$ is mixed\nby a random scattering medium to compute the projection $\\mathbf{y} =\n\\mathbf{A} \\mathbf{\\xi}$, with $\\mathbf{A} \\in \\mathbb{C}^{M \\times N}$ being a\nrealization of a standard complex Gaussian iid random matrix. Such optics-based\nmatrix multiplications can be much faster and energy-efficient than their CPU\nor GPU counterparts, yet two difficulties must be resolved: only the intensity\n${|\\mathbf{y}|}^2$ can be recorded by the camera, and the transmission matrix\n$\\mathbf{A}$ is unknown. We show that even without knowing $\\mathbf{A}$, we can\nrecover the unknown phase of $\\mathbf{y}$ for some equivalent transmission\nmatrix with the same distribution as $\\mathbf{A}$. Our method is based on two\nobservations: first, conjugating or changing the phase of any row of\n$\\mathbf{A}$ does not change its distribution; and second, since we control the\ninput we can interfere $\\mathbf{\\xi}$ with arbitrary reference signals. We show\nhow to leverage these observations to cast the measurement phase retrieval\nproblem as a Euclidean distance geometry problem. We demonstrate appealing\nproperties of the proposed algorithm in both numerical simulations and real\nhardware experiments. Not only does our algorithm accurately recover the\nmissing phase, but it mitigates the effects of quantization and the sensitivity\nthreshold, thus improving the measured magnitudes.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 02:01:41 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 01:58:53 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 21:55:55 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Gupta", "Sidharth", ""], ["Gribonval", "R\u00e9mi", ""], ["Daudet", "Laurent", ""], ["Dokmani\u0107", "Ivan", ""]]}, {"id": "1907.01705", "submitter": "Keegan Hines E", "authors": "C. Bayan Bruss, Anish Khazane, Jonathan Rider, Richard Serpe, Saurabh\n  Nagrecha, Keegan E. Hines", "title": "Graph Embeddings at Scale", "comments": "Workshop on Mining and Learning with Graphs 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph embedding is a popular algorithmic approach for creating vector\nrepresentations for individual vertices in networks. Training these algorithms\nat scale is important for creating embeddings that can be used for\nclassification, ranking, recommendation and other common applications in\nindustry. While industrial systems exist for training graph embeddings on large\ndatasets, many of these distributed architectures are forced to partition\ncopious amounts of data and model logic across many worker nodes. In this\npaper, we propose a distributed infrastructure that completely avoids graph\npartitioning, dynamically creates size constrained computational graphs across\nworker nodes, and uses highly efficient indexing operations for updating\nembeddings that allow the system to function at scale. We show that our system\ncan scale an existing embeddings algorithm - skip-gram - to train on the\nopen-source Friendster network (68 million vertices) and on an internal\nheterogeneous graph (50 million vertices). We measure the performance of our\nsystem on two key quantitative metrics: link-prediction accuracy and rate of\nconvergence. We conclude this work by analyzing how a greater number of worker\nnodes actually improves our system's performance on the aforementioned metrics\nand discuss our next steps for rigorously evaluating the embedding vectors\nproduced by our system.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 02:02:39 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Bruss", "C. Bayan", ""], ["Khazane", "Anish", ""], ["Rider", "Jonathan", ""], ["Serpe", "Richard", ""], ["Nagrecha", "Saurabh", ""], ["Hines", "Keegan E.", ""]]}, {"id": "1907.01709", "submitter": "Kyoung-Woon On", "authors": "Kyoung-Woon On, Eun-Sol Kim, Yu-Jung Heo, Byoung-Tak Zhang", "title": "Compositional Structure Learning for Sequential Video Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional sequential learning methods such as Recurrent Neural Networks\n(RNNs) focus on interactions between consecutive inputs, i.e. first-order\nMarkovian dependency. However, most of sequential data, as seen with videos,\nhave complex temporal dependencies that imply variable-length semantic flows\nand their compositions, and those are hard to be captured by conventional\nmethods. Here, we propose Temporal Dependency Networks (TDNs) for learning\nvideo data by discovering these complex structures of the videos. The TDNs\nrepresent video as a graph whose nodes and edges correspond to frames of the\nvideo and their dependencies respectively. Via a parameterized kernel with\ngraph-cut and graph convolutions, the TDNs find compositional temporal\ndependencies of the data in multilevel graph forms. We evaluate the proposed\nmethod on the large-scale video dataset Youtube-8M. The experimental results\nshow that our model efficiently learns the complex semantic structure of video\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 02:28:48 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["On", "Kyoung-Woon", ""], ["Kim", "Eun-Sol", ""], ["Heo", "Yu-Jung", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1907.01723", "submitter": "Yihuang Kang", "authors": "Yihuang Kang, I-Ling Cheng, Wenjui Mao, Bowen Kuo, Pei-Ju Lee", "title": "Towards Interpretable Deep Extreme Multi-label Learning", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Machine Learning algorithms, such as deep neural networks, have long\nbeen criticized for being \"black-boxes\"-a kind of models unable to provide how\nit arrive at a decision without further efforts to interpret. This problem has\nraised concerns on model applications' trust, safety, nondiscrimination, and\nother ethical issues. In this paper, we discuss the machine learning\ninterpretability of a real-world application, eXtreme Multi-label Learning\n(XML), which involves learning models from annotated data with many pre-defined\nlabels. We propose a two-step XML approach that combines deep non-negative\nautoencoder with other multi-label classifiers to tackle different data\napplications with a large number of labels. Our experimental result shows that\nthe proposed approach is able to cope with many-label problems as well as to\nprovide interpretable label hierarchies and dependencies that helps us\nunderstand how the model recognizes the existences of objects in an image.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 03:51:31 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Kang", "Yihuang", ""], ["Cheng", "I-Ling", ""], ["Mao", "Wenjui", ""], ["Kuo", "Bowen", ""], ["Lee", "Pei-Ju", ""]]}, {"id": "1907.01728", "submitter": "Yahya Sattar", "authors": "Yahya Sattar and Samet Oymak", "title": "Quickly Finding the Best Linear Model in High Dimensions", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of finding the best linear model that can minimize\nleast-squares loss given a data-set. While this problem is trivial in the low\ndimensional regime, it becomes more interesting in high dimensions where the\npopulation minimizer is assumed to lie on a manifold such as sparse vectors. We\npropose projected gradient descent (PGD) algorithm to estimate the population\nminimizer in the finite sample regime. We establish linear convergence rate and\ndata dependent estimation error bounds for PGD. Our contributions include: 1)\nThe results are established for heavier tailed sub-exponential distributions\nbesides sub-gaussian. 2) We directly analyze the empirical risk minimization\nand do not require a realizable model that connects input data and labels. 3)\nOur PGD algorithm is augmented to learn the bias terms which boosts the\nperformance. The numerical experiments validate our theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 04:16:49 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Sattar", "Yahya", ""], ["Oymak", "Samet", ""]]}, {"id": "1907.01729", "submitter": "Thomas Viehmann", "authors": "Thomas Viehmann", "title": "Implementation of batched Sinkhorn iterations for entropy-regularized\n  Wasserstein loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we review the calculation of entropy-regularised Wasserstein\nloss introduced by Cuturi and document a practical implementation in PyTorch.\nCode is available at\nhttps://github.com/t-vi/pytorch-tvmisc/blob/master/wasserstein-distance/Pytorch_Wasserstein.ipynb\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:25:49 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 14:08:44 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Viehmann", "Thomas", ""]]}, {"id": "1907.01734", "submitter": "Zeyuan Wang", "authors": "Zeyuan Wang, Josiah Poon, and Simon Poon", "title": "AMI-Net+: A Novel Multi-Instance Neural Network for Medical Diagnosis\n  from Incomplete and Imbalanced Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In medical real-world study (RWS), how to fully utilize the fragmentary and\nscarce information in model training to generate the solid diagnosis results is\na challenging task. In this work, we introduce a novel multi-instance neural\nnetwork, AMI-Net+, to train and predict from the incomplete and extremely\nimbalanced data. It is more effective than the state-of-art method, AMI-Net.\nFirst, we also implement embedding, multi-head attention and gated\nattention-based multi-instance pooling to capture the relations of symptoms\nthemselves and with the given disease. Besides, we propose var-ious\nimprovements to AMI-Net, that the cross-entropy loss is replaced by focal loss\nand we propose a novel self-adaptive multi-instance pooling method on\ninstance-level to obtain the bag representation. We validate the performance of\nAMI-Net+ on two real-world datasets, from two different medical domains.\nResults show that our approach outperforms other base-line models by a\nconsiderable margin.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 04:37:31 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Wang", "Zeyuan", ""], ["Poon", "Josiah", ""], ["Poon", "Simon", ""]]}, {"id": "1907.01739", "submitter": "Charu Sharma", "authors": "Charu Sharma, Deepak Nathani, Manohar Kaul", "title": "Solving Partial Assignment Problems using Random Clique Complexes", "comments": "Accepted as a long talk at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an alternate formulation of the partial assignment problem as\nmatching random clique complexes, that are higher-order analogues of random\ngraphs, designed to provide a set of invariants that better detect higher-order\nstructure. The proposed method creates random clique adjacency matrices for\neach k-skeleton of the random clique complexes and matches them, taking into\naccount each point as the affine combination of its geometric neighbourhood. We\njustify our solution theoretically, by analyzing the runtime and storage\ncomplexity of our algorithm along with the asymptotic behaviour of the\nquadratic assignment problem (QAP) that is associated with the underlying\nrandom clique adjacency matrices. Experiments on both synthetic and real-world\ndatasets, containing severe occlusions and distortions, provide insight into\nthe accuracy, efficiency, and robustness of our approach. We outperform diverse\nmatching algorithms by a significant margin.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 04:56:34 GMT"}, {"version": "v2", "created": "Wed, 8 Jul 2020 12:28:06 GMT"}, {"version": "v3", "created": "Wed, 29 Jul 2020 15:12:50 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Sharma", "Charu", ""], ["Nathani", "Deepak", ""], ["Kaul", "Manohar", ""]]}, {"id": "1907.01749", "submitter": "Zexin Cai", "authors": "Zexin Cai, Yaogen Yang, Chuxiong Zhang, Xiaoyi Qin, Ming Li", "title": "Polyphone Disambiguation for Mandarin Chinese Using Conditional Neural\n  Network with Multi-level Embedding Features", "comments": "5 pages, 1 figure, 2 tables, submit to INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a conditional neural network architecture for Mandarin\nChinese polyphone disambiguation. The system is composed of a bidirectional\nrecurrent neural network component acting as a sentence encoder to accumulate\nthe context correlations, followed by a prediction network that maps the\npolyphonic character embeddings along with the conditions to corresponding\npronunciations. We obtain the word-level condition from a pre-trained\nword-to-vector lookup table. One goal of polyphone disambiguation is to address\nthe homograph problem existing in the front-end processing of Mandarin Chinese\ntext-to-speech system. Our system achieves an accuracy of 94.69\\% on a publicly\navailable polyphonic character dataset. To further validate our choices on the\nconditional feature, we investigate polyphone disambiguation systems with\nmulti-level conditions respectively. The experimental results show that both\nthe sentence-level and the word-level conditional embedding features are able\nto attain good performance for Mandarin Chinese polyphone disambiguation.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 05:50:34 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Cai", "Zexin", ""], ["Yang", "Yaogen", ""], ["Zhang", "Chuxiong", ""], ["Qin", "Xiaoyi", ""], ["Li", "Ming", ""]]}, {"id": "1907.01755", "submitter": "Ba Dung Le Dr", "authors": "Ba Dung Le, Guanhua Wang, Mehwish Nasim and Ali Babar", "title": "Gathering Cyber Threat Intelligence from Twitter Using Novelty\n  Classification", "comments": "ACCEPTED by the 2019 International Conference on Cyberworlds (CW2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Preventing organizations from Cyber exploits needs timely intelligence about\nCyber vulnerabilities and attacks, referred as threats. Cyber threat\nintelligence can be extracted from various sources including social media\nplatforms where users publish the threat information in real time. Gathering\nCyber threat intelligence from social media sites is a time consuming task for\nsecurity analysts that can delay timely response to emerging Cyber threats. We\npropose a framework for automatically gathering Cyber threat intelligence from\nTwitter by using a novelty detection model. Our model learns the features of\nCyber threat intelligence from the threat descriptions published in public\nrepositories such as Common Vulnerabilities and Exposures (CVE) and classifies\na new unseen tweet as either normal or anomalous to Cyber threat intelligence.\nWe evaluate our framework using a purpose-built data set of tweets from 50\ninfluential Cyber security related accounts over twelve months (in 2018). Our\nclassifier achieves the F1-score of 0.643 for classifying Cyber threat tweets\nand outperforms several baselines including binary classification models. Our\nanalysis of the classification results suggests that Cyber threat relevant\ntweets on Twitter do not often include the CVE identifier of the related\nthreats. Hence, it would be valuable to collect these tweets and associate them\nwith the related CVE identifier for cyber security applications.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 06:31:52 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 00:45:40 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Le", "Ba Dung", ""], ["Wang", "Guanhua", ""], ["Nasim", "Mehwish", ""], ["Babar", "Ali", ""]]}, {"id": "1907.01771", "submitter": "Ulysse Marteau-Ferey", "authors": "Ulysse Marteau-Ferey (SIERRA, DI-ENS, PSL), Francis Bach (SIERRA,\n  DI-ENS, PSL), Alessandro Rudi (SIERRA, DI-ENS, PSL)", "title": "Globally Convergent Newton Methods for Ill-conditioned Generalized\n  Self-concordant Losses", "comments": null, "journal-ref": "NeurIPS 2019 - Conference on Neural Information Processing\n  Systems, Dec 2019, Vancouver, Canada", "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study large-scale convex optimization algorithms based on\nthe Newton method applied to regularized generalized self-concordant losses,\nwhich include logistic regression and softmax regression. We first prove that\nour new simple scheme based on a sequence of problems with decreasing\nregularization parameters is provably globally convergent, that this\nconvergence is linear with a constant factor which scales only logarithmically\nwith the condition number. In the parametric setting, we obtain an algorithm\nwith the same scaling than regular first-order methods but with an improved\nbehavior, in particular in ill-conditioned problems. Second, in the non\nparametric machine learning setting, we provide an explicit algorithm combining\nthe previous scheme with Nystr{\\\"o}m projection techniques, and prove that it\nachieves optimal generalization bounds with a time complexity of order O(ndf\n$\\lambda$), a memory complexity of order O(df 2 $\\lambda$) and no dependence on\nthe condition number, generalizing the results known for least-squares\nregression. Here n is the number of observations and df $\\lambda$ is the\nassociated degrees of freedom. In particular, this is the first large-scale\nalgorithm to solve logistic and softmax regressions in the non-parametric\nsetting with large condition numbers and theoretical guarantees.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 07:15:44 GMT"}, {"version": "v2", "created": "Thu, 21 Nov 2019 15:09:01 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Marteau-Ferey", "Ulysse", "", "SIERRA, DI-ENS, PSL"], ["Bach", "Francis", "", "SIERRA,\n  DI-ENS, PSL"], ["Rudi", "Alessandro", "", "SIERRA, DI-ENS, PSL"]]}, {"id": "1907.01803", "submitter": "Khaled Koutini", "authors": "Khaled Koutini, Hamid Eghbal-zadeh, Matthias Dorfer and Gerhard Widmer", "title": "The Receptive Field as a Regularizer in Deep Convolutional Neural\n  Networks for Acoustic Scene Classification", "comments": "IEEE EUSIPCO 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have had great success in many machine\nvision as well as machine audition tasks. Many image recognition network\narchitectures have consequently been adapted for audio processing tasks.\nHowever, despite some successes, the performance of many of these did not\ntranslate from the image to the audio domain. For example, very deep\narchitectures such as ResNet and DenseNet, which significantly outperform VGG\nin image recognition, do not perform better in audio processing tasks such as\nAcoustic Scene Classification (ASC). In this paper, we investigate the reasons\nwhy such powerful architectures perform worse in ASC compared to simpler models\n(e.g., VGG). To this end, we analyse the receptive field (RF) of these CNNs and\ndemonstrate the importance of the RF to the generalization capability of the\nmodels. Using our receptive field analysis, we adapt both ResNet and DenseNet,\nachieving state-of-the-art performance and eventually outperforming the\nVGG-based models. We introduce systematic ways of adapting the RF in CNNs, and\npresent results on three data sets that show how changing the RF over the time\nand frequency dimensions affects a model's performance. Our experimental\nresults show that very small or very large RFs can cause performance\ndegradation, but deep models can be made to generalize well by carefully\nchoosing an appropriate RF size within a certain range.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 09:06:42 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Koutini", "Khaled", ""], ["Eghbal-zadeh", "Hamid", ""], ["Dorfer", "Matthias", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1907.01824", "submitter": "Guillaume Doras", "authors": "Guillaume Doras, Geoffroy Peeters", "title": "Cover Detection using Dominant Melody Embeddings", "comments": null, "journal-ref": "20th International Society for Music Information Retrieval\n  Conference, Delft, The Netherlands, 2019", "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic cover detection -- the task of finding in an audio database all the\ncovers of one or several query tracks -- has long been seen as a challenging\ntheoretical problem in the MIR community and as an acute practical problem for\nauthors and composers societies. Original algorithms proposed for this task\nhave proven their accuracy on small datasets, but are unable to scale up to\nmodern real-life audio corpora. On the other hand, faster approaches designed\nto process thousands of pairwise comparisons resulted in lower accuracy, making\nthem unsuitable for practical use.\n  In this work, we propose a neural network architecture that is trained to\nrepresent each track as a single embedding vector. The computation burden is\ntherefore left to the embedding extraction -- that can be conducted offline and\nstored, while the pairwise comparison task reduces to a simple Euclidean\ndistance computation. We further propose to extract each track's embedding out\nof its dominant melody representation, obtained by another neural network\ntrained for this task. We then show that this architecture improves\nstate-of-the-art accuracy both on small and large datasets, and is able to\nscale to query databases of thousands of tracks in a few seconds.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 09:56:58 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Doras", "Guillaume", ""], ["Peeters", "Geoffroy", ""]]}, {"id": "1907.01845", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu and Bo Zhang and Ruijun Xu", "title": "FairNAS: Rethinking Evaluation Fairness of Weight Sharing Neural\n  Architecture Search", "comments": "Accepted to ICCV21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most critical problems in weight-sharing neural architecture\nsearch is the evaluation of candidate models within a predefined search space.\nIn practice, a one-shot supernet is trained to serve as an evaluator. A\nfaithful ranking certainly leads to more accurate searching results. However,\ncurrent methods are prone to making misjudgments. In this paper, we prove that\ntheir biased evaluation is due to inherent unfairness in the supernet training.\nIn view of this, we propose two levels of constraints: expectation fairness and\nstrict fairness. Particularly, strict fairness ensures equal optimization\nopportunities for all choice blocks throughout the training, which neither\noverestimates nor underestimates their capacity. We demonstrate that this is\ncrucial for improving the confidence of models' ranking. Incorporating the\none-shot supernet trained under the proposed fairness constraints with a\nmulti-objective evolutionary search algorithm, we obtain various\nstate-of-the-art models, e.g., FairNAS-A attains 77.5% top-1 validation\naccuracy on ImageNet. The models and their evaluation codes are made publicly\navailable online http://github.com/fairnas/FairNAS .\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 10:50:38 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 06:16:45 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 06:41:45 GMT"}, {"version": "v4", "created": "Tue, 10 Mar 2020 11:53:02 GMT"}, {"version": "v5", "created": "Wed, 28 Jul 2021 10:19:08 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Zhang", "Bo", ""], ["Xu", "Ruijun", ""]]}, {"id": "1907.01860", "submitter": "Patricio Cerda", "authors": "Patricio Cerda (PARIETAL), Ga\\\"el Varoquaux (NEUROSPIN)", "title": "Encoding high-cardinality string categorical variables", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering, Institute of\n  Electrical and Electronics Engineers, pp.1-1", "doi": "10.1109/TKDE.2020.2992529", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical models usually require vector representations of categorical\nvariables, using for instance one-hot encoding. This strategy breaks down when\nthe number of categories grows, as it creates high-dimensional feature vectors.\nAdditionally, for string entries, one-hot encoding does not capture information\nin their representation.Here, we seek low-dimensional encoding of\nhigh-cardinality string categorical variables. Ideally, these should be:\nscalable to many categories; interpretable to end users; and facilitate\nstatistical analysis. We introduce two encoding approaches for string\ncategories: a Gamma-Poisson matrix factorization on substring counts, and the\nmin-hash encoder, for fast approximation of string similarities. We show that\nmin-hash turns set inclusions into inequality relations that are easier to\nlearn. Both approaches are scalable and streamable. Experiments on real and\nsimulated data show that these methods improve supervised learning with\nhigh-cardinality categorical variables. We recommend the following: if\nscalability is central, the min-hash encoder is the best option as it does not\nrequire any data fit; if interpretability is important, the Gamma-Poisson\nfactorization is the best alternative, as it can be interpreted as one-hot\nencoding on inferred categories with informative feature names. Both models\nenable autoML on the original string entries as they remove the need for\nfeature engineering or data cleaning.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:36:07 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 12:32:56 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 10:17:59 GMT"}, {"version": "v4", "created": "Thu, 5 Sep 2019 08:54:06 GMT"}, {"version": "v5", "created": "Mon, 18 May 2020 15:18:45 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Cerda", "Patricio", "", "PARIETAL"], ["Varoquaux", "Ga\u00ebl", "", "NEUROSPIN"]]}, {"id": "1907.01867", "submitter": "C\\'esar Lincoln Cavalcante Mattos", "authors": "Daniel Augusto R. M. A. de Souza, Diego Mesquita, C\\'esar Lincoln C.\n  Mattos, Jo\\~ao Paulo P. Gomes", "title": "Learning GPLVM with arbitrary kernels using the unscented transformation", "comments": "10 pages, currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Process Latent Variable Model (GPLVM) is a flexible framework to\nhandle uncertain inputs in Gaussian Processes (GPs) and incorporate GPs as\ncomponents of larger graphical models. Nonetheless, the standard GPLVM\nvariational inference approach is tractable only for a narrow family of kernel\nfunctions. The most popular implementations of GPLVM circumvent this limitation\nusing quadrature methods, which may become a computational bottleneck even for\nrelatively low dimensions. For instance, the widely employed Gauss-Hermite\nquadrature has exponential complexity on the number of dimensions. In this\nwork, we propose using the unscented transformation instead. Overall, this\nmethod presents comparable, if not better, performance than offthe-shelf\nsolutions to GPLVM and its computational complexity scales only linearly on\ndimension. In contrast to Monte Carlo methods, our approach is deterministic\nand works well with quasi-Newton methods, such as the\nBroyden-Fletcher-Goldfarb-Shanno (BFGS) algorithm. We illustrate the\napplicability of our method with experiments on dimensionality reduction and\nmultistep-ahead prediction with uncertainty propagation.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:59:04 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 19:35:03 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["de Souza", "Daniel Augusto R. M. A.", ""], ["Mesquita", "Diego", ""], ["Mattos", "C\u00e9sar Lincoln C.", ""], ["Gomes", "Jo\u00e3o Paulo P.", ""]]}, {"id": "1907.01882", "submitter": "Fangcheng Fu", "authors": "Fangcheng Fu, Jiawei Jiang, Yingxia Shao, Bin Cui", "title": "An Experimental Evaluation of Large Scale GBDT Systems", "comments": "Technical Report for paper to appear in VLDB 2019", "journal-ref": null, "doi": "10.14778/3342263.3342273", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient boosting decision tree (GBDT) is a widely-used machine learning\nalgorithm in both data analytic competitions and real-world industrial\napplications. Further, driven by the rapid increase in data volume, efforts\nhave been made to train GBDT in a distributed setting to support large-scale\nworkloads. However, we find it surprising that the existing systems manage the\ntraining dataset in different ways, but none of them have studied the impact of\ndata management. To that end, this paper aims to study the pros and cons of\ndifferent data management methods regarding the performance of distributed\nGBDT. We first introduce a quadrant categorization of data management policies\nbased on data partitioning and data storage. Then we conduct an in-depth\nsystematic analysis and summarize the advantageous scenarios of the quadrants.\nBased on the analysis, we further propose a novel distributed GBDT system named\nVero, which adopts the unexplored composition of vertical partitioning and\nrow-store and suits for many large-scale cases. To validate our analysis\nempirically, we implement different quadrants in the same code base and compare\nthem under extensive workloads, and finally compare Vero with other\nstate-of-the-art systems over a wide range of datasets. Our theoretical and\nexperimental results provide a guideline on choosing a proper data management\npolicy for a given workload.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 12:26:38 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 15:51:47 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Fu", "Fangcheng", ""], ["Jiang", "Jiawei", ""], ["Shao", "Yingxia", ""], ["Cui", "Bin", ""]]}, {"id": "1907.01894", "submitter": "Francis Bunnin", "authors": "F.O.Bunnin and J.Q.Smith", "title": "A Bayesian Hierarchical Model for Criminal Investigations", "comments": "57 pages, 20 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Potential violent criminals will often need to go through a sequence of\npreparatory steps before they can execute their plans. During this escalation\nprocess police have the opportunity to evaluate the threat posed by such people\nthrough what they know, observe and learn from intelligence reports about their\nactivities. In this paper we customise a three-level Bayesian hierarchical\nmodel to describe this process. This is able to propagate both routine and\nunexpected evidence in real time. We discuss how to set up such a model so that\nit calibrates to domain expert judgments. The model illustrations include a\nhypothetical example based on a potential vehicle based terrorist attack.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 12:40:42 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 14:39:31 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Bunnin", "F. O.", ""], ["Smith", "J. Q.", ""]]}, {"id": "1907.01898", "submitter": "Amit Moscovich", "authors": "Amit Moscovich and Amit Halevi and Joakim And\\'en and Amit Singer", "title": "Cryo-EM reconstruction of continuous heterogeneity by Laplacian spectral\n  volumes", "comments": "33 pages, 10 figures", "journal-ref": "Inverse Problems, 36:2 (2020)", "doi": "10.1088/1361-6420/ab4f55", "report-no": null, "categories": "eess.IV cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-particle electron cryomicroscopy is an essential tool for\nhigh-resolution 3D reconstruction of proteins and other biological\nmacromolecules. An important challenge in cryo-EM is the reconstruction of\nnon-rigid molecules with parts that move and deform. Traditional reconstruction\nmethods fail in these cases, resulting in smeared reconstructions of the moving\nparts. This poses a major obstacle for structural biologists, who need\nhigh-resolution reconstructions of entire macromolecules, moving parts\nincluded. To address this challenge, we present a new method for the\nreconstruction of macromolecules exhibiting continuous heterogeneity. The\nproposed method uses projection images from multiple viewing directions to\nconstruct a graph Laplacian through which the manifold of three-dimensional\nconformations is analyzed. The 3D molecular structures are then expanded in a\nbasis of Laplacian eigenvectors, using a novel generalized tomographic\nreconstruction algorithm to compute the expansion coefficients. These\ncoefficients, which we name spectral volumes, provide a high-resolution\nvisualization of the molecular dynamics. We provide a theoretical analysis and\nevaluate the method empirically on several simulated data sets.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 22:58:05 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 21:00:48 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Moscovich", "Amit", ""], ["Halevi", "Amit", ""], ["And\u00e9n", "Joakim", ""], ["Singer", "Amit", ""]]}, {"id": "1907.01901", "submitter": "Ross Kleiman PhD", "authors": "Ross S. Kleiman, Paul S. Bennett, Peggy L. Peissig, Richard L. Berg,\n  Zhaobin Kuang, Scott J. Hebbring, Michael D. Caldwell, David Page", "title": "High-Throughput Machine Learning from Electronic Health Records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widespread digitization of patient data via electronic health records\n(EHRs) has created an unprecedented opportunity to use machine learning\nalgorithms to better predict disease risk at the patient level. Although\npredictive models have previously been constructed for a few important\ndiseases, such as breast cancer and myocardial infarction, we currently know\nvery little about how accurately the risk for most diseases or events can be\npredicted, and how far in advance. Machine learning algorithms use training\ndata rather than preprogrammed rules to make predictions and are well suited\nfor the complex task of disease prediction. Although there are thousands of\nconditions and illnesses patients can encounter, no prior research\nsimultaneously predicts risks for thousands of diagnosis codes and thereby\nestablishes a comprehensive patient risk profile. Here we show that such\npandiagnostic prediction is possible with a high level of performance across\ndiagnosis codes. For the tasks of predicting diagnosis risks both 1 and 6\nmonths in advance, we achieve average areas under the receiver operating\ncharacteristic curve (AUCs) of 0.803 and 0.758, respectively, across thousands\nof prediction tasks. Finally, our research contributes a new clinical\nprediction dataset in which researchers can explore how well a diagnosis can be\npredicted and what health factors are most useful for prediction. For the first\ntime, we can get a much more complete picture of how well risks for thousands\nof different diagnosis codes can be predicted.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 12:46:33 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Kleiman", "Ross S.", ""], ["Bennett", "Paul S.", ""], ["Peissig", "Peggy L.", ""], ["Berg", "Richard L.", ""], ["Kuang", "Zhaobin", ""], ["Hebbring", "Scott J.", ""], ["Caldwell", "Michael D.", ""], ["Page", "David", ""]]}, {"id": "1907.01913", "submitter": "Rahman Attar", "authors": "Rahman Attar, Marco Pereanez, Christopher Bowles, Stefan K. Piechnik,\n  Stefan Neubauer, Steffen E. Petersen, Alejandro F. Frangi", "title": "3D Cardiac Shape Prediction with Deep Neural Networks: Simultaneous Use\n  of Images and Patient Metadata", "comments": "Accepted for publication in MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large prospective epidemiological studies acquire cardiovascular magnetic\nresonance (CMR) images for pre-symptomatic populations and follow these over\ntime. To support this approach, fully automatic large-scale 3D analysis is\nessential. In this work, we propose a novel deep neural network using both CMR\nimages and patient metadata to directly predict cardiac shape parameters. The\nproposed method uses the promising ability of statistical shape models to\nsimplify shape complexity and variability together with the advantages of\nconvolutional neural networks for the extraction of solid visual features. To\nthe best of our knowledge, this is the first work that uses such an approach\nfor 3D cardiac shape prediction. We validated our proposed CMR analytics method\nagainst a reference cohort containing 500 3D shapes of the cardiac ventricles.\nOur results show broadly significant agreement with the reference shapes in\nterms of the estimated volume of the cardiac ventricles, myocardial mass, 3D\nDice, and mean and Hausdorff distance.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 12:29:20 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Attar", "Rahman", ""], ["Pereanez", "Marco", ""], ["Bowles", "Christopher", ""], ["Piechnik", "Stefan K.", ""], ["Neubauer", "Stefan", ""], ["Petersen", "Steffen E.", ""], ["Frangi", "Alejandro F.", ""]]}, {"id": "1907.01914", "submitter": "Dmytro Tkanov", "authors": "Ievgen Karaulov, Dmytro Tkanov", "title": "Attention model for articulatory features detection", "comments": "Interspeech 2019, 5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Articulatory distinctive features, as well as phonetic transcription, play\nimportant role in speech-related tasks: computer-assisted pronunciation\ntraining, text-to-speech conversion (TTS), studying speech production\nmechanisms, speech recognition for low-resourced languages. End-to-end\napproaches to speech-related tasks got a lot of traction in recent years. We\napply Listen, Attend and Spell~(LAS)~\\cite{Chan-LAS2016} architecture to phones\nrecognition on a small small training set, like TIMIT~\\cite{TIMIT-1992}. Also,\nwe introduce a novel decoding technique that allows to train manners and places\nof articulation detectors end-to-end using attention models. We also explore\njoint phones recognition and articulatory features detection in multitask\nlearning setting.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 10:30:27 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Karaulov", "Ievgen", ""], ["Tkanov", "Dmytro", ""]]}, {"id": "1907.01949", "submitter": "Shi Hu", "authors": "Shi Hu and Daniel Worrall and Stefan Knegt and Bas Veeling and Henkjan\n  Huisman and Max Welling", "title": "Supervised Uncertainty Quantification for Segmentation with Multiple\n  Annotations", "comments": "Accepted as a conference paper to MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accurate estimation of predictive uncertainty carries importance in\nmedical scenarios such as lung node segmentation. Unfortunately, most existing\nworks on predictive uncertainty do not return calibrated uncertainty estimates,\nwhich could be used in practice. In this work we exploit multi-grader\nannotation variability as a source of 'groundtruth' aleatoric uncertainty,\nwhich can be treated as a target in a supervised learning problem. We combine\nthis groundtruth uncertainty with a Probabilistic U-Net and test on the\nLIDC-IDRI lung nodule CT dataset and MICCAI2012 prostate MRI dataset. We find\nthat we are able to improve predictive uncertainty estimates. We also find that\nwe can improve sample accuracy and sample diversity.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 13:53:54 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Hu", "Shi", ""], ["Worrall", "Daniel", ""], ["Knegt", "Stefan", ""], ["Veeling", "Bas", ""], ["Huisman", "Henkjan", ""], ["Welling", "Max", ""]]}, {"id": "1907.01953", "submitter": "Armin Thomas", "authors": "Armin W. Thomas, Klaus-Robert M\\\"uller and Wojciech Samek", "title": "Deep Transfer Learning For Whole-Brain fMRI Analyses", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The application of deep learning (DL) models to the decoding of cognitive\nstates from whole-brain functional Magnetic Resonance Imaging (fMRI) data is\noften hindered by the small sample size and high dimensionality of these\ndatasets. Especially, in clinical settings, where patient data are scarce. In\nthis work, we demonstrate that transfer learning represents a solution to this\nproblem. Particularly, we show that a DL model, which has been previously\ntrained on a large openly available fMRI dataset of the Human Connectome\nProject, outperforms a model variant with the same architecture, but which is\ntrained from scratch, when both are applied to the data of a new, unrelated\nfMRI task. Even further, the pre-trained DL model variant is already able to\ncorrectly decode 67.51% of the cognitive states from a test dataset with 100\nindividuals, when fine-tuned on a dataset of the size of only three subjects.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 10:03:54 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Thomas", "Armin W.", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1907.01959", "submitter": "Saeid Soheily Khah", "authors": "Saeid Soheily Khah, Yiming Wu", "title": "An Enhanced Ad Event-Prediction Method Based on Feature Engineering", "comments": "8th International Conference on Soft Computing, Artificial\n  Intelligence and Applications (SAI 2019), June 29-30, 2019, Copenhagen,\n  Denmark", "journal-ref": "AIRCC Publishing Corporation, 8th International Conference on Soft\n  Computing, Artificial Intelligence and Applications (SAI 2019), Volume\n  Editors: Natarajan Meghanathan and David wyld(Eds), ISBN: 978-1-925953-03-9", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In digital advertising, Click-Through Rate (CTR) and Conversion Rate (CVR)\nare very important metrics for evaluating ad performance. As a result, ad event\nprediction systems are vital and widely used for sponsored search and display\nadvertising as well as Real-Time Bidding (RTB). In this work, we introduce an\nenhanced method for ad event prediction (i.e. clicks, conversions) by proposing\na new efficient feature engineering approach. A large real-world event-based\ndataset of a running marketing campaign is used to evaluate the efficiency of\nthe proposed prediction algorithm. The results illustrate the benefits of the\nproposed ad event prediction approach, which significantly outperforms the\nalternative ones.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 14:16:10 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Khah", "Saeid Soheily", ""], ["Wu", "Yiming", ""]]}, {"id": "1907.01974", "submitter": "Jonathan Johannemann", "authors": "Jonathan Johannemann, Robert Tibshirani", "title": "Spectral Overlap and a Comparison of Parameter-Free, Dimensionality\n  Reduction Quality Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nonlinear dimensionality reduction methods are a popular tool for data\nscientists and researchers to visualize complex, high dimensional data.\nHowever, while these methods continue to improve and grow in number, it is\noften difficult to evaluate the quality of a visualization due to a variety of\nfactors such as lack of information about the intrinsic dimension of the data\nand additional tuning required for many evaluation metrics. In this paper, we\nseek to provide a systematic comparison of dimensionality reduction quality\nmetrics using datasets where we know the ground truth manifold. We utilize each\nmetric for hyperparameter optimization in popular dimensionality reduction\nmethods used for visualization and provide quantitative metrics to objectively\ncompare visualizations to their original manifold. In our results, we find a\nfew methods that appear to consistently do well and propose the best performer\nas a benchmark for evaluating dimensionality reduction based visualizations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 14:53:21 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 06:37:50 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Johannemann", "Jonathan", ""], ["Tibshirani", "Robert", ""]]}, {"id": "1907.01989", "submitter": "Juhyun Lee", "authors": "Juhyun Lee, Nikolay Chirkov, Ekaterina Ignasheva, Yury Pisarchyk,\n  Mogan Shieh, Fabio Riccardi, Raman Sarokin, Andrei Kulik, and Matthias\n  Grundmann", "title": "On-Device Neural Net Inference with Mobile GPUs", "comments": "Computer Vision and Pattern Recognition Workshop: Efficient Deep\n  Learning for Computer Vision 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-device inference of machine learning models for mobile phones is desirable\ndue to its lower latency and increased privacy. Running such a\ncompute-intensive task solely on the mobile CPU, however, can be difficult due\nto limited computing power, thermal constraints, and energy consumption. App\ndevelopers and researchers have begun exploiting hardware accelerators to\novercome these challenges. Recently, device manufacturers are adding neural\nprocessing units into high-end phones for on-device inference, but these\naccount for only a small fraction of hand-held devices. In this paper, we\npresent how we leverage the mobile GPU, a ubiquitous hardware accelerator on\nvirtually every phone, to run inference of deep neural networks in real-time\nfor both Android and iOS devices. By describing our architecture, we also\ndiscuss how to design networks that are mobile GPU-friendly. Our\nstate-of-the-art mobile GPU inference engine is integrated into the open-source\nproject TensorFlow Lite and publicly available at https://tensorflow.org/lite.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:23:20 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Lee", "Juhyun", ""], ["Chirkov", "Nikolay", ""], ["Ignasheva", "Ekaterina", ""], ["Pisarchyk", "Yury", ""], ["Shieh", "Mogan", ""], ["Riccardi", "Fabio", ""], ["Sarokin", "Raman", ""], ["Kulik", "Andrei", ""], ["Grundmann", "Matthias", ""]]}, {"id": "1907.01991", "submitter": "Alan Mishchenko", "authors": "Satrajit Chatterjee, Alan Mishchenko", "title": "Circuit-Based Intrinsic Methods to Detect Overfitting", "comments": "37th International Conference on Machine Learning held as a virtual\n  conference on July 12-18, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of this paper is on intrinsic methods to detect overfitting. By\nintrinsic methods, we mean methods that rely only on the model and the training\ndata, as opposed to traditional methods (we call them extrinsic methods) that\nrely on performance on a test set or on bounds from model complexity. We\npropose a family of intrinsic methods, called Counterfactual Simulation (CFS),\nwhich analyze the flow of training examples through the model by identifying\nand perturbing rare patterns. By applying CFS to logic circuits we get a method\nthat has no hyper-parameters and works uniformly across different types of\nmodels such as neural networks, random forests and lookup tables.\nExperimentally, CFS can separate models with different levels of overfit using\nonly their logic circuit representations without any access to the high level\nstructure. By comparing lookup tables, neural networks, and random forests\nusing CFS, we get insight into why neural networks generalize. In particular,\nwe find that stochastic gradient descent in neural nets does not lead to \"brute\nforce\" memorization, but finds common patterns (whether we train with actual or\nrandomized labels), and neural networks are not unlike forests in this regard.\nFinally, we identify a limitation with our proposal that makes it unsuitable in\nan adversarial setting, but points the way to future work on robust intrinsic\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:32:35 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 23:35:09 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Chatterjee", "Satrajit", ""], ["Mishchenko", "Alan", ""]]}, {"id": "1907.01992", "submitter": "Andreas Maier", "authors": "Andreas K. Maier, Christopher Syben, Bernhard Stimpel, Tobias W\\\"urfl,\n  Mathis Hoffmann, Frank Schebesch, Weilin Fu, Leonid Mill, Lasse Kling, and\n  Silke Christiansen", "title": "Learning with Known Operators reduces Maximum Training Error Bounds", "comments": "Paper conditionally accepted in Nature Machine Intelligence", "journal-ref": "Nature Machine Intelligence 1, 373-380, 2019", "doi": "10.1038/s42256-019-0077-5", "report-no": null, "categories": "cs.LG cs.CV physics.med-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe an approach for incorporating prior knowledge into machine\nlearning algorithms. We aim at applications in physics and signal processing in\nwhich we know that certain operations must be embedded into the algorithm. Any\noperation that allows computation of a gradient or sub-gradient towards its\ninputs is suited for our framework. We derive a maximal error bound for deep\nnets that demonstrates that inclusion of prior knowledge results in its\nreduction. Furthermore, we also show experimentally that known operators reduce\nthe number of free parameters. We apply this approach to various tasks ranging\nfrom CT image reconstruction over vessel segmentation to the derivation of\npreviously unknown imaging algorithms. As such the concept is widely applicable\nfor many researchers in physics, imaging, and signal processing. We assume that\nour analysis will support further investigation of known operators in other\nfields of physics, imaging, and signal processing.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:35:16 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Maier", "Andreas K.", ""], ["Syben", "Christopher", ""], ["Stimpel", "Bernhard", ""], ["W\u00fcrfl", "Tobias", ""], ["Hoffmann", "Mathis", ""], ["Schebesch", "Frank", ""], ["Fu", "Weilin", ""], ["Mill", "Leonid", ""], ["Kling", "Lasse", ""], ["Christiansen", "Silke", ""]]}, {"id": "1907.01995", "submitter": "Mingxi Zhu", "authors": "Mingxi Zhu, Kresimir Mihic, Yinyu Ye", "title": "On a Randomized Multi-Block ADMM for Solving Selected Machine Learning\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Alternating Direction Method of Multipliers (ADMM) has now days gained\ntremendous attentions for solving large-scale machine learning and signal\nprocessing problems due to the relative simplicity. However, the two-block\nstructure of the classical ADMM still limits the size of the real problems\nbeing solved. When one forces a more-than-two-block structure by\nvariable-splitting, the convergence speed slows down greatly as observed in\npractice. Recently, a randomly assembled cyclic multi-block ADMM (RAC-MBADMM)\nwas developed by the authors for solving general convex and nonconvex quadratic\noptimization problems where the number of blocks can go greater than two so\nthat each sub-problem has a smaller size and can be solved much more\nefficiently. In this paper, we apply this method to solving few selected\nmachine learning problems related to convex quadratic optimization, such as\nLinear Regression, LASSO, Elastic-Net, and SVM. We prove that the algorithm\nwould converge in expectation linearly under the standard statistical data\nassumptions. We use our general-purpose solver to conduct multiple numerical\ntests, solving both synthetic and large-scale bench-mark problems. Our results\nshow that RAC-MBADMM could significantly outperform, in both solution time and\nquality, other optimization algorithms/codes for solving these machine learning\nproblems, and match up the performance of the best tailored methods such as\nGlmnet or LIBSVM. In certain problem regions RAC-MBADMM even achieves a\nsuperior performance than that of the tailored methods.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:38:01 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 07:52:02 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Zhu", "Mingxi", ""], ["Mihic", "Kresimir", ""], ["Ye", "Yinyu", ""]]}, {"id": "1907.02015", "submitter": "Jonas Fassbender", "authors": "Jonas Fassbender", "title": "libconform v0.1.0: a Python library for conformal prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces libconform v0.1.0, a Python library for the conformal\nprediction framework, licensed under the MIT-license. libconform is not yet\nstable. This paper describes the main algorithms implemented and documents the\nAPI of libconform. Also some details about the implementation and changes in\nfuture versions are described.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 16:24:10 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Fassbender", "Jonas", ""]]}, {"id": "1907.02044", "submitter": "Francesco Croce", "authors": "Francesco Croce, Matthias Hein", "title": "Minimally distorted Adversarial Examples with a Fast Adaptive Boundary\n  Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of robustness against adversarial manipulation of neural\nnetworks-based classifiers is mainly tested with empirical attacks as methods\nfor the exact computation, even when available, do not scale to large networks.\nWe propose in this paper a new white-box adversarial attack wrt the $l_p$-norms\nfor $p \\in \\{1,2,\\infty\\}$ aiming at finding the minimal perturbation necessary\nto change the class of a given input. It has an intuitive geometric meaning,\nyields quickly high quality results, minimizes the size of the perturbation (so\nthat it returns the robust accuracy at every threshold with a single run). It\nperforms better or similar to state-of-the-art attacks which are partially\nspecialized to one $l_p$-norm, and is robust to the phenomenon of gradient\nmasking.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 17:22:05 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 15:18:47 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Croce", "Francesco", ""], ["Hein", "Matthias", ""]]}, {"id": "1907.02051", "submitter": "Arman Hasanzadeh Moghimi", "authors": "Arman Hasanzadeh, Nagaraj T. Janakiraman, Vamsi K. Amalladinne,\n  Krishna R. Narayanan", "title": "Spatially-Coupled Neural Network Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we leverage advances in sparse coding techniques to reduce the\nnumber of trainable parameters in a fully connected neural network. While most\nof the works in literature impose $\\ell_1$ regularization, DropOut or\nDropConnect techniques to induce sparsity, our scheme considers feature\nimportance as a criterion to allocate the trainable parameters (resources)\nefficiently in the network. Even though sparsity is ensured, $\\ell_1$\nregularization requires training on all the resources in a deep neural network.\nThe DropOut/DropConnect techniques reduce the number of trainable parameters in\nthe training stage by dropping a random collection of neurons/edges in the\nhidden layers. However, both these techniques do not pay heed to the underlying\nstructure in the data when dropping the neurons/edges. Moreover, these\nframeworks require a storage space equivalent to the number of parameters in a\nfully connected neural network. We address the above issues with a more\nstructured architecture inspired from spatially-coupled sparse constructions.\nThe proposed architecture is shown to have a performance akin to a conventional\nfully connected neural network with dropouts, and yet achieving a $94\\%$\nreduction in the training parameters. Extensive simulations are presented and\nthe performance of the proposed scheme is compared against traditional neural\nnetwork architectures.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 17:37:35 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Hasanzadeh", "Arman", ""], ["Janakiraman", "Nagaraj T.", ""], ["Amalladinne", "Vamsi K.", ""], ["Narayanan", "Krishna R.", ""]]}, {"id": "1907.02052", "submitter": "Jieh-Sheng Lee", "authors": "Jieh-Sheng Lee and Jieh Hsiang", "title": "Patent Claim Generation by Fine-Tuning OpenAI GPT-2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we focus on fine-tuning an OpenAI GPT-2 pre-trained model for\ngenerating patent claims. GPT-2 has demonstrated impressive efficacy of\npre-trained language models on various tasks, particularly coherent text\ngeneration. Patent claim language itself has rarely been explored in the past\nand poses a unique challenge. We are motivated to generate coherent patent\nclaims automatically so that augmented inventing might be viable someday. In\nour implementation, we identified a unique language structure in patent claims\nand leveraged its implicit human annotations. We investigated the fine-tuning\nprocess by probing the first 100 steps and observing the generated text at each\nstep. Based on both conditional and unconditional random sampling, we analyze\nthe overall quality of generated patent claims. Our contributions include: (1)\nbeing the first to generate patent claims by machines and being the first to\napply GPT-2 to patent claim generation, (2) providing various experiment\nresults for qualitative analysis and future research, (3) proposing a new\nsampling approach for text generation, and (4) building an e-mail bot for\nfuture researchers to explore the fine-tuned GPT-2 model further.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 00:02:59 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Lee", "Jieh-Sheng", ""], ["Hsiang", "Jieh", ""]]}, {"id": "1907.02057", "submitter": "Tingwu Wang", "authors": "Tingwu Wang, Xuchan Bao, Ignasi Clavera, Jerrick Hoang, Yeming Wen,\n  Eric Langlois, Shunshi Zhang, Guodong Zhang, Pieter Abbeel, Jimmy Ba", "title": "Benchmarking Model-Based Reinforcement Learning", "comments": "8 main pages, 8 figures; 14 appendix pages, 25 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Model-based reinforcement learning (MBRL) is widely seen as having the\npotential to be significantly more sample efficient than model-free RL.\nHowever, research in model-based RL has not been very standardized. It is\nfairly common for authors to experiment with self-designed environments, and\nthere are several separate lines of research, which are sometimes\nclosed-sourced or not reproducible. Accordingly, it is an open question how\nthese various existing MBRL algorithms perform relative to each other. To\nfacilitate research in MBRL, in this paper we gather a wide collection of MBRL\nalgorithms and propose over 18 benchmarking environments specially designed for\nMBRL. We benchmark these algorithms with unified problem settings, including\nnoisy environments. Beyond cataloguing performance, we explore and unify the\nunderlying algorithmic differences across MBRL algorithms. We characterize\nthree key research challenges for future MBRL research: the dynamics\nbottleneck, the planning horizon dilemma, and the early-termination dilemma.\nFinally, to maximally facilitate future research on MBRL, we open-source our\nbenchmark in http://www.cs.toronto.edu/~tingwuwang/mbrl.html.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 17:53:02 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Wang", "Tingwu", ""], ["Bao", "Xuchan", ""], ["Clavera", "Ignasi", ""], ["Hoang", "Jerrick", ""], ["Wen", "Yeming", ""], ["Langlois", "Eric", ""], ["Zhang", "Shunshi", ""], ["Zhang", "Guodong", ""], ["Abbeel", "Pieter", ""], ["Ba", "Jimmy", ""]]}, {"id": "1907.02088", "submitter": "Sambit Panda", "authors": "Sambit Panda, Satish Palaniappan, Junhao Xiong, Eric W. Bridgeford,\n  Ronak Mehta, Cencheng Shen, Joshua T. Vogelstein", "title": "hyppo: A Multivariate Hypothesis Testing Python Package", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.MS stat.ME stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce hyppo, a unified library for performing multivariate hypothesis\ntesting, including independence, two-sample, and k-sample testing. While many\nmultivariate independence tests have R packages available, the interfaces are\ninconsistent and most are not available in Python. hyppo includes many state of\nthe art multivariate testing procedures. The package is easy-to-use and is\nflexible enough to enable future extensions. The documentation and all releases\nare available at https://hyppo.neurodata.io.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 18:05:25 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 19:20:43 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 18:29:49 GMT"}, {"version": "v4", "created": "Thu, 9 Apr 2020 15:21:36 GMT"}, {"version": "v5", "created": "Thu, 20 Aug 2020 12:28:44 GMT"}, {"version": "v6", "created": "Thu, 1 Apr 2021 15:13:13 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Panda", "Sambit", ""], ["Palaniappan", "Satish", ""], ["Xiong", "Junhao", ""], ["Bridgeford", "Eric W.", ""], ["Mehta", "Ronak", ""], ["Shen", "Cencheng", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1907.02109", "submitter": "Ryan Cory-Wright", "authors": "Dimitris Bertsimas, Ryan Cory-Wright, Jean Pauphilet", "title": "A unified approach to mixed-integer optimization problems with logical\n  constraints", "comments": "Revised version (including title change). The old title was \"A\n  unified approach to mixed-integer optimization: Nonlinear formulations and\n  scalable algorithms\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified framework to address a family of classical mixed-integer\noptimization problems with logically constrained decision variables, including\nnetwork design, facility location, unit commitment, sparse portfolio selection,\nbinary quadratic optimization, sparse principal analysis and sparse learning\nproblems. These problems exhibit logical relationships between continuous and\ndiscrete variables, which are usually reformulated linearly using a big-M\nformulation. In this work, we challenge this longstanding modeling practice and\nexpress the logical constraints in a non-linear way. By imposing a\nregularization condition, we reformulate these problems as convex binary\noptimization problems, which are solvable using an outer-approximation\nprocedure. In numerical experiments, we establish that a general-purpose\nnumerical strategy, which combines cutting-plane, first-order and local search\nmethods, solves these problems faster and at a larger scale than\nstate-of-the-art mixed-integer linear or second-order cone methods. Our\napproach successfully solves network design problems with 100s of nodes and\nprovides solutions up to 40\\% better than the state-of-the-art; sparse\nportfolio selection problems with up to 3,200 securities compared with 400\nsecurities for previous attempts; and sparse regression problems with up to\n100,000 covariates.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 19:02:28 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 03:42:06 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 15:23:12 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Cory-Wright", "Ryan", ""], ["Pauphilet", "Jean", ""]]}, {"id": "1907.02110", "submitter": "Jimit Doshi", "authors": "Jimit Doshi, Guray Erus, Mohamad Habes, Christos Davatzikos", "title": "DeepMRSeg: A convolutional deep neural network for anatomy and\n  abnormality segmentation on MR images", "comments": "18 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation has been a major task in neuroimaging. A large number of\nautomated methods have been developed for segmenting healthy and diseased brain\ntissues. In recent years, deep learning techniques have attracted a lot of\nattention as a result of their high accuracy in different segmentation\nproblems. We present a new deep learning based segmentation method, DeepMRSeg,\nthat can be applied in a generic way to a variety of segmentation tasks. The\nproposed architecture combines recent advances in the field of biomedical image\nsegmentation and computer vision. We use a modified UNet architecture that\ntakes advantage of multiple convolution filter sizes to achieve multi-scale\nfeature extraction adaptive to the desired segmentation task. Importantly, our\nmethod operates on minimally processed raw MRI scan. We validated our method on\na wide range of segmentation tasks, including white matter lesion segmentation,\nsegmentation of deep brain structures and hippocampus segmentation. We provide\ncode and pre-trained models to allow researchers apply our method on their own\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 19:10:37 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Doshi", "Jimit", ""], ["Erus", "Guray", ""], ["Habes", "Mohamad", ""], ["Davatzikos", "Christos", ""]]}, {"id": "1907.02114", "submitter": "Falcon Dai", "authors": "Falcon Z. Dai, Matthew R. Walter", "title": "Maximum Expected Hitting Cost of a Markov Decision Process and\n  Informativeness of Rewards", "comments": "Minor post-review revision. Main paper with appendix. To appear at\n  NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new complexity measure for Markov decision processes (MDPs), the\nmaximum expected hitting cost (MEHC). This measure tightens the closely related\nnotion of diameter [JOA10] by accounting for the reward structure. We show that\nthis parameter replaces diameter in the upper bound on the optimal value span\nof an extended MDP, thus refining the associated upper bounds on the regret of\nseveral UCRL2-like algorithms. Furthermore, we show that potential-based reward\nshaping [NHR99] can induce equivalent reward functions with varying\ninformativeness, as measured by MEHC. We further establish that shaping can\nreduce or increase MEHC by at most a factor of two in a large class of MDPs\nwith finite MEHC and unsaturated optimal average rewards.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 19:41:04 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 19:47:40 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Dai", "Falcon Z.", ""], ["Walter", "Matthew R.", ""]]}, {"id": "1907.02124", "submitter": "Xiaolong Ma", "authors": "Xiaolong Ma, Sheng Lin, Shaokai Ye, Zhezhi He, Linfeng Zhang, Geng\n  Yuan, Sia Huat Tan, Zhengang Li, Deliang Fan, Xuehai Qian, Xue Lin, Kaisheng\n  Ma, Yanzhi Wang", "title": "Non-Structured DNN Weight Pruning -- Is It Beneficial in Any Platform?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large deep neural network (DNN) models pose the key challenge to energy\nefficiency due to the significantly higher energy consumption of off-chip DRAM\naccesses than arithmetic or SRAM operations. It motivates the intensive\nresearch on model compression with two main approaches. Weight pruning\nleverages the redundancy in the number of weights and can be performed in a\nnon-structured, which has higher flexibility and pruning rate but incurs index\naccesses due to irregular weights, or structured manner, which preserves the\nfull matrix structure with lower pruning rate. Weight quantization leverages\nthe redundancy in the number of bits in weights. Compared to pruning,\nquantization is much more hardware-friendly, and has become a \"must-do\" step\nfor FPGA and ASIC implementations. This paper provides a definitive answer to\nthe question for the first time. First, we build ADMM-NN-S by extending and\nenhancing ADMM-NN, a recently proposed joint weight pruning and quantization\nframework. Second, we develop a methodology for fair and fundamental comparison\nof non-structured and structured pruning in terms of both storage and\ncomputation efficiency. Our results show that ADMM-NN-S consistently\noutperforms the prior art: (i) it achieves 348x, 36x, and 8x overall weight\npruning on LeNet-5, AlexNet, and ResNet-50, respectively, with (almost) zero\naccuracy loss; (ii) we demonstrate the first fully binarized (for all layers)\nDNNs can be lossless in accuracy in many cases. These results provide a strong\nbaseline and credibility of our study. Based on the proposed comparison\nframework, with the same accuracy and quantization, the results show that\nnon-structrued pruning is not competitive in terms of both storage and\ncomputation efficiency. Thus, we conclude that non-structured pruning is\nconsidered harmful. We urge the community not to continue the DNN inference\nacceleration for non-structured sparsity.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 20:27:51 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 19:43:16 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Ma", "Xiaolong", ""], ["Lin", "Sheng", ""], ["Ye", "Shaokai", ""], ["He", "Zhezhi", ""], ["Zhang", "Linfeng", ""], ["Yuan", "Geng", ""], ["Tan", "Sia Huat", ""], ["Li", "Zhengang", ""], ["Fan", "Deliang", ""], ["Qian", "Xuehai", ""], ["Lin", "Xue", ""], ["Ma", "Kaisheng", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1907.02140", "submitter": "Tadahiro Taniguchi", "authors": "Akira Kinose and Tadahiro Taniguchi", "title": "Integration of Imitation Learning using GAIL and Reinforcement Learning\n  using Task-achievement Rewards via Probabilistic Graphical Model", "comments": "Submitted to Advanced Robotics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integration of reinforcement learning and imitation learning is an important\nproblem that has been studied for a long time in the field of intelligent\nrobotics. Reinforcement learning optimizes policies to maximize the cumulative\nreward, whereas imitation learning attempts to extract general knowledge about\nthe trajectories demonstrated by experts, i.e., demonstrators. Because each of\nthem has their own drawbacks, methods combining them and compensating for each\nset of drawbacks have been explored thus far. However, many of the methods are\nheuristic and do not have a solid theoretical basis. In this paper, we present\na new theory for integrating reinforcement and imitation learning by extending\nthe probabilistic generative model framework for reinforcement learning, {\\it\nplan by inference}. We develop a new probabilistic graphical model for\nreinforcement learning with multiple types of rewards and a probabilistic\ngraphical model for Markov decision processes with multiple optimality\nemissions (pMDP-MO). Furthermore, we demonstrate that the integrated learning\nmethod of reinforcement learning and imitation learning can be formulated as a\nprobabilistic inference of policies on pMDP-MO by considering the output of the\ndiscriminator in generative adversarial imitation learning as an additional\noptimal emission observation. We adapt the generative adversarial imitation\nlearning and task-achievement reward to our proposed framework, achieving\nsignificantly better performance than agents trained with reinforcement\nlearning or imitation learning alone. Experiments demonstrate that our\nframework successfully integrates imitation and reinforcement learning even\nwhen the number of demonstrators is only a few.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 21:38:48 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 08:24:58 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Kinose", "Akira", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "1907.02159", "submitter": "Jacob Imola", "authors": "Kamalika Chaudhuri, Jacob Imola, Ashwin Machanavajjhala", "title": "Capacity Bounded Differential Privacy", "comments": "10 pages, 2 figures, Neurips 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy, a notion of algorithmic stability, is a gold standard\nfor measuring the additional risk an algorithm's output poses to the privacy of\na single record in the dataset. Differential privacy is defined as the distance\nbetween the output distribution of an algorithm on neighboring datasets that\ndiffer in one entry. In this work, we present a novel relaxation of\ndifferential privacy, capacity bounded differential privacy, where the\nadversary that distinguishes output distributions is assumed to be\ncapacity-bounded -- i.e. bounded not in computational power, but in terms of\nthe function class from which their attack algorithm is drawn. We model\nadversaries in terms of restricted f-divergences between probability\ndistributions, and study properties of the definition and algorithms that\nsatisfy them.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 23:07:34 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Chaudhuri", "Kamalika", ""], ["Imola", "Jacob", ""], ["Machanavajjhala", "Ashwin", ""]]}, {"id": "1907.02163", "submitter": "Robert Bamler", "authors": "Robert Bamler and Stephan Mandt", "title": "A Quantum Field Theory of Representation Learning", "comments": "Presented at the ICML 2019 Workshop on Theoretical Physics for Deep\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous symmetries and their breaking play a prominent role in\ncontemporary physics. Effective low-energy field theories around symmetry\nbreaking states explain diverse phenomena such as superconductivity, magnetism,\nand the mass of nucleons. We show that such field theories can also be a useful\ntool in machine learning, in particular for loss functions with continuous\nsymmetries that are spontaneously broken by random initializations. In this\npaper, we illuminate our earlier published work (Bamler & Mandt, 2018) on this\ntopic more from the perspective of theoretical physics. We show that the\nanalogies between superconductivity and symmetry breaking in temporal\nrepresentation learning are rather deep, allowing us to formulate a gauge\ntheory of `charged' embedding vectors in time series models. We show that\nmaking the loss function gauge invariant speeds up convergence in such models.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 00:01:34 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Bamler", "Robert", ""], ["Mandt", "Stephan", ""]]}, {"id": "1907.02177", "submitter": "Masaaki Imaizumi", "authors": "Ryumei Nakada, Masaaki Imaizumi", "title": "Adaptive Approximation and Generalization of Deep Neural Network with\n  Intrinsic Dimensionality", "comments": "38 pages", "journal-ref": "Journal of Machine Learning Research, 21(174), 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we prove that an intrinsic low dimensionality of covariates is\nthe main factor that determines the performance of deep neural networks (DNNs).\nDNNs generally provide outstanding empirical performance. Hence, numerous\nstudies have actively investigated the theoretical properties of DNNs to\nunderstand their underlying mechanisms. In particular, the behavior of DNNs in\nterms of high-dimensional data is one of the most critical questions. However,\nthis issue has not been sufficiently investigated from the aspect of\ncovariates, although high-dimensional data have practically low intrinsic\ndimensionality. In this study, we derive bounds for an approximation error and\na generalization error regarding DNNs with intrinsically low dimensional\ncovariates. We apply the notion of the Minkowski dimension and develop a novel\nproof technique. Consequently, we show that convergence rates of the errors by\nDNNs do not depend on the nominal high dimensionality of data, but on its lower\nintrinsic dimension. We further prove that the rate is optimal in the minimax\nsense. We identify an advantage of DNNs by showing that DNNs can handle a\nbroader class of intrinsic low dimensional data than other adaptive estimators.\nFinally, we conduct a numerical simulation to validate the theoretical results.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 01:10:58 GMT"}, {"version": "v2", "created": "Sat, 2 Nov 2019 02:58:45 GMT"}, {"version": "v3", "created": "Thu, 17 Sep 2020 16:09:04 GMT"}], "update_date": "2020-09-18", "authors_parsed": [["Nakada", "Ryumei", ""], ["Imaizumi", "Masaaki", ""]]}, {"id": "1907.02178", "submitter": "Harikesh Nair", "authors": "Tong Geng, Xiliang Lin, Harikesh S. Nair", "title": "Online Evaluation of Audiences for Targeted Advertising via Bandit\n  Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Firms implementing digital advertising campaigns face a complex problem in\ndetermining the right match between their advertising creatives and target\naudiences. Typical solutions to the problem have leveraged non-experimental\nmethods, or used \"split-testing\" strategies that have not explicitly addressed\nthe complexities induced by targeted audiences that can potentially overlap\nwith one another. This paper presents an adaptive algorithm that addresses the\nproblem via online experimentation. The algorithm is set up as a contextual\nbandit and addresses the overlap issue by partitioning the target audiences\ninto disjoint, non-overlapping sub-populations. It learns an optimal creative\ndisplay policy in the disjoint space, while assessing in parallel which\ncreative has the best match in the space of possibly overlapping target\naudiences. Experiments show that the proposed method is more efficient compared\nto naive \"split-testing\" or non-adaptive \"A/B/n\" testing based methods. We also\ndescribe a testing product we built that uses the algorithm. The product is\ncurrently deployed on the advertising platform of JD.com, an eCommerce company\nand a publisher of digital ads in China.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 01:14:46 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 20:43:21 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 23:52:25 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Geng", "Tong", ""], ["Lin", "Xiliang", ""], ["Nair", "Harikesh S.", ""]]}, {"id": "1907.02188", "submitter": "Brosnan Yuen", "authors": "Brosnan Yuen", "title": "Classifying Multi-Gas Spectrums using Monte Carlo KNN and\n  Multi-Resolution CNN", "comments": "It was submitted without proper permission granted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A Monte Carlo k-nearest neighbours (KNN) and a multi-resolution convolutional\nneural network (CNN) were developed to detect the presences of multiple gasses\nin near infrared (IR) spectrums. High Resolution Transmission database was used\nto synthesize the near IR spectrums. Monte Carlo KNN determined the optimal\nkernel sizes and the optimal number of channels. The multi-resolution CNN,\ncomposed of multiple different kernels, was created using the optimal kernel\nsizes and the optimal number of channels. The multi-resolution CNN outperforms\nthe multilayer perceptron and the partial least squares.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 01:59:28 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 01:19:25 GMT"}, {"version": "v3", "created": "Sun, 13 Oct 2019 04:52:37 GMT"}, {"version": "v4", "created": "Mon, 23 Mar 2020 22:26:05 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Yuen", "Brosnan", ""]]}, {"id": "1907.02189", "submitter": "Xiang Li", "authors": "Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, Zhihua Zhang", "title": "On the Convergence of FedAvg on Non-IID Data", "comments": "2020 International Conference on Learning Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables a large amount of edge computing devices to\njointly learn a model without data sharing. As a leading algorithm in this\nsetting, Federated Averaging (\\texttt{FedAvg}) runs Stochastic Gradient Descent\n(SGD) in parallel on a small subset of the total devices and averages the\nsequences only once in a while. Despite its simplicity, it lacks theoretical\nguarantees under realistic settings. In this paper, we analyze the convergence\nof \\texttt{FedAvg} on non-iid data and establish a convergence rate of\n$\\mathcal{O}(\\frac{1}{T})$ for strongly convex and smooth problems, where $T$\nis the number of SGDs. Importantly, our bound demonstrates a trade-off between\ncommunication-efficiency and convergence rate. As user devices may be\ndisconnected from the server, we relax the assumption of full device\nparticipation to partial device participation and study different averaging\nschemes; low device participation rate can be achieved without severely slowing\ndown the learning. Our results indicate that heterogeneity of data slows down\nthe convergence, which matches empirical observations. Furthermore, we provide\na necessary condition for \\texttt{FedAvg} on non-iid data: the learning rate\n$\\eta$ must decay, even if full-gradient is used; otherwise, the solution will\nbe $\\Omega (\\eta)$ away from the optimal.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 02:04:56 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 15:07:31 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 10:17:45 GMT"}, {"version": "v4", "created": "Thu, 25 Jun 2020 06:45:52 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Li", "Xiang", ""], ["Huang", "Kaixuan", ""], ["Yang", "Wenhao", ""], ["Wang", "Shusen", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1907.02204", "submitter": "Shuo Zhang", "authors": "Shuo Zhang, Lei Xie", "title": "Improving Attention Mechanism in Graph Neural Networks via Cardinality\n  Preservation", "comments": "The short version of this paper has been accepted by IJCAI 2020", "journal-ref": null, "doi": "10.24963/ijcai.2020/194", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) are powerful to learn the representation of\ngraph-structured data. Most of the GNNs use the message-passing scheme, where\nthe embedding of a node is iteratively updated by aggregating the information\nof its neighbors. To achieve a better expressive capability of node influences,\nattention mechanism has grown to be popular to assign trainable weights to the\nnodes in aggregation. Though the attention-based GNNs have achieved remarkable\nresults in various tasks, a clear understanding of their discriminative\ncapacities is missing. In this work, we present a theoretical analysis of the\nrepresentational properties of the GNN that adopts the attention mechanism as\nan aggregator. Our analysis determines all cases when those attention-based\nGNNs can always fail to distinguish certain distinct structures. Those cases\nappear due to the ignorance of cardinality information in attention-based\naggregation. To improve the performance of attention-based GNNs, we propose\ncardinality preserved attention (CPA) models that can be applied to any kind of\nattention mechanisms. Our experiments on node and graph classification confirm\nour theoretical analysis and show the competitive performance of our CPA\nmodels.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 03:48:22 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 12:49:07 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 05:00:38 GMT"}, {"version": "v4", "created": "Mon, 4 May 2020 00:18:01 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Zhang", "Shuo", ""], ["Xie", "Lei", ""]]}, {"id": "1907.02220", "submitter": "Soheil Kolouri", "authors": "Soheil Kolouri, Xuwang Yin, Gustavo K. Rohde", "title": "Neural Networks, Hypersurfaces, and Radon Transforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connections between integration along hypersufaces, Radon transforms, and\nneural networks are exploited to highlight an integral geometric mathematical\ninterpretation of neural networks. By analyzing the properties of neural\nnetworks as operators on probability distributions for observed data, we show\nthat the distribution of outputs for any node in a neural network can be\ninterpreted as a nonlinear projection along hypersurfaces defined by level\nsurfaces over the input data space. We utilize these descriptions to provide\nnew interpretation for phenomena such as nonlinearity, pooling, activation\nfunctions, and adversarial examples in neural network-based learning problems.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 05:01:14 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Kolouri", "Soheil", ""], ["Yin", "Xuwang", ""], ["Rohde", "Gustavo K.", ""]]}, {"id": "1907.02226", "submitter": "Byung Cheol Song", "authors": "Seunghyun Lee and Byung Cheol Song", "title": "Graph-based Knowledge Distillation by Multi-head Attention Network", "comments": "Accepted to BMVC 2019 as an oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) is a technique to derive optimal performance from\na small student network (SN) by distilling knowledge of a large teacher network\n(TN) and transferring the distilled knowledge to the small SN. Since a role of\nconvolutional neural network (CNN) in KD is to embed a dataset so as to perform\na given task well, it is very important to acquire knowledge that considers\nintra-data relations. Conventional KD methods have concentrated on distilling\nknowledge in data units. To our knowledge, any KD methods for distilling\ninformation in dataset units have not yet been proposed. Therefore, this paper\nproposes a novel method that enables distillation of dataset-based knowledge\nfrom the TN using an attention network. The knowledge of the embedding\nprocedure of the TN is distilled to graph by multi-head attention (MHA), and\nmulti-task learning is performed to give relational inductive bias to the SN.\nThe MHA can provide clear information about the source dataset, which can\ngreatly improves the performance of the SN. Experimental results show that the\nproposed method is 7.05% higher than the SN alone for CIFAR100, which is 2.46%\nhigher than the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 05:29:08 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 02:46:35 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Lee", "Seunghyun", ""], ["Song", "Byung Cheol", ""]]}, {"id": "1907.02237", "submitter": "Xu Zou", "authors": "Xu Zou, Qiuye Jia, Jianwei Zhang, Chang Zhou, Hongxia Yang, Jie Tang", "title": "Dimensional Reweighting Graph Convolutional Networks", "comments": "We decide to drastically modify the article so we don't wish to let\n  this outdated version continue to confuse readers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolution Networks (GCNs) are becoming more and more popular for\nlearning node representations on graphs. Though there exist various\ndevelopments on sampling and aggregation to accelerate the training process and\nimprove the performances, limited works focus on dealing with the dimensional\ninformation imbalance of node representations. To bridge the gap, we propose a\nmethod named Dimensional reweighting Graph Convolution Network (DrGCN). We\ntheoretically prove that our DrGCN can guarantee to improve the stability of\nGCNs via mean field theory. Our dimensional reweighting method is very flexible\nand can be easily combined with most sampling and aggregation techniques for\nGCNs. Experimental results demonstrate its superior performances on several\nchallenging transductive and inductive node classification benchmark datasets.\nOur DrGCN also outperforms existing models on an industrial-sized Alibaba\nrecommendation dataset.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 06:01:32 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 03:05:12 GMT"}, {"version": "v3", "created": "Thu, 29 Oct 2020 09:00:53 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Zou", "Xu", ""], ["Jia", "Qiuye", ""], ["Zhang", "Jianwei", ""], ["Zhou", "Chang", ""], ["Yang", "Hongxia", ""], ["Tang", "Jie", ""]]}, {"id": "1907.02242", "submitter": "Austin Okray", "authors": "Austin Okray, Hui Hu, Chao Lan", "title": "Fair Kernel Regression via Fair Feature Embedding in Kernel Space", "comments": "ICTAI 2019, fair machine learning, kernel regression, fair feature\n  embedding, feature selection for kernel methods, mean discrepancy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there have been significant efforts on mitigating unethical\ndemographic biases in machine learning methods. However, very little is done\nfor kernel methods. In this paper, we propose a new fair kernel regression\nmethod via fair feature embedding (FKR-F$^2$E) in kernel space. Motivated by\nprior works on feature selection in kernel space and feature processing for\nfair machine learning, we propose to learn fair feature embedding functions\nthat minimize demographic discrepancy of feature distributions in kernel space.\nCompared to the state-of-the-art fair kernel regression method and several\nbaseline methods, we show FKR-F$^2$E achieves significantly lower prediction\ndisparity across three real-world data sets.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 06:22:38 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 23:13:58 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Okray", "Austin", ""], ["Hu", "Hui", ""], ["Lan", "Chao", ""]]}, {"id": "1907.02253", "submitter": "Byung-Hak Kim", "authors": "Byung-Hak Kim and Varun Ganapathi", "title": "Lumi\\`ereNet: Lecture Video Synthesis from Audio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Lumi\\`ereNet, a simple, modular, and completely deep-learning\nbased architecture that synthesizes, high quality, full-pose headshot lecture\nvideos from instructor's new audio narration of any length. Unlike prior works,\nLumi\\`ereNet is entirely composed of trainable neural network modules to learn\nmapping functions from the audio to video through (intermediate) estimated\npose-based compact and abstract latent codes. Our video demos are available at\n[22] and [23].\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 07:21:24 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Kim", "Byung-Hak", ""], ["Ganapathi", "Varun", ""]]}, {"id": "1907.02265", "submitter": "Ond\\v{r}ej C\\'ifka", "authors": "Ond\\v{r}ej C\\'ifka, Umut \\c{S}im\\c{s}ekli, Ga\\\"el Richard", "title": "Supervised Symbolic Music Style Translation Using Synthetic Data", "comments": "ISMIR 2019 camera-ready", "journal-ref": "Proceedings of the 20th International Society for Music\n  Information Retrieval Conference (2019) 588-595", "doi": "10.5281/zenodo.3527878", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research on style transfer and domain translation has clearly demonstrated\nthe ability of deep learning-based algorithms to manipulate images in terms of\nartistic style. More recently, several attempts have been made to extend such\napproaches to music (both symbolic and audio) in order to enable transforming\nmusical style in a similar manner. In this study, we focus on symbolic music\nwith the goal of altering the 'style' of a piece while keeping its original\n'content'. As opposed to the current methods, which are inherently restricted\nto be unsupervised due to the lack of 'aligned' data (i.e. the same musical\npiece played in multiple styles), we develop the first fully supervised\nalgorithm for this task. At the core of our approach lies a synthetic data\ngeneration scheme which allows us to produce virtually unlimited amounts of\naligned data, and hence avoid the above issue. In view of this data generation\nscheme, we propose an encoder-decoder model for translating symbolic music\naccompaniments between a number of different styles. Our experiments show that\nour models, although trained entirely on synthetic data, are capable of\nproducing musically meaningful accompaniments even for real (non-synthetic)\nMIDI recordings.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 08:16:20 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["C\u00edfka", "Ond\u0159ej", ""], ["\u015eim\u015fekli", "Umut", ""], ["Richard", "Ga\u00ebl", ""]]}, {"id": "1907.02271", "submitter": "Mohammad Rostami", "authors": "Alex Gabourie, Mohammad Rostami, Philip Pope, Soheil Kolouri, Kyungnam\n  Kim", "title": "Learning a Domain-Invariant Embedding for Unsupervised Domain Adaptation\n  Using Class-Conditioned Distribution Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of unsupervised domain adaptation (UDA) by learning a\ncross-domain agnostic embedding space, where the distance between the\nprobability distributions of the two source and target visual domains is\nminimized. We use the output space of a shared cross-domain deep encoder to\nmodel the embedding space anduse the Sliced-Wasserstein Distance (SWD) to\nmeasure and minimize the distance between the embedded distributions of two\nsource and target domains to enforce the embedding to be\ndomain-agnostic.Additionally, we use the source domain labeled data to train a\ndeep classifier from the embedding space to the label space to enforce the\nembedding space to be discriminative.As a result of this training scheme, we\nprovide an effective solution to train the deep classification network on the\nsource domain such that it will generalize well on the target domain, where\nonly unlabeled training data is accessible. To mitigate the challenge of class\nmatching, we also align corresponding classes in the embedding space by using\nhigh confidence pseudo-labels for the target domain, i.e. assigning the class\nfor which the source classifier has a high prediction probability. We provide\nexperimental results on UDA benchmark tasks to demonstrate that our method is\neffective and leads to state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 08:29:11 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 16:09:11 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Gabourie", "Alex", ""], ["Rostami", "Mohammad", ""], ["Pope", "Philip", ""], ["Kolouri", "Soheil", ""], ["Kim", "Kyungnam", ""]]}, {"id": "1907.02306", "submitter": "Vincent Margot", "authors": "Vincent Margot (LPSM UMR 8001), Jean-Patrick Baudry (LPSM UMR 8001),\n  Fr\\'ed\\'eric Guilloux (LPSM UMR 8001), Olivier Wintenberger (LPSM UMR 8001)", "title": "Consistent Regression using Data-Dependent Coverings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel method to generate interpretable\nregression function estimators. The idea is based on called data-dependent\ncoverings. The aim is to extract from the data a covering of the feature space\ninstead of a partition. The estimator predicts the empirical conditional\nexpectation over the cells of the partitions generated from the coverings.\nThus, such estimator has the same form as those issued from data-dependent\npartitioning algorithms. We give sufficient conditions to ensure the\nconsistency, avoiding the sufficient condition of shrinkage of the cells that\nappears in the former literature. Doing so, we reduce the number of covering\nelements. We show that such coverings are interpretable and each element of the\ncovering is tagged as significant or insignificant. The proof of the\nconsistency is based on a control of the error of the empirical estimation of\nconditional expectations which is interesting on its own.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 09:54:44 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 12:48:27 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 13:36:45 GMT"}, {"version": "v4", "created": "Fri, 25 Sep 2020 12:52:06 GMT"}, {"version": "v5", "created": "Tue, 26 Jan 2021 08:43:34 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Margot", "Vincent", "", "LPSM UMR 8001"], ["Baudry", "Jean-Patrick", "", "LPSM UMR 8001"], ["Guilloux", "Fr\u00e9d\u00e9ric", "", "LPSM UMR 8001"], ["Wintenberger", "Olivier", "", "LPSM UMR 8001"]]}, {"id": "1907.02343", "submitter": "Sibylle Hess", "authors": "Sibylle Hess, Wouter Duivesteijn", "title": "k is the Magic Number -- Inferring the Number of Clusters Through\n  Nonparametric Concentration Inequalities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most convex and nonconvex clustering algorithms come with one crucial\nparameter: the $k$ in $k$-means. To this day, there is not one generally\naccepted way to accurately determine this parameter. Popular methods are simple\nyet theoretically unfounded, such as searching for an elbow in the curve of a\ngiven cost measure. In contrast, statistically founded methods often make\nstrict assumptions over the data distribution or come with their own\noptimization scheme for the clustering objective. This limits either the set of\napplicable datasets or clustering algorithms. In this paper, we strive to\ndetermine the number of clusters by answering a simple question: given two\nclusters, is it likely that they jointly stem from a single distribution? To\nthis end, we propose a bound on the probability that two clusters originate\nfrom the distribution of the unified cluster, specified only by the sample mean\nand variance. Our method is applicable as a simple wrapper to the result of any\nclustering method minimizing the objective of $k$-means, which includes\nGaussian mixtures and Spectral Clustering. We focus in our experimental\nevaluation on an application for nonconvex clustering and demonstrate the\nsuitability of our theoretical results. Our \\textsc{SpecialK} clustering\nalgorithm automatically determines the appropriate value for $k$, without\nrequiring any data transformation or projection, and without assumptions on the\ndata distribution. Additionally, it is capable to decide that the data consists\nof only a single cluster, which many existing algorithms cannot.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 11:57:01 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Hess", "Sibylle", ""], ["Duivesteijn", "Wouter", ""]]}, {"id": "1907.02345", "submitter": "Yaxin Shi", "authors": "Yaxin Shi, Yuangang Pan, Donna Xu, Ivor Tsang", "title": "Probabilistic CCA with Implicit Distributions", "comments": "23 pages, 9 Figures; Keywords: Multi-view Learning, Nonlinear\n  Dependency, Deep Generative models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical Correlation Analysis (CCA) is a classic technique for multi-view\ndata analysis. To overcome the deficiency of linear correlation in practical\nmulti-view learning tasks, various CCA variants were proposed to capture\nnonlinear dependency. However, it is non-trivial to have an in-principle\nunderstanding of these variants due to their inherent restrictive assumption on\nthe data and latent code distributions. Although some works have studied\nprobabilistic interpretation for CCA, these models still require the explicit\nform of the distributions to achieve a tractable solution for the inference. In\nthis work, we study probabilistic interpretation for CCA based on implicit\ndistributions. We present Conditional Mutual Information (CMI) as a new\ncriterion for CCA to consider both linear and nonlinear dependency for\narbitrarily distributed data. To eliminate direct estimation for CMI, in which\nexplicit form of the distributions is still required, we derive an objective\nwhich can provide an estimation for CMI with efficient inference methods. To\nfacilitate Bayesian inference of multi-view analysis, we propose Adversarial\nCCA (ACCA), which achieves consistent encoding for multi-view data with the\nconsistent constraint imposed on the marginalization of the implicit\nposteriors. Such a model would achieve superiority in the alignment of the\nmulti-view data with implicit distributions. It is interesting to note that\nmost of the existing CCA variants can be connected with our proposed CCA model\nby assigning specific form for the posterior and likelihood distributions.\nExtensive experiments on nonlinear correlation analysis and cross-view\ngeneration on benchmark and real-world datasets demonstrate the superiority of\nour model.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 11:59:06 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Shi", "Yaxin", ""], ["Pan", "Yuangang", ""], ["Xu", "Donna", ""], ["Tsang", "Ivor", ""]]}, {"id": "1907.02404", "submitter": "Man Shun Ang", "authors": "Valentin Leplat, Nicolas Gillis, Man Shun Ang", "title": "Blind Audio Source Separation with Minimum-Volume Beta-Divergence NMF", "comments": "24 pages, 10 figures, 3 tables", "journal-ref": null, "doi": "10.1109/TSP.2020.2991801", "report-no": null, "categories": "eess.SP cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering a mixed signal composed of various audio sources and recorded\nwith a single microphone, we consider on this paper the blind audio source\nseparation problem which consists in isolating and extracting each of the\nsources. To perform this task, nonnegative matrix factorization (NMF) based on\nthe Kullback-Leibler and Itakura-Saito $\\beta$-divergences is a standard and\nstate-of-the-art technique that uses the time-frequency representation of the\nsignal. We present a new NMF model better suited for this task. It is based on\nthe minimization of $\\beta$-divergences along with a penalty term that promotes\nthe columns of the dictionary matrix to have a small volume. Under some mild\nassumptions and in noiseless conditions, we prove that this model is provably\nable to identify the sources. In order to solve this problem, we propose\nmultiplicative updates whose derivations are based on the standard\nmajorization-minimization framework. We show on several numerical experiments\nthat our new model is able to obtain more interpretable results than standard\nNMF models. Moreover, we show that it is able to recover the sources even when\nthe number of sources present into the mixed signal is overestimated. In fact,\nour model automatically sets sources to zero in this situation, hence performs\nmodel order selection automatically.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 13:56:25 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2020 16:00:15 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Leplat", "Valentin", ""], ["Gillis", "Nicolas", ""], ["Ang", "Man Shun", ""]]}, {"id": "1907.02426", "submitter": "Susanne Trick", "authors": "Susanne Trick, Dorothea Koert, Jan Peters, Constantin Rothkopf", "title": "Multimodal Uncertainty Reduction for Intention Recognition in\n  Human-Robot Interaction", "comments": "Submitted to IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assistive robots can potentially improve the quality of life and personal\nindependence of elderly people by supporting everyday life activities. To\nguarantee a safe and intuitive interaction between human and robot, human\nintentions need to be recognized automatically. As humans communicate their\nintentions multimodally, the use of multiple modalities for intention\nrecognition may not just increase the robustness against failure of individual\nmodalities but especially reduce the uncertainty about the intention to be\npredicted. This is desirable as particularly in direct interaction between\nrobots and potentially vulnerable humans a minimal uncertainty about the\nsituation as well as knowledge about this actual uncertainty is necessary.\nThus, in contrast to existing methods, in this work a new approach for\nmultimodal intention recognition is introduced that focuses on uncertainty\nreduction through classifier fusion. For the four considered modalities speech,\ngestures, gaze directions and scene objects individual intention classifiers\nare trained, all of which output a probability distribution over all possible\nintentions. By combining these output distributions using the Bayesian method\nIndependent Opinion Pool the uncertainty about the intention to be recognized\ncan be decreased. The approach is evaluated in a collaborative human-robot\ninteraction task with a 7-DoF robot arm. The results show that fused\nclassifiers which combine multiple modalities outperform the respective\nindividual base classifiers with respect to increased accuracy, robustness, and\nreduced uncertainty.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 14:33:49 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Trick", "Susanne", ""], ["Koert", "Dorothea", ""], ["Peters", "Jan", ""], ["Rothkopf", "Constantin", ""]]}, {"id": "1907.02431", "submitter": "Guy Gaziv", "authors": "Roman Beliy, Guy Gaziv, Assaf Hoogi, Francesca Strappini, Tal Golan,\n  Michal Irani", "title": "From voxels to pixels and back: Self-supervision in natural-image\n  reconstruction from fMRI", "comments": "*First two authors contributed equally. NeurIPS 2019", "journal-ref": "https://proceedings.neurips.cc/paper/2019/file/7d2be41b1bde6ff8fe45150c37488ebb-Paper.pdf", "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing observed images from fMRI brain recordings is challenging.\nUnfortunately, acquiring sufficient \"labeled\" pairs of {Image, fMRI} (i.e.,\nimages with their corresponding fMRI responses) to span the huge space of\nnatural images is prohibitive for many reasons. We present a novel approach\nwhich, in addition to the scarce labeled data (training pairs), allows to train\nfMRI-to-image reconstruction networks also on \"unlabeled\" data (i.e., images\nwithout fMRI recording, and fMRI recording without images). The proposed model\nutilizes both an Encoder network (image-to-fMRI) and a Decoder network\n(fMRI-to-image). Concatenating these two networks back-to-back (Encoder-Decoder\n& Decoder-Encoder) allows augmenting the training with both types of unlabeled\ndata. Importantly, it allows training on the unlabeled test-fMRI data. This\nself-supervision adapts the reconstruction network to the new input test-data,\ndespite its deviation from the statistics of the scarce training data.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 14:49:26 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Beliy", "Roman", ""], ["Gaziv", "Guy", ""], ["Hoogi", "Assaf", ""], ["Strappini", "Francesca", ""], ["Golan", "Tal", ""], ["Irani", "Michal", ""]]}, {"id": "1907.02437", "submitter": "Liang Guo", "authors": "Liang Guo, Jianya Liu, Ruodan Lu", "title": "Subsampling Bias and The Best-Discrepancy Systematic Cross Validation", "comments": "SCIENCE China Mathematics. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical machine learning models should be evaluated and validated before\nputting to work. Conventional k-fold Monte Carlo Cross-Validation (MCCV)\nprocedure uses a pseudo-random sequence to partition instances into k subsets,\nwhich usually causes subsampling bias, inflates generalization errors and\njeopardizes the reliability and effectiveness of cross-validation. Based on\nordered systematic sampling theory in statistics and low-discrepancy sequence\ntheory in number theory, we propose a new k-fold cross-validation procedure by\nreplacing a pseudo-random sequence with a best-discrepancy sequence, which\nensures low subsampling bias and leads to more precise\nExpected-Prediction-Error estimates. Experiments with 156 benchmark datasets\nand three classifiers (logistic regression, decision tree and naive bayes) show\nthat in general, our cross-validation procedure can extrude subsampling bias in\nthe MCCV by lowering the EPE around 7.18% and the variances around 26.73%. In\ncomparison, the stratified MCCV can reduce the EPE and variances of the MCCV\naround 1.58% and 11.85% respectively. The Leave-One-Out (LOO) can lower the EPE\naround 2.50% but its variances are much higher than the any other CV procedure.\nThe computational time of our cross-validation procedure is just 8.64% of the\nMCCV, 8.67% of the stratified MCCV and 16.72% of the LOO. Experiments also show\nthat our approach is more beneficial for datasets characterized by relatively\nsmall size and large aspect ratio. This makes our approach particularly\npertinent when solving bioscience classification problems. Our proposed\nsystematic subsampling technique could be generalized to other machine learning\nalgorithms that involve random subsampling mechanism.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 14:55:02 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Guo", "Liang", ""], ["Liu", "Jianya", ""], ["Lu", "Ruodan", ""]]}, {"id": "1907.02443", "submitter": "Tianxi Li", "authors": "Tianxi Li, Cheng Qian, Elizaveta Levina, Ji Zhu", "title": "High-dimensional Gaussian graphical model for network-linked data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical models are commonly used to represent conditional dependence\nrelationships between variables. There are multiple methods available for\nexploring them from high-dimensional data, but almost all of them rely on the\nassumption that the observations are independent and identically distributed.\nAt the same time, observations connected by a network are becoming increasingly\ncommon, and tend to violate these assumptions. Here we develop a Gaussian\ngraphical model for observations connected by a network with potentially\ndifferent mean vectors, varying smoothly over the network. We propose an\nefficient estimation algorithm and demonstrate its effectiveness on both\nsimulated and real data, obtaining meaningful and interpretable results on a\nstatistics coauthorship network. We also prove that our method estimates both\nthe inverse covariance matrix and the corresponding graph structure correctly\nunder the assumption of network \u00e2\u0080\u009ccohesion\u00e2\u0080\u009d, which refers to the empirically\nobserved phenomenon of network neighbors sharing similar traits.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 15:08:24 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 14:40:31 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Li", "Tianxi", ""], ["Qian", "Cheng", ""], ["Levina", "Elizaveta", ""], ["Zhu", "Ji", ""]]}, {"id": "1907.02447", "submitter": "Arthur Guillaumin", "authors": "Arthur P. Guillaumin, Adam M. Sykulski, Sofia C. Olhede, Frederik J.\n  Simons", "title": "The Debiased Spatial Whittle Likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a computationally and statistically efficient method for\nestimating the parameters of a stochastic Gaussian model observed on a regular\nspatial grid in any number of dimensions. Our proposed method, which we call\nthe debiased spatial Whittle likelihood, makes important corrections to the\nwell-known Whittle likelihood to account for large sources of bias caused by\nboundary effects and aliasing. We generalise the approach to flexibly allow for\nsignificant volumes of missing data, for the usage of irregular sampling\nschemes including those with lower-dimensional substructure, and for irregular\nsampling boundaries. We build a theoretical framework under relatively weak\nassumptions which ensures consistency and asymptotic normality in numerous\npractical settings. We provide detailed implementation guidelines which ensure\nthe estimation procedure can still be conducted in $\\mathcal{O}(n\\log n)$\noperations, where $n$ is the number of points of the encapsulating rectangular\ngrid, thus keeping the computational scalability of Fourier and Whittle-based\nmethods for large data sets. We validate our procedure over a range of\nsimulated and real world settings, and compare with state-of-the-art\nalternatives, demonstrating the enduring significant practical appeal of\nFourier-based methods, provided they are corrected by the constructive\nprocedures developed in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 15:11:36 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 14:33:14 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 21:17:15 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Guillaumin", "Arthur P.", ""], ["Sykulski", "Adam M.", ""], ["Olhede", "Sofia C.", ""], ["Simons", "Frederik J.", ""]]}, {"id": "1907.02452", "submitter": "Said Ouala", "authors": "Said Ouala, Duong Nguyen, Lucas Drumetz, Bertrand Chapron, Ananda\n  Pascual, Fabrice Collard, Lucile Gaultier and Ronan Fablet", "title": "Learning Latent Dynamics for Partially-Observed Chaotic Systems", "comments": null, "journal-ref": null, "doi": "10.1063/5.0019309", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the data-driven identification of latent dynamical\nrepresentations of partially-observed systems, i.e., dynamical systems for\nwhich some components are never observed, with an emphasis on forecasting\napplications, including long-term asymptotic patterns. Whereas state-of-the-art\ndata-driven approaches rely on delay embeddings and linear decompositions of\nthe underlying operators, we introduce a framework based on the data-driven\nidentification of an augmented state-space model using a neural-network-based\nrepresentation. For a given training dataset, it amounts to jointly learn an\nODE (Ordinary Differential Equation) representation in the latent space and\nreconstructing latent states. Through numerical experiments, we demonstrate the\nrelevance of the proposed framework w.r.t. state-of-the-art approaches in terms\nof short-term forecasting performance and long-term behaviour. We further\ndiscuss how the proposed framework relates to Koopman operator theory and\nTakens' embedding theorem.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 15:23:12 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Ouala", "Said", ""], ["Nguyen", "Duong", ""], ["Drumetz", "Lucas", ""], ["Chapron", "Bertrand", ""], ["Pascual", "Ananda", ""], ["Collard", "Fabrice", ""], ["Gaultier", "Lucile", ""], ["Fablet", "Ronan", ""]]}, {"id": "1907.02511", "submitter": "Evaggelia Tsiligianni", "authors": "Evaggelia Tsiligianni and Nikos Deligiannis", "title": "Deep Coupled-Representation Learning for Sparse Linear Inverse Problems\n  with Side Information", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": "10.1109/LSP.2019.2929869", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In linear inverse problems, the goal is to recover a target signal from\nundersampled, incomplete or noisy linear measurements. Typically, the recovery\nrelies on complex numerical optimization methods; recent approaches perform an\nunfolding of a numerical algorithm into a neural network form, resulting in a\nsubstantial reduction of the computational complexity. In this paper, we\nconsider the recovery of a target signal with the aid of a correlated signal,\nthe so-called side information (SI), and propose a deep unfolding model that\nincorporates SI. The proposed model is used to learn coupled representations of\ncorrelated signals from different modalities, enabling the recovery of\nmultimodal data at a low computational cost. As such, our work introduces the\nfirst deep unfolding method with SI, which actually comes from a different\nmodality. We apply our model to reconstruct near-infrared images from\nundersampled measurements given RGB images as SI. Experimental results\ndemonstrate the superior performance of the proposed framework against\nsingle-modal deep learning methods that do not use SI, multimodal deep learning\ndesigns, and optimization algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 17:47:32 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Tsiligianni", "Evaggelia", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1907.02513", "submitter": "Uri Stemmer", "authors": "Uri Stemmer", "title": "Locally Private k-Means Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a new algorithm for the Euclidean $k$-means problem that operates\nin the local model of differential privacy. Unlike in the non-private\nliterature, differentially private algorithms for the $k$-means objective incur\nboth additive and multiplicative errors. Our algorithm significantly reduces\nthe additive error while keeping the multiplicative error the same as in\nprevious state-of-the-art results. Specifically, on a database of size $n$, our\nalgorithm guarantees $O(1)$ multiplicative error and $\\approx n^{1/2+a}$\nadditive error for an arbitrarily small constant $a>0$. All previous algorithms\nin the local model had additive error $\\approx n^{2/3+a}$. Our techniques\nextend to $k$-median clustering.\n  We show that the additive error we obtain is almost optimal in terms of its\ndependency on the database size $n$. Specifically, we give a simple lower bound\nshowing that every locally-private algorithm for the $k$-means objective must\nhave additive error at least $\\approx\\sqrt{n}$.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 17:50:33 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 00:29:49 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Stemmer", "Uri", ""]]}, {"id": "1907.02517", "submitter": "Alessandro Betti", "authors": "Alessandro Betti, Marco Gori", "title": "Least Action Principles and Well-Posed Learning Problems", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning algorithms are typically regarded as appropriate\noptimization schemes for minimizing risk functions that are constructed on the\ntraining set, which conveys statistical flavor to the corresponding learning\nproblem. When the focus is shifted on perception, which is inherently\ninterwound with time, recent alternative formulations of learning have been\nproposed that rely on the principle of Least Cognitive Action, which very much\nreminds us of the Least Action Principle in mechanics. In this paper, we\ndiscuss different forms of the cognitive action and show the well-posedness of\nlearning. In particular, unlike the special case of the action in mechanics,\nwhere the stationarity is typically gained on saddle points, we prove the\nexistence of the minimum of a special form of cognitive action, which yields\nforth-order differential equations of learning. We also briefly discuss the\ndissipative behavior of these equations that turns out to characterize the\nprocess of learning.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 17:54:45 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Betti", "Alessandro", ""], ["Gori", "Marco", ""]]}, {"id": "1907.02519", "submitter": "Kamil Adamczewski", "authors": "Kamil Adamczewski, Mijung Park", "title": "Neuron ranking -- an informed way to condense convolutional neural\n  networks architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) in recent years have made a dramatic\nimpact in science, technology and industry, yet the theoretical mechanism of\nCNN architecture design remains surprisingly vague. The CNN neurons, including\nits distinctive element, convolutional filters, are known to be learnable\nfeatures, yet their individual role in producing the output is rather unclear.\nThe thesis of this work is that not all neurons are equally important and some\nof them contain more useful information to perform a given task . Consequently,\nwe quantify the significance of each filter and rank its importance in\ndescribing input to produce the desired output. This work presents two\ndifferent methods: (1) a game theoretical approach based on Shapley value which\ncomputes the marginal contribution of each filter; and (2) a probabilistic\napproach based on what-we-call, the Importance switch using variational\ninference. Strikingly, these two vastly different methods produce similar\nexperimental results, confirming the general theory that some of the filters\nare inherently more important that the others. The learned ranks can be readily\nuseable for network compression and interpretability.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:20:21 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 21:34:19 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Adamczewski", "Kamil", ""], ["Park", "Mijung", ""]]}, {"id": "1907.02531", "submitter": "Souvik Chakraborty", "authors": "Somdatta Goswami and Cosmin Anitescu and Souvik Chakraborty and Timon\n  Rabczuk", "title": "Transfer learning enhanced physics informed neural network for\n  phase-field modeling of fracture", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new physics informed neural network (PINN) algorithm for solving\nbrittle fracture problems. While most of the PINN algorithms available in the\nliterature minimize the residual of the governing partial differential\nequation, the proposed approach takes a different path by minimizing the\nvariational energy of the system. Additionally, we modify the neural network\noutput such that the boundary conditions associated with the problem are\nexactly satisfied. Compared to conventional residual based PINN, the proposed\napproach has two major advantages. First, the imposition of boundary conditions\nis relatively simpler and more robust. Second, the order of derivatives present\nin the functional form of the variational energy is of lower order than in the\nresidual form. Hence, training the network is faster. To compute the total\nvariational energy of the system, an efficient scheme that takes as input a\ngeometry described by spline based CAD model and employs Gauss quadrature rules\nfor numerical integration has been proposed. Moreover, we utilize the concept\nof transfer learning to obtain the crack path in an efficient manner. The\nproposed approach is used to solve four fracture mechanics problems. For all\nthe examples, results obtained using the proposed approach match closely with\nthe results available in the literature. For the first two examples, we compare\nthe results obtained using the proposed approach with the conventional residual\nbased neural network results. For both the problems, the proposed approach is\nfound to yield better accuracy compared to conventional residual based PINN\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 17:03:43 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Goswami", "Somdatta", ""], ["Anitescu", "Cosmin", ""], ["Chakraborty", "Souvik", ""], ["Rabczuk", "Timon", ""]]}, {"id": "1907.02544", "submitter": "Jeff Donahue", "authors": "Jeff Donahue and Karen Simonyan", "title": "Large Scale Adversarial Representation Learning", "comments": "32 pages. In proceedings of NeurIPS 2019. This is the camera-ready\n  version of the paper, with supplementary material included as appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarially trained generative models (GANs) have recently achieved\ncompelling image synthesis results. But despite early successes in using GANs\nfor unsupervised representation learning, they have since been superseded by\napproaches based on self-supervision. In this work we show that progress in\nimage generation quality translates to substantially improved representation\nlearning performance. Our approach, BigBiGAN, builds upon the state-of-the-art\nBigGAN model, extending it to representation learning by adding an encoder and\nmodifying the discriminator. We extensively evaluate the representation\nlearning and generation capabilities of these BigBiGAN models, demonstrating\nthat these generation-based models achieve the state of the art in unsupervised\nrepresentation learning on ImageNet, as well as in unconditional image\ngeneration. Pretrained BigBiGAN models -- including image generators and\nencoders -- are available on TensorFlow Hub\n(https://tfhub.dev/s?publisher=deepmind&q=bigbigan).\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 18:00:17 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 18:05:57 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Donahue", "Jeff", ""], ["Simonyan", "Karen", ""]]}, {"id": "1907.02549", "submitter": "Hlynur Dav\\'i{\\dh} Hlynsson", "authors": "Hlynur Dav\\'i{\\dh} Hlynsson, Alberto N. Escalante-B., Laurenz Wiskott", "title": "Measuring the Data Efficiency of Deep Learning Methods", "comments": "8 pages", "journal-ref": "In Proceedings of the 8th International Conference on Pattern\n  Recognition Applications and Methods - Volume 1: ICPRAM (2019) pages 691-698", "doi": "10.5220/0007456306910698", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new experimental protocol and use it to benchmark\nthe data efficiency --- performance as a function of training set size --- of\ntwo deep learning algorithms, convolutional neural networks (CNNs) and\nhierarchical information-preserving graph-based slow feature analysis (HiGSFA),\nfor tasks in classification and transfer learning scenarios. The algorithms are\ntrained on different-sized subsets of the MNIST and Omniglot data sets. HiGSFA\noutperforms standard CNN networks when the models are trained on 50 and 200\nsamples per class for MNIST classification. In other cases, the CNNs perform\nbetter. The results suggest that there are cases where greedy, locally optimal\nbottom-up learning is equally or more powerful than global gradient-based\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:22:23 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Hlynsson", "Hlynur Dav\u00ed\u00f0", ""], ["Escalante-B.", "Alberto N.", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "1907.02571", "submitter": "Stefano  Trac\\`a", "authors": "Stefano Trac\\`a, Cynthia Rudin, Weiyu Yan", "title": "Reducing Exploration of Dying Arms in Mortal Bandits", "comments": "Conference: UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mortal bandits have proven to be extremely useful for providing news article\nrecommendations, running automated online advertising campaigns, and for other\napplications where the set of available options changes over time. Previous\nwork on this problem showed how to regulate exploration of new arms when they\nhave recently appeared, but they do not adapt when the arms are about to\ndisappear. Since in most applications we can determine either exactly or\napproximately when arms will disappear, we can leverage this information to\nimprove performance: we should not be exploring arms that are about to\ndisappear. We provide adaptations of algorithms, regret bounds, and experiments\nfor this study, showing a clear benefit from regulating greed\n(exploration/exploitation) for arms that will soon disappear. We illustrate\nnumerical performance on the Yahoo! Front Page Today Module User Click Log\nDataset.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 19:57:03 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Trac\u00e0", "Stefano", ""], ["Rudin", "Cynthia", ""], ["Yan", "Weiyu", ""]]}, {"id": "1907.02577", "submitter": "Akshay Iyer", "authors": "Akshay Iyer, Yichi Zhang, Aditya Prasad, Siyu Tao, Yixing Wang, Linda\n  Schadler, L Catherine Brinson and Wei Chen", "title": "Data-Centric Mixed-Variable Bayesian Optimization For Materials Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cond-mat.mtrl-sci cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Materials design can be cast as an optimization problem with the goal of\nachieving desired properties, by varying material composition, microstructure\nmorphology, and processing conditions. Existence of both qualitative and\nquantitative material design variables leads to disjointed regions in property\nspace, making the search for optimal design challenging. Limited availability\nof experimental data and the high cost of simulations magnify the challenge.\nThis situation calls for design methodologies that can extract useful\ninformation from existing data and guide the search for optimal designs\nefficiently. To this end, we present a data-centric, mixed-variable Bayesian\nOptimization framework that integrates data from literature, experiments, and\nsimulations for knowledge discovery and computational materials design. Our\nframework pivots around the Latent Variable Gaussian Process (LVGP), a novel\nGaussian Process technique which projects qualitative variables on a continuous\nlatent space for covariance formulation, as the surrogate model to quantify\n\"lack of data\" uncertainty. Expected improvement, an acquisition criterion that\nbalances exploration and exploitation, helps navigate a complex, nonlinear\ndesign space to locate the optimum design. The proposed framework is tested\nthrough a case study which seeks to concurrently identify the optimal\ncomposition and morphology for insulating polymer nanocomposites. We also\npresent an extension of mixed-variable Bayesian Optimization for multiple\nobjectives to identify the Pareto Frontier within tens of iterations. These\nfindings project Bayesian Optimization as a powerful tool for design of\nengineered material systems.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 20:21:40 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Iyer", "Akshay", ""], ["Zhang", "Yichi", ""], ["Prasad", "Aditya", ""], ["Tao", "Siyu", ""], ["Wang", "Yixing", ""], ["Schadler", "Linda", ""], ["Brinson", "L Catherine", ""], ["Chen", "Wei", ""]]}, {"id": "1907.02582", "submitter": "Ana Lucic", "authors": "Ana Lucic, Hinda Haned, Maarten de Rijke", "title": "Explaining Predictions from Tree-based Boosting Ensembles", "comments": "SIGIR 2019: FACTS-IR Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how \"black-box\" models arrive at their predictions has sparked\nsignificant interest from both within and outside the AI community. Our work\nfocuses on doing this by generating local explanations about individual\npredictions for tree-based ensembles, specifically Gradient Boosting Decision\nTrees (GBDTs). Given a correctly predicted instance in the training set, we\nwish to generate a counterfactual explanation for this instance, that is, the\nminimal perturbation of this instance such that the prediction flips to the\nopposite class. Most existing methods for counterfactual explanations are (1)\nmodel-agnostic, so they do not take into account the structure of the original\nmodel, and/or (2) involve building a surrogate model on top of the original\nmodel, which is not guaranteed to represent the original model accurately.\nThere exists a method specifically for random forests; we wish to extend this\nmethod for GBDTs. This involves accounting for (1) the sequential dependency\nbetween trees and (2) training on the negative gradients instead of the\noriginal labels.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 20:43:12 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Lucic", "Ana", ""], ["Haned", "Hinda", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1907.02584", "submitter": "Janis Klaise", "authors": "Arnaud Van Looveren and Janis Klaise", "title": "Interpretable Counterfactual Explanations Guided by Prototypes", "comments": "17 pages, 13 figures. For an open source implementation of the\n  algorithm, see https://github.com/SeldonIO/alibi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fast, model agnostic method for finding interpretable\ncounterfactual explanations of classifier predictions by using class\nprototypes. We show that class prototypes, obtained using either an encoder or\nthrough class specific k-d trees, significantly speed up the the search for\ncounterfactual instances and result in more interpretable explanations. We\nintroduce two novel metrics to quantitatively evaluate local interpretability\nat the instance level. We use these metrics to illustrate the effectiveness of\nour method on an image and tabular dataset, respectively MNIST and Breast\nCancer Wisconsin (Diagnostic). The method also eliminates the computational\nbottleneck that arises because of numerical gradient evaluation for\n$\\textit{black box}$ models.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 13:12:08 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 11:46:29 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Van Looveren", "Arnaud", ""], ["Klaise", "Janis", ""]]}, {"id": "1907.02586", "submitter": "Guangfeng Lin", "authors": "Guangfeng Lin and Jing Wang and Kaiyang Liao and Fan Zhao and Wanjun\n  Chen", "title": "Structure fusion based on graph convolutional networks for\n  semi-supervised classification", "comments": null, "journal-ref": "Electronics,2020", "doi": "10.3390/electronics9030432", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Suffering from the multi-view data diversity and complexity for\nsemi-supervised classification, most of existing graph convolutional networks\nfocus on the networks architecture construction or the salient graph structure\npreservation, and ignore the the complete graph structure for semi-supervised\nclassification contribution. To mine the more complete distribution structure\nfrom multi-view data with the consideration of the specificity and the\ncommonality, we propose structure fusion based on graph convolutional networks\n(SF-GCN) for improving the performance of semi-supervised classification.\nSF-GCN can not only retain the special characteristic of each view data by\nspectral embedding, but also capture the common style of multi-view data by\ndistance metric between multi-graph structures. Suppose the linear relationship\nbetween multi-graph structures, we can construct the optimization function of\nstructure fusion model by balancing the specificity loss and the commonality\nloss. By solving this function, we can simultaneously obtain the fusion\nspectral embedding from the multi-view data and the fusion structure as\nadjacent matrix to input graph convolutional networks for semi-supervised\nclassification. Experiments demonstrate that the performance of SF-GCN\noutperforms that of the state of the arts on three challenging datasets, which\nare Cora,Citeseer and Pubmed in citation networks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 23:43:05 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Lin", "Guangfeng", ""], ["Wang", "Jing", ""], ["Liao", "Kaiyang", ""], ["Zhao", "Fan", ""], ["Chen", "Wanjun", ""]]}, {"id": "1907.02596", "submitter": "Abderrazak Chahid Mr", "authors": "Abderrazak Chahid, Fahad Albalawi, Turky Nayef Alotaiby, Majed Hamad\n  Al-Hameed, Saleh Alshebeili, Taous-Meriem Laleg-Kirati", "title": "QuPWM: Feature Extraction Method for MEG Epileptic Spike Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy is a neurological disorder classified as the second most serious\nneurological disease known to humanity, after stroke. Localization of the\nepileptogenic zone is an important step for epileptic patient treatment, which\nstarts with epileptic spike detection. The common practice for spike detection\nof brain signals is via visual scanning of the recordings, which is a\nsubjective and a very time-consuming task. Motivated by that, this paper\nfocuses on using machine learning for automatic detection of epileptic spikes\nin magnetoencephalography (MEG) signals. First, we used the Position Weight\nMatrix (PWM) method combined with a uniform quantizer to generate useful\nfeatures. Second, the extracted features are classified using a Support Vector\nMachine (SVM) for the purpose of epileptic spikes detection. The proposed\ntechnique shows great potential in improving the spike detection accuracy and\nreducing the feature vector size. Specifically, the proposed technique achieved\naverage accuracy up to 98\\% in using 5-folds cross-validation applied to a\nbalanced dataset of 3104 samples. These samples are extracted from 16 subjects\nwhere eight are healthy and eight are epileptic subjects using a sliding frame\nof size of 100 samples-points with a step-size of 2 sample-points\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:11:19 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Chahid", "Abderrazak", ""], ["Albalawi", "Fahad", ""], ["Alotaiby", "Turky Nayef", ""], ["Al-Hameed", "Majed Hamad", ""], ["Alshebeili", "Saleh", ""], ["Laleg-Kirati", "Taous-Meriem", ""]]}, {"id": "1907.02610", "submitter": "Chongli Qin", "authors": "Chongli Qin, James Martens, Sven Gowal, Dilip Krishnan, Krishnamurthy\n  Dvijotham, Alhussein Fawzi, Soham De, Robert Stanforth, Pushmeet Kohli", "title": "Adversarial Robustness through Local Linearization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial training is an effective methodology for training deep neural\nnetworks that are robust against adversarial, norm-bounded perturbations.\nHowever, the computational cost of adversarial training grows prohibitively as\nthe size of the model and number of input dimensions increase. Further,\ntraining against less expensive and therefore weaker adversaries produces\nmodels that are robust against weak attacks but break down under attacks that\nare stronger. This is often attributed to the phenomenon of gradient\nobfuscation; such models have a highly non-linear loss surface in the vicinity\nof training examples, making it hard for gradient-based attacks to succeed even\nthough adversarial examples still exist. In this work, we introduce a novel\nregularizer that encourages the loss to behave linearly in the vicinity of the\ntraining data, thereby penalizing gradient obfuscation while encouraging\nrobustness. We show via extensive experiments on CIFAR-10 and ImageNet, that\nmodels trained with our regularizer avoid gradient obfuscation and can be\ntrained significantly faster than adversarial training. Using this regularizer,\nwe exceed current state of the art and achieve 47% adversarial accuracy for\nImageNet with l-infinity adversarial perturbations of radius 4/255 under an\nuntargeted, strong, white-box attack. Additionally, we match state of the art\nresults for CIFAR-10 at 8/255.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 21:55:29 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 16:43:35 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Qin", "Chongli", ""], ["Martens", "James", ""], ["Gowal", "Sven", ""], ["Krishnan", "Dilip", ""], ["Dvijotham", "Krishnamurthy", ""], ["Fawzi", "Alhussein", ""], ["De", "Soham", ""], ["Stanforth", "Robert", ""], ["Kohli", "Pushmeet", ""]]}, {"id": "1907.02633", "submitter": "Romuald Elie", "authors": "Romuald Elie, Julien P\\'erolat, Mathieu Lauri\\`ere, Matthieu Geist,\n  Olivier Pietquin", "title": "On the Convergence of Model Free Learning in Mean Field Games", "comments": null, "journal-ref": "AAAI 2020 conference proceedings", "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning by experience in Multi-Agent Systems (MAS) is a difficult and\nexciting task, due to the lack of stationarity of the environment, whose\ndynamics evolves as the population learns. In order to design scalable\nalgorithms for systems with a large population of interacting agents (e.g.\nswarms), this paper focuses on Mean Field MAS, where the number of agents is\nasymptotically infinite. Recently, a very active burgeoning field studies the\neffects of diverse reinforcement learning algorithms for agents with no prior\ninformation on a stationary Mean Field Game (MFG) and learn their policy\nthrough repeated experience. We adopt a high perspective on this problem and\nanalyze in full generality the convergence of a fictitious iterative scheme\nusing any single agent learning algorithm at each step. We quantify the quality\nof the computed approximate Nash equilibrium, in terms of the accumulated\nerrors arising at each learning iteration step. Notably, we show for the first\ntime convergence of model free learning algorithms towards non-stationary MFG\nequilibria, relying only on classical assumptions on the MFG dynamics. We\nillustrate our theoretical results with a numerical experiment in a continuous\naction-space environment, where the approximate best response of the iterative\nfictitious play scheme is computed with a deep RL algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 11:54:09 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 16:01:32 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 00:13:13 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Elie", "Romuald", ""], ["P\u00e9rolat", "Julien", ""], ["Lauri\u00e8re", "Mathieu", ""], ["Geist", "Matthieu", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1907.02644", "submitter": "Adalberto Claudio Quiros", "authors": "Adalberto Claudio Quiros, Roderick Murray-Smith, Ke Yuan", "title": "PathologyGAN: Learning deep representations of cancer tissue", "comments": "Accepted for publication at the Journal of Machine Learning for\n  Biomedical Imaging (MELBA) https://melba-journal.org", "journal-ref": "Journal of Machine Learning for Biomedical Imaging. 2021:4. pp\n  1-48. Special Issue: Medical Imaging with Deep Learning (MIDL) 2020", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Histopathological images of tumors contain abundant information about how\ntumors grow and how they interact with their micro-environment. Better\nunderstanding of tissue phenotypes in these images could reveal novel\ndeterminants of pathological processes underlying cancer, and in turn improve\ndiagnosis and treatment options. Advances of Deep learning makes it ideal to\nachieve those goals, however, its application is limited by the cost of high\nquality labels from patients data. Unsupervised learning, in particular, deep\ngenerative models with representation learning properties provides an\nalternative path to further understand cancer tissue phenotypes, capturing\ntissue morphologies. In this paper, we develop a framework which allows GANs to\ncapture key tissue features and uses these characteristics to give structure to\nits latent space. To this end, we trained our model on two different datasets,\nan H&E colorectal cancer tissue from the National Center for Tumor diseases\n(NCT) and an H&E breast cancer tissue from the Netherlands Cancer Institute\n(NKI) and Vancouver General Hospital (VGH). Composed of 86 slide images and 576\nTMAs respectively. We show that our model generates high quality images, with a\nFID of 16.65 (breast cancer) and 32.05 (colorectal cancer). We further assess\nthe quality of the images with cancer tissue characteristics (e.g. count of\ncancer, lymphocytes, or stromal cells), using quantitative information to\ncalculate the FID and showing consistent performance of 9.86. Additionally, the\nlatent space of our model shows an interpretable structure and allows semantic\nvector operations that translate into tissue feature transformations.\nFurthermore, ratings from two expert pathologists found no significant\ndifference between our generated tissue images from real ones. The code,\nimages, and pretrained models are available at\nhttps://github.com/AdalbertoCq/Pathology-GAN\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 15:27:22 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 11:30:01 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 11:45:40 GMT"}, {"version": "v4", "created": "Thu, 28 May 2020 15:16:08 GMT"}, {"version": "v5", "created": "Tue, 13 Apr 2021 16:54:45 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Quiros", "Adalberto Claudio", ""], ["Murray-Smith", "Roderick", ""], ["Yuan", "Ke", ""]]}, {"id": "1907.02647", "submitter": "F. William Townes", "authors": "F. William Townes", "title": "Generalized Principal Component Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized principal component analysis (GLM-PCA) facilitates dimension\nreduction of non-normally distributed data. We provide a detailed derivation of\nGLM-PCA with a focus on optimization. We also demonstrate how to incorporate\ncovariates, and suggest post-processing transformations to improve\ninterpretability of latent factors.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 04:18:31 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Townes", "F. William", ""]]}, {"id": "1907.02649", "submitter": "Owen Marschall", "authors": "Owen Marschall, Kyunghyun Cho, Cristina Savin", "title": "A Unified Framework of Online Learning Algorithms for Training Recurrent\n  Neural Networks", "comments": "29 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for compactly summarizing many recent results in\nefficient and/or biologically plausible online training of recurrent neural\nnetworks (RNN). The framework organizes algorithms according to several\ncriteria: (a) past vs. future facing, (b) tensor structure, (c) stochastic vs.\ndeterministic, and (d) closed form vs. numerical. These axes reveal latent\nconceptual connections among several recent advances in online learning.\nFurthermore, we provide novel mathematical intuitions for their degree of\nsuccess. Testing various algorithms on two synthetic tasks shows that\nperformances cluster according to our criteria. Although a similar clustering\nis also observed for gradient alignment, alignment with exact methods does not\nalone explain ultimate performance, especially for stochastic algorithms. This\nsuggests the need for better comparison metrics.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 01:49:45 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Marschall", "Owen", ""], ["Cho", "Kyunghyun", ""], ["Savin", "Cristina", ""]]}, {"id": "1907.02662", "submitter": "Amit Rege", "authors": "Amit Rege, Claire Monteleoni", "title": "Evaluating the distribution learning capabilities of GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We evaluate the distribution learning capabilities of generative adversarial\nnetworks by testing them on synthetic datasets. The datasets include common\ndistributions of points in $R^n$ space and images containing polygons of\nvarious shapes and sizes. We find that by and large GANs fail to faithfully\nrecreate point datasets which contain discontinous support or sharp bends with\nnoise. Additionally, on image datasets, we find that GANs do not seem to learn\nto count the number of objects of the same kind in an image. We also highlight\nthe apparent tension between generalization and learning in GANs.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 02:59:40 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Rege", "Amit", ""], ["Monteleoni", "Claire", ""]]}, {"id": "1907.02677", "submitter": "Jos\\'e Camacho", "authors": "Jos\\'e Camacho, Rasmus Bro, David Kotz", "title": "Networkmetrics unraveled: MBDA in Action", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose networkmetrics, a new data-driven approach for monitoring,\ntroubleshooting and understanding communication networks using multivariate\nanalysis. Networkmetric models are powerful machine-learning tools to interpret\nand interact with data collected from a network. In this paper, we illustrate\nthe application of Multivariate Big Data Analysis (MBDA), a recently proposed\nnetworkmetric method with application to Big Data sets. We use MBDA for the\ndetection and troubleshooting of network problems in a campus-wide Wi-Fi\nnetwork. Data includes a seven-year trace (from 2012 to 2018) of the network's\nmost recent activity, with approximately 3,000 distinct access points, 40,000\nauthenticated users, and 600,000 distinct Wi-Fi stations. This is the longest\nand largest Wi-Fi trace known to date. To analyze this data, we propose\nlearning and visualization procedures that extend MBDA. These procedures result\nin a methodology that allows network analysts to identify problems and diagnose\nand troubleshoot them, optimizing the network performance. In the paper, we go\nthrough the entire workflow of the approach, illustrating its application in\ndetail and discussing processing times for parallel hardware.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 04:51:49 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Camacho", "Jos\u00e9", ""], ["Bro", "Rasmus", ""], ["Kotz", "David", ""]]}, {"id": "1907.02690", "submitter": "Yanwu Xu", "authors": "Mingming Gong, Yanwu Xu, Chunyuan Li, Kun Zhang, Kayhan Batmanghelich", "title": "Twin Auxiliary Classifiers GAN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional generative models enjoy remarkable progress over the past few\nyears. One of the popular conditional models is Auxiliary Classifier GAN\n(AC-GAN), which generates highly discriminative images by extending the loss\nfunction of GAN with an auxiliary classifier. However, the diversity of the\ngenerated samples by AC-GAN tends to decrease as the number of classes\nincreases, hence limiting its power on large-scale data. In this paper, we\nidentify the source of the low diversity issue theoretically and propose a\npractical solution to solve the problem. We show that the auxiliary classifier\nin AC-GAN imposes perfect separability, which is disadvantageous when the\nsupports of the class distributions have significant overlap. To address the\nissue, we propose Twin Auxiliary Classifiers Generative Adversarial Net\n(TAC-GAN) that further benefits from a new player that interacts with other\nplayers (the generator and the discriminator) in GAN. Theoretically, we\ndemonstrate that TAC-GAN can effectively minimize the divergence between the\ngenerated and real-data distributions. Extensive experimental results show that\nour TAC-GAN can successfully replicate the true data distributions on simulated\ndata, and significantly improves the diversity of class-conditional image\ngeneration on real datasets.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 06:29:06 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 03:04:06 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 05:14:12 GMT"}, {"version": "v4", "created": "Mon, 4 Nov 2019 20:30:21 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Gong", "Mingming", ""], ["Xu", "Yanwu", ""], ["Li", "Chunyuan", ""], ["Zhang", "Kun", ""], ["Batmanghelich", "Kayhan", ""]]}, {"id": "1907.02796", "submitter": "David Zimmerer", "authors": "David Zimmerer, Fabian Isensee, Jens Petersen, Simon Kohl, Klaus\n  Maier-Hein", "title": "Unsupervised Anomaly Localization using Variational Auto-Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An assumption-free automatic check of medical images for potentially overseen\nanomalies would be a valuable assistance for a radiologist. Deep learning and\nespecially Variational Auto-Encoders (VAEs) have shown great potential in the\nunsupervised learning of data distributions. In principle, this allows for such\na check and even the localization of parts in the image that are most\nsuspicious. Currently, however, the reconstruction-based localization by design\nrequires adjusting the model architecture to the specific problem looked at\nduring evaluation. This contradicts the principle of building assumption-free\nmodels. We propose complementing the localization part with a term derived from\nthe Kullback-Leibler (KL)-divergence. For validation, we perform a series of\nexperiments on FashionMNIST as well as on a medical task including >1000\nhealthy and >250 brain tumor patients. Results show that the proposed formalism\noutperforms the state of the art VAE-based localization of anomalies across\nmany hyperparameter settings and also shows a competitive max performance.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 13:03:29 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 09:55:21 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Zimmerer", "David", ""], ["Isensee", "Fabian", ""], ["Petersen", "Jens", ""], ["Kohl", "Simon", ""], ["Maier-Hein", "Klaus", ""]]}, {"id": "1907.02821", "submitter": "Lia Morra", "authors": "Lia Morra and Fabrizio Lamberti", "title": "Benchmarking unsupervised near-duplicate image detection", "comments": "Accepted for publication in Expert Systems with Applications", "journal-ref": "Expert Systems with Applications, online first, 2019", "doi": "10.1016/j.eswa.2019.05.002", "report-no": null, "categories": "cs.CV cs.CR cs.LG cs.MM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised near-duplicate detection has many practical applications ranging\nfrom social media analysis and web-scale retrieval, to digital image forensics.\nIt entails running a threshold-limited query on a set of descriptors extracted\nfrom the images, with the goal of identifying all possible near-duplicates,\nwhile limiting the false positives due to visually similar images. Since the\nrate of false alarms grows with the dataset size, a very high specificity is\nthus required, up to $1 - 10^{-9}$ for realistic use cases; this important\nrequirement, however, is often overlooked in literature. In recent years,\ndescriptors based on deep convolutional neural networks have matched or\nsurpassed traditional feature extraction methods in content-based image\nretrieval tasks. To the best of our knowledge, ours is the first attempt to\nestablish the performance range of deep learning-based descriptors for\nunsupervised near-duplicate detection on a range of datasets, encompassing a\nbroad spectrum of near-duplicate definitions. We leverage both established and\nnew benchmarks, such as the Mir-Flick Near-Duplicate (MFND) dataset, in which a\nknown ground truth is provided for all possible pairs over a general, large\nscale image collection. To compare the specificity of different descriptors, we\nreduce the problem of unsupervised detection to that of binary classification\nof near-duplicate vs. not-near-duplicate images. The latter can be conveniently\ncharacterized using Receiver Operating Curve (ROC). Our findings in general\nfavor the choice of fine-tuning deep convolutional networks, as opposed to\nusing off-the-shelf features, but differences at high specificity settings\ndepend on the dataset and are often small. The best performance was observed on\nthe MFND benchmark, achieving 96\\% sensitivity at a false positive rate of\n$1.43 \\times 10^{-6}$.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 09:08:47 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Morra", "Lia", ""], ["Lamberti", "Fabrizio", ""]]}, {"id": "1907.02844", "submitter": "Joshua Vogelstein", "authors": "Meghana Madhyastha, Percy Li, James Browne, Veronika Strnadova-Neeley,\n  Carey E. Priebe, Randal Burns, Joshua T. Vogelstein", "title": "Geodesic Learning via Unsupervised Decision Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geodesic distance is the shortest path between two points in a Riemannian\nmanifold. Manifold learning algorithms, such as Isomap, seek to learn a\nmanifold that preserves geodesic distances. However, such methods operate on\nthe ambient dimensionality, and are therefore fragile to noise dimensions. We\ndeveloped an unsupervised random forest method (URerF) to approximately learn\ngeodesic distances in linear and nonlinear manifolds with noise. URerF operates\non low-dimensional sparse linear combinations of features, rather than the full\nobserved dimensionality. To choose the optimal split in a computationally\nefficient fashion, we developed a fast Bayesian Information Criterion statistic\nfor Gaussian mixture models. We introduce geodesic precision-recall curves\nwhich quantify performance relative to the true latent manifold. Empirical\nresults on simulated and real data demonstrate that URerF is robust to\nhigh-dimensional noise, where as other methods, such as Isomap, UMAP, and\nFLANN, quickly deteriorate in such settings. In particular, URerF is able to\nestimate geodesic distances on a real connectome dataset better than other\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 14:15:07 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Madhyastha", "Meghana", ""], ["Li", "Percy", ""], ["Browne", "James", ""], ["Strnadova-Neeley", "Veronika", ""], ["Priebe", "Carey E.", ""], ["Burns", "Randal", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1907.02874", "submitter": "Oliver Richter", "authors": "Timo Bram, Gino Brunner, Oliver Richter, Roger Wattenhofer", "title": "Attentive Multi-Task Deep Reinforcement Learning", "comments": "Accepted as conference paper at ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharing knowledge between tasks is vital for efficient learning in a\nmulti-task setting. However, most research so far has focused on the easier\ncase where knowledge transfer is not harmful, i.e., where knowledge from one\ntask cannot negatively impact the performance on another task. In contrast, we\npresent an approach to multi-task deep reinforcement learning based on\nattention that does not require any a-priori assumptions about the\nrelationships between tasks. Our attention network automatically groups task\nknowledge into sub-networks on a state level granularity. It thereby achieves\npositive knowledge transfer if possible, and avoids negative transfer in cases\nwhere tasks interfere. We test our algorithm against two state-of-the-art\nmulti-task/transfer learning approaches and show comparable or superior\nperformance while requiring fewer network parameters.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 14:59:41 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Bram", "Timo", ""], ["Brunner", "Gino", ""], ["Richter", "Oliver", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1907.02882", "submitter": "Micha Pfeiffer", "authors": "Micha Pfeiffer, Isabel Funke, Maria R. Robu, Sebastian Bodenstedt,\n  Leon Strenger, Sandy Engelhardt, Tobias Ro{\\ss}, Matthew J. Clarkson,\n  Kurinchi Gurusamy, Brian R. Davidson, Lena Maier-Hein, Carina Riediger, Thilo\n  Welsch, J\\\"urgen Weitz and Stefanie Speidel", "title": "Generating large labeled data sets for laparoscopic image processing\n  tasks using unpaired image-to-image translation", "comments": "Accepted at MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the medical domain, the lack of large training data sets and benchmarks is\noften a limiting factor for training deep neural networks. In contrast to\nexpensive manual labeling, computer simulations can generate large and fully\nlabeled data sets with a minimum of manual effort. However, models that are\ntrained on simulated data usually do not translate well to real scenarios. To\nbridge the domain gap between simulated and real laparoscopic images, we\nexploit recent advances in unpaired image-to-image translation. We extent an\nimage-to-image translation method to generate a diverse multitude of\nrealistically looking synthetic images based on images from a simple\nlaparoscopy simulation. By incorporating means to ensure that the image content\nis preserved during the translation process, we ensure that the labels given\nfor the simulated images remain valid for their realistically looking\ntranslations. This way, we are able to generate a large, fully labeled\nsynthetic data set of laparoscopic images with realistic appearance. We show\nthat this data set can be used to train models for the task of liver\nsegmentation of laparoscopic images. We achieve average dice scores of up to\n0.89 in some patients without manually labeling a single laparoscopic image and\nshow that using our synthetic data to pre-train models can greatly improve\ntheir performance. The synthetic data set will be made publicly available,\nfully labeled with segmentation maps, depth maps, normal maps, and positions of\ntools and camera (http://opencas.dkfz.de/image2image).\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 15:10:20 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Pfeiffer", "Micha", ""], ["Funke", "Isabel", ""], ["Robu", "Maria R.", ""], ["Bodenstedt", "Sebastian", ""], ["Strenger", "Leon", ""], ["Engelhardt", "Sandy", ""], ["Ro\u00df", "Tobias", ""], ["Clarkson", "Matthew J.", ""], ["Gurusamy", "Kurinchi", ""], ["Davidson", "Brian R.", ""], ["Maier-Hein", "Lena", ""], ["Riediger", "Carina", ""], ["Welsch", "Thilo", ""], ["Weitz", "J\u00fcrgen", ""], ["Speidel", "Stefanie", ""]]}, {"id": "1907.02893", "submitter": "Martin Arjovsky", "authors": "Martin Arjovsky, L\\'eon Bottou, Ishaan Gulrajani, David Lopez-Paz", "title": "Invariant Risk Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Invariant Risk Minimization (IRM), a learning paradigm to\nestimate invariant correlations across multiple training distributions. To\nachieve this goal, IRM learns a data representation such that the optimal\nclassifier, on top of that data representation, matches for all training\ndistributions. Through theory and experiments, we show how the invariances\nlearned by IRM relate to the causal structures governing the data and enable\nout-of-distribution generalization.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 15:26:26 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 09:17:10 GMT"}, {"version": "v3", "created": "Fri, 27 Mar 2020 19:07:58 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Arjovsky", "Martin", ""], ["Bottou", "L\u00e9on", ""], ["Gulrajani", "Ishaan", ""], ["Lopez-Paz", "David", ""]]}, {"id": "1907.02907", "submitter": "Jianmei Luo", "authors": "Jianmei Luo, ChandraVyas Annakula, Aruna Sai Kannamareddy, Jasjeet S.\n  Sekhon, William Henry Hsu, Michael Higgins", "title": "Hybridized Threshold Clustering for Massive Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the size $n$ of datasets become massive, many commonly-used clustering\nalgorithms (for example, $k$-means or hierarchical agglomerative clustering\n(HAC) require prohibitive computational cost and memory. In this paper, we\npropose a solution to these clustering problems by extending threshold\nclustering (TC) to problems of instance selection. TC is a recently developed\nclustering algorithm designed to partition data into many small clusters in\nlinearithmic time (on average). Our proposed clustering method is as follows.\nFirst, TC is performed and clusters are reduced into single \"prototype\" points.\nThen, TC is applied repeatedly on these prototype points until sufficient data\nreduction has been obtained. Finally, a more sophisticated clustering algorithm\nis applied to the reduced prototype points, thereby obtaining a clustering on\nall $n$ data points. This entire procedure for clustering is called iterative\nhybridized threshold clustering (IHTC). Through simulation results and by\napplying our methodology on several real datasets, we show that IHTC combined\nwith $k$-means or HAC substantially reduces the run time and memory usage of\nthe original clustering algorithms while still preserving their performance.\nAdditionally, IHTC helps prevent singular data points from being overfit by\nclustering algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 16:10:57 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Luo", "Jianmei", ""], ["Annakula", "ChandraVyas", ""], ["Kannamareddy", "Aruna Sai", ""], ["Sekhon", "Jasjeet S.", ""], ["Hsu", "William Henry", ""], ["Higgins", "Michael", ""]]}, {"id": "1907.02908", "submitter": "Matteo Hessel", "authors": "Matteo Hessel, Hado van Hasselt, Joseph Modayil, David Silver", "title": "On Inductive Biases in Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many deep reinforcement learning algorithms contain inductive biases that\nsculpt the agent's objective and its interface to the environment. These\ninductive biases can take many forms, including domain knowledge and pretuned\nhyper-parameters. In general, there is a trade-off between generality and\nperformance when algorithms use such biases. Stronger biases can lead to faster\nlearning, but weaker biases can potentially lead to more general algorithms.\nThis trade-off is important because inductive biases are not free; substantial\neffort may be required to obtain relevant domain knowledge or to tune\nhyper-parameters effectively. In this paper, we re-examine several\ndomain-specific components that bias the objective and the environmental\ninterface of common deep reinforcement learning agents. We investigated whether\nthe performance deteriorates when these components are replaced with adaptive\nsolutions from the literature. In our experiments, performance sometimes\ndecreased with the adaptive components, as one might expect when comparing to\ncomponents crafted for the domain, but sometimes the adaptive components\nperformed better. We investigated the main benefit of having fewer\ndomain-specific components, by comparing the learning performance of the two\nsystems on a different set of continuous control problems, without additional\ntuning of either system. As hypothesized, the system with adaptive components\nperformed better on many of the new tasks.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 16:14:55 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Hessel", "Matteo", ""], ["van Hasselt", "Hado", ""], ["Modayil", "Joseph", ""], ["Silver", "David", ""]]}, {"id": "1907.02911", "submitter": "Berfin Simsek Mrs.", "authors": "Johanni Brea, Berfin Simsek, Bernd Illing and Wulfram Gerstner", "title": "Weight-space symmetry in deep networks gives rise to permutation\n  saddles, connected by equal-loss valleys across the loss landscape", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The permutation symmetry of neurons in each layer of a deep neural network\ngives rise not only to multiple equivalent global minima of the loss function,\nbut also to first-order saddle points located on the path between the global\nminima. In a network of $d-1$ hidden layers with $n_k$ neurons in layers $k =\n1, \\ldots, d$, we construct smooth paths between equivalent global minima that\nlead through a `permutation point' where the input and output weight vectors of\ntwo neurons in the same hidden layer $k$ collide and interchange. We show that\nsuch permutation points are critical points with at least $n_{k+1}$ vanishing\neigenvalues of the Hessian matrix of second derivatives indicating a local\nplateau of the loss function. We find that a permutation point for the exchange\nof neurons $i$ and $j$ transits into a flat valley (or generally, an extended\nplateau of $n_{k+1}$ flat dimensions) that enables all $n_k!$ permutations of\nneurons in a given layer $k$ at the same loss value. Moreover, we introduce\nhigh-order permutation points by exploiting the recursive structure in neural\nnetwork functions, and find that the number of $K^{\\text{th}}$-order\npermutation points is at least by a factor\n$\\sum_{k=1}^{d-1}\\frac{1}{2!^K}{n_k-K \\choose K}$ larger than the (already\nhuge) number of equivalent global minima. In two tasks, we illustrate\nnumerically that some of the permutation points correspond to first-order\nsaddles (`permutation saddles'): first, in a toy network with a single hidden\nlayer on a function approximation task and, second, in a multilayer network on\nthe MNIST task. Our geometric approach yields a lower bound on the number of\ncritical points generated by weight-space symmetries and provides a simple\nintuitive link between previous mathematical results and numerical\nobservations.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 16:17:01 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Brea", "Johanni", ""], ["Simsek", "Berfin", ""], ["Illing", "Bernd", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "1907.02936", "submitter": "Vasiliki Liakoni", "authors": "Vasiliki Liakoni, Alireza Modirshanechi, Wulfram Gerstner, Johanni\n  Brea", "title": "Learning in Volatile Environments with the Bayes Factor Surprise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surprise-based learning allows agents to rapidly adapt to non-stationary\nstochastic environments characterized by sudden changes. We show that exact\nBayesian inference in a hierarchical model gives rise to a surprise-modulated\ntrade-off between forgetting old observations and integrating them with the new\nones. The modulation depends on a probability ratio, which we call \"Bayes\nFactor Surprise\", that tests the prior belief against the current belief. We\ndemonstrate that in several existing approximate algorithms the Bayes Factor\nSurprise modulates the rate of adaptation to new observations. We derive three\nnovel surprised-based algorithms, one in the family of particle filters, one in\nthe family of variational learning, and the other in the family of message\npassing, that have constant scaling in observation sequence length and\nparticularly simple update dynamics for any distribution in the exponential\nfamily. Empirical results show that these surprise-based algorithms estimate\nparameters better than alternative approximate approaches and reach levels of\nperformance comparable to computationally more expensive algorithms. The Bayes\nFactor Surprise is related to but different from Shannon Surprise. In two\nhypothetical experiments, we make testable predictions for physiological\nindicators that dissociate the Bayes Factor Surprise from Shannon Surprise. The\ntheoretical insight of casting various approaches as surprise-based learning,\nas well as the proposed online algorithms, may be applied to the analysis of\nanimal and human behavior, and to reinforcement learning in non-stationary\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 17:07:18 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 13:50:28 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2020 19:55:12 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Liakoni", "Vasiliki", ""], ["Modirshanechi", "Alireza", ""], ["Gerstner", "Wulfram", ""], ["Brea", "Johanni", ""]]}, {"id": "1907.02940", "submitter": "Jae Seo", "authors": "Jae Duk Seo", "title": "Visualizing Uncertainty and Saliency Maps of Deep Convolutional Neural\n  Networks for Medical Imaging Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are now used in many different industries, while in\ncertain domains safety is not a critical issue in the medical field it is a\nhuge concern. Not only, we want the models to generalize well but we also want\nto know the models confidence respect to its decision and which features matter\nthe most. Our team aims to develop a full pipeline in which not only displays\nthe uncertainty of the models decision but also, the saliency map to show which\nsets of pixels of the input image contribute most to the predictions.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 17:23:04 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Seo", "Jae Duk", ""]]}, {"id": "1907.02957", "submitter": "Yao Qin", "authors": "Yao Qin, Nicholas Frosst, Sara Sabour, Colin Raffel, Garrison Cottrell\n  and Geoffrey Hinton", "title": "Detecting and Diagnosing Adversarial Images with Class-Conditional\n  Capsule Reconstructions", "comments": null, "journal-ref": "ICLR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples raise questions about whether neural network models are\nsensitive to the same visual features as humans. In this paper, we first detect\nadversarial examples or otherwise corrupted images based on a class-conditional\nreconstruction of the input. To specifically attack our detection mechanism, we\npropose the Reconstructive Attack which seeks both to cause a misclassification\nand a low reconstruction error. This reconstructive attack produces undetected\nadversarial examples but with much smaller success rate. Among all these\nattacks, we find that CapsNets always perform better than convolutional\nnetworks. Then, we diagnose the adversarial examples for CapsNets and find that\nthe success of the reconstructive attack is highly related to the visual\nsimilarity between the source and target class. Additionally, the resulting\nperturbations can cause the input image to appear visually more like the target\nclass and hence become non-adversarial. This suggests that CapsNets use\nfeatures that are more aligned with human perception and have the potential to\naddress the central issue raised by adversarial examples.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 17:57:57 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 05:05:45 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Qin", "Yao", ""], ["Frosst", "Nicholas", ""], ["Sabour", "Sara", ""], ["Raffel", "Colin", ""], ["Cottrell", "Garrison", ""], ["Hinton", "Geoffrey", ""]]}, {"id": "1907.02998", "submitter": "Srinivas Venkattaramanujam", "authors": "Srinivas Venkattaramanujam, Eric Crawford, Thang Doan and Doina Precup", "title": "Self-supervised Learning of Distance Functions for Goal-Conditioned\n  Reinforcement Learning", "comments": "Preprint; Under Review (updated)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-conditioned policies are used in order to break down complex\nreinforcement learning (RL) problems by using subgoals, which can be defined\neither in state space or in a latent feature space. This can increase the\nefficiency of learning by using a curriculum, and also enables simultaneous\nlearning and generalization across goals. A crucial requirement of\ngoal-conditioned policies is to be able to determine whether the goal has been\nachieved. Having a notion of distance to a goal is thus a crucial component of\nthis approach. However, it is not straightforward to come up with an\nappropriate distance, and in some tasks, the goal space may not even be known a\npriori. In this work we learn a distance-to-goal estimate which is computed in\nterms of the number of actions that would need to be carried out in a\nself-supervised approach. Our method solves complex tasks without prior domain\nknowledge in the online setting in three different scenarios in the context of\ngoal-conditioned policies a) the goal space is the same as the state space b)\nthe goal space is given but an appropriate distance is unknown and c) the state\nspace is accessible, but only a subset of the state space represents desired\ngoals, and this subset is known a priori. We also propose a goal-generation\nmechanism as a secondary contribution.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 19:00:14 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2020 15:42:15 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Venkattaramanujam", "Srinivas", ""], ["Crawford", "Eric", ""], ["Doan", "Thang", ""], ["Precup", "Doina", ""]]}, {"id": "1907.03010", "submitter": "Fabrice Daniel", "authors": "Fabrice Daniel", "title": "Financial Time Series Data Processing for Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article studies the financial time series data processing for machine\nlearning. It introduces the most frequent scaling methods, then compares the\nresulting stationarity and preservation of useful information for trend\nforecasting. It proposes an empirical test based on the capability to learn\nsimple data relationship with simple models. It also speaks about the data\nsplit method specific to time series, avoiding unwanted overfitting and\nproposes various labelling for classification and regression.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:10:23 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Daniel", "Fabrice", ""]]}, {"id": "1907.03043", "submitter": "Feng Yin", "authors": "Yuxin Zhao and Feng Yin and Fredrik Gunnarsson and Fredrik Hultkrantz", "title": "Gaussian Processes for Analyzing Positioned Trajectories in Sports", "comments": "31pages, 28 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel-based machine learning approaches are gaining increasing interest for\nexploring and modeling large dataset in recent years. Gaussian process (GP) is\none example of such kernel-based approaches, which can provide very good\nperformance for nonlinear modeling problems. In this work, we first propose a\ngrey-box modeling approach to analyze the forces in cross country skiing races.\nTo be more precise, a disciplined set of kinetic motion model formulae is\ncombined with data-driven Gaussian process regression model, which accounts for\neverything unknown in the system. Then, a modeling approach is proposed to\nanalyze the kinetic flow of both individual and clusters of skiers. The\nproposed approaches can be generally applied to use cases where positioned\ntrajectories and kinetic measurements are available. The proposed approaches\nare evaluated using data collected from the Falun Nordic World Ski\nChampionships 2015, in particular the Men's cross country $4\\times10$ km relay.\nForces during the cross country skiing races are analyzed and compared.\nVelocity models for skiers at different competition stages are also evaluated.\nFinally, the comparisons between the grey-box and black-box approach are\ncarried out, where the grey-box approach can reduce the predictive uncertainty\nby $30\\%$ to $40\\%$.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 23:00:44 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Zhao", "Yuxin", ""], ["Yin", "Feng", ""], ["Gunnarsson", "Fredrik", ""], ["Hultkrantz", "Fredrik", ""]]}, {"id": "1907.03050", "submitter": "Soheil Khorram", "authors": "Soheil Khorram, Melvin G McInnis, Emily Mower Provost", "title": "Jointly Aligning and Predicting Continuous Emotion Annotations", "comments": "IEEE Transactions on Affective Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-continuous dimensional descriptions of emotions (e.g., arousal, valence)\nallow researchers to characterize short-time changes and to capture long-term\ntrends in emotion expression. However, continuous emotion labels are generally\nnot synchronized with the input speech signal due to delays caused by\nreaction-time, which is inherent in human evaluations. To deal with this\nchallenge, we introduce a new convolutional neural network (multi-delay sinc\nnetwork) that is able to simultaneously align and predict labels in an\nend-to-end manner. The proposed network is a stack of convolutional layers\nfollowed by an aligner network that aligns the speech signal and emotion\nlabels. This network is implemented using a new convolutional layer that we\nintroduce, the delayed sinc layer. It is a time-shifted low-pass (sinc) filter\nthat uses a gradient-based algorithm to learn a single delay. Multiple delayed\nsinc layers can be used to compensate for a non-stationary delay that is a\nfunction of the acoustic space. We test the efficacy of this system on two\ncommon emotion datasets, RECOLA and SEWA, and show that this approach obtains\nstate-of-the-art speech-only results by learning time-varying delays while\npredicting dimensional descriptors of emotions.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 23:49:49 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 22:40:43 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Khorram", "Soheil", ""], ["McInnis", "Melvin G", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1907.03053", "submitter": "Ji Liu", "authors": "Yixuan Lin, Kaiqing Zhang, Zhuoran Yang, Zhaoran Wang, Tamer\n  Ba\\c{s}ar, Romeil Sandhu, Ji Liu", "title": "A Communication-Efficient Multi-Agent Actor-Critic Algorithm for\n  Distributed Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a distributed reinforcement learning problem in which a\nnetwork of multiple agents aim to cooperatively maximize the globally averaged\nreturn through communication with only local neighbors. A randomized\ncommunication-efficient multi-agent actor-critic algorithm is proposed for\npossibly unidirectional communication relationships depicted by a directed\ngraph. It is shown that the algorithm can solve the problem for strongly\nconnected graphs by allowing each agent to transmit only two scalar-valued\nvariables at one time.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 00:20:50 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Lin", "Yixuan", ""], ["Zhang", "Kaiqing", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Ba\u015far", "Tamer", ""], ["Sandhu", "Romeil", ""], ["Liu", "Ji", ""]]}, {"id": "1907.03077", "submitter": "Shusen Liu", "authors": "Shusen Liu, Bhavya Kailkhura, Donald Loveland, Yong Han", "title": "Generative Counterfactual Introspection for Explainable Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose an introspection technique for deep neural networks\nthat relies on a generative model to instigate salient editing of the input\nimage for model interpretation. Such modification provides the fundamental\ninterventional operation that allows us to obtain answers to counterfactual\ninquiries, i.e., what meaningful change can be made to the input image in order\nto alter the prediction. We demonstrate how to reveal interesting properties of\nthe given classifiers by utilizing the proposed introspection approach on both\nthe MNIST and the CelebA dataset.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 04:30:13 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Liu", "Shusen", ""], ["Kailkhura", "Bhavya", ""], ["Loveland", "Donald", ""], ["Han", "Yong", ""]]}, {"id": "1907.03087", "submitter": "Ankit Pensia", "authors": "Ankit Pensia, Varun Jog, Po-Ling Loh", "title": "Estimating location parameters in entangled single-sample distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT cs.LG math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the common mean of independently\nsampled data, where samples are drawn in a possibly non-identical manner from\nsymmetric, unimodal distributions with a common mean. This generalizes the\nsetting of Gaussian mixture modeling, since the number of distinct mixture\ncomponents may diverge with the number of observations. We propose an estimator\nthat adapts to the level of heterogeneity in the data, achieving\nnear-optimality in both the i.i.d. setting and some heterogeneous settings,\nwhere the fraction of ``low-noise'' points is as small as $\\frac{\\log n}{n}$.\nOur estimator is a hybrid of the modal interval, shorth, and median estimators\nfrom classical statistics; however, the key technical contributions rely on\nnovel empirical process theory results that we derive for independent but\nnon-i.i.d. data. In the multivariate setting, we generalize our theory to mean\nestimation for mixtures of radially symmetric distributions, and derive minimax\nlower bounds on the expected error of any estimator that is agnostic to the\nscales of individual data points. Finally, we describe an extension of our\nestimators applicable to linear regression. In the multivariate mean estimation\nand regression settings, we present computationally feasible versions of our\nestimators that run in time polynomial in the number of data points.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 06:39:25 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Pensia", "Ankit", ""], ["Jog", "Varun", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1907.03100", "submitter": "Reinhard Heckel", "authors": "Reinhard Heckel", "title": "Regularizing linear inverse problems with convolutional neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks trained on large datsets have emerged as\nan intriguing alternative for compressing images and solving inverse problems\nsuch as denoising and compressive sensing. However, it has only recently been\nrealized that even without training, convolutional networks can function as\nconcise image models, and thus regularize inverse problems. In this paper, we\nprovide further evidence for this finding by studying variations of\nconvolutional neural networks that map few weight parameters to an image. The\nnetworks we consider only consist of convolutional operations, with either\nfixed or parameterized filters followed by ReLU non-linearities. We demonstrate\nthat with both fixed and parameterized convolutional filters those networks\nenable representing images with few coefficients. What is more, the\nunderparameterization enables regularization of inverse problems, in particular\nrecovering an image from few observations. We show that, similar to standard\ncompressive sensing guarantees, on the order of the number of model parameters\nmany measurements suffice for recovering an image from compressive\nmeasurements. Finally, we demonstrate that signal recovery with a un-trained\nconvolutional network outperforms standard l1 and total variation minimization\nfor magnetic resonance imaging (MRI).\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 09:30:51 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Heckel", "Reinhard", ""]]}, {"id": "1907.03103", "submitter": "Vasisht Duddu", "authors": "Vasisht Duddu, D. Vijay Rao, Valentina E. Balas", "title": "Towards Enhancing Fault Tolerance in Neural Networks", "comments": "MobiQuitous 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning Accelerators are prone to faults which manifest in the form of\nerrors in Neural Networks. Fault Tolerance in Neural Networks is crucial in\nreal-time safety critical applications requiring computation for long\ndurations. Neural Networks with high regularisation exhibit superior fault\ntolerance, however, at the cost of classification accuracy. In the view of\ndifference in functionality, a Neural Network is modelled as two separate\nnetworks, i.e, the Feature Extractor with unsupervised learning objective and\nthe Classifier with a supervised learning objective. Traditional approaches of\ntraining the entire network using a single supervised learning objective is\ninsufficient to achieve the objectives of the individual components optimally.\nIn this work, a novel multi-criteria objective function, combining unsupervised\ntraining of the Feature Extractor followed by supervised tuning with Classifier\nNetwork is proposed. The unsupervised training solves two games simultaneously\nin the presence of adversary neural networks with conflicting objectives to the\nFeature Extractor. The first game minimises the loss in reconstructing the\ninput image for indistinguishability given the features from the Extractor, in\nthe presence of a generative decoder. The second game solves a minimax\nconstraint optimisation for distributional smoothening of feature space to\nmatch a prior distribution, in the presence of a Discriminator network. The\nresultant strongly regularised Feature Extractor is combined with the\nClassifier Network for supervised fine-tuning. The proposed Adversarial Fault\nTolerant Neural Network Training is scalable to large networks and is\nindependent of the architecture. The evaluation on benchmarking datasets:\nFashionMNIST and CIFAR10, indicates that the resultant networks have high\naccuracy with superior tolerance to stuck at \"0\" faults compared to widely used\nregularisers.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 09:39:26 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2019 05:37:21 GMT"}, {"version": "v3", "created": "Sun, 30 May 2021 03:31:58 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Duddu", "Vasisht", ""], ["Rao", "D. Vijay", ""], ["Balas", "Valentina E.", ""]]}, {"id": "1907.03116", "submitter": "Sungeui Yoon", "authors": "JaeWon Choi, Sung-eui Yoon", "title": "Intrinsic Motivation Driven Intuitive Physics Learning using Deep\n  Reinforcement Learning with Intrinsic Reward Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At an early age, human infants are able to learn and build a model of the\nworld very quickly by constantly observing and interacting with objects around\nthem. One of the most fundamental intuitions human infants acquire is intuitive\nphysics. Human infants learn and develop these models, which later serve as\nprior knowledge for further learning. Inspired by such behaviors exhibited by\nhuman infants, we introduce a graphical physics network integrated with deep\nreinforcement learning. Specifically, we introduce an intrinsic reward\nnormalization method that allows our agent to efficiently choose actions that\ncan improve its intuitive physics model the most.\n  Using a 3D physics engine, we show that our graphical physics network is able\nto infer object's positions and velocities very effectively, and our deep\nreinforcement learning network encourages an agent to improve its model by\nmaking it continuously interact with objects only using intrinsic motivation.\nWe experiment our model in both stationary and non-stationary state problems\nand show benefits of our approach in terms of the number of different actions\nthe agent performs and the accuracy of agent's intuition model.\n  Videos are at https://www.youtube.com/watch?v=pDbByp91r3M&t=2s\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 11:08:17 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Choi", "JaeWon", ""], ["Yoon", "Sung-eui", ""]]}, {"id": "1907.03122", "submitter": "Bicky Marquez", "authors": "Bicky A. Marquez, Jose Suarez-Vargas, Bhavin J. Shastri", "title": "Takens-inspired neuromorphic processor: a downsizing tool for random\n  recurrent neural networks via feature extraction", "comments": "12 pages, 8 figures", "journal-ref": "Phys. Rev. Research 1, 033030 (2019)", "doi": "10.1103/PhysRevResearch.1.033030", "report-no": null, "categories": "cs.NE cs.LG nlin.CD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new technique which minimizes the amount of neurons in the\nhidden layer of a random recurrent neural network (rRNN) for time series\nprediction. Merging Takens-based attractor reconstruction methods with machine\nlearning, we identify a mechanism for feature extraction that can be leveraged\nto lower the network size. We obtain criteria specific to the particular\nprediction task and derive the scaling law of the prediction error. The\nconsequences of our theory are demonstrated by designing a Takens-inspired\nhybrid processor, which extends a rRNN with a priori designed delay external\nmemory. Our hybrid architecture is therefore designed including both, real and\nvirtual nodes. Via this symbiosis, we show performance of the hybrid processor\nby stabilizing an arrhythmic neural model. Thanks to our obtained design rules,\nwe can reduce the stabilizing neural network's size by a factor of 15 with\nrespect to a standard system.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 12:10:25 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Marquez", "Bicky A.", ""], ["Suarez-Vargas", "Jose", ""], ["Shastri", "Bhavin J.", ""]]}, {"id": "1907.03141", "submitter": "Ning Liu", "authors": "Ning Liu and Xiaolong Ma and Zhiyuan Xu and Yanzhi Wang and Jian Tang\n  and Jieping Ye", "title": "AutoCompress: An Automatic DNN Structured Pruning Framework for\n  Ultra-High Compression Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structured weight pruning is a representative model compression technique of\nDNNs to reduce the storage and computation requirements and accelerate\ninference. An automatic hyperparameter determination process is necessary due\nto the large number of flexible hyperparameters. This work proposes\nAutoCompress, an automatic structured pruning framework with the following key\nperformance improvements: (i) effectively incorporate the combination of\nstructured pruning schemes in the automatic process; (ii) adopt the\nstate-of-art ADMM-based structured weight pruning as the core algorithm, and\npropose an innovative additional purification step for further weight reduction\nwithout accuracy loss; and (iii) develop effective heuristic search method\nenhanced by experience-based guided search, replacing the prior deep\nreinforcement learning technique which has underlying incompatibility with the\ntarget pruning problem. Extensive experiments on CIFAR-10 and ImageNet datasets\ndemonstrate that AutoCompress is the key to achieve ultra-high pruning rates on\nthe number of weights and FLOPs that cannot be achieved before. As an example,\nAutoCompress outperforms the prior work on automatic model compression by up to\n33x in pruning rate (120x reduction in the actual parameter count) under the\nsame accuracy. Significant inference speedup has been observed from the\nAutoCompress framework on actual measurements on smartphone. We release all\nmodels of this work at anonymous link: http://bit.ly/2VZ63dS.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 15:40:02 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 12:15:38 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Liu", "Ning", ""], ["Ma", "Xiaolong", ""], ["Xu", "Zhiyuan", ""], ["Wang", "Yanzhi", ""], ["Tang", "Jian", ""], ["Ye", "Jieping", ""]]}, {"id": "1907.03143", "submitter": "Seyed Mehran Kazemi", "authors": "Rishab Goel, Seyed Mehran Kazemi, Marcus Brubaker, Pascal Poupart", "title": "Diachronic Embedding for Temporal Knowledge Graph Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge graphs (KGs) typically contain temporal facts indicating\nrelationships among entities at different times. Due to their incompleteness,\nseveral approaches have been proposed to infer new facts for a KG based on the\nexisting ones-a problem known as KG completion. KG embedding approaches have\nproved effective for KG completion, however, they have been developed mostly\nfor static KGs. Developing temporal KG embedding models is an increasingly\nimportant problem. In this paper, we build novel models for temporal KG\ncompletion through equipping static models with a diachronic entity embedding\nfunction which provides the characteristics of entities at any point in time.\nThis is in contrast to the existing temporal KG embedding approaches where only\nstatic entity features are provided. The proposed embedding function is\nmodel-agnostic and can be potentially combined with any static model. We prove\nthat combining it with SimplE, a recent model for static KG embedding, results\nin a fully expressive model for temporal KG completion. Our experiments\nindicate the superiority of our proposal compared to existing baselines.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 15:51:29 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Goel", "Rishab", ""], ["Kazemi", "Seyed Mehran", ""], ["Brubaker", "Marcus", ""], ["Poupart", "Pascal", ""]]}, {"id": "1907.03149", "submitter": "Nathaniel Bastian PhD", "authors": "Sean M. Devine and Nathaniel D. Bastian", "title": "Intelligent Systems Design for Malware Classification Under Adversarial\n  Conditions", "comments": "21 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of machine learning and intelligent systems has become an established\npractice in the realm of malware detection and cyber threat prevention. In an\nenvironment characterized by widespread accessibility and big data, the\nfeasibility of malware classification without the use of artificial\nintelligence-based techniques has been diminished exponentially. Also\ncharacteristic of the contemporary realm of automated, intelligent malware\ndetection is the threat of adversarial machine learning. Adversaries are\nlooking to target the underlying data and/or algorithm responsible for the\nfunctionality of malware classification to map its behavior or corrupt its\nfunctionality. The ends of such adversaries are bypassing the cyber security\nmeasures and increasing malware effectiveness. The focus of this research is\nthe design of an intelligent systems approach using machine learning that can\naccurately and robustly classify malware under adversarial conditions. Such an\noutcome ultimately relies on increased flexibility and adaptability to build a\nmodel robust enough to identify attacks on the underlying algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 16:10:02 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Devine", "Sean M.", ""], ["Bastian", "Nathaniel D.", ""]]}, {"id": "1907.03164", "submitter": "Bilal Soomro", "authors": "Bilal Soomro, Anssi Kanervisto, Trung Ngo Trong, Ville Hautam\\\"aki", "title": "Towards Debugging Deep Neural Networks by Generating Speech Utterances", "comments": "Accepted to Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNN) are able to successfully process and classify\nspeech utterances. However, understanding the reason behind a classification by\nDNN is difficult. One such debugging method used with image classification DNNs\nis activation maximization, which generates example-images that are classified\nas one of the classes. In this work, we evaluate applicability of this method\nto speech utterance classifiers as the means to understanding what DNN \"listens\nto\". We trained a classifier using the speech command corpus and then use\nactivation maximization to pull samples from the trained model. Then we\nsynthesize audio from features using WaveNet vocoder for subjective analysis.\nWe measure the quality of generated samples by objective measurements and\ncrowd-sourced human evaluations. Results show that when combined with the prior\nof natural speech, activation maximization can be used to generate examples of\ndifferent classes. Based on these results, activation maximization can be used\nto start opening up the DNN black-box in speech tasks.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 18:19:32 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Soomro", "Bilal", ""], ["Kanervisto", "Anssi", ""], ["Trong", "Trung Ngo", ""], ["Hautam\u00e4ki", "Ville", ""]]}, {"id": "1907.03167", "submitter": "Jingcheng Du", "authors": "Jingcheng Du, Chongliang Luo, Qiang Wei, Yong Chen, Cui Tao", "title": "Exploring difference in public perceptions on HPV vaccine between gender\n  groups from Twitter using deep learning", "comments": "This manuscript has been accepted by 2019 KDD Workshop on Applied\n  Data Science for Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we proposed a convolutional neural network model for gender\nprediction using English Twitter text as input. Ensemble of proposed model\nachieved an accuracy at 0.8237 on gender prediction and compared favorably with\nthe state-of-the-art performance in a recent author profiling task. We further\nleveraged the trained models to predict the gender labels from an HPV vaccine\nrelated corpus and identified gender difference in public perceptions regarding\nHPV vaccine. The findings are largely consistent with previous survey-based\nstudies.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 18:58:54 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Du", "Jingcheng", ""], ["Luo", "Chongliang", ""], ["Wei", "Qiang", ""], ["Chen", "Yong", ""], ["Tao", "Cui", ""]]}, {"id": "1907.03178", "submitter": "Alexander M\\\"arz", "authors": "Alexander M\\\"arz", "title": "XGBoostLSS -- An extension of XGBoost to probabilistic forecasting", "comments": "Bayesian Optimization; Distributional Modeling; Expectile Regression;\n  GAMLSS; Probabilistic Forecast; Uncertainty Quantification; XGBoost", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework of XGBoost that predicts the entire conditional\ndistribution of a univariate response variable. In particular, XGBoostLSS\nmodels all moments of a parametric distribution (i.e., mean, location, scale\nand shape [LSS]) instead of the conditional mean only. Choosing from a wide\nrange of continuous, discrete and mixed discrete-continuous distribution,\nmodelling and predicting the entire conditional distribution greatly enhances\nthe flexibility of XGBoost, as it allows to gain additional insight into the\ndata generating process, as well as to create probabilistic forecasts from\nwhich prediction intervals and quantiles of interest can be derived. We present\nboth a simulation study and real world examples that demonstrate the virtues of\nour approach.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 20:25:16 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 10:32:31 GMT"}, {"version": "v3", "created": "Sun, 11 Aug 2019 09:16:42 GMT"}, {"version": "v4", "created": "Sun, 25 Aug 2019 09:30:15 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["M\u00e4rz", "Alexander", ""]]}, {"id": "1907.03179", "submitter": "Meng Qu", "authors": "Meng Qu, Jian Tang, Yoshua Bengio", "title": "Weakly-supervised Knowledge Graph Alignment with Adversarial Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies aligning knowledge graphs from different sources or\nlanguages. Most existing methods train supervised methods for the alignment,\nwhich usually require a large number of aligned knowledge triplets. However,\nsuch a large number of aligned knowledge triplets may not be available or are\nexpensive to obtain in many domains. Therefore, in this paper we propose to\nstudy aligning knowledge graphs in fully-unsupervised or weakly-supervised\nfashion, i.e., without or with only a few aligned triplets. We propose an\nunsupervised framework to align the entity and relation embddings of different\nknowledge graphs with an adversarial learning framework. Moreover, a\nregularization term which maximizes the mutual information between the\nembeddings of different knowledge graphs is used to mitigate the problem of\nmode collapse when learning the alignment functions. Such a framework can be\nfurther seamlessly integrated with existing supervised methods by utilizing a\nlimited number of aligned triples as guidance. Experimental results on multiple\ndatasets prove the effectiveness of our proposed approach in both the\nunsupervised and the weakly-supervised settings.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 20:31:13 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Qu", "Meng", ""], ["Tang", "Jian", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1907.03182", "submitter": "Maryam Aliakbarpour", "authors": "Maryam Aliakbarpour, Themis Gouleakis, John Peebles, Ronitt Rubinfeld,\n  Anak Yodpinyanee", "title": "Towards Testing Monotonicity of Distributions Over General Posets", "comments": "Appeared in COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the sample complexity required for testing the\nmonotonicity of distributions over partial orders. A distribution $p$ over a\nposet is monotone if, for any pair of domain elements $x$ and $y$ such that $x\n\\preceq y$, $p(x) \\leq p(y)$. To understand the sample complexity of this\nproblem, we introduce a new property called bigness over a finite domain, where\nthe distribution is $T$-big if the minimum probability for any domain element\nis at least $T$. We establish a lower bound of $\\Omega(n/\\log n)$ for testing\nbigness of distributions on domains of size $n$. We then build on these lower\nbounds to give $\\Omega(n/\\log{n})$ lower bounds for testing monotonicity over a\nmatching poset of size $n$ and significantly improved lower bounds over the\nhypercube poset. We give sublinear sample complexity bounds for testing bigness\nand for testing monotonicity over the matching poset.\n  We then give a number of tools for analyzing upper bounds on the sample\ncomplexity of\n  the monotonicity testing problem.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 20:45:01 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Aliakbarpour", "Maryam", ""], ["Gouleakis", "Themis", ""], ["Peebles", "John", ""], ["Rubinfeld", "Ronitt", ""], ["Yodpinyanee", "Anak", ""]]}, {"id": "1907.03190", "submitter": "Maryam Aliakbarpour", "authors": "Maryam Aliakbarpour, Ravi Kumar, Ronitt Rubinfeld", "title": "Testing Mixtures of Discrete Distributions", "comments": "Appeared in COLT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been significant study on the sample complexity of testing\nproperties of distributions over large domains. For many properties, it is\nknown that the sample complexity can be substantially smaller than the domain\nsize. For example, over a domain of size $n$, distinguishing the uniform\ndistribution from distributions that are far from uniform in $\\ell_1$-distance\nuses only $O(\\sqrt{n})$ samples.\n  However, the picture is very different in the presence of arbitrary noise,\neven when the amount of noise is quite small. In this case, one must\ndistinguish if samples are coming from a distribution that is $\\epsilon$-close\nto uniform from the case where the distribution is $(1-\\epsilon)$-far from\nuniform. The latter task requires nearly linear in $n$ samples [Valiant 2008,\nValian and Valiant 2011].\n  In this work, we present a noise model that on one hand is more tractable for\nthe testing problem, and on the other hand represents a rich class of noise\nfamilies. In our model, the noisy distribution is a mixture of the original\ndistribution and noise, where the latter is known to the tester either\nexplicitly or via sample access; the form of the noise is also known a priori.\nFocusing on the identity and closeness testing problems leads to the following\nmixture testing question: Given samples of distributions $p, q_1,q_2$, can we\ntest if $p$ is a mixture of $q_1$ and $q_2$? We consider this general question\nin various scenarios that differ in terms of how the tester can access the\ndistributions, and show that indeed this problem is more tractable. Our results\nshow that the sample complexity of our testers are exactly the same as for the\nclassical non-mixture case.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 21:24:54 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Aliakbarpour", "Maryam", ""], ["Kumar", "Ravi", ""], ["Rubinfeld", "Ronitt", ""]]}, {"id": "1907.03192", "submitter": "Gilles Blanchard", "authors": "Franziska G\\\"obel and Gilles Blanchard", "title": "Volume Doubling Condition and a Local Poincar\\'e Inequality on\n  Unweighted Random Geometric Graphs", "comments": "Only updated acknowlegements wrt. version 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to establish two fundamental measure-metric\nproperties of particular random geometric graphs. We consider\n$\\varepsilon$-neighborhood graphs whose vertices are drawn independently and\nidentically distributed from a common distribution defined on a regular\nsubmanifold of $\\mathbb{R}^K$. We show that a volume doubling condition (VD)\nand local Poincar\\'e inequality (LPI) hold for the random geometric graph (with\nhigh probability, and uniformly over all shortest path distance balls in a\ncertain radius range) under suitable regularity conditions of the underlying\nsubmanifold and the sampling distribution.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 21:36:47 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 15:16:18 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["G\u00f6bel", "Franziska", ""], ["Blanchard", "Gilles", ""]]}, {"id": "1907.03199", "submitter": "Andreas Loukas", "authors": "Andreas Loukas", "title": "What graph neural networks cannot learn: depth vs width", "comments": "17 pages, 10 figures. International Conference on Learning\n  Representations (ICLR), 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the expressive power of graph neural networks falling\nwithin the message-passing framework (GNNmp). Two results are presented. First,\nGNNmp are shown to be Turing universal under sufficient conditions on their\ndepth, width, node attributes, and layer expressiveness. Second, it is\ndiscovered that GNNmp can lose a significant portion of their power when their\ndepth and width is restricted. The proposed impossibility statements stem from\na new technique that enables the repurposing of seminal results from\ndistributed computing and leads to lower bounds for an array of decision,\noptimization, and estimation problems involving graphs. Strikingly, several of\nthese problems are deemed impossible unless the product of a GNNmp's depth and\nwidth exceeds a polynomial of the graph size; this dependence remains\nsignificant even for tasks that appear simple or when considering\napproximation.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 22:26:17 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 13:24:15 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Loukas", "Andreas", ""]]}, {"id": "1907.03207", "submitter": "Guang-He Lee", "authors": "Guang-He Lee and David Alvarez-Melis and Tommi S. Jaakkola", "title": "Towards Robust, Locally Linear Deep Networks", "comments": "Published in International Conference on Learning Representations\n  (ICLR), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks realize complex mappings that are often understood by their\nlocally linear behavior at or around points of interest. For example, we use\nthe derivative of the mapping with respect to its inputs for sensitivity\nanalysis, or to explain (obtain coordinate relevance for) a prediction. One key\nchallenge is that such derivatives are themselves inherently unstable. In this\npaper, we propose a new learning problem to encourage deep networks to have\nstable derivatives over larger regions. While the problem is challenging in\ngeneral, we focus on networks with piecewise linear activation functions. Our\nalgorithm consists of an inference step that identifies a region around a point\nwhere linear approximation is provably stable, and an optimization step to\nexpand such regions. We propose a novel relaxation to scale the algorithm to\nrealistic models. We illustrate our method with residual and recurrent networks\non image and sequence datasets.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 00:18:22 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Lee", "Guang-He", ""], ["Alvarez-Melis", "David", ""], ["Jaakkola", "Tommi S.", ""]]}, {"id": "1907.03211", "submitter": "Andrew Song", "authors": "Bahareh Tolooshams, Andrew H. Song, Simona Temereanca, Demba Ba", "title": "Convolutional dictionary learning based auto-encoders for natural\n  exponential-family distributions", "comments": null, "journal-ref": "International Conference on Machine Learning (ICML) 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a class of auto-encoder neural networks tailored to data from\nthe natural exponential family (e.g., count data). The architectures are\ninspired by the problem of learning the filters in a convolutional generative\nmodel with sparsity constraints, often referred to as convolutional dictionary\nlearning (CDL). Our work is the first to combine ideas from convolutional\ngenerative models and deep learning for data that are naturally modeled with a\nnon-Gaussian distribution (e.g., binomial and Poisson). This perspective\nprovides us with a scalable and flexible framework that can be re-purposed for\na wide range of tasks and assumptions on the generative model. Specifically,\nthe iterative optimization procedure for solving CDL, an unsupervised task, is\nmapped to an unfolded and constrained neural network, with iterative\nadjustments to the inputs to account for the generative distribution. We also\nshow that the framework can easily be extended for discriminative training,\nappropriate for a supervised task. We demonstrate 1) that fitting the\ngenerative model to learn, in an unsupervised fashion, the latent stimulus that\nunderlies neural spiking data leads to better goodness-of-fit compared to other\nbaselines, 2) competitive performance compared to state-of-the-art algorithms\nfor supervised Poisson image denoising, with significantly fewer parameters,\nand 3) gradient dynamics of shallow binomial auto-encoder.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 01:45:42 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 23:36:18 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 11:55:04 GMT"}, {"version": "v4", "created": "Sun, 28 Jun 2020 23:35:04 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Tolooshams", "Bahareh", ""], ["Song", "Andrew H.", ""], ["Temereanca", "Simona", ""], ["Ba", "Demba", ""]]}, {"id": "1907.03215", "submitter": "Xiang Cheng", "authors": "Xiang Cheng, Dong Yin, Peter L. Bartlett, Michael I. Jordan", "title": "Stochastic Gradient and Langevin Processes", "comments": "ICML 2020, code available at\n  https://github.com/dongyin92/noise_covariance", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove quantitative convergence rates at which discrete Langevin-like\nprocesses converge to the invariant distribution of a related stochastic\ndifferential equation. We study the setup where the additive noise can be\nnon-Gaussian and state-dependent and the potential function can be non-convex.\nWe show that the key properties of these processes depend on the potential\nfunction and the second moment of the additive noise. We apply our theoretical\nfindings to studying the convergence of Stochastic Gradient Descent (SGD) for\nnon-convex problems and corroborate them with experiments using SGD to train\ndeep neural networks on the CIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 03:27:17 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 16:22:38 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 22:35:20 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 00:33:16 GMT"}, {"version": "v5", "created": "Wed, 22 Jul 2020 20:36:53 GMT"}, {"version": "v6", "created": "Wed, 18 Nov 2020 05:41:20 GMT"}, {"version": "v7", "created": "Thu, 19 Nov 2020 02:35:38 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Cheng", "Xiang", ""], ["Yin", "Dong", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1907.03222", "submitter": "Dipendra Jha", "authors": "Dipendra Jha, Logan Ward, Zijiang Yang, Christopher Wolverton, Ian\n  Foster, Wei-keng Liao, Alok Choudhary, Ankit Agrawal", "title": "IRNet: A General Purpose Deep Residual Regression Framework for\n  Materials Discovery", "comments": "9 pages, under publication at KDD'19", "journal-ref": null, "doi": "10.1145/3292500.3330703", "report-no": null, "categories": "physics.comp-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Materials discovery is crucial for making scientific advances in many\ndomains. Collections of data from experiments and first-principle computations\nhave spurred interest in applying machine learning methods to create predictive\nmodels capable of mapping from composition and crystal structures to materials\nproperties. Generally, these are regression problems with the input being a 1D\nvector composed of numerical attributes representing the material composition\nand/or crystal structure. While neural networks consisting of fully connected\nlayers have been applied to such problems, their performance often suffers from\nthe vanishing gradient problem when network depth is increased. In this paper,\nwe study and propose design principles for building deep regression networks\ncomposed of fully connected layers with numerical vectors as input. We\nintroduce a novel deep regression network with individual residual learning,\nIRNet, that places shortcut connections after each layer so that each layer\nlearns the residual mapping between its output and input. We use the problem of\nlearning properties of inorganic materials from numerical attributes derived\nfrom material composition and/or crystal structure to compare IRNet's\nperformance against that of other machine learning techniques. Using multiple\ndatasets from the Open Quantum Materials Database (OQMD) and Materials Project\nfor training and evaluation, we show that IRNet provides significantly better\nprediction performance than the state-of-the-art machine learning approaches\ncurrently used by domain scientists. We also show that IRNet's use of\nindividual residual learning leads to better convergence during the training\nphase than when shortcut connections are between multi-layer stacks while\nmaintaining the same number of parameters.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 05:19:35 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Jha", "Dipendra", ""], ["Ward", "Logan", ""], ["Yang", "Zijiang", ""], ["Wolverton", "Christopher", ""], ["Foster", "Ian", ""], ["Liao", "Wei-keng", ""], ["Choudhary", "Alok", ""], ["Agrawal", "Ankit", ""]]}, {"id": "1907.03236", "submitter": "Kei Majima", "authors": "Naoko Koide-Majima, Kei Majima", "title": "Quantum-inspired canonical correlation analysis for exponentially large\n  dimensional data", "comments": "45 pages, 9 figures. This article will appear in Neural Networks", "journal-ref": "Neural Networks, 2020", "doi": "10.1016/j.neunet.2020.11.019", "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Canonical correlation analysis (CCA) is a technique to find statistical\ndependencies between a pair of multivariate data. However, its application to\nhigh dimensional data is limited due to the resulting time complexity. While\nthe conventional CCA algorithm requires polynomial time, we have developed an\nalgorithm that approximates CCA with computational time proportional to the\nlogarithm of the input dimensionality using quantum-inspired computation. The\ncomputational efficiency and approximation performance of the proposed\nquantum-inspired CCA (qiCCA) algorithm are experimentally demonstrated.\nFurthermore, the fast computation of qiCCA allows us to directly apply CCA even\nafter nonlinearly mapping raw input data into very high dimensional spaces.\nExperiments performed using a benchmark dataset demonstrated that, by mapping\nthe raw input data into the high dimensional spaces with second-order\nmonomials, the proposed qiCCA extracted more correlations than linear CCA and\nwas comparable to deep CCA and kernel CCA. These results suggest that qiCCA is\nconsiderably useful and quantum-inspired computation has the potential to\nunlock a new field in which exponentially large dimensional data can be\nanalyzed.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 07:35:55 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 14:19:47 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Koide-Majima", "Naoko", ""], ["Majima", "Kei", ""]]}, {"id": "1907.03247", "submitter": "Mahdi Pedram", "authors": "Mahdi Pedram, Mahsan Rofouei, Francesco Fraternali, Zhila Esna Ashari,\n  Hassan Ghasemzadeh", "title": "Resource-Efficient Computing in Wearable Systems", "comments": null, "journal-ref": "Fourth IEEE Workshop on Smart Service Systems (SmartSys 2019), 12\n  June 2019, Washington D.C., USA", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two optimization techniques to minimize memory usage and\ncomputation while meeting system timing constraints for real-time\nclassification in wearable systems. Our method derives a hierarchical\nclassifier structure for Support Vector Machine (SVM) in order to reduce the\namount of computations, based on the probability distribution of output classes\noccurrences. Also, we propose a memory optimization technique based on SVM\nparameters, which results in storing fewer support vectors and as a result\nrequiring less memory. To demonstrate the efficiency of our proposed\ntechniques, we performed an activity recognition experiment and were able to\nsave up to 35% and 56% in memory storage when classifying 14 and 6 different\nactivities, respectively. In addition, we demonstrated that there is a\ntrade-off between accuracy of classification and memory savings, which can be\ncontrolled based on application requirements.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 08:26:30 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Pedram", "Mahdi", ""], ["Rofouei", "Mahsan", ""], ["Fraternali", "Francesco", ""], ["Ashari", "Zhila Esna", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "1907.03324", "submitter": "Hilde Weerts MSc", "authors": "Hilde J.P. Weerts and Werner van Ipenburg and Mykola Pechenizkiy", "title": "A Human-Grounded Evaluation of SHAP for Alert Processing", "comments": "Will be published in proceedings of KDD workshop on Explainable AI\n  2019 (KDD-XAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past years, many new explanation methods have been proposed to achieve\ninterpretability of machine learning predictions. However, the utility of these\nmethods in practical applications has not been researched extensively. In this\npaper we present the results of a human-grounded evaluation of SHAP, an\nexplanation method that has been well-received in the XAI and related\ncommunities. In particular, we study whether this local model-agnostic\nexplanation method can be useful for real human domain experts to assess the\ncorrectness of positive predictions, i.e. alerts generated by a classifier. We\nperformed experimentation with three different groups of participants (159 in\ntotal), who had basic knowledge of explainable machine learning. We performed a\nqualitative analysis of recorded reflections of experiment participants\nperforming alert processing with and without SHAP information. The results\nsuggest that the SHAP explanations do impact the decision-making process,\nalthough the model's confidence score remains to be a leading source of\nevidence. We statistically test whether there is a significant difference in\ntask utility metrics between tasks for which an explanation was available and\ntasks in which it was not provided. As opposed to common intuitions, we did not\nfind a significant difference in alert processing performance when a SHAP\nexplanation is available compared to when it is not.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 17:50:06 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Weerts", "Hilde J. P.", ""], ["van Ipenburg", "Werner", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1907.03329", "submitter": "Kaung Khin", "authors": "Andrew Redd, Kaung Khin, Aldo Marini", "title": "Fast ES-RNN: A GPU Implementation of the ES-RNN Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their prevalence, time series forecasting is crucial in multiple\ndomains. We seek to make state-of-the-art forecasting fast, accessible, and\ngeneralizable. ES-RNN is a hybrid between classical state space forecasting\nmodels and modern RNNs that achieved a 9.4% sMAPE improvement in the M4\ncompetition. Crucially, ES-RNN implementation requires per-time series\nparameters. By vectorizing the original implementation and porting the\nalgorithm to a GPU, we achieve up to 322x training speedup depending on batch\nsize with similar results as those reported in the original submission. Our\ncode can be found at: https://github.com/damitkwr/ESRNN-GPU\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 18:23:17 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Redd", "Andrew", ""], ["Khin", "Kaung", ""], ["Marini", "Aldo", ""]]}, {"id": "1907.03334", "submitter": "Hilde Weerts MSc", "authors": "Hilde J.P. Weerts and Werner van Ipenburg and Mykola Pechenizkiy", "title": "Case-Based Reasoning for Assisting Domain Experts in Processing Fraud\n  Alerts of Black-Box Machine Learning Models", "comments": "Will be published in proceedings of KDD workshop on Anomaly Detection\n  in Finance 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many contexts, it can be useful for domain experts to understand to what\nextent predictions made by a machine learning model can be trusted. In\nparticular, estimates of trustworthiness can be useful for fraud analysts who\nprocess machine learning-generated alerts of fraudulent transactions. In this\nwork, we present a case-based reasoning (CBR) approach that provides evidence\non the trustworthiness of a prediction in the form of a visualization of\nsimilar previous instances. Different from previous works, we consider\nsimilarity of local post-hoc explanations of predictions and show empirically\nthat our visualization can be useful for processing alerts. Furthermore, our\napproach is perceived useful and easy to use by fraud analysts at a major Dutch\nbank.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 19:12:49 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Weerts", "Hilde J. P.", ""], ["van Ipenburg", "Werner", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1907.03343", "submitter": "Fabi\\'an Latorre G\\'omez", "authors": "Fabian Latorre G\\'omez, Armin Eftekhari, Volkan Cevher", "title": "Fast and Provable ADMM for Learning with Generative Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose a (linearized) Alternating Direction\nMethod-of-Multipliers (ADMM) algorithm for minimizing a convex function subject\nto a nonconvex constraint. We focus on the special case where such constraint\narises from the specification that a variable should lie in the range of a\nneural network. This is motivated by recent successful applications of\nGenerative Adversarial Networks (GANs) in tasks like compressive sensing,\ndenoising and robustness against adversarial examples. The derived rates for\nour algorithm are characterized in terms of certain geometric properties of the\ngenerator network, which we show hold for feedforward architectures, under mild\nassumptions. Unlike gradient descent (GD), it can efficiently handle non-smooth\nobjectives as well as exploit efficient partial minimization procedures, thus\nbeing faster in many practical scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 20:09:58 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["G\u00f3mez", "Fabian Latorre", ""], ["Eftekhari", "Armin", ""], ["Cevher", "Volkan", ""]]}, {"id": "1907.03346", "submitter": "Yogev Bar-On", "authors": "Yogev Bar-On and Yishay Mansour", "title": "Individual Regret in Cooperative Nonstochastic Multi-Armed Bandits", "comments": "To appear in Proc. Neural Information Processing Systems (NeurIPS),\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study agents communicating over an underlying network by exchanging\nmessages, in order to optimize their individual regret in a common\nnonstochastic multi-armed bandit problem. We derive regret minimization\nalgorithms that guarantee for each agent $v$ an individual expected regret of\n$\\widetilde{O}\\left(\\sqrt{\\left(1+\\frac{K}{\\left|\\mathcal{N}\\left(v\\right)\\right|}\\right)T}\\right)$,\nwhere $T$ is the number of time steps, $K$ is the number of actions and\n$\\mathcal{N}\\left(v\\right)$ is the set of neighbors of agent $v$ in the\ncommunication graph. We present algorithms both for the case that the\ncommunication graph is known to all the agents, and for the case that the graph\nis unknown. When the graph is unknown, each agent knows only the set of its\nneighbors and an upper bound on the total number of agents. The individual\nregret between the models differs only by a logarithmic factor. Our work\nresolves an open problem from [Cesa-Bianchi et al., 2019b].\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 20:58:29 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 16:03:02 GMT"}, {"version": "v3", "created": "Sat, 16 Nov 2019 22:13:25 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Bar-On", "Yogev", ""], ["Mansour", "Yishay", ""]]}, {"id": "1907.03361", "submitter": "Magnus Wiese", "authors": "Magnus Wiese, Robert Knobloch, Ralf Korn", "title": "Copula & Marginal Flows: Disentangling the Marginal from its Joint", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative networks such as GANs and normalizing flows flourish in the\ncontext of high-dimensional tasks such as image generation. However, so far\nexact modeling or extrapolation of distributional properties such as the tail\nasymptotics generated by a generative network is not available. In this paper,\nwe address this issue for the first time in the deep learning literature by\nmaking two novel contributions. First, we derive upper bounds for the tails\nthat can be expressed by a generative network and demonstrate Lp-space related\nproperties. There we show specifically that in various situations an optimal\ngenerative network does not exist. Second, we introduce and propose copula and\nmarginal generative flows (CM flows) which allow for an exact modeling of the\ntail and any prior assumption on the CDF up to an approximation of the uniform\ndistribution. Our numerical results support the use of CM flows.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 22:45:26 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Wiese", "Magnus", ""], ["Knobloch", "Robert", ""], ["Korn", "Ralf", ""]]}, {"id": "1907.03373", "submitter": "Valentin Hartmann", "authors": "Valentin Hartmann, Konark Modi, Josep M. Pujol, Robert West", "title": "Privacy-Preserving Classification with Secret Vector Machines", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, large amounts of valuable data are distributed among millions of\nuser-held devices, such as personal computers, phones, or Internet-of-things\ndevices. Many companies collect such data with the goal of using it for\ntraining machine learning models allowing them to improve their services.\nUser-held data is, however, often sensitive, and collecting it is problematic\nin terms of privacy. We address this issue by proposing a novel way of training\na supervised classifier in a distributed setting akin to the recently proposed\nfederated learning paradigm, but under the stricter privacy requirement that\nthe server that trains the model is assumed to be untrusted and potentially\nmalicious. We thus preserve user privacy by design, rather than by trust. In\nparticular, our framework, called secret vector machine (SecVM), provides an\nalgorithm for training linear support vector machines (SVM) in a setting in\nwhich data-holding clients communicate with an untrusted server by exchanging\nmessages designed to not reveal any personally identifiable information. We\nevaluate our model in two ways. First, in an offline evaluation, we train SecVM\nto predict user gender from tweets, showing that we can preserve user privacy\nwithout sacrificing classification performance. Second, we implement SecVM's\ndistributed framework for the Cliqz web browser and deploy it for predicting\nuser gender in a large-scale online evaluation with thousands of clients,\noutperforming baselines by a large margin and thus showcasing that SecVM is\nsuitable for production environments.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 00:57:10 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 23:00:55 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Hartmann", "Valentin", ""], ["Modi", "Konark", ""], ["Pujol", "Josep M.", ""], ["West", "Robert", ""]]}, {"id": "1907.03382", "submitter": "Atilim Gunes Baydin", "authors": "At{\\i}l{\\i}m G\\\"une\\c{s} Baydin, Lei Shao, Wahid Bhimji, Lukas\n  Heinrich, Lawrence Meadows, Jialin Liu, Andreas Munk, Saeid Naderiparizi,\n  Bradley Gram-Hansen, Gilles Louppe, Mingfei Ma, Xiaohui Zhao, Philip Torr,\n  Victor Lee, Kyle Cranmer, Prabhat, Frank Wood", "title": "Etalumis: Bringing Probabilistic Programming to Scientific Simulators at\n  Scale", "comments": "14 pages, 8 figures", "journal-ref": "Proceedings of the International Conference for High Performance\n  Computing, Networking, Storage, and Analysis (SC19), November 17--22, 2019", "doi": "10.1145/3295500.3356180", "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic programming languages (PPLs) are receiving widespread attention\nfor performing Bayesian inference in complex generative models. However,\napplications to science remain limited because of the impracticability of\nrewriting complex scientific simulators in a PPL, the computational cost of\ninference, and the lack of scalable implementations. To address these, we\npresent a novel PPL framework that couples directly to existing scientific\nsimulators through a cross-platform probabilistic execution protocol and\nprovides Markov chain Monte Carlo (MCMC) and deep-learning-based inference\ncompilation (IC) engines for tractable inference. To guide IC inference, we\nperform distributed training of a dynamic 3DCNN--LSTM architecture with a\nPyTorch-MPI-based framework on 1,024 32-core CPU nodes of the Cori\nsupercomputer with a global minibatch size of 128k: achieving a performance of\n450 Tflop/s through enhancements to PyTorch. We demonstrate a Large Hadron\nCollider (LHC) use-case with the C++ Sherpa simulator and achieve the\nlargest-scale posterior inference in a Turing-complete PPL.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 02:03:36 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 13:26:21 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Baydin", "At\u0131l\u0131m G\u00fcne\u015f", ""], ["Shao", "Lei", ""], ["Bhimji", "Wahid", ""], ["Heinrich", "Lukas", ""], ["Meadows", "Lawrence", ""], ["Liu", "Jialin", ""], ["Munk", "Andreas", ""], ["Naderiparizi", "Saeid", ""], ["Gram-Hansen", "Bradley", ""], ["Louppe", "Gilles", ""], ["Ma", "Mingfei", ""], ["Zhao", "Xiaohui", ""], ["Torr", "Philip", ""], ["Lee", "Victor", ""], ["Cranmer", "Kyle", ""], ["Prabhat", "", ""], ["Wood", "Frank", ""]]}, {"id": "1907.03389", "submitter": "Ziliang Chen", "authors": "Ziliang Chen, Jingyu Zhuang, Xiaodan Liang and Liang Lin", "title": "Blending-target Domain Adaptation by Adversarial Meta-Adaptation\n  Networks", "comments": "CVPR-19 (oral). Code is available at\n  http://github.com/zjy526223908/BTDA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (Unsupervised) Domain Adaptation (DA) seeks for classifying target instances\nwhen solely provided with source labeled and target unlabeled examples for\ntraining. Learning domain-invariant features helps to achieve this goal,\nwhereas it underpins unlabeled samples drawn from a single or multiple explicit\ntarget domains (Multi-target DA). In this paper, we consider a more realistic\ntransfer scenario: our target domain is comprised of multiple sub-targets\nimplicitly blended with each other, so that learners could not identify which\nsub-target each unlabeled sample belongs to. This Blending-target Domain\nAdaptation (BTDA) scenario commonly appears in practice and threatens the\nvalidities of most existing DA algorithms, due to the presence of domain gaps\nand categorical misalignments among these hidden sub-targets.\n  To reap the transfer performance gains in this new scenario, we propose\nAdversarial Meta-Adaptation Network (AMEAN). AMEAN entails two adversarial\ntransfer learning processes. The first is a conventional adversarial transfer\nto bridge our source and mixed target domains. To circumvent the intra-target\ncategory misalignment, the second process presents as ``learning to adapt'': It\ndeploys an unsupervised meta-learner receiving target data and their ongoing\nfeature-learning feedbacks, to discover target clusters as our\n``meta-sub-target'' domains. These meta-sub-targets auto-design our\nmeta-sub-target DA loss, which empirically eliminates the implicit category\nmismatching in our mixed target. We evaluate AMEAN and a variety of DA\nalgorithms in three benchmarks under the BTDA setup. Empirical results show\nthat BTDA is a quite challenging transfer setup for most existing DA\nalgorithms, yet AMEAN significantly outperforms these state-of-the-art\nbaselines and effectively restrains the negative transfer effects in BTDA.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 02:54:35 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Chen", "Ziliang", ""], ["Zhuang", "Jingyu", ""], ["Liang", "Xiaodan", ""], ["Lin", "Liang", ""]]}, {"id": "1907.03411", "submitter": "Micha{\\l} Derezi\\'nski", "authors": "Micha{\\l} Derezi\\'nski, Manfred K. Warmuth and Daniel Hsu", "title": "Unbiased estimators for random design regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In linear regression we wish to estimate the optimum linear least squares\npredictor for a distribution over d-dimensional input points and real-valued\nresponses, based on a small sample. Under standard random design analysis,\nwhere the sample is drawn i.i.d. from the input distribution, the least squares\nsolution for that sample can be viewed as the natural estimator of the optimum.\nUnfortunately, this estimator almost always incurs an undesirable bias coming\nfrom the randomness of the input points. In this paper we show that it is\npossible to draw a non-i.i.d. sample of input points such that, regardless of\nthe response model, the least squares solution is an unbiased estimator of the\noptimum. Moreover, this sample can be produced efficiently by augmenting a\npreviously drawn i.i.d. sample with an additional set of d points drawn jointly\nfrom the input distribution rescaled by the squared volume spanned by the\npoints. Motivated by this, we develop a theoretical framework for studying\nvolume-rescaled sampling, and in the process prove a number of new matrix\nexpectation identities. We use them to show that for any input distribution and\n$\\epsilon>0$ there is a random design consisting of $O(d\\log d+ d/\\epsilon)$\npoints from which an unbiased estimator can be constructed whose square loss\nover the entire distribution is with high probability bounded by $1+\\epsilon$\ntimes the loss of the optimum. We provide efficient algorithms for generating\nsuch unbiased estimators in a number of practical settings and support our\nclaims experimentally.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 06:01:19 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Derezi\u0144ski", "Micha\u0142", ""], ["Warmuth", "Manfred K.", ""], ["Hsu", "Daniel", ""]]}, {"id": "1907.03419", "submitter": "Sebastien Martin", "authors": "Dimitris Bertsimas, Arthur Delarue, Patrick Jaillet, Sebastien Martin", "title": "The Price of Interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When quantitative models are used to support decision-making on complex and\nimportant topics, understanding a model's ``reasoning'' can increase trust in\nits predictions, expose hidden biases, or reduce vulnerability to adversarial\nattacks. However, the concept of interpretability remains loosely defined and\napplication-specific. In this paper, we introduce a mathematical framework in\nwhich machine learning models are constructed in a sequence of interpretable\nsteps. We show that for a variety of models, a natural choice of interpretable\nsteps recovers standard interpretability proxies (e.g., sparsity in linear\nmodels). We then generalize these proxies to yield a parametrized family of\nconsistent measures of model interpretability. This formal definition allows us\nto quantify the ``price'' of interpretability, i.e., the tradeoff with\npredictive accuracy. We demonstrate practical algorithms to apply our framework\non real and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 06:42:59 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Delarue", "Arthur", ""], ["Jaillet", "Patrick", ""], ["Martin", "Sebastien", ""]]}, {"id": "1907.03426", "submitter": "Ziliang Chen", "authors": "Ziliang Chen, Zhanfu Yang, Xiaoxi Wang, Xiaodan Liang, Xiaopeng Yan,\n  Guanbin Li and Liang Lin", "title": "Multivariate-Information Adversarial Ensemble for Scalable Joint\n  Distribution Matching", "comments": "ICML-19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A broad range of cross-$m$-domain generation researches boil down to matching\na joint distribution by deep generative models (DGMs). Hitherto algorithms\nexcel in pairwise domains while as $m$ increases, remain struggling to scale\nthemselves to fit a joint distribution. In this paper, we propose a\ndomain-scalable DGM, i.e., MMI-ALI for $m$-domain joint distribution matching.\nAs an $m$-domain ensemble model of ALIs \\cite{dumoulin2016adversarially},\nMMI-ALI is adversarially trained with maximizing Multivariate Mutual\nInformation (MMI) w.r.t. joint variables of each pair of domains and their\nshared feature. The negative MMIs are upper bounded by a series of feasible\nlosses that provably lead to matching $m$-domain joint distributions. MMI-ALI\nlinearly scales as $m$ increases and thus, strikes a right balance between\nefficacy and scalability. We evaluate MMI-ALI in diverse challenging $m$-domain\nscenarios and verify its superiority.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 07:11:54 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Chen", "Ziliang", ""], ["Yang", "Zhanfu", ""], ["Wang", "Xiaoxi", ""], ["Liang", "Xiaodan", ""], ["Yan", "Xiaopeng", ""], ["Li", "Guanbin", ""], ["Lin", "Liang", ""]]}, {"id": "1907.03451", "submitter": "Aahlad Manas Puli", "authors": "Aahlad Manas Puli and Rajesh Ranganath", "title": "General Control Functions for Causal Effect Estimation from Instrumental\n  Variables", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal effect estimation relies on separating the variation in the outcome\ninto parts due to the treatment and due to the confounders. To achieve this\nseparation, practitioners often use external sources of randomness that only\ninfluence the treatment called instrumental variables (IVs). We study variables\nconstructed from treatment and IV that help estimate effects, called control\nfunctions. We characterize general control functions for effect estimation in a\nmeta-identification result. Then, we show that structural assumptions on the\ntreatment process allow the construction of general control functions, thereby\nguaranteeing identification. To construct general control functions and\nestimate effects, we develop the general control function method (GCFN). GCFN's\nfirst stage called variational decoupling (VDE) constructs general control\nfunctions by recovering the residual variation in the treatment given the IV.\nUsing VDE's control function, GCFN's second stage estimates effects via\nregression. Further, we develop semi-supervised GCFN to construct general\ncontrol functions using subsets of data that have both IV and confounders\nobserved as supervision; this needs no structural treatment process\nassumptions. We evaluate GCFN on low and high dimensional simulated data and on\nrecovering the causal effect of slave export on modern community trust.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 08:27:12 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 05:37:18 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Puli", "Aahlad Manas", ""], ["Ranganath", "Rajesh", ""]]}, {"id": "1907.03452", "submitter": "Ariel Neufeld", "authors": "Christian Beck, Sebastian Becker, Patrick Cheridito, Arnulf Jentzen,\n  and Ariel Neufeld", "title": "Deep splitting method for parabolic PDEs", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a numerical method for nonlinear parabolic PDEs\nthat combines operator splitting with deep learning. It divides the PDE\napproximation problem into a sequence of separate learning problems. Since the\ncomputational graph for each of the subproblems is comparatively small, the\napproach can handle extremely high-dimensional PDEs. We test the method on\ndifferent examples from physics, stochastic control and mathematical finance.\nIn all cases, it yields very good results in up to 10,000 dimensions with short\nrun times.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 08:30:23 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 15:36:53 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Beck", "Christian", ""], ["Becker", "Sebastian", ""], ["Cheridito", "Patrick", ""], ["Jentzen", "Arnulf", ""], ["Neufeld", "Ariel", ""]]}, {"id": "1907.03507", "submitter": "Vikas Dwivedi", "authors": "Vikas Dwivedi, Balaji Srinivasan", "title": "Physics Informed Extreme Learning Machine (PIELM) -- A rapid method for\n  the numerical solution of partial differential equations", "comments": "29 pages, 30 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been rapid progress recently on the application of deep networks to\nthe solution of partial differential equations, collectively labelled as\nPhysics Informed Neural Networks (PINNs). In this paper, we develop Physics\nInformed Extreme Learning Machine (PIELM), a rapid version of PINNs which can\nbe applied to stationary and time dependent linear partial differential\nequations. We demonstrate that PIELM matches or exceeds the accuracy of PINNs\non a range of problems. We also discuss the limitations of neural network based\napproaches, including our PIELM, in the solution of PDEs on large domains and\nsuggest an extension, a distributed version of our algorithm -{}- DPIELM. We\nshow that DPIELM produces excellent results comparable to conventional\nnumerical techniques in the solution of time-dependent problems. Collectively,\nthis work contributes towards making the use of neural networks in the solution\nof partial differential equations in complex domains as a competitive\nalternative to conventional discretization techniques.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 11:02:08 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Dwivedi", "Vikas", ""], ["Srinivasan", "Balaji", ""]]}, {"id": "1907.03511", "submitter": "Nicolas Scheiner", "authors": "Nicolas Scheiner, Nils Appenrodt, J\\\"urgen Dickmann, Bernhard Sick", "title": "A Multi-Stage Clustering Framework for Automotive Radar Data", "comments": "8 pages, 5 figures, accepted paper for 2019 IEEE 22nd Intelligent\n  Transportation Systems Conference (ITSC), Auckland, New Zealand, October 2019", "journal-ref": null, "doi": "10.1109/ITSC.2019.8916873", "report-no": null, "categories": "cs.LG cs.RO eess.IV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radar sensors provide a unique method for executing environmental perception\ntasks towards autonomous driving. Especially their capability to perform well\nin adverse weather conditions often makes them superior to other sensors such\nas cameras or lidar. Nevertheless, the high sparsity and low dimensionality of\nthe commonly used detection data level is a major challenge for subsequent\nsignal processing. Therefore, the data points are often merged in order to form\nlarger entities from which more information can be gathered. The merging\nprocess is often implemented in form of a clustering algorithm. This article\ndescribes a novel approach for first filtering out static background data\nbefore applying a twostage clustering approach. The two-stage clustering\nfollows the same paradigm as the idea for data association itself: First,\nclustering what is ought to belong together in a low dimensional parameter\nspace, then, extracting additional features from the newly created clusters in\norder to perform a final clustering step. Parameters are optimized for\nfiltering and both clustering steps. All techniques are assessed both\nindividually and as a whole in order to demonstrate their effectiveness. Final\nresults indicate clear benefits of the first two methods and also the cluster\nmerging process under specific circumstances.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 11:10:16 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Scheiner", "Nicolas", ""], ["Appenrodt", "Nils", ""], ["Dickmann", "J\u00fcrgen", ""], ["Sick", "Bernhard", ""]]}, {"id": "1907.03540", "submitter": "Mohamed Abdelfattah", "authors": "{\\L}ukasz Dudziak, Mohamed S. Abdelfattah, Ravichander Vipperla,\n  Stefanos Laskaridis, Nicholas D. Lane", "title": "ShrinkML: End-to-End ASR Model Compression Using Reinforcement Learning", "comments": "INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end automatic speech recognition (ASR) models are increasingly large\nand complex to achieve the best possible accuracy. In this paper, we build an\nAutoML system that uses reinforcement learning (RL) to optimize the per-layer\ncompression ratios when applied to a state-of-the-art attention based\nend-to-end ASR model composed of several LSTM layers. We use singular value\ndecomposition (SVD) low-rank matrix factorization as the compression method.\nFor our RL-based AutoML system, we focus on practical considerations such as\nthe choice of the reward/punishment functions, the formation of an effective\nsearch space, and the creation of a representative but small data set for quick\nevaluation between search steps. Finally, we present accuracy results on\nLibriSpeech of the model compressed by our AutoML system, and we compare it to\nmanually-compressed models. Our results show that in the absence of retraining\nour RL-based search is an effective and practical method to compress a\nproduction-grade ASR system. When retraining is possible, we show that our\nAutoML system can select better highly-compressed seed models compared to\nmanually hand-crafted rank selection, thus allowing for more compression than\npreviously possible.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 12:10:18 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 10:06:29 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Dudziak", "\u0141ukasz", ""], ["Abdelfattah", "Mohamed S.", ""], ["Vipperla", "Ravichander", ""], ["Laskaridis", "Stefanos", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "1907.03572", "submitter": "Shreyan Chowdhury", "authors": "Shreyan Chowdhury, Andreu Vall, Verena Haunschmid, Gerhard Widmer", "title": "Towards Explainable Music Emotion Recognition: The Route via Mid-level\n  Features", "comments": "International Society for Music Information Retrieval Conference,\n  Delft, The Netherlands, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Emotional aspects play an important part in our interaction with music.\nHowever, modelling these aspects in MIR systems have been notoriously\nchallenging since emotion is an inherently abstract and subjective experience,\nthus making it difficult to quantify or predict in the first place, and to make\nsense of the predictions in the next. In an attempt to create a model that can\ngive a musically meaningful and intuitive explanation for its predictions, we\npropose a VGG-style deep neural network that learns to predict emotional\ncharacteristics of a musical piece together with (and based on)\nhuman-interpretable, mid-level perceptual features. We compare this to\npredicting emotion directly with an identical network that does not take into\naccount the mid-level features and observe that the loss in predictive\nperformance of going through the mid-level features is surprisingly low, on\naverage. The design of our network allows us to visualize the effects of\nperceptual features on individual emotion predictions, and we argue that the\nsmall loss in performance in going through the mid-level features is justified\nby the gain in explainability of the predictions.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 12:58:02 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Chowdhury", "Shreyan", ""], ["Vall", "Andreu", ""], ["Haunschmid", "Verena", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1907.03576", "submitter": "Ashis Banerjee", "authors": "Ekta U. Samani, Wei Guo, and Ashis G. Banerjee", "title": "Deep Learning-Based Semantic Segmentation of Microscale Objects", "comments": "A condensed version of the paper is published in the Proceedings of\n  the 2019 International Conference on Manipulation, Automation and Robotics at\n  Small Scales", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate estimation of the positions and shapes of microscale objects is\ncrucial for automated imaging-guided manipulation using a non-contact technique\nsuch as optical tweezers. Perception methods that use traditional computer\nvision algorithms tend to fail when the manipulation environments are crowded.\nIn this paper, we present a deep learning model for semantic segmentation of\nthe images representing such environments. Our model successfully performs\nsegmentation with a high mean Intersection Over Union score of 0.91.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 23:07:01 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Samani", "Ekta U.", ""], ["Guo", "Wei", ""], ["Banerjee", "Ashis G.", ""]]}, {"id": "1907.03591", "submitter": "Junyu Chen", "authors": "Junyu Chen and Eric C. Frey", "title": "Feature-Based Image Clustering and Segmentation Using Wavelets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pixel intensity is a widely used feature for clustering and segmentation\nalgorithms, the resulting segmentation using only intensity values might suffer\nfrom noises and lack of spatial context information. Wavelet transform is often\nused for image denoising and classification. We proposed a novel method to\nincorporate Wavelet features in segmentation and clustering algorithms. The\nconventional K-means, Fuzzy c-means (FCM), and Active contour without edges\n(ACWE) algorithms were modified to adapt Wavelet features, leading to robust\nclustering/segmentation algorithms. A weighting parameter to control the weight\nof low-frequency sub-band information was also introduced. The new algorithms\nshowed the capability to converge to different segmentation results based on\nthe frequency information derived from the Wavelet sub-bands.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 02:30:07 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Chen", "Junyu", ""], ["Frey", "Eric C.", ""]]}, {"id": "1907.03680", "submitter": "Sarah Dean", "authors": "Sarah Dean, Nikolai Matni, Benjamin Recht, Vickie Ye", "title": "Robust Guarantees for Perception-Based Control", "comments": "This revision includes reframing the local generalization problem,\n  with relaxed the assumptions so that the robust problem depends on a local\n  slope bound rather than a Lipschitz constant, and provide a method for\n  learning the slope bound from data. We also include additional experiments\n  with a CNN perception module", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by vision-based control of autonomous vehicles, we consider the\nproblem of controlling a known linear dynamical system for which partial state\ninformation, such as vehicle position, is extracted from complex and nonlinear\ndata, such as a camera image. Our approach is to use a learned perception map\nthat predicts some linear function of the state and to design a corresponding\nsafe set and robust controller for the closed loop system with this sensing\nscheme. We show that under suitable smoothness assumptions on both the\nperception map and the generative model relating state to complex and nonlinear\ndata, parameters of the safe set can be learned via appropriately dense\nsampling of the state space. We then prove that the resulting\nperception-control loop has favorable generalization properties. We illustrate\nthe usefulness of our approach on a synthetic example and on the self-driving\ncar simulation platform CARLA.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 15:35:56 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 13:46:56 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Dean", "Sarah", ""], ["Matni", "Nikolai", ""], ["Recht", "Benjamin", ""], ["Ye", "Vickie", ""]]}, {"id": "1907.03687", "submitter": "Hado van Hasselt", "authors": "Hado van Hasselt, John Quan, Matteo Hessel, Zhongwen Xu, Diana Borsa,\n  Andre Barreto", "title": "General non-linear Bellman equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general class of non-linear Bellman equations. These open up a\ndesign space of algorithms that have interesting properties, which has two\npotential advantages. First, we can perhaps better model natural phenomena. For\ninstance, hyperbolic discounting has been proposed as a mathematical model that\nmatches human and animal data well, and can therefore be used to explain\npreference orderings. We present a different mathematical model that matches\nthe same data, but that makes very different predictions under other\ncircumstances. Second, the larger design space can perhaps lead to algorithms\nthat perform better, similar to how discount factors are often used in practice\neven when the true objective is undiscounted. We show that many of the\nresulting Bellman operators still converge to a fixed point, and therefore that\nthe resulting algorithms are reasonable and inherit many beneficial properties\nof their linear counterparts.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 15:51:01 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["van Hasselt", "Hado", ""], ["Quan", "John", ""], ["Hessel", "Matteo", ""], ["Xu", "Zhongwen", ""], ["Borsa", "Diana", ""], ["Barreto", "Andre", ""]]}, {"id": "1907.03698", "submitter": "Ts\\`i-U\\'i \\.Ik", "authors": "Yu-Chuan Huang, I-No Liao, Ching-Hsuan Chen, Ts\\`i-U\\'i \\.Ik, Wen-Chih\n  Peng", "title": "TrackNet: A Deep Learning Network for Tracking High-speed and Tiny\n  Objects in Sports Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ball trajectory data are one of the most fundamental and useful information\nin the evaluation of players' performance and analysis of game strategies.\nAlthough vision-based object tracking techniques have been developed to analyze\nsport competition videos, it is still challenging to recognize and position a\nhigh-speed and tiny ball accurately. In this paper, we develop a deep learning\nnetwork, called TrackNet, to track the tennis ball from broadcast videos in\nwhich the ball images are small, blurry, and sometimes with afterimage tracks\nor even invisible. The proposed heatmap-based deep learning network is trained\nto not only recognize the ball image from a single frame but also learn flying\npatterns from consecutive frames. TrackNet takes images with a size of\n$640\\times360$ to generate a detection heatmap from either a single frame or\nseveral consecutive frames to position the ball and can achieve high precision\neven on public domain videos. The network is evaluated on the video of the\nmen's singles final at the 2017 Summer Universiade, which is available on\nYouTube. The precision, recall, and F1-measure of TrackNet reach $99.7\\%$,\n$97.3\\%$, and $98.5\\%$, respectively. To prevent overfitting, 9 additional\nvideos are partially labeled together with a subset from the previous dataset\nto implement 10-fold cross-validation, and the precision, recall, and\nF1-measure are $95.3\\%$, $75.7\\%$, and $84.3\\%$, respectively. A conventional\nimage processing algorithm is also implemented to compare with TrackNet. Our\nexperiments indicate that TrackNet outperforms conventional method by a big\nmargin and achieves exceptional ball tracking performance. The dataset and demo\nvideo are available at https://nol.cs.nctu.edu.tw/ndo3je6av9/.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 16:08:43 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Huang", "Yu-Chuan", ""], ["Liao", "I-No", ""], ["Chen", "Ching-Hsuan", ""], ["\u0130k", "Ts\u00ec-U\u00ed", ""], ["Peng", "Wen-Chih", ""]]}, {"id": "1907.03712", "submitter": "Eric Mazumdar", "authors": "Eric Mazumdar, Lillian J. Ratliff, Michael I. Jordan, S. Shankar\n  Sastry", "title": "Policy-Gradient Algorithms Have No Guarantees of Convergence in Linear\n  Quadratic Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show by counterexample that policy-gradient algorithms have no guarantees\nof even local convergence to Nash equilibria in continuous action and state\nspace multi-agent settings. To do so, we analyze gradient-play in N-player\ngeneral-sum linear quadratic games, a classic game setting which is recently\nemerging as a benchmark in the field of multi-agent learning. In such games the\nstate and action spaces are continuous and global Nash equilibria can be found\nbe solving coupled Ricatti equations. Further, gradient-play in LQ games is\nequivalent to multi agent policy-gradient. We first show that these games are\nsurprisingly not convex games. Despite this, we are still able to show that the\nonly critical points of the gradient dynamics are global Nash equilibria. We\nthen give sufficient conditions under which policy-gradient will avoid the Nash\nequilibria, and generate a large number of general-sum linear quadratic games\nthat satisfy these conditions. In such games we empirically observe the players\nconverging to limit cycles for which the time average does not coincide with a\nNash equilibrium. The existence of such games indicates that one of the most\npopular approaches to solving reinforcement learning problems in the classic\nreinforcement learning setting has no local guarantee of convergence in\nmulti-agent settings. Further, the ease with which we can generate these\ncounterexamples suggests that such situations are not mere edge cases and are\nin fact quite common.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 16:35:03 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2019 20:32:31 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Mazumdar", "Eric", ""], ["Ratliff", "Lillian J.", ""], ["Jordan", "Michael I.", ""], ["Sastry", "S. Shankar", ""]]}, {"id": "1907.03715", "submitter": "Junmei Zhong", "authors": "Junmei Zhong, William Li", "title": "Predicting Customer Call Intent by Analyzing Phone Call Transcripts\n  based on CNN for Multi-Class Classification", "comments": "12 pages, 4 figures. 8th International Conference on Soft Computing,\n  Artificial Intelligence and Applications (SAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Auto dealerships receive thousands of calls daily from customers who are\ninterested in sales, service, vendors and jobseekers. With so many calls, it is\nvery important for auto dealers to understand the intent of these calls to\nprovide positive customer experiences that ensure customer satisfaction, deep\ncustomer engagement to boost sales and revenue, and optimum allocation of\nagents or customer service representatives across the business. In this paper,\nwe define the problem of customer phone call intent as a multi-class\nclassification problem stemming from the large database of recorded phone call\ntranscripts. To solve this problem, we develop a convolutional neural network\n(CNN)-based supervised learning model to classify the customer calls into four\nintent categories: sales, service, vendor and jobseeker. Experimental results\nshow that with the thrust of our scalable data labeling method to provide\nsufficient training data, the CNN-based predictive model performs very well on\nlong text classification according to the quantitative metrics of F1-Score,\nprecision, recall, and accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 16:39:23 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Zhong", "Junmei", ""], ["Li", "William", ""]]}, {"id": "1907.03741", "submitter": "Ivan Glasser", "authors": "Ivan Glasser, Ryan Sweke, Nicola Pancotti, Jens Eisert, J. Ignacio\n  Cirac", "title": "Expressive power of tensor-network factorizations for probabilistic\n  modeling, with applications from hidden Markov models to quantum machine\n  learning", "comments": "14 pages + 14 pages supplementary material, extended version, code\n  available at\n  http://github.com/glivan/tensor_networks_for_probabilistic_modeling", "journal-ref": "Advances in Neural Information Processing Systems 32, Proceedings\n  of the NeurIPS 2019 Conference", "doi": null, "report-no": null, "categories": "cs.LG cond-mat.str-el math.OC quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor-network techniques have enjoyed outstanding success in physics, and\nhave recently attracted attention in machine learning, both as a tool for the\nformulation of new learning algorithms and for enhancing the mathematical\nunderstanding of existing methods. Inspired by these developments, and the\nnatural correspondence between tensor networks and probabilistic graphical\nmodels, we provide a rigorous analysis of the expressive power of various\ntensor-network factorizations of discrete multivariate probability\ndistributions. These factorizations include non-negative tensor-trains/MPS,\nwhich are in correspondence with hidden Markov models, and Born machines, which\nare naturally related to local quantum circuits. When used to model probability\ndistributions, they exhibit tractable likelihoods and admit efficient learning\nalgorithms. Interestingly, we prove that there exist probability distributions\nfor which there are unbounded separations between the resource requirements of\nsome of these tensor-network factorizations. Particularly surprising is the\nfact that using complex instead of real tensors can lead to an arbitrarily\nlarge reduction in the number of parameters of the network. Additionally, we\nintroduce locally purified states (LPS), a new factorization inspired by\ntechniques for the simulation of quantum systems, with provably better\nexpressive power than all other representations considered. The ramifications\nof this result are explored through numerical experiments. Our findings imply\nthat LPS should be considered over hidden Markov models, and furthermore\nprovide guidelines for the design of local quantum circuits for probabilistic\nmodeling.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 17:54:26 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 14:20:27 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Glasser", "Ivan", ""], ["Sweke", "Ryan", ""], ["Pancotti", "Nicola", ""], ["Eisert", "Jens", ""], ["Cirac", "J. Ignacio", ""]]}, {"id": "1907.03748", "submitter": "Carolin Lawrence", "authors": "Laura Jehl, Carolin Lawrence, Stefan Riezler", "title": "Learning Neural Sequence-to-Sequence Models from Weak Feedback with\n  Bipolar Ramp Loss", "comments": "Transactions of the Association for Computational Linguistics 2019\n  Vol. 7, 233-248. Presented at ACL, Florence, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many machine learning scenarios, supervision by gold labels is not\navailable and consequently neural models cannot be trained directly by maximum\nlikelihood estimation (MLE). In a weak supervision scenario, metric-augmented\nobjectives can be employed to assign feedback to model outputs, which can be\nused to extract a supervision signal for training. We present several\nobjectives for two separate weakly supervised tasks, machine translation and\nsemantic parsing. We show that objectives should actively discourage negative\noutputs in addition to promoting a surrogate gold structure. This notion of\nbipolarity is naturally present in ramp loss objectives, which we adapt to\nneural models. We show that bipolar ramp loss objectives outperform other\nnon-bipolar ramp loss objectives and minimum risk training (MRT) on both weakly\nsupervised tasks, as well as on a supervised machine translation task.\nAdditionally, we introduce a novel token-level ramp loss objective, which is\nable to outperform even the best sequence-level ramp loss on both weakly\nsupervised tasks.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 10:04:12 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Jehl", "Laura", ""], ["Lawrence", "Carolin", ""], ["Riezler", "Stefan", ""]]}, {"id": "1907.03750", "submitter": "Hongliang Dai", "authors": "Hongliang Dai and Yangqiu Song", "title": "Neural Aspect and Opinion Term Extraction with Mined Rules as Weak\n  Supervision", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lack of labeled training data is a major bottleneck for neural network based\naspect and opinion term extraction on product reviews. To alleviate this\nproblem, we first propose an algorithm to automatically mine extraction rules\nfrom existing training examples based on dependency parsing results. The mined\nrules are then applied to label a large amount of auxiliary data. Finally, we\nstudy training procedures to train a neural model which can learn from both the\ndata automatically labeled by the rules and a small amount of data accurately\nannotated by human. Experimental results show that although the mined rules\nthemselves do not perform well due to their limited flexibility, the\ncombination of human annotated data and rule labeled auxiliary data can improve\nthe neural model and allow it to achieve performance better than or comparable\nwith the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 12:59:04 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Dai", "Hongliang", ""], ["Song", "Yangqiu", ""]]}, {"id": "1907.03755", "submitter": "Ahmed BaniMustafa", "authors": "Ahmed BaniMustafa and Nigel Hardy", "title": "Applications of a Novel Knowledge Discovery and Data Mining Process\n  Model for Metabolomics", "comments": "references information updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work demonstrates the execution of a novel process model for knowledge\ndiscovery and data mining for metabolomics (MeKDDaM). It aims to illustrate\nMeKDDaM process model applicability using four different real-world\napplications and to highlight its strengths and unique features. The\ndemonstrated applications provide coverage for metabolite profiling, target\nanalysis, and metabolic fingerprinting. The data analysed in these applications\nwere captured by chromatographic separation and mass spectrometry technique\n(LC-MS), Fourier transform infrared spectroscopy (FT-IR), and nuclear magnetic\nresonance spectroscopy (NMR) and involve the analysis of plant, animal, and\nhuman samples. The process was executed using both data-driven and\nhypothesis-driven data mining approaches in order to perform various data\nmining goals and tasks by applying a number of data mining techniques. The\napplications were selected to achieve a range of analytical goals and research\nquestions and to provide coverage for metabolite profiling, target analysis,\nand metabolic fingerprinting using datasets that were captured by NMR, LC-MS,\nand FT-IR using samples of a plant, animal, and human origin. The process was\napplied using an implementation environment which was created in order to\nprovide a computer-aided realisation of the process model execution.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 01:14:55 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 07:57:31 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["BaniMustafa", "Ahmed", ""], ["Hardy", "Nigel", ""]]}, {"id": "1907.03783", "submitter": "Guojun Zhang", "authors": "Guojun Zhang, Pascal Poupart and George Trimponias", "title": "Comparing EM with GD in Mixture Models of Two Components", "comments": "UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expectation-maximization (EM) algorithm has been widely used in\nminimizing the negative log likelihood (also known as cross entropy) of mixture\nmodels. However, little is understood about the goodness of the fixed points it\nconverges to. In this paper, we study the regions where one component is\nmissing in two-component mixture models, which we call one-cluster regions. We\nanalyze the propensity of such regions to trap EM and gradient descent (GD) for\nmixtures of two Gaussians and mixtures of two Bernoullis. In the case of\nGaussian mixtures, EM escapes one-cluster regions exponentially fast, while GD\nescapes them linearly fast. In the case of mixtures of Bernoullis, we find that\nthere exist one-cluster regions that are stable for GD and therefore trap GD,\nbut those regions are unstable for EM, allowing EM to escape. Those regions are\nlocal minima that appear universally in experiments and can be arbitrarily bad.\nThis work implies that EM is less likely than GD to converge to certain bad\nlocal optima in mixture models.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 18:00:32 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 03:28:45 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 15:13:38 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Zhang", "Guojun", ""], ["Poupart", "Pascal", ""], ["Trimponias", "George", ""]]}, {"id": "1907.03792", "submitter": "Marc Lelarge", "authors": "Marc Lelarge and Leo Miolane", "title": "Asymptotic Bayes risk for Gaussian mixture in a semi-supervised setting", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning (SSL) uses unlabeled data for training and has been\nshown to greatly improve performance when compared to a supervised approach on\nthe labeled data available. This claim depends both on the amount of labeled\ndata available and on the algorithm used.\n  In this paper, we compute analytically the gap between the best\nfully-supervised approach using only labeled data and the best semi-supervised\napproach using both labeled and unlabeled data. We quantify the best possible\nincrease in performance obtained thanks to the unlabeled data, i.e. we compute\nthe accuracy increase due to the information contained in the unlabeled data.\nOur work deals with a simple high-dimensional Gaussian mixture model for the\ndata in a Bayesian setting. Our rigorous analysis builds on recent theoretical\nbreakthroughs in high-dimensional inference and a large body of mathematical\ntools from statistical physics initially developed for spin glasses.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 18:08:05 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 21:26:23 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Lelarge", "Marc", ""], ["Miolane", "Leo", ""]]}, {"id": "1907.03793", "submitter": "Quoc Tran-Dinh", "authors": "Quoc Tran-Dinh, Nhan H. Pham, Dzung T. Phan, and Lam M. Nguyen", "title": "A Hybrid Stochastic Optimization Framework for Stochastic Composite\n  Nonconvex Optimization", "comments": "49 pages, 2 tables, 9 figures", "journal-ref": null, "doi": null, "report-no": "UNC-STOR-2019.07.V1-03", "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new approach to develop stochastic optimization algorithms for\na class of stochastic composite and possibly nonconvex optimization problems.\nThe main idea is to combine two stochastic estimators to create a new hybrid\none. We first introduce our hybrid estimator and then investigate its\nfundamental properties to form a foundational theory for algorithmic\ndevelopment. Next, we apply our theory to develop several variants of\nstochastic gradient methods to solve both expectation and finite-sum composite\noptimization problems. Our first algorithm can be viewed as a variant of\nproximal stochastic gradient methods with a single-loop, but can achieve\n$\\mathcal{O}(\\sigma^3\\varepsilon^{-1} + \\sigma \\varepsilon^{-3})$-oracle\ncomplexity bound, matching the best-known ones from state-of-the-art\ndouble-loop algorithms in the literature, where $\\sigma > 0$ is the variance\nand $\\varepsilon$ is a desired accuracy. Then, we consider two different\nvariants of our method: adaptive step-size and restarting schemes that have\nsimilar theoretical guarantees as in our first algorithm. We also study two\nmini-batch variants of the proposed methods. In all cases, we achieve the\nbest-known complexity bounds under standard assumptions. We test our methods on\nseveral numerical examples with real datasets and compare them with\nstate-of-the-arts. Our numerical experiments show that the new methods are\ncomparable and, in many cases, outperform their competitors.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 18:12:37 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 02:21:49 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Tran-Dinh", "Quoc", ""], ["Pham", "Nhan H.", ""], ["Phan", "Dzung T.", ""], ["Nguyen", "Lam M.", ""]]}, {"id": "1907.03799", "submitter": "Vincenzo Lomonaco PhD", "authors": "Vincenzo Lomonaco, Davide Maltoni, Lorenzo Pellegrini", "title": "Rehearsal-Free Continual Learning over Small Non-I.I.D. Batches", "comments": "Accepted in the CLVision Workshop at CVPR2020: 12 pages, 7 figures, 5\n  tables, 3 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robotic vision is a field where continual learning can play a significant\nrole. An embodied agent operating in a complex environment subject to frequent\nand unpredictable changes is required to learn and adapt continuously. In the\ncontext of object recognition, for example, a robot should be able to learn\n(without forgetting) objects of never before seen classes as well as improving\nits recognition capabilities as new instances of already known classes are\ndiscovered. Ideally, continual learning should be triggered by the availability\nof short videos of single objects and performed on-line on on-board hardware\nwith fine-grained updates. In this paper, we introduce a novel continual\nlearning protocol based on the CORe50 benchmark and propose two rehearsal-free\ncontinual learning techniques, CWR* and AR1*, that can learn effectively even\nin the challenging case of nearly 400 small non-i.i.d. incremental batches. In\nparticular, our experiments show that AR1* can outperform other\nstate-of-the-art rehearsal-free techniques by more than 15% accuracy in some\ncases, with a very light and constant computational and memory overhead across\ntraining batches.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 18:32:25 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 21:18:49 GMT"}, {"version": "v3", "created": "Tue, 21 Apr 2020 16:13:12 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Lomonaco", "Vincenzo", ""], ["Maltoni", "Davide", ""], ["Pellegrini", "Lorenzo", ""]]}, {"id": "1907.03802", "submitter": "Carlos Rodr\\'iguez - Pardo", "authors": "Carlos Rodr\\'iguez - Pardo and Hakan Bilen", "title": "Personalised aesthetics with residual adapters", "comments": "12 pages, 4 figures. In Iberian Conference on Pattern Recognition and\n  Image Analysis proceedings", "journal-ref": null, "doi": "10.1007/978-3-030-31332-6_44", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of computational methods to evaluate aesthetics in photography has\ngained interest in recent years due to the popularization of convolutional\nneural networks and the availability of new annotated datasets. Most studies in\nthis area have focused on designing models that do not take into account\nindividual preferences for the prediction of the aesthetic value of pictures.\nWe propose a model based on residual learning that is capable of learning\nsubjective, user specific preferences over aesthetics in photography, while\nsurpassing the state-of-the-art methods and keeping a limited number of\nuser-specific parameters in the model. Our model can also be used for picture\nenhancement, and it is suitable for content-based or hybrid recommender systems\nin which the amount of computational resources is limited.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 18:40:16 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Pardo", "Carlos Rodr\u00edguez -", ""], ["Bilen", "Hakan", ""]]}, {"id": "1907.03813", "submitter": "Xiaoyi Gu", "authors": "Xiaoyi Gu, Leman Akoglu, Alessandro Rinaldo", "title": "Statistical Analysis of Nearest Neighbor Methods for Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nearest-neighbor (NN) procedures are well studied and widely used in both\nsupervised and unsupervised learning problems. In this paper we are concerned\nwith investigating the performance of NN-based methods for anomaly detection.\nWe first show through extensive simulations that NN methods compare favorably\nto some of the other state-of-the-art algorithms for anomaly detection based on\na set of benchmark synthetic datasets. We further consider the performance of\nNN methods on real datasets, and relate it to the dimensionality of the\nproblem. Next, we analyze the theoretical properties of NN-methods for anomaly\ndetection by studying a more general quantity called distance-to-measure (DTM),\noriginally developed in the literature on robust geometric and topological\ninference. We provide finite-sample uniform guarantees for the empirical DTM\nand use them to derive misclassification rates for anomalous observations under\nvarious settings. In our analysis we rely on Huber's contamination model and\nformulate mild geometric regularity assumptions on the underlying distribution\nof the data.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 18:58:35 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Gu", "Xiaoyi", ""], ["Akoglu", "Leman", ""], ["Rinaldo", "Alessandro", ""]]}, {"id": "1907.03816", "submitter": "Max Hopkins", "authors": "Max Hopkins, Daniel M. Kane, Shachar Lovett", "title": "The Power of Comparisons for Actively Learning Linear Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the world of big data, large but costly to label datasets dominate many\nfields. Active learning, a semi-supervised alternative to the standard\nPAC-learning model, was introduced to explore whether adaptive labeling could\nlearn concepts with exponentially fewer labeled samples. While previous results\nshow that active learning performs no better than its supervised alternative\nfor important concept classes such as linear separators, we show that by adding\nweak distributional assumptions and allowing comparison queries, active\nlearning requires exponentially fewer samples. Further, we show that these\nresults hold as well for a stronger model of learning called Reliable and\nProbably Useful (RPU) learning. In this model, our learner is not allowed to\nmake mistakes, but may instead answer \"I don't know.\" While previous negative\nresults showed this model to have intractably large sample complexity for label\nqueries, we show that comparison queries make RPU-learning at worst\nlogarithmically more expensive in both the passive and active regimes.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 19:08:59 GMT"}, {"version": "v2", "created": "Sat, 30 May 2020 22:46:48 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Hopkins", "Max", ""], ["Kane", "Daniel M.", ""], ["Lovett", "Shachar", ""]]}, {"id": "1907.03821", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey and Alex Pentland", "title": "Thompson Sampling on Symmetric $\\alpha$-Stable Bandits", "comments": "IJCAI 2019 Camera Ready with appendix, updated Theorem 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson Sampling provides an efficient technique to introduce prior\nknowledge in the multi-armed bandit problem, along with providing remarkable\nempirical performance. In this paper, we revisit the Thompson Sampling\nalgorithm under rewards drawn from symmetric $\\alpha$-stable distributions,\nwhich are a class of heavy-tailed probability distributions utilized in finance\nand economics, in problems such as modeling stock prices and human behavior. We\npresent an efficient framework for posterior inference, which leads to two\nalgorithms for Thompson Sampling in this setting. We prove finite-time regret\nbounds for both algorithms, and demonstrate through a series of experiments the\nstronger performance of Thompson Sampling in this setting. With our results, we\nprovide an exposition of symmetric $\\alpha$-stable distributions in sequential\ndecision-making, and enable sequential Bayesian inference in applications from\ndiverse fields in finance and complex systems that operate on heavy-tailed\nfeatures.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 19:32:22 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 20:20:16 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Dubey", "Abhimanyu", ""], ["Pentland", "Alex", ""]]}, {"id": "1907.03870", "submitter": "Ana Fern\\'andez del R\\'io", "authors": "Ana Fern\\'andez del R\\'io, Pei Pei Chen and \\'Africa Peri\\'a\\~nez", "title": "Profiling Players with Engagement Predictions", "comments": "Accepted for IEEE Conference on Games (CoG) 2019", "journal-ref": "2019 IEEE Conference in Games (CoG)", "doi": "10.1109/CIG.2019.8848074", "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The possibility of using player engagement predictions to profile high\nspending video game users is explored. In particular, individual-player\nsurvival curves in terms of days after first login, game level reached and\naccumulated playtime are used to classify players into different groups.\nLifetime value predictions for each player---generated using a deep learning\nmethod based on long short-term memory---are also included in the analysis, and\nthe relations between all these variables are thoroughly investigated. Our\nresults suggest this constitutes a promising approach to user profiling.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 01:13:38 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["del R\u00edo", "Ana Fern\u00e1ndez", ""], ["Chen", "Pei Pei", ""], ["Peri\u00e1\u00f1ez", "\u00c1frica", ""]]}, {"id": "1907.03875", "submitter": "Lorenzo Rosasco", "authors": "Enrico Cecini and Ernesto De Vito and Lorenzo Rosasco", "title": "Multi-Scale Vector Quantization with Reconstruction Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study a multi-scale approach to vector quantization. We\ndevelop an algorithm, dubbed reconstruction trees, inspired by decision trees.\nHere the objective is parsimonious reconstruction of unsupervised data, rather\nthan classification. Contrasted to more standard vector quantization methods,\nsuch as K-means, the proposed approach leverages a family of given partitions,\nto quickly explore the data in a coarse to fine-- multi-scale-- fashion. Our\nmain technical contribution is an analysis of the expected distortion achieved\nby the proposed algorithm, when the data are assumed to be sampled from a fixed\nunknown distribution. In this context, we derive both asymptotic and finite\nsample results under suitable regularity assumptions on the distribution. As a\nspecial case, we consider the setting where the data generating distribution is\nsupported on a compact Riemannian sub-manifold. Tools from differential\ngeometry and concentration of measure are useful in our analysis.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 21:11:24 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 13:49:45 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Cecini", "Enrico", ""], ["De Vito", "Ernesto", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1907.03907", "submitter": "Yulia Rubanova", "authors": "Yulia Rubanova, Ricky T. Q. Chen, David Duvenaud", "title": "Latent ODEs for Irregularly-Sampled Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series with non-uniform intervals occur in many applications, and are\ndifficult to model using standard recurrent neural networks (RNNs). We\ngeneralize RNNs to have continuous-time hidden dynamics defined by ordinary\ndifferential equations (ODEs), a model we call ODE-RNNs. Furthermore, we use\nODE-RNNs to replace the recognition network of the recently-proposed Latent ODE\nmodel. Both ODE-RNNs and Latent ODEs can naturally handle arbitrary time gaps\nbetween observations, and can explicitly model the probability of observation\ntimes using Poisson processes. We show experimentally that these ODE-based\nmodels outperform their RNN-based counterparts on irregularly-sampled data.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 23:21:32 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Rubanova", "Yulia", ""], ["Chen", "Ricky T. Q.", ""], ["Duvenaud", "David", ""]]}, {"id": "1907.03922", "submitter": "Chulhee Yun", "authors": "Chulhee Yun, Suvrit Sra, Ali Jadbabaie", "title": "Are deep ResNets provably better than linear predictors?", "comments": "15 pages. NeurIPS 2019 Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results in the literature indicate that a residual network (ResNet)\ncomposed of a single residual block outperforms linear predictors, in the sense\nthat all local minima in its optimization landscape are at least as good as the\nbest linear predictor. However, these results are limited to a single residual\nblock (i.e., shallow ResNets), instead of the deep ResNets composed of multiple\nresidual blocks. We take a step towards extending this result to deep ResNets.\nWe start by two motivating examples. First, we show that there exist datasets\nfor which all local minima of a fully-connected ReLU network are no better than\nthe best linear predictor, whereas a ResNet has strictly better local minima.\nSecond, we show that even at the global minimum, the representation obtained\nfrom the residual block outputs of a 2-block ResNet do not necessarily improve\nmonotonically over subsequent blocks, which highlights a fundamental difficulty\nin analyzing deep ResNets. Our main theorem on deep ResNets shows under simple\ngeometric conditions that, any critical point in the optimization landscape is\neither (i) at least as good as the best linear predictor; or (ii) the Hessian\nat this critical point has a strictly negative eigenvalue. Notably, our theorem\nshows that a chain of multiple skip-connections can improve the optimization\nlandscape, whereas existing results study direct skip-connections to the last\nhidden layer or output layer. Finally, we complement our results by showing\nbenign properties of the \"near-identity regions\" of deep ResNets, showing\ndepth-independent upper bounds for the risk attained at critical points as well\nas the Rademacher complexity.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 00:58:34 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 05:32:39 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Yun", "Chulhee", ""], ["Sra", "Suvrit", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "1907.03925", "submitter": "Jiangteng Li", "authors": "Jiangteng Li, Fei Wang", "title": "Non-technical Loss Detection with Statistical Profile Images Based on\n  Semi-supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to keep track of the operational state of power grid, the world's\nlargest sensor systems, smart grid, was built by deploying hundreds of millions\nof smart meters. Such system makes it possible to discover and make quick\nresponse to any hidden threat to the entire power grid. Non-technical losses\n(NTLs) have always been a major concern for its consequent security risks as\nwell as immeasurable revenue loss. However, various causes of NTL may have\ndifferent characteristics reflected in the data. Accurately capturing these\nanomalies faced with such large scale of collected data records is rather\ntricky as a result. In this paper, we proposed a new methodology of detecting\nabnormal electricity consumptions. We did a transformation of the collected\ntime-series data which turns it into an image representation that could well\nreflect users' relatively long term consumption behaviors. Inspired by the\nexcellent neural network architecture used for objective detection in computer\nvision domain, we designed our deep learning model that takes the transformed\nimages as input and yields joint featured inferred from the multiple aspects\nthe input provides. Considering the limited labeled samples, especially the\nabnormal ones, we used our model in a semi-supervised fashion that is brought\nout in recent years. The model is tested on samples which are verified by\non-field inspections and our method showed significant improvement.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 01:06:03 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Li", "Jiangteng", ""], ["Wang", "Fei", ""]]}, {"id": "1907.03947", "submitter": "Anna Guitart Atienza", "authors": "Anna Guitart, Ana Fern\\'andez del R\\'io and \\'Africa Peri\\'a\\~nez", "title": "Understanding Player Engagement and In-Game Purchasing Behavior with\n  Ensemble Learning", "comments": "Churn Prediction, Ensemble Methods, Survival Analysis, On- line\n  Games, User Behavior", "journal-ref": "Proceedings of GAME-ON'2019 AI and Simulation in Games, September\n  2019, breda, the Netherlands. ISBN 978-94-92859-08-2", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As video games attract more and more players, the major challenge for game\nstudios is to retain them. We present a deep behavioral analysis of churn (game\nabandonment) and what we called \"purchase churn\" (the transition from paying to\nnon-paying user). A series of churning behavior profiles are identified, which\nallows a classification of churners in terms of whether they eventually return\nto the game (false churners)--or start purchasing again (false purchase\nchurners)--and their subsequent behavior. The impact of excluding some or all\nof these churners from the training sample is then explored in several churn\nand purchase churn prediction models. Our results suggest that discarding\ncertain combinations of \"zombies\" (players whose activity is extremely\nsporadic) and false churners has a significant positive impact in all models\nconsidered.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 02:40:40 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Guitart", "Anna", ""], ["del R\u00edo", "Ana Fern\u00e1ndez", ""], ["Peri\u00e1\u00f1ez", "\u00c1frica", ""]]}, {"id": "1907.03976", "submitter": "Daniel Brown", "authors": "Daniel S. Brown, Wonjoon Goo, and Scott Niekum", "title": "Better-than-Demonstrator Imitation Learning via Automatically-Ranked\n  Demonstrations", "comments": "In proceedings of 3rd Conference on Robot Learning (CoRL) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of imitation learning is typically upper-bounded by the\nperformance of the demonstrator. While recent empirical results demonstrate\nthat ranked demonstrations allow for better-than-demonstrator performance,\npreferences over demonstrations may be difficult to obtain, and little is known\ntheoretically about when such methods can be expected to successfully\nextrapolate beyond the performance of the demonstrator. To address these\nissues, we first contribute a sufficient condition for better-than-demonstrator\nimitation learning and provide theoretical results showing why preferences over\ndemonstrations can better reduce reward function ambiguity when performing\ninverse reinforcement learning. Building on this theory, we introduce\nDisturbance-based Reward Extrapolation (D-REX), a ranking-based imitation\nlearning method that injects noise into a policy learned through behavioral\ncloning to automatically generate ranked demonstrations. These ranked\ndemonstrations are used to efficiently learn a reward function that can then be\noptimized using reinforcement learning. We empirically validate our approach on\nsimulated robot and Atari imitation learning benchmarks and show that D-REX\noutperforms standard imitation learning approaches and can significantly\nsurpass the performance of the demonstrator. D-REX is the first imitation\nlearning approach to achieve significant extrapolation beyond the\ndemonstrator's performance without additional side-information or supervision,\nsuch as rewards or human preferences. By generating rankings automatically, we\nshow that preference-based inverse reinforcement learning can be applied in\ntraditional imitation learning settings where only unlabeled demonstrations are\navailable.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 04:11:53 GMT"}, {"version": "v2", "created": "Sat, 13 Jul 2019 01:11:51 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 17:44:45 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Brown", "Daniel S.", ""], ["Goo", "Wonjoon", ""], ["Niekum", "Scott", ""]]}, {"id": "1907.03989", "submitter": "Jos\\'e Camacho", "authors": "J. Camacho, A.K. Smilde, E. Saccenti, J.A. Westerhuis", "title": "All Sparse PCA Models Are Wrong, But Some Are Useful. Part I:\n  Computation of Scores, Residuals and Explained Variance", "comments": null, "journal-ref": "Chemometrics and Intelligent Laboratory Systems, 2020, 196:\n  1039072-", "doi": "10.1016/j.chemolab.2019.103907", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Principal Component Analysis (sPCA) is a popular matrix factorization\napproach based on Principal Component Analysis (PCA) that combines variance\nmaximization and sparsity with the ultimate goal of improving data\ninterpretation. When moving from PCA to sPCA, there are a number of\nimplications that the practitioner needs to be aware of. A relevant one is that\nscores and loadings in sPCA may not be orthogonal. For this reason, the\ntraditional way of computing scores, residuals and variance explained that is\nused in the classical PCA cannot directly be applied to sPCA models. This also\naffects how sPCA components should be visualized. In this paper we illustrate\nthis problem both theoretically and numerically using simulations for several\nstate-of-the-art sPCA algorithms, and provide proper computation of the\ndifferent elements mentioned. We show that sPCA approaches present disparate\nand limited performance when modeling noise-free, sparse data. In a follow-up\npaper, we discuss the theoretical properties that lead to this problem.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 05:27:20 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Camacho", "J.", ""], ["Smilde", "A. K.", ""], ["Saccenti", "E.", ""], ["Westerhuis", "J. A.", ""]]}, {"id": "1907.04003", "submitter": "Anand Subramanian", "authors": "Anand Krishnamoorthy Subramanian, Nak Young Chong", "title": "Mean Spectral Normalization of Deep Neural Networks for Embedded\n  Automation", "comments": "8 pagesm IEEE CASE 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) have begun to thrive in the field of automation\nsystems, owing to the recent advancements in standardising various aspects such\nas architecture, optimization techniques, and regularization. In this paper, we\ntake a step towards a better understanding of Spectral Normalization (SN) and\nits potential for standardizing regularization of a wider range of Deep\nLearning models, following an empirical approach. We conduct several\nexperiments to study their training dynamics, in comparison with the ubiquitous\nBatch Normalization (BN) and show that SN increases the gradient sparsity and\ncontrols the gradient variance. Furthermore, we show that SN suffers from a\nphenomenon, we call the mean-drift effect, which mitigates its performance. We,\nthen, propose a weight reparameterization called as the Mean Spectral\nNormalization (MSN) to resolve the mean drift, thereby significantly improving\nthe network's performance. Our model performs ~16% faster as compared to BN in\npractice, and has fewer trainable parameters. We also show the performance of\nour MSN for small, medium, and large CNNs - 3-layer CNN, VGG7 and DenseNet-BC,\nrespectively - and unsupervised image generation tasks using Generative\nAdversarial Networks (GANs) to evaluate its applicability for a broad range of\nembedded automation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 06:24:22 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Subramanian", "Anand Krishnamoorthy", ""], ["Chong", "Nak Young", ""]]}, {"id": "1907.04004", "submitter": "Kwangho Kim", "authors": "Kwangho Kim, Edward H. Kennedy, and Ashley I. Naimi", "title": "Incremental Intervention Effects in Studies with Dropout and Many\n  Timepoints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern longitudinal studies collect feature data at many timepoints, often of\nthe same order of sample size. Such studies are typically affected by {dropout}\nand positivity violations. We tackle these problems by generalizing effects of\nrecent incremental interventions (which shift propensity scores rather than set\ntreatment values deterministically) to accommodate multiple outcomes and\nsubject dropout. We give an identifying expression for incremental effects when\ndropout is conditionally ignorable (without requiring treatment positivity),\nand derive the nonparametric efficiency bound for estimating such effects. Then\nwe present efficient nonparametric estimators, showing that they converge at\nfast parametric rates and yield uniform inferential guarantees, even when\nnuisance functions are estimated flexibly at slower rates. We also study the\nefficiency of incremental effects relative to more conventional deterministic\neffects in a novel infinite time horizon setting, where the number of\ntimepoints can grow with sample size, and show that incremental effects yield\nnear-exponential gains in this setup. Finally we conclude with simulations and\napply our methods in a study of the effect of low-dose aspirin on pregnancy\noutcomes.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 06:26:41 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 21:39:43 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Kim", "Kwangho", ""], ["Kennedy", "Edward H.", ""], ["Naimi", "Ashley I.", ""]]}, {"id": "1907.04018", "submitter": "Ben Mussay", "authors": "Ben Mussay, Margarita Osadchy, Vladimir Braverman, Samson Zhou, Dan\n  Feldman", "title": "Data-Independent Neural Pruning via Coresets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work showed empirically that large neural networks can be\nsignificantly reduced in size while preserving their accuracy. Model\ncompression became a central research topic, as it is crucial for deployment of\nneural networks on devices with limited computational and memory resources. The\nmajority of the compression methods are based on heuristics and offer no\nworst-case guarantees on the trade-off between the compression rate and the\napproximation error for an arbitrarily new sample. We propose the first\nefficient, data-independent neural pruning algorithm with a provable trade-off\nbetween its compression rate and the approximation error for any future test\nsample. Our method is based on the coreset framework, which finds a small\nweighted subset of points that provably approximates the original inputs.\nSpecifically, we approximate the output of a layer of neurons by a coreset of\nneurons in the previous layer and discard the rest. We apply this framework in\na layer-by-layer fashion from the top to the bottom. Unlike previous works, our\ncoreset is data independent, meaning that it provably guarantees the accuracy\nof the function for any input $x\\in \\mathbb{R}^d$, including an adversarial\none. We demonstrate the effectiveness of our method on popular network\narchitectures. In particular, our coresets yield 90\\% compression of the\nLeNet-300-100 architecture on MNIST while improving the accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 07:11:39 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 10:40:25 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 05:42:38 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Mussay", "Ben", ""], ["Osadchy", "Margarita", ""], ["Braverman", "Vladimir", ""], ["Zhou", "Samson", ""], ["Feldman", "Dan", ""]]}, {"id": "1907.04021", "submitter": "Zheng Li", "authors": "Zheng Li, Shi Shu", "title": "SVGD: A Virtual Gradients Descent Method for Stochastic Optimization", "comments": "12 pages, 12 figures, conference papers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by dynamic programming, we propose Stochastic Virtual Gradient\nDescent (SVGD) algorithm where the Virtual Gradient is defined by computational\ngraph and automatic differentiation. The method is computationally efficient\nand has little memory requirements. We also analyze the theoretical convergence\nproperties and implementation of the algorithm. Experimental results on\nmultiple datasets and network models show that SVGD has advantages over other\nstochastic optimization methods.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 07:28:13 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 11:13:32 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Li", "Zheng", ""], ["Shu", "Shi", ""]]}, {"id": "1907.04027", "submitter": "Xiaoou Pan", "authors": "Xiaoou Pan, Qiang Sun and Wen-Xin Zhou", "title": "Iteratively Reweighted $\\ell_1$-Penalized Robust Regression", "comments": "62 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates tradeoffs among optimization errors, statistical\nrates of convergence and the effect of heavy-tailed errors for high-dimensional\nrobust regression with nonconvex regularization. When the additive errors in\nlinear models have only bounded second moment, we show that iteratively\nreweighted $\\ell_1$-penalized adaptive Huber regression estimator satisfies\nexponential deviation bounds and oracle properties, including the oracle\nconvergence rate and variable selection consistency, under a weak beta-min\ncondition. Computationally, we need as many as $O(\\log s + \\log\\log d)$\niterations to reach such an oracle estimator, where $s$ and $d$ denote the\nsparsity and ambient dimension, respectively. Extension to a general class of\nrobust loss functions is also considered. Numerical studies lend strong support\nto our methodology and theory.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 07:45:04 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 06:52:11 GMT"}, {"version": "v3", "created": "Tue, 29 Dec 2020 08:21:42 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Pan", "Xiaoou", ""], ["Sun", "Qiang", ""], ["Zhou", "Wen-Xin", ""]]}, {"id": "1907.04028", "submitter": "Bin Yang", "authors": "Sean Bin Yang, Bin Yang", "title": "PathRank: A Multi-Task Learning Framework to Rank Paths in Spatial\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern navigation services often provide multiple paths connecting the same\nsource and destination for users to select. Hence, ranking such paths becomes\nincreasingly important, which directly affects the service quality. We present\nPathRank, a data-driven framework for ranking paths based on historical\ntrajectories using multi-task learning. If a trajectory used path P from source\ns to destination d, PathRank considers this as an evidence that P is preferred\nover all other paths from s to d. Thus, a path that is similar to P should have\na larger ranking score than a path that is dissimilar to P. Based on this\nintuition, PathRank models path ranking as a regression problem, where each\npath is associated with a ranking score.\n  To enable PathRank, we first propose an effective method to generate a\ncompact set of training data: for each trajectory, we generate a small set of\ndiversified paths. Next, we propose a multi-task learning framework to solve\nthe regression problem. In particular, a spatial network embedding is proposed\nto embed each vertex to a feature vector by considering both road network\ntopology and spatial properties, such as distances and travel times. Since a\npath is represented by a sequence of vertices, which is now a sequence of\nfeature vectors after embedding, recurrent neural network is applied to model\nthe sequence. The objective function is designed to consider errors on both\nranking scores and spatial properties, making the framework a multi-task\nlearning framework. Empirical studies on a substantial trajectory data set\noffer insight into the designed properties of the proposed framework and\nindicating that it is effective and practical.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 07:45:55 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Yang", "Sean Bin", ""], ["Yang", "Bin", ""]]}, {"id": "1907.04050", "submitter": "Luca Ambrogioni", "authors": "Luca Ambrogioni, Umut G\\\"u\\c{c}l\\\"u and Marcel van Gerven", "title": "k-GANs: Ensemble of Generative Models with Semi-Discrete Optimal\n  Transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are the state of the art in generative\nmodeling. Unfortunately, most GAN methods are susceptible to mode collapse,\nmeaning that they tend to capture only a subset of the modes of the true\ndistribution. A possible way of dealing with this problem is to use an ensemble\nof GANs, where (ideally) each network models a single mode. In this paper, we\nintroduce a principled method for training an ensemble of GANs using\nsemi-discrete optimal transport theory. In our approach, each generative\nnetwork models the transportation map between a point mass (Dirac measure) and\nthe restriction of the data distribution on a tile of a Voronoi tessellation\nthat is defined by the location of the point masses. We iteratively train the\ngenerative networks and the point masses until convergence. The resulting\nk-GANs algorithm has strong theoretical connection with the k-medoids\nalgorithm. In our experiments, we show that our ensemble method consistently\noutperforms baseline GANs.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 08:57:49 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Ambrogioni", "Luca", ""], ["G\u00fc\u00e7l\u00fc", "Umut", ""], ["van Gerven", "Marcel", ""]]}, {"id": "1907.04068", "submitter": "Alexis Bellot", "authors": "Alexis Bellot and Mihaela van der Schaar", "title": "Conditional Independence Testing using Generative Adversarial Networks", "comments": "Updated version published at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the hypothesis testing problem of detecting conditional\ndependence, with a focus on high-dimensional feature spaces. Our contribution\nis a new test statistic based on samples from a generative adversarial network\ndesigned to approximate directly a conditional distribution that encodes the\nnull hypothesis, in a manner that maximizes power (the rate of true negatives).\nWe show that such an approach requires only that density approximation be\nviable in order to ensure that we control type I error (the rate of false\npositives); in particular, no assumptions need to be made on the form of the\ndistributions or feature dependencies. Using synthetic simulations with\nhigh-dimensional data we demonstrate significant gains in power over competing\nmethods. In addition, we illustrate the use of our test to discover causal\nmarkers of disease in genetic data.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 10:24:40 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 19:03:57 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Bellot", "Alexis", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1907.04081", "submitter": "Alexis Bellot", "authors": "Alexis Bellot and Mihaela van der Schaar", "title": "Kernel Hypothesis Testing with Set-valued Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general framework for hypothesis testing on distributions of\nsets of individual examples. Sets may represent many common data sources such\nas groups of observations in time series, collections of words in text or a\nbatch of images of a given phenomenon. This observation pattern, however,\ndiffers from the common assumptions required for hypothesis testing: each set\ndiffers in size, may have differing levels of noise, and also may incorporate\nnuisance variability, irrelevant for the analysis of the phenomenon of\ninterest; all features that bias test decisions if not accounted for. In this\npaper, we propose to interpret sets as independent samples from a collection of\nlatent probability distributions, and introduce kernel two-sample and\nindependence tests in this latent space of distributions. We prove the\nconsistency of tests and observe them to outperform in a wide range of\nsynthetic experiments. Finally, we showcase their use in practice with\nexperiments of healthcare and climate data, where previously heuristics were\nneeded for feature extraction and testing.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 11:17:35 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 10:43:08 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 08:21:13 GMT"}, {"version": "v4", "created": "Tue, 2 Feb 2021 09:38:54 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Bellot", "Alexis", ""], ["van der Schaar", "Mihaela", ""]]}, {"id": "1907.04092", "submitter": "Chunsheng Liu", "authors": "Chunsheng Liu, Hong Shan, Chunlei Chen", "title": "Tensor p-shrinkage nuclear norm for low-rank tensor completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, a new definition of tensor p-shrinkage nuclear norm (p-TNN) is\nproposed based on tensor singular value decomposition (t-SVD). In particular,\nit can be proved that p-TNN is a better approximation of the tensor average\nrank than the tensor nuclear norm when p < 1. Therefore, by employing the\np-shrinkage nuclear norm, a novel low-rank tensor completion (LRTC) model is\nproposed to estimate a tensor from its partial observations. Statistically, the\nupper bound of recovery error is provided for the LRTC model. Furthermore, an\nefficient algorithm, accelerated by the adaptive momentum scheme, is developed\nto solve the resulting nonconvex optimization problem. It can be further\nguaranteed that the algorithm enjoys a global convergence rate under the\nsmoothness assumption. Numerical experiments conducted on both synthetic and\nreal-world data sets verify our results and demonstrate the superiority of our\np-TNN in LRTC problems over several state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 11:37:15 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Liu", "Chunsheng", ""], ["Shan", "Hong", ""], ["Chen", "Chunlei", ""]]}, {"id": "1907.04102", "submitter": "Christian Wachinger", "authors": "Christian Wachinger, Benjamin Gutierrez Becker, Anna Rieckmann,\n  Sebastian P\\\"olsterl", "title": "Quantifying Confounding Bias in Neuroimaging Datasets with Causal\n  Inference", "comments": "MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroimaging datasets keep growing in size to address increasingly complex\nmedical questions. However, even the largest datasets today alone are too small\nfor training complex machine learning models. A potential solution is to\nincrease sample size by pooling scans from several datasets. In this work, we\ncombine 12,207 MRI scans from 15 studies and show that simple pooling is often\nill-advised due to introducing various types of biases in the training data.\nFirst, we systematically define these biases. Second, we detect bias by\nexperimentally showing that scans can be correctly assigned to their respective\ndataset with 73.3% accuracy. Finally, we propose to tell causal from\nconfounding factors by quantifying the extent of confounding and causality in a\nsingle dataset using causal inference. We achieve this by finding the simplest\ngraphical model in terms of Kolmogorov complexity. As Kolmogorov complexity is\nnot directly computable, we employ the minimum description length to\napproximate it. We empirically show that our approach is able to estimate\nplausible causal relationships from real neuroimaging data.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 11:57:22 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Wachinger", "Christian", ""], ["Becker", "Benjamin Gutierrez", ""], ["Rieckmann", "Anna", ""], ["P\u00f6lsterl", "Sebastian", ""]]}, {"id": "1907.04108", "submitter": "Konstantinos Spiliopoulos", "authors": "Justin Sirignano and Konstantinos Spiliopoulos", "title": "Scaling Limit of Neural Networks with the Xavier Initialization and\n  Convergence to a Global Minimum", "comments": "The results of this technical note have been extended and generalized\n  in arXiv:1911.07304. In the present note the full details for the proof of\n  the special case studied here are presented", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze single-layer neural networks with the Xavier initialization in the\nasymptotic regime of large numbers of hidden units and large numbers of\nstochastic gradient descent training steps. The evolution of the neural network\nduring training can be viewed as a stochastic system and, using techniques from\nstochastic analysis, we prove the neural network converges in distribution to a\nrandom ODE with a Gaussian distribution. The limit is completely different than\nin the typical mean-field results for neural networks due to the\n$\\frac{1}{\\sqrt{N}}$ normalization factor in the Xavier initialization (versus\nthe $\\frac{1}{N}$ factor in the typical mean-field framework). Although the\npre-limit problem of optimizing a neural network is non-convex (and therefore\nthe neural network may converge to a local minimum), the limit equation\nminimizes a (quadratic) convex objective function and therefore converges to a\nglobal minimum. Furthermore, under reasonable assumptions, the matrix in the\nlimiting quadratic objective function is positive definite and thus the neural\nnetwork (in the limit) will converge to a global minimum with zero loss on the\ntraining set.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 12:17:03 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 13:50:15 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Sirignano", "Justin", ""], ["Spiliopoulos", "Konstantinos", ""]]}, {"id": "1907.04135", "submitter": "James Wexler", "authors": "James Wexler, Mahima Pushkarna, Tolga Bolukbasi, Martin Wattenberg,\n  Fernanda Viegas, Jimbo Wilson", "title": "The What-If Tool: Interactive Probing of Machine Learning Models", "comments": "IEEE VIS (VAST) 2019", "journal-ref": null, "doi": "10.1109/TVCG.2019.2934619", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in developing and deploying Machine Learning (ML) systems is\nunderstanding their performance across a wide range of inputs. To address this\nchallenge, we created the What-If Tool, an open-source application that allows\npractitioners to probe, visualize, and analyze ML systems, with minimal coding.\nThe What-If Tool lets practitioners test performance in hypothetical\nsituations, analyze the importance of different data features, and visualize\nmodel behavior across multiple models and subsets of input data. It also lets\npractitioners measure systems according to multiple ML fairness metrics. We\ndescribe the design of the tool, and report on real-life usage at different\norganizations.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 13:16:24 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 17:00:59 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Wexler", "James", ""], ["Pushkarna", "Mahima", ""], ["Bolukbasi", "Tolga", ""], ["Wattenberg", "Martin", ""], ["Viegas", "Fernanda", ""], ["Wilson", "Jimbo", ""]]}, {"id": "1907.04138", "submitter": "Michael Oberst", "authors": "Michael Oberst, Fredrik D. Johansson, Dennis Wei, Tian Gao, Gabriel\n  Brat, David Sontag, Kush R. Varshney", "title": "Characterization of Overlap in Observational Studies", "comments": "To appear at AISTATS 2020", "journal-ref": "Proceedings of the Twenty Third International Conference on\n  Artificial Intelligence and Statistics, PMLR 108:788-798, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overlap between treatment groups is required for non-parametric estimation of\ncausal effects. If a subgroup of subjects always receives the same\nintervention, we cannot estimate the effect of intervention changes on that\nsubgroup without further assumptions. When overlap does not hold globally,\ncharacterizing local regions of overlap can inform the relevance of causal\nconclusions for new subjects, and can help guide additional data collection. To\nhave impact, these descriptions must be interpretable for downstream users who\nare not machine learning experts, such as policy makers. We formalize overlap\nestimation as a problem of finding minimum volume sets subject to coverage\nconstraints and reduce this problem to binary classification with Boolean rule\nclassifiers. We then generalize this method to estimate overlap in off-policy\npolicy evaluation. In several real-world applications, we demonstrate that\nthese rules have comparable accuracy to black-box estimators and provide\nintuitive and informative explanations that can inform policy making.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 13:18:47 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 07:49:35 GMT"}, {"version": "v3", "created": "Thu, 4 Jun 2020 01:46:10 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Oberst", "Michael", ""], ["Johansson", "Fredrik D.", ""], ["Wei", "Dennis", ""], ["Gao", "Tian", ""], ["Brat", "Gabriel", ""], ["Sontag", "David", ""], ["Varshney", "Kush R.", ""]]}, {"id": "1907.04150", "submitter": "Chong Peng", "authors": "Chong Peng, Zhao Kang, Chenglizhao Chen, and Qiang Cheng", "title": "Nonnegative Matrix Factorization with Local Similarity Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing nonnegative matrix factorization methods focus on learning global\nstructure of the data to construct basis and coefficient matrices, which\nignores the local structure that commonly exists among data. In this paper, we\npropose a new type of nonnegative matrix factorization method, which learns\nlocal similarity and clustering in a mutually enhancing way. The learned new\nrepresentation is more representative in that it better reveals inherent\ngeometric property of the data. Nonlinear expansion is given and efficient\nmultiplicative updates are developed with theoretical convergence guarantees.\nExtensive experimental results have confirmed the effectiveness of the proposed\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 13:25:50 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Peng", "Chong", ""], ["Kang", "Zhao", ""], ["Chen", "Chenglizhao", ""], ["Cheng", "Qiang", ""]]}, {"id": "1907.04152", "submitter": "Adam Dobrakowski", "authors": "Adam Gabriel Dobrakowski, Agnieszka Mykowiecka, Ma{\\l}gorzata\n  Marciniak, Wojciech Jaworski, Przemys{\\l}aw Biecek", "title": "Interpretable Segmentation of Medical Free-Text Records Based on Word\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Is it true that patients with similar conditions get similar diagnoses? In\nthis paper we show NLP methods and a unique corpus of documents to validate\nthis claim. We (1) introduce a method for representation of medical visits\nbased on free-text descriptions recorded by doctors, (2) introduce a new method\nfor clustering of patients' visits and (3) present an~application of the\nproposed method on a corpus of 100,000 visits. With the proposed method we\nobtained stable and separated segments of visits which were positively\nvalidated against final medical diagnoses. We show how the presented algorithm\nmay be used to aid doctors during their practice.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 15:22:04 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 11:13:32 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 10:09:48 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Dobrakowski", "Adam Gabriel", ""], ["Mykowiecka", "Agnieszka", ""], ["Marciniak", "Ma\u0142gorzata", ""], ["Jaworski", "Wojciech", ""], ["Biecek", "Przemys\u0142aw", ""]]}, {"id": "1907.04155", "submitter": "Vincent Fortuin", "authors": "Vincent Fortuin, Dmitry Baranchuk, Gunnar R\\\"atsch, Stephan Mandt", "title": "GP-VAE: Deep Probabilistic Time Series Imputation", "comments": "Accepted for publication at the 23rd International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate time series with missing values are common in areas such as\nhealthcare and finance, and have grown in number and complexity over the years.\nThis raises the question whether deep learning methodologies can outperform\nclassical data imputation methods in this domain. However, naive applications\nof deep learning fall short in giving reliable confidence estimates and lack\ninterpretability. We propose a new deep sequential latent variable model for\ndimensionality reduction and data imputation. Our modeling assumption is simple\nand interpretable: the high dimensional time series has a lower-dimensional\nrepresentation which evolves smoothly in time according to a Gaussian process.\nThe non-linear dimensionality reduction in the presence of missing data is\nachieved using a VAE approach with a novel structured variational\napproximation. We demonstrate that our approach outperforms several classical\nand deep learning-based data imputation methods on high-dimensional data from\nthe domains of computer vision and healthcare, while additionally improving the\nsmoothness of the imputations and providing interpretable uncertainty\nestimates.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 13:34:49 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 11:44:12 GMT"}, {"version": "v3", "created": "Fri, 12 Jul 2019 12:18:34 GMT"}, {"version": "v4", "created": "Sat, 19 Oct 2019 12:14:48 GMT"}, {"version": "v5", "created": "Thu, 20 Feb 2020 14:36:34 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Fortuin", "Vincent", ""], ["Baranchuk", "Dmitry", ""], ["R\u00e4tsch", "Gunnar", ""], ["Mandt", "Stephan", ""]]}, {"id": "1907.04164", "submitter": "Guodong Zhang", "authors": "Guodong Zhang, Lala Li, Zachary Nado, James Martens, Sushant Sachdeva,\n  George E. Dahl, Christopher J. Shallue, Roger Grosse", "title": "Which Algorithmic Choices Matter at Which Batch Sizes? Insights From a\n  Noisy Quadratic Model", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing the batch size is a popular way to speed up neural network\ntraining, but beyond some critical batch size, larger batch sizes yield\ndiminishing returns. In this work, we study how the critical batch size changes\nbased on properties of the optimization algorithm, including acceleration and\npreconditioning, through two different lenses: large scale experiments, and\nanalysis of a simple noisy quadratic model (NQM). We experimentally demonstrate\nthat optimization algorithms that employ preconditioning, specifically Adam and\nK-FAC, result in much larger critical batch sizes than stochastic gradient\ndescent with momentum. We also demonstrate that the NQM captures many of the\nessential features of real neural network training, despite being drastically\nsimpler to work with. The NQM predicts our results with preconditioned\noptimizers, previous results with accelerated gradient descent, and other\nresults around optimal learning rates and large batch training, making it a\nuseful tool to generate testable predictions about neural network optimization.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 13:44:10 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 14:28:48 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Zhang", "Guodong", ""], ["Li", "Lala", ""], ["Nado", "Zachary", ""], ["Martens", "James", ""], ["Sachdeva", "Sushant", ""], ["Dahl", "George E.", ""], ["Shallue", "Christopher J.", ""], ["Grosse", "Roger", ""]]}, {"id": "1907.04197", "submitter": "Desmond Ong", "authors": "Zhengxuan Wu, Xiyu Zhang, Tan Zhi-Xuan, Jamil Zaki, Desmond C. Ong", "title": "Attending to Emotional Narratives", "comments": "Accepted at IEEE Affective Computing and Intelligent Interaction\n  (ACII) 2019; 6 pages + 1 page ref; 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms in deep neural networks have achieved excellent\nperformance on sequence-prediction tasks. Here, we show that these\nrecently-proposed attention-based mechanisms---in particular, the Transformer\nwith its parallelizable self-attention layers, and the Memory Fusion Network\nwith attention across modalities and time---also generalize well to multimodal\ntime-series emotion recognition. Using a recently-introduced dataset of\nemotional autobiographical narratives, we adapt and apply these two attention\nmechanisms to predict emotional valence over time. Our models perform extremely\nwell, in some cases reaching a performance comparable with human raters. We end\nwith a discussion of the implications of attention mechanisms to affective\ncomputing.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 03:50:43 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Wu", "Zhengxuan", ""], ["Zhang", "Xiyu", ""], ["Zhi-Xuan", "Tan", ""], ["Zaki", "Jamil", ""], ["Ong", "Desmond C.", ""]]}, {"id": "1907.04201", "submitter": "Cem Tekin", "authors": "Alihan H\\\"uy\\\"uk and Cem Tekin", "title": "Thompson Sampling for Combinatorial Network Optimization in Unknown\n  Environments", "comments": "14 pages, 3 figures. Accepted for publication in the IEEE/ACM\n  Transactions on Networking. arXiv admin note: text overlap with\n  arXiv:1809.02707", "journal-ref": "IEEE/ACM Transactions on Networking, vol. 28, no. 6, pp.\n  2836-2849, Dec. 2020", "doi": "10.1109/TNET.2020.3025904", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence maximization, adaptive routing, and dynamic spectrum allocation all\nrequire choosing the right action from a large set of alternatives. Thanks to\nthe advances in combinatorial optimization, these and many similar problems can\nbe efficiently solved given an environment with known stochasticity. In this\npaper, we take this one step further and focus on combinatorial optimization in\nunknown environments. We consider a very general learning framework called\ncombinatorial multi-armed bandit with probabilistically triggered arms and a\nvery powerful Bayesian algorithm called Combinatorial Thompson Sampling (CTS).\nUnder the semi-bandit feedback model and assuming access to an oracle without\nknowing the expected base arm outcomes beforehand, we show that when the\nexpected reward is Lipschitz continuous in the expected base arm outcomes CTS\nachieves $O(\\sum_{i =1}^m\\log T/(p_i\\Delta_i))$ regret and\n$O(\\max\\{\\mathbb{E}[m\\sqrt{T\\log T/p^*}],\\mathbb{E}[m^2/p^*]\\})$ Bayesian\nregret, where $m$ denotes the number of base arms, $p_i$ and $\\Delta_i$ denote\nthe minimum non-zero triggering probability and the minimum suboptimality gap\nof base arm $i$ respectively, $T$ denotes the time horizon, and $p^*$ denotes\nthe overall minimum non-zero triggering probability. We also show that when the\nexpected reward satisfies the triggering probability modulated Lipschitz\ncontinuity, CTS achieves $O(\\max\\{m\\sqrt{T\\log T},m^2\\})$ Bayesian regret, and\nwhen triggering probabilities are non-zero for all base arms, CTS achieves\n$O(1/p^*\\log(1/p^*))$ regret independent of the time horizon. Finally, we\nnumerically compare CTS with algorithms based on upper confidence bounds in\nseveral networking problems and show that CTS outperforms these algorithms by\nat least an order of magnitude in majority of the cases.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 17:03:00 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 09:25:32 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 17:22:06 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["H\u00fcy\u00fck", "Alihan", ""], ["Tekin", "Cem", ""]]}, {"id": "1907.04202", "submitter": "Masashi Okada Dr", "authors": "Masashi Okada, Tadahiro Taniguchi", "title": "Variational Inference MPC for Bayesian Model-based Reinforcement\n  Learning", "comments": "Accepted to CoRL2019. Camera-ready ver", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent studies on model-based reinforcement learning (MBRL), incorporating\nuncertainty in forward dynamics is a state-of-the-art strategy to enhance\nlearning performance, making MBRLs competitive to cutting-edge model free\nmethods, especially in simulated robotics tasks. Probabilistic ensembles with\ntrajectory sampling (PETS) is a leading type of MBRL, which employs Bayesian\ninference to dynamics modeling and model predictive control (MPC) with\nstochastic optimization via the cross entropy method (CEM). In this paper, we\npropose a novel extension to the uncertainty-aware MBRL. Our main contributions\nare twofold: Firstly, we introduce a variational inference MPC, which\nreformulates various stochastic methods, including CEM, in a Bayesian fashion.\nSecondly, we propose a novel instance of the framework, called probabilistic\naction ensembles with trajectory sampling (PaETS). As a result, our Bayesian\nMBRL can involve multimodal uncertainties both in dynamics and optimal\ntrajectories. In comparison to PETS, our method consistently improves\nasymptotic performance on several challenging locomotion tasks.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 01:54:08 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 01:03:08 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Okada", "Masashi", ""], ["Taniguchi", "Tadahiro", ""]]}, {"id": "1907.04212", "submitter": "Koichi Tojo", "authors": "Koichi Tojo, Taro Yoshino", "title": "On a method to construct exponential families by representation theory", "comments": "Conference paper at Geometric Science of Information 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.RT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exponential family plays an important role in information geometry. In\narXiv:1811.01394, we introduced a method to construct an exponential family\n$\\mathcal{P}=\\{p_\\theta\\}_{\\theta\\in\\Theta}$ on a homogeneous space $G/H$ from\na pair $(V,v_0)$. Here $V$ is a representation of $G$ and $v_0$ is an $H$-fixed\nvector in $V$. Then the following questions naturally arise: (Q1) when is the\ncorrespondence $\\theta\\mapsto p_\\theta$ injective? (Q2) when do distinct pairs\n$(V,v_0)$ and $(V',v_0')$ generate the same family? In this paper, we answer\nthese two questions (Theorems 1 and 2). Moreover, in Section 3, we consider the\ncase $(G,H)=(\\mathbb{R}_{>0}, \\{1\\})$ with a certain representation on\n$\\mathbb{R}^2$. Then we see the family obtained by our method is essentially\ngeneralized inverse Gaussian distribution (GIG).\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 06:43:58 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Tojo", "Koichi", ""], ["Yoshino", "Taro", ""]]}, {"id": "1907.04214", "submitter": "Boris Belousov", "authors": "Boris Belousov, Jan Peters", "title": "Entropic Regularization of Markov Decision Processes", "comments": "16 pages, 4 figures, updated formatting, arXiv admin note: text\n  overlap with arXiv:1801.00056", "journal-ref": "Entropy 2019, 21(7), 674", "doi": "10.3390/e21070674", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An optimal feedback controller for a given Markov decision process (MDP) can\nin principle be synthesized by value or policy iteration. However, if the\nsystem dynamics and the reward function are unknown, a learning agent must\ndiscover an optimal controller via direct interaction with the environment.\nSuch interactive data gathering commonly leads to divergence towards dangerous\nor uninformative regions of the state space unless additional regularization\nmeasures are taken. Prior works proposed bounding the information loss measured\nby the Kullback-Leibler (KL) divergence at every policy improvement step to\neliminate instability in the learning dynamics. In this paper, we consider a\nbroader family of $f$-divergences, and more concretely $\\alpha$-divergences,\nwhich inherit the beneficial property of providing the policy improvement step\nin closed form at the same time yielding a corresponding dual objective for\npolicy evaluation. Such entropic proximal policy optimization view gives a\nunified perspective on compatible actor-critic architectures. In particular,\ncommon least-squares value function estimation coupled with advantage-weighted\nmaximum likelihood policy improvement is shown to correspond to the Pearson\n$\\chi^2$-divergence penalty. Other actor-critic pairs arise for various choices\nof the penalty-generating function $f$. On a concrete instantiation of our\nframework with the $\\alpha$-divergence, we carry out asymptotic analysis of the\nsolutions for different values of $\\alpha$ and demonstrate the effects of the\ndivergence function choice on common standard reinforcement learning problems.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 15:02:56 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 07:12:31 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Belousov", "Boris", ""], ["Peters", "Jan", ""]]}, {"id": "1907.04223", "submitter": "Donald Hulsey", "authors": "Donald Waagen, Katie Rainey, Jamie Gantert, David Gray, Megan King, M.\n  Shane Thompson, Jonathan Barton, Will Waldron, Samantha Livingston, and Don\n  Hulsey", "title": "Characterizing Inter-Layer Functional Mappings of Deep Learning Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning architectures have demonstrated state-of-the-art performance\nfor object classification and have become ubiquitous in commercial products.\nThese methods are often applied without understanding (a) the difficulty of a\nclassification task given the input data, and (b) how a specific deep learning\narchitecture transforms that data. To answer (a) and (b), we illustrate the\nutility of a multivariate nonparametric estimator of class separation, the\nHenze-Penrose (HP) statistic, in the original as well as layer-induced\nrepresentations. Given an $N$-class problem, our contribution defines the\n$C(N,2)$ combinations of HP statistics as a sample from a distribution of\nclass-pair separations. This allows us to characterize the distributional\nchange to class separation induced at each layer of the model. Fisher\npermutation tests are used to detect statistically significant changes within a\nmodel. By comparing the HP statistic distributions between layers, one can\nstatistically characterize: layer adaptation during training, the contribution\nof each layer to the classification task, and the presence or absence of\nconsistency between training and validation data. This is demonstrated for a\nsimple deep neural network using CIFAR10 with random-labels, CIFAR10, and MNIST\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 14:58:59 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 23:23:37 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Waagen", "Donald", ""], ["Rainey", "Katie", ""], ["Gantert", "Jamie", ""], ["Gray", "David", ""], ["King", "Megan", ""], ["Thompson", "M. Shane", ""], ["Barton", "Jonathan", ""], ["Waldron", "Will", ""], ["Livingston", "Samantha", ""], ["Hulsey", "Don", ""]]}, {"id": "1907.04232", "submitter": "Sebastian U. Stich", "authors": "Sebastian U. Stich", "title": "Unified Optimal Analysis of the (Stochastic) Gradient Method", "comments": "11 pages, version 2 fixes typos and case distinction in the proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we give a simple proof for the convergence of stochastic\ngradient (SGD) methods on $\\mu$-convex functions under a (milder than standard)\n$L$-smoothness assumption. We show that for carefully chosen stepsizes SGD\nconverges after $T$ iterations as $O\\left( LR^2 \\exp\n\\bigl[-\\frac{\\mu}{4L}T\\bigr] + \\frac{\\sigma^2}{\\mu T} \\right)$ where $\\sigma^2$\nmeasures the variance in the stochastic noise. For deterministic gradient\ndescent (GD) and SGD in the interpolation setting we have $\\sigma^2 =0$ and we\nrecover the exponential convergence rate. The bound matches with the best known\niteration complexity of GD and SGD, up to constants.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 15:14:25 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 13:14:42 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Stich", "Sebastian U.", ""]]}, {"id": "1907.04233", "submitter": "Richard Hugh Moulton", "authors": "Richard Hugh Moulton, Herna L. Viktor, Nathalie Japkowicz, Jo\\~ao Gama", "title": "Contextual One-Class Classification in Data Streams", "comments": "49 pages, 18 figures, 2 appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, the one-class classification problem occurs when\ntraining instances are only available from one class. It has been observed that\nmaking use of this class's structure, or its different contexts, may improve\none-class classifier performance. Although this observation has been\ndemonstrated for static data, a rigorous application of the idea within the\ndata stream environment is lacking. To address this gap, we propose the use of\ncontext to guide one-class classifier learning in data streams, paying\nparticular attention to the challenges presented by the dynamic learning\nenvironment. We present three frameworks that learn contexts and conduct\nexperiments with synthetic and benchmark data streams. We conclude that the\nparadigm of contexts in data streams can be used to improve the performance of\nstreaming one-class classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 15:14:38 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Moulton", "Richard Hugh", ""], ["Viktor", "Herna L.", ""], ["Japkowicz", "Nathalie", ""], ["Gama", "Jo\u00e3o", ""]]}, {"id": "1907.04240", "submitter": "Xihaier Luo", "authors": "Xihaier Luo, Ahsan Kareem", "title": "Bayesian deep learning with hierarchical prior: Predictions from limited\n  and noisy data", "comments": "33 pages, 11 figures", "journal-ref": "Structural Safety, 84, p.101918 (2020)", "doi": "10.1016/j.strusafe.2019.101918", "report-no": null, "categories": "stat.ML cs.LG eess.SP physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Datasets in engineering applications are often limited and contaminated,\nmainly due to unavoidable measurement noise and signal distortion. Thus, using\nconventional data-driven approaches to build a reliable discriminative model,\nand further applying this identified surrogate to uncertainty analysis remains\nto be very challenging. A deep learning approach is presented to provide\npredictions based on limited and noisy data. To address noise perturbation, the\nBayesian learning method that naturally facilitates an automatic updating\nmechanism is considered to quantify and propagate model uncertainties into\npredictive quantities. Specifically, hierarchical Bayesian modeling (HBM) is\nfirst adopted to describe model uncertainties, which allows the prior\nassumption to be less subjective, while also makes the proposed surrogate more\nrobust. Next, the Bayesian inference is seamlessly integrated into the DL\nframework, which in turn supports probabilistic programming by yielding a\nprobability distribution of the quantities of interest rather than their point\nestimates. Variational inference (VI) is implemented for the posterior\ndistribution analysis where the intractable marginalization of the likelihood\nfunction over parameter space is framed in an optimization format, and\nstochastic gradient descent method is applied to solve this optimization\nproblem. Finally, Monte Carlo simulation is used to obtain an unbiased\nestimator in the predictive phase of Bayesian inference, where the proposed\nBayesian deep learning (BDL) scheme is able to offer confidence bounds for the\noutput estimation by analyzing propagated uncertainties. The effectiveness of\nBayesian shrinkage is demonstrated in improving predictive performance using\ncontaminated data, and various examples are provided to illustrate concepts,\nmethodologies, and algorithms of this proposed BDL modeling technique.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 15:37:40 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Luo", "Xihaier", ""], ["Kareem", "Ahsan", ""]]}, {"id": "1907.04275", "submitter": "Seonguk Seo", "authors": "Seonguk Seo, Yumin Suh, Dongwan Kim, Geeho Kim, Jongwoo Han, Bohyung\n  Han", "title": "Learning to Optimize Domain Specific Normalization for Domain\n  Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a simple but effective multi-source domain generalization\ntechnique based on deep neural networks by incorporating optimized\nnormalization layers that are specific to individual domains. Our approach\nemploys multiple normalization methods while learning separate affine\nparameters per domain. For each domain, the activations are normalized by a\nweighted average of multiple normalization statistics. The normalization\nstatistics are kept track of separately for each normalization type if\nnecessary. Specifically, we employ batch and instance normalizations in our\nimplementation to identify the best combination of these two normalization\nmethods in each domain. The optimized normalization layers are effective to\nenhance the generalizability of the learned model. We demonstrate the\nstate-of-the-art accuracy of our algorithm in the standard domain\ngeneralization benchmarks, as well as viability to further tasks such as\nmulti-source domain adaptation and domain generalization in the presence of\nlabel noise.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 16:24:31 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 15:56:47 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 07:10:51 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Seo", "Seonguk", ""], ["Suh", "Yumin", ""], ["Kim", "Dongwan", ""], ["Kim", "Geeho", ""], ["Han", "Jongwoo", ""], ["Han", "Bohyung", ""]]}, {"id": "1907.04318", "submitter": "Ahmed BaniMustafa Dr.", "authors": "Ahmed BaniMustafa and Nigel Hardy", "title": "Computer-Aided Data Mining: Automating a Novel Knowledge Discovery and\n  Data Mining Process Model for Metabolomics", "comments": "arXiv admin note: text overlap with arXiv:1907.03755", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.DB cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents MeKDDaM-SAGA, computer-aided automation software for\nimplementing a novel knowledge discovery and data mining process model that was\ndesigned for performing justifiable, traceable and reproducible metabolomics\ndata analysis. The process model focuses on achieving metabolomics analytical\nobjectives and on considering the nature of its involved data. MeKDDaM-SAGA was\nsuccessfully used for guiding the process model execution in a number of\nmetabolomics applications. It satisfies the requirements of the proposed\nprocess model design and execution. The software realises the process model\nlayout, structure and flow and it enables its execution externally using\nvarious data mining and machine learning tools or internally using a number of\nembedded facilities that were built for performing a number of automated\nactivities such as data preprocessing, data exploration, data acclimatization,\nmodelling, evaluation and visualization. MeKDDaM-SAGA was developed using\nobject-oriented software engineering methodology and was constructed in Java.\nIt consists of 241 design classes that were designed to implement 27 use-cases.\nThe software uses an XML database to guarantee portability and uses a GUI\ninterface to ensure its user-friendliness. It implements an internal embedded\nversion control system that is used to realise and manage the process flow,\nfeedback and iterations and to enable undoing and redoing the execution of the\nprocess phases, activities, and the internal tasks within its phases.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 01:14:53 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["BaniMustafa", "Ahmed", ""], ["Hardy", "Nigel", ""]]}, {"id": "1907.04358", "submitter": "Shruthi Chari", "authors": "Shruthi Chari, Miao Qi, Nkcheniyere N. Agu, Oshani Seneviratne, James\n  P. McCusker, Kristin P. Bennett, Amar K. Das, Deborah L. McGuinness", "title": "Making Study Populations Visible through Knowledge Graphs", "comments": "16 pages, 4 figures, 1 table, accepted to the ISWC 2019 Resources\n  Track (https://iswc2019.semanticweb.org/call-for-resources-track-papers/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO q-bio.PE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Treatment recommendations within Clinical Practice Guidelines (CPGs) are\nlargely based on findings from clinical trials and case studies, referred to\nhere as research studies, that are often based on highly selective clinical\npopulations, referred to here as study cohorts. When medical practitioners\napply CPG recommendations, they need to understand how well their patient\npopulation matches the characteristics of those in the study cohort, and thus\nare confronted with the challenges of locating the study cohort information and\nmaking an analytic comparison. To address these challenges, we develop an\nontology-enabled prototype system, which exposes the population descriptions in\nresearch studies in a declarative manner, with the ultimate goal of allowing\nmedical practitioners to better understand the applicability and\ngeneralizability of treatment recommendations. We build a Study Cohort Ontology\n(SCO) to encode the vocabulary of study population descriptions, that are often\nreported in the first table in the published work, thus they are often referred\nto as Table 1. We leverage the well-used Semanticscience Integrated Ontology\n(SIO) for defining property associations between classes. Further, we model the\nkey components of Table 1s, i.e., collections of study subjects, subject\ncharacteristics, and statistical measures in RDF knowledge graphs. We design\nscenarios for medical practitioners to perform population analysis, and\ngenerate cohort similarity visualizations to determine the applicability of a\nstudy population to the clinical population of interest. Our semantic approach\nto make study populations visible, by standardized representations of Table 1s,\nallows users to quickly derive clinically relevant inferences about study\npopulations.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 18:27:55 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Chari", "Shruthi", ""], ["Qi", "Miao", ""], ["Agu", "Nkcheniyere N.", ""], ["Seneviratne", "Oshani", ""], ["McCusker", "James P.", ""], ["Bennett", "Kristin P.", ""], ["Das", "Amar K.", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "1907.04371", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Haihao Lu", "title": "Ordered SGD: A New Stochastic Optimization Framework for Empirical Risk\n  Minimization", "comments": "Accepted in AISTATS 2020. Code available at:\n  https://github.com/k9k2/qSGD", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new stochastic optimization framework for empirical risk\nminimization problems such as those that arise in machine learning. The\ntraditional approaches, such as (mini-batch) stochastic gradient descent (SGD),\nutilize an unbiased gradient estimator of the empirical average loss. In\ncontrast, we develop a computationally efficient method to construct a gradient\nestimator that is purposely biased toward those observations with higher\ncurrent losses. On the theory side, we show that the proposed method minimizes\na new ordered modification of the empirical average loss, and is guaranteed to\nconverge at a sublinear rate to a global optimum for convex loss and to a\ncritical point for weakly convex (non-convex) loss. Furthermore, we prove a new\ngeneralization bound for the proposed algorithm. On the empirical side, the\nnumerical experiments show that our proposed method consistently improves the\ntest errors compared with the standard mini-batch SGD in various models\nincluding SVM, logistic regression, and deep learning problems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 19:09:51 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 20:01:12 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 19:04:14 GMT"}, {"version": "v4", "created": "Wed, 15 Jan 2020 22:52:03 GMT"}, {"version": "v5", "created": "Sat, 1 Feb 2020 21:34:16 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Lu", "Haihao", ""]]}, {"id": "1907.04377", "submitter": "Nhat Ho", "authors": "Nhat Ho and Chiao-Yu Yang and Michael I. Jordan", "title": "Convergence Rates for Gaussian Mixtures of Experts", "comments": "55 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a theoretical treatment of over-specified Gaussian mixtures of\nexperts with covariate-free gating networks. We establish the convergence rates\nof the maximum likelihood estimation (MLE) for these models. Our proof\ntechnique is based on a novel notion of \\emph{algebraic independence} of the\nexpert functions. Drawing on optimal transport theory, we establish a\nconnection between the algebraic independence and a certain class of partial\ndifferential equations (PDEs). Exploiting this connection allows us to derive\nconvergence rates and minimax lower bounds for parameter estimation.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 19:31:37 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Ho", "Nhat", ""], ["Yang", "Chiao-Yu", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1907.04409", "submitter": "Brendon G. Anderson", "authors": "Brendon G. Anderson, Somayeh Sojoudi", "title": "Global Optimality Guarantees for Nonconvex Unsupervised Video\n  Segmentation", "comments": "Proceedings of the 57th Annual Allerton Conference on Communication,\n  Control, and Computing, 2019; added funding source information and notation\n  definitions", "journal-ref": "Proceedings of the 57th Annual Allerton Conference on\n  Communication, Control, and Computing, pp. 965--972, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of unsupervised video object\nsegmentation via background subtraction. Specifically, we pose the nonsemantic\nextraction of a video's moving objects as a nonconvex optimization problem via\na sum of sparse and low-rank matrices. The resulting formulation, a nonnegative\nvariant of robust principal component analysis, is more computationally\ntractable than its commonly employed convex relaxation, although not generally\nsolvable to global optimality. In spite of this limitation, we derive intuitive\nand interpretable conditions on the video data under which the uniqueness and\nglobal optimality of the object segmentation are guaranteed using local search\nmethods. We illustrate these novel optimality criteria through example\nsegmentations using real video data.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 20:53:13 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 21:45:47 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Anderson", "Brendon G.", ""], ["Sojoudi", "Somayeh", ""]]}, {"id": "1907.04433", "submitter": "Aston Zhang", "authors": "Jian Guo, He He, Tong He, Leonard Lausen, Mu Li, Haibin Lin, Xingjian\n  Shi, Chenguang Wang, Junyuan Xie, Sheng Zha, Aston Zhang, Hang Zhang, Zhi\n  Zhang, Zhongyue Zhang, Shuai Zheng, Yi Zhu", "title": "GluonCV and GluonNLP: Deep Learning in Computer Vision and Natural\n  Language Processing", "comments": null, "journal-ref": "Journal of Machine Learning Research 21 (2020) 1-7", "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present GluonCV and GluonNLP, the deep learning toolkits for computer\nvision and natural language processing based on Apache MXNet (incubating).\nThese toolkits provide state-of-the-art pre-trained models, training scripts,\nand training logs, to facilitate rapid prototyping and promote reproducible\nresearch. We also provide modular APIs with flexible building blocks to enable\nefficient customization. Leveraging the MXNet ecosystem, the deep learning\nmodels in GluonCV and GluonNLP can be deployed onto a variety of platforms with\ndifferent programming languages. The Apache 2.0 license has been adopted by\nGluonCV and GluonNLP to allow for software distribution, modification, and\nusage.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 21:59:44 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 00:54:42 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Guo", "Jian", ""], ["He", "He", ""], ["He", "Tong", ""], ["Lausen", "Leonard", ""], ["Li", "Mu", ""], ["Lin", "Haibin", ""], ["Shi", "Xingjian", ""], ["Wang", "Chenguang", ""], ["Xie", "Junyuan", ""], ["Zha", "Sheng", ""], ["Zhang", "Aston", ""], ["Zhang", "Hang", ""], ["Zhang", "Zhi", ""], ["Zhang", "Zhongyue", ""], ["Zheng", "Shuai", ""], ["Zhu", "Yi", ""]]}, {"id": "1907.04450", "submitter": "Songtao Lu", "authors": "Songtao Lu and Meisam Razaviyayn and Bo Yang and Kejun Huang and\n  Mingyi Hong", "title": "SNAP: Finding Approximate Second-Order Stationary Solutions Efficiently\n  for Non-convex Linearly Constrained Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes low-complexity algorithms for finding approximate\nsecond-order stationary points (SOSPs) of problems with smooth non-convex\nobjective and linear constraints. While finding (approximate) SOSPs is\ncomputationally intractable, we first show that generic instances of the\nproblem can be solved efficiently. More specifically, for a generic problem\ninstance, certain strict complementarity (SC) condition holds for all\nKarush-Kuhn-Tucker (KKT) solutions (with probability one). The SC condition is\nthen used to establish an equivalence relationship between two different\nnotions of SOSPs, one of which is computationally easy to verify. Based on this\nparticular notion of SOSP, we design an algorithm named the Successive\nNegative-curvature grAdient Projection (SNAP), which successively performs\neither conventional gradient projection or some negative curvature based\nprojection steps to find SOSPs. SNAP and its first-order extension SNAP$^+$,\nrequire $\\mathcal{O}(1/\\epsilon^{2.5})$ iterations to compute an $(\\epsilon,\n\\sqrt{\\epsilon})$-SOSP, and their per-iteration computational complexities are\npolynomial in the number of constraints and problem dimension. To our\nknowledge, this is the first time that first-order algorithms with polynomial\nper-iteration complexity and global sublinear rate have been designed to find\nSOSPs of the important class of non-convex problems with linear constraints.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 22:46:41 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Lu", "Songtao", ""], ["Razaviyayn", "Meisam", ""], ["Yang", "Bo", ""], ["Huang", "Kejun", ""], ["Hong", "Mingyi", ""]]}, {"id": "1907.04471", "submitter": "Cong Li", "authors": "Manas R. Joglekar, Cong Li, Jay K. Adams, Pranav Khaitan, Quoc V. Le", "title": "Neural Input Search for Large Scale Recommendation Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation problems with large numbers of discrete items, such as\nproducts, webpages, or videos, are ubiquitous in the technology industry. Deep\nneural networks are being increasingly used for these recommendation problems.\nThese models use embeddings to represent discrete items as continuous vectors,\nand the vocabulary sizes and embedding dimensions, although heavily influence\nthe model's accuracy, are often manually selected in a heuristical manner. We\npresent Neural Input Search (NIS), a technique for learning the optimal\nvocabulary sizes and embedding dimensions for categorical features. The goal is\nto maximize prediction accuracy subject to a constraint on the total memory\nused by all embeddings. Moreover, we argue that the traditional Single-size\nEmbedding (SE), which uses the same embedding dimension for all values of a\nfeature, suffers from inefficient usage of model capacity and training data. We\npropose a novel type of embedding, namely Multi-size Embedding (ME), which\nallows the embedding dimension to vary for different values of the feature.\nDuring training we use reinforcement learning to find the optimal vocabulary\nsize for each feature and embedding dimension for each value of the feature. In\nexperiments on two common types of large scale recommendation problems, i.e.\nretrieval and ranking problems, NIS automatically found better vocabulary and\nembedding sizes that result in $6.8\\%$ and $1.8\\%$ relative improvements on\nRecall@1 and ROC-AUC over manually optimized ones.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 00:49:06 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Joglekar", "Manas R.", ""], ["Li", "Cong", ""], ["Adams", "Jay K.", ""], ["Khaitan", "Pranav", ""], ["Le", "Quoc V.", ""]]}, {"id": "1907.04472", "submitter": "Suyun Liu", "authors": "Suyun Liu, Luis Nunes Vicente", "title": "The stochastic multi-gradient algorithm for multi-objective optimization\n  and its application to supervised machine learning", "comments": "31 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": "ISE Technical Report 19T-011", "categories": "math.NA cs.NA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization of conflicting functions is of paramount importance in decision\nmaking, and real world applications frequently involve data that is uncertain\nor unknown, resulting in multi-objective optimization (MOO) problems of\nstochastic type. We study the stochastic multi-gradient (SMG) method, seen as\nan extension of the classical stochastic gradient method for single-objective\noptimization.\n  At each iteration of the SMG method, a stochastic multi-gradient direction is\ncalculated by solving a quadratic subproblem, and it is shown that this\ndirection is biased even when all individual gradient estimators are unbiased.\nWe establish rates to compute a point in the Pareto front, of order similar to\nwhat is known for stochastic gradient in both convex and strongly convex cases.\nThe analysis handles the bias in the multi-gradient and the unknown a priori\nweights of the limiting Pareto point.\n  The SMG method is framed into a Pareto-front type algorithm for the\ncomputation of the entire Pareto front. The Pareto-front SMG algorithm is\ncapable of robustly determining Pareto fronts for a number of synthetic test\nproblems. One can apply it to any stochastic MOO problem arising from\nsupervised machine learning, and we report results for logistic binary\nclassification where multiple objectives correspond to distinct-sources data\ngroups.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 00:51:51 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 17:43:57 GMT"}, {"version": "v3", "created": "Fri, 5 Feb 2021 05:28:49 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Liu", "Suyun", ""], ["Vicente", "Luis Nunes", ""]]}, {"id": "1907.04481", "submitter": "Marcus A. Brubaker", "authors": "Priyank Jaini, Ivan Kobyzev, Yaoliang Yu, Marcus Brubaker", "title": "Tails of Lipschitz Triangular Flows", "comments": "Published at the 37th International Conference of Machine Learning,\n  (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the ability of popular flow based methods to capture\ntail-properties of a target density by studying the increasing triangular maps\nused in these flow methods acting on a tractable source density. We show that\nthe density quantile functions of the source and target density provide a\nprecise characterization of the slope of transformation required to capture\ntails in a target density. We further show that any Lipschitz-continuous\ntransport map acting on a source density will result in a density with similar\ntail properties as the source, highlighting the trade-off between a complex\nsource density and a sufficiently expressive transformation to capture\ndesirable properties of a target density. Subsequently, we illustrate that flow\nmodels like Real-NVP, MAF, and Glow as implemented originally lack the ability\nto capture a distribution with non-Gaussian tails. We circumvent this problem\nby proposing tail-adaptive flows consisting of a source distribution that can\nbe learned simultaneously with the triangular map to capture tail-properties of\na target density. We perform several synthetic and real-world experiments to\ncompliment our theoretical findings.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 01:46:39 GMT"}, {"version": "v2", "created": "Sat, 6 Jun 2020 10:27:13 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2020 18:05:25 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Jaini", "Priyank", ""], ["Kobyzev", "Ivan", ""], ["Yu", "Yaoliang", ""], ["Brubaker", "Marcus", ""]]}, {"id": "1907.04483", "submitter": "Roy Freedman", "authors": "Roy S. Freedman", "title": "Copula Representations and Error Surface Projections for the Exclusive\n  Or Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exclusive or (xor) function is one of the simplest examples that\nillustrate why nonlinear feedforward networks are superior to linear regression\nfor machine learning applications. We review the xor representation and\napproximation problems and discuss their solutions in terms of probabilistic\nlogic and associative copula functions. After briefly reviewing the\nspecification of feedforward networks, we compare the dynamics of learned error\nsurfaces with different activation functions such as RELU and tanh through a\nset of colorful three-dimensional charts. The copula representations extend xor\nfrom Boolean to real values, thereby providing a convenient way to demonstrate\nthe concept of cross-validation on in-sample and out-sample data sets. Our\napproach is pedagogical and is meant to be a machine learning prolegomenon.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 00:20:25 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Freedman", "Roy S.", ""]]}, {"id": "1907.04484", "submitter": "Jialin Song", "authors": "Jialin Song, Ravi Lanka, Yisong Yue, Masahiro Ono", "title": "Co-training for Policy Learning", "comments": "UAI 2019, oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning sequential decision-making policies in\nsettings with multiple state-action representations. Such settings naturally\narise in many domains, such as planning (e.g., multiple integer programming\nformulations) and various combinatorial optimization problems (e.g., those with\nboth integer programming and graph-based formulations). Inspired by the\nclassical co-training framework for classification, we study the problem of\nco-training for policy learning. We present sufficient conditions under which\nlearning from two views can improve upon learning from a single view alone.\nMotivated by these theoretical insights, we present a meta-algorithm for\nco-training for sequential decision making. Our framework is compatible with\nboth reinforcement learning and imitation learning. We validate the\neffectiveness of our approach across a wide range of tasks, including\ndiscrete/continuous control and combinatorial optimization.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 02:54:13 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Song", "Jialin", ""], ["Lanka", "Ravi", ""], ["Yue", "Yisong", ""], ["Ono", "Masahiro", ""]]}, {"id": "1907.04490", "submitter": "Michael Lutter", "authors": "Michael Lutter, Christian Ritter, Jan Peters", "title": "Deep Lagrangian Networks: Using Physics as Model Prior for Deep Learning", "comments": "Published at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved astonishing results on many tasks with large\namounts of data and generalization within the proximity of training data. For\nmany important real-world applications, these requirements are unfeasible and\nadditional prior knowledge on the task domain is required to overcome the\nresulting problems. In particular, learning physics models for model-based\ncontrol requires robust extrapolation from fewer samples - often collected\nonline in real-time - and model errors may lead to drastic damages of the\nsystem. Directly incorporating physical insight has enabled us to obtain a\nnovel deep model learning approach that extrapolates well while requiring fewer\nsamples. As a first example, we propose Deep Lagrangian Networks (DeLaN) as a\ndeep network structure upon which Lagrangian Mechanics have been imposed. DeLaN\ncan learn the equations of motion of a mechanical system (i.e., system\ndynamics) with a deep network efficiently while ensuring physical plausibility.\nThe resulting DeLaN network performs very well at robot tracking control. The\nproposed method did not only outperform previous model learning approaches at\nlearning speed but exhibits substantially improved and more robust\nextrapolation to novel trajectories and learns online in real-time\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 02:31:51 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Lutter", "Michael", ""], ["Ritter", "Christian", ""], ["Peters", "Jan", ""]]}, {"id": "1907.04502", "submitter": "Lu Lu", "authors": "Lu Lu, Xuhui Meng, Zhiping Mao, and George E. Karniadakis", "title": "DeepXDE: A deep learning library for solving differential equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep learning has achieved remarkable success in diverse applications;\nhowever, its use in solving partial differential equations (PDEs) has emerged\nonly recently. Here, we present an overview of physics-informed neural networks\n(PINNs), which embed a PDE into the loss of the neural network using automatic\ndifferentiation. The PINN algorithm is simple, and it can be applied to\ndifferent types of PDEs, including integro-differential equations, fractional\nPDEs, and stochastic PDEs. Moreover, from the implementation point of view,\nPINNs solve inverse problems as easily as forward problems. We propose a new\nresidual-based adaptive refinement (RAR) method to improve the training\nefficiency of PINNs. For pedagogical reasons, we compare the PINN algorithm to\na standard finite element method. We also present a Python library for PINNs,\nDeepXDE, which is designed to serve both as an education tool to be used in the\nclassroom as well as a research tool for solving problems in computational\nscience and engineering. Specifically, DeepXDE can solve forward problems given\ninitial and boundary conditions, as well as inverse problems given some extra\nmeasurements. DeepXDE supports complex-geometry domains based on the technique\nof constructive solid geometry, and enables the user code to be compact,\nresembling closely the mathematical formulation. We introduce the usage of\nDeepXDE and its customizability, and we also demonstrate the capability of\nPINNs and the user-friendliness of DeepXDE for five different examples. More\nbroadly, DeepXDE contributes to the more rapid development of the emerging\nScientific Machine Learning field.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 04:06:21 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 23:05:44 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Lu", "Lu", ""], ["Meng", "Xuhui", ""], ["Mao", "Zhiping", ""], ["Karniadakis", "George E.", ""]]}, {"id": "1907.04524", "submitter": "Andre Goncalves", "authors": "Andre Goncalves, Xiaoli Liu, Arindam Banerjee", "title": "Two-block vs. Multi-block ADMM: An empirical evaluation of convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alternating Direction Method of Multipliers (ADMM) has become a widely used\noptimization method for convex problems, particularly in the context of data\nmining in which large optimization problems are often encountered. ADMM has\nseveral desirable properties, including the ability to decompose large problems\ninto smaller tractable sub-problems and ease of parallelization, that are\nessential in these scenarios. The most common form of ADMM is the two-block, in\nwhich two sets of primal variables are updated alternatingly. Recent years have\nseen advances in multi-block ADMM, which update more than two blocks of primal\nvariables sequentially. In this paper, we study the empirical question: {\\em Is\ntwo-block ADMM always comparable with sequential multi-block ADMM solving an\nequivalent problem?} In the context of optimization problems arising in\nmulti-task learning, through a comprehensive set of experiments we surprisingly\nshow that multi-block ADMM consistently outperformed two-block ADMM on\noptimization performance, and as a consequence on prediction performance,\nacross all datasets and for the entire range of dual step sizes. Our results\nhave an important practical implication: rather than simply using the popular\ntwo-block ADMM, one may considerably benefit from experimenting with\nmulti-block ADMM applied to an equivalent problem.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 05:57:36 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Goncalves", "Andre", ""], ["Liu", "Xiaoli", ""], ["Banerjee", "Arindam", ""]]}, {"id": "1907.04536", "submitter": "Ruisen Luo", "authors": "Ruisen Luo, Tianran Sun, Chen Wang, Miao Du, Zuodong Tang, Kai Zhou,\n  and Xiaofeng Gong, and Xiaomei Yang", "title": "Multi-layer Attention Mechanism for Speech Keyword Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  As an important part of speech recognition technology, automatic speech\nkeyword recognition has been intensively studied in recent years. Such\ntechnology becomes especially pivotal under situations with limited\ninfrastructures and computational resources, such as voice command recognition\nin vehicles and robot interaction. At present, the mainstream methods in\nautomatic speech keyword recognition are based on long short-term memory (LSTM)\nnetworks with attention mechanism. However, due to inevitable information\nlosses for the LSTM layer caused during feature extraction, the calculated\nattention weights are biased. In this paper, a novel approach, namely\nMulti-layer Attention Mechanism, is proposed to handle the inaccurate attention\nweights problem. The key idea is that, in addition to the conventional\nattention mechanism, information of layers prior to feature extraction and LSTM\nare introduced into attention weights calculations. Therefore, the attention\nweights are more accurate because the overall model can have more precise and\nfocused areas. We conduct a comprehensive comparison and analysis on the\nkeyword spotting performances on convolution neural network, bi-directional\nLSTM cyclic neural network, and cyclic neural network with the proposed\nattention mechanism on Google Speech Command datasets V2 datasets. Experimental\nresults indicate favorable results for the proposed method and demonstrate the\nvalidity of the proposed method. The proposed multi-layer attention methods can\nbe useful for other researches related to object spotting.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 06:57:01 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Luo", "Ruisen", ""], ["Sun", "Tianran", ""], ["Wang", "Chen", ""], ["Du", "Miao", ""], ["Tang", "Zuodong", ""], ["Zhou", "Kai", ""], ["Gong", "Xiaofeng", ""], ["Yang", "Xiaomei", ""]]}, {"id": "1907.04543", "submitter": "Rishabh Agarwal", "authors": "Rishabh Agarwal, Dale Schuurmans, Mohammad Norouzi", "title": "An Optimistic Perspective on Offline Reinforcement Learning", "comments": "ICML 2020. An earlier version was titled \"Striving for Simplicity in\n  Off-Policy Deep Reinforcement Learning\". Project Website:\n  https://offline-rl.github.io", "journal-ref": "Proceedings of the 37th International Conference on Machine\n  Learning, PMLR 119:104-114, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy reinforcement learning (RL) using a fixed offline dataset of\nlogged interactions is an important consideration in real world applications.\nThis paper studies offline RL using the DQN replay dataset comprising the\nentire replay experience of a DQN agent on 60 Atari 2600 games. We demonstrate\nthat recent off-policy deep RL algorithms, even when trained solely on this\nfixed dataset, outperform the fully trained DQN agent. To enhance\ngeneralization in the offline setting, we present Random Ensemble Mixture\n(REM), a robust Q-learning algorithm that enforces optimal Bellman consistency\non random convex combinations of multiple Q-value estimates. Offline REM\ntrained on the DQN replay dataset surpasses strong RL baselines. Ablation\nstudies highlight the role of offline dataset size and diversity as well as the\nalgorithm choice in our positive results. Overall, the results here present an\noptimistic view that robust RL algorithms trained on sufficiently large and\ndiverse offline datasets can lead to high quality policies. The DQN replay\ndataset can serve as an offline RL benchmark and is open-sourced.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 07:23:27 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 16:35:52 GMT"}, {"version": "v3", "created": "Fri, 6 Mar 2020 00:35:57 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2020 04:32:50 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Agarwal", "Rishabh", ""], ["Schuurmans", "Dale", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1907.04572", "submitter": "Yujia Huang", "authors": "Yujia Huang, Sihui Dai, Tan Nguyen, Richard G. Baraniuk, Anima\n  Anandkumar", "title": "Out-of-Distribution Detection Using Neural Rendering Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-distribution (OoD) detection is a natural downstream task for deep\ngenerative models, due to their ability to learn the input probability\ndistribution. There are mainly two classes of approaches for OoD detection\nusing deep generative models, viz., based on likelihood measure and the\nreconstruction loss. However, both approaches are unable to carry out OoD\ndetection effectively, especially when the OoD samples have smaller variance\nthan the training samples. For instance, both flow based and VAE models assign\nhigher likelihood to images from SVHN when trained on CIFAR-10 images. We use a\nrecently proposed generative model known as neural rendering model (NRM) and\nderive metrics for OoD. We show that NRM unifies both approaches since it\nprovides a likelihood estimate and also carries out reconstruction in each\nlayer of the neural network. Among various measures, we found the joint\nlikelihood of latent variables to be the most effective one for OoD detection.\nOur results show that when trained on CIFAR-10, lower likelihood (of latent\nvariables) is assigned to SVHN images. Additionally, we show that this metric\nis consistent across other OoD datasets. To the best of our knowledge, this is\nthe first work to show consistently lower likelihood for OoD data with smaller\nvariance with deep generative models.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 08:32:53 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Huang", "Yujia", ""], ["Dai", "Sihui", ""], ["Nguyen", "Tan", ""], ["Baraniuk", "Richard G.", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1907.04595", "submitter": "Colin Wei", "authors": "Yuanzhi Li, Colin Wei, Tengyu Ma", "title": "Towards Explaining the Regularization Effect of Initial Large Learning\n  Rate in Training Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent with a large initial learning rate is widely used\nfor training modern neural net architectures. Although a small initial learning\nrate allows for faster training and better test performance initially, the\nlarge learning rate achieves better generalization soon after the learning rate\nis annealed. Towards explaining this phenomenon, we devise a setting in which\nwe can prove that a two layer network trained with large initial learning rate\nand annealing provably generalizes better than the same network trained with a\nsmall learning rate from the start. The key insight in our analysis is that the\norder of learning different types of patterns is crucial: because the small\nlearning rate model first memorizes easy-to-generalize, hard-to-fit patterns,\nit generalizes worse on hard-to-generalize, easier-to-fit patterns than its\nlarge learning rate counterpart. This concept translates to a larger-scale\nsetting: we demonstrate that one can add a small patch to CIFAR-10 images that\nis immediately memorizable by a model with small initial learning rate, but\nignored by the model with large learning rate until after annealing. Our\nexperiments show that this causes the small learning rate model's accuracy on\nunmodified images to suffer, as it relies too much on the patch early on.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 09:47:43 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 06:30:13 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Li", "Yuanzhi", ""], ["Wei", "Colin", ""], ["Ma", "Tengyu", ""]]}, {"id": "1907.04615", "submitter": "Jan Kudlicka", "authors": "Jan Kudlicka and Lawrence M. Murray and Fredrik Ronquist and Thomas B.\n  Sch\\\"on", "title": "Probabilistic programming for birth-death models of evolution using an\n  alive particle filter with delayed sampling", "comments": null, "journal-ref": "Conference on Uncertainty in Artificial Intelligence (UAI) 2019", "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider probabilistic programming for birth-death models of evolution and\nintroduce a new widely-applicable inference method that combines an extension\nof the alive particle filter (APF) with automatic Rao-Blackwellization via\ndelayed sampling. Birth-death models of evolution are an important family of\nphylogenetic models of the diversification processes that lead to evolutionary\ntrees. Probabilistic programming languages (PPLs) give phylogeneticists a new\nand exciting tool: their models can be implemented as probabilistic programs\nwith just a basic knowledge of programming. The general inference methods in\nPPLs reduce the need for external experts, allow quick prototyping and testing,\nand accelerate the development and deployment of new models. We show how these\nbirth-death models can be implemented as simple programs in existing PPLs, and\ndemonstrate the usefulness of the proposed inference method for such models.\nFor the popular BiSSE model the method yields an increase of the effective\nsample size and the conditional acceptance rate by a factor of 30 in comparison\nwith a standard bootstrap particle filter. Although concentrating on\nphylogenetics, the extended APF is a general inference method that shows its\nstrength in situations where particles are often assigned zero weight. In the\ncase when the weights are always positive, the extra cost of using the APF\nrather than the bootstrap particle filter is negligible, making our method a\nsuitable drop-in replacement for the bootstrap particle filter in probabilistic\nprogramming inference.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 11:09:00 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 10:01:29 GMT"}, {"version": "v3", "created": "Sun, 14 Feb 2021 17:23:33 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Kudlicka", "Jan", ""], ["Murray", "Lawrence M.", ""], ["Ronquist", "Fredrik", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1907.04651", "submitter": "Brendan Bennett", "authors": "Brendan Bennett, Wesley Chung, Muhammad Zaheer, Vincent Liu", "title": "Incrementally Learning Functions of the Return", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal difference methods enable efficient estimation of value functions in\nreinforcement learning in an incremental fashion, and are of broader interest\nbecause they correspond learning as observed in biological systems. Standard\nvalue functions correspond to the expected value of a sum of discounted\nreturns. While this formulation is often sufficient for many purposes, it would\noften be useful to be able to represent functions of the return as well.\nUnfortunately, most such functions cannot be estimated directly using TD\nmethods. We propose a means of estimating functions of the return using its\nmoments, which can be learned online using a modified TD algorithm. The moments\nof the return are then used as part of a Taylor expansion to approximate\nanalytic functions of the return.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 22:33:36 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Bennett", "Brendan", ""], ["Chung", "Wesley", ""], ["Zaheer", "Muhammad", ""], ["Liu", "Vincent", ""]]}, {"id": "1907.04652", "submitter": "Hongyang Gao", "authors": "Hongyang Gao and Shuiwang Ji", "title": "Graph Representation Learning via Hard and Channel-Wise Attention\n  Networks", "comments": "9 pages, KDD19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention operators have been widely applied in various fields, including\ncomputer vision, natural language processing, and network embedding learning.\nAttention operators on graph data enables learnable weights when aggregating\ninformation from neighboring nodes. However, graph attention operators (GAOs)\nconsume excessive computational resources, preventing their applications on\nlarge graphs. In addition, GAOs belong to the family of soft attention, instead\nof hard attention, which has been shown to yield better performance. In this\nwork, we propose novel hard graph attention operator (hGAO) and channel-wise\ngraph attention operator (cGAO). hGAO uses the hard attention mechanism by\nattending to only important nodes. Compared to GAO, hGAO improves performance\nand saves computational cost by only attending to important nodes. To further\nreduce the requirements on computational resources, we propose the cGAO that\nperforms attention operations along channels. cGAO avoids the dependency on the\nadjacency matrix, leading to dramatic reductions in computational resource\nrequirements. Experimental results demonstrate that our proposed deep models\nwith the new operators achieve consistently better performance. Comparison\nresults also indicates that hGAO achieves significantly better performance than\nGAO on both node and graph embedding tasks. Efficiency comparison shows that\nour cGAO leads to dramatic savings in computational resources, making them\napplicable to large graphs.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 20:04:14 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Gao", "Hongyang", ""], ["Ji", "Shuiwang", ""]]}, {"id": "1907.04662", "submitter": "Mirco Mutti", "authors": "Mirco Mutti, Marcello Restelli", "title": "An Intrinsically-Motivated Approach for Learning Highly Exploring and\n  Fast Mixing Policies", "comments": "In 34th AAAI Conference on Artificial Intelligence (AAAI 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is a good exploration strategy for an agent that interacts with an\nenvironment in the absence of external rewards? Ideally, we would like to get a\npolicy driving towards a uniform state-action visitation (highly exploring) in\na minimum number of steps (fast mixing), in order to ease efficient learning of\nany goal-conditioned policy later on. Unfortunately, it is remarkably arduous\nto directly learn an optimal policy of this nature. In this paper, we propose a\nnovel surrogate objective for learning highly exploring and fast mixing\npolicies, which focuses on maximizing a lower bound to the entropy of the\nsteady-state distribution induced by the policy. In particular, we introduce\nthree novel lower bounds, that lead to as many optimization problems, that\ntradeoff the theoretical guarantees with computational complexity. Then, we\npresent a model-based reinforcement learning algorithm, IDE$^{3}$AL, to learn\nan optimal policy according to the introduced objective. Finally, we provide an\nempirical evaluation of this algorithm on a set of hard-exploration tasks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 12:28:37 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 10:49:28 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Mutti", "Mirco", ""], ["Restelli", "Marcello", ""]]}, {"id": "1907.04666", "submitter": "Paul Compagnon", "authors": "Paul Compagnon (imagine), Gr\\'egoire Lefebvre, Stefan Duffner\n  (imagine), Christophe Garcia (imagine)", "title": "Routine Modeling with Time Series Metric Learning", "comments": null, "journal-ref": "28th International Conference on Artificial Neural Networks, Sep\n  2019, Munich, Germany", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, the automatic recognition of human activities is performed\nwith supervised learning algorithms on limited sets of specific activities.\nThis work proposes to recognize recurrent activity patterns, called routines,\ninstead of precisely defined activities. The modeling of routines is defined as\na metric learning problem, and an architecture, called SS2S, based on\nsequence-to-sequence models is proposed to learn a distance between time\nseries. This approach only relies on inertial data and is thus non intrusive\nand preserves privacy. Experimental results show that a clustering algorithm\nprovided with the learned distance is able to recover daily routines.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 14:10:01 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Compagnon", "Paul", "", "imagine"], ["Lefebvre", "Gr\u00e9goire", "", "imagine"], ["Duffner", "Stefan", "", "imagine"], ["Garcia", "Christophe", "", "imagine"]]}, {"id": "1907.04669", "submitter": "Sebastien Martin", "authors": "Dimitris Bertsimas, Arthur Delarue, Patrick Jaillet, Sebastien Martin", "title": "Optimal Explanations of Linear Models", "comments": "arXiv admin note: substantial text overlap with arXiv:1907.03419", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When predictive models are used to support complex and important decisions,\nthe ability to explain a model's reasoning can increase trust, expose hidden\nbiases, and reduce vulnerability to adversarial attacks. However, attempts at\ninterpreting models are often ad hoc and application-specific, and the concept\nof interpretability itself is not well-defined. We propose a general\noptimization framework to create explanations for linear models. Our\nmethodology decomposes a linear model into a sequence of models of increasing\ncomplexity using coordinate updates on the coefficients. Computing this\ndecomposition optimally is a difficult optimization problem for which we\npropose exact algorithms and scalable heuristics. By solving this problem, we\ncan derive a parametrized family of interpretability metrics for linear models\nthat generalizes typical proxies, and study the tradeoff between\ninterpretability and predictive accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 06:59:05 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Delarue", "Arthur", ""], ["Jaillet", "Patrick", ""], ["Martin", "Sebastien", ""]]}, {"id": "1907.04670", "submitter": "Larkin Liu", "authors": "Larkin Liu, Yu-Chung Lin, Joshua Reid", "title": "Improving the Performance of the LSTM and HMM Model via Hybridization", "comments": "Working Manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.CO stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Language models based on deep neural networks and traditional stochastic\nmodelling have become both highly functional and effective in recent times. In\nthis work, a general survey into the two types of language modelling is\nconducted. We investigate the effectiveness of the Hidden Markov Model (HMM),\nand the Long Short-Term Memory Model (LSTM). We analyze the hidden state\nstructures common to both models, and present an analysis on structural\nsimilarity of the hidden states, common to both HMM's and LSTM's. We compare\nthe LSTM's predictive accuracy and hidden state output with respect to the HMM\nfor a varying number of hidden states. In this work, we justify that the less\ncomplex HMM can serve as an appropriate approximation of the LSTM model.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 15:12:51 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 21:05:24 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2019 10:56:06 GMT"}, {"version": "v4", "created": "Sun, 28 Feb 2021 13:16:57 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Liu", "Larkin", ""], ["Lin", "Yu-Chung", ""], ["Reid", "Joshua", ""]]}, {"id": "1907.04675", "submitter": "S\\\"oren Dittmer", "authors": "S\\\"oren Dittmer and Peter Maass", "title": "A Projectional Ansatz to Reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently the field of inverse problems has seen a growing usage of\nmathematically only partially understood learned and non-learned priors. Based\non first principles, we develop a projectional approach to inverse problems\nthat addresses the incorporation of these priors, while still guaranteeing data\nconsistency. We implement this projectional method (PM) on the one hand via\nvery general Plug-and-Play priors and on the other hand, via an end-to-end\ntraining approach. To this end, we introduce a novel alternating neural\narchitecture, allowing for the incorporation of highly customized priors from\ndata in a principled manner. We also show how the recent success of\nRegularization by Denoising (RED) can, at least to some extent, be explained as\nan approximation of the PM. Furthermore, we demonstrate how the idea can be\napplied to stop the degradation of Deep Image Prior (DIP) reconstructions over\ntime.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 12:49:07 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 11:36:52 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Dittmer", "S\u00f6ren", ""], ["Maass", "Peter", ""]]}, {"id": "1907.04707", "submitter": "Hao Chen", "authors": "Hao Chen, Yue Xu, Feiran Huang, Zengde Deng, Wenbing Huang, Senzhang\n  Wang, Peng He, Zhoujun Li", "title": "Label-Aware Graph Convolutional Networks", "comments": "Accepted by CIKM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in Graph Convolutional Networks (GCNs) have led to\nstate-of-the-art performance on various graph-related tasks. However, most\nexisting GCN models do not explicitly identify whether all the aggregated\nneighbors are valuable to the learning tasks, which may harm the learning\nperformance. In this paper, we consider the problem of node classification and\npropose the Label-Aware Graph Convolutional Network (LAGCN) framework which can\ndirectly identify valuable neighbors to enhance the performance of existing GCN\nmodels. Our contribution is three-fold. First, we propose a label-aware edge\nclassifier that can filter distracting neighbors and add valuable neighbors for\neach node to refine the original graph into a label-aware~(LA) graph. Existing\nGCN models can directly learn from the LA graph to improve the performance\nwithout changing their model architectures. Second, we introduce the concept of\npositive ratio to evaluate the density of valuable neighbors in the LA graph.\nTheoretical analysis reveals that using the edge classifier to increase the\npositive ratio can improve the learning performance of existing GCN models.\nThird, we conduct extensive node classification experiments on benchmark\ndatasets. The results verify that LAGCN can improve the performance of existing\nGCN models considerably, in terms of node classification.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:20:49 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 07:01:37 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Chen", "Hao", ""], ["Xu", "Yue", ""], ["Huang", "Feiran", ""], ["Deng", "Zengde", ""], ["Huang", "Wenbing", ""], ["Wang", "Senzhang", ""], ["He", "Peng", ""], ["Li", "Zhoujun", ""]]}, {"id": "1907.04708", "submitter": "Martin Tappler", "authors": "Bernhard K. Aichernig and Roderick Bloem and Masoud Ebrahimi and\n  Martin Horn and Franz Pernkopf and Wolfgang Roth and Astrid Rupp and Martin\n  Tappler and Markus Tranninger", "title": "Learning a Behavior Model of Hybrid Systems Through Combining\n  Model-Based Testing and Machine Learning (Full Version)", "comments": "This is an extended version of the conference paper \"Learning a\n  Behavior Model of Hybrid Systems Through Combining Model-Based Testing and\n  Machine Learning\" accepted for presentation at IFIP-ICTSS 2019, the 31st\n  International Conference on Testing Software and Systems in Paris, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models play an essential role in the design process of cyber-physical\nsystems. They form the basis for simulation and analysis and help in\nidentifying design problems as early as possible. However, the construction of\nmodels that comprise physical and digital behavior is challenging. Therefore,\nthere is considerable interest in learning such hybrid behavior by means of\nmachine learning which requires sufficient and representative training data\ncovering the behavior of the physical system adequately. In this work, we\nexploit a combination of automata learning and model-based testing to generate\nsufficient training data fully automatically.\n  Experimental results on a platooning scenario show that recurrent neural\nnetworks learned with this data achieved significantly better results compared\nto models learned from randomly generated data. In particular, the\nclassification error for crash detection is reduced by a factor of five and a\nsimilar F1-score is obtained with up to three orders of magnitude fewer\ntraining samples.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:22:32 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Aichernig", "Bernhard K.", ""], ["Bloem", "Roderick", ""], ["Ebrahimi", "Masoud", ""], ["Horn", "Martin", ""], ["Pernkopf", "Franz", ""], ["Roth", "Wolfgang", ""], ["Rupp", "Astrid", ""], ["Tappler", "Martin", ""], ["Tranninger", "Markus", ""]]}, {"id": "1907.04710", "submitter": "Oleg Arenz", "authors": "Oleg Arenz, Mingjun Zhong and Gerhard Neumann", "title": "Trust-Region Variational Inference with Gaussian Mixture Models", "comments": null, "journal-ref": "Journal of Machine Learning Research. 21(163):1-60, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many methods for machine learning rely on approximate inference from\nintractable probability distributions. Variational inference approximates such\ndistributions by tractable models that can be subsequently used for approximate\ninference. Learning sufficiently accurate approximations requires a rich model\nfamily and careful exploration of the relevant modes of the target\ndistribution. We propose a method for learning accurate GMM approximations of\nintractable probability distributions based on insights from policy search by\nusing information-geometric trust regions for principled exploration. For\nefficient improvement of the GMM approximation, we derive a lower bound on the\ncorresponding optimization objective enabling us to update the components\nindependently. Our use of the lower bound ensures convergence to a stationary\npoint of the original objective. The number of components is adapted online by\nadding new components in promising regions and by deleting components with\nnegligible weight. We demonstrate on several domains that we can learn\napproximations of complex, multimodal distributions with a quality that is\nunmet by previous variational inference methods, and that the GMM approximation\ncan be used for drawing samples that are on par with samples created by\nstate-of-the-art MCMC samplers while requiring up to three orders of magnitude\nless computational resources.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:31:17 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 12:43:25 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Arenz", "Oleg", ""], ["Zhong", "Mingjun", ""], ["Neumann", "Gerhard", ""]]}, {"id": "1907.04711", "submitter": "Paulo Roberto De Oliveira Da Costa", "authors": "Paulo R. de O. da Costa, J. Rhuggenaath, Y. Zhang, A. Akcay, W. Lee\n  and U. Kaymak", "title": "Data-driven Policy on Feasibility Determination for the Train Shunting\n  Problem", "comments": "Accepted as conference paper at ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parking, matching, scheduling, and routing are common problems in train\nmaintenance. In particular, train units are commonly maintained and cleaned at\ndedicated shunting yards. The planning problem that results from such\nsituations is referred to as the Train Unit Shunting Problem (TUSP). This\nproblem involves matching arriving train units to service tasks and determining\nthe schedule for departing trains. The TUSP is an important problem as it is\nused to determine the capacity of shunting yards and arises as a sub-problem of\nmore general scheduling and planning problems. In this paper, we consider the\ncase of the Dutch Railways (NS) TUSP. As the TUSP is complex, NS currently uses\na local search (LS) heuristic to determine if an instance of the TUSP has a\nfeasible solution. Given the number of shunting yards and the size of the\nplanning problems, improving the evaluation speed of the LS brings significant\ncomputational gain. In this work, we use a machine learning approach that\ncomplements the LS and accelerates the search process. We use a Deep Graph\nConvolutional Neural Network (DGCNN) model to predict the feasibility of\nsolutions obtained during the run of the LS heuristic. We use this model to\ndecide whether to continue or abort the search process. In this way, the\ncomputation time is used more efficiently as it is spent on instances that are\nmore likely to be feasible. Using simulations based on real-life instances of\nthe TUSP, we show how our approach improves upon the previous method on\nprediction accuracy and leads to computational gains for the decision-making\nprocess.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:32:14 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["da Costa", "Paulo R. de O.", ""], ["Rhuggenaath", "J.", ""], ["Zhang", "Y.", ""], ["Akcay", "A.", ""], ["Lee", "W.", ""], ["Kaymak", "U.", ""]]}, {"id": "1907.04723", "submitter": "Firas Jarboui", "authors": "Firas Jarboui, C\\'elya Gruson-daniel, Pierre Chanial, Alain Durmus,\n  Vincent Rocchisani, Sophie-helene Goulet Ebongue, Anneliese Depoux, Wilfried\n  Kirschenmann, Vianney Perchet", "title": "Markov Decision Process for MOOC users behavioral inference", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-19875-6_9", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies on massive open online courses (MOOCs) users discuss the existence of\ntypical profiles and their impact on the learning process of the students.\nHowever defining the typical behaviors as well as classifying the users\naccordingly is a difficult task. In this paper we suggest two methods to model\nMOOC users behaviour given their log data. We mold their behavior into a Markov\nDecision Process framework. We associate the user's intentions with the MDP\nreward and argue that this allows us to classify them.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:43:48 GMT"}, {"version": "v2", "created": "Wed, 10 Mar 2021 16:05:36 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Jarboui", "Firas", ""], ["Gruson-daniel", "C\u00e9lya", ""], ["Chanial", "Pierre", ""], ["Durmus", "Alain", ""], ["Rocchisani", "Vincent", ""], ["Ebongue", "Sophie-helene Goulet", ""], ["Depoux", "Anneliese", ""], ["Kirschenmann", "Wilfried", ""], ["Perchet", "Vianney", ""]]}, {"id": "1907.04786", "submitter": "Yuguang Wang", "authors": "Ming Li, Zheng Ma, Yu Guang Wang, Xiaosheng Zhuang", "title": "Fast Haar Transforms for Graph Neural Networks", "comments": "24 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have become a topic of intense research recently\ndue to their powerful capability in high-dimensional classification and\nregression tasks for graph-structured data. However, as GNNs typically define\nthe graph convolution by the orthonormal basis for the graph Laplacian, they\nsuffer from high computational cost when the graph size is large. This paper\nintroduces Haar basis which is a sparse and localized orthonormal system for a\ncoarse-grained chain on graph. The graph convolution under Haar basis, called\nHaar convolution, can be defined accordingly for GNNs. The sparsity and\nlocality of the Haar basis allow Fast Haar Transforms (FHTs) on graph, by which\na fast evaluation of Haar convolution between graph data and filters can be\nachieved. We conduct experiments on GNNs equipped with Haar convolution, which\ndemonstrates state-of-the-art results on graph-based regression and node\nclassification tasks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 15:22:37 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 11:22:02 GMT"}, {"version": "v3", "created": "Wed, 30 Oct 2019 16:57:18 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Li", "Ming", ""], ["Ma", "Zheng", ""], ["Wang", "Yu Guang", ""], ["Zhuang", "Xiaosheng", ""]]}, {"id": "1907.04805", "submitter": "Amit Sharma", "authors": "Rathin Desai and Amit Sharma", "title": "Quantifying Error in the Presence of Confounders for Causal Inference", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating average causal effect (ACE) is useful whenever we want to know the\neffect of an intervention on a given outcome. In the absence of a randomized\nexperiment, many methods such as stratification and inverse propensity\nweighting have been proposed to estimate ACE. However, it is hard to know which\nmethod is optimal for a given dataset or which hyperparameters to use for a\nchosen method. To this end, we provide a framework to characterize the loss of\na causal inference method against the true ACE, by framing causal inference as\na representation learning problem. We show that many popular methods, including\nback-door methods can be considered as weighting or representation learning\nalgorithms, and provide general error bounds for their causal estimates. In\naddition, we consider the case when unobserved variables can confound the\ncausal estimate and extend proposed bounds using principles of robust\nstatistics, considering confounding as contamination under the Huber\ncontamination model. These bounds are also estimable; as an example, we provide\nempirical bounds for the Inverse Propensity Weighting (IPW) estimator and show\nhow the bounds can be used to optimize the threshold of clipping extreme\npropensity scores. Our work provides a new way to reason about competing\nestimators, and opens up the potential of deriving new methods by minimizing\nthe proposed error bounds.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 15:53:07 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Desai", "Rathin", ""], ["Sharma", "Amit", ""]]}, {"id": "1907.04809", "submitter": "Ilyes Khemakhem", "authors": "Ilyes Khemakhem, Diederik P. Kingma, Ricardo Pio Monti, Aapo\n  Hyv\\\"arinen", "title": "Variational Autoencoders and Nonlinear ICA: A Unifying Framework", "comments": "Accepted for publication at AISTATS 2020. This is a slightly updated\n  version of the published manuscript; see Corrigendum at the end of the paper", "journal-ref": "Proceedings of the Twenty Third International Conference on\n  Artificial Intelligence and Statistics, pages 2207-2217, year 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The framework of variational autoencoders allows us to efficiently learn deep\nlatent-variable models, such that the model's marginal distribution over\nobserved variables fits the data. Often, we're interested in going a step\nfurther, and want to approximate the true joint distribution over observed and\nlatent variables, including the true prior and posterior distributions over\nlatent variables. This is known to be generally impossible due to\nunidentifiability of the model. We address this issue by showing that for a\nbroad family of deep latent-variable models, identification of the true joint\ndistribution over observed and latent variables is actually possible up to very\nsimple transformations, thus achieving a principled and powerful form of\ndisentanglement. Our result requires a factorized prior distribution over the\nlatent variables that is conditioned on an additionally observed variable, such\nas a class label or almost any other observation. We build on recent\ndevelopments in nonlinear ICA, which we extend to the case with noisy,\nundercomplete or discrete observations, integrated in a maximum likelihood\nframework. The result also trivially contains identifiable flow-based\ngenerative models as a special case.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 16:08:32 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 09:50:03 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 13:49:16 GMT"}, {"version": "v4", "created": "Mon, 21 Dec 2020 10:20:53 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Khemakhem", "Ilyes", ""], ["Kingma", "Diederik P.", ""], ["Monti", "Ricardo Pio", ""], ["Hyv\u00e4rinen", "Aapo", ""]]}, {"id": "1907.04831", "submitter": "Muhammad R. A. Khandaker PhD", "authors": "Tian-Hao Li, Muhammad R. A. Khandaker, Faisal Tariq, Kai-Kit Wong and\n  Risala T. Khan", "title": "Learning the Wireless V2I Channels Using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For high data rate wireless communication systems, developing an efficient\nchannel estimation approach is extremely vital for channel detection and signal\nrecovery. With the trend of high-mobility wireless communications between\nvehicles and vehicles-to-infrastructure (V2I), V2I communications pose\nadditional challenges to obtaining real-time channel measurements. Deep\nlearning (DL) techniques, in this context, offer learning ability and\noptimization capability that can approximate many kinds of functions. In this\npaper, we develop a DL-based channel prediction method to estimate channel\nresponses for V2I communications. We have demonstrated how fast neural networks\ncan learn V2I channel properties and the changing trend. The network is trained\nwith a series of channel responses and known pilots, which then speculates the\nnext channel response based on the acquired knowledge. The predicted channel is\nthen used to evaluate the system performance.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 17:24:45 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Li", "Tian-Hao", ""], ["Khandaker", "Muhammad R. A.", ""], ["Tariq", "Faisal", ""], ["Wong", "Kai-Kit", ""], ["Khan", "Risala T.", ""]]}, {"id": "1907.04840", "submitter": "Tim Dettmers", "authors": "Tim Dettmers, Luke Zettlemoyer", "title": "Sparse Networks from Scratch: Faster Training without Losing Performance", "comments": "9 page NeurIPS 2019 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the possibility of what we call sparse learning: accelerated\ntraining of deep neural networks that maintain sparse weights throughout\ntraining while achieving dense performance levels. We accomplish this by\ndeveloping sparse momentum, an algorithm which uses exponentially smoothed\ngradients (momentum) to identify layers and weights which reduce the error\nefficiently. Sparse momentum redistributes pruned weights across layers\naccording to the mean momentum magnitude of each layer. Within a layer, sparse\nmomentum grows weights according to the momentum magnitude of zero-valued\nweights. We demonstrate state-of-the-art sparse performance on MNIST, CIFAR-10,\nand ImageNet, decreasing the mean error by a relative 8%, 15%, and 6% compared\nto other sparse algorithms. Furthermore, we show that sparse momentum reliably\nreproduces dense performance levels while providing up to 5.61x faster\ntraining. In our analysis, ablations show that the benefits of momentum\nredistribution and growth increase with the depth and size of the network.\nAdditionally, we find that sparse momentum is insensitive to the choice of its\nhyperparameters suggesting that sparse momentum is robust and easy to use.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 17:40:20 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 18:30:16 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Dettmers", "Tim", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1907.04846", "submitter": "Alina Oprea", "authors": "Talha Ongun, Timothy Sakharaov, Simona Boboila, Alina Oprea, and Tina\n  Eliassi-Rad", "title": "On Designing Machine Learning Models for Malicious Network Traffic\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) started to become widely deployed in cyber security\nsettings for shortening the detection cycle of cyber attacks. To date, most\nML-based systems are either proprietary or make specific choices of feature\nrepresentations and machine learning models. The success of these techniques is\ndifficult to assess as public benchmark datasets are currently unavailable. In\nthis paper, we provide concrete guidelines and recommendations for using\nsupervised ML in cyber security. As a case study, we consider the problem of\nbotnet detection from network traffic data. Among our findings we highlight\nthat: (1) feature representations should take into consideration attack\ncharacteristics; (2) ensemble models are well-suited to handle class imbalance;\n(3) the granularity of ground truth plays an important role in the success of\nthese methods.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 17:50:34 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Ongun", "Talha", ""], ["Sakharaov", "Timothy", ""], ["Boboila", "Simona", ""], ["Oprea", "Alina", ""], ["Eliassi-Rad", "Tina", ""]]}, {"id": "1907.04868", "submitter": "Chris Donahue", "authors": "Chris Donahue, Huanru Henry Mao, Yiting Ethan Li, Garrison W.\n  Cottrell, Julian McAuley", "title": "LakhNES: Improving multi-instrumental music generation with cross-domain\n  pre-training", "comments": "Published as a conference paper at ISMIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG cs.MM eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We are interested in the task of generating multi-instrumental music scores.\nThe Transformer architecture has recently shown great promise for the task of\npiano score generation; here we adapt it to the multi-instrumental setting.\nTransformers are complex, high-dimensional language models which are capable of\ncapturing long-term structure in sequence data, but require large amounts of\ndata to fit. Their success on piano score generation is partially explained by\nthe large volumes of symbolic data readily available for that domain. We\nleverage the recently-introduced NES-MDB dataset of four-instrument scores from\nan early video game sound synthesis chip (the NES), which we find to be\nwell-suited to training with the Transformer architecture. To further improve\nthe performance of our model, we propose a pre-training technique to leverage\nthe information in a large collection of heterogeneous music, namely the Lakh\nMIDI dataset. Despite differences between the two corpora, we find that this\ntransfer learning procedure improves both quantitative and qualitative\nperformance for our primary task.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 18:00:04 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Donahue", "Chris", ""], ["Mao", "Huanru Henry", ""], ["Li", "Yiting Ethan", ""], ["Cottrell", "Garrison W.", ""], ["McAuley", "Julian", ""]]}, {"id": "1907.04895", "submitter": "Hrushikesh Mhaskar", "authors": "H. N. Mhaskar", "title": "Super-resolution meets machine learning: approximation of measures", "comments": "14 pages, To appear in Journal of Fourier Analysis and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of super-resolution in general terms is to recuperate a finitely\nsupported measure $\\mu$ given finitely many of its coefficients $\\hat{\\mu}(k)$\nwith respect to some orthonormal system. The interesting case concerns\nsituations, where the number of coefficients required is substantially smaller\nthan a power of the reciprocal of the minimal separation among the points in\nthe support of $\\mu$. In this paper, we consider the more severe problem of\nrecuperating $\\mu$ approximately without any assumption on $\\mu$ beyond having\na finite total variation. In particular, $\\mu$ may be supported on a continuum,\nso that the minimal separation among the points in the support of $\\mu$ is $0$.\nA variant of this problem is also of interest in machine learning as well as\nthe inverse problem of de-convolution. We define an appropriate notion of a\ndistance between the target measure and its recuperated version, give an\nexplicit expression for the recuperation operator, and estimate the distance\nbetween $\\mu$ and its approximation. We show that these estimates are the best\npossible in many different ways. We also explain why for a finitely supported\nmeasure the approximation quality of its recuperation is bounded from below if\nthe amount of information is smaller than what is demanded in the\nsuper-resolution problem.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 19:15:24 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Mhaskar", "H. N.", ""]]}, {"id": "1907.04902", "submitter": "Markus Kaiser", "authors": "Markus Kaiser, Clemens Otte, Thomas Runkler, Carl Henrik Ek", "title": "Interpretable Dynamics Models for Data-Efficient Reinforcement Learning", "comments": "ESANN 2019 proceedings, European Symposium on Artificial Neural\n  Networks, Computational Intelligence and Machine Learning. Bruges (Belgium),\n  24-26 April 2019, i6doc.com publ., ISBN 978-287-587-065-0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a Bayesian view on model-based reinforcement\nlearning. We use expert knowledge to impose structure on the transition model\nand present an efficient learning scheme based on variational inference. This\nscheme is applied to a heteroskedastic and bimodal benchmark problem on which\nwe compare our results to NFQ and show how our approach yields\nhuman-interpretable insight about the underlying dynamics while also increasing\ndata-efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 19:50:45 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Kaiser", "Markus", ""], ["Otte", "Clemens", ""], ["Runkler", "Thomas", ""], ["Ek", "Carl Henrik", ""]]}, {"id": "1907.04907", "submitter": "Adji Bousso Dieng", "authors": "Adji B. Dieng, Francisco J. R. Ruiz, and David M. Blei", "title": "Topic Modeling in Embedding Spaces", "comments": "Code can be found at https://github.com/adjidieng/ETM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic modeling analyzes documents to learn meaningful patterns of words.\nHowever, existing topic models fail to learn interpretable topics when working\nwith large and heavy-tailed vocabularies. To this end, we develop the Embedded\nTopic Model (ETM), a generative model of documents that marries traditional\ntopic models with word embeddings. In particular, it models each word with a\ncategorical distribution whose natural parameter is the inner product between a\nword embedding and an embedding of its assigned topic. To fit the ETM, we\ndevelop an efficient amortized variational inference algorithm. The ETM\ndiscovers interpretable topics even with large vocabularies that include rare\nwords and stop words. It outperforms existing document models, such as latent\nDirichlet allocation (LDA), in terms of both topic quality and predictive\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 03:50:57 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Dieng", "Adji B.", ""], ["Ruiz", "Francisco J. R.", ""], ["Blei", "David M.", ""]]}, {"id": "1907.04911", "submitter": "Michaela Mila", "authors": "Michaela Hardt, Alvin Rajkomar, Gerardo Flores, Andrew Dai, Michael\n  Howell, Greg Corrado, Claire Cui and Moritz Hardt", "title": "Explaining an increase in predicted risk for clinical alerts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much work aims to explain a model's prediction on a static input. We consider\nexplanations in a temporal setting where a stateful dynamical model produces a\nsequence of risk estimates given an input at each time step. When the estimated\nrisk increases, the goal of the explanation is to attribute the increase to a\nfew relevant inputs from the past. While our formal setup and techniques are\ngeneral, we carry out an in-depth case study in a clinical setting. The goal\nhere is to alert a clinician when a patient's risk of deterioration rises. The\nclinician then has to decide whether to intervene and adjust the treatment.\nGiven a potentially long sequence of new events since she last saw the patient,\na concise explanation helps her to quickly triage the alert. We develop methods\nto lift static attribution techniques to the dynamical setting, where we\nidentify and address challenges specific to dynamics. We then experimentally\nassess the utility of different explanations of clinical alerts through expert\nevaluation.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 20:26:43 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Hardt", "Michaela", ""], ["Rajkomar", "Alvin", ""], ["Flores", "Gerardo", ""], ["Dai", "Andrew", ""], ["Howell", "Michael", ""], ["Corrado", "Greg", ""], ["Cui", "Claire", ""], ["Hardt", "Moritz", ""]]}, {"id": "1907.04913", "submitter": "Amir Mosavi", "authors": "Danial Mohammadzadeh, Seyed-Farzan Kazemi, Amir Mosavi, Ehsan\n  Nasseralshariati, Joseph H. M. Tah", "title": "Prediction of Compression Index of Fine-Grained Soils Using a Gene\n  Expression Programming Model", "comments": "8 figures, 5 tables, 12 pages", "journal-ref": "Infrastructures 2019, 4, 26", "doi": "10.3390/infrastructures4020026", "report-no": null, "categories": "stat.AP cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In construction projects, estimation of the settlement of fine-grained soils\nis of critical importance, and yet is a challenging task. The coefficient of\nconsolidation for the compression index (Cc) is a key parameter in modeling the\nsettlement of fine-grained soil layers. However, the estimation of this\nparameter is costly, time-consuming, and requires skilled technicians. To\novercome these drawbacks, we aimed to predict Cc through other soil parameters,\ni.e., the liquid limit (LL), plastic limit (PL), and initial void ratio (e0).\nUsing these parameters is more convenient and requires substantially less time\nand cost compared to the conventional tests to estimate Cc. This study presents\na novel prediction model for the Cc of fine-grained soils using gene expression\nprogramming (GEP). A database consisting of 108 different data points was used\nto develop the model. A closed-form equation solution was derived to estimate\nCc based on LL, PL, and e0. The performance of the developed GEP-based model\nwas evaluated through the coefficient of determination (R2), the root mean\nsquared error (RMSE), and the mean average error (MAE). The proposed model\nperformed better in terms of R2, RMSE, and MAE compared to the other models.\n", "versions": [{"version": "v1", "created": "Sun, 26 May 2019 07:12:35 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Mohammadzadeh", "Danial", ""], ["Kazemi", "Seyed-Farzan", ""], ["Mosavi", "Amir", ""], ["Nasseralshariati", "Ehsan", ""], ["Tah", "Joseph H. M.", ""]]}, {"id": "1907.04916", "submitter": "Felix Weninger", "authors": "Felix Weninger, Jes\\'us Andr\\'es-Ferrer, Xinwei Li, Puming Zhan", "title": "Listen, Attend, Spell and Adapt: Speaker Adapted Sequence-to-Sequence\n  ASR", "comments": "To appear in INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence-to-sequence (seq2seq) based ASR systems have shown state-of-the-art\nperformances while having clear advantages in terms of simplicity. However,\ncomparisons are mostly done on speaker independent (SI) ASR systems, though\nspeaker adapted conventional systems are commonly used in practice for\nimproving robustness to speaker and environment variations. In this paper, we\napply speaker adaptation to seq2seq models with the goal of matching the\nperformance of conventional ASR adaptation. Specifically, we investigate\nKullback-Leibler divergence (KLD) as well as Linear Hidden Network (LHN) based\nadaptation for seq2seq ASR, using different amounts (up to 20 hours) of\nadaptation data per speaker. Our SI models are trained on large amounts of\ndictation data and achieve state-of-the-art results. We obtained 25% relative\nword error rate (WER) improvement with KLD adaptation of the seq2seq model vs.\n18.7% gain from acoustic model adaptation in the conventional system. We also\nshow that the WER of the seq2seq model decreases log-linearly with the amount\nof adaptation data. Finally, we analyze adaptation based on the minimum WER\ncriterion and adapting the language model (LM) for score fusion with the\nspeaker adapted seq2seq model, which result in further improvements of the\nseq2seq system performance.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 15:09:40 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Weninger", "Felix", ""], ["Andr\u00e9s-Ferrer", "Jes\u00fas", ""], ["Li", "Xinwei", ""], ["Zhan", "Puming", ""]]}, {"id": "1907.04919", "submitter": "Stefanos Poulis", "authors": "Sanjoy Dasgupta, Stefanos Poulis, Christopher Tosh", "title": "Interactive Topic Modeling with Anchor Words", "comments": "presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The formalism of anchor words has enabled the development of fast topic\nmodeling algorithms with provable guarantees. In this paper, we introduce a\nprotocol that allows users to interact with anchor words to build customized\nand interpretable topic models. Experimental evidence validating the usefulness\nof our approach is also presented.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 23:42:23 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Dasgupta", "Sanjoy", ""], ["Poulis", "Stefanos", ""], ["Tosh", "Christopher", ""]]}, {"id": "1907.04924", "submitter": "Xichen Ding", "authors": "Xichen Ding, Jie Tang, Tracy Liu, Cheng Xu, Yaping Zhang, Feng Shi,\n  Qixia Jiang, Dan Shen", "title": "Infer Implicit Contexts in Real-time Online-to-Offline Recommendation", "comments": "9 pages,KDD,KDD2019", "journal-ref": null, "doi": "10.1145/3292500.3330716", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding users' context is essential for successful recommendations,\nespecially for Online-to-Offline (O2O) recommendation, such as Yelp, Groupon,\nand Koubei. Different from traditional recommendation where individual\npreference is mostly static, O2O recommendation should be dynamic to capture\nvariation of users' purposes across time and location. However, precisely\ninferring users' real-time contexts information, especially those implicit\nones, is extremely difficult, and it is a central challenge for O2O\nrecommendation. In this paper, we propose a new approach, called Mixture\nAttentional Constrained Denoise AutoEncoder (MACDAE), to infer implicit\ncontexts and consequently, to improve the quality of real-time O2O\nrecommendation. In MACDAE, we first leverage the interaction among users,\nitems, and explicit contexts to infer users' implicit contexts, then combine\nthe learned implicit-context representation into an end-to-end model to make\nthe recommendation. MACDAE works quite well in the real system. We conducted\nboth offline and online evaluations of the proposed approach. Experiments on\nseveral real-world datasets (Yelp, Dianping, and Koubei) show our approach\ncould achieve significant improvements over state-of-the-arts. Furthermore,\nonline A/B test suggests a 2.9% increase for click-through rate and 5.6%\nimprovement for conversion rate in real-world traffic. Our model has been\ndeployed in the product of \"Guess You Like\" recommendation in Koubei.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 05:37:30 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Ding", "Xichen", ""], ["Tang", "Jie", ""], ["Liu", "Tracy", ""], ["Xu", "Cheng", ""], ["Zhang", "Yaping", ""], ["Shi", "Feng", ""], ["Jiang", "Qixia", ""], ["Shen", "Dan", ""]]}, {"id": "1907.04928", "submitter": "Alessandro Lameiras Koerich", "authors": "Mohammed Senoussaoui, Patrick Cardinal, Alessandro Lameiras Koerich", "title": "Bag-of-Audio-Words based on Autoencoder Codebook for Continuous Emotion\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel approach for extracting a Bag-of-Words (BoW)\nrepresentation based on a Neural Network codebook. The conventional BoW model\nis based on a dictionary (codebook) built from elementary representations which\nare selected randomly or by using a clustering algorithm on a training dataset.\nA metric is then used to assign unseen elementary representations to the\nclosest dictionary entries in order to produce a histogram. In the proposed\napproach, an autoencoder (AE) encompasses the role of both the dictionary\ncreation and the assignment metric. The dimension of the encoded layer of the\nAE corresponds to the size of the dictionary and the output of its neurons\nrepresents the assignment metric. Experimental results for the continuous\nemotion prediction task on the AVEC 2017 audio dataset have shown an\nimprovement of the Concordance Correlation Coefficient (CCC) from 0.225 to\n0.322 for arousal dimension and from 0.244 to 0.368 for valence dimension\nrelative to the conventional BoW version implemented in a baseline system.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 21:16:53 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Senoussaoui", "Mohammed", ""], ["Cardinal", "Patrick", ""], ["Koerich", "Alessandro Lameiras", ""]]}, {"id": "1907.04931", "submitter": "Hanqing Zeng", "authors": "Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan,\n  Viktor Prasanna", "title": "GraphSAINT: Graph Sampling Based Inductive Learning Method", "comments": "Published at ICLR 2020; Code release:\n  github.com/GraphSAINT/GraphSAINT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Convolutional Networks (GCNs) are powerful models for learning\nrepresentations of attributed graphs. To scale GCNs to large graphs,\nstate-of-the-art methods use various layer sampling techniques to alleviate the\n\"neighbor explosion\" problem during minibatch training. We propose GraphSAINT,\na graph sampling based inductive learning method that improves training\nefficiency and accuracy in a fundamentally different way. By changing\nperspective, GraphSAINT constructs minibatches by sampling the training graph,\nrather than the nodes or edges across GCN layers. Each iteration, a complete\nGCN is built from the properly sampled subgraph. Thus, we ensure fixed number\nof well-connected nodes in all layers. We further propose normalization\ntechnique to eliminate bias, and sampling algorithms for variance reduction.\nImportantly, we can decouple the sampling from the forward and backward\npropagation, and extend GraphSAINT with many architecture variants (e.g., graph\nattention, jumping connection). GraphSAINT demonstrates superior performance in\nboth accuracy and training time on five large graphs, and achieves new\nstate-of-the-art F1 scores for PPI (0.995) and Reddit (0.970).\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 21:11:13 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 08:36:31 GMT"}, {"version": "v3", "created": "Fri, 27 Dec 2019 23:58:33 GMT"}, {"version": "v4", "created": "Sun, 16 Feb 2020 00:42:48 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Zeng", "Hanqing", ""], ["Zhou", "Hongkuan", ""], ["Srivastava", "Ajitesh", ""], ["Kannan", "Rajgopal", ""], ["Prasanna", "Viktor", ""]]}, {"id": "1907.04964", "submitter": "Nicholas Charles Landolfi", "authors": "Nicholas C. Landolfi and Garrett Thomas and Tengyu Ma", "title": "A Model-based Approach for Sample-efficient Multi-task Reinforcement\n  Learning", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of multi-task reinforcement learning is two-fold: (1) efficiently\nlearn by training against multiple tasks and (2) quickly adapt, using limited\nsamples, to a variety of new tasks. In this work, the tasks correspond to\nreward functions for environments with the same (or similar) dynamical models.\nWe propose to learn a dynamical model during the training process and use this\nmodel to perform sample-efficient adaptation to new tasks at test time. We use\nsignificantly fewer samples by performing policy optimization only in a\n\"virtual\" environment whose transitions are given by our learned dynamical\nmodel. Our algorithm sequentially trains against several tasks. Upon\nencountering a new task, we first warm-up a policy on our learned dynamical\nmodel, which requires no new samples from the environment. We then adapt the\ndynamical model with samples from this policy in the real environment. We\nevaluate our approach on several continuous control benchmarks and demonstrate\nits efficacy over MAML, a state-of-the-art meta-learning algorithm, on these\ntasks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 00:45:44 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 05:35:35 GMT"}, {"version": "v3", "created": "Sun, 3 Nov 2019 20:30:47 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Landolfi", "Nicholas C.", ""], ["Thomas", "Garrett", ""], ["Ma", "Tengyu", ""]]}, {"id": "1907.05008", "submitter": "Nima Dehmamy", "authors": "Nima Dehmamy, Albert-L\\'aszl\\'o Barab\\'asi, Rose Yu", "title": "Understanding the Representation Power of Graph Neural Networks in\n  Learning Graph Topology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deepen our understanding of graph neural networks, we investigate the\nrepresentation power of Graph Convolutional Networks (GCN) through the looking\nglass of graph moments, a key property of graph topology encoding path of\nvarious lengths. We find that GCNs are rather restrictive in learning graph\nmoments. Without careful design, GCNs can fail miserably even with multiple\nlayers and nonlinear activation functions. We analyze theoretically the\nexpressiveness of GCNs, concluding a modular GCN design, using different\npropagation rules with residual connections could significantly improve the\nperformance of GCN. We demonstrate that such modular designs are capable of\ndistinguishing graphs from different graph generation models for surprisingly\nsmall graphs, a notoriously difficult problem in network science. Our\ninvestigation suggests that, depth is much more influential than width, with\ndeeper GCNs being more capable of learning higher order graph moments.\nAdditionally, combining GCN modules with different propagation rules is\ncritical to the representation power of GCNs.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 05:59:38 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 20:38:40 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Dehmamy", "Nima", ""], ["Barab\u00e1si", "Albert-L\u00e1szl\u00f3", ""], ["Yu", "Rose", ""]]}, {"id": "1907.05012", "submitter": "Antonio Ginart", "authors": "Antonio Ginart, Melody Y. Guan, Gregory Valiant, James Zou", "title": "Making AI Forget You: Data Deletion in Machine Learning", "comments": "To appear in NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Intense recent discussions have focused on how to provide individuals with\ncontrol over when their data can and cannot be used --- the EU's Right To Be\nForgotten regulation is an example of this effort. In this paper we initiate a\nframework studying what to do when it is no longer permissible to deploy models\nderivative from specific user data. In particular, we formulate the problem of\nefficiently deleting individual data points from trained machine learning\nmodels. For many standard ML models, the only way to completely remove an\nindividual's data is to retrain the whole model from scratch on the remaining\ndata, which is often not computationally practical. We investigate algorithmic\nprinciples that enable efficient data deletion in ML. For the specific setting\nof k-means clustering, we propose two provably efficient deletion algorithms\nwhich achieve an average of over 100X improvement in deletion efficiency across\n6 datasets, while producing clusters of comparable statistical quality to a\ncanonical k-means++ baseline.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 06:19:51 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 23:20:07 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Ginart", "Antonio", ""], ["Guan", "Melody Y.", ""], ["Valiant", "Gregory", ""], ["Zou", "James", ""]]}, {"id": "1907.05079", "submitter": "Kimia Nadjahi", "authors": "Kimia Nadjahi, Romain Laroche, R\\'emi Tachet des Combes", "title": "Safe Policy Improvement with Soft Baseline Bootstrapping", "comments": "Accepted paper at ECML-PKDD2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Reinforcement Learning (Batch RL) consists in training a policy using\ntrajectories collected with another policy, called the behavioural policy. Safe\npolicy improvement (SPI) provides guarantees with high probability that the\ntrained policy performs better than the behavioural policy, also called\nbaseline in this setting. Previous work shows that the SPI objective improves\nmean performance as compared to using the basic RL objective, which boils down\nto solving the MDP with maximum likelihood. Here, we build on that work and\nimprove more precisely the SPI with Baseline Bootstrapping algorithm (SPIBB) by\nallowing the policy search over a wider set of policies. Instead of binarily\nclassifying the state-action pairs into two sets (the \\textit{uncertain} and\nthe \\textit{safe-to-train-on} ones), we adopt a softer strategy that controls\nthe error in the value estimates by constraining the policy change according to\nthe local model uncertainty. The method can take more risks on uncertain\nactions all the while remaining provably-safe, and is therefore less\nconservative than the state-of-the-art methods. We propose two algorithms (one\noptimal and one approximate) to solve this constrained optimization problem and\nempirically show a significant improvement over existing SPI algorithms both on\nfinite MDPs and on infinite MDPs with a neural network function approximation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 09:59:10 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Nadjahi", "Kimia", ""], ["Laroche", "Romain", ""], ["Combes", "R\u00e9mi Tachet des", ""]]}, {"id": "1907.05106", "submitter": "Alessandro Betti", "authors": "Alessandro Betti, Marco Gori", "title": "Spatiotemporal Local Propagation", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an in-depth re-thinking of neural computation that\nparallels apparently unrelated laws of physics, that are formulated in the\nvariational framework of the least action principle. The theory holds for\nneural networks that are also based on any digraph, and the resulting\ncomputational scheme exhibits the intriguing property of being truly\nbiologically plausible. The scheme, which is referred to as SpatioTemporal\nLocal Propagation (STLP), is local in both space and time. Space locality comes\nfrom the expression of the network connections by an appropriate Lagrangian\nterm, so as the corresponding computational scheme does not need the\nbackpropagation (BP) of the error, while temporal locality is the outcome of\nthe variational formulation of the problem. Overall, in addition to conquering\nthe often invoked biological plausibility missed by BP, the locality in both\nspace and time that arises from the proposed theory can neither be exhibited by\nBackpropagation Through Time (BPTT) nor by Real-Time Recurrent Learning (RTRL).\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 11:03:09 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Betti", "Alessandro", ""], ["Gori", "Marco", ""]]}, {"id": "1907.05124", "submitter": "Liubov Markovich", "authors": "A. Yavorsky, L.A. Markovich, E.A. Polyakov, A.N. Rubtsov", "title": "Highly parallel algorithm for the Ising ground state searching problem", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding an energy minimum in the Ising model is an exemplar objective,\nassociated with many combinatorial optimization problems, that is\ncomputationally hard in general, but occurs in all areas of modern science.\nThere are several numerical methods, providing solution for the medium size\nIsing spin systems. However, they are either computationally slow and badly\nparallelized, or do not give sufficiently good results for the large systems.\nIn this paper, we present a highly parallel algorithm, called Mean-field\nAnnealing from a Random State (MARS), incorporating the best features of the\nclassical simulated annealing (SA) and Mean-Field Annealing (MFA) methods. The\nalgorithm is based on the mean-field descent from a randomly selected\nconfiguration and temperature. Since a single run requires little computational\neffort, the effectiveness can be achieved by massive parallelisation. MARS\nshows excellent performance both on the large Ising spin systems and on the set\nof exemplary maximum cut benchmark instances in terms of both solution quality\nand computational time.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 11:50:21 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 12:18:26 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Yavorsky", "A.", ""], ["Markovich", "L. A.", ""], ["Polyakov", "E. A.", ""], ["Rubtsov", "A. N.", ""]]}, {"id": "1907.05146", "submitter": "Mathias Kraus", "authors": "Mathias Kraus and Stefan Feuerriegel", "title": "Forecasting remaining useful life: Interpretable deep learning approach\n  via variational Bayesian inferences", "comments": null, "journal-ref": null, "doi": "10.1016/j.dss.2019.113100", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the remaining useful life of machinery, infrastructure, or other\nequipment can facilitate preemptive maintenance decisions, whereby a failure is\nprevented through timely repair or replacement. This allows for a better\ndecision support by considering the anticipated time-to-failure and thus\npromises to reduce costs. Here a common baseline may be derived by fitting a\nprobability density function to past lifetimes and then utilizing the\n(conditional) expected remaining useful life as a prognostic. This approach\nfinds widespread use in practice because of its high explanatory power. A more\naccurate alternative is promised by machine learning, where forecasts\nincorporate deterioration processes and environmental variables through sensor\ndata. However, machine learning largely functions as a black-box method and its\nforecasts thus forfeit most of the desired interpretability. As our primary\ncontribution, we propose a structured-effect neural network for predicting the\nremaining useful life which combines the favorable properties of both\napproaches: its key innovation is that it offers both a high accountability and\nthe flexibility of deep learning. The parameters are estimated via variational\nBayesian inferences. The different approaches are compared based on the actual\ntime-to-failure for aircraft engines. This demonstrates the performance and\nsuperior interpretability of our method, while we finally discuss implications\nfor decision support.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 12:33:45 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 14:46:08 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Kraus", "Mathias", ""], ["Feuerriegel", "Stefan", ""]]}, {"id": "1907.05156", "submitter": "Sai Praneeth Karimireddy", "authors": "Elo\\\"ise Berthier and Sai Praneeth Karimireddy", "title": "Amplifying R\\'enyi Differential Privacy via Shuffling", "comments": "This version has incorrect proofs! We are currently working on fixing\n  these", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential privacy is a useful tool to build machine learning models which\ndo not release too much information about the training data. We study the\nR\\'enyi differential privacy of stochastic gradient descent when each training\nexample is sampled without replacement (also known as cyclic SGD). Cyclic SGD\nis typically faster than traditional SGD and is the algorithm of choice in\nlarge-scale implementations. We recover privacy guarantees for cyclic SGD which\nare competitive with those known for sampling with replacement. Our proof\ntechniques make no assumptions on the model or on the data and are hence widely\napplicable.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 12:44:27 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 14:56:19 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 13:29:15 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Berthier", "Elo\u00efse", ""], ["Karimireddy", "Sai Praneeth", ""]]}, {"id": "1907.05159", "submitter": "Marcus Hutter", "authors": "Marcus Hutter", "title": "Fairness without Regret", "comments": "11 pages, 2 figures, 1 table, keywords: utility, objective, optimal,\n  fair/equitable/just, cost/regret, uncertainty", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular approach of achieving fairness in optimization problems is by\nconstraining the solution space to \"fair\" solutions, which unfortunately\ntypically reduces solution quality. In practice, the ultimate goal is often an\naggregate of sub-goals without a unique or best way of combining them or which\nis otherwise only partially known. I turn this problem into a feature and\nsuggest to use a parametrized objective and vary the parameters within\nreasonable ranges to get a \"set\" of optimal solutions, which can then be\noptimized using secondary criteria such as fairness without compromising the\nprimary objective, i.e. without regret (societal cost).\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 12:49:27 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Hutter", "Marcus", ""]]}, {"id": "1907.05190", "submitter": "Julia Kreutzer", "authors": "Julia Kreutzer, Stefan Riezler", "title": "Self-Regulated Interactive Sequence-to-Sequence Learning", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Not all types of supervision signals are created equal: Different types of\nfeedback have different costs and effects on learning. We show how\nself-regulation strategies that decide when to ask for which kind of feedback\nfrom a teacher (or from oneself) can be cast as a learning-to-learn problem\nleading to improved cost-aware sequence-to-sequence learning. In experiments on\ninteractive neural machine translation, we find that the self-regulator\ndiscovers an $\\epsilon$-greedy strategy for the optimal cost-quality trade-off\nby mixing different feedback types including corrections, error markups, and\nself-supervision. Furthermore, we demonstrate its robustness under domain shift\nand identify it as a promising alternative to active learning.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 13:42:46 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 15:15:13 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Kreutzer", "Julia", ""], ["Riezler", "Stefan", ""]]}, {"id": "1907.05195", "submitter": "Stephen Odaibo", "authors": "Stephen G. Odaibo", "title": "retina-VAE: Variationally Decoding the Spectrum of Macular Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.TO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we seek a clinically-relevant latent code for representing the\nspectrum of macular disease. Towards this end, we construct retina-VAE, a\nvariational autoencoder-based model that accepts a patient profile vector\n(pVec) as input. The pVec components include clinical exam findings and\ndemographic information. We evaluate the model on a subspectrum of the retinal\nmaculopathies, in particular, exudative age-related macular degeneration,\ncentral serous chorioretinopathy, and polypoidal choroidal vasculopathy. For\nthese three maculopathies, a database of 3000 6-dimensional pVecs (1000 each)\nwas synthetically generated based on known disease statistics in the\nliterature. The database was then used to train the VAE and generate latent\nvector representations. We found training performance to be best for a\n3-dimensional latent vector architecture compared to 2 or 4 dimensional\nlatents. Additionally, for the 3D latent architecture, we discovered that the\nresulting latent vectors were strongly clustered spontaneously into one of 14\nclusters. Kmeans was then used only to identify members of each cluster and to\ninspect cluster properties. These clusters suggest underlying disease subtypes\nwhich may potentially respond better or worse to particular pharmaceutical\ntreatments such as anti-vascular endothelial growth factor variants. The\nretina-VAE framework will potentially yield new fundamental insights into the\nmechanisms and manifestations of disease. And will potentially facilitate the\ndevelopment of personalized pharmaceuticals and gene therapies.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 13:49:25 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Odaibo", "Stephen G.", ""]]}, {"id": "1907.05226", "submitter": "Bharath Sriperumbudur", "authors": "Nicholas Sterge, Bharath Sriperumbudur, Lorenzo Rosasco and Alessandro\n  Rudi", "title": "Gain with no Pain: Efficient Kernel-PCA by Nystr\\\"om Sampling", "comments": "19 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and study a Nystr\\\"om based approach to efficient\nlarge scale kernel principal component analysis (PCA). The latter is a natural\nnonlinear extension of classical PCA based on considering a nonlinear feature\nmap or the corresponding kernel. Like other kernel approaches, kernel PCA\nenjoys good mathematical and statistical properties but, numerically, it scales\npoorly with the sample size. Our analysis shows that Nystr\\\"om sampling greatly\nimproves computational efficiency without incurring any loss of statistical\naccuracy. While similar effects have been observed in supervised learning, this\nis the first such result for PCA. Our theoretical findings, which are also\nillustrated by numerical results, are based on a combination of analytic and\nconcentration of measure techniques. Our study is more broadly motivated by the\nquestion of understanding the interplay between statistical and computational\nrequirements for learning.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 14:16:25 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Sterge", "Nicholas", ""], ["Sriperumbudur", "Bharath", ""], ["Rosasco", "Lorenzo", ""], ["Rudi", "Alessandro", ""]]}, {"id": "1907.05231", "submitter": "Shuai Ma", "authors": "Shuai Ma and Jia Yuan Yu", "title": "Variance-Based Risk Estimations in Markov Processes via Transformation\n  with State Lumping", "comments": "7 pages, 7 figures, SMC 2019 accepted. arXiv admin note: text overlap\n  with arXiv:1907.04269", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variance plays a crucial role in risk-sensitive reinforcement learning, and\nmost risk measures can be analyzed via variance. In this paper, we consider two\nlaw-invariant risks as examples: mean-variance risk and exponential utility\nrisk. With the aid of the state-augmentation transformation (SAT), we show\nthat, the two risks can be estimated in Markov decision processes (MDPs) with a\nstochastic transition-based reward and a randomized policy. To relieve the\nenlarged state space, a novel definition of isotopic states is proposed for\nstate lumping, considering the special structure of the transformed transition\nprobability. In the numerical experiment, we illustrate state lumping in the\nSAT, errors from a naive reward simplification, and the validity of the SAT for\nthe two risk estimations.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 16:04:33 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Ma", "Shuai", ""], ["Yu", "Jia Yuan", ""]]}, {"id": "1907.05234", "submitter": "Chainarong Amornbunchornvej", "authors": "Chainarong Amornbunchornvej, Navaporn Surasvadi, Anon Plangprasopchok,\n  and Suttipong Thajchayapong", "title": "Identifying Linear Models in Multi-Resolution Population Data using\n  Minimum Description Length Principle to Predict Household Income", "comments": "This is the accepted manuscript for publication in TKDD. The R\n  package is available at https://github.com/DarkEyes/MRReg", "journal-ref": "ACM Transactions on Knowledge Discovery from Data (TKDD), 15(2),\n  15 (2021)", "doi": "10.1145/3424670", "report-no": null, "categories": "cs.LG cs.CY stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One shirt size cannot fit everybody, while we cannot make a unique shirt that\nfits perfectly for everyone because of resource limitation. This analogy is\ntrue for the policy making. Policy makers cannot establish a single policy to\nsolve all problems for all regions because each region has its own unique\nissue. In the other extreme, policy makers also cannot create a policy for each\nsmall village due to the resource limitation. Would it be better if we can find\na set of largest regions such that the population of each region within this\nset has common issues and we can establish a single policy for them? In this\nwork, we propose a framework using regression analysis and minimum description\nlength (MDL) to find a set of largest areas that have common indicators, which\ncan be used to predict household incomes efficiently. Given a set of household\nfeatures, and a multi-resolution partition that represents administrative\ndivisions, our framework reports a set C* of largest subdivisions that have a\ncommon model for population-income prediction. We formalize a problem of\nfinding C* and propose the algorithm as a solution. We use both simulation\ndatasets as well as a real-world dataset of Thailand's population household\ninformation to demonstrate our framework performance and application. The\nresults show that our framework performance is better than the baseline\nmethods. We show the results of our method can be used to find indicators of\nincome prediction for many areas in Thailand. By increasing these indicator\nvalues, we expect people in these areas to gain more incomes. Hence, the policy\nmakers can plan to establish the policies by using these indicators in our\nresults as a guideline to solve low-income issues. Our framework can be used to\nsupport policy makers to establish policies regarding any other dependent\nvariable beyond incomes in order to combat poverty and other issues.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 03:08:31 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 15:32:25 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2021 08:39:38 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Amornbunchornvej", "Chainarong", ""], ["Surasvadi", "Navaporn", ""], ["Plangprasopchok", "Anon", ""], ["Thajchayapong", "Suttipong", ""]]}, {"id": "1907.05251", "submitter": "Karl {\\O}yvind Mikalsen", "authors": "Karl {\\O}yvind Mikalsen, Cristina Soguero-Ruiz, Filippo Maria Bianchi,\n  Arthur Revhaug, Robert Jenssen", "title": "Time series cluster kernels to exploit informative missingness and\n  incomplete label information", "comments": "arXiv admin note: text overlap with arXiv:1803.07879", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The time series cluster kernel (TCK) provides a powerful tool for analysing\nmultivariate time series subject to missing data. TCK is designed using an\nensemble learning approach in which Bayesian mixture models form the base\nmodels. Because of the Bayesian approach, TCK can naturally deal with missing\nvalues without resorting to imputation and the ensemble strategy ensures\nrobustness to hyperparameters, making it particularly well suited for\nunsupervised learning.\n  However, TCK assumes missing at random and that the underlying missingness\nmechanism is ignorable, i.e. uninformative, an assumption that does not hold in\nmany real-world applications, such as e.g. medicine. To overcome this\nlimitation, we present a kernel capable of exploiting the potentially rich\ninformation in the missing values and patterns, as well as the information from\nthe observed data. In our approach, we create a representation of the missing\npattern, which is incorporated into mixed mode mixture models in such a way\nthat the information provided by the missing patterns is effectively exploited.\nMoreover, we also propose a semi-supervised kernel, capable of taking advantage\nof incomplete label information to learn more accurate similarities.\n  Experiments on benchmark data, as well as a real-world case study of patients\ndescribed by longitudinal electronic health record data who potentially suffer\nfrom hospital-acquired infections, demonstrate the effectiveness of the\nproposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 08:05:15 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Mikalsen", "Karl \u00d8yvind", ""], ["Soguero-Ruiz", "Cristina", ""], ["Bianchi", "Filippo Maria", ""], ["Revhaug", "Arthur", ""], ["Jenssen", "Robert", ""]]}, {"id": "1907.05267", "submitter": "Helena Andres Terre", "authors": "Helena Andr\\'es-Terr\\'e, Pietro Li\\'o", "title": "Perturbation theory approach to study the latent space degeneracy of\n  Variational Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Variational Autoencoders in different Machine Learning tasks has\ndrastically increased in the last years. They have been developed as denoising,\nclustering and generative tools, highlighting a large potential in a wide range\nof fields. Their embeddings are able to extract relevant information from\nhighly dimensional inputs, but the converged models can differ significantly\nand lead to degeneracy on the latent space. We leverage the relation between\ntheoretical physics and machine learning to explain this behaviour, and\nintroduce a new approach to correct for degeneration by using perturbation\ntheory. The re-formulation of the embedding as multi-dimensional generative\ndistribution, allows mapping to a new set of functions and their corresponding\nenergy spectrum. We optimise for a perturbed Hamiltonian, with an additional\nenergy potential that is related to the unobserved topology of the data. Our\nresults show the potential of a new theoretical approach that can be used to\ninterpret the latent space and generative nature of unsupervised learning,\nwhile the energy landscapes defined by the perturbations can be further used\nfor modelling and dynamical purposes.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 16:14:13 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Andr\u00e9s-Terr\u00e9", "Helena", ""], ["Li\u00f3", "Pietro", ""]]}, {"id": "1907.05269", "submitter": "Leszek Pecyna", "authors": "Leszek Pecyna, Angelo Cangelosi", "title": "Influence of Pointing on Learning to Count: A Neuro-Robotics Model", "comments": "8 pages, 5 figures. In Proceedings of the 2018 IEEE Symposium Series\n  on Computational Intelligence (SSCI) (pp. 358-365). IEEE", "journal-ref": null, "doi": "10.1109/SSCI.2018.8628811", "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a neuro-robotics model capable of counting using gestures is\nintroduced. The contribution of gestures to learning to count is tested with\nvarious model and training conditions. Two studies were presented in this\narticle. In the first, we combine different modalities of the robot's neural\nnetwork, in the second, a novel training procedure for it is proposed. The\nmodel is trained with pointing data from an iCub robot simulator. The behaviour\nof the model is in line with that of human children in terms of performance\nchange depending on gesture production.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 13:59:36 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Pecyna", "Leszek", ""], ["Cangelosi", "Angelo", ""]]}, {"id": "1907.05270", "submitter": "Leszek Pecyna", "authors": "Leszek Pecyna, Angelo Cangelosi, Alessandro Di Nuovo", "title": "A Deep Neural Network for Finger Counting and Numerosity Estimation", "comments": "8 pages, accepted and presented on a conference. In Proceedings of\n  the 2019 IEEE Symposium Series on Computational Intelligence (SSCI)", "journal-ref": "2019 IEEE Symposium Series on Computational Intelligence", "doi": "10.1109/SSCI44817.2019.9002694", "report-no": null, "categories": "cs.CV cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present neuro-robotics models with a deep artificial neural\nnetwork capable of generating finger counting positions and number estimation.\nWe first train the model in an unsupervised manner where each layer is treated\nas a Restricted Boltzmann Machine or an autoencoder. Such a model is further\ntrained in a supervised way. This type of pre-training is tested on our\nbaseline model and two methods of pre-training are compared. The network is\nextended to produce finger counting positions. The performance in number\nestimation of such an extended model is evaluated. We test the hypothesis if\nthe subitizing process can be obtained by one single model used also for\nestimation of higher numerosities. The results confirm the importance of\nunsupervised training in our enumeration task and show some similarities to\nhuman behaviour in the case of subitizing.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 13:10:28 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 17:33:53 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Pecyna", "Leszek", ""], ["Cangelosi", "Angelo", ""], ["Di Nuovo", "Alessandro", ""]]}, {"id": "1907.05278", "submitter": "Youssef Mourchid", "authors": "Youssef Mourchid, Mohammed El Hassouni, Hocine Cherifi", "title": "A General Framework for Complex Network-Based Image Segmentation", "comments": null, "journal-ref": "Multimedia Tools and Applications (2019)", "doi": "10.1007/s11042-019-7304-2", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent advances in complex networks theory, graph-based techniques\nfor image segmentation has attracted great attention recently. In order to\nsegment the image into meaningful connected components, this paper proposes an\nimage segmentation general framework using complex networks based community\ndetection algorithms. If we consider regions as communities, using community\ndetection algorithms directly can lead to an over-segmented image. To address\nthis problem, we start by splitting the image into small regions using an\ninitial segmentation. The obtained regions are used for building the complex\nnetwork. To produce meaningful connected components and detect homogeneous\ncommunities, some combinations of color and texture based features are employed\nin order to quantify the regions similarities. To sum up, the network of\nregions is constructed adaptively to avoid many small regions in the image, and\nthen, community detection algorithms are applied on the resulting adaptive\nsimilarity matrix to obtain the final segmented image. Experiments are\nconducted on Berkeley Segmentation Dataset and four of the most influential\ncommunity detection algorithms are tested. Experimental results have shown that\nthe proposed general framework increases the segmentation performances compared\nto some existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 11:59:42 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Mourchid", "Youssef", ""], ["Hassouni", "Mohammed El", ""], ["Cherifi", "Hocine", ""]]}, {"id": "1907.05279", "submitter": "Lukas Prantl", "authors": "Lukas Prantl, Nuttapong Chentanez, Stefan Jeschke, and Nils Thuerey", "title": "Tranquil Clouds: Neural Networks for Learning Temporally Coherent\n  Features in Point Clouds", "comments": "Further information and videos at\n  https://ge.in.tum.de/publications/2020-iclr-prantl/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point clouds, as a form of Lagrangian representation, allow for powerful and\nflexible applications in a large number of computational disciplines. We\npropose a novel deep-learning method to learn stable and temporally coherent\nfeature spaces for points clouds that change over time. We identify a set of\ninherent problems with these approaches: without knowledge of the time\ndimension, the inferred solutions can exhibit strong flickering, and easy\nsolutions to suppress this flickering can result in undesirable local minima\nthat manifest themselves as halo structures. We propose a novel temporal loss\nfunction that takes into account higher time derivatives of the point\npositions, and encourages mingling, i.e., to prevent the aforementioned halos.\nWe combine these techniques in a super-resolution method with a truncation\napproach to flexibly adapt the size of the generated positions. We show that\nour method works for large, deforming point sets from different sources to\ndemonstrate the flexibility of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 18:54:02 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 10:55:16 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Prantl", "Lukas", ""], ["Chentanez", "Nuttapong", ""], ["Jeschke", "Stefan", ""], ["Thuerey", "Nils", ""]]}, {"id": "1907.05280", "submitter": "Maximilian Bachl", "authors": "Maximilian Bachl and Daniel C. Ferreira", "title": "City-GAN: Learning architectural styles using a custom Conditional GAN\n  architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.GR cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Generative Adversarial Networks (GANs) are a well-known technique that is\ntrained on samples (e.g. pictures of fruits) and which after training is able\nto generate realistic new samples. Conditional GANs (CGANs) additionally\nprovide label information for subclasses (e.g. apple, orange, pear) which\nenables the GAN to learn more easily and increase the quality of its output\nsamples. We use GANs to learn architectural features of major cities and to\ngenerate images of buildings which do not exist. We show that currently\navailable GAN and CGAN architectures are unsuited for this task and propose a\ncustom architecture and demonstrate that our architecture has superior\nperformance for this task and verify its capabilities with extensive\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:43:36 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 20:19:30 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Bachl", "Maximilian", ""], ["Ferreira", "Daniel C.", ""]]}, {"id": "1907.05282", "submitter": "Zhuangzi Li", "authors": "Zhuangzi Li", "title": "Image Super-Resolution Using Attention Based DenseNet with Residual\n  Deconvolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image super-resolution is a challenging task and has attracted increasing\nattention in research and industrial communities. In this paper, we propose a\nnovel end-to-end Attention-based DenseNet with Residual Deconvolution named as\nADRD. In our ADRD, a weighted dense block, in which the current layer receives\nweighted features from all previous levels, is proposed to capture valuable\nfeatures rely in dense layers adaptively. And a novel spatial attention module\nis presented to generate a group of attentive maps for emphasizing informative\nregions. In addition, we design an innovative strategy to upsample residual\ninformation via the deconvolution layer, so that the high-frequency details can\nbe accurately upsampled. Extensive experiments conducted on publicly available\ndatasets demonstrate the promising performance of the proposed ADRD against the\nstate-of-the-arts, both quantitatively and qualitatively.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 08:28:13 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Li", "Zhuangzi", ""]]}, {"id": "1907.05283", "submitter": "Cem Sahin", "authors": "Evan Koester, Cem Safak Sahin", "title": "A Comparison of Super-Resolution and Nearest Neighbors Interpolation\n  Applied to Object Detection on Satellite Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Super-Resolution (SR) has matured as a research topic, it has been applied\nto additional topics beyond image reconstruction. In particular, combining\nclassification or object detection tasks with a super-resolution preprocessing\nstage has yielded improvements in accuracy especially with objects that are\nsmall relative to the scene. While SR has shown promise, a study comparing SR\nand naive upscaling methods such as Nearest Neighbors (NN) interpolation when\napplied as a preprocessing step for object detection has not been performed. We\napply the topic to satellite data and compare the Multi-scale Deep\nSuper-Resolution (MDSR) system to NN on the xView challenge dataset. To do so,\nwe propose a pipeline for processing satellite data that combines multi-stage\nimage tiling and upscaling, the YOLOv2 object detection architecture, and label\nstitching. We compare the effects of training models using an upscaling factor\nof 4, upscaling images from 30cm Ground Sample Distance (GSD) to an effective\nGSD of 7.5cm. Upscaling by this factor significantly improves detection\nresults, increasing Average Precision (AP) of a generalized vehicle class by 23\npercent. We demonstrate that while SR produces upscaled images that are more\nvisually pleasing than their NN counterparts, object detection networks see\nlittle difference in accuracy with images upsampled using NN obtaining nearly\nidentical results to the MDSRx4 enhanced images with a difference of 0.0002 AP\nbetween the two methods.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 17:03:12 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Koester", "Evan", ""], ["Sahin", "Cem Safak", ""]]}, {"id": "1907.05286", "submitter": "Bei Wang", "authors": "Bei Wang, Jianping An and Jiayan Cao", "title": "Voxel-FPN: multi-scale voxel feature aggregation in 3D object detection\n  from point clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Object detection in point cloud data is one of the key components in computer\nvision systems, especially for autonomous driving applications. In this work,\nwe present Voxel-FPN, a novel one-stage 3D object detector that utilizes raw\ndata from LIDAR sensors only. The core framework consists of an encoder network\nand a corresponding decoder followed by a region proposal network. Encoder\nextracts multi-scale voxel information in a bottom-up manner while decoder\nfuses multiple feature maps from various scales in a top-down way. Extensive\nexperiments show that the proposed method has better performance on extracting\nfeatures from point data and demonstrates its superiority over some baselines\non the challenging KITTI-3D benchmark, obtaining good performance on both speed\nand accuracy in real-world scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 09:49:10 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 08:22:44 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Wang", "Bei", ""], ["An", "Jianping", ""], ["Cao", "Jiayan", ""]]}, {"id": "1907.05297", "submitter": "Mariel Pettee", "authors": "Mariel Pettee, Chase Shimmin, Douglas Duhaime, Ilya Vidrin", "title": "Beyond Imitation: Generative and Variational Choreography via Machine\n  Learning", "comments": "8 pages, 11 figures, presented at the 10th International Conference\n  on Computational Creativity (ICCC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our team of dance artists, physicists, and machine learning researchers has\ncollectively developed several original, configurable machine-learning tools to\ngenerate novel sequences of choreography as well as tunable variations on input\nchoreographic sequences. We use recurrent neural network and autoencoder\narchitectures from a training dataset of movements captured as 53\nthree-dimensional points at each timestep. Sample animations of generated\nsequences and an interactive version of our model can be found at http:\n//www.beyondimitation.com.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 15:12:10 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Pettee", "Mariel", ""], ["Shimmin", "Chase", ""], ["Duhaime", "Douglas", ""], ["Vidrin", "Ilya", ""]]}, {"id": "1907.05325", "submitter": "Andrew McRae", "authors": "Andrew D. McRae and Mark A. Davenport", "title": "Low-rank matrix completion and denoising under Poisson noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of estimating a low-rank matrix from the\nobservation of all or a subset of its entries in the presence of Poisson noise.\nWhen we observe all entries, this is a problem of matrix denoising; when we\nobserve only a subset of the entries, this is a problem of matrix completion.\nIn both cases, we exploit an assumption that the underlying matrix is low-rank.\nSpecifically, we analyze several estimators, including a constrained\nnuclear-norm minimization program, nuclear-norm regularized least squares, and\na nonconvex constrained low-rank optimization problem. We show that for all\nthree estimators, with high probability, we have an upper error bound (in the\nFrobenius norm error metric) that depends on the matrix rank, the fraction of\nthe elements observed, and maximal row and column sums of the true matrix. We\nfurthermore show that the above results are minimax optimal (within a universal\nconstant) in classes of matrices with low rank and bounded row and column sums.\nWe also extend these results to handle the case of matrix multinomial denoising\nand completion.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 16:00:42 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 16:20:17 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["McRae", "Andrew D.", ""], ["Davenport", "Mark A.", ""]]}, {"id": "1907.05336", "submitter": "Mojtaba Nayyeri", "authors": "Mojtaba Nayyeri, Xiaotian Zhou, Sahar Vahdati, Hamed Shariat Yazdi,\n  Jens Lehmann", "title": "Adaptive Margin Ranking Loss for Knowledge Graph Embeddings via a\n  Correntropy Objective Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Translation-based embedding models have gained significant attention in link\nprediction tasks for knowledge graphs. TransE is the primary model among\ntranslation-based embeddings and is well-known for its low complexity and high\nefficiency. Therefore, most of the earlier works have modified the score\nfunction of the TransE approach in order to improve the performance of link\nprediction tasks. Nevertheless, proven theoretically and experimentally, the\nperformance of TransE strongly depends on the loss function. Margin Ranking\nLoss (MRL) has been one of the earlier loss functions which is widely used for\ntraining TransE. However, the scores of positive triples are not necessarily\nenforced to be sufficiently small to fulfill the translation from head to tail\nby using relation vector (original assumption of TransE). To tackle this\nproblem, several loss functions have been proposed recently by adding upper\nbounds and lower bounds to the scores of positive and negative samples.\nAlthough highly effective, previously developed models suffer from an expansion\nin search space for a selection of the hyperparameters (in particular the upper\nand lower bounds of scores) on which the performance of the translation-based\nmodels is highly dependent. In this paper, we propose a new loss function\ndubbed Adaptive Margin Loss (AML) for training translation-based embedding\nmodels. The formulation of the proposed loss function enables an adaptive and\nautomated adjustment of the margin during the learning process. Therefore,\ninstead of obtaining two values (upper bound and lower bound), only the center\nof a margin needs to be determined. During learning, the margin is expanded\nautomatically until it converges. In our experiments on a set of standard\nbenchmark datasets including Freebase and WordNet, the effectiveness of AML is\nconfirmed for training TransE on link prediction tasks.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 12:32:40 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Nayyeri", "Mojtaba", ""], ["Zhou", "Xiaotian", ""], ["Vahdati", "Sahar", ""], ["Yazdi", "Hamed Shariat", ""], ["Lehmann", "Jens", ""]]}, {"id": "1907.05358", "submitter": "Ankit Gupta", "authors": "Ankit Gupta", "title": "StrokeSave: A Novel, High-Performance Mobile Application for Stroke\n  Diagnosis using Deep Learning and Computer Vision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the WHO, Cerebrovascular Stroke, or CS, is the second largest\ncause of death worldwide. Current diagnosis of CS relies on labor and cost\nintensive neuroimaging techniques, unsuitable for areas with inadequate access\nto quality medical facilities. Thus, there is a great need for an efficient\ndiagnosis alternative. StrokeSave is a platform for users to self-diagnose for\nprevalence to stroke. The mobile app is continuously updated with heart rate,\nblood pressure, and blood oxygen data from sensors on the patient wrist. Once\nthese measurements reach a threshold for possible stroke, the patient takes\nfacial images and vocal recordings to screen for paralysis attributed to\nstroke. A custom designed lens attached to a phone's camera then takes retinal\nimages for the deep learning model to classify based on presence of retinopathy\nand sends a comprehensive diagnosis. The deep learning model, which consists of\na RNN trained on 100 voice slurred audio files, a SVM trained on 410 vascular\ndata points, and a CNN trained on 520 retinopathy images, achieved a holistic\naccuracy of 95.0 percent when validated on 327 samples. This value exceeds that\nof clinical examination accuracy, which is around 40 to 89 percent, further\ndemonstrating the vital utility of such a medical device. Through this\nautomated platform, users receive efficient, highly accurate diagnosis without\nprofessional medical assistance, revolutionizing medical diagnosis of CS and\npotentially saving millions of lives.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 21:01:58 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Gupta", "Ankit", ""]]}, {"id": "1907.05364", "submitter": "Felix Batsch", "authors": "Felix Batsch, Alireza Daneshkhah, Madeline Cheah, Stratis Kanarachos,\n  Anthony Baxendale", "title": "Performance Boundary Identification for the Evaluation of Automated\n  Vehicles using Gaussian Process Classification", "comments": "6 pages, 5 figures, accepted at 2019 IEEE Intelligent Transportation\n  Systems Conference - ITSC 2019, Auckland, New Zealand, October 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety is an essential aspect in the facilitation of automated vehicle\ndeployment. Current testing practices are not enough, and going beyond them\nleads to infeasible testing requirements, such as needing to drive billions of\nkilometres on public roads. Automated vehicles are exposed to an indefinite\nnumber of scenarios. Handling of the most challenging scenarios should be\ntested, which leads to the question of how such corner cases can be determined.\nWe propose an approach to identify the performance boundary, where these corner\ncases are located, using Gaussian Process Classification. We also demonstrate\nthe classification on an exemplary traffic jam approach scenario, showing that\nit is feasible and would lead to more efficient testing practices.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 16:35:59 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Batsch", "Felix", ""], ["Daneshkhah", "Alireza", ""], ["Cheah", "Madeline", ""], ["Kanarachos", "Stratis", ""], ["Baxendale", "Anthony", ""]]}, {"id": "1907.05378", "submitter": "Yassine Hamoudi", "authors": "Yassine Hamoudi, Patrick Rebentrost, Ansis Rosmanis, Miklos Santha", "title": "Quantum and Classical Algorithms for Approximate Submodular Function\n  Minimization", "comments": "24 pages, Journal version", "journal-ref": "Quantum Information & Computation, vol. 19, pp. 1325-1349 (2019)", "doi": null, "report-no": null, "categories": "cs.DS cs.LG math.OC quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Submodular functions are set functions mapping every subset of some ground\nset of size $n$ into the real numbers and satisfying the diminishing returns\nproperty. Submodular minimization is an important field in discrete\noptimization theory due to its relevance for various branches of mathematics,\ncomputer science and economics. The currently fastest strongly polynomial\nalgorithm for exact minimization [LSW15] runs in time $\\widetilde{O}(n^3 \\cdot\n\\mathrm{EO} + n^4)$ where $\\mathrm{EO}$ denotes the cost to evaluate the\nfunction on any set. For functions with range $[-1,1]$, the best\n$\\epsilon$-additive approximation algorithm [CLSW17] runs in time\n$\\widetilde{O}(n^{5/3}/\\epsilon^{2} \\cdot \\mathrm{EO})$. In this paper we\npresent a classical and a quantum algorithm for approximate submodular\nminimization. Our classical result improves on the algorithm of [CLSW17] and\nruns in time $\\widetilde{O}(n^{3/2}/\\epsilon^2 \\cdot \\mathrm{EO})$. Our quantum\nalgorithm is, up to our knowledge, the first attempt to use quantum computing\nfor submodular optimization. The algorithm runs in time\n$\\widetilde{O}(n^{5/4}/\\epsilon^{5/2} \\cdot \\log(1/\\epsilon) \\cdot\n\\mathrm{EO})$. The main ingredient of the quantum result is a new method for\nsampling with high probability $T$ independent elements from any discrete\nprobability distribution of support size $n$ in time $O(\\sqrt{Tn})$. Previous\nquantum algorithms for this problem were of complexity $O(T\\sqrt{n})$.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 16:54:20 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 10:42:39 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Hamoudi", "Yassine", ""], ["Rebentrost", "Patrick", ""], ["Rosmanis", "Ansis", ""], ["Santha", "Miklos", ""]]}, {"id": "1907.05381", "submitter": "Yuqing Zhang", "authors": "Yuqing Zhang and Neil Walton", "title": "Adaptive Pricing in Insurance: Generalized Linear Models and Gaussian\n  Process Regression Approaches", "comments": "33 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM math.OC q-fin.MF q-fin.RM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the application of dynamic pricing to insurance. We view this as an\nonline revenue management problem where the insurance company looks to set\nprices to optimize the long-run revenue from selling a new insurance product.\nWe develop two pricing models: an adaptive Generalized Linear Model (GLM) and\nan adaptive Gaussian Process (GP) regression model. Both balance between\nexploration, where we choose prices in order to learn the distribution of\ndemands & claims for the insurance product, and exploitation, where we\nmyopically choose the best price from the information gathered so far. The\nperformance of the pricing policies is measured in terms of regret: the\nexpected revenue loss caused by not using the optimal price. As is commonplace\nin insurance, we model demand and claims by GLMs. In our adaptive GLM design,\nwe use the maximum quasi-likelihood estimation (MQLE) to estimate the unknown\nparameters. We show that, if prices are chosen with suitably decreasing\nvariability, the MQLE parameters eventually exist and converge to the correct\nvalues, which in turn implies that the sequence of chosen prices will also\nconverge to the optimal price. In the adaptive GP regression model, we sample\ndemand and claims from Gaussian Processes and then choose selling prices by the\nupper confidence bound rule. We also analyze these GLM and GP pricing\nalgorithms with delayed claims. Although similar results exist in other\ndomains, this is among the first works to consider dynamic pricing problems in\nthe field of insurance. We also believe this is the first work to consider\nGaussian Process regression in the context of insurance pricing. These initial\nfindings suggest that online machine learning algorithms could be a fruitful\narea of future investigation and application in insurance.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 08:18:54 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Zhang", "Yuqing", ""], ["Walton", "Neil", ""]]}, {"id": "1907.05388", "submitter": "Chi Jin", "authors": "Chi Jin, Zhuoran Yang, Zhaoran Wang, Michael I. Jordan", "title": "Provably Efficient Reinforcement Learning with Linear Function\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Reinforcement Learning (RL) is commonly applied to practical problems\nwith an enormous number of states, where function approximation must be\ndeployed to approximate either the value function or the policy. The\nintroduction of function approximation raises a fundamental set of challenges\ninvolving computational and statistical efficiency, especially given the need\nto manage the exploration/exploitation tradeoff. As a result, a core RL\nquestion remains open: how can we design provably efficient RL algorithms that\nincorporate function approximation? This question persists even in a basic\nsetting with linear dynamics and linear rewards, for which only linear function\napproximation is needed.\n  This paper presents the first provable RL algorithm with both polynomial\nruntime and polynomial sample complexity in this linear setting, without\nrequiring a \"simulator\" or additional assumptions. Concretely, we prove that an\noptimistic modification of Least-Squares Value Iteration (LSVI)---a classical\nalgorithm frequently studied in the linear setting---achieves\n$\\tilde{\\mathcal{O}}(\\sqrt{d^3H^3T})$ regret, where $d$ is the ambient\ndimension of feature space, $H$ is the length of each episode, and $T$ is the\ntotal number of steps. Importantly, such regret is independent of the number of\nstates and actions.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 17:06:11 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 07:23:12 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Jin", "Chi", ""], ["Yang", "Zhuoran", ""], ["Wang", "Zhaoran", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1907.05409", "submitter": "Solt Kov\\'acs", "authors": "Malte Londschien, Solt Kov\\'acs, Peter B\\\"uhlmann", "title": "Change point detection for graphical models in the presence of missing\n  values", "comments": "14 pages, 6 figures, 3 tables, hdcd R package; added explanations and\n  clarifications, methodology and simulation results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose estimation methods for change points in high-dimensional\ncovariance structures with an emphasis on challenging scenarios with missing\nvalues. We advocate three imputation like methods and investigate their\nimplications on common losses used for change point detection. We also discuss\nhow model selection methods have to be adapted to the setting of incomplete\ndata. The methods are compared in a simulation study and applied to a time\nseries from an environmental monitoring system. An implementation of our\nproposals within the R-package hdcd is available via the Supplementary\nmaterials.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 17:50:47 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2020 20:51:57 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Londschien", "Malte", ""], ["Kov\u00e1cs", "Solt", ""], ["B\u00fchlmann", "Peter", ""]]}, {"id": "1907.05418", "submitter": "Dawei Yang", "authors": "Yulong Cao, Chaowei Xiao, Dawei Yang, Jing Fang, Ruigang Yang, Mingyan\n  Liu, Bo Li", "title": "Adversarial Objects Against LiDAR-Based Autonomous Driving Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are found to be vulnerable against adversarial\nexamples, which are carefully crafted inputs with a small magnitude of\nperturbation aiming to induce arbitrarily incorrect predictions. Recent studies\nshow that adversarial examples can pose a threat to real-world\nsecurity-critical applications: a \"physical adversarial Stop Sign\" can be\nsynthesized such that the autonomous driving cars will misrecognize it as\nothers (e.g., a speed limit sign). However, these image-space adversarial\nexamples cannot easily alter 3D scans of widely equipped LiDAR or radar on\nautonomous vehicles. In this paper, we reveal the potential vulnerabilities of\nLiDAR-based autonomous driving detection systems, by proposing an optimization\nbased approach LiDAR-Adv to generate adversarial objects that can evade the\nLiDAR-based detection system under various conditions. We first show the\nvulnerabilities using a blackbox evolution-based algorithm, and then explore\nhow much a strong adversary can do, using our gradient-based approach\nLiDAR-Adv. We test the generated adversarial objects on the Baidu Apollo\nautonomous driving platform and show that such physical systems are indeed\nvulnerable to the proposed attacks. We also 3D-print our adversarial objects\nand perform physical experiments to illustrate that such vulnerability exists\nin the real world. Please find more visualizations and results on the anonymous\nwebsite: https://sites.google.com/view/lidar-adv.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 17:59:13 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Cao", "Yulong", ""], ["Xiao", "Chaowei", ""], ["Yang", "Dawei", ""], ["Fang", "Jing", ""], ["Yang", "Ruigang", ""], ["Liu", "Mingyan", ""], ["Li", "Bo", ""]]}, {"id": "1907.05431", "submitter": "Abhinav Verma", "authors": "Abhinav Verma, Hoang M. Le, Yisong Yue, Swarat Chaudhuri", "title": "Imitation-Projected Programmatic Reinforcement Learning", "comments": "Published in Advances in Neural Information Processing Systems\n  (NeurIPS) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of programmatic reinforcement learning, in which\npolicies are represented as short programs in a symbolic language. Programmatic\npolicies can be more interpretable, generalizable, and amenable to formal\nverification than neural policies; however, designing rigorous learning\napproaches for such policies remains a challenge. Our approach to this\nchallenge -- a meta-algorithm called PROPEL -- is based on three insights.\nFirst, we view our learning task as optimization in policy space, modulo the\nconstraint that the desired policy has a programmatic representation, and solve\nthis optimization problem using a form of mirror descent that takes a gradient\nstep into the unconstrained policy space and then projects back onto the\nconstrained space. Second, we view the unconstrained policy space as mixing\nneural and programmatic representations, which enables employing\nstate-of-the-art deep policy gradient approaches. Third, we cast the projection\nstep as program synthesis via imitation learning, and exploit contemporary\ncombinatorial methods for this task. We present theoretical convergence results\nfor PROPEL and empirically evaluate the approach in three continuous control\ndomains. The experiments show that PROPEL can significantly outperform\nstate-of-the-art approaches for learning programmatic policies.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 18:00:56 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 05:14:08 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 12:32:34 GMT"}, {"version": "v4", "created": "Tue, 19 Jan 2021 20:52:42 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Verma", "Abhinav", ""], ["Le", "Hoang M.", ""], ["Yue", "Yisong", ""], ["Chaudhuri", "Swarat", ""]]}, {"id": "1907.05444", "submitter": "Alon Brutzkus", "authors": "Alon Brutzkus, Amit Daniely, Eran Malach", "title": "On the Optimality of Trees Generated by ID3", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since its inception in the 1980s, ID3 has become one of the most successful\nand widely used algorithms for learning decision trees. However, its\ntheoretical properties remain poorly understood. In this work, we introduce a\nnovel metric of a decision tree algorithm's performance, called mean iteration\nstatistical consistency (MIC), which measures optimality of trees generated by\nID3. As opposed to previous metrics, MIC can differentiate between different\ndecision tree algorithms and compare their performance. We provide theoretical\nand empirical evidence that the TopDown variant of ID3, introduced by Kearns\nand Mansour (1996), has near-optimal MIC in various settings for learning\nread-once DNFs under product distributions. In contrast, another widely used\nvariant of ID3 has MIC which is not near-optimal. We show that the MIC analysis\npredicts well the performance of these algorithms in practice. Our results\npresent a novel view of decision tree algorithms which may lead to better and\nmore practical guarantees for these algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 18:40:25 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 09:55:17 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Brutzkus", "Alon", ""], ["Daniely", "Amit", ""], ["Malach", "Eran", ""]]}, {"id": "1907.05476", "submitter": "Marco Loog", "authors": "Marco Loog, Tom Viering, Alexander Mey", "title": "Minimizers of the Empirical Risk and Risk Monotonicity", "comments": "New version fixes some minor issues especially in the proof of\n  Theorem 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plotting a learner's average performance against the number of training\nsamples results in a learning curve. Studying such curves on one or more data\nsets is a way to get to a better understanding of the generalization properties\nof this learner. The behavior of learning curves is, however, not very well\nunderstood and can display (for most researchers) quite unexpected behavior.\nOur work introduces the formal notion of \\emph{risk monotonicity}, which asks\nthe risk to not deteriorate with increasing training set sizes in expectation\nover the training samples. We then present the surprising result that various\nstandard learners, specifically those that minimize the empirical risk, can act\n\\emph{non}monotonically irrespective of the training sample size. We provide a\ntheoretical underpinning for specific instantiations from classification,\nregression, and density estimation. Altogether, the proposed monotonicity\nnotion opens up a whole new direction of research.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 20:18:19 GMT"}, {"version": "v2", "created": "Sat, 21 Sep 2019 11:33:19 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2020 16:18:37 GMT"}, {"version": "v4", "created": "Fri, 13 Mar 2020 08:36:37 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Loog", "Marco", ""], ["Viering", "Tom", ""], ["Mey", "Alexander", ""]]}, {"id": "1907.05496", "submitter": "Hai Xiao", "authors": "Hai Xiao", "title": "Online Learning to Estimate Warfarin Dose with Contextual Linear Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Warfarin is one of the most commonly used oral blood anticoagulant agent in\nthe world, the proper dose of Warfarin is difficult to establish not only\nbecause it is substantially variant among patients, but also adverse even\nsevere consequences of taking an incorrect dose. Typical practice is to\nprescribe an initial dose, then doctor closely monitor patient response and\nadjust accordingly to the correct dosage. The three commonly used strategies\nfor an initial dosage are the fixed-dose approach, the Warfarin Clinical\nalgorithm, and the Pharmacogenetic algorithm developed by the IWPC\n(International Warfarin Pharmacogenetics Consortium). It is always best to\nprescribe correct initial dosage, motivated by this challenge, this work\nexplores the performance of multi-armed bandit algorithms to best predict the\ncorrect dosage of Warfarin instead of trial-and-error procedure. Real data from\nthe Pharmacogenetics and Pharmacogenomics Knowledge Base (PharmGKB) is used,\nwith it a series of linear bandit algorithms and variants are developed and\nevaluated on Warfarin dataset. All proposed algorithms outperformed the\nfixed-dose baseline algorithm, and some even matched up the Warfarin Clinical\nDosing Algorithm. In addition, a few promising future directions are given for\nfurther exploration and development.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 21:27:24 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Xiao", "Hai", ""]]}, {"id": "1907.05505", "submitter": "Iman Tabrizian", "authors": "Saeedeh Parsaeefard, Iman Tabrizian, Alberto Leon-Garcia", "title": "Artificial Intelligence as a Services (AI-aaS) on Software-Defined\n  Infrastructure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a paradigm for offering artificial intelligence as a\nservice (AI-aaS) on software-defined infrastructures (SDIs). The increasing\ncomplexity of networking and computing infrastructures is already driving the\nintroduction of automation in networking and cloud computing management\nsystems. Here we consider how these automation mechanisms can be leveraged to\noffer AI-aaS. Use cases for AI-aaS are easily found in addressing smart\napplications in sectors such as transportation, manufacturing, energy, water,\nair quality, and emissions. We propose an architectural scheme based on SDIs\nwhere each AI-aaS application is comprised of a monitoring, analysis, policy,\nexecution plus knowledge (MAPE-K) loop (MKL). Each application is composed as\none or more specific service chains embedded in SDI, some of which will include\na Machine Learning (ML) pipeline. Our model includes a new training plane and\nan AI-aaS plane to deal with the model-development and operational phases of AI\napplications. We also consider the role of an ML/MKL sandbox in ensuring\ncoherency and consistency in the operation of multiple parallel MKL loops. We\npresent experimental measurement results for three AI-aaS applications deployed\non the SAVI testbed: 1. Compressing monitored data in SDI using autoencoders;\n2. Traffic monitoring to allocate CPUs resources to VNFs; and 3. Highway\nsegment classification in smart transportation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 22:02:18 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Parsaeefard", "Saeedeh", ""], ["Tabrizian", "Iman", ""], ["Leon-Garcia", "Alberto", ""]]}, {"id": "1907.05520", "submitter": "Shuang Li", "authors": "Shuang Li, Gongguo Tang, and Michael B. Wakin", "title": "The Landscape of Non-convex Empirical Risk with Degenerate Population\n  Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The landscape of empirical risk has been widely studied in a series of\nmachine learning problems, including low-rank matrix factorization, matrix\nsensing, matrix completion, and phase retrieval. In this work, we focus on the\nsituation where the corresponding population risk is a degenerate non-convex\nloss function, namely, the Hessian of the population risk can have zero\neigenvalues. Instead of analyzing the non-convex empirical risk directly, we\nfirst study the landscape of the corresponding population risk, which is\nusually easier to characterize, and then build a connection between the\nlandscape of the empirical risk and its population risk. In particular, we\nestablish a correspondence between the critical points of the empirical risk\nand its population risk without the strongly Morse assumption, which is\nrequired in existing literature but not satisfied in degenerate scenarios. We\nalso apply the theory to matrix sensing and phase retrieval to demonstrate how\nto infer the landscape of empirical risk from that of the corresponding\npopulation risk.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 23:16:30 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 02:02:56 GMT"}, {"version": "v3", "created": "Fri, 8 Nov 2019 19:56:34 GMT"}, {"version": "v4", "created": "Tue, 3 Dec 2019 17:48:28 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Li", "Shuang", ""], ["Tang", "Gongguo", ""], ["Wakin", "Michael B.", ""]]}, {"id": "1907.05545", "submitter": "Adji Bousso Dieng", "authors": "Adji B. Dieng, Francisco J. R. Ruiz, and David M. Blei", "title": "The Dynamic Embedded Topic Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic modeling analyzes documents to learn meaningful patterns of words. For\ndocuments collected in sequence, dynamic topic models capture how these\npatterns vary over time. We develop the dynamic embedded topic model (D-ETM), a\ngenerative model of documents that combines dynamic latent Dirichlet allocation\n(D-LDA) and word embeddings. The D-ETM models each word with a categorical\ndistribution parameterized by the inner product between the word embedding and\na per-time-step embedding representation of its assigned topic. The D-ETM\nlearns smooth topic trajectories by defining a random walk prior over the\nembedding representations of the topics. We fit the D-ETM using structured\namortized variational inference with a recurrent neural network. On three\ndifferent corpora---a collection of United Nations debates, a set of ACL\nabstracts, and a dataset of Science Magazine articles---we found that the D-ETM\noutperforms D-LDA on a document completion task. We further found that the\nD-ETM learns more diverse and coherent topics than D-LDA while requiring\nsignificantly less time to fit.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 01:55:36 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 22:44:28 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Dieng", "Adji B.", ""], ["Ruiz", "Francisco J. R.", ""], ["Blei", "David M.", ""]]}, {"id": "1907.05600", "submitter": "Yang Song", "authors": "Yang Song and Stefano Ermon", "title": "Generative Modeling by Estimating Gradients of the Data Distribution", "comments": "NeurIPS 2019 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new generative model where samples are produced via Langevin\ndynamics using gradients of the data distribution estimated with score\nmatching. Because gradients can be ill-defined and hard to estimate when the\ndata resides on low-dimensional manifolds, we perturb the data with different\nlevels of Gaussian noise, and jointly estimate the corresponding scores, i.e.,\nthe vector fields of gradients of the perturbed data distribution for all noise\nlevels. For sampling, we propose an annealed Langevin dynamics where we use\ngradients corresponding to gradually decreasing noise levels as the sampling\nprocess gets closer to the data manifold. Our framework allows flexible model\narchitectures, requires no sampling during training or the use of adversarial\nmethods, and provides a learning objective that can be used for principled\nmodel comparisons. Our models produce samples comparable to GANs on MNIST,\nCelebA and CIFAR-10 datasets, achieving a new state-of-the-art inception score\nof 8.87 on CIFAR-10. Additionally, we demonstrate that our models learn\neffective representations via image inpainting experiments.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 07:37:26 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 07:10:40 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2020 07:46:19 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Song", "Yang", ""], ["Ermon", "Stefano", ""]]}, {"id": "1907.05628", "submitter": "Vikash Singh", "authors": "Vikash Singh, Pietro Lio'", "title": "Towards Probabilistic Generative Models Harnessing Graph Neural Networks\n  for Disease-Gene Prediction", "comments": "Workshop on Computational Biology (WCB) at ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disease-gene prediction (DGP) refers to the computational challenge of\npredicting associations between genes and diseases. Effective solutions to the\nDGP problem have the potential to accelerate the therapeutic development\npipeline at early stages via efficient prioritization of candidate genes for\nvarious diseases. In this work, we introduce the variational graph auto-encoder\n(VGAE) as a promising unsupervised approach for learning powerful latent\nembeddings in disease-gene networks that can be used for the DGP problem, the\nfirst approach using a generative model involving graph neural networks (GNNs).\nIn addition to introducing the VGAE as a promising approach to the DGP problem,\nwe further propose an extension (constrained-VGAE or C-VGAE) which adapts the\nlearning algorithm for link prediction between two distinct node types in\nheterogeneous graphs. We evaluate and demonstrate the effectiveness of the VGAE\non general link prediction in a disease-gene association network and the C-VGAE\non disease-gene prediction in the same network, using popular random walk\ndriven methods as baselines. While the methodology presented demonstrates\npotential solely based on utilizing the topology of a disease-gene association\nnetwork, it can be further enhanced and explored through the integration of\nadditional biological networks such as gene/protein interaction networks and\nadditional biological features pertaining to the diseases and genes represented\nin the disease-gene association network.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 08:47:05 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Singh", "Vikash", ""], ["Lio'", "Pietro", ""]]}, {"id": "1907.05632", "submitter": "Kaige Yang Mr", "authors": "Kaige Yang and Xiaowen Dong and Laura Toni", "title": "Laplacian-regularized graph bandits: Algorithms and theoretical analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider a stochastic linear bandit problem with multiple users, where the\nrelationship between users is captured by an underlying graph and user\npreferences are represented as smooth signals on the graph. We introduce a\nnovel bandit algorithm where the smoothness prior is imposed via the\nrandom-walk graph Laplacian, which leads to a single-user cumulative regret\nscaling as $\\tilde{\\mathcal{O}}(\\Psi d \\sqrt{T})$ with time horizon $T$,\nfeature dimensionality $d$, and the scalar parameter $\\Psi \\in (0,1)$ that\ndepends on the graph connectivity. This is an improvement over\n$\\tilde{\\mathcal{O}}(d \\sqrt{T})$ in \\algo{LinUCB}~\\Ccite{li2010contextual},\nwhere user relationship is not taken into account. In terms of network regret\n(sum of cumulative regret over $n$ users), the proposed algorithm leads to a\nscaling as $\\tilde{\\mathcal{O}}(\\Psi d\\sqrt{nT})$, which is a significant\nimprovement over $\\tilde{\\mathcal{O}}(nd\\sqrt{T})$ in the state-of-the-art\nalgorithm \\algo{Gob.Lin} \\Ccite{cesa2013gang}. To improve scalability, we\nfurther propose a simplified algorithm with a linear computational complexity\nwith respect to the number of users, while maintaining the same regret.\nFinally, we present a finite-time analysis on the proposed algorithms, and\ndemonstrate their advantage in comparison with state-of-the-art graph-based\nbandit algorithms on both synthetic and real-world data.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 08:57:26 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 11:22:30 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 18:24:44 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Yang", "Kaige", ""], ["Dong", "Xiaowen", ""], ["Toni", "Laura", ""]]}, {"id": "1907.05634", "submitter": "Yuping Luo", "authors": "Yuping Luo, Huazhe Xu, Tengyu Ma", "title": "Learning Self-Correctable Policies and Value Functions from\n  Demonstrations with Negative Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imitation learning, followed by reinforcement learning algorithms, is a\npromising paradigm to solve complex control tasks sample-efficiently. However,\nlearning from demonstrations often suffers from the covariate shift problem,\nwhich results in cascading errors of the learned policy. We introduce a notion\nof conservatively-extrapolated value functions, which provably lead to policies\nwith self-correction. We design an algorithm Value Iteration with Negative\nSampling (VINS) that practically learns such value functions with conservative\nextrapolation. We show that VINS can correct mistakes of the behavioral cloning\npolicy on simulated robotics benchmark tasks. We also propose the algorithm of\nusing VINS to initialize a reinforcement learning algorithm, which is shown to\noutperform significantly prior works in sample efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 09:00:49 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 00:43:42 GMT"}, {"version": "v3", "created": "Fri, 11 Oct 2019 05:44:14 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Luo", "Yuping", ""], ["Xu", "Huazhe", ""], ["Ma", "Tengyu", ""]]}, {"id": "1907.05638", "submitter": "Prateek Jain", "authors": "Chirag Pabbaraju, Prateek Jain", "title": "Learning Functions over Sets via Permutation Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of learning functions over sets, i.e.,\nfunctions that are invariant to permutations of input set items. Recent\napproaches of pooling individual element embeddings can necessitate extremely\nlarge embedding sizes for challenging functions. We address this challenge by\nallowing standard neural networks like LSTMs to succinctly capture the function\nover the set. However, to ensure invariance with respect to permutations of set\nelements, we propose a novel architecture called SPAN that simultaneously\nlearns the function as well as adversarial or worst-case permutations for each\ninput set. The learning problem reduces to a min-max optimization problem that\nis solved via a simple alternating block coordinate descent technique. We\nconduct extensive experiments on a variety of set-learning tasks and\ndemonstrate that SPAN learns nearly permutation-invariant functions while still\nensuring accuracy on test data. On a variety of tasks sampled from the domains\nof statistics, graph functions and linear algebra, we show that our method can\nsignificantly outperform state-of-the-art methods such as DeepSets and Janossy\nPooling. Finally, we present a case study of how learning set-functions can\nhelp extract powerful features for recommendation systems, and show that such a\nmethod can be as much as 2% more accurate than carefully hand-tuned features on\na real-world recommendation system.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 09:20:29 GMT"}, {"version": "v2", "created": "Fri, 10 Jan 2020 14:59:28 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Pabbaraju", "Chirag", ""], ["Jain", "Prateek", ""]]}, {"id": "1907.05671", "submitter": "Graham Spinks", "authors": "Graham Spinks, Marie-Francine Moens", "title": "Justifying Diagnosis Decisions by Deep Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.jbi.2019.103248", "report-no": null, "categories": "cs.LG cs.CL cs.HC eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An integrated approach is proposed across visual and textual data to both\ndetermine and justify a medical diagnosis by a neural network. As deep learning\ntechniques improve, interest grows to apply them in medical applications. To\nenable a transition to workflows in a medical context that are aided by machine\nlearning, the need exists for such algorithms to help justify the obtained\noutcome so human clinicians can judge their validity. In this work, deep\nlearning methods are used to map a frontal X-Ray image to a continuous textual\nrepresentation. This textual representation is decoded into a diagnosis and the\nassociated textual justification that will help a clinician evaluate the\noutcome. Additionally, more explanatory data is provided for the diagnosis by\ngenerating a realistic X-Ray that belongs to the nearest alternative diagnosis.\nWith a clinical expert opinion study on a subset of the X-Ray data set from the\nIndiana University hospital network, we demonstrate that our justification\nmechanism significantly outperforms existing methods that use saliency maps.\nWhile performing multi-task training with multiple loss functions, our method\nachieves excellent diagnosis accuracy and captioning quality when compared to\ncurrent state-of-the-art single-task methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 10:51:48 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Spinks", "Graham", ""], ["Moens", "Marie-Francine", ""]]}, {"id": "1907.05681", "submitter": "D\\'avid Terj\\'ek", "authors": "D\\'avid Terj\\'ek", "title": "Adversarial Lipschitz Regularization", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) are one of the most popular approaches\nwhen it comes to training generative models, among which variants of\nWasserstein GANs are considered superior to the standard GAN formulation in\nterms of learning stability and sample quality. However, Wasserstein GANs\nrequire the critic to be 1-Lipschitz, which is often enforced implicitly by\npenalizing the norm of its gradient, or by globally restricting its Lipschitz\nconstant via weight normalization techniques. Training with a regularization\nterm penalizing the violation of the Lipschitz constraint explicitly, instead\nof through the norm of the gradient, was found to be practically infeasible in\nmost situations. Inspired by Virtual Adversarial Training, we propose a method\ncalled Adversarial Lipschitz Regularization, and show that using an explicit\nLipschitz penalty is indeed viable and leads to competitive performance when\napplied to Wasserstein GANs, highlighting an important connection between\nLipschitz regularization and adversarial training.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 11:41:18 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 16:02:17 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 09:11:31 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Terj\u00e9k", "D\u00e1vid", ""]]}, {"id": "1907.05701", "submitter": "Wei Zhang", "authors": "Wei Zhang, Xiaodong Cui, Ulrich Finkler, George Saon, Abdullah Kayi,\n  Alper Buyuktosunoglu, Brian Kingsbury, David Kung, Michael Picheny", "title": "A Highly Efficient Distributed Deep Learning System For Automatic Speech\n  Recognition", "comments": null, "journal-ref": "INTERSPEECH 2019", "doi": null, "report-no": null, "categories": "eess.AS cs.DC cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Automatic Speech Recognition (ASR) systems rely on distributed deep\nlearning to for quick training completion. To enable efficient distributed\ntraining, it is imperative that the training algorithms can converge with a\nlarge mini-batch size. In this work, we discovered that Asynchronous\nDecentralized Parallel Stochastic Gradient Descent (ADPSGD) can work with much\nlarger batch size than commonly used Synchronous SGD (SSGD) algorithm. On\ncommonly used public SWB-300 and SWB-2000 ASR datasets, ADPSGD can converge\nwith a batch size 3X as large as the one used in SSGD, thus enable training at\na much larger scale. Further, we proposed a Hierarchical-ADPSGD (H-ADPSGD)\nsystem in which learners on the same computing node construct a super learner\nvia a fast allreduce implementation, and super learners deploy ADPSGD algorithm\namong themselves. On a 64 Nvidia V100 GPU cluster connected via a 100Gb/s\nEthernet network, our system is able to train SWB-2000 to reach a 7.6% WER on\nthe Hub5-2000 Switchboard (SWB) test-set and a 13.2% WER on the Call-home (CH)\ntest-set in 5.2 hours. To the best of our knowledge, this is the fastest ASR\ntraining system that attains this level of model accuracy for SWB-2000 task to\nbe ever reported in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 14:32:59 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Zhang", "Wei", ""], ["Cui", "Xiaodong", ""], ["Finkler", "Ulrich", ""], ["Saon", "George", ""], ["Kayi", "Abdullah", ""], ["Buyuktosunoglu", "Alper", ""], ["Kingsbury", "Brian", ""], ["Kung", "David", ""], ["Picheny", "Michael", ""]]}, {"id": "1907.05715", "submitter": "Arthur Jacot", "authors": "Arthur Jacot, Franck Gabriel, Fran\\c{c}ois Ged, Cl\\'ement Hongler", "title": "Order and Chaos: NTK views on DNN Normalization, Checkerboard and\n  Boundary Artifacts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze architectural features of Deep Neural Networks (DNNs) using the\nso-called Neural Tangent Kernel (NTK), which describes the training and\ngeneralization of DNNs in the infinite-width setting. In this setting, we show\nthat for fully-connected DNNs, as the depth grows, two regimes appear: \"order\",\nwhere the (scaled) NTK converges to a constant, and \"chaos\", where it converges\nto a Kronecker delta. Extreme order slows down training while extreme chaos\nhinders generalization. Using the scaled ReLU as a nonlinearity, we end up in\nthe ordered regime. In contrast, Layer Normalization brings the network into\nthe chaotic regime. We observe a similar effect for Batch Normalization (BN)\napplied after the last nonlinearity. We uncover the same order and chaos modes\nin Deep Deconvolutional Networks (DC-NNs). Our analysis explains the appearance\nof so-called checkerboard patterns and border artifacts. Moving the network\ninto the chaotic regime prevents checkerboard patterns; we propose a\ngraph-based parametrization which eliminates border artifacts; finally, we\nintroduce a new layer-dependent learning rate to improve the convergence of\nDC-NNs. We illustrate our findings on DCGANs: the ordered regime leads to a\ncollapse of the generator to a checkerboard mode, which can be avoided by\ntuning the nonlinearity to reach the chaotic regime. As a result, we are able\nto obtain good quality samples for DCGANs without BN.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 10:55:39 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 16:39:39 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Jacot", "Arthur", ""], ["Gabriel", "Franck", ""], ["Ged", "Fran\u00e7ois", ""], ["Hongler", "Cl\u00e9ment", ""]]}, {"id": "1907.05718", "submitter": "Ziv Katzir", "authors": "Ziv Katzir, Yuval Elovici", "title": "Why Blocking Targeted Adversarial Perturbations Impairs the Ability to\n  Learn", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their accuracy, neural network-based classifiers are still prone to\nmanipulation through adversarial perturbations. Those perturbations are\ndesigned to be misclassified by the neural network, while being perceptually\nidentical to some valid input. The vast majority of attack methods rely on\nwhite-box conditions, where the attacker has full knowledge of the attacked\nnetwork's parameters. This allows the attacker to calculate the network's loss\ngradient with respect to some valid input and use this gradient in order to\ncreate an adversarial example. The task of blocking white-box attacks has\nproven difficult to solve. While a large number of defense methods have been\nsuggested, they have had limited success. In this work we examine this\ndifficulty and try to understand it. We systematically explore the abilities\nand limitations of defensive distillation, one of the most promising defense\nmechanisms against adversarial perturbations suggested so far in order to\nunderstand the defense challenge. We show that contrary to commonly held\nbelief, the ability to bypass defensive distillation is not dependent on an\nattack's level of sophistication. In fact, simple approaches, such as the\nTargeted Gradient Sign Method, are capable of effectively bypassing defensive\ndistillation. We prove that defensive distillation is highly effective against\nnon-targeted attacks but is unsuitable for targeted attacks. This discovery\nleads us to realize that targeted attacks leverage the same input gradient that\nallows a network to be trained. This implies that blocking them will require\nlosing the network's ability to learn, presenting an impossible tradeoff to the\nresearch community.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 06:28:25 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Katzir", "Ziv", ""], ["Elovici", "Yuval", ""]]}, {"id": "1907.05743", "submitter": "Kaisheng Gao", "authors": "Kaisheng Gao, Jing Zhang, Cangqi Zhou", "title": "Semi-Supervised Graph Embedding for Multi-Label Graph Node\n  Classification", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph convolution network (GCN) is a widely-used facility to realize\ngraph-based semi-supervised learning, which usually integrates node features\nand graph topologic information to build learning models. However, as for\nmulti-label learning tasks, the supervision part of GCN simply minimizes the\ncross-entropy loss between the last layer outputs and the ground-truth label\ndistribution, which tends to lose some useful information such as label\ncorrelations, so that prevents from obtaining high performance. In this paper,\nwe pro-pose a novel GCN-based semi-supervised learning approach for multi-label\nclassification, namely ML-GCN. ML-GCN first uses a GCN to embed the node\nfeatures and graph topologic information. Then, it randomly generates a label\nmatrix, where each row (i.e., label vector) represents a kind of labels. The\ndimension of the label vector is the same as that of the node vector before the\nlast convolution operation of GCN. That is, all labels and nodes are embedded\nin a uniform vector space. Finally, during the ML-GCN model training, label\nvectors and node vectors are concatenated to serve as the inputs of the relaxed\nskip-gram model to detect the node-label correlation as well as the label-label\ncorrelation. Experimental results on several graph classification datasets show\nthat the proposed ML-GCN outperforms four state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 13:43:04 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Gao", "Kaisheng", ""], ["Zhang", "Jing", ""], ["Zhou", "Cangqi", ""]]}, {"id": "1907.05772", "submitter": "Tor Lattimore", "authors": "Tor Lattimore and Csaba Szepesvari", "title": "Exploration by Optimisation in Partial Monitoring", "comments": "high probability bounds, experiments and simplified\n  algorithms/analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a simple and efficient algorithm for adversarial $k$-action\n$d$-outcome non-degenerate locally observable partial monitoring game for which\nthe $n$-round minimax regret is bounded by $6(d+1) k^{3/2} \\sqrt{n \\log(k)}$,\nmatching the best known information-theoretic upper bound. The same algorithm\nalso achieves near-optimal regret for full information, bandit and globally\nobservable games.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 14:46:50 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 10:40:25 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2019 10:54:52 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Lattimore", "Tor", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1907.05790", "submitter": "Christophe Servan", "authors": "Estelle Maudet, Oralie Cattan, Maureen de Seyssel, Christophe Servan", "title": "Qwant Research @DEFT 2019: Document matching and information retrieval\n  using clinical cases", "comments": "Article accepted at the workshop DEfi fouille de Texte (DEFT 2019).\n  Article in French", "journal-ref": "DEFT 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on Qwant Research contribution to tasks 2 and 3 of the\nDEFT 2019's challenge, focusing on French clinical cases analysis. Task 2 is a\ntask on semantic similarity between clinical cases and discussions. For this\ntask, we propose an approach based on language models and evaluate the impact\non the results of different preprocessings and matching techniques. For task 3,\nwe have developed an information extraction system yielding very encouraging\nresults accuracy-wise. We have experimented two different approaches, one based\non the exclusive use of neural networks, the other based on a linguistic\nanalysis.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 08:29:21 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Maudet", "Estelle", ""], ["Cattan", "Oralie", ""], ["de Seyssel", "Maureen", ""], ["Servan", "Christophe", ""]]}, {"id": "1907.05830", "submitter": "Mathurin Massias", "authors": "Mathurin Massias and Samuel Vaiter and Alexandre Gramfort and Joseph\n  Salmon", "title": "Dual Extrapolation for Sparse Generalized Linear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized Linear Models (GLM) form a wide class of regression and\nclassification models, where prediction is a function of a linear combination\nof the input variables. For statistical inference in high dimension, sparsity\ninducing regularizations have proven to be useful while offering statistical\nguarantees. However, solving the resulting optimization problems can be\nchallenging: even for popular iterative algorithms such as coordinate descent,\none needs to loop over a large number of variables. To mitigate this,\ntechniques known as screening rules and working sets diminish the size of the\noptimization problem at hand, either by progressively removing variables, or by\nsolving a growing sequence of smaller problems. For both techniques,\nsignificant variables are identified thanks to convex duality arguments. In\nthis paper, we show that the dual iterates of a GLM exhibit a Vector\nAutoRegressive (VAR) behavior after sign identification, when the primal\nproblem is solved with proximal gradient descent or cyclic coordinate descent.\nExploiting this regularity, one can construct dual points that offer tighter\ncertificates of optimality, enhancing the performance of screening rules and\nhelping to design competitive working set algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 16:35:39 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 11:01:52 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Massias", "Mathurin", ""], ["Vaiter", "Samuel", ""], ["Gramfort", "Alexandre", ""], ["Salmon", "Joseph", ""]]}, {"id": "1907.05855", "submitter": "Timoth\\'ee Lesort", "authors": "Ren\\'e Traor\\'e, Hugo Caselles-Dupr\\'e, Timoth\\'ee Lesort, Te Sun,\n  Guanghang Cai, Natalia D\\'iaz-Rodr\\'iguez, David Filliat", "title": "DisCoRL: Continual Reinforcement Learning via Policy Distillation", "comments": "arXiv admin note: text overlap with arXiv:1906.04452", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-task reinforcement learning there are two main challenges: at\ntraining time, the ability to learn different policies with a single model; at\ntest time, inferring which of those policies applying without an external\nsignal. In the case of continual reinforcement learning a third challenge\narises: learning tasks sequentially without forgetting the previous ones. In\nthis paper, we tackle these challenges by proposing DisCoRL, an approach\ncombining state representation learning and policy distillation. We experiment\non a sequence of three simulated 2D navigation tasks with a 3 wheel\nomni-directional robot. Moreover, we tested our approach's robustness by\ntransferring the final policy into a real life setting. The policy can solve\nall tasks and automatically infer which one to run.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 09:12:42 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Traor\u00e9", "Ren\u00e9", ""], ["Caselles-Dupr\u00e9", "Hugo", ""], ["Lesort", "Timoth\u00e9e", ""], ["Sun", "Te", ""], ["Cai", "Guanghang", ""], ["D\u00edaz-Rodr\u00edguez", "Natalia", ""], ["Filliat", "David", ""]]}, {"id": "1907.05911", "submitter": "Namuk Park", "authors": "Namuk Park, Taekyu Lee, Songkuk Kim", "title": "Vector Quantized Bayesian Neural Network Inference for Data Streams", "comments": "AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian neural networks (BNN) can estimate the uncertainty in predictions,\nas opposed to non-Bayesian neural networks (NNs). However, BNNs have been far\nless widely used than non-Bayesian NNs in practice since they need iterative NN\nexecutions to predict a result for one data, and it gives rise to prohibitive\ncomputational cost. This computational burden is a critical problem when\nprocessing data streams with low-latency. To address this problem, we propose a\nnovel model VQ-BNN, which approximates BNN inference for data streams. In order\nto reduce the computational burden, VQ-BNN inference predicts NN only once and\ncompensates the result with previously memorized predictions. To be specific,\nVQ-BNN inference for data streams is given by temporal exponential smoothing of\nrecent predictions. The computational cost of this model is almost the same as\nthat of non-Bayesian NNs. Experiments including semantic segmentation on\nreal-world data show that this model performs significantly faster than BNNs\nwhile estimating predictive results comparable to or superior to the results of\nBNNs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 18:15:56 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 16:12:37 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2021 07:15:21 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Park", "Namuk", ""], ["Lee", "Taekyu", ""], ["Kim", "Songkuk", ""]]}, {"id": "1907.05943", "submitter": "Sanjay Chakraborty", "authors": "Agnip Dasgupta, Ardhendu Banerjee, Aniket Ghosh Dastidar, Antara\n  Barman, Sanjay Chakraborty", "title": "A Study and Analysis of a Feature Subset Selection Technique using\n  Penguin Search Optimization Algorithm (FS-PeSOA)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In today world of enormous amounts of data, it is very important to extract\nuseful knowledge from it. This can be accomplished by feature subset selection.\nFeature subset selection is a method of selecting a minimum number of features\nwith the help of which our machine can learn and predict which class a\nparticular data belongs to. We will introduce a new adaptive algorithm called\nFeature selection Penguin Search optimization algorithm which is a\nmetaheuristic approach. It is adapted from the natural hunting strategy of\npenguins in which a group of penguins take jumps at random depths and come back\nand share the status of food availability with other penguins and in this way,\nthe global optimum solution is found. In order to explore the feature subset\ncandidates, the bioinspired approach Penguin Search optimization algorithm\ngenerates during the process a trial feature subset and estimates its fitness\nvalue by using three different classifiers for each case: Random Forest,\nNearest Neighbour and Support Vector Machines. However, we are planning to\nimplement our proposed approach Feature selection Penguin Search optimization\nalgorithm on some well known benchmark datasets collected from the UCI\nrepository and also try to evaluate and compare its classification accuracy\nwith some state of art algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 05:27:57 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Dasgupta", "Agnip", ""], ["Banerjee", "Ardhendu", ""], ["Dastidar", "Aniket Ghosh", ""], ["Barman", "Antara", ""], ["Chakraborty", "Sanjay", ""]]}, {"id": "1907.06010", "submitter": "George Monta\\~nez", "authors": "George D. Montanez, Jonathan Hayase, Julius Lauw, Dominique Macias,\n  Akshay Trikha, Julia Vendemiatti", "title": "The Futility of Bias-Free Learning and Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building on the view of machine learning as search, we demonstrate the\nnecessity of bias in learning, quantifying the role of bias (measured relative\nto a collection of possible datasets, or more generally, information resources)\nin increasing the probability of success. For a given degree of bias towards a\nfixed target, we show that the proportion of favorable information resources is\nstrictly bounded from above. Furthermore, we demonstrate that bias is a\nconserved quantity, such that no algorithm can be favorably biased towards many\ndistinct targets simultaneously. Thus bias encodes trade-offs. The probability\nof success for a task can also be measured geometrically, as the angle of\nagreement between what holds for the actual task and what is assumed by the\nalgorithm, represented in its bias. Lastly, finding a favorably biasing\ndistribution over a fixed set of information resources is provably difficult,\nunless the set of resources itself is already favorable with respect to the\ngiven task and algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 05:16:39 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Montanez", "George D.", ""], ["Hayase", "Jonathan", ""], ["Lauw", "Julius", ""], ["Macias", "Dominique", ""], ["Trikha", "Akshay", ""], ["Vendemiatti", "Julia", ""]]}, {"id": "1907.06011", "submitter": "Peter Y. Lu", "authors": "Peter Y. Lu, Samuel Kim, Marin Solja\\v{c}i\\'c", "title": "Extracting Interpretable Physical Parameters from Spatiotemporal Systems\n  using Unsupervised Learning", "comments": "19 pages, 9 figures, 2 tables", "journal-ref": "Phys. Rev. X 10, 031056 (2020)", "doi": "10.1103/PhysRevX.10.031056", "report-no": null, "categories": "physics.comp-ph cs.LG physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental data is often affected by uncontrolled variables that make\nanalysis and interpretation difficult. For spatiotemporal systems, this problem\nis further exacerbated by their intricate dynamics. Modern machine learning\nmethods are particularly well-suited for analyzing and modeling complex\ndatasets, but to be effective in science, the result needs to be interpretable.\nWe demonstrate an unsupervised learning technique for extracting interpretable\nphysical parameters from noisy spatiotemporal data and for building a\ntransferable model of the system. In particular, we implement a\nphysics-informed architecture based on variational autoencoders that is\ndesigned for analyzing systems governed by partial differential equations\n(PDEs). The architecture is trained end-to-end and extracts latent parameters\nthat parameterize the dynamics of a learned predictive model for the system. To\ntest our method, we train our model on simulated data from a variety of PDEs\nwith varying dynamical parameters that act as uncontrolled variables. Numerical\nexperiments show that our method can accurately identify relevant parameters\nand extract them from raw and even noisy spatiotemporal data (tested with\nroughly 10% added noise). These extracted parameters correlate well (linearly\nwith $R^2 > 0.95$) with the ground truth physical parameters used to generate\nthe datasets. We then apply this method to nonlinear fiber propagation data,\ngenerated by an ab-initio simulation, to demonstrate its capabilities on a more\nrealistic dataset. Our method for discovering interpretable latent parameters\nin spatiotemporal systems will allow us to better analyze and understand\nreal-world phenomena and datasets, which often have unknown and uncontrolled\nvariables that alter the system dynamics and cause varying behaviors that are\ndifficult to disentangle.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 05:21:05 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 04:42:36 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 19:04:01 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Lu", "Peter Y.", ""], ["Kim", "Samuel", ""], ["Solja\u010di\u0107", "Marin", ""]]}, {"id": "1907.06022", "submitter": "Yantao Wei", "authors": "Yantao Wei, Shujian Yu, Luis Sanchez Giraldo, Jose C. Principe", "title": "Multiscale Principle of Relevant Information for Hyperspectral Image\n  Classification", "comments": "Mansucript to be published in Machine Learning Journal (Springer).\n  Code available at\n  https://github.com/SJYuCNEL/Principle-of-Relevant-Information-and-HSI-Classification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel architecture, termed multiscale principle of\nrelevant information (MPRI), to learn discriminative spectral-spatial features\nfor hyperspectral image (HSI) classification. MPRI inherits the merits of the\nprinciple of relevant information (PRI) to effectively extract multiscale\ninformation embedded in the given data, and also takes advantage of the\nmultilayer structure to learn representations in a coarse-to-fine manner.\nSpecifically, MPRI performs spectral-spatial pixel characterization (using PRI)\nand feature dimensionality reduction (using regularized linear discriminant\nanalysis) iteratively and successively. Extensive experiments on three\nbenchmark data sets demonstrate that MPRI outperforms existing state-of-the-art\nmethods (including deep learning based ones) qualitatively and quantitatively,\nespecially in the scenario of limited training samples. Code of MPRI is\navailable at \\url{http://bit.ly/MPRI_HSI}.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 07:29:42 GMT"}, {"version": "v2", "created": "Fri, 15 May 2020 17:12:17 GMT"}, {"version": "v3", "created": "Sat, 5 Jun 2021 01:39:18 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Wei", "Yantao", ""], ["Yu", "Shujian", ""], ["Giraldo", "Luis Sanchez", ""], ["Principe", "Jose C.", ""]]}, {"id": "1907.06032", "submitter": "Yuqing Xia", "authors": "Zhenyue Zhang and Yuqing Xia", "title": "Minimal Sample Subspace Learning: Theory and Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace segmentation or subspace learning is a challenging and complicated\ntask in machine learning. This paper builds a primary frame and solid\ntheoretical bases for the minimal subspace segmentation (MSS) of finite\nsamples. Existence and conditional uniqueness of MSS are discussed with\nconditions generally satisfied in applications. Utilizing weak prior\ninformation of MSS, the minimality inspection of segments is further simplified\nto the prior detection of partitions. The MSS problem is then modeled as a\ncomputable optimization problem via self-expressiveness of samples. A closed\nform of representation matrices is first given for the self-expressiveness, and\nthe connection of diagonal blocks is then addressed. The MSS model uses a rank\nrestriction on the sum of segment ranks. Theoretically, it can retrieve the\nminimal sample subspaces that could be heavily intersected. The optimization\nproblem is solved via a basic manifold conjugate gradient algorithm,\nalternative optimization and hybrid optimization, taking into account of\nsolving both the primal MSS problem and its pseudo-dual problem. The MSS model\nis further modified for handling noisy data, and solved by an ADMM algorithm.\nThe reported experiments show the strong ability of the MSS method on\nretrieving minimal sample subspaces that are heavily intersected.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 09:15:02 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 04:13:06 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Zhang", "Zhenyue", ""], ["Xia", "Yuqing", ""]]}, {"id": "1907.06048", "submitter": "Abhijit Mahalunkar", "authors": "Abhijit Mahalunkar and John D. Kelleher", "title": "Multi-Element Long Distance Dependencies: Using SPk Languages to Explore\n  the Characteristics of Long-Distance Dependencies", "comments": "To appear in ACL 2019 workshop on Deep Learning and Formal Languages:\n  Building Bridges. arXiv admin note: substantial text overlap with\n  arXiv:1810.02966", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.FL stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In order to successfully model Long Distance Dependencies (LDDs) it is\nnecessary to understand the full-range of the characteristics of the LDDs\nexhibited in a target dataset. In this paper, we use Strictly k-Piecewise\nlanguages to generate datasets with various properties. We then compute the\ncharacteristics of the LDDs in these datasets using mutual information and\nanalyze the impact of factors such as (i) k, (ii) length of LDDs, (iii)\nvocabulary size, (iv) forbidden subsequences, and (v) dataset size. This\nanalysis reveal that the number of interacting elements in a dependency is an\nimportant characteristic of LDDs. This leads us to the challenge of modelling\nmulti-element long-distance dependencies. Our results suggest that attention\nmechanisms in neural networks may aide in modeling datasets with multi-element\nlong-distance dependencies. However, we conclude that there is a need to\ndevelop more efficient attention mechanisms to address this issue.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 11:27:13 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Mahalunkar", "Abhijit", ""], ["Kelleher", "John D.", ""]]}, {"id": "1907.06051", "submitter": "Giannis Nikolentzos", "authors": "Giannis Nikolentzos, George Dasoulas, Michalis Vazirgiannis", "title": "k-hop Graph Neural Networks", "comments": "Accepted at Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have emerged recently as a powerful architecture\nfor learning node and graph representations. Standard GNNs have the same\nexpressive power as the Weisfeiler-Leman test of graph isomorphism in terms of\ndistinguishing non-isomorphic graphs. However, it was recently shown that this\ntest cannot identify fundamental graph properties such as connectivity and\ntriangle freeness. We show that GNNs also suffer from the same limitation. To\naddress this limitation, we propose a more expressive architecture, k-hop GNNs,\nwhich updates a node's representation by aggregating information not only from\nits direct neighbors, but from its k-hop neighborhood. We show that the\nproposed architecture can identify fundamental graph properties. We evaluate\nthe proposed architecture on standard node classification and graph\nclassification datasets. Our experimental evaluation confirms our theoretical\nfindings since the proposed model achieves performance better or comparable to\nstandard GNNs and to state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 11:31:57 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2020 21:50:43 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Nikolentzos", "Giannis", ""], ["Dasoulas", "George", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1907.06058", "submitter": "Maria Bampa", "authors": "Maria Bampa and Panagiotis Papapetrou", "title": "Aggregate-Eliminate-Predict: Detecting Adverse Drug Events from\n  Heterogeneous Electronic Health Records", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of detecting adverse drug events in electronic\nhealthcare records. The challenge in this work is to aggregate heterogeneous\ndata types involving diagnosis codes, drug codes, as well as lab measurements.\nAn earlier framework proposed for the same problem demonstrated promising\npredictive performance for the random forest classifier by using only lab\nmeasurements as data features. We extend this framework, by additionally\nincluding diagnosis and drug prescription codes, concurrently. In addition, we\nemploy a recursive feature selection mechanism on top, that extracts the top-k\nmost important features. Our experimental evaluation on five medical datasets\nof adverse drug events and six different classifiers, suggests that the\nintegration of these additional features provides substantial and statistically\nsignificant improvements in terms of AUC, while employing medically relevant\nfeatures.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 11:46:19 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Bampa", "Maria", ""], ["Papapetrou", "Panagiotis", ""]]}, {"id": "1907.06064", "submitter": "Islem Rekik", "authors": "Can Gafuroglu and Islem Rekik", "title": "Image Evolution Trajectory Prediction and Classification from Baseline\n  using Learning-based Patch Atlas Selection for Early Diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients initially diagnosed with early mild cognitive impairment (eMCI) are\nknown to be a clinically heterogeneous group with very subtle patterns of brain\natrophy. To examine the boarders between normal controls (NC) and eMCI,\nMagnetic Resonance Imaging (MRI) was extensively used as a non-invasive imaging\nmodality to pin-down subtle changes in brain images of MCI patients. However,\neMCI research remains limited by the number of available MRI acquisition\ntimepoints. Ideally, one would learn how to diagnose MCI patients in an early\nstage from MRI data acquired at a single timepoint, while leveraging\n'non-existing' follow-up observations. To this aim, we propose novel supervised\nand unsupervised frameworks that learn how to jointly predict and label the\nevolution trajectory of intensity patches, each seeded at a specific brain\nlandmark, from a baseline intensity patch. Specifically, both strategies aim to\nidentify the best training atlas patches at baseline timepoint to predict and\nclassify the evolution trajectory of a given testing baseline patch. The\nsupervised technique learns how to select the best atlas patches by training\nbidirectional mappings from the space of pairwise patch similarities to their\ncorresponding prediction errors -when one patch was used to predict the other.\nOn the other hand, the unsupervised technique learns a manifold of baseline\natlas and testing patches using multiple kernels to well capture patch\ndistributions at multiple scales. Once the best baseline atlas patches are\nselected, we retrieve their evolution trajectories and average them to predict\nthe evolution trajectory of the testing baseline patch. Next, we input the\npredicted trajectories to an ensemble of linear classifiers, each trained at a\nspecific landmark. Our classification accuracy increased by up to 10% points in\ncomparison to single timepoint-based classification methods.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 12:17:00 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Gafuroglu", "Can", ""], ["Rekik", "Islem", ""]]}, {"id": "1907.06065", "submitter": "Yehui Tang", "authors": "Yehui Tang, Shan You, Chang Xu, Boxin Shi and Chao Xu", "title": "Bringing Giant Neural Networks Down to Earth with Unlabeled Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressing giant neural networks has gained much attention for their\nextensive applications on edge devices such as cellphones. During the\ncompressing process, one of the most important procedures is to retrain the\npre-trained models using the original training dataset. However, due to the\nconsideration of security, privacy or commercial profits, in practice, only a\nfraction of sample training data are made available, which makes the retraining\ninfeasible. To solve this issue, this paper proposes to resort to unlabeled\ndata in hand that can be cheaper to acquire. Specifically, we exploit the\nunlabeled data to mimic the classification characteristics of giant networks,\nso that the original capacity can be preserved nicely. Nevertheless, there\nexists a dataset bias between the labeled and unlabeled data, which may disturb\nthe training and degrade the performance. We thus fix this bias by an\nadversarial loss to make an alignment on the distributions of their low-level\nfeature representations. We further provide theoretical discussions about how\nthe unlabeled data help compressed networks to generalize better. Experimental\nresults demonstrate that the unlabeled data can significantly improve the\nperformance of the compressed networks.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 12:24:37 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 14:25:16 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Tang", "Yehui", ""], ["You", "Shan", ""], ["Xu", "Chang", ""], ["Shi", "Boxin", ""], ["Xu", "Chao", ""]]}, {"id": "1907.06066", "submitter": "Simo S\\\"arkk\\\"a", "authors": "Simo S\\\"arkk\\\"a", "title": "The Use of Gaussian Processes in System Identification", "comments": "To appear in Encyclopedia of systems and control, 2nd edition", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes are used in machine learning to learn input-output\nmappings from observed data. Gaussian process regression is based on imposing a\nGaussian process prior on the unknown regressor function and statistically\nconditioning it on the observed data. In system identification, Gaussian\nprocesses are used to form time series prediction models such as non-linear\nfinite-impulse response (NFIR) models as well as non-linear autoregressive\n(NARX) models. Gaussian process state-space models (GPSS) can be used to learn\nthe dynamic and measurement models for a state-space representation of the\ninput-output data. Temporal and spatio-temporal Gaussian processes can be\ndirectly used to form regressor on the data in the time domain. The aim of this\narticle is to briefly outline the main directions in system identification\nmethods using Gaussian processes.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 12:28:11 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["S\u00e4rkk\u00e4", "Simo", ""]]}, {"id": "1907.06090", "submitter": "Jesse Clifton", "authors": "Jesse Clifton, Lili Wu, Eric Laber", "title": "Parameterized Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Parameterized Exploration (PE), a simple family of methods for\nmodel-based tuning of the exploration schedule in sequential decision problems.\nUnlike common heuristics for exploration, our method accounts for the time\nhorizon of the decision problem as well as the agent's current state of\nknowledge of the dynamics of the decision problem. We show our method as\napplied to several common exploration techniques has superior performance\nrelative to un-tuned counterparts in Bernoulli and Gaussian multi-armed\nbandits, contextual bandits, and a Markov decision process based on a mobile\nhealth (mHealth) study. We also examine the effects of the accuracy of the\nestimated dynamics model on the performance of PE.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 14:55:11 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Clifton", "Jesse", ""], ["Wu", "Lili", ""], ["Laber", "Eric", ""]]}, {"id": "1907.06123", "submitter": "Viktor Bengs", "authors": "Viktor Bengs and Eyke H\\\"ullermeier", "title": "Preselection Bandits under the Plackett-Luce Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce the Preselection Bandit problem, in which the\nlearner preselects a subset of arms (choice alternatives) for a user, which\nthen chooses the final arm from this subset. The learner is not aware of the\nuser's preferences, but can learn them from observed choices. In our concrete\nsetting, we allow these choices to be stochastic and model the user's actions\nby means of the Plackett-Luce model. The learner's main task is to preselect\nsubsets that eventually lead to highly preferred choices. To formalize this\ngoal, we introduce a reasonable notion of regret and derive lower bounds on the\nexpected regret. Moreover, we propose algorithms for which the upper bound on\nexpected regret matches the lower bound up to a logarithmic term of the time\nhorizon.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 20:27:15 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Bengs", "Viktor", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1907.06138", "submitter": "Ji Liu", "authors": "Wesley Suttle, Zhuoran Yang, Kaiqing Zhang, Ji Liu", "title": "A Convergence Result for Regularized Actor-Critic Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a probability one convergence proof, under suitable\nconditions, of a certain class of actor-critic algorithms for finding\napproximate solutions to entropy-regularized MDPs using the machinery of\nstochastic approximation. To obtain this overall result, we prove the\nconvergence of policy evaluation with general regularizers when using linear\napproximation architectures and show convergence of entropy-regularized policy\nimprovement.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 21:58:06 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 17:16:14 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Suttle", "Wesley", ""], ["Yang", "Zhuoran", ""], ["Zhang", "Kaiqing", ""], ["Liu", "Ji", ""]]}, {"id": "1907.06162", "submitter": "Riyi Qiu", "authors": "Riyi Qiu, Yugang Jia, Mirsad Hadzikadic, Michael Dulin, Xi Niu, and\n  Xin Wang", "title": "Modeling the Uncertainty in Electronic Health Records: a Bayesian Deep\n  Learning Approach", "comments": "4 pages, 3 figures, 2 tables. 2019 KDD Workshop on Applied Data\n  Science for Healthcare. Anchorage, AK, USA, August 5, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have exhibited superior performance in predictive tasks\nwith the explosively increasing Electronic Health Records (EHR). However, due\nto the lack of transparency, behaviors of deep learning models are difficult to\ninterpret. Without trustworthiness, deep learning models will not be able to\nassist in the real-world decision-making process of healthcare issues. We\npropose a deep learning model based on Bayesian Neural Networks (BNN) to\npredict uncertainty induced by data noise. The uncertainty is introduced to\nprovide model predictions with an extra level of confidence. Our experiments\nverify that instances with high uncertainty are harmful to model performance.\nMoreover, by investigating the distributions of model prediction and\nuncertainty, we show that it is possible to identify a group of patients for\ntimely intervention, such that decreasing data noise will benefit more on the\nprediction accuracy for these patients.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 03:50:38 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Qiu", "Riyi", ""], ["Jia", "Yugang", ""], ["Hadzikadic", "Mirsad", ""], ["Dulin", "Michael", ""], ["Niu", "Xi", ""], ["Wang", "Xin", ""]]}, {"id": "1907.06166", "submitter": "Yuantao Gu", "authors": "Yuchen Jiao, Gen Li, and Yuantao Gu", "title": "Compressed Subspace Learning Based on Canonical Angle Preserving\n  Property", "comments": "38 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Union of Subspaces (UoS) is a popular model to describe the underlying\nlow-dimensional structure of data. The fine details of UoS structure can be\ndescribed in terms of canonical angles (also known as principal angles) between\nsubspaces, which is a well-known characterization for relative subspace\npositions. In this paper, we prove that random projection with the so-called\nJohnson-Lindenstrauss (JL) property approximately preserves canonical angles\nbetween subspaces with overwhelming probability. This result indicates that\nrandom projection approximately preserves the UoS structure. Inspired by this\nresult, we propose a framework of Compressed Subspace Learning (CSL), which\nenables to extract useful information from the UoS structure of data in a\ngreatly reduced dimension. We demonstrate the effectiveness of CSL in various\nsubspace-related tasks such as subspace visualization, active subspace\ndetection, and subspace clustering.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 05:01:05 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 09:31:31 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Jiao", "Yuchen", ""], ["Li", "Gen", ""], ["Gu", "Yuantao", ""]]}, {"id": "1907.06173", "submitter": "Eric Balkanski", "authors": "Adam Breuer, Eric Balkanski, Yaron Singer", "title": "The FAST Algorithm for Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a new algorithm called Fast Adaptive Sequencing\nTechnique (FAST) for maximizing a monotone submodular function under a\ncardinality constraint $k$ whose approximation ratio is arbitrarily close to\n$1-1/e$, is $O(\\log(n) \\log^2(\\log k))$ adaptive, and uses a total of $O(n\n\\log\\log(k))$ queries. Recent algorithms have comparable guarantees in terms of\nasymptotic worst case analysis, but their actual number of rounds and query\ncomplexity depend on very large constants and polynomials in terms of precision\nand confidence, making them impractical for large data sets. Our main\ncontribution is a design that is extremely efficient both in terms of its\nnon-asymptotic worst case query complexity and number of rounds, and in terms\nof its practical runtime. We show that this algorithm outperforms any algorithm\nfor submodular maximization we are aware of, including hyper-optimized parallel\nversions of state-of-the-art serial algorithms, by running experiments on large\ndata sets. These experiments show FAST is orders of magnitude faster than the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 06:37:24 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Breuer", "Adam", ""], ["Balkanski", "Eric", ""], ["Singer", "Yaron", ""]]}, {"id": "1907.06198", "submitter": "Alessandro Betti", "authors": "Alessandro Betti, Marco Gori", "title": "On the Role of Time in Learning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By and large the process of learning concepts that are embedded in time is\nregarded as quite a mature research topic. Hidden Markov models, recurrent\nneural networks are, amongst others, successful approaches to learning from\ntemporal data. In this paper, we claim that the dominant approach minimizing\nappropriate risk functions defined over time by classic stochastic gradient\nmight miss the deep interpretation of time given in other fields like physics.\nWe show that a recent reformulation of learning according to the principle of\nLeast Cognitive Action is better suited whenever time is involved in learning.\nThe principle gives rise to a learning process that is driven by differential\nequations, that can somehow descrive the process within the same framework as\nother laws of nature.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 10:10:28 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Betti", "Alessandro", ""], ["Gori", "Marco", ""]]}, {"id": "1907.06205", "submitter": "Venkatesh Theru Mohan", "authors": "Venkatesh Theru Mohan and Ali Jannesari", "title": "Automatic Repair and Type Binding of Undeclared Variables using Neural\n  Networks", "comments": "16 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.FL cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning had been used in program analysis for the prediction of hidden\nsoftware defects using software defect datasets, security vulnerabilities using\ngenerative adversarial networks as well as identifying syntax errors by\nlearning a trained neural machine translation on program codes. However, all\nthese approaches either require defect datasets or bug-free source codes that\nare executable for training the deep learning model. Our neural network model\nis neither trained with any defect datasets nor bug-free programming source\ncodes, instead it is trained using structural semantic details of Abstract\nSyntax Tree (AST) where each node represents a construct appearing in the\nsource code. This model is implemented to fix one of the most common semantic\nerrors, such as undeclared variable errors as well as infer their type\ninformation before program compilation. By this approach, the model has\nachieved in correctly locating and identifying 81% of the programs on prutor\ndataset of 1059 programs with only undeclared variable errors and also\ninferring their types correctly in 80% of the programs.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 11:14:14 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Mohan", "Venkatesh Theru", ""], ["Jannesari", "Ali", ""]]}, {"id": "1907.06214", "submitter": "John Glover", "authors": "John Glover and Chris Hokamp", "title": "Task Selection Policies for Multitask Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the questions that arises when designing models that learn to solve\nmultiple tasks simultaneously is how much of the available training budget\nshould be devoted to each individual task. We refer to any formalized approach\nto addressing this problem (learned or otherwise) as a task selection policy.\nIn this work we provide an empirical evaluation of the performance of some\ncommon task selection policies in a synthetic bandit-style setting, as well as\non the GLUE benchmark for natural language understanding. We connect task\nselection policy learning to existing work on automated curriculum learning and\noff-policy evaluation, and suggest a method based on counterfactual estimation\nthat leads to improved model performance in our experimental settings.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 12:22:57 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Glover", "John", ""], ["Hokamp", "Chris", ""]]}, {"id": "1907.06246", "submitter": "Zhuoran Yang", "authors": "Zhuoran Yang, Yongxin Chen, Mingyi Hong, Zhaoran Wang", "title": "On the Global Convergence of Actor-Critic: A Case for Linear Quadratic\n  Regulator with Ergodic Cost", "comments": "41 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the empirical success of the actor-critic algorithm, its theoretical\nunderstanding lags behind. In a broader context, actor-critic can be viewed as\nan online alternating update algorithm for bilevel optimization, whose\nconvergence is known to be fragile. To understand the instability of\nactor-critic, we focus on its application to linear quadratic regulators, a\nsimple yet fundamental setting of reinforcement learning. We establish a\nnonasymptotic convergence analysis of actor-critic in this setting. In\nparticular, we prove that actor-critic finds a globally optimal pair of actor\n(policy) and critic (action-value function) at a linear rate of convergence.\nOur analysis may serve as a preliminary step towards a complete theoretical\nunderstanding of bilevel optimization with nonconvex subproblems, which is\nNP-hard in the worst case and is often solved using heuristics.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 16:50:26 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Yang", "Zhuoran", ""], ["Chen", "Yongxin", ""], ["Hong", "Mingyi", ""], ["Wang", "Zhaoran", ""]]}, {"id": "1907.06257", "submitter": "Zhuoran Yang", "authors": "Xinyang Yi, Zhaoran Wang, Zhuoran Yang, Constantine Caramanis, Han Liu", "title": "More Supervision, Less Computation: Statistical-Computational Tradeoffs\n  in Weakly Supervised Learning", "comments": "This work has been published in NeurIPS 2016. The first three authors\n  contribute equally", "journal-ref": "Advances in Neural Information Processing Systems (2016):\n  4482-4490", "doi": null, "report-no": null, "categories": "cs.LG cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the weakly supervised binary classification problem where the\nlabels are randomly flipped with probability $1- {\\alpha}$. Although there\nexist numerous algorithms for this problem, it remains theoretically unexplored\nhow the statistical accuracies and computational efficiency of these algorithms\ndepend on the degree of supervision, which is quantified by ${\\alpha}$. In this\npaper, we characterize the effect of ${\\alpha}$ by establishing the\ninformation-theoretic and computational boundaries, namely, the minimax-optimal\nstatistical accuracy that can be achieved by all algorithms, and\npolynomial-time algorithms under an oracle computational model. For small\n${\\alpha}$, our result shows a gap between these two boundaries, which\nrepresents the computational price of achieving the information-theoretic\nboundary due to the lack of supervision. Interestingly, we also show that this\ngap narrows as ${\\alpha}$ increases. In other words, having more supervision,\ni.e., more correct labels, not only improves the optimal statistical accuracy\nas expected, but also enhances the computational efficiency for achieving such\naccuracy.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 18:34:44 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Yi", "Xinyang", ""], ["Wang", "Zhaoran", ""], ["Yang", "Zhuoran", ""], ["Caramanis", "Constantine", ""], ["Liu", "Han", ""]]}, {"id": "1907.06258", "submitter": "Jose Ortiz-Bejar", "authors": "Jose Ortiz-Bejar, Eric S. Tellez and Mario Graff", "title": "Improving classification performance by feature space transformations\n  and model selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the performance of classifiers is the realm of feature mapping,\nprototype selection, and kernel function transformations; these techniques aim\nfor reducing the complexity, and also, improving the accuracy of models. In\nparticular, our objective is to combine them to transform data's shape into\nanother more convenient distribution; such that some simple algorithms, such as\nNa\\\"ive Bayes or k-Nearest Neighbors, can produce competitive classifiers. In\nthis paper, we introduce a family of classifiers based on feature mapping and\nkernel functions, orchestrated by a model selection scheme that excels in\nperformance. We provide an extensive experimental comparison of our methods\nwith sixteen popular classifiers on more than thirty benchmarks supporting our\nclaims. In addition to their competitive performance, our statistical tests\nalso found that our methods are different among them, supporting our claim of a\ncompelling family of classifiers.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 18:35:58 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 19:57:28 GMT"}, {"version": "v3", "created": "Thu, 3 Oct 2019 02:03:56 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Ortiz-Bejar", "Jose", ""], ["Tellez", "Eric S.", ""], ["Graff", "Mario", ""]]}, {"id": "1907.06260", "submitter": "Stephen Pfohl", "authors": "Stephen Pfohl, Tony Duan, Daisy Yi Ding, Nigam H. Shah", "title": "Counterfactual Reasoning for Fair Clinical Risk Prediction", "comments": "Machine Learning for Healthcare 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of machine learning systems to support decision making in healthcare\nraises questions as to what extent these systems may introduce or exacerbate\ndisparities in care for historically underrepresented and mistreated groups,\ndue to biases implicitly embedded in observational data in electronic health\nrecords. To address this problem in the context of clinical risk prediction\nmodels, we develop an augmented counterfactual fairness criteria to extend the\ngroup fairness criteria of equalized odds to an individual level. We do so by\nrequiring that the same prediction be made for a patient, and a counterfactual\npatient resulting from changing a sensitive attribute, if the factual and\ncounterfactual outcomes do not differ. We investigate the extent to which the\naugmented counterfactual fairness criteria may be applied to develop fair\nmodels for prolonged inpatient length of stay and mortality with observational\nelectronic health records data. As the fairness criteria is ill-defined without\nknowledge of the data generating process, we use a variational autoencoder to\nperform counterfactual inference in the context of an assumed causal graph.\nWhile our technique provides a means to trade off maintenance of fairness with\nreduction in predictive performance in the context of a learned generative\nmodel, further work is needed to assess the generality of this approach.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 18:44:09 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Pfohl", "Stephen", ""], ["Duan", "Tony", ""], ["Ding", "Daisy Yi", ""], ["Shah", "Nigam H.", ""]]}, {"id": "1907.06288", "submitter": "Yao-Hung Tsai", "authors": "Han Zhao and Yao-Hung Hubert Tsai and Ruslan Salakhutdinov and\n  Geoffrey J. Gordon", "title": "Learning Neural Networks with Adaptive Regularization", "comments": "Camera ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feed-forward neural networks can be understood as a combination of an\nintermediate representation and a linear hypothesis. While most previous works\naim to diversify the representations, we explore the complementary direction by\nperforming an adaptive and data-dependent regularization motivated by the\nempirical Bayes method. Specifically, we propose to construct a matrix-variate\nnormal prior (on weights) whose covariance matrix has a Kronecker product\nstructure. This structure is designed to capture the correlations in neurons\nthrough backpropagation. Under the assumption of this Kronecker factorization,\nthe prior encourages neurons to borrow statistical strength from one another.\nHence, it leads to an adaptive and data-dependent regularization when training\nnetworks on small datasets. To optimize the model, we present an efficient\nblock coordinate descent algorithm with analytical solutions. Empirically, we\ndemonstrate that the proposed method helps networks converge to local optima\nwith smaller stable ranks and spectral norms. These properties suggest better\ngeneralizations and we present empirical results to support this expectation.\nWe also verify the effectiveness of the approach on multiclass classification\nand multitask regression problems with various network structures.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 22:07:15 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 04:17:02 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Zhao", "Han", ""], ["Tsai", "Yao-Hung Hubert", ""], ["Salakhutdinov", "Ruslan", ""], ["Gordon", "Geoffrey J.", ""]]}, {"id": "1907.06290", "submitter": "Harsh Gupta", "authors": "Harsh Gupta, R. Srikant and Lei Ying", "title": "Finite-Time Performance Bounds and Adaptive Learning Rate Selection for\n  Two Time-Scale Reinforcement Learning", "comments": "17 pages, 3 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two time-scale linear stochastic approximation algorithms, which can\nbe used to model well-known reinforcement learning algorithms such as GTD,\nGTD2, and TDC. We present finite-time performance bounds for the case where the\nlearning rate is fixed. The key idea in obtaining these bounds is to use a\nLyapunov function motivated by singular perturbation theory for linear\ndifferential equations. We use the bound to design an adaptive learning rate\nscheme which significantly improves the convergence rate over the known optimal\npolynomial decay rule in our experiments, and can be used to potentially\nimprove the performance of any other schedule where the learning rate is\nchanged at pre-determined time instants.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 22:20:46 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Gupta", "Harsh", ""], ["Srikant", "R.", ""], ["Ying", "Lei", ""]]}, {"id": "1907.06291", "submitter": "Deyan Petrov", "authors": "Deyan Petrov, Timothy M. Hospedales", "title": "Measuring the Transferability of Adversarial Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial examples are of wide concern due to their impact on the\nreliability of contemporary machine learning systems. Effective adversarial\nexamples are mostly found via white-box attacks. However, in some cases they\ncan be transferred across models, thus enabling them to attack black-box\nmodels. In this work we evaluate the transferability of three adversarial\nattacks - the Fast Gradient Sign Method, the Basic Iterative Method, and the\nCarlini & Wagner method, across two classes of models - the VGG class(using\nVGG16, VGG19 and an ensemble of VGG16 and VGG19), and the Inception\nclass(Inception V3, Xception, Inception Resnet V2, and an ensemble of the\nthree). We also outline the problems with the assessment of transferability in\nthe current body of research and attempt to amend them by picking specific\n\"strong\" parameters for the attacks, and by using a L-Infinity clipping\ntechnique and the SSIM metric for the final evaluation of the attack\ntransferability.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 22:20:58 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Petrov", "Deyan", ""], ["Hospedales", "Timothy M.", ""]]}, {"id": "1907.06312", "submitter": "Xiaoyan Li", "authors": "Xiaoyan Li, Iluju Kiringa, Tet Yeap, Xiaodan Zhu, Yifeng Li", "title": "Exploring Deep Anomaly Detection Methods Based on Capsule Net", "comments": "Presented in the \"ICML 2019 Workshop on Uncertainty & Robustness in\n  Deep Learning\", June 14, Long Beach, California, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop and explore deep anomaly detection techniques based\non the capsule network (CapsNet) for image data. Being able to encoding\nintrinsic spatial relationship between parts and a whole, CapsNet has been\napplied as both a classifier and deep autoencoder. This inspires us to design a\nprediction-probability-based and a reconstruction-error-based normality score\nfunctions for evaluating the \"outlierness\" of unseen images. Our results on\nthree datasets demonstrate that the prediction-probability-based method\nperforms consistently well, while the reconstruction-error-based approach is\nrelatively sensitive to the similarity between labeled and unlabeled images.\nFurthermore, both of the CapsNet-based methods outperform the principled\nbenchmark methods in many cases.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 02:15:58 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Li", "Xiaoyan", ""], ["Kiringa", "Iluju", ""], ["Yeap", "Tet", ""], ["Zhu", "Xiaodan", ""], ["Li", "Yifeng", ""]]}, {"id": "1907.06333", "submitter": "Sedrick Scott Keh", "authors": "Sedrick Scott Keh, I-Tsun Cheng", "title": "Myers-Briggs Personality Classification and Personality-Specific\n  Language Generation Using Pre-trained Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Myers-Briggs Type Indicator (MBTI) is a popular personality metric that\nuses four dichotomies as indicators of personality traits. This paper examines\nthe use of pre-trained language models to predict MBTI personality types based\non scraped labeled texts. The proposed model reaches an accuracy of $0.47$ for\ncorrectly predicting all 4 types and $0.86$ for correctly predicting at least 2\ntypes. Furthermore, we investigate the possible uses of a fine-tuned BERT model\nfor personality-specific language generation. This is a task essential for both\nmodern psychology and for intelligent empathetic systems.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 05:04:39 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Keh", "Sedrick Scott", ""], ["Cheng", "I-Tsun", ""]]}, {"id": "1907.06341", "submitter": "Shota Saito", "authors": "Shota Saito, Shinichi Shirakawa", "title": "Controlling Model Complexity in Probabilistic Model-Based Dynamic\n  Optimization of Neural Network Structures", "comments": "Accepted as a conference paper at the 28th International Conference\n  on Artificial Neural Networks (ICANN 2019). The final authenticated\n  publication will be available in the Springer Lecture Notes in Computer\n  Science (LNCS). 13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method of simultaneously optimizing both the structure of neural networks\nand the connection weights in a single training loop can reduce the enormous\ncomputational cost of neural architecture search. We focus on the probabilistic\nmodel-based dynamic neural network structure optimization that considers the\nprobability distribution of structure parameters and simultaneously optimizes\nboth the distribution parameters and connection weights based on gradient\nmethods. Since the existing algorithm searches for the structures that only\nminimize the training loss, this method might find overly complicated\nstructures. In this paper, we propose the introduction of a penalty term to\ncontrol the model complexity of obtained structures. We formulate a penalty\nterm using the number of weights or units and derive its analytical natural\ngradient. The proposed method minimizes the objective function injected the\npenalty term based on the stochastic gradient descent. We apply the proposed\nmethod in the unit selection of a fully-connected neural network and the\nconnection selection of a convolutional neural network. The experimental\nresults show that the proposed method can control model complexity while\nmaintaining performance.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 06:28:40 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Saito", "Shota", ""], ["Shirakawa", "Shinichi", ""]]}, {"id": "1907.06347", "submitter": "Daniel Gissin", "authors": "Daniel Gissin, Shai Shalev-Shwartz", "title": "Discriminative Active Learning", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new batch mode active learning algorithm designed for neural\nnetworks and large query batch sizes. The method, Discriminative Active\nLearning (DAL), poses active learning as a binary classification task,\nattempting to choose examples to label in such a way as to make the labeled set\nand the unlabeled pool indistinguishable. Experimenting on image classification\ntasks, we empirically show our method to be on par with state of the art\nmethods in medium and large query batch sizes, while being simple to implement\nand also extend to other domains besides classification tasks. Our experiments\nalso show that none of the state of the art methods of today are clearly better\nthan uncertainty sampling when the batch size is relatively large, negating\nsome of the reported results in the recent literature.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 06:47:58 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Gissin", "Daniel", ""], ["Shalev-Shwartz", "Shai", ""]]}, {"id": "1907.06356", "submitter": "Marian-Andrei Rizoiu", "authors": "Adriana-Simona Mihaita, Haowen Li, Zongyang He, Marian-Andrei Rizoiu", "title": "Motorway Traffic Flow Prediction using Advanced Deep Learning", "comments": "Published in the Proceedings of the 22nd IEEE Intelligent\n  Transportation Systems Conference (ITSC'19). Auckland, New Zealand", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Congestion prediction represents a major priority for traffic management\ncentres around the world to ensure timely incident response handling. The\nincreasing amounts of generated traffic data have been used to train machine\nlearning predictors for traffic, however this is a challenging task due to\ninter-dependencies of traffic flow both in time and space. Recently, deep\nlearning techniques have shown significant prediction improvements over\ntraditional models, however open questions remain around their applicability,\naccuracy and parameter tuning. This paper proposes an advanced deep learning\nframework for simultaneously predicting the traffic flow on a large number of\nmonitoring stations along a highly circulated motorway in Sydney, Australia,\nincluding exit and entry loop count stations, and over varying training and\nprediction time horizons. The spatial and temporal features extracted from the\n36.34 million data points are used in various deep learning architectures that\nexploit their spatial structure (convolutional neuronal networks), their\ntemporal dynamics (recurrent neuronal networks), or both through a hybrid\nspatio-temporal modelling (CNN-LSTM). We show that our deep learning models\nconsistently outperform traditional methods, and we conduct a comparative\nanalysis of the optimal time horizon of historical data required to predict\ntraffic flow at different time points in the future.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 08:05:08 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 09:45:41 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 02:07:05 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Mihaita", "Adriana-Simona", ""], ["Li", "Haowen", ""], ["He", "Zongyang", ""], ["Rizoiu", "Marian-Andrei", ""]]}, {"id": "1907.06374", "submitter": "Timothy Lillicrap", "authors": "Timothy P. Lillicrap and Konrad P. Kording", "title": "What does it mean to understand a neural network?", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We can define a neural network that can learn to recognize objects in less\nthan 100 lines of code. However, after training, it is characterized by\nmillions of weights that contain the knowledge about many object types across\nvisual scenes. Such networks are thus dramatically easier to understand in\nterms of the code that makes them than the resulting properties, such as tuning\nor connections. In analogy, we conjecture that rules for development and\nlearning in brains may be far easier to understand than their resulting\nproperties. The analogy suggests that neuroscience would benefit from a focus\non learning and development.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 08:58:26 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Lillicrap", "Timothy P.", ""], ["Kording", "Konrad P.", ""]]}, {"id": "1907.06377", "submitter": "Bin Liu", "authors": "Bin Liu, Yu Qi, Ke-Jia Chen", "title": "Sequential online prediction in the presence of outliers and change\n  points: an instant temporal structure learning approach", "comments": "43 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider sequential online prediction (SOP) for streaming\ndata in the presence of outliers and change points. We propose an INstant\nTEmporal structure Learning (INTEL) algorithm to address this problem. Our\nINTEL algorithm is developed based on a full consideration of the duality\nbetween online prediction and anomaly detection. We first employ a mixture of\nweighted Gaussian process models (WGPs) to cover the expected possible temporal\nstructures of the data. Then, based on the rich modeling capacity of this WGP\nmixture, we develop an efficient technique to instantly learn (capture) the\ntemporal structure of the data that follows a regime shift. This instant\nlearning is achieved only by adjusting one hyper-parameter value of the mixture\nmodel. A weighted generalization of the product of experts (POE) model is used\nfor fusing predictions yielded from multiple GP models. An outlier is declared\nonce a real observation seriously deviates from the fused prediction. If a\ncertain number of outliers are consecutively declared, then a change point is\ndeclared. Extensive experiments are performed using a diverse of real datasets.\nResults show that the proposed algorithm is significantly better than benchmark\nmethods for SOP in the presence of outliers and change points.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 09:05:05 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 03:21:25 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["Liu", "Bin", ""], ["Qi", "Yu", ""], ["Chen", "Ke-Jia", ""]]}, {"id": "1907.06382", "submitter": "Peter Tino", "authors": "Peter Tino", "title": "Dynamical Systems as Temporal Feature Spaces", "comments": "45 pages, 17 figures, accepted", "journal-ref": "JMLR, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameterized state space models in the form of recurrent networks are often\nused in machine learning to learn from data streams exhibiting temporal\ndependencies. To break the black box nature of such models it is important to\nunderstand the dynamical features of the input driving time series that are\nformed in the state space. We propose a framework for rigorous analysis of such\nstate representations in vanishing memory state space models such as echo state\nnetworks (ESN). In particular, we consider the state space a temporal feature\nspace and the readout mapping from the state space a kernel machine operating\nin that feature space. We show that: (1) The usual ESN strategy of randomly\ngenerating input-to-state, as well as state coupling leads to shallow memory\ntime series representations, corresponding to cross-correlation operator with\nfast exponentially decaying coefficients; (2) Imposing symmetry on dynamic\ncoupling yields a constrained dynamic kernel matching the input time series\nwith straightforward exponentially decaying motifs or exponentially decaying\nmotifs of the highest frequency; (3) Simple cycle high-dimensional reservoir\ntopology specified only through two free parameters can implement deep memory\ndynamic kernels with a rich variety of matching motifs. We quantify richness of\nfeature representations imposed by dynamic kernels and demonstrate that for\ndynamic kernel associated with cycle reservoir topology, the kernel richness\nundergoes a phase transition close to the edge of stability.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 09:19:56 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 10:17:25 GMT"}, {"version": "v3", "created": "Sat, 15 Feb 2020 11:17:48 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Tino", "Peter", ""]]}, {"id": "1907.06396", "submitter": "Wonshick Ko", "authors": "Wonshick Ko, Dong Eui Chang", "title": "A Dual Memory Structure for Efficient Use of Replay Memory in Deep\n  Reinforcement Learning", "comments": "4 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a dual memory structure for reinforcement learning\nalgorithms with replay memory. The dual memory consists of a main memory that\nstores various data and a cache memory that manages the data and trains the\nreinforcement learning agent efficiently. Experimental results show that the\ndual memory structure achieves higher training and test scores than the\nconventional single memory structure in three selected environments of OpenAI\nGym. This implies that the dual memory structure enables better and more\nefficient training than the single memory structure.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 09:45:54 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Ko", "Wonshick", ""], ["Chang", "Dong Eui", ""]]}, {"id": "1907.06414", "submitter": "Tatiana Fountoukidou", "authors": "Tatiana Fountoukidou and Raphael Sznitman", "title": "Concept-Centric Visual Turing Tests for Method Validation", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": "10.1007/978-3-030-32254-0_29", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in machine learning for medical imaging have led to\nimpressive increases in model complexity and overall capabilities. However, the\nability to discern the precise information a machine learning method is using\nto make decisions has lagged behind and it is often unclear how these\nperformances are in fact achieved. Conventional evaluation metrics that reduce\nmethod performance to a single number or a curve only provide limited insights.\nYet, systems used in clinical practice demand thorough validation that such\ncrude characterizations miss. To this end, we present a framework to evaluate\nclassification methods based on a number of interpretable concepts that are\ncrucial for a clinical task. Our approach is inspired by the Turing Test\nconcept and how to devise a test that adaptively questions a method for its\nability to interpret medical images. To do this, we make use of a Twenty\nQuestions paradigm whereby we use a probabilistic model to characterize the\nmethod's capacity to grasp task-specific concepts, and we introduce a strategy\nto sequentially query the method according to its previous answers. The results\nshow that the probabilistic model is able to expose both the dataset's and the\nmethod's biases, and can be used to reduced the number of queries needed for\nconfident performance evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 10:21:54 GMT"}, {"version": "v2", "created": "Sun, 15 Mar 2020 11:04:20 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Fountoukidou", "Tatiana", ""], ["Sznitman", "Raphael", ""]]}, {"id": "1907.06426", "submitter": "Eunjeong Jeong", "authors": "Eunjeong Jeong, Seungeun Oh, Jihong Park, Hyesung Kim, Mehdi Bennis,\n  Seong-Lyun Kim", "title": "Multi-hop Federated Private Data Augmentation with Sample Compression", "comments": "to be presented at the 28th International Joint Conference on\n  Artificial Intelligence (IJCAI-19), 1st International Workshop on Federated\n  Machine Learning for User Privacy and Data Confidentiality (FML'19), Macao,\n  China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-device machine learning (ML) has brought about the accessibility to a\ntremendous amount of data from the users while keeping their local data private\ninstead of storing it in a central entity. However, for privacy guarantee, it\nis inevitable at each device to compensate for the quality of data or learning\nperformance, especially when it has a non-IID training dataset. In this paper,\nwe propose a data augmentation framework using a generative model: multi-hop\nfederated augmentation with sample compression (MultFAug). A multi-hop protocol\nspeeds up the end-to-end over-the-air transmission of seed samples by enhancing\nthe transport capacity. The relaying devices guarantee stronger privacy\npreservation as well since the origin of each seed sample is hidden in those\nparticipants. For further privatization on the individual sample level, the\ndevices compress their data samples. The devices sparsify their data samples\nprior to transmissions to reduce the sample size, which impacts the\ncommunication payload. This preprocessing also strengthens the privacy of each\nsample, which corresponds to the input perturbation for preserving sample\nprivacy. The numerical evaluations show that the proposed framework\nsignificantly improves privacy guarantee, transmission delay, and local\ntraining performance with adjustment to the number of hops and compression\nrate.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 10:54:18 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Jeong", "Eunjeong", ""], ["Oh", "Seungeun", ""], ["Park", "Jihong", ""], ["Kim", "Hyesung", ""], ["Bennis", "Mehdi", ""], ["Kim", "Seong-Lyun", ""]]}, {"id": "1907.06430", "submitter": "Silvia Chiappa", "authors": "Silvia Chiappa and William S. Isaac", "title": "A Causal Bayesian Networks Viewpoint on Fairness", "comments": null, "journal-ref": "Privacy and Identity Management. Fairness, Accountability, and\n  Transparency in the Age of Big Data. IFIP Advances in Information and\n  Communication Technology, vol 547. Springer, Cham, 2019", "doi": "10.1007/978-3-030-16744-8_1", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We offer a graphical interpretation of unfairness in a dataset as the\npresence of an unfair causal path in the causal Bayesian network representing\nthe data-generation mechanism. We use this viewpoint to revisit the recent\ndebate surrounding the COMPAS pretrial risk assessment tool and, more\ngenerally, to point out that fairness evaluation on a model requires careful\nconsiderations on the patterns of unfairness underlying the training data. We\nshow that causal Bayesian networks provide us with a powerful tool to measure\nunfairness in a dataset and to design fair models in complex unfairness\nscenarios.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 11:06:06 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Chiappa", "Silvia", ""], ["Isaac", "William S.", ""]]}, {"id": "1907.06481", "submitter": "Gabriel Michau Dr.", "authors": "Gabriel Michau and Olga Fink", "title": "Unsupervised Fault Detection in Varying Operating Conditions", "comments": null, "journal-ref": "Proceedings of the 2019 IEEE International Conference on\n  Prognostics and Health Management, San Francisco", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training data-driven approaches for complex industrial system health\nmonitoring is challenging. When data on faulty conditions are rare or not\navailable, the training has to be performed in a unsupervised manner. In\naddition, when the observation period, used for training, is kept short, to be\nable to monitor the system in its early life, the training data might not be\nrepresentative of all the system normal operating conditions. In this paper, we\npropose five approaches to perform fault detection in such context. Two\napproaches rely on the data from the unit to be monitored only: the baseline is\ntrained on the early life of the unit. An incremental learning procedure tries\nto learn new operating conditions as they arise. Three other approaches take\nadvantage of data from other similar units within a fleet. In two cases, units\nare directly compared to each other with similarity measures, and the data from\nsimilar units are combined in the training set. We propose, in the third case,\na new deep-learning methodology to perform, first, a feature alignment of\ndifferent units with an Unsupervised Feature Alignment Network (UFAN). Then,\nfeatures of both units are combined in the training set of the fault detection\nneural network.\n  The approaches are tested on a fleet comprising 112 units, observed over one\nyear of data. All approaches proposed here are an improvement to the baseline,\ntrained with two months of data only. As units in the fleet are found to be\nvery dissimilar, the new architecture UFAN, that aligns units in the feature\nspace, is outperforming others.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 13:01:26 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Michau", "Gabriel", ""], ["Fink", "Olga", ""]]}, {"id": "1907.06496", "submitter": "Reuben Feinman", "authors": "Reuben Feinman, Nikhil Parthasarathy", "title": "A Linear Systems Theory of Normalizing Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing Flows are a promising new class of algorithms for unsupervised\nlearning based on maximum likelihood optimization with change of variables.\nThey offer to learn a factorized component representation for complex nonlinear\ndata and, simultaneously, yield a density function that can evaluate\nlikelihoods and generate samples. Despite these diverse offerings, applications\nof Normalizing Flows have focused primarily on sampling and likelihoods, with\nlittle emphasis placed on feature representation. A lack of theoretical\nfoundation has left many open questions about how to interpret and apply the\nlearned components of the model. We provide a new theoretical perspective of\nNormalizing Flows using the lens of linear systems theory, showing that optimal\nflows learn to represent the local covariance at each region of input space.\nUsing this insight, we develop a new algorithm to extract interpretable\ncomponent representations from the learned model, where components correspond\nto Cartesian dimensions and are scaled according to their manifold\nsignificance. In addition, we highlight a stability concern for the learning\nalgorithm that was previously unaddressed, providing a theoretically-grounded\nsolution to mediate the problem. Experiments with toy manifold learning\ndatasets, as well as the MNIST image dataset, provide convincing support for\nour theory and tools.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 13:28:27 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 16:31:17 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 20:42:01 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 17:30:42 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Feinman", "Reuben", ""], ["Parthasarathy", "Nikhil", ""]]}, {"id": "1907.06508", "submitter": "Wolfgang Konen K", "authors": "Wolfgang Konen", "title": "General Board Game Playing for Education and Research in Generic AI Game\n  Learning", "comments": "8 pages, for: Conference on Games (CoG), London, 2019. Index Terms:\n  game learning, general game playing, AI, temporal difference learning, board\n  games, n-tuple systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new general board game (GBG) playing and learning framework. GBG\ndefines the common interfaces for board games, game states and their AI agents.\nIt allows one to run competitions of different agents on different games. It\nstandardizes those parts of board game playing and learning that otherwise\nwould be tedious and repetitive parts in coding. GBG is suitable for arbitrary\n1-, 2-, ..., N-player board games. It makes a generic TD($\\lambda$)-n-tuple\nagent for the first time available to arbitrary games. On various games,\nTD($\\lambda$)-n-tuple is found to be superior to other generic agents like\nMCTS. GBG aims at the educational perspective, where it helps students to start\nfaster in the area of game learning. GBG aims as well at the research\nperspective by collecting a growing set of games and AI agents to assess their\nstrengths and generalization capabilities in meaningful competitions. Initial\nsuccessful educational and research results are reported.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 13:02:25 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Konen", "Wolfgang", ""]]}, {"id": "1907.06536", "submitter": "Han Cha", "authors": "Han Cha, Jihong Park, Hyesung Kim, Seong-Lyun Kim, Mehdi Bennis", "title": "Federated Reinforcement Distillation with Proxy Experience Memory", "comments": "To be presented at the 28th International Joint Conference on\n  Artificial Intelligence (IJCAI-19), 1st International Workshop on Federated\n  Machine Learning for User Privacy and Data Confidentiality (FML'19), Macao,\n  China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed reinforcement learning, it is common to exchange the\nexperience memory of each agent and thereby collectively train their local\nmodels. The experience memory, however, contains all the preceding state\nobservations and their corresponding policies of the host agent, which may\nviolate the privacy of the agent. To avoid this problem, in this work, we\npropose a privacy-preserving distributed reinforcement learning (RL) framework,\ntermed federated reinforcement distillation (FRD). The key idea is to exchange\na proxy experience memory comprising a pre-arranged set of states and\ntime-averaged policies, thereby preserving the privacy of actual experiences.\nBased on an advantage actor-critic RL architecture, we numerically evaluate the\neffectiveness of FRD and investigate how the performance of FRD is affected by\nthe proxy memory structure and different memory exchanging rules.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 15:03:14 GMT"}, {"version": "v2", "created": "Mon, 13 Apr 2020 06:33:38 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Cha", "Han", ""], ["Park", "Jihong", ""], ["Kim", "Hyesung", ""], ["Kim", "Seong-Lyun", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1907.06543", "submitter": "Sophia Bano Dr", "authors": "Sophia Bano, Francisco Vasconcelos, Marcel Tella Amo, George Dwyer,\n  Caspar Gruijthuijsen, Jan Deprest, Sebastien Ourselin, Emmanuel Vander\n  Poorten, Tom Vercauteren, Danail Stoyanov", "title": "Deep Sequential Mosaicking of Fetoscopic Videos", "comments": "Accepted at MICCAI 2019", "journal-ref": null, "doi": "10.1007/978-3-030-32239-7_35", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twin-to-twin transfusion syndrome treatment requires fetoscopic laser\nphotocoagulation of placental vascular anastomoses to regulate blood flow to\nboth fetuses. Limited field-of-view (FoV) and low visual quality during\nfetoscopy make it challenging to identify all vascular connections. Mosaicking\ncan align multiple overlapping images to generate an image with increased FoV,\nhowever, existing techniques apply poorly to fetoscopy due to the low visual\nquality, texture paucity, and hence fail in longer sequences due to the drift\naccumulated over time. Deep learning techniques can facilitate in overcoming\nthese challenges. Therefore, we present a new generalized Deep Sequential\nMosaicking (DSM) framework for fetoscopic videos captured from different\nsettings such as simulation, phantom, and real environments. DSM extends an\nexisting deep image-based homography model to sequential data by proposing\ncontrolled data augmentation and outlier rejection methods. Unlike existing\nmethods, DSM can handle visual variations due to specular highlights and\nreflection across adjacent frames, hence reducing the accumulated drift. We\nperform experimental validation and comparison using 5 diverse fetoscopic\nvideos to demonstrate the robustness of our framework.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 15:11:09 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Bano", "Sophia", ""], ["Vasconcelos", "Francisco", ""], ["Amo", "Marcel Tella", ""], ["Dwyer", "George", ""], ["Gruijthuijsen", "Caspar", ""], ["Deprest", "Jan", ""], ["Ourselin", "Sebastien", ""], ["Poorten", "Emmanuel Vander", ""], ["Vercauteren", "Tom", ""], ["Stoyanov", "Danail", ""]]}, {"id": "1907.06544", "submitter": "Joonha Park", "authors": "Joonha Park, Yves F. Atchad\\'e", "title": "Markov chain Monte Carlo algorithms with sequential proposals", "comments": "corrects Figure 7 (previously it showed the same plot as Figure 6)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a general framework in Markov chain Monte Carlo (MCMC) sampling\nwhere sequential proposals are tried as a candidate for the next state of the\nMarkov chain. This sequential-proposal framework can be applied to various\nexisting MCMC methods, including Metropolis-Hastings algorithms using random\nproposals and methods that use deterministic proposals such as Hamiltonian\nMonte Carlo (HMC) or the bouncy particle sampler. Sequential-proposal MCMC\nmethods construct the same Markov chains as those constructed by the delayed\nrejection method under certain circumstances. In the context of HMC, the\nsequential-proposal approach has been proposed as extra chance generalized\nhybrid Monte Carlo (XCGHMC). We develop two novel methods in which the\ntrajectories leading to proposals in HMC are automatically tuned to avoid\ndoubling back, as in the No-U-Turn sampler (NUTS). The numerical efficiency of\nthese new methods compare favorably to the NUTS. We additionally show that the\nsequential-proposal bouncy particle sampler enables the constructed Markov\nchain to pass through regions of low target density and thus facilitates better\nmixing of the chain when the target density is multimodal.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 15:16:58 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 17:20:40 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 02:57:06 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Park", "Joonha", ""], ["Atchad\u00e9", "Yves F.", ""]]}, {"id": "1907.06550", "submitter": "Wenhao Li", "authors": "Wenhao Li, Ningyuan Chen, L.Jeff Hong", "title": "A Dimension-free Algorithm for Contextual Continuum-armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In contextual continuum-armed bandits, the contexts $x$ and the arms $y$ are\nboth continuous and drawn from high-dimensional spaces. The payoff function to\nlearn $f(x,y)$ does not have a particular parametric form. The literature has\nshown that for Lipschitz-continuous functions, the optimal regret is\n$\\tilde{O}(T^{\\frac{d_x+d_y+1}{d_x+d_y+2}})$, where $d_x$ and $d_y$ are the\ndimensions of contexts and arms, and thus suffers from the curse of\ndimensionality. We develop an algorithm that achieves regret\n$\\tilde{O}(T^{\\frac{d_x+1}{d_x+2}})$ when $f$ is globally concave in $y$. The\nglobal concavity is a common assumption in many applications. The algorithm is\nbased on stochastic approximation and estimates the gradient information in an\nonline fashion. Our results generate a valuable insight that the curse of\ndimensionality of the arms can be overcome with some mild structures of the\npayoff function.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 15:27:30 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 06:30:54 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Li", "Wenhao", ""], ["Chen", "Ningyuan", ""], ["Hong", "L. Jeff", ""]]}, {"id": "1907.06558", "submitter": "Sofia Ira Ktena", "authors": "Sofia Ira Ktena, Alykhan Tejani, Lucas Theis, Pranay Kumar Myana,\n  Deepak Dilipkumar, Ferenc Huszar, Steven Yoo, Wenzhe Shi", "title": "Addressing Delayed Feedback for Continuous Training with Neural Networks\n  in CTR prediction", "comments": "Accepted at RecSys '19", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in display advertising is that the distribution of\nfeatures and click through rate (CTR) can exhibit large shifts over time due to\nseasonality, changes to ad campaigns and other factors. The predominant\nstrategy to keep up with these shifts is to train predictive models\ncontinuously, on fresh data, in order to prevent them from becoming stale.\nHowever, in many ad systems positive labels are only observed after a possibly\nlong and random delay. These delayed labels pose a challenge to data freshness\nin continuous training: fresh data may not have complete label information at\nthe time they are ingested by the training algorithm. Naive strategies which\nconsider any data point a negative example until a positive label becomes\navailable tend to underestimate CTR, resulting in inferior user experience and\nsuboptimal performance for advertisers. The focus of this paper is to identify\nthe best combination of loss functions and models that enable large-scale\nlearning from a continuous stream of data in the presence of delayed labels. In\nthis work, we compare 5 different loss functions, 3 of them applied to this\nproblem for the first time. We benchmark their performance in offline settings\non both public and proprietary datasets in conjunction with shallow and deep\nmodel architectures. We also discuss the engineering cost associated with\nimplementing each loss function in a production environment. Finally, we\ncarried out online experiments with the top performing methods, in order to\nvalidate their performance in a continuous training scheme. While training on\n668 million in-house data points offline, our proposed methods outperform\nprevious state-of-the-art by 3% relative cross entropy (RCE). During online\nexperiments, we observed 55% gain in revenue per thousand requests (RPMq)\nagainst naive log loss.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 15:56:49 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2021 18:39:39 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Ktena", "Sofia Ira", ""], ["Tejani", "Alykhan", ""], ["Theis", "Lucas", ""], ["Myana", "Pranay Kumar", ""], ["Dilipkumar", "Deepak", ""], ["Huszar", "Ferenc", ""], ["Yoo", "Steven", ""], ["Shi", "Wenzhe", ""]]}, {"id": "1907.06565", "submitter": "Jasjeet Dhaliwal", "authors": "Jasjeet Dhaliwal, Kyle Hambrook", "title": "Recovery Guarantees for Compressible Signals with Adversarial Noise", "comments": "Theorem 1 updated, \\ell_\\infty defense added, Lemma 9 added, comp.\n  section updated, abstract updated, and other minor writing edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.DS cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide recovery guarantees for compressible signals that have been\ncorrupted with noise and extend the framework introduced in\n\\cite{bafna2018thwarting} to defend neural networks against $\\ell_0$-norm,\n$\\ell_2$-norm, and $\\ell_{\\infty}$-norm attacks. Our results are general as\nthey can be applied to most unitary transforms used in practice and hold for\n$\\ell_0$-norm, $\\ell_2$-norm, and $\\ell_\\infty$-norm bounded noise. In the case\nof $\\ell_0$-norm noise, we prove recovery guarantees for Iterative Hard\nThresholding (IHT) and Basis Pursuit (BP). For $\\ell_2$-norm bounded noise, we\nprovide recovery guarantees for BP and for the case of $\\ell_\\infty$-norm\nbounded noise, we provide recovery guarantees for Dantzig Selector (DS). These\nguarantees theoretically bolster the defense framework introduced in\n\\cite{bafna2018thwarting} for defending neural networks against adversarial\ninputs. Finally, we experimentally demonstrate the effectiveness of this\ndefense framework against an array of $\\ell_0$, $\\ell_2$ and $\\ell_\\infty$ norm\nattacks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 16:15:12 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 12:56:03 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 16:53:34 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Dhaliwal", "Jasjeet", ""], ["Hambrook", "Kyle", ""]]}, {"id": "1907.06566", "submitter": "Haisheng Fu", "authors": "Haisheng Fu, Feng Liang, Bo Lei, Nai Bian, Qian zhang, Mohammad\n  Akbari, Jie Liang and Chengjie Tu", "title": "Improved Hybrid Layered Image Compression using Deep Learning and\n  Traditional Codecs", "comments": "Submitted to Signal Processing: Image Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deep learning-based methods have been applied in image compression\nand achieved many promising results. In this paper, we propose an improved\nhybrid layered image compression framework by combining deep learning and the\ntraditional image codecs. At the encoder, we first use a convolutional neural\nnetwork (CNN) to obtain a compact representation of the input image, which is\nlosslessly encoded by the FLIF codec as the base layer of the bit stream. A\ncoarse reconstruction of the input is obtained by another CNN from the\nreconstructed compact representation. The residual between the input and the\ncoarse reconstruction is then obtained and encoded by the H.265/HEVC-based BPG\ncodec as the enhancement layer of the bit stream. Experimental results using\nthe Kodak and Tecnick datasets show that the proposed scheme outperforms the\nstate-of-the-art deep learning-based layered coding scheme and traditional\ncodecs including BPG in both PSNR and MS-SSIM metrics across a wide range of\nbit rates, when the images are coded in the RGB444 domain.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 16:16:21 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Fu", "Haisheng", ""], ["Liang", "Feng", ""], ["Lei", "Bo", ""], ["Bian", "Nai", ""], ["zhang", "Qian", ""], ["Akbari", "Mohammad", ""], ["Liang", "Jie", ""], ["Tu", "Chengjie", ""]]}, {"id": "1907.06571", "submitter": "Aidan Clark", "authors": "Aidan Clark, Jeff Donahue, Karen Simonyan", "title": "Adversarial Video Generation on Complex Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models of natural images have progressed towards high fidelity\nsamples by the strong leveraging of scale. We attempt to carry this success to\nthe field of video modeling by showing that large Generative Adversarial\nNetworks trained on the complex Kinetics-600 dataset are able to produce video\nsamples of substantially higher complexity and fidelity than previous work. Our\nproposed model, Dual Video Discriminator GAN (DVD-GAN), scales to longer and\nhigher resolution videos by leveraging a computationally efficient\ndecomposition of its discriminator. We evaluate on the related tasks of video\nsynthesis and video prediction, and achieve new state-of-the-art Fr\\'echet\nInception Distance for prediction for Kinetics-600, as well as state-of-the-art\nInception Score for synthesis on the UCF-101 dataset, alongside establishing a\nstrong baseline for synthesis on Kinetics-600.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 16:27:04 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 16:37:55 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Clark", "Aidan", ""], ["Donahue", "Jeff", ""], ["Simonyan", "Karen", ""]]}, {"id": "1907.06582", "submitter": "Lin Guo", "authors": "Zheng Gao, Lin Guo, Chi Ma, Xiao Ma, Kai Sun, Hang Xiang, Xiaoqiang\n  Zhu, Hongsong Li, Xiaozhong Liu", "title": "AMAD: Adversarial Multiscale Anomaly Detection on High-Dimensional and\n  Time-Evolving Categorical Data", "comments": "Accepted by 2019 KDD Workshop on Deep Learning Practice for\n  High-Dimensional Sparse Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is facing with emerging challenges in many important\nindustry domains, such as cyber security and online recommendation and\nadvertising. The recent trend in these areas calls for anomaly detection on\ntime-evolving data with high-dimensional categorical features without labeled\nsamples. Also, there is an increasing demand for identifying and monitoring\nirregular patterns at multiple resolutions. In this work, we propose a unified\nend-to-end approach to solve these challenges by combining the advantages of\nAdversarial Autoencoder and Recurrent Neural Network. The model learns data\nrepresentations cross different scales with attention mechanisms, on which an\nenhanced two-resolution anomaly detector is developed for both instances and\ndata blocks. Extensive experiments are performed over three types of datasets\nto demonstrate the efficacy of our method and its superiority over the\nstate-of-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 05:51:33 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Gao", "Zheng", ""], ["Guo", "Lin", ""], ["Ma", "Chi", ""], ["Ma", "Xiao", ""], ["Sun", "Kai", ""], ["Xiang", "Hang", ""], ["Zhu", "Xiaoqiang", ""], ["Li", "Hongsong", ""], ["Liu", "Xiaozhong", ""]]}, {"id": "1907.06584", "submitter": "Yang Yu", "authors": "Wenjie Shang, Yang Yu, Qingyang Li, Zhiwei Qin, Yiping Meng, Jieping\n  Ye", "title": "Environment Reconstruction with Hidden Confounders for Reinforcement\n  Learning based Recommendation", "comments": "Appears in KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning aims at searching the best policy model for decision\nmaking, and has been shown powerful for sequential recommendations. The\ntraining of the policy by reinforcement learning, however, is placed in an\nenvironment. In many real-world applications, however, the policy training in\nthe real environment can cause an unbearable cost, due to the exploration in\nthe environment. Environment reconstruction from the past data is thus an\nappealing way to release the power of reinforcement learning in these\napplications. The reconstruction of the environment is, basically, to extract\nthe casual effect model from the data. However, real-world applications are\noften too complex to offer fully observable environment information. Therefore,\nquite possibly there are unobserved confounding variables lying behind the\ndata. The hidden confounder can obstruct an effective reconstruction of the\nenvironment. In this paper, by treating the hidden confounder as a hidden\npolicy, we propose a deconfounded multi-agent environment reconstruction\n(DEMER) approach in order to learn the environment together with the hidden\nconfounder. DEMER adopts a multi-agent generative adversarial imitation\nlearning framework. It proposes to introduce the confounder embedded policy,\nand use the compatible discriminator for training the policies. We then apply\nDEMER in an application of driver program recommendation. We firstly use an\nartificial driver program recommendation environment, abstracted from the real\napplication, to verify and analyze the effectiveness of DEMER. We then test\nDEMER in the real application of Didi Chuxing. Experiment results show that\nDEMER can effectively reconstruct the hidden confounder, and thus can build the\nenvironment better. DEMER also derives a recommendation policy with a\nsignificantly improved performance in the test phase of the real application.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 10:13:05 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Shang", "Wenjie", ""], ["Yu", "Yang", ""], ["Li", "Qingyang", ""], ["Qin", "Zhiwei", ""], ["Meng", "Yiping", ""], ["Ye", "Jieping", ""]]}, {"id": "1907.06592", "submitter": "Paschalis Bizopoulos", "authors": "Paschalis Bizopoulos, and Dimitrios Koutsouris", "title": "Sparsely Activated Networks", "comments": "10 pages, 5 figures, 4 algorithms, 4 tables, submission to IEEE\n  Transactions on Neural Networks and Learning Systems", "journal-ref": null, "doi": "10.1109/TNNLS.2020.2984514", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous literature on unsupervised learning focused on designing structural\npriors with the aim of learning meaningful features. However, this was done\nwithout considering the description length of the learned representations which\nis a direct and unbiased measure of the model complexity. In this paper, first\nwe introduce the $\\varphi$ metric that evaluates unsupervised models based on\ntheir reconstruction accuracy and the degree of compression of their internal\nrepresentations. We then present and define two activation functions (Identity,\nReLU) as base of reference and three sparse activation functions (top-k\nabsolutes, Extrema-Pool indices, Extrema) as candidate structures that minimize\nthe previously defined $\\varphi$. We lastly present Sparsely Activated Networks\n(SANs) that consist of kernels with shared weights that, during encoding, are\nconvolved with the input and then passed through a sparse activation function.\nDuring decoding, the same weights are convolved with the sparse activation map\nand subsequently the partial reconstructions from each weight are summed to\nreconstruct the input. We compare SANs using the five previously defined\nactivation functions on a variety of datasets (Physionet, UCI-epilepsy, MNIST,\nFMNIST) and show that models that are selected using $\\varphi$ have small\ndescription representation length and consist of interpretable kernels.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 08:01:47 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 14:24:02 GMT"}, {"version": "v3", "created": "Sun, 2 Feb 2020 13:05:55 GMT"}, {"version": "v4", "created": "Wed, 3 Feb 2021 16:25:28 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Bizopoulos", "Paschalis", ""], ["Koutsouris", "Dimitrios", ""]]}, {"id": "1907.06594", "submitter": "Shuhao Xia", "authors": "Shuhao Xia and Yuanming Shi", "title": "Learning One-hidden-layer neural networks via Provable Gradient Descent\n  with Random Initialization", "comments": "the provement need to be corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep learning has shown its powerful performance in many\napplications, the mathematical principles behind neural networks are still\nmysterious. In this paper, we consider the problem of learning a\none-hidden-layer neural network with quadratic activations. We focus on the\nunder-parameterized regime where the number of hidden units is smaller than the\ndimension of the inputs. We shall propose to solve the problem via a provable\ngradient-based method with random initialization. For the non-convex neural\nnetworks training problem we reveal that the gradient descent iterates are able\nto enter a local region that enjoys strong convexity and smoothness within a\nfew iterations, and then provably converges to a globally optimal model at a\nlinear rate with near-optimal sample complexity. We further corroborate our\ntheoretical findings via various experiments.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 08:50:04 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 01:37:41 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Xia", "Shuhao", ""], ["Shi", "Yuanming", ""]]}, {"id": "1907.06600", "submitter": "Qiuyue Zhong", "authors": "Qiu-Yue Zhong, Andrew H. Fairless, Jasmine M. McCammon, Farbod\n  Rahmanian", "title": "Medical Concept Representation Learning from Claims Data and Application\n  to Health Plan Payment Risk Adjustment", "comments": "Accepted as a poster presentation at the 2019 KDD Workshop on Applied\n  Data Science for Healthcare (KDD-DSHealth2019), Aug 5, 2019, Anchorage,\n  Alaska USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk adjustment has become an increasingly important tool in healthcare. It\nhas been extensively applied to payment adjustment for health plans to reflect\nthe expected cost of providing coverage for members. Risk adjustment models are\ntypically estimated using linear regression, which does not fully exploit the\ninformation in claims data. Moreover, the development of such linear regression\nmodels requires substantial domain expert knowledge and computational effort\nfor data preprocessing. In this paper, we propose a novel approach for risk\nadjustment that uses semantic embeddings to represent patient medical\nhistories. Embeddings efficiently represent medical concepts learned from\ndiagnostic, procedure, and prescription codes in patients' medical histories.\nThis approach substantially reduces the need for feature engineering. Our\nresults show that models using embeddings had better performance than a\ncommercial risk adjustment model on the task of prospective risk score\nprediction.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 16:53:43 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Zhong", "Qiu-Yue", ""], ["Fairless", "Andrew H.", ""], ["McCammon", "Jasmine M.", ""], ["Rahmanian", "Farbod", ""]]}, {"id": "1907.06607", "submitter": "Matthew Spellings", "authors": "Matthew Spellings", "title": "Agglomerative Attention", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural networks using transformer-based architectures have recently\ndemonstrated great power and flexibility in modeling sequences of many types.\nOne of the core components of transformer networks is the attention layer,\nwhich allows contextual information to be exchanged among sequence elements.\nWhile many of the prevalent network structures thus far have utilized full\nattention -- which operates on all pairs of sequence elements -- the quadratic\nscaling of this attention mechanism significantly constrains the size of models\nthat can be trained. In this work, we present an attention model that has only\nlinear requirements in memory and computation time. We show that, despite the\nsimpler attention model, networks using this attention mechanism can attain\ncomparable performance to full attention networks on language modeling tasks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 17:11:05 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Spellings", "Matthew", ""]]}, {"id": "1907.06614", "submitter": "Argyris Kalogeratos", "authors": "Ioannis Bargiotas, Argyris Kalogeratos, Myrto Limnios, Pierre-Paul\n  Vidal, Damien Ricard, Nicolas Vayatis", "title": "Revealing posturographic features associated with the risk of falling in\n  patients with Parkinsonian syndromes via machine learning", "comments": "16 pages, 11 figures (plots, tables, algorithms)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Falling in Parkinsonian syndromes (PS) is associated with postural\ninstability and consists a common cause of disability among PS patients.\nCurrent posturographic practices record the body's center-of-pressure\ndisplacement (statokinesigram) while the patient stands on a force platform.\nStatokinesigrams, after appropriate signal processing, can offer numerous\nposturographic features, which however challenges the efforts for valid\nstatistics via standard univariate approaches. In this work, we present the\nts-AUC, a non-parametric multivariate two-sample test, which we employ to\nanalyze statokinesigram differences among PS patients that are fallers (PSf)\nand non-fallers (PSNF). We included 123 PS patients who were classified into\nPSF or PSNF based on clinical assessment and underwent simple Romberg Test\n(eyes open/eyes closed). We analyzed posturographic features using both\nmultiple testing with p-value adjustment and the ts-AUC. While the ts-AUC\nshowed significant difference between groups (p-value = 0.01), multiple testing\ndid not show any such difference. Interestingly, significant difference between\nthe two groups was found only using the open-eyes protocol. PSF showed\nsignificantly increased antero-posterior movements as well as increased\nposturographic area, compared to PSNF. Our study demonstrates the superiority\nof the ts-AUC test compared to standard statistical tools in distinguishing PSF\nand PSNF in the multidimensional feature space. This result highlights more\ngenerally the fact that machine learning-based statistical tests can be seen as\na natural extension of classical statistical approaches and should be\nconsidered, especially when dealing with multifactorial assessments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 17:21:13 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Bargiotas", "Ioannis", ""], ["Kalogeratos", "Argyris", ""], ["Limnios", "Myrto", ""], ["Vidal", "Pierre-Paul", ""], ["Ricard", "Damien", ""], ["Vayatis", "Nicolas", ""]]}, {"id": "1907.06622", "submitter": "Christopher Walters", "authors": "Patrick Kline and Christopher Walters", "title": "Audits as Evidence: Experiments, Ensembles, and Enforcement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop tools for utilizing correspondence experiments to detect illegal\ndiscrimination by individual employers. Employers violate US employment law if\ntheir propensity to contact applicants depends on protected characteristics\nsuch as race or sex. We establish identification of higher moments of the\ncausal effects of protected characteristics on callback rates as a function of\nthe number of fictitious applications sent to each job ad. These moments are\nused to bound the fraction of jobs that illegally discriminate. Applying our\nresults to three experimental datasets, we find evidence of significant\nemployer heterogeneity in discriminatory behavior, with the standard deviation\nof gaps in job-specific callback probabilities across protected groups\naveraging roughly twice the mean gap. In a recent experiment manipulating\nracially distinctive names, we estimate that at least 85% of jobs that contact\nboth of two white applications and neither of two black applications are\nengaged in illegal discrimination. To assess the tradeoff between type I and II\nerrors presented by these patterns, we consider the performance of a series of\ndecision rules for investigating suspicious callback behavior under a simple\ntwo-type model that rationalizes the experimental data. Though, in our\npreferred specification, only 17% of employers are estimated to discriminate on\nthe basis of race, we find that an experiment sending 10 applications to each\njob would enable accurate detection of 7-10% of discriminators while falsely\naccusing fewer than 0.2% of non-discriminators. A minimax decision rule\nacknowledging partial identification of the joint distribution of callback\nrates yields higher error rates but more investigations than our baseline\ntwo-type model. Our results suggest illegal labor market discrimination can be\nreliably monitored with relatively small modifications to existing audit\ndesigns.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 17:43:02 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 16:26:53 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Kline", "Patrick", ""], ["Walters", "Christopher", ""]]}, {"id": "1907.06627", "submitter": "Babak Ehteshami Bejnordi", "authors": "Babak Ehteshami Bejnordi, Tijmen Blankevoort and Max Welling", "title": "Batch-Shaping for Learning Conditional Channel Gated Networks", "comments": "Published as a conference paper at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method that trains large capacity neural networks with\nsignificantly improved accuracy and lower dynamic computational cost. We\nachieve this by gating the deep-learning architecture on a fine-grained-level.\nIndividual convolutional maps are turned on/off conditionally on features in\nthe network. To achieve this, we introduce a new residual block architecture\nthat gates convolutional channels in a fine-grained manner. We also introduce a\ngenerally applicable tool $batch$-$shaping$ that matches the marginal aggregate\nposteriors of features in a neural network to a pre-specified prior\ndistribution. We use this novel technique to force gates to be more conditional\non the data. We present results on CIFAR-10 and ImageNet datasets for image\nclassification, and Cityscapes for semantic segmentation. Our results show that\nour method can slim down large architectures conditionally, such that the\naverage computational cost on the data is on par with a smaller architecture,\nbut with higher accuracy. In particular, on ImageNet, our ResNet50 and ResNet34\ngated networks obtain 74.60% and 72.55% top-1 accuracy compared to the 69.76%\naccuracy of the baseline ResNet18 model, for similar complexity. We also show\nthat the resulting networks automatically learn to use more features for\ndifficult examples and fewer features for simple examples.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 17:58:04 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 12:13:32 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 09:10:52 GMT"}, {"version": "v4", "created": "Fri, 3 Apr 2020 08:42:24 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Bejnordi", "Babak Ehteshami", ""], ["Blankevoort", "Tijmen", ""], ["Welling", "Max", ""]]}, {"id": "1907.06633", "submitter": "Apdullah Yayik", "authors": "Apdullah Yay{\\i}k, Yakup Kutlu, G\\\"okhan Altan", "title": "On improving learning capability of ELM and an application to\n  brain-computer interface", "comments": "11 pages, 6 figures, Neural Computing and Application, Springer\n  (under-review)", "journal-ref": null, "doi": "10.13140/RG.2.2.30778.34248", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As a type of pseudoinverse learning, extreme learning machine (ELM) is able\nto achieve high performances in a rapid pace on benchmark datasets. However,\nwhen it is applied to real life large data, decline related to low-convergence\nof singular value decomposition (SVD) method occurs. Our study aims to resolve\nthis issue via replacing SVD with theoretically and empirically much efficient\n5 number of methods: lower upper triangularization, Hessenberg decomposition,\nSchur decomposition, modified Gram Schmidt algorithm and Householder\nreflection. Comparisons were made on electroencephalography based\nbrain-computer interface classification problem to decide which method is the\nmost useful. Results of subject-based classifications suggested that if\npriority was given to training pace, Hessenberg decomposition method, whereas\nif priority was given to performances Householder reflection method should be\npreferred.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 09:28:07 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Yay\u0131k", "Apdullah", ""], ["Kutlu", "Yakup", ""], ["Altan", "G\u00f6khan", ""]]}, {"id": "1907.06637", "submitter": "Cheng-Zhi Anna Huang", "authors": "Cheng-Zhi Anna Huang, Curtis Hawthorne, Adam Roberts, Monica\n  Dinculescu, James Wexler, Leon Hong, Jacob Howcroft", "title": "The Bach Doodle: Approachable music composition with machine learning at\n  scale", "comments": "Proceedings of the 18th International Society for Music Information\n  Retrieval Conference, ISMIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.HC cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make music composition more approachable, we designed the first AI-powered\nGoogle Doodle, the Bach Doodle, where users can create their own melody and\nhave it harmonized by a machine learning model Coconet (Huang et al., 2017) in\nthe style of Bach. For users to input melodies, we designed a simplified\nsheet-music based interface. To support an interactive experience at scale, we\nre-implemented Coconet in TensorFlow.js (Smilkov et al., 2019) to run in the\nbrowser and reduced its runtime from 40s to 2s by adopting dilated depth-wise\nseparable convolutions and fusing operations. We also reduced the model\ndownload size to approximately 400KB through post-training weight quantization.\nWe calibrated a speed test based on partial model evaluation time to determine\nif the harmonization request should be performed locally or sent to remote TPU\nservers. In three days, people spent 350 years worth of time playing with the\nBach Doodle, and Coconet received more than 55 million queries. Users could\nchoose to rate their compositions and contribute them to a public dataset,\nwhich we are releasing with this paper. We hope that the community finds this\ndataset useful for applications ranging from ethnomusicological studies, to\nmusic education, to improving machine learning models.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 23:39:12 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Huang", "Cheng-Zhi Anna", ""], ["Hawthorne", "Curtis", ""], ["Roberts", "Adam", ""], ["Dinculescu", "Monica", ""], ["Wexler", "James", ""], ["Hong", "Leon", ""], ["Howcroft", "Jacob", ""]]}, {"id": "1907.06652", "submitter": "Bryan Ostdiek", "authors": "Bryan Ostdiek, Lina Necib, Timothy Cohen, Marat Freytsis, Mariangela\n  Lisanti, Shea Garrison-Kimmel, Andrew Wetzel, Robyn E. Sanderson, and Philip\n  F. Hopkins", "title": "Cataloging Accreted Stars within Gaia DR2 using Deep Learning", "comments": "v1: 24 pages and 13 Figures + 4 appendices, v2: Journal version,\n  fixed bug resulting in incorrect final catalog scores, updated plots,\n  conclusions unchanged", "journal-ref": "A&A 636, A75 (2020)", "doi": "10.1051/0004-6361/201936866", "report-no": null, "categories": "astro-ph.GA hep-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this study is to present the development of a machine learning\nbased approach that utilizes phase space alone to separate the Gaia DR2 stars\ninto two categories: those accreted onto the Milky Way from those that are in\nsitu. Traditional selection methods that have been used to identify accreted\nstars typically rely on full 3D velocity, metallicity information, or both,\nwhich significantly reduces the number of classifiable stars. The approach\nadvocated here is applicable to a much larger portion of Gaia DR2. A method\nknown as \"transfer learning\" is shown to be effective through extensive testing\non a set of mock Gaia catalogs that are based on the FIRE cosmological zoom-in\nhydrodynamic simulations of Milky Way-mass galaxies. The machine is first\ntrained on simulated data using only 5D kinematics as inputs and is then\nfurther trained on a cross-matched Gaia/RAVE data set, which improves\nsensitivity to properties of the real Milky Way. The result is a catalog that\nidentifies around 767,000 accreted stars within Gaia DR2. This catalog can\nyield empirical insights into the merger history of the Milky Way and could be\nused to infer properties of the dark matter distribution.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 18:00:03 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 16:58:52 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Ostdiek", "Bryan", ""], ["Necib", "Lina", ""], ["Cohen", "Timothy", ""], ["Freytsis", "Marat", ""], ["Lisanti", "Mariangela", ""], ["Garrison-Kimmel", "Shea", ""], ["Wetzel", "Andrew", ""], ["Sanderson", "Robyn E.", ""], ["Hopkins", "Philip F.", ""]]}, {"id": "1907.06671", "submitter": "Sim\\~ao Eduardo", "authors": "Sim\\~ao Eduardo, Alfredo Naz\\'abal, Christopher K. I. Williams,\n  Charles Sutton", "title": "Robust Variational Autoencoders for Outlier Detection and Repair of\n  Mixed-Type Data", "comments": "Accepted for publication at AISTATS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of unsupervised cell outlier detection and repair in\nmixed-type tabular data. Traditional methods are concerned only with detecting\nwhich rows in the dataset are outliers. However, identifying which cells are\ncorrupted in a specific row is an important problem in practice, and the very\nfirst step towards repairing them. We introduce the Robust Variational\nAutoencoder (RVAE), a deep generative model that learns the joint distribution\nof the clean data while identifying the outlier cells, allowing their\nimputation (repair). RVAE explicitly learns the probability of each cell being\nan outlier, balancing different likelihood models in the row outlier score,\nmaking the method suitable for outlier detection in mixed-type datasets. We\nshow experimentally that not only RVAE performs better than several\nstate-of-the-art methods in cell outlier detection and repair for tabular data,\nbut also that is robust against the initial hyper-parameter selection.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 18:06:49 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 23:50:11 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Eduardo", "Sim\u00e3o", ""], ["Naz\u00e1bal", "Alfredo", ""], ["Williams", "Christopher K. I.", ""], ["Sutton", "Charles", ""]]}, {"id": "1907.06673", "submitter": "Magnus Wiese", "authors": "Magnus Wiese, Robert Knobloch, Ralf Korn, Peter Kretschmer", "title": "Quant GANs: Deep Generation of Financial Time Series", "comments": "Corrected typos. Added section 2 as an overview of existing\n  literature. Added section 5.3 to clarify the modeling assumptions. Appendix B\n  now contains more details on the neural network architectures used. Changed\n  latex template", "journal-ref": "Quantitative Finance, 2020", "doi": "10.1080/14697688.2020.1730426", "report-no": null, "categories": "q-fin.MF cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling financial time series by stochastic processes is a challenging task\nand a central area of research in financial mathematics. As an alternative, we\nintroduce Quant GANs, a data-driven model which is inspired by the recent\nsuccess of generative adversarial networks (GANs). Quant GANs consist of a\ngenerator and discriminator function, which utilize temporal convolutional\nnetworks (TCNs) and thereby achieve to capture long-range dependencies such as\nthe presence of volatility clusters. The generator function is explicitly\nconstructed such that the induced stochastic process allows a transition to its\nrisk-neutral distribution. Our numerical results highlight that distributional\nproperties for small and large lags are in an excellent agreement and\ndependence properties such as volatility clusters, leverage effects, and serial\nautocorrelations can be generated by the generator function of Quant GANs,\ndemonstrably in high fidelity.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 18:08:43 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 10:59:00 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Wiese", "Magnus", ""], ["Knobloch", "Robert", ""], ["Korn", "Ralf", ""], ["Kretschmer", "Peter", ""]]}, {"id": "1907.06698", "submitter": "Terence Parr", "authors": "Terence Parr and James D. Wilson", "title": "Technical Report: Partial Dependence through Stratification", "comments": "Tweaks/clarifications, added ntrials optional hyper parameter,\n  corrected interpretation of Integrated Gradients technique. For code, see\n  repo https://github.com/parrt/stratx", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial dependence curves (FPD) introduced by Friedman, are an important\nmodel interpretation tool, but are often not accessible to business analysts\nand scientists who typically lack the skills to choose, tune, and assess\nmachine learning models. It is also common for the same partial dependence\nalgorithm on the same data to give meaningfully different curves for different\nmodels, which calls into question their precision. Expertise is required to\ndistinguish between model artifacts and true relationships in the data.\n  In this paper, we contribute methods for computing partial dependence curves,\nfor both numerical (StratPD) and categorical explanatory variables\n(CatStratPD), that work directly from training data rather than predictions of\na model. Our methods provide a direct estimate of partial dependence, and rely\non approximating the partial derivative of an unknown regression function\nwithout first fitting a model and then approximating its partial derivative. We\ninvestigate settings where contemporary partial dependence methods---including\nFPD, ALE, and SHAP methods---give biased results. Furthermore, we demonstrate\nthat our approach works correctly on synthetic and plausibly on real data sets.\nOur goal is not to argue that model-based techniques are not useful. Rather, we\nhope to open a new line of inquiry into nonparametric partial dependence.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 19:04:42 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 17:22:36 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 17:00:10 GMT"}, {"version": "v4", "created": "Fri, 24 Apr 2020 21:31:34 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Parr", "Terence", ""], ["Wilson", "James D.", ""]]}, {"id": "1907.06771", "submitter": "Ruben Becker", "authors": "Ruben Becker, Imane Hafnaoui, Michael E. Houle, Pan Li, Arthur Zimek", "title": "Subspace Determination through Local Intrinsic Dimensional\n  Decomposition: Theory and Experimentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Axis-aligned subspace clustering generally entails searching through enormous\nnumbers of subspaces (feature combinations) and evaluation of cluster quality\nwithin each subspace. In this paper, we tackle the problem of identifying\nsubsets of features with the most significant contribution to the formation of\nthe local neighborhood surrounding a given data point. For each point, the\nrecently-proposed Local Intrinsic Dimension (LID) model is used in identifying\nthe axis directions along which features have the greatest local\ndiscriminability, or equivalently, the fewest number of components of LID that\ncapture the local complexity of the data. In this paper, we develop an\nestimator of LID along axis projections, and provide preliminary evidence that\nthis LID decomposition can indicate axis-aligned data subspaces that support\nthe formation of clusters.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 22:13:00 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Becker", "Ruben", ""], ["Hafnaoui", "Imane", ""], ["Houle", "Michael E.", ""], ["Li", "Pan", ""], ["Zimek", "Arthur", ""]]}, {"id": "1907.06795", "submitter": "Mark Koren", "authors": "Mark Koren and Mykel Kochenderfer", "title": "Efficient Autonomy Validation in Simulation with Adaptive Stress Testing", "comments": "Submitted to IEEE ITSC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SE cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the development of autonomous systems such as driverless cars, it is\nimportant to characterize the scenarios that are most likely to result in\nfailure. Adaptive Stress Testing (AST) provides a way to search for the\nmost-likely failure scenario as a Markov decision process (MDP). Our previous\nwork used a deep reinforcement learning (DRL) solver to identify likely failure\nscenarios. However, the solver's use of a feed-forward neural network with a\ndiscretized space of possible initial conditions poses two major problems.\nFirst, the system is not treated as a black box, in that it requires analyzing\nthe internal state of the system, which leads to considerable implementation\ncomplexities. Second, in order to simulate realistic settings, a new instance\nof the solver needs to be run for each initial condition. Running a new solver\nfor each initial condition not only significantly increases the computational\ncomplexity, but also disregards the underlying relationship between similar\ninitial conditions. We provide a solution to both problems by employing a\nrecurrent neural network that takes a set of initial conditions from a\ncontinuous space as input. This approach enables robust and efficient detection\nof failures because the solution generalizes across the entire space of initial\nconditions. By simulating an instance where an autonomous car drives while a\npedestrian is crossing a road, we demonstrate the solver is now capable of\nfinding solutions for problems that would have previously been intractable.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 00:12:09 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Koren", "Mark", ""], ["Kochenderfer", "Mykel", ""]]}, {"id": "1907.06800", "submitter": "Bao Wang", "authors": "Bao Wang and Stanley J. Osher", "title": "Graph Interpolating Activation Improves Both Natural and Robust\n  Accuracies in Data-Efficient Deep Learning", "comments": "34 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving the accuracy and robustness of deep neural nets (DNNs) and adapting\nthem to small training data are primary tasks in deep learning research. In\nthis paper, we replace the output activation function of DNNs, typically the\ndata-agnostic softmax function, with a graph Laplacian-based high dimensional\ninterpolating function which, in the continuum limit, converges to the solution\nof a Laplace-Beltrami equation on a high dimensional manifold. Furthermore, we\npropose end-to-end training and testing algorithms for this new architecture.\nThe proposed DNN with graph interpolating activation integrates the advantages\nof both deep learning and manifold learning. Compared to the conventional DNNs\nwith the softmax function as output activation, the new framework demonstrates\nthe following major advantages: First, it is better applicable to\ndata-efficient learning in which we train high capacity DNNs without using a\nlarge number of training data. Second, it remarkably improves both natural\naccuracy on the clean images and robust accuracy on the adversarial images\ncrafted by both white-box and black-box adversarial attacks. Third, it is a\nnatural choice for semi-supervised learning. For reproducibility, the code is\navailable at \\url{https://github.com/BaoWangMath/DNN-DataDependentActivation}.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 00:28:19 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Wang", "Bao", ""], ["Osher", "Stanley J.", ""]]}, {"id": "1907.06814", "submitter": "Yuxuan Du", "authors": "Yuxuan Du, Min-Hsiu Hsieh, Tongliang Liu, Dacheng Tao", "title": "A Quantum-inspired Algorithm for General Minimum Conical Hull Problems", "comments": null, "journal-ref": "Phys. Rev. Research 2, 033199 (2020)", "doi": "10.1103/PhysRevResearch.2.033199", "report-no": null, "categories": "cs.LG cs.CG cs.DS quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A wide range of fundamental machine learning tasks that are addressed by the\nmaximum a posteriori estimation can be reduced to a general minimum conical\nhull problem. The best-known solution to tackle general minimum conical hull\nproblems is the divide-and-conquer anchoring learning scheme (DCA), whose\nruntime complexity is polynomial in size. However, big data is pushing these\npolynomial algorithms to their performance limits. In this paper, we propose a\nsublinear classical algorithm to tackle general minimum conical hull problems\nwhen the input has stored in a sample-based low-overhead data structure. The\nalgorithm's runtime complexity is polynomial in the rank and polylogarithmic in\nsize. The proposed algorithm achieves the exponential speedup over DCA and,\ntherefore, provides advantages for high dimensional problems.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 02:42:19 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Du", "Yuxuan", ""], ["Hsieh", "Min-Hsiu", ""], ["Liu", "Tongliang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1907.06826", "submitter": "Yulong Cao", "authors": "Yulong Cao, Chaowei Xiao, Benjamin Cyr, Yimeng Zhou, Won Park, Sara\n  Rampazzi, Qi Alfred Chen, Kevin Fu, Z. Morley Mao", "title": "Adversarial Sensor Attack on LiDAR-based Perception in Autonomous\n  Driving", "comments": "Accepted at the ACM Conference on Computer and Communications\n  Security (CCS), 2019", "journal-ref": null, "doi": "10.1145/3319535.3339815", "report-no": null, "categories": "cs.CR cs.CV eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Autonomous Vehicles (AVs), one fundamental pillar is perception, which\nleverages sensors like cameras and LiDARs (Light Detection and Ranging) to\nunderstand the driving environment. Due to its direct impact on road safety,\nmultiple prior efforts have been made to study its the security of perception\nsystems. In contrast to prior work that concentrates on camera-based\nperception, in this work we perform the first security study of LiDAR-based\nperception in AV settings, which is highly important but unexplored. We\nconsider LiDAR spoofing attacks as the threat model and set the attack goal as\nspoofing obstacles close to the front of a victim AV. We find that blindly\napplying LiDAR spoofing is insufficient to achieve this goal due to the machine\nlearning-based object detection process. Thus, we then explore the possibility\nof strategically controlling the spoofed attack to fool the machine learning\nmodel. We formulate this task as an optimization problem and design modeling\nmethods for the input perturbation function and the objective function. We also\nidentify the inherent limitations of directly solving the problem using\noptimization and design an algorithm that combines optimization and global\nsampling, which improves the attack success rates to around 75%. As a case\nstudy to understand the attack impact at the AV driving decision level, we\nconstruct and evaluate two attack scenarios that may damage road safety and\nmobility. We also discuss defense directions at the AV system, sensor, and\nmachine learning model levels.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 04:00:56 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 13:26:03 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Cao", "Yulong", ""], ["Xiao", "Chaowei", ""], ["Cyr", "Benjamin", ""], ["Zhou", "Yimeng", ""], ["Park", "Won", ""], ["Rampazzi", "Sara", ""], ["Chen", "Qi Alfred", ""], ["Fu", "Kevin", ""], ["Mao", "Z. Morley", ""]]}, {"id": "1907.06831", "submitter": "Fan Yang", "authors": "Fan Yang, Mengnan Du, Xia Hu", "title": "Evaluating Explanation Without Ground Truth in Interpretable Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable Machine Learning (IML) has become increasingly important in\nmany real-world applications, such as autonomous cars and medical diagnosis,\nwhere explanations are significantly preferred to help people better understand\nhow machine learning systems work and further enhance their trust towards\nsystems. However, due to the diversified scenarios and subjective nature of\nexplanations, we rarely have the ground truth for benchmark evaluation in IML\non the quality of generated explanations. Having a sense of explanation quality\nnot only matters for assessing system boundaries, but also helps to realize the\ntrue benefits to human users in practical settings. To benchmark the evaluation\nin IML, in this article, we rigorously define the problem of evaluating\nexplanations, and systematically review the existing efforts from\nstate-of-the-arts. Specifically, we summarize three general aspects of\nexplanation (i.e., generalizability, fidelity and persuasibility) with formal\ndefinitions, and respectively review the representative methodologies for each\nof them under different tasks. Further, a unified evaluation framework is\ndesigned according to the hierarchical needs from developers and end-users,\nwhich could be easily adopted for different scenarios in practice. In the end,\nopen problems are discussed, and several limitations of current evaluation\ntechniques are raised for future explorations.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 04:25:39 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 21:13:50 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Yang", "Fan", ""], ["Du", "Mengnan", ""], ["Hu", "Xia", ""]]}, {"id": "1907.06835", "submitter": "Sung-Ho Bae", "authors": "Kang-Ho Lee, JoonHyun Jeong, and Sung-Ho Bae", "title": "An Inter-Layer Weight Prediction and Quantization for Deep Neural\n  Networks based on a Smoothly Varying Weight Hypothesis", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to a resource-constrained environment, network compression has become an\nimportant part of deep neural networks research. In this paper, we propose a\nnew compression method, \\textit{Inter-Layer Weight Prediction} (ILWP) and\nquantization method which quantize the predicted residuals between the weights\nin all convolution layers based on an inter-frame prediction method in\nconventional video coding schemes. Furthermore, we found a phenomenon\n\\textit{Smoothly Varying Weight Hypothesis} (SVWH) which is that the weights in\nadjacent convolution layers share strong similarity in shapes and values, i.e.,\nthe weights tend to vary smoothly along with the layers. Based on SVWH, we\npropose a second ILWP and quantization method which quantize the predicted\nresiduals between the weights in adjacent convolution layers. Since the\npredicted weight residuals tend to follow Laplace distributions with very low\nvariance, the weight quantization can more effectively be applied, thus\nproducing more zero weights and enhancing the weight compression ratio. In\naddition, we propose a new \\textit{inter-layer loss} for eliminating\nnon-texture bits, which enabled us to more effectively store only texture bits.\nThat is, the proposed loss regularizes the weights such that the collocated\nweights between the adjacent two layers have the same values. Finally, we\npropose an ILWP with an inter-layer loss and quantization method. Our\ncomprehensive experiments show that the proposed method achieves a much higher\nweight compression rate at the same accuracy level compared with the previous\nquantization-based compression methods in deep neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 04:44:59 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 02:32:12 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Lee", "Kang-Ho", ""], ["Jeong", "JoonHyun", ""], ["Bae", "Sung-Ho", ""]]}, {"id": "1907.06837", "submitter": "Shalini Pandey", "authors": "Shalini Pandey, George Karypis", "title": "A Self-Attentive model for Knowledge Tracing", "comments": "International Conference on Education Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing is the task of modeling each student's mastery of knowledge\nconcepts (KCs) as (s)he engages with a sequence of learning activities. Each\nstudent's knowledge is modeled by estimating the performance of the student on\nthe learning activities. It is an important research area for providing a\npersonalized learning platform to students. In recent years, methods based on\nRecurrent Neural Networks (RNN) such as Deep Knowledge Tracing (DKT) and\nDynamic Key-Value Memory Network (DKVMN) outperformed all the traditional\nmethods because of their ability to capture complex representation of human\nlearning. However, these methods face the issue of not generalizing well while\ndealing with sparse data which is the case with real-world data as students\ninteract with few KCs. In order to address this issue, we develop an approach\nthat identifies the KCs from the student's past activities that are\n\\textit{relevant} to the given KC and predicts his/her mastery based on the\nrelatively few KCs that it picked. Since predictions are made based on\nrelatively few past activities, it handles the data sparsity problem better\nthan the methods based on RNN. For identifying the relevance between the KCs,\nwe propose a self-attention based approach, Self Attentive Knowledge Tracing\n(SAKT). Extensive experimentation on a variety of real-world dataset shows that\nour model outperforms the state-of-the-art models for knowledge tracing,\nimproving AUC by 4.43% on average.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 04:47:35 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Pandey", "Shalini", ""], ["Karypis", "George", ""]]}, {"id": "1907.06840", "submitter": "Kamil Khadiev", "authors": "Kamil Khadiev, Ilnaz Mannapov and Liliya Safina", "title": "The Quantum Version Of Classification Decision Tree Constructing\n  Algorithm C5.0", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper, we focus on complexity of C5.0 algorithm for constructing\ndecision tree classifier that is the models for the classification problem from\nmachine learning. In classical case the decision tree is constructed in\n$O(hd(NM+N \\log N))$ running time, where $M$ is a number of classes, $N$ is the\nsize of a training data set, $d$ is a number of attributes of each element, $h$\nis a tree height. Firstly, we improved the classical version, the running time\nof the new version is $O(h\\cdot d\\cdot N\\log N)$. Secondly, we suggest a\nquantum version of this algorithm, which uses quantum subroutines like the\namplitude amplification and the D{\\\"u}rr-H{\\o}yer minimum search algorithms\nthat are based on Grover's algorithm. The running time of the quantum algorithm\nis $O\\big(h\\cdot \\sqrt{d}\\log d \\cdot N \\log N\\big)$ that is better than\ncomplexity of the classical algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 04:53:48 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Khadiev", "Kamil", ""], ["Mannapov", "Ilnaz", ""], ["Safina", "Liliya", ""]]}, {"id": "1907.06845", "submitter": "Gabriel Loaiza-Ganem", "authors": "Gabriel Loaiza-Ganem, John P. Cunningham", "title": "The continuous Bernoulli: fixing a pervasive error in variational\n  autoencoders", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders (VAE) have quickly become a central tool in machine\nlearning, applicable to a broad range of data types and latent variable models.\nBy far the most common first step, taken by seminal papers and by core software\nlibraries alike, is to model MNIST data using a deep network parameterizing a\nBernoulli likelihood. This practice contains what appears to be and what is\noften set aside as a minor inconvenience: the pixel data is [0,1] valued, not\n{0,1} as supported by the Bernoulli likelihood. Here we show that, far from\nbeing a triviality or nuisance that is convenient to ignore, this error has\nprofound importance to VAE, both qualitative and quantitative. We introduce and\nfully characterize a new [0,1]-supported, single parameter distribution: the\ncontinuous Bernoulli, which patches this pervasive bug in VAE. This\ndistribution is not nitpicking; it produces meaningful performance improvements\nacross a range of metrics and datasets, including sharper image samples, and\nsuggests a broader class of performant VAE.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 05:11:46 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 04:45:07 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 19:59:42 GMT"}, {"version": "v4", "created": "Wed, 2 Oct 2019 00:11:02 GMT"}, {"version": "v5", "created": "Sun, 29 Dec 2019 23:44:06 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Loaiza-Ganem", "Gabriel", ""], ["Cunningham", "John P.", ""]]}, {"id": "1907.06890", "submitter": "Antonio Loquercio", "authors": "Antonio Loquercio, Mattia Seg\\`u, Davide Scaramuzza", "title": "A General Framework for Uncertainty Estimation in Deep Learning", "comments": "Accepted for publication in the Robotics and Automation Letters 2020,\n  and for presentation at the International Conference on Robotics and\n  Automation (ICRA) 2020", "journal-ref": "IEEE Robotics and Automation Letters 2020", "doi": "10.1109/LRA.2020.2974682", "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks predictions are unreliable when the input sample is out of\nthe training distribution or corrupted by noise. Being able to detect such\nfailures automatically is fundamental to integrate deep learning algorithms\ninto robotics. Current approaches for uncertainty estimation of neural networks\nrequire changes to the network and optimization process, typically ignore prior\nknowledge about the data, and tend to make over-simplifying assumptions which\nunderestimate uncertainty. To address these limitations, we propose a novel\nframework for uncertainty estimation. Based on Bayesian belief networks and\nMonte-Carlo sampling, our framework not only fully models the different sources\nof prediction uncertainty, but also incorporates prior data information, e.g.\nsensor noise. We show theoretically that this gives us the ability to capture\nuncertainty better than existing methods. In addition, our framework has\nseveral desirable properties: (i) it is agnostic to the network architecture\nand task; (ii) it does not require changes in the optimization process; (iii)\nit can be applied to already trained architectures. We thoroughly validate the\nproposed framework through extensive experiments on both computer vision and\ncontrol tasks, where we outperform previous methods by up to 23% in accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 08:46:03 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 13:56:53 GMT"}, {"version": "v3", "created": "Fri, 11 Oct 2019 10:45:59 GMT"}, {"version": "v4", "created": "Fri, 7 Feb 2020 12:10:56 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Loquercio", "Antonio", ""], ["Seg\u00f9", "Mattia", ""], ["Scaramuzza", "Davide", ""]]}, {"id": "1907.06901", "submitter": "Pankaj Malhotra", "authors": "Vishnu TV, Pankaj Malhotra, Jyoti Narwariya, Lovekesh Vig, Gautam\n  Shroff", "title": "Meta-Learning for Black-box Optimization", "comments": "Accepted at ECML-PKDD 2019 Research Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, neural networks trained as optimizers under the \"learning to learn\"\nor meta-learning framework have been shown to be effective for a broad range of\noptimization tasks including derivative-free black-box function optimization.\nRecurrent neural networks (RNNs) trained to optimize a diverse set of synthetic\nnon-convex differentiable functions via gradient descent have been effective at\noptimizing derivative-free black-box functions. In this work, we propose\nRNN-Opt: an approach for learning RNN-based optimizers for optimizing\nreal-parameter single-objective continuous functions under limited budget\nconstraints. Existing approaches utilize an observed improvement based\nmeta-learning loss function for training such models. We propose training\nRNN-Opt by using synthetic non-convex functions with known (approximate)\noptimal values by directly using discounted regret as our meta-learning loss\nfunction. We hypothesize that a regret-based loss function mimics typical\ntesting scenarios, and would therefore lead to better optimizers compared to\noptimizers trained only to propose queries that improve over previous queries.\nFurther, RNN-Opt incorporates simple yet effective enhancements during training\nand inference procedures to deal with the following practical challenges: i)\nUnknown range of possible values for the black-box function to be optimized,\nand ii) Practical and domain-knowledge based constraints on the input\nparameters. We demonstrate the efficacy of RNN-Opt in comparison to existing\nmethods on several synthetic as well as standard benchmark black-box functions\nalong with an anonymized industrial constrained optimization problem.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 09:10:50 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 06:25:39 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["TV", "Vishnu", ""], ["Malhotra", "Pankaj", ""], ["Narwariya", "Jyoti", ""], ["Vig", "Lovekesh", ""], ["Shroff", "Gautam", ""]]}, {"id": "1907.06916", "submitter": "Mark McDonnell", "authors": "Mark D. McDonnell, Hesham Mostafa, Runchun Wang and Andre van Schaik", "title": "Single-bit-per-weight deep convolutional neural networks without\n  batch-normalization layers for embedded systems", "comments": "8 pages, published IEEE conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch-normalization (BN) layers are thought to be an integrally important\nlayer type in today's state-of-the-art deep convolutional neural networks for\ncomputer vision tasks such as classification and detection. However, BN layers\nintroduce complexity and computational overheads that are highly undesirable\nfor training and/or inference on low-power custom hardware implementations of\nreal-time embedded vision systems such as UAVs, robots and Internet of Things\n(IoT) devices. They are also problematic when batch sizes need to be very small\nduring training, and innovations such as residual connections introduced more\nrecently than BN layers could potentially have lessened their impact. In this\npaper we aim to quantify the benefits BN layers offer in image classification\nnetworks, in comparison with alternative choices. In particular, we study\nnetworks that use shifted-ReLU layers instead of BN layers. We found, following\nexperiments with wide residual networks applied to the ImageNet, CIFAR 10 and\nCIFAR 100 image classification datasets, that BN layers do not consistently\noffer a significant advantage. We found that the accuracy margin offered by BN\nlayers depends on the data set, the network size, and the bit-depth of weights.\nWe conclude that in situations where BN layers are undesirable due to speed,\nmemory or complexity costs, that using shifted-ReLU layers instead should be\nconsidered; we found they can offer advantages in all these areas, and often do\nnot impose a significant accuracy cost.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 09:42:02 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 13:04:27 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["McDonnell", "Mark D.", ""], ["Mostafa", "Hesham", ""], ["Wang", "Runchun", ""], ["van Schaik", "Andre", ""]]}, {"id": "1907.06923", "submitter": "Hyenkyun Woo", "authors": "Hyenkyun Woo", "title": "The Bregman-Tweedie Classification Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes the Bregman-Tweedie classification model and analyzes the\ndomain structure of the extended exponential function, an extension of the\nclassic generalized exponential function with additional scaling parameter, and\nrelated high-level mathematical structures, such as the Bregman-Tweedie loss\nfunction and the Bregman-Tweedie divergence. The base function of this\ndivergence is the convex function of Legendre type induced from the extended\nexponential function. The Bregman-Tweedie loss function of the proposed\nclassification model is the regular Legendre transformation of the\nBregman-Tweedie divergence. This loss function is a polynomial parameterized\nfunction between unhinge loss and the logistic loss function. Actually, we have\ntwo sub-models of the Bregman-Tweedie classification model; H-Bregman with\nhinge-like loss function and L-Bregman with logistic-like loss function.\nAlthough the proposed classification model is nonconvex and unbounded,\nempirically, we have observed that the H-Bregman and L-Bregman outperform, in\nterms of the Friedman ranking, logistic regression and SVM and show reasonable\nperformance in terms of the classification accuracy in the category of the\nbinary linear classification problem.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 09:59:09 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Woo", "Hyenkyun", ""]]}, {"id": "1907.06969", "submitter": "Dennis Rohde", "authors": "Stefan Meintrup, Alexander Munteanu, Dennis Rohde", "title": "Random Projections and Sampling Algorithms for Clustering of\n  High-Dimensional Polygonal Curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the $k$-median clustering problem for high-dimensional polygonal\ncurves with finite but unbounded number of vertices. We tackle the\ncomputational issue that arises from the high number of dimensions by defining\na Johnson-Lindenstrauss projection for polygonal curves. We analyze the\nresulting error in terms of the Fr\\'echet distance, which is a tractable and\nnatural dissimilarity measure for curves. Our clustering algorithms achieve\nsublinear dependency on the number of input curves via subsampling. Also, we\nshow that the Fr\\'echet distance can not be approximated within any factor of\nless than $\\sqrt{2}$ by probabilistically reducing the dependency on the number\nof vertices of the curves. As a consequence we provide a fast,\nCUDA-parallelized version of the Alt and Godau algorithm for computing the\nFr\\'echet distance and use it to evaluate our results empirically.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 12:52:34 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 15:28:33 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2020 08:31:20 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Meintrup", "Stefan", ""], ["Munteanu", "Alexander", ""], ["Rohde", "Dennis", ""]]}, {"id": "1907.06986", "submitter": "Christopher Nemeth", "authors": "Christopher Nemeth, Paul Fearnhead", "title": "Stochastic gradient Markov chain Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chain Monte Carlo (MCMC) algorithms are generally regarded as the gold\nstandard technique for Bayesian inference. They are theoretically\nwell-understood and conceptually simple to apply in practice. The drawback of\nMCMC is that in general performing exact inference requires all of the data to\nbe processed at each iteration of the algorithm. For large data sets, the\ncomputational cost of MCMC can be prohibitive, which has led to recent\ndevelopments in scalable Monte Carlo algorithms that have a significantly lower\ncomputational cost than standard MCMC. In this paper, we focus on a particular\nclass of scalable Monte Carlo algorithms, stochastic gradient Markov chain\nMonte Carlo (SGMCMC) which utilises data subsampling techniques to reduce the\nper-iteration cost of MCMC. We provide an introduction to some popular SGMCMC\nalgorithms and review the supporting theoretical results, as well as comparing\nthe efficiency of SGMCMC algorithms against MCMC on benchmark examples. The\nsupporting R code is available online.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 13:34:44 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Nemeth", "Christopher", ""], ["Fearnhead", "Paul", ""]]}, {"id": "1907.06992", "submitter": "Nicholas Carrara", "authors": "Nicholas Carrara, Kevin Vanslette", "title": "The Design of Global Correlation Quantifiers and Continuous Notions of\n  Statistical Sufficiency", "comments": null, "journal-ref": "Entropy 2020, 22(3), 357", "doi": "10.3390/e22030357", "report-no": null, "categories": "cs.IT math.IT physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using first principles from inference, we design a set of functionals for the\npurposes of \\textit{ranking} joint probability distributions with respect to\ntheir correlations. Starting with a general functional, we impose its desired\nbehaviour through the \\textit{Principle of Constant Correlations} (PCC), which\nconstrains the correlation functional to behave in a consistent way under\nstatistically independent inferential transformations. The PCC guides us in\nchoosing the appropriate design criteria for constructing the desired\nfunctionals. Since the derivations depend on a choice of partitioning the\nvariable space into $n$ disjoint subspaces, the general functional we design is\nthe $n$-partite information (NPI), of which the \\textit{total correlation} and\n\\textit{mutual information} are special cases. Thus, these functionals are\nfound to be uniquely capable of determining whether a certain class of\ninferential transformations, $\\rho\\xrightarrow{*}\\rho'$, preserve, destroy or\ncreate correlations. This provides conceptual clarity by ruling out other\npossible global correlation quantifiers. Finally, the derivation and results\nallow us to quantify non-binary notions of statistical sufficency. Our results\nexpress what percentage of the correlations are preserved under a given\ninferential transformation or variable mapping.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 12:04:03 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 15:16:39 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 03:13:47 GMT"}, {"version": "v4", "created": "Sun, 2 Feb 2020 16:10:53 GMT"}, {"version": "v5", "created": "Thu, 19 Mar 2020 23:28:53 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Carrara", "Nicholas", ""], ["Vanslette", "Kevin", ""]]}, {"id": "1907.06994", "submitter": "Faicel Chamroukhi", "authors": "Bao Tuyen Huynh and Faicel Chamroukhi", "title": "Estimation and Feature Selection in Mixtures of Generalized Linear\n  Experts Models", "comments": "arXiv admin note: text overlap with arXiv:1810.12161", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mixtures-of-Experts (MoE) are conditional mixture models that have shown\ntheir performance in modeling heterogeneity in data in many statistical\nlearning approaches for prediction, including regression and classification, as\nwell as for clustering. Their estimation in high-dimensional problems is still\nhowever challenging. We consider the problem of parameter estimation and\nfeature selection in MoE models with different generalized linear experts\nmodels, and propose a regularized maximum likelihood estimation that\nefficiently encourages sparse solutions for heterogeneous data with\nhigh-dimensional predictors. The developed proximal-Newton EM algorithm\nincludes proximal Newton-type procedures to update the model parameter by\nmonotonically maximizing the objective function and allows to perform efficient\nestimation and feature selection. An experimental study shows the good\nperformance of the algorithms in terms of recovering the actual sparse\nsolutions, parameter estimation, and clustering of heterogeneous regression\ndata, compared to the main state-of-the art competitors.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 10:58:31 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Huynh", "Bao Tuyen", ""], ["Chamroukhi", "Faicel", ""]]}, {"id": "1907.07035", "submitter": "Sebastian Curi", "authors": "Silvan Melchior, Sebastian Curi, Felix Berkenkamp, Andreas Krause", "title": "Structured Variational Inference in Unstable Gaussian Process State\n  Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new variational inference algorithm for learning in Gaussian\nProcess State-Space Models (GPSSMs). Our algorithm enables learning of unstable\nand partially observable systems, where previous algorithms fail. Our main\nalgorithmic contribution is a novel approximate posterior that can be\ncalculated efficiently using a single forward and backward pass along the\ntraining trajectories. The forward-backward pass is inspired on Kalman\nsmoothing for linear dynamical systems but generalizes to GPSSMs. Our second\ncontribution is a modification of the conditioning step that effectively lowers\nthe Kalman gain. This modification is crucial to attaining good test\nperformance where no measurements are available. Finally, we show\nexperimentally that our learning algorithm performs well in stable and unstable\nreal systems with hidden states.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 14:34:47 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 12:11:49 GMT"}, {"version": "v3", "created": "Wed, 10 Jun 2020 07:06:25 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Melchior", "Silvan", ""], ["Curi", "Sebastian", ""], ["Berkenkamp", "Felix", ""], ["Krause", "Andreas", ""]]}, {"id": "1907.07036", "submitter": "Melvin Wong", "authors": "Melvin Wong and Bilal Farooq", "title": "Information processing constraints in travel behaviour modelling: A\n  generative learning approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Travel decisions tend to exhibit sensitivity to uncertainty and information\nprocessing constraints. These behavioural conditions can be characterized by a\ngenerative learning process. We propose a data-driven generative model version\nof rational inattention theory to emulate these behavioural representations. We\noutline the methodology of the generative model and the associated learning\nprocess as well as provide an intuitive explanation of how this process\ncaptures the value of prior information in the choice utility specification. We\ndemonstrate the effects of information heterogeneity on a travel choice,\nanalyze the econometric interpretation, and explore the properties of our\ngenerative model. Our findings indicate a strong correlation with rational\ninattention behaviour theory, which suggest that individuals may ignore certain\nexogenous variables and rely on prior information for evaluating decisions\nunder uncertainty. Finally, the principles demonstrated in this study can be\nformulated as a generalized entropy and utility based multinomial logit model.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 14:35:23 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 18:12:06 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Wong", "Melvin", ""], ["Farooq", "Bilal", ""]]}, {"id": "1907.07063", "submitter": "Jarek Duda Dr", "authors": "Jarek Duda", "title": "SGD momentum optimizer with step estimation by online parabola model", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stochastic gradient descent, especially for neural network training, there\nare currently dominating first order methods: not modeling local distance to\nminimum. This information required for optimal step size is provided by second\norder methods, however, they have many difficulties, starting with full Hessian\nhaving square of dimension number of coefficients.\n  This article proposes a minimal step from successful first order momentum\nmethod toward second order: online parabola modelling in just a single\ndirection: normalized $\\hat{v}$ from momentum method. It is done by estimating\nlinear trend of gradients $\\vec{g}=\\nabla F(\\vec{\\theta})$ in $\\hat{v}$\ndirection: such that $g(\\vec{\\theta}_\\bot+\\theta\\hat{v})\\approx \\lambda (\\theta\n-p)$ for $\\theta = \\vec{\\theta}\\cdot \\hat{v}$, $g= \\vec{g}\\cdot \\hat{v}$,\n$\\vec{\\theta}_\\bot=\\vec{\\theta}-\\theta\\hat{v}$. Using linear regression,\n$\\lambda$, $p$ are MSE estimated by just updating four averages (of $g$,\n$\\theta$, $g\\theta$, $\\theta^2$) in the considered direction. Exponential\nmoving averages allow here for inexpensive online estimation, weakening\ncontribution of the old gradients. Controlling sign of curvature $\\lambda$, we\ncan repel from saddles in contrast to attraction in standard Newton method. In\nthe remaining directions: not considered in second order model, we can\nsimultaneously perform e.g. gradient descent.\n  There is also discussed its learning rate approximation as $\\mu=\\sigma_\\theta\n/ \\sigma_g$, allowing e.g. for adaptive SGD - with learning rate separately\noptimized (2nd order) for each parameter.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 15:22:34 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 16:18:44 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 15:09:21 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Duda", "Jarek", ""]]}, {"id": "1907.07066", "submitter": "Mario Graff", "authors": "Claudia N. S\\'anchez and Mario Graff", "title": "Selection Heuristics on Semantic Genetic Programming for Classification\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual's semantics have been used for guiding the learning process of\nGenetic Programming solving supervised learning problems. The semantics has\nbeen used to proposed novel genetic operators as well as different ways of\nperforming parent selection. The latter is the focus of this contribution by\nproposing three heuristics for parent selection that replace the fitness\nfunction on the selection mechanism entirely. These heuristics complement\nprevious work by being inspired in the characteristics of the addition, Naive\nBayes, and Nearest Centroid functions and applying them only when the function\nis used to create an offspring. These heuristics use different similarity\nmeasures among the parents to decide which of them is more appropriate given a\nfunction. The similarity functions considered are the cosine similarity,\nPearson's correlation, and agreement. We analyze these heuristics' performance\nagainst random selection, state-of-the-art selection schemes, and 18\nclassifiers, including auto-machine-learning techniques, on 30 classification\nproblems with a variable number of samples, variables, and classes. The result\nindicated that the combination of parent selection based on agreement and\nrandom selection to replace an individual in the population produces\nstatistically better results than the classical selection and state-of-the-art\nschemes, and it is competitive with state-of-the-art classifiers. Finally, the\ncode is released as open-source software.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 15:25:01 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 15:12:15 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 03:10:59 GMT"}, {"version": "v4", "created": "Fri, 2 Apr 2021 18:48:49 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["S\u00e1nchez", "Claudia N.", ""], ["Graff", "Mario", ""]]}, {"id": "1907.07129", "submitter": "Kin Sum Liu", "authors": "Kin Sum Liu, Chien-Chun Ni, Yu-Yao Lin, Jie Gao", "title": "Topology Based Scalable Graph Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new graph kernel for graph classification and comparison using\nOllivier Ricci curvature. The Ricci curvature of an edge in a graph describes\nthe connectivity in the local neighborhood. An edge in a densely connected\nneighborhood has positive curvature and an edge serving as a local bridge has\nnegative curvature. We use the edge curvature distribution to form a graph\nkernel which is then used to compare and cluster graphs. The curvature kernel\nuses purely the graph topology and thereby works for settings when node\nattributes are not available.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 00:23:17 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Liu", "Kin Sum", ""], ["Ni", "Chien-Chun", ""], ["Lin", "Yu-Yao", ""], ["Gao", "Jie", ""]]}, {"id": "1907.07131", "submitter": "Ying Da Wang", "authors": "Ying Da Wang, Ryan T. Armstrong, Peyman Mostaghimi", "title": "Boosting Resolution and Recovering Texture of micro-CT Images with Deep\n  Learning", "comments": "\\keywords{Digital Rock Imaging \\and Super Resolution \\and\n  Convolutional Neural Networks \\and Generative Adversarial Networks}", "journal-ref": null, "doi": "10.1029/2019WR026052", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital Rock Imaging is constrained by detector hardware, and a trade-off\nbetween the image field of view (FOV) and the image resolution must be made.\nThis can be compensated for with super resolution (SR) techniques that take a\nwide FOV, low resolution (LR) image, and super resolve a high resolution (HR),\nhigh FOV image. The Enhanced Deep Super Resolution Generative Adversarial\nNetwork (EDSRGAN) is trained on the Deep Learning Digital Rock Super Resolution\nDataset, a diverse compilation 12000 of raw and processed uCT images. The\nnetwork shows comparable performance of 50% to 70% reduction in relative error\nover bicubic interpolation. GAN performance in recovering texture shows\nsuperior visual similarity compared to SRCNN and other methods. Difference maps\nindicate that the SRCNN section of the SRGAN network recovers large scale edge\n(grain boundaries) features while the GAN network regenerates perceptually\nindistinguishable high frequency texture. Network performance is generalised\nwith augmentation, showing high adaptability to noise and blur. HR images are\nfed into the network, generating HR-SR images to extrapolate network\nperformance to sub-resolution features present in the HR images themselves.\nResults show that under-resolution features such as dissolved minerals and thin\nfractures are regenerated despite the network operating outside of trained\nspecifications. Comparison with Scanning Electron Microscope images shows\ndetails are consistent with the underlying geometry of the sample. Recovery of\ntextures benefits the characterisation of digital rocks with a high proportion\nof under-resolution micro-porous features, such as carbonate and coal samples.\nImages that are normally constrained by the mineralogy of the rock (coal), by\nfast transient imaging (waterflooding), or by the energy of the source\n(microporosity), can be super resolved accurately for further analysis\ndownstream.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 04:32:50 GMT"}, {"version": "v2", "created": "Wed, 17 Jul 2019 06:17:34 GMT"}, {"version": "v3", "created": "Sat, 27 Jul 2019 01:37:33 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Da Wang", "Ying", ""], ["Armstrong", "Ryan T.", ""], ["Mostaghimi", "Peyman", ""]]}, {"id": "1907.07148", "submitter": "Ping Li", "authors": "Martin Slawski, Emanuel Ben-David, Ping Li", "title": "A Two-Stage Approach to Multivariate Linear Regression with Sparsely\n  Mismatched Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A tacit assumption in linear regression is that (response, predictor)-pairs\ncorrespond to identical observational units. A series of recent works have\nstudied scenarios in which this assumption is violated under terms such as\n``Unlabeled Sensing and ``Regression with Unknown Permutation''. In this paper,\nwe study the setup of multiple response variables and a notion of mismatches\nthat generalizes permutations in order to allow for missing matches as well as\nfor one-to-many matches. A two-stage method is proposed under the assumption\nthat most pairs are correctly matched. In the first stage, the regression\nparameter is estimated by handling mismatches as contaminations, and\nsubsequently the generalized permutation is estimated by a basic variant of\nmatching. The approach is both computationally convenient and equipped with\nfavorable statistical guarantees. Specifically, it is shown that the conditions\nfor permutation recovery become considerably less stringent as the number of\nresponses $m$ per observation increase. Particularly, for $m = \\Omega(\\log n)$,\nthe required signal-to-noise ratio no longer depends on the sample size $n$.\nNumerical results on synthetic and real data are presented to support the main\nfindings of our analysis.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 17:12:19 GMT"}, {"version": "v2", "created": "Sun, 28 Jun 2020 15:28:13 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Slawski", "Martin", ""], ["Ben-David", "Emanuel", ""], ["Li", "Ping", ""]]}, {"id": "1907.07157", "submitter": "Mengwei Yang", "authors": "Mengwei Yang, Linqi Song, Jie Xu, Congduan Li, Guozhen Tan", "title": "The Tradeoff Between Privacy and Accuracy in Anomaly Detection Using\n  Federated XGBoost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy has raised considerable concerns recently, especially with the advent\nof information explosion and numerous data mining techniques to explore the\ninformation inside large volumes of data. In this context, a new distributed\nlearning paradigm termed federated learning becomes prominent recently to\ntackle the privacy issues in distributed learning, where only learning models\nwill be transmitted from the distributed nodes to servers without revealing\nusers' own data and hence protecting the privacy of users.\n  In this paper, we propose a horizontal federated XGBoost algorithm to solve\nthe federated anomaly detection problem, where the anomaly detection aims to\nidentify abnormalities from extremely unbalanced datasets and can be considered\nas a special classification problem. Our proposed federated XGBoost algorithm\nincorporates data aggregation and sparse federated update processes to balance\nthe tradeoff between privacy and learning performance. In particular, we\nintroduce the virtual data sample by aggregating a group of users' data\ntogether at a single distributed node. We compute parameters based on these\nvirtual data samples in the local nodes and aggregate the learning model in the\ncentral server. In the learning model upgrading process, we focus more on the\nwrongly classified data before in the virtual sample and hence to generate\nsparse learning model parameters. By carefully controlling the size of these\ngroups of samples, we can achieve a tradeoff between privacy and learning\nperformance. Our experimental results show the effectiveness of our proposed\nscheme by comparing with existing state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 17:30:42 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 13:22:57 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Yang", "Mengwei", ""], ["Song", "Linqi", ""], ["Xu", "Jie", ""], ["Li", "Congduan", ""], ["Tan", "Guozhen", ""]]}, {"id": "1907.07165", "submitter": "Yash Goyal", "authors": "Yash Goyal, Amir Feder, Uri Shalit, Been Kim", "title": "Explaining Classifiers with Causal Concept Effect (CaCE)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we understand classification decisions made by deep neural networks?\nMany existing explainability methods rely solely on correlations and fail to\naccount for confounding, which may result in potentially misleading\nexplanations. To overcome this problem, we define the Causal Concept Effect\n(CaCE) as the causal effect of (the presence or absence of) a\nhuman-interpretable concept on a deep neural net's predictions. We show that\nthe CaCE measure can avoid errors stemming from confounding. Estimating CaCE is\ndifficult in situations where we cannot easily simulate the do-operator. To\nmitigate this problem, we use a generative model, specifically a Variational\nAutoEncoder (VAE), to measure VAE-CaCE. In an extensive experimental analysis,\nwe show that the VAE-CaCE is able to estimate the true concept causal effect,\ncompared to baselines for a number of datasets including high dimensional\nimages.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 17:47:43 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 18:56:14 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Goyal", "Yash", ""], ["Feder", "Amir", ""], ["Shalit", "Uri", ""], ["Kim", "Been", ""]]}, {"id": "1907.07174", "submitter": "Dan Hendrycks", "authors": "Dan Hendrycks, Kevin Zhao, Steven Basart, Jacob Steinhardt, Dawn Song", "title": "Natural Adversarial Examples", "comments": "CVPR 2021; dataset and code available at\n  https://github.com/hendrycks/natural-adv-examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two challenging datasets that reliably cause machine learning\nmodel performance to substantially degrade. The datasets are collected with a\nsimple adversarial filtration technique to create datasets with limited\nspurious cues. Our datasets' real-world, unmodified examples transfer to\nvarious unseen models reliably, demonstrating that computer vision models have\nshared weaknesses. The first dataset is called ImageNet-A and is like the\nImageNet test set, but it is far more challenging for existing models. We also\ncurate an adversarial out-of-distribution detection dataset called ImageNet-O,\nwhich is the first out-of-distribution detection dataset created for ImageNet\nmodels. On ImageNet-A a DenseNet-121 obtains around 2% accuracy, an accuracy\ndrop of approximately 90%, and its out-of-distribution detection performance on\nImageNet-O is near random chance levels. We find that existing data\naugmentation techniques hardly boost performance, and using other public\ntraining datasets provides improvements that are limited. However, we find that\nimprovements to computer vision architectures provide a promising path towards\nrobust models.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 17:56:30 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 16:32:28 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 01:30:54 GMT"}, {"version": "v4", "created": "Thu, 4 Mar 2021 21:56:19 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Hendrycks", "Dan", ""], ["Zhao", "Kevin", ""], ["Basart", "Steven", ""], ["Steinhardt", "Jacob", ""], ["Song", "Dawn", ""]]}, {"id": "1907.07181", "submitter": "Radha Nagarajan", "authors": "Radhakrishnan Nagarajan", "title": "Deciphering Dynamical Nonlinearities in Short Time Series Using\n  Recurrent Neural Networks", "comments": "18 pages, 7 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surrogate testing techniques have been used widely to investigate the\npresence of dynamical nonlinearities, an essential ingredient of deterministic\nchaotic processes. Traditional surrogate testing subscribes to statistical\nhypothesis testing and investigates potential differences in discriminant\nstatistics between the given empirical sample and its surrogate counterparts.\nThe choice and estimation of the discriminant statistics can be challenging\nacross short time series. Also, conclusion based on a single empirical sample\nis an inherent limitation. The present study proposes a recurrent neural\nnetwork classification framework that uses the raw time series obviating the\nneed for discriminant statistic while accommodating multiple time series\nrealizations for enhanced generalizability of the findings. The results are\ndemonstrated on short time series with lengths (L = 32, 64, 128) from\ncontinuous and discrete dynamical systems in chaotic regimes, nonlinear\ntransform of linearly correlated noise and experimental data. Accuracy of the\nclassifier is shown to be markedly higher than >> 50% for the processes in\nchaotic regimes whereas those of nonlinearly correlated noise were around ~50%\nsimilar to that of random guess from a one-sample binomial test. These results\nare promising and elucidate the usefulness of the proposed framework in\nidentifying potential dynamical nonlinearities from short experimental time\nseries.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 20:08:20 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Nagarajan", "Radhakrishnan", ""]]}, {"id": "1907.07207", "submitter": "Victor G. Turrisi Costa", "authors": "Victor G. Turrisi da Costa, Saulo Martiello Mastelini, Andr\\'e C.\n  Ponce de Leon Ferreira de Carvalho, Sylvio Barbon Jr", "title": "Online Local Boosting: improving performance in online decision trees", "comments": "To appear on the 8th Brazilian Conference on Intelligent Systems\n  (BRACIS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more data are produced each day, and faster, data stream mining is growing\nin importance, making clear the need for algorithms able to fast process these\ndata. Data stream mining algorithms are meant to be solutions to extract\nknowledge online, specially tailored from continuous data problem. Many of the\ncurrent algorithms for data stream mining have high processing and memory\ncosts. Often, the higher the predictive performance, the higher these costs. To\nincrease predictive performance without largely increasing memory and time\ncosts, this paper introduces a novel algorithm, named Online Local Boosting\n(OLBoost), which can be combined into online decision tree algorithms to\nimprove their predictive performance without modifying the structure of the\ninduced decision trees. For such, OLBoost applies a boosting to small separate\nregions of the instances space. Experimental results presented in this paper\nshow that by using OLBoost the online learning decision tree algorithms can\nsignificantly improve their predictive performance. Additionally, it can make\nsmaller trees perform as good or better than larger trees.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 18:26:45 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["da Costa", "Victor G. Turrisi", ""], ["Mastelini", "Saulo Martiello", ""], ["de Carvalho", "Andr\u00e9 C. Ponce de Leon Ferreira", ""], ["Barbon", "Sylvio", "Jr"]]}, {"id": "1907.07223", "submitter": "Vasileios Iosifidis", "authors": "Vasileios Iosifidis, Thi Ngoc Han Tran, Eirini Ntoutsi", "title": "Fairness-enhancing interventions in stream classification", "comments": "15 pages, 7 figures. To appear in the proceedings of 30th\n  International Conference on Database and Expert Systems Applications, Linz,\n  Austria August 26 - 29, 2019", "journal-ref": null, "doi": "10.1007/978-3-030-27615-7_20", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The wide spread usage of automated data-driven decision support systems has\nraised a lot of concerns regarding accountability and fairness of the employed\nmodels in the absence of human supervision. Existing fairness-aware approaches\ntackle fairness as a batch learning problem and aim at learning a fair model\nwhich can then be applied to future instances of the problem. In many\napplications, however, the data comes sequentially and its characteristics\nmight evolve with time. In such a setting, it is counter-intuitive to \"fix\" a\n(fair) model over the data stream as changes in the data might incur changes in\nthe underlying model therefore, affecting its fairness. In this work, we\npropose fairness-enhancing interventions that modify the input data so that the\noutcome of any stream classifier applied to that data will be fair. Experiments\non real and synthetic data show that our approach achieves good predictive\nperformance and low discrimination scores over the course of the stream.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 19:27:19 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Iosifidis", "Vasileios", ""], ["Tran", "Thi Ngoc Han", ""], ["Ntoutsi", "Eirini", ""]]}, {"id": "1907.07225", "submitter": "Keegan Hines E", "authors": "C. Bayan Bruss, Anish Khazane, Jonathan Rider, Richard Serpe, Antonia\n  Gogoglou, Keegan E. Hines", "title": "DeepTrax: Embedding Graphs of Financial Transactions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial transactions can be considered edges in a heterogeneous graph\nbetween entities sending money and entities receiving money. For financial\ninstitutions, such a graph is likely large (with millions or billions of edges)\nwhile also sparsely connected. It becomes challenging to apply machine learning\nto such large and sparse graphs. Graph representation learning seeks to embed\nthe nodes of a graph into a Euclidean vector space such that graph topological\nproperties are preserved after the transformation. In this paper, we present a\nnovel application of representation learning to bipartite graphs of credit card\ntransactions in order to learn embeddings of account and merchant entities. Our\nframework is inspired by popular approaches in graph embeddings and is trained\non two internal transaction datasets. This approach yields highly effective\nembeddings, as quantified by link prediction AUC and F1 score. Further, the\nresulting entity vectors retain intuitive semantic similarity that is explored\nthrough visualizations and other qualitative analyses. Finally, we show how\nthese embeddings can be used as features in downstream machine learning\nbusiness applications such as fraud detection.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 19:32:57 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Bruss", "C. Bayan", ""], ["Khazane", "Anish", ""], ["Rider", "Jonathan", ""], ["Serpe", "Richard", ""], ["Gogoglou", "Antonia", ""], ["Hines", "Keegan E.", ""]]}, {"id": "1907.07237", "submitter": "Wenbin Zhang", "authors": "Wenbin Zhang and Eirini Ntoutsi", "title": "FAHT: An Adaptive Fairness-aware Decision Tree Classifier", "comments": "Accepted to IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated data-driven decision-making systems are ubiquitous across a wide\nspread of online as well as offline services. These systems, depend on\nsophisticated learning algorithms and available data, to optimize the service\nfunction for decision support assistance. However, there is a growing concern\nabout the accountability and fairness of the employed models by the fact that\noften the available historic data is intrinsically discriminatory, i.e., the\nproportion of members sharing one or more sensitive attributes is higher than\nthe proportion in the population as a whole when receiving positive\nclassification, which leads to a lack of fairness in decision support system. A\nnumber of fairness-aware learning methods have been proposed to handle this\nconcern. However, these methods tackle fairness as a static problem and do not\ntake the evolution of the underlying stream population into consideration. In\nthis paper, we introduce a learning mechanism to design a fair classifier for\nonline stream based decision-making. Our learning model, FAHT (Fairness-Aware\nHoeffding Tree), is an extension of the well-known Hoeffding Tree algorithm for\ndecision tree induction over streams, that also accounts for fairness. Our\nexperiments show that our algorithm is able to deal with discrimination in\nstreaming environments, while maintaining a moderate predictive performance\nover the stream.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 20:00:41 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Zhang", "Wenbin", ""], ["Ntoutsi", "Eirini", ""]]}, {"id": "1907.07273", "submitter": "Zikang Xiong", "authors": "He Zhu, Zikang Xiong, Stephen Magill, Suresh Jagannathan", "title": "An Inductive Synthesis Framework for Verifiable Reinforcement Learning", "comments": "Published on PLDI 2019", "journal-ref": null, "doi": "10.1145/3314221.3314638", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the tremendous advances that have been made in the last decade on\ndeveloping useful machine-learning applications, their wider adoption has been\nhindered by the lack of strong assurance guarantees that can be made about\ntheir behavior. In this paper, we consider how formal verification techniques\ndeveloped for traditional software systems can be repurposed for verification\nof reinforcement learning-enabled ones, a particularly important class of\nmachine learning systems. Rather than enforcing safety by examining and\naltering the structure of a complex neural network implementation, our\ntechnique uses blackbox methods to synthesizes deterministic programs, simpler,\nmore interpretable, approximations of the network that can nonetheless\nguarantee desired safety properties are preserved, even when the network is\ndeployed in unanticipated or previously unobserved environments. Our\nmethodology frames the problem of neural network verification in terms of a\ncounterexample and syntax-guided inductive synthesis procedure over these\nprograms. The synthesis procedure searches for both a deterministic program and\nan inductive invariant over an infinite state transition system that represents\na specification of an application's control logic. Additional specifications\ndefining environment-based constraints can also be provided to further refine\nthe search space. Synthesized programs deployed in conjunction with a neural\nnetwork implementation dynamically enforce safety conditions by monitoring and\npreventing potentially unsafe actions proposed by neural policies. Experimental\nresults over a wide range of cyber-physical applications demonstrate that\nsoftware-inspired formal verification techniques can be used to realize\ntrustworthy reinforcement learning systems with low overhead.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 21:57:17 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Zhu", "He", ""], ["Xiong", "Zikang", ""], ["Magill", "Stephen", ""], ["Jagannathan", "Suresh", ""]]}, {"id": "1907.07287", "submitter": "Simon Guiroy", "authors": "Simon Guiroy, Vikas Verma, Christopher Pal", "title": "Towards Understanding Generalization in Gradient-Based Meta-Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study generalization of neural networks in gradient-based\nmeta-learning by analyzing various properties of the objective landscapes. We\nexperimentally demonstrate that as meta-training progresses, the meta-test\nsolutions, obtained after adapting the meta-train solution of the model, to new\ntasks via few steps of gradient-based fine-tuning, become flatter, lower in\nloss, and further away from the meta-train solution. We also show that those\nmeta-test solutions become flatter even as generalization starts to degrade,\nthus providing an experimental evidence against the correlation between\ngeneralization and flat minima in the paradigm of gradient-based meta-leaning.\nFurthermore, we provide empirical evidence that generalization to new tasks is\ncorrelated with the coherence between their adaptation trajectories in\nparameter space, measured by the average cosine similarity between\ntask-specific trajectory directions, starting from a same meta-train solution.\nWe also show that coherence of meta-test gradients, measured by the average\ninner product between the task-specific gradient vectors evaluated at\nmeta-train solution, is also correlated with generalization. Based on these\nobservations, we propose a novel regularizer for MAML and provide experimental\nevidence for its effectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 23:22:14 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Guiroy", "Simon", ""], ["Verma", "Vikas", ""], ["Pal", "Christopher", ""]]}, {"id": "1907.07291", "submitter": "Arif Siddiqi", "authors": "Arif Siddiqi", "title": "Adversarial Security Attacks and Perturbations on Machine Learning and\n  Deep Learning Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ever-growing big data and emerging artificial intelligence (AI) demand\nthe use of machine learning (ML) and deep learning (DL) methods. Cybersecurity\nalso benefits from ML and DL methods for various types of applications. These\nmethods however are susceptible to security attacks. The adversaries can\nexploit the training and testing data of the learning models or can explore the\nworkings of those models for launching advanced future attacks. The topic of\nadversarial security attacks and perturbations within the ML and DL domains is\na recent exploration and a great interest is expressed by the security\nresearchers and practitioners. The literature covers different adversarial\nsecurity attacks and perturbations on ML and DL methods and those have their\nown presentation styles and merits. A need to review and consolidate knowledge\nthat is comprehending of this increasingly focused and growing topic of\nresearch; however, is the current demand of the research communities. In this\nreview paper, we specifically aim to target new researchers in the\ncybersecurity domain who may seek to acquire some basic knowledge on the\nmachine learning and deep learning models and algorithms, as well as some of\nthe relevant adversarial security attacks and perturbations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 00:00:07 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Siddiqi", "Arif", ""]]}, {"id": "1907.07307", "submitter": "Bradley Sturt", "authors": "Dimitris Bertsimas, Christopher McCord, Bradley Sturt", "title": "Dynamic optimization with side information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a tractable and flexible approach for incorporating side\ninformation into dynamic optimization under uncertainty. The proposed framework\nuses predictive machine learning methods (such as $k$-nearest neighbors, kernel\nregression, and random forests) to weight the relative importance of various\ndata-driven uncertainty sets in a robust optimization formulation. Through a\nnovel measure concentration result for a class of machine learning methods, we\nprove that the proposed approach is asymptotically optimal for multi-period\nstochastic programming with side information. We also describe a\ngeneral-purpose approximation for these optimization problems, based on\noverlapping linear decision rules, which is computationally tractable and\nproduces high-quality solutions for dynamic problems with many stages. Across a\nvariety of examples in inventory management, finance, and shipment planning,\nour method achieves improvements of up to 15\\% over alternatives and requires\nless than one minute of computation time on problems with twelve stages.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 02:38:37 GMT"}, {"version": "v2", "created": "Tue, 21 Jul 2020 22:54:55 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["McCord", "Christopher", ""], ["Sturt", "Bradley", ""]]}, {"id": "1907.07321", "submitter": "Ziyu Ye", "authors": "Ziyu Ye, Andrew Gilman, Qihang Peng, Kelly Levick, Pamela Cosman,\n  Larry Milstein", "title": "Comparison of Neural Network Architectures for Spectrum Sensing", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different neural network (NN) architectures have different advantages.\nConvolutional neural networks (CNNs) achieved enormous success in computer\nvision, while recurrent neural networks (RNNs) gained popularity in speech\nrecognition. It is not known which type of NN architecture is the best fit for\nclassification of communication signals. In this work, we compare the behavior\nof fully-connected NN (FC), CNN, RNN, and bi-directional RNN (BiRNN) in a\nspectrum sensing task. The four NN architectures are compared on their\ndetection performance, requirement of training data, computational complexity,\nand memory requirement. Given abundant training data and computational and\nmemory resources, CNN, RNN, and BiRNN are shown to achieve similar performance.\nThe performance of FC is worse than that of the other three types, except in\nthe case where computational complexity is stringently limited.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 21:24:31 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Ye", "Ziyu", ""], ["Gilman", "Andrew", ""], ["Peng", "Qihang", ""], ["Levick", "Kelly", ""], ["Cosman", "Pamela", ""], ["Milstein", "Larry", ""]]}, {"id": "1907.07326", "submitter": "Ziyu Ye", "authors": "Ziyu Ye, Qihang Peng, Kelly Levick, Hui Rong, Andrew Gilman, Pamela\n  Cosman, Larry Milstein", "title": "A Neural Network Detector for Spectrum Sensing under Uncertainties", "comments": "6 pages, 4 figures, submitted to ICNC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectrum sensing is of critical importance in any cognitive radio system.\nWhen the primary user's signal has uncertain parameters, the likelihood ratio\ntest, which is the theoretically optimal detector, generally has no closed-form\nexpression. As a result, spectrum sensing under parameter uncertainty remains\nan open question, though many detectors exploiting specific features of a\nprimary signal have been proposed and have achieved reasonably good\nperformance. In this paper, a neural network is trained as a detector for\nmodulated signals. The result shows by training on an appropriate dataset, the\nneural network gains robustness under uncertainties in system parameters\nincluding the carrier frequency offset, carrier phase offset, and symbol time\noffset. The result displays the neural network's potential in exploiting\nimplicit and incomplete knowledge about the signal's structure.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 21:13:19 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 04:29:52 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Ye", "Ziyu", ""], ["Peng", "Qihang", ""], ["Levick", "Kelly", ""], ["Rong", "Hui", ""], ["Gilman", "Andrew", ""], ["Cosman", "Pamela", ""], ["Milstein", "Larry", ""]]}, {"id": "1907.07327", "submitter": "Ross Harper", "authors": "Ross Harper and Joshua Southern", "title": "End-To-End Prediction of Emotion From Heartbeat Data Collected by a\n  Consumer Fitness Tracker", "comments": "7 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic detection of emotion has the potential to revolutionize mental\nhealth and wellbeing. Recent work has been successful in predicting affect from\nunimodal electrocardiogram (ECG) data. However, to be immediately relevant for\nreal-world applications, physiology-based emotion detection must make use of\nubiquitous photoplethysmogram (PPG) data collected by affordable consumer\nfitness trackers. Additionally, applications of emotion detection in healthcare\nsettings will require some measure of uncertainty over model predictions. We\npresent here a Bayesian deep learning model for end-to-end classification of\nemotional valence, using only the unimodal heartbeat time series collected by a\nconsumer fitness tracker (Garmin V\\'ivosmart 3). We collected a new dataset for\nthis task, and report a peak F1 score of 0.7. This demonstrates a practical\nrelevance of physiology-based emotion detection `in the wild' today.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 09:24:23 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Harper", "Ross", ""], ["Southern", "Joshua", ""]]}, {"id": "1907.07330", "submitter": "Jessica Finocchiaro", "authors": "Jessie Finocchiaro, Rafael Frongillo, Bo Waggoner", "title": "An Embedding Framework for Consistent Polyhedral Surrogates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize and study the natural approach of designing convex surrogate\nloss functions via embeddings for problems such as classification or ranking.\nIn this approach, one embeds each of the finitely many predictions (e.g.\nclasses) as a point in R^d, assigns the original loss values to these points,\nand convexifies the loss in between to obtain a surrogate. We prove that this\napproach is equivalent, in a strong sense, to working with polyhedral\n(piecewise linear convex) losses. Moreover, given any polyhedral loss $L$, we\ngive a construction of a link function through which $L$ is a consistent\nsurrogate for the loss it embeds. We go on to illustrate the power of this\nembedding framework with succinct proofs of consistency or inconsistency of\nvarious polyhedral surrogates in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 04:43:36 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Finocchiaro", "Jessie", ""], ["Frongillo", "Rafael", ""], ["Waggoner", "Bo", ""]]}, {"id": "1907.07331", "submitter": "Tailin Wu", "authors": "Tailin Wu, Ian Fischer, Isaac L. Chuang, Max Tegmark", "title": "Learnability for the Information Bottleneck", "comments": "Accepted at UAI 2019", "journal-ref": null, "doi": "10.3390/e21100924", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Information Bottleneck (IB) method (\\cite{tishby2000information})\nprovides an insightful and principled approach for balancing compression and\nprediction for representation learning. The IB objective $I(X;Z)-\\beta I(Y;Z)$\nemploys a Lagrange multiplier $\\beta$ to tune this trade-off. However, in\npractice, not only is $\\beta$ chosen empirically without theoretical guidance,\nthere is also a lack of theoretical understanding between $\\beta$,\nlearnability, the intrinsic nature of the dataset and model capacity. In this\npaper, we show that if $\\beta$ is improperly chosen, learning cannot happen --\nthe trivial representation $P(Z|X)=P(Z)$ becomes the global minimum of the IB\nobjective. We show how this can be avoided, by identifying a sharp phase\ntransition between the unlearnable and the learnable which arises as $\\beta$ is\nvaried. This phase transition defines the concept of IB-Learnability. We prove\nseveral sufficient conditions for IB-Learnability, which provides theoretical\nguidance for choosing a good $\\beta$. We further show that IB-learnability is\ndetermined by the largest confident, typical, and imbalanced subset of the\nexamples (the conspicuous subset), and discuss its relation with model\ncapacity. We give practical algorithms to estimate the minimum $\\beta$ for a\ngiven dataset. We also empirically demonstrate our theoretical conditions with\nanalyses of synthetic datasets, MNIST, and CIFAR10.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 04:48:01 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Wu", "Tailin", ""], ["Fischer", "Ian", ""], ["Chuang", "Isaac L.", ""], ["Tegmark", "Max", ""]]}, {"id": "1907.07346", "submitter": "Hanlin Tang", "authors": "Hanlin Tang, Xiangru Lian, Shuang Qiu, Lei Yuan, Ce Zhang, Tong Zhang,\n  Ji Liu", "title": "$\\texttt{DeepSqueeze}$: Decentralization Meets Error-Compensated\n  Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication is a key bottleneck in distributed training. Recently, an\n\\emph{error-compensated} compression technology was particularly designed for\nthe \\emph{centralized} learning and receives huge successes, by showing\nsignificant advantages over state-of-the-art compression based methods in\nsaving the communication cost. Since the \\emph{decentralized} training has been\nwitnessed to be superior to the traditional \\emph{centralized} training in the\ncommunication restricted scenario, therefore a natural question to ask is \"how\nto apply the error-compensated technology to the decentralized learning to\nfurther reduce the communication cost.\" However, a trivial extension of\ncompression based centralized training algorithms does not exist for the\ndecentralized scenario. key difference between centralized and decentralized\ntraining makes this extension extremely non-trivial. In this paper, we propose\nan elegant algorithmic design to employ error-compensated stochastic gradient\ndescent for the decentralized scenario, named $\\texttt{DeepSqueeze}$. Both the\ntheoretical analysis and the empirical study are provided to show the proposed\n$\\texttt{DeepSqueeze}$ algorithm outperforms the existing compression based\ndecentralized learning algorithms. To the best of our knowledge, this is the\nfirst time to apply the error-compensated compression to the decentralized\nlearning.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 05:59:31 GMT"}, {"version": "v2", "created": "Sat, 3 Aug 2019 15:20:38 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Tang", "Hanlin", ""], ["Lian", "Xiangru", ""], ["Qiu", "Shuang", ""], ["Yuan", "Lei", ""], ["Zhang", "Ce", ""], ["Zhang", "Tong", ""], ["Liu", "Ji", ""]]}, {"id": "1907.07384", "submitter": "Mario Beraha", "authors": "Mario Beraha, Alberto Maria Metelli, Matteo Papini, Andrea Tirinzoni\n  and Marcello Restelli", "title": "Feature Selection via Mutual Information: New Theoretical Insights", "comments": "Accepted for presentation at the International Joint Conference on\n  Neural Networks (IJCNN) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual information has been successfully adopted in filter feature-selection\nmethods to assess both the relevancy of a subset of features in predicting the\ntarget variable and the redundancy with respect to other variables. However,\nexisting algorithms are mostly heuristic and do not offer any guarantee on the\nproposed solution. In this paper, we provide novel theoretical results showing\nthat conditional mutual information naturally arises when bounding the ideal\nregression/classification errors achieved by different subsets of features.\nLeveraging on these insights, we propose a novel stopping condition for\nbackward and forward greedy methods which ensures that the ideal prediction\nerror using the selected feature subset remains bounded by a user-specified\nthreshold. We provide numerical simulations to support our theoretical claims\nand compare to common heuristic methods.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 08:36:27 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Beraha", "Mario", ""], ["Metelli", "Alberto Maria", ""], ["Papini", "Matteo", ""], ["Tirinzoni", "Andrea", ""], ["Restelli", "Marcello", ""]]}, {"id": "1907.07410", "submitter": "P B Mr", "authors": "Prasad Bhavana, Vikas Kumar, Vineet Padmanabhan", "title": "Block based Singular Value Decomposition approach to matrix\n  factorization for recommender systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the abundance of data in recent years, interesting challenges are posed\nin the area of recommender systems. Producing high quality recommendations with\nscalability and performance is the need of the hour. Singular Value\nDecomposition(SVD) based recommendation algorithms have been leveraged to\nproduce better results. In this paper, we extend the SVD technique further for\nscalability and performance in the context of 1) multi-threading 2) multiple\ncomputational units (with the use of Graphical Processing Units) and 3)\ndistributed computation. We propose block based matrix factorization (BMF)\npaired with SVD. This enabled us to take advantage of SVD over basic matrix\nfactorization(MF) while taking advantage of parallelism and scalability through\nBMF. We used Compute Unified Device Architecture (CUDA) platform and related\nhardware for leveraging Graphical Processing Unit (GPU) along with block based\nSVD to demonstrate the advantages in terms of performance and memory.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 09:35:56 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Bhavana", "Prasad", ""], ["Kumar", "Vikas", ""], ["Padmanabhan", "Vineet", ""]]}, {"id": "1907.07442", "submitter": "Yiming Li", "authors": "Yiming Li, Yang Zhang, Qingtao Tang, Weipeng Huang, Yong Jiang,\n  Shu-Tao Xia", "title": "$t$-$k$-means: A Robust and Stable $k$-means Variant", "comments": "Accepted by the ICASSP 2021. The first two authors contributed\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $k$-means algorithm is one of the most classical clustering methods, which\nhas been widely and successfully used in signal processing. However, due to the\nthin-tailed property of the Gaussian distribution, $k$-means algorithm suffers\nfrom relatively poor performance on the dataset containing heavy-tailed data or\noutliers. Besides, standard $k$-means algorithm also has relatively weak\nstability, $i.e.$ its results have a large variance, which reduces its\ncredibility. In this paper, we propose a robust and stable $k$-means variant,\ndubbed the $t$-$k$-means, as well as its fast version to alleviate those\nproblems. Theoretically, we derive the $t$-$k$-means and analyze its robustness\nand stability from the aspect of the loss function and the expression of the\nclustering center, respectively. Extensive experiments are also conducted,\nwhich verify the effectiveness and efficiency of the proposed method. The code\nfor reproducing main results is available at\n\\url{https://github.com/THUYimingLi/t-k-means}.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 11:19:00 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 04:32:48 GMT"}, {"version": "v3", "created": "Thu, 24 Sep 2020 16:05:12 GMT"}, {"version": "v4", "created": "Sun, 31 Jan 2021 15:00:58 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Li", "Yiming", ""], ["Zhang", "Yang", ""], ["Tang", "Qingtao", ""], ["Huang", "Weipeng", ""], ["Jiang", "Yong", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "1907.07464", "submitter": "Moritz Kulessa", "authors": "Moritz Kulessa, Eneldo Loza Menc\\'ia, Johannes F\\\"urnkranz", "title": "Improving Outbreak Detection with Stacking of Statistical Surveillance\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epidemiologists use a variety of statistical algorithms for the early\ndetection of outbreaks. The practical usefulness of such methods highly depends\non the trade-off between the detection rate of outbreaks and the chances of\nraising a false alarm. Recent research has shown that the use of machine\nlearning for the fusion of multiple statistical algorithms improves outbreak\ndetection. Instead of relying only on the binary output (alarm or no alarm) of\nthe statistical algorithms, we propose to make use of their p-values for\ntraining a fusion classifier. In addition, we also show that adding additional\nfeatures and adapting the labeling of an epidemic period may further improve\nperformance. For comparison and evaluation, a new measure is introduced which\ncaptures the performance of an outbreak detection method with respect to a low\nrate of false alarms more precisely than previous works. Our results on\nsynthetic data show that it is challenging to improve the performance with a\ntrainable fusion method based on machine learning. In particular, the use of a\nfusion classifier that is only based on binary outputs of the statistical\nsurveillance methods can make the overall performance worse than directly using\nthe underlying algorithms. However, the use of p-values and additional\ninformation for the learning is promising, enabling to identify more valuable\npatterns to detect outbreaks.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 12:04:46 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Kulessa", "Moritz", ""], ["Menc\u00eda", "Eneldo Loza", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1907.07480", "submitter": "Paulo Roberto de Oliveira da Costa", "authors": "Paulo R. de O. da Costa, Alp Akcay, Yingqian Zhang, Uzay Kaymak", "title": "Remaining Useful Lifetime Prediction via Deep Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Prognostics and Health Management (PHM) sufficient prior observed\ndegradation data is usually critical for Remaining Useful Lifetime (RUL)\nprediction. Most previous data-driven prediction methods assume that training\n(source) and testing (target) condition monitoring data have similar\ndistributions. However, due to different operating conditions, fault modes,\nnoise and equipment updates distribution shift exists across different data\ndomains. This shift reduces the performance of predictive models previously\nbuilt to specific conditions when no observed run-to-failure data is available\nfor retraining. To address this issue, this paper proposes a new data-driven\napproach for domain adaptation in prognostics using Long Short-Term Neural\nNetworks (LSTM). We use a time window approach to extract temporal information\nfrom time-series data in a source domain with observed RUL values and a target\ndomain containing only sensor information. We propose a Domain Adversarial\nNeural Network (DANN) approach to learn domain-invariant features that can be\nused to predict the RUL in the target domain. The experimental results show\nthat the proposed method can provide more reliable RUL predictions under\ndatasets with different operating conditions and fault modes. These results\nsuggest that the proposed method offers a promising approach to performing\ndomain adaptation in practical PHM applications.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 12:44:04 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["da Costa", "Paulo R. de O.", ""], ["Akcay", "Alp", ""], ["Zhang", "Yingqian", ""], ["Kaymak", "Uzay", ""]]}, {"id": "1907.07484", "submitter": "Robert Geirhos", "authors": "Claudio Michaelis, Benjamin Mitzkus, Robert Geirhos, Evgenia Rusak,\n  Oliver Bringmann, Alexander S. Ecker, Matthias Bethge, Wieland Brendel", "title": "Benchmarking Robustness in Object Detection: Autonomous Driving when\n  Winter is Coming", "comments": "21 pages, 10 figures, 1 dragon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to detect objects regardless of image distortions or weather\nconditions is crucial for real-world applications of deep learning like\nautonomous driving. We here provide an easy-to-use benchmark to assess how\nobject detection models perform when image quality degrades. The three\nresulting benchmark datasets, termed Pascal-C, Coco-C and Cityscapes-C, contain\na large variety of image corruptions. We show that a range of standard object\ndetection models suffer a severe performance loss on corrupted images (down to\n30--60\\% of the original performance). However, a simple data augmentation\ntrick---stylizing the training images---leads to a substantial increase in\nrobustness across corruption type, severity and dataset. We envision our\ncomprehensive benchmark to track future progress towards building robust object\ndetection models. Benchmark, code and data are publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 12:51:10 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 08:42:46 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Michaelis", "Claudio", ""], ["Mitzkus", "Benjamin", ""], ["Geirhos", "Robert", ""], ["Rusak", "Evgenia", ""], ["Bringmann", "Oliver", ""], ["Ecker", "Alexander S.", ""], ["Bethge", "Matthias", ""], ["Brendel", "Wieland", ""]]}, {"id": "1907.07496", "submitter": "Martin Maritsch", "authors": "Martin Maritsch, Caterina B\\'erub\\'e, Mathias Kraus, Vera Lehmann,\n  Thomas Z\\\"uger, Stefan Feuerriegel, Tobias Kowatsch, Felix Wortmann", "title": "Improving Heart Rate Variability Measurements from Consumer Smartwatches\n  with Machine Learning", "comments": "Adjunct Proceedings of the 2019 ACM International Joint Conference on\n  Pervasive and Ubiquitous Computing and the 2019 International Symposium on\n  Wearable Computers", "journal-ref": null, "doi": "10.1145/3341162.3346276", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reactions of the human body to physical exercise, psychophysiological\nstress and heart diseases are reflected in heart rate variability (HRV). Thus,\ncontinuous monitoring of HRV can contribute to determining and predicting\nissues in well-being and mental health. HRV can be measured in everyday life by\nconsumer wearable devices such as smartwatches which are easily accessible and\naffordable. However, they are arguably accurate due to the stability of the\nsensor. We hypothesize a systematic error which is related to the wearer\nmovement. Our evidence builds upon explanatory and predictive modeling: we find\na statistically significant correlation between error in HRV measurements and\nthe wearer movement. We show that this error can be minimized by bringing into\ncontext additional available sensor information, such as accelerometer data.\nThis work demonstrates our research-in-progress on how neural learning can\nminimize the error of such smartwatch HRV measurements.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 13:16:57 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Maritsch", "Martin", ""], ["B\u00e9rub\u00e9", "Caterina", ""], ["Kraus", "Mathias", ""], ["Lehmann", "Vera", ""], ["Z\u00fcger", "Thomas", ""], ["Feuerriegel", "Stefan", ""], ["Kowatsch", "Tobias", ""], ["Wortmann", "Felix", ""]]}, {"id": "1907.07502", "submitter": "Cynthia Rush", "authors": "Zhiqi Bu, Jason Klusowski, Cynthia Rush, Weijie Su", "title": "Algorithmic Analysis and Statistical Estimation of SLOPE via Approximate\n  Message Passing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SLOPE is a relatively new convex optimization procedure for high-dimensional\nlinear regression via the sorted l1 penalty: the larger the rank of the fitted\ncoefficient, the larger the penalty. This non-separable penalty renders many\nexisting techniques invalid or inconclusive in analyzing the SLOPE solution. In\nthis paper, we develop an asymptotically exact characterization of the SLOPE\nsolution under Gaussian random designs through solving the SLOPE problem using\napproximate message passing (AMP). This algorithmic approach allows us to\napproximate the SLOPE solution via the much more amenable AMP iterates.\nExplicitly, we characterize the asymptotic dynamics of the AMP iterates relying\non a recently developed state evolution analysis for non-separable penalties,\nthereby overcoming the difficulty caused by the sorted l1 penalty. Moreover, we\nprove that the AMP iterates converge to the SLOPE solution in an asymptotic\nsense, and numerical simulations show that the convergence is surprisingly\nfast. Our proof rests on a novel technique that specifically leverages the\nSLOPE problem. In contrast to prior literature, our work not only yields an\nasymptotically sharp analysis but also offers an algorithmic, flexible, and\nconstructive approach to understanding the SLOPE problem.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 13:21:51 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Bu", "Zhiqi", ""], ["Klusowski", "Jason", ""], ["Rush", "Cynthia", ""], ["Su", "Weijie", ""]]}, {"id": "1907.07504", "submitter": "Andrew Wilson", "authors": "Pavel Izmailov, Wesley J. Maddox, Polina Kirichenko, Timur Garipov,\n  Dmitry Vetrov, Andrew Gordon Wilson", "title": "Subspace Inference for Bayesian Deep Learning", "comments": "Published at UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference was once a gold standard for learning with neural\nnetworks, providing accurate full predictive distributions and well calibrated\nuncertainty. However, scaling Bayesian inference techniques to deep neural\nnetworks is challenging due to the high dimensionality of the parameter space.\nIn this paper, we construct low-dimensional subspaces of parameter space, such\nas the first principal components of the stochastic gradient descent (SGD)\ntrajectory, which contain diverse sets of high performing models. In these\nsubspaces, we are able to apply elliptical slice sampling and variational\ninference, which struggle in the full parameter space. We show that Bayesian\nmodel averaging over the induced posterior in these subspaces produces accurate\npredictions and well calibrated predictive uncertainty for both regression and\nimage classification.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 13:26:07 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Izmailov", "Pavel", ""], ["Maddox", "Wesley J.", ""], ["Kirichenko", "Polina", ""], ["Garipov", "Timur", ""], ["Vetrov", "Dmitry", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1907.07514", "submitter": "Peter Cotton", "authors": "Peter Cotton", "title": "Self Organizing Supply Chains for Micro-Prediction: Present and Future\n  uses of the ROAR Protocol", "comments": "Thirty-sixth International Conference on Machine Learning Workshop on\n  AI in Finance: Applications and Infrastructure for Multi-Agent Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CY q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multi-agent system is trialed as a means of crowd-sourcing inexpensive but\nhigh quality streams of predictions. Each agent is a microservice embodying\nstatistical models and endowed with economic self-interest. The ability to fork\nand modify simple agents is granted to a large number of employees in a firm\nand empirical lessons are reported. We suggest that one plausible trajectory\nfor this project is the creation of a Prediction Web.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 13:40:15 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Cotton", "Peter", ""]]}, {"id": "1907.07523", "submitter": "Anne Sabourin", "authors": "Ma\\\"el Chiapino (LTCI), St\\'ephan Cl\\'emen\\c{c}on (LTCI), Vincent\n  Feuillard, Anne Sabourin (LTCI)", "title": "A Multivariate Extreme Value Theory Approach to Anomaly Clustering and\n  Visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a wide variety of situations, anomalies in the behaviour of a complex\nsystem, whose health is monitored through the observation of a random vector X\n= (X1,. .. , X d) valued in R d , correspond to the simultaneous occurrence of\nextreme values for certain subgroups $\\alpha$ $\\subset$ {1,. .. , d} of\nvariables Xj. Under the heavy-tail assumption, which is precisely appropriate\nfor modeling these phenomena, statistical methods relying on multivariate\nextreme value theory have been developed in the past few years for identifying\nsuch events/subgroups. This paper exploits this approach much further by means\nof a novel mixture model that permits to describe the distribution of extremal\nobservations and where the anomaly type $\\alpha$ is viewed as a latent\nvariable. One may then take advantage of the model by assigning to any extreme\npoint a posterior probability for each anomaly type $\\alpha$, defining\nimplicitly a similarity measure between anomalies. It is explained at length\nhow the latter permits to cluster extreme observations and obtain an\ninformative planar representation of anomalies using standard graph-mining\ntools. The relevance and usefulness of the clustering and 2-d visual display\nthus designed is illustrated on simulated datasets and on real observations as\nwell, in the aeronautics application domain.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 13:48:58 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Chiapino", "Ma\u00ebl", "", "LTCI"], ["Cl\u00e9men\u00e7on", "St\u00e9phan", "", "LTCI"], ["Feuillard", "Vincent", "", "LTCI"], ["Sabourin", "Anne", "", "LTCI"]]}, {"id": "1907.07543", "submitter": "Peter Usherwood", "authors": "Peter Usherwood and Steven Smit", "title": "Low-Shot Classification: A Comparison of Classical and Deep Transfer\n  Machine Learning Approaches", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the recent success of deep transfer learning approaches in NLP, there\nis a lack of quantitative studies demonstrating the gains these models offer in\nlow-shot text classification tasks over existing paradigms. Deep transfer\nlearning approaches such as BERT and ULMFiT demonstrate that they can beat\nstate-of-the-art results on larger datasets, however when one has only 100-1000\nlabelled examples per class, the choice of approach is less clear, with\nclassical machine learning and deep transfer learning representing valid\noptions. This paper compares the current best transfer learning approach with\ntop classical machine learning approaches on a trinary sentiment classification\ntask to assess the best paradigm. We find that BERT, representing the best of\ndeep transfer learning, is the best performing approach, outperforming top\nclassical machine learning algorithms by 9.7% on average when trained with 100\nexamples per class, narrowing to 1.8% at 1000 labels per class. We also show\nthe robustness of deep transfer learning in moving across domains, where the\nmaximum loss in accuracy is only 0.7% in similar domain tasks and 3.2% cross\ndomain, compared to classical machine learning which loses up to 20.6%.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 14:23:15 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Usherwood", "Peter", ""], ["Smit", "Steven", ""]]}, {"id": "1907.07552", "submitter": "Themistoklis Sapsis", "authors": "Themistoklis P. Sapsis", "title": "Output-weighted optimal sampling for Bayesian regression and rare event\n  statistics using few samples", "comments": "34 pages; 13 figures", "journal-ref": null, "doi": "10.1098/rspa.2019.0834", "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many important problems the quantity of interest is an unknown function\nof the parameters, which is a random vector with known statistics. Since the\ndependence of the output on this random vector is unknown, the challenge is to\nidentify its statistics, using the minimum number of function evaluations. This\nproblem can been seen in the context of active learning or optimal experimental\ndesign. We employ Bayesian regression to represent the derived model\nuncertainty due to finite and small number of input-output pairs. In this\ncontext we evaluate existing methods for optimal sample selection, such as\nmodel error minimization and mutual information maximization. We show that for\nthe case of known output variance, the commonly employed criteria in the\nliterature do not take into account the output values of the existing\ninput-output pairs, while for the case of unknown output variance this\ndependence can be very weak. We introduce a criterion that takes into account\nthe values of the output for the existing samples and adaptively selects inputs\nfrom regions of the parameter space which have important contribution to the\noutput. The new method allows for application to high-dimensional inputs,\npaving the way for optimal experimental design in high-dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 14:51:11 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 16:14:43 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Sapsis", "Themistoklis P.", ""]]}, {"id": "1907.07561", "submitter": "Qiang Zhang", "authors": "Qiang Zhang, Aldo Lipani, Omer Kirnap, Emine Yilmaz", "title": "Self-Attentive Hawkes Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchronous events on the continuous time domain, e.g., social media actions\nand stock transactions, occur frequently in the world. The ability to recognize\noccurrence patterns of event sequences is crucial to predict which typeof\nevents will happen next and when. A de facto standard mathematical framework to\ndo this is the Hawkes process. In order to enhance expressivity of multivariate\nHawkes processes, conventional statistical methods and deep recurrent networks\nhave been employed to modify its intensity function. The former is highly\ninterpretable and requires small size of training data but relies on correct\nmodel design while the latter has less dependency on prior knowledge and is\nmore powerful in capturing complicated patterns. We leverage pros and cons of\nthese models and propose a self-attentive Hawkes process(SAHP). The proposed\nmethod adapts self-attention to fit the intensity function of Hawkes processes.\nThis design has two benefits:(1) compared with conventional statistical\nmethods, the SAHP is more powerful to identify complicated dependency\nrelationships between temporal events; (2)compared with deep recurrent\nnetworks, the self-attention mechanism is able to capture longer historical\ninformation, and is more interpretable because the learnt attention weight\ntensor shows contributions of each historical event. Experiments on four\nreal-world datasets demonstrate the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 15:02:15 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 17:36:25 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Zhang", "Qiang", ""], ["Lipani", "Aldo", ""], ["Kirnap", "Omer", ""], ["Yilmaz", "Emine", ""]]}, {"id": "1907.07564", "submitter": "Nishchay Sharma", "authors": "Madan Gopal Jhawar, Vipindeep Vangala, Nishchay Sharma, Ankur\n  Hayatnagarkar, Mansi Saxena, Swati Valecha", "title": "Conversational Help for Task Completion and Feature Discovery in\n  Personal Assistants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.LG cs.SD eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Intelligent Personal Assistants (IPAs) have become widely popular in recent\ntimes. Most of the commercial IPAs today support a wide range of skills\nincluding Alarms, Reminders, Weather Updates, Music, News, Factual\nQuestioning-Answering, etc. The list grows every day, making it difficult to\nremember the command structures needed to execute various tasks. An IPA must\nhave the ability to communicate information about supported skills and direct\nusers towards the right commands needed to execute them. Users interact with\npersonal assistants in natural language. A query is defined to be a Help Query\nif it seeks information about a personal assistant's capabilities, or asks for\ninstructions to execute a task. In this paper, we propose an interactive system\nwhich identifies help queries and retrieves appropriate responses. Our system\ncomprises of a C-BiLSTM based classifier, which is a fusion of Convolutional\nNeural Networks (CNN) and Bidirectional LSTM (BiLSTM) architectures, to detect\nhelp queries and a semantic Approximate Nearest Neighbours (ANN) module to map\nthe query to an appropriate predefined response. Evaluation of our system on\nreal-world queries from a commercial IPA and a detailed comparison with popular\ntraditional machine learning and deep learning based models reveal that our\nsystem outperforms other approaches and returns relevant responses for help\nqueries.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 09:25:13 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Jhawar", "Madan Gopal", ""], ["Vangala", "Vipindeep", ""], ["Sharma", "Nishchay", ""], ["Hayatnagarkar", "Ankur", ""], ["Saxena", "Mansi", ""], ["Valecha", "Swati", ""]]}, {"id": "1907.07573", "submitter": "Ankit Gupta", "authors": "Ankit Gupta, Elliott Ruebush", "title": "AquaSight: Automatic Water Impurity Detection Utilizing Convolutional\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the United Nations World Water Assessment Programme, every day,\n2 million tons of sewage and industrial and agricultural waste are discharged\ninto the worlds water. In order to address this pervasive issue of increasing\nwater pollution, while ensuring that the global population has an efficient,\naccurate, and low cost method to assess whether the water they drink is\ncontaminated, we propose AquaSight, a novel mobile application that utilizes\ndeep learning methods, specifically Convolutional Neural Networks, for\nautomated water impurity detection. After comprehensive training with a dataset\nof 105 images representing varying magnitudes of contamination, the deep\nlearning algorithm achieved a 96 percent accuracy and loss of 0.108.\nFurthermore, the machine learning model uses efficient analysis of the\nturbidity and transparency levels of water to estimate a particular sample of\nwaters level of contamination. When deployed, the AquaSight system will provide\nan efficient way for individuals to secure an estimation of water quality,\nalerting local and national government to take action and potentially saving\nmillions of lives worldwide.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 15:17:21 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Gupta", "Ankit", ""], ["Ruebush", "Elliott", ""]]}, {"id": "1907.07578", "submitter": "Enrico Maria Malatesta", "authors": "Carlo Baldassi, Enrico M. Malatesta, Riccardo Zecchina", "title": "Properties of the geometry of solutions and capacity of multi-layer\n  neural networks with Rectified Linear Units activations", "comments": "11 pages, 3 figures", "journal-ref": "Phys. Rev. Lett. 123, 170602 (2019)", "doi": "10.1103/PhysRevLett.123.170602", "report-no": null, "categories": "cond-mat.dis-nn cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rectified Linear Units (ReLU) have become the main model for the neural units\nin current deep learning systems. This choice has been originally suggested as\na way to compensate for the so called vanishing gradient problem which can\nundercut stochastic gradient descent (SGD) learning in networks composed of\nmultiple layers. Here we provide analytical results on the effects of ReLUs on\nthe capacity and on the geometrical landscape of the solution space in\ntwo-layer neural networks with either binary or real-valued weights. We study\nthe problem of storing an extensive number of random patterns and find that,\nquite unexpectedly, the capacity of the network remains finite as the number of\nneurons in the hidden layer increases, at odds with the case of threshold units\nin which the capacity diverges. Possibly more important, a large deviation\napproach allows us to find that the geometrical landscape of the solution space\nhas a peculiar structure: while the majority of solutions are close in distance\nbut still isolated, there exist rare regions of solutions which are much more\ndense than the similar ones in the case of threshold units. These solutions are\nrobust to perturbations of the weights and can tolerate large perturbations of\nthe inputs. The analytical results are corroborated by numerical findings.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 15:23:17 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 00:20:26 GMT"}, {"version": "v3", "created": "Sat, 21 Sep 2019 15:45:35 GMT"}, {"version": "v4", "created": "Wed, 23 Oct 2019 16:10:41 GMT"}, {"version": "v5", "created": "Thu, 30 Jul 2020 10:52:05 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Baldassi", "Carlo", ""], ["Malatesta", "Enrico M.", ""], ["Zecchina", "Riccardo", ""]]}, {"id": "1907.07580", "submitter": "Juan M. Morales Dr.", "authors": "Miguel \\'A. Mu\\~noz, Juan M. Morales and Salvador Pineda", "title": "Feature-driven Improvement of Renewable Energy Forecasting and Trading", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired from recent insights into the common ground of machine learning,\noptimization and decision-making, this paper proposes an easy-to-implement, but\neffective procedure to enhance both the quality of renewable energy forecasts\nand the competitive edge of renewable energy producers in electricity markets\nwith a dual-price settlement of imbalances. The quality and economic gains\nbrought by the proposed procedure essentially stem from the utilization of\nvaluable predictors (also known as features) in a data-driven newsvendor model\nthat renders a computationally inexpensive linear program. We illustrate the\nproposed procedure and numerically assess its benefits on a realistic case\nstudy that considers the aggregate wind power production in the Danish DK1\nbidding zone as the variable to be predicted and traded. Within this context,\nour procedure leverages, among others, spatial information in the form of wind\npower forecasts issued by transmission system operators (TSO) in surrounding\nbidding zones and publicly available in online platforms. We show that our\nmethod is able to improve the quality of the wind power forecast issued by the\nDanish TSO by several percentage points (when measured in terms of the mean\nabsolute or the root mean square error) and to significantly reduce the\nbalancing costs incurred by the wind power producer.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 15:23:32 GMT"}, {"version": "v2", "created": "Fri, 22 Nov 2019 12:01:41 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 17:51:06 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Mu\u00f1oz", "Miguel \u00c1.", ""], ["Morales", "Juan M.", ""], ["Pineda", "Salvador", ""]]}, {"id": "1907.07590", "submitter": "Xuchao Zhang", "authors": "Xuchao Zhang, Fanglan Chen, Chang-Tien Lu, Naren Ramakrishnan", "title": "Mitigating Uncertainty in Document Classification", "comments": "Accepted by NAACL19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The uncertainty measurement of classifiers' predictions is especially\nimportant in applications such as medical diagnoses that need to ensure limited\nhuman resources can focus on the most uncertain predictions returned by machine\nlearning models. However, few existing uncertainty models attempt to improve\noverall prediction accuracy where human resources are involved in the text\nclassification task. In this paper, we propose a novel neural-network-based\nmodel that applies a new dropout-entropy method for uncertainty measurement. We\nalso design a metric learning method on feature representations, which can\nboost the performance of dropout-based uncertainty methods with smaller\nprediction variance in accurate prediction trials. Extensive experiments on\nreal-world data sets demonstrate that our method can achieve a considerable\nimprovement in overall prediction accuracy compared to existing approaches. In\nparticular, our model improved the accuracy from 0.78 to 0.92 when 30\\% of the\nmost uncertain predictions were handed over to human experts in \"20NewsGroup\"\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 15:38:13 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Zhang", "Xuchao", ""], ["Chen", "Fanglan", ""], ["Lu", "Chang-Tien", ""], ["Ramakrishnan", "Naren", ""]]}, {"id": "1907.07603", "submitter": "Renjie Chen", "authors": "Renjie Chen, Jingyue Zhang, Nalini Ravishanker, Karthik Konduri", "title": "Clustering Activity-Travel Behavior Time Series using Topological Data\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Over the last few years, traffic data has been exploding and the\ntransportation discipline has entered the era of big data. It brings out new\nopportunities for doing data-driven analysis, but it also challenges\ntraditional analytic methods. This paper proposes a new Divide and Combine\nbased approach to do K means clustering on activity-travel behavior time series\nusing features that are derived using tools in Time Series Analysis and\nTopological Data Analysis. Clustering data from five waves of the National\nHousehold Travel Survey ranging from 1990 to 2017 suggests that activity-travel\npatterns of individuals over the last three decades can be grouped into three\nclusters. Results also provide evidence in support of recent claims about\ndifferences in activity-travel patterns of different survey cohorts. The\nproposed method is generally applicable and is not limited only to\nactivity-travel behavior analysis in transportation studies. Driving behavior,\ntravel mode choice, household vehicle ownership, when being characterized as\ncategorical time series, can all be analyzed using the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 16:05:37 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Chen", "Renjie", ""], ["Zhang", "Jingyue", ""], ["Ravishanker", "Nalini", ""], ["Konduri", "Karthik", ""]]}, {"id": "1907.07640", "submitter": "Emin Orhan", "authors": "A. Emin Orhan", "title": "Robustness properties of Facebook's ResNeXt WSL models", "comments": "10 pages, 4 figures, 4 tables; v5 corrects the ImageNet-A results and\n  revises the discussion accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the robustness properties of ResNeXt class image recognition\nmodels trained with billion scale weakly supervised data (ResNeXt WSL models).\nThese models, recently made public by Facebook AI, were trained with ~1B images\nfrom Instagram and fine-tuned on ImageNet. We show that these models display an\nunprecedented degree of robustness against common image corruptions and\nperturbations, as measured by the ImageNet-C and ImageNet-P benchmarks. They\nalso achieve substantially improved accuracies on the recently introduced\n\"natural adversarial examples\" benchmark (ImageNet-A). The largest of the\nreleased models, in particular, achieves state-of-the-art results on\nImageNet-C, ImageNet-P, and ImageNet-A by a large margin. The gains on\nImageNet-C, ImageNet-P, and ImageNet-A far outpace the gains on ImageNet\nvalidation accuracy, suggesting the former as more useful benchmarks to measure\nfurther progress in image recognition. Remarkably, the ResNeXt WSL models even\nachieve a limited degree of adversarial robustness against state-of-the-art\nwhite-box attacks (10-step PGD attacks). However, in contrast to adversarially\ntrained models, the robustness of the ResNeXt WSL models rapidly declines with\nthe number of PGD steps, suggesting that these models do not achieve genuine\nadversarial robustness. Visualization of the learned features also confirms\nthis conclusion. Finally, we show that although the ResNeXt WSL models are more\nshape-biased than comparable ImageNet-trained models in a shape-texture cue\nconflict experiment, they still remain much more texture-biased than humans,\nsuggesting that they share some of the underlying characteristics of\nImageNet-trained models that make this benchmark challenging.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 17:03:52 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 17:59:19 GMT"}, {"version": "v3", "created": "Thu, 25 Jul 2019 15:52:53 GMT"}, {"version": "v4", "created": "Fri, 2 Aug 2019 16:30:13 GMT"}, {"version": "v5", "created": "Mon, 9 Dec 2019 16:28:47 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Orhan", "A. Emin", ""]]}, {"id": "1907.07671", "submitter": "Syed Anwar", "authors": "Sanay Muhammad Umar Saeed, Syed Muhammad Anwar, Humaira Khalid,\n  Muhammad Majid, Ulas Bagci", "title": "Electroencephalography based Classification of Long-term Stress using\n  Psychological Labeling", "comments": "Submitted to IEEE JBHI", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stress research is a rapidly emerging area in thefield of\nelectroencephalography (EEG) based signal processing.The use of EEG as an\nobjective measure for cost effective andpersonalized stress management becomes\nimportant in particularsituations such as the non-availability of mental health\nfacilities.In this study, long-term stress is classified using baseline\nEEGsignal recordings. The labelling for the stress and control groupsis\nperformed using two methods (i) the perceived stress scalescore and (ii) expert\nevaluation. The frequency domain featuresare extracted from five-channel EEG\nrecordings in addition tothe frontal and temporal alpha and beta asymmetries.\nThe alphaasymmetry is computed from four channels and used as a feature.Feature\nselection is also performed using a t-test to identifystatistically significant\nfeatures for both stress and control groups.We found that support vector\nmachine is best suited to classifylong-term human stress when used with alpha\nasymmetry asa feature. It is observed that expert evaluation based\nlabellingmethod has improved the classification accuracy up to 85.20%.Based on\nthese results, it is concluded that alpha asymmetry maybe used as a potential\nbio-marker for stress classification, when labels are assigned using expert\nevaluation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 01:49:04 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Saeed", "Sanay Muhammad Umar", ""], ["Anwar", "Syed Muhammad", ""], ["Khalid", "Humaira", ""], ["Majid", "Muhammad", ""], ["Bagci", "Ulas", ""]]}, {"id": "1907.07673", "submitter": "Deepak Pahwa", "authors": "Deepak Pahwa, Binil Starly", "title": "Network Based Pricing for 3D Printing Services in Two-Sided\n  Manufacturing-as-a-Service Marketplace", "comments": "Manuscript accepted July 4th, 2019; Rapid Prototyping Journal", "journal-ref": null, "doi": "10.1108/RPJ-01-2019-0018", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents approaches to determine a network based pricing for 3D\nprinting services in the context of a two-sided manufacturing-as-a-service\nmarketplace. The intent is to provide cost analytics to enable service bureaus\nto better compete in the market by moving away from setting ad-hoc and\nsubjective prices. A data mining approach with machine learning methods is used\nto estimate a price range based on the profile characteristics of 3D printing\nservice suppliers. The model considers factors such as supplier experience,\nsupplier capabilities, customer reviews and ratings from past orders, and scale\nof operations among others to estimate a price range for suppliers' services.\nData was gathered from existing marketplace websites, which was then used to\ntrain and test the model. The model demonstrates an accuracy of 65% for US\nbased suppliers and 59% for Europe based suppliers to classify a supplier's 3D\nPrinter listing in one of the seven price categories. The improvement over\nbaseline accuracy of 25% demonstrates that machine learning based methods are\npromising for network based pricing in manufacturing marketplaces. Conventional\nmethodologies for pricing services through activity based costing are\ninefficient in strategically pricing 3D printing service offering in a\nconnected marketplace. As opposed to arbitrarily determining prices, this work\nproposes an approach to determine prices through data mining methods to\nestimate competitive prices. Such tools can be built into online marketplaces\nto help independent service bureaus to determine service price rates.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 19:14:55 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Pahwa", "Deepak", ""], ["Starly", "Binil", ""]]}, {"id": "1907.07713", "submitter": "Xin Hunt", "authors": "Xin J. Hunt, Ralph Abbey, Ricky Tharrington, Joost Huiskens, Nina\n  Wesdorp", "title": "An AI-Augmented Lesion Detection Framework For Liver Metastases With\n  Model Interpretability", "comments": "4 pages, 2 figures, 2019 KDD Workshop on Applied Data Science for\n  Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Colorectal cancer (CRC) is the third most common cancer and the second\nleading cause of cancer-related deaths worldwide. Most CRC deaths are the\nresult of progression of metastases. The assessment of metastases is done using\nthe RECIST criterion, which is time consuming and subjective, as clinicians\nneed to manually measure anatomical tumor sizes. AI has many successes in image\nobject detection, but often suffers because the models used are not\ninterpretable, leading to issues in trust and implementation in the clinical\nsetting. We propose a framework for an AI-augmented system in which an\ninteractive AI system assists clinicians in the metastasis assessment. We\ninclude model interpretability to give explanations of the reasoning of the\nunderlying models.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 18:35:25 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Hunt", "Xin J.", ""], ["Abbey", "Ralph", ""], ["Tharrington", "Ricky", ""], ["Huiskens", "Joost", ""], ["Wesdorp", "Nina", ""]]}, {"id": "1907.07723", "submitter": "Adrian Rivera Cardoso", "authors": "Adrian Rivera Cardoso and Jacob Abernethy and He Wang and Huan Xu", "title": "Competing Against Equilibria in Zero-Sum Games with Evolving Payoffs", "comments": "arXiv admin note: text overlap with arXiv:1806.08301", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of repeated play in a zero-sum game in which the payoff\nmatrix may change, in a possibly adversarial fashion, on each round; we call\nthese Online Matrix Games. Finding the Nash Equilibrium (NE) of a two player\nzero-sum game is core to many problems in statistics, optimization, and\neconomics, and for a fixed game matrix this can be easily reduced to solving a\nlinear program. But when the payoff matrix evolves over time our goal is to\nfind a sequential algorithm that can compete with, in a certain sense, the NE\nof the long-term-averaged payoff matrix. We design an algorithm with small NE\nregret--that is, we ensure that the long-term payoff of both players is close\nto minimax optimum in hindsight. Our algorithm achieves near-optimal dependence\nwith respect to the number of rounds and depends poly-logarithmically on the\nnumber of available actions of the players. Additionally, we show that the\nnaive reduction, where each player simply minimizes its own regret, fails to\nachieve the stated objective regardless of which algorithm is used. We also\nconsider the so-called bandit setting, where the feedback is significantly\nlimited, and we provide an algorithm with small NE regret using one-point\nestimates of each payoff matrix.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 18:57:55 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Cardoso", "Adrian Rivera", ""], ["Abernethy", "Jacob", ""], ["Wang", "He", ""], ["Xu", "Huan", ""]]}, {"id": "1907.07735", "submitter": "Yaochen Hu", "authors": "Yaochen Hu, Peng Liu, Linglong Kong, Di Niu", "title": "Learning Privately over Distributed Features: An ADMM Sharing Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed machine learning has been widely studied in order to handle\nexploding amount of data. In this paper, we study an important yet less visited\ndistributed learning problem where features are inherently distributed or\nvertically partitioned among multiple parties, and sharing of raw data or model\nparameters among parties is prohibited due to privacy concerns. We propose an\nADMM sharing framework to approach risk minimization over distributed features,\nwhere each party only needs to share a single value for each sample in the\ntraining process, thus minimizing the data leakage risk. We establish\nconvergence and iteration complexity results for the proposed parallel ADMM\nalgorithm under non-convex loss. We further introduce a novel differentially\nprivate ADMM sharing algorithm and bound the privacy guarantee with carefully\ndesigned noise perturbation. The experiments based on a prototype system shows\nthat the proposed ADMM algorithms converge efficiently in a robust fashion,\ndemonstrating advantage over gradient based methods especially for data set\nwith high dimensional feature spaces.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 20:02:05 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Hu", "Yaochen", ""], ["Liu", "Peng", ""], ["Kong", "Linglong", ""], ["Niu", "Di", ""]]}, {"id": "1907.07739", "submitter": "Heather Couture", "authors": "Heather D. Couture, Roland Kwitt, J.S. Marron, Melissa Troester,\n  Charles M. Perou, Marc Niethammer", "title": "Deep Multi-View Learning via Task-Optimal CCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical Correlation Analysis (CCA) is widely used for multimodal data\nanalysis and, more recently, for discriminative tasks such as multi-view\nlearning; however, it makes no use of class labels. Recent CCA methods have\nstarted to address this weakness but are limited in that they do not\nsimultaneously optimize the CCA projection for discrimination and the CCA\nprojection itself, or they are linear only. We address these deficiencies by\nsimultaneously optimizing a CCA-based and a task objective in an end-to-end\nmanner. Together, these two objectives learn a non-linear CCA projection to a\nshared latent space that is highly correlated and discriminative. Our method\nshows a significant improvement over previous state-of-the-art (including deep\nsupervised approaches) for cross-view classification, regularization with a\nsecond view, and semi-supervised learning on real data.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 20:06:47 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Couture", "Heather D.", ""], ["Kwitt", "Roland", ""], ["Marron", "J. S.", ""], ["Troester", "Melissa", ""], ["Perou", "Charles M.", ""], ["Niethammer", "Marc", ""]]}, {"id": "1907.07746", "submitter": "Robin Tibor Schirrmeister", "authors": "Robin Tibor Schirrmeister, Tonio Ball", "title": "Deep Invertible Networks for EEG-based brain-signal decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript, we investigate deep invertible networks for EEG-based\nbrain signal decoding and find them to generate realistic EEG signals as well\nas classify novel signals above chance. Further ideas for their regularization\ntowards better decoding accuracies are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 20:26:21 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Schirrmeister", "Robin Tibor", ""], ["Ball", "Tonio", ""]]}, {"id": "1907.07751", "submitter": "Andrew Jacobsen", "authors": "Andrew Jacobsen, Matthew Schlegel, Cameron Linke, Thomas Degris, Adam\n  White, Martha White", "title": "Meta-descent for Online, Continual Prediction", "comments": "AAAI Conference on Artificial Intelligence 2019. v2: Correction to\n  Baird's counterexample. A bug in the code lead to results being reported for\n  AMSGrad in this experiment, when they were actually results for Adam", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates different vector step-size adaptation approaches for\nnon-stationary online, continual prediction problems. Vanilla stochastic\ngradient descent can be considerably improved by scaling the update with a\nvector of appropriately chosen step-sizes. Many methods, including AdaGrad,\nRMSProp, and AMSGrad, keep statistics about the learning process to approximate\na second order update---a vector approximation of the inverse Hessian. Another\nfamily of approaches use meta-gradient descent to adapt the step-size\nparameters to minimize prediction error. These meta-descent strategies are\npromising for non-stationary problems, but have not been as extensively\nexplored as quasi-second order methods. We first derive a general, incremental\nmeta-descent algorithm, called AdaGain, designed to be applicable to a much\nbroader range of algorithms, including those with semi-gradient updates or even\nthose with accelerations, such as RMSProp. We provide an empirical comparison\nof methods from both families. We conclude that methods from both families can\nperform well, but in non-stationary prediction problems the meta-descent\nmethods exhibit advantages. Our method is particularly robust across several\nprediction problems, and is competitive with the state-of-the-art method on a\nlarge-scale, time-series prediction problem on real data from a mobile robot.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 20:51:58 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 05:43:15 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Jacobsen", "Andrew", ""], ["Schlegel", "Matthew", ""], ["Linke", "Cameron", ""], ["Degris", "Thomas", ""], ["White", "Adam", ""], ["White", "Martha", ""]]}, {"id": "1907.07755", "submitter": "Shweta Singh", "authors": "Renganathan Subramanian and Shweta Singh", "title": "Can Machine Learning Identify Governing Laws For Dynamics in Complex\n  Engineered Systems ? : A Study in Chemical Engineering", "comments": "8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning recently has been used to identify the governing equations\nfor dynamics in physical systems. The promising results from applications on\nsystems such as fluid dynamics and chemical kinetics inspire further\ninvestigation of these methods on complex engineered systems. Dynamics of these\nsystems play a crucial role in design and operations. Hence, it would be\nadvantageous to learn about the mechanisms that may be driving the complex\ndynamics of systems. In this work, our research question was aimed at\naddressing this open question about applicability and usefulness of novel\nmachine learning approach in identifying the governing dynamical equations for\nengineered systems. We focused on distillation column which is an ubiquitous\nunit operation in chemical engineering and demonstrates complex dynamics i.e.\nit's dynamics is a combination of heuristics and fundamental physical laws. We\ntested the method of Sparse Identification of Non-Linear Dynamics (SINDy)\nbecause of it's ability to produce white-box models with terms that can be used\nfor physical interpretation of dynamics. Time series data for dynamics was\ngenerated from simulation of distillation column using ASPEN Dynamics. One\npromising result was reduction of number of equations for dynamic simulation\nfrom 1000s in ASPEN to only 13 - one for each state variable. Prediction\naccuracy was high on the test data from system within the perturbation range,\nhowever outside perturbation range equations did not perform well. In terms of\nphysical law extraction, some terms were interpretable as related to Fick's law\nof diffusion (with concentration terms) and Henry's law (with ratio of\nconcentration and pressure terms). While some terms were interpretable, we\nconclude that more research is needed on combining engineering systems with\nmachine learning approach to improve understanding of governing laws for\nunknown dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 11:31:12 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Subramanian", "Renganathan", ""], ["Singh", "Shweta", ""]]}, {"id": "1907.07768", "submitter": "Avishek Bose", "authors": "Avishek Bose, Vahid Behzadan, Carlos Aguirre, William H. Hsu", "title": "A Novel Approach for Detection and Ranking of Trendy and Emerging Cyber\n  Threat Events in Twitter Streams", "comments": "9 pages, 3 figures, and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new machine learning and text information extraction approach to\ndetection of cyber threat events in Twitter that are novel (previously\nnon-extant) and developing (marked by significance with respect to similarity\nwith a previously detected event). While some existing approaches to event\ndetection measure novelty and trendiness, typically as independent criteria and\noccasionally as a holistic measure, this work focuses on detecting both novel\nand developing events using an unsupervised machine learning approach.\nFurthermore, our proposed approach enables the ranking of cyber threat events\nbased on an importance score by extracting the tweet terms that are\ncharacterized as named entities, keywords, or both. We also impute influence to\nusers in order to assign a weighted score to noun phrases in proportion to user\ninfluence and the corresponding event scores for named entities and keywords.\nTo evaluate the performance of our proposed approach, we measure the efficiency\nand detection error rate for events over a specified time interval, relative to\nhuman annotator ground truth.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 22:17:17 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Bose", "Avishek", ""], ["Behzadan", "Vahid", ""], ["Aguirre", "Carlos", ""], ["Hsu", "William H.", ""]]}, {"id": "1907.07769", "submitter": "Praveen Narayanan", "authors": "Praveen Narayanan, Punarjay Chakravarty, Francois Charette, Gint\n  Puskorius", "title": "Hierarchical Sequence to Sequence Voice Conversion with Limited Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a voice conversion solution using recurrent sequence to sequence\nmodeling for DNNs. Our solution takes advantage of recent advances in attention\nbased modeling in the fields of Neural Machine Translation (NMT),\nText-to-Speech (TTS) and Automatic Speech Recognition (ASR). The problem\nconsists of converting between voices in a parallel setting when {\\it\n$<$source,target$>$} audio pairs are available. Our seq2seq architecture makes\nuse of a hierarchical encoder to summarize input audio frames. On the decoder\nside, we use an attention based architecture used in recent TTS works. Since\nthere is a dearth of large multispeaker voice conversion databases needed for\ntraining DNNs, we resort to training the network with a large single speaker\ndataset as an autoencoder. This is then adapted for the smaller multispeaker\nvoice conversion datasets available for voice conversion. In contrast with\nother voice conversion works that use $F_0$, duration and linguistic features,\nour system uses mel spectrograms as the audio representation. Output mel frames\nare converted back to audio using a wavenet vocoder.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 07:54:46 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Narayanan", "Praveen", ""], ["Chakravarty", "Punarjay", ""], ["Charette", "Francois", ""], ["Puskorius", "Gint", ""]]}, {"id": "1907.07772", "submitter": "Patrick Gikunda Mr.", "authors": "Patrick Kinyua Gikunda", "title": "Modern CNNs for IoT Based Farms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent introduction of ICT in agriculture has brought a number of changes in\nthe way farming is done. This means use of Internet of Things(IoT), Cloud\nComputing(CC), Big Data (BD) and automation to gain better control over the\nprocess of farming. As the use of these technologies in farms has grown\nexponentially with massive data production, there is need to develop and use\nstate-of-the-art tools in order to gain more insight from the data within\nreasonable time. In this paper, we present an initial understanding of\nConvolutional Neural Network (CNN), the recent architectures of\nstate-of-the-art CNN and their underlying complexities. Then we propose a\nclassification taxonomy tailored for agricultural application of CNN. Finally,\nwe present a comprehensive review of research dedicated to applications of\nstate-of-the-art CNNs in agricultural production systems. Our contribution is\nin two-fold. First, for end users of agricultural deep learning tools, our\nbenchmarking finding can serve as a guide to selecting appropriate architecture\nto use. Second, for agricultural software developers of deep learning tools,\nour in-depth analysis explains the state-of-the-art CNN complexities and points\nout possible future directions to further optimize the running performance.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 19:28:46 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Gikunda", "Patrick Kinyua", ""]]}, {"id": "1907.07775", "submitter": "Junya Ikemoto", "authors": "Junya Ikemoto and Toshimitsu Ushio", "title": "Model-free Control of Chaos with Continuous Deep Q-learning", "comments": "7 pages, 8 figures, Submitted to Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The OGY method is one of control methods for a chaotic system. In the method,\nwe have to calculate a stabilizing periodic orbit embedded in its chaotic\nattractor. Thus, we cannot use this method in the case where a precise\nmathematical model of the chaotic system cannot be identified. In this case,\nthe delayed feedback control proposed by Pyragas is useful. However, even in\nthe delayed feedback control, we need the mathematical model to determine a\nfeedback gain that stabilizes the periodic orbit. To overcome this problem, we\npropose a model-free reinforcement learning algorithm to the design of a\ncontroller for the chaotic system. In recent years, model-free reinforcement\nlearning algorithms with deep neural networks have been paid much attention to.\nThose algorithms make it possible to control complex systems. However, it is\nknown that model-free reinforcement learning algorithms are not efficient\nbecause learners must explore their control policies over the entire state\nspace. Moreover, model-free reinforcement learning algorithms with deep neural\nnetworks have the disadvantage in taking much time to learn their control\noptimal policies. Thus, we propose a data-based control policy consisting of\ntwo steps, where we determine a region including the stabilizing periodic orbit\nfirst, and make the controller learn an optimal control policy for its\nstabilization. In the proposed method, the controller efficiently explores its\ncontrol policy only in the region.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 09:14:43 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 02:23:01 GMT"}, {"version": "v3", "created": "Sat, 24 Aug 2019 13:58:22 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Ikemoto", "Junya", ""], ["Ushio", "Toshimitsu", ""]]}, {"id": "1907.07786", "submitter": "Alex Burnap", "authors": "Alex Burnap, John R. Hauser, Artem Timoshenko", "title": "Design and Evaluation of Product Aesthetics: A Human-Machine Hybrid\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aesthetics are critically important to market acceptance in many product\ncategories. In the automotive industry in particular, an improved aesthetic\ndesign can boost sales by 30% or more. Firms invest heavily in designing and\ntesting new product aesthetics. A single automotive \"theme clinic\" costs\nbetween \\$100,000 and \\$1,000,000, and hundreds are conducted annually. We use\nmachine learning to augment human judgment when designing and testing new\nproduct aesthetics. The model combines a probabilistic variational autoencoder\n(VAE) and adversarial components from generative adversarial networks (GAN),\nalong with modeling assumptions that address managerial requirements for firm\nadoption. We train our model with data from an automotive partner-7,000 images\nevaluated by targeted consumers and 180,000 high-quality unrated images. Our\nmodel predicts well the appeal of new aesthetic designs-38% improvement\nrelative to a baseline and substantial improvement over both conventional\nmachine learning models and pretrained deep learning models. New automotive\ndesigns are generated in a controllable manner for the design team to consider,\nwhich we also empirically verify are appealing to consumers. These results,\ncombining human and machine inputs for practical managerial usage, suggest that\nmachine learning offers significant opportunity to augment aesthetic design.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 21:56:55 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Burnap", "Alex", ""], ["Hauser", "John R.", ""], ["Timoshenko", "Artem", ""]]}, {"id": "1907.07788", "submitter": "Sheng Zhang", "authors": "Sheng Zhang, Guang Lin", "title": "SubTSBR to tackle high noise and outliers for data-driven discovery of\n  differential equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven discovery of differential equations has been an emerging research\ntopic. We propose a novel algorithm subsampling-based threshold sparse Bayesian\nregression (SubTSBR) to tackle high noise and outliers. The subsampling\ntechnique is used for improving the accuracy of the Bayesian learning\nalgorithm. It has two parameters: subsampling size and the number of\nsubsamples. When the subsampling size increases with fixed total sample size,\nthe accuracy of our algorithm goes up and then down. When the number of\nsubsamples increases, the accuracy of our algorithm keeps going up. We\ndemonstrate how to use our algorithm step by step and compare our algorithm\nwith threshold sparse Bayesian regression (TSBR) for the discovery of\ndifferential equations. We show that our algorithm produces better results. We\nalso discuss the merits of discovering differential equations from data and\ndemonstrate how to discover models with random initial and boundary condition\nas well as models with bifurcations. The numerical examples are: (1)\npredator-prey model with noise, (2) shallow water equations with outliers, (3)\nheat diffusion with random initial and boundary condition, and (4)\nfish-harvesting problem with bifurcations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 22:00:48 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 00:40:37 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 01:52:33 GMT"}, {"version": "v4", "created": "Tue, 27 Oct 2020 16:35:16 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Zhang", "Sheng", ""], ["Lin", "Guang", ""]]}, {"id": "1907.07802", "submitter": "Garrett Wilson", "authors": "Garrett Wilson and Diane J. Cook", "title": "Multi-Purposing Domain Adaptation Discriminators for Pseudo Labeling\n  Confidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Often domain adaptation is performed using a discriminator (domain\nclassifier) to learn domain-invariant feature representations so that a\nclassifier trained on labeled source data will generalize well to unlabeled\ntarget data. A line of research stemming from semi-supervised learning uses\npseudo labeling to directly generate \"pseudo labels\" for the unlabeled target\ndata and trains a classifier on the now-labeled target data, where the samples\nare selected or weighted based on some measure of confidence. In this paper, we\npropose multi-purposing the discriminator to not only aid in producing\ndomain-invariant representations but also to provide pseudo labeling\nconfidence.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 22:51:33 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Wilson", "Garrett", ""], ["Cook", "Diane J.", ""]]}, {"id": "1907.07804", "submitter": "Subhojeet Pramanik", "authors": "Subhojeet Pramanik, Priyanka Agrawal, Aman Hussain", "title": "OmniNet: A unified architecture for multi-modal multi-task learning", "comments": "Source code available at: https://github.com/subho406/OmniNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer is a popularly used neural network architecture, especially for\nlanguage understanding. We introduce an extended and unified architecture that\ncan be used for tasks involving a variety of modalities like image, text,\nvideos, etc. We propose a spatio-temporal cache mechanism that enables learning\nspatial dimension of the input in addition to the hidden states corresponding\nto the temporal input sequence. The proposed architecture further enables a\nsingle model to support tasks with multiple input modalities as well as\nasynchronous multi-task learning, thus we refer to it as OmniNet. For example,\na single instance of OmniNet can concurrently learn to perform the tasks of\npart-of-speech tagging, image captioning, visual question answering and video\nactivity recognition. We demonstrate that training these four tasks together\nresults in about three times compressed model while retaining the performance\nin comparison to training them individually. We also show that using this\nneural network pre-trained on some modalities assists in learning unseen tasks\nsuch as video captioning and video question answering. This illustrates the\ngeneralization capacity of the self-attention mechanism on the spatio-temporal\ncache present in OmniNet.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 22:59:56 GMT"}, {"version": "v2", "created": "Fri, 3 Jul 2020 09:59:06 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Pramanik", "Subhojeet", ""], ["Agrawal", "Priyanka", ""], ["Hussain", "Aman", ""]]}, {"id": "1907.07843", "submitter": "Hui Ye", "authors": "Hui Ye, Xiaopeng Ma, Qingfeng Pan, Huaqiang Fang, Hang Xiang, Tongzhen\n  Shao", "title": "An Adaptive Approach for Anomaly Detector Selection and Fine-Tuning in\n  Time Series", "comments": "7 pages, 5 figures it has been accepted to DLP-KDD 2019 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The anomaly detection of time series is a hotspot of time series data mining.\nThe own characteristics of different anomaly detectors determine the abnormal\ndata that they are good at. There is no detector can be optimizing in all types\nof anomalies. Moreover, it still has difficulties in industrial production due\nto problems such as a single detector can't be optimized at different time\nwindows of the same time series. This paper proposes an adaptive model based on\ntime series characteristics and selecting appropriate detector and run-time\nparameters for anomaly detection, which is called ATSDLN(Adaptive Time Series\nDetector Learning Network). We take the time series as the input of the model,\nand learn the time series representation through FCN. In order to realize the\nadaptive selection of detectors and run-time parameters according to the input\ntime series, the outputs of FCN are the inputs of two sub-networks: the\ndetector selection network and the run-time parameters selection network. In\naddition, the way that the variable layer width design of the parameter\nselection sub-network and the introduction of transfer learning make the model\nbe with more expandability. Through experiments, it is found that ATSDLN can\nselect appropriate anomaly detector and run-time parameters, and have strong\nexpandability, which can quickly transfer. We investigate the performance of\nATSDLN in public data sets, our methods outperform other methods in most cases\nwith higher effect and better adaptation. We also show experimental results on\npublic data sets to demonstrate how model structure and transfer learning\naffect the effectiveness.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 02:19:20 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Ye", "Hui", ""], ["Ma", "Xiaopeng", ""], ["Pan", "Qingfeng", ""], ["Fang", "Huaqiang", ""], ["Xiang", "Hang", ""], ["Shao", "Tongzhen", ""]]}, {"id": "1907.07847", "submitter": "Qisheng Wang", "authors": "Qisheng Wang and Qichao Wang", "title": "Prioritized Guidance for Efficient Multi-Agent Reinforcement Learning\n  Exploration", "comments": "Theequations (7)-(10) in the paper are incorrectly derived, and need\n  to be withdrawn and revised in many places", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration efficiency is a challenging problem in multi-agent reinforcement\nlearning (MARL), as the policy learned by confederate MARL depends on the\ncollaborative approach among multiple agents. Another important problem is the\nless informative reward restricts the learning speed of MARL compared with the\ninformative label in supervised learning. In this work, we leverage on a novel\ncommunication method to guide MARL to accelerate exploration and propose a\npredictive network to forecast the reward of current state-action pair and use\nthe guidance learned by the predictive network to modify the reward function.\nAn improved prioritized experience replay is employed to better take advantage\nof the different knowledge learned by different agents which utilizes\nTime-difference (TD) error more effectively. Experimental results demonstrates\nthat the proposed algorithm outperforms existing methods in cooperative\nmulti-agent environments. We remark that this algorithm can be extended to\nsupervised learning to speed up its training.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 02:27:55 GMT"}, {"version": "v2", "created": "Fri, 19 Jul 2019 07:34:39 GMT"}, {"version": "v3", "created": "Wed, 25 Dec 2019 07:05:14 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Wang", "Qisheng", ""], ["Wang", "Qichao", ""]]}, {"id": "1907.07872", "submitter": "Euntae Choi", "authors": "Euntae Choi, Kyungmi Lee, Kiyoung Choi", "title": "Autoencoder-Based Incremental Class Learning without Retraining on Old\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incremental class learning, a scenario in continual learning context where\nclasses and their training data are sequentially and disjointedly observed,\nchallenges a problem widely known as catastrophic forgetting. In this work, we\npropose a novel incremental class learning method that can significantly reduce\nmemory overhead compared to previous approaches. Apart from conventional\nclassification scheme using softmax, our model bases on an autoencoder to\nextract prototypes for given inputs so that no change in its output unit is\nrequired. It stores only the mean of prototypes per class to perform\nmetric-based classification, unlike rehearsal approaches which rely on large\nmemory or generative model. To mitigate catastrophic forgetting, regularization\nmethods are applied on our model when a new task is encountered. We evaluate\nour method by experimenting on CIFAR-100 and CUB-200-2011 and show that its\nperformance is comparable to the state-of-the-art method with much lower\nadditional memory cost.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 04:51:25 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Choi", "Euntae", ""], ["Lee", "Kyungmi", ""], ["Choi", "Kiyoung", ""]]}, {"id": "1907.07890", "submitter": "Julia Schulte", "authors": "Julia Schulte, Daniel Staps, Alexander Lampe", "title": "A feasibility study of deep neural networks for the recognition of\n  banknotes regarding central bank requirements", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contains a feasibility study of deep neural networks for the\nclassification of Euro banknotes with respect to requirements of central banks\non the ATM and high speed sorting industry. Instead of concentrating on the\naccuracy for a large number of classes as in the famous ImageNet Challenge we\nfocus thus on conditions with few classes and the requirement of rejection of\nimages belonging clearly to neither of the trained classes (i.e. classification\nin a so-called 0-class). These special requirements are part of frameworks\ndefined by central banks as the European Central Bank and are met by current\nATMs and high speed sorting machines. We also consider training and\nclassification time on state of the art GPU hardware. The study concentrates on\nthe banknote recognition whereas banknote class dependent authenticity and\nfitness checks are a topic of its own which is not considered in this work.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 06:29:31 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 08:21:15 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Schulte", "Julia", ""], ["Staps", "Daniel", ""], ["Lampe", "Alexander", ""]]}, {"id": "1907.07904", "submitter": "Giuseppe Marra", "authors": "Francesco Giannini and Giuseppe Marra and Michelangelo Diligenti and\n  Marco Maggini and Marco Gori", "title": "On the relation between Loss Functions and T-Norms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has been shown to achieve impressive results in several domains\nlike computer vision and natural language processing. A key element of this\nsuccess has been the development of new loss functions, like the popular\ncross-entropy loss, which has been shown to provide faster convergence and to\nreduce the vanishing gradient problem in very deep structures. While the\ncross-entropy loss is usually justified from a probabilistic perspective, this\npaper shows an alternative and more direct interpretation of this loss in terms\nof t-norms and their associated generator functions, and derives a general\nrelation between loss functions and t-norms. In particular, the presented work\nshows intriguing results leading to the development of a novel class of loss\nfunctions. These losses can be exploited in any supervised learning task and\nwhich could lead to faster convergence rates that the commonly employed\ncross-entropy loss.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 06:58:36 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Giannini", "Francesco", ""], ["Marra", "Giuseppe", ""], ["Diligenti", "Michelangelo", ""], ["Maggini", "Marco", ""], ["Gori", "Marco", ""]]}, {"id": "1907.07945", "submitter": "Yang Song", "authors": "Yang Song and Chenlin Meng and Stefano Ermon", "title": "MintNet: Building Invertible Neural Networks with Masked Convolutions", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new way of constructing invertible neural networks by combining\nsimple building blocks with a novel set of composition rules. This leads to a\nrich set of invertible architectures, including those similar to ResNets.\nInversion is achieved with a locally convergent iterative procedure that is\nparallelizable and very fast in practice. Additionally, the determinant of the\nJacobian can be computed analytically and efficiently, enabling their\ngenerative use as flow models. To demonstrate their flexibility, we show that\nour invertible neural networks are competitive with ResNets on MNIST and\nCIFAR-10 classification. When trained as generative models, our invertible\nnetworks achieve competitive likelihoods on MNIST, CIFAR-10 and ImageNet 32x32,\nwith bits per dimension of 0.98, 3.32 and 4.06 respectively.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 09:24:55 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 07:20:45 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Song", "Yang", ""], ["Meng", "Chenlin", ""], ["Ermon", "Stefano", ""]]}, {"id": "1907.08006", "submitter": "Hristo Inouzhe Valdes", "authors": "Eustasio del Barrio and Hristo Inouzhe and Jean-Michel Loubes and\n  Carlos Matr\\'an and Agust\\'in Mayo-\\'Iscar", "title": "optimalFlow: Optimal-transport approach to flow cytometry gating and\n  population matching", "comments": "26 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data obtained from Flow Cytometry present pronounced variability due to\nbiological and technical reasons. Biological variability is a well-known\nphenomenon produced by measurements on different individuals, with different\ncharacteristics such as illness, age, sex, etc. The use of different settings\nfor measurement, the variation of the conditions during experiments and the\ndifferent types of flow cytometers are some of the technical causes of\nvariability. This mixture of sources of variability makes the use of supervised\nmachine learning for identification of cell populations difficult. The present\nwork is conceived as a combination of strategies to facilitate the task of\nsupervised gating.\n  We propose $optimalFlowTemplates$, based on a similarity distance and\n$\\text{Wasserstein barycenters}$, which clusters cytometries and produces\nprototype cytometries for the different groups. We show that supervised\nlearning, restricted to the new groups, performs better than the same\ntechniques applied to the whole collection. We also present\n$optimalFlowClassification$, which uses a database of gated cytometries and\noptimalFlowTemplates to assign cell types to a new cytometry. We show that this\nprocedure can outperform state of the art techniques in the proposed datasets.\nOur code is freely available as $optimalFlow$ a Bioconductor R package at\nhttps://bioconductor.org/packages/optimalFlow.\n  optimalFlowTemplates+optimalFlowClassification addresses the problem of using\nsupervised learning while accounting for biological and technical variability.\nOur methodology provides a robust automated gating workflow that handles the\nintrinsic variability of flow cytometry data well. Our main innovation is the\nmethodology itself and the optimal-transport techniques that we apply to flow\ncytometry analysis.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 11:54:47 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2020 11:28:03 GMT"}], "update_date": "2020-04-30", "authors_parsed": [["del Barrio", "Eustasio", ""], ["Inouzhe", "Hristo", ""], ["Loubes", "Jean-Michel", ""], ["Matr\u00e1n", "Carlos", ""], ["Mayo-\u00cdscar", "Agust\u00edn", ""]]}, {"id": "1907.08040", "submitter": "Hanten Chang", "authors": "Hanten Chang and Katsuya Futagami", "title": "Convolutional Reservoir Computing for World Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, reinforcement learning models have achieved great success,\ncompleting complex tasks such as mastering Go and other games with higher\nscores than human players. Many of these models collect considerable data on\nthe tasks and improve accuracy by extracting visual and time-series features\nusing convolutional neural networks (CNNs) and recurrent neural networks,\nrespectively. However, these networks have very high computational costs\nbecause they need to be trained by repeatedly using a large volume of past\nplaying data. In this study, we propose a novel practical approach called\nreinforcement learning with convolutional reservoir computing (RCRC) model. The\nRCRC model has several desirable features: 1. it can extract visual and\ntime-series features very fast because it uses random fixed-weight CNN and the\nreservoir computing model; 2. it does not require the training data to be\nstored because it extracts features without training and decides action with\nevolution strategy. Furthermore, the model achieves state of the art score in\nthe popular reinforcement learning task. Incredibly, we find the random\nweight-fixed simple networks like only one dense layer network can also reach\nhigh score in the RL task.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 13:16:39 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Chang", "Hanten", ""], ["Futagami", "Katsuya", ""]]}, {"id": "1907.08059", "submitter": "Andreas Grammenos", "authors": "Andreas Grammenos, Rodrigo Mendoza-Smith, Jon Crowcroft, Cecilia\n  Mascolo", "title": "Federated Principal Component Analysis", "comments": "36 pages, 13 figures, 1 table. Accepted for publication at Neural\n  Information Processing Systems (NeurIPS 2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a federated, asynchronous, and $(\\varepsilon,\n\\delta)$-differentially private algorithm for PCA in the memory-limited\nsetting. Our algorithm incrementally computes local model updates using a\nstreaming procedure and adaptively estimates its $r$ leading principal\ncomponents when only $\\mathcal{O}(dr)$ memory is available with $d$ being the\ndimensionality of the data. We guarantee differential privacy via an\ninput-perturbation scheme in which the covariance matrix of a dataset\n$\\mathbf{X} \\in \\mathbb{R}^{d \\times n}$ is perturbed with a non-symmetric\nrandom Gaussian matrix with variance in\n$\\mathcal{O}\\left(\\left(\\frac{d}{n}\\right)^2 \\log d \\right)$, thus improving\nupon the state-of-the-art. Furthermore, contrary to previous federated or\ndistributed algorithms for PCA, our algorithm is also invariant to permutations\nin the incoming data, which provides robustness against straggler or failed\nnodes. Numerical simulations show that, while using limited-memory, our\nalgorithm exhibits performance that closely matches or outperforms traditional\nnon-federated algorithms, and in the absence of communication latency, it\nexhibits attractive horizontal scalability.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 14:05:51 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 02:57:19 GMT"}, {"version": "v3", "created": "Thu, 22 Oct 2020 19:10:41 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Grammenos", "Andreas", ""], ["Mendoza-Smith", "Rodrigo", ""], ["Crowcroft", "Jon", ""], ["Mascolo", "Cecilia", ""]]}, {"id": "1907.08082", "submitter": "Adam Golinski", "authors": "Adam Goli\\'nski, Frank Wood, Tom Rainforth", "title": "Amortized Monte Carlo Integration", "comments": "Awarded Best Paper Honourable Mention at International Conference on\n  Machine Learning (ICML) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current approaches to amortizing Bayesian inference focus solely on\napproximating the posterior distribution. Typically, this approximation is, in\nturn, used to calculate expectations for one or more target functions - a\ncomputational pipeline which is inefficient when the target function(s) are\nknown upfront. In this paper, we address this inefficiency by introducing AMCI,\na method for amortizing Monte Carlo integration directly. AMCI operates\nsimilarly to amortized inference but produces three distinct amortized\nproposals, each tailored to a different component of the overall expectation\ncalculation. At runtime, samples are produced separately from each amortized\nproposal, before being combined to an overall estimate of the expectation. We\nshow that while existing approaches are fundamentally limited in the level of\naccuracy they can achieve, AMCI can theoretically produce arbitrarily small\nerrors for any integrable target function using only a single sample from each\nproposal at runtime. We further show that it is able to empirically outperform\nthe theoretically optimal self-normalized importance sampler on a number of\nexample problems. Furthermore, AMCI allows not only for amortizing over\ndatasets but also amortizing over target functions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 14:36:48 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Goli\u0144ski", "Adam", ""], ["Wood", "Frank", ""], ["Rainforth", "Tom", ""]]}, {"id": "1907.08087", "submitter": "Jesse Read", "authors": "Jesse Read and Luca Martino", "title": "Probabilistic Regressor Chains with Monte Carlo Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number and diversity of techniques have been offered in the\nliterature in recent years for solving multi-label classification tasks,\nincluding classifier chains where predictions are cascaded to other models as\nadditional features. The idea of extending this chaining methodology to\nmulti-output regression has already been suggested and trialed: regressor\nchains. However, this has so-far been limited to greedy inference and has\nprovided relatively poor results compared to individual models, and of limited\napplicability. In this paper we identify and discuss the main limitations,\nincluding an analysis of different base models, loss functions, explainability,\nand other desiderata of real-world applications. To overcome the identified\nlimitations we study and develop methods for regressor chains. In particular we\npresent a sequential Monte Carlo scheme in the framework of a probabilistic\nregressor chain, and we show it can be effective, flexible and useful in\nseveral types of data. We place regressor chains in context in general terms of\nmulti-output learning with continuous outputs, and in doing this shed\nadditional light on classifier chains.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 14:41:25 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Read", "Jesse", ""], ["Martino", "Luca", ""]]}, {"id": "1907.08100", "submitter": "Yoshihiro Hirose", "authors": "Yoshihiro Hirose", "title": "Least Angle Regression in Tangent Space and LASSO for Generalized Linear\n  Models", "comments": "PDFLaTeX, 17 pages with 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes sparse estimation methods for the generalized linear\nmodels, which run one of least angle regression (LARS) and least absolute\nshrinkage and selection operator (LASSO) in the tangent space of the manifold\nof the statistical model. This study approximates the statistical model and\nsubsequently uses exact calculations. LARS was proposed as an efficient\nalgorithm for parameter estimation and variable selection for the normal linear\nmodel. The LARS algorithm is described in terms of Euclidean geometry regarding\nthe correlation as the metric of the parameter space. Since the LARS algorithm\nonly works in Euclidean space, we transform a manifold of the statistical model\ninto the tangent space at the origin. In the generalized linear regression,\nthis transformation allows us to run the original LARS algorithm for the\ngeneralized linear models. The proposed methods are efficient and perform well.\nReal-data analysis indicates that the proposed methods output similar results\nto that of the $l_1$-regularized maximum likelihood estimation for the\naforementioned models. Numerical experiments reveal that our methods work well\nand they may be better than the $l_1$-regularization in generalization,\nparameter estimation, and model selection.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 14:58:18 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 03:03:52 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2020 08:33:29 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Hirose", "Yoshihiro", ""]]}, {"id": "1907.08120", "submitter": "Francesco Ventura", "authors": "Tania Cerquitelli, Stefano Proto, Francesco Ventura, Daniele Apiletti,\n  Elena Baralis", "title": "Automating concept-drift detection by self-evaluating predictive model\n  degradation", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A key aspect of automating predictive machine learning entails the capability\nof properly triggering the update of the trained model. To this aim, suitable\nautomatic solutions to self-assess the prediction quality and the data\ndistribution drift between the original training set and the new data have to\nbe devised. In this paper, we propose a novel methodology to automatically\ndetect prediction-quality degradation of machine learning models due to\nclass-based concept drift, i.e., when new data contains samples that do not fit\nthe set of class labels known by the currently-trained predictive model.\nExperiments on synthetic and real-world public datasets show the effectiveness\nof the proposed methodology in automatically detecting and describing concept\ndrift caused by changes in the class-label data distributions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 15:50:37 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Cerquitelli", "Tania", ""], ["Proto", "Stefano", ""], ["Ventura", "Francesco", ""], ["Apiletti", "Daniele", ""], ["Baralis", "Elena", ""]]}, {"id": "1907.08127", "submitter": "Yishai Shimoni", "authors": "Ehud Karavani, Peter Bak, Yishai Shimoni", "title": "A discriminative approach for finding and characterizing positivity\n  violations using decision trees", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The assumption of positivity in causal inference (also known as common\nsupport and co-variate overlap) is necessary to obtain valid causal estimates.\nTherefore, confirming it holds in a given dataset is an important first step of\nany causal analysis. Most common methods to date are insufficient for\ndiscovering non-positivity, as they do not scale for modern high-dimensional\ncovariate spaces, or they cannot pinpoint the subpopulation violating\npositivity. To overcome these issues, we suggest to harness decision trees for\ndetecting violations. By dividing the covariate space into mutually exclusive\nregions, each with maximized homogeneity of treatment groups, decision trees\ncan be used to automatically detect subspaces violating positivity. By\naugmenting the method with an additional random forest model, we can quantify\nthe robustness of the violation within each subspace. This solution is scalable\nand provides an interpretable characterization of the subspaces in which\nviolations occur. We provide a visualization of the stratification rules that\ndefine each subpopulation, combined with the severity of positivity violation\nwithin it. We also provide an interactive version of the visualization that\nallows a deeper dive into the properties of each subspace.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 16:06:30 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Karavani", "Ehud", ""], ["Bak", "Peter", ""], ["Shimoni", "Yishai", ""]]}, {"id": "1907.08167", "submitter": "Huaixiu Zheng", "authors": "Yue Weng, Huaixiu Zheng, Franziska Bell, Gokhan Tur", "title": "OCC: A Smart Reply System for Efficient In-App Communications", "comments": "link to demo: https://www.youtube.com/watch?v=nOffUT7rS0A&t=32s", "journal-ref": "KDD 19, August 4-8, 2019, Anchorage, AK, USA", "doi": "10.1145/3292500.3330694", "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart reply systems have been developed for various messaging platforms. In\nthis paper, we introduce Uber's smart reply system: one-click-chat (OCC), which\nis a key enhanced feature on top of the Uber in-app chat system. It enables\ndriver-partners to quickly respond to rider messages using smart replies. The\nsmart replies are dynamically selected according to conversation content using\nmachine learning algorithms. Our system consists of two major components:\nintent detection and reply retrieval, which are very different from standard\nsmart reply systems where the task is to directly predict a reply. It is\ndesigned specifically for mobile applications with short and non-canonical\nmessages. Reply retrieval utilizes pairings between intent and reply based on\ntheir popularity in chat messages as derived from historical data. For intent\ndetection, a set of embedding and classification techniques are experimented\nwith, and we choose to deploy a solution using unsupervised distributed\nembedding and nearest-neighbor classifier. It has the advantage of only\nrequiring a small amount of labeled training data, simplicity in developing and\ndeploying to production, and fast inference during serving and hence highly\nscalable. At the same time, it performs comparably with deep learning\narchitectures such as word-level convolutional neural network. Overall, the\nsystem achieves a high accuracy of 76% on intent detection. Currently, the\nsystem is deployed in production for English-speaking countries and 71% of\nin-app communications between riders and driver-partners adopted the smart\nreplies to speedup the communication process.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 17:19:30 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Weng", "Yue", ""], ["Zheng", "Huaixiu", ""], ["Bell", "Franziska", ""], ["Tur", "Gokhan", ""]]}, {"id": "1907.08175", "submitter": "Terrance DeVries", "authors": "Terrance DeVries, Adriana Romero, Luis Pineda, Graham W. Taylor,\n  Michal Drozdzal", "title": "On the Evaluation of Conditional GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Generative Adversarial Networks (cGANs) are finding increasingly\nwidespread use in many application domains. Despite outstanding progress,\nquantitative evaluation of such models often involves multiple distinct metrics\nto assess different desirable properties, such as image quality, conditional\nconsistency, and intra-conditioning diversity. In this setting, model\nbenchmarking becomes a challenge, as each metric may indicate a different\n\"best\" model. In this paper, we propose the Frechet Joint Distance (FJD), which\nis defined as the Frechet distance between joint distributions of images and\nconditioning, allowing it to implicitly capture the aforementioned properties\nin a single metric. We conduct proof-of-concept experiments on a controllable\nsynthetic dataset, which consistently highlight the benefits of FJD when\ncompared to currently established metrics. Moreover, we use the newly\nintroduced metric to compare existing cGAN-based models for a variety of\nconditioning modalities (e.g. class labels, object masks, bounding boxes,\nimages, and text captions). We show that FJD can be used as a promising single\nmetric for cGAN benchmarking and model selection. Code can be found at\nhttps://github.com/facebookresearch/fjd.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 17:41:57 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 21:02:23 GMT"}, {"version": "v3", "created": "Tue, 24 Dec 2019 02:53:54 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["DeVries", "Terrance", ""], ["Romero", "Adriana", ""], ["Pineda", "Luis", ""], ["Taylor", "Graham W.", ""], ["Drozdzal", "Michal", ""]]}, {"id": "1907.08189", "submitter": "Zafiirah Hosenie", "authors": "Zafiirah Hosenie, Robert Lyon, Benjamin Stappers, and Arrykrishna\n  Mootoovaloo", "title": "Comparing Multi-class, Binary and Hierarchical Machine Learning\n  Classification schemes for variable stars", "comments": "16 pages, 11 figures, accepted for publication in MNRAS", "journal-ref": null, "doi": "10.1093/mnras/stz1999", "report-no": null, "categories": "astro-ph.IM cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Upcoming synoptic surveys are set to generate an unprecedented amount of\ndata. This requires an automatic framework that can quickly and efficiently\nprovide classification labels for several new object classification challenges.\nUsing data describing 11 types of variable stars from the Catalina Real-Time\nTransient Surveys (CRTS), we illustrate how to capture the most important\ninformation from computed features and describe detailed methods of how to\nrobustly use Information Theory for feature selection and evaluation. We apply\nthree Machine Learning (ML) algorithms and demonstrate how to optimize these\nclassifiers via cross-validation techniques. For the CRTS dataset, we find that\nthe Random Forest (RF) classifier performs best in terms of balanced-accuracy\nand geometric means. We demonstrate substantially improved classification\nresults by converting the multi-class problem into a binary classification\ntask, achieving a balanced-accuracy rate of $\\sim$99 per cent for the\nclassification of ${\\delta}$-Scuti and Anomalous Cepheids (ACEP). Additionally,\nwe describe how classification performance can be improved via converting a\n'flat-multi-class' problem into a hierarchical taxonomy. We develop a new\nhierarchical structure and propose a new set of classification features,\nenabling the accurate identification of subtypes of cepheids, RR Lyrae and\neclipsing binary stars in CRTS data.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 17:59:02 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Hosenie", "Zafiirah", ""], ["Lyon", "Robert", ""], ["Stappers", "Benjamin", ""], ["Mootoovaloo", "Arrykrishna", ""]]}, {"id": "1907.08209", "submitter": "Benjamin Nachman", "authors": "Anders Andreassen, Benjamin Nachman", "title": "Neural Networks for Full Phase-space Reweighting and Parameter Tuning", "comments": "7 pages, 3 figures; v2 has updated citations and clarifications; v3\n  has a new appendix with an alternative fitting method", "journal-ref": "Phys. Rev. D 101, 091901 (2020)", "doi": "10.1103/PhysRevD.101.091901", "report-no": null, "categories": "hep-ph hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precise scientific analysis in collider-based particle physics is possible\nbecause of complex simulations that connect fundamental theories to observable\nquantities. The significant computational cost of these programs limits the\nscope, precision, and accuracy of Standard Model measurements and searches for\nnew phenomena. We therefore introduce Deep neural networks using Classification\nfor Tuning and Reweighting (DCTR), a neural network-based approach to reweight\nand fit simulations using all kinematic and flavor information -- the full\nphase space. DCTR can perform tasks that are currently not possible with\nexisting methods, such as estimating non-perturbative fragmentation\nuncertainties. The core idea behind the new approach is to exploit powerful\nhigh-dimensional classifiers to reweight phase space as well as to identify the\nbest parameters for describing data. Numerical examples from\n$e^+e^-\\rightarrow\\text{jets}$ demonstrate the fidelity of these methods for\nsimulation parameters that have a big and broad impact on phase space as well\nas those that have a minimal and/or localized impact. The high fidelity of the\nfull phase-space reweighting enables a new paradigm for simulations, parameter\ntuning, and model systematic uncertainties across particle physics and possibly\nbeyond.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 18:00:02 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 06:19:50 GMT"}, {"version": "v3", "created": "Mon, 26 Aug 2019 20:58:17 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Andreassen", "Anders", ""], ["Nachman", "Benjamin", ""]]}, {"id": "1907.08220", "submitter": "Mojtaba Moattari", "authors": "Mojtaba Moattari, Mohammad Hassan Moradi, Reza Boostani", "title": "Modified swarm-based metaheuristics enhance Gradient Descent\n  initialization performance: Application for EEG spatial filtering", "comments": "10 tables, 32 references, 11 formulas. arXiv admin note: text overlap\n  with arXiv:1209.4115 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient Descent (GD) approximators often fail in the solution space with\nmultiple scales of convexities, i.e., in subspace learning and neural network\nscenarios. To handle that, one solution is to run GD multiple times from\ndifferent randomized initial states and select the best solution over all\nexperiments. However, this idea is proved impractical in plenty of cases. Even\nSwarm-based optimizers like Particle Swarm Optimization (PSO) or Imperialistic\nCompetitive Algorithm (ICA), as commonly used GD initializers, have failed to\nfind optimal solutions in some applications. In this paper, Swarm-based\noptimizers like ICA and PSO are modified by a new optimization framework to\nimprove GD optimization performance. This improvement is for applications with\nhigh number of convex localities in multiple scales. Performance of the\nproposed method is analyzed in a nonlinear subspace filtering objective\nfunction over EEG data. The proposed metaheuristic outperforms commonly used\nbaseline optimizers as GD initializers in both the EEG classification accuracy\nand EEG loss function fitness. The optimizers have been also compared to each\nother in some of CEC 2014 benchmark functions, where again our method\noutperforms other algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jun 2019 07:50:16 GMT"}, {"version": "v2", "created": "Wed, 6 May 2020 16:44:02 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Moattari", "Mojtaba", ""], ["Moradi", "Mohammad Hassan", ""], ["Boostani", "Reza", ""]]}, {"id": "1907.08225", "submitter": "Kristian Hartikainen", "authors": "Kristian Hartikainen, Xinyang Geng, Tuomas Haarnoja, Sergey Levine", "title": "Dynamical Distance Learning for Semi-Supervised and Unsupervised Skill\n  Discovery", "comments": "11+6 pages, 6+2 figures, last two authors (Tuomas Haarnoja, Sergey\n  Levine) advised equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning requires manual specification of a reward function to\nlearn a task. While in principle this reward function only needs to specify the\ntask goal, in practice reinforcement learning can be very time-consuming or\neven infeasible unless the reward function is shaped so as to provide a smooth\ngradient towards a successful outcome. This shaping is difficult to specify by\nhand, particularly when the task is learned from raw observations, such as\nimages. In this paper, we study how we can automatically learn dynamical\ndistances: a measure of the expected number of time steps to reach a given goal\nstate from any other state. These dynamical distances can be used to provide\nwell-shaped reward functions for reaching new goals, making it possible to\nlearn complex tasks efficiently. We show that dynamical distances can be used\nin a semi-supervised regime, where unsupervised interaction with the\nenvironment is used to learn the dynamical distances, while a small amount of\npreference supervision is used to determine the task goal, without any manually\nengineered reward function or goal examples. We evaluate our method both on a\nreal-world robot and in simulation. We show that our method can learn to turn a\nvalve with a real-world 9-DoF hand, using raw image observations and just ten\npreference labels, without any other supervision. Videos of the learned skills\ncan be found on the project website:\nhttps://sites.google.com/view/dynamical-distance-learning.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 18:07:47 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 18:25:04 GMT"}, {"version": "v3", "created": "Sat, 16 Nov 2019 14:15:46 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 10:16:54 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Hartikainen", "Kristian", ""], ["Geng", "Xinyang", ""], ["Haarnoja", "Tuomas", ""], ["Levine", "Sergey", ""]]}, {"id": "1907.08226", "submitter": "Stefano Sarao Mannelli", "authors": "Stefano Sarao Mannelli, Giulio Biroli, Chiara Cammarota, Florent\n  Krzakala, and Lenka Zdeborov\\'a", "title": "Who is Afraid of Big Bad Minima? Analysis of Gradient-Flow in a Spiked\n  Matrix-Tensor Model", "comments": "9 pages, 4 figures + appendix. Appears in Proceedings of the Advances\n  in Neural Information Processing Systems 2019 (NeurIPS 2019)", "journal-ref": "Advances in Neural Information Processing Systems, pp. 8676-8686.\n  2019", "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-based algorithms are effective for many machine learning tasks, but\ndespite ample recent effort and some progress, it often remains unclear why\nthey work in practice in optimising high-dimensional non-convex functions and\nwhy they find good minima instead of being trapped in spurious ones.\n  Here we present a quantitative theory explaining this behaviour in a spiked\nmatrix-tensor model.\n  Our framework is based on the Kac-Rice analysis of stationary points and a\nclosed-form analysis of gradient-flow originating from statistical physics. We\nshow that there is a well defined region of parameters where the gradient-flow\nalgorithm finds a good global minimum despite the presence of exponentially\nmany spurious local minima.\n  We show that this is achieved by surfing on saddles that have strong negative\ndirection towards the global minima, a phenomenon that is connected to a\nBBP-type threshold in the Hessian describing the critical points of the\nlandscapes.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 18:11:24 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 13:43:09 GMT"}, {"version": "v3", "created": "Mon, 20 Jan 2020 15:08:26 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Mannelli", "Stefano Sarao", ""], ["Biroli", "Giulio", ""], ["Cammarota", "Chiara", ""], ["Krzakala", "Florent", ""], ["Zdeborov\u00e1", "Lenka", ""]]}, {"id": "1907.08259", "submitter": "Mukul Bhutani", "authors": "Prakhar Gupta, Vinayshekhar Bannihatti Kumar, Mukul Bhutani, Alan W\n  Black", "title": "WriterForcing: Generating more interesting story endings", "comments": "Accepted in ACL workshop on Storytelling 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of generating interesting endings for stories. Neural\ngenerative models have shown promising results for various text generation\nproblems. Sequence to Sequence (Seq2Seq) models are typically trained to\ngenerate a single output sequence for a given input sequence. However, in the\ncontext of a story, multiple endings are possible. Seq2Seq models tend to\nignore the context and generate generic and dull responses. Very few works have\nstudied generating diverse and interesting story endings for a given story\ncontext. In this paper, we propose models which generate more diverse and\ninteresting outputs by 1) training models to focus attention on important\nkeyphrases of the story, and 2) promoting generation of non-generic words. We\nshow that the combination of the two leads to more diverse and interesting\nendings.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 19:29:29 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Gupta", "Prakhar", ""], ["Kumar", "Vinayshekhar Bannihatti", ""], ["Bhutani", "Mukul", ""], ["Black", "Alan W", ""]]}, {"id": "1907.08268", "submitter": "Ari Seff", "authors": "Ari Seff, Wenda Zhou, Farhan Damani, Abigail Doyle, Ryan P. Adams", "title": "Discrete Object Generation with Reversible Inductive Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of generative modeling in continuous domains has led to a surge\nof interest in generating discrete data such as molecules, source code, and\ngraphs. However, construction histories for these discrete objects are\ntypically not unique and so generative models must reason about intractably\nlarge spaces in order to learn. Additionally, structured discrete domains are\noften characterized by strict constraints on what constitutes a valid object\nand generative models must respect these requirements in order to produce\nuseful novel samples. Here, we present a generative model for discrete objects\nemploying a Markov chain where transitions are restricted to a set of local\noperations that preserve validity. Building off of generative interpretations\nof denoising autoencoders, the Markov chain alternates between producing 1) a\nsequence of corrupted objects that are valid but not from the data\ndistribution, and 2) a learned reconstruction distribution that attempts to fix\nthe corruptions while also preserving validity. This approach constrains the\ngenerative model to only produce valid objects, requires the learner to only\ndiscover local modifications to the objects, and avoids marginalization over an\nunknown and potentially large space of construction histories. We evaluate the\nproposed approach on two highly structured discrete domains, molecules and\nLaman graphs, and find that it compares favorably to alternative methods at\ncapturing distributional statistics for a host of semantically relevant\nmetrics.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 20:17:27 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 17:51:12 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Seff", "Ari", ""], ["Zhou", "Wenda", ""], ["Damani", "Farhan", ""], ["Doyle", "Abigail", ""], ["Adams", "Ryan P.", ""]]}, {"id": "1907.08288", "submitter": "Canyi Lu", "authors": "Canyi Lu and Pan Zhou", "title": "Exact Recovery of Tensor Robust Principal Component Analysis under\n  Linear Transforms", "comments": "arXiv admin note: text overlap with arXiv:1804.03728; text overlap\n  with arXiv:1311.6182 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the Tensor Robust Principal Component Analysis (TRPCA)\nproblem, which aims to exactly recover the low-rank and sparse components from\ntheir sum. Our model is motivated by the recently proposed linear transforms\nbased tensor-tensor product and tensor SVD. We define a new transforms depended\ntensor rank and the corresponding tensor nuclear norm. Then we solve the TRPCA\nproblem by convex optimization whose objective is a weighted combination of the\nnew tensor nuclear norm and the $\\ell_1$-norm. In theory, we show that under\ncertain incoherence conditions, the convex program exactly recovers the\nunderlying low-rank and sparse components. It is of great interest that our new\nTRPCA model generalizes existing works. In particular, if the studied tensor\nreduces to a matrix, our TRPCA model reduces to the known matrix RPCA. Our new\nTRPCA which is allowed to use general linear transforms can be regarded as an\nextension of our former TRPCA work which uses the discrete Fourier transform.\nBut their proof of the recovery guarantee is different. Numerical experiments\nverify our results and the application on image recovery demonstrates the\nsuperiority of our method.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 19:05:15 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Lu", "Canyi", ""], ["Zhou", "Pan", ""]]}, {"id": "1907.08294", "submitter": "Yuki Saito", "authors": "Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari", "title": "DNN-based Speaker Embedding Using Subjective Inter-speaker Similarity\n  for Multi-speaker Modeling in Speech Synthesis", "comments": "6 pages, 7 figures, accepted for The 10th ISCA Speech Synthesis\n  Workshop (SSW10)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes novel algorithms for speaker embedding using subjective\ninter-speaker similarity based on deep neural networks (DNNs). Although\nconventional DNN-based speaker embedding such as a $d$-vector can be applied to\nmulti-speaker modeling in speech synthesis, it does not correlate with the\nsubjective inter-speaker similarity and is not necessarily appropriate speaker\nrepresentation for open speakers whose speech utterances are not included in\nthe training data. We propose two training algorithms for DNN-based speaker\nembedding model using an inter-speaker similarity matrix obtained by\nlarge-scale subjective scoring. One is based on similarity vector embedding and\ntrains the model to predict a vector of the similarity matrix as speaker\nrepresentation. The other is based on similarity matrix embedding and trains\nthe model to minimize the squared Frobenius norm between the similarity matrix\nand the Gram matrix of $d$-vectors, i.e., the inter-speaker similarity derived\nfrom the $d$-vectors. We crowdsourced the inter-speaker similarity scores of\n153 Japanese female speakers, and the experimental results demonstrate that our\nalgorithms learn speaker embedding that is highly correlated with the\nsubjective similarity. We also apply the proposed speaker embedding to\nmulti-speaker modeling in DNN-based speech synthesis and reveal that the\nproposed similarity vector embedding improves synthetic speech quality for open\nspeakers whose speech utterances are unseen during the training.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 09:11:35 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Saito", "Yuki", ""], ["Takamichi", "Shinnosuke", ""], ["Saruwatari", "Hiroshi", ""]]}, {"id": "1907.08307", "submitter": "Martin Wistuba", "authors": "Martin Wistuba", "title": "XferNAS: Transfer Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The term Neural Architecture Search (NAS) refers to the automatic\noptimization of network architectures for a new, previously unknown task. Since\ntesting an architecture is computationally very expensive, many optimizers need\ndays or even weeks to find suitable architectures. However, this search time\ncan be significantly reduced if knowledge from previous searches on different\ntasks is reused. In this work, we propose a generally applicable framework that\nintroduces only minor changes to existing optimizers to leverage this feature.\nAs an example, we select an existing optimizer and demonstrate the complexity\nof the integration of the framework as well as its impact. In experiments on\nCIFAR-10 and CIFAR-100, we observe a reduction in the search time from 200 to\nonly 6 GPU days, a speed up by a factor of 33. In addition, we observe new\nrecords of 1.99 and 14.06 for NAS optimizers on the CIFAR benchmarks,\nrespectively. In a separate study, we analyze the impact of the amount of\nsource and target data. Empirically, we demonstrate that the proposed framework\ngenerally gives better results and, in the worst case, is just as good as the\nunmodified optimizer.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 22:05:49 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Wistuba", "Martin", ""]]}, {"id": "1907.08322", "submitter": "Xuling Wang", "authors": "Shirly Wang, Matthew B. A. McDermott, Geeticka Chauhan, Michael C.\n  Hughes, Tristan Naumann, Marzyeh Ghassemi", "title": "MIMIC-Extract: A Data Extraction, Preprocessing, and Representation\n  Pipeline for MIMIC-III", "comments": null, "journal-ref": null, "doi": "10.1145/3368555.3384469", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust machine learning relies on access to data that can be used with\nstandardized frameworks in important tasks and the ability to develop models\nwhose performance can be reasonably reproduced. In machine learning for\nhealthcare, the community faces reproducibility challenges due to a lack of\npublicly accessible data and a lack of standardized data processing frameworks.\nWe present MIMIC-Extract, an open-source pipeline for transforming raw\nelectronic health record (EHR) data for critical care patients contained in the\npublicly-available MIMIC-III database into dataframes that are directly usable\nin common machine learning pipelines. MIMIC-Extract addresses three primary\nchallenges in making complex health records data accessible to the broader\nmachine learning community. First, it provides standardized data processing\nfunctions, including unit conversion, outlier detection, and aggregating\nsemantically equivalent features, thus accounting for duplication and reducing\nmissingness. Second, it preserves the time series nature of clinical data and\ncan be easily integrated into clinically actionable prediction tasks in machine\nlearning for health. Finally, it is highly extensible so that other researchers\nwith related questions can easily use the same pipeline. We demonstrate the\nutility of this pipeline by showcasing several benchmark tasks and baseline\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 00:13:52 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2020 17:38:36 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Wang", "Shirly", ""], ["McDermott", "Matthew B. A.", ""], ["Chauhan", "Geeticka", ""], ["Hughes", "Michael C.", ""], ["Naumann", "Tristan", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "1907.08325", "submitter": "Shusen Liu", "authors": "Shusen Liu, Di Wang, Dan Maljovec, Rushil Anirudh, Jayaraman J.\n  Thiagarajan, Sam Ade Jacobs, Brian C. Van Essen, David Hysom, Jae-Seung Yeom,\n  Jim Gaffney, Luc Peterson, Peter B. Robinson, Harsh Bhatia, Valerio Pascucci,\n  Brian K. Spears and Peer-Timo Bremer", "title": "Scalable Topological Data Analysis and Visualization for Evaluating\n  Data-Driven Models in Scientific Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid adoption of machine learning techniques for large-scale\napplications in science and engineering comes the convergence of two grand\nchallenges in visualization. First, the utilization of black box models (e.g.,\ndeep neural networks) calls for advanced techniques in exploring and\ninterpreting model behaviors. Second, the rapid growth in computing has\nproduced enormous datasets that require techniques that can handle millions or\nmore samples. Although some solutions to these interpretability challenges have\nbeen proposed, they typically do not scale beyond thousands of samples, nor do\nthey provide the high-level intuition scientists are looking for. Here, we\npresent the first scalable solution to explore and analyze high-dimensional\nfunctions often encountered in the scientific data analysis pipeline. By\ncombining a new streaming neighborhood graph construction, the corresponding\ntopology computation, and a novel data aggregation scheme, namely topology\naware datacubes, we enable interactive exploration of both the topological and\nthe geometric aspect of high-dimensional data. Following two use cases from\nhigh-energy-density (HED) physics and computational biology, we demonstrate how\nthese capabilities have led to crucial new insights in both applications.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 00:37:39 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Liu", "Shusen", ""], ["Wang", "Di", ""], ["Maljovec", "Dan", ""], ["Anirudh", "Rushil", ""], ["Thiagarajan", "Jayaraman J.", ""], ["Jacobs", "Sam Ade", ""], ["Van Essen", "Brian C.", ""], ["Hysom", "David", ""], ["Yeom", "Jae-Seung", ""], ["Gaffney", "Jim", ""], ["Peterson", "Luc", ""], ["Robinson", "Peter B.", ""], ["Bhatia", "Harsh", ""], ["Pascucci", "Valerio", ""], ["Spears", "Brian K.", ""], ["Bremer", "Peer-Timo", ""]]}, {"id": "1907.08333", "submitter": "Abdul Karim", "authors": "Abdul Karim, Jaspreet Singh, Avinash Mishra, Abdollah Dehzangi, M. A.\n  Hakim Newton, and Abdul Sattar", "title": "Toxicity Prediction by Multimodal Deep Learning", "comments": "Preprint Version", "journal-ref": "2019 Pacific Rim Knowledge Acquisition Workshop", "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of toxicity levels of chemical compounds is an important issue in\nQuantitative Structure-Activity Relationship (QSAR) modeling. Although toxicity\nprediction has achieved significant progress in recent times through deep\nlearning, prediction accuracy levels obtained by even very recent methods are\nnot yet very high. We propose a multimodal deep learning method using multiple\nheterogeneous neural network types and data representations. We represent\nchemical compounds by strings, images, and numerical features. We train fully\nconnected, convolutional, and recurrent neural networks and their ensembles.\nEach data representation or neural network type has its own strengths and\nweaknesses. Our motivation is to obtain a collective performance that could go\nbeyond individual performance of each data representation or each neural\nnetwork type. On a standard toxicity benchmark, our proposed method obtains\nsignificantly better accuracy levels than that by the state-of-the-art toxicity\nprediction methods.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 01:32:02 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Karim", "Abdul", ""], ["Singh", "Jaspreet", ""], ["Mishra", "Avinash", ""], ["Dehzangi", "Abdollah", ""], ["Newton", "M. A. Hakim", ""], ["Sattar", "Abdul", ""]]}, {"id": "1907.08334", "submitter": "Harrison Nguyen", "authors": "Eddie Anderson, Harrison Nguyen", "title": "When can we improve on sample average approximation for stochastic\n  optimization?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the performance of sample average approximation in comparison with\nseveral other methods for stochastic optimization when there is information\navailable on the underlying true probability distribution. The methods we\nevaluate are (a) bagging; (b) kernel smoothing; (c) maximum likelihood\nestimation (MLE); and (d) a Bayesian approach. We use two test sets, the first\nhas a quadratic objective function allowing for very different types of\ninteraction between the random component and the univariate decision variable.\nHere the sample average approximation is remarkably effective and only\nconsistently outperformed by a Bayesian approach. The second test set is a\nportfolio optimization problem in which we use different covariance structures\nfor a set of 5 stocks. Here bagging, MLE and a Bayesian approach all do well.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 01:33:11 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Anderson", "Eddie", ""], ["Nguyen", "Harrison", ""]]}, {"id": "1907.08338", "submitter": "Yuma Koizumi", "authors": "Yuma Koizumi, Shoichiro Saito, Masataka Yamaguchi, Shin Murata and\n  Noboru Harada", "title": "Batch Uniformization for Minimizing Maximum Anomaly Score of DNN-based\n  Anomaly Detection in Sounds", "comments": "5 pages, to appear in IEEE WASPAA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Use of an autoencoder (AE) as a normal model is a state-of-the-art technique\nfor unsupervised-anomaly detection in sounds (ADS). The AE is trained to\nminimize the sample mean of the anomaly score of normal sounds in a mini-batch.\nOne problem with this approach is that the anomaly score of rare-normal sounds\nbecomes higher than that of frequent-normal sounds, because the sample mean is\nstrongly affected by frequent-normal samples, resulting in preferentially\ndecreasing the anomaly score of frequent-normal samples. To decrease anomaly\nscores for both frequent- and rare-normal sounds, we propose batch\nuniformization, a training method for unsupervised-ADS for minimizing a\nweighted average of the anomaly score on each sample in a mini-batch. We used\nthe reciprocal of the probabilistic density of each sample as the weight, more\nintuitively, a large weight is given for rare-normal sounds. Such a weight\nworks to give a constant anomaly score for both frequent- and rare-normal\nsounds. Since the probabilistic density is unknown, we estimate it by using the\nkernel density estimation on each training mini-batch. Verification- and\nobjective-experiments show that the proposed batch uniformization improves the\nperformance of unsupervised-ADS.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 01:58:20 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Koizumi", "Yuma", ""], ["Saito", "Shoichiro", ""], ["Yamaguchi", "Masataka", ""], ["Murata", "Shin", ""], ["Harada", "Noboru", ""]]}, {"id": "1907.08350", "submitter": "Yusuke Tanaka", "authors": "Yusuke Tanaka, Toshiyuki Tanaka, Tomoharu Iwata, Takeshi Kurashima,\n  Maya Okawa, Yasunori Akagi, Hiroyuki Toda", "title": "Spatially Aggregated Gaussian Processes with Multivariate Areal Outputs", "comments": "Accepted at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a probabilistic model for inferring the multivariate function from\nmultiple areal data sets with various granularities. Here, the areal data are\nobserved not at location points but at regions. Existing regression-based\nmodels can only utilize the sufficiently fine-grained auxiliary data sets on\nthe same domain (e.g., a city). With the proposed model, the functions for\nrespective areal data sets are assumed to be a multivariate dependent Gaussian\nprocess (GP) that is modeled as a linear mixing of independent latent GPs.\nSharing of latent GPs across multiple areal data sets allows us to effectively\nestimate the spatial correlation for each areal data set; moreover it can\neasily be extended to transfer learning across multiple domains. To handle the\nmultivariate areal data, we design an observation model with a spatial\naggregation process for each areal data set, which is an integral of the mixed\nGP over the corresponding region. By deriving the posterior GP, we can predict\nthe data value at any location point by considering the spatial correlations\nand the dependences between areal data sets, simultaneously. Our experiments on\nreal-world data sets demonstrate that our model can 1) accurately refine\ncoarse-grained areal data, and 2) offer performance improvements by using the\nareal data sets from multiple domains.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 02:45:50 GMT"}, {"version": "v2", "created": "Tue, 7 Jan 2020 11:08:57 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Tanaka", "Yusuke", ""], ["Tanaka", "Toshiyuki", ""], ["Iwata", "Tomoharu", ""], ["Kurashima", "Takeshi", ""], ["Okawa", "Maya", ""], ["Akagi", "Yasunori", ""], ["Toda", "Hiroyuki", ""]]}, {"id": "1907.08375", "submitter": "Feng Liu", "authors": "Zhen Fang, Jie Lu, Feng Liu, Junyu Xuan, Guangquan Zhang", "title": "Open Set Domain Adaptation: Theoretical Bound and Algorithm", "comments": "This paper has been accepted by IEEE-TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The aim of unsupervised domain adaptation is to leverage the knowledge in a\nlabeled (source) domain to improve a model's learning performance with an\nunlabeled (target) domain -- the basic strategy being to mitigate the effects\nof discrepancies between the two distributions. Most existing algorithms can\nonly handle unsupervised closed set domain adaptation (UCSDA), i.e., where the\nsource and target domains are assumed to share the same label set. In this\npaper, we target a more challenging but realistic setting: unsupervised open\nset domain adaptation (UOSDA), where the target domain has unknown classes that\nare not found in the source domain. This is the first study to provide a\nlearning bound for open set domain adaptation, which we do by theoretically\ninvestigating the risk of the target classifier on unknown classes. The\nproposed learning bound has a special term, namely open set difference, which\nreflects the risk of the target classifier on unknown classes. Further, we\npresent a novel and theoretically guided unsupervised algorithm for open set\ndomain adaptation, called distribution alignment with ppen difference (DAOD),\nwhich is based on regularizing this open set difference bound. The experiments\non several benchmark datasets show the superior performance of the proposed\nUOSDA method compared with the state-of-the-art methods in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 05:39:32 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 01:22:17 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Fang", "Zhen", ""], ["Lu", "Jie", ""], ["Liu", "Feng", ""], ["Xuan", "Junyu", ""], ["Zhang", "Guangquan", ""]]}, {"id": "1907.08392", "submitter": "Thilo Stadelmann", "authors": "Lukas Tuggener, Mohammadreza Amirian, Katharina Rombach, Stefan\n  L\\\"orwald, Anastasia Varlet, Christian Westermann, Thilo Stadelmann", "title": "Automated Machine Learning in Practice: State of the Art and Recent\n  Results", "comments": "Accepted full paper at SDS2019, the 6th Swiss Conference on Data\n  Science", "journal-ref": null, "doi": "10.1109/SDS.2019.00-11", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A main driver behind the digitization of industry and society is the belief\nthat data-driven model building and decision making can contribute to higher\ndegrees of automation and more informed decisions. Building such models from\ndata often involves the application of some form of machine learning. Thus,\nthere is an ever growing demand in work force with the necessary skill set to\ndo so. This demand has given rise to a new research topic concerned with\nfitting machine learning models fully automatically - AutoML. This paper gives\nan overview of the state of the art in AutoML with a focus on practical\napplicability in a business context, and provides recent benchmark results on\nthe most important AutoML algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 07:19:07 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Tuggener", "Lukas", ""], ["Amirian", "Mohammadreza", ""], ["Rombach", "Katharina", ""], ["L\u00f6rwald", "Stefan", ""], ["Varlet", "Anastasia", ""], ["Westermann", "Christian", ""], ["Stadelmann", "Thilo", ""]]}, {"id": "1907.08410", "submitter": "Rajiv Khanna", "authors": "Rajiv Khanna, Michael W. Mahoney", "title": "On Linear Convergence of Weighted Kernel Herding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a novel convergence analysis of two popular sampling algorithms,\nWeighted Kernel Herding and Sequential Bayesian Quadrature, that are used to\napproximate the expectation of a function under a distribution. Existing\ntheoretical analysis was insufficient to explain the empirical successes of\nthese algorithms. We improve upon existing convergence rates to show that,\nunder mild assumptions, these algorithms converge linearly. To this end, we\nalso suggest a simplifying assumption that is true for most cases in finite\ndimensions, and that acts as a sufficient condition for linear convergence to\nhold in the much harder case of infinite dimensions. When this condition is not\nsatisfied, we provide a weaker convergence guarantee. Our analysis also yields\na new distributed algorithm for large-scale computation that we prove converges\nlinearly under the same assumptions. Finally, we provide an empirical\nevaluation to test the proposed algorithm for a real world application.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 08:49:12 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 02:18:12 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Khanna", "Rajiv", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1907.08440", "submitter": "Vijaikumar M", "authors": "Vijaikumar M and Shirish Shevade and M N Murty", "title": "Neural Cross-Domain Collaborative Filtering with Shared Entities", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-Domain Collaborative Filtering (CDCF) provides a way to alleviate data\nsparsity and cold-start problems present in recommendation systems by\nexploiting the knowledge from related domains. Existing CDCF models are either\nbased on matrix factorization or deep neural networks. Either of the techniques\nin isolation may result in suboptimal performance for the prediction task.\nAlso, most of the existing models face challenges particularly in handling\ndiversity between domains and learning complex non-linear relationships that\nexist amongst entities (users/items) within and across domains. In this work,\nwe propose an end-to-end neural network model -- NeuCDCF, to address these\nchallenges in a cross-domain setting. More importantly, NeuCDCF follows a wide\nand deep framework and it learns the representations combinedly from both\nmatrix factorization and deep neural networks. We perform experiments on four\nreal-world datasets and demonstrate that our model performs better than\nstate-of-the-art CDCF models.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 10:04:28 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["M", "Vijaikumar", ""], ["Shevade", "Shirish", ""], ["Murty", "M N", ""]]}, {"id": "1907.08456", "submitter": "Frederik Kratzert", "authors": "Frederik Kratzert, Daniel Klotz, Guy Shalev, G\\\"unter Klambauer, Sepp\n  Hochreiter, Grey Nearing", "title": "Towards Learning Universal, Regional, and Local Hydrological Behaviors\n  via Machine-Learning Applied to Large-Sample Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Regional rainfall-runoff modeling is an old but still mostly out-standing\nproblem in Hydrological Sciences. The problem currently is that traditional\nhydrological models degrade significantly in performance when calibrated for\nmultiple basins together instead of for a single basin alone. In this paper, we\npropose a novel, data-driven approach using Long Short-Term Memory networks\n(LSTMs), and demonstrate that under a 'big data' paradigm, this is not\nnecessarily the case. By training a single LSTM model on 531 basins from the\nCAMELS data set using meteorological time series data and static catchment\nattributes, we were able to significantly improve performance compared to a set\nof several different hydrological benchmark models. Our proposed approach not\nonly significantly outperforms hydrological models that were calibrated\nregionally but also achieves better performance than hydrological models that\nwere calibrated for each basin individually. Furthermore, we propose an\nadaption to the standard LSTM architecture, which we call an Entity-Aware-LSTM\n(EA-LSTM), that allows for learning, and embedding as a feature layer in a deep\nlearning model, catchment similarities. We show that this learned catchment\nsimilarity corresponds well with what we would expect from prior hydrological\nunderstanding.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 10:52:12 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 15:03:52 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Kratzert", "Frederik", ""], ["Klotz", "Daniel", ""], ["Shalev", "Guy", ""], ["Klambauer", "G\u00fcnter", ""], ["Hochreiter", "Sepp", ""], ["Nearing", "Grey", ""]]}, {"id": "1907.08461", "submitter": "Vanessa Kosoy", "authors": "Vanessa Kosoy", "title": "Delegative Reinforcement Learning: learning to avoid traps with a little\n  help", "comments": "22 pages", "journal-ref": "SafeML ICLR 2019 Workshop", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most known regret bounds for reinforcement learning are either episodic or\nassume an environment without traps. We derive a regret bound without making\neither assumption, by allowing the algorithm to occasionally delegate an action\nto an external advisor. We thus arrive at a setting of active one-shot\nmodel-based reinforcement learning that we call DRL (delegative reinforcement\nlearning.) The algorithm we construct in order to demonstrate the regret bound\nis a variant of Posterior Sampling Reinforcement Learning supplemented by a\nsubroutine that decides which actions should be delegated. The algorithm is not\nanytime, since the parameters must be adjusted according to the target time\ndiscount. Currently, our analysis is limited to Markov decision processes with\nfinite numbers of hypotheses, states and actions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 11:19:03 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Kosoy", "Vanessa", ""]]}, {"id": "1907.08467", "submitter": "Iuri Frosio", "authors": "Steven Dalton and Iuri Frosio and Michael Garland", "title": "Accelerating Reinforcement Learning through GPU Atari Emulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce CuLE (CUDA Learning Environment), a CUDA port of the Atari\nLearning Environment (ALE) which is used for the development of deep\nreinforcement algorithms. CuLE overcomes many limitations of existing CPU-based\nemulators and scales naturally to multiple GPUs. It leverages GPU\nparallelization to run thousands of games simultaneously and it renders frames\ndirectly on the GPU, to avoid the bottleneck arising from the limited CPU-GPU\ncommunication bandwidth. CuLE generates up to 155M frames per hour on a single\nGPU, a finding previously achieved only through a cluster of CPUs. Beyond\nhighlighting the differences between CPU and GPU emulators in the context of\nreinforcement learning, we show how to leverage the high throughput of CuLE by\neffective batching of the training data, and show accelerated convergence for\nA2C+V-trace. CuLE is available at https://github.com/NVLabs/cule .\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 11:36:10 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2020 18:49:48 GMT"}], "update_date": "2020-10-07", "authors_parsed": [["Dalton", "Steven", ""], ["Frosio", "Iuri", ""], ["Garland", "Michael", ""]]}, {"id": "1907.08475", "submitter": "Bernhard Bermeitinger", "authors": "Bernhard Bermeitinger, Tomas Hrycej, Siegfried Handschuh", "title": "Representational Capacity of Deep Neural Networks -- A Computing Study", "comments": null, "journal-ref": "2019 11th International Conference on Knowledge Discovery and\n  Information Retrieval (KDIR)", "doi": "10.5220/0008364305320538", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is some theoretical evidence that deep neural networks with multiple\nhidden layers have a potential for more efficient representation of\nmultidimensional mappings than shallow networks with a single hidden layer. The\nquestion is whether it is possible to exploit this theoretical advantage for\nfinding such representations with help of numerical training methods. Tests\nusing prototypical problems with a known mean square minimum did not confirm\nthis hypothesis. Minima found with the help of deep networks have always been\nworse than those found using shallow networks. This does not directly\ncontradict the theoretical findings---it is possible that the superior\nrepresentational capacity of deep networks is genuine while finding the mean\nsquare minimum of such deep networks is a substantially harder problem than\nwith shallow ones.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 11:56:09 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Bermeitinger", "Bernhard", ""], ["Hrycej", "Tomas", ""], ["Handschuh", "Siegfried", ""]]}, {"id": "1907.08535", "submitter": "Rasmus Jones", "authors": "Rasmus T. Jones, Metodi P. Yankov, Darko Zibar", "title": "End-to-end Learning for GMI Optimized Geometric Constellation Shape", "comments": "submitted to ECOC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT eess.SP math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoencoder-based geometric shaping is proposed that includes optimizing bit\nmappings. Up to 0.2 bits/QAM symbol gain in GMI is achieved for a variety of\ndata rates and in the presence of transceiver impairments. The gains can be\nharvested with standard binary FEC at no cost w.r.t. conventional BICM.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 14:48:06 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Jones", "Rasmus T.", ""], ["Yankov", "Metodi P.", ""], ["Zibar", "Darko", ""]]}, {"id": "1907.08544", "submitter": "Enzo Tartaglione", "authors": "Enzo Tartaglione, Daniele Perlo and Marco Grangetto", "title": "Post-synaptic potential regularization has potential", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving generalization is one of the main challenges for training deep\nneural networks on classification tasks. In particular, a number of techniques\nhave been proposed, aiming to boost the performance on unseen data: from\nstandard data augmentation techniques to the $\\ell_2$ regularization, dropout,\nbatch normalization, entropy-driven SGD and many more.\\\\ In this work we\npropose an elegant, simple and principled approach: post-synaptic potential\nregularization (PSP). We tested this regularization on a number of different\nstate-of-the-art scenarios. Empirical results show that PSP achieves a\nclassification error comparable to more sophisticated learning strategies in\nthe MNIST scenario, while improves the generalization compared to $\\ell_2$\nregularization in deep architectures trained on CIFAR-10.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 15:25:21 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Tartaglione", "Enzo", ""], ["Perlo", "Daniele", ""], ["Grangetto", "Marco", ""]]}, {"id": "1907.08556", "submitter": "Divya Saxena", "authors": "Divya Saxena, Jiannong Cao", "title": "D-GAN: Deep Generative Adversarial Nets for Spatio-Temporal Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatio-temporal (ST) data for urban applications, such as taxi demand,\ntraffic flow, regional rainfall is inherently stochastic and unpredictable.\nRecently, deep learning based ST prediction models are proposed to learn the ST\ncharacteristics of data. However, it is still very challenging (1) to\nadequately learn the complex and non-linear ST relationships; (2) to model the\nhigh variations in the ST data volumes as it is inherently dynamic, changing\nover time (i.e., irregular) and highly influenced by many external factors,\nsuch as adverse weather, accidents, traffic control, PoI, etc.; and (3) as\nthere can be many complicated external factors that can affect the accuracy and\nit is impossible to list them explicitly. To handle the aforementioned issues,\nin this paper, we propose a novel deep generative adversarial network based\nmodel (named, D-GAN) for more accurate ST prediction by implicitly learning ST\nfeature representations in an unsupervised manner. D-GAN adopts a GAN-based\nstructure and jointly learns generation and variational inference of data. More\nspecifically, D-GAN consists of two major parts: (1) a deep ST feature learning\nnetwork to model the ST correlations and semantic variations, and underlying\nfactors of variations and irregularity in the data through the implicit\ndistribution modelling; (2) a fusion module to incorporate external factors for\nreaching a better inference. To the best our knowledge, no prior work studies\nST prediction problem via deep implicit generative model and in an unsupervised\nmanner. Extensive experiments performed on two real-world datasets show that\nD-GAN achieves more accurate results than traditional as well as deep learning\nbased ST prediction methods.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 15:54:54 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 08:56:50 GMT"}, {"version": "v3", "created": "Sat, 29 May 2021 10:17:13 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Saxena", "Divya", ""], ["Cao", "Jiannong", ""]]}, {"id": "1907.08566", "submitter": "Peter Tait A", "authors": "Peter A. Tait, Paul D. McNicholas and Joyce Obeid", "title": "Clustering Higher Order Data: An Application to Pediatric Multi-variable\n  Longitudinal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical activity levels are an important predictor of cardiovascular health\nand increasingly being measured by sensors, like accelerometers. Accelerometers\nproduce rich multivariate data that can inform important clinical decisions\nrelated to individual patients and public health. The CHAMPION study, a study\nof youth with chronic inflammatory conditions, aims to determine the links\nbetween heart health, inflammation, physical activity, and fitness. The\naccelerometer data from CHAMPION is represented as 4-dimensional arrays, and a\nfinite mixture of multidimensional arrays model is developed for clustering.\nThe use of model-based clustering for multidimensional arrays has thus far been\nlimited to two-dimensional arrays, i.e., matrices or order-two tensors, and the\nwork in this paper can also be seen as an approach for clustering D-dimensional\narrays for D > 2 or, in other words, for clustering order-D tensors.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 16:40:01 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2019 21:33:56 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2020 17:09:19 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Tait", "Peter A.", ""], ["McNicholas", "Paul D.", ""], ["Obeid", "Joyce", ""]]}, {"id": "1907.08577", "submitter": "Abdelaali Hassaine", "authors": "Abdelaali Hassaine, Dexter Canoy, Jose Roberto Ayala Solares, Yajie\n  Zhu, Shishir Rao, Yikuan Li, Mariagrazia Zottoli, Kazem Rahimi, Gholamreza\n  Salimi-Khorshidi", "title": "Learning Multimorbidity Patterns from Electronic Health Records Using\n  Non-negative Matrix Factorisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimorbidity, or the presence of several medical conditions in the same\nindividual, has been increasing in the population, both in absolute and\nrelative terms. However, multimorbidity remains poorly understood, and the\nevidence from existing research to describe its burden, determinants and\nconsequences has been limited. Previous studies attempting to understand\nmultimorbidity patterns are often cross-sectional and do not explicitly account\nfor multimorbidity patterns' evolution over time; some of them are based on\nsmall datasets and/or use arbitrary and narrow age ranges; and those that\nemployed advanced models, usually lack appropriate benchmarking and\nvalidations. In this study, we (1) introduce a novel approach for using\nNon-negative Matrix Factorisation (NMF) for temporal phenotyping (i.e.,\nsimultaneously mining disease clusters and their trajectories); (2) provide\nquantitative metrics for the evaluation of disease clusters from such studies;\nand (3) demonstrate how the temporal characteristics of the disease clusters\nthat result from our model can help mine multimorbidity networks and generate\nnew hypotheses for the emergence of various multimorbidity patterns over time.\nWe trained and evaluated our models on one of the world's largest electronic\nhealth records (EHR), with 7 million patients, from which over 2 million where\nrelevant to this study.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 17:03:44 GMT"}, {"version": "v2", "created": "Mon, 18 Nov 2019 10:33:55 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Hassaine", "Abdelaali", ""], ["Canoy", "Dexter", ""], ["Solares", "Jose Roberto Ayala", ""], ["Zhu", "Yajie", ""], ["Rao", "Shishir", ""], ["Li", "Yikuan", ""], ["Zottoli", "Mariagrazia", ""], ["Rahimi", "Kazem", ""], ["Salimi-Khorshidi", "Gholamreza", ""]]}, {"id": "1907.08589", "submitter": "Justin Shenk", "authors": "Justin Shenk, Mats L. Richter, Anders Arpteg, Mikael Huss", "title": "Spectral Analysis of Latent Representations", "comments": "13 pages, 16 figures, code: https://github.com/delve-team/delve", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a metric, Layer Saturation, defined as the proportion of the\nnumber of eigenvalues needed to explain 99% of the variance of the latent\nrepresentations, for analyzing the learned representations of neural network\nlayers. Saturation is based on spectral analysis and can be computed\nefficiently, making live analysis of the representations practical during\ntraining. We provide an outlook for future applications of this metric by\noutlining the behaviour of layer saturation in different neural architectures\nand problems. We further show that saturation is related to the generalization\nand predictive performance of neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 17:41:28 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Shenk", "Justin", ""], ["Richter", "Mats L.", ""], ["Arpteg", "Anders", ""], ["Huss", "Mikael", ""]]}, {"id": "1907.08592", "submitter": "Houman Owhadi", "authors": "Houman Owhadi and Clint Scovel and Gene Ryan Yoo", "title": "Kernel Mode Decomposition and programmable/interpretable regression\n  networks", "comments": "102 pages, 39 figures. Python source codes available at\n  https://github.com/kernel-enthusiasts/Kernel-Mode-Decomposition-1D", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mode decomposition is a prototypical pattern recognition problem that can be\naddressed from the (a priori distinct) perspectives of numerical approximation,\nstatistical inference and deep learning. Could its analysis through these\ncombined perspectives be used as a Rosetta stone for deciphering mechanisms at\nplay in deep learning? Motivated by this question we introduce programmable and\ninterpretable regression networks for pattern recognition and address mode\ndecomposition as a prototypical problem. The programming of these networks is\nachieved by assembling elementary modules decomposing and recomposing kernels\nand data. These elementary steps are repeated across levels of abstraction and\ninterpreted from the equivalent perspectives of optimal recovery, game theory\nand Gaussian process regression (GPR). The prototypical mode/kernel\ndecomposition module produces an optimal approximation $(w_1,w_2,\\cdots,w_m)$\nof an element $(v_1,v_2,\\ldots,v_m)$ of a product of Hilbert subspaces of a\ncommon Hilbert space from the observation of the sum $v:=v_1+\\cdots+v_m$. The\nprototypical mode/kernel recomposition module performs partial sums of the\nrecovered modes $w_i$ based on the alignment between each recovered mode $w_i$\nand the data $v$. We illustrate the proposed framework by programming\nregression networks approximating the modes $v_i=\na_i(t)y_i\\big(\\theta_i(t)\\big)$ of a (possibly noisy) signal $\\sum_i v_i$ when\nthe amplitudes $a_i$, instantaneous phases $\\theta_i$ and periodic waveforms\n$y_i$ may all be unknown and show near machine precision recovery under\nregularity and separation assumptions on the instantaneous amplitudes $a_i$ and\nfrequencies $\\dot{\\theta}_i$. The structure of some of these networks share\nintriguing similarities with convolutional neural networks while being\ninterpretable, programmable and amenable to theoretical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 17:42:27 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 19:07:36 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Owhadi", "Houman", ""], ["Scovel", "Clint", ""], ["Yoo", "Gene Ryan", ""]]}, {"id": "1907.08600", "submitter": "Luca Manneschi", "authors": "Luca Manneschi, Andrew C. Lin, Eleni Vasilaki", "title": "Learning sparsity in reservoir computing through a novel bio-inspired\n  algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mushroom body is the key network for the representation of learned\nolfactory stimuli in Drosophila and insects. The sparse activity of Kenyon\ncells, the principal neurons in the mushroom body, plays a key role in the\nlearned classification of different odours. In the specific case of the fruit\nfly, the sparseness of the network is enforced by an inhibitory feedback neuron\ncalled APL, and by an intrinsic high firing threshold of the Kenyon cells. In\nthis work we took inspiration from the fruit fly brain to formulate a novel\nmachine learning algorithm that is able to optimize the sparsity level of a\nreservoir by changing the firing thresholds of the nodes. The sparsity is only\napplied on the readout layer so as not to change the timescales of the\nreservoir and to allow the derivation of a one-layer update rule for the firing\nthresholds. The proposed algorithm is a combination of learning a\nneuron-specific sparsity threshold via gradient descent and a global sparsity\nthreshold via a Markov chain Monte Carlo method. The proposed model outperforms\nthe standard gradient descent, which is limited to the readout weights of the\nreservoir, on two example tasks. It demonstrates how the learnt sparse\nrepresentation can lead to better classification performance, memorization\nability and convergence time.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 17:53:29 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Manneschi", "Luca", ""], ["Lin", "Andrew C.", ""], ["Vasilaki", "Eleni", ""]]}, {"id": "1907.08610", "submitter": "Michael Zhang", "authors": "Michael R. Zhang, James Lucas, Geoffrey Hinton, Jimmy Ba", "title": "Lookahead Optimizer: k steps forward, 1 step back", "comments": "Accepted to Neural Information Processing Systems 2019. Code\n  available at: https://github.com/michaelrzhang/lookahead", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vast majority of successful deep neural networks are trained using\nvariants of stochastic gradient descent (SGD) algorithms. Recent attempts to\nimprove SGD can be broadly categorized into two approaches: (1) adaptive\nlearning rate schemes, such as AdaGrad and Adam, and (2) accelerated schemes,\nsuch as heavy-ball and Nesterov momentum. In this paper, we propose a new\noptimization algorithm, Lookahead, that is orthogonal to these previous\napproaches and iteratively updates two sets of weights. Intuitively, the\nalgorithm chooses a search direction by looking ahead at the sequence of fast\nweights generated by another optimizer. We show that Lookahead improves the\nlearning stability and lowers the variance of its inner optimizer with\nnegligible computation and memory cost. We empirically demonstrate Lookahead\ncan significantly improve the performance of SGD and Adam, even with their\ndefault hyperparameter settings on ImageNet, CIFAR-10/100, neural machine\ntranslation, and Penn Treebank.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 17:59:50 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 15:55:38 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Zhang", "Michael R.", ""], ["Lucas", "James", ""], ["Hinton", "Geoffrey", ""], ["Ba", "Jimmy", ""]]}, {"id": "1907.08615", "submitter": "Ben Gelman", "authors": "Jacob Dormuth, Ben Gelman, Jessica Moore, and David Slater", "title": "Logical Segmentation of Source Code", "comments": "SEKE2019 Conference Full Paper", "journal-ref": null, "doi": "10.18293/SEKE2019-026", "report-no": null, "categories": "cs.SE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many software analysis methods have come to rely on machine learning\napproaches. Code segmentation - the process of decomposing source code into\nmeaningful blocks - can augment these methods by featurizing code, reducing\nnoise, and limiting the problem space. Traditionally, code segmentation has\nbeen done using syntactic cues; current approaches do not intentionally capture\nlogical content. We develop a novel deep learning approach to generate logical\ncode segments regardless of the language or syntactic correctness of the code.\nDue to the lack of logically segmented source code, we introduce a unique data\nset construction technique to approximate ground truth for logically segmented\ncode. Logical code segmentation can improve tasks such as automatically\ncommenting code, detecting software vulnerabilities, repairing bugs, labeling\ncode functionality, and synthesizing new code.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 18:23:26 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Dormuth", "Jacob", ""], ["Gelman", "Ben", ""], ["Moore", "Jessica", ""], ["Slater", "David", ""]]}, {"id": "1907.08646", "submitter": "John Lafferty", "authors": "Dana Yang, John Lafferty, David Pollard", "title": "Fair quantile regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantile regression is a tool for learning conditional distributions. In this\npaper we study quantile regression in the setting where a protected attribute\nis unavailable when fitting the model. This can lead to \"unfair'' quantile\nestimators for which the effective quantiles are very different for the\nsubpopulations defined by the protected attribute. We propose a procedure for\nadjusting the estimator on a heldout sample where the protected attribute is\navailable. The main result of the paper is an empirical process analysis\nshowing that the adjustment leads to a fair estimator for which the target\nquantiles are brought into balance, in a statistical sense that we call\n$\\sqrt{n}$-fairness. We illustrate the ideas and adjustment procedure on a\ndataset of 200,000 live births, where the objective is to characterize the\ndependence of the birth weights of the babies on demographic attributes of the\nbirth mother; the protected attribute is the mother's race.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 18:52:35 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Yang", "Dana", ""], ["Lafferty", "John", ""], ["Pollard", "David", ""]]}, {"id": "1907.08650", "submitter": "Sutanay Choudhury", "authors": "Khushbu Agarwal, Tome Eftimov, Raghavendra Addanki, Sutanay Choudhury,\n  Suzanne Tamang, and Robert Rallo", "title": "Snomed2Vec: Random Walk and Poincar\\'e Embeddings of a Clinical\n  Knowledge Base for Healthcare Analytics", "comments": "2019 KDD Workshop on Applied Data Science for Healthcare (DSHealth\n  '19). https://gitlab.com/agarwal.khushbu/Snomed2Vec", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning methods that transform encoded data (e.g., diagnosis\nand drug codes) into continuous vector spaces (i.e., vector embeddings) are\ncritical for the application of deep learning in healthcare. Initial work in\nthis area explored the use of variants of the word2vec algorithm to learn\nembeddings for medical concepts from electronic health records or medical\nclaims datasets. We propose learning embeddings for medical concepts by using\ngraph-based representation learning methods on SNOMED-CT, a widely popular\nknowledge graph in the healthcare domain with numerous operational and research\napplications. Current work presents an empirical analysis of various embedding\nmethods, including the evaluation of their performance on multiple tasks of\nbiomedical relevance (node classification, link prediction, and patient state\nprediction). Our results show that concept embeddings derived from the\nSNOMED-CT knowledge graph significantly outperform state-of-the-art embeddings,\nshowing 5-6x improvement in ``concept similarity\" and 6-20\\% improvement in\npatient diagnosis.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 19:11:39 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Agarwal", "Khushbu", ""], ["Eftimov", "Tome", ""], ["Addanki", "Raghavendra", ""], ["Choudhury", "Sutanay", ""], ["Tamang", "Suzanne", ""], ["Rallo", "Robert", ""]]}, {"id": "1907.08651", "submitter": "Daniel Karapetyan Dr", "authors": "Dobromir Marinov and Daniel Karapetyan", "title": "Hyperparameter Optimisation with Early Termination of Poor Performers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is typical for a machine learning system to have numerous hyperparameters\nthat affect its learning rate and prediction quality. Finding a good\ncombination of the hyperparameters is, however, a challenging job. This is\nmainly because evaluation of each combination is extremely expensive\ncomputationally; indeed, training a machine learning system on real data with\njust a single combination of hyperparameters usually takes hours or even days.\nIn this paper, we address this challenge by trying to predict the performance\nof the machine learning system with a given combination of hyperparameters\nwithout completing the expensive learning process. Instead, we terminate the\ntraining process at an early stage, collect the model performance data and use\nit to predict which of the combinations of hyperparameters is most promising.\nOur preliminary experiments show that such a prediction improves the\nperformance of the commonly used random search approach.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 19:14:18 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 19:29:13 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Marinov", "Dobromir", ""], ["Karapetyan", "Daniel", ""]]}, {"id": "1907.08653", "submitter": "John Lafferty", "authors": "Ganlin Song, Zhou Fan, John Lafferty", "title": "Surfing: Iterative optimization over incrementally trained deep networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a sequential optimization procedure to minimize the empirical\nrisk functional $f_{\\hat\\theta}(x) = \\frac{1}{2}\\|G_{\\hat\\theta}(x) - y\\|^2$\nfor certain families of deep networks $G_{\\theta}(x)$. The approach is to\noptimize a sequence of objective functions that use network parameters obtained\nduring different stages of the training process. When initialized with random\nparameters $\\theta_0$, we show that the objective $f_{\\theta_0}(x)$ is \"nice''\nand easy to optimize with gradient descent. As learning is carried out, we\nobtain a sequence of generative networks $x \\mapsto G_{\\theta_t}(x)$ and\nassociated risk functions $f_{\\theta_t}(x)$, where $t$ indicates a stage of\nstochastic gradient descent during training. Since the parameters of the\nnetwork do not change by very much in each step, the surface evolves slowly and\ncan be incrementally optimized. The algorithm is formalized and analyzed for a\nfamily of expansive networks. We call the procedure {\\it surfing} since it\nrides along the peak of the evolving (negative) empirical risk function,\nstarting from a smooth surface at the beginning of learning and ending with a\nwavy nonconvex surface after learning is complete. Experiments show how surfing\ncan be used to find the global optimum and for compressed sensing even when\ndirect gradient descent on the final learned network fails.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 19:16:04 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Song", "Ganlin", ""], ["Fan", "Zhou", ""], ["Lafferty", "John", ""]]}, {"id": "1907.08674", "submitter": "Kiran Rama", "authors": "Kiran Rama, Pradeep Kumar, Bharat Bhasker", "title": "Deep Learning to Address Candidate Generation and Cold Start Challenges\n  in Recommender Systems: A Research Survey", "comments": "22 pages, Submitted and Presented at PAN IIM Conference in IIM\n  Bangalore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the machine learning applications to business, recommender systems\nwould take one of the top places when it comes to success and adoption. They\nhelp the user in accelerating the process of search while helping businesses\nmaximize sales. Post phenomenal success in computer vision and speech\nrecognition, deep learning methods are beginning to get applied to recommender\nsystems. Current survey papers on deep learning in recommender systems provide\na historical overview and taxonomy of recommender systems based on type. Our\npaper addresses the gaps of providing a taxonomy of deep learning approaches to\naddress recommender systems problems in the areas of cold start and candidate\ngeneration in recommender systems. We outline different challenges in\nrecommender systems into those related to the recommendations themselves\n(include relevance, speed, accuracy and scalability), those related to the\nnature of the data (cold start problem, imbalance and sparsity) and candidate\ngeneration. We then provide a taxonomy of deep learning techniques to address\nthese challenges. Deep learning techniques are mapped to the different\nchallenges in recommender systems providing an overview of how deep learning\ntechniques can be used to address them. We contribute a taxonomy of deep\nlearning techniques to address the cold start and candidate generation problems\nin recommender systems. Cold Start is addressed through additional features\n(for audio, images, text) and by learning hidden user and item representations.\nCandidate generation has been addressed by separate networks, RNNs,\nautoencoders and hybrid methods. We also summarize the advantages and\nlimitations of these techniques while outlining areas for future research.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 06:22:38 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Rama", "Kiran", ""], ["Kumar", "Pradeep", ""], ["Bhasker", "Bharat", ""]]}, {"id": "1907.08679", "submitter": "Zitao Liu", "authors": "Tianqiao Liu, Zhiwei Wang, Jiliang Tang, Songfan Yang, Gale Yan Huang,\n  Zitao Liu", "title": "Recommender Systems with Heterogeneous Side Information", "comments": null, "journal-ref": "Proceedings of the 2019 World Wide Web Conference", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern recommender systems, both users and items are associated with rich\nside information, which can help understand users and items. Such information\nis typically heterogeneous and can be roughly categorized into flat and\nhierarchical side information. While side information has been proved to be\nvaluable, the majority of existing systems have exploited either only flat side\ninformation or only hierarchical side information due to the challenges brought\nby the heterogeneity. In this paper, we investigate the problem of exploiting\nheterogeneous side information for recommendations. Specifically, we propose a\nnovel framework jointly captures flat and hierarchical side information with\nmathematical coherence. We demonstrate the effectiveness of the proposed\nframework via extensive experiments on various real-world datasets. Empirical\nresults show that our approach is able to lead a significant performance gain\nover the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 03:20:21 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Liu", "Tianqiao", ""], ["Wang", "Zhiwei", ""], ["Tang", "Jiliang", ""], ["Yang", "Songfan", ""], ["Huang", "Gale Yan", ""], ["Liu", "Zitao", ""]]}, {"id": "1907.08686", "submitter": "Zhipeng Li", "authors": "Zhipeng Li, Jianwei Wu, Lin Sun, Tao Rong", "title": "Combinatorial Keyword Recommendations for Sponsored Search with Deep\n  Reinforcement Learning", "comments": "6 pages, adKDD 2019", "journal-ref": "In Proceedings of 2019 AdKDD, Anchorage, Alaska, USA, August,\n  2019, 6 pages", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sponsored search, keyword recommendations help advertisers to achieve much\nbetter performance within limited budget. Many works have been done to mine\nnumerous candidate keywords from search logs or landing pages. However, the\nstrategy to select from given candidates remains to be improved. The existing\nrelevance-based, popularity-based and regular combinatorial strategies fail to\ntake the internal or external competitions among keywords into consideration.\nIn this paper, we regard keyword recommendations as a combinatorial\noptimization problem and solve it with a modified pointer network structure.\nThe model is trained on an actor-critic based deep reinforcement learning\nframework. A pre-clustering method called Equal Size K-Means is proposed to\naccelerate the training and testing procedure on the framework by reducing the\naction space. The performance of framework is evaluated both in offline and\nonline environments, and remarkable improvements can be observed.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 13:29:04 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Li", "Zhipeng", ""], ["Wu", "Jianwei", ""], ["Sun", "Lin", ""], ["Rong", "Tao", ""]]}, {"id": "1907.08687", "submitter": "Douglas Turnbull", "authors": "Daniel Akimchuk and Timothy Clerico and Douglas Turnbull", "title": "Evaluating Recommender System Algorithms for Generating Local Music\n  Playlists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore the task of local music recommendation: provide listeners with\npersonalized playlists of relevant tracks by artists who play most of their\nlive events within a small geographic area. Most local artists tend to be\nobscure, long-tail artists and generally have little or no available user\npreference data associated with them. This creates a cold-start problem for\ncollaborative filtering-based recommendation algorithms that depend on large\namounts of such information to make accurate recommendations. In this paper, we\ncompare the performance of three standard recommender system algorithms\n(Item-Item Neighborhood (IIN), Alternating Least Squares for Implicit Feedback\n(ALS), and Bayesian Personalized Ranking (BPR)) on the task of local music\nrecommendation using the Million Playlist Dataset. To do this, we modify the\nstandard evaluation procedure such that the algorithms only rank tracks by\nlocal artists for each of the eight different cities. Despite the fact that\ntechniques based on matrix factorization (ALS, BPR) typically perform best on\nlarge recommendation tasks, we find that the neighborhood-based approach (IIN)\nperforms best for long-tail local music recommendation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 17:20:33 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Akimchuk", "Daniel", ""], ["Clerico", "Timothy", ""], ["Turnbull", "Douglas", ""]]}, {"id": "1907.08696", "submitter": "Zhongkai Sun", "authors": "Zhongkai Sun, Prathusha K Sarma, William Sethares, Erik P. Bucy", "title": "Multi-modal Sentiment Analysis using Deep Canonical Correlation Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper learns multi-modal embeddings from text, audio, and video\nviews/modes of data in order to improve upon down-stream sentiment\nclassification. The experimental framework also allows investigation of the\nrelative contributions of the individual views in the final multi-modal\nembedding. Individual features derived from the three views are combined into a\nmulti-modal embedding using Deep Canonical Correlation Analysis (DCCA) in two\nways i) One-Step DCCA and ii) Two-Step DCCA. This paper learns text embeddings\nusing BERT, the current state-of-the-art in text encoders. We posit that this\nhighly optimized algorithm dominates over the contribution of other views,\nthough each view does contribute to the final result. Classification tasks are\ncarried out on two benchmark datasets and on a new Debate Emotion data set, and\ntogether these demonstrate that the one-Step DCCA outperforms the current\nstate-of-the-art in learning multi-modal embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 21:48:28 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Sun", "Zhongkai", ""], ["Sarma", "Prathusha K", ""], ["Sethares", "William", ""], ["Bucy", "Erik P.", ""]]}, {"id": "1907.08697", "submitter": "Cristian Rusu", "authors": "Cristian Rusu and Lorenzo Rosasco", "title": "Fast approximation of orthogonal matrices and application to PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of approximating orthogonal matrices so that their\napplication is numerically fast and yet accurate. We find an approximation by\nsolving an optimization problem over a set of structured matrices, that we call\nextended orthogonal Givens transformations, including Givens rotations as a\nspecial case. We propose an efficient greedy algorithm to solve such a problem\nand show that it strikes a balance between approximation accuracy and speed of\ncomputation. The approach is relevant to spectral methods and we illustrate its\napplication to PCA.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 09:33:11 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 12:34:33 GMT"}, {"version": "v3", "created": "Fri, 20 Mar 2020 19:23:34 GMT"}, {"version": "v4", "created": "Fri, 8 May 2020 15:31:51 GMT"}, {"version": "v5", "created": "Tue, 23 Mar 2021 16:30:44 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Rusu", "Cristian", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1907.08698", "submitter": "Romain Hennequin", "authors": "Elena V. Epure, Anis Khlif, Romain Hennequin", "title": "Leveraging Knowledge Bases And Parallel Annotations For Music Genre\n  Translation", "comments": "Published in ISMIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prevalent efforts have been put in automatically inferring genres of musical\nitems. Yet, the propose solutions often rely on simplifications and fail to\naddress the diversity and subjectivity of music genres. Accounting for these\nhas, though, many benefits for aligning knowledge sources, integrating data and\nenriching musical items with tags. Here, we choose a new angle for the genre\nstudy by seeking to predict what would be the genres of musical items in a\ntarget tag system, knowing the genres assigned to them within source tag\nsystems. We call this a translation task and identify three cases: 1) no common\nannotated corpus between source and target tag systems exists, 2) such a large\ncorpus exists, 3) only few common annotations exist. We propose the related\nsolutions: a knowledge-based translation modeled as taxonomy mapping, a\nstatistical translation modeled with maximum likelihood logistic regression; a\nhybrid translation modeled with maximum a posteriori logistic regression with\npriors given by the knowledge-based translation. During evaluation, the\nsolutions fit well the identified cases and the hybrid translation is\nsystematically the most effective w.r.t. multilabel classification metrics.\nThis is a first attempt to unify genre tag systems by leveraging both\nrepresentation and interpretation diversity.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 15:23:15 GMT"}, {"version": "v2", "created": "Sat, 27 Jul 2019 20:31:33 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Epure", "Elena V.", ""], ["Khlif", "Anis", ""], ["Hennequin", "Romain", ""]]}, {"id": "1907.08738", "submitter": "Taehee Lee", "authors": "Taehee Lee, Lorraine E. Lisiecki, Devin Rand, Geoffrey Gebbie, Charles\n  E. Lawrence", "title": "Bayesian Inference Gaussian Process Multiproxy Alignment of Continuous\n  Signals (BIGMACS): Applications for Paleoceanography", "comments": "This article has been submitted to \"Bayesian Analysis\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first introduce a novel profile-based alignment algorithm, the multiple\ncontinuous Signal Alignment algorithm with Gaussian Process Regression profiles\n(SA-GPR). SA-GPR addresses the limitations of currently available signal\nalignment methods by adopting a hybrid of the particle smoothing and\nMarkov-chain Monte Carlo (MCMC) algorithms to align signals, and by applying\nthe Gaussian process regression to construct profiles to be aligned\ncontinuously. SA-GPR shares all the strengths of the existing alignment\nalgorithms that depend on profiles but is more exact in the sense that profiles\ndo not need to be discretized as sequential bins. The uncertainty of\nperformance over the resolution of such bins is thereby eliminated. This\nmethodology produces alignments that are consistent, that regularize extreme\ncases, and that properly reflect the inherent uncertainty.\n  Then we extend SA-GPR to a specific problem in the field of paleoceanography\nwith a method called Bayesian Inference Gaussian Process Multiproxy Alignment\nof Continuous Signals (BIGMACS). The goal of BIGMACS is to infer continuous\nages for ocean sediment cores using two classes of age proxies: proxies that\nexplicitly return calendar ages (e.g., radiocarbon) and those used to\nsynchronize ages in multiple marine records (e.g., an oxygen isotope based\nmarine proxy known as benthic ${\\delta}^{18}{\\rm O}$). BIGMACS integrates these\ntwo proxies by iteratively performing two steps: profile construction from\nbenthic ${\\delta}^{18}{\\rm O}$ age models and alignment of each core to the\nprofile also reflecting radiocarbon dates. We use BIGMACS to construct a new\nDeep Northeastern Atlantic stack (i.e., a profile from a particular benthic\n${\\delta}^{18}{\\rm O}$ records) of five ocean sediment cores. We conclude by\nconstructing multiproxy age models for two additional cores from the same\nregion by aligning them to the stack.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 02:44:00 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 05:25:07 GMT"}, {"version": "v3", "created": "Fri, 27 Dec 2019 05:56:21 GMT"}, {"version": "v4", "created": "Sun, 13 Jun 2021 09:11:58 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lee", "Taehee", ""], ["Lisiecki", "Lorraine E.", ""], ["Rand", "Devin", ""], ["Gebbie", "Geoffrey", ""], ["Lawrence", "Charles E.", ""]]}, {"id": "1907.08742", "submitter": "Miles Lopes", "authors": "Miles E. Lopes", "title": "Estimating the Algorithmic Variance of Randomized Ensembles via the\n  Bootstrap", "comments": "53 pages", "journal-ref": "Annals of Statistics 47 (2019), no. 2, 1088--1112", "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the methods of bagging and random forests are some of the most\nwidely used prediction methods, relatively little is known about their\nalgorithmic convergence. In particular, there are not many theoretical\nguarantees for deciding when an ensemble is \"large enough\" --- so that its\naccuracy is close to that of an ideal infinite ensemble. Due to the fact that\nbagging and random forests are randomized algorithms, the choice of ensemble\nsize is closely related to the notion of \"algorithmic variance\" (i.e. the\nvariance of prediction error due only to the training algorithm). In the\npresent work, we propose a bootstrap method to estimate this variance for\nbagging, random forests, and related methods in the context of classification.\nTo be specific, suppose the training dataset is fixed, and let the random\nvariable $Err_t$ denote the prediction error of a randomized ensemble of size\n$t$. Working under a \"first-order model\" for randomized ensembles, we prove\nthat the centered law of $Err_t$ can be consistently approximated via the\nproposed method as $t\\to\\infty$. Meanwhile, the computational cost of the\nmethod is quite modest, by virtue of an extrapolation technique. As a\nconsequence, the method offers a practical guideline for deciding when the\nalgorithmic fluctuations of $Err_t$ are negligible.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 02:55:41 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Lopes", "Miles E.", ""]]}, {"id": "1907.08793", "submitter": "Pedro Almagro-Blanco", "authors": "Pedro Almagro-Blanco, Fernando Sancho-Caparrini", "title": "Improving Skip-Gram based Graph Embeddings via Centrality-Weighted\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding techniques inspired by word2vec represent an effective\nunsupervised relational learning model. Commonly, by means of a Skip-Gram\nprocedure, these techniques learn low dimensional vector representations of the\nnodes in a graph by sampling node-context examples. Although many ways of\nsampling the context of a node have been proposed, the effects of the way a\nnode is chosen have not been analyzed in depth. To fill this gap, we have\nre-implemented the main four word2vec inspired graph embedding techniques under\nthe same framework and analyzed how different sampling distributions affects\nembeddings performance when tested in node classification problems. We present\na set of experiments on different well known real data sets that show how the\nuse of popular centrality distributions in sampling leads to improvements,\nobtaining speeds of up to 2 times in learning times and increasing accuracy in\nall cases.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 10:46:03 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Almagro-Blanco", "Pedro", ""], ["Sancho-Caparrini", "Fernando", ""]]}, {"id": "1907.08823", "submitter": "Bhaskar Ramasubramanian", "authors": "Baicen Xiao, Bhaskar Ramasubramanian, Andrew Clark, Hannaneh\n  Hajishirzi, Linda Bushnell, Radha Poovendran", "title": "Potential-Based Advice for Stochastic Policy Learning", "comments": "Accepted to the IEEE Conference on Decision and Control, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper augments the reward received by a reinforcement learning agent\nwith potential functions in order to help the agent learn (possibly stochastic)\noptimal policies. We show that a potential-based reward shaping scheme is able\nto preserve optimality of stochastic policies, and demonstrate that the ability\nof an agent to learn an optimal policy is not affected when this scheme is\naugmented to soft Q-learning. We propose a method to impart potential based\nadvice schemes to policy gradient algorithms. An algorithm that considers an\nadvantage actor-critic architecture augmented with this scheme is proposed, and\nwe give guarantees on its convergence. Finally, we evaluate our approach on a\npuddle-jump grid world with indistinguishable states, and the continuous state\nand action mountain car environment from classical control. Our results\nindicate that these schemes allow the agent to learn a stochastic optimal\npolicy faster and obtain a higher average reward.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 15:21:11 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Xiao", "Baicen", ""], ["Ramasubramanian", "Bhaskar", ""], ["Clark", "Andrew", ""], ["Hajishirzi", "Hannaneh", ""], ["Bushnell", "Linda", ""], ["Poovendran", "Radha", ""]]}, {"id": "1907.08880", "submitter": "Jiaming Xu", "authors": "Zhou Fan, Cheng Mao, Yihong Wu, and Jiaming Xu", "title": "Spectral Graph Matching and Regularized Quadratic Relaxations I: The\n  Gaussian Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.SP math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph matching aims at finding the vertex correspondence between two\nunlabeled graphs that maximizes the total edge weight correlation. This amounts\nto solving a computationally intractable quadratic assignment problem. In this\npaper we propose a new spectral method, GRAph Matching by Pairwise\neigen-Alignments (GRAMPA). Departing from prior spectral approaches that only\ncompare top eigenvectors, or eigenvectors of the same order, GRAMPA first\nconstructs a similarity matrix as a weighted sum of outer products between all\npairs of eigenvectors of the two graphs, with weights given by a Cauchy kernel\napplied to the separation of the corresponding eigenvalues, then outputs a\nmatching by a simple rounding procedure. The similarity matrix can also be\ninterpreted as the solution to a regularized quadratic programming relaxation\nof the quadratic assignment problem.\n  For the Gaussian Wigner model in which two complete graphs on $n$ vertices\nhave Gaussian edge weights with correlation coefficient $1-\\sigma^2$, we show\nthat GRAMPA exactly recovers the correct vertex correspondence with high\nprobability when $\\sigma = O(\\frac{1}{\\log n})$. This matches the state of the\nart of polynomial-time algorithms, and significantly improves over existing\nspectral methods which require $\\sigma$ to be polynomially small in $n$. The\nsuperiority of GRAMPA is also demonstrated on a variety of synthetic and real\ndatasets, in terms of both statistical accuracy and computational efficiency.\nUniversality results, including similar guarantees for dense and sparse\nErd\\H{o}s-R\\'{e}nyi graphs, are deferred to the companion paper.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 23:36:41 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Fan", "Zhou", ""], ["Mao", "Cheng", ""], ["Wu", "Yihong", ""], ["Xu", "Jiaming", ""]]}, {"id": "1907.08883", "submitter": "Jiaming Xu", "authors": "Zhou Fan, Cheng Mao, Yihong Wu, and Jiaming Xu", "title": "Spectral Graph Matching and Regularized Quadratic Relaxations II:\n  Erd\\H{o}s-R\\'enyi Graphs and Universality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG math.SP math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a new spectral graph matching algorithm, GRAph Matching by\nPairwise eigen-Alignments (GRAMPA), for recovering the latent vertex\ncorrespondence between two unlabeled, edge-correlated weighted graphs.\nExtending the exact recovery guarantees established in the companion paper for\nGaussian weights, in this work, we prove the universality of these guarantees\nfor a general correlated Wigner model. In particular, for two Erd\\H{o}s-R\\'enyi\ngraphs with edge correlation coefficient $1-\\sigma^2$ and average degree at\nleast $\\operatorname{polylog}(n)$, we show that GRAMPA exactly recovers the\nlatent vertex correspondence with high probability when $\\sigma \\lesssim\n1/\\operatorname{polylog}(n)$. Moreover, we establish a similar guarantee for a\nvariant of GRAMPA, corresponding to a tighter quadratic programming relaxation\nof the quadratic assignment problem. Our analysis exploits a resolvent\nrepresentation of the GRAMPA similarity matrix and local laws for the\nresolvents of sparse Wigner matrices.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 23:50:02 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Fan", "Zhou", ""], ["Mao", "Cheng", ""], ["Wu", "Yihong", ""], ["Xu", "Jiaming", ""]]}, {"id": "1907.08892", "submitter": "Jan Strappa Figueroa", "authors": "Jan Strappa and Facundo Bromberg", "title": "Efficient comparison of independence structures of log-linear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Log-linear models are a family of probability distributions which capture\nrelationships between variables, including context-specific independencies.\nMany approaches exist for automatic learning of their independence structures\nfrom data, although the only known methods for evaluating these approaches are\nindirect measures of their complete density. This requires additional learning\nof numerical parameters, and introduces distortions when used for comparing\nstructures. This work addresses this issue by presenting a measure for the\ndirect and efficient comparison of independence structures of log-linear\nmodels. We present proof that the measure is a metric, and a method for its\ncomputation that is efficient in the number of variables of the domain.\nEfficiency in the number of features in the models is not guaranteed and will\nbe the subject of future work.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 01:52:28 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 14:10:35 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 21:18:32 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Strappa", "Jan", ""], ["Bromberg", "Facundo", ""]]}, {"id": "1907.08908", "submitter": "Yi-Wei Chen", "authors": "Yi-Wei Chen, Qingquan Song, Xia Hu", "title": "Techniques for Automated Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated machine learning (AutoML) aims to find optimal machine learning\nsolutions automatically given a machine learning problem. It could release the\nburden of data scientists from the multifarious manual tuning process and\nenable the access of domain experts to the off-the-shelf machine learning\nsolutions without extensive experience. In this paper, we review the current\ndevelopments of AutoML in terms of three categories, automated feature\nengineering (AutoFE), automated model and hyperparameter learning (AutoMHL),\nand automated deep learning (AutoDL). State-of-the-art techniques adopted in\nthe three categories are presented, including Bayesian optimization,\nreinforcement learning, evolutionary algorithm, and gradient-based approaches.\nWe summarize popular AutoML frameworks and conclude with current open\nchallenges of AutoML.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 04:03:36 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Chen", "Yi-Wei", ""], ["Song", "Qingquan", ""], ["Hu", "Xia", ""]]}, {"id": "1907.08922", "submitter": "Melvin Wevers", "authors": "Melvin Wevers", "title": "Using Word Embeddings to Examine Gender Bias in Dutch Newspapers,\n  1950-1990", "comments": "6 pages with appendix. Published in Proceedings of the 1st\n  International Workshop on Computational Approaches to Historical Language\n  Change 2019 co-organized with ACL2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary debates on filter bubbles and polarization in public and social\nmedia raise the question to what extent news media of the past exhibited\nbiases. This paper specifically examines bias related to gender in six Dutch\nnational newspapers between 1950 and 1990. We measure bias related to gender by\ncomparing local changes in word embedding models trained on newspapers with\ndivergent ideological backgrounds. We demonstrate clear differences in gender\nbias and changes within and between newspapers over time. In relation to themes\nsuch as sexuality and leisure, we see the bias moving toward women, whereas,\ngenerally, the bias shifts in the direction of men, despite growing female\nemployment number and feminist movements. Even though Dutch society became less\nstratified ideologically (depillarization), we found an increasing divergence\nin gender bias between religious and social-democratic on the one hand and\nliberal newspapers on the other. Methodologically, this paper illustrates how\nword embeddings can be used to examine historical language change. Future work\nwill investigate how fine-tuning deep contextualized embedding models, such as\nELMO, might be used for similar tasks with greater contextual information.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 06:58:22 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Wevers", "Melvin", ""]]}, {"id": "1907.08931", "submitter": "Kensuke Nakamura", "authors": "Kensuke Nakamura, Byung-Woo Hong", "title": "Adaptive Weight Decay for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization in the optimization of deep neural networks is often critical\nto avoid undesirable over-fitting leading to better generalization of model.\nOne of the most popular regularization algorithms is to impose L-2 penalty on\nthe model parameters resulting in the decay of parameters, called weight-decay,\nand the decay rate is generally constant to all the model parameters in the\ncourse of optimization. In contrast to the previous approach based on the\nconstant rate of weight-decay, we propose to consider the residual that\nmeasures dissimilarity between the current state of model and observations in\nthe determination of the weight-decay for each parameter in an adaptive way,\ncalled adaptive weight-decay (AdaDecay) where the gradient norms are normalized\nwithin each layer and the degree of regularization for each parameter is\ndetermined in proportional to the magnitude of its gradient using the sigmoid\nfunction. We empirically demonstrate the effectiveness of AdaDecay in\ncomparison to the state-of-the-art optimization algorithms using popular\nbenchmark datasets: MNIST, Fashion-MNIST, and CIFAR-10 with conventional neural\nnetwork models ranging from shallow to deep. The quantitative evaluation of our\nproposed algorithm indicates that AdaDecay improves generalization leading to\nbetter accuracy across all the datasets and models.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 08:04:29 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 20:27:52 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Nakamura", "Kensuke", ""], ["Hong", "Byung-Woo", ""]]}, {"id": "1907.08937", "submitter": "Hao Zhu", "authors": "Weize Chen, Hao Zhu, Xu Han, Zhiyuan Liu, Maosong Sun", "title": "Quantifying Similarity between Relations with Fact Distribution", "comments": "ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We introduce a conceptually simple and effective method to quantify the\nsimilarity between relations in knowledge bases. Specifically, our approach is\nbased on the divergence between the conditional probability distributions over\nentity pairs. In this paper, these distributions are parameterized by a very\nsimple neural network. Although computing the exact similarity is in-tractable,\nwe provide a sampling-based method to get a good approximation. We empirically\nshow the outputs of our approach significantly correlate with human judgments.\nBy applying our method to various tasks, we also find that (1) our approach\ncould effectively detect redundant relations extracted by open information\nextraction (Open IE) models, that (2) even the most competitive models for\nrelational classification still make mistakes among very similar relations, and\nthat (3) our approach could be incorporated into negative sampling and softmax\nclassification to alleviate these mistakes. The source code and experiment\ndetails of this paper can be obtained from\nhttps://github.com/thunlp/relation-similarity.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 09:22:50 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Chen", "Weize", ""], ["Zhu", "Hao", ""], ["Han", "Xu", ""], ["Liu", "Zhiyuan", ""], ["Sun", "Maosong", ""]]}, {"id": "1907.08953", "submitter": "Miao Zhang", "authors": "Miao Zhang, Huiqi Li, Steven Su", "title": "High Dimensional Bayesian Optimization via Supervised Dimension\n  Reduction", "comments": "7 pages, 3 figures, IJCAI 2019 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) has been broadly applied to computational\nexpensive problems, but it is still challenging to extend BO to high\ndimensions. Existing works are usually under strict assumption of an additive\nor a linear embedding structure for objective functions. This paper directly\nintroduces a supervised dimension reduction method, Sliced Inverse Regression\n(SIR), to high dimensional Bayesian optimization, which could effectively learn\nthe intrinsic sub-structure of objective function during the optimization.\nFurthermore, a kernel trick is developed to reduce computational complexity and\nlearn nonlinear subset of the unknowing function when applying SIR to extremely\nhigh dimensional BO. We present several computational benefits and derive\ntheoretical regret bounds of our algorithm. Extensive experiments on synthetic\nexamples and two real applications demonstrate the superiority of our\nalgorithms for high dimensional Bayesian optimization.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 10:31:23 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Zhang", "Miao", ""], ["Li", "Huiqi", ""], ["Su", "Steven", ""]]}, {"id": "1907.08956", "submitter": "Stephen Odaibo", "authors": "Stephen Odaibo", "title": "Tutorial: Deriving the Standard Variational Autoencoder (VAE) Loss\n  Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bayesian machine learning, the posterior distribution is typically\ncomputationally intractable, hence variational inference is often required. In\nthis approach, an evidence lower bound on the log likelihood of data is\nmaximized during training. Variational Autoencoders (VAE) are one important\nexample where variational inference is utilized. In this tutorial, we derive\nthe variational lower bound loss function of the standard variational\nautoencoder. We do so in the instance of a gaussian latent prior and gaussian\napproximate posterior, under which assumptions the Kullback-Leibler term in the\nvariational lower bound has a closed form solution. We derive essentially\neverything we use along the way; everything from Bayes' theorem to the\nKullback-Leibler divergence.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 11:09:42 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Odaibo", "Stephen", ""]]}, {"id": "1907.08967", "submitter": "Vikas Dwivedi", "authors": "Vikas Dwivedi, Nishant Parashar, Balaji Srinivasan", "title": "Distributed physics informed neural network for data-efficient solution\n  to partial differential equations", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The physics informed neural network (PINN) is evolving as a viable method to\nsolve partial differential equations. In the recent past PINNs have been\nsuccessfully tested and validated to find solutions to both linear and\nnon-linear partial differential equations (PDEs). However, the literature lacks\ndetailed investigation of PINNs in terms of their representation capability. In\nthis work, we first test the original PINN method in terms of its capability to\nrepresent a complicated function. Further, to address the shortcomings of the\nPINN architecture, we propose a novel distributed PINN, named DPINN. We first\nperform a direct comparison of the proposed DPINN approach against PINN to\nsolve a non-linear PDE (Burgers' equation). We show that DPINN not only yields\na more accurate solution to the Burgers' equation, but it is found to be more\ndata-efficient as well. At last, we employ our novel DPINN to two-dimensional\nsteady-state Navier-Stokes equation, which is a system of non-linear PDEs. To\nthe best of the authors' knowledge, this is the first such attempt to directly\nsolve the Navier-Stokes equation using a physics informed neural network.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 12:45:18 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Dwivedi", "Vikas", ""], ["Parashar", "Nishant", ""], ["Srinivasan", "Balaji", ""]]}, {"id": "1907.08968", "submitter": "Antonia Saravanou", "authors": "Antonia Saravanou, Clemens Noelke, Nicholas Huntington, Dolores\n  Acevedo-Garcia, Dimitrios Gunopulos", "title": "Infant Mortality Prediction using Birth Certificate Data", "comments": "DSHealth Workshop, Health Day, SIGKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Infant Mortality Rate (IMR) is the number of infants per 1000 that do not\nsurvive until their first birthday. It is an important metric providing\ninformation about infant health but it also measures the society's general\nhealth status. Despite the high level of prosperity in the U.S.A., the\ncountry's IMR is higher than that of many other developed countries.\nAdditionally, the U.S.A. exhibits persistent inequalities in the IMR across\ndifferent racial and ethnic groups. In this paper, we study the infant\nmortality prediction using features extracted from birth certificates. We are\ninterested in training classification models to decide whether an infant will\nsurvive or not. We focus on exploring and understanding the importance of\nfeatures in subsets of the population; we compare models trained for individual\nraces to general models. Our evaluation shows that our methodology outperforms\nstandard classification methods used by epidemiology researchers.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 12:45:59 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 09:14:54 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Saravanou", "Antonia", ""], ["Noelke", "Clemens", ""], ["Huntington", "Nicholas", ""], ["Acevedo-Garcia", "Dolores", ""], ["Gunopulos", "Dimitrios", ""]]}, {"id": "1907.08969", "submitter": "Sandeep Kumar", "authors": "Sandeep Kumar, Ketan Rajawat, and Daniel P. Palomar", "title": "Distributed Inexact Successive Convex Approximation ADMM: Analysis-Part\n  I", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this two-part work, we propose an algorithmic framework for solving\nnon-convex problems whose objective function is the sum of a number of smooth\ncomponent functions plus a convex (possibly non-smooth) or/and smooth (possibly\nnon-convex) regularization function. The proposed algorithm incorporates ideas\nfrom several existing approaches such as alternate direction method of\nmultipliers (ADMM), successive convex approximation (SCA), distributed and\nasynchronous algorithms, and inexact gradient methods. Different from a number\nof existing approaches, however, the proposed framework is flexible enough to\nincorporate a class of non-convex objective functions, allow distributed\noperation with and without a fusion center, and include variance reduced\nmethods as special cases. Remarkably, the proposed algorithms are robust to\nuncertainties arising from random, deterministic, and adversarial sources. The\npart I of the paper develops two variants of the algorithm under very mild\nassumptions and establishes first-order convergence rate guarantees. The proof\ndeveloped here allows for generic errors and delays, paving the way for\ndifferent variance-reduced, asynchronous, and stochastic implementations,\noutlined and evaluated in part II.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 12:46:05 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Kumar", "Sandeep", ""], ["Rajawat", "Ketan", ""], ["Palomar", "Daniel P.", ""]]}, {"id": "1907.08971", "submitter": "Eyal Shnarch", "authors": "Martin Gleize, Eyal Shnarch, Leshem Choshen, Lena Dankin, Guy\n  Moshkowich, Ranit Aharonov, Noam Slonim", "title": "Are You Convinced? Choosing the More Convincing Evidence with a Siamese\n  Network", "comments": "accepted to ACL 2019 - long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the advancement in argument detection, we suggest to pay more attention\nto the challenging task of identifying the more convincing arguments. Machines\ncapable of responding and interacting with humans in helpful ways have become\nubiquitous. We now expect them to discuss with us the more delicate questions\nin our world, and they should do so armed with effective arguments. But what\nmakes an argument more persuasive? What will convince you? In this paper, we\npresent a new data set, IBM-EviConv, of pairs of evidence labeled for\nconvincingness, designed to be more challenging than existing alternatives. We\nalso propose a Siamese neural network architecture shown to outperform several\nbaselines on both a prior convincingness data set and our own. Finally, we\nprovide insights into our experimental results and the various kinds of\nargumentative value our method is capable of detecting.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 13:05:45 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 09:14:32 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Gleize", "Martin", ""], ["Shnarch", "Eyal", ""], ["Choshen", "Leshem", ""], ["Dankin", "Lena", ""], ["Moshkowich", "Guy", ""], ["Aharonov", "Ranit", ""], ["Slonim", "Noam", ""]]}, {"id": "1907.08982", "submitter": "Jonas Rothfuss", "authors": "Jonas Rothfuss, Fabio Ferreira, Simon Boehm, Simon Walther, Maxim\n  Ulrich, Tamim Asfour, Andreas Krause", "title": "Noise Regularization for Conditional Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modelling statistical relationships beyond the conditional mean is crucial in\nmany settings. Conditional density estimation (CDE) aims to learn the full\nconditional probability density from data. Though highly expressive, neural\nnetwork based CDE models can suffer from severe over-fitting when trained with\nthe maximum likelihood objective. Due to the inherent structure of such models,\nclassical regularization approaches in the parameter space are rendered\nineffective. To address this issue, we develop a model-agnostic noise\nregularization method for CDE that adds random perturbations to the data during\ntraining. We demonstrate that the proposed approach corresponds to a smoothness\nregularization and prove its asymptotic consistency. In our experiments, noise\nregularization significantly and consistently outperforms other regularization\nmethods across seven data sets and three CDE models. The effectiveness of noise\nregularization makes neural network based CDE the preferable method over\nprevious non- and semi-parametric approaches, even when training data is\nscarce.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 14:17:28 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 09:37:59 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Rothfuss", "Jonas", ""], ["Ferreira", "Fabio", ""], ["Boehm", "Simon", ""], ["Walther", "Simon", ""], ["Ulrich", "Maxim", ""], ["Asfour", "Tamim", ""], ["Krause", "Andreas", ""]]}, {"id": "1907.08990", "submitter": "Yi Ma", "authors": "Yi Ma, Jianye Hao, Yaodong Yang, Han Li, Junqi Jin, Guangyong Chen", "title": "Spectral-based Graph Convolutional Network for Directed Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional networks(GCNs) have become the most popular approaches\nfor graph data in these days because of their powerful ability to extract\nfeatures from graph. GCNs approaches are divided into two categories,\nspectral-based and spatial-based. As the earliest convolutional networks for\ngraph data, spectral-based GCNs have achieved impressive results in many graph\nrelated analytics tasks. However, spectral-based models cannot directly work on\ndirected graphs. In this paper, we propose an improved spectral-based GCN for\nthe directed graph by leveraging redefined Laplacians to improve its\npropagation model. Our approach can work directly on directed graph data in\nsemi-supervised nodes classification tasks. Experiments on a number of directed\ngraph datasets demonstrate that our approach outperforms the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 15:35:16 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Ma", "Yi", ""], ["Hao", "Jianye", ""], ["Yang", "Yaodong", ""], ["Li", "Han", ""], ["Jin", "Junqi", ""], ["Chen", "Guangyong", ""]]}, {"id": "1907.09008", "submitter": "Fanhua Shang", "authors": "Dong Wang, Yicheng Liu, Wenwo Tang, Fanhua Shang, Hongying Liu, Qigong\n  Sun, Licheng Jiao", "title": "signADAM: Learning Confidences for Deep Neural Networks", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new first-order gradient-based algorithm to train\ndeep neural networks. We first introduce the sign operation of stochastic\ngradients (as in sign-based methods, e.g., SIGN-SGD) into ADAM, which is called\nas signADAM. Moreover, in order to make the rate of fitting each feature\ncloser, we define a confidence function to distinguish different components of\ngradients and apply it to our algorithm. It can generate more sparse gradients\nthan existing algorithms do. We call this new algorithm signADAM++. In\nparticular, both our algorithms are easy to implement and can speed up training\nof various deep neural networks. The motivation of signADAM++ is preferably\nlearning features from the most different samples by updating large and useful\ngradients regardless of useless information in stochastic gradients. We also\nestablish theoretical convergence guarantees for our algorithms. Empirical\nresults on various datasets and models show that our algorithms yield much\nbetter performance than many state-of-the-art algorithms including SIGN-SGD,\nSIGNUM and ADAM. We also analyze the performance from multiple perspectives\nincluding the loss landscape and develop an adaptive method to further improve\ngeneralization. The source code is available at\nhttps://github.com/DongWanginxdu/signADAM-Learn-by-Confidence.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 17:08:50 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Wang", "Dong", ""], ["Liu", "Yicheng", ""], ["Tang", "Wenwo", ""], ["Shang", "Fanhua", ""], ["Liu", "Hongying", ""], ["Sun", "Qigong", ""], ["Jiao", "Licheng", ""]]}, {"id": "1907.09013", "submitter": "Tom LaGatta", "authors": "Brian d'Alessandro, Cathy O'Neil, Tom LaGatta", "title": "Conscientious Classification: A Data Scientist's Guide to\n  Discrimination-Aware Classification", "comments": "30 pages, 3 figures", "journal-ref": "Big Data, 5(2), 120-134 (2017)", "doi": "10.1089/big.2016.0048", "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has helped to cultivate growing awareness that machine\nlearning systems fueled by big data can create or exacerbate troubling\ndisparities in society. Much of this research comes from outside of the\npracticing data science community, leaving its members with little concrete\nguidance to proactively address these concerns. This article introduces issues\nof discrimination to the data science community on its own terms. In it, we\ntour the familiar data mining process while providing a taxonomy of common\npractices that have the potential to produce unintended discrimination. We also\nsurvey how discrimination is commonly measured, and suggest how familiar\ndevelopment processes can be augmented to mitigate systems' discriminatory\npotential. We advocate that data scientists should be intentional about\nmodeling and reducing discriminatory outcomes. Without doing so, their efforts\nwill result in perpetuating any systemic discrimination that may exist, but\nunder a misleading veil of data-driven objectivity.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 17:57:45 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["d'Alessandro", "Brian", ""], ["O'Neil", "Cathy", ""], ["LaGatta", "Tom", ""]]}, {"id": "1907.09053", "submitter": "Evan Rosenman", "authors": "Evan Rosenman", "title": "Some New Results for Poisson Binomial Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of ecological inference, in which individual-level\ncovariates are known, but labeled data is available only at the aggregate\nlevel. The intended application is modeling voter preferences in elections. In\nRosenman and Viswanathan (2018), we proposed modeling individual voter\nprobabilities via a logistic regression, and posing the problem as a maximum\nlikelihood estimation for the parameter vector beta. The likelihood is a\nPoisson binomial, the distribution of the sum of independent but not\nidentically distributed Bernoulli variables, though we approximate it with a\nheteroscedastic Gaussian for computational efficiency. Here, we extend the\nprior work by proving results about the existence of the MLE and the curvature\nof this likelihood, which is not log-concave in general. We further demonstrate\nthe utility of our method on a real data example. Using data on voters in\nMorris County, NJ, we demonstrate that our approach outperforms other\necological inference methods in predicting a related, but known outcome:\nwhether an individual votes.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 23:42:07 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Rosenman", "Evan", ""]]}, {"id": "1907.09059", "submitter": "Lei Lei", "authors": "Lei Lei, Yue Tan, Kan Zheng, Shiwen Liu, Kuan Zhang, Xuemin (Sherman)\n  Shen", "title": "Deep Reinforcement Learning for Autonomous Internet of Things: Model,\n  Applications and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) extends the Internet connectivity into billions\nof IoT devices around the world, where the IoT devices collect and share\ninformation to reflect status of the physical world. The Autonomous Control\nSystem (ACS), on the other hand, performs control functions on the physical\nsystems without external intervention over an extended period of time. The\nintegration of IoT and ACS results in a new concept - autonomous IoT (AIoT).\nThe sensors collect information on the system status, based on which the\nintelligent agents in the IoT devices as well as the Edge/Fog/Cloud servers\nmake control decisions for the actuators to react. In order to achieve\nautonomy, a promising method is for the intelligent agents to leverage the\ntechniques in the field of artificial intelligence, especially reinforcement\nlearning (RL) and deep reinforcement learning (DRL) for decision making. In\nthis paper, we first provide a tutorial of DRL, and then propose a general\nmodel for the applications of RL/DRL in AIoT. Next, a comprehensive survey of\nthe state-of-art research on DRL for AIoT is presented, where the existing\nworks are classified and summarized under the umbrella of the proposed general\nDRL model. Finally, the challenges and open issues for future research are\nidentified.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 00:06:49 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 15:10:04 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 16:08:11 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Lei", "Lei", "", "Sherman"], ["Tan", "Yue", "", "Sherman"], ["Zheng", "Kan", "", "Sherman"], ["Liu", "Shiwen", "", "Sherman"], ["Zhang", "Kuan", "", "Sherman"], ["Xuemin", "", "", "Sherman"], ["Shen", "", ""]]}, {"id": "1907.09061", "submitter": "Dian Ang Yap", "authors": "Vinay Uday Prabhu, Dian Ang Yap, Joyce Xu, John Whaley", "title": "Understanding Adversarial Robustness Through Loss Landscape Geometries", "comments": "Presented at the ICML 2019 Workshop on Uncertainty and Robustness in\n  Deep Learning, and CVPR 2019 Workshop on The Bright and Dark Sides of\n  Computer Vision: Challenges and Opportunities for Privacy and Security\n  (CV-COPS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The pursuit of explaining and improving generalization in deep learning has\nelicited efforts both in regularization techniques as well as visualization\ntechniques of the loss surface geometry. The latter is related to the intuition\nprevalent in the community that flatter local optima leads to lower\ngeneralization error. In this paper, we harness the state-of-the-art \"filter\nnormalization\" technique of loss-surface visualization to qualitatively\nunderstand the consequences of using adversarial training data augmentation as\nthe explicit regularization technique of choice. Much to our surprise, we\ndiscover that this oft deployed adversarial augmentation technique does not\nactually result in \"flatter\" loss-landscapes, which requires rethinking\nadversarial training generalization, and the relationship between\ngeneralization and loss landscapes geometries.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 00:24:29 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Prabhu", "Vinay Uday", ""], ["Yap", "Dian Ang", ""], ["Xu", "Joyce", ""], ["Whaley", "John", ""]]}, {"id": "1907.09065", "submitter": "Cheng Li", "authors": "Cheng Li, Santu Rana, Sunil Gupta, Vu Nguyen, Svetha Venkatesh,\n  Alessandra Sutti, David Rubin, Teo Slezak, Murray Height, Mazher Mohammed,\n  Ian Gibson", "title": "Accelerating Experimental Design by Incorporating Experimenter Hunches", "comments": "IEEE International Conference on Data Mining (ICDM) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental design is a process of obtaining a product with target property\nvia experimentation. Bayesian optimization offers a sample-efficient tool for\nexperimental design when experiments are expensive. Often, expert experimenters\nhave 'hunches' about the behavior of the experimental system, offering\npotentials to further improve the efficiency. In this paper, we consider\nper-variable monotonic trend in the underlying property that results in a\nunimodal trend in those variables for a target value optimization. For example,\nsweetness of a candy is monotonic to the sugar content. However, to obtain a\ntarget sweetness, the utility of the sugar content becomes a unimodal function,\nwhich peaks at the value giving the target sweetness and falls off both ways.\nIn this paper, we propose a novel method to solve such problems that achieves\ntwo main objectives: a) the monotonicity information is used to the fullest\nextent possible, whilst ensuring that b) the convergence guarantee remains\nintact. This is achieved by a two-stage Gaussian process modeling, where the\nfirst stage uses the monotonicity trend to model the underlying property, and\nthe second stage uses `virtual' samples, sampled from the first, to model the\ntarget value optimization function. The process is made theoretically\nconsistent by adding appropriate adjustment factor in the posterior\ncomputation, necessitated because of using the `virtual' samples. The proposed\nmethod is evaluated through both simulations and real world experimental design\nproblems of a) new short polymer fiber with the target length, and b) designing\nof a new three dimensional porous scaffolding with a target porosity. In all\nscenarios our method demonstrates faster convergence than the basic Bayesian\noptimization approach not using such `hunches'.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 00:48:24 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Li", "Cheng", ""], ["Rana", "Santu", ""], ["Gupta", "Sunil", ""], ["Nguyen", "Vu", ""], ["Venkatesh", "Svetha", ""], ["Sutti", "Alessandra", ""], ["Rubin", "David", ""], ["Slezak", "Teo", ""], ["Height", "Murray", ""], ["Mohammed", "Mazher", ""], ["Gibson", "Ian", ""]]}, {"id": "1907.09109", "submitter": "Miao Zhang", "authors": "Miao Zhang, Huiqi Li, Shirui Pan, Taoping Liu, Steven Su", "title": "Efficient Novelty-Driven Neural Architecture Search", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-Shot Neural architecture search (NAS) attracts broad attention recently\ndue to its capacity to reduce the computational hours through weight sharing.\nHowever, extensive experiments on several recent works show that there is no\npositive correlation between the validation accuracy with inherited weights\nfrom the supernet and the test accuracy after re-training for One-Shot NAS.\nDifferent from devising a controller to find the best performing architecture\nwith inherited weights, this paper focuses on how to sample architectures to\ntrain the supernet to make it more predictive. A single-path supernet is\nadopted, where only a small part of weights are optimized in each step, to\nreduce the memory demand greatly. Furthermore, we abandon devising complicated\nreward based architecture sampling controller, and sample architectures to\ntrain supernet based on novelty search. An efficient novelty search method for\nNAS is devised in this paper, and extensive experiments demonstrate the\neffectiveness and efficiency of our novelty search based architecture sampling\nmethod. The best architecture obtained by our algorithm with the same search\nspace achieves the state-of-the-art test error rate of 2.51\\% on CIFAR-10 with\nonly 7.5 hours search time in a single GPU, and a validation perplexity of\n60.02 and a test perplexity of 57.36 on PTB. We also transfer these search cell\nstructures to larger datasets ImageNet and WikiText-2, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:17:13 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Zhang", "Miao", ""], ["Li", "Huiqi", ""], ["Pan", "Shirui", ""], ["Liu", "Taoping", ""], ["Su", "Steven", ""]]}, {"id": "1907.09137", "submitter": "Dravyansh Sharma", "authors": "Maria-Florina Balcan, Travis Dick, Dravyansh Sharma", "title": "Learning piecewise Lipschitz functions in changing environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization in the presence of sharp (non-Lipschitz), unpredictable (w.r.t.\ntime and amount) changes is a challenging and largely unexplored problem of\ngreat significance. We consider the class of piecewise Lipschitz functions,\nwhich is the most general online setting considered in the literature for the\nproblem, and arises naturally in various combinatorial algorithm selection\nproblems where utility functions can have sharp discontinuities. The usual\nperformance metric of $\\mathit{static}$ regret minimizes the gap between the\npayoff accumulated and that of the best fixed point for the entire duration,\nand thus fails to capture changing environments. Shifting regret is a useful\nalternative, which allows for up to $s$ environment shifts. In this work we\nprovide an $O(\\sqrt{sdT\\log T}+sT^{1-\\beta})$ regret bound for\n$\\beta$-dispersed functions, where $\\beta$ roughly quantifies the rate at which\ndiscontinuities appear in the utility functions in expectation (typically\n$\\beta\\ge1/2$ in problems of practical interest). We also present a lower bound\ntight up to sub-logarithmic factors. We further obtain improved bounds when\nselecting from a small pool of experts. We empirically demonstrate a key\napplication of our algorithms to online clustering problems on popular\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 04:57:59 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 21:32:58 GMT"}, {"version": "v3", "created": "Wed, 18 Mar 2020 19:44:12 GMT"}, {"version": "v4", "created": "Fri, 7 Aug 2020 01:03:37 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["Dick", "Travis", ""], ["Sharma", "Dravyansh", ""]]}, {"id": "1907.09164", "submitter": "Catherine Matias", "authors": "Tabea Rebafka (LPSM (UMR\\_8001)), Estelle Kuhn (MaIAGE), Catherine\n  Matias (LPSM (UMR\\_8001))", "title": "Properties of the Stochastic Approximation EM Algorithm with Mini-batch\n  Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To deal with very large datasets a mini-batch version of the Monte Carlo\nMarkov Chain Stochastic Approximation Expectation-Maximization algorithm for\ngeneral latent variable models is proposed. For exponential models the\nalgorithm is shown to be convergent under classicalconditions as the number of\niterations increases. Numerical experiments illustrate the performance of the\nmini-batch algorithm in various models.In particular, we highlight that\nmini-batch sampling results in an important speed-up of the convergence of the\nsequence of estimators generated by the algorithm. Moreover, insights on the\neffect of the mini-batch size on the limit distribution are presented. Finally,\nwe illustrate how to use mini-batch sampling in practice to improve results\nwhen a constraint on the computing time is given.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 07:29:55 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 13:43:00 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 16:26:19 GMT"}], "update_date": "2020-05-13", "authors_parsed": [["Rebafka", "Tabea", "", "LPSM"], ["Kuhn", "Estelle", "", "MaIAGE"], ["Matias", "Catherine", "", "LPSM"]]}, {"id": "1907.09204", "submitter": "Gabriel Michau Dr.", "authors": "Gabriel Michau and Olga Fink", "title": "Domain Adaptation for One-Class Classification: Monitoring the Health of\n  Critical Systems Under Limited Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The failure of a complex and safety critical industrial asset can have\nextremely high consequences. Close monitoring for early detection of abnormal\nsystem conditions is therefore required. Data-driven solutions to this problem\nhave been limited for two reasons: First, safety critical assets are designed\nand maintained to be highly reliable and faults are rare. Fault detection can\nthus not be solved with supervised learning. Second, complex industrial systems\nusually have long lifetime during which they face very different operating\nconditions. In the early life of the system, the collected data is probably not\nrepresentative of future operating conditions, making it challenging to train a\nrobust model.\n  In this paper, we propose a methodology to monitor the systems in their early\nlife. To do so, we enhance the training dataset with other units from a fleet,\nfor which longer observations are available. Since each unit has its own\nspecificity, we propose to extract features made independent of their origin by\nthree unsupervised feature alignment techniques. First, using a variational\nencoder, we impose a shared probabilistic encoder/decoder for both units.\nSecond, we introduce a new loss designed to conserve inter-point spacial\nrelationships between the input and the learned features. Last, we propose to\ntrain in an adversarial manner a discriminator on the origin of the features.\nOnce aligned, the features are fed to a one-class classifier to monitor the\nhealth of the system. By exploring the different combinations of the proposed\nalignment strategies, and by testing them on a real case study, a fleet\ncomposed of 112 power plants operated in different geographical locations and\nunder very different operating regimes, we demonstrate that this alignment is\nnecessary and beneficial.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 09:49:50 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 07:24:00 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Michau", "Gabriel", ""], ["Fink", "Olga", ""]]}, {"id": "1907.09207", "submitter": "Alberto Gasparin Mr", "authors": "Alberto Gasparin, Slobodan Lukovic, Cesare Alippi", "title": "Deep Learning for Time Series Forecasting: The Electric Load Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Management and efficient operations in critical infrastructure such as Smart\nGrids take huge advantage of accurate power load forecasting which, due to its\nnonlinear nature, remains a challenging task. Recently, deep learning has\nemerged in the machine learning field achieving impressive performance in a\nvast range of tasks, from image classification to machine translation.\nApplications of deep learning models to the electric load forecasting problem\nare gaining interest among researchers as well as the industry, but a\ncomprehensive and sound comparison among different architectures is not yet\navailable in the literature. This work aims at filling the gap by reviewing and\nexperimentally evaluating on two real-world datasets the most recent trends in\nelectric load forecasting, by contrasting deep learning architectures on short\nterm forecast (one day ahead prediction). Specifically, we focus on feedforward\nand recurrent neural networks, sequence to sequence models and temporal\nconvolutional neural networks along with architectural variants, which are\nknown in the signal processing community but are novel to the load forecasting\none.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 10:03:17 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Gasparin", "Alberto", ""], ["Lukovic", "Slobodan", ""], ["Alippi", "Cesare", ""]]}, {"id": "1907.09239", "submitter": "Tom Hanika", "authors": "Maximilian Stubbemann and Tom Hanika and Gerd Stumme", "title": "Orometric Methods in Bounded Metric Data", "comments": "8 Pages, 1 figure", "journal-ref": null, "doi": "10.1007/978-3-030-44584-3_39", "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large amount of data accommodated in knowledge graphs (KG) is actually\nmetric. For example, the Wikidata KG contains a plenitude of metric facts about\ngeographic entities like cities, chemical compounds or celestial objects. In\nthis paper, we propose a novel approach that transfers orometric (topographic)\nmeasures to bounded metric spaces. While these methods were originally designed\nto identify relevant mountain peaks on the surface of the earth, we demonstrate\na notion to use them for metric data sets in general. Notably, metric sets of\nitems inclosed in knowledge graphs. Based on this we present a method for\nidentifying outstanding items using the transferred valuations functions\n'isolation' and 'prominence'. Building up on this we imagine an item\nrecommendation process. To demonstrate the relevance of the novel valuations\nfor such processes we use item sets from the Wikidata knowledge graph. We then\nevaluate the usefulness of 'isolation' and 'prominence' empirically in a\nsupervised machine learning setting. In particular, we find structurally\nrelevant items in the geographic population distributions of Germany and\nFrance.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 11:30:06 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Stubbemann", "Maximilian", ""], ["Hanika", "Tom", ""], ["Stumme", "Gerd", ""]]}, {"id": "1907.09286", "submitter": "Besher Alhalabi", "authors": "Besher Alhalabi, Mohamed Medhat Gaber, Shadi Basurra", "title": "EnSyth: A Pruning Approach to Synthesis of Deep Learning Ensembles", "comments": "accepted in SMC2019", "journal-ref": null, "doi": "10.1109/SMC.2019.8913944", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved state-of-art performance in many domains\nincluding computer vision, natural language processing and self-driving cars.\nHowever, they are very computationally expensive and memory intensive which\nraises significant challenges when it comes to deploy or train them on strict\nlatency applications or resource-limited environments. As a result, many\nattempts have been introduced to accelerate and compress deep learning models,\nhowever the majority were not able to maintain the same accuracy of the\nbaseline models. In this paper, we describe EnSyth, a deep learning ensemble\napproach to enhance the predictability of compact neural network's models.\nFirst, we generate a set of diverse compressed deep learning models using\ndifferent hyperparameters for a pruning method, after that we utilise ensemble\nlearning to synthesise the outputs of the compressed models to compose a new\npool of classifiers. Finally, we apply backward elimination on the generated\npool to explore the best performing combinations of models. On CIFAR-10,\nCIFAR-5 data-sets with LeNet-5, EnSyth outperforms the predictability of the\nbaseline model.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 12:44:46 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Alhalabi", "Besher", ""], ["Gaber", "Mohamed Medhat", ""], ["Basurra", "Shadi", ""]]}, {"id": "1907.09294", "submitter": "Thibault Laugel", "authors": "Thibault Laugel, Marie-Jeanne Lesot, Christophe Marsala, Xavier\n  Renard, Marcin Detyniecki", "title": "The Dangers of Post-hoc Interpretability: Unjustified Counterfactual\n  Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-hoc interpretability approaches have been proven to be powerful tools to\ngenerate explanations for the predictions made by a trained black-box model.\nHowever, they create the risk of having explanations that are a result of some\nartifacts learned by the model instead of actual knowledge from the data. This\npaper focuses on the case of counterfactual explanations and asks whether the\ngenerated instances can be justified, i.e. continuously connected to some\nground-truth data. We evaluate the risk of generating unjustified\ncounterfactual examples by investigating the local neighborhoods of instances\nwhose predictions are to be explained and show that this risk is quite high for\nseveral datasets. Furthermore, we show that most state of the art approaches do\nnot differentiate justified from unjustified counterfactual examples, leading\nto less useful explanations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 13:10:24 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Laugel", "Thibault", ""], ["Lesot", "Marie-Jeanne", ""], ["Marsala", "Christophe", ""], ["Renard", "Xavier", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "1907.09350", "submitter": "Tiancheng Yu", "authors": "Tiancheng Yu, Suvrit Sra", "title": "Efficient Policy Learning for Non-Stationary MDPs under Adversarial\n  Manipulation", "comments": "There is a problem in the Theorem 1. We will try to fix it and update\n  a new version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Markov Decision Process (MDP) is a popular model for reinforcement\nlearning. However, its commonly used assumption of stationary dynamics and\nrewards is too stringent and fails to hold in adversarial, nonstationary, or\nmulti-agent problems. We study an episodic setting where the parameters of an\nMDP can differ across episodes. We learn a reliable policy of this potentially\nadversarial MDP by developing an Adversarial Reinforcement Learning (ARL)\nalgorithm that reduces our MDP to a sequence of \\emph{adversarial} bandit\nproblems. ARL achieves $O(\\sqrt{SATH^3})$ regret, which is optimal with respect\nto $S$, $A$, and $T$, and its dependence on $H$ is the best (even for the usual\nstationary MDP) among existing model-free methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:48:49 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 14:36:57 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Yu", "Tiancheng", ""], ["Sra", "Suvrit", ""]]}, {"id": "1907.09356", "submitter": "Anastasiia Koloskova", "authors": "Anastasia Koloskova, Tao Lin, Sebastian U. Stich, Martin Jaggi", "title": "Decentralized Deep Learning with Arbitrary Communication Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized training of deep learning models is a key element for enabling\ndata privacy and on-device learning over networks, as well as for efficient\nscaling to large compute clusters. As current approaches suffer from limited\nbandwidth of the network, we propose the use of communication compression in\nthe decentralized training context. We show that Choco-SGD $-$ recently\nintroduced and analyzed for strongly-convex objectives only $-$ converges under\narbitrary high compression ratio on general non-convex functions at the rate\n$O\\bigl(1/\\sqrt{nT}\\bigr)$ where $T$ denotes the number of iterations and $n$\nthe number of workers. The algorithm achieves linear speedup in the number of\nworkers and supports higher compression than previous state-of-the art methods.\nWe demonstrate the practical performance of the algorithm in two key scenarios:\nthe training of deep learning models (i) over distributed user devices,\nconnected by a social network and (ii) in a datacenter (outperforming\nall-reduce time-wise).\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:53:02 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2020 11:06:08 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 17:24:35 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Koloskova", "Anastasia", ""], ["Lin", "Tao", ""], ["Stich", "Sebastian U.", ""], ["Jaggi", "Martin", ""]]}, {"id": "1907.09452", "submitter": "Adamantios Ntakaris Mr", "authors": "Adamantios Ntakaris, Juho Kanniainen, Moncef Gabbouj, Alexandros\n  Iosifidis", "title": "Mid-price Prediction Based on Machine Learning Methods with Technical\n  and Quantitative Indicators", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0234107", "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stock price prediction is a challenging task, but machine learning methods\nhave recently been used successfully for this purpose. In this paper, we\nextract over 270 hand-crafted features (factors) inspired by technical and\nquantitative analysis and tested their validity on short-term mid-price\nmovement prediction. We focus on a wrapper feature selection method using\nentropy, least-mean squares, and linear discriminant analysis. We also build a\nnew quantitative feature based on adaptive logistic regression for online\nlearning, which is constantly selected first among the majority of the proposed\nfeature selection methods. This study examines the best combination of features\nusing high frequency limit order book data from Nasdaq Nordic. Our results\nsuggest that sorting methods and classifiers can be used in such a way that one\ncan reach the best performance with a combination of only very few advanced\nhand-crafted features.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 13:26:47 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Ntakaris", "Adamantios", ""], ["Kanniainen", "Juho", ""], ["Gabbouj", "Moncef", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1907.09455", "submitter": "Abdallah Chehade", "authors": "Abdallah A. Chehade, Ala A. Hussein", "title": "Latent Function Decomposition for Forecasting Li-ion Battery Cells\n  Capacity: A Multi-Output Convolved Gaussian Process Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A latent function decomposition method is proposed for forecasting the\ncapacity of lithium-ion battery cells. The method uses the Multi-Output\nGaussian Process, a generative machine learning framework for multi-task and\ntransfer learning. The MCGP decomposes the available capacity trends from\nmultiple battery cells into latent functions. The latent functions are then\nconvolved over kernel smoothers to reconstruct and/or forecast capacity trends\nof the battery cells. Besides the high prediction accuracy the proposed method\npossesses, it provides uncertainty information for the predictions and captures\nnontrivial cross-correlations between capacity trends of different battery\ncells. These two merits make the proposed MCGP a very reliable and practical\nsolution for applications that use battery cell packs. The MCGP is derived and\ncompared to benchmark methods on an experimental lithium-ion battery cells\ndata. The results show the effectiveness of the proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 15:48:22 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Chehade", "Abdallah A.", ""], ["Hussein", "Ala A.", ""]]}, {"id": "1907.09466", "submitter": "Elaheh Barati", "authors": "Elaheh Barati and Xuewen Chen", "title": "An Actor-Critic-Attention Mechanism for Deep Reinforcement Learning in\n  Multi-view Environments", "comments": "The 28th International Joint Conference on Artificial Intelligence\n  (IJCAI'19). arXiv admin note: text overlap with arXiv:1905.03985", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning algorithms, leveraging multiple views of the\nenvironment can improve the learning of complicated policies. In multi-view\nenvironments, due to the fact that the views may frequently suffer from partial\nobservability, their level of importance are often different. In this paper, we\npropose a deep reinforcement learning method and an attention mechanism in a\nmulti-view environment. Each view can provide various representative\ninformation about the environment. Through our attention mechanism, our method\ngenerates a single feature representation of environment given its multiple\nviews. It learns a policy to dynamically attend to each view based on its\nimportance in the decision-making process. Through experiments, we show that\nour method outperforms its state-of-the-art baselines on TORCS racing car\nsimulator and three other complex 3D environments with obstacles. We also\nprovide experimental results to evaluate the performance of our method on noisy\nconditions and partial observation settings.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 19:38:02 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Barati", "Elaheh", ""], ["Chen", "Xuewen", ""]]}, {"id": "1907.09470", "submitter": "Xinlei Pan", "authors": "Chaowei Xiao, Xinlei Pan, Warren He, Jian Peng, Mingjie Sun, Jinfeng\n  Yi, Mingyan Liu, Bo Li, Dawn Song", "title": "Characterizing Attacks on Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has achieved great success in various\napplications. However, recent studies show that machine learning models are\nvulnerable to adversarial attacks. DRL models have been attacked by adding\nperturbations to observations. While such observation based attack is only one\naspect of potential attacks on DRL, other forms of attacks which are more\npractical require further analysis, such as manipulating environment dynamics.\nTherefore, we propose to understand the vulnerabilities of DRL from various\nperspectives and provide a thorough taxonomy of potential attacks. We conduct\nthe first set of experiments on the unexplored parts within the taxonomy. In\naddition to current observation based attacks against DRL, we propose the first\ntargeted attacks based on action space and environment dynamics. We also\nintroduce the online sequential attacks based on temporal consistency\ninformation among frames. To better estimate gradient in black-box setting, we\npropose a sampling strategy and theoretically prove its efficiency and\nestimation error bound. We conduct extensive experiments to compare the\neffectiveness of different attacks with several baselines in various\nenvironments, including game playing, robotics control, and autonomous driving.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 22:00:24 GMT"}, {"version": "v2", "created": "Wed, 24 Jul 2019 07:46:39 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Xiao", "Chaowei", ""], ["Pan", "Xinlei", ""], ["He", "Warren", ""], ["Peng", "Jian", ""], ["Sun", "Mingjie", ""], ["Yi", "Jinfeng", ""], ["Liu", "Mingyan", ""], ["Li", "Bo", ""], ["Song", "Dawn", ""]]}, {"id": "1907.09471", "submitter": "Shalin Shah", "authors": "Jianfeng Gao, Qiang Wu, Chris Burges, Krysta Svore, Yi Su, Nazan Khan,\n  Shalin Shah, Hongyan Zhou", "title": "Model Adaptation via Model Interpolation and Boosting for Web Search\n  Ranking", "comments": null, "journal-ref": null, "doi": "10.3115/1699571.1699578", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores two classes of model adaptation methods for Web search\nranking: Model Interpolation and error-driven learning approaches based on a\nboosting algorithm. The results show that model interpolation, though simple,\nachieves the best results on all the open test sets where the test data is very\ndifferent from the training data. The tree-based boosting algorithm achieves\nthe best performance on most of the closed test sets where the test data and\nthe training data are similar, but its performance drops significantly on the\nopen test sets due to the instability of trees. Several methods are explored to\nimprove the robustness of the algorithm, with limited success.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 03:03:15 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Gao", "Jianfeng", ""], ["Wu", "Qiang", ""], ["Burges", "Chris", ""], ["Svore", "Krysta", ""], ["Su", "Yi", ""], ["Khan", "Nazan", ""], ["Shah", "Shalin", ""], ["Zhou", "Hongyan", ""]]}, {"id": "1907.09474", "submitter": "Vicent Blanes-Selva", "authors": "Vicent Blanes-Selva, Vicente Ruiz-Garc\\'ia, Salvador Tortajada,\n  Jos\\'e-Miguel Bened\\'i, Bernardo Valdivieso, Juan M. Garc\\'ia-G\\'omez", "title": "Design of one-year mortality forecast at hospital admission based: a\n  machine learning approach", "comments": null, "journal-ref": null, "doi": "10.1177/1460458220987580", "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Palliative care is referred to a set of programs for patients\nthat suffer life-limiting illnesses. These programs aim to guarantee a minimum\nlevel of quality of life (QoL) for the last stage of life. They are currently\nbased on clinical evaluation of risk of one-year mortality.\n  Objectives: The main objective of this work is to develop and validate\nmachine-learning based models to predict the exitus of a patient within the\nnext year using data gathered at hospital admission.\n  Methods: Five machine learning techniques were applied in our study to\ndevelop machine-learning predictive models: Support Vector Machines,\nK-neighbors Classifier, Gradient Boosting Classifier, Random Forest and\nMultilayer Perceptron. All models were trained and evaluated using the\nretrospective dataset. The evaluation was performed with five metrics computed\nby a resampling strategy: Accuracy, the area under the ROC curve, Specificity,\nSensitivity, and the Balanced Error Rate.\n  Results: All models for forecasting one-year mortality achieved an AUC ROC\nfrom 0.858 to 0.911. Specifically, Gradient Boosting Classifier was the best\nmodel, producing an AUC ROC of 0.911 (CI 95%, 0.911 to 0.912), a sensitivity of\n0.858 (CI 95%, 0.856 to 0.86) and a specificity of 0.807 (CI 95%, 0.806 to\n0808) and a BER of 0.168 (CI 95%, 0.167 to 0.169).\n  Conclusions: The analysis of common information at hospital admission\ncombined with machine learning techniques produced models with competitive\ndiscriminative power. Our models reach the best results reported in state of\nthe art. These results demonstrate that they can be used as an accurate\ndata-driven palliative care criteria inclusion.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:18:04 GMT"}], "update_date": "2021-01-14", "authors_parsed": [["Blanes-Selva", "Vicent", ""], ["Ruiz-Garc\u00eda", "Vicente", ""], ["Tortajada", "Salvador", ""], ["Bened\u00ed", "Jos\u00e9-Miguel", ""], ["Valdivieso", "Bernardo", ""], ["Garc\u00eda-G\u00f3mez", "Juan M.", ""]]}, {"id": "1907.09475", "submitter": "Siqi Liu", "authors": "Siqi Liu, Kee Yuan Ngiam, Mengling Feng", "title": "Deep Reinforcement Learning for Clinical Decision Support: A Brief\n  Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owe to the recent advancements in Artificial Intelligence especially deep\nlearning, many data-driven decision support systems have been implemented to\nfacilitate medical doctors in delivering personalized care. We focus on the\ndeep reinforcement learning (DRL) models in this paper. DRL models have\ndemonstrated human-level or even superior performance in the tasks of computer\nvision and game playings, such as Go and Atari game. However, the adoption of\ndeep reinforcement learning techniques in clinical decision optimization is\nstill rare. We present the first survey that summarizes reinforcement learning\nalgorithms with Deep Neural Networks (DNN) on clinical decision support. We\nalso discuss some case studies, where different DRL algorithms were applied to\naddress various clinical challenges. We further compare and contrast the\nadvantages and limitations of various DRL algorithms and present a preliminary\nguide on how to choose the appropriate DRL algorithm for particular clinical\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:44:25 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Liu", "Siqi", ""], ["Ngiam", "Kee Yuan", ""], ["Feng", "Mengling", ""]]}, {"id": "1907.09478", "submitter": "Muhammad Shaban", "authors": "Muhammad Shaban, Ruqayya Awan, Muhammad Moazam Fraz, Ayesha Azam,\n  David Snead, Nasir M. Rajpoot", "title": "Context-Aware Convolutional Neural Network for Grading of Colorectal\n  Cancer Histology Images", "comments": "10 pages, 4 figures, Supplementary Document", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Digital histology images are amenable to the application of convolutional\nneural network (CNN) for analysis due to the sheer size of pixel data present\nin them. CNNs are generally used for representation learning from small image\npatches (e.g. 224x224) extracted from digital histology images due to\ncomputational and memory constraints. However, this approach does not\nincorporate high-resolution contextual information in histology images. We\npropose a novel way to incorporate larger context by a context-aware neural\nnetwork based on images with a dimension of 1,792x1,792 pixels. The proposed\nframework first encodes the local representation of a histology image into high\ndimensional features then aggregates the features by considering their spatial\norganization to make a final prediction. The proposed method is evaluated for\ncolorectal cancer grading and breast cancer classification. A comprehensive\nanalysis of some variants of the proposed method is presented. Our method\noutperformed the traditional patch-based approaches, problem-specific methods,\nand existing context-based methods quantitatively by a margin of 3.61%. Code\nand dataset related information is available at this link:\nhttps://tia-lab.github.io/Context-Aware-CNN\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 16:37:36 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Shaban", "Muhammad", ""], ["Awan", "Ruqayya", ""], ["Fraz", "Muhammad Moazam", ""], ["Azam", "Ayesha", ""], ["Snead", "David", ""], ["Rajpoot", "Nasir M.", ""]]}, {"id": "1907.09495", "submitter": "Lin Meng", "authors": "Lin Meng and Jiawei Zhang", "title": "IsoNN: Isomorphic Neural Network for Graph Representation Learning and\n  Classification", "comments": "14 pages, 6 figures, submitted to ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have achieved huge success in numerous fields, such as\ncomputer vision and natural language processing. However, unlike such fields,\nit is hard to apply traditional deep learning models on the graph data due to\nthe 'node-orderless' property. Normally, adjacency matrices will cast an\nartificial and random node-order on the graphs, which renders the performance\nof deep models on graph classification tasks extremely erratic, and the\nrepresentations learned by such models lack clear interpretability. To\neliminate the unnecessary node-order constraint, we propose a novel model named\nIsomorphic Neural Network (IsoNN), which learns the graph representation by\nextracting its isomorphic features via the graph matching between input graph\nand templates. IsoNN has two main components: graph isomorphic feature\nextraction component and classification component. The graph isomorphic feature\nextraction component utilizes a set of subgraph templates as the kernel\nvariables to learn the possible subgraph patterns existing in the input graph\nand then computes the isomorphic features. A set of permutation matrices is\nused in the component to break the node-order brought by the matrix\nrepresentation. Three fully-connected layers are used as the classification\ncomponent in IsoNN. Extensive experiments are conducted on benchmark datasets,\nthe experimental results can demonstrate the effectiveness of ISONN, especially\ncompared with both classic and state-of-the-art graph classification methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 18:01:04 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 03:55:50 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Meng", "Lin", ""], ["Zhang", "Jiawei", ""]]}, {"id": "1907.09504", "submitter": "Fatemeh Hadaeghi", "authors": "Fatemeh Hadaeghi", "title": "Reservoir Computing Models for Patient-Adaptable ECG Monitoring in\n  Wearable Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The reservoir computing paradigm is employed to classify heartbeat anomalies\nonline based on electrocardiogram signals. Inspired by the principles of\ninformation processing in the brain, reservoir computing provides a framework\nto design, train, and analyze recurrent neural networks (RNNs) for processing\ntime-dependent information. Due to its computational efficiency and the fact\nthat training amounts to a simple linear regression, this supervised learning\nalgorithm has been variously considered as a strategy to implement useful\ncomputations not only on digital computers but also on emerging unconventional\nhardware platforms such as neuromorphic microchips. Here, this\nbiological-inspired learning framework is exploited to devise an accurate\npatient-adaptive model that has the potential to be integrated into wearable\ncardiac events monitoring devices. The proposed patient-customized model was\ntrained and tested on ECG recordings selected from the MIT-BIH arrhythmia\ndatabase. Restrictive inclusion criteria were used to conduct the study only on\nECGs including, at least, two classes of heartbeats with highly unequal number\nof instances. The results of extensive simulations showed this model not only\nprovides accurate, cheap and fast patient-customized heartbeat classifier but\nalso circumvents the problem of \"imbalanced classes\" when the readout weights\nare trained using weighted ridge-regression.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 18:11:21 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Hadaeghi", "Fatemeh", ""]]}, {"id": "1907.09538", "submitter": "Shishir Rao", "authors": "Yikuan Li, Shishir Rao, Jose Roberto Ayala Solares, Abdelaali\n  Hassaine, Dexter Canoy, Yajie Zhu, Kazem Rahimi, Gholamreza Salimi-Khorshidi", "title": "BEHRT: Transformer for Electronic Health Records", "comments": "Shishir Rao and Yikuan Li have equally contributed to this work as\n  first authors. Shishir Rao is Corresponding Author for this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Today, despite decades of developments in medicine and the growing interest\nin precision healthcare, vast majority of diagnoses happen once patients begin\nto show noticeable signs of illness. Early indication and detection of\ndiseases, however, can provide patients and carers with the chance of early\nintervention, better disease management, and efficient allocation of healthcare\nresources. The latest developments in machine learning (more specifically, deep\nlearning) provides a great opportunity to address this unmet need. In this\nstudy, we introduce BEHRT: A deep neural sequence transduction model for EHR\n(electronic health records), capable of multitask prediction and disease\ntrajectory mapping. When trained and evaluated on the data from nearly 1.6\nmillion individuals, BEHRT shows a striking absolute improvement of 8.0-10.8%,\nin terms of Average Precision Score, compared to the existing state-of-the-art\ndeep EHR models (in terms of average precision, when predicting for the onset\nof 301 conditions). In addition to its superior prediction power, BEHRT\nprovides a personalised view of disease trajectories through its attention\nmechanism; its flexible architecture enables it to incorporate multiple\nheterogeneous concepts (e.g., diagnosis, medication, measurements, and more) to\nimprove the accuracy of its predictions; and its (pre-)training results in\ndisease and patient representations that can help us get a step closer to\ninterpretable predictions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 19:22:06 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Li", "Yikuan", ""], ["Rao", "Shishir", ""], ["Solares", "Jose Roberto Ayala", ""], ["Hassaine", "Abdelaali", ""], ["Canoy", "Dexter", ""], ["Zhu", "Yajie", ""], ["Rahimi", "Kazem", ""], ["Salimi-Khorshidi", "Gholamreza", ""]]}, {"id": "1907.09539", "submitter": "Zhenwei Dai", "authors": "Zhenwei Dai and Reinhard Heckel", "title": "Channel Normalization in Convolutional Neural Network avoids Vanishing\n  Gradients", "comments": "13 pages, 5 figures", "journal-ref": "ICML 2019 Workshop Deep Phenomena", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalization layers are widely used in deep neural networks to stabilize\ntraining. In this paper, we consider the training of convolutional neural\nnetworks with gradient descent on a single training example. This optimization\nproblem arises in recent approaches for solving inverse problems such as the\ndeep image prior or the deep decoder. We show that for this setup, channel\nnormalization, which centers and normalizes each channel individually, avoids\nvanishing gradients, whereas, without normalization, gradients vanish which\nprevents efficient optimization. This effect prevails in deep single-channel\nlinear convolutional networks, and we show that without channel normalization,\ngradient descent takes at least exponentially many steps to come close to an\noptimum. Contrary, with channel normalization, the gradients remain bounded,\nthus avoiding exploding gradients.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 19:25:25 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Dai", "Zhenwei", ""], ["Heckel", "Reinhard", ""]]}, {"id": "1907.09543", "submitter": "Adrian Albert", "authors": "Adrian Albert and Jasleen Kaur and Emanuele Strano and Marta Gonzalez", "title": "Spatial sensitivity analysis for urban land use prediction with\n  physics-constrained conditional generative adversarial networks", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately forecasting urban development and its environmental and climate\nimpacts critically depends on realistic models of the spatial structure of the\nbuilt environment, and of its dependence on key factors such as population and\neconomic development. Scenario simulation and sensitivity analysis, i.e.,\npredicting how changes in underlying factors at a given location affect\nurbanization outcomes at other locations, is currently not achievable at a\nlarge scale with traditional urban growth models, which are either too\nsimplistic, or depend on detailed locally-collected socioeconomic data that is\nnot available in most places. Here we develop a framework to estimate, purely\nfrom globally-available remote-sensing data and without parametric assumptions,\nthe spatial sensitivity of the (\\textit{static}) rate of change of urban sprawl\nto key macroeconomic development indicators. We formulate this spatial\nregression problem as an image-to-image translation task using conditional\ngenerative adversarial networks (GANs), where the gradients necessary for\ncomparative static analysis are provided by the backpropagation algorithm used\nto train the model. This framework allows to naturally incorporate physical\nconstraints, e.g., the inability to build over water bodies. To validate the\nspatial structure of model-generated built environment distributions, we use\nspatial statistics commonly used in urban form analysis. We apply our method to\na novel dataset comprising of layers on the built environment, nightlighs\nmeasurements (a proxy for economic development and energy use), and population\ndensity for the world's most populous 15,000 cities.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 19:32:43 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Albert", "Adrian", ""], ["Kaur", "Jasleen", ""], ["Strano", "Emanuele", ""], ["Gonzalez", "Marta", ""]]}, {"id": "1907.09547", "submitter": "Damek Davis", "authors": "Damek Davis, Dmitriy Drusvyatskiy, Vasileios Charisopoulos", "title": "Stochastic algorithms with geometric step decay converge linearly on\n  sharp functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic (sub)gradient methods require step size schedule tuning to perform\nwell in practice. Classical tuning strategies decay the step size polynomially\nand lead to optimal sublinear rates on (strongly) convex problems. An\nalternative schedule, popular in nonconvex optimization, is called\n\\emph{geometric step decay} and proceeds by halving the step size after every\nfew epochs. In recent work, geometric step decay was shown to improve\nexponentially upon classical sublinear rates for the class of \\emph{sharp}\nconvex functions. In this work, we ask whether geometric step decay similarly\nimproves stochastic algorithms for the class of sharp nonconvex problems. Such\nlosses feature in modern statistical recovery problems and lead to a new\nchallenge not present in the convex setting: the region of convergence is\nlocal, so one must bound the probability of escape. Our main result shows that\nfor a large class of stochastic, sharp, nonsmooth, and nonconvex problems a\ngeometric step decay schedule endows well-known algorithms with a local linear\nrate of convergence to global minimizers. This guarantee applies to the\nstochastic projected subgradient, proximal point, and prox-linear algorithms.\nAs an application of our main result, we analyze two statistical recovery\ntasks---phase retrieval and blind deconvolution---and match the best known\nguarantees under Gaussian measurement models and establish new guarantees under\nheavy-tailed distributions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 19:52:11 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Davis", "Damek", ""], ["Drusvyatskiy", "Dmitriy", ""], ["Charisopoulos", "Vasileios", ""]]}, {"id": "1907.09553", "submitter": "Andrew Brown", "authors": "Carl Ehrett, D. Andrew Brown, Evan Chodora, Christopher Kitchens, and\n  Sez Atamturktur", "title": "Coupling material and mechanical design processes via computer model\n  calibration", "comments": "20 pages, 7 figures. Supplementary material and computer code\n  available from the authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer model calibration typically operates by choosing parameter values in\na computer model so that the model output faithfully predicts reality. By using\nperformance targets in place of observed data, we show that calibration\ntechniques can be repurposed to wed engineering and material design, two\nprocesses that are traditionally carried out separately. This allows materials\nto be designed with specific engineering targets in mind while quantifying the\nassociated sources of uncertainty. We demonstrate our proposed approach by\n\"calibrating\" material design settings to performance targets for a wind\nturbine blade.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 20:16:55 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 16:44:59 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Ehrett", "Carl", ""], ["Brown", "D. Andrew", ""], ["Chodora", "Evan", ""], ["Kitchens", "Christopher", ""], ["Atamturktur", "Sez", ""]]}, {"id": "1907.09557", "submitter": "Xiahan Shi", "authors": "Xiahan Shi, Leonard Salewski, Martin Schiegg, Zeynep Akata, Max\n  Welling", "title": "Relational Generalized Few-Shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transferring learned models to novel tasks is a challenging problem,\nparticularly if only very few labeled examples are available. Although this\nfew-shot learning setup has received a lot of attention recently, most proposed\nmethods focus on discriminating novel classes only. Instead, we consider the\nextended setup of generalized few-shot learning (GFSL), where the model is\nrequired to perform classification on the joint label space consisting of both\npreviously seen and novel classes. We propose a graph-based framework that\nexplicitly models relationships between all seen and novel classes in the joint\nlabel space. Our model Graph-convolutional Global Prototypical Networks (GcGPN)\nincorporates these inter-class relations using graph-convolution in order to\nembed novel class representations into the existing space of previously seen\nclasses in a globally consistent manner. Our approach ensures both fast\nadaptation and global discrimination, which is the major challenge in GFSL. We\ndemonstrate the benefits of our model on two challenging benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 20:23:27 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 09:23:48 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Shi", "Xiahan", ""], ["Salewski", "Leonard", ""], ["Schiegg", "Martin", ""], ["Akata", "Zeynep", ""], ["Welling", "Max", ""]]}, {"id": "1907.09562", "submitter": "Samira Sheikhi", "authors": "Samira Sheikhi", "title": "Practical Newton-Type Distributed Learning using Gradient Based\n  Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed algorithms for expected loss minimization where the\ndatasets are large and have to be stored on different machines. Often we deal\nwith minimizing the average of a set of convex functions where each function is\nthe empirical risk of the corresponding part of the data. In the distributed\nsetting where the individual data instances can be accessed only on the local\nmachines, there would be a series of rounds of local computations followed by\nsome communication among the machines. Since the cost of the communication is\nusually higher than the local machine computations, it is important to reduce\nit as much as possible. However, we should not allow this to make the\ncomputation too expensive to become a burden in practice. Using second-order\nmethods could make the algorithms converge faster and decrease the amount of\ncommunication needed. There are some successful attempts in developing\ndistributed second-order methods. Although these methods have shown fast\nconvergence, their local computation is expensive and could enjoy more\nimprovement for practical uses. In this study we modify an existing approach,\nDANE (Distributed Approximate NEwton), in order to improve the computational\ncost while maintaining the accuracy. We tackle this problem by using iterative\nmethods for solving the local subproblems approximately instead of providing\nexact solutions for each round of communication. We study how using different\niterative methods affect the behavior of the algorithm and try to provide an\nappropriate tradeoff between the amount of local computation and the required\namount of communication. We demonstrate the practicality of our algorithm and\ncompare it to the existing distributed gradient based methods such as SGD.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 20:36:23 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Sheikhi", "Samira", ""]]}, {"id": "1907.09565", "submitter": "Ranjan Maitra", "authors": "Geoffrey Z. Thompson and Ranjan Maitra and William Q. Meeker and\n  Ashraf Bastawros", "title": "Classification with the matrix-variate-$t$ distribution", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": "10.1080/10618600.2019.1696208", "report-no": null, "categories": "stat.ME stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix-variate distributions can intuitively model the dependence structure\nof matrix-valued observations that arise in applications with multivariate time\nseries, spatio-temporal or repeated measures. This paper develops an\nExpectation-Maximization algorithm for discriminant analysis and classification\nwith matrix-variate $t$-distributions. The methodology shows promise on\nsimulated datasets or when applied to the forensic matching of fractured\nsurfaces or the classification of functional Magnetic Resonance, satellite or\nhand gestures images.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 20:44:34 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 22:07:55 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Thompson", "Geoffrey Z.", ""], ["Maitra", "Ranjan", ""], ["Meeker", "William Q.", ""], ["Bastawros", "Ashraf", ""]]}, {"id": "1907.09569", "submitter": "Peiye Liu", "authors": "Peiye Liu, Bo Wu, Huadong Ma, Mingoo Seok", "title": "MemNet: Memory-Efficiency Guided Neural Architecture Search with\n  Augment-Trim learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on automatic neural architectures search have demonstrated\nsignificant performance, competitive to or even better than hand-crafted neural\narchitectures. However, most of the existing network architecture tend to use\nresidual, parallel structures and concatenation block between shallow and deep\nfeatures to construct a large network. This requires large amounts of memory\nfor storing both weights and feature maps. This is challenging for mobile and\nembedded devices since they may not have enough memory to perform inference\nwith the designed large network model. To close this gap, we propose MemNet, an\naugment-trim learning-based neural network search framework that optimizes not\nonly performance but also memory requirement. Specifically, it employs memory\nconsumption based ranking score which forces an upper bound on memory\nconsumption for navigating the search process. Experiment results show that, as\ncompared to the state-of-the-art efficient designing methods, MemNet can find\nan architecture which can achieve competitive accuracy and save an average of\n24.17% on the total memory needed.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 20:49:53 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 20:12:57 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Liu", "Peiye", ""], ["Wu", "Bo", ""], ["Ma", "Huadong", ""], ["Seok", "Mingoo", ""]]}, {"id": "1907.09588", "submitter": "Wenkai Xu", "authors": "Wenkai Xu, Gang Niu, Aapo Hyv\\\"arinen, Masashi Sugiyama", "title": "Direction Matters: On Influence-Preserving Graph Summarization and\n  Max-cut Principle for Directed Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Summarizing large-scaled directed graphs into small-scale representations is\na useful but less studied problem setting. Conventional clustering approaches,\nwhich based on \"Min-Cut\"-style criteria, compress both the vertices and edges\nof the graph into the communities, that lead to a loss of directed edge\ninformation. On the other hand, compressing the vertices while preserving the\ndirected edge information provides a way to learn the small-scale\nrepresentation of a directed graph. The reconstruction error, which measures\nthe edge information preserved by the summarized graph, can be used to learn\nsuch representation. Compared to the original graphs, the summarized graphs are\neasier to analyze and are capable of extracting group-level features which is\nuseful for efficient interventions of population behavior. In this paper, we\npresent a model, based on minimizing reconstruction error with non-negative\nconstraints, which relates to a \"Max-Cut\" criterion that simultaneously\nidentifies the compressed nodes and the directed compressed relations between\nthese nodes. A multiplicative update algorithm with column-wise normalization\nis proposed. We further provide theoretical results on the identifiability of\nthe model and on the convergence of the proposed algorithms. Experiments are\nconducted to demonstrate the accuracy and robustness of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 21:34:47 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Xu", "Wenkai", ""], ["Niu", "Gang", ""], ["Hyv\u00e4rinen", "Aapo", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1907.09600", "submitter": "Lorenzo A. Rossi", "authors": "Lorenzo A. Rossi, Chad Shawber, Janet Munu and Finly Zachariah", "title": "Evaluation of Embeddings of Laboratory Test Codes for Patients at a\n  Cancer Center", "comments": "2019 KDD Workshop on Applied Data Science for Healthcare (DSHealth,\n  August 2019, Anchorage, AK). Make sure you have downloaded the latest version\n  with the link to the DSHealth2019_loinc_embeddings GitHub repository:\n  https://github.com/elleros/DSHealth2019_loinc_embeddings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Laboratory test results are an important and generally high dimensional\ncomponent of a patient's Electronic Health Record (EHR). We train embedding\nrepresentations (via Word2Vec and GloVe) for LOINC codes of laboratory tests\nfrom the EHRs of about 80,000 patients at a cancer center. To include\ninformation about lab test outcomes, we also train embeddings on the\nconcatenation of a LOINC code with a symbol indicating normality or abnormality\nof the result. We observe several clinically meaningful similarities among\nLOINC embeddings trained over our data. For the embeddings of the concatenation\nof LOINCs with abnormality codes, we evaluate the performance for mortality\nprediction tasks and the ability to preserve ordinality properties: i.e. a lab\ntest with normal outcome should be more similar to an abnormal one than to the\na very abnormal one.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 21:58:40 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 15:29:44 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Rossi", "Lorenzo A.", ""], ["Shawber", "Chad", ""], ["Munu", "Janet", ""], ["Zachariah", "Finly", ""]]}, {"id": "1907.09607", "submitter": "Prashnna Gyawali", "authors": "Prashnna Kumar Gyawali, Zhiyuan Li, Sandesh Ghimire and Linwei Wang", "title": "Semi-Supervised Learning by Disentangling and Self-Ensembling Over\n  Stochastic Latent Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The success of deep learning in medical imaging is mostly achieved at the\ncost of a large labeled data set. Semi-supervised learning (SSL) provides a\npromising solution by leveraging the structure of unlabeled data to improve\nlearning from a small set of labeled data. Self-ensembling is a simple approach\nused in SSL to encourage consensus among ensemble predictions of unknown\nlabels, improving generalization of the model by making it more insensitive to\nthe latent space. Currently, such an ensemble is obtained by randomization such\nas dropout regularization and random data augmentation. In this work, we\nhypothesize -- from the generalization perspective -- that self-ensembling can\nbe improved by exploiting the stochasticity of a disentangled latent space. To\nthis end, we present a stacked SSL model that utilizes unsupervised\ndisentangled representation learning as the stochastic embedding for\nself-ensembling. We evaluate the presented model for multi-label classification\nusing chest X-ray images, demonstrating its improved performance over related\nSSL models as well as the interpretability of its disentangled representations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 22:19:04 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Gyawali", "Prashnna Kumar", ""], ["Li", "Zhiyuan", ""], ["Ghimire", "Sandesh", ""], ["Wang", "Linwei", ""]]}, {"id": "1907.09613", "submitter": "Alessandro Lameiras Koerich", "authors": "Alexandre Reeberg de Mello and Marcelo Ricardo Stemmer and Alessandro\n  Lameiras Koerich", "title": "Incremental and Decremental Fuzzy Bounded Twin Support Vector Machine", "comments": "23 pages", "journal-ref": "Information Sciences, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an incremental variant of the Twin Support Vector\nMachine (TWSVM) called Fuzzy Bounded Twin Support Vector Machine (FBTWSVM) to\ndeal with large datasets and learning from data streams. We combine the TWSVM\nwith a fuzzy membership function, so that each input has a different\ncontribution to each hyperplane in a binary classifier. To solve the pair of\nquadratic programming problems (QPPs) we use a dual coordinate descent\nalgorithm with a shrinking strategy, and to obtain a robust classification with\na fast training we propose the use of a Fourier Gaussian approximation function\nwith our linear FBTWSVM. Inspired by the shrinking technique, the incremental\nalgorithm re-utilizes part of the training method with some heuristics, while\nthe decremental procedure is based on a scored window. The FBTWSVM is also\nextended for multi-class problems by combining binary classifiers using a\nDirected Acyclic Graph (DAG) approach. Moreover, we analyzed the theoretical\nfoundations properties of the proposed approach and its extension, and the\nexperimental results on benchmark datasets indicate that the FBTWSVM has a fast\ntraining and retraining process while maintaining a robust classification\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 22:32:36 GMT"}, {"version": "v2", "created": "Mon, 23 Mar 2020 11:28:19 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["de Mello", "Alexandre Reeberg", ""], ["Stemmer", "Marcelo Ricardo", ""], ["Koerich", "Alessandro Lameiras", ""]]}, {"id": "1907.09615", "submitter": "Shalmali Joshi", "authors": "Shalmali Joshi, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim,\n  Joydeep Ghosh", "title": "Towards Realistic Individual Recourse and Actionable Explanations in\n  Black-Box Decision Making Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning based decision making systems are increasingly affecting\nhumans. An individual can suffer an undesirable outcome under such decision\nmaking systems (e.g. denied credit) irrespective of whether the decision is\nfair or accurate. Individual recourse pertains to the problem of providing an\nactionable set of changes a person can undertake in order to improve their\noutcome. We propose a recourse algorithm that models the underlying data\ndistribution or manifold. We then provide a mechanism to generate the smallest\nset of changes that will improve an individual's outcome. This mechanism can be\neasily used to provide recourse for any differentiable machine learning based\ndecision making system. Further, the resulting algorithm is shown to be\napplicable to both supervised classification and causal decision making\nsystems. Our work attempts to fill gaps in existing fairness literature that\nhave primarily focused on discovering and/or algorithmically enforcing fairness\nconstraints on decision making systems. This work also provides an alternative\napproach to generating counterfactual explanations.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 22:35:51 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Joshi", "Shalmali", ""], ["Koyejo", "Oluwasanmi", ""], ["Vijitbenjaronk", "Warut", ""], ["Kim", "Been", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "1907.09623", "submitter": "Yi Su", "authors": "Yi Su, Maria Dimakopoulou, Akshay Krishnamurthy, Miroslav Dud\\'ik", "title": "Doubly robust off-policy evaluation with shrinkage", "comments": null, "journal-ref": "International Conference on Machine Learning (2020)", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework for designing estimators for off-policy evaluation\nin contextual bandits. Our approach is based on the asymptotically optimal\ndoubly robust estimator, but we shrink the importance weights to minimize a\nbound on the mean squared error, which results in a better bias-variance\ntradeoff in finite samples. We use this optimization-based framework to obtain\nthree estimators: (a) a weight-clipping estimator, (b) a new weight-shrinkage\nestimator, and (c) the first shrinkage-based estimator for combinatorial action\nsets. Extensive experiments in both standard and combinatorial bandit benchmark\nproblems show that our estimators are highly adaptive and typically outperform\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 22:55:31 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 20:53:19 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Su", "Yi", ""], ["Dimakopoulou", "Maria", ""], ["Krishnamurthy", "Akshay", ""], ["Dud\u00edk", "Miroslav", ""]]}, {"id": "1907.09636", "submitter": "Woojay Jeon", "authors": "Woojay Jeon, Maxwell Jordan, Mahesh Krishnamoorthy", "title": "On Modeling ASR Word Confidence", "comments": "Presented at IEEE ICASSP 2020, May 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for computing ASR word confidences that effectively\nmitigates the effect of ASR errors for diverse downstream applications,\nimproves the word error rate of the 1-best result, and allows better comparison\nof scores across different models. We propose 1) a new method for modeling word\nconfidence using a Heterogeneous Word Confusion Network (HWCN) that addresses\nsome key flaws in conventional Word Confusion Networks, and 2) a new score\ncalibration method for facilitating direct comparison of scores from different\nmodels. Using a bidirectional lattice recurrent neural network to compute the\nconfidence scores of each word in the HWCN, we show that the word sequence with\nthe best overall confidence is more accurate than the default 1-best result of\nthe recognizer, and that the calibration method can substantially improve the\nreliability of recognizer combination.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 23:53:41 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 00:43:25 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 01:48:54 GMT"}, {"version": "v4", "created": "Tue, 2 Jun 2020 04:59:37 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Jeon", "Woojay", ""], ["Jordan", "Maxwell", ""], ["Krishnamoorthy", "Mahesh", ""]]}, {"id": "1907.09648", "submitter": "Usman Khan", "authors": "Ran Xin and Soummya Kar and Usman A. Khan", "title": "An introduction to decentralized stochastic optimization with gradient\n  tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized solutions to finite-sum minimization are of significant\nimportance in many signal processing, control, and machine learning\napplications. In such settings, the data is distributed over a network of\narbitrarily-connected nodes and raw data sharing is prohibitive often due to\ncommunication or privacy constraints. In this article, we review decentralized\nstochastic first-order optimization methods and illustrate some recent\nimprovements based on gradient tracking and variance reduction, focusing\nparticularly on smooth and strongly-convex objective functions. We provide\nintuitive illustrations of the main technical ideas as well as applications of\nthe algorithms in the context of decentralized training of machine learning\nmodels.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 01:36:41 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 22:15:02 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Xin", "Ran", ""], ["Kar", "Soummya", ""], ["Khan", "Usman A.", ""]]}, {"id": "1907.09652", "submitter": "Li He", "authors": "Li He, Long Xia, Wei Zeng, Zhi-Ming Ma, Yihong Zhao, and Dawei Yin", "title": "Off-policy Learning for Multiple Loggers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that the historical logs are used for evaluating and\nlearning policies in interactive systems, e.g. recommendation, search, and\nonline advertising. Since direct online policy learning usually harms user\nexperiences, it is more crucial to apply off-policy learning in real-world\napplications instead. Though there have been some existing works, most are\nfocusing on learning with one single historical policy. However, in practice,\nusually a number of parallel experiments, e.g. multiple AB tests, are performed\nsimultaneously. To make full use of such historical data, learning policies\nfrom multiple loggers becomes necessary. Motivated by this, in this paper, we\ninvestigate off-policy learning when the training data coming from multiple\nhistorical policies. Specifically, policies, e.g. neural networks, can be\nlearned directly from multi-logger data, with counterfactual estimators. In\norder to understand the generalization ability of such estimator better, we\nconduct generalization error analysis for the empirical risk minimization\nproblem. We then introduce the generalization error bound as the new risk\nfunction, which can be reduced to a constrained optimization problem. Finally,\nwe give the corresponding learning algorithm for the new constrained problem,\nwhere we can appeal to the minimax problems to control the constraints.\nExtensive experiments on benchmark datasets demonstrate that the proposed\nmethods achieve better performances than the state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 01:52:34 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 08:47:53 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["He", "Li", ""], ["Xia", "Long", ""], ["Zeng", "Wei", ""], ["Ma", "Zhi-Ming", ""], ["Zhao", "Yihong", ""], ["Yin", "Dawei", ""]]}, {"id": "1907.09693", "submitter": "Qinbin Li", "authors": "Qinbin Li, Zeyi Wen, Zhaomin Wu, Sixu Hu, Naibo Wang, Yuan Li, Xu Liu,\n  Bingsheng He", "title": "A Survey on Federated Learning Systems: Vision, Hype and Reality for\n  Data Privacy and Protection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning has been a hot research topic in enabling the\ncollaborative training of machine learning models among different organizations\nunder the privacy restrictions. As researchers try to support more machine\nlearning models with different privacy-preserving approaches, there is a\nrequirement in developing systems and infrastructures to ease the development\nof various federated learning algorithms. Similar to deep learning systems such\nas PyTorch and TensorFlow that boost the development of deep learning,\nfederated learning systems (FLSs) are equivalently important, and face\nchallenges from various aspects such as effectiveness, efficiency, and privacy.\nIn this survey, we conduct a comprehensive review on federated learning\nsystems. To achieve smooth flow and guide future research, we introduce the\ndefinition of federated learning systems and analyze the system components.\nMoreover, we provide a thorough categorization for federated learning systems\naccording to six different aspects, including data distribution, machine\nlearning model, privacy mechanism, communication architecture, scale of\nfederation and motivation of federation. The categorization can help the design\nof federated learning systems as shown in our case studies. By systematically\nsummarizing the existing federated learning systems, we present the design\nfactors, case studies, and future research opportunities.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 04:30:50 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 08:06:54 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 13:34:19 GMT"}, {"version": "v4", "created": "Wed, 1 Apr 2020 13:33:21 GMT"}, {"version": "v5", "created": "Wed, 13 Jan 2021 11:30:07 GMT"}, {"version": "v6", "created": "Thu, 1 Jul 2021 04:04:38 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Li", "Qinbin", ""], ["Wen", "Zeyi", ""], ["Wu", "Zhaomin", ""], ["Hu", "Sixu", ""], ["Wang", "Naibo", ""], ["Li", "Yuan", ""], ["Liu", "Xu", ""], ["He", "Bingsheng", ""]]}, {"id": "1907.09696", "submitter": "Yeonjong Shin", "authors": "Yeonjong Shin, George Em Karniadakis", "title": "Trainability of ReLU networks and Data-dependent Initialization", "comments": null, "journal-ref": null, "doi": "10.1615/.2020034126", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we study the trainability of rectified linear unit (ReLU)\nnetworks. A ReLU neuron is said to be dead if it only outputs a constant for\nany input. Two death states of neurons are introduced; tentative and permanent\ndeath. A network is then said to be trainable if the number of permanently dead\nneurons is sufficiently small for a learning task. We refer to the probability\nof a network being trainable as trainability. We show that a network being\ntrainable is a necessary condition for successful training and the trainability\nserves as an upper bound of successful training rates. In order to quantify the\ntrainability, we study the probability distribution of the number of active\nneurons at the initialization. In many applications, over-specified or\nover-parameterized neural networks are successfully employed and shown to be\ntrained effectively. With the notion of trainability, we show that\nover-parameterization is both a necessary and a sufficient condition for\nminimizing the training loss. Furthermore, we propose a data-dependent\ninitialization method in the over-parameterized setting. Numerical examples are\nprovided to demonstrate the effectiveness of the method and our theoretical\nfindings.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 05:11:32 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 04:25:31 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Shin", "Yeonjong", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1907.09697", "submitter": "Tao Sun", "authors": "Tao Sun, Dongsheng Li, Zhe Quan, Hao Jiang, Shengguo Li, Yong Dou", "title": "Heavy-ball Algorithms Always Escape Saddle Points", "comments": "IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonconvex optimization algorithms with random initialization have attracted\nincreasing attention recently. It has been showed that many first-order methods\nalways avoid saddle points with random starting points. In this paper, we\nanswer a question: can the nonconvex heavy-ball algorithms with random\ninitialization avoid saddle points? The answer is yes! Direct using the\nexisting proof technique for the heavy-ball algorithms is hard due to that each\niteration of the heavy-ball algorithm consists of current and last points. It\nis impossible to formulate the algorithms as iteration like xk+1= g(xk) under\nsome mapping g. To this end, we design a new mapping on a new space. With some\ntransfers, the heavy-ball algorithm can be interpreted as iterations after this\nmapping. Theoretically, we prove that heavy-ball gradient descent enjoys larger\nstepsize than the gradient descent to escape saddle points to escape the saddle\npoint. And the heavy-ball proximal point algorithm is also considered; we also\nproved that the algorithm can always escape the saddle point.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 05:15:55 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Sun", "Tao", ""], ["Li", "Dongsheng", ""], ["Quan", "Zhe", ""], ["Jiang", "Hao", ""], ["Li", "Shengguo", ""], ["Dou", "Yong", ""]]}, {"id": "1907.09701", "submitter": "Mengjiao Yang", "authors": "Mengjiao Yang, Been Kim", "title": "Benchmarking Attribution Methods with Relative Feature Importance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretability is an important area of research for safe deployment of\nmachine learning systems. One particular type of interpretability method\nattributes model decisions to input features. Despite active development,\nquantitative evaluation of feature attribution methods remains difficult due to\nthe lack of ground truth: we do not know which input features are in fact\nimportant to a model. In this work, we propose a framework for Benchmarking\nAttribution Methods (BAM) with a priori knowledge of relative feature\nimportance. BAM includes 1) a carefully crafted dataset and models trained with\nknown relative feature importance and 2) three complementary metrics to\nquantitatively evaluate attribution methods by comparing feature attributions\nbetween pairs of models and pairs of inputs. Our evaluation on several\nwidely-used attribution methods suggests that certain methods are more likely\nto produce false positive explanations---features that are incorrectly\nattributed as more important to model prediction. We open source our dataset,\nmodels, and metrics.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 05:50:14 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 20:50:25 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Yang", "Mengjiao", ""], ["Kim", "Been", ""]]}, {"id": "1907.09708", "submitter": "Huangjie Zheng", "authors": "Xu Chen, Siheng Chen, Huangjie Zheng, Jiangchao Yao, Kenan Cui, Ya\n  Zhang, Ivor W. Tsang", "title": "Node Attribute Generation on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph structured data provide two-fold information: graph structures and node\nattributes. Numerous graph-based algorithms rely on both information to achieve\nsuccess in supervised tasks, such as node classification and link prediction.\nHowever, node attributes could be missing or incomplete, which significantly\ndeteriorates the performance. The task of node attribute generation aims to\ngenerate attributes for those nodes whose attributes are completely unobserved.\nThis task benefits many real-world problems like profiling, node classification\nand graph data augmentation. To tackle this task, we propose a deep adversarial\nlearning based method to generate node attributes; called node attribute neural\ngenerator (NANG). NANG learns a unifying latent representation which is shared\nby both node attributes and graph structures and can be translated to different\nmodalities. We thus use this latent representation as a bridge to convert\ninformation from one modality to another. We further introduce practical\napplications to quantify the performance of node attribute generation.\nExtensive experiments are conducted on four real-world datasets and the\nempirical results show that node attributes generated by the proposed method\nare high-qualitative and beneficial to other applications. The datasets and\ncodes are available online.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 06:02:45 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Chen", "Xu", ""], ["Chen", "Siheng", ""], ["Zheng", "Huangjie", ""], ["Yao", "Jiangchao", ""], ["Cui", "Kenan", ""], ["Zhang", "Ya", ""], ["Tsang", "Ivor W.", ""]]}, {"id": "1907.09720", "submitter": "Tsendsuren Munkhdalai", "authors": "Tsendsuren Munkhdalai, Alessandro Sordoni, Tong Wang and Adam\n  Trischler", "title": "Metalearned Neural Memory", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We augment recurrent neural networks with an external memory mechanism that\nbuilds upon recent progress in metalearning. We conceptualize this memory as a\nrapidly adaptable function that we parameterize as a deep neural network.\nReading from the neural memory function amounts to pushing an input (the key\nvector) through the function to produce an output (the value vector). Writing\nto memory means changing the function; specifically, updating the parameters of\nthe neural network to encode desired information. We leverage training and\nalgorithmic techniques from metalearning to update the neural memory function\nin one shot. The proposed memory-augmented model achieves strong performance on\na variety of learning problems, from supervised question answering to\nreinforcement learning.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 07:04:07 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 14:16:23 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Munkhdalai", "Tsendsuren", ""], ["Sordoni", "Alessandro", ""], ["Wang", "Tong", ""], ["Trischler", "Adam", ""]]}, {"id": "1907.09725", "submitter": "Takeshi Ise", "authors": "Takeshi Ise and Yurika Oba", "title": "VARENN: Graphical representation of spatiotemporal data and application\n  to climate studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing and utilizing spatiotemporal big data are essential for studies\nconcerning climate change. However, such data are not fully integrated into\nclimate models owing to limitations in statistical frameworks. Herein, we\nemploy VARENN (visually augmented representation of environment for neural\nnetworks) to efficiently summarize monthly observations of climate data for\n1901-2016 into 2-dimensional graphical images. Using red, green, and blue\nchannels of color images, three different variables are simultaneously\nrepresented in a single image. For global datasets, models were trained via\nconvolutional neural networks. These models successfully classified rises and\nfalls in temperature and precipitation. Moreover, similarities between the\ninput and target variables were observed to have a significant effect on model\naccuracy. The input variables had both seasonal and interannual variations,\nwhose importance was quantified for model efficacy. VARENN is thus an effective\nmethod to summarize spatiotemporal data objectively and accurately.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 07:23:01 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Ise", "Takeshi", ""], ["Oba", "Yurika", ""]]}, {"id": "1907.09728", "submitter": "Yao Ming", "authors": "Yao Ming and Panpan Xu and Huamin Qu and Liu Ren", "title": "Interpretable and Steerable Sequence Learning via Prototypes", "comments": "Accepted as a full paper at KDD 2019 on May 8, 2019", "journal-ref": "Proceedings of the 25th ACM SIGKDD International Conference on\n  Knowledge Discovery & Data Mining, KDD 2019", "doi": "10.1145/3292500.3330908", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major challenges in machine learning nowadays is to provide\npredictions with not only high accuracy but also user-friendly explanations.\nAlthough in recent years we have witnessed increasingly popular use of deep\nneural networks for sequence modeling, it is still challenging to explain the\nrationales behind the model outputs, which is essential for building trust and\nsupporting the domain experts to validate, critique and refine the model. We\npropose ProSeNet, an interpretable and steerable deep sequence model with\nnatural explanations derived from case-based reasoning. The prediction is\nobtained by comparing the inputs to a few prototypes, which are exemplar cases\nin the problem domain. For better interpretability, we define several criteria\nfor constructing the prototypes, including simplicity, diversity, and sparsity\nand propose the learning objective and the optimization procedure. ProSeNet\nalso provides a user-friendly approach to model steering: domain experts\nwithout any knowledge on the underlying model or parameters can easily\nincorporate their intuition and experience by manually refining the prototypes.\nWe conduct experiments on a wide range of real-world applications, including\npredictive diagnostics for automobiles, ECG, and protein sequence\nclassification and sentiment analysis on texts. The result shows that ProSeNet\ncan achieve accuracy on par with state-of-the-art deep learning models. We also\nevaluate the interpretability of the results with concrete case studies.\nFinally, through user study on Amazon Mechanical Turk (MTurk), we demonstrate\nthat the model selects high-quality prototypes which align well with human\nknowledge and can be interactively refined for better interpretability without\nloss of performance.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 07:28:28 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Ming", "Yao", ""], ["Xu", "Panpan", ""], ["Qu", "Huamin", ""], ["Ren", "Liu", ""]]}, {"id": "1907.09750", "submitter": "Junghee Cho", "authors": "Junghee Cho, Junseok Kwon, Byung-Woo Hong", "title": "Adaptive Regularization via Residual Smoothing in Deep Learning\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an adaptive regularization algorithm that can be effectively\napplied to the optimization problem in deep learning framework. Our\nregularization algorithm aims to take into account the fitness of data to the\ncurrent state of model in the determination of regularity to achieve better\ngeneralization. The degree of regularization at each element in the target\nspace of the neural network architecture is determined based on the residual at\neach optimization iteration in an adaptive way. Our adaptive regularization\nalgorithm is designed to apply a diffusion process driven by the heat equation\nwith spatially varying diffusivity depending on the probability density\nfunction following a certain distribution of residual. Our data-driven\nregularity is imposed by adaptively smoothing a simplified objective function\nin which the explicit regularization term is omitted in an alternating manner\nbetween the evaluation of residual and the determination of the degree of its\nregularity. The effectiveness of our algorithm is empirically demonstrated by\nthe numerical experiments in the application of image classification problems,\nindicating that our algorithm outperforms other commonly used optimization\nalgorithms in terms of generalization using popular deep learning models and\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 08:28:09 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 14:27:37 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Cho", "Junghee", ""], ["Kwon", "Junseok", ""], ["Hong", "Byung-Woo", ""]]}, {"id": "1907.09764", "submitter": "Nishchal Dwivedi", "authors": "Nishchal R. Dwivedi", "title": "Trees and Islands -- Machine learning approach to nuclear physics", "comments": "8 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "nucl-th cs.LG nucl-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement machine learning algorithms to nuclear data. These algorithms\nare purely data driven and generate models that are capable to capture\nintricate trends. Gradient boosted trees algorithm is employed to generate a\ntrained model from existing nuclear data, which is used for prediction for data\nof damping parameter, shell correction energies, quadrupole deformation,\npairing gaps, level densities and giant dipole resonance for large number of\nnuclei. We, in particular, predict level density parameter for superheavy\nelements which is of great current interest. The predictions made by the\nmachine learning algorithm is found to have standard deviation from 0.00035 to\n0.73.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 08:54:01 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Dwivedi", "Nishchal R.", ""]]}, {"id": "1907.09765", "submitter": "Eric Benhamou", "authors": "Eric Benhamou", "title": "Variance Reduction in Actor Critic Methods (ACM)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After presenting Actor Critic Methods (ACM), we show ACM are control variate\nestimators. Using the projection theorem, we prove that the Q and Advantage\nActor Critic (A2C) methods are optimal in the sense of the $L^2$ norm for the\ncontrol variate estimators spanned by functions conditioned by the current\nstate and action. This straightforward application of Pythagoras theorem\nprovides a theoretical justification of the strong performance of QAC and AAC\nmost often referred to as A2C methods in deep policy gradient methods. This\nenables us to derive a new formulation for Advantage Actor Critic methods that\nhas lower variance and improves the traditional A2C method.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 08:56:08 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Benhamou", "Eric", ""]]}, {"id": "1907.09844", "submitter": "Abdul-Saboor Sheikh", "authors": "Abdul-Saboor Sheikh, Romain Guigoures, Evgenii Koriagin, Yuen King Ho,\n  Reza Shirvany, Roland Vollgraf, Urs Bergmann", "title": "A Deep Learning System for Predicting Size and Fit in Fashion E-Commerce", "comments": "Published at the Thirteenth ACM Conference on Recommender Systems\n  (RecSys '19), September 16--20, 2019, Copenhagen, Denmark", "journal-ref": null, "doi": "10.1145/3298689.3347006", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized size and fit recommendations bear crucial significance for any\nfashion e-commerce platform. Predicting the correct fit drives customer\nsatisfaction and benefits the business by reducing costs incurred due to\nsize-related returns. Traditional collaborative filtering algorithms seek to\nmodel customer preferences based on their previous orders. A typical challenge\nfor such methods stems from extreme sparsity of customer-article orders. To\nalleviate this problem, we propose a deep learning based content-collaborative\nmethodology for personalized size and fit recommendation. Our proposed method\ncan ingest arbitrary customer and article data and can model multiple\nindividuals or intents behind a single account. The method optimizes a global\nset of parameters to learn population-level abstractions of size and fit\nrelevant information from observed customer-article interactions. It further\nemploys customer and article specific embedding variables to learn their\nproperties. Together with learned entity embeddings, the method maps additional\ncustomer and article attributes into a latent space to derive personalized\nrecommendations. Application of our method to two publicly available datasets\ndemonstrate an improvement over the state-of-the-art published results. On two\nproprietary datasets, one containing fit feedback from fashion experts and the\nother involving customer purchases, we further outperform comparable\nmethodologies, including a recent Bayesian approach for size recommendation.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 12:47:53 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Sheikh", "Abdul-Saboor", ""], ["Guigoures", "Romain", ""], ["Koriagin", "Evgenii", ""], ["Ho", "Yuen King", ""], ["Shirvany", "Reza", ""], ["Vollgraf", "Roland", ""], ["Bergmann", "Urs", ""]]}, {"id": "1907.09881", "submitter": "Javier Zazo", "authors": "Javier Zazo, Bahareh Tolooshams, Demba Ba", "title": "Convolutional Dictionary Learning in Hierarchical Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filter banks are a popular tool for the analysis of piecewise smooth signals\nsuch as natural images. Motivated by the empirically observed properties of\nscale and detail coefficients of images in the wavelet domain, we propose a\nhierarchical deep generative model of piecewise smooth signals that is a\nrecursion across scales: the low pass scale coefficients at one layer are\nobtained by filtering the scale coefficients at the next layer, and adding a\nhigh pass detail innovation obtained by filtering a sparse vector. This\nrecursion describes a linear dynamic system that is a non-Gaussian Markov\nprocess across scales and is closely related to multilayer-convolutional sparse\ncoding (ML-CSC) generative model for deep networks, except that our model\nallows for deeper architectures, and combines sparse and non-sparse signal\nrepresentations. We propose an alternating minimization algorithm for learning\nthe filters in this hierarchical model given observations at layer zero, e.g.,\nnatural images. The algorithm alternates between a coefficient-estimation step\nand a filter update step. The coefficient update step performs sparse (detail)\nand smooth (scale) coding and, when unfolded, leads to a deep neural network.\nWe use MNIST to demonstrate the representation capabilities of the model, and\nits derived features (coefficients) for classification.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 13:57:03 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Zazo", "Javier", ""], ["Tolooshams", "Bahareh", ""], ["Ba", "Demba", ""]]}, {"id": "1907.09915", "submitter": "Huajun Liu", "authors": "Huajun Liu, Hui Zhang, Christoph Mertz", "title": "DeepDA: LSTM-based Deep Data Association Network for Multi-Targets\n  Tracking in Clutter", "comments": "8 pages, 12 figures. arXiv admin note: text overlap with\n  arXiv:1802.06897, arXiv:1604.03635 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Long Short-Term Memory (LSTM) neural network based data association\nalgorithm named as DeepDA for multi-target tracking in clutters is proposed to\ndeal with the NP-hard combinatorial optimization problem in this paper.\nDifferent from the classical data association methods involving complex models\nand accurate prior knowledge on clutter density, filter covariance or\nassociated gating etc, data-driven deep learning methods have been extensively\nresearched for this topic. Firstly, data association mathematical problem for\nmultitarget tracking on unknown target number, missed detection and clutter,\nwhich is beyond one-to-one mapping between observations and targets is\nredefined formally. Subsequently, an LSTM network is designed to learn the\nmeasurement-to-track association probability from radar noisy measurements and\nexist tracks. Moreover, an LSTM-based data-driven deep neural network after a\nsupervised training through the BPTT and RMSprop optimization method can get\nthe association probability directly. Experimental results on simulated data\nshow a significant performance on association ratio, target ID switching and\ntime-consuming for tracking multiple targets even they are crossing each other\nin the complicated clutter environment.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 23:00:42 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Liu", "Huajun", ""], ["Zhang", "Hui", ""], ["Mertz", "Christoph", ""]]}, {"id": "1907.09929", "submitter": "Daniel Lopez-Martinez", "authors": "Daniel Lopez-Martinez and Neska El-Haouij and Rosalind Picard", "title": "Detection of Real-world Driving-induced Affective State Using\n  Physiological Signals and Multi-view Multi-task Machine Learning", "comments": "Affective Computing and Intelligent Interaction Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affective states have a critical role in driving performance and safety. They\ncan degrade driver situation awareness and negatively impact cognitive\nprocesses, severely diminishing road safety. Therefore, detecting and assessing\ndrivers' affective states is crucial in order to help improve the driving\nexperience, and increase safety, comfort and well-being. Recent advances in\naffective computing have enabled the detection of such states. This may lead to\nempathic automotive user interfaces that account for the driver's emotional\nstate and influence the driver in order to improve safety. In this work, we\npropose a multiview multi-task machine learning method for the detection of\ndriver's affective states using physiological signals. The proposed approach is\nable to account for inter-drive variability in physiological responses while\nenabling interpretability of the learned models, a factor that is especially\nimportant in systems deployed in the real world. We evaluate the models on\nthree different datasets containing real-world driving experiences. Our results\nindicate that accounting for drive-specific differences significantly improves\nmodel performance.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 19:16:00 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Lopez-Martinez", "Daniel", ""], ["El-Haouij", "Neska", ""], ["Picard", "Rosalind", ""]]}, {"id": "1907.09949", "submitter": "Peng Cheng", "authors": "Rui Zhang, Peng Cheng, Zhuo Chen, Yonghui Li, Branka Vucetic", "title": "A Learning-Based Two-Stage Spectrum Sharing Strategy with Multiple\n  Primary Transmit Power Levels", "comments": "46 pages, 10 figures, accepted by IEEE Transactions on Signal\n  Processing 2019", "journal-ref": null, "doi": "10.1109/TSP.2019.2932866", "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-parameter cognition in a cognitive radio network (CRN) provides a more\nthorough understanding of the radio environments, and could potentially lead to\nfar more intelligent and efficient spectrum usage for a secondary user. In this\npaper, we investigate the multi-parameter cognition problem for a CRN where the\nprimary transmitter (PT) radiates multiple transmit power levels, and propose a\nlearning-based two-stage spectrum sharing strategy. We first propose a\ndata-driven/machine learning based multi-level spectrum sensing scheme,\nincluding the spectrum learning (Stage I) and prediction (the first part in\nStage II). This fully blind sensing scheme does not require any prior knowledge\nof the PT power characteristics. Then, based on a novel normalized power level\nalignment metric, we propose two prediction-transmission structures, namely\nperiodic and non-periodic, for spectrum access (the second part in Stage II),\nwhich enable the secondary transmitter (ST) to closely follow the PT power\nlevel variation. The periodic structure features a fixed prediction interval,\nwhile the non-periodic one dynamically determines the interval with a proposed\nreinforcement learning algorithm to further improve the alignment metric.\nFinally, we extend the prediction-transmission structure to an online scenario,\nwhere the number of PT power levels might change as a consequence of PT\nadapting to the environment fluctuation or quality of service variation. The\nsimulation results demonstrate the effectiveness of the proposed strategy in\nvarious scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 10:54:21 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Zhang", "Rui", ""], ["Cheng", "Peng", ""], ["Chen", "Zhuo", ""], ["Li", "Yonghui", ""], ["Vucetic", "Branka", ""]]}, {"id": "1907.09987", "submitter": "Assad Oberai", "authors": "Dhruv Patel and Assad A Oberai", "title": "Bayesian Inference with Generative Adversarial Network Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference is used extensively to infer and to quantify the\nuncertainty in a field of interest from a measurement of a related field when\nthe two are linked by a physical model. Despite its many applications, Bayesian\ninference faces challenges when inferring fields that have discrete\nrepresentations of large dimension, and/or have prior distributions that are\ndifficult to represent mathematically. In this manuscript we consider the use\nof Generative Adversarial Networks (GANs) in addressing these challenges. A GAN\nis a type of deep neural network equipped with the ability to learn the\ndistribution implied by multiple samples of a given field. Once trained on\nthese samples, the generator component of a GAN maps the iid components of a\nlow-dimensional latent vector to an approximation of the distribution of the\nfield of interest. In this work we demonstrate how this approximate\ndistribution may be used as a prior in a Bayesian update, and how it addresses\nthe challenges associated with characterizing complex prior distributions and\nthe large dimension of the inferred field. We demonstrate the efficacy of this\napproach by applying it to the problem of inferring and quantifying uncertainty\nin the initial temperature field in a heat conduction problem from a noisy\nmeasurement of the temperature at later time.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 05:08:20 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Patel", "Dhruv", ""], ["Oberai", "Assad A", ""]]}, {"id": "1907.10085", "submitter": "Angelica I. Aviles-Rivero", "authors": "Angelica I. Aviles-Rivero, Nicolas Papadakis, Ruoteng Li, Philip\n  Sellars, Qingnan Fan, Robby T. Tan, Carola-Bibiane Sch\\\"onlieb", "title": "GraphX$^{NET}-$ Chest X-Ray Classification Under Extreme Minimal\n  Supervision", "comments": "MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of classifying X-ray data is a problem of both theoretical and\nclinical interest. Whilst supervised deep learning methods rely upon huge\namounts of labelled data, the critical problem of achieving a good\nclassification accuracy when an extremely small amount of labelled data is\navailable has yet to be tackled. In this work, we introduce a novel\nsemi-supervised framework for X-ray classification which is based on a\ngraph-based optimisation model. To the best of our knowledge, this is the first\nmethod that exploits graph-based semi-supervised learning for X-ray data\nclassification. Furthermore, we introduce a new multi-class classification\nfunctional with carefully selected class priors which allows for a smooth\nsolution that strengthens the synergy between the limited number of labels and\nthe huge amount of unlabelled data. We demonstrate, through a set of numerical\nand visual experiments, that our method produces highly competitive results on\nthe ChestX-ray14 data set whilst drastically reducing the need for annotated\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 18:10:32 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 12:39:10 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2020 21:42:19 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Aviles-Rivero", "Angelica I.", ""], ["Papadakis", "Nicolas", ""], ["Li", "Ruoteng", ""], ["Sellars", "Philip", ""], ["Fan", "Qingnan", ""], ["Tan", "Robby T.", ""], ["Sch\u00f6nlieb", "Carola-Bibiane", ""]]}, {"id": "1907.10132", "submitter": "Sebastian Niehaus", "authors": "Marie Kloenne, Sebastian Niehaus, Leonie Lampe, Alberto Merola, Janis\n  Reinelt, Ingo Roeder, Nico Scherf", "title": "Domain specific cues improve robustness of deep learning based\n  segmentation of ct volumes", "comments": null, "journal-ref": "Scientific Reports 10, 10712 (2020)", "doi": "10.1038/s41598-020-67544-y", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning has considerably improved medical image analysis in the past\nyears. Although data-driven approaches are intrinsically adaptive and thus,\ngeneric, they often do not perform the same way on data from different imaging\nmodalities. In particular Computed tomography (CT) data poses many challenges\nto medical image segmentation based on convolutional neural networks (CNNs),\nmostly due to the broad dynamic range of intensities and the varying number of\nrecorded slices of CT volumes. In this paper, we address these issues with a\nframework that combines domain-specific data preprocessing and augmentation\nwith state-of-the-art CNN architectures. The focus is not limited to optimise\nthe score, but also to stabilise the prediction performance since this is a\nmandatory requirement for use in automated and semi-automated workflows in the\nclinical environment.\n  The framework is validated with an architecture comparison to show CNN\narchitecture-independent effects of our framework functionality. We compare a\nmodified U-Net and a modified Mixed-Scale Dense Network (MS-D Net) to compare\ndilated convolutions for parallel multi-scale processing to the U-Net approach\nbased on traditional scaling operations. Finally, we propose an ensemble model\ncombining the strengths of different individual methods. The framework performs\nwell on a range of tasks such as liver and kidney segmentation, without\nsignificant differences in prediction performance on strongly differing volume\nsizes and varying slice thickness. Thus our framework is an essential step\ntowards performing robust segmentation of unknown real-world samples.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 21:11:22 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 14:37:34 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 09:26:58 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Kloenne", "Marie", ""], ["Niehaus", "Sebastian", ""], ["Lampe", "Leonie", ""], ["Merola", "Alberto", ""], ["Reinelt", "Janis", ""], ["Roeder", "Ingo", ""], ["Scherf", "Nico", ""]]}, {"id": "1907.10134", "submitter": "Shang Wang", "authors": "Shang Wang and Yifan Bai and Gennady Pekhimenko", "title": "BPPSA: Scaling Back-propagation by Parallel Scan Algorithm", "comments": "In Proceedings of MLSys 2020:\n  https://mlsys.org/Conferences/2020/Schedule?showEvent=1407", "journal-ref": "Proceedings of Machine Learning and Systems 2020 (2020) 451-469", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In an era when the performance of a single compute device plateaus, software\nmust be designed to scale on massively parallel systems for better runtime\nperformance. However, in the context of training deep learning models, the\npopular back-propagation (BP) algorithm imposes a strong sequential dependency\nin the process of gradient computation. Under model parallelism, BP takes\n$\\Theta (n)$ steps to complete which hinders its scalability on parallel\nsystems ($n$ represents the number of compute devices into which a model is\npartitioned).\n  In this work, in order to improve the scalability of BP, we reformulate BP\ninto a scan operation which is a primitive that performs an in-order\naggregation on a sequence of values and returns the partial result at each\nstep. We can then scale such reformulation of BP on parallel systems by our\nmodified version of the Blelloch scan algorithm which theoretically takes\n$\\Theta (\\log n)$ steps. We evaluate our approach on a vanilla Recurrent Neural\nNetwork (RNN) training with synthetic datasets and a RNN with Gated Recurrent\nUnits (GRU) training with the IRMAS dataset, and demonstrate up to $2.75\\times$\nspeedup on the overall training time and $108\\times$ speedup on the backward\npass. We also demonstrate that the retraining of pruned networks can be a\npractical use case of our method.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 21:14:56 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 21:46:59 GMT"}, {"version": "v3", "created": "Sat, 7 Mar 2020 05:45:50 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Wang", "Shang", ""], ["Bai", "Yifan", ""], ["Pekhimenko", "Gennady", ""]]}, {"id": "1907.10147", "submitter": "Mineto Tsukada", "authors": "Mineto Tsukada, Masaaki Kondo, Hiroki Matsutani", "title": "A Neural Network-Based On-device Learning Anomaly Detector for Edge\n  Devices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised anomaly detection is an approach to identify anomalies by\nlearning the distribution of normal data. Backpropagation neural networks\n(i.e., BP-NNs) based approaches have recently drawn attention because of their\ngood generalization capability. In a typical situation, BP-NN-based models are\niteratively optimized in server machines with input data gathered from edge\ndevices. However, (1) the iterative optimization often requires significant\nefforts to follow changes in the distribution of normal data (i.e., concept\ndrift), and (2) data transfers between edge and server impose additional\nlatency and energy consumption. To address these issues, we propose ONLAD and\nits IP core, named ONLAD Core. ONLAD is highly optimized to perform fast\nsequential learning to follow concept drift in less than one millisecond. ONLAD\nCore realizes on-device learning for edge devices at low power consumption,\nwhich realizes standalone execution where data transfers between edge and\nserver are not required. Experiments show that ONLAD has favorable anomaly\ndetection capability in an environment that simulates concept drift.\nEvaluations of ONLAD Core confirm that the training latency is 1.95x~6.58x\nfaster than the other software implementations. Also, the runtime power\nconsumption of ONLAD Core implemented on PYNQ-Z1 board, a small FPGA/CPU SoC\nplatform, is 5.0x~25.4x lower than them.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 21:40:46 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 12:23:16 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2019 17:25:50 GMT"}, {"version": "v4", "created": "Wed, 2 Oct 2019 15:42:33 GMT"}, {"version": "v5", "created": "Sun, 2 Feb 2020 18:58:01 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Tsukada", "Mineto", ""], ["Kondo", "Masaaki", ""], ["Matsutani", "Hiroki", ""]]}, {"id": "1907.10154", "submitter": "Matthew Faw", "authors": "Matthew Faw, Rajat Sen, Karthikeyan Shanmugam, Constantine Caramanis,\n  Sanjay Shakkottai", "title": "Mix and Match: An Optimistic Tree-Search Approach for Learning Models\n  from Mixture Distributions", "comments": "New from previous version: Adds Acknowledgements section", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a covariate shift problem where one has access to several\ndifferent training datasets for the same learning problem and a small\nvalidation set which possibly differs from all the individual training\ndistributions. This covariate shift is caused, in part, due to unobserved\nfeatures in the datasets. The objective, then, is to find the best mixture\ndistribution over the training datasets (with only observed features) such that\ntraining a learning algorithm using this mixture has the best validation\nperformance. Our proposed algorithm, ${\\sf Mix\\&Match}$, combines stochastic\ngradient descent (SGD) with optimistic tree search and model re-use (evolving\npartially trained models with samples from different mixture distributions)\nover the space of mixtures, for this task. We prove simple regret guarantees\nfor our algorithm with respect to recovering the optimal mixture, given a total\nbudget of SGD evaluations. Finally, we validate our algorithm on two real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 22:02:52 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 03:51:12 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 03:42:33 GMT"}, {"version": "v4", "created": "Sat, 8 Feb 2020 01:40:03 GMT"}, {"version": "v5", "created": "Tue, 14 Jul 2020 19:43:16 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Faw", "Matthew", ""], ["Sen", "Rajat", ""], ["Shanmugam", "Karthikeyan", ""], ["Caramanis", "Constantine", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "1907.10165", "submitter": "Derek Tam", "authors": "Derek Tam, Nicholas Monath, Ari Kobren, Aaron Traylor, Rajarshi Das,\n  Andrew McCallum", "title": "Optimal Transport-based Alignment of Learned Character Representations\n  for String Similarity", "comments": "ACL Long Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String similarity models are vital for record linkage, entity resolution, and\nsearch. In this work, we present STANCE --a learned model for computing the\nsimilarity of two strings. Our approach encodes the characters of each string,\naligns the encodings using Sinkhorn Iteration (alignment is posed as an\ninstance of optimal transport) and scores the alignment with a convolutional\nneural network. We evaluate STANCE's ability to detect whether two strings can\nrefer to the same entity--a task we term alias detection. We construct five new\nalias detection datasets (and make them publicly available). We show that\nSTANCE or one of its variants outperforms both state-of-the-art and classic,\nparameter-free similarity models on four of the five datasets. We also\ndemonstrate STANCE's ability to improve downstream tasks by applying it to an\ninstance of cross-document coreference and show that it leads to a 2.8 point\nimprovement in B^3 F1 over the previous state-of-the-art approach.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 22:41:22 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Tam", "Derek", ""], ["Monath", "Nicholas", ""], ["Kobren", "Ari", ""], ["Traylor", "Aaron", ""], ["Das", "Rajarshi", ""], ["McCallum", "Andrew", ""]]}, {"id": "1907.10170", "submitter": "Yeping Hu", "authors": "Yeping Hu, Liting Sun, Masayoshi Tomizuka", "title": "Generic Prediction Architecture Considering both Rational and Irrational\n  Driving Behaviors", "comments": "Accepted by 2019 IEEE Intelligent Transportation Systems Conference\n  (ITSC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting future behaviors of surrounding vehicles is an\nessential capability for autonomous vehicles in order to plan safe and feasible\ntrajectories. The behaviors of others, however, are full of uncertainties. Both\nrational and irrational behaviors exist, and the autonomous vehicles need to be\naware of this in their prediction module. The prediction module is also\nexpected to generate reasonable results in the presence of unseen and corner\nscenarios. Two types of prediction models are typically used to solve the\nprediction problem: learning-based model and planning-based model.\nLearning-based model utilizes real driving data to model the human behaviors.\nDepending on the structure of the data, learning-based models can predict both\nrational and irrational behaviors. But the balance between them cannot be\ncustomized, which creates challenges in generalizing the prediction results.\nPlanning-based model, on the other hand, usually assumes human as a rational\nagent, i.e., it anticipates only rational behavior of human drivers. In this\npaper, a generic prediction architecture is proposed to address various\nrationalities in human behavior. We leverage the advantages from both\nlearning-based and planning-based prediction models. The proposed approach is\nable to predict continuous trajectories that well-reflect possible future\nsituations of other drivers. Moreover, the prediction performance remains\nstable under various unseen driving scenarios. A case study under a real-world\nroundabout scenario is provided to demonstrate the performance and capability\nof the proposed prediction architecture.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 23:07:22 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Hu", "Yeping", ""], ["Sun", "Liting", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1907.10178", "submitter": "Luca Anthony Thiede", "authors": "Luca Anthony Thiede and Pratik Prabhanjan Brahma", "title": "Analyzing the Variety Loss in the Context of Probabilistic Trajectory\n  Prediction", "comments": "Accepted for publication at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trajectory or behavior prediction of traffic agents is an important component\nof autonomous driving and robot planning in general. It can be framed as a\nprobabilistic future sequence generation problem and recent literature has\nstudied the applicability of generative models in this context. The variety or\nMinimum over N (MoN) loss, which tries to minimize the error between the ground\ntruth and the closest of N output predictions, has been used in these recent\nlearning models to improve the diversity of predictions. In this work, we\npresent a proof to show that the MoN loss does not lead to the ground truth\nprobability density function, but approximately to its square root instead. We\nvalidate this finding with extensive experiments on both simulated toy as well\nas real world datasets. We also propose multiple solutions to compensate for\nthe dilation to show improvement of log likelihood of the ground truth samples\nin the corrected probability density function.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 23:56:02 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Thiede", "Luca Anthony", ""], ["Brahma", "Pratik Prabhanjan", ""]]}, {"id": "1907.10225", "submitter": "Zhenghang Cui", "authors": "Zhenghang Cui, Nontawat Charoenphakdee, Issei Sato, Masashi Sugiyama", "title": "Classification from Triplet Comparison Data", "comments": "Code: https://github.com/zchenry/triplet_classification", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from triplet comparison data has been extensively studied in the\ncontext of metric learning, where we want to learn a distance metric between\ntwo instances, and ordinal embedding, where we want to learn an embedding in an\nEuclidean space of the given instances that preserves the comparison order as\nwell as possible. Unlike fully-labeled data, triplet comparison data can be\ncollected in a more accurate and human-friendly way. Although learning from\ntriplet comparison data has been considered in many applications, an important\nfundamental question of whether we can learn a classifier only from triplet\ncomparison data has remained unanswered. In this paper, we give a positive\nanswer to this important question by proposing an unbiased estimator for the\nclassification risk under the empirical risk minimization framework. Since the\nproposed method is based on the empirical risk minimization framework, it\ninherently has the advantage that any surrogate loss function and any model,\nincluding neural networks, can be easily applied. Furthermore, we theoretically\nestablish an estimation error bound for the proposed empirical risk minimizer.\nFinally, we provide experimental results to show that our method empirically\nworks well and outperforms various baseline methods.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 03:49:16 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 05:09:32 GMT"}, {"version": "v3", "created": "Sat, 18 Apr 2020 05:17:47 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Cui", "Zhenghang", ""], ["Charoenphakdee", "Nontawat", ""], ["Sato", "Issei", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1907.10235", "submitter": "Junwei Pan", "authors": "Junwei Pan, Yizhi Mao, Alfonso Lobos Ruiz, Yu Sun, Aaron Flores", "title": "Predicting Different Types of Conversions with Multi-Task Learning in\n  Online Advertising", "comments": "SIGKDD", "journal-ref": "SIGKDD 2019", "doi": "10.1145/3292500.3330783", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversion prediction plays an important role in online advertising since\nCost-Per-Action (CPA) has become one of the primary campaign performance\nobjectives in the industry. Unlike click prediction, conversions have different\ntypes in nature, and each type may be associated with different decisive\nfactors. In this paper, we formulate conversion prediction as a multi-task\nlearning problem, so that the prediction models for different types of\nconversions can be learned together. These models share feature\nrepresentations, but have their specific parameters, providing the benefit of\ninformation-sharing across all tasks. We then propose Multi-Task Field-weighted\nFactorization Machine (MT-FwFM) to solve these tasks jointly. Our experiment\nresults show that, compared with two state-of-the-art models, MT-FwFM improve\nthe AUC by 0.74% and 0.84% on two conversion types, and the weighted AUC across\nall conversion types is also improved by 0.50%.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 04:47:05 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 23:46:52 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Pan", "Junwei", ""], ["Mao", "Yizhi", ""], ["Ruiz", "Alfonso Lobos", ""], ["Sun", "Yu", ""], ["Flores", "Aaron", ""]]}, {"id": "1907.10247", "submitter": "Yijie Guo", "authors": "Yijie Guo, Jongwook Choi, Marcin Moczulski, Shengyu Feng, Samy Bengio,\n  Mohammad Norouzi, Honglak Lee", "title": "Memory Based Trajectory-conditioned Policies for Learning from Sparse\n  Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning with sparse rewards is challenging because an agent\ncan rarely obtain non-zero rewards and hence, gradient-based optimization of\nparameterized policies can be incremental and slow. Recent work demonstrated\nthat using a memory buffer of previous successful trajectories can result in\nmore effective policies. However, existing methods may overly exploit past\nsuccessful experiences, which can encourage the agent to adopt sub-optimal and\nmyopic behaviors. In this work, instead of focusing on good experiences with\nlimited diversity, we propose to learn a trajectory-conditioned policy to\nfollow and expand diverse past trajectories from a memory buffer. Our method\nallows the agent to reach diverse regions in the state space and improve upon\nthe past trajectories to reach new states. We empirically show that our\napproach significantly outperforms count-based exploration methods (parametric\napproach) and self-imitation learning (parametric approach with non-parametric\nmemory) on various complex tasks with local optima. In particular, without\nusing expert demonstrations or resetting to arbitrary states, we achieve the\nstate-of-the-art scores under five billion number of frames, on challenging\nAtari games such as Montezuma's Revenge and Pitfall.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 05:46:27 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 00:41:38 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2021 03:53:20 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Guo", "Yijie", ""], ["Choi", "Jongwook", ""], ["Moczulski", "Marcin", ""], ["Feng", "Shengyu", ""], ["Bengio", "Samy", ""], ["Norouzi", "Mohammad", ""], ["Lee", "Honglak", ""]]}, {"id": "1907.10265", "submitter": "Sara Mohammadinejad", "authors": "Sara Mohammadinejad, Jyotirmoy V. Deshmukh, Aniruddh G. Puranic,\n  Marcell Vazquez-Chanlatte, Alexandre Donz\\'e", "title": "Interpretable Classification of Time-Series Data using Efficient\n  Enumerative Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyber-physical system applications such as autonomous vehicles, wearable\ndevices, and avionic systems generate a large volume of time-series data.\nDesigners often look for tools to help classify and categorize the data.\nTraditional machine learning techniques for time-series data offer several\nsolutions to solve these problems; however, the artifacts trained by these\nalgorithms often lack interpretability. On the other hand, temporal logics,\nsuch as Signal Temporal Logic (STL) have been successfully used in the formal\nmethods community as specifications of time-series behaviors. In this work, we\npropose a new technique to automatically learn temporal logic formulae that are\nable to cluster and classify real-valued time-series data. Previous work on\nlearning STL formulas from data either assumes a formula-template to be given\nby the user, or assumes some special fragment of STL that enables exploring the\nformula structure in a systematic fashion. In our technique, we relax these\nassumptions, and provide a way to systematically explore the space of all STL\nformulas. As the space of all STL formulas is very large, and contains many\nsemantically equivalent formulas, we suggest a technique to heuristically prune\nthe space of formulas considered. Finally, we illustrate our technique on\nvarious case studies from the automotive, transportation and healthcare domain.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 06:54:04 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Mohammadinejad", "Sara", ""], ["Deshmukh", "Jyotirmoy V.", ""], ["Puranic", "Aniruddh G.", ""], ["Vazquez-Chanlatte", "Marcell", ""], ["Donz\u00e9", "Alexandre", ""]]}, {"id": "1907.10267", "submitter": "Jun Chen", "authors": "Jun Chen, Heye Zhang, Yanping Zhang, Shu Zhao, Raad Mohiaddin, Tom\n  Wong, David Firmin, Guang Yang, Jennifer Keegan", "title": "Discriminative Consistent Domain Generation for Semi-supervised Learning", "comments": "MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning based task systems normally rely on a large amount of manually\nlabeled training data, which is expensive to obtain and subject to operator\nvariations. Moreover, it does not always hold that the manually labeled data\nand the unlabeled data are sitting in the same distribution. In this paper, we\nalleviate these problems by proposing a discriminative consistent domain\ngeneration (DCDG) approach to achieve a semi-supervised learning. The\ndiscriminative consistent domain is achieved by a double-sided domain\nadaptation. The double-sided domain adaptation aims to make a fusion of the\nfeature spaces of labeled data and unlabeled data. In this way, we can fit the\ndifferences of various distributions between labeled data and unlabeled data.\nIn order to keep the discriminativeness of generated consistent domain for the\ntask learning, we apply an indirect learning for the double-sided domain\nadaptation. Based on the generated discriminative consistent domain, we can use\nthe unlabeled data to learn the task model along with the labeled data via a\nconsistent image generation. We demonstrate the performance of our proposed\nDCDG on the late gadolinium enhancement cardiac MRI (LGE-CMRI) images acquired\nfrom patients with atrial fibrillation in two clinical centers for the\nsegmentation of the left atrium anatomy (LA) and proximal pulmonary veins\n(PVs). The experiments show that our semi-supervised approach achieves\ncompelling segmentation results, which can prove the robustness of DCDG for the\nsemi-supervised learning using the unlabeled data along with labeled data\nacquired from a single center or multicenter studies.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 06:59:23 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Chen", "Jun", ""], ["Zhang", "Heye", ""], ["Zhang", "Yanping", ""], ["Zhao", "Shu", ""], ["Mohiaddin", "Raad", ""], ["Wong", "Tom", ""], ["Firmin", "David", ""], ["Yang", "Guang", ""], ["Keegan", "Jennifer", ""]]}, {"id": "1907.10290", "submitter": "Shi-Ju Ran", "authors": "Shi-Ju Ran, Zheng-Zhi Sun, Shao-Ming Fei, Gang Su, and Maciej\n  Lewenstein", "title": "Quantum Compressed Sensing with Unsupervised Tensor-Network Machine\n  Learning", "comments": "5+6 pages, 3+6 figures. Essential changes and new data were added to\n  this new version", "journal-ref": "Phys. Rev. Research 2, 033293 (2020)", "doi": "10.1103/PhysRevResearch.2.033293", "report-no": null, "categories": "stat.ML cond-mat.str-el cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose tensor-network compressed sensing (TNCS) by combining the ideas of\ncompressed sensing, tensor network (TN), and machine learning, which permits\nnovel and efficient quantum communications of realistic data. The strategy is\nto use the unsupervised TN machine learning algorithm to obtain the entangled\nstate $|\\Psi \\rangle$ that describes the probability distribution of a huge\namount of classical information considered to be communicated. To transfer a\nspecific piece of information with $|\\Psi \\rangle$, our proposal is to encode\nsuch information in the separable state with the minimal distance to the\nmeasured state $|\\Phi \\rangle$ that is obtained by partially measuring on\n$|\\Psi \\rangle$ in a designed way. To this end, a measuring protocol analogous\nto the compressed sensing with neural-network machine learning is suggested,\nwhere the measurements are designed to minimize uncertainty of information from\nthe probability distribution given by $|\\Phi \\rangle$. In this way, those who\nhave $|\\Phi \\rangle$ can reliably access the information by simply measuring on\n$|\\Phi \\rangle$. We propose q-sparsity to characterize the sparsity of quantum\nstates and the efficiency of the quantum communications by TNCS. The high\nq-sparsity is essentially due to the fact that the TN states describing nicely\nthe probability distribution obey the area law of entanglement entropy. Testing\non realistic datasets (hand-written digits and fashion images), TNCS is shown\nto possess high efficiency and accuracy, where the security of communications\nis guaranteed by the fundamental quantum principles.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 08:09:03 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 12:25:58 GMT"}], "update_date": "2020-09-02", "authors_parsed": [["Ran", "Shi-Ju", ""], ["Sun", "Zheng-Zhi", ""], ["Fei", "Shao-Ming", ""], ["Su", "Gang", ""], ["Lewenstein", "Maciej", ""]]}, {"id": "1907.10300", "submitter": "Lenaic Chizat", "authors": "Lenaic Chizat (CNRS, LMO)", "title": "Sparse Optimization on Measures with Over-parameterized Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimizing a convex function of a measure with a sparsity-inducing penalty is\na typical problem arising, e.g., in sparse spikes deconvolution or two-layer\nneural networks training. We show that this problem can be solved by\ndiscretizing the measure and running non-convex gradient descent on the\npositions and weights of the particles. For measures on a $d$-dimensional\nmanifold and under some non-degeneracy assumptions, this leads to a global\noptimization algorithm with a complexity scaling as $\\log(1/\\epsilon)$ in the\ndesired accuracy $\\epsilon$, instead of $\\epsilon^{-d}$ for convex methods. The\nkey theoretical tools are a local convergence analysis in Wasserstein space and\nan analysis of a perturbed mirror descent in the space of measures. Our bounds\ninvolve quantities that are exponential in $d$ which is unavoidable under our\nassumptions.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 08:42:11 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2020 14:25:47 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Chizat", "Lenaic", "", "CNRS, LMO"]]}, {"id": "1907.10323", "submitter": "Paul Weng", "authors": "Paul Weng", "title": "Fairness in Reinforcement Learning", "comments": "Presented at the AI for Social Good Workshop at IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision support systems (e.g., for ecological conservation) and autonomous\nsystems (e.g., adaptive controllers in smart cities) start to be deployed in\nreal applications. Although their operations often impact many users or\nstakeholders, no fairness consideration is generally taken into account in\ntheir design, which could lead to completely unfair outcomes for some users or\nstakeholders. To tackle this issue, we advocate for the use of social welfare\nfunctions that encode fairness and present this general novel problem in the\ncontext of (deep) reinforcement learning, although it could possibly be\nextended to other machine learning tasks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 09:27:11 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Weng", "Paul", ""]]}, {"id": "1907.10348", "submitter": "Vlad Niculae", "authors": "Andr\\'e F.T. Martins, Vlad Niculae", "title": "Notes on Latent Structure Models and SPIGOT", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These notes aim to shed light on the recently proposed structured projected\nintermediate gradient optimization technique (SPIGOT, Peng et al., 2018).\nSPIGOT is a variant of the straight-through estimator (Bengio et al., 2013)\nwhich bypasses gradients of the argmax function by back-propagating a surrogate\n\"gradient.\" We provide a new interpretation to the proposed gradient and put\nthis technique into perspective, linking it to other methods for training\nneural networks with discrete latent variables. As a by-product, we suggest\nalternate variants of SPIGOT which will be further explored in future work.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 10:26:45 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Martins", "Andr\u00e9 F. T.", ""], ["Niculae", "Vlad", ""]]}, {"id": "1907.10383", "submitter": "Alonso Marco", "authors": "Alonso Marco, Dominik Baumann, Philipp Hennig, Sebastian Trimpe", "title": "Classified Regression for Bayesian Optimization: Robot Learning with\n  Unknown Penalties", "comments": "This paper was submitted to JMLR in 2018 and rejected. Currently, it\n  is not published, nor under review in any conference or journal venue", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning robot controllers by minimizing a black-box objective cost using\nBayesian optimization (BO) can be time-consuming and challenging. It is very\noften the case that some roll-outs result in failure behaviors, causing\npremature experiment detention. In such cases, the designer is forced to decide\non heuristic cost penalties because the acquired data is often scarce, or not\ncomparable with that of the stable policies. To overcome this, we propose a\nBayesian model that captures exactly what we know about the cost of unstable\ncontrollers prior to data collection: Nothing, except that it should be a\nsomewhat large number. The resulting Bayesian model, approximated with a\nGaussian process, predicts high cost values in regions where failures are\nlikely to occur. In this way, the model guides the BO exploration toward\nregions of stability. We demonstrate the benefits of the proposed model in\nseveral illustrative and statistical synthetic benchmarks, and also in\nexperiments on a real robotic platform. In addition, we propose and\nexperimentally validate a new BO method to account for unknown constraints.\nSuch method is an extension of Max-Value Entropy Search, a recent\ninformation-theoretic method, to solve unconstrained global optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 12:25:37 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2020 19:22:36 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Marco", "Alonso", ""], ["Baumann", "Dominik", ""], ["Hennig", "Philipp", ""], ["Trimpe", "Sebastian", ""]]}, {"id": "1907.10388", "submitter": "Eric Mitchell", "authors": "Eric Mitchell, Selim Engin, Volkan Isler, Daniel D Lee", "title": "Higher-Order Function Networks for Learning Composable 3D Object\n  Representations", "comments": "To be published in International Conference on Learning\n  Representations (ICLR 2020) [https://openreview.net/forum?id=HJgfDREKDB]; 19\n  pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to 3D object representation where a neural network\nencodes the geometry of an object directly into the weights and biases of a\nsecond 'mapping' network. This mapping network can be used to reconstruct an\nobject by applying its encoded transformation to points randomly sampled from a\nsimple geometric space, such as the unit sphere. We study the effectiveness of\nour method through various experiments on subsets of the ShapeNet dataset. We\nfind that the proposed approach can reconstruct encoded objects with accuracy\nequal to or exceeding state-of-the-art methods with orders of magnitude fewer\nparameters. Our smallest mapping network has only about 7000 parameters and\nshows reconstruction quality on par with state-of-the-art object decoder\narchitectures with millions of parameters. Further experiments on feature\nmixing through the composition of learned functions show that the encoding\ncaptures a meaningful subspace of objects.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 12:31:16 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 05:18:09 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Mitchell", "Eric", ""], ["Engin", "Selim", ""], ["Isler", "Volkan", ""], ["Lee", "Daniel D", ""]]}, {"id": "1907.10393", "submitter": "Qingjian Lin", "authors": "Qingjian Lin, Ruiqing Yin, Ming Li, Herv\\'e Bredin, Claude Barras", "title": "LSTM based Similarity Measurement with Spectral Clustering for Speaker\n  Diarization", "comments": "Accepted for INTERSPEECH 2019", "journal-ref": null, "doi": "10.21437/Interspeech.2019-1388", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More and more neural network approaches have achieved considerable\nimprovement upon submodules of speaker diarization system, including speaker\nchange detection and segment-wise speaker embedding extraction. Still, in the\nclustering stage, traditional algorithms like probabilistic linear discriminant\nanalysis (PLDA) are widely used for scoring the similarity between two speech\nsegments. In this paper, we propose a supervised method to measure the\nsimilarity matrix between all segments of an audio recording with sequential\nbidirectional long short-term memory networks (Bi-LSTM). Spectral clustering is\napplied on top of the similarity matrix to further improve the performance.\nExperimental results show that our system significantly outperforms the\nstate-of-the-art methods and achieves a diarization error rate of 6.63% on the\nNIST SRE 2000 CALLHOME database.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 04:17:58 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Lin", "Qingjian", ""], ["Yin", "Ruiqing", ""], ["Li", "Ming", ""], ["Bredin", "Herv\u00e9", ""], ["Barras", "Claude", ""]]}, {"id": "1907.10401", "submitter": "Camille Roth", "authors": "Camille Roth (CAMS, CMB)", "title": "Algorithmic Distortion of Informational Landscapes", "comments": null, "journal-ref": "Intellectica, In press", "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The possible impact of algorithmic recommendation on the autonomy and free\nchoice of Internet users is being increasingly discussed, especially in terms\nof the rendering of information and the structuring of interactions. This paper\naims at reviewing and framing this issue along a double dichotomy. The first\none addresses the discrepancy between users' intentions and actions (1) under\nsome algorithmic influence and (2) without it. The second one distinguishes\nalgorithmic biases on (1) prior information rearrangement and (2) posterior\ninformation arrangement. In all cases, we focus on and differentiate situations\nwhere algorithms empirically appear to expand the cognitive and social horizon\nof users, from those where they seem to limit that horizon. We additionally\nsuggest that these biases may not be properly appraised without taking into\naccount the underlying social processes which algorithms are building upon.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 08:13:18 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Roth", "Camille", "", "CAMS, CMB"]]}, {"id": "1907.10410", "submitter": "Adel Bibi", "authors": "Adel Bibi, Baoyuan Wu and Bernard Ghanem", "title": "Constrained K-means with General Pairwise and Cardinality Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study constrained clustering, where constraints are utilized\nto guide the clustering process. In existing works, two categories of\nconstraints have been widely explored, namely pairwise and cardinality\nconstraints. Pairwise constraints enforce the cluster labels of two instances\nto be the same (must-link constraints) or different (cannot-link constraints).\nCardinality constraints encourage cluster sizes to satisfy a user-specified\ndistribution. However, most existing constrained clustering models can only\nutilize one category of constraints at a time. In this paper, we enforce the\nabove two categories into a unified clustering model starting with the integer\nprogram formulation of the standard K-means. As these two categories provide\nuseful information at different levels, utilizing both of them is expected to\nallow for better clustering performance. However, the optimization is difficult\ndue to the binary and quadratic constraints in the proposed unified\nformulation. To alleviate this difficulty, we utilize two techniques:\nequivalently replacing the binary constraints by the intersection of two\ncontinuous constraints; the other is transforming the quadratic constraints\ninto bi-linear constraints by introducing extra variables. Then we derive an\nequivalent continuous reformulation with simple constraints, which can be\nefficiently solved by Alternating Direction Method of Multipliers (ADMM)\nalgorithm. Extensive experiments on both synthetic and real data demonstrate:\n(1) when utilizing a single category of constraint, the proposed model is\nsuperior to or competitive with state-of-the-art constrained clustering models,\nand (2) when utilizing both categories of constraints jointly, the proposed\nmodel shows better performance than the case of the single category.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 12:53:19 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Bibi", "Adel", ""], ["Wu", "Baoyuan", ""], ["Ghanem", "Bernard", ""]]}, {"id": "1907.10418", "submitter": "Mahdy Rahman Chowdhury Mahdy", "authors": "Aimon Rahman, Hasib Zunair, M Sohel Rahman, Jesia Quader Yuki,\n  Sabyasachi Biswas, Md Ashraful Alam, Nabila Binte Alam, M.R.C. Mahdy", "title": "Improving Malaria Parasite Detection from Red Blood Cell using Deep\n  Convolutional Neural Networks", "comments": "Application of deep learning in biological science for the early\n  detection of disease", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malaria is a female anopheles mosquito-bite inflicted life-threatening\ndisease which is considered endemic in many parts of the world. This article\nfocuses on improving malaria detection from patches segmented from microscopic\nimages of red blood cell smears by introducing a deep convolutional neural\nnetwork. Compared to the traditional methods that use tedious hand engineering\nfeature extraction, the proposed method uses deep learning in an end-to-end\narrangement that performs both feature extraction and classification directly\nfrom the raw segmented patches of the red blood smears. The dataset used in\nthis study was taken from National Institute of Health named NIH Malaria\nDataset. The evaluation metric accuracy and loss along with 5-fold cross\nvalidation was used to compare and select the best performing architecture. To\nmaximize the performance, existing standard pre-processing techniques from the\nliterature has also been experimented. In addition, several other complex\narchitectures have been implemented and tested to pick the best performing\nmodel. A holdout test has also been conducted to verify how well the proposed\nmodel generalizes on unseen data. Our best model achieves an accuracy of almost\n97.77%.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 04:30:12 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Rahman", "Aimon", ""], ["Zunair", "Hasib", ""], ["Rahman", "M Sohel", ""], ["Yuki", "Jesia Quader", ""], ["Biswas", "Sabyasachi", ""], ["Alam", "Md Ashraful", ""], ["Alam", "Nabila Binte", ""], ["Mahdy", "M. R. C.", ""]]}, {"id": "1907.10419", "submitter": "Po-Yu Kao", "authors": "Po-Yu Kao, Jefferson W. Chen, B.S. Manjunath", "title": "Predicting Clinical Outcome of Stroke Patients with Tractographic\n  Feature", "comments": "12 pages, 4 figures, 3 tables. Accepted by MICCAI-BrainLesion 2019 as\n  an oral presentation", "journal-ref": null, "doi": "10.1007/978-3-030-46640-4_4", "report-no": null, "categories": "eess.IV cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The volume of stroke lesion is the gold standard for predicting the clinical\noutcome of stroke patients. However, the presence of stroke lesion may cause\nneural disruptions to other brain regions, and these potentially damaged\nregions may affect the clinical outcome of stroke patients. In this paper, we\nintroduce the tractographic feature to capture these potentially damaged\nregions and predict the modified Rankin Scale (mRS), which is a widely used\noutcome measure in stroke clinical trials. The tractographic feature is built\nfrom the stroke lesion and average connectome information from a group of\nnormal subjects. The tractographic feature takes into account different\nfunctional regions that may be affected by the stroke, thus complementing the\ncommonly used stroke volume features. The proposed tractographic feature is\ntested on a public stroke benchmark Ischemic Stroke Lesion Segmentation 2017\nand achieves higher accuracy than the stroke volume and the state-of-the-art\nfeature on predicting the mRS grades of stroke patients. In addition, the\ntractographic feature also yields a lower average absolute error than the\ncommonly used stroke volume feature.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 23:27:54 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 23:15:17 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 23:12:58 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Kao", "Po-Yu", ""], ["Chen", "Jefferson W.", ""], ["Manjunath", "B. S.", ""]]}, {"id": "1907.10420", "submitter": "Amirhossein Hajavi", "authors": "Amirhossein Hajavi and Ali Etemad", "title": "A Deep Neural Network for Short-Segment Speaker Recognition", "comments": "Accepted in Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Todays interactive devices such as smart-phone assistants and smart speakers\noften deal with short-duration speech segments. As a result, speaker\nrecognition systems integrated into such devices will be much better suited\nwith models capable of performing the recognition task with short-duration\nutterances. In this paper, a new deep neural network, UtterIdNet, capable of\nperforming speaker recognition with short speech segments is proposed. Our\nproposed model utilizes a novel architecture that makes it suitable for\nshort-segment speaker recognition through an efficiently increased use of\ninformation in short speech segments. UtterIdNet has been trained and tested on\nthe VoxCeleb datasets, the latest benchmarks in speaker recognition.\nEvaluations for different segment durations show consistent and stable\nperformance for short segments, with significant improvement over the previous\nmodels for segments of 2 seconds, 1 second, and especially sub-second durations\n(250 ms and 500 ms).\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 23:43:20 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Hajavi", "Amirhossein", ""], ["Etemad", "Ali", ""]]}, {"id": "1907.10421", "submitter": "Sumedh Yadav", "authors": "Sumedh Yadav and Mathis Bode", "title": "A graphical heuristic for reduction and partitioning of large datasets\n  for scalable supervised training", "comments": "30 pages, 25 figures, undergoing revision for publication in the\n  Journal of Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A scalable graphical method is presented for selecting, and partitioning\ndatasets for the training phase of a classification task. For the heuristic, a\nclustering algorithm is required to get its computation cost in a reasonable\nproportion to the task itself. This step is proceeded by construction of an\ninformation graph of the underlying classification patterns using approximate\nnearest neighbor methods. The presented method constitutes of two approaches,\none for reducing a given training set, and another for partitioning the\nselected/reduced set. The heuristic targets large datasets, since the primary\ngoal is significant reduction in training computation run-time without\ncompromising prediction accuracy. Test results show that both approaches\nsignificantly speed-up the training task when compared against that of\nstate-of-the-art shrinking heuristic available in LIBSVM. Furthermore, the\napproaches closely follow or even outperform in prediction accuracy. A network\ndesign is also presented for the partitioning based distributed training\nformulation. Added speed-up in training run-time is observed when compared to\nthat of serial implementation of the approaches.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 13:05:15 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Yadav", "Sumedh", ""], ["Bode", "Mathis", ""]]}, {"id": "1907.10430", "submitter": "Octavian-Eugen Ganea", "authors": "Octavian-Eugen Ganea, Yashas Annadani, Gary B\\'ecigneul", "title": "Noise Contrastive Variational Autoencoders", "comments": "There is a mistake common to all the main proofs. In summary, what we\n  find are saddle points or global maxima of the respective loss functions and\n  not the global minima. We apologize for this", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We take steps towards understanding the \"posterior collapse (PC)\" difficulty\nin variational autoencoders (VAEs),~i.e. a degenerate optimum in which the\nlatent codes become independent of their corresponding inputs. We rely on\ncalculus of variations and theoretically explore a few popular VAE models,\nshowing that PC always occurs for non-parametric encoders and decoders.\nInspired by the popular noise contrastive estimation algorithm, we propose\nNC-VAE where the encoder discriminates between the latent codes of real data\nand of some artificially generated noise, in addition to encouraging good data\nreconstruction abilities. Theoretically, we prove that our model cannot reach\nPC and provide novel lower bounds. Our method is straightforward to implement\nand has the same run-time as vanilla VAE. Empirically, we showcase its benefits\non popular image and text datasets.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 15:06:23 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 13:47:43 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Ganea", "Octavian-Eugen", ""], ["Annadani", "Yashas", ""], ["B\u00e9cigneul", "Gary", ""]]}, {"id": "1907.10477", "submitter": "Axel Finke", "authors": "Axel Finke, Alexandre H. Thiery", "title": "On importance-weighted autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance weighted autoencoder (IWAE) (Burda et al., 2016) is a popular\nvariational-inference method which achieves a tighter evidence bound (and hence\na lower bias) than standard variational autoencoders by optimising a\nmulti-sample objective, i.e. an objective that is expressible as an integral\nover $K > 1$ Monte Carlo samples. Unfortunately, IWAE crucially relies on the\navailability of reparametrisations and even if these exist, the multi-sample\nobjective leads to inference-network gradients which break down as $K$ is\nincreased (Rainforth et al., 2018). This breakdown can only be circumvented by\nremoving high-variance score-function terms, either by heuristically ignoring\nthem (which yields the 'sticking-the-landing' IWAE (IWAE-STL) gradient from\nRoeder et al. (2017)) or through an identity from Tucker et al. (2019) (which\nyields the 'doubly-reparametrised' IWAE (IWAE-DREG) gradient). In this work, we\nargue that directly optimising the proposal distribution in importance sampling\nas in the reweighted wake-sleep (RWS) algorithm from Bornschein & Bengio (2015)\nis preferable to optimising IWAE-type multi-sample objectives. To formalise\nthis argument, we introduce an adaptive-importance sampling framework termed\nadaptive importance sampling for learning (AISLE) which slightly generalises\nthe RWS algorithm. We then show that AISLE admits IWAE-STL and IWAE-DREG (i.e.\nthe IWAE-gradients which avoid breakdown) as special cases.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 14:52:12 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 09:46:02 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Finke", "Axel", ""], ["Thiery", "Alexandre H.", ""]]}, {"id": "1907.10480", "submitter": "Evgeny Postnikov", "authors": "Evgeny Postnikov (1), Alexander Kryukov (1), Stanislav Polyakov (1),\n  Dmitry Zhurov (2 and 3) ((1) Lomonosov Moscow State University Skobeltsyn\n  Institute of Nuclear Physics (MSU SINP), Moscow, Russia, (2) Applied Physics\n  Institute of Irkutsk State University (API ISU), Irkutsk, Russia, (3) Irkutsk\n  National Research Technical University, Irkutsk, Russia)", "title": "Deep Learning for Energy Estimation and Particle Identification in\n  Gamma-ray Astronomy", "comments": "10 pages, 6 figures. arXiv admin note: text overlap with\n  arXiv:1812.01551", "journal-ref": "Proc. of the 3rd Int. Workshop DLC-2019, CEUR-WS Proceedings,\n  Vol-2406, pp.90-99", "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques, namely convolutional neural networks (CNN), have\npreviously been adapted to select gamma-ray events in the TAIGA experiment,\nhaving achieved a good quality of selection as compared with the conventional\nHillas approach. Another important task for the TAIGA data analysis was also\nsolved with CNN: gamma-ray energy estimation showed some improvement in\ncomparison with the conventional method based on the Hillas analysis.\nFurthermore, our software was completely redeveloped for the graphics\nprocessing unit (GPU), which led to significantly faster calculations in both\nof these tasks. All the results have been obtained with the simulated data of\nTAIGA Monte Carlo software; their experimental confirmation is envisaged for\nthe near future.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 11:27:56 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Postnikov", "Evgeny", "", "2 and 3"], ["Kryukov", "Alexander", "", "2 and 3"], ["Polyakov", "Stanislav", "", "2 and 3"], ["Zhurov", "Dmitry", "", "2 and 3"]]}, {"id": "1907.10509", "submitter": "Anti Ingel", "authors": "Anti Ingel, Ilya Kuzovkin, Raul Vicente", "title": "Direct information transfer rate optimisation for SSVEP-based BCI", "comments": null, "journal-ref": "Journal of neural engineering, 16(1), 016016 (2018)", "doi": "10.1088/1741-2552/aae8c7", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a classification method for SSVEP-based BCI is proposed. The\nclassification method uses features extracted by traditional SSVEP-based BCI\nmethods and finds optimal discrimination thresholds for each feature to\nclassify the targets. Optimising the thresholds is formalised as a maximisation\ntask of a performance measure of BCIs called information transfer rate (ITR).\nHowever, instead of the standard method of calculating ITR, which makes certain\nassumptions about the data, a more general formula is derived to avoid\nincorrect ITR calculation when the standard assumptions are not met. This\nallows the optimal discrimination thresholds to be automatically calculated and\nthus eliminates the need for manual parameter selection or performing\ncomputationally expensive grid searches. The proposed method shows good\nperformance in classifying targets of a BCI, outperforming previously reported\nresults on the same dataset by a factor of 2 in terms of ITR. The highest\nachieved ITR on the used dataset was 62 bit/min. The proposed method also\nprovides a way to reduce false classifications, which is important in\nreal-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 23:09:51 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Ingel", "Anti", ""], ["Kuzovkin", "Ilya", ""], ["Vicente", "Raul", ""]]}, {"id": "1907.10516", "submitter": "Ganesh Ghalme", "authors": "Vishakha Patil, Ganesh Ghalme, Vineet Nair, Y. Narahari", "title": "Achieving Fairness in the Stochastic Multi-armed Bandit Problem", "comments": "arXiv admin note: substantial text overlap with arXiv:1905.11260", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study an interesting variant of the stochastic multi-armed bandit problem,\ncalled the Fair-SMAB problem, where each arm is required to be pulled for at\nleast a given fraction of the total available rounds. We investigate the\ninterplay between learning and fairness in terms of a pre-specified vector\ndenoting the fractions of guaranteed pulls. We define a fairness-aware regret,\ncalled $r$-Regret, that takes into account the above fairness constraints and\nnaturally extends the conventional notion of regret. Our primary contribution\nis characterizing a class of Fair-SMAB algorithms by two parameters: the\nunfairness tolerance and the learning algorithm used as a black-box. We provide\na fairness guarantee for this class that holds uniformly over time irrespective\nof the choice of the learning algorithm. In particular, when the learning\nalgorithm is UCB1, we show that our algorithm achieves $O(\\ln T)$ $r$-Regret.\nFinally, we evaluate the cost of fairness in terms of the conventional notion\nof regret.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 04:02:56 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 11:13:33 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Patil", "Vishakha", ""], ["Ghalme", "Ganesh", ""], ["Nair", "Vineet", ""], ["Narahari", "Y.", ""]]}, {"id": "1907.10580", "submitter": "Nirbhay Modhe", "authors": "Nirbhay Modhe, Prithvijit Chattopadhyay, Mohit Sharma, Abhishek Das,\n  Devi Parikh, Dhruv Batra, Ramakrishna Vedantam", "title": "IR-VIC: Unsupervised Discovery of Sub-goals for Transfer in RL", "comments": null, "journal-ref": null, "doi": "10.24963/ijcai.2020/280", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel framework to identify sub-goals useful for exploration in\nsequential decision making tasks under partial observability. We utilize the\nvariational intrinsic control framework (Gregor et.al., 2016) which maximizes\nempowerment -- the ability to reliably reach a diverse set of states and show\nhow to identify sub-goals as states with high necessary option information\nthrough an information theoretic regularizer. Despite being discovered without\nexplicit goal supervision, our sub-goals provide better exploration and sample\ncomplexity on challenging grid-world navigation tasks compared to supervised\ncounterparts in prior work.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 17:30:39 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 15:17:00 GMT"}, {"version": "v3", "created": "Tue, 15 Oct 2019 15:59:01 GMT"}, {"version": "v4", "created": "Sat, 4 Jul 2020 20:47:39 GMT"}, {"version": "v5", "created": "Sun, 3 Jan 2021 17:37:08 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Modhe", "Nirbhay", ""], ["Chattopadhyay", "Prithvijit", ""], ["Sharma", "Mohit", ""], ["Das", "Abhishek", ""], ["Parikh", "Devi", ""], ["Batra", "Dhruv", ""], ["Vedantam", "Ramakrishna", ""]]}, {"id": "1907.10592", "submitter": "Cathy Maugis-Rabusseau", "authors": "Yohann de Castro (ECL, ICJ), S\\'ebastien Gadat (TSE), Cl\\'ement\n  Marteau (ICJ), Cathy Maugis (IMT)", "title": "SuperMix: Sparse Regularization for Mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the statistical estimation of a discrete mixing\nmeasure $\\mu$0 involved in a kernel mixture model. Using some recent advances\nin l1-regularization over the space of measures, we introduce a \"data fitting\nand regularization\" convex program for estimating $\\mu$0 in a grid-less manner\nfrom a sample of mixture law, this method is referred to as Beurling-LASSO. Our\ncontribution is twofold: we derive a lower bound on the bandwidth of our data\nfitting term depending only on the support of $\\mu$0 and its so-called \"minimum\nseparation\" to ensure quantitative support localization error bounds; and under\na so-called \"non-degenerate source condition\" we derive a non-asymptotic\nsupport stability property. This latter shows that for a sufficiently large\nsample size n, our estimator has exactly as many weighted Dirac masses as the\ntarget $\\mu$0 , converging in amplitude and localization towards the true ones.\nFinally, we also introduce some tractable algorithms for solving this convex\nprogram based on \"Sliding Frank-Wolfe\" or \"Conic Particle Gradient Descent\".\nStatistical performances of this estimator are investigated designing a\nso-called \"dual certificate\", which is appropriate to our setting. Some\nclassical situations, as e.g. mixtures of super-smooth distributions (e.g.\nGaussian distributions) or ordinary-smooth distributions (e.g. Laplace\ndistributions), are discussed at the end of the paper.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 08:45:57 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2020 19:07:32 GMT"}], "update_date": "2020-06-22", "authors_parsed": [["de Castro", "Yohann", "", "ECL, ICJ"], ["Gadat", "S\u00e9bastien", "", "TSE"], ["Marteau", "Cl\u00e9ment", "", "ICJ"], ["Maugis", "Cathy", "", "IMT"]]}, {"id": "1907.10595", "submitter": "Amirhossein Reisizadeh", "authors": "Amirhossein Reisizadeh, Hossein Taheri, Aryan Mokhtari, Hamed Hassani,\n  Ramtin Pedarsani", "title": "Robust and Communication-Efficient Collaborative Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a decentralized learning problem, where a set of computing nodes\naim at solving a non-convex optimization problem collaboratively. It is\nwell-known that decentralized optimization schemes face two major system\nbottlenecks: stragglers' delay and communication overhead. In this paper, we\ntackle these bottlenecks by proposing a novel decentralized and gradient-based\noptimization algorithm named as QuanTimed-DSGD. Our algorithm stands on two\nmain ideas: (i) we impose a deadline on the local gradient computations of each\nnode at each iteration of the algorithm, and (ii) the nodes exchange quantized\nversions of their local models. The first idea robustifies to straggling nodes\nand the second alleviates communication efficiency. The key technical\ncontribution of our work is to prove that with non-vanishing noises for\nquantization and stochastic gradients, the proposed method exactly converges to\nthe global optimal for convex loss functions, and finds a first-order\nstationary point in non-convex scenarios. Our numerical evaluations of the\nQuanTimed-DSGD on training benchmark datasets, MNIST and CIFAR-10, demonstrate\nspeedups of up to 3x in run-time, compared to state-of-the-art decentralized\noptimization methods.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 17:55:44 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 21:53:56 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Reisizadeh", "Amirhossein", ""], ["Taheri", "Hossein", ""], ["Mokhtari", "Aryan", ""], ["Hassani", "Hamed", ""], ["Pedarsani", "Ramtin", ""]]}, {"id": "1907.10599", "submitter": "Greg Yang", "authors": "Greg Yang and Hadi Salman", "title": "A Fine-Grained Spectral Perspective on Neural Networks", "comments": "8 pages of main text, 19 figures, 51 pages including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Are neural networks biased toward simple functions? Does depth always help\nlearn more complex features? Is training the last layer of a network as good as\ntraining all layers? How to set the range for learning rate tuning? These\nquestions seem unrelated at face value, but in this work we give all of them a\ncommon treatment from the spectral perspective. We will study the spectra of\nthe *Conjugate Kernel, CK,* (also called the *Neural Network-Gaussian Process\nKernel*), and the *Neural Tangent Kernel, NTK*. Roughly, the CK and the NTK\ntell us respectively \"what a network looks like at initialization\" and \"what a\nnetwork looks like during and after training.\" Their spectra then encode\nvaluable information about the initial distribution and the training and\ngeneralization properties of neural networks. By analyzing the eigenvalues, we\nlend novel insights into the questions put forth at the beginning, and we\nverify these insights by extensive experiments of neural networks. We derive\nfast algorithms for computing the spectra of CK and NTK when the data is\nuniformly distributed over the boolean cube, and show this spectra is the same\nin high dimensions when data is drawn from isotropic Gaussian or uniformly over\nthe sphere. Code replicating our results is available at\ngithub.com/thegregyang/NNspectra.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 17:58:45 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 23:05:20 GMT"}, {"version": "v3", "created": "Sat, 4 Apr 2020 21:12:24 GMT"}, {"version": "v4", "created": "Thu, 9 Apr 2020 15:12:11 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Yang", "Greg", ""], ["Salman", "Hadi", ""]]}, {"id": "1907.10621", "submitter": "Johann Brehmer Mr", "authors": "Johann Brehmer, Felix Kling, Irina Espejo, Kyle Cranmer", "title": "MadMiner: Machine learning-based inference for particle physics", "comments": "MadMiner is available at https://github.com/diana-hep/madminer . v2:\n  improved text, fixed typos, better colors, added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph hep-ex physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision measurements at the LHC often require analyzing high-dimensional\nevent data for subtle kinematic signatures, which is challenging for\nestablished analysis methods. Recently, a powerful family of multivariate\ninference techniques that leverage both matrix element information and machine\nlearning has been developed. This approach neither requires the reduction of\nhigh-dimensional data to summary statistics nor any simplifications to the\nunderlying physics or detector response. In this paper we introduce MadMiner, a\nPython module that streamlines the steps involved in this procedure. Wrapping\naround MadGraph5_aMC and Pythia 8, it supports almost any physics process and\nmodel. To aid phenomenological studies, the tool also wraps around Delphes 3,\nthough it is extendable to a full Geant4-based detector simulation. We\ndemonstrate the use of MadMiner in an example analysis of dimension-six\noperators in ttH production, finding that the new techniques substantially\nincrease the sensitivity to new physics.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 18:00:02 GMT"}, {"version": "v2", "created": "Mon, 20 Jan 2020 16:25:39 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Brehmer", "Johann", ""], ["Kling", "Felix", ""], ["Espejo", "Irina", ""], ["Cranmer", "Kyle", ""]]}, {"id": "1907.10628", "submitter": "Vinod Kumar Kurmi", "authors": "Vinod Kumar Kurmi, Vipul Bajaj, Venkatesh K Subramanian, Vinay P\n  Namboodiri", "title": "Curriculum based Dropout Discriminator for Domain Adaptation", "comments": "BMVC 2019 Accepted, Project Page:\n  https://delta-lab-iitk.github.io/CD3A/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation is essential to enable wide usage of deep learning based\nnetworks trained using large labeled datasets. Adversarial learning based\ntechniques have shown their utility towards solving this problem using a\ndiscriminator that ensures source and target distributions are close. However,\nhere we suggest that rather than using a point estimate, it would be useful if\na distribution based discriminator could be used to bridge this gap. This could\nbe achieved using multiple classifiers or using traditional ensemble methods.\nIn contrast, we suggest that a Monte Carlo dropout based ensemble discriminator\ncould suffice to obtain the distribution based discriminator. Specifically, we\npropose a curriculum based dropout discriminator that gradually increases the\nvariance of the sample based distribution and the corresponding reverse\ngradients are used to align the source and target feature representations. The\ndetailed results and thorough ablation analysis show that our model outperforms\nstate-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 18:00:12 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 19:43:26 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Kurmi", "Vinod Kumar", ""], ["Bajaj", "Vipul", ""], ["Subramanian", "Venkatesh K", ""], ["Namboodiri", "Vinay P", ""]]}, {"id": "1907.10662", "submitter": "Xuankang Lin", "authors": "Xuankang Lin, He Zhu, Roopsha Samanta, Suresh Jagannathan", "title": "ART: Abstraction Refinement-Guided Training for Provably Correct Neural\n  Networks", "comments": "FMCAD'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL cs.SC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Artificial Neural Networks (ANNs) have demonstrated remarkable utility in\nvarious challenging machine learning applications. While formally verified\nproperties of their behaviors are highly desired, they have proven notoriously\ndifficult to derive and enforce. Existing approaches typically formulate this\nproblem as a post facto analysis process. In this paper, we present a novel\nlearning framework that ensures such formal guarantees are enforced by\nconstruction. Our technique enables training provably correct networks with\nrespect to a broad class of safety properties, a capability that goes\nwell-beyond existing approaches, without compromising much accuracy. Our key\ninsight is that we can integrate an optimization-based abstraction refinement\nloop into the learning process and operate over dynamically constructed\npartitions of the input space that considers accuracy and safety objectives\nsynergistically. The refinement procedure iteratively splits the input space\nfrom which training data is drawn, guided by the efficacy with which such\npartitions enable safety verification. We have implemented our approach in a\ntool (ART) and applied it to enforce general safety properties on unmanned\naviator collision avoidance system ACAS Xu dataset and the Collision Detection\ndataset. Importantly, we empirically demonstrate that realizing safety does not\ncome at the price of much accuracy. Our methodology demonstrates that an\nabstraction refinement methodology provides a meaningful pathway for building\nboth accurate and correct machine learning networks.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 16:58:33 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 02:42:17 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 21:49:51 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Lin", "Xuankang", ""], ["Zhu", "He", ""], ["Samanta", "Roopsha", ""], ["Jagannathan", "Suresh", ""]]}, {"id": "1907.10697", "submitter": "Kari Torkkola", "authors": "Ruofeng Wen, Kari Torkkola", "title": "Deep Generative Quantile-Copula Models for Probabilistic Forecasting", "comments": "Published at the 36th International Conference on Machine Learning\n  (ICML2019), Time Series Workshop, Long Beach, California, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new category of multivariate conditional generative models and\ndemonstrate its performance and versatility in probabilistic time series\nforecasting and simulation. Specifically, the output of quantile regression\nnetworks is expanded from a set of fixed quantiles to the whole Quantile\nFunction by a univariate mapping from a latent uniform distribution to the\ntarget distribution. Then the multivariate case is solved by learning such\nquantile functions for each dimension's marginal distribution, followed by\nestimating a conditional Copula to associate these latent uniform random\nvariables. The quantile functions and copula, together defining the joint\npredictive distribution, can be parameterized by a single implicit generative\nDeep Neural Network.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 20:11:41 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Wen", "Ruofeng", ""], ["Torkkola", "Kari", ""]]}, {"id": "1907.10701", "submitter": "Yu Emma Wang", "authors": "Yu Emma Wang, Gu-Yeon Wei, David Brooks", "title": "Benchmarking TPU, GPU, and CPU Platforms for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Training deep learning models is compute-intensive and there is an\nindustry-wide trend towards hardware specialization to improve performance. To\nsystematically benchmark deep learning platforms, we introduce ParaDnn, a\nparameterized benchmark suite for deep learning that generates end-to-end\nmodels for fully connected (FC), convolutional (CNN), and recurrent (RNN)\nneural networks. Along with six real-world models, we benchmark Google's Cloud\nTPU v2/v3, NVIDIA's V100 GPU, and an Intel Skylake CPU platform. We take a deep\ndive into TPU architecture, reveal its bottlenecks, and highlight valuable\nlessons learned for future specialized system design. We also provide a\nthorough comparison of the platforms and find that each has unique strengths\nfor some types of models. Finally, we quantify the rapid performance\nimprovements that specialized software stacks provide for the TPU and GPU\nplatforms.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 20:18:28 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 20:27:59 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 21:30:47 GMT"}, {"version": "v4", "created": "Tue, 22 Oct 2019 06:07:55 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Wang", "Yu Emma", ""], ["Wei", "Gu-Yeon", ""], ["Brooks", "David", ""]]}, {"id": "1907.10709", "submitter": "Giulio Siracusano Dr.", "authors": "Giulio Siracusano, Aurelio La Corte, Riccardo Tomasello, Francesco\n  Lamonaca, Carmelo Scuro, Francesca Garesc\\`i, Mario Carpentieri and Giovanni\n  Finocchio", "title": "Automatic crack detection and classification by exploiting statistical\n  event descriptors for Deep Learning", "comments": "34 pages, 2 tables, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern building infrastructures, the chance to devise adaptive and\nunsupervised data-driven health monitoring systems is gaining in popularity due\nto the large availability of data from low-cost sensors with internetworking\ncapabilities. In particular, deep learning provides the tools for processing\nand analyzing this unprecedented amount of data efficiently. The main purpose\nof this paper is to combine the recent advances of Deep Learning (DL) and\nstatistical analysis on structural health monitoring (SHM) to develop an\naccurate classification tool able to discriminate among different acoustic\nemission events (cracks) by means of the identification of tensile, shear and\nmixed modes. The applications of DL in SHM systems is described by using the\nconcept of Bidirectional Long Short Term Memory. We investigated on effective\nevent descriptors to capture the unique characteristics from the different\ntypes of modes. Among them, Spectral Kurtosis and Spectral L2/L1 Norm exhibit\ndistinctive behavior and effectively contributed to the learning process. This\nclassification will contribute to unambiguously detect incipient damages, which\nis advantageous to realize predictive maintenance. Tests on experimental\nresults confirm that this method achieves accurate classification (92%)\ncapabilities of crack events and can impact on the design of future SHM\ntechnologies.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 20:39:49 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Siracusano", "Giulio", ""], ["La Corte", "Aurelio", ""], ["Tomasello", "Riccardo", ""], ["Lamonaca", "Francesco", ""], ["Scuro", "Carmelo", ""], ["Garesc\u00ec", "Francesca", ""], ["Carpentieri", "Mario", ""], ["Finocchio", "Giovanni", ""]]}, {"id": "1907.10732", "submitter": "Xinyan Li", "authors": "Xinyan Li, Qilong Gu, Yingxue Zhou, Tiancong Chen, and Arindam\n  Banerjee", "title": "Hessian based analysis of SGD for Deep Nets: Dynamics and Generalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While stochastic gradient descent (SGD) and variants have been surprisingly\nsuccessful for training deep nets, several aspects of the optimization dynamics\nand generalization are still not well understood. In this paper, we present new\nempirical observations and theoretical results on both the optimization\ndynamics and generalization behavior of SGD for deep nets based on the Hessian\nof the training loss and associated quantities. We consider three specific\nresearch questions: (1) what is the relationship between the Hessian of the\nloss and the second moment of stochastic gradients (SGs)? (2) how can we\ncharacterize the stochastic optimization dynamics of SGD with fixed and\nadaptive step sizes and diagonal pre-conditioning based on the first and second\nmoments of SGs? and (3) how can we characterize a scale-invariant\ngeneralization bound of deep nets based on the Hessian of the loss, which by\nitself is not scale invariant? We shed light on these three questions using\ntheoretical results supported by extensive empirical observations, with\nexperiments on synthetic data, MNIST, and CIFAR-10, with different batch sizes,\nand with different difficulty levels by synthetically adding random labels.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 21:27:13 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Li", "Xinyan", ""], ["Gu", "Qilong", ""], ["Zhou", "Yingxue", ""], ["Chen", "Tiancong", ""], ["Banerjee", "Arindam", ""]]}, {"id": "1907.10747", "submitter": "Ankit Singh Rawat", "authors": "Ankit Singh Rawat, Jiecao Chen, Felix Yu, Ananda Theertha Suresh,\n  Sanjiv Kumar", "title": "Sampled Softmax with Random Fourier Features", "comments": "In NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational cost of training with softmax cross entropy loss grows\nlinearly with the number of classes. For the settings where a large number of\nclasses are involved, a common method to speed up training is to sample a\nsubset of classes and utilize an estimate of the loss gradient based on these\nclasses, known as the sampled softmax method. However, the sampled softmax\nprovides a biased estimate of the gradient unless the samples are drawn from\nthe exact softmax distribution, which is again expensive to compute. Therefore,\na widely employed practical approach involves sampling from a simpler\ndistribution in the hope of approximating the exact softmax distribution. In\nthis paper, we develop the first theoretical understanding of the role that\ndifferent sampling distributions play in determining the quality of sampled\nsoftmax. Motivated by our analysis and the work on kernel-based sampling, we\npropose the Random Fourier Softmax (RF-softmax) method that utilizes the\npowerful Random Fourier Features to enable more efficient and accurate sampling\nfrom an approximate softmax distribution. We show that RF-softmax leads to low\nbias in estimation in terms of both the full softmax distribution and the full\nsoftmax gradient. Furthermore, the cost of RF-softmax scales only\nlogarithmically with the number of classes.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 22:04:42 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2019 16:59:14 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Rawat", "Ankit Singh", ""], ["Chen", "Jiecao", ""], ["Yu", "Felix", ""], ["Suresh", "Ananda Theertha", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1907.10772", "submitter": "Jorge Gustavo Madrid Perez", "authors": "Jorge G. Madrid, Hugo Jair Escalante, Eduardo F. Morales, Wei-Wei Tu,\n  Yang Yu, Lisheng Sun-Hosoya, Isabelle Guyon, Michele Sebag", "title": "Towards AutoML in the presence of Drift: first results", "comments": "AutoML 2018 @ ICML/IJCAI-ECAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research progress in AutoML has lead to state of the art solutions that can\ncope quite wellwith supervised learning task, e.g., classification with\nAutoSklearn. However, so far thesesystems do not take into account the changing\nnature of evolving data over time (i.e., theystill assume i.i.d. data); even\nwhen this sort of domains are increasingly available in realapplications (e.g.,\nspam filtering, user preferences, etc.). We describe a first attempt to\nde-velop an AutoML solution for scenarios in which data distribution changes\nrelatively slowlyover time and in which the problem is approached in a lifelong\nlearning setting. We extendAuto-Sklearn with sound and intuitive mechanisms\nthat allow it to cope with this sort ofproblems. The extended Auto-Sklearn is\ncombined with concept drift detection techniquesthat allow it to automatically\ndetermine when the initial models have to be adapted. Wereport experimental\nresults in benchmark data from AutoML competitions that adhere tothis scenario.\nResults demonstrate the effectiveness of the proposed methodology.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 23:28:37 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Madrid", "Jorge G.", ""], ["Escalante", "Hugo Jair", ""], ["Morales", "Eduardo F.", ""], ["Tu", "Wei-Wei", ""], ["Yu", "Yang", ""], ["Sun-Hosoya", "Lisheng", ""], ["Guyon", "Isabelle", ""], ["Sebag", "Michele", ""]]}, {"id": "1907.10794", "submitter": "Byunghyun Ban", "authors": "Byunghyun Ban, Donghun Ryu, Minwoo Lee", "title": "Machine learning approach to remove ion interference effect in\n  agricultural nutrient solutions", "comments": "6 pages, 5 figures, 5 tables. Accepted to 2019 International\n  Conference on Information and Communication Technology Convergence (ICTC) -\n  ICTC2019", "journal-ref": "2019 International Conference on Information and Communication\n  Technology Convergence (ICTC)", "doi": "10.1109/ICTC46691.2019.8939812", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High concentration agricultural facilities such as vertical farms or plant\nfactories consider hydroponic techniques as optimal solutions. Although\nclosed-system dramatically reduces water consumption and pollution issues, it\nhas ion-ratio related problem. As the root absorbs individual ions with\ndifferent rate, ion rate in a nutrient solution should be adjusted\nperiodically. But traditional method only considers pH and electrical\nconductivity to adjust the nutrient solution, leading to ion imbalance and\naccumulation of excessive salts. To avoid those problems, some researchers have\nproposed ion-balancing methods which measure and control each ion\nconcentration. However, those approaches do not overcome the innate limitations\nof ISEs, especially ion interference effect. An anion sensor is affected by\nother anions, and the error grows larger in higher concentration solution. A\nmachine learning approach to modify ISE data distorted by ion interference\neffect is proposed in this paper. As measurement of TDS value is relatively\nrobust than any other signals, we applied TDS as key parameter to build a\nreadjustment function to remove the artifact. Once a readjustment model is\nestablished, application on ISE data can be done in real time. Readjusted data\nwith proposed model showed about 91.6 ~ 98.3% accuracies. This method will\nenable the fields to apply recent methods in feasible status.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 01:50:29 GMT"}, {"version": "v2", "created": "Fri, 26 Jul 2019 02:57:41 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 05:51:17 GMT"}, {"version": "v4", "created": "Tue, 3 Sep 2019 00:36:21 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Ban", "Byunghyun", ""], ["Ryu", "Donghun", ""], ["Lee", "Minwoo", ""]]}, {"id": "1907.10823", "submitter": "Qian Huang", "authors": "Qian Huang, Isay Katsman, Horace He, Zeqi Gu, Serge Belongie, Ser-Nam\n  Lim", "title": "Enhancing Adversarial Example Transferability with an Intermediate Level\n  Attack", "comments": "ICCV 2019 camera-ready. Imagenet results are updated after fixing the\n  normalization. arXiv admin note: text overlap with arXiv:1811.08458", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are vulnerable to adversarial examples, malicious inputs\ncrafted to fool trained models. Adversarial examples often exhibit black-box\ntransfer, meaning that adversarial examples for one model can fool another\nmodel. However, adversarial examples are typically overfit to exploit the\nparticular architecture and feature representation of a source model, resulting\nin sub-optimal black-box transfer attacks to other target models. We introduce\nthe Intermediate Level Attack (ILA), which attempts to fine-tune an existing\nadversarial example for greater black-box transferability by increasing its\nperturbation on a pre-specified layer of the source model, improving upon\nstate-of-the-art methods. We show that we can select a layer of the source\nmodel to perturb without any knowledge of the target models while achieving\nhigh transferability. Additionally, we provide some explanatory insights\nregarding our method and the effect of optimizing for adversarial examples\nusing intermediate feature maps. Our code is available at\nhttps://github.com/CUVL/Intermediate-Level-Attack.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 23:37:15 GMT"}, {"version": "v2", "created": "Sun, 6 Oct 2019 00:45:51 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 22:43:49 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Huang", "Qian", ""], ["Katsman", "Isay", ""], ["He", "Horace", ""], ["Gu", "Zeqi", ""], ["Belongie", "Serge", ""], ["Lim", "Ser-Nam", ""]]}, {"id": "1907.10827", "submitter": "Pablo Hernandez-Leal", "authors": "Bilal Kartal, Pablo Hernandez-Leal and Matthew E. Taylor", "title": "Terminal Prediction as an Auxiliary Task for Deep Reinforcement Learning", "comments": "AAAI Conference on Artificial Intelligence and Interactive Digital\n  Entertainment (AIIDE'19). arXiv admin note: text overlap with\n  arXiv:1812.00045", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has achieved great successes in recent years, but\nthere are still open challenges, such as convergence to locally optimal\npolicies and sample inefficiency. In this paper, we contribute a novel\nself-supervised auxiliary task, i.e., Terminal Prediction (TP), estimating\ntemporal closeness to terminal states for episodic tasks. The intuition is to\nhelp representation learning by letting the agent predict how close it is to a\nterminal state, while learning its control policy. Although TP could be\nintegrated with multiple algorithms, this paper focuses on Asynchronous\nAdvantage Actor-Critic (A3C) and demonstrating the advantages of A3C-TP. Our\nextensive evaluation includes: a set of Atari games, the BipedalWalker domain,\nand a mini version of the recently proposed multi-agent Pommerman game. Our\nresults on Atari games and the BipedalWalker domain suggest that A3C-TP\noutperforms standard A3C in most of the tested domains and in others it has\nsimilar performance. In Pommerman, our proposed method provides significant\nimprovement both in learning efficiency and converging to better policies\nagainst different opponents.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 16:26:21 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Kartal", "Bilal", ""], ["Hernandez-Leal", "Pablo", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1907.10834", "submitter": "Chang Min Hyun", "authors": "Chang Min Hyun, Kang Cheol Kim, Hyun Cheol Cho, Jae Kyu Choi and Jin\n  Keun Seo", "title": "Framelet Pooling Aided Deep Learning Network : The Method to Process\n  High Dimensional Medical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA eess.IV math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning-based analysis of medical images often faces several\nhurdles, such as the lack of training data, the curse of dimensionality\nproblem, and the generalization issues. One of the main difficulties is that\nthere exists computational cost problem in dealing with input data of large\nsize matrices which represent medical images. The purpose of this paper is to\nintroduce a framelet-pooling aided deep learning method for mitigating\ncomputational bundle, caused by large dimensionality. By transforming high\ndimensional data into low dimensional components by filter banks with\npreserving detailed information, the proposed method aims to reduce the\ncomplexity of the neural network and computational costs significantly during\nthe learning process. Various experiments show that our method is comparable to\nthe standard unreduced learning method, while reducing computational burdens by\ndecomposing large-sized learning tasks into several small-scale learning tasks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 04:40:16 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Hyun", "Chang Min", ""], ["Kim", "Kang Cheol", ""], ["Cho", "Hyun Cheol", ""], ["Choi", "Jae Kyu", ""], ["Seo", "Jin Keun", ""]]}, {"id": "1907.10892", "submitter": "Ahmed Nassar", "authors": "Ahmed Samy Nassar, Sebastien Lefevre, Jan D. Wegner", "title": "Simultaneous multi-view instance detection with learned geometric\n  soft-constraints", "comments": "Internationcal Conference on Computer Vision 2019 (ICCV 19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose to jointly learn multi-view geometry and warping between views of\nthe same object instances for robust cross-view object detection. What makes\nmulti-view object instance detection difficult are strong changes in viewpoint,\nlighting conditions, high similarity of neighbouring objects, and strong\nvariability in scale. By turning object detection and instance\nre-identification in different views into a joint learning task, we are able to\nincorporate both image appearance and geometric soft constraints into a single,\nmulti-view detection process that is learnable end-to-end. We validate our\nmethod on a new, large data set of street-level panoramas of urban objects and\nshow superior performance compared to various baselines. Our contribution is\nthreefold: a large-scale, publicly available data set for multi-view instance\ndetection and re-identification; an annotation tool custom-tailored for\nmulti-view instance detection; and a novel, holistic multi-view instance\ndetection and re-identification method that jointly models geometry and\nappearance across views.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 08:11:22 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Nassar", "Ahmed Samy", ""], ["Lefevre", "Sebastien", ""], ["Wegner", "Jan D.", ""]]}, {"id": "1907.10900", "submitter": "Yoshikazu Terada", "authors": "Yoshikazu Terada and Ryoma Hirose", "title": "Fast generalization error bound of deep learning without scale\n  invariance of activation functions", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In theoretical analysis of deep learning, discovering which features of deep\nlearning lead to good performance is an important task. In this paper, using\nthe framework for analyzing the generalization error developed in Suzuki\n(2018), we derive a fast learning rate for deep neural networks with more\ngeneral activation functions. In Suzuki (2018), assuming the scale invariance\nof activation functions, the tight generalization error bound of deep learning\nwas derived. They mention that the scale invariance of the activation function\nis essential to derive tight error bounds. Whereas the rectified linear unit\n(ReLU; Nair and Hinton, 2010) satisfies the scale invariance, the other famous\nactivation functions including the sigmoid and the hyperbolic tangent\nfunctions, and the exponential linear unit (ELU; Clevert et al., 2016) does not\nsatisfy this condition. The existing analysis indicates a possibility that a\ndeep learning with the non scale invariant activations may have a slower\nconvergence rate of $O(1/\\sqrt{n})$ when one with the scale invariant\nactivations can reach a rate faster than $O(1/\\sqrt{n})$. In this paper,\nwithout the scale invariance of activation functions, we derive the tight\ngeneralization error bound which is essentially the same as that of Suzuki\n(2018). From this result, at least in the framework of Suzuki (2018), it is\nshown that the scale invariance of the activation functions is not essential to\nget the fast rate of convergence. Simultaneously, it is also shown that the\ntheoretical framework proposed by Suzuki (2018) can be widely applied for\nanalysis of deep learning with general activation functions.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 08:41:39 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Terada", "Yoshikazu", ""], ["Hirose", "Ryoma", ""]]}, {"id": "1907.10902", "submitter": "Toshihiko Yanase", "authors": "Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta and Masanori\n  Koyama", "title": "Optuna: A Next-generation Hyperparameter Optimization Framework", "comments": "10 pages, Accepted at KDD 2019 Applied Data Science track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this study is to introduce new design-criteria for\nnext-generation hyperparameter optimization software. The criteria we propose\ninclude (1) define-by-run API that allows users to construct the parameter\nsearch space dynamically, (2) efficient implementation of both searching and\npruning strategies, and (3) easy-to-setup, versatile architecture that can be\ndeployed for various purposes, ranging from scalable distributed computing to\nlight-weight experiment conducted via interactive interface. In order to prove\nour point, we will introduce Optuna, an optimization software which is a\nculmination of our effort in the development of a next generation optimization\nsoftware. As an optimization software designed with define-by-run principle,\nOptuna is particularly the first of its kind. We will present the\ndesign-techniques that became necessary in the development of the software that\nmeets the above criteria, and demonstrate the power of our new design through\nexperimental results and real world applications. Our software is available\nunder the MIT license (https://github.com/pfnet/optuna/).\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 08:55:22 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Akiba", "Takuya", ""], ["Sano", "Shotaro", ""], ["Yanase", "Toshihiko", ""], ["Ohta", "Takeru", ""], ["Koyama", "Masanori", ""]]}, {"id": "1907.10903", "submitter": "Wenbing Huang", "authors": "Yu Rong, Wenbing Huang, Tingyang Xu, Junzhou Huang", "title": "DropEdge: Towards Deep Graph Convolutional Networks on Node\n  Classification", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\emph{Over-fitting} and \\emph{over-smoothing} are two main obstacles of\ndeveloping deep Graph Convolutional Networks (GCNs) for node classification. In\nparticular, over-fitting weakens the generalization ability on small dataset,\nwhile over-smoothing impedes model training by isolating output representations\nfrom the input features with the increase in network depth. This paper proposes\nDropEdge, a novel and flexible technique to alleviate both issues. At its core,\nDropEdge randomly removes a certain number of edges from the input graph at\neach training epoch, acting like a data augmenter and also a message passing\nreducer. Furthermore, we theoretically demonstrate that DropEdge either reduces\nthe convergence speed of over-smoothing or relieves the information loss caused\nby it. More importantly, our DropEdge is a general skill that can be equipped\nwith many other backbone models (e.g. GCN, ResGCN, GraphSAGE, and JKNet) for\nenhanced performance. Extensive experiments on several benchmarks verify that\nDropEdge consistently improves the performance on a variety of both shallow and\ndeep GCNs. The effect of DropEdge on preventing over-smoothing is empirically\nvisualized and validated as well. Codes are released\non~\\url{https://github.com/DropEdge/DropEdge}.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 08:57:45 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 09:08:42 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 14:02:35 GMT"}, {"version": "v4", "created": "Thu, 12 Mar 2020 08:04:36 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Rong", "Yu", ""], ["Huang", "Wenbing", ""], ["Xu", "Tingyang", ""], ["Huang", "Junzhou", ""]]}, {"id": "1907.10905", "submitter": "Shuxiao Chen", "authors": "Shuxiao Chen, Edgar Dobriban, Jane H Lee", "title": "A Group-Theoretic Framework for Data Augmentation", "comments": "To appear in Journal of Machine Learning Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is a widely used trick when training deep neural networks:\nin addition to the original data, properly transformed data are also added to\nthe training set. However, to the best of our knowledge, a clear mathematical\nframework to explain the performance benefits of data augmentation is not\navailable. In this paper, we develop such a theoretical framework. We show data\naugmentation is equivalent to an averaging operation over the orbits of a\ncertain group that keeps the data distribution approximately invariant. We\nprove that it leads to variance reduction. We study empirical risk\nminimization, and the examples of exponential families, linear regression, and\ncertain two-layer neural networks. We also discuss how data augmentation could\nbe used in problems with symmetry where other approaches are prevalent, such as\nin cryo-electron microscopy (cryo-EM).\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 08:58:59 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 19:29:42 GMT"}, {"version": "v3", "created": "Fri, 21 Feb 2020 20:50:50 GMT"}, {"version": "v4", "created": "Fri, 6 Nov 2020 19:48:43 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chen", "Shuxiao", ""], ["Dobriban", "Edgar", ""], ["Lee", "Jane H", ""]]}, {"id": "1907.10906", "submitter": "Yuantao Gu", "authors": "Gen Li and Yuantao Gu", "title": "Theory of Spectral Method for Union of Subspaces-Based Random Geometry\n  Graph", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral Method is a commonly used scheme to cluster data points lying close\nto Union of Subspaces by first constructing a Random Geometry Graph, called\nSubspace Clustering. This paper establishes a theory to analyze this method.\nBased on this theory, we demonstrate the efficiency of Subspace Clustering in\nfairly broad conditions. The insights and analysis techniques developed in this\npaper might also have implications for other random graph problems. Numerical\nexperiments demonstrate the effectiveness of our theoretical study.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 09:02:10 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Li", "Gen", ""], ["Gu", "Yuantao", ""]]}, {"id": "1907.10940", "submitter": "Ziwen An", "authors": "Ziwen An, Leah F South and Christopher Drovandi", "title": "BSL: An R Package for Efficient Parameter Estimation for\n  Simulation-Based Models via Bayesian Synthetic Likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian synthetic likelihood (BSL) is a popular method for estimating the\nparameter posterior distribution for complex statistical models and stochastic\nprocesses that possess a computationally intractable likelihood function.\nInstead of evaluating the likelihood, BSL approximates the likelihood of a\njudiciously chosen summary statistic of the data via model simulation and\ndensity estimation. Compared to alternative methods such as approximate\nBayesian computation (ABC), BSL requires little tuning and requires less model\nsimulations than ABC when the chosen summary statistic is high-dimensional. The\noriginal synthetic likelihood relies on a multivariate normal approximation of\nthe intractable likelihood, where the mean and covariance are estimated by\nsimulation. An extension of BSL considers replacing the sample covariance with\na penalised covariance estimator to reduce the number of required model\nsimulations. Further, a semi-parametric approach has been developed to relax\nthe normality assumption. In this paper, we present an R package called BSL\nthat amalgamates the aforementioned methods and more into a single, easy-to-use\nand coherent piece of software. The R package also includes several examples to\nillustrate how to use the package and demonstrate the utility of the methods.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 10:06:08 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["An", "Ziwen", ""], ["South", "Leah F", ""], ["Drovandi", "Christopher", ""]]}, {"id": "1907.10953", "submitter": "Andrew Cropper", "authors": "Andrew Cropper and Rolf Morel and Stephen H. Muggleton", "title": "Learning higher-order logic programs", "comments": "Submitted to the MLJ", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key feature of inductive logic programming (ILP) is its ability to learn\nfirst-order programs, which are intrinsically more expressive than\npropositional programs. In this paper, we introduce techniques to learn\nhigher-order programs. Specifically, we extend meta-interpretive learning (MIL)\nto support learning higher-order programs by allowing for \\emph{higher-order\ndefinitions} to be used as background knowledge. Our theoretical results show\nthat learning higher-order programs, rather than first-order programs, can\nreduce the textual complexity required to express programs which in turn\nreduces the size of the hypothesis space and sample complexity. We implement\nour idea in two new MIL systems: the Prolog system \\namea{} and the ASP system\n\\nameb{}. Both systems support learning higher-order programs and higher-order\npredicate invention, such as inventing functions for \\tw{map/3} and conditions\nfor \\tw{filter/3}. We conduct experiments on four domains (robot strategies,\nchess playing, list transformations, and string decryption) that compare\nlearning first-order and higher-order programs. Our experimental results\nsupport our theoretical claims and show that, compared to learning first-order\nprograms, learning higher-order programs can significantly improve predictive\naccuracies and reduce learning times.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 10:36:01 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Cropper", "Andrew", ""], ["Morel", "Rolf", ""], ["Muggleton", "Stephen H.", ""]]}, {"id": "1907.10982", "submitter": "Zeju Li", "authors": "Zeju Li and Konstantinos Kamnitsas and Ben Glocker", "title": "Overfitting of neural nets under class imbalance: Analysis and\n  improvements for segmentation", "comments": "Accepted at MICCAI 2019; typo corrected in Table 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overfitting in deep learning has been the focus of a number of recent works,\nyet its exact impact on the behavior of neural networks is not well understood.\nThis study analyzes overfitting by examining how the distribution of logits\nalters in relation to how much the model overfits. Specifically, we find that\nwhen training with few data samples, the distribution of logit activations when\nprocessing unseen test samples of an under-represented class tends to shift\ntowards and even across the decision boundary, while the over-represented class\nseems unaffected. In image segmentation, foreground samples are often heavily\nunder-represented. We observe that sensitivity of the model drops as a result\nof overfitting, while precision remains mostly stable. Based on our analysis,\nwe derive asymmetric modifications of existing loss functions and regularizers\nincluding a large margin loss, focal loss, adversarial training and mixup,\nwhich specifically aim at reducing the shift observed when embedding unseen\nsamples of the under-represented class. We study the case of binary\nsegmentation of brain tumor core and show that our proposed simple\nmodifications lead to significantly improved segmentation performance over the\nsymmetric variants.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 11:47:12 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 13:22:58 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Li", "Zeju", ""], ["Kamnitsas", "Konstantinos", ""], ["Glocker", "Ben", ""]]}, {"id": "1907.10994", "submitter": "Maria H\\\"ugle", "authors": "Maria H\\\"ugle, Gabriel Kalweit, Branka Mirchevska, Moritz Werling,\n  Joschka Boedecker", "title": "Dynamic Input for Deep Reinforcement Learning in Autonomous Driving", "comments": "Accepted at IROS 2019", "journal-ref": null, "doi": "10.1109/IROS40897.2019.8968560", "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world decision making problems, reaching an optimal decision\nrequires taking into account a variable number of objects around the agent.\nAutonomous driving is a domain in which this is especially relevant, since the\nnumber of cars surrounding the agent varies considerably over time and affects\nthe optimal action to be taken. Classical methods that process object lists can\ndeal with this requirement. However, to take advantage of recent\nhigh-performing methods based on deep reinforcement learning in modular\npipelines, special architectures are necessary. For these, a number of options\nexist, but a thorough comparison of the different possibilities is missing. In\nthis paper, we elaborate limitations of fully-connected neural networks and\nother established approaches like convolutional and recurrent neural networks\nin the context of reinforcement learning problems that have to deal with\nvariable sized inputs. We employ the structure of Deep Sets in off-policy\nreinforcement learning for high-level decision making, highlight their\ncapabilities to alleviate these limitations, and show that Deep Sets not only\nyield the best overall performance but also offer better generalization to\nunseen situations than the other approaches.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 12:08:28 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["H\u00fcgle", "Maria", ""], ["Kalweit", "Gabriel", ""], ["Mirchevska", "Branka", ""], ["Werling", "Moritz", ""], ["Boedecker", "Joschka", ""]]}, {"id": "1907.11025", "submitter": "Patrick Wenzel", "authors": "Qadeer Khan, Patrick Wenzel, Daniel Cremers, Laura Leal-Taix\\'e", "title": "Towards Generalizing Sensorimotor Control Across Weather Conditions", "comments": "Accepted for publication in 2019 IEEE/RSJ International Conference on\n  Intelligent Robots and Systems (IROS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of deep learning models to generalize well across different\nscenarios depends primarily on the quality and quantity of annotated data.\nLabeling large amounts of data for all possible scenarios that a model may\nencounter would not be feasible; if even possible. We propose a framework to\ndeal with limited labeled training data and demonstrate it on the application\nof vision-based vehicle control. We show how limited steering angle data\navailable for only one condition can be transferred to multiple different\nweather scenarios. This is done by leveraging unlabeled images in a\nteacher-student learning paradigm complemented with an image-to-image\ntranslation network. The translation network transfers the images to a new\ndomain, whereas the teacher provides soft supervised targets to train the\nstudent on this domain. Furthermore, we demonstrate how utilization of\nauxiliary networks can reduce the size of a model at inference time, without\naffecting the accuracy. The experiments show that our approach generalizes well\nacross multiple different weather conditions using only ground truth labels\nfrom one domain.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 13:22:05 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Khan", "Qadeer", ""], ["Wenzel", "Patrick", ""], ["Cremers", "Daniel", ""], ["Leal-Taix\u00e9", "Laura", ""]]}, {"id": "1907.11039", "submitter": "Nathan Hurley", "authors": "Nathan C. Hurley, Adrian D. Haimovich, R. Andrew Taylor, Bobak J.\n  Mortazavi", "title": "Visualization of Emergency Department Clinical Data for Interpretable\n  Patient Phenotyping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual summarization of clinical data collected on patients contained within\nthe electronic health record (EHR) may enable precise and rapid triage at the\ntime of patient presentation to an emergency department (ED). The triage\nprocess is critical in the appropriate allocation of resources and in\nanticipating eventual patient disposition, typically admission to the hospital\nor discharge home. EHR data are high-dimensional and complex, but offer the\nopportunity to discover and characterize underlying data-driven patient\nphenotypes. These phenotypes will enable improved, personalized therapeutic\ndecision making and prognostication. In this work, we focus on the challenge of\ntwo-dimensional patient projections. A low dimensional embedding offers visual\ninterpretability lost in higher dimensions. While linear dimensionality\nreduction techniques such as principal component analysis are often used\ntowards this aim, they are insufficient to describe the variance of patient\ndata. In this work, we employ the newly-described non-linear embedding\ntechnique called uniform manifold approximation and projection (UMAP). UMAP\nseeks to capture both local and global structures in high-dimensional data. We\nthen use Gaussian mixture models to identify clusters in the embedded data and\nuse the adjusted Rand index (ARI) to establish stability in the discovery of\nthese clusters. This technique is applied to five common clinical chief\ncomplaints from a real-world ED EHR dataset, describing the emergent properties\nof discovered clusters. We observe clinically-relevant cluster attributes,\nsuggesting that visual embeddings of EHR data using non-linear dimensionality\nreduction is a promising approach to reveal data-driven patient phenotypes. In\nthe five chief complaints, we find between 2 and 6 clusters, with the peak mean\npairwise ARI between subsequent training iterations to range from 0.35 to 0.74.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 19:01:56 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Hurley", "Nathan C.", ""], ["Haimovich", "Adrian D.", ""], ["Taylor", "R. Andrew", ""], ["Mortazavi", "Bobak J.", ""]]}, {"id": "1907.11075", "submitter": "Andrew Warrington", "authors": "Andrew Warrington, Arthur Spencer, Frank Wood", "title": "The Virtual Patch Clamp: Imputing C. elegans Membrane Potentials from\n  Calcium Imaging", "comments": "Includes Supplementary Materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a stochastic whole-brain and body simulator of the nematode\nroundworm Caenorhabditis elegans (C. elegans) and show that it is sufficiently\nregularizing to allow imputation of latent membrane potentials from partial\ncalcium fluorescence imaging observations. This is the first attempt we know of\nto \"complete the circle,\" where an anatomically grounded whole-connectome\nsimulator is used to impute a time-varying \"brain\" state at single-cell\nfidelity from covariates that are measurable in practice. The sequential Monte\nCarlo (SMC) method we employ not only enables imputation of said latent states\nbut also presents a strategy for learning simulator parameters via variational\noptimization of the noisy model evidence approximation provided by SMC. Our\nimputation and parameter estimation experiments were conducted on distributed\nsystems using novel implementations of the aforementioned techniques applied to\nsynthetic data of dimension and type representative of that which are measured\nin laboratories currently.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 17:57:39 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Warrington", "Andrew", ""], ["Spencer", "Arthur", ""], ["Wood", "Frank", ""]]}, {"id": "1907.11086", "submitter": "Alan Chern", "authors": "Alan Chern, Phuong Hoang, Madhav Sigdel, Janani Balaji, and Mohammed\n  Korayem", "title": "Automated Discovery and Classification of Training Videos for Career\n  Progression", "comments": "5 pages, 4 figures, Proceedings of the Data Collection, Curation, and\n  Labeling for Mining and Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Job transitions and upskilling are common actions taken by many industry\nworking professionals throughout their career. With the current rapidly\nchanging job landscape where requirements are constantly changing and industry\nsectors are emerging, it is especially difficult to plan and navigate a\npredetermined career path. In this work, we implemented a system to automate\nthe collection and classification of training videos to help job seekers\nidentify and acquire the skills necessary to transition to the next step in\ntheir career. We extracted educational videos and built a machine learning\nclassifier to predict video relevancy. This system allows us to discover\nrelevant videos at a large scale for job title-skill pairs. Our experiments\nshow significant improvements in the model performance by incorporating\nembedding vectors associated with the video attributes. Additionally, we\nevaluated the optimal probability threshold to extract as many videos as\npossible with minimal false positive rate.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 18:23:57 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Chern", "Alan", ""], ["Hoang", "Phuong", ""], ["Sigdel", "Madhav", ""], ["Balaji", "Janani", ""], ["Korayem", "Mohammed", ""]]}, {"id": "1907.11090", "submitter": "Heyang Gong", "authors": "Gong Heyang and Zhu Ke", "title": "Info Intervention", "comments": "See more information on Causal AI:\n  https://sites.google.com/view/minituring/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal diagrams based on do intervention are useful tools to formalize,\nprocess and understand causal relationship among variables. However, the do\nintervention has controversial interpretation of causal questions for\nnon-manipulable variables, and it also lacks the power to check the conditions\nrelated to counterfactual variables. This paper introduces a new info\nintervention to tackle these two problems, and provides causal diagrams for\ncommunication and theoretical focus based on this info intervention. Our info\nintervention intervenes the input/output information of causal mechanisms,\nwhile the do intervention intervenes the causal mechanisms. Consequently, the\ncausality is viewed as information transfer in the info intervention framework.\nAs an extension, the generalized info intervention is also proposed and studied\nin this paper.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 07:31:14 GMT"}, {"version": "v2", "created": "Sun, 29 Dec 2019 02:59:06 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 15:33:59 GMT"}, {"version": "v4", "created": "Fri, 17 Apr 2020 03:22:07 GMT"}, {"version": "v5", "created": "Mon, 1 Jun 2020 08:11:52 GMT"}, {"version": "v6", "created": "Tue, 2 Jun 2020 03:25:10 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Heyang", "Gong", ""], ["Ke", "Zhu", ""]]}, {"id": "1907.11094", "submitter": "Guihong Wan", "authors": "Guihong Wan, Crystal Maung, Haim Schweitzer", "title": "Improving the Accuracy of Principal Component Analysis by the Maximum\n  Entropy Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical Principal Component Analysis (PCA) approximates data in terms of\nprojections on a small number of orthogonal vectors. There are simple\nprocedures to efficiently compute various functions of the data from the PCA\napproximation. The most important function is arguably the Euclidean distance\nbetween data items, This can be used, for example, to solve the approximate\nnearest neighbor problem. We use random variables to model the inherent\nuncertainty in such approximations, and apply the Maximum Entropy Method to\ninfer the underlying probability distribution. We propose using the expected\nvalues of distances between these random variables as improved estimates of the\ndistance. We show by analysis and experimentally that in most cases results\nobtained by our method are more accurate than what is obtained by the classical\napproach. This improves the accuracy of a classical technique that have been\nused with little change for over 100 years.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 03:24:33 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Wan", "Guihong", ""], ["Maung", "Crystal", ""], ["Schweitzer", "Haim", ""]]}, {"id": "1907.11105", "submitter": "Raoul Heese", "authors": "Raoul Heese and Micha{\\l} Walczak and Lukas Morand and Dirk Helm and\n  Michael Bortz", "title": "The Good, the Bad and the Ugly: Augmenting a black-box model with expert\n  knowledge", "comments": "International Conference on Artificial Neural Networks (ICANN) 2019", "journal-ref": "Artificial Neural Networks and Machine Learning - ICANN 2019:\n  Workshop and Special Sessions. ICANN 2019. Lecture Notes in Computer Science\n  11731 (2019) 391-395", "doi": "10.1007/978-3-030-30493-5_38", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a non-unique parameter fitting problem in the context of material\nscience. In particular, we propose to resolve ambiguities in parameter space by\naugmenting a black-box artificial neural network (ANN) model with two different\nlevels of expert knowledge and benchmark them against a pure black-box model.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 09:15:01 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 17:07:49 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Heese", "Raoul", ""], ["Walczak", "Micha\u0142", ""], ["Morand", "Lukas", ""], ["Helm", "Dirk", ""], ["Bortz", "Michael", ""]]}, {"id": "1907.11110", "submitter": "Seyed Mehdi Ayyoubzadeh", "authors": "Seyed Mehdi Ayyoubzadeh, Xiaolin Wu", "title": "Filter Bank Regularization of Convolutional Neural Networks", "comments": "11 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization techniques are widely used to improve the generality,\nrobustness, and efficiency of deep convolutional neural networks (DCNNs). In\nthis paper, we propose a novel approach of regulating DCNN convolutional\nkernels by a structured filter bank. Comparing with the existing regularization\nmethods, such as $\\ell_1$ or $\\ell_2$ minimization of DCNN kernel weights and\nthe kernel orthogonality, which ignore sample correlations within a kernel, the\nuse of filter bank in regularization of DCNNs can mold the DCNN kernels to\ncommon spatial structures and features (e.g., edges or textures of various\norientations and frequencies) of natural images. On the other hand, unlike\ndirectly making DCNN kernels fixed filters, the filter bank regularization\nstill allows the freedom of optimizing DCNN weights via deep learning. This new\nDCNN design strategy aims to combine the best of two worlds: the inclusion of\nstructural image priors of traditional filter banks to improve the robustness\nand generality of DCNN solutions and the capability of modern deep learning to\nmodel complex non-linear functions hidden in training data. Experimental\nresults on object recognition tasks show that the proposed regularization\napproach guides DCNNs to faster convergence and better generalization than\nexisting regularization methods of weight decay and kernel orthogonality.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 14:43:10 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2019 20:45:53 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 20:43:51 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Ayyoubzadeh", "Seyed Mehdi", ""], ["Wu", "Xiaolin", ""]]}, {"id": "1907.11114", "submitter": "Jiawei Zhang", "authors": "Yixin Chen, Lin Meng, and Jiawei Zhang", "title": "Graph Neural Lasso for Dynamic Network Regression", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The regression of multiple inter-connected sequence data is a problem in\nvarious disciplines. Formally, we name the regression problem of multiple\ninter-connected data entities as the \"dynamic network regression\" in this\npaper. Within the problem of stock forecasting or traffic speed prediction, we\nneed to consider both the trends of the entities and the relationships among\nthe entities. A majority of existing approaches can't capture that information\ntogether. Some of the approaches are proposed to deal with the sequence data,\nlike LSTM. The others use the prior knowledge in a network to get a fixed graph\nstructure and do prediction on some unknown entities, like GCN. To overcome the\nlimitations in those methods, we propose a novel graph neural network, namely\nGraph Neural Lasso (GNL), to deal with the dynamic network problem. GNL extends\nthe GDU (gated diffusive unit) as the base neuron to capture the information\nbehind the sequence. Rather than using a fixed graph structure, GNL can learn\nthe dynamic graph structure automatically. By adding the attention mechanism in\nGNL, we can learn the dynamic relations among entities within each network\nsnapshot. Combining these two parts, GNL is able to model the dynamic network\nproblem well. Experimental results provided on two networked sequence datasets,\ni.e., Nasdaq-100 and METR-LA, show that GNL can address the network regression\nproblem very well and is also very competitive among the existing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 14:52:10 GMT"}, {"version": "v2", "created": "Fri, 16 Oct 2020 03:58:03 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Chen", "Yixin", ""], ["Meng", "Lin", ""], ["Zhang", "Jiawei", ""]]}, {"id": "1907.11129", "submitter": "Casey Kneale Ph.D", "authors": "Casey Kneale, Kolia Sadeghi", "title": "Semisupervised Adversarial Neural Networks for Cyber Security Transfer\n  Learning", "comments": "14 figures, 17 pages, Draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.NE stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On the path to establishing a global cybersecurity framework where each\nenterprise shares information about malicious behavior, an important question\narises. How can a machine learning representation characterizing a cyber attack\non one network be used to detect similar attacks on other enterprise networks\nif each networks has wildly different distributions of benign and malicious\ntraffic? We address this issue by comparing the results of naively transferring\na model across network domains and using CORrelation ALignment, to our novel\nadversarial Siamese neural network. Our proposed model learns attack\nrepresentations that are more invariant to each network's particularities via\nan adversarial approach. It uses a simple ranking loss that prioritizes the\nlabeling of the most egregious malicious events correctly over average\naccuracy. This is appropriate for driving an alert triage workflow wherein an\nanalyst only has time to inspect the top few events ranked highest by the\nmodel. In terms of accuracy, the other approaches fail completely to detect any\nmalicious events when models were trained on one dataset are evaluated on\nanother for the first 100 events. While, the method presented here retrieves\nsizable proportions of malicious events, at the expense of some training\ninstabilities due in adversarial modeling. We evaluate these approaches using 2\npublicly available networking datasets, and suggest areas for future research.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 15:14:38 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Kneale", "Casey", ""], ["Sadeghi", "Kolia", ""]]}, {"id": "1907.11142", "submitter": "Marzia Cremona", "authors": "Jacopo Di Iorio, Francesca Chiaromonte and Marzia A. Cremona", "title": "On the bias of H-scores for comparing biclusters, and how to correct it", "comments": "12 pages, 3 figures", "journal-ref": "Bioinformatics 2020, 36(1): 2955-2957", "doi": "10.1093/bioinformatics/btaa060", "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last two decades several biclustering methods have been developed as\nnew unsupervised learning techniques to simultaneously cluster rows and columns\nof a data matrix. These algorithms play a central role in contemporary machine\nlearning and in many applications, e.g. to computational biology and\nbioinformatics. The H-score is the evaluation score underlying the seminal\nbiclustering algorithm by Cheng and Church, as well as many other subsequent\nbiclustering methods. In this paper, we characterize a potentially troublesome\nbias in this score, that can distort biclustering results. We prove, both\nanalytically and by simulation, that the average H-score increases with the\nnumber of rows/columns in a bicluster. This makes the H-score, and hence all\nalgorithms based on it, biased towards small clusters. Based on our analytical\nproof, we are able to provide a straightforward way to correct this bias,\nallowing users to accurately compare biclusters.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 15:24:27 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Di Iorio", "Jacopo", ""], ["Chiaromonte", "Francesca", ""], ["Cremona", "Marzia A.", ""]]}, {"id": "1907.11180", "submitter": "Anton Raichuk", "authors": "Karol Kurach, Anton Raichuk, Piotr Sta\\'nczyk, Micha{\\l} Zaj\\k{a}c,\n  Olivier Bachem, Lasse Espeholt, Carlos Riquelme, Damien Vincent, Marcin\n  Michalski, Olivier Bousquet, Sylvain Gelly", "title": "Google Research Football: A Novel Reinforcement Learning Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent progress in the field of reinforcement learning has been accelerated\nby virtual learning environments such as video games, where novel algorithms\nand ideas can be quickly tested in a safe and reproducible manner. We introduce\nthe Google Research Football Environment, a new reinforcement learning\nenvironment where agents are trained to play football in an advanced,\nphysics-based 3D simulator. The resulting environment is challenging, easy to\nuse and customize, and it is available under a permissive open-source license.\nIn addition, it provides support for multiplayer and multi-agent experiments.\nWe propose three full-game scenarios of varying difficulty with the Football\nBenchmarks and report baseline results for three commonly used reinforcement\nalgorithms (IMPALA, PPO, and Ape-X DQN). We also provide a diverse set of\nsimpler scenarios with the Football Academy and showcase several promising\nresearch directions.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 16:39:27 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 18:11:24 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Kurach", "Karol", ""], ["Raichuk", "Anton", ""], ["Sta\u0144czyk", "Piotr", ""], ["Zaj\u0105c", "Micha\u0142", ""], ["Bachem", "Olivier", ""], ["Espeholt", "Lasse", ""], ["Riquelme", "Carlos", ""], ["Vincent", "Damien", ""], ["Michalski", "Marcin", ""], ["Bousquet", "Olivier", ""], ["Gelly", "Sylvain", ""]]}, {"id": "1907.11195", "submitter": "Xiao Wang", "authors": "Xiao Wang, Zhijie Wang, Yolande M. Pengetnze, Barry S. Lachman, Vikas\n  Chowdhry", "title": "Deep Learning Models to Predict Pediatric Asthma Emergency Department\n  Visits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pediatric asthma is the most prevalent chronic childhood illness, afflicting\nabout 6.2 million children in the United States. However, asthma could be\nbetter managed by identifying and avoiding triggers, educating about\nmedications and proper disease management strategies. This research utilizes\ndeep learning methodologies to predict asthma-related emergency department (ED)\nvisit within 3 months using Medicaid claims data. We compare prediction results\nagainst traditional statistical classification model - penalized Lasso logistic\nregression, which we trained and have deployed since 2015. The results have\nindicated that deep learning model Artificial Neural Networks (ANN) slightly\noutperforms (with AUC = 0.845) the Lasso logistic regression (with AUC =\n0.842). The reason may come from the nonlinear nature of ANN.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 16:56:56 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Wang", "Xiao", ""], ["Wang", "Zhijie", ""], ["Pengetnze", "Yolande M.", ""], ["Lachman", "Barry S.", ""], ["Chowdhry", "Vikas", ""]]}, {"id": "1907.11202", "submitter": "Ligong Han", "authors": "Ligong Han, Yang Zou, Ruijiang Gao, Lezi Wang, Dimitris Metaxas", "title": "Unsupervised Domain Adaptation via Calibrating Uncertainties", "comments": "4 pages", "journal-ref": "The IEEE Conference on Computer Vision and Pattern Recognition\n  (CVPR) Workshops, 2019, pp. 99-102", "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unsupervised domain adaptation (UDA) aims at inferring class labels for\nunlabeled target domain given a related labeled source dataset. Intuitively, a\nmodel trained on source domain normally produces higher uncertainties for\nunseen data. In this work, we build on this assumption and propose to adapt\nfrom source to target domain via calibrating their predictive uncertainties.\nThe uncertainty is quantified as the Renyi entropy, from which we propose a\ngeneral Renyi entropy regularization (RER) framework. We further employ\nvariational Bayes learning for reliable uncertainty estimation. In addition,\ncalibrating the sample variance of network parameters serves as a plug-in\nregularizer for training. We discuss the theoretical properties of the proposed\nmethod and demonstrate its effectiveness on three domain-adaptation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 17:02:51 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Han", "Ligong", ""], ["Zou", "Yang", ""], ["Gao", "Ruijiang", ""], ["Wang", "Lezi", ""], ["Metaxas", "Dimitris", ""]]}, {"id": "1907.11208", "submitter": "David Augustin", "authors": "David Augustin, Marius Hofmann, Ulrich Konigorski", "title": "Prediction of Highway Lane Changes Based on Prototype Trajectories", "comments": "VDI AUTOREG 2019, 17 pages, 5 figures", "journal-ref": "VDI-Berichte Nr. 2349: 111-127, 2019, VDI Wissensforum GmbH, ISSN:\n  0083-5560, ISBN: 978-3-18-092349-9", "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vision of automated driving is to increase both road safety and\nefficiency, while offering passengers a convenient travel experience. This\nrequires that autonomous systems correctly estimate the current traffic scene\nand its likely evolution. In highway scenarios early recognition of cut-in\nmaneuvers is essential for risk-aware maneuver planning. In this paper, a\nstatistical approach is proposed, which advantageously utilizes a set of\nprototypical lane change trajectories to realize both early maneuver detection\nand uncertainty-aware trajectory prediction for traffic participants.\nGeneration of prototype trajectories from real traffic data is accomplished by\nAgglomerative Hierarchical Clustering. During clustering, the alignment of the\ncluster prototypes to each other is optimized and the cohesion of the resulting\nprototype is limited when two clusters merge. In the prediction stage, the\nsimilarity of observed vehicle motion and typical lane change patterns in the\ndata base is evaluated to construct a set of significant features for maneuver\nclassification via Boosted Decision Trees. The future trajectory is predicted\ncombining typical lane change realizations in a mixture model. B-splines based\ntrajectory adaptations guarantee continuity during transition from actually\nobserved to predicted vehicle states. Quantitative evaluation results\ndemonstrate the proposed concept's improved performance for both maneuver and\ntrajectory prediction compared to a previously implemented reference approach.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 17:18:53 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Augustin", "David", ""], ["Hofmann", "Marius", ""], ["Konigorski", "Ulrich", ""]]}, {"id": "1907.11216", "submitter": "Shoubo Hu", "authors": "Shoubo Hu, Kun Zhang, Zhitang Chen, Laiwan Chan", "title": "Domain Generalization via Multidomain Discriminant Analysis", "comments": "UAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain generalization (DG) aims to incorporate knowledge from multiple source\ndomains into a single model that could generalize well on unseen target\ndomains. This problem is ubiquitous in practice since the distributions of the\ntarget data may rarely be identical to those of the source data. In this paper,\nwe propose Multidomain Discriminant Analysis (MDA) to address DG of\nclassification tasks in general situations. MDA learns a domain-invariant\nfeature transformation that aims to achieve appealing properties, including a\nminimal divergence among domains within each class, a maximal separability\namong classes, and overall maximal compactness of all classes. Furthermore, we\nprovide the bounds on excess risk and generalization error by learning theory\nanalysis. Comprehensive experiments on synthetic and real benchmark datasets\ndemonstrate the effectiveness of MDA.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 17:39:44 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Hu", "Shoubo", ""], ["Zhang", "Kun", ""], ["Chen", "Zhitang", ""], ["Chan", "Laiwan", ""]]}, {"id": "1907.11223", "submitter": "Wengong Jin", "authors": "Wengong Jin, Regina Barzilay, Tommi Jaakkola", "title": "Hierarchical Graph-to-Graph Translation for Molecules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of accelerating drug discovery relies heavily on automatic tools\nto optimize precursor molecules to afford them with better biochemical\nproperties. Our work in this paper substantially extends prior state-of-the-art\non graph-to-graph translation methods for molecular optimization. In\nparticular, we realize coherent multi-resolution representations by\ninterweaving the encoding of substructure components with the atom-level\nencoding of the original molecular graph. Moreover, our graph decoder is fully\nautoregressive, and interleaves each step of adding a new substructure with the\nprocess of resolving its attachment to the emerging molecule. We evaluate our\nmodel on multiple molecular optimization tasks and show that our model\nsignificantly outperforms previous state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 21:50:42 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 19:52:58 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Jin", "Wengong", ""], ["Barzilay", "Regina", ""], ["Jaakkola", "Tommi", ""]]}, {"id": "1907.11235", "submitter": "Peichang Guo", "authors": "Pei-Chang Guo", "title": "A Frobenius norm regularization method for convolutional kernels to\n  avoid unstable gradient problem", "comments": "arXiv admin note: text overlap with arXiv:1906.04866", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural network is a very important model of deep learning. It\ncan help avoid the exploding/vanishing gradient problem and improve the\ngeneralizability of a neural network if the singular values of the Jacobian of\na layer are bounded around $1$ in the training process. We propose a new\npenalty function for a convolutional kernel to let the singular values of the\ncorresponding transformation matrix are bounded around $1$. We show how to\ncarry out the gradient type methods. The penalty is about the structured\ntransformation matrix corresponding to a convolutional kernel. This provides a\nnew regularization method about the weights of convolutional layers.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 23:43:05 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Guo", "Pei-Chang", ""]]}, {"id": "1907.11277", "submitter": "Gabriel Aguiar", "authors": "Gabriel Jonas Aguiar, Everton Jos\\'e Santana, Saulo Martiello\n  Mastelini, Rafael Gomes Mantovani, Sylvio Barbon Jr", "title": "Towards meta-learning for multi-target regression problems", "comments": "To appear on the 8th Brazilian Conference on Intelligent Systems\n  (BRACIS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several multi-target regression methods were devel-oped in the last years\naiming at improving predictive performanceby exploring inter-target correlation\nwithin the problem. However, none of these methods outperforms the others for\nall problems. This motivates the development of automatic approachesto\nrecommend the most suitable multi-target regression method. In this paper, we\npropose a meta-learning system to recommend the best predictive method for a\ngiven multi-target regression problem. We performed experiments with a\nmeta-dataset generated by a total of 648 synthetic datasets. These datasets\nwere created to explore distinct inter-targets characteristics toward\nrecommending the most promising method. In experiments, we evaluated four\ndifferent algorithms with different biases as meta-learners. Our meta-dataset\nis composed of 58 meta-features, based on: statistical information, correlation\ncharacteristics, linear landmarking, from the distribution and smoothness of\nthe data, and has four different meta-labels. Results showed that induced\nmeta-models were able to recommend the best methodfor different base level\ndatasets with a balanced accuracy superior to 70% using a Random Forest\nmeta-model, which statistically outperformed the meta-learning baselines.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 19:05:16 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Aguiar", "Gabriel Jonas", ""], ["Santana", "Everton Jos\u00e9", ""], ["Mastelini", "Saulo Martiello", ""], ["Mantovani", "Rafael Gomes", ""], ["Barbon", "Sylvio", "Jr"]]}, {"id": "1907.11281", "submitter": "G\\\"unther Waxenegger-Wilfing", "authors": "G\\\"unther Waxenegger-Wilfing, Kai Dresia, Jan Christian Deeken,\n  Michael Oschwald", "title": "Heat Transfer Prediction for Methane in Regenerative Cooling Channels\n  with Neural Networks", "comments": null, "journal-ref": null, "doi": "10.2514/1.T5865", "report-no": null, "categories": "cs.LG physics.app-ph physics.flu-dyn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methane is considered being a good choice as a propellant for future reusable\nlaunch systems. However, the heat transfer prediction for supercritical methane\nflowing in cooling channels of a regeneratively cooled combustion chamber is\nchallenging. Because accurate heat transfer predictions are essential to design\nreliable and efficient cooling systems, heat transfer modeling is a fundamental\nissue to address. Advanced computational fluid dynamics (CFD) calculations\nachieve sufficient accuracy, but the associated computational cost prevents an\nefficient integration in optimization loops. Surrogate models based on\nartificial neural networks (ANNs) offer a great speed advantage. It is shown\nthat an ANN, trained on data extracted from samples of CFD simulations, is able\nto predict the maximum wall temperature along straight rocket engine cooling\nchannels using methane with convincing precision. The combination of the ANN\nmodel with simple relations for pressure drop and enthalpy rise results in a\ncomplete reduced order model, which can be used for numerically efficient\ndesign space exploration and optimization.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 16:49:09 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Waxenegger-Wilfing", "G\u00fcnther", ""], ["Dresia", "Kai", ""], ["Deeken", "Jan Christian", ""], ["Oschwald", "Michael", ""]]}, {"id": "1907.11307", "submitter": "Jiyang Bai", "authors": "Jiyang Bai, Yuxiang Ren and Jiawei Zhang", "title": "DEAM: Adaptive Momentum with Discriminative Weight for Stochastic\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization algorithms with momentum, e.g., (ADAM), have been widely used\nfor building deep learning models due to the faster convergence rates compared\nwith stochastic gradient descent (SGD). Momentum helps accelerate SGD in the\nrelevant directions in parameter updating, which can minify the oscillations of\nparameters update route. However, there exist errors in some update steps in\noptimization algorithms with momentum like ADAM. The fixed momentum weight\n(e.g., \\beta_1 in ADAM) will propagate errors in momentum computing. In this\npaper, we introduce a novel optimization algorithm, namely Discriminative\nwEight on Adaptive Momentum (DEAM). Instead of assigning the momentum term\nweight with a fixed hyperparameter, DEAM proposes to compute the momentum\nweight automatically based on the discriminative angle. In this way, DEAM\ninvolves fewer hyperparameters. DEAM also contains a novel backtrack term,\nwhich restricts redundant updates when the correction of the last step is\nneeded. Extensive experiments demonstrate that DEAM can achieve a faster\nconvergence rate than the existing optimization algorithms in training the deep\nlearning models of both convex and non-convex situations.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 20:55:54 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 04:36:41 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Bai", "Jiyang", ""], ["Ren", "Yuxiang", ""], ["Zhang", "Jiawei", ""]]}, {"id": "1907.11313", "submitter": "Piyush Pandita", "authors": "Piyush Pandita, Jesper Kristensen and Liping Wang", "title": "Towards Scalable Gaussian Process Modeling", "comments": "15 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous engineering problems of interest to the industry are often\ncharacterized by expensive black-box objective experiments or computer\nsimulations. Obtaining insight into the problem or performing subsequent\noptimizations requires hundreds of thousands of evaluations of the objective\nfunction which is most often a practically unachievable task. Gaussian Process\n(GP) surrogate modeling replaces the expensive function with a\ncheap-to-evaluate data-driven probabilistic model. While the GP does not assume\na functional form of the problem, it is defined by a set of parameters, called\nhyperparameters. The hyperparameters define the characteristics of the\nobjective function, such as smoothness, magnitude, periodicity, etc. Accurately\nestimating these hyperparameters is a key ingredient in developing a reliable\nand generalizable surrogate model. Markov chain Monte Carlo (MCMC) is a\nubiquitously used Bayesian method to estimate these hyperparameters. At the GE\nGlobal Research Center, a customized industry-strength Bayesian hybrid modeling\nframework utilizing the GP, called GEBHM, has been employed and validated over\nmany years. GEBHM is very effective on problems of small and medium size,\ntypically less than 1000 training points. However, the GP does not scale well\nin time with a growing dataset and problem dimensionality which can be a major\nimpediment in such problems. In this work, we extend and implement in GEBHM an\nAdaptive Sequential Monte Carlo (ASMC) methodology for training the GP enabling\nthe modeling of large-scale industry problems. This implementation saves\ncomputational time (especially for large-scale problems) while not sacrificing\npredictability over the current MCMC implementation. We demonstrate the\neffectiveness and accuracy of GEBHM with ASMC on four mathematical problems and\non two challenging industry applications of varying complexity.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 21:15:57 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Pandita", "Piyush", ""], ["Kristensen", "Jesper", ""], ["Wang", "Liping", ""]]}, {"id": "1907.11318", "submitter": "Jaak Simm", "authors": "Jaak Simm, Adam Arany, Edward De Brouwer, Yves Moreau", "title": "Expressive Graph Informer Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying machine learning to molecules is challenging because of their\nnatural representation as graphs rather than vectors.Several architectures have\nbeen recently proposed for deep learning from molecular graphs, but they suffer\nfrom informationbottlenecks because they only pass information from a graph\nnode to its direct neighbors. Here, we introduce a more expressiveroute-based\nmulti-attention mechanism that incorporates features from routes between node\npairs. We call the resulting methodGraph Informer. A single network layer can\ntherefore attend to nodes several steps away. We show empirically that the\nproposedmethod compares favorably against existing approaches in two prediction\ntasks: (1) 13C Nuclear Magnetic Resonance (NMR)spectra, improving the\nstate-of-the-art with an MAE of 1.35 ppm and (2) predicting drug bioactivity\nand toxicity. Additionally, wedevelop a variant called injective Graph Informer\nthat isprovablyas powerful as the Weisfeiler-Lehman test for graph\nisomorphism.Furthermore, we demonstrate that the route information allows the\nmethod to be informed about thenonlocal topologyof the graphand, thus, even go\nbeyond the capabilities of the Weisfeiler-Lehman test.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 22:01:32 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2020 12:56:17 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Simm", "Jaak", ""], ["Arany", "Adam", ""], ["De Brouwer", "Edward", ""], ["Moreau", "Yves", ""]]}, {"id": "1907.11331", "submitter": "Wenlong Mou", "authors": "Wenlong Mou, Nicolas Flammarion, Martin J. Wainwright, Peter L.\n  Bartlett", "title": "Improved Bounds for Discretization of Langevin Diffusions: Near-Optimal\n  Rates without Convexity", "comments": "Changes from v1: corrections in the proof of Lemma 6 and Lemma 10;\n  fixed some minor typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an improved analysis of the Euler-Maruyama discretization of the\nLangevin diffusion. Our analysis does not require global contractivity, and\nyields polynomial dependence on the time horizon. Compared to existing\napproaches, we make an additional smoothness assumption, and improve the\nexisting rate from $O(\\eta)$ to $O(\\eta^2)$ in terms of the KL divergence. This\nresult matches the correct order for numerical SDEs, without suffering from\nexponential time dependence. When applied to algorithms for sampling and\nlearning, this result simultaneously improves all those methods based on\nDalayan's approach.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 22:54:45 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 17:57:36 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Mou", "Wenlong", ""], ["Flammarion", "Nicolas", ""], ["Wainwright", "Martin J.", ""], ["Bartlett", "Peter L.", ""]]}, {"id": "1907.11362", "submitter": "Gi-Soo Kim", "authors": "Gi-Soo Kim and Myunghee Cho Paik", "title": "Doubly-Robust Lasso Bandit", "comments": "Corrections to previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual multi-armed bandit algorithms are widely used in sequential\ndecision tasks such as news article recommendation systems, web page ad\nplacement algorithms, and mobile health. Most of the existing algorithms have\nregret proportional to a polynomial function of the context dimension, $d$. In\nmany applications however, it is often the case that contexts are\nhigh-dimensional with only a sparse subset of size $s_0 (\\ll d)$ being\ncorrelated with the reward. We consider the stochastic linear contextual bandit\nproblem and propose a novel algorithm, namely the Doubly-Robust Lasso Bandit\nalgorithm, which exploits the sparse structure of the regression parameter as\nin Lasso, while blending the doubly-robust technique used in missing data\nliterature. The high-probability upper bound of the regret incurred by the\nproposed algorithm does not depend on the number of arms and scales with\n$\\mathrm{log}(d)$ instead of a polynomial function of $d$. The proposed\nalgorithm shows good performance when contexts of different arms are correlated\nand requires less tuning parameters than existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 02:41:09 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 04:57:50 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Kim", "Gi-Soo", ""], ["Paik", "Myunghee Cho", ""]]}, {"id": "1907.11374", "submitter": "Mert Sabuncu", "authors": "Cagla D. Bahadir, Alan Q. Wang, Adrian V. Dalca and Mert R. Sabuncu", "title": "Deep-learning-based Optimization of the Under-sampling Pattern in MRI", "comments": "18 pages, 9 figures, 2 tables", "journal-ref": "IEEE Transactions on Computational Imaging, 2020", "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In compressed sensing MRI (CS-MRI), k-space measurements are under-sampled to\nachieve accelerated scan times. CS-MRI presents two fundamental problems: (1)\nwhere to sample and (2) how to reconstruct an under-sampled scan. In this\npaper, we tackle both problems simultaneously for the specific case of 2D\nCartesian sampling, using a novel end-to-end learning framework that we call\nLOUPE (Learning-based Optimization of the Under-sampling PattErn). Our method\ntrains a neural network model on a set of full-resolution MRI scans, which are\nretrospectively under-sampled on a 2D Cartesian grid and forwarded to an\nanti-aliasing (a.k.a. reconstruction) model that computes a reconstruction,\nwhich is in turn compared with the input. This formulation enables a\ndata-driven optimized under-sampling pattern at a given sparsity level. In our\nexperiments, we demonstrate that LOUPE-optimized under-sampling masks are\ndata-dependent, varying significantly with the imaged anatomy, and perform well\nwith different reconstruction methods. We present empirical results obtained\nwith a large-scale, publicly available knee MRI dataset, where LOUPE offered\nsuperior reconstruction quality across different conditions. Even with an\naggressive 8-fold acceleration rate, LOUPE's reconstructions contained much of\nthe anatomical detail that was missed by alternative masks and reconstruction\nmethods. Our experiments also show how LOUPE yielded optimal under-sampling\npatterns that were significantly different for brain vs knee MRI scans. Our\ncode is made freely available at https://github.com/cagladbahadir/LOUPE/.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 03:28:48 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 01:57:44 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2020 15:30:54 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Bahadir", "Cagla D.", ""], ["Wang", "Alan Q.", ""], ["Dalca", "Adrian V.", ""], ["Sabuncu", "Mert R.", ""]]}, {"id": "1907.11377", "submitter": "Dongpeng Liu", "authors": "Ming Liu, Dongpeng Liu, Guangyu Sun, Yi Zhao, Duolin Wang, Fangxing\n  Liu, Xiang Fang, Qing He, Dong Xu", "title": "Deep Learning Detection of Inaccurate Smart Electricity Meters: A Case\n  Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting inaccurate smart meters and targeting them for replacement can save\nsignificant resources. For this purpose, a novel deep-learning method was\ndeveloped based on long short-term memory (LSTM) and a modified convolutional\nneural network (CNN) to predict electricity usage trajectories based on\nhistorical data. From the significant difference between the predicted\ntrajectory and the observed one, the meters that cannot measure electricity\naccurately are located. In a case study, a proof of principle was demonstrated\nin detecting inaccurate meters with high accuracy for practical usage to\nprevent unnecessary replacement and increase the service life span of smart\nmeters.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 04:05:07 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 01:10:07 GMT"}, {"version": "v3", "created": "Fri, 7 Aug 2020 23:29:32 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Liu", "Ming", ""], ["Liu", "Dongpeng", ""], ["Sun", "Guangyu", ""], ["Zhao", "Yi", ""], ["Wang", "Duolin", ""], ["Liu", "Fangxing", ""], ["Fang", "Xiang", ""], ["He", "Qing", ""], ["Xu", "Dong", ""]]}, {"id": "1907.11452", "submitter": "Heinke Hihn", "authors": "Heinke Hihn, Sebastian Gottwald, and Daniel A. Braun", "title": "An Information-theoretic On-line Learning Principle for Specialization\n  in Hierarchical Decision-Making Systems", "comments": null, "journal-ref": null, "doi": "10.1109/CDC40024.2019.9029255", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information-theoretic bounded rationality describes utility-optimizing\ndecision-makers whose limited information-processing capabilities are\nformalized by information constraints. One of the consequences of bounded\nrationality is that resource-limited decision-makers can join together to solve\ndecision-making problems that are beyond the capabilities of each individual.\nHere, we study an information-theoretic principle that drives division of labor\nand specialization when decision-makers with information constraints are joined\ntogether. We devise an on-line learning rule of this principle that learns a\npartitioning of the problem space such that it can be solved by specialized\nlinear policies. We demonstrate the approach for decision-making problems whose\ncomplexity exceeds the capabilities of individual decision-makers, but can be\nsolved by combining the decision-makers optimally. The strength of the model is\nthat it is abstract and principled, yet has direct applications in\nclassification, regression, reinforcement learning and adaptive control.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 09:28:18 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 12:37:49 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 09:22:15 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Hihn", "Heinke", ""], ["Gottwald", "Sebastian", ""], ["Braun", "Daniel A.", ""]]}, {"id": "1907.11457", "submitter": "Eduardo Paluzo-Hidalgo", "authors": "Rocio Gonzalez-Diaz, Miguel A. Guti\\'errez-Naranjo, Eduardo\n  Paluzo-Hidalgo", "title": "Two-hidden-layer Feedforward Neural Networks are Universal\n  Approximators: A Constructive Approach", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2020.07.021", "report-no": null, "categories": "cs.LG math.AT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that Artificial Neural Networks are universal approximators.\nThe classical result proves that, given a continuous function on a compact set\non an n-dimensional space, then there exists a one-hidden-layer feedforward\nnetwork which approximates the function. Such result proves the existence, but\nit does not provide a method for finding it. In this paper, a constructive\napproach to the proof of this property is given for the case of\ntwo-hidden-layer feedforward networks. This approach is based on an\napproximation of continuous functions by simplicial maps. Once a triangulation\nof the space is given, a concrete architecture and set of weights can be\nobtained. The quality of the approximation depends on the refinement of the\ncovering of the space by simplicial complexes.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 09:43:24 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 20:05:27 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Gonzalez-Diaz", "Rocio", ""], ["Guti\u00e9rrez-Naranjo", "Miguel A.", ""], ["Paluzo-Hidalgo", "Eduardo", ""]]}, {"id": "1907.11505", "submitter": "Jos\\'e Enrique Chac\\'on", "authors": "Jos\\'e E. Chac\\'on", "title": "A close-up comparison of the misclassification error distance and the\n  adjusted Rand index for external clustering evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The misclassification error distance and the adjusted Rand index are two of\nthe most commonly used criteria to evaluate the performance of clustering\nalgorithms. This paper provides an in-depth comparison of the two criteria,\naimed to better understand exactly what they measure, their properties and\ntheir differences. Starting from their population origins, the investigation\nincludes many data analysis examples and the study of particular cases in great\ndetail. An exhaustive simulation study allows inspecting the criteria\ndistributions and reveals some previous misconceptions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 12:11:40 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Chac\u00f3n", "Jos\u00e9 E.", ""]]}, {"id": "1907.11510", "submitter": "Fabien Ringeval", "authors": "Fabien Ringeval, Bj\\\"orn Schuller, Michel Valstar, NIcholas Cummins,\n  Roddy Cowie, Leili Tavabi, Maximilian Schmitt, Sina Alisamir, Shahin\n  Amiriparian, Eva-Maria Messner, Siyang Song, Shuo Liu, Ziping Zhao, Adria\n  Mallol-Ragolta, Zhao Ren, Mohammad Soleymani, Maja Pantic", "title": "AVEC 2019 Workshop and Challenge: State-of-Mind, Detecting Depression\n  with AI, and Cross-Cultural Affect Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Audio/Visual Emotion Challenge and Workshop (AVEC 2019) \"State-of-Mind,\nDetecting Depression with AI, and Cross-cultural Affect Recognition\" is the\nninth competition event aimed at the comparison of multimedia processing and\nmachine learning methods for automatic audiovisual health and emotion analysis,\nwith all participants competing strictly under the same conditions. The goal of\nthe Challenge is to provide a common benchmark test set for multimodal\ninformation processing and to bring together the health and emotion recognition\ncommunities, as well as the audiovisual processing communities, to compare the\nrelative merits of various approaches to health and emotion recognition from\nreal-life data. This paper presents the major novelties introduced this year,\nthe challenge guidelines, the data used, and the performance of the baseline\nsystems on the three proposed tasks: state-of-mind recognition, depression\nassessment with AI, and cross-cultural affect sensing, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:41:42 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Ringeval", "Fabien", ""], ["Schuller", "Bj\u00f6rn", ""], ["Valstar", "Michel", ""], ["Cummins", "NIcholas", ""], ["Cowie", "Roddy", ""], ["Tavabi", "Leili", ""], ["Schmitt", "Maximilian", ""], ["Alisamir", "Sina", ""], ["Amiriparian", "Shahin", ""], ["Messner", "Eva-Maria", ""], ["Song", "Siyang", ""], ["Liu", "Shuo", ""], ["Zhao", "Ziping", ""], ["Mallol-Ragolta", "Adria", ""], ["Ren", "Zhao", ""], ["Soleymani", "Mohammad", ""], ["Pantic", "Maja", ""]]}, {"id": "1907.11546", "submitter": "Simone Scardapane", "authors": "Riccardo Vecchi, Simone Scardapane, Danilo Comminiello, Aurelio Uncini", "title": "Compressing deep quaternion neural networks with targeted regularization", "comments": "Published on CAAI Transactions on Intelligence Technology,\n  https://digital-library.theiet.org/content/journals/10.1049/trit.2020.0020", "journal-ref": null, "doi": "10.1049/trit.2020.0020", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, hyper-complex deep networks (such as complex-valued and\nquaternion-valued neural networks) have received a renewed interest in the\nliterature. They find applications in multiple fields, ranging from image\nreconstruction to 3D audio processing. Similar to their real-valued\ncounterparts, quaternion neural networks (QVNNs) require custom regularization\nstrategies to avoid overfitting. In addition, for many real-world applications\nand embedded implementations, there is the need of designing sufficiently\ncompact networks, with few weights and neurons. However, the problem of\nregularizing and/or sparsifying QVNNs has not been properly addressed in the\nliterature as of now. In this paper, we show how to address both problems by\ndesigning targeted regularization strategies, which are able to minimize the\nnumber of connections and neurons of the network during training. To this end,\nwe investigate two extensions of l1 and structured regularization to the\nquaternion domain. In our experimental evaluation, we show that these tailored\nstrategies significantly outperform classical (real-valued) regularization\napproaches, resulting in small networks especially suitable for low-power and\nreal-time applications.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 12:55:55 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 14:50:23 GMT"}, {"version": "v3", "created": "Mon, 13 Jul 2020 08:23:37 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Vecchi", "Riccardo", ""], ["Scardapane", "Simone", ""], ["Comminiello", "Danilo", ""], ["Uncini", "Aurelio", ""]]}, {"id": "1907.11555", "submitter": "Zach Eaton-Rosen", "authors": "Zach Eaton-Rosen, Thomas Varsavsky, Sebastien Ourselin and M. Jorge\n  Cardoso", "title": "As easy as 1, 2... 4? Uncertainty in counting tasks for medical imaging", "comments": "Early Accept to MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counting is a fundamental task in biomedical imaging and count is an\nimportant biomarker in a number of conditions. Estimating the uncertainty in\nthe measurement is thus vital to making definite, informed conclusions. In this\npaper, we first compare a range of existing methods to perform counting in\nmedical imaging and suggest ways of deriving predictive intervals from these.\nWe then propose and test a method for calculating intervals as an output of a\nmulti-task network. These predictive intervals are optimised to be as narrow as\npossible, while also enclosing a desired percentage of the data. We demonstrate\nthe effectiveness of this technique on histopathological cell counting and\nwhite matter hyperintensity counting. Finally, we offer insight into other\nareas where this technique may apply.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 15:11:32 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Eaton-Rosen", "Zach", ""], ["Varsavsky", "Thomas", ""], ["Ourselin", "Sebastien", ""], ["Cardoso", "M. Jorge", ""]]}, {"id": "1907.11559", "submitter": "Guilherme Pombo", "authors": "Guilherme Pombo, Robert Gray, Tom Varsavsky, John Ashburner, Parashkev\n  Nachev", "title": "Bayesian Volumetric Autoregressive generative models for better\n  semisupervised learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are rapidly gaining traction in medical imaging.\nNonetheless, most generative architectures struggle to capture the underlying\nprobability distributions of volumetric data, exhibit convergence problems, and\noffer no robust indices of model uncertainty. By comparison, the autoregressive\ngenerative model PixelCNN can be extended to volumetric data with relative\nease, it readily attempts to learn the true underlying probability distribution\nand it still admits a Bayesian reformulation that provides a principled\nframework for reasoning about model uncertainty. Our contributions in this\npaper are two fold: first, we extend PixelCNN to work with volumetric brain\nmagnetic resonance imaging data. Second, we show that reformulating this model\nto approximate a deep Gaussian process yields a measure of uncertainty that\nimproves the performance of semi-supervised learning, in particular\nclassification performance in settings where the proportion of labelled data is\nlow. We quantify this improvement across classification, regression, and\nsemantic segmentation tasks, training and testing on clinical magnetic\nresonance brain imaging data comprising T1-weighted and diffusion-weighted\nsequences.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 13:08:36 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Pombo", "Guilherme", ""], ["Gray", "Robert", ""], ["Varsavsky", "Tom", ""], ["Ashburner", "John", ""], ["Nachev", "Parashkev", ""]]}, {"id": "1907.11569", "submitter": "Anna Nguyen", "authors": "Anna Nguyen and Tobias Weller and Michael F\\\"arber and York\n  Sure-Vetter", "title": "Making Neural Networks FAIR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research on neural networks has gained significant momentum over the past few\nyears. Because training is a resource-intensive process and training data\ncannot always be made available to everyone, there has been a trend to reuse\npre-trained neural networks. As such, neural networks themselves have become\nresearch data. In this paper, we first present the neural network ontology\nFAIRnets Ontology, an ontology to make existing neural network models findable,\naccessible, interoperable, and reusable according to the FAIR principles. Our\nontology allows us to model neural networks on a meta-level in a structured\nway, including the representation of all network layers and their\ncharacteristics. Secondly, we have modeled over 18,400 neural networks from\nGitHub based on this ontology, which we provide to the public as a knowledge\ngraph called FAIRnets, ready to be used for recommending suitable neural\nnetworks to data scientists.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 13:30:02 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2020 12:32:41 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2020 21:51:37 GMT"}, {"version": "v4", "created": "Tue, 1 Dec 2020 16:02:49 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Nguyen", "Anna", ""], ["Weller", "Tobias", ""], ["F\u00e4rber", "Michael", ""], ["Sure-Vetter", "York", ""]]}, {"id": "1907.11572", "submitter": "Nathan Wycoff", "authors": "Nathan Wycoff and Mickael Binois and Stefan M. Wild", "title": "Sequential Learning of Active Subspaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, active subspace methods (ASMs) have become a popular means\nof performing subspace sensitivity analysis on black-box functions. Naively\napplied, however, ASMs require gradient evaluations of the target function. In\nthe event of noisy, expensive, or stochastic simulators, evaluating gradients\nvia finite differencing may be infeasible. In such cases, often a surrogate\nmodel is employed, on which finite differencing is performed. When the\nsurrogate model is a Gaussian process, we show that the ASM estimator is\navailable in closed form, rendering the finite-difference approximation\nunnecessary. We use our closed-form solution to develop acquisition functions\nfocused on sequential learning tailored to sensitivity analysis on top of ASMs.\nWe also show that the traditional ASM estimator may be viewed as a method of\nmoments estimator for a certain class of Gaussian processes. We demonstrate how\nuncertainty on Gaussian process hyperparameters may be propagated to\nuncertainty on the sensitivity analysis, allowing model-based confidence\nintervals on the active subspace. Our methodological developments are\nillustrated on several examples.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 13:39:23 GMT"}, {"version": "v2", "created": "Sun, 20 Sep 2020 16:14:39 GMT"}], "update_date": "2020-09-22", "authors_parsed": [["Wycoff", "Nathan", ""], ["Binois", "Mickael", ""], ["Wild", "Stefan M.", ""]]}, {"id": "1907.11584", "submitter": "Xiang Geng", "authors": "Xiang Geng, Bin Gu, Xiang Li, Wanli Shi, Guansheng Zheng and Heng\n  Huang", "title": "Scalable Semi-Supervised SVM via Triply Stochastic Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning (SSL) plays an increasingly important role in the\nbig data era because a large number of unlabeled samples can be used\neffectively to improve the performance of the classifier. Semi-supervised\nsupport vector machine (S$^3$VM) is one of the most appealing methods for SSL,\nbut scaling up S$^3$VM for kernel learning is still an open problem. Recently,\na doubly stochastic gradient (DSG) algorithm has been proposed to achieve\nefficient and scalable training for kernel methods. However, the algorithm and\ntheoretical analysis of DSG are developed based on the convexity assumption\nwhich makes them incompetent for non-convex problems such as S$^3$VM. To\naddress this problem, in this paper, we propose a triply stochastic gradient\nalgorithm for S$^3$VM, called TSGS$^3$VM. Specifically, to handle two types of\ndata instances involved in S$^3$VM, TSGS$^3$VM samples a labeled instance and\nan unlabeled instance as well with the random features in each iteration to\ncompute a triply stochastic gradient. We use the approximated gradient to\nupdate the solution. More importantly, we establish new theoretic analysis for\nTSGS$^3$VM which guarantees that TSGS$^3$VM can converge to a stationary point.\nExtensive experimental results on a variety of datasets demonstrate that\nTSGS$^3$VM is much more efficient and scalable than existing S$^3$VM\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 14:10:23 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Geng", "Xiang", ""], ["Gu", "Bin", ""], ["Li", "Xiang", ""], ["Shi", "Wanli", ""], ["Zheng", "Guansheng", ""], ["Huang", "Heng", ""]]}, {"id": "1907.11605", "submitter": "Cem Tekin", "authors": "Alihan H\\\"uy\\\"uk and Cem Tekin", "title": "Lexicographic Multiarmed Bandit", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a multiobjective multiarmed bandit problem with lexicographically\nordered objectives. In this problem, the goal of the learner is to select arms\nthat are lexicographic optimal as much as possible without knowing the arm\nreward distributions beforehand. We capture this goal by defining a\nmultidimensional form of regret that measures the loss of the learner due to\nnot selecting lexicographic optimal arms, and then, consider two settings where\nthe learner has prior information on the expected arm rewards. In the first\nsetting, the learner only knows for each objective the lexicographic optimal\nexpected reward. In the second setting, it only knows for each objective\nnear-lexicographic optimal expected rewards. For both settings we prove that\nthe learner achieves expected regret uniformly bounded in time. The algorithm\nwe propose for the second setting also attains bounded regret for the\nmultiarmed bandit with satisficing objectives. In addition, we also consider\nthe harder prior-free case, and show that the learner can still achieve\nsublinear in time gap-free regret. Finally, we experimentally evaluate\nperformance of the proposed algorithms in a variety of multiobjective learning\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 14:48:07 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 10:52:11 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["H\u00fcy\u00fck", "Alihan", ""], ["Tekin", "Cem", ""]]}, {"id": "1907.11612", "submitter": "Ido Hakimi", "authors": "Ido Hakimi, Saar Barkai, Moshe Gabel, Assaf Schuster", "title": "Taming Momentum in a Distributed Asynchronous Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although distributed computing can significantly reduce the training time of\ndeep neural networks, scaling the training process while maintaining high\nefficiency and final accuracy is challenging. Distributed asynchronous training\nenjoys near-linear speedup, but asynchrony causes gradient staleness - the main\ndifficulty in scaling stochastic gradient descent to large clusters. Momentum,\nwhich is often used to accelerate convergence and escape local minima,\nexacerbates the gradient staleness, thereby hindering convergence. We propose\nDANA: a novel technique for asynchronous distributed SGD with momentum that\nmitigates gradient staleness by computing the gradient on an estimated future\nposition of the model's parameters. Thereby, we show for the first time that\nmomentum can be fully incorporated in asynchronous training with almost no\nramifications to final accuracy. Our evaluation on the CIFAR and ImageNet\ndatasets shows that DANA outperforms existing methods, in both final accuracy\nand convergence speed while scaling up to a total batch size of 16K on 64\nasynchronous workers.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 15:07:49 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 15:23:20 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 06:09:35 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Hakimi", "Ido", ""], ["Barkai", "Saar", ""], ["Gabel", "Moshe", ""], ["Schuster", "Assaf", ""]]}, {"id": "1907.11629", "submitter": "Stefano B. Blumberg", "authors": "Stefano B. Blumberg, Marco Palombo, Can Son Khoo, Chantal M. W. Tax,\n  Ryutaro Tanno, and Daniel C. Alexander", "title": "Multi-Stage Prediction Networks for Data Harmonization", "comments": "Accepted In Medical Image Computing and Computer Assisted\n  Intervention (MICCAI) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce multi-task learning (MTL) to data harmonization\n(DH); where we aim to harmonize images across different acquisition platforms\nand sites. This allows us to integrate information from multiple acquisitions\nand improve the predictive performance and learning efficiency of the\nharmonization model. Specifically, we introduce the Multi Stage Prediction\n(MSP) Network, a MTL framework that incorporates neural networks of potentially\ndisparate architectures, trained for different individual acquisition\nplatforms, into a larger architecture that is refined in unison. The MSP\nutilizes high-level features of single networks for individual tasks, as inputs\nof additional neural networks to inform the final prediction, therefore\nexploiting redundancy across tasks to make the most of limited training data.\nWe validate our methods on a dMRI harmonization challenge dataset, where we\npredict three modern platform types, from one obtained from an old scanner. We\nshow how MTL architectures, such as the MSP, produce around 20\\% improvement of\npatch-based mean-squared error over current state-of-the-art methods and that\nour MSP outperforms off-the-shelf MTL networks. Our code is available\nhttps://github.com/sbb-gh/ .\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 15:29:46 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Blumberg", "Stefano B.", ""], ["Palombo", "Marco", ""], ["Khoo", "Can Son", ""], ["Tax", "Chantal M. W.", ""], ["Tanno", "Ryutaro", ""], ["Alexander", "Daniel C.", ""]]}, {"id": "1907.11634", "submitter": "Ke Ren", "authors": "Ke Ren and Avinash Malik", "title": "Recommendation Engine for Lower Interest Borrowing on Peer to Peer\n  Lending (P2PL) Platform", "comments": "Accepted in Web intelligence 2019, this is a long version", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online Peer to Peer Lending (P2PL) systems connect lenders and borrowers\ndirectly, thereby making it convenient to borrow and lend money without\nintermediaries such as banks. Many recommendation systems have been developed\nfor lenders to achieve higher interest rates and avoid defaulting loans.\nHowever, there has not been much research in developing recommendation systems\nto help borrowers make wise decisions. On P2PL platforms, borrowers can either\napply for bidding loans, where the interest rate is determined by lenders\nbidding on a loan or traditional loans where the P2PL platform determines the\ninterest rate. Different borrower grades -- determining the credit worthiness\nof borrowers get different interest rates via these two mechanisms. Hence, it\nis essential to determine which type of loans borrowers should apply for. In\nthis paper, we build a recommendation system that recommends to any new\nborrower the type of loan they should apply for. Using our recommendation\nsystem, any borrower can achieve lowered interest rates with a higher\nlikelihood of getting funded.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 06:26:47 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Ren", "Ke", ""], ["Malik", "Avinash", ""]]}, {"id": "1907.11635", "submitter": "Alexander Wein", "authors": "Yunzi Ding, Dmitriy Kunisky, Alexander S. Wein, Afonso S. Bandeira", "title": "Subexponential-Time Algorithms for Sparse PCA", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.DS stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational cost of recovering a unit-norm sparse principal\ncomponent $x \\in \\mathbb{R}^n$ planted in a random matrix, in either the Wigner\nor Wishart spiked model (observing either $W + \\lambda xx^\\top$ with $W$ drawn\nfrom the Gaussian orthogonal ensemble, or $N$ independent samples from\n$\\mathcal{N}(0, I_n + \\beta xx^\\top)$, respectively). Prior work has shown that\nwhen the signal-to-noise ratio ($\\lambda$ or $\\beta\\sqrt{N/n}$, respectively)\nis a small constant and the fraction of nonzero entries in the planted vector\nis $\\|x\\|_0 / n = \\rho$, it is possible to recover $x$ in polynomial time if\n$\\rho \\lesssim 1/\\sqrt{n}$. While it is possible to recover $x$ in exponential\ntime under the weaker condition $\\rho \\ll 1$, it is believed that\npolynomial-time recovery is impossible unless $\\rho \\lesssim 1/\\sqrt{n}$. We\ninvestigate the precise amount of time required for recovery in the \"possible\nbut hard\" regime $1/\\sqrt{n} \\ll \\rho \\ll 1$ by exploring the power of\nsubexponential-time algorithms, i.e., algorithms running in time\n$\\exp(n^\\delta)$ for some constant $\\delta \\in (0,1)$. For any $1/\\sqrt{n} \\ll\n\\rho \\ll 1$, we give a recovery algorithm with runtime roughly $\\exp(\\rho^2\nn)$, demonstrating a smooth tradeoff between sparsity and runtime. Our family\nof algorithms interpolates smoothly between two existing algorithms: the\npolynomial-time diagonal thresholding algorithm and the $\\exp(\\rho n)$-time\nexhaustive search algorithm. Furthermore, by analyzing the low-degree\nlikelihood ratio, we give rigorous evidence suggesting that the tradeoff\nachieved by our algorithms is optimal.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 15:45:13 GMT"}, {"version": "v2", "created": "Mon, 2 Mar 2020 02:24:47 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Ding", "Yunzi", ""], ["Kunisky", "Dmitriy", ""], ["Wein", "Alexander S.", ""], ["Bandeira", "Afonso S.", ""]]}, {"id": "1907.11636", "submitter": "Alexander Wein", "authors": "Dmitriy Kunisky, Alexander S. Wein, Afonso S. Bandeira", "title": "Notes on Computational Hardness of Hypothesis Testing: Predictions using\n  the Low-Degree Likelihood Ratio", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC cs.DS stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These notes survey and explore an emerging method, which we call the\nlow-degree method, for predicting and understanding\nstatistical-versus-computational tradeoffs in high-dimensional inference\nproblems. In short, the method posits that a certain quantity -- the second\nmoment of the low-degree likelihood ratio -- gives insight into how much\ncomputational time is required to solve a given hypothesis testing problem,\nwhich can in turn be used to predict the computational hardness of a variety of\nstatistical inference tasks. While this method originated in the study of the\nsum-of-squares (SoS) hierarchy of convex programs, we present a self-contained\nintroduction that does not require knowledge of SoS. In addition to showing how\nto carry out predictions using the method, we include a discussion\ninvestigating both rigorous and conjectural consequences of these predictions.\n  These notes include some new results, simplified proofs, and refined\nconjectures. For instance, we point out a formal connection between spectral\nmethods and the low-degree likelihood ratio, and we give a sharp low-degree\nlower bound against subexponential-time algorithms for tensor PCA.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 15:46:05 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Kunisky", "Dmitriy", ""], ["Wein", "Alexander S.", ""], ["Bandeira", "Afonso S.", ""]]}, {"id": "1907.11639", "submitter": "Michael Hauser", "authors": "Michael Hauser", "title": "Training capsules as a routing-weighted product of expert neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsules are the multidimensional analogue to scalar neurons in neural\nnetworks, and because they are multidimensional, much more complex routing\nschemes can be used to pass information forward through the network than what\ncan be used in traditional neural networks. This work treats capsules as\ncollections of neurons in a fully connected neural network, where sub-networks\nconnecting capsules are weighted according to the routing coefficients\ndetermined by routing by agreement. An energy function is designed to reflect\nthis model, and it follows that capsule networks with dynamic routing can be\nformulated as a product of expert neurons. By alternating between dynamic\nrouting, which acts to both find subnetworks within the overall network as well\nas to mix the model distribution, and updating the parameters by the gradient\nof the contrastive divergence, a bottom-up, unsupervised learning algorithm is\nconstructed for capsule networks with dynamic routing. The model and its\ntraining algorithm are qualitatively tested in the generative sense, and is\nable to produce realistic looking images from standard vision datasets.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 15:51:49 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Hauser", "Michael", ""]]}, {"id": "1907.11643", "submitter": "Michael Hauser", "authors": "Michael Hauser", "title": "Training products of expert capsules with mixing by dynamic routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study develops an unsupervised learning algorithm for products of expert\ncapsules with dynamic routing. Analogous to binary-valued neurons in Restricted\nBoltzmann Machines, the magnitude of a squashed capsule firing takes values\nbetween zero and one, representing the probability of the capsule being on.\nThis analogy motivates the design of an energy function for capsule networks.\nIn order to have an efficient sampling procedure where hidden layer nodes are\nnot connected, the energy function is made consistent with dynamic routing in\nthe sense of the probability of a capsule firing, and inference on the capsule\nnetwork is computed with the dynamic routing between capsules procedure. In\norder to optimize the log-likelihood of the visible layer capsules, the\ngradient is found in terms of this energy function. The developed unsupervised\nlearning algorithm is used to train a capsule network on standard vision\ndatasets, and is able to generate realistic looking images from its learned\ndistribution.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 15:58:56 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Hauser", "Michael", ""]]}, {"id": "1907.11651", "submitter": "Mohsen Rakhshandehroo", "authors": "Mohsen Rakhshandehroo, Mohammad Rajabdorri", "title": "Time Series Analysis of Electricity Price and Demand to Find\n  Cyber-attacks using Stationary Analysis", "comments": "9pages, 13 figs, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CR cs.DB cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With developing of computation tools in the last years, data analysis methods\nto find insightful information are becoming more common among industries and\nresearchers. This paper is the first part of the times series analysis of New\nEngland electricity price and demand to find anomaly in the data. In this paper\ntime-series stationary criteria to prepare data for further times-series\nrelated analysis is investigated. Three main analysis are conducted in this\npaper, including moving average, moving standard deviation and augmented\nDickey-Fuller test. The data used in this paper is New England big data from 9\ndifferent operational zones. For each zone, 4 different variables including\nday-ahead (DA) electricity demand, price and real-time (RT) electricity demand\nprice are considered.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 18:11:05 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 15:15:11 GMT"}, {"version": "v3", "created": "Sun, 29 Sep 2019 19:21:14 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Rakhshandehroo", "Mohsen", ""], ["Rajabdorri", "Mohammad", ""]]}, {"id": "1907.11703", "submitter": "Pablo Hernandez-Leal", "authors": "Bilal Kartal, Pablo Hernandez-Leal and Matthew E. Taylor", "title": "Action Guidance with MCTS for Deep Reinforcement Learning", "comments": "AAAI Conference on Artificial Intelligence and Interactive Digital\n  Entertainment (AIIDE'19). arXiv admin note: substantial text overlap with\n  arXiv:1904.05759, arXiv:1812.00045", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has achieved great successes in recent years,\nhowever, one main challenge is the sample inefficiency. In this paper, we focus\non how to use action guidance by means of a non-expert demonstrator to improve\nsample efficiency in a domain with sparse, delayed, and possibly deceptive\nrewards: the recently-proposed multi-agent benchmark of Pommerman. We propose a\nnew framework where even a non-expert simulated demonstrator, e.g., planning\nalgorithms such as Monte Carlo tree search with a small number rollouts, can be\nintegrated within asynchronous distributed deep reinforcement learning methods.\nCompared to a vanilla deep RL algorithm, our proposed methods both learn faster\nand converge to better policies on a two-player mini version of the Pommerman\ngame.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 19:19:42 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Kartal", "Bilal", ""], ["Hernandez-Leal", "Pablo", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1907.11711", "submitter": "Jing Cheng", "authors": "Dong Liang, Jing Cheng, Ziwen Ke, Leslie Ying", "title": "Deep MRI Reconstruction: Unrolled Optimization Algorithms Meet Neural\n  Networks", "comments": "a review paper on deep learning MR reconstruction", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG eess.SP physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image reconstruction from undersampled k-space data has been playing an\nimportant role for fast MRI. Recently, deep learning has demonstrated\ntremendous success in various fields and also shown potential to significantly\nspeed up MR reconstruction with reduced measurements. This article gives an\noverview of deep learning-based image reconstruction methods for MRI. Three\ntypes of deep learning-based approaches are reviewed, the data-driven,\nmodel-driven and integrated approaches. The main structure of each network in\nthree approaches is explained and the analysis of common parts of reviewed\nnetworks and differences in-between are highlighted. Based on the review, a\nnumber of signal processing issues are discussed for maximizing the potential\nof deep reconstruction for fast MRI. the discussion may facilitate further\ndevelopment of \"optimal\" network and performance analysis from a theoretical\npoint of view.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 08:22:53 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Liang", "Dong", ""], ["Cheng", "Jing", ""], ["Ke", "Ziwen", ""], ["Ying", "Leslie", ""]]}, {"id": "1907.11739", "submitter": "Sayan Ghosh", "authors": "Sayan Ghosh, Jesper Kristensen, Yiming Zhang, Waad Subber, Liping Wang", "title": "A Strategy for Adaptive Sampling of Multi-fidelity Gaussian Process to\n  Reduce Predictive Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-fidelity Gaussian process is a common approach to address the extensive\ncomputationally demanding algorithms such as optimization, calibration and\nuncertainty quantification. Adaptive sampling for multi-fidelity Gaussian\nprocess is a changing task due to the fact that not only we seek to estimate\nthe next sampling location of the design variable, but also the level of the\nsimulator fidelity. This issue is often addressed by including the cost of the\nsimulator as an another factor in the searching criterion in conjunction with\nthe uncertainty reduction metric. In this work, we extent the traditional\ndesign of experiment framework for the multi-fidelity Gaussian process by\npartitioning the prediction uncertainty based on the fidelity level and the\nassociated cost of execution. In addition, we utilize the concept of Believer\nwhich quantifies the effect of adding an exploratory design point on the\nGaussian process uncertainty prediction. We demonstrated our framework using\nacademic examples as well as a industrial application of steady-state\nthermodynamic operation point of a fluidized bed process\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 18:17:45 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Ghosh", "Sayan", ""], ["Kristensen", "Jesper", ""], ["Zhang", "Yiming", ""], ["Subber", "Waad", ""], ["Wang", "Liping", ""]]}, {"id": "1907.11746", "submitter": "Denali Molitor", "authors": "Denali Molitor, Deanna Needell, Rachel Ward", "title": "Bias of Homotopic Gradient Descent for the Hinge Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient descent is a simple and widely used optimization method for machine\nlearning. For homogeneous linear classifiers applied to separable data,\ngradient descent has been shown to converge to the maximal margin (or\nequivalently, the minimal norm) solution for various smooth loss functions. The\nprevious theory does not, however, apply to non-smooth functions such as the\nhinge loss which is widely used in practice. Here, we study the convergence of\na homotopic variant of gradient descent applied to the hinge loss and provide\nexplicit convergence rates to the max-margin solution for linearly separable\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 18:38:44 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Molitor", "Denali", ""], ["Needell", "Deanna", ""], ["Ward", "Rachel", ""]]}, {"id": "1907.11754", "submitter": "Jiasheng Zhang", "authors": "Jason (Jiasheng) Zhang, Junming Yin, Dongwon Lee, Linhong Zhu", "title": "Deep Reinforcement Learning for Personalized Search Story Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, \\emph{search story}, a combined display with other organic\nchannels, has become a major source of user traffic on platforms such as\ne-commerce search platforms, news feed platforms and web and image search\nplatforms. The recommended search story guides a user to identify her own\npreference and personal intent, which subsequently influences the user's\nreal-time and long-term search behavior. %With such an increased importance of\nsearch stories, As search stories become increasingly important, in this work,\nwe study the problem of personalized search story recommendation within a\nsearch engine, which aims to suggest a search story relevant to both a search\nkeyword and an individual user's interest. To address the challenge of modeling\nboth immediate and future values of recommended search stories (i.e.,\ncross-channel effect), for which conventional supervised learning framework is\nnot applicable, we resort to a Markov decision process and propose a deep\nreinforcement learning architecture trained by both imitation learning and\nreinforcement learning. We empirically demonstrate the effectiveness of our\nproposed approach through extensive experiments on real-world data sets from\nJD.com.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 19:01:48 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Jason", "", "", "Jiasheng"], ["Zhang", "", ""], ["Yin", "Junming", ""], ["Lee", "Dongwon", ""], ["Zhu", "Linhong", ""]]}, {"id": "1907.11778", "submitter": "Yingshui Tan", "authors": "Baihong Jin and Yingshui Tan and Alexander Nettekoven and Yuxin Chen\n  and Ufuk Topcu and Yisong Yue and Alberto Sangiovanni Vincentelli", "title": "An Encoder-Decoder Based Approach for Anomaly Detection with Application\n  in Additive Manufacturing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel unsupervised deep learning approach that utilizes the\nencoder-decoder architecture for detecting anomalies in sequential sensor data\ncollected during industrial manufacturing. Our approach is designed not only to\ndetect whether there exists an anomaly at a given time step, but also to\npredict what will happen next in the (sequential) process. We demonstrate our\napproach on a dataset collected from a real-world testbed. The dataset contains\nimages collected under both normal conditions and synthetic anomalies. We show\nthat the encoder-decoder model is able to identify the injected anomalies in a\nmodern manufacturing process in an unsupervised fashion. In addition, it also\ngives hints about the temperature non-uniformity of the testbed during\nmanufacturing, which is what we are not aware of before doing the experiment.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 20:03:26 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Jin", "Baihong", ""], ["Tan", "Yingshui", ""], ["Nettekoven", "Alexander", ""], ["Chen", "Yuxin", ""], ["Topcu", "Ufuk", ""], ["Yue", "Yisong", ""], ["Vincentelli", "Alberto Sangiovanni", ""]]}, {"id": "1907.11780", "submitter": "Kaiwen Wu", "authors": "Kaiwen Wu and Yaoliang Yu", "title": "Understanding Adversarial Robustness: The Trade-off between Minimum and\n  Average Margin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep models, while being extremely versatile and accurate, are vulnerable to\nadversarial attacks: slight perturbations that are imperceptible to humans can\ncompletely flip the prediction of deep models. Many attack and defense\nmechanisms have been proposed, although a satisfying solution still largely\nremains elusive. In this work, we give strong evidence that during training,\ndeep models maximize the minimum margin in order to achieve high accuracy, but\nat the same time decrease the \\emph{average} margin hence hurting robustness.\nOur empirical results highlight an intrinsic trade-off between accuracy and\nrobustness for current deep model training. To further address this issue, we\npropose a new regularizer to explicitly promote average margin, and we verify\nthrough extensive experiments that it does lead to better robustness. Our\nregularized objective remains Fisher-consistent, hence asymptotically can still\nrecover the Bayes optimal classifier.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 20:05:19 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Wu", "Kaiwen", ""], ["Yu", "Yaoliang", ""]]}, {"id": "1907.11788", "submitter": "Pablo Hernandez-Leal", "authors": "Chao Gao, Bilal Kartal, Pablo Hernandez-Leal and Matthew E. Taylor", "title": "On Hard Exploration for Reinforcement Learning: a Case Study in\n  Pommerman", "comments": "AAAI Conference on Artificial Intelligence and Interactive Digital\n  Entertainment (AIIDE) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to best explore in domains with sparse, delayed, and deceptive rewards is\nan important open problem for reinforcement learning (RL). This paper considers\none such domain, the recently-proposed multi-agent benchmark of Pommerman. This\ndomain is very challenging for RL --- past work has shown that model-free RL\nalgorithms fail to achieve significant learning without artificially reducing\nthe environment's complexity. In this paper, we illuminate reasons behind this\nfailure by providing a thorough analysis on the hardness of random exploration\nin Pommerman. While model-free random exploration is typically futile, we\ndevelop a model-based automatic reasoning module that can be used for safer\nexploration by pruning actions that will surely lead the agent to death. We\nempirically demonstrate that this module can significantly improve learning.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 20:36:09 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Gao", "Chao", ""], ["Kartal", "Bilal", ""], ["Hernandez-Leal", "Pablo", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1907.11792", "submitter": "Marcell Vazquez-Chanlatte", "authors": "Marcell Vazquez-Chanlatte, Sanjit A. Seshia", "title": "Maximum Causal Entropy Specification Inference from Demonstrations", "comments": "Computer Aided Verification, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many settings (e.g., robotics) demonstrations provide a natural way to\nspecify tasks; however, most methods for learning from demonstrations either do\nnot provide guarantees that the artifacts learned for the tasks, such as\nrewards or policies, can be safely composed and/or do not explicitly capture\nhistory dependencies. Motivated by this deficit, recent works have proposed\nlearning Boolean task specifications, a class of Boolean non-Markovian rewards\nwhich admit well-defined composition and explicitly handle historical\ndependencies. This work continues this line of research by adapting maximum\ncausal entropy inverse reinforcement learning to estimate the posteriori\nprobability of a specification given a multi-set of demonstrations. The key\nalgorithmic insight is to leverage the extensive literature and tooling on\nreduced ordered binary decision diagrams to efficiently encode a time unrolled\nMarkov Decision Process. This enables transforming a naive exponential time\nalgorithm into a polynomial time algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 21:03:53 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 02:08:37 GMT"}, {"version": "v3", "created": "Mon, 13 Jan 2020 22:38:12 GMT"}, {"version": "v4", "created": "Sat, 15 Feb 2020 01:02:41 GMT"}, {"version": "v5", "created": "Sat, 16 May 2020 18:55:44 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Vazquez-Chanlatte", "Marcell", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1907.11804", "submitter": "Kartikeya Bhardwaj", "authors": "Kartikeya Bhardwaj, Chingyi Lin, Anderson Sartor, Radu Marculescu", "title": "Memory- and Communication-Aware Model Compression for Distributed Deep\n  Learning Inference on IoT", "comments": "This preprint is for personal use only. The official article will\n  appear as part of the ESWEEK-TECS special issue and will be presented in the\n  International Conference on Hardware/Software Codesign and System Synthesis\n  (CODES+ISSS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model compression has emerged as an important area of research for deploying\ndeep learning models on Internet-of-Things (IoT). However, for extremely\nmemory-constrained scenarios, even the compressed models cannot fit within the\nmemory of a single device and, as a result, must be distributed across multiple\ndevices. This leads to a distributed inference paradigm in which memory and\ncommunication costs represent a major bottleneck. Yet, existing model\ncompression techniques are not communication-aware. Therefore, we propose\nNetwork of Neural Networks (NoNN), a new distributed IoT learning paradigm that\ncompresses a large pretrained 'teacher' deep network into several disjoint and\nhighly-compressed 'student' modules, without loss of accuracy. Moreover, we\npropose a network science-based knowledge partitioning algorithm for the\nteacher model, and then train individual students on the resulting disjoint\npartitions. Extensive experimentation on five image classification datasets,\nfor user-defined memory/performance budgets, show that NoNN achieves higher\naccuracy than several baselines and similar accuracy as the teacher model,\nwhile using minimal communication among students. Finally, as a case study, we\ndeploy the proposed model for CIFAR-10 dataset on edge devices and demonstrate\nsignificant improvements in memory footprint (up to 24x), performance (up to\n12x), and energy per node (up to 14x) compared to the large teacher model. We\nfurther show that for distributed inference on multiple edge devices, our\nproposed NoNN model results in up to 33x reduction in total latency w.r.t. a\nstate-of-the-art model compression baseline.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 22:17:42 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Bhardwaj", "Kartikeya", ""], ["Lin", "Chingyi", ""], ["Sartor", "Anderson", ""], ["Marculescu", "Radu", ""]]}, {"id": "1907.11806", "submitter": "Harish S. Bhat", "authors": "Harish S. Bhat", "title": "Learning and Interpreting Potentials for Classical Hamiltonian Systems", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.DS physics.class-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning an interpretable potential energy\nfunction from a Hamiltonian system's trajectories. We address this problem for\nclassical, separable Hamiltonian systems. Our approach first constructs a\nneural network model of the potential and then applies an equation discovery\ntechnique to extract from the neural potential a closed-form algebraic\nexpression. We demonstrate this approach for several systems, including\noscillators, a central force problem, and a problem of two charged particles in\na classical Coulomb potential. Through these test problems, we show close\nagreement between learned neural potentials, the interpreted potentials we\nobtain after training, and the ground truth. In particular, for the central\nforce problem, we show that our approach learns the correct effective\npotential, a reduced-order model of the system.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 22:32:12 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Bhat", "Harish S.", ""]]}, {"id": "1907.11815", "submitter": "Matthew Middlehurst", "authors": "Matthew Middlehurst, William Vickers and Anthony Bagnall", "title": "Scalable Dictionary Classifiers for Time Series Classification", "comments": null, "journal-ref": "In proceedings of Intelligent Data Engineering and Automated\n  Learning, pages 11-19. 2019", "doi": "10.1007/978-3-030-33607-3_2", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionary based classifiers are a family of algorithms for time series\nclassification (TSC), that focus on capturing the frequency of pattern\noccurrences in a time series. The ensemble based Bag of Symbolic Fourier\nApproximation Symbols (BOSS) was found to be a top performing TSC algorithm in\na recent evaluation, as well as the best performing dictionary based\nclassifier. A recent addition to the category, the Word Extraction for Time\nSeries Classification (WEASEL), claims an improvement on this performance. Both\nof these algorithms however have non-trivial scalability issues, taking a\nconsiderable amount of build time and space on larger datasets. We evaluate\nchanges to the way BOSS chooses classifiers for its ensemble, replacing its\nparameter search with random selection. This change allows for the easy\nimplementation of contracting, setting a build time limit for the classifier\nand check-pointing, saving progress during the classifiers build. To\ndifferentiate between the two BOSS ensemble methods we refer to our randomised\nversion as RBOSS. Additionally we test the application of common ensembling\ntechniques to help retain accuracy from the loss of the BOSS parameter search.\nWe achieve a significant reduction in build time without a significant change\nin accuracy on average when compared to BOSS by creating a size $n$ weighted\nensemble selecting the best performers from $k$ randomly chosen parameter sets.\nOur experiments are conducted on datasets from the recently expanded UCR time\nseries archive. We demonstrate the usability improvements to RBOSS with a case\nstudy using a large whale acoustics dataset for which BOSS proved infeasible.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 23:13:46 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Middlehurst", "Matthew", ""], ["Vickers", "William", ""], ["Bagnall", "Anthony", ""]]}, {"id": "1907.11826", "submitter": "Kush Bhatia", "authors": "Kush Bhatia, Yi-An Ma, Anca D. Dragan, Peter L. Bartlett, Michael I.\n  Jordan", "title": "Bayesian Robustness: A Nonasymptotic Viewpoint", "comments": "30 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of robustly estimating the posterior distribution for\nthe setting where observed data can be contaminated with potentially\nadversarial outliers. We propose Rob-ULA, a robust variant of the Unadjusted\nLangevin Algorithm (ULA), and provide a finite-sample analysis of its sampling\ndistribution. In particular, we show that after $T=\n\\tilde{\\mathcal{O}}(d/\\varepsilon_{\\textsf{acc}})$ iterations, we can sample\nfrom $p_T$ such that $\\text{dist}(p_T, p^*) \\leq \\varepsilon_{\\textsf{acc}} +\n\\tilde{\\mathcal{O}}(\\epsilon)$, where $\\epsilon$ is the fraction of\ncorruptions. We corroborate our theoretical analysis with experiments on both\nsynthetic and real-world data sets for mean estimation, regression and binary\nclassification.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 01:42:29 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Bhatia", "Kush", ""], ["Ma", "Yi-An", ""], ["Dragan", "Anca D.", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1907.11857", "submitter": "Yi Zhang", "authors": "Yi Zhang, Cheng Zeng, Hao Cheng, Chongjun Wang, Lei Zhang", "title": "Many could be better than all: A novel instance-oriented algorithm for\n  Multi-modal Multi-label problem", "comments": "To be published in ICME 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With the emergence of diverse data collection techniques, objects in real\napplications can be represented as multi-modal features. What's more, objects\nmay have multiple semantic meanings. Multi-modal and Multi-label (MMML) problem\nbecomes a universal phenomenon. The quality of data collected from different\nchannels are inconsistent and some of them may not benefit for prediction. In\nreal life, not all the modalities are needed for prediction. As a result, we\npropose a novel instance-oriented Multi-modal Classifier Chains (MCC) algorithm\nfor MMML problem, which can make convince prediction with partial modalities.\nMCC extracts different modalities for different instances in the testing phase.\nExtensive experiments are performed on one real-world herbs dataset and two\npublic datasets to validate our proposed algorithm, which reveals that it may\nbe better to extract many instead of all of the modalities at hand.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 06:55:24 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Zhang", "Yi", ""], ["Zeng", "Cheng", ""], ["Cheng", "Hao", ""], ["Wang", "Chongjun", ""], ["Zhang", "Lei", ""]]}, {"id": "1907.11864", "submitter": "Cuong Nguyen", "authors": "Cuong Nguyen, Thanh-Toan Do, Gustavo Carneiro", "title": "Uncertainty in Model-Agnostic Meta-Learning using Variational Inference", "comments": "Revise Experiments by adding regression quantile calibration and\n  re-running classification calibration under the same setting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new, rigorously-formulated Bayesian meta-learning algorithm\nthat learns a probability distribution of model parameter prior for few-shot\nlearning. The proposed algorithm employs a gradient-based variational inference\nto infer the posterior of model parameters to a new task. Our algorithm can be\napplied to any model architecture and can be implemented in various machine\nlearning paradigms, including regression and classification. We show that the\nmodels trained with our proposed meta-learning algorithm are well calibrated\nand accurate, with state-of-the-art calibration and classification results on\ntwo few-shot classification benchmarks (Omniglot and Mini-ImageNet), and\ncompetitive results in a multi-modal task-distribution regression.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 07:18:50 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 04:32:23 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Nguyen", "Cuong", ""], ["Do", "Thanh-Toan", ""], ["Carneiro", "Gustavo", ""]]}, {"id": "1907.11879", "submitter": "Aaqib Saeed", "authors": "Aaqib Saeed, Tanir Ozcelebi, Johan Lukkien", "title": "Multi-task Self-Supervised Learning for Human Activity Detection", "comments": null, "journal-ref": null, "doi": "10.1145/3328932", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning methods are successfully used in applications pertaining to\nubiquitous computing, health, and well-being. Specifically, the area of human\nactivity recognition (HAR) is primarily transformed by the convolutional and\nrecurrent neural networks, thanks to their ability to learn semantic\nrepresentations from raw input. However, to extract generalizable features,\nmassive amounts of well-curated data are required, which is a notoriously\nchallenging task; hindered by privacy issues, and annotation costs. Therefore,\nunsupervised representation learning is of prime importance to leverage the\nvast amount of unlabeled data produced by smart devices. In this work, we\npropose a novel self-supervised technique for feature learning from sensory\ndata that does not require access to any form of semantic labels. We learn a\nmulti-task temporal convolutional network to recognize transformations applied\non an input signal. By exploiting these transformations, we demonstrate that\nsimple auxiliary tasks of the binary classification result in a strong\nsupervisory signal for extracting useful features for the downstream task. We\nextensively evaluate the proposed approach on several publicly available\ndatasets for smartphone-based HAR in unsupervised, semi-supervised, and\ntransfer learning settings. Our method achieves performance levels superior to\nor comparable with fully-supervised networks, and it performs significantly\nbetter than autoencoders. Notably, for the semi-supervised case, the\nself-supervised features substantially boost the detection rate by attaining a\nkappa score between 0.7-0.8 with only 10 labeled examples per class. We get\nsimilar impressive performance even if the features are transferred from a\ndifferent data source. While this paper focuses on HAR as the application\ndomain, the proposed technique is general and could be applied to a wide\nvariety of problems in other areas.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 09:14:43 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Saeed", "Aaqib", ""], ["Ozcelebi", "Tanir", ""], ["Lukkien", "Johan", ""]]}, {"id": "1907.11881", "submitter": "Satyajit Neogi", "authors": "Satyajit Neogi, Michael Hoy, Kang Dang, Hang Yu and Justin Dauwels", "title": "Context Model for Pedestrian Intention Prediction using Factored\n  Latent-Dynamic Conditional Random Fields", "comments": "Accepted by IEEE Transactions on Intelligent Transportation Systems", "journal-ref": null, "doi": "10.1109/TITS.2020.2995166", "report-no": null, "categories": "cs.CV cs.RO eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smooth handling of pedestrian interactions is a key requirement for\nAutonomous Vehicles (AV) and Advanced Driver Assistance Systems (ADAS). Such\nsystems call for early and accurate prediction of a pedestrian's\ncrossing/not-crossing behaviour in front of the vehicle. Existing approaches to\npedestrian behaviour prediction make use of pedestrian motion, his/her location\nin a scene and static context variables such as traffic lights, zebra crossings\netc. We stress on the necessity of early prediction for smooth operation of\nsuch systems. We introduce the influence of vehicle interactions on pedestrian\nintention for this purpose. In this paper, we show a discernible advance in\nprediction time aided by the inclusion of such vehicle interaction context. We\napply our methods to two different datasets, one in-house collected - NTU\ndataset and another public real-life benchmark - JAAD dataset. We also propose\na generic graphical model Factored Latent-Dynamic Conditional Random Fields\n(FLDCRF) for single and multi-label sequence prediction as well as joint\ninteraction modeling tasks. FLDCRF outperforms Long Short-Term Memory (LSTM)\nnetworks across the datasets ($\\sim$100 sequences per dataset) over identical\ntime-series features. While the existing best system predicts pedestrian\nstopping behaviour with 70\\% accuracy 0.38 seconds before the actual events,\nour system achieves such accuracy at least 0.9 seconds on an average before the\nactual events across datasets.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 09:34:12 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2019 16:51:20 GMT"}, {"version": "v3", "created": "Tue, 7 Jul 2020 10:24:04 GMT"}, {"version": "v4", "created": "Tue, 15 Sep 2020 11:19:23 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Neogi", "Satyajit", ""], ["Hoy", "Michael", ""], ["Dang", "Kang", ""], ["Yu", "Hang", ""], ["Dauwels", "Justin", ""]]}, {"id": "1907.11891", "submitter": "Mingtian Zhang", "authors": "Mingtian Zhang, Thomas Bird, Raza Habib, Tianlin Xu, David Barber", "title": "Variational f-divergence Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic models are often trained by maximum likelihood, which\ncorresponds to minimizing a specific f-divergence between the model and data\ndistribution. In light of recent successes in training Generative Adversarial\nNetworks, alternative non-likelihood training criteria have been proposed.\nWhilst not necessarily statistically efficient, these alternatives may better\nmatch user requirements such as sharp image generation. A general variational\nmethod for training probabilistic latent variable models using maximum\nlikelihood is well established; however, how to train latent variable models\nusing other f-divergences is comparatively unknown. We discuss a variational\napproach that, when combined with the recently introduced Spread Divergence,\ncan be applied to train a large class of latent variable models using any\nf-divergence.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 10:32:08 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Zhang", "Mingtian", ""], ["Bird", "Thomas", ""], ["Habib", "Raza", ""], ["Xu", "Tianlin", ""], ["Barber", "David", ""]]}, {"id": "1907.11911", "submitter": "Cheng Qian", "authors": "Cheng Qian, Amin Emad, and Nicholas D. Sidiropoulos", "title": "REP: Predicting the Time-Course of Drug Sensitivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The biological processes involved in a drug's mechanisms of action are\noftentimes dynamic, complex and difficult to discern. Time-course gene\nexpression data is a rich source of information that can be used to unravel\nthese complex processes, identify biomarkers of drug sensitivity and predict\nthe response to a drug. However, the majority of previous work has not fully\nutilized this temporal dimension. In these studies, the gene expression data is\neither considered at one time-point (before the administration of the drug) or\ntwo timepoints (before and after the administration of the drug). This is\nclearly inadequate in modeling dynamic gene-drug interactions, especially for\napplications such as long-term drug therapy.\n  In this work, we present a novel REcursive Prediction (REP) framework for\ndrug response prediction by taking advantage of time-course gene expression\ndata. Our goal is to predict drug response values at every stage of a long-term\ntreatment, given the expression levels of genes collected in the previous\ntime-points. To this end, REP employs a built-in recursive structure that\nexploits the intrinsic time-course nature of the data and integrates past\nvalues of drug responses for subsequent predictions. It also incorporates\ntensor completion that can not only alleviate the impact of noise and missing\ndata, but also predict unseen gene expression levels (GELs). These advantages\nenable REP to estimate drug response at any stage of a given treatment from\nsome GELs measured in the beginning of the treatment. Extensive experiments on\na dataset corresponding to 53 multiple sclerosis patients treated with\ninterferon are included to showcase the effectiveness of REP.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 13:49:40 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Qian", "Cheng", ""], ["Emad", "Amin", ""], ["Sidiropoulos", "Nicholas D.", ""]]}, {"id": "1907.11943", "submitter": "Guangcong Wang", "authors": "Guangcong Wang and Jianhuang Lai and Wenqi Liang and Guangrun Wang", "title": "Learnable Parameter Similarity", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing approaches focus on specific visual tasks while ignoring\nthe relations between them. Estimating task relation sheds light on the\nlearning of high-order semantic concepts, e.g., transfer learning. How to\nreveal the underlying relations between different visual tasks remains largely\nunexplored. In this paper, we propose a novel \\textbf{L}earnable\n\\textbf{P}arameter \\textbf{S}imilarity (\\textbf{LPS}) method that learns an\neffective metric to measure the similarity of second-order semantics hidden in\ntrained models. LPS is achieved by using a second-order neural network to align\nhigh-dimensional model parameters and learning second-order similarity in an\nend-to-end way. In addition, we create a model set called ModelSet500 as a\nparameter similarity learning benchmark that contains 500 trained models.\nExtensive experiments on ModelSet500 validate the effectiveness of the proposed\nmethod. Code will be released at\n\\url{https://github.com/Wanggcong/learnable-parameter-similarity}.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 16:14:08 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Wang", "Guangcong", ""], ["Lai", "Jianhuang", ""], ["Liang", "Wenqi", ""], ["Wang", "Guangrun", ""]]}, {"id": "1907.11951", "submitter": "Xin Liu", "authors": "Xin Liu, Konstantinos Pelechrinis, Alexandros Labrinidis", "title": "hood2vec: Identifying Similar Urban Areas Using Mobility Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Which area in NYC is the most similar to Lower East Side? What about the NoHo\nArts District in Los Angeles? Traditionally this task utilizes information\nabout the type of places located within the areas and some popularity/quality\nmetric. We take a different approach. In particular, urban dwellers'\ntime-variant mobility is a reflection of how they interact with their city over\ntime. Hence, in this paper, we introduce an approach, namely hood2vec, to\nidentify the similarity between urban areas through learning a node embedding\nof the mobility network captured through Foursquare check-ins. We compare the\npairwise similarities obtained from hood2vec with the ones obtained from\ncomparing the types of venues in the different areas. The low correlation\nbetween the two indicates that the mobility dynamics and the venue types\npotentially capture different aspects of similarity between urban areas.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 12:34:12 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Liu", "Xin", ""], ["Pelechrinis", "Konstantinos", ""], ["Labrinidis", "Alexandros", ""]]}, {"id": "1907.11959", "submitter": "Wenye Li", "authors": "Wenye Li", "title": "Modeling Winner-Take-All Competition in Sparse Binary Projections", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the advances in biological science, the study of sparse binary\nprojection models has attracted considerable recent research attention. The\nmodels project dense input samples into a higher-dimensional space and output\nsparse binary data representations after the Winner-Take-All competition,\nsubject to the constraint that the projection matrix is also sparse and binary.\nFollowing the work along this line, we developed a supervised-WTA model when\ntraining samples with both input and output representations are available, from\nwhich the optimal projection matrix can be obtained with a simple, effective\nyet efficient algorithm. We further extended the model and the algorithm to an\nunsupervised setting where only the input representation of the samples is\navailable. In a series of empirical evaluation on similarity search tasks, the\nproposed models reported significantly improved results over the\nstate-of-the-art methods in both search accuracies and running speed. The\nsuccessful results give us strong confidence that the work provides a highly\npractical tool to real world applications.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 18:23:48 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 03:51:07 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Li", "Wenye", ""]]}, {"id": "1907.11970", "submitter": "Ranjan Maitra", "authors": "Fan Dai, Somak Dutta and Ranjan Maitra", "title": "A Matrix--free Likelihood Method for Exploratory Factor Analysis of\n  High-dimensional Gaussian Data", "comments": "10 pages, 5 figures, 4 tables", "journal-ref": null, "doi": "10.1080/10618600.2019.1704296", "report-no": null, "categories": "stat.ME q-bio.QM stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel profile likelihood method for estimating the\ncovariance parameters in exploratory factor analysis of high-dimensional\nGaussian datasets with fewer observations than number of variables. An\nimplicitly restarted Lanczos algorithm and a limited-memory quasi-Newton method\nare implemented to develop a matrix-free framework for likelihood maximization.\nSimulation results show that our method is substantially faster than the\nexpectation-maximization solution without sacrificing accuracy. Our method is\napplied to fit factor models on data from suicide attempters, suicide ideators\nand a control group.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 20:04:55 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 19:25:43 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Dai", "Fan", ""], ["Dutta", "Somak", ""], ["Maitra", "Ranjan", ""]]}, {"id": "1907.11975", "submitter": "Soumya Basu", "authors": "Soumya Basu, Rajat Sen, Sujay Sanghavi, Sanjay Shakkottai", "title": "Blocking Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a novel stochastic multi-armed bandit setting, where playing an\narm makes it unavailable for a fixed number of time slots thereafter. This\nmodels situations where reusing an arm too often is undesirable (e.g. making\nthe same product recommendation repeatedly) or infeasible (e.g. compute job\nscheduling on machines). We show that with prior knowledge of the rewards and\ndelays of all the arms, the problem of optimizing cumulative reward does not\nadmit any pseudo-polynomial time algorithm (in the number of arms) unless\nrandomized exponential time hypothesis is false, by mapping to the PINWHEEL\nscheduling problem. Subsequently, we show that a simple greedy algorithm that\nplays the available arm with the highest reward is asymptotically $(1-1/e)$\noptimal. When the rewards are unknown, we design a UCB based algorithm which is\nshown to have $c \\log T + o(\\log T)$ cumulative regret against the greedy\nalgorithm, leveraging the free exploration of arms due to the unavailability.\nFinally, when all the delays are equal the problem reduces to Combinatorial\nSemi-bandits providing us with a lower bound of $c' \\log T+ \\omega(\\log T)$.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 20:42:01 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Basu", "Soumya", ""], ["Sen", "Rajat", ""], ["Sanghavi", "Sujay", ""], ["Shakkottai", "Sanjay", ""]]}, {"id": "1907.12003", "submitter": "Zhila Esna Ashari", "authors": "Zhila Esna Ashari and Hassan Ghasemzadeh", "title": "Mindful Active Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel active learning framework for activity recognition using\nwearable sensors. Our work is unique in that it takes physical and cognitive\nlimitations of the oracle into account when selecting sensor data to be\nannotated by the oracle. Our approach is inspired by human-beings' limited\ncapacity to respond to external stimulus such as responding to a prompt on\ntheir mobile devices. This capacity constraint is manifested not only in the\nnumber of queries that a person can respond to in a given time-frame but also\nin the lag between the time that a query is made and when it is responded to.\nWe introduce the notion of mindful active learning and propose a computational\nframework, called EMMA, to maximize the active learning performance taking\ninformativeness of sensor data, query budget, and human memory into account. We\nformulate this optimization problem, propose an approach to model memory\nretention, discuss complexity of the problem, and propose a greedy heuristic to\nsolve the problem. We demonstrate the effectiveness of our approach on three\npublicly available datasets and by simulating oracles with various memory\nstrengths. We show that the activity recognition accuracy ranges from 21% to\n97% depending on memory strength, query budget, and difficulty of the machine\nlearning task. Our results also indicate that EMMA achieves an accuracy level\nthat is, on average, 13.5% higher than the case when only informativeness of\nthe sensor data is considered for active learning. Additionally, we show that\nthe performance of our approach is at most 20% less than experimental\nupper-bound and up to 80% higher than experimental lower-bound. We observe that\nmindful active learning is most beneficial when query budget is small and/or\noracle's memory is weak, thus emphasizing contributions of our work in\nhuman-centered mobile health settings and for elderly with cognitive\nimpairments.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 02:44:52 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Ashari", "Zhila Esna", ""], ["Ghasemzadeh", "Hassan", ""]]}, {"id": "1907.12012", "submitter": "Michael Weylandt", "authors": "Michael Weylandt", "title": "Multi-Rank Sparse and Functional PCA: Manifold Optimization and\n  Iterative Deflation Techniques", "comments": "To appear in IEEE CAMSAP 2019", "journal-ref": "2019 IEEE 8th International Workshop on Computational Advances in\n  Multi-Sensor Adaptive Processing (CAMSAP), pp.500-504", "doi": "10.1109/CAMSAP45676.2019.9022486", "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the problem of estimating multiple principal components using the\nrecently-proposed Sparse and Functional Principal Components Analysis (SFPCA)\nestimator. We first propose an extension of SFPCA which estimates several\nprincipal components simultaneously using manifold optimization techniques to\nenforce orthogonality constraints. While effective, this approach is\ncomputationally burdensome so we also consider iterative deflation approaches\nwhich take advantage of existing fast algorithms for rank-one SFPCA. We show\nthat alternative deflation schemes can more efficiently extract signal from the\ndata, in turn improving estimation of subsequent components. Finally, we\ncompare the performance of our manifold optimization and deflation techniques\nin a scenario where orthogonality does not hold and find that they still lead\nto significantly improved performance.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 04:43:54 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 20:57:59 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Weylandt", "Michael", ""]]}, {"id": "1907.12048", "submitter": "Xavier Holt Mr", "authors": "Xavier Holt", "title": "Probabilistic Models of Relational Implication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relational data in its most basic form is a static collection of known facts.\nHowever, by learning to infer and deduct additional information and structure,\nwe can massively increase the usefulness of the underlying data. One common\nform of inferential reasoning in knowledge bases is implication discovery.\nHere, by learning when one relation implies another, we can extend our\nknowledge representation. There are several existing models for relational\nimplication, however we argue they are motivated but not principled. To this\nend, we define a formal probabilistic model of relational implication. By using\nestimators based on the empirical distribution of our dataset, we demonstrate\nthat our model outperforms existing approaches. While previous work achieves a\nbest score of 0.7812 AUC on an evaluatory dataset, our ProbE model improves\nthis to 0.7915. Furthermore, we demonstrate that our model can be improved\nsubstantially through the use of link prediction models and dense latent\nrepresentations of the underlying argument and relations. This variant, denoted\nProbL, improves the state of the art on our evaluation dataset to 0.8143. In\naddition to developing a new framework and providing novel scores of relational\nimplication, we provide two pragmatic resources to assist future research.\nFirst, we motivate and develop an improved crowd framework for constructing\nlabelled datasets of relational implication. Using this, we reannotate and make\npublic a dataset comprised of 17,848 instances of labelled relational\nimplication. We demonstrate that precision (as evaluated by expert consensus\nwith the crowd labels) on the resulting dataset improves from 53% to 95%.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 08:56:06 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Holt", "Xavier", ""]]}, {"id": "1907.12059", "submitter": "Silvia Chiappa", "authors": "Ray Jiang and Aldo Pacchiano and Tom Stepleton and Heinrich Jiang and\n  Silvia Chiappa", "title": "Wasserstein Fair Classification", "comments": null, "journal-ref": "Proceedings of the Thirty-Fifth Conference on Uncertainty in\n  Artificial Intelligence, 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach to fair classification that enforces independence\nbetween the classifier outputs and sensitive information by minimizing\nWasserstein-1 distances. The approach has desirable theoretical properties and\nis robust to specific choices of the threshold used to obtain class predictions\nfrom model outputs. We introduce different methods that enable hiding sensitive\ninformation at test time or have a simple and fast implementation. We show\nempirical performance against different fairness baselines on several benchmark\nfairness datasets.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 09:57:37 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Jiang", "Ray", ""], ["Pacchiano", "Aldo", ""], ["Stepleton", "Tom", ""], ["Jiang", "Heinrich", ""], ["Chiappa", "Silvia", ""]]}, {"id": "1907.12087", "submitter": "Nupur Kumari", "authors": "Puneet Mangla, Mayank Singh, Abhishek Sinha, Nupur Kumari, Vineeth N\n  Balasubramanian, Balaji Krishnamurthy", "title": "Charting the Right Manifold: Manifold Mixup for Few-shot Learning", "comments": "WACV 2020, Code: https://github.com/nupurkmr9/S2M2_fewshot", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning algorithms aim to learn model parameters capable of\nadapting to unseen classes with the help of only a few labeled examples. A\nrecent regularization technique - Manifold Mixup focuses on learning a\ngeneral-purpose representation, robust to small changes in the data\ndistribution. Since the goal of few-shot learning is closely linked to robust\nrepresentation learning, we study Manifold Mixup in this problem setting.\nSelf-supervised learning is another technique that learns semantically\nmeaningful features, using only the inherent structure of the data. This work\ninvestigates the role of learning relevant feature manifold for few-shot tasks\nusing self-supervision and regularization techniques. We observe that\nregularizing the feature manifold, enriched via self-supervised techniques,\nwith Manifold Mixup significantly improves few-shot learning performance. We\nshow that our proposed method S2M2 beats the current state-of-the-art accuracy\non standard few-shot learning datasets like CIFAR-FS, CUB, mini-ImageNet and\ntiered-ImageNet by 3-8 %. Through extensive experimentation, we show that the\nfeatures learned using our approach generalize to complex few-shot evaluation\ntasks, cross-domain scenarios and are robust against slight changes to data\ndistribution.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 14:14:55 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 19:40:53 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 08:02:11 GMT"}, {"version": "v4", "created": "Sat, 18 Jan 2020 20:01:55 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Mangla", "Puneet", ""], ["Singh", "Mayank", ""], ["Sinha", "Abhishek", ""], ["Kumari", "Nupur", ""], ["Balasubramanian", "Vineeth N", ""], ["Krishnamurthy", "Balaji", ""]]}, {"id": "1907.12116", "submitter": "Ryan Giordano", "authors": "Ryan Giordano, Michael I. Jordan, Tamara Broderick", "title": "A Higher-Order Swiss Army Infinitesimal Jackknife", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross validation (CV) and the bootstrap are ubiquitous model-agnostic tools\nfor assessing the error or variability of machine learning and statistical\nestimators. However, these methods require repeatedly re-fitting the model with\ndifferent weighted versions of the original dataset, which can be prohibitively\ntime-consuming. For sufficiently regular optimization problems the optimum\ndepends smoothly on the data weights, and so the process of repeatedly\nre-fitting can be approximated with a Taylor series that can be often evaluated\nrelatively quickly. The first-order approximation is known as the\n\"infinitesimal jackknife\" in the statistics literature and has been the subject\nof recent interest in machine learning for approximate CV. In this work, we\nconsider high-order approximations, which we call the \"higher-order\ninfinitesimal jackknife\" (HOIJ). Under mild regularity conditions, we provide a\nsimple recursive procedure to compute approximations of all orders with\nfinite-sample accuracy bounds. Additionally, we show that the HOIJ can be\nefficiently computed even in high dimensions using forward-mode automatic\ndifferentiation. We show that a linear approximation with bootstrap weights\napproximation is equivalent to those provided by asymptotic normal\napproximations. Consequently, the HOIJ opens up the possibility of enjoying\nhigher-order accuracy properties of the bootstrap using local approximations.\nConsistency of the HOIJ for leave-one-out CV under different asymptotic regimes\nfollows as corollaries from our finite-sample bounds under additional\nregularity assumptions. The generality of the computation and bounds motivate\nthe name \"higher-order Swiss Army infinitesimal jackknife.\"\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 17:49:48 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Giordano", "Ryan", ""], ["Jordan", "Michael I.", ""], ["Broderick", "Tamara", ""]]}, {"id": "1907.12138", "submitter": "Hossein Hosseini", "authors": "Hossein Hosseini, Sreeram Kannan, Radha Poovendran", "title": "Are Odds Really Odd? Bypassing Statistical Detection of Adversarial\n  Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning classifiers are known to be vulnerable to adversarial examples.\nA recent paper presented at ICML 2019 proposed a statistical test detection\nmethod based on the observation that logits of noisy adversarial examples are\nbiased toward the true class. The method is evaluated on CIFAR-10 dataset and\nis shown to achieve 99% true positive rate (TPR) at only 1% false positive rate\n(FPR). In this paper, we first develop a classifier-based adaptation of the\nstatistical test method and show that it improves the detection performance. We\nthen propose Logit Mimicry Attack method to generate adversarial examples such\nthat their logits mimic those of benign images. We show that our attack\nbypasses both statistical test and classifier-based methods, reducing their TPR\nto less than 2:2% and 1:6%, respectively, even at 5% FPR. We finally show that\na classifier-based detector that is trained with logits of mimicry adversarial\nexamples can be evaded by an adaptive attacker that specifically targets the\ndetector. Furthermore, even a detector that is iteratively trained to defend\nagainst adaptive attacker cannot be made robust, indicating that statistics of\nlogits cannot be used to detect adversarial examples.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 20:45:02 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Hosseini", "Hossein", ""], ["Kannan", "Sreeram", ""], ["Poovendran", "Radha", ""]]}, {"id": "1907.12175", "submitter": "Ramin Ramazi", "authors": "Ramin Ramazi, Christine Perndorfer, Emily Soriano, Jean-Philippe\n  Laurenceau, Rahmatollah Beheshti", "title": "Multi-modal Predictive Models of Diabetes Progression", "comments": null, "journal-ref": null, "doi": "10.1145/3307339.3342177", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing availability of wearable devices, continuous monitoring\nof individuals' physiological and behavioral patterns has become significantly\nmore accessible. Access to these continuous patterns about individuals'\nstatuses offers an unprecedented opportunity for studying complex diseases and\nhealth conditions such as type 2 diabetes (T2D). T2D is a widely common chronic\ndisease that its roots and progression patterns are not fully understood.\nPredicting the progression of T2D can inform timely and more effective\ninterventions to prevent or manage the disease. In this study, we have used a\ndataset related to 63 patients with T2D that includes the data from two\ndifferent types of wearable devices worn by the patients: continuous glucose\nmonitoring (CGM) devices and activity trackers (ActiGraphs). Using this\ndataset, we created a model for predicting the levels of four major biomarkers\nrelated to T2D after a one-year period. We developed a wide and deep neural\nnetwork and used the data from the demographic information, lab tests, and\nwearable sensors to create the model. The deep part of our method was developed\nbased on the long short-term memory (LSTM) structure to process the time-series\ndataset collected by the wearables. In predicting the patterns of the four\nbiomarkers, we have obtained a root mean square error of 1.67% for HBA1c, 6.22\nmg/dl for HDL cholesterol, 10.46 mg/dl for LDL cholesterol, and 18.38 mg/dl for\nTriglyceride. Compared to existing models for studying T2D, our model offers a\nmore comprehensive tool for combining a large variety of factors that\ncontribute to the disease.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 02:19:05 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Ramazi", "Ramin", ""], ["Perndorfer", "Christine", ""], ["Soriano", "Emily", ""], ["Laurenceau", "Jean-Philippe", ""], ["Beheshti", "Rahmatollah", ""]]}, {"id": "1907.12179", "submitter": "Fatima Zahra Azayite", "authors": "Fatima Zahra Azayite, Said Achchab", "title": "A hybrid neural network model based on improved PSO and SA for\n  bankruptcy prediction", "comments": "13 pages", "journal-ref": "International Journal of Computer Science Issues, Vol 16, Issue 1,\n  January 2019", "doi": null, "report-no": null, "categories": "q-fin.RM cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting firm's failure is one of the most interesting subjects for\ninvestors and decision makers. In this paper, a bankruptcy prediction model is\nproposed based on Artificial Neural networks (ANN). Taking into consideration\nthat the choice of variables to discriminate between bankrupt and non-bankrupt\nfirms influences significantly the model's accuracy and considering the problem\nof local minima, we propose a hybrid ANN based on variables selection\ntechniques. Moreover, we evolve the convergence of Particle Swarm Optimization\n(PSO) by proposing a training algorithm based on an improved PSO and Simulated\nAnnealing. A comparative performance study is reported, and the proposed hybrid\nmodel shows a high performance and convergence in the context of missing data.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 13:07:21 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Azayite", "Fatima Zahra", ""], ["Achchab", "Said", ""]]}, {"id": "1907.12189", "submitter": "Teodor Vanislavov Marinov", "authors": "Raman Arora, Teodor V. Marinov, Mehryar Mohri", "title": "Bandits with Feedback Graphs and Switching Costs", "comments": "Camera ready from NeurIPS 2019, new algorithm and improved results in\n  Section 3.2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the adversarial multi-armed bandit problem where partial\nobservations are available and where, in addition to the loss incurred for each\naction, a \\emph{switching cost} is incurred for shifting to a new action. All\npreviously known results incur a factor proportional to the independence number\nof the feedback graph. We give a new algorithm whose regret guarantee depends\nonly on the domination number of the graph. We further supplement that result\nwith a lower bound. Finally, we also give a new algorithm with improved policy\nregret bounds when partial counterfactual feedback is available.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 03:01:08 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 18:35:57 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Arora", "Raman", ""], ["Marinov", "Teodor V.", ""], ["Mohri", "Mehryar", ""]]}, {"id": "1907.12205", "submitter": "Shashank Rajput", "authors": "Shashank Rajput, Hongyi Wang, Zachary Charles and Dimitris\n  Papailiopoulos", "title": "DETOX: A Redundancy-based Framework for Faster and More Robust Gradient\n  Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the resilience of distributed training to worst-case, or Byzantine\nnode failures, several recent approaches have replaced gradient averaging with\nrobust aggregation methods. Such techniques can have high computational costs,\noften quadratic in the number of compute nodes, and only have limited\nrobustness guarantees. Other methods have instead used redundancy to guarantee\nrobustness, but can only tolerate limited number of Byzantine failures. In this\nwork, we present DETOX, a Byzantine-resilient distributed training framework\nthat combines algorithmic redundancy with robust aggregation. DETOX operates in\ntwo steps, a filtering step that uses limited redundancy to significantly\nreduce the effect of Byzantine nodes, and a hierarchical aggregation step that\ncan be used in tandem with any state-of-the-art robust aggregation method. We\nshow theoretically that this leads to a substantial increase in robustness, and\nhas a per iteration runtime that can be nearly linear in the number of compute\nnodes. We provide extensive experiments over real distributed setups across a\nvariety of large-scale machine learning tasks, showing that DETOX leads to\norders of magnitude accuracy and speedup improvements over many\nstate-of-the-art Byzantine-resilient approaches.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 04:02:35 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 03:02:12 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Rajput", "Shashank", ""], ["Wang", "Hongyi", ""], ["Charles", "Zachary", ""], ["Papailiopoulos", "Dimitris", ""]]}, {"id": "1907.12207", "submitter": "Ismael Lemhadri", "authors": "Ismael Lemhadri, Feng Ruan, Louis Abraham, Robert Tibshirani", "title": "LassoNet: A Neural Network with Feature Sparsity", "comments": "18 pages, 10 fg. arXiv admin note: text overlap with arXiv:1901.09346\n  by other authors", "journal-ref": "Journal of Machine Learning Research 22 (2021) 1-29", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much work has been done recently to make neural networks more interpretable,\nand one obvious approach is to arrange for the network to use only a subset of\nthe available features. In linear models, Lasso (or $\\ell_1$-regularized)\nregression assigns zero weights to the most irrelevant or redundant features,\nand is widely used in data science. However the Lasso only applies to linear\nmodels. Here we introduce LassoNet, a neural network framework with global\nfeature selection. Our approach enforces a hierarchy: specifically a feature\ncan participate in a hidden unit only if its linear representative is active.\nUnlike other approaches to feature selection for neural nets, our method uses a\nmodified objective function with constraints, and so integrates feature\nselection with the parameter learning directly. As a result, it delivers an\nentire regularization path of solutions with a range of feature sparsity. On\nsystematic experiments, LassoNet significantly outperforms state-of-the-art\nmethods for feature selection and regression. The LassoNet method uses\nprojected proximal gradient descent, and generalizes directly to deep networks.\nIt can be implemented by adding just a few lines of code to a standard neural\nnetwork.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 04:23:21 GMT"}, {"version": "v10", "created": "Wed, 16 Jun 2021 04:43:38 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 03:35:46 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2019 12:32:49 GMT"}, {"version": "v4", "created": "Wed, 30 Oct 2019 06:05:03 GMT"}, {"version": "v5", "created": "Sat, 8 Feb 2020 09:17:50 GMT"}, {"version": "v6", "created": "Fri, 12 Jun 2020 01:33:22 GMT"}, {"version": "v7", "created": "Mon, 16 Nov 2020 02:17:14 GMT"}, {"version": "v8", "created": "Thu, 21 Jan 2021 20:25:22 GMT"}, {"version": "v9", "created": "Tue, 23 Feb 2021 16:57:45 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Lemhadri", "Ismael", ""], ["Ruan", "Feng", ""], ["Abraham", "Louis", ""], ["Tibshirani", "Robert", ""]]}, {"id": "1907.12245", "submitter": "Kan Ming", "authors": "Chen He, Kan Ming, Yongwei Wang, and Z. Jane Wang", "title": "A Deep Learning Based Attack for The Chaos-based Image Encryption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, as a proof of concept, we propose a deep learning-based\napproach to attack the chaos-based image encryption algorithm in\n\\cite{guan2005chaos}. The proposed method first projects the chaos-based\nencrypted images into the low-dimensional feature space, where essential\ninformation of plain images has been largely preserved. With the\nlow-dimensional features, a deconvolutional generator is utilized to regenerate\nperceptually similar decrypted images to approximate the plain images in the\nhigh-dimensional space. Compared with conventional image encryption attack\nalgorithms, the proposed method does not require to manually analyze and infer\nkeys in a time-consuming way. Instead, we directly attack the chaos-based\nencryption algorithms in a key-independent manner. Moreover, the proposed\nmethod can be trained end-to-end. Given the chaos-based encrypted images, a\nwell-trained decryption model is able to automatically reconstruct plain images\nwith high fidelity. In the experiments, we successfully attack the chaos-based\nalgorithm \\cite{guan2005chaos} and the decrypted images are visually similar to\ntheir ground truth plain images. Experimental results on both static-key and\ndynamic-key scenarios verify the efficacy of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 07:36:21 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["He", "Chen", ""], ["Ming", "Kan", ""], ["Wang", "Yongwei", ""], ["Wang", "Z. Jane", ""]]}, {"id": "1907.12268", "submitter": "Jian Ma", "authors": "Jian Ma", "title": "Discovering Association with Copula Entropy", "comments": "Minor revision. The code is available at\n  https://github.com/majianthu/copent", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT q-bio.QM stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering associations is of central importance in scientific practices.\nCurrently, most researches consider only linear association measured by\ncorrelation coefficient, which has its theoretical limitations. In this paper,\nwe propose a new method for discovering association with copula entropy -- a\nuniversal applicable association measure for not only linear cases, but\nnonlinear cases. The advantage of the method based on copula entropy over\ntraditional method is demonstrated on the NHANES data by discovering more\nbiomedical meaningful associations.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 08:23:21 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 06:26:38 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Ma", "Jian", ""]]}, {"id": "1907.12279", "submitter": "Takuhiro Kaneko", "authors": "Takuhiro Kaneko, Hirokazu Kameoka, Kou Tanaka, Nobukatsu Hojo", "title": "StarGAN-VC2: Rethinking Conditional Methods for StarGAN-Based Voice\n  Conversion", "comments": "Accepted to Interspeech 2019. Project page:\n  http://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/stargan-vc2/index.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-parallel multi-domain voice conversion (VC) is a technique for learning\nmappings among multiple domains without relying on parallel data. This is\nimportant but challenging owing to the requirement of learning multiple\nmappings and the non-availability of explicit supervision. Recently, StarGAN-VC\nhas garnered attention owing to its ability to solve this problem only using a\nsingle generator. However, there is still a gap between real and converted\nspeech. To bridge this gap, we rethink conditional methods of StarGAN-VC, which\nare key components for achieving non-parallel multi-domain VC in a single\nmodel, and propose an improved variant called StarGAN-VC2. Particularly, we\nrethink conditional methods in two aspects: training objectives and network\narchitectures. For the former, we propose a source-and-target conditional\nadversarial loss that allows all source domain data to be convertible to the\ntarget domain data. For the latter, we introduce a modulation-based conditional\nmethod that can transform the modulation of the acoustic feature in a\ndomain-specific manner. We evaluated our methods on non-parallel multi-speaker\nVC. An objective evaluation demonstrates that our proposed methods improve\nspeech quality in terms of both global and local structure measures.\nFurthermore, a subjective evaluation shows that StarGAN-VC2 outperforms\nStarGAN-VC in terms of naturalness and speaker similarity. The converted speech\nsamples are provided at\nhttp://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/stargan-vc2/index.html.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 08:51:52 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 10:21:30 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Kaneko", "Takuhiro", ""], ["Kameoka", "Hirokazu", ""], ["Tanaka", "Kou", ""], ["Hojo", "Nobukatsu", ""]]}, {"id": "1907.12299", "submitter": "Victor Bouvier", "authors": "Victor Bouvier, Philippe Very, C\\'eline Hudelot, Cl\\'ement Chastagnol", "title": "Hidden Covariate Shift: A Minimal Assumption For Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised Domain Adaptation aims to learn a model on a source domain with\nlabeled data in order to perform well on unlabeled data of a target domain.\nCurrent approaches focus on learning \\textit{Domain Invariant Representations}.\nIt relies on the assumption that such representations are well-suited for\nlearning the supervised task in the target domain. We rather believe that a\nbetter and minimal assumption for performing Domain Adaptation is the\n\\textit{Hidden Covariate Shift} hypothesis. Such approach consists in learning\na representation of the data such that the label distribution conditioned on\nthis representation is domain invariant. From the Hidden Covariate Shift\nassumption, we derive an optimization procedure which learns to match an\nestimated joint distribution on the target domain and a re-weighted joint\ndistribution on the source domain. The re-weighting is done in the\nrepresentation space and is learned during the optimization procedure. We show\non synthetic data and real world data that our approach deals with both\n\\textit{Target Shift} and \\textit{Concept Drift}. We report state-of-the-art\nperformances on Amazon Reviews dataset \\cite{blitzer2007biographies}\ndemonstrating the viability of this approach.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 09:39:27 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Bouvier", "Victor", ""], ["Very", "Philippe", ""], ["Hudelot", "C\u00e9line", ""], ["Chastagnol", "Cl\u00e9ment", ""]]}, {"id": "1907.12305", "submitter": "Victor Bouvier", "authors": "Victor Bouvier, Philippe Very, C\\'eline Hudelot, Cl\\'ement Chastagnol", "title": "Learning Invariant Representations for Sentiment Analysis: The Missing\n  Material is Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations which remain invariant to a nuisance factor has a\ngreat interest in Domain Adaptation, Transfer Learning, and Fair Machine\nLearning. Finding such representations becomes highly challenging in NLP tasks\nsince the nuisance factor is entangled in a raw text. To our knowledge, a major\nissue is also that only few NLP datasets allow assessing the impact of such\nfactor. In this paper, we introduce two generalization metrics to assess model\nrobustness to a nuisance factor: \\textit{generalization under target bias} and\n\\textit{generalization onto unknown}. We combine those metrics with a simple\ndata filtering approach to control the impact of the nuisance factor on the\ndata and thus to build experimental biased datasets. We apply our method to\nstandard datasets of the literature (\\textit{Amazon} and \\textit{Yelp}). Our\nwork shows that a simple text classification baseline (i.e., sentiment analysis\non reviews) may be badly affected by the \\textit{product ID} (considered as a\nnuisance factor) when learning the polarity of a review. The method proposed is\ngeneric and applicable as soon as the nuisance variable is annotated in the\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 09:44:49 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Bouvier", "Victor", ""], ["Very", "Philippe", ""], ["Hudelot", "C\u00e9line", ""], ["Chastagnol", "Cl\u00e9ment", ""]]}, {"id": "1907.12340", "submitter": "Zhi-Hua Zhou", "authors": "Peng Zhao and Guanghui Wang and Lijun Zhang and Zhi-Hua Zhou", "title": "Bandit Convex Optimization in Non-stationary Environments", "comments": null, "journal-ref": "AISTATS 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandit Convex Optimization (BCO) is a fundamental framework for modeling\nsequential decision-making with partial information, where the only feedback\navailable to the player is the one-point or two-point function values. In this\npaper, we investigate BCO in non-stationary environments and choose the\n\\emph{dynamic regret} as the performance measure, which is defined as the\ndifference between the cumulative loss incurred by the algorithm and that of\nany feasible comparator sequence. Let $T$ be the time horizon and $P_T$ be the\npath-length of the comparator sequence that reflects the non-stationarity of\nenvironments. We propose a novel algorithm that achieves\n$O(T^{3/4}(1+P_T)^{1/2})$ and $O(T^{1/2}(1+P_T)^{1/2})$ dynamic regret\nrespectively for the one-point and two-point feedback models. The latter result\nis optimal, matching the $\\Omega(T^{1/2}(1+P_T)^{1/2})$ lower bound established\nin this paper. Notably, our algorithm is more adaptive to non-stationary\nenvironments since it does not require prior knowledge of the path-length $P_T$\nahead of time, which is generally unknown.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 11:33:28 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 16:24:37 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhao", "Peng", ""], ["Wang", "Guanghui", ""], ["Zhang", "Lijun", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1907.12363", "submitter": "Eric Charton", "authors": "Louis Marceau and Lingling Qiu and Nick Vandewiele and Eric Charton", "title": "A comparison of Deep Learning performances with other machine learning\n  algorithms on credit scoring unbalanced data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training models on highly unbalanced data is admitted to be a challenging\ntask for machine learning algorithms. Current studies on deep learning mainly\nfocus on data sets with balanced class labels or unbalanced data, but with\nmassive amount of samples available, like in speech recognition. However, the\ncapacities of deep learning on imbalanced data with little samples is not\ndeeply investigated in literature, while it is a very common application\ncontext in numerous industries. To contribute to fill this gap, this paper\ncompares the performances of several popular machine learning algorithms\npreviously applied with success to unbalanced data set with deep learning\nalgorithms. We conduct those experiments on a highly unbalanced data set, used\nfor credit scoring. We evaluate various configuration including neural network\noptimization techniques and try to determine their capacities when they operate\nwith imbalanced corpora.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 18:47:50 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 19:35:35 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Marceau", "Louis", ""], ["Qiu", "Lingling", ""], ["Vandewiele", "Nick", ""], ["Charton", "Eric", ""]]}, {"id": "1907.12365", "submitter": "Vikas Kumar", "authors": "Vikas Kumar", "title": "Collaborative Filtering and Multi-Label Classification with Matrix\n  Factorization", "comments": "Ph.D. Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques for Recommendation System (RS) and Classification\nhas become a prime focus of research to tackle the problem of information\noverload. RS are software tools that aim at making informed decisions about the\nservices that a user may like. On the other hand, classification technique\ndeals with the categorization of a data object into one of the several\npredefined classes. In the multi-label classification problem, unlike the\ntraditional multi-class classification setting, each instance can be\nsimultaneously associated with a subset of labels. The focus of thesis is on\nthe development of novel techniques for collaborative filtering and multi-label\nclassification.\n  We propose a novel method of constructing a hierarchical bi-level maximum\nmargin matrix factorization to handle matrix completion of ordinal rating\nmatrix. Taking the cue from the alternative formulation of support vector\nmachines, a novel loss function is derived by considering proximity as an\nalternative criterion instead of margin maximization criterion for matrix\nfactorization framework.\n  We extended the concept of matrix factorization for yet another important\nproblem of machine learning namely multi-label classification which deals with\nthe classification of data with multiple labels. We propose a novel\npiecewise-linear embedding method with a low-rank constraint on parametrization\nto capture nonlinear intrinsic relationships that exist in the original feature\nand label space. We also study the embedding of labels together with the group\ninformation with an objective to build an efficient multi-label classifier. We\nassume the existence of a low-dimensional space onto which the feature vectors\nand label vectors can be embedded. We ensure that labels belonging to the same\ngroup share the same sparsity pattern in their low-rank representations.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 11:39:39 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Kumar", "Vikas", ""]]}, {"id": "1907.12366", "submitter": "Lukas Galke", "authors": "Lukas Galke, Florian Mai, Iacopo Vagliano, Ansgar Scherp", "title": "Multi-Modal Adversarial Autoencoders for Recommendations of Citations\n  and Subject Labels", "comments": "Published in: UMAP '18 Proceedings of the 26th Conference on User\n  Modeling, Adaptation and Personalization Pages 197-205", "journal-ref": null, "doi": "10.1145/3209219.3209236", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present multi-modal adversarial autoencoders for recommendation and\nevaluate them on two different tasks: citation recommendation and subject label\nrecommendation. We analyze the effects of adversarial regularization, sparsity,\nand different input modalities. By conducting 408 experiments, we show that\nadversarial regularization consistently improves the performance of\nautoencoders for recommendation. We demonstrate, however, that the two tasks\ndiffer in the semantics of item co-occurrence in the sense that item\nco-occurrence resembles relatedness in case of citations, yet implies diversity\nin case of subject labels. Our results reveal that supplying the partial item\nset as input is only helpful, when item co-occurrence resembles relatedness.\nWhen facing a new recommendation task it is therefore crucial to consider the\nsemantics of item co-occurrence for the choice of an appropriate model.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 10:23:20 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Galke", "Lukas", ""], ["Mai", "Florian", ""], ["Vagliano", "Iacopo", ""], ["Scherp", "Ansgar", ""]]}, {"id": "1907.12368", "submitter": "Armaan Kaur", "authors": "Armaan Kaur, Jaspal Kaur Saini, Divya Bansal", "title": "Detecting Radical Text over Online Media using Deep Learning", "comments": "The Paper consists of 7 pages with 5 figures. The paper is accepted\n  in Intelligent Information Feed Workshop of 25th ACM SIGKDD Conference 2019\n  for oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social Media has influenced the way people socially connect, interact and\nopinionize. The growth in technology has enhanced communication and\ndissemination of information. Unfortunately,many terror groups like jihadist\ncommunities have started consolidating a virtual community online for various\npurposes such as recruitment, online donations, targeting youth online and\nspread of extremist ideologies. Everyday a large number of articles, tweets,\nposts, posters, blogs, comments, views and news are posted online without a\ncheck which in turn imposes a threat to the security of any nation. However,\ndifferent agencies are working on getting down this radical content from\nvarious online social media platforms. The aim of our paper is to utilise deep\nlearning algorithm in detection of radicalization contrary to the existing\nworks based on machine learning algorithms. An LSTM based feed forward neural\nnetwork is employed to detect radical content. We collected total 61601 records\nfrom various online sources constituting news, articles and blogs. These\nrecords are annotated by domain experts into three categories: Radical(R),\nNon-Radical (NR) and Irrelevant(I) which are further applied to LSTM based\nnetwork to classify radical content. A precision of 85.9% has been achieved\nwith the proposed approach\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 17:27:37 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 19:07:10 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Kaur", "Armaan", ""], ["Saini", "Jaspal Kaur", ""], ["Bansal", "Divya", ""]]}, {"id": "1907.12372", "submitter": "Murium Iqbal", "authors": "Murium Iqbal, Nishan Subedi, Kamelia Aryafar", "title": "Production Ranking Systems: A Review", "comments": "SIGIR eComm Accepted Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of ranking is a multi-billion dollar problem. In this paper we\npresent an overview of several production quality ranking systems. We show that\ndue to conflicting goals of employing the most effective machine learning\nmodels and responding to users in real time, ranking systems have evolved into\na system of systems, where each subsystem can be viewed as a component layer.\nWe view these layers as being data processing, representation learning,\ncandidate selection and online inference. Each layer employs different\nalgorithms and tools, with every end-to-end ranking system spanning multiple\narchitectures. Our goal is to familiarize the general audience with a working\nknowledge of ranking at scale, the tools and algorithms employed and the\nchallenges introduced by adopting a layered approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 19:30:28 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Iqbal", "Murium", ""], ["Subedi", "Nishan", ""], ["Aryafar", "Kamelia", ""]]}, {"id": "1907.12378", "submitter": "Brett Vintch", "authors": "Tim Schmeier, Sam Garrett, Joseph Chisari, and Brett Vintch", "title": "Music Recommendations in Hyperbolic Space: An Application of Empirical\n  Bayes and Hierarchical Poincar\\'e Embeddings", "comments": null, "journal-ref": "Thirteenth ACM Conference on Recommender Systems (RecSys '19),\n  September 16--20, 2019, Copenhagen, Denmark", "doi": "10.1145/3298689.3347029", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix Factorization (MF) is a common method for generating recommendations,\nwhere the proximity of entities like users or items in the embedded space\nindicates their similarity to one another. Though almost all applications\nimplicitly use a Euclidean embedding space to represent two entity types,\nrecent work has suggested that a hyperbolic Poincar\\'e ball may be more well\nsuited to representing multiple entity types, and in particular, hierarchies.\nWe describe a novel method to embed a hierarchy of related music entities in\nhyperbolic space. We also describe how a parametric empirical Bayes approach\ncan be used to estimate link reliability between entities in the hierarchy.\nApplying these methods together to build personalized playlists for users in a\ndigital music service yielded a large and statistically significant increase in\nperformance during an A/B test, as compared to the Euclidean model.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 15:53:40 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Schmeier", "Tim", ""], ["Garrett", "Sam", ""], ["Chisari", "Joseph", ""], ["Vintch", "Brett", ""]]}, {"id": "1907.12380", "submitter": "Agnieszka Maria S{\\l}owik", "authors": "Paula Ferm\\'in Cueto, Meeke Roet, Agnieszka S{\\l}owik", "title": "Completing partial recipes using item-based collaborative filtering to\n  recommend ingredients", "comments": "The authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increased public interest in healthy lifestyles has motivated the study of\nalgorithms that encourage people to follow a healthy diet. Applying\ncollaborative filtering to build recommendation systems in domains where only\nimplicit feedback is available is also a rapidly growing research area. In this\nreport we combine these two trends by developing a recommendation system to\nsuggest ingredients that can be added to a partial recipe. We implement the\nitem-based collaborative filtering algorithm using a high-dimensional, sparse\ndataset of recipes, which inherently contains only implicit feedback. We\nexplore the effect of different similarity measures and dimensionality\nreduction on the quality of the recommendations, and find that our best method\nachieves a recall@10 of circa 40%.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 13:42:29 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 16:05:38 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Cueto", "Paula Ferm\u00edn", ""], ["Roet", "Meeke", ""], ["S\u0142owik", "Agnieszka", ""]]}, {"id": "1907.12384", "submitter": "Olivier Jeunen", "authors": "Olivier Jeunen, David Rohde, Flavian Vasile", "title": "On the Value of Bandit Feedback for Offline Recommender System\n  Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In academic literature, recommender systems are often evaluated on the task\nof next-item prediction. The procedure aims to give an answer to the question:\n\"Given the natural sequence of user-item interactions up to time t, can we\npredict which item the user will interact with at time t+1?\". Evaluation\nresults obtained through said methodology are then used as a proxy to predict\nwhich system will perform better in an online setting. The online setting,\nhowever, poses a subtly different question: \"Given the natural sequence of\nuser-item interactions up to time t, can we get the user to interact with a\nrecommended item at time t+1?\". From a causal perspective, the system performs\nan intervention, and we want to measure its effect. Next-item prediction is\noften used as a fall-back objective when information about interventions and\ntheir effects (shown recommendations and whether they received a click) is\nunavailable. When this type of data is available, however, it can provide great\nvalue for reliably estimating online recommender system performance. Through a\nseries of simulated experiments with the RecoGym environment, we show where\ntraditional offline evaluation schemes fall short. Additionally, we show how\nso-called bandit feedback can be exploited for effective offline evaluation\nthat more accurately reflects online performance.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 12:50:50 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Jeunen", "Olivier", ""], ["Rohde", "David", ""], ["Vasile", "Flavian", ""]]}, {"id": "1907.12385", "submitter": "Ruizhe Li", "authors": "Xiao Li, Chenghua Lin, Ruizhe Li, Chaozheng Wang, Frank Guerin", "title": "Latent Space Factorisation and Manipulation via Matrix Subspace\n  Projection", "comments": "Final camera ready version for ICML 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem disentangling the latent space of an autoencoder in\norder to separate labelled attribute information from other characteristic\ninformation. This then allows us to change selected attributes while preserving\nother information. Our method, matrix subspace projection, is much simpler than\nprevious approaches to latent space factorisation, for example not requiring\nmultiple discriminators or a careful weighting among their loss functions.\nFurthermore our new model can be applied to autoencoders as a plugin, and works\nacross diverse domains such as images or text. We demonstrate the utility of\nour method for attribute manipulation in autoencoders trained across varied\ndomains, using both human evaluation and automated methods. The quality of\ngeneration of our new model (e.g. reconstruction, conditional generation) is\nhighly competitive to a number of strong baselines.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 06:37:18 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 13:09:24 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2020 22:33:16 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Li", "Xiao", ""], ["Lin", "Chenghua", ""], ["Li", "Ruizhe", ""], ["Wang", "Chaozheng", ""], ["Guerin", "Frank", ""]]}, {"id": "1907.12388", "submitter": "Murium Iqbal", "authors": "Murium Iqbal, Kamelia Aryafar, Timothy Anderton", "title": "Style Conditioned Recommendations", "comments": "9 pages, 10 figures, Accepted to RecSys '19", "journal-ref": null, "doi": "10.1145/3298689.3347007", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Style Conditioned Recommendations (SCR) and introduce style\ninjection as a method to diversify recommendations. We use Conditional\nVariational Autoencoder (CVAE) architecture, where both the encoder and decoder\nare conditioned on a user profile learned from item content data. This allows\nus to apply style transfer methodologies to the task of recommendations, which\nwe refer to as injection. To enable style injection, user profiles are learned\nto be interpretable such that they express users' propensities for specific\npredefined styles. These are learned via label-propagation from a dataset of\nitem content, with limited labeled points. To perform injection, the condition\non the encoder is learned while the condition on the decoder is selected per\nexplicit feedback. Explicit feedback can be taken either from a user's response\nto a style or interest quiz, or from item ratings. In the absence of explicit\nfeedback, the condition at the encoder is applied to the decoder. We show a 12%\nimprovement on NDCG@20 over the traditional VAE based approach and an average\n22% improvement on AUC across all classes for predicting user style profiles\nagainst our best performing baseline. After injecting styles we compare the\nuser style profile to the style of the recommendations and show that injected\nstyles have an average +133% increase in presence. Our results show that style\ninjection is a powerful method to diversify recommendations while maintaining\npersonal relevance. Our main contribution is an application of a\nsemi-supervised approach that extends item labels to interpretable user\nprofiles.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 15:43:12 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 15:51:51 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Iqbal", "Murium", ""], ["Aryafar", "Kamelia", ""], ["Anderton", "Timothy", ""]]}, {"id": "1907.12392", "submitter": "Felix Leibfried", "authors": "Felix Leibfried and Sergio Pascual-Diaz and Jordi Grau-Moya", "title": "A Unified Bellman Optimality Principle Combining Reward Maximization and\n  Empowerment", "comments": "Proceedings of the 33rd Conference on Neural Information Processing\n  Systems (NeurIPS), Vancouver, Canada, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Empowerment is an information-theoretic method that can be used to\nintrinsically motivate learning agents. It attempts to maximize an agent's\ncontrol over the environment by encouraging visiting states with a large number\nof reachable next states. Empowered learning has been shown to lead to complex\nbehaviors, without requiring an explicit reward signal. In this paper, we\ninvestigate the use of empowerment in the presence of an extrinsic reward\nsignal. We hypothesize that empowerment can guide reinforcement learning (RL)\nagents to find good early behavioral solutions by encouraging highly empowered\nstates. We propose a unified Bellman optimality principle for empowered reward\nmaximization. Our empowered reward maximization approach generalizes both\nBellman's optimality principle as well as recent information-theoretical\nextensions to it. We prove uniqueness of the empowered values and show\nconvergence to the optimal solution. We then apply this idea to develop\noff-policy actor-critic RL algorithms which we validate in high-dimensional\ncontinuous robotics domains (MuJoCo). Our methods demonstrate improved initial\nand competitive final performance compared to model-free state-of-the-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 16:34:21 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 12:13:31 GMT"}, {"version": "v3", "created": "Mon, 9 Sep 2019 14:24:58 GMT"}, {"version": "v4", "created": "Tue, 8 Oct 2019 15:25:58 GMT"}, {"version": "v5", "created": "Wed, 8 Jan 2020 11:08:57 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Leibfried", "Felix", ""], ["Pascual-Diaz", "Sergio", ""], ["Grau-Moya", "Jordi", ""]]}, {"id": "1907.12410", "submitter": "Paul Patras", "authors": "Chaoyun Zhang, Marco Fiore, Iain Murray, Paul Patras", "title": "CloudLSTM: A Recurrent Neural Model for Spatiotemporal Point-cloud\n  Stream Forecasting", "comments": "17 pages, 15 figures, AAAI'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces CloudLSTM, a new branch of recurrent neural models\ntailored to forecasting over data streams generated by geospatial point-cloud\nsources. We design a Dynamic Point-cloud Convolution (DConv) operator as the\ncore component of CloudLSTMs, which performs convolution directly over\npoint-clouds and extracts local spatial features from sets of neighboring\npoints that surround different elements of the input. This operator maintains\nthe permutation invariance of sequence-to-sequence learning frameworks, while\nrepresenting neighboring correlations at each time step -- an important aspect\nin spatiotemporal predictive learning. The DConv operator resolves the\ngrid-structural data requirements of existing spatiotemporal forecasting models\nand can be easily plugged into traditional LSTM architectures with\nsequence-to-sequence learning and attention mechanisms. We apply our proposed\narchitecture to two representative, practical use cases that involve\npoint-cloud streams, i.e., mobile service traffic forecasting and air quality\nindicator forecasting. Our results, obtained with real-world datasets collected\nin diverse scenarios for each use case, show that CloudLSTM delivers accurate\nlong-term predictions, outperforming a variety of competitor neural network\nmodels.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 13:20:52 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 13:42:28 GMT"}, {"version": "v3", "created": "Sun, 21 Feb 2021 22:13:18 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Zhang", "Chaoyun", ""], ["Fiore", "Marco", ""], ["Murray", "Iain", ""], ["Patras", "Paul", ""]]}, {"id": "1907.12416", "submitter": "Wanli Shi", "authors": "Wanli Shi, Bin Gu, Xiang Li, Xiang Geng, Heng Huang", "title": "Quadruply Stochastic Gradients for Large Scale Nonlinear Semi-Supervised\n  AUC Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning is pervasive in real-world applications, where only\na few labeled data are available and large amounts of instances remain\nunlabeled. Since AUC is an important model evaluation metric in classification,\ndirectly optimizing AUC in semi-supervised learning scenario has drawn much\nattention in the machine learning community. Recently, it has been shown that\none could find an unbiased solution for the semi-supervised AUC maximization\nproblem without knowing the class prior distribution. However, this method is\nhardly scalable for nonlinear classification problems with kernels. To address\nthis problem, in this paper, we propose a novel scalable quadruply stochastic\ngradient algorithm (QSG-S2AUC) for nonlinear semi-supervised AUC optimization.\nIn each iteration of the stochastic optimization process, our method randomly\nsamples a positive instance, a negative instance, an unlabeled instance and\ntheir random features to compute the gradient and then update the model by\nusing this quadruply stochastic gradient to approach the optimal solution. More\nimportantly, we prove that QSG-S2AUC can converge to the optimal solution in\nO(1/t), where t is the iteration number. Extensive experimental results on a\nvariety of benchmark datasets show that QSG-S2AUC is far more efficient than\nthe existing state-of-the-art algorithms for semi-supervised AUC maximization\nwhile retaining the similar generalization performance.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 13:31:13 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Shi", "Wanli", ""], ["Gu", "Bin", ""], ["Li", "Xiang", ""], ["Geng", "Xiang", ""], ["Huang", "Heng", ""]]}, {"id": "1907.12439", "submitter": "Hanbo Zhang", "authors": "Hanbo Zhang, Site Bai, Xuguang Lan, David Hsu, Nanning Zheng", "title": "Hindsight Trust Region Policy Optimization", "comments": "Accepted by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning(RL) with sparse rewards is a major challenge. We\npropose \\emph{Hindsight Trust Region Policy Optimization}(HTRPO), a new RL\nalgorithm that extends the highly successful TRPO algorithm with\n\\emph{hindsight} to tackle the challenge of sparse rewards. Hindsight refers to\nthe algorithm's ability to learn from information across goals, including ones\nnot intended for the current task. HTRPO leverages two main ideas. It\nintroduces QKL, a quadratic approximation to the KL divergence constraint on\nthe trust region, leading to reduced variance in KL divergence estimation and\nimproved stability in policy update. It also presents Hindsight Goal\nFiltering(HGF) to select conductive hindsight goals. In experiments, we\nevaluate HTRPO in various sparse reward tasks, including simple benchmarks,\nimage-based Atari games, and simulated robot control. Ablation studies indicate\nthat QKL and HGF contribute greatly to learning stability and high performance.\nComparison results show that in all tasks, HTRPO consistently outperforms both\nTRPO and HPG, a state-of-the-art algorithm for RL with sparse rewards.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 13:59:42 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 15:16:59 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 02:00:15 GMT"}, {"version": "v4", "created": "Wed, 12 May 2021 14:24:39 GMT"}, {"version": "v5", "created": "Mon, 17 May 2021 06:09:53 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Zhang", "Hanbo", ""], ["Bai", "Site", ""], ["Lan", "Xuguang", ""], ["Hsu", "David", ""], ["Zheng", "Nanning", ""]]}, {"id": "1907.12489", "submitter": "Frederik Dennig", "authors": "Frederik L. Dennig, Tom Polk, Zudi Lin, Tobias Schreck, Hanspeter\n  Pfister, and Michael Behrisch", "title": "FDive: Learning Relevance Models using Pattern-based Similarity Measures", "comments": "12 pages, 7 figures, 2 tables, LaTeX; corrected typo; added DOI", "journal-ref": "2019 IEEE Conference on Visual Analytics Science and Technology\n  (VAST)", "doi": "10.1109/VAST47406.2019.8986940", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of interesting patterns in large high-dimensional datasets is\ndifficult because of their dimensionality and pattern complexity. Therefore,\nanalysts require automated support for the extraction of relevant patterns. In\nthis paper, we present FDive, a visual active learning system that helps to\ncreate visually explorable relevance models, assisted by learning a\npattern-based similarity. We use a small set of user-provided labels to rank\nsimilarity measures, consisting of feature descriptor and distance function\ncombinations, by their ability to distinguish relevant from irrelevant data.\nBased on the best-ranked similarity measure, the system calculates an\ninteractive Self-Organizing Map-based relevance model, which classifies data\naccording to the cluster affiliation. It also automatically prompts further\nrelevance feedback to improve its accuracy. Uncertain areas, especially near\nthe decision boundaries, are highlighted and can be refined by the user. We\nevaluate our approach by comparison to state-of-the-art feature selection\ntechniques and demonstrate the usefulness of our approach by a case study\nclassifying electron microscopy images of brain cells. The results show that\nFDive enhances both the quality and understanding of relevance models and can\nthus lead to new insights for brain research.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 15:37:43 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 09:10:47 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 15:09:51 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Dennig", "Frederik L.", ""], ["Polk", "Tom", ""], ["Lin", "Zudi", ""], ["Schreck", "Tobias", ""], ["Pfister", "Hanspeter", ""], ["Behrisch", "Michael", ""]]}, {"id": "1907.12508", "submitter": "Lu Wang", "authors": "Lu Wang and Dongxiao Zhu", "title": "Tackling Ordinal Regression Problem for Heterogeneous Data: Sparse and\n  Deep Multi-Task Learning Approaches", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world datasets are labeled with natural orders, i.e., ordinal\nlabels. Ordinal regression is a method to predict ordinal labels that finds a\nwide range of applications in data-rich domains, such as natural, health and\nsocial sciences. Most existing ordinal regression approaches work well for\nindependent and identically distributed (IID) instances via formulating a\nsingle ordinal regression task. However, for heterogeneous non-IID instances\nwith well-defined local geometric structures, e.g., subpopulation groups,\nmulti-task learning (MTL) provides a promising framework to encode task\n(subgroup) relatedness, bridge data from all tasks, and simultaneously learn\nmultiple related tasks in efforts to improve generalization performance. Even\nthough MTL methods have been extensively studied, there is barely existing work\ninvestigating MTL for heterogeneous data with ordinal labels. We tackle this\nimportant problem via sparse and deep multi-task approaches. Specifically, we\ndevelop a regularized multi-task ordinal regression (MTOR) model for smaller\ndatasets and a deep neural networks based MTOR model for large-scale datasets.\nWe evaluate the performance using three real-world healthcare datasets with\napplications to multi-stage disease progression diagnosis. Our experiments\nindicate that the proposed MTOR models markedly improve the prediction\nperformance comparing with single-task ordinal regression models.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 16:20:00 GMT"}, {"version": "v2", "created": "Mon, 27 Apr 2020 03:37:11 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Wang", "Lu", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "1907.12581", "submitter": "Mark Newman", "authors": "M. E. J. Newman, George T. Cantwell, and Jean-Gabriel Young", "title": "Improved mutual information measure for classification and community\n  detection", "comments": "12 pages, 3 figures", "journal-ref": "Phys. Rev. E 101, 042304 (2020)", "doi": "10.1103/PhysRevE.101.042304", "report-no": null, "categories": "cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information theoretic quantity known as mutual information finds wide use\nin classification and community detection analyses to compare two\nclassifications of the same set of objects into groups. In the context of\nclassification algorithms, for instance, it is often used to compare discovered\nclasses to known ground truth and hence to quantify algorithm performance. Here\nwe argue that the standard mutual information, as commonly defined, omits a\ncrucial term which can become large under real-world conditions, producing\nresults that can be substantially in error. We demonstrate how to correct this\nerror and define a mutual information that works in all cases. We discuss\npractical implementation of the new measure and give some example applications.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 18:05:30 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Newman", "M. E. J.", ""], ["Cantwell", "George T.", ""], ["Young", "Jean-Gabriel", ""]]}, {"id": "1907.12596", "submitter": "Zhicheng Cui", "authors": "Zhicheng Cui, Bradley A Fritz, Christopher R King, Michael S Avidan,\n  Yixin Chen", "title": "A Factored Generalized Additive Model for Clinical Decision Support in\n  the Operating Room", "comments": "Accepted for publication in AMIA 2019 Annual Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logistic regression (LR) is widely used in clinical prediction because it is\nsimple to deploy and easy to interpret. Nevertheless, being a linear model, LR\nhas limited expressive capability and often has unsatisfactory performance.\nGeneralized additive models (GAMs) extend the linear model with transformations\nof input features, though feature interaction is not allowed for all GAM\nvariants. In this paper, we propose a factored generalized additive model\n(F-GAM) to preserve the model interpretability for targeted features while\nallowing a rich model for interaction with features fixed within the\nindividual. We evaluate F-GAM on prediction of two targets, postoperative acute\nkidney injury and acute respiratory failure, from a single-center database. We\nfind superior model performance of F-GAM in terms of AUPRC and AUROC compared\nto several other GAM implementations, random forests, support vector machine,\nand a deep neural network. We find that the model interpretability is good with\nresults with high face validity.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 18:39:50 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Cui", "Zhicheng", ""], ["Fritz", "Bradley A", ""], ["King", "Christopher R", ""], ["Avidan", "Michael S", ""], ["Chen", "Yixin", ""]]}, {"id": "1907.12608", "submitter": "Erhan Bilal", "authors": "Erhan Bilal", "title": "Deep Gradient Boosting -- Layer-wise Input Normalization of Neural\n  Networks", "comments": "Solving the pseudo-inverse with SVD and splitting this into two\n  separate papers. There are too many changes to just update this version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient descent (SGD) has been the dominant optimization method\nfor training deep neural networks due to its many desirable properties. One of\nthe more remarkable and least understood quality of SGD is that it generalizes\nrelatively well on unseen data even when the neural network has millions of\nparameters. We hypothesize that in certain cases it is desirable to relax its\nintrinsic generalization properties and introduce an extension of SGD called\ndeep gradient boosting (DGB). The key idea of DGB is that back-propagated\ngradients inferred using the chain rule can be viewed as pseudo-residual\ntargets of a gradient boosting problem. Thus at each layer of a neural network\nthe weight update is calculated by solving the corresponding boosting problem\nusing a linear base learner. The resulting weight update formula can also be\nviewed as a normalization procedure of the data that arrives at each layer\nduring the forward pass. When implemented as a separate input normalization\nlayer (INN) the new architecture shows improved performance on image\nrecognition tasks when compared to the same architecture without normalization\nlayers. As opposed to batch normalization (BN), INN has no learnable parameters\nhowever it matches its performance on CIFAR10 and ImageNet classification\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 19:24:40 GMT"}, {"version": "v2", "created": "Thu, 24 Oct 2019 18:07:38 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 17:03:26 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Bilal", "Erhan", ""]]}, {"id": "1907.12635", "submitter": "Anjul Tyagi", "authors": "Ayush Kumar, Anjul Tyagi, Michael Burch, Daniel Weiskopf, Klaus\n  Mueller", "title": "Task Classification Model for Visual Fixation, Exploration, and Search", "comments": "4 pages", "journal-ref": "In proceedings of the 11th ACM Symposium on Eye Tracking Research\n  and Applications, 2019", "doi": "10.1145/3314111.3323073", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Yarbus' claim to decode the observer's task from eye movements has received\nmixed reactions. In this paper, we have supported the hypothesis that it is\npossible to decode the task. We conducted an exploratory analysis on the\ndataset by projecting features and data points into a scatter plot to visualize\nthe nuance properties for each task. Following this analysis, we eliminated\nhighly correlated features before training an SVM and Ada Boosting classifier\nto predict the tasks from this filtered eye movements data. We achieve an\naccuracy of 95.4% on this task classification problem and hence, support the\nhypothesis that task classification is possible from a user's eye movement\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 20:50:37 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Kumar", "Ayush", ""], ["Tyagi", "Anjul", ""], ["Burch", "Michael", ""], ["Weiskopf", "Daniel", ""], ["Mueller", "Klaus", ""]]}, {"id": "1907.12647", "submitter": "Arpan Sainju", "authors": "Arpan Sainju and Zhe Jiang", "title": "Mapping road safety features from streetview imagery: A deep learning\n  approach", "comments": "17 pages, 16 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Each year, around 6 million car accidents occur in the U.S. on average. Road\nsafety features (e.g., concrete barriers, metal crash barriers, rumble strips)\nplay an important role in preventing or mitigating vehicle crashes. Accurate\nmaps of road safety features is an important component of safety management\nsystems for federal or state transportation agencies, helping traffic engineers\nidentify locations to invest on safety infrastructure. In current practice,\nmapping road safety features is largely done manually (e.g., observations on\nthe road or visual interpretation of streetview imagery), which is both\nexpensive and time consuming. In this paper, we propose a deep learning\napproach to automatically map road safety features from streetview imagery.\nUnlike existing Convolutional Neural Networks (CNNs) that classify each image\nindividually, we propose to further add Recurrent Neural Network (Long Short\nTerm Memory) to capture geographic context of images (spatial autocorrelation\neffect along linear road network paths). Evaluations on real world streetview\nimagery show that our proposed model outperforms several baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 20:38:33 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Sainju", "Arpan", ""], ["Jiang", "Zhe", ""]]}, {"id": "1907.12665", "submitter": "Pouya Rezazadeh Kalehbasti", "authors": "Pouya Rezazadeh Kalehbasti, Liubov Nikolenko, Hoormazd Rezaei", "title": "Airbnb Price Prediction Using Machine Learning and Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pricing a rental property on Airbnb is a challenging task for the owner as it\ndetermines the number of customers for the place. On the other hand, customers\nhave to evaluate an offered price with minimal knowledge of an optimal value\nfor the property. This paper aims to develop a reliable price prediction model\nusing machine learning, deep learning, and natural language processing\ntechniques to aid both the property owners and the customers with price\nevaluation given minimal available information about the property. Features of\nthe rentals, owner characteristics, and the customer reviews will comprise the\npredictors, and a range of methods from linear regression to tree-based models,\nsupport-vector regression (SVR), K-means Clustering (KMC), and neural networks\n(NNs) will be used for creating the prediction model.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 21:45:42 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Kalehbasti", "Pouya Rezazadeh", ""], ["Nikolenko", "Liubov", ""], ["Rezaei", "Hoormazd", ""]]}, {"id": "1907.12690", "submitter": "Byunghyun Ban", "authors": "Byunghyun Ban, Soobin Kim", "title": "Control of nonlinear, complex and black-boxed greenhouse system with\n  reinforcement learning", "comments": "4 pages, 2 figures, 1 table. 2 pages of supplementary information.\n  Published on ICTC 2017", "journal-ref": "2017 International Conference on Information and Communication\n  Technology Convergence (ICTC)", "doi": "10.1109/ICTC.2017.8190813", "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern control theories such as systems engineering approaches try to solve\nnonlinear system problems by revelation of causal relationship or\nco-relationship among the components; most of those approaches focus on control\nof sophisticatedly modeled white-boxed systems. We suggest an application of\nactor-critic reinforcement learning approach to control a nonlinear, complex\nand black-boxed system. We demonstrated this approach on artificial green-house\nenvironment simulator all of whose control inputs have several side effects so\nhuman cannot figure out how to control this system easily. Our approach\nsucceeded to maintain the circumstance at least 20 times longer than PID and\nDeep Q Learning.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 00:06:47 GMT"}], "update_date": "2021-01-07", "authors_parsed": [["Ban", "Byunghyun", ""], ["Kim", "Soobin", ""]]}, {"id": "1907.12706", "submitter": "Dong Liu", "authors": "Chengjian Sun, Dong Liu, Chenyang Yang", "title": "Model-Free Unsupervised Learning for Optimization Problems with\n  Constraints", "comments": "Submitted to Asia-Pacific Conference on Communications (APCC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many optimization problems in wireless communications, the expressions of\nobjective function or constraints are hard or even impossible to derive, which\nmakes the solutions difficult to find. In this paper, we propose a model-free\nlearning framework to solve constrained optimization problems without the\nsupervision of the optimal solution. Neural networks are used respectively for\nparameterizing the function to be optimized, parameterizing the Lagrange\nmultiplier associated with instantaneous constraints, and approximating the\nunknown objective function or constraints. We provide learning algorithms to\ntrain all the neural networks simultaneously, and reveal the connections of the\nproposed framework with reinforcement learning. Numerical and simulation\nresults validate the proposed framework and demonstrate the efficiency of\nmodel-free learning by taking power control problem as an example.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 02:26:24 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Sun", "Chengjian", ""], ["Liu", "Dong", ""], ["Yang", "Chenyang", ""]]}, {"id": "1907.12727", "submitter": "Qingyu Zhao", "authors": "Qingyu Zhao, Ehsan Adeli, Adolf Pfefferbaum, Edith V. Sullivan, Kilian\n  M. Pohl", "title": "Confounder-Aware Visualization of ConvNets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent advances in deep learning, neuroimaging studies increasingly rely\non convolutional networks (ConvNets) to predict diagnosis based on MR images.\nTo gain a better understanding of how a disease impacts the brain, the studies\nvisualize the salience maps of the ConvNet highlighting voxels within the brain\nmajorly contributing to the prediction. However, these salience maps are\ngenerally confounded, i.e., some salient regions are more predictive of\nconfounding variables (such as age) than the diagnosis. To avoid such\nmisinterpretation, we propose in this paper an approach that aims to visualize\nconfounder-free saliency maps that only highlight voxels predictive of the\ndiagnosis. The approach incorporates univariate statistical tests to identify\nconfounding effects within the intermediate features learned by ConvNet. The\ninfluence from the subset of confounded features is then removed by a novel\npartial back-propagation procedure. We use this two-step approach to visualize\nconfounder-free saliency maps extracted from synthetic and two real datasets.\nThese experiments reveal the potential of our visualization in producing\nunbiased model-interpretation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 03:54:08 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 01:06:42 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Zhao", "Qingyu", ""], ["Adeli", "Ehsan", ""], ["Pfefferbaum", "Adolf", ""], ["Sullivan", "Edith V.", ""], ["Pohl", "Kilian M.", ""]]}, {"id": "1907.12740", "submitter": "Gioele Ciaparrone", "authors": "Gioele Ciaparrone, Francisco Luque S\\'anchez, Siham Tabik, Luigi\n  Troiano, Roberto Tagliaferri, Francisco Herrera", "title": "Deep Learning in Video Multi-Object Tracking: A Survey", "comments": "Accepted in Neurocomputing, 2019. New in v4: updated license in\n  compliance with Elsevier policy. Main text: 29 pages, 10 figures, 7 tables.\n  Summary table in appendix at the end of the paper", "journal-ref": null, "doi": "10.1016/j.neucom.2019.11.023", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of Multiple Object Tracking (MOT) consists in following the\ntrajectory of different objects in a sequence, usually a video. In recent\nyears, with the rise of Deep Learning, the algorithms that provide a solution\nto this problem have benefited from the representational power of deep models.\nThis paper provides a comprehensive survey on works that employ Deep Learning\nmodels to solve the task of MOT on single-camera videos. Four main steps in MOT\nalgorithms are identified, and an in-depth review of how Deep Learning was\nemployed in each one of these stages is presented. A complete experimental\ncomparison of the presented works on the three MOTChallenge datasets is also\nprovided, identifying a number of similarities among the top-performing methods\nand presenting some possible future research directions.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 11:51:26 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 02:11:24 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 11:49:43 GMT"}, {"version": "v4", "created": "Tue, 19 Nov 2019 11:26:20 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Ciaparrone", "Gioele", ""], ["S\u00e1nchez", "Francisco Luque", ""], ["Tabik", "Siham", ""], ["Troiano", "Luigi", ""], ["Tagliaferri", "Roberto", ""], ["Herrera", "Francisco", ""]]}, {"id": "1907.12744", "submitter": "Utku Ozbulak", "authors": "Utku Ozbulak, Arnout Van Messem, Wesley De Neve", "title": "Not All Adversarial Examples Require a Complex Defense: Identifying\n  Over-optimized Adversarial Examples with IQR-based Logit Thresholding", "comments": "Accepted for the 2019 International Joint Conference on Neural\n  Networks (IJCNN-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting adversarial examples currently stands as one of the biggest\nchallenges in the field of deep learning. Adversarial attacks, which produce\nadversarial examples, increase the prediction likelihood of a target class for\na particular data point. During this process, the adversarial example can be\nfurther optimized, even when it has already been wrongly classified with 100%\nconfidence, thus making the adversarial example even more difficult to detect.\nFor this kind of adversarial examples, which we refer to as over-optimized\nadversarial examples, we discovered that the logits of the model provide solid\nclues on whether the data point at hand is adversarial or genuine. In this\ncontext, we first discuss the masking effect of the softmax function for the\nprediction made and explain why the logits of the model are more useful in\ndetecting over-optimized adversarial examples. To identify this type of\nadversarial examples in practice, we propose a non-parametric and\ncomputationally efficient method which relies on interquartile range, with this\nmethod becoming more effective as the image resolution increases. We support\nour observations throughout the paper with detailed experiments for different\ndatasets (MNIST, CIFAR-10, and ImageNet) and several architectures.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 05:46:49 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Ozbulak", "Utku", ""], ["Van Messem", "Arnout", ""], ["De Neve", "Wesley", ""]]}, {"id": "1907.12778", "submitter": "Jingwen Wang", "authors": "Jingwen Wang, Jingxin Liu, Juntao Pu, Qinghong Yang, Zhongchen Miao,\n  Jian Gao, You Song", "title": "An anomaly prediction framework for financial IT systems using hybrid\n  machine learning methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In financial field, a robust software system is of vital importance to ensure\nthe smooth operation of financial transactions. However, many financial\ncorporations still depend on operators to identify and eliminate the system\nfailures when financial software systems break down. This traditional operation\nmethod is time consuming and extremely inefficient. To improve the efficiency\nand accuracy of system failure detection and thereby reduce the impact of\nsystem failures on financial services, we propose a novel machine\nlearning-based framework to predict the occurrence of system exceptions and\nfailures in a financial software system. In particular, we first extract rich\ninformation from system logs and eliminate noises in the data. Then the cleaned\ndata is leveraged as the input of our proposed anomaly prediction framework\nwhich consists of three modules: key performance indicator(KPI) data prediction\nmodule, anomaly identification module and severity classification module.\nNotably, we design a hierarchical architecture of alarm classifiers and try to\nalleviate the influence of class-imbalance problem on the overall performance.\nEmpirically, the experimental results demonstrate the superior performance of\nour proposed method on a real-world financial software system log data set.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 08:36:37 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 14:53:57 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 17:10:01 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Wang", "Jingwen", ""], ["Liu", "Jingxin", ""], ["Pu", "Juntao", ""], ["Yang", "Qinghong", ""], ["Miao", "Zhongchen", ""], ["Gao", "Jian", ""], ["Song", "You", ""]]}, {"id": "1907.12827", "submitter": "Junhua Li", "authors": "Tian Wang, Anastasios Bezerianos, Andrzej Cichocki, Junhua Li", "title": "Multi-Kernel Capsule Network for Schizophrenia Identification", "comments": "IEEE Transactions on Cybernetics (2020)", "journal-ref": null, "doi": "10.1109/TCYB.2020.3035282", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Schizophrenia seriously affects the quality of life. To date, both\nsimple (linear discriminant analysis) and complex (deep neural network) machine\nlearning methods have been utilized to identify schizophrenia based on\nfunctional connectivity features. The existing simple methods need two separate\nsteps (i.e., feature extraction and classification) to achieve the\nidentification, which disables simultaneous tuning for the best feature\nextraction and classifier training. The complex methods integrate two steps and\ncan be simultaneously tuned to achieve optimal performance, but these methods\nrequire a much larger amount of data for model training. Methods: To overcome\nthe aforementioned drawbacks, we proposed a multi-kernel capsule network\n(MKCapsnet), which was developed by considering the brain anatomical structure.\nKernels were set to match with partition sizes of brain anatomical structure in\norder to capture interregional connectivities at the varying scales. With the\ninspiration of widely-used dropout strategy in deep learning, we developed\nvector dropout in the capsule layer to prevent overfitting of the model.\nResults: The comparison results showed that the proposed method outperformed\nthe state-of-the-art methods. Besides, we compared performances using different\nparameters and illustrated the routing process to reveal characteristics of the\nproposed method. Conclusion: MKCapsnet is promising for schizophrenia\nidentification. Significance: Our study not only proposed a multi-kernel\ncapsule network but also provided useful information in the parameter setting,\nwhich is informative for further studies using a capsule network for\nneurophysiological signal classification.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 10:28:43 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Wang", "Tian", ""], ["Bezerianos", "Anastasios", ""], ["Cichocki", "Andrzej", ""], ["Li", "Junhua", ""]]}, {"id": "1907.12851", "submitter": "Waleed Yousef", "authors": "Waleed A. Yousef", "title": "AUC: Nonparametric Estimators and Their Smoothness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonparametric estimation of a statistic, in general, and of the error rate of\na classification rule, in particular, from just one available dataset through\nresampling is well mathematically founded in the literature using several\nversions of bootstrap and influence function. This article first provides a\nconcise review of this literature to establish the theoretical framework that\nwe use to construct, in a single coherent framework, nonparametric estimators\nof the AUC (a two-sample statistic) other than the error rate (a one-sample\nstatistic). In addition, the smoothness of some of these estimators is well\ninvestigated and explained. Our experiments show that the behavior of the\ndesigned AUC estimators confirms the findings of the literature for the\nbehavior of error rate estimators in many aspects including: the weak\ncorrelation between the bootstrap-based estimators and the true conditional\nAUC; and the comparable accuracy of the different versions of the bootstrap\nestimators in terms of the RMS with little superiority of the .632+ bootstrap\nestimator.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 12:03:18 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 04:11:18 GMT"}, {"version": "v3", "created": "Thu, 8 Apr 2021 04:26:30 GMT"}], "update_date": "2021-04-09", "authors_parsed": [["Yousef", "Waleed A.", ""]]}, {"id": "1907.12852", "submitter": "Waleed Yousef", "authors": "Waleed A. Yousef", "title": "Prudence When Assuming Normality: an advice for machine learning\n  practitioners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a binary classification problem the feature vector (predictor) is the\ninput to a scoring function that produces a decision value (score), which is\ncompared to a particular chosen threshold to provide a final class prediction\n(output). Although the normal assumption of the scoring function is important\nin many applications, sometimes it is severely violated even under the simple\nmultinormal assumption of the feature vector. This article proves this result\nmathematically with a counter example to provide an advice for practitioners to\navoid blind assumptions of normality. On the other hand, the article provides a\nset of experiments that illustrate some of the expected and well-behaved\nresults of the Area Under the ROC curve (AUC) under the multinormal assumption\nof the feature vector. Therefore, the message of the article is not to avoid\nthe normal assumption of either the input feature vector or the output scoring\nfunction; however, a prudence is needed when adopting either of both.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 12:04:01 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 12:26:05 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Yousef", "Waleed A.", ""]]}, {"id": "1907.12887", "submitter": "Fabian B. Fuchs Mr", "authors": "Fabian B. Fuchs, Adam R. Kosiorek, Li Sun, Oiwi Parker Jones, Ingmar\n  Posner", "title": "End-to-end Recurrent Multi-Object Tracking and Trajectory Prediction\n  with Relational Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of contemporary object-tracking approaches do not model\ninteractions between objects. This contrasts with the fact that objects' paths\nare not independent: a cyclist might abruptly deviate from a previously planned\ntrajectory in order to avoid colliding with a car. Building upon HART, a neural\nclass-agnostic single-object tracker, we introduce a multi-object tracking\nmethod MOHART capable of relational reasoning. Importantly, the entire system,\nincluding the understanding of interactions and relations between objects, is\nclass-agnostic and learned simultaneously in an end-to-end fashion. We explore\na number of relational reasoning architectures and show that\npermutation-invariant models outperform non-permutation-invariant alternatives.\nWe also find that architectures using a single permutation invariant operation\nlike DeepSets, despite, in theory, being universal function approximators, are\nnonetheless outperformed by a more complex architecture based on multi-headed\nattention. The latter better accounts for complex physical interactions in a\nchallenging toy experiment. Further, we find that modelling interactions leads\nto consistent performance gains in tracking as well as future trajectory\nprediction on three real-world datasets (MOTChallenge, UA-DETRAC, and Stanford\nDrone dataset), particularly in the presence of ego-motion, occlusions, crowded\nscenes, and faulty sensor inputs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 22:40:13 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 17:17:49 GMT"}, {"version": "v3", "created": "Mon, 30 Sep 2019 15:44:01 GMT"}, {"version": "v4", "created": "Thu, 30 Apr 2020 21:40:28 GMT"}, {"version": "v5", "created": "Mon, 28 Sep 2020 14:25:23 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Fuchs", "Fabian B.", ""], ["Kosiorek", "Adam R.", ""], ["Sun", "Li", ""], ["Jones", "Oiwi Parker", ""], ["Posner", "Ingmar", ""]]}, {"id": "1907.12892", "submitter": "Francis Brochu", "authors": "Francis Brochu", "title": "Increasing Shape Bias in ImageNet-Trained Networks Using Transfer\n  Learning and Domain-Adversarial Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Convolutional Neural Networks (CNNs) have become the state-of-the-art method\nto learn from image data. However, recent research shows that they may include\na texture and colour bias in their representation, contrary to the intuition\nthat they learn the shapes of the image content and to human biological\nlearning. Thus, recent works have attempted to increase the shape bias in CNNs\nin order to train more robust and accurate networks on tasks. One such approach\nuses style-transfer in order to remove texture clues from the data. This work\nreproduces this methodology on four image classification datasets, as well as\nextends the method to use domain-adversarial training in order to further\nincrease the shape bias in the learned representation. The results show the\nproposed method increases the robustness and shape bias of the CNNs, while it\ndoes not provide a gain in accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 13:30:46 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Brochu", "Francis", ""]]}, {"id": "1907.12898", "submitter": "Yang Hu", "authors": "Ling Jiang, Yang Hu, Xilin Xia, Qiuhua Liang, Andrea Soltoggio", "title": "A Multi-Scale Mapping Approach Based on a Deep Learning CNN Model for\n  Reconstructing High-Resolution Urban DEMs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shortage of high-resolution urban digital elevation model (DEM) datasets\nhas been a challenge for modelling urban flood and managing its risk. A\nsolution is to develop effective approaches to reconstruct high-resolution DEMs\nfrom their low-resolution equivalents that are more widely available. However,\nthe current high-resolution DEM reconstruction approaches mainly focus on\nnatural topography. Few attempts have been made for urban topography which is\ntypically an integration of complex man-made and natural features. This study\nproposes a novel multi-scale mapping approach based on convolutional neural\nnetwork (CNN) to deal with the complex characteristics of urban topography and\nreconstruct high-resolution urban DEMs. The proposed multi-scale CNN model is\nfirstly trained using urban DEMs that contain topographic features at different\nresolutions, and then used to reconstruct the urban DEM at a specified (high)\nresolution from a low-resolution equivalent. A two-level accuracy assessment\napproach is also designed to evaluate the performance of the proposed urban DEM\nreconstruction method, in terms of numerical accuracy and morphological\naccuracy. The proposed DEM reconstruction approach is applied to a 121 km2\nurbanized area in London, UK. Compared with other commonly used methods, the\ncurrent CNN based approach produces superior results, providing a\ncost-effective innovative method to acquire high-resolution DEMs in other\ndata-scarce environments.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 21:20:49 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 09:21:58 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Jiang", "Ling", ""], ["Hu", "Yang", ""], ["Xia", "Xilin", ""], ["Liang", "Qiuhua", ""], ["Soltoggio", "Andrea", ""]]}, {"id": "1907.12902", "submitter": "Matias Valdenegro-Toro", "authors": "Nour Soufi, Matias Valdenegro-Toro", "title": "Data augmentation with Symbolic-to-Real Image Translation GANs for\n  Traffic Sign Recognition", "comments": "6 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic sign recognition is an important component of many advanced driving\nassistance systems, and it is required for full autonomous driving.\nComputational performance is usually the bottleneck in using large scale neural\nnetworks for this purpose. SqueezeNet is a good candidate for efficient image\nclassification of traffic signs, but in our experiments it does not reach high\naccuracy, and we believe this is due to lack of data, requiring data\naugmentation. Generative adversarial networks can learn the high dimensional\ndistribution of empirical data, allowing the generation of new data points. In\nthis paper we apply pix2pix GANs architecture to generate new traffic sign\nimages and evaluate the use of these images in data augmentation. We were\nmotivated to use pix2pix to translate symbolic sign images to real ones due to\nthe mode collapse in Conditional GANs. Through our experiments we found that\ndata augmentation using GAN can increase classification accuracy for circular\ntraffic signs from 92.1% to 94.0%, and for triangular traffic signs from 93.8%\nto 95.3%, producing an overall improvement of 2%. However some traditional\naugmentation techniques can outperform GAN data augmentation, for example\ncontrast variation in circular traffic signs (95.5%) and displacement on\ntriangular traffic signs (96.7 %). Our negative results shows that while GANs\ncan be naively used for data augmentation, they are not always the best choice,\ndepending on the problem and variability in the data.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 21:52:01 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Soufi", "Nour", ""], ["Valdenegro-Toro", "Matias", ""]]}, {"id": "1907.12906", "submitter": "Silvia Chiappa", "authors": "Silvia Chiappa and Ulrich Paquet", "title": "Unsupervised Separation of Dynamics from Pixels", "comments": null, "journal-ref": "METRON, Springer, 2019", "doi": "10.1007/s40300-019-00155-4", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to learn the dynamics of multiple objects from image\nsequences in an unsupervised way. We introduce a probabilistic model that first\ngenerate noisy positions for each object through a separate linear state-space\nmodel, and then renders the positions of all objects in the same image through\na highly non-linear process. Such a linear representation of the dynamics\nenables us to propose an inference method that uses exact and efficient\ninference tools and that can be deployed to query the model in different ways\nwithout retraining.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 10:22:14 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Chiappa", "Silvia", ""], ["Paquet", "Ulrich", ""]]}, {"id": "1907.12916", "submitter": "Subrata Mitra", "authors": "Subrata Mitra, Shanka Subhra Mondal, Nikhil Sheoran, Neeraj Dhake,\n  Ravinder Nehra, Ramanuja Simha", "title": "DeepPlace: Learning to Place Applications in Multi-Tenant Clusters", "comments": "APSys 2019", "journal-ref": null, "doi": "10.1145/3343737.3343741", "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large multi-tenant production clusters often have to handle a variety of jobs\nand applications with a variety of complex resource usage characteristics. It\nis non-trivial and non-optimal to manually create placement rules for\nscheduling that would decide which applications should co-locate. In this\npaper, we present DeepPlace, a scheduler that learns to exploits various\ntemporal resource usage patterns of applications using Deep Reinforcement\nLearning (Deep RL) to reduce resource competition across jobs running in the\nsame machine while at the same time optimizing for overall cluster utilization.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 16:23:30 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Mitra", "Subrata", ""], ["Mondal", "Shanka Subhra", ""], ["Sheoran", "Nikhil", ""], ["Dhake", "Neeraj", ""], ["Nehra", "Ravinder", ""], ["Simha", "Ramanuja", ""]]}, {"id": "1907.12919", "submitter": "Jo\\~ao Antunes", "authors": "Jo\\~ao Antunes, Pedro Abreu, Alexandre Bernardino, Asim Smailagic,\n  Daniel Siewiorek", "title": "Attention Filtering for Multi-person Spatiotemporal Action Detection on\n  Deep Two-Stream CNN Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action detection and recognition tasks have been the target of much focus in\nthe computer vision community due to their many applications, namely, security,\nrobotics and recommendation systems. Recently, datasets like AVA, provide\nmulti-person, multi-label, spatiotemporal action detection and recognition\nchallenges. Being unable to discern which portions of the input to use for\nclassification is a limitation of two-stream CNN approaches, once the vision\ntask involves several people with several labels. We address this limitation\nand improve the state-of-the-art performance of two-stream CNNs. In this paper\nwe present four contributions: our fovea attention filtering that highlights\ntargets for classification without discarding background; a generalized binary\nloss function designed for the AVA dataset; miniAVA, a partition of AVA that\nmaintains temporal continuity and class distribution with only one tenth of the\ndataset size; and ablation studies on alternative attention filters. Our\nmethod, using fovea attention filtering and our generalized binary loss,\nachieves a relative video mAP improvement of 20% over the two-stream baseline\nin AVA, and is competitive with the state-of-the-art in the UCF101-24. We also\nshow a relative video mAP improvement of 12.6% when using our generalized\nbinary loss over the standard sum-of-sigmoids.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 16:53:43 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Antunes", "Jo\u00e3o", ""], ["Abreu", "Pedro", ""], ["Bernardino", "Alexandre", ""], ["Smailagic", "Asim", ""], ["Siewiorek", "Daniel", ""]]}, {"id": "1907.12920", "submitter": "Elie Aljalbout", "authors": "Axel Sauer, Elie Aljalbout, Sami Haddadin", "title": "Tracking Holistic Object Representations", "comments": "Accepted for oral presentation at BMVC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in visual tracking are based on siamese feature extractors\nand template matching. For this category of trackers, latest research focuses\non better feature embeddings and similarity measures. In this work, we focus on\nbuilding holistic object representations for tracking. We propose a framework\nthat is designed to be used on top of previous trackers without any need for\nfurther training of the siamese network. The framework leverages the idea of\nobtaining additional object templates during the tracking process. Since the\nnumber of stored templates is limited, our method only keeps the most diverse\nones. We achieve this by providing a new diversity measure in the space of\nsiamese features. The obtained representation contains information beyond the\nground truth object location provided to the system. It is then useful for\ntracking itself but also for further tasks which require a visual understanding\nof objects. Strong empirical results on tracking benchmarks indicate that our\nmethod can improve the performance and robustness of the underlying trackers\nwhile barely reducing their speed. In addition, our method is able to match\ncurrent state-of-the-art results, while using a simpler and older network\narchitecture and running three times faster.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 10:51:21 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 09:27:19 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Sauer", "Axel", ""], ["Aljalbout", "Elie", ""], ["Haddadin", "Sami", ""]]}, {"id": "1907.12926", "submitter": "Jayaraman J. Thiagarajan", "authors": "Jayaraman J. Thiagarajan, Satyananda Kashyap and Alexandros Karagyris", "title": "Distill-to-Label: Weakly Supervised Instance Labeling Using Knowledge\n  Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weakly supervised instance labeling using only image-level labels, in lieu of\nexpensive fine-grained pixel annotations, is crucial in several applications\nincluding medical image analysis. In contrast to conventional instance\nsegmentation scenarios in computer vision, the problems that we consider are\ncharacterized by a small number of training images and non-local patterns that\nlead to the diagnosis. In this paper, we explore the use of multiple instance\nlearning (MIL) to design an instance label generator under this weakly\nsupervised setting. Motivated by the observation that an MIL model can handle\nbags of varying sizes, we propose to repurpose an MIL model originally trained\nfor bag-level classification to produce reliable predictions for single\ninstances, i.e., bags of size $1$. To this end, we introduce a novel\nregularization strategy based on virtual adversarial training for improving MIL\ntraining, and subsequently develop a knowledge distillation technique for\nrepurposing the trained MIL model. Using empirical studies on colon cancer and\nbreast cancer detection from histopathological images, we show that the\nproposed approach produces high-quality instance-level prediction and\nsignificantly outperforms state-of-the MIL methods.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 04:39:17 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Thiagarajan", "Jayaraman J.", ""], ["Kashyap", "Satyananda", ""], ["Karagyris", "Alexandros", ""]]}, {"id": "1907.12934", "submitter": "Soufiane Belharbi", "authors": "Soufiane Belharbi, J\\'er\\^ome Rony, Jose Dolz, Ismail Ben Ayed, Luke\n  McCaffrey, Eric Granger", "title": "Min-max Entropy for Weakly Supervised Pointwise Localization", "comments": "27 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pointwise localization allows more precise localization and accurate\ninterpretability, compared to bounding box, in applications where objects are\nhighly unstructured such as in medical domain. In this work, we focus on weakly\nsupervised localization (WSL) where a model is trained to classify an image and\nlocalize regions of interest at pixel-level using only global image annotation.\nTypical convolutional attentions maps are prune to high false positive regions.\nTo alleviate this issue, we propose a new deep learning method for WSL,\ncomposed of a localizer and a classifier, where the localizer is constrained to\ndetermine relevant and irrelevant regions using conditional entropy (CE) with\nthe aim to reduce false positive regions. Experimental results on a public\nmedical dataset and two natural datasets, using Dice index, show that, compared\nto state of the art WSL methods, our proposal can provide significant\nimprovements in terms of image-level classification and pixel-level\nlocalization (low false positive) with robustness to overfitting. A public\nreproducible PyTorch implementation is provided in:\nhttps://github.com/sbelharbi/wsol-min-max-entropy-interpretability .\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 00:51:18 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 22:00:15 GMT"}, {"version": "v3", "created": "Sat, 31 Aug 2019 14:54:43 GMT"}, {"version": "v4", "created": "Thu, 26 Sep 2019 04:42:50 GMT"}, {"version": "v5", "created": "Thu, 21 Jan 2021 04:08:10 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Belharbi", "Soufiane", ""], ["Rony", "J\u00e9r\u00f4me", ""], ["Dolz", "Jose", ""], ["Ayed", "Ismail Ben", ""], ["McCaffrey", "Luke", ""], ["Granger", "Eric", ""]]}, {"id": "1907.12935", "submitter": "Davit Soselia", "authors": "Davit Soselia, Shota Amashukeli, Irakli Koberidze, Levan Shugliashvili", "title": "RNN-based Online Handwritten Character Recognition Using Accelerometer\n  and Gyroscope Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This abstract explores an RNN-based approach to online handwritten\nrecognition problem. Our method uses data from an accelerometer and a gyroscope\nmounted on a handheld pen-like device to train and run a character pre-diction\nmodel. We have built a dataset of timestamped gyroscope and accelerometer data\ngathered during the manual process of handwriting Latin characters, labeled\nwith the character being written; in total, the dataset con-sists of 1500\ngyroscope and accelerometer data sequenc-es for 8 characters of the Latin\nalphabet from 6 different people, and 20 characters, each 1500 samples from\nGeorgian alphabet from 5 different people. with each sequence containing the\ngyroscope and accelerometer data captured during the writing of a particular\ncharacter sampled once every 10ms. We train an RNN-based neural network\narchitecture on this dataset to predict the character being written. The model\nis optimized with categorical cross-entropy loss and RMSprop optimizer and\nachieves high accuracy on test data.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 20:44:00 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Soselia", "Davit", ""], ["Amashukeli", "Shota", ""], ["Koberidze", "Irakli", ""], ["Shugliashvili", "Levan", ""]]}, {"id": "1907.12953", "submitter": "Arindam Paul", "authors": "Arindam Paul, Mojtaba Mozaffar, Zijiang Yang, Wei-keng Liao, Alok\n  Choudhary, Jian Cao, Ankit Agrawal", "title": "A real-time iterative machine learning approach for temperature profile\n  prediction in additive manufacturing processes", "comments": "10 pages, 8 figures", "journal-ref": "6th IEEE International Conference on Data Science and Advanced\n  Analytics (DSAA), 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Additive Manufacturing (AM) is a manufacturing paradigm that builds\nthree-dimensional objects from a computer-aided design model by successively\nadding material layer by layer. AM has become very popular in the past decade\ndue to its utility for fast prototyping such as 3D printing as well as\nmanufacturing functional parts with complex geometries using processes such as\nlaser metal deposition that would be difficult to create using traditional\nmachining. As the process for creating an intricate part for an expensive metal\nsuch as Titanium is prohibitive with respect to cost, computational models are\nused to simulate the behavior of AM processes before the experimental run.\nHowever, as the simulations are computationally costly and time-consuming for\npredicting multiscale multi-physics phenomena in AM, physics-informed\ndata-driven machine-learning systems for predicting the behavior of AM\nprocesses are immensely beneficial. Such models accelerate not only multiscale\nsimulation tools but also empower real-time control systems using in-situ data.\nIn this paper, we design and develop essential components of a scientific\nframework for developing a data-driven model-based real-time control system.\nFinite element methods are employed for solving time-dependent heat equations\nand developing the database. The proposed framework uses extremely randomized\ntrees - an ensemble of bagged decision trees as the regression algorithm\niteratively using temperatures of prior voxels and laser information as inputs\nto predict temperatures of subsequent voxels. The models achieve mean absolute\npercentage errors below 1% for predicting temperature profiles for AM\nprocesses. The code is made available for the research community at\nhttps://github.com/paularindam/ml-iter-additive.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 22:43:02 GMT"}, {"version": "v2", "created": "Fri, 9 Aug 2019 05:14:45 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Paul", "Arindam", ""], ["Mozaffar", "Mojtaba", ""], ["Yang", "Zijiang", ""], ["Liao", "Wei-keng", ""], ["Choudhary", "Alok", ""], ["Cao", "Jian", ""], ["Agrawal", "Ankit", ""]]}, {"id": "1907.12972", "submitter": "Ron Levie", "authors": "Ron Levie, Wei Huang, Lorenzo Bucci, Michael M. Bronstein, Gitta\n  Kutyniok", "title": "Transferability of Spectral Graph Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on spectral graph convolutional neural networks\n(ConvNets), where filters are defined as elementwise multiplication in the\nfrequency domain of a graph. In machine learning settings where the dataset\nconsists of signals defined on many different graphs, the trained ConvNet\nshould generalize to signals on graphs unseen in the training set. It is thus\nimportant to transfer ConvNets between graphs. Transferability, which is a\ncertain type of generalization capability, can be loosely defined as follows:\nif two graphs describe the same phenomenon, then a single filter or ConvNet\nshould have similar repercussions on both graphs. This paper aims at debunking\nthe common misconception that spectral filters are not transferable. We show\nthat if two graphs discretize the same \"continuous\" space, then a spectral\nfilter or ConvNet has approximately the same repercussion on both graphs. Our\nanalysis is more permissive than the standard analysis. Transferability is\ntypically described as the robustness of the filter to small graph\nperturbations and re-indexing of the vertices. Our analysis accounts also for\nlarge graph perturbations. We prove transferability between graphs that can\nhave completely different dimensions and topologies, only requiring that both\ngraphs discretize the same underlying space in some generic sense.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 14:16:45 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 21:48:08 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 20:45:19 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Levie", "Ron", ""], ["Huang", "Wei", ""], ["Bucci", "Lorenzo", ""], ["Bronstein", "Michael M.", ""], ["Kutyniok", "Gitta", ""]]}, {"id": "1907.12991", "submitter": "Jorge Guevara", "authors": "Jorge Guevara, Roberto Hirata Jr, St\\'ephane Canu", "title": "Kernels on fuzzy sets: an overview", "comments": "Learning on Distributions, Functions, Graphs and Groups @ NIPS-2017,\n  8th Dec", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the concept of kernels on fuzzy sets as a similarity\nmeasure for $[0,1]$-valued functions, a.k.a. \\emph{membership functions of\nfuzzy sets}.\n  We defined the following classes of kernels: the cross product, the\nintersection, the non-singleton and the distance-based kernels on fuzzy sets.\n  Applicability of those kernels are on machine learning and data science tasks\nwhere uncertainty in data has an ontic or epistemistic interpretation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 14:54:01 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Guevara", "Jorge", ""], ["Hirata", "Roberto", "Jr"], ["Canu", "St\u00e9phane", ""]]}, {"id": "1907.12998", "submitter": "Tomasz Arodz", "authors": "Han Zhang, Xi Gao, Jacob Unterman, Tom Arodz", "title": "Approximation Capabilities of Neural ODEs and Invertible Residual\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural ODEs and i-ResNet are recently proposed methods for enforcing\ninvertibility of residual neural models. Having a generic technique for\nconstructing invertible models can open new avenues for advances in learning\nsystems, but so far the question of whether Neural ODEs and i-ResNets can model\nany continuous invertible function remained unresolved. Here, we show that both\nof these models are limited in their approximation capabilities. We then prove\nthat any homeomorphism on a $p$-dimensional Euclidean space can be approximated\nby a Neural ODE operating on a $2p$-dimensional Euclidean space, and a similar\nresult for i-ResNets. We conclude by showing that capping a Neural ODE or an\ni-ResNet with a single linear layer is sufficient to turn the model into a\nuniversal approximator for non-invertible continuous functions.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 15:04:01 GMT"}, {"version": "v2", "created": "Sun, 1 Mar 2020 03:28:45 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Zhang", "Han", ""], ["Gao", "Xi", ""], ["Unterman", "Jacob", ""], ["Arodz", "Tom", ""]]}, {"id": "1907.13016", "submitter": "Mohsen Rakhshandehroo", "authors": "Mohsen Rakhshandehroo, Mohammad Rajabdorri", "title": "Time Series Analysis of Big Data for Electricity Price and Demand to\n  Find Cyber-Attacks part 2: Decomposition Analysis", "comments": "7pages, 8 tables, 17 figs", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, in following of the first part (which ADF tests using ACI\nevaluation) has conducted, Time Series (TSs) are analyzed using decomposition\nanalysis. In fact, TSs are composed of four components including trend (long\nterm behavior or progression of series), cyclic component (non-periodic\nfluctuation behavior which are usually long term), seasonal component (periodic\nfluctuations due to seasonal variations like temperature, weather condition and\netc.) and error term. For our case of cyber-attack detection, in this paper,\ntwo common ways of TS decomposition are investigated. The first method is\nadditive decomposition and the second is multiplicative method to decompose a\nTS into its components. After decomposition, the error term is tested using\nDurbin-Watson and Breusch-Godfrey test to see whether the error follows any\npredictable pattern, it can be concluded that there is a chance of cyber-attack\nto the system.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 15:31:51 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Rakhshandehroo", "Mohsen", ""], ["Rajabdorri", "Mohammad", ""]]}, {"id": "1907.13052", "submitter": "Martin Engelcke", "authors": "Martin Engelcke, Adam R. Kosiorek, Oiwi Parker Jones, Ingmar Posner", "title": "GENESIS: Generative Scene Inference and Sampling with Object-Centric\n  Latent Representations", "comments": "Published at the International Conference on Learning Representations\n  (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative latent-variable models are emerging as promising tools in robotics\nand reinforcement learning. Yet, even though tasks in these domains typically\ninvolve distinct objects, most state-of-the-art generative models do not\nexplicitly capture the compositional nature of visual scenes. Two recent\nexceptions, MONet and IODINE, decompose scenes into objects in an unsupervised\nfashion. Their underlying generative processes, however, do not account for\ncomponent interactions. Hence, neither of them allows for principled sampling\nof novel scenes. Here we present GENESIS, the first object-centric generative\nmodel of 3D visual scenes capable of both decomposing and generating scenes by\ncapturing relationships between scene components. GENESIS parameterises a\nspatial GMM over images which is decoded from a set of object-centric latent\nvariables that are either inferred sequentially in an amortised fashion or\nsampled from an autoregressive prior. We train GENESIS on several publicly\navailable datasets and evaluate its performance on scene generation,\ndecomposition, and semi-supervised learning.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 16:22:39 GMT"}, {"version": "v2", "created": "Sun, 29 Sep 2019 20:19:08 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2020 14:02:16 GMT"}, {"version": "v4", "created": "Mon, 23 Nov 2020 10:31:22 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Engelcke", "Martin", ""], ["Kosiorek", "Adam R.", ""], ["Jones", "Oiwi Parker", ""], ["Posner", "Ingmar", ""]]}, {"id": "1907.13057", "submitter": "Jungkyu Park", "authors": "Jungkyu Park, Jason Phang, Yiqiu Shen, Nan Wu, S. Gene Kim, Linda Moy,\n  Kyunghyun Cho, Krzysztof J. Geras", "title": "Screening Mammogram Classification with Prior Exams", "comments": "MIDL 2019 [arXiv:1907.08612]", "journal-ref": null, "doi": null, "report-no": "MIDL/2019/ExtendedAbstract/HkgCdUaMq4", "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Radiologists typically compare a patient's most recent breast cancer\nscreening exam to their previous ones in making informed diagnoses. To reflect\nthis practice, we propose new neural network models that compare pairs of\nscreening mammograms from the same patient. We train and evaluate our proposed\nmodels on over 665,000 pairs of images (over 166,000 pairs of exams). Our best\nmodel achieves an AUC of 0.866 in predicting malignancy in patients who\nunderwent breast cancer screening, reducing the error rate of the corresponding\nbaseline.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 16:34:53 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Park", "Jungkyu", ""], ["Phang", "Jason", ""], ["Shen", "Yiqiu", ""], ["Wu", "Nan", ""], ["Kim", "S. Gene", ""], ["Moy", "Linda", ""], ["Cho", "Kyunghyun", ""], ["Geras", "Krzysztof J.", ""]]}, {"id": "1907.13070", "submitter": "Telma Pereira", "authors": "Telma Pereira, Sofia Pires, Marta Gromicho, Susana Pinto, Mamede de\n  Carvalho, Sara C.Madeira", "title": "Predicting assisted ventilation in Amyotrophic Lateral Sclerosis using a\n  mixture of experts and conformal predictors", "comments": null, "journal-ref": "KDD 2019 Workshop on Applied Data Science for Healthcare", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Amyotrophic Lateral Sclerosis (ALS) is a neurodegenerative disease\ncharacterized by a rapid motor decline, leading to respiratory failure and\nsubsequently to death. In this context, researchers have sought for models to\nautomatically predict disease progression to assisted ventilation in ALS\npatients. However, the clinical translation of such models is limited by the\nlack of insight 1) on the risk of error for predictions at patient-level, and\n2) on the most adequate time to administer the non-invasive ventilation. To\naddress these issues, we combine Conformal Prediction (a machine learning\nframework that complements predictions with confidence measures) and a mixture\nexperts into a prognostic model which not only predicts whether an ALS patient\nwill suffer from respiratory insufficiency but also the most likely time window\nof occurrence, at a given reliability level. Promising results were obtained,\nwith near 80% of predictions being correctly identified.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 16:55:29 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Pereira", "Telma", ""], ["Pires", "Sofia", ""], ["Gromicho", "Marta", ""], ["Pinto", "Susana", ""], ["de Carvalho", "Mamede", ""], ["Madeira", "Sara C.", ""]]}, {"id": "1907.13095", "submitter": "Fabio Sanchez PhD", "authors": "Paola V\\'asquez, Antonio Lor\\'ia, Fabio Sanchez, Luis A. Barboza", "title": "Climate-driven statistical models as effective predictors of local\n  dengue incidence in Costa Rica: A Generalized Additive Model and Random\n  Forest approach", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.PE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Climate has been an important factor in shaping the distribution and\nincidence of dengue cases in tropical and subtropical countries. In Costa Rica,\na tropical country with distinctive micro-climates, dengue has been endemic\nsince its introduction in 1993, inflicting substantial economic, social, and\npublic health repercussions. Using the number of dengue reported cases and\nclimate data from 2007-2017, we fitted a prediction model applying a\nGeneralized Additive Model (GAM) and Random Forest (RF) approach, which allowed\nus to retrospectively predict the relative risk of dengue in five\nclimatological diverse municipalities around the country.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 17:27:39 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 15:28:37 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["V\u00e1squez", "Paola", ""], ["Lor\u00eda", "Antonio", ""], ["Sanchez", "Fabio", ""], ["Barboza", "Luis A.", ""]]}, {"id": "1907.13100", "submitter": "Chao Qian", "authors": "Chao Bian, Chao Qian, Yang Yu", "title": "On the Robustness of Median Sampling in Noisy Evolutionary Optimization", "comments": "19 pages. arXiv admin note: text overlap with arXiv:1810.05045,\n  arXiv:1711.00956", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.CC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world optimization tasks, the objective (i.e., fitness) function\nevaluation is often disturbed by noise due to a wide range of uncertainties.\nEvolutionary algorithms (EAs) have been widely applied to tackle noisy\noptimization, where reducing the negative effect of noise is a crucial issue.\nOne popular strategy to cope with noise is sampling, which evaluates the\nfitness multiple times and uses the sample average to approximate the true\nfitness. In this paper, we introduce median sampling as a noise handling\nstrategy into EAs, which uses the median of the multiple evaluations to\napproximate the true fitness instead of the mean. We theoretically show that\nmedian sampling can reduce the expected running time of EAs from exponential to\npolynomial by considering the (1+1)-EA on OneMax under the commonly used\none-bit noise. We also compare mean sampling with median sampling by\nconsidering two specific noise models, suggesting that when the 2-quantile of\nthe noisy fitness increases with the true fitness, median sampling can be a\nbetter choice. The results provide us with some guidance to employ median\nsampling efficiently in practice.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 11:54:18 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Bian", "Chao", ""], ["Qian", "Chao", ""], ["Yu", "Yang", ""]]}, {"id": "1907.13113", "submitter": "Evita Bakopoulou", "authors": "Evita Bakopoulou, Balint Tillman, and Athina Markopoulou", "title": "A Federated Learning Approach for Mobile Packet Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to improve mobile data transparency, a number of network-based\napproaches have been proposed to inspect packets generated by mobile devices\nand detect personally identifiable information (PII), ad requests, or other\nactivities. State-of-the-art approaches train classifiers based on features\nextracted from HTTP packets. So far, these classifiers have only been trained\nin a centralized way, where mobile users label and upload their packet logs to\na central server, which then trains a global classifier and shares it with the\nusers to apply on their devices. However, packet logs used as training data may\ncontain sensitive information that users may not want to share/upload. In this\npaper, we apply, for the first time, a Federated Learning approach to mobile\npacket classification, which allows mobile devices to collaborate and train a\nglobal model, without sharing raw training data. Methodological challenges we\naddress in this context include: model and feature selection, and tuning the\nFederated Learning parameters. We apply our framework to two different packet\nclassification tasks (i.e., to predict PII exposure or ad requests in HTTP\npackets) and we demonstrate its effectiveness in terms of classification\nperformance, communication and computation cost, using three real-world\ndatasets.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 17:54:50 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Bakopoulou", "Evita", ""], ["Tillman", "Balint", ""], ["Markopoulou", "Athina", ""]]}, {"id": "1907.13120", "submitter": "Boonsap Witchayangkoon Assoc Prof Dr", "authors": "Piyasak Thiandee, Boonsap Witchayangkoon, Sayan Sirimontree, Ponlathep\n  Lertworawanich", "title": "An Experiment on Measurement of Pavement Roughness via Android-Based\n  Smartphones", "comments": "9 pages, 11 figures", "journal-ref": "International Transaction Journal of Engineering, Management, &\n  Applied Sciences & Technologies (2019) 1-9", "doi": null, "report-no": "10A09G", "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study focuses on the experiment of using three different smartphones to\ncollect acceleration data from vibration for the road roughness detection. The\nAndroid operating system is used in the application. The study takes place on\nasphaltic pavement of the expressway system of Thailand, with 9 km distance.\nThe run vehicle has an inertial profiler with laser line sensors to record road\nroughness according to the IRI. The RMS and Machine Learning (ML) methods are\nused in this study. There is different ability of each smartphone to detect the\nvibration, thus different detected values are obtained. The results are\ncompared to the IRI observation. ML method gives better result compared to RMS.\nThis study finds little relationship between IRI and acceleration data from\nvibration collected from smartphones.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 09:37:10 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Thiandee", "Piyasak", ""], ["Witchayangkoon", "Boonsap", ""], ["Sirimontree", "Sayan", ""], ["Lertworawanich", "Ponlathep", ""]]}, {"id": "1907.13124", "submitter": "Utku Ozbulak", "authors": "Utku Ozbulak, Arnout Van Messem, Wesley De Neve", "title": "Impact of Adversarial Examples on Deep Learning Models for Biomedical\n  Image Segmentation", "comments": "Accepted for the 22nd International Conference on Medical Image\n  Computing and Computer Assisted Intervention (MICCAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CR cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models, which are increasingly being used in the field of\nmedical image analysis, come with a major security risk, namely, their\nvulnerability to adversarial examples. Adversarial examples are carefully\ncrafted samples that force machine learning models to make mistakes during\ntesting time. These malicious samples have been shown to be highly effective in\nmisguiding classification tasks. However, research on the influence of\nadversarial examples on segmentation is significantly lacking. Given that a\nlarge portion of medical imaging problems are effectively segmentation\nproblems, we analyze the impact of adversarial examples on deep learning-based\nimage segmentation models. Specifically, we expose the vulnerability of these\nmodels to adversarial examples by proposing the Adaptive Segmentation Mask\nAttack (ASMA). This novel algorithm makes it possible to craft targeted\nadversarial examples that come with (1) high intersection-over-union rates\nbetween the target adversarial mask and the prediction and (2) with\nperturbation that is, for the most part, invisible to the bare eye. We lay out\nexperimental and visual evidence by showing results obtained for the ISIC skin\nlesion segmentation challenge and the problem of glaucoma optic disc\nsegmentation. An implementation of this algorithm and additional examples can\nbe found at https://github.com/utkuozbulak/adaptive-segmentation-mask-attack.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 06:03:57 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Ozbulak", "Utku", ""], ["Van Messem", "Arnout", ""], ["De Neve", "Wesley", ""]]}, {"id": "1907.13177", "submitter": "Huy Phan", "authors": "Huy Phan and Oliver Y. Ch\\'en and Philipp Koch and Zongqing Lu and Ian\n  McLoughlin and Alfred Mertins and Maarten De Vos", "title": "Towards More Accurate Automatic Sleep Staging via Deep Transfer Learning", "comments": "This article has been published in IEEE Transactions on Biomedical\n  Engineering", "journal-ref": null, "doi": "10.1109/TBME.2020.3020381", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Despite recent significant progress in the development of\nautomatic sleep staging methods, building a good model still remains a big\nchallenge for sleep studies with a small cohort due to the data-variability and\ndata-inefficiency issues. This work presents a deep transfer learning approach\nto overcome these issues and enable transferring knowledge from a large dataset\nto a small cohort for automatic sleep staging. Methods: We start from a generic\nend-to-end deep learning framework for sequence-to-sequence sleep staging and\nderive two networks as the means for transfer learning. The networks are first\ntrained in the source domain (i.e. the large database). The pretrained networks\nare then finetuned in the target domain (i.e. the small cohort) to complete\nknowledge transfer. We employ the Montreal Archive of Sleep Studies (MASS)\ndatabase consisting of 200 subjects as the source domain and study deep\ntransfer learning on three different target domains: the Sleep Cassette subset\nand the Sleep Telemetry subset of the Sleep-EDF Expanded database, and the\nSurrey-cEEGrid database. The target domains are purposely adopted to cover\ndifferent degrees of data mismatch to the source domains. Results: Our\nexperimental results show significant performance improvement on automatic\nsleep staging on the target domains achieved with the proposed deep transfer\nlearning approach. Conclusions: These results suggest the efficacy of the\nproposed approach in addressing the above-mentioned data-variability and\ndata-inefficiency issues. Significance: As a consequence, it would enable one\nto improve the quality of automatic sleep staging models when the amount of\ndata is relatively small. The source code and the pretrained models are\navailable at http://github.com/pquochuy/sleep_transfer_learning.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 18:49:57 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2020 14:09:36 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2020 16:26:17 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Phan", "Huy", ""], ["Ch\u00e9n", "Oliver Y.", ""], ["Koch", "Philipp", ""], ["Lu", "Zongqing", ""], ["McLoughlin", "Ian", ""], ["Mertins", "Alfred", ""], ["De Vos", "Maarten", ""]]}, {"id": "1907.13188", "submitter": "Mark Thomas", "authors": "Mark Thomas, Bruce Martin, Katie Kowarski, Briand Gaudet, Stan Matwin", "title": "Marine Mammal Species Classification using Convolutional Neural Networks\n  and a Novel Acoustic Representation", "comments": "16 pages, To appear in ECML-PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research into automated systems for detecting and classifying marine mammals\nin acoustic recordings is expanding internationally due to the necessity to\nanalyze large collections of data for conservation purposes. In this work, we\npresent a Convolutional Neural Network that is capable of classifying the\nvocalizations of three species of whales, non-biological sources of noise, and\na fifth class pertaining to ambient noise. In this way, the classifier is\ncapable of detecting the presence and absence of whale vocalizations in an\nacoustic recording. Through transfer learning, we show that the classifier is\ncapable of learning high-level representations and can generalize to additional\nspecies. We also propose a novel representation of acoustic signals that builds\nupon the commonly used spectrogram representation by way of interpolating and\nstacking multiple spectrograms produced using different Short-time Fourier\nTransform (STFT) parameters. The proposed representation is particularly\neffective for the task of marine mammal species classification where the\nacoustic events we are attempting to classify are sensitive to the parameters\nof the STFT.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 19:17:41 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Thomas", "Mark", ""], ["Martin", "Bruce", ""], ["Kowarski", "Katie", ""], ["Gaudet", "Briand", ""], ["Matwin", "Stan", ""]]}, {"id": "1907.13196", "submitter": "Mohammed Amin Abdullah Dr", "authors": "Mohammed Amin Abdullah and Hang Ren and Haitham Bou Ammar and Vladimir\n  Milenkovic and Rui Luo and Mingtian Zhang and Jun Wang", "title": "Wasserstein Robust Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning algorithms, though successful, tend to over-fit to\ntraining environments hampering their application to the real-world. This paper\nproposes $\\text{W}\\text{R}^{2}\\text{L}$ -- a robust reinforcement learning\nalgorithm with significant robust performance on low and high-dimensional\ncontrol tasks. Our method formalises robust reinforcement learning as a novel\nmin-max game with a Wasserstein constraint for a correct and convergent solver.\nApart from the formulation, we also propose an efficient and scalable solver\nfollowing a novel zero-order optimisation method that we believe can be useful\nto numerical optimisation in general. We empirically demonstrate significant\ngains compared to standard and robust state-of-the-art algorithms on\nhigh-dimensional MuJuCo environments.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 19:42:52 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 12:17:48 GMT"}, {"version": "v3", "created": "Sat, 10 Aug 2019 10:05:35 GMT"}, {"version": "v4", "created": "Mon, 16 Sep 2019 22:43:14 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Abdullah", "Mohammed Amin", ""], ["Ren", "Hang", ""], ["Ammar", "Haitham Bou", ""], ["Milenkovic", "Vladimir", ""], ["Luo", "Rui", ""], ["Zhang", "Mingtian", ""], ["Wang", "Jun", ""]]}, {"id": "1907.13208", "submitter": "Donghui Yan", "authors": "Donghui Yan, Ying Xu", "title": "Learning over inherently distributed data", "comments": "26 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent decades have seen a surge of interests in distributed computing.\nExisting work focus primarily on either distributed computing platforms, data\nquery tools, or, algorithms to divide big data and conquer at individual\nmachines etc. It is, however, increasingly often that the data of interest are\ninherently distributed, i.e., data are stored at multiple distributed sites due\nto diverse collection channels, business operations etc. We propose to enable\nlearning and inference in such a setting via a general framework based on the\ndistortion minimizing local transformations. This framework only requires a\nsmall amount of local signatures to be shared among distributed sites,\neliminating the need of having to transmitting big data. Computation can be\ndone very efficiently via parallel local computation. The error incurred due to\ndistributed computing vanishes when increasing the size of local signatures. As\nthe shared data need not be in their original form, data privacy may also be\npreserved. Experiments on linear (logistic) regression and Random Forests have\nshown promise of this approach. This framework is expected to apply to a\ngeneral class of tools in learning and inference with the continuity property.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 20:11:19 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Yan", "Donghui", ""], ["Xu", "Ying", ""]]}, {"id": "1907.13216", "submitter": "Seyed Hamed Fatemi Langroudi", "authors": "Hamed F. Langroudi, Zachariah Carmichael, and Dhireesha Kudithipudi", "title": "Deep Learning Training on the Edge with Low-Precision Posits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the posit numerical format has shown promise for DNN data\nrepresentation and compute with ultra-low precision ([5..8]-bit). However,\nmajority of studies focus only on DNN inference. In this work, we propose DNN\ntraining using posits and compare with the floating point training. We evaluate\non both MNIST and Fashion MNIST corpuses, where 16-bit posits outperform 16-bit\nfloating point for end-to-end DNN training.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 20:45:09 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Langroudi", "Hamed F.", ""], ["Carmichael", "Zachariah", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "1907.13220", "submitter": "Lantao Yu", "authors": "Lantao Yu, Jiaming Song, Stefano Ermon", "title": "Multi-Agent Adversarial Inverse Reinforcement Learning", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents are prone to undesired behaviors due to reward\nmis-specification. Finding a set of reward functions to properly guide agent\nbehaviors is particularly challenging in multi-agent scenarios. Inverse\nreinforcement learning provides a framework to automatically acquire suitable\nreward functions from expert demonstrations. Its extension to multi-agent\nsettings, however, is difficult due to the more complex notions of rational\nbehaviors. In this paper, we propose MA-AIRL, a new framework for multi-agent\ninverse reinforcement learning, which is effective and scalable for Markov\ngames with high-dimensional state-action space and unknown dynamics. We derive\nour algorithm based on a new solution concept and maximum pseudolikelihood\nestimation within an adversarial reward learning framework. In the experiments,\nwe demonstrate that MA-AIRL can recover reward functions that are highly\ncorrelated with ground truth ones, and significantly outperforms prior methods\nin terms of policy imitation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 20:57:43 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Yu", "Lantao", ""], ["Song", "Jiaming", ""], ["Ermon", "Stefano", ""]]}, {"id": "1907.13246", "submitter": "Caio Ponte", "authors": "Caio Ponte, Carlos Caminha, Rafael Bomfim, Ronaldo Moreira, Vasco\n  Furtado", "title": "A Temporal Clustering Algorithm for Achieving the trade-off between the\n  User Experience and the Equipment Economy in the Context of IoT", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present here the Temporal Clustering Algorithm (TCA), an incremental\nlearning algorithm applicable to problems of anticipatory computing in the\ncontext of the Internet of Things. This algorithm was tested in a specific\nprediction scenario of consumption of an electric water dispenser typically\nused in tropical countries, in which the ambient temperature is around\n30-degree Celsius. In this context, the user typically wants to drinking iced\nwater therefore uses the cooler function of the dispenser. Real and synthetic\nwater consumption data was used to test a forecasting capacity on how much\nenergy can be saved by predicting the pattern of use of the equipment. In\naddition to using a small constant amount of memory, which allows the algorithm\nto be implemented at the lowest cost, while using microcontrollers with a small\namount of memory (less than 1Kbyte) available on the market. The algorithm can\nalso be configured according to user preference, prioritizing comfort, keeping\nthe water at the desired temperature longer, or prioritizing energy savings.\nThe main result is that the TCA achieved energy savings of up to 40% compared\nto the conventional mode of operation of the dispenser with an average success\nrate higher than 90% in its times of use.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 22:17:27 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Ponte", "Caio", ""], ["Caminha", "Carlos", ""], ["Bomfim", "Rafael", ""], ["Moreira", "Ronaldo", ""], ["Furtado", "Vasco", ""]]}, {"id": "1907.13257", "submitter": "Saptadeep Pal", "authors": "Saptadeep Pal and Eiman Ebrahimi and Arslan Zulfiqar and Yaosheng Fu\n  and Victor Zhang and Szymon Migacz and David Nellans and Puneet Gupta", "title": "Optimizing Multi-GPU Parallelization Strategies for Deep Learning\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deploying deep learning (DL) models across multiple compute devices to train\nlarge and complex models continues to grow in importance because of the demand\nfor faster and more frequent training. Data parallelism (DP) is the most widely\nused parallelization strategy, but as the number of devices in data parallel\ntraining grows, so does the communication overhead between devices.\nAdditionally, a larger aggregate batch size per step leads to statistical\nefficiency loss, i.e., a larger number of epochs are required to converge to a\ndesired accuracy. These factors affect overall training time and beyond a\ncertain number of devices, the speedup from leveraging DP begins to scale\npoorly. In addition to DP, each training step can be accelerated by exploiting\nmodel parallelism (MP). This work explores hybrid parallelization, where each\ndata parallel worker is comprised of more than one device, across which the\nmodel dataflow graph (DFG) is split using MP. We show that at scale, hybrid\ntraining will be more effective at minimizing end-to-end training time than\nexploiting DP alone. We project that for Inception-V3, GNMT, and BigLSTM, the\nhybrid strategy provides an end-to-end training speedup of at least 26.5%, 8%,\nand 22% respectively compared to what DP alone can achieve at scale.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 23:20:50 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Pal", "Saptadeep", ""], ["Ebrahimi", "Eiman", ""], ["Zulfiqar", "Arslan", ""], ["Fu", "Yaosheng", ""], ["Zhang", "Victor", ""], ["Migacz", "Szymon", ""], ["Nellans", "David", ""], ["Gupta", "Puneet", ""]]}, {"id": "1907.13276", "submitter": "Ji Meng Loh", "authors": "Laure Berti-Equille, Ji Meng Loh and Saravanan Thirumuruganathan", "title": "Are Outlier Detection Methods Resilient to Sampling?", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlier detection is a fundamental task in data mining and has many\napplications including detecting errors in databases. While there has been\nextensive prior work on methods for outlier detection, modern datasets often\nhave sizes that are beyond the ability of commonly used methods to process the\ndata within a reasonable time. To overcome this issue, outlier detection\nmethods can be trained over samples of the full-sized dataset. However, it is\nnot clear how a model trained on a sample compares with one trained on the\nentire dataset. In this paper, we introduce the notion of resilience to\nsampling for outlier detection methods. Orthogonal to traditional performance\nmetrics such as precision/recall, resilience represents the extent to which the\noutliers detected by a method applied to samples from a sampling scheme matches\nthose when applied to the whole dataset. We propose a novel approach for\nestimating the resilience to sampling of both individual outlier methods and\ntheir ensembles. We performed an extensive experimental study on synthetic and\nreal-world datasets where we study seven diverse and representative outlier\ndetection methods, compare results obtained from samples versus those obtained\nfrom the whole datasets and evaluate the accuracy of our resilience estimates.\nWe observed that the methods are not equally resilient to a given sampling\nscheme and it is often the case that careful joint selection of both the\nsampling scheme and the outlier detection method is necessary. It is our hope\nthat the paper initiates research on designing outlier detection algorithms\nthat are resilient to sampling.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 01:32:26 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Berti-Equille", "Laure", ""], ["Loh", "Ji Meng", ""], ["Thirumuruganathan", "Saravanan", ""]]}, {"id": "1907.13301", "submitter": "Gal Sadeh", "authors": "Gal Sadeh and Edith Cohen and Haim Kaplan", "title": "Sample Complexity Bounds for Influence Maximization", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Influence maximization (IM) is the problem of finding for a given $s\\geq 1$ a\nset $S$ of $|S|=s$ nodes in a network with maximum influence. With stochastic\ndiffusion models, the influence of a set $S$ of seed nodes is defined as the\nexpectation of its reachability over simulations, where each simulation\nspecifies a deterministic reachability function. Two well-studied special cases\nare the Independent Cascade (IC) and the Linear Threshold (LT) models of Kempe,\nKleinberg, and Tardos. The influence function in stochastic diffusion is\nunbiasedly estimated by averaging reachability values over i.i.d. simulations.\nWe study the IM sample complexity: the number of simulations needed to\ndetermine a $(1-\\epsilon)$-approximate maximizer with confidence $1-\\delta$.\nOur main result is a surprising upper bound of $O( s \\tau \\epsilon^{-2} \\ln\n\\frac{n}{\\delta})$ for a broad class of models that includes IC and LT models\nand their mixtures, where $n$ is the number of nodes and $\\tau$ is the number\nof diffusion steps. Generally $\\tau \\ll n$, so this significantly improves over\nthe generic upper bound of $O(s n \\epsilon^{-2} \\ln \\frac{n}{\\delta})$. Our\nsample complexity bounds are derived from novel upper bounds on the variance of\nthe reachability that allow for small relative error for influential sets and\nadditive error when influence is small. Moreover, we provide a data-adaptive\nmethod that can detect and utilize fewer simulations on models where it\nsuffices. Finally, we provide an efficient greedy design that computes an\n$(1-1/e-\\epsilon)$-approximate maximizer from simulations and applies to any\nsubmodular stochastic diffusion model that satisfies the variance bounds.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 03:57:00 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 22:30:43 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Sadeh", "Gal", ""], ["Cohen", "Edith", ""], ["Kaplan", "Haim", ""]]}, {"id": "1907.13307", "submitter": "Dmitriy Drusvyatskiy", "authors": "Damek Davis, Dmitriy Drusvyatskiy, Lin Xiao, Junyu Zhang", "title": "From low probability to high confidence in stochastic convex\n  optimization", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard results in stochastic convex optimization bound the number of\nsamples that an algorithm needs to generate a point with small function value\nin expectation. More nuanced high probability guarantees are rare, and\ntypically either rely on \"light-tail\" noise assumptions or exhibit worse sample\ncomplexity. In this work, we show that a wide class of stochastic optimization\nalgorithms for strongly convex problems can be augmented with high confidence\nbounds at an overhead cost that is only logarithmic in the confidence level and\npolylogarithmic in the condition number. The procedure we propose, called\nproxBoost, is elementary and builds on two well-known ingredients: robust\ndistance estimation and the proximal point method. We discuss consequences for\nboth streaming (online) algorithms and offline algorithms based on empirical\nrisk minimization.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 04:58:02 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 22:30:06 GMT"}, {"version": "v3", "created": "Thu, 17 Oct 2019 03:16:03 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Davis", "Damek", ""], ["Drusvyatskiy", "Dmitriy", ""], ["Xiao", "Lin", ""], ["Zhang", "Junyu", ""]]}, {"id": "1907.13308", "submitter": "Thanh Tung Khuat", "authors": "Thanh Tung Khuat, Bogdan Gabrys", "title": "A comparative study of general fuzzy min-max neural networks for pattern\n  classification problems", "comments": "18 pages, 7 figures, 12 tables", "journal-ref": "Neurocomputing, 2019", "doi": "10.1016/j.neucom.2019.12.090", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  General fuzzy min-max (GFMM) neural network is a generalization of fuzzy\nneural networks formed by hyperbox fuzzy sets for classification and clustering\nproblems. Two principle algorithms are deployed to train this type of neural\nnetwork, i.e., incremental learning and agglomerative learning. This paper\npresents a comprehensive empirical study of performance influencing factors,\nadvantages, and drawbacks of the general fuzzy min-max neural network on\npattern classification problems. The subjects of this study include (1) the\nimpact of maximum hyperbox size, (2) the influence of the similarity threshold\nand measures on the agglomerative learning algorithm, (3) the effect of data\npresentation order, (4) comparative performance evaluation of the GFMM with\nother types of fuzzy min-max neural networks and prevalent machine learning\nalgorithms. The experimental results on benchmark datasets widely used in\nmachine learning showed overall strong and weak points of the GFMM classifier.\nThese outcomes also informed potential research directions for this class of\nmachine learning algorithms in the future.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 04:58:49 GMT"}, {"version": "v2", "created": "Wed, 8 Jan 2020 06:29:23 GMT"}], "update_date": "2020-01-09", "authors_parsed": [["Khuat", "Thanh Tung", ""], ["Gabrys", "Bogdan", ""]]}, {"id": "1907.13353", "submitter": "Zhen Gao", "authors": "Zhen Gao, Maryam Zand and Jianhua Ruan", "title": "A Novel Multiple Classifier Generation and Combination Framework Based\n  on Fuzzy Clustering and Individualized Ensemble Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple classifier system (MCS) has become a successful alternative for\nimproving classification performance. However, studies have shown inconsistent\nresults for different MCSs, and it is often difficult to predict which MCS\nalgorithm works the best on a particular problem. We believe that the two\ncrucial steps of MCS - base classifier generation and multiple classifier\ncombination, need to be designed coordinately to produce robust results.\n  In this work, we show that for different testing instances, better\nclassifiers may be trained from different subdomains of training instances\nincluding, for example, neighboring instances of the testing instance, or even\ninstances far away from the testing instance. To utilize this intuition, we\npropose Individualized Classifier Ensemble (ICE). ICE groups training data into\noverlapping clusters, builds a classifier for each cluster, and then associates\neach training instance to the top-performing models while taking into account\nmodel types and frequency. In testing, ICE finds the k most similar training\ninstances for a testing instance, then predicts class label of the testing\ninstance by averaging the prediction from models associated with these training\ninstances.\n  Evaluation results on 49 benchmarks show that ICE has a stable improvement on\na significant proportion of datasets over existing MCS methods. ICE provides a\nnovel choice of utilizing internal patterns among instances to improve\nclassification, and can be easily combined with various classification models\nand applied to many application domains.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 07:47:54 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Gao", "Zhen", ""], ["Zand", "Maryam", ""], ["Ruan", "Jianhua", ""]]}, {"id": "1907.13359", "submitter": "Xiang Zhang", "authors": "Xiang Zhang, Xiaocong Chen, Lina Yao, Chang Ge, Manqing Dong", "title": "Deep Neural Network Hyperparameter Optimization with Orthogonal Array\n  Tuning", "comments": null, "journal-ref": "Published on ICONIP 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms have achieved excellent performance lately in a wide\nrange of fields (e.g., computer version). However, a severe challenge faced by\ndeep learning is the high dependency on hyper-parameters. The algorithm results\nmay fluctuate dramatically under the different configuration of\nhyper-parameters. Addressing the above issue, this paper presents an efficient\nOrthogonal Array Tuning Method (OATM) for deep learning hyper-parameter tuning.\nWe describe the OATM approach in five detailed steps and elaborate on it using\ntwo widely used deep neural network structures (Recurrent Neural Networks and\nConvolutional Neural Networks). The proposed method is compared to the\nstate-of-the-art hyper-parameter tuning methods including manually (e.g., grid\nsearch and random search) and automatically (e.g., Bayesian Optimization) ones.\nThe experiment results state that OATM can significantly save the tuning time\ncompared to the state-of-the-art methods while preserving the satisfying\nperformance. The codes are open in GitHub\n(https://github.com/xiangzhang1015/OATM)\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 08:15:49 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 10:09:05 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Zhang", "Xiang", ""], ["Chen", "Xiaocong", ""], ["Yao", "Lina", ""], ["Ge", "Chang", ""], ["Dong", "Manqing", ""]]}, {"id": "1907.13411", "submitter": "Pablo Samuel Castro", "authors": "Pablo Samuel Castro, Shijian Li, Daqing Zhang", "title": "Inverse Reinforcement Learning with Multiple Ranked Experts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning to behave optimally in a Markov Decision\nProcess when a reward function is not specified, but instead we have access to\na set of demonstrators of varying performance. We assume the demonstrators are\nclassified into one of k ranks, and use ideas from ordinal regression to find a\nreward function that maximizes the margin between the different ranks. This\napproach is based on the idea that agents should not only learn how to behave\nfrom experts, but also how not to behave from non-experts. We show there are\nMDPs where important differences in the reward function would be hidden from\nexisting algorithms by the behaviour of the expert. Our method is particularly\nuseful for problems where we have access to a large set of agent behaviours\nwith varying degrees of expertise (such as through GPS or cellphones). We\nhighlight the differences between our approach and existing methods using a\nsimple grid domain and demonstrate its efficacy on determining\npassenger-finding strategies for taxi drivers, using a large dataset of GPS\ntrajectories.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 10:49:26 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Castro", "Pablo Samuel", ""], ["Li", "Shijian", ""], ["Zhang", "Daqing", ""]]}, {"id": "1907.13413", "submitter": "Waleed Yousef", "authors": "Waleed A. Yousef", "title": "A Leisurely Look at Versions and Variants of the Cross Validation\n  Estimator", "comments": "The paper is currently under review in Pattern Recognition Letters\n  (PRL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many versions of cross-validation (CV) exist in the literature; and each\nversion though has different variants. All are used interchangeably by many\npractitioners; yet, without explanation to the connection or difference among\nthem. This article has three contributions. First, it starts by mathematical\nformalization of these different versions and variants that estimate the error\nrate and the Area Under the ROC Curve (AUC) of a classification rule, to show\nthe connection and difference among them. Second, we prove some of their\nproperties and prove that many variants are either redundant or \"not smooth\".\nHence, we suggest to abandon all redundant versions and variants and only keep\nthe leave-one-out, the $K$-fold, and the repeated $K$-fold. We show that the\nlatter is the only among the three versions that is \"smooth\" and hence looks\nmathematically like estimating the mean performance of the classification\nrules. However, empirically, for the known phenomenon of \"weak correlation\",\nwhich we explain mathematically and experimentally, it estimates both\nconditional and mean performance almost with the same accuracy. Third, we\nconclude the article with suggesting two research points that may answer the\nremaining question of whether we can come up with a finalist among the three\nestimators: (1) a comparative study, that is much more comprehensive than those\navailable in literature and conclude no overall winner, is needed to consider a\nwide range of distributions, datasets, and classifiers including complex ones\nobtained via the recent deep learning approach. (2) we sketch the path of\nderiving a rigorous method for estimating the variance of the only \"smooth\"\nversion, repeated $K$-fold CV, rather than those ad-hoc methods available in\nthe literature that ignore the covariance structure among the folds of CV.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 10:55:51 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 15:39:25 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 15:50:49 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Yousef", "Waleed A.", ""]]}, {"id": "1907.13418", "submitter": "Ryutaro Tanno", "authors": "Ryutaro Tanno, Daniel Worrall, Enrico Kaden, Aurobrata Ghosh,\n  Francesco Grussu, Alberto Bizzi, Stamatios N. Sotiropoulos, Antonio\n  Criminisi, Daniel C. Alexander", "title": "Uncertainty Quantification in Deep Learning for Safer Neuroimage\n  Enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning (DL) has shown great potential in medical image enhancement\nproblems, such as super-resolution or image synthesis. However, to date, little\nconsideration has been given to uncertainty quantification over the output\nimage. Here we introduce methods to characterise different components of\nuncertainty in such problems and demonstrate the ideas using diffusion MRI\nsuper-resolution. Specifically, we propose to account for $intrinsic$\nuncertainty through a heteroscedastic noise model and for $parameter$\nuncertainty through approximate Bayesian inference, and integrate the two to\nquantify $predictive$ uncertainty over the output image. Moreover, we introduce\na method to propagate the predictive uncertainty on a multi-channelled image to\nderived scalar parameters, and separately quantify the effects of intrinsic and\nparameter uncertainty therein. The methods are evaluated for super-resolution\nof two different signal representations of diffusion MR images---DTIs and Mean\nApparent Propagator MRI---and their derived quantities such as MD and FA, on\nmultiple datasets of both healthy and pathological human brains. Results\nhighlight three key benefits of uncertainty modelling for improving the safety\nof DL-based image enhancement systems. Firstly, incorporating uncertainty\nimproves the predictive performance even when test data departs from training\ndata. Secondly, the predictive uncertainty highly correlates with errors, and\nis therefore capable of detecting predictive \"failures\". Results demonstrate\nthat such an uncertainty measure enables subject-specific and voxel-wise risk\nassessment of the output images. Thirdly, we show that the method for\ndecomposing predictive uncertainty into its independent sources provides\nhigh-level \"explanations\" for the performance by quantifying how much\nuncertainty arises from the inherent difficulty of the task or the limited\ntraining examples.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 11:17:45 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Tanno", "Ryutaro", ""], ["Worrall", "Daniel", ""], ["Kaden", "Enrico", ""], ["Ghosh", "Aurobrata", ""], ["Grussu", "Francesco", ""], ["Bizzi", "Alberto", ""], ["Sotiropoulos", "Stamatios N.", ""], ["Criminisi", "Antonio", ""], ["Alexander", "Daniel C.", ""]]}, {"id": "1907.13432", "submitter": "Dong Liu", "authors": "Dong Liu, Minh Th\\`anh Vu, Saikat Chatterjee, Lars K. Rasmussen", "title": "Neural Network based Explicit Mixture Models and\n  Expectation-maximization based Learning", "comments": "IJCNN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two neural network based mixture models in this article. The\nproposed mixture models are explicit in nature. The explicit models have\nanalytical forms with the advantages of computing likelihood and efficiency of\ngenerating samples. Computation of likelihood is an important aspect of our\nmodels. Expectation-maximization based algorithms are developed for learning\nparameters of the proposed models. We provide sufficient conditions to realize\nthe expectation-maximization based learning. The main requirements are\ninvertibility of neural networks that are used as generators and Jacobian\ncomputation of functional form of the neural networks. The requirements are\npractically realized using a flow-based neural network. In our first mixture\nmodel, we use multiple flow-based neural networks as generators. Naturally the\nmodel is complex. A single latent variable is used as the common input to all\nthe neural networks. The second mixture model uses a single flow-based neural\nnetwork as a generator to reduce complexity. The single generator has a latent\nvariable input that follows a Gaussian mixture distribution. We demonstrate\nefficiency of proposed mixture models through extensive experiments for\ngenerating samples and maximum likelihood based classification.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 11:57:17 GMT"}, {"version": "v2", "created": "Sun, 24 May 2020 19:57:55 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Liu", "Dong", ""], ["Vu", "Minh Th\u00e0nh", ""], ["Chatterjee", "Saikat", ""], ["Rasmussen", "Lars K.", ""]]}, {"id": "1907.13440", "submitter": "William Guss", "authors": "William H. Guss, Brandon Houghton, Nicholay Topin, Phillip Wang,\n  Cayden Codel, Manuela Veloso, Ruslan Salakhutdinov", "title": "MineRL: A Large-Scale Dataset of Minecraft Demonstrations", "comments": "Accepted at IJCAI 2019, 7 pages, 6 figures. arXiv admin note: text\n  overlap with arXiv:1904.10079", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sample inefficiency of standard deep reinforcement learning methods\nprecludes their application to many real-world problems. Methods which leverage\nhuman demonstrations require fewer samples but have been researched less. As\ndemonstrated in the computer vision and natural language processing\ncommunities, large-scale datasets have the capacity to facilitate research by\nserving as an experimental and benchmarking platform for new methods. However,\nexisting datasets compatible with reinforcement learning simulators do not have\nsufficient scale, structure, and quality to enable the further development and\nevaluation of methods focused on using human examples. Therefore, we introduce\na comprehensive, large-scale, simulator-paired dataset of human demonstrations:\nMineRL. The dataset consists of over 60 million automatically annotated\nstate-action pairs across a variety of related tasks in Minecraft, a dynamic,\n3D, open-world environment. We present a novel data collection scheme which\nallows for the ongoing introduction of new tasks and the gathering of complete\nstate information suitable for a variety of methods. We demonstrate the\nhierarchality, diversity, and scale of the MineRL dataset. Further, we show the\ndifficulty of the Minecraft domain along with the potential of MineRL in\ndeveloping techniques to solve key research challenges within it.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 18:10:30 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Guss", "William H.", ""], ["Houghton", "Brandon", ""], ["Topin", "Nicholay", ""], ["Wang", "Phillip", ""], ["Codel", "Cayden", ""], ["Veloso", "Manuela", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1907.13443", "submitter": "Jo\\~ao Pereira", "authors": "Jo\\~ao Pereira and Albert Groen and Erik Stroes and Evgeni Levin", "title": "Graph Space Embedding", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Graph Space Embedding (GSE), a technique that maps the input\ninto a space where interactions are implicitly encoded, with little\ncomputations required. We provide theoretical results on an optimal regime for\nthe GSE, namely a feasibility region for its parameters, and demonstrate the\nexperimental relevance of our findings. Next, we introduce a strategy to gain\ninsight on which interactions are responsible for the certain predictions,\npaving the way for a far more transparent model. In an empirical evaluation on\na real-world clinical cohort containing patients with suspected coronary artery\ndisease, the GSE achieves far better performance than traditional algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 12:21:50 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Pereira", "Jo\u00e3o", ""], ["Groen", "Albert", ""], ["Stroes", "Erik", ""], ["Levin", "Evgeni", ""]]}, {"id": "1907.13463", "submitter": "Feihu Huang", "authors": "Feihu Huang, Shangqian Gao, Jian Pei and Heng Huang", "title": "Nonconvex Zeroth-Order Stochastic ADMM Methods with Lower Function Query\n  Complexity", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zeroth-order methods powerful optimization tools for solving many machine\nlearning problems because it only need function values (not gradient) in the\noptimization. Recently, although many zeroth-order methods have been developed,\nthese approaches still have two main drawbacks: 1) high function query\ncomplexity; 2) not being well suitable for solving the problems with complex\npenalties and constraints. To address these challenging drawbacks, in this\npaper, we propose a class of faster zeroth-order stochastic alternating\ndirection method of multipliers (ADMM) methods (ZO-SPIDER-ADMM) to solve the\nnonconvex finite-sum problems with multiple nonsmooth penalties. Moreover, we\nprove that the ZO-SPIDER-ADMM methods can achieve a lower function query\ncomplexity of $O(nd+dn^{\\frac{1}{2}}\\epsilon^{-1})$ for finding an\n$\\epsilon$-stationary point, which improves the existing best nonconvex\nzeroth-order ADMM methods by a factor of $O(d^{\\frac{1}{3}}n^{\\frac{1}{6}})$,\nwhere $n$ and $d$ denote the sample size and dimension of data, respectively.\nAt the same time, we propose a class of faster zeroth-order online ADMM methods\n(ZOO-ADMM+) to solve the nonconvex online problems with multiple nonsmooth\npenalties. We also prove that the proposed ZOO-ADMM+ methods can achieve a\nlower function query complexity of $O(d\\epsilon^{-\\frac{3}{2}})$, which\nimproves the existing best result by a factor of $O(\\epsilon^{-\\frac{1}{2}})$.\nExtensive experimental results on the structure adversarial attack on black-box\ndeep neural networks demonstrate the efficiency of our new algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 02:21:43 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2020 15:17:25 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 19:52:49 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Huang", "Feihu", ""], ["Gao", "Shangqian", ""], ["Pei", "Jian", ""], ["Huang", "Heng", ""]]}, {"id": "1907.13494", "submitter": "Alberto Testolin Dr.", "authors": "Alberto Cenzato, Alberto Testolin and Marco Zorzi", "title": "On the difficulty of learning and predicting the long-term dynamics of\n  bouncing objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to accurately predict the surrounding environment is a\nfoundational principle of intelligence in biological and artificial agents. In\nrecent years, a variety of approaches have been proposed for learning to\npredict the physical dynamics of objects interacting in a visual scene. Here we\nconduct a systematic empirical evaluation of several state-of-the-art\nunsupervised deep learning models that are considered capable of learning the\nspatio-temporal structure of a popular dataset composed by synthetic videos of\nbouncing objects. We show that most of the models indeed obtain high accuracy\non the standard benchmark of predicting the next frame of a sequence, and one\nof them even achieves state-of-the-art performance. However, all models fall\nshort when probed with the more challenging task of generating multiple\nsuccessive frames. Our results show that the ability to perform short-term\npredictions does not imply that the model has captured the underlying structure\nand dynamics of the visual environment, thereby calling for a careful\nrethinking of the metrics commonly adopted for evaluating temporal models. We\nalso investigate whether the learning outcome could be affected by the use of\ncurriculum-based teaching.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 13:29:34 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Cenzato", "Alberto", ""], ["Testolin", "Alberto", ""], ["Zorzi", "Marco", ""]]}, {"id": "1907.13513", "submitter": "Ahmad Ilham", "authors": "Andy Arief Setyawan, Ahmad Ilham", "title": "A novel framework of the fuzzy c-means distances problem based weighted\n  distance", "comments": "25 pages, 6 figure, was submitted online submission at the Applied\n  Computing and Informatics, Elsevier, July 18, 2019. King Saud University,\n  Riyadh, Saudi Arabia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clustering is one of the major roles in data mining that is widely\napplication in pattern recognition and image segmentation. Fuzzy C-means (FCM)\nis the most used clustering algorithm that proven efficient, fast and easy to\nimplement, however, FCM uses the Euclidean distance that often leads to\nclustering errors, especially when handling multidimensional and noisy data. In\nthe last few years, many distances metric have been proposed by researchers to\nimprove the performance of the FCM algorithms, and the majority of researchers\npropose weighted distance. In this paper, we proposed Canberra Weighted\nDistance to improved performance of the FCM algorithm. The experimental result\nusing the UCI data set show the proposed method is superior to the original\nmethod and other clustering methods.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 14:10:19 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Setyawan", "Andy Arief", ""], ["Ilham", "Ahmad", ""]]}, {"id": "1907.13525", "submitter": "Tiago Botari T.B.", "authors": "Tiago Botari, Rafael Izbicki, and Andre C. P. L. F. de Carvalho", "title": "Local Interpretation Methods to Machine Learning Using the Domain of the\n  Feature Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As machine learning becomes an important part of many real world applications\naffecting human lives, new requirements, besides high predictive accuracy,\nbecome important. One important requirement is transparency, which has been\nassociated with model interpretability. Many machine learning algorithms induce\nmodels difficult to interpret, named black box. Moreover, people have\ndifficulty to trust models that cannot be explained. In particular for machine\nlearning, many groups are investigating new methods able to explain black box\nmodels. These methods usually look inside the black models to explain their\ninner work. By doing so, they allow the interpretation of the decision making\nprocess used by black box models. Among the recently proposed model\ninterpretation methods, there is a group, named local estimators, which are\ndesigned to explain how the label of particular instance is predicted. For\nsuch, they induce interpretable models on the neighborhood of the instance to\nbe explained. Local estimators have been successfully used to explain specific\npredictions. Although they provide some degree of model interpretability, it is\nstill not clear what is the best way to implement and apply them. Open\nquestions include: how to best define the neighborhood of an instance? How to\ncontrol the trade-off between the accuracy of the interpretation method and its\ninterpretability? How to make the obtained solution robust to small variations\non the instance to be explained? To answer to these questions, we propose and\ninvestigate two strategies: (i) using data instance properties to provide\nimproved explanations, and (ii) making sure that the neighborhood of an\ninstance is properly defined by taking the geometry of the domain of the\nfeature space into account. We evaluate these strategies in a regression task\nand present experimental results that show that they can improve local\nexplanations.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 14:28:55 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Botari", "Tiago", ""], ["Izbicki", "Rafael", ""], ["de Carvalho", "Andre C. P. L. F.", ""]]}, {"id": "1907.13548", "submitter": "Alessio Russo", "authors": "Alessio Russo, Alexandre Proutiere", "title": "Optimal Attacks on Reinforcement Learning Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control policies, trained using the Deep Reinforcement Learning, have been\nrecently shown to be vulnerable to adversarial attacks introducing even very\nsmall perturbations to the policy input. The attacks proposed so far have been\ndesigned using heuristics, and build on existing adversarial example crafting\ntechniques used to dupe classifiers in supervised learning. In contrast, this\npaper investigates the problem of devising optimal attacks, depending on a\nwell-defined attacker's objective, e.g., to minimize the main agent average\nreward. When the policy and the system dynamics, as well as rewards, are known\nto the attacker, a scenario referred to as a white-box attack, designing\noptimal attacks amounts to solving a Markov Decision Process. For what we call\nblack-box attacks, where neither the policy nor the system is known, optimal\nattacks can be trained using Reinforcement Learning techniques. Through\nnumerical experiments, we demonstrate the efficiency of our attacks compared to\nexisting attacks (usually based on Gradient methods). We further quantify the\npotential impact of attacks and establish its connection to the smoothness of\nthe policy under attack. Smooth policies are naturally less prone to attacks\n(this explains why Lipschitz policies, with respect to the state, are more\nresilient). Finally, we show that from the main agent perspective, the system\nuncertainties and the attacker can be modeled as a Partially Observable Markov\nDecision Process. We actually demonstrate that using Reinforcement Learning\ntechniques tailored to POMDP (e.g. using Recurrent Neural Networks) leads to\nmore resilient policies.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 15:16:00 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Russo", "Alessio", ""], ["Proutiere", "Alexandre", ""]]}, {"id": "1907.13553", "submitter": "Anupama Nandi", "authors": "Anupama Nandi and Raef Bassily", "title": "Privately Answering Classification Queries in the Agnostic PAC Model", "comments": "Made a a small tweak in the analysis to save a factor of $1/\\epsilon$", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of differentially private release of classification\nqueries. In this problem, the goal is to design an algorithm that can\naccurately answer a sequence of classification queries based on a private\ntraining set while ensuring differential privacy. We formally study this\nproblem in the agnostic PAC model and derive a new upper bound on the private\nsample complexity. Our results improve over those obtained in a recent work\n[BTT18] for the agnostic PAC setting. In particular, we give an improved\nconstruction that yields a tighter upper bound on the sample complexity.\nMoreover, unlike [BTT18], our accuracy guarantee does not involve any blow-up\nin the approximation error associated with the given hypothesis class.\n  Given any hypothesis class with VC-dimension $d$, we show that our\nconstruction can privately answer up to $m$ classification queries with average\nexcess error $\\alpha$ using a private sample of size $\\approx\n\\frac{d}{\\alpha^2}\\,\\max\\left(1, \\sqrt{m}\\,\\alpha^{3/2}\\right)$. Using recent\nresults on private learning with auxiliary public data, we extend our\nconstruction to show that one can privately answer any number of classification\nqueries with average excess error $\\alpha$ using a private sample of size\n$\\approx \\frac{d}{\\alpha^2}\\,\\max\\left(1, \\sqrt{d}\\,\\alpha\\right)$. When\n$\\alpha=O\\left(\\frac{1}{\\sqrt{d}}\\right)$, our private sample complexity bound\nis essentially optimal.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 15:28:12 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 05:22:10 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 04:09:58 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Nandi", "Anupama", ""], ["Bassily", "Raef", ""]]}, {"id": "1907.13561", "submitter": "Vahab Mostafapour", "authors": "Vahab Mostafapour, O\\u{g}uz Dikenelli", "title": "Attention-Wrapped Hierarchical BLSTMs for DDI Extraction", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drug-Drug Interactions (DDIs) Extraction refers to the efforts to generate\nhand-made or automatic tools to extract embedded information from text and\nliterature in the biomedical domain.\n  Because of restrictions in hand-made efforts and their lower speed,\nMachine-Learning, or Deep-Learning approaches have become more popular for\nextracting DDIs. In this study, we propose a novel and generic Deep-Learning\nmodel which wraps Hierarchical Bidirectional LSTMs with two Attention\nMechanisms that outperforms state-of-the-art models for DDIs Extraction, based\non the DDIExtraction-2013 corpora. This model has obtained the macro F1-score\nof 0.785, and the precision of 0.80.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 15:42:26 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Mostafapour", "Vahab", ""], ["Dikenelli", "O\u011fuz", ""]]}, {"id": "1907.13616", "submitter": "Krishnakumar Balasubramanian", "authors": "Abhishek Roy, Krishnakumar Balasubramanian, Saeed Ghadimi, Prasant\n  Mohapatra", "title": "Multi-Point Bandit Algorithms for Nonstationary Online Nonconvex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.OC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandit algorithms have been predominantly analyzed in the convex setting with\nfunction-value based stationary regret as the performance measure. In this\npaper, motivated by online reinforcement learning problems, we propose and\nanalyze bandit algorithms for both general and structured nonconvex problems\nwith nonstationary (or dynamic) regret as the performance measure, in both\nstochastic and non-stochastic settings. First, for general nonconvex functions,\nwe consider nonstationary versions of first-order and second-order stationary\nsolutions as a regret measure, motivated by similar performance measures for\noffline nonconvex optimization. In the case of second-order stationary solution\nbased regret, we propose and analyze online and bandit versions of the cubic\nregularized Newton's method. The bandit version is based on estimating the\nHessian matrices in the bandit setting, based on second-order Gaussian Stein's\nidentity. Our nonstationary regret bounds in terms of second-order stationary\nsolutions have interesting consequences for avoiding saddle points in the\nbandit setting. Next, for weakly quasi convex functions and monotone weakly\nsubmodular functions we consider nonstationary regret measures in terms of\nfunction-values; such structured classes of nonconvex functions enable one to\nconsider regret measure defined in terms of function values, similar to convex\nfunctions. For this case of function-value, and first-order stationary solution\nbased regret measures, we provide regret bounds in both the low- and\nhigh-dimensional settings, for some scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 17:32:07 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 07:06:09 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Roy", "Abhishek", ""], ["Balasubramanian", "Krishnakumar", ""], ["Ghadimi", "Saeed", ""], ["Mohapatra", "Prasant", ""]]}, {"id": "1907.13625", "submitter": "Michael Tschannen", "authors": "Michael Tschannen, Josip Djolonga, Paul K. Rubenstein, Sylvain Gelly,\n  Mario Lucic", "title": "On Mutual Information Maximization for Representation Learning", "comments": "ICLR 2020. Michael Tschannen and Josip Djolonga contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent methods for unsupervised or self-supervised representation\nlearning train feature extractors by maximizing an estimate of the mutual\ninformation (MI) between different views of the data. This comes with several\nimmediate problems: For example, MI is notoriously hard to estimate, and using\nit as an objective for representation learning may lead to highly entangled\nrepresentations due to its invariance under arbitrary invertible\ntransformations. Nevertheless, these methods have been repeatedly shown to\nexcel in practice. In this paper we argue, and provide empirical evidence, that\nthe success of these methods cannot be attributed to the properties of MI\nalone, and that they strongly depend on the inductive bias in both the choice\nof feature extractor architectures and the parametrization of the employed MI\nestimators. Finally, we establish a connection to deep metric learning and\nargue that this interpretation may be a plausible explanation for the success\nof the recently introduced methods.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 17:50:51 GMT"}, {"version": "v2", "created": "Thu, 23 Jan 2020 09:08:54 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Tschannen", "Michael", ""], ["Djolonga", "Josip", ""], ["Rubenstein", "Paul K.", ""], ["Gelly", "Sylvain", ""], ["Lucic", "Mario", ""]]}]