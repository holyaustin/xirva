[{"id": "1804.00021", "submitter": "Xishuang Dong", "authors": "Xishuang Dong, Hsiang-Huang Wu, Yuzhong Yan, Lijun Qian", "title": "Hierarchical Transfer Convolutional Neural Networks for Image\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the issue of how to enhance the generalization\nperformance of convolutional neural networks (CNN) in the early learning stage\nfor image classification. This is motivated by real-time applications that\nrequire the generalization performance of CNN to be satisfactory within limited\ntraining time. In order to achieve this, a novel hierarchical transfer CNN\nframework is proposed. It consists of a group of shallow CNNs and a cloud CNN,\nwhere the shallow CNNs are trained firstly and then the first layers of the\ntrained shallow CNNs are used to initialize the first layer of the cloud CNN.\nThis method will boost the generalization performance of the cloud CNN\nsignificantly, especially during the early stage of training. Experiments using\nCIFAR-10 and ImageNet datasets are performed to examine the proposed method.\nResults demonstrate the improvement of testing accuracy is 12% on average and\nas much as 20% for the CIFAR-10 case while 5% testing accuracy improvement for\nthe ImageNet case during the early stage of learning. It is also shown that\nuniversal improvements of testing accuracy are obtained across different\nsettings of dropout and number of shallow CNNs.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 18:19:32 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 19:38:24 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Dong", "Xishuang", ""], ["Wu", "Hsiang-Huang", ""], ["Yan", "Yuzhong", ""], ["Qian", "Lijun", ""]]}, {"id": "1804.00057", "submitter": "Shujian Yu", "authors": "Shujian Yu, Jose C. Principe", "title": "Understanding Autoencoders with Information Theoretic Concepts", "comments": "Paper accepted by Neural Networks. Code for estimating information\n  quantities and drawing the information plane is available from\n  https://drive.google.com/drive/folders/1e5sIywZfmWp4Dn0WEesb6fqQRM0DIGxZ?usp=sharing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite their great success in practical applications, there is still a lack\nof theoretical and systematic methods to analyze deep neural networks. In this\npaper, we illustrate an advanced information theoretic methodology to\nunderstand the dynamics of learning and the design of autoencoders, a special\ntype of deep learning architectures that resembles a communication channel. By\ngeneralizing the information plane to any cost function, and inspecting the\nroles and dynamics of different layers using layer-wise information quantities,\nwe emphasize the role that mutual information plays in quantifying learning\nfrom data. We further suggest and also experimentally validate, for mean square\nerror training, three fundamental properties regarding the layer-wise flow of\ninformation and intrinsic dimensionality of the bottleneck layer, using\nrespectively the data processing inequality and the identification of a\nbifurcation point in the information plane that is controlled by the given\ndata. Our observations have a direct impact on the optimal design of\nautoencoders, the design of alternative feedforward training methods, and even\nin the problem of generalization.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 21:13:34 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 21:14:20 GMT"}, {"version": "v3", "created": "Wed, 8 May 2019 01:29:39 GMT"}], "update_date": "2019-05-09", "authors_parsed": [["Yu", "Shujian", ""], ["Principe", "Jose C.", ""]]}, {"id": "1804.00069", "submitter": "Edward Raff", "authors": "Edward Raff, Jared Sylvester, Charles Nicholas", "title": "Engineering a Simplified 0-Bit Consistent Weighted Sampling", "comments": null, "journal-ref": "In Proceedings of the 27th ACM International Conference on\n  Information and Knowledge Management. (2018) 1203-1212", "doi": "10.1145/3269206.3271690", "report-no": null, "categories": "stat.ML cs.DS cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Min-Hashing approach to sketching has become an important tool in data\nanalysis, information retrial, and classification. To apply it to real-valued\ndatasets, the ICWS algorithm has become a seminal approach that is widely used,\nand provides state-of-the-art performance for this problem space. However, ICWS\nsuffers a computational burden as the sketch size K increases. We develop a new\nSimplified approach to the ICWS algorithm, that enables us to obtain over 20x\nspeedups compared to the standard algorithm. The veracity of our approach is\ndemonstrated empirically on multiple datasets and scenarios, showing that our\nnew Simplified CWS obtains the same quality of results while being an order of\nmagnitude faster.\n", "versions": [{"version": "v1", "created": "Fri, 30 Mar 2018 22:12:44 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 07:45:44 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Raff", "Edward", ""], ["Sylvester", "Jared", ""], ["Nicholas", "Charles", ""]]}, {"id": "1804.00097", "submitter": "Alexey Kurakin", "authors": "Alexey Kurakin, Ian Goodfellow, Samy Bengio, Yinpeng Dong, Fangzhou\n  Liao, Ming Liang, Tianyu Pang, Jun Zhu, Xiaolin Hu, Cihang Xie, Jianyu Wang,\n  Zhishuai Zhang, Zhou Ren, Alan Yuille, Sangxia Huang, Yao Zhao, Yuzhe Zhao,\n  Zhonglin Han, Junjiajia Long, Yerkebulan Berdibekov, Takuya Akiba, Seiya\n  Tokui, Motoki Abe", "title": "Adversarial Attacks and Defences Competition", "comments": "36 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To accelerate research on adversarial examples and robustness of machine\nlearning classifiers, Google Brain organized a NIPS 2017 competition that\nencouraged researchers to develop new methods to generate adversarial examples\nas well as to develop new ways to defend against them. In this chapter, we\ndescribe the structure and organization of the competition and the solutions\ndeveloped by several of the top-placing teams.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 00:52:20 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Kurakin", "Alexey", ""], ["Goodfellow", "Ian", ""], ["Bengio", "Samy", ""], ["Dong", "Yinpeng", ""], ["Liao", "Fangzhou", ""], ["Liang", "Ming", ""], ["Pang", "Tianyu", ""], ["Zhu", "Jun", ""], ["Hu", "Xiaolin", ""], ["Xie", "Cihang", ""], ["Wang", "Jianyu", ""], ["Zhang", "Zhishuai", ""], ["Ren", "Zhou", ""], ["Yuille", "Alan", ""], ["Huang", "Sangxia", ""], ["Zhao", "Yao", ""], ["Zhao", "Yuzhe", ""], ["Han", "Zhonglin", ""], ["Long", "Junjiajia", ""], ["Berdibekov", "Yerkebulan", ""], ["Akiba", "Takuya", ""], ["Tokui", "Seiya", ""], ["Abe", "Motoki", ""]]}, {"id": "1804.00102", "submitter": "Cheng Ju", "authors": "Cheng Ju and Antoine Chambaz and Mark J. van der Laan", "title": "Collaborative targeted inference from continuously indexed nuisance\n  parameter estimators", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We wish to infer the value of a parameter at a law from which we sample\nindependent observations. The parameter is smooth and we can define two\nvariation-independent features of the law, its $Q$- and $G$-components, such\nthat estimating them consistently at a fast enough product of rates allows to\nbuild a confidence interval (CI) with a given asymptotic level from a plain\ntargeted minimum loss estimator (TMLE). Say that the above product is not fast\nenough and the algorithm for the $G$-component is fine-tuned by a real-valued\n$h$. A plain TMLE with an $h$ chosen by cross-validation would typically not\nyield a CI. We construct a collaborative TMLE (C-TMLE) and show under mild\nconditions that, if there exists an oracle $h$ that makes a bulky remainder\nterm asymptotically Gaussian, then the C-TMLE yields a CI. We illustrate our\nfindings with the inference of the average treatment effect. We conduct a\nsimulation study where the $G$-component is estimated by the LASSO and $h$ is\nthe bound on the coefficients' norms. It sheds light on small sample\nproperties, in the face of low- to high-dimensional baseline covariates, and\npossibly positivity violation.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 01:30:36 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 18:29:43 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Ju", "Cheng", ""], ["Chambaz", "Antoine", ""], ["van der Laan", "Mark J.", ""]]}, {"id": "1804.00104", "submitter": "Emilien Dupont", "authors": "Emilien Dupont", "title": "Learning Disentangled Joint Continuous and Discrete Representations", "comments": "NIPS camera ready, added quantitative evaluation and figures for\n  dsprites dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for learning disentangled and interpretable jointly\ncontinuous and discrete representations in an unsupervised manner. By\naugmenting the continuous latent distribution of variational autoencoders with\na relaxed discrete distribution and controlling the amount of information\nencoded in each latent unit, we show how continuous and categorical factors of\nvariation can be discovered automatically from data. Experiments show that the\nframework disentangles continuous and discrete generative factors on various\ndatasets and outperforms current disentangling methods when a discrete\ngenerative factor is prominent.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 01:37:56 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 01:13:36 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 13:53:07 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Dupont", "Emilien", ""]]}, {"id": "1804.00130", "submitter": "Saikat  Chatterjee", "authors": "Ahmed Zaki and Saikat Chatterjee and Partha P. Mitra and Lars K.\n  Rasmussen", "title": "Locally Convex Sparse Learning over Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a distributed learning setup where a sparse signal is estimated\nover a network. Our main interest is to save communication resource for\ninformation exchange over the network and reduce processing time. Each node of\nthe network uses a convex optimization based algorithm that provides a locally\noptimum solution for that node. The nodes exchange their signal estimates over\nthe network in order to refine their local estimates. At a node, the\noptimization algorithm is based on an $\\ell_1$-norm minimization with\nappropriate modifications to promote sparsity as well as to include influence\nof estimates from neighboring nodes. Our expectation is that local estimates in\neach node improve fast and converge, resulting in a limited demand for\ncommunication of estimates between nodes and reducing the processing time. We\nprovide restricted-isometry-property (RIP)-based theoretical analysis on\nestimation quality. In the scenario of clean observation, it is shown that the\nlocal estimates converge to the exact sparse signal under certain technical\nconditions. Simulation results show that the proposed algorithms show\ncompetitive performance compared to a globally optimum distributed LASSO\nalgorithm in the sense of convergence speed and estimation error.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 07:50:38 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Zaki", "Ahmed", ""], ["Chatterjee", "Saikat", ""], ["Mitra", "Partha P.", ""], ["Rasmussen", "Lars K.", ""]]}, {"id": "1804.00140", "submitter": "Sujit Gujar Dr", "authors": "P Manisha and Sujit Gujar", "title": "Generative Adversarial Networks (GANs): What it can generate and What it\n  cannot?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Generative Adversarial Networks (GANs) have received\nsignificant attention from the research community. With a straightforward\nimplementation and outstanding results, GANs have been used for numerous\napplications. Despite the success, GANs lack a proper theoretical explanation.\nThese models suffer from issues like mode collapse, non-convergence, and\ninstability during training. To address these issues, researchers have proposed\ntheoretically rigorous frameworks inspired by varied fields of Game theory,\nStatistical theory, Dynamical systems, etc.\n  In this paper, we propose to give an appropriate structure to study these\ncontributions systematically. We essentially categorize the papers based on the\nissues they raise and the kind of novelty they introduce to address them.\nBesides, we provide insight into how each of the discussed articles solves the\nconcerned problems. We compare and contrast different results and put forth a\nsummary of theoretical contributions about GANs with focus on image/visual\napplications. We expect this summary paper to give a bird's eye view to a\nperson wishing to understand the theoretical progress in GANs so far.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 09:01:21 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 03:50:51 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Manisha", "P", ""], ["Gujar", "Sujit", ""]]}, {"id": "1804.00217", "submitter": "Seyed Mohammadreza Mousavi Kalan", "authors": "A. Salman Avestimehr, Seyed Mohammadreza Mousavi Kalan, Mahdi\n  Soltanolkotabi", "title": "Fundamental Resource Trade-offs for Encoded Distributed Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with the shear size and complexity of today's massive data sets\nrequires computational platforms that can analyze data in a parallelized and\ndistributed fashion. A major bottleneck that arises in such modern distributed\ncomputing environments is that some of the worker nodes may run slow. These\nnodes a.k.a.~stragglers can significantly slow down computation as the slowest\nnode may dictate the overall computational time. A recent computational\nframework, called encoded optimization, creates redundancy in the data to\nmitigate the effect of stragglers. In this paper we develop novel mathematical\nunderstanding for this framework demonstrating its effectiveness in much\nbroader settings than was previously understood. We also analyze the\nconvergence behavior of iterative encoded optimization algorithms, allowing us\nto characterize fundamental trade-offs between convergence rate, size of data\nset, accuracy, computational load (or data redundancy), and straggler\ntoleration in this framework.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 21:29:33 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 18:04:19 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Avestimehr", "A. Salman", ""], ["Kalan", "Seyed Mohammadreza Mousavi", ""], ["Soltanolkotabi", "Mahdi", ""]]}, {"id": "1804.00218", "submitter": "Lazar Valkov", "authors": "Lazar Valkov, Dipak Chaudhari, Akash Srivastava, Charles Sutton,\n  Swarat Chaudhuri", "title": "HOUDINI: Lifelong Learning as Program Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neurosymbolic framework for the lifelong learning of algorithmic\ntasks that mix perception and procedural reasoning. Reusing high-level concepts\nacross domains and learning complex procedures are key challenges in lifelong\nlearning. We show that a program synthesis approach that combines gradient\ndescent with combinatorial search over programs can be a more effective\nresponse to these challenges than purely neural methods. Our framework, called\nHOUDINI, represents neural networks as strongly typed, differentiable\nfunctional programs that use symbolic higher-order combinators to compose a\nlibrary of neural functions. Our learning algorithm consists of: (1) a symbolic\nprogram synthesizer that performs a type-directed search over parameterized\nprograms, and decides on the library functions to reuse, and the architectures\nto combine them, while learning a sequence of tasks; and (2) a neural module\nthat trains these programs using stochastic gradient descent. We evaluate\nHOUDINI on three benchmarks that combine perception with the algorithmic tasks\nof counting, summing, and shortest-path computation. Our experiments show that\nHOUDINI transfers high-level concepts more effectively than traditional\ntransfer learning and progressive neural networks, and that the typed\nrepresentation of networks significantly accelerates the search.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 21:34:50 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 15:59:35 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Valkov", "Lazar", ""], ["Chaudhari", "Dipak", ""], ["Srivastava", "Akash", ""], ["Sutton", "Charles", ""], ["Chaudhuri", "Swarat", ""]]}, {"id": "1804.00222", "submitter": "Luke Metz", "authors": "Luke Metz, Niru Maheswaranathan, Brian Cheung, Jascha Sohl-Dickstein", "title": "Meta-Learning Update Rules for Unsupervised Representation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major goal of unsupervised learning is to discover data representations\nthat are useful for subsequent tasks, without access to supervised labels\nduring training. Typically, this involves minimizing a surrogate objective,\nsuch as the negative log likelihood of a generative model, with the hope that\nrepresentations useful for subsequent tasks will arise as a side effect. In\nthis work, we propose instead to directly target later desired tasks by\nmeta-learning an unsupervised learning rule which leads to representations\nuseful for those tasks. Specifically, we target semi-supervised classification\nperformance, and we meta-learn an algorithm -- an unsupervised weight update\nrule -- that produces representations useful for this task. Additionally, we\nconstrain our unsupervised update rule to a be a biologically-motivated,\nneuron-local function, which enables it to generalize to different neural\nnetwork architectures, datasets, and data modalities. We show that the\nmeta-learned update rule produces useful features and sometimes outperforms\nexisting unsupervised learning techniques. We further show that the\nmeta-learned unsupervised update rule generalizes to train networks with\ndifferent widths, depths, and nonlinearities. It also generalizes to train on\ndata with randomly permuted input dimensions and even generalizes from image\ndatasets to a text task.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2018 22:44:28 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 01:41:23 GMT"}, {"version": "v3", "created": "Tue, 26 Feb 2019 05:26:00 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Metz", "Luke", ""], ["Maheswaranathan", "Niru", ""], ["Cheung", "Brian", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1804.00236", "submitter": "Andreas K\\\"olsch", "authors": "Andreas K\\\"olsch, Ashutosh Mishra, Saurabh Varshneya, Muhammad Zeshan\n  Afzal, Marcus Liwicki", "title": "Recognizing Challenging Handwritten Annotations with Fully Convolutional\n  Networks", "comments": null, "journal-ref": "16th International Conference on Frontiers in Handwriting\n  Recognition 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a very challenging dataset of historic German documents\nand evaluates Fully Convolutional Neural Network (FCNN) based methods to locate\nhandwritten annotations of any kind in these documents. The handwritten\nannotations can appear in form of underlines and text by using various writing\ninstruments, e.g., the use of pencils makes the data more challenging. We train\nand evaluate various end-to-end semantic segmentation approaches and report the\nresults. The task is to classify the pixels of documents into two classes:\nbackground and handwritten annotation. The best model achieves a mean\nIntersection over Union (IoU) score of 95.6% on the test documents of the\npresented dataset. We also present a comparison of different strategies used\nfor data augmentation and training on our presented dataset. For evaluation, we\nuse the Layout Analysis Evaluator for the ICDAR 2017 Competition on Layout\nAnalysis for Challenging Medieval Manuscripts.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 00:56:02 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 12:40:23 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["K\u00f6lsch", "Andreas", ""], ["Mishra", "Ashutosh", ""], ["Varshneya", "Saurabh", ""], ["Afzal", "Muhammad Zeshan", ""], ["Liwicki", "Marcus", ""]]}, {"id": "1804.00243", "submitter": "Baochang Zhang", "authors": "Baochang Zhang, Lian Zhuo, Ze Wang, Jungong Han, Xiantong Zhen", "title": "The Structure Transfer Machine Theory and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning is a fundamental but challenging problem, especially\nwhen the distribution of data is unknown. We propose a new representation\nlearning method, termed Structure Transfer Machine (STM), which enables feature\nlearning process to converge at the representation expectation in a\nprobabilistic way. We theoretically show that such an expected value of the\nrepresentation (mean) is achievable if the manifold structure can be\ntransferred from the data space to the feature space. The resulting structure\nregularization term, named manifold loss, is incorporated into the loss\nfunction of the typical deep learning pipeline. The STM architecture is\nconstructed to enforce the learned deep representation to satisfy the intrinsic\nmanifold structure from the data, which results in robust features that suit\nvarious application scenarios, such as digit recognition, image classification\nand object tracking. Compared to state-of-the-art CNN architectures, we achieve\nthe better results on several commonly used benchmarks\\footnote{The source code\nis available. https://github.com/stmstmstm/stm }.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 01:40:10 GMT"}, {"version": "v2", "created": "Sun, 4 Aug 2019 08:17:02 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Zhang", "Baochang", ""], ["Zhuo", "Lian", ""], ["Wang", "Ze", ""], ["Han", "Jungong", ""], ["Zhen", "Xiantong", ""]]}, {"id": "1804.00281", "submitter": "Zhikuan Zhao", "authors": "Zhikuan Zhao, Jack K. Fitzsimons, Patrick Rebentrost, Vedran Dunjko\n  and Joseph F. Fitzsimons", "title": "Smooth input preparation for quantum and quantum-inspired machine\n  learning", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has recently emerged as a fruitful area for finding\npotential quantum computational advantage. Many of the quantum enhanced machine\nlearning algorithms critically hinge upon the ability to efficiently produce\nstates proportional to high-dimensional data points stored in a quantum\naccessible memory. Even given query access to exponentially many entries stored\nin a database, the construction of which is considered a one-off overhead, it\nhas been argued that the cost of preparing such amplitude-encoded states may\noffset any exponential quantum advantage. Here we prove using smoothed\nanalysis, that if the data-analysis algorithm is robust against small\nentry-wise input perturbation, state preparation can always be achieved with\nconstant queries. This criterion is typically satisfied in realistic machine\nlearning applications, where input data is subjective to moderate noise. Our\nresults are equally applicable to the recent seminal progress in\nquantum-inspired algorithms, where specially constructed databases suffice for\npolylogarithmic classical algorithm in low-rank cases. The consequence of our\nfinding is that for the purpose of practical machine learning, polylogarithmic\nprocessing time is possible under a general and flexible input model with\nquantum algorithms or quantum-inspired classical algorithms in the low-rank\ncases.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 11:10:00 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 20:15:48 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Zhao", "Zhikuan", ""], ["Fitzsimons", "Jack K.", ""], ["Rebentrost", "Patrick", ""], ["Dunjko", "Vedran", ""], ["Fitzsimons", "Joseph F.", ""]]}, {"id": "1804.00292", "submitter": "Ronald Kemker", "authors": "Ronald Kemker and Utsav B. Gewali and Christopher Kanan", "title": "EarthMapper: A Tool Box for the Semantic Segmentation of Remote Sensing\n  Imagery", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning continues to push state-of-the-art performance for the semantic\nsegmentation of color (i.e., RGB) imagery; however, the lack of annotated data\nfor many remote sensing sensors (i.e. hyperspectral imagery (HSI)) prevents\nresearchers from taking advantage of this recent success. Since generating\nsensor specific datasets is time intensive and cost prohibitive, remote sensing\nresearchers have embraced deep unsupervised feature extraction. Although these\nmethods have pushed state-of-the-art performance on current HSI benchmarks,\nmany of these tools are not readily accessible to many researchers. In this\nletter, we introduce a software pipeline, which we call EarthMapper, for the\nsemantic segmentation of non-RGB remote sensing imagery. It includes\nself-taught spatial-spectral feature extraction, various standard and deep\nlearning classifiers, and undirected graphical models for post-processing. We\nevaluated EarthMapper on the Indian Pines and Pavia University datasets and\nhave released this code for public use.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 12:44:20 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Kemker", "Ronald", ""], ["Gewali", "Utsav B.", ""], ["Kanan", "Christopher", ""]]}, {"id": "1804.00293", "submitter": "Kien Do", "authors": "Kien Do, Truyen Tran, Thin Nguyen, Svetha Venkatesh", "title": "Attentional Multilabel Learning over Graphs: A Message Passing Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a largely open problem of multilabel classification over graphs.\nUnlike traditional vector input, a graph has rich variable-size substructures\nwhich are related to the labels in some ways. We believe that uncovering these\nrelations might hold the key to classification performance and explainability.\nWe introduce GAML (Graph Attentional Multi-Label learning), a novel graph\nneural network that can handle this problem effectively. GAML regards labels as\nauxiliary nodes and models them in conjunction with the input graph. By\napplying message passing and attention mechanisms to both the label nodes and\nthe input nodes iteratively, GAML can capture the relations between the labels\nand the input subgraphs at various resolution scales. Moreover, our model can\ntake advantage of explicit label dependencies. It also scales linearly with the\nnumber of labels and graph size thanks to our proposed hierarchical attention.\nWe evaluate GAML on an extensive set of experiments with both graph-structured\ninputs and classical unstructured inputs. The results show that GAML\nsignificantly outperforms other competing methods. Importantly, GAML enables\nintuitive visualizations for better understanding of the label-substructure\nrelations and explanation of the model behaviors.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 13:01:24 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 07:19:29 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Do", "Kien", ""], ["Tran", "Truyen", ""], ["Nguyen", "Thin", ""], ["Venkatesh", "Svetha", ""]]}, {"id": "1804.00306", "submitter": "Cun Mu", "authors": "Cun Mu, Guang Yang and Zheng Yan", "title": "Revisiting Skip-Gram Negative Sampling Model with Rectification", "comments": "Accepted for publication in the proceedings of 2019 Computing\n  Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit skip-gram negative sampling (SGNS), one of the most popular\nneural-network based approaches to learning distributed word representation. We\nfirst point out the ambiguity issue undermining the SGNS model, in the sense\nthat the word vectors can be entirely distorted without changing the objective\nvalue. To resolve the issue, we investigate the intrinsic structures in\nsolution that a good word embedding model should deliver. Motivated by this, we\nrectify the SGNS model with quadratic regularization, and show that this simple\nmodification suffices to structure the solution in the desired manner. A\ntheoretical justification is presented, which provides novel insights into\nquadratic regularization . Preliminary experiments are also conducted on\nGoogle's analytical reasoning task to support the modified SGNS model.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 15:41:01 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 16:14:55 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Mu", "Cun", ""], ["Yang", "Guang", ""], ["Yan", "Zheng", ""]]}, {"id": "1804.00325", "submitter": "James Lucas", "authors": "James Lucas, Shengyang Sun, Richard Zemel, Roger Grosse", "title": "Aggregated Momentum: Stability Through Passive Damping", "comments": "11 primary pages, 11 supplementary pages, 12 figures total", "journal-ref": "International Conference on Learning Representations, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Momentum is a simple and widely used trick which allows gradient-based\noptimizers to pick up speed along low curvature directions. Its performance\ndepends crucially on a damping coefficient $\\beta$. Large $\\beta$ values can\npotentially deliver much larger speedups, but are prone to oscillations and\ninstability; hence one typically resorts to small values such as 0.5 or 0.9. We\npropose Aggregated Momentum (AggMo), a variant of momentum which combines\nmultiple velocity vectors with different $\\beta$ parameters. AggMo is trivial\nto implement, but significantly dampens oscillations, enabling it to remain\nstable even for aggressive $\\beta$ values such as 0.999. We reinterpret\nNesterov's accelerated gradient descent as a special case of AggMo and analyze\nrates of convergence for quadratic objectives. Empirically, we find that AggMo\nis a suitable drop-in replacement for other momentum methods, and frequently\ndelivers faster convergence.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 17:53:03 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 16:49:44 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 14:09:52 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Lucas", "James", ""], ["Sun", "Shengyang", ""], ["Zemel", "Richard", ""], ["Grosse", "Roger", ""]]}, {"id": "1804.00335", "submitter": "Zhili Feng", "authors": "Zhili Feng, Po-Ling Loh", "title": "Online learning with graph-structured feedback against adaptive\n  adversaries", "comments": "This paper has been accepted to ISIT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive upper and lower bounds for the policy regret of $T$-round online\nlearning problems with graph-structured feedback, where the adversary is\nnonoblivious but assumed to have a bounded memory. We obtain upper bounds of\n$\\widetilde O(T^{2/3})$ and $\\widetilde O(T^{3/4})$ for strongly-observable and\nweakly-observable graphs, respectively, based on analyzing a variant of the\nExp3 algorithm. When the adversary is allowed a bounded memory of size 1, we\nshow that a matching lower bound of $\\widetilde\\Omega(T^{2/3})$ is achieved in\nthe case of full-information feedback. We also study the particular loss\nstructure of an oblivious adversary with switching costs, and show that in such\na setting, non-revealing strongly-observable feedback graphs achieve a lower\nbound of $\\widetilde\\Omega(T^{2/3})$, as well.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 19:56:10 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Feng", "Zhili", ""], ["Loh", "Po-Ling", ""]]}, {"id": "1804.00338", "submitter": "Le Liang", "authors": "Le Liang and Hao Ye and Geoffrey Ye Li", "title": "Toward Intelligent Vehicular Networks: A Machine Learning Framework", "comments": "Updated title. Accepted by IEEE Internet of Things Journal", "journal-ref": null, "doi": "10.1109/JIOT.2018.2872122", "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As wireless networks evolve towards high mobility and providing better\nsupport for connected vehicles, a number of new challenges arise due to the\nresulting high dynamics in vehicular environments and thus motive rethinking of\ntraditional wireless design methodologies. Future intelligent vehicles, which\nare at the heart of high mobility networks, are increasingly equipped with\nmultiple advanced onboard sensors and keep generating large volumes of data.\nMachine learning, as an effective approach to artificial intelligence, can\nprovide a rich set of tools to exploit such data for the benefit of the\nnetworks. In this article, we first identify the distinctive characteristics of\nhigh mobility vehicular networks and motivate the use of machine learning to\naddress the resulting challenges. After a brief introduction of the major\nconcepts of machine learning, we discuss its applications to learn the dynamics\nof vehicular networks and make informed decisions to optimize network\nperformance. In particular, we discuss in greater detail the application of\nreinforcement learning in managing network resources as an alternative to the\nprevalent optimization approach. Finally, some open issues worth further\ninvestigation are highlighted.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 20:28:18 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 00:22:58 GMT"}, {"version": "v3", "created": "Mon, 10 Jun 2019 16:03:01 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Liang", "Le", ""], ["Ye", "Hao", ""], ["Li", "Geoffrey Ye", ""]]}, {"id": "1804.00341", "submitter": "N. Benjamin Erichson", "authors": "N. Benjamin Erichson, Peng Zheng, Krithika Manohar, Steven L. Brunton,\n  J. Nathan Kutz and Aleksandr Y. Aravkin", "title": "Sparse Principal Component Analysis via Variable Projection", "comments": null, "journal-ref": "SIAM Journal on Applied Mathematics 2020 80:2, 977-1002", "doi": "10.1137/18M1211350", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse principal component analysis (SPCA) has emerged as a powerful\ntechnique for modern data analysis, providing improved interpretation of\nlow-rank structures by identifying localized spatial structures in the data and\ndisambiguating between distinct time scales. We demonstrate a robust and\nscalable SPCA algorithm by formulating it as a value-function optimization\nproblem. This viewpoint leads to a flexible and computationally efficient\nalgorithm. Further, we can leverage randomized methods from linear algebra to\nextend the approach to the large-scale (big data) setting. Our proposed\ninnovation also allows for a robust SPCA formulation which obtains meaningful\nsparse principal components in spite of grossly corrupted input data. The\nproposed algorithms are demonstrated using both synthetic and real world data,\nand show exceptional computational efficiency and diagnostic performance.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 20:49:56 GMT"}, {"version": "v2", "created": "Sun, 2 Sep 2018 22:41:07 GMT"}, {"version": "v3", "created": "Mon, 28 Dec 2020 02:00:30 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Erichson", "N. Benjamin", ""], ["Zheng", "Peng", ""], ["Manohar", "Krithika", ""], ["Brunton", "Steven L.", ""], ["Kutz", "J. Nathan", ""], ["Aravkin", "Aleksandr Y.", ""]]}, {"id": "1804.00361", "submitter": "{\\L}ukasz Kidzi\\'nski", "authors": "{\\L}ukasz Kidzi\\'nski, Sharada Prasanna Mohanty, Carmichael Ong,\n  Zhewei Huang, Shuchang Zhou, Anton Pechenko, Adam Stelmaszczyk, Piotr\n  Jarosik, Mikhail Pavlov, Sergey Kolesnikov, Sergey Plis, Zhibo Chen, Zhizheng\n  Zhang, Jiale Chen, Jun Shi, Zhuobin Zheng, Chun Yuan, Zhihui Lin, Henryk\n  Michalewski, Piotr Mi{\\l}o\\'s, B{\\l}a\\.zej Osi\\'nski, Andrew Melnik, Malte\n  Schilling, Helge Ritter, Sean Carroll, Jennifer Hicks, Sergey Levine, Marcel\n  Salath\\'e, Scott Delp", "title": "Learning to Run challenge solutions: Adapting reinforcement learning\n  methods for neuromusculoskeletal environments", "comments": "27 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the NIPS 2017 Learning to Run challenge, participants were tasked with\nbuilding a controller for a musculoskeletal model to make it run as fast as\npossible through an obstacle course. Top participants were invited to describe\ntheir algorithms. In this work, we present eight solutions that used deep\nreinforcement learning approaches, based on algorithms such as Deep\nDeterministic Policy Gradient, Proximal Policy Optimization, and Trust Region\nPolicy Optimization. Many solutions use similar relaxations and heuristics,\nsuch as reward shaping, frame skipping, discretization of the action space,\nsymmetry, and policy blending. However, each of the eight teams implemented\ndifferent modifications of the known algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 00:19:31 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Kidzi\u0144ski", "\u0141ukasz", ""], ["Mohanty", "Sharada Prasanna", ""], ["Ong", "Carmichael", ""], ["Huang", "Zhewei", ""], ["Zhou", "Shuchang", ""], ["Pechenko", "Anton", ""], ["Stelmaszczyk", "Adam", ""], ["Jarosik", "Piotr", ""], ["Pavlov", "Mikhail", ""], ["Kolesnikov", "Sergey", ""], ["Plis", "Sergey", ""], ["Chen", "Zhibo", ""], ["Zhang", "Zhizheng", ""], ["Chen", "Jiale", ""], ["Shi", "Jun", ""], ["Zheng", "Zhuobin", ""], ["Yuan", "Chun", ""], ["Lin", "Zhihui", ""], ["Michalewski", "Henryk", ""], ["Mi\u0142o\u015b", "Piotr", ""], ["Osi\u0144ski", "B\u0142a\u017cej", ""], ["Melnik", "Andrew", ""], ["Schilling", "Malte", ""], ["Ritter", "Helge", ""], ["Carroll", "Sean", ""], ["Hicks", "Jennifer", ""], ["Levine", "Sergey", ""], ["Salath\u00e9", "Marcel", ""], ["Delp", "Scott", ""]]}, {"id": "1804.00379", "submitter": "William Fedus", "authors": "Anirudh Goyal, Philemon Brakel, William Fedus, Soumye Singhal, Timothy\n  Lillicrap, Sergey Levine, Hugo Larochelle, Yoshua Bengio", "title": "Recall Traces: Backtracking Models for Efficient Reinforcement Learning", "comments": "Accepted at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many environments only a tiny subset of all states yield high reward. In\nthese cases, few of the interactions with the environment provide a relevant\nlearning signal. Hence, we may want to preferentially train on those\nhigh-reward states and the probable trajectories leading to them. To this end,\nwe advocate for the use of a backtracking model that predicts the preceding\nstates that terminate at a given high-reward state. We can train a model which,\nstarting from a high value state (or one that is estimated to have high value),\npredicts and sample for which the (state, action)-tuples may have led to that\nhigh value state. These traces of (state, action) pairs, which we refer to as\nRecall Traces, sampled from this backtracking model starting from a high value\nstate, are informative as they terminate in good states, and hence we can use\nthese traces to improve a policy. We provide a variational interpretation for\nthis idea and a practical algorithm in which the backtracking model samples\nfrom an approximate posterior distribution over trajectories which lead to\nlarge rewards. Our method improves the sample efficiency of both on- and\noff-policy RL algorithms across several environments and tasks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 03:02:33 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2019 22:56:28 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Goyal", "Anirudh", ""], ["Brakel", "Philemon", ""], ["Fedus", "William", ""], ["Singhal", "Soumye", ""], ["Lillicrap", "Timothy", ""], ["Levine", "Sergey", ""], ["Larochelle", "Hugo", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1804.00403", "submitter": "Ke Ding", "authors": "Ke Ding", "title": "A Note on Kaldi's PLDA Implementation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some explanations to Kaldi's PLDA implementation to make formula derivation\neasier to catch.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 05:44:59 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Ding", "Ke", ""]]}, {"id": "1804.00408", "submitter": "Nilin Abrahamsen", "authors": "Nilin Abrahamsen, Philippe Rigollet", "title": "Sparse Gaussian ICA", "comments": "Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent component analysis (ICA) is a cornerstone of modern data\nanalysis. Its goal is to recover a latent random vector S with independent\ncomponents from samples of X=AS where A is an unknown mixing matrix.\nCritically, all existing methods for ICA rely on and exploit strongly the\nassumption that S is not Gaussian as otherwise A becomes unidentifiable. In\nthis paper, we show that in fact one can handle the case of Gaussian components\nby imposing structure on the matrix A. Specifically, we assume that A is sparse\nand generic in the sense that it is generated from a sparse Bernoulli-Gaussian\nensemble. Under this condition, we give an efficient algorithm to recover the\ncolumns of A given only the covariance matrix of X as input even when S has\nseveral Gaussian components.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 06:14:08 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 14:07:46 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Abrahamsen", "Nilin", ""], ["Rigollet", "Philippe", ""]]}, {"id": "1804.00425", "submitter": "Fuming Fang", "authors": "Fuming Fang, Junichi Yamagishi, Isao Echizen, Jaime Lorenzo-Trueba", "title": "High-quality nonparallel voice conversion based on cycle-consistent\n  adversarial network", "comments": "accepted at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although voice conversion (VC) algorithms have achieved remarkable success\nalong with the development of machine learning, superior performance is still\ndifficult to achieve when using nonparallel data. In this paper, we propose\nusing a cycle-consistent adversarial network (CycleGAN) for nonparallel\ndata-based VC training. A CycleGAN is a generative adversarial network (GAN)\noriginally developed for unpaired image-to-image translation. A subjective\nevaluation of inter-gender conversion demonstrated that the proposed method\nsignificantly outperformed a method based on the Merlin open source neural\nnetwork speech synthesis system (a parallel VC system adapted for our setup)\nand a GAN-based parallel VC system. This is the first research to show that the\nperformance of a nonparallel VC method can exceed that of state-of-the-art\nparallel VC methods.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 07:58:23 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Fang", "Fuming", ""], ["Yamagishi", "Junichi", ""], ["Echizen", "Isao", ""], ["Lorenzo-Trueba", "Jaime", ""]]}, {"id": "1804.00432", "submitter": "Jong Chul Ye", "authors": "Dongwook Lee, Jaejun Yoo, Sungho Tak and Jong Chul Ye", "title": "Deep Residual Learning for Accelerated MRI using Magnitude and Phase\n  Networks", "comments": "This paper will appear in IEEE Trans. Biomedical Engineering, Special\n  Section on Deep Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerated magnetic resonance (MR) scan acquisition with compressed sensing\n(CS) and parallel imaging is a powerful method to reduce MR imaging scan time.\nHowever, many reconstruction algorithms have high computational costs. To\naddress this, we investigate deep residual learning networks to remove aliasing\nartifacts from artifact corrupted images. The proposed deep residual learning\nnetworks are composed of magnitude and phase networks that are separately\ntrained. If both phase and magnitude information are available, the proposed\nalgorithm can work as an iterative k-space interpolation algorithm using\nframelet representation. When only magnitude data is available, the proposed\napproach works as an image domain post-processing algorithm. Even with strong\ncoherent aliasing artifacts, the proposed network successfully learned and\nremoved the aliasing artifacts, whereas current parallel and CS reconstruction\nmethods were unable to remove these artifacts. Comparisons using single and\nmultiple coil show that the proposed residual network provides good\nreconstruction results with orders of magnitude faster computational time than\nexisting compressed sensing methods. The proposed deep learning framework may\nhave a great potential for accelerated MR reconstruction by generating accurate\nresults immediately.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 09:08:02 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Lee", "Dongwook", ""], ["Yoo", "Jaejun", ""], ["Tak", "Sungho", ""], ["Ye", "Jong Chul", ""]]}, {"id": "1804.00445", "submitter": "Stefano Gualandi", "authors": "Federico Bassetti and Stefano Gualandi and Marco Veneroni", "title": "On the Computation of Kantorovich-Wasserstein Distances between\n  2D-Histograms by Uncapacitated Minimum Cost Flows", "comments": "27 pages, 35 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a method to compute the Kantorovich-Wasserstein\ndistance of order one between a pair of two-dimensional histograms. Recent\nworks in Computer Vision and Machine Learning have shown the benefits of\nmeasuring Wasserstein distances of order one between histograms with $n$ bins,\nby solving a classical transportation problem on very large complete bipartite\ngraphs with $n$ nodes and $n^2$ edges. The main contribution of our work is to\napproximate the original transportation problem by an uncapacitated min cost\nflow problem on a reduced flow network of size $O(n)$ that exploits the\ngeometric structure of the cost function. More precisely, when the distance\namong the bin centers is measured with the 1-norm or the $\\infty$-norm, our\napproach provides an optimal solution. When the distance among bins is measured\nwith the 2-norm: (i) we derive a quantitative estimate on the error between\noptimal and approximate solution; (ii) given the error, we construct a reduced\nflow network of size $O(n)$. We numerically show the benefits of our approach\nby computing Wasserstein distances of order one on a set of grey scale images\nused as benchmark in the literature. We show how our approach scales with the\nsize of the images with 1-norm, 2-norm and $\\infty$-norm ground distances, and\nwe compare it with other two methods which are largely used in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 10:40:48 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 18:02:39 GMT"}, {"version": "v3", "created": "Fri, 26 Jul 2019 12:25:16 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Bassetti", "Federico", ""], ["Gualandi", "Stefano", ""], ["Veneroni", "Marco", ""]]}, {"id": "1804.00448", "submitter": "Luiz Gustavo Hafemann", "authors": "Luiz G. Hafemann, Robert Sabourin, Luiz S. Oliveira", "title": "Fixed-sized representation learning from Offline Handwritten Signatures\n  of different sizes", "comments": "This is a pre-print of an article published in the International\n  Journal on Document Analysis and Recognition", "journal-ref": null, "doi": "10.1007/s10032-018-0301-6", "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for learning feature representations for Offline Handwritten\nSignature Verification have been successfully proposed in recent literature,\nusing Deep Convolutional Neural Networks to learn representations from\nsignature pixels. Such methods reported large performance improvements compared\nto handcrafted feature extractors. However, they also introduced an important\nconstraint: the inputs to the neural networks must have a fixed size, while\nsignatures vary significantly in size between different users. In this paper we\npropose addressing this issue by learning a fixed-sized representation from\nvariable-sized signatures by modifying the network architecture, using Spatial\nPyramid Pooling. We also investigate the impact of the resolution of the images\nused for training, and the impact of adapting (fine-tuning) the representations\nto new operating conditions (different acquisition protocols, such as writing\ninstruments and scan resolution). On the GPDS dataset, we achieve results\ncomparable with the state-of-the-art, while removing the constraint of having a\nmaximum size for the signatures to be processed. We also show that using higher\nresolutions (300 or 600dpi) can improve performance when skilled forgeries from\na subset of users are available for feature learning, but lower resolutions\n(around 100dpi) can be used if only genuine signatures are used. Lastly, we\nshow that fine-tuning can improve performance when the operating conditions\nchange.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 11:07:01 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 17:06:46 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Hafemann", "Luiz G.", ""], ["Sabourin", "Robert", ""], ["Oliveira", "Luiz S.", ""]]}, {"id": "1804.00602", "submitter": "Mohamad Dia", "authors": "Mohamad Dia, Vahid Aref, Laurent Schmalen", "title": "A Compressed Sensing Approach for Distribution Matching", "comments": "in the 2018 IEEE International Symposium on Information Theory (ISIT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we formulate the fixed-length distribution matching as a\nBayesian inference problem. Our proposed solution is inspired from the\ncompressed sensing paradigm and the sparse superposition (SS) codes. First, we\nintroduce sparsity in the binary source via position modulation (PM). We then\npresent a simple and exact matcher based on Gaussian signal quantization. At\nthe receiver, the dematcher exploits the sparsity in the source and performs\nlow-complexity dematching based on generalized approximate message-passing\n(GAMP). We show that GAMP dematcher and spatial coupling lead to asymptotically\noptimal performance, in the sense that the rate tends to the entropy of the\ntarget distribution with vanishing reconstruction error in a proper limit.\nFurthermore, we assess the performance of the dematcher on practical\nHadamard-based operators. A remarkable feature of our proposed solution is the\npossibility to: i) perform matching at the symbol level (nonbinary); ii)\nperform joint channel coding and matching.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 15:57:01 GMT"}, {"version": "v2", "created": "Sun, 25 Nov 2018 09:10:07 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Dia", "Mohamad", ""], ["Aref", "Vahid", ""], ["Schmalen", "Laurent", ""]]}, {"id": "1804.00636", "submitter": "Dionysios Kalogerias", "authors": "Dionysios S. Kalogerias, Warren B. Powell", "title": "Recursive Optimization of Convex Risk Measures: Mean-Semideviation\n  Models", "comments": "90 pages, 3 figures. Update: Substantial revision of the technical\n  content, with an additional fully detailed analysis in regard to the rate of\n  convergence of the MESSAGEp algorithm. NOTE: Please open in browser to see\n  the math in the abstract!", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop recursive, data-driven, stochastic subgradient methods for\noptimizing a new, versatile, and application-driven class of convex risk\nmeasures, termed here as mean-semideviations, strictly generalizing the\nwell-known and popular mean-upper-semideviation. We introduce the MESSAGEp\nalgorithm, which is an efficient compositional subgradient procedure for\niteratively solving convex mean-semideviation risk-averse problems to\noptimality. We analyze the asymptotic behavior of the MESSAGEp algorithm under\na flexible and structure-exploiting set of problem assumptions. In particular:\n1) Under appropriate stepsize rules, we establish pathwise convergence of the\nMESSAGEp algorithm in a strong technical sense, confirming its asymptotic\nconsistency. 2) Assuming a strongly convex cost, we show that, for fixed\nsemideviation order $p>1$ and for $\\epsilon\\in\\left[0,1\\right)$, the MESSAGEp\nalgorithm achieves a squared-${\\cal L}_{2}$ solution suboptimality rate of the\norder of ${\\cal O}(n^{-\\left(1-\\epsilon\\right)/2})$ iterations, where, for\n$\\epsilon>0$, pathwise convergence is simultaneously guaranteed. This result\nestablishes a rate of order arbitrarily close to ${\\cal O}(n^{-1/2})$, while\nensuring strongly stable pathwise operation. For $p\\equiv1$, the rate order\nimproves to ${\\cal O}(n^{-2/3})$, which also suffices for pathwise convergence,\nand matches previous results. 3) Likewise, in the general case of a convex\ncost, we show that, for any $\\epsilon\\in\\left[0,1\\right)$, the MESSAGEp\nalgorithm with iterate smoothing achieves an ${\\cal L}_{1}$ objective\nsuboptimality rate of the order of ${\\cal\nO}(n^{-\\left(1-\\epsilon\\right)/\\left(4\\bf{1}_{\\left\\{ p>1\\right\\} }+4\\right)})$\niterations. This result provides maximal rates of ${\\cal O}(n^{-1/4})$, if\n$p\\equiv1$, and ${\\cal O}(n^{-1/8})$, if $p>1$, matching the state of the art,\nas well.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 17:27:52 GMT"}, {"version": "v2", "created": "Tue, 1 May 2018 02:36:03 GMT"}, {"version": "v3", "created": "Mon, 4 Jun 2018 03:15:25 GMT"}, {"version": "v4", "created": "Mon, 25 Jun 2018 00:47:36 GMT"}, {"version": "v5", "created": "Mon, 29 Oct 2018 15:49:58 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Kalogerias", "Dionysios S.", ""], ["Powell", "Warren B.", ""]]}, {"id": "1804.00645", "submitter": "Aravind Srinivas", "authors": "Aravind Srinivas, Allan Jabri, Pieter Abbeel, Sergey Levine, Chelsea\n  Finn", "title": "Universal Planning Networks", "comments": "Videos available at https://sites.google.com/view/upn-public/home", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge in complex visuomotor control is learning abstract\nrepresentations that are effective for specifying goals, planning, and\ngeneralization. To this end, we introduce universal planning networks (UPN).\nUPNs embed differentiable planning within a goal-directed policy. This planning\ncomputation unrolls a forward model in a latent space and infers an optimal\naction plan through gradient descent trajectory optimization. The\nplan-by-gradient-descent process and its underlying representations are learned\nend-to-end to directly optimize a supervised imitation learning objective. We\nfind that the representations learned are not only effective for goal-directed\nvisual imitation via gradient-based trajectory optimization, but can also\nprovide a metric for specifying goals using images. The learned representations\ncan be leveraged to specify distance-based rewards to reach new target states\nfor model-free reinforcement learning, resulting in substantially more\neffective learning when solving new tasks described via image-based goals. We\nwere able to achieve successful transfer of visuomotor planning strategies\nacross robots with significantly different morphologies and actuation\ncapabilities.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 17:51:53 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 17:36:36 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Srinivas", "Aravind", ""], ["Jabri", "Allan", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""], ["Finn", "Chelsea", ""]]}, {"id": "1804.00681", "submitter": "Abubakar Abid", "authors": "Abubakar Abid, James Zou", "title": "Stochastic EM for Shuffled Linear Regression", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of inference in a linear regression model in which\nthe relative ordering of the input features and output labels is not known.\nSuch datasets naturally arise from experiments in which the samples are\nshuffled or permuted during the protocol. In this work, we propose a framework\nthat treats the unknown permutation as a latent variable. We maximize the\nlikelihood of observations using a stochastic expectation-maximization (EM)\napproach. We compare this to the dominant approach in the literature, which\ncorresponds to hard EM in our framework. We show on synthetic data that the\nstochastic EM algorithm we develop has several advantages, including lower\nparameter error, less sensitivity to the choice of initialization, and\nsignificantly better performance on datasets that are only partially shuffled.\nWe conclude by performing two experiments on real datasets that have been\npartially shuffled, in which we show that the stochastic EM algorithm can\nrecover the weights with modest error.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 18:13:49 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Abid", "Abubakar", ""], ["Zou", "James", ""]]}, {"id": "1804.00684", "submitter": "Bao Wang", "authors": "Bao Wang, Xiyang Luo, Fangbo Zhang, Baichuan Yuan, Andrea L. Bertozzi,\n  P. Jeffrey Brantingham", "title": "Graph-Based Deep Modeling and Real Time Forecasting of Sparse\n  Spatio-Temporal Data", "comments": "9 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a generic framework for spatio-temporal (ST) data modeling,\nanalysis, and forecasting, with a special focus on data that is sparse in both\nspace and time. Our multi-scaled framework is a seamless coupling of two major\ncomponents: a self-exciting point process that models the macroscale\nstatistical behaviors of the ST data and a graph structured recurrent neural\nnetwork (GSRNN) to discover the microscale patterns of the ST data on the\ninferred graph. This novel deep neural network (DNN) incorporates the real time\ninteractions of the graph nodes to enable more accurate real time forecasting.\nThe effectiveness of our method is demonstrated on both crime and traffic\nforecasting.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 18:23:27 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Wang", "Bao", ""], ["Luo", "Xiyang", ""], ["Zhang", "Fangbo", ""], ["Yuan", "Baichuan", ""], ["Bertozzi", "Andrea L.", ""], ["Brantingham", "P. Jeffrey", ""]]}, {"id": "1804.00709", "submitter": "Kemal Davaslioglu", "authors": "Kemal Davaslioglu and Yalin E. Sagduyu", "title": "Generative Adversarial Learning for Spectrum Sensing", "comments": "IEEE ICC 2018 COGNITIVE RADIO AND NETWORKING (ICC'18 CRN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach of training data augmentation and domain adaptation is\npresented to support machine learning applications for cognitive radio. Machine\nlearning provides effective tools to automate cognitive radio functionalities\nby reliably extracting and learning intrinsic spectrum dynamics. However, there\nare two important challenges to overcome, in order to fully utilize the machine\nlearning benefits with cognitive radios. First, machine learning requires\nsignificant amount of truthed data to capture complex channel and emitter\ncharacteristics, and train the underlying algorithm (e.g., a classifier).\nSecond, the training data that has been identified for one spectrum environment\ncannot be used for another one (e.g., after channel and emitter conditions\nchange). To address these challenges, a generative adversarial network (GAN)\nwith deep learning structures is used to 1)~generate additional synthetic\ntraining data to improve classifier accuracy, and 2) adapt training data to\nspectrum dynamics. This approach is applied to spectrum sensing by assuming\nonly limited training data without knowledge of spectrum statistics. Machine\nlearning classifiers are trained with limited, augmented and adapted training\ndata to detect signals. Results show that training data augmentation increases\nthe classifier accuracy significantly and this increase is sustained with\ndomain adaptation as spectrum conditions change.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 19:23:06 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Davaslioglu", "Kemal", ""], ["Sagduyu", "Yalin E.", ""]]}, {"id": "1804.00714", "submitter": "Anshul Ramachandran", "authors": "Anshul Ramachandran, Ashwin Balakrishna, Peter Kundzicz, Anirudh Neti", "title": "Predicting Electric Vehicle Charging Station Usage: Using Machine\n  Learning to Estimate Individual Station Statistics from Physical\n  Configurations of Charging Station Networks", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electric vehicles (EVs) have been gaining popularity due to their\nenvironmental friendliness and efficiency. EV charging station networks are\nscalable solutions for supporting increasing numbers of EVs within modern\nelectric grid constraints, yet few tools exist to aid the physical\nconfiguration design of new networks. We use neural networks to predict\nindividual charging station usage statistics from the station's physical\nlocation within a network. We have shown this quickly gives accurate estimates\nof average usage statistics given a proposed configuration, without the need\nfor running many computationally expensive simulations. The trained neural\nnetwork can help EV charging network designers rapidly test various placements\nof charging stations under additional individual constraints in order to find\nan optimal configuration given their design objectives.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 19:41:47 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Ramachandran", "Anshul", ""], ["Balakrishna", "Ashwin", ""], ["Kundzicz", "Peter", ""], ["Neti", "Anirudh", ""]]}, {"id": "1804.00722", "submitter": "Kibok Lee", "authors": "Kibok Lee, Kimin Lee, Kyle Min, Yuting Zhang, Jinwoo Shin, Honglak Lee", "title": "Hierarchical Novelty Detection for Visual Object Recognition", "comments": "CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have achieved impressive success in large-scale visual\nobject recognition tasks with a predefined set of classes. However, recognizing\nobjects of novel classes unseen during training still remains challenging. The\nproblem of detecting such novel classes has been addressed in the literature,\nbut most prior works have focused on providing simple binary or regressive\ndecisions, e.g., the output would be \"known,\" \"novel,\" or corresponding\nconfidence intervals. In this paper, we study more informative novelty\ndetection schemes based on a hierarchical classification framework. For an\nobject of a novel class, we aim for finding its closest super class in the\nhierarchical taxonomy of known classes. To this end, we propose two different\napproaches termed top-down and flatten methods, and their combination as well.\nThe essential ingredients of our methods are confidence-calibrated classifiers,\ndata relabeling, and the leave-one-out strategy for modeling novel classes\nunder the hierarchical taxonomy. Furthermore, our method can generate a\nhierarchical embedding that leads to improved generalized zero-shot learning\nperformance in combination with other commonly-used semantic embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 20:36:43 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 10:18:15 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Lee", "Kibok", ""], ["Lee", "Kimin", ""], ["Min", "Kyle", ""], ["Zhang", "Yuting", ""], ["Shin", "Jinwoo", ""], ["Lee", "Honglak", ""]]}, {"id": "1804.00727", "submitter": "Shun Kataoka", "authors": "Kazuyuki Tanaka, Masamichi Nakamura, Shun Kataoka, Masayuki Ohzeki,\n  Muneki Yasuda", "title": "Momentum-Space Renormalization Group Transformation in Bayesian Image\n  Modeling by Gaussian Graphical Model", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": "10.7566/JPSJ.87.085001", "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new Bayesian modeling method is proposed by combining the maximization of\nthe marginal likelihood with a momentum-space renormalization group\ntransformation for Gaussian graphical models. Moreover, we present a scheme for\ncomputint the statistical averages of hyperparameters and mean square errors in\nour proposed method based on a momentumspace renormalization transformation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 01:29:13 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Tanaka", "Kazuyuki", ""], ["Nakamura", "Masamichi", ""], ["Kataoka", "Shun", ""], ["Ohzeki", "Masayuki", ""], ["Yasuda", "Muneki", ""]]}, {"id": "1804.00779", "submitter": "Chin-Wei Huang", "authors": "Chin-Wei Huang, David Krueger, Alexandre Lacoste, Aaron Courville", "title": "Neural Autoregressive Flows", "comments": "16 pages, 10 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing flows and autoregressive models have been successfully combined\nto produce state-of-the-art results in density estimation, via Masked\nAutoregressive Flows (MAF), and to accelerate state-of-the-art WaveNet-based\nspeech synthesis to 20x faster than real-time, via Inverse Autoregressive Flows\n(IAF). We unify and generalize these approaches, replacing the (conditionally)\naffine univariate transformations of MAF/IAF with a more general class of\ninvertible univariate transformations expressed as monotonic neural networks.\nWe demonstrate that the proposed neural autoregressive flows (NAF) are\nuniversal approximators for continuous probability distributions, and their\ngreater expressivity allows them to better capture multimodal target\ndistributions. Experimentally, NAF yields state-of-the-art performance on a\nsuite of density estimation tasks and outperforms IAF in variational\nautoencoders trained on binarized MNIST.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 01:41:27 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Huang", "Chin-Wei", ""], ["Krueger", "David", ""], ["Lacoste", "Alexandre", ""], ["Courville", "Aaron", ""]]}, {"id": "1804.00792", "submitter": "Wenqian Ronny Huang", "authors": "Ali Shafahi, W. Ronny Huang, Mahyar Najibi, Octavian Suciu, Christoph\n  Studer, Tudor Dumitras, Tom Goldstein", "title": "Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks", "comments": "Presented at the NIPS 2018 conference. 11 pages, 4 figures, with a\n  supplementary section of 7 pages, 7 figures. First two authors contributed\n  equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data poisoning is an attack on machine learning models wherein the attacker\nadds examples to the training set to manipulate the behavior of the model at\ntest time. This paper explores poisoning attacks on neural nets. The proposed\nattacks use \"clean-labels\"; they don't require the attacker to have any control\nover the labeling of training data. They are also targeted; they control the\nbehavior of the classifier on a $\\textit{specific}$ test instance without\ndegrading overall classifier performance. For example, an attacker could add a\nseemingly innocuous image (that is properly labeled) to a training set for a\nface recognition engine, and control the identity of a chosen person at test\ntime. Because the attacker does not need to control the labeling function,\npoisons could be entered into the training set simply by leaving them on the\nweb and waiting for them to be scraped by a data collection bot.\n  We present an optimization-based method for crafting poisons, and show that\njust one single poison image can control classifier behavior when transfer\nlearning is used. For full end-to-end training, we present a \"watermarking\"\nstrategy that makes poisoning reliable using multiple ($\\approx$50) poisoned\ntraining instances. We demonstrate our method by generating poisoned frog\nimages from the CIFAR dataset and using them to manipulate image classifiers.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 02:24:31 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 15:37:17 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Shafahi", "Ali", ""], ["Huang", "W. Ronny", ""], ["Najibi", "Mahyar", ""], ["Suciu", "Octavian", ""], ["Studer", "Christoph", ""], ["Dumitras", "Tudor", ""], ["Goldstein", "Tom", ""]]}, {"id": "1804.00795", "submitter": "Xudong Li", "authors": "Xudong Li, Mengdi Wang, Anru Zhang", "title": "Estimation of Markov Chain via Rank-Constrained Likelihood", "comments": "Accepted at ICML 2018", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning (ICML2018), Stockholm, Sweden, PMLR 80, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the estimation of low-rank Markov chains from empirical\ntrajectories. We propose a non-convex estimator based on rank-constrained\nlikelihood maximization. Statistical upper bounds are provided for the\nKullback-Leiber divergence and the $\\ell_2$ risk between the estimator and the\ntrue transition matrix. The estimator reveals a compressed state space of the\nMarkov chain. We also develop a novel DC (difference of convex function)\nprogramming algorithm to tackle the rank-constrained non-smooth optimization\nproblem. Convergence results are established. Experiments show that the\nproposed estimator achieves better empirical performance than other popular\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 02:28:47 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 02:01:04 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Li", "Xudong", ""], ["Wang", "Mengdi", ""], ["Zhang", "Anru", ""]]}, {"id": "1804.00815", "submitter": "Shamak Dutta", "authors": "Shamak Dutta, Bryan Tripp, Graham Taylor", "title": "Convolutional Neural Networks Regularized by Correlated Noise", "comments": "Accepted at CRV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons in the visual cortex are correlated in their variability. The\npresence of correlation impacts cortical processing because noise cannot be\naveraged out over many neurons. In an effort to understand the functional\npurpose of correlated variability, we implement and evaluate correlated noise\nmodels in deep convolutional neural networks. Inspired by the cortex,\ncorrelation is defined as a function of the distance between neurons and their\nselectivity. We show how to sample from high-dimensional correlated\ndistributions while keeping the procedure differentiable, so that\nback-propagation can proceed as usual. The impact of correlated variability is\nevaluated on the classification of occluded and non-occluded images with and\nwithout the presence of other regularization techniques, such as dropout. More\nwork is needed to understand the effects of correlations in various conditions,\nhowever in 10/12 of the cases we studied, the best performance on occluded\nimages was obtained from a model with correlated noise.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 04:05:00 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Dutta", "Shamak", ""], ["Tripp", "Bryan", ""], ["Taylor", "Graham", ""]]}, {"id": "1804.00823", "submitter": "Lingfei Wu", "authors": "Kun Xu, Lingfei Wu, Zhiguo Wang, Yansong Feng, Michael Witbrock, and\n  Vadim Sheinin", "title": "Graph2Seq: Graph to Sequence Learning with Attention-based Neural\n  Networks", "comments": "16 pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The celebrated Sequence to Sequence learning (Seq2Seq) technique and its\nnumerous variants achieve excellent performance on many tasks. However, many\nmachine learning tasks have inputs naturally represented as graphs; existing\nSeq2Seq models face a significant challenge in achieving accurate conversion\nfrom graph form to the appropriate sequence. To address this challenge, we\nintroduce a novel general end-to-end graph-to-sequence neural encoder-decoder\nmodel that maps an input graph to a sequence of vectors and uses an\nattention-based LSTM method to decode the target sequence from these vectors.\nOur method first generates the node and graph embeddings using an improved\ngraph-based neural network with a novel aggregation strategy to incorporate\nedge direction information in the node embeddings. We further introduce an\nattention mechanism that aligns node embeddings and the decoding sequence to\nbetter cope with large graphs. Experimental results on bAbI, Shortest Path, and\nNatural Language Generation tasks demonstrate that our model achieves\nstate-of-the-art performance and significantly outperforms existing graph\nneural networks, Seq2Seq, and Tree2Seq models; using the proposed\nbi-directional node embedding aggregation strategy, the model can converge\nrapidly to the optimal performance.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 04:47:22 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 11:58:25 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 06:13:54 GMT"}, {"version": "v4", "created": "Mon, 3 Dec 2018 16:43:37 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Xu", "Kun", ""], ["Wu", "Lingfei", ""], ["Wang", "Zhiguo", ""], ["Feng", "Yansong", ""], ["Witbrock", "Michael", ""], ["Sheinin", "Vadim", ""]]}, {"id": "1804.00836", "submitter": "Canh Hao Nguyen", "authors": "Canh Hao Nguyen, Hiroshi Mamitsuka", "title": "Learning on Hypergraphs with Sparsity", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  (2020)", "doi": "10.1109/TPAMI.2020.2974746", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypergraph is a general way of representing high-order relations on a set of\nobjects. It is a generalization of graph, in which only pairwise relations can\nbe represented. It finds applications in various domains where relationships of\nmore than two objects are observed. On a hypergraph, as a generalization of\ngraph, one wishes to learn a smooth function with respect to its topology. A\nfundamental issue is to find suitable smoothness measures of functions on the\nnodes of a graph/hypergraph. We show a general framework that generalizes\npreviously proposed smoothness measures and also gives rise to new ones. To\naddress the problem of irrelevant or noisy data, we wish to incorporate sparse\nlearning framework into learning on hypergraphs. We propose sparsely smooth\nformulations that learn smooth functions and induce sparsity on hypergraphs at\nboth hyperedge and node levels. We show their properties and sparse support\nrecovery results. We conduct experiments to show that our sparsely smooth\nmodels have benefits to irrelevant and noisy data, and usually give similar or\nimproved performances compared to dense models.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 06:16:35 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Nguyen", "Canh Hao", ""], ["Mamitsuka", "Hiroshi", ""]]}, {"id": "1804.00846", "submitter": "Jialin Song", "authors": "Jialin Song, Ravi Lanka, Albert Zhao, Aadyot Bhatnagar, Yisong Yue,\n  Masahiro Ono", "title": "Learning to Search via Retrospective Imitation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of learning a good search policy for combinatorial\nsearch spaces. We propose retrospective imitation learning, which, after\ninitial training by an expert, improves itself by learning from\n\\textit{retrospective inspections} of its own roll-outs. That is, when the\npolicy eventually reaches a feasible solution in a combinatorial search tree\nafter making mistakes and backtracks, it retrospectively constructs an improved\nsearch trace to the solution by removing backtracks, which is then used to\nfurther train the policy. A key feature of our approach is that it can\niteratively scale up, or transfer, to larger problem sizes than those solved by\nthe initial expert demonstrations, thus dramatically expanding its\napplicability beyond that of conventional imitation learning. We showcase the\neffectiveness of our approach on a range of tasks, including synthetic maze\nsolving and combinatorial problems expressed as integer programs.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 06:52:09 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 22:33:54 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 07:57:21 GMT"}, {"version": "v4", "created": "Sun, 23 Jun 2019 17:23:11 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Song", "Jialin", ""], ["Lanka", "Ravi", ""], ["Zhao", "Albert", ""], ["Bhatnagar", "Aadyot", ""], ["Yue", "Yisong", ""], ["Ono", "Masahiro", ""]]}, {"id": "1804.00864", "submitter": "Botond Szabo", "authors": "Botond Szabo and Harry van Zanten", "title": "Adaptive distributed methods under communication constraints", "comments": "46 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed estimation methods under communication constraints in a\ndistributed version of the nonparametric random design regression model. We\nderive minimax lower bounds and exhibit methods that attain those bounds.\nMoreover, we show that adaptive estimation is possible in this setting.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 08:18:12 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2019 23:45:56 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Szabo", "Botond", ""], ["van Zanten", "Harry", ""]]}, {"id": "1804.00891", "submitter": "Nicola De Cao", "authors": "Tim R. Davidson, Luca Falorsi, Nicola De Cao, Thomas Kipf, Jakub M.\n  Tomczak", "title": "Hyperspherical Variational Auto-Encoders", "comments": "GitHub repository: http://github.com/nicola-decao/s-vae-tf, Blogpost:\n  https://nicola-decao.github.io/s-vae", "journal-ref": "Uncertainty in Artificial Intelligence (UAI). Proceedings of the\n  Thirty-Fourth Conference (2018) 856- 865", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Variational Auto-Encoder (VAE) is one of the most used unsupervised\nmachine learning models. But although the default choice of a Gaussian\ndistribution for both the prior and posterior represents a mathematically\nconvenient distribution often leading to competitive results, we show that this\nparameterization fails to model data with a latent hyperspherical structure. To\naddress this issue we propose using a von Mises-Fisher (vMF) distribution\ninstead, leading to a hyperspherical latent space. Through a series of\nexperiments we show how such a hyperspherical VAE, or $\\mathcal{S}$-VAE, is\nmore suitable for capturing data with a hyperspherical latent structure, while\noutperforming a normal, $\\mathcal{N}$-VAE, in low dimensions on other data\ntypes.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 09:57:26 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 14:55:34 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Davidson", "Tim R.", ""], ["Falorsi", "Luca", ""], ["De Cao", "Nicola", ""], ["Kipf", "Thomas", ""], ["Tomczak", "Jakub M.", ""]]}, {"id": "1804.00920", "submitter": "Lauri Juvela", "authors": "Lauri Juvela and Bajibabu Bollepalli and Xin Wang and Hirokazu Kameoka\n  and Manu Airaksinen and Junichi Yamagishi and Paavo Alku", "title": "Speech waveform synthesis from MFCC sequences with generative\n  adversarial networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a method for generating speech from filterbank mel\nfrequency cepstral coefficients (MFCC), which are widely used in speech\napplications, such as ASR, but are generally considered unusable for speech\nsynthesis. First, we predict fundamental frequency and voicing information from\nMFCCs with an autoregressive recurrent neural net. Second, the spectral\nenvelope information contained in MFCCs is converted to all-pole filters, and a\npitch-synchronous excitation model matched to these filters is trained.\nFinally, we introduce a generative adversarial network -based noise model to\nadd a realistic high-frequency stochastic component to the modeled excitation\nsignal. The results show that high quality speech reconstruction can be\nobtained, given only MFCC information at test time.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 11:43:36 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Juvela", "Lauri", ""], ["Bollepalli", "Bajibabu", ""], ["Wang", "Xin", ""], ["Kameoka", "Hirokazu", ""], ["Airaksinen", "Manu", ""], ["Yamagishi", "Junichi", ""], ["Alku", "Paavo", ""]]}, {"id": "1804.00921", "submitter": "Camille Couprie", "authors": "Othman Sbai, Mohamed Elhoseiny, Antoine Bordes, Yann LeCun, Camille\n  Couprie", "title": "DeSIGN: Design Inspiration from Generative Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can an algorithm create original and compelling fashion designs to serve as\nan inspirational assistant? To help answer this question, we design and\ninvestigate different image generation models associated with different loss\nfunctions to boost creativity in fashion generation. The dimensions of our\nexplorations include: (i) different Generative Adversarial Networks\narchitectures that start from noise vectors to generate fashion items, (ii)\nnovel loss functions that encourage novelty, inspired from Sharma-Mittal\ndivergence, a generalized mutual information measure for the widely used\nrelative entropies such as Kullback-Leibler, and (iii) a generation process\nfollowing the key elements of fashion design (disentangling shape and texture\ncomponents). A key challenge of this study is the evaluation of generated\ndesigns and the retrieval of best ones, hence we put together an evaluation\nprotocol associating automatic metrics and human experimental studies that we\nhope will help ease future research. We show that our proposed creativity\ncriterion yield better overall appreciation than the one employed in Creative\nAdversarial Networks. In the end, about 61% of our images are thought to be\ncreated by human designers rather than by a computer while also being\nconsidered original per our human subject experiments, and our proposed loss\nscores the highest compared to existing losses in both novelty and likability.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 11:54:57 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 10:17:31 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Sbai", "Othman", ""], ["Elhoseiny", "Mohamed", ""], ["Bordes", "Antoine", ""], ["LeCun", "Yann", ""], ["Couprie", "Camille", ""]]}, {"id": "1804.00925", "submitter": "Ratnik Gandhi", "authors": "Shreyas Patel, Ashutosh Kakadiya, Maitrey Mehta, Raj Derasari, Rahul\n  Patel, Ratnik Gandhi", "title": "Correlated discrete data generation using adversarial training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GAN) have shown great promise in tasks like\nsynthetic image generation, image inpainting, style transfer, and anomaly\ndetection. However, generating discrete data is a challenge. This work presents\nan adversarial training based correlated discrete data (CDD) generation model.\nIt also details an approach for conditional CDD generation. The results of our\napproach are presented over two datasets; job-seeking candidates skill set\n(private dataset) and MNIST (public dataset). From quantitative and qualitative\nanalysis of these results, we show that our model performs better as it\nleverages inherent correlation in the data, than an existing model that\noverlooks correlation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 12:10:39 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Patel", "Shreyas", ""], ["Kakadiya", "Ashutosh", ""], ["Mehta", "Maitrey", ""], ["Derasari", "Raj", ""], ["Patel", "Rahul", ""], ["Gandhi", "Ratnik", ""]]}, {"id": "1804.00934", "submitter": "Adil Salim", "authors": "Adil Salim, Pascal Bianchi and Walid Hachem", "title": "A Constant Step Stochastic Douglas-Rachford Algorithm with Application\n  to Non Separable Regularizations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Douglas Rachford algorithm is an algorithm that converges to a minimizer\nof a sum of two convex functions. The algorithm consists in fixed point\niterations involving computations of the proximity operators of the two\nfunctions separately. The paper investigates a stochastic version of the\nalgorithm where both functions are random and the step size is constant. We\nestablish that the iterates of the algorithm stay close to the set of solution\nwith high probability when the step size is small enough. Application to\nstructured regularization is considered.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 12:42:07 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Salim", "Adil", ""], ["Bianchi", "Pascal", ""], ["Hachem", "Walid", ""]]}, {"id": "1804.00982", "submitter": "Sebastian Ruder", "authors": "Sebastian Ruder, John Glover, Afshin Mehrabani, Parsa Ghaffari", "title": "360{\\deg} Stance Detection", "comments": "Proceedings of NAACL-HLT 2018: System Demonstrations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of fake news and filter bubbles makes it increasingly\ndifficult to form an unbiased, balanced opinion towards a topic. To ameliorate\nthis, we propose 360{\\deg} Stance Detection, a tool that aggregates news with\nmultiple perspectives on a topic. It presents them on a spectrum ranging from\nsupport to opposition, enabling the user to base their opinion on multiple\npieces of diverse evidence.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 14:17:09 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Ruder", "Sebastian", ""], ["Glover", "John", ""], ["Mehrabani", "Afshin", ""], ["Ghaffari", "Parsa", ""]]}, {"id": "1804.01002", "submitter": "Chuan Zhang", "authors": "Xiaosi Tan (1 and 2 and 3), Weihong Xu (1 and 2 and 3), Yair Be'ery\n  (4), Zaichen Zhang (2 and 3), Xiaohu You (2), and Chuan Zhang (1 and 2 and 3)\n  ((1) Lab of Efficient Architectures for Digital-communication and\n  Signal-processing (LEADS), (2) National Mobile Communications Research\n  Laboratory, (3) Quantum Information Center, Southeast University, China, (4)\n  School of Electrical Engineering, Tel-Aviv University, Tel-Aviv, Israel)", "title": "Improving Massive MIMO Belief Propagation Detector with Deep Neural\n  Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, deep neural network (DNN) is utilized to improve the belief\npropagation (BP) detection for massive multiple-input multiple-output (MIMO)\nsystems. A neural network architecture suitable for detection task is firstly\nintroduced by unfolding BP algorithms. DNN MIMO detectors are then proposed\nbased on two modified BP detectors, damped BP and max-sum BP. The correction\nfactors in these algorithms are optimized through deep learning techniques,\naiming at improved detection performance. Numerical results are presented to\ndemonstrate the performance of the DNN detectors in comparison with various BP\nmodifications. The neural network is trained once and can be used for multiple\nonline detections. The results show that, compared to other state-of-the-art\ndetectors, the DNN detectors can achieve lower bit error rate (BER) with\nimproved robustness against various antenna configurations and channel\nconditions at the same level of complexity.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 10:39:53 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2018 08:58:12 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Tan", "Xiaosi", "", "1 and 2 and 3"], ["Xu", "Weihong", "", "1 and 2 and 3"], ["Be'ery", "Yair", "", "2 and 3"], ["Zhang", "Zaichen", "", "2 and 3"], ["You", "Xiaohu", "", "1 and 2 and 3"], ["Zhang", "Chuan", "", "1 and 2 and 3"]]}, {"id": "1804.01013", "submitter": "Vasileios Tzoumas", "authors": "Vasileios Tzoumas, Ali Jadbabaie, George J. Pappas", "title": "Resilient Non-Submodular Maximization over Matroid Constraints", "comments": "arXiv admin note: substantial text overlap with arXiv:1803.07954.\n  Correction on problem statement (Problem 1), and change in authors' info", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The control and sensing of large-scale systems results in combinatorial\nproblems not only for sensor and actuator placement but also for scheduling or\nobservability/controllability. Such combinatorial constraints in system design\nand implementation can be captured using a structure known as matroids. In\nparticular, the algebraic structure of matroids can be exploited to develop\nscalable algorithms for sensor and actuator selection, along with quantifiable\napproximation bounds. However, in large-scale systems, sensors and actuators\nmay fail or may be (cyber-)attacked. The objective of this paper is to focus on\nresilient matroid-constrained problems arising in control and sensing but in\nthe presence of sensor and actuator failures. In general, resilient\nmatroid-constrained problems are computationally hard. Contrary to the\nnon-resilient case (with no failures), even though they often involve objective\nfunctions that are monotone or submodular, no scalable approximation algorithms\nare known for their solution. In this paper, we provide the first algorithm,\nthat also has the following properties: First, it achieves system-wide\nresiliency, i.e., the algorithm is valid for any number of denial-of-service\nattacks or failures. Second, it is scalable, as our algorithm terminates with\nthe same running time as state-of-the-art algorithms for (non-resilient)\nmatroid-constrained optimization. Third, it provides provable approximation\nbounds on the system performance, since for monotone objective functions our\nalgorithm guarantees a solution close to the optimal. We quantify our\nalgorithm's approximation performance using a notion of curvature for monotone\n(not necessarily submodular) set functions. Finally, we support our theoretical\nanalyses with numerical experiments, by considering a control-aware sensor\nselection scenario, namely, sensing-constrained robot navigation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 17:26:26 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 20:44:03 GMT"}, {"version": "v3", "created": "Thu, 5 Jul 2018 17:03:08 GMT"}, {"version": "v4", "created": "Thu, 6 Dec 2018 00:59:35 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Tzoumas", "Vasileios", ""], ["Jadbabaie", "Ali", ""], ["Pappas", "George J.", ""]]}, {"id": "1804.01016", "submitter": "S.T. John", "authors": "S.T. John and James Hensman", "title": "Large-Scale Cox Process Inference using Variational Fourier Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process modulated Poisson processes provide a flexible framework for\nmodelling spatiotemporal point patterns. So far this had been restricted to one\ndimension, binning to a pre-determined grid, or small data sets of up to a few\nthousand data points. Here we introduce Cox process inference based on Fourier\nfeatures. This sparse representation induces global rather than local\nconstraints on the function space and is computationally efficient. This allows\nus to formulate a grid-free approximation that scales well with the number of\ndata points and the size of the domain. We demonstrate that this allows MCMC\napproximations to the non-Gaussian posterior. We also find that, in practice,\nFourier features have more consistent optimization behavior than previous\napproaches. Our approximate Bayesian method can fit over 100,000 events with\ncomplex spatiotemporal patterns in three dimensions on a single GPU.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 15:00:01 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["John", "S. T.", ""], ["Hensman", "James", ""]]}, {"id": "1804.01050", "submitter": "Garoe Dorta", "authors": "Garoe Dorta, Sara Vicente, Lourdes Agapito, Neill D.F. Campbell, Ivor\n  Simpson", "title": "Training VAEs Under Structured Residuals", "comments": "Simplified training methodology, added more results", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational auto-encoders (VAEs) are a popular and powerful deep generative\nmodel. Previous works on VAEs have assumed a factorized likelihood model,\nwhereby the output uncertainty of each pixel is assumed to be independent. This\napproximation is clearly limited as demonstrated by observing a residual image\nfrom a VAE reconstruction, which often possess a high level of structure. This\npaper demonstrates a novel scheme to incorporate a structured Gaussian\nlikelihood prediction network within the VAE that allows the residual\ncorrelations to be modeled. Our novel architecture, with minimal increase in\ncomplexity, incorporates the covariance matrix prediction within the VAE. We\nalso propose a new mechanism for allowing structured uncertainty on color\nimages. Furthermore, we provide a scheme for effectively training this model,\nand include some suggestions for improving performance in terms of efficiency\nor modeling longer range correlations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 16:04:22 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 19:00:03 GMT"}, {"version": "v3", "created": "Tue, 31 Jul 2018 16:53:19 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Dorta", "Garoe", ""], ["Vicente", "Sara", ""], ["Agapito", "Lourdes", ""], ["Campbell", "Neill D. F.", ""], ["Simpson", "Ivor", ""]]}, {"id": "1804.01071", "submitter": "Stephane Chretien", "authors": "Stephane Chretien, Christophe Guyeux and Zhen-Wai Olivier HO", "title": "Average performance analysis of the stochastic gradient method for\n  online PCA", "comments": "11 pages, 1 figure, Submitted to LOD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the complexity of the stochastic gradient algorithm for\nPCA when the data are observed in a streaming setting. We also propose an\nonline approach for selecting the learning rate. Simulation experiments confirm\nthe practical relevance of the plain stochastic gradient approach and that\ndrastic improvements can be achieved by learning the learning rate.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 17:31:32 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Chretien", "Stephane", ""], ["Guyeux", "Christophe", ""], ["HO", "Zhen-Wai Olivier", ""]]}, {"id": "1804.01116", "submitter": "Jayakumar Subramanian", "authors": "Jayakumar Subramanian and Aditya Mahajan", "title": "Renewal Monte Carlo: Renewal theory based reinforcement learning", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an online reinforcement learning algorithm, called\nRenewal Monte Carlo (RMC), for infinite horizon Markov decision processes with\na designated start state. RMC is a Monte Carlo algorithm and retains the\nadvantages of Monte Carlo methods including low bias, simplicity, and ease of\nimplementation while, at the same time, circumvents their key drawbacks of high\nvariance and delayed (end of episode) updates. The key ideas behind RMC are as\nfollows. First, under any reasonable policy, the reward process is ergodic. So,\nby renewal theory, the performance of a policy is equal to the ratio of\nexpected discounted reward to the expected discounted time over a regenerative\ncycle. Second, by carefully examining the expression for performance gradient,\nwe propose a stochastic approximation algorithm that only requires estimates of\nthe expected discounted reward and discounted time over a regenerative cycle\nand their gradients. We propose two unbiased estimators for evaluating\nperformance gradients---a likelihood ratio based estimator and a simultaneous\nperturbation based estimator---and show that for both estimators, RMC converges\nto a locally optimal policy. We generalize the RMC algorithm to post-decision\nstate models and also present a variant that converges faster to an\napproximately optimal policy. We conclude by presenting numerical experiments\non a randomly generated MDP, event-triggered communication, and inventory\nmanagement.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 18:18:54 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Subramanian", "Jayakumar", ""], ["Mahajan", "Aditya", ""]]}, {"id": "1804.01118", "submitter": "Yaroslav Ganin", "authors": "Yaroslav Ganin, Tejas Kulkarni, Igor Babuschkin, S.M. Ali Eslami,\n  Oriol Vinyals", "title": "Synthesizing Programs for Images using Reinforced Adversarial Learning", "comments": "12 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in deep generative networks have led to impressive results in recent\nyears. Nevertheless, such models can often waste their capacity on the minutiae\nof datasets, presumably due to weak inductive biases in their decoders. This is\nwhere graphics engines may come in handy since they abstract away low-level\ndetails and represent images as high-level programs. Current methods that\ncombine deep learning and renderers are limited by hand-crafted likelihood or\ndistance functions, a need for large amounts of supervision, or difficulties in\nscaling their inference algorithms to richer datasets. To mitigate these\nissues, we present SPIRAL, an adversarially trained agent that generates a\nprogram which is executed by a graphics engine to interpret and sample images.\nThe goal of this agent is to fool a discriminator network that distinguishes\nbetween real and rendered data, trained with a distributed reinforcement\nlearning setup without any supervision. A surprising finding is that using the\ndiscriminator's output as a reward signal is the key to allow the agent to make\nmeaningful progress at matching the desired output rendering. To the best of\nour knowledge, this is the first demonstration of an end-to-end, unsupervised\nand adversarial inverse graphics agent on challenging real world (MNIST,\nOmniglot, CelebA) and synthetic 3D datasets.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 18:25:42 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Ganin", "Yaroslav", ""], ["Kulkarni", "Tejas", ""], ["Babuschkin", "Igor", ""], ["Eslami", "S. M. Ali", ""], ["Vinyals", "Oriol", ""]]}, {"id": "1804.01119", "submitter": "Stephane Chretien", "authors": "Stephane Chretien and Zhen-Wai Olivier Ho", "title": "Feature selection in weakly coherent matrices", "comments": "14 pages, 6 Figures, Accepted for LVA-ICA 2018 Surrey", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A problem of paramount importance in both pure (Restricted Invertibility\nproblem) and applied mathematics (Feature extraction) is the one of selecting a\nsubmatrix of a given matrix, such that this submatrix has its smallest singular\nvalue above a specified level. Such problems can be addressed using\nperturbation analysis. In this paper, we propose a perturbation bound for the\nsmallest singular value of a given matrix after appending a column, under the\nassumption that its initial coherence is not large, and we use this bound to\nderive a fast algorithm for feature extraction.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 18:26:46 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Chretien", "Stephane", ""], ["Ho", "Zhen-Wai Olivier", ""]]}, {"id": "1804.01155", "submitter": "M\\'arton Karsai", "authors": "Jacob Levy Abitbol, M\\'arton Karsai, Jean-Philippe Magu\\'e,\n  Jean-Pierre Chevrot and Eric Fleury", "title": "Socioeconomic Dependencies of Linguistic Patterns in Twitter: A\n  Multivariate Analysis", "comments": "In WWW 2018: The Web Conference, 10 pages, 6 figures", "journal-ref": null, "doi": "10.1145/3178876.3186011", "report-no": null, "categories": "cs.CL cs.CY cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our usage of language is not solely reliant on cognition but is arguably\ndetermined by myriad external factors leading to a global variability of\nlinguistic patterns. This issue, which lies at the core of sociolinguistics and\nis backed by many small-scale studies on face-to-face communication, is\naddressed here by constructing a dataset combining the largest French Twitter\ncorpus to date with detailed socioeconomic maps obtained from national census\nin France. We show how key linguistic variables measured in individual Twitter\nstreams depend on factors like socioeconomic status, location, time, and the\nsocial network of individuals. We found that (i) people of higher socioeconomic\nstatus, active to a greater degree during the daytime, use a more standard\nlanguage; (ii) the southern part of the country is more prone to use more\nstandard language than the northern one, while locally the used variety or\ndialect is determined by the spatial distribution of socioeconomic status; and\n(iii) individuals connected in the social network are closer linguistically\nthan disconnected ones, even after the effects of status homophily have been\nremoved. Our results inform sociolinguistic theory and may inspire novel\nlearning methods for the inference of socioeconomic status of people from the\nway they tweet.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 20:18:11 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Abitbol", "Jacob Levy", ""], ["Karsai", "M\u00e1rton", ""], ["Magu\u00e9", "Jean-Philippe", ""], ["Chevrot", "Jean-Pierre", ""], ["Fleury", "Eric", ""]]}, {"id": "1804.01188", "submitter": "Jialiang Jiang", "authors": "Jialiang Jiang, Sharon Hewner, Varun Chandola", "title": "Hospital Readmission Prediction - Applying Hierarchical Sparsity Norms\n  for Interpretable Models", "comments": "included in the proceedings of the MLDM 2016 conference, #1323", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hospital readmissions have become one of the key measures of healthcare\nquality. Preventable readmissions have been identified as one of the primary\ntargets for reducing costs and improving healthcare delivery. However, most\ndata driven studies for understanding readmissions have produced black box\nclassification and predictive models with moderate performance, which precludes\nthem from being used effectively within the decision support systems in the\nhospitals. In this paper we present an application of structured\nsparsity-inducing norms for predicting readmission risk for patients based on\ntheir disease history and demographics. Most existing studies have focused on\nhospital utilization, test results, etc., to assign a readmission label to each\nepisode of hospitalization. However, we focus on assigning a readmission risk\nlabel to a patient based on their disease history. Our emphasis is on\ninterpreting the models to improve the understanding of the readmission\nproblem. To achieve this, we exploit the domain induced hierarchical structure\navailable for the disease codes which are the features for the classification\nalgorithm. We use a tree based sparsity-inducing regularization strategy that\nexplicitly uses the domain hierarchy. The resulting model not only outperforms\nstandard regularization procedures but is also highly sparse and interpretable.\nWe analyze the model and identify several significant factors that have an\neffect on readmission risk. Some of these factors conform to existing beliefs,\ne.g., impact of surgical complications and infections during hospital stay.\nOther factors, such as the impact of mental disorder and substance abuse on\nreadmission, provide empirical evidence for several pre-existing but unverified\nhypotheses. The analysis also reveals previously undiscovered connections such\nas the influence of socioeconomic factors like lack of housing and\nmalnutrition.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 22:56:25 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Jiang", "Jialiang", ""], ["Hewner", "Sharon", ""], ["Chandola", "Varun", ""]]}, {"id": "1804.01189", "submitter": "Baosen Zhang", "authors": "Aaron Jaech and Baosen Zhang and Mari Ostendorf and Daniel S. Kirschen", "title": "Real-Time Prediction of the Duration of Distribution System Outages", "comments": "Appears in IEEE Transactions on Power Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.CL math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of predicting duration of unplanned power\noutages, using historical outage records to train a series of neural network\npredictors. The initial duration prediction is made based on environmental\nfactors, and it is updated based on incoming field reports using natural\nlanguage processing to automatically analyze the text. Experiments using 15\nyears of outage records show good initial results and improved performance\nleveraging text. Case studies show that the language processing identifies\nphrases that point to outage causes and repair steps.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 23:10:36 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 01:55:15 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Jaech", "Aaron", ""], ["Zhang", "Baosen", ""], ["Ostendorf", "Mari", ""], ["Kirschen", "Daniel S.", ""]]}, {"id": "1804.01221", "submitter": "Max Simchowitz", "authors": "Max Simchowitz and Ahmed El Alaoui and Benjamin Recht", "title": "Tight Query Complexity Lower Bounds for PCA via Finite Sample Deformed\n  Wigner Law", "comments": "To appear in STOC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a \\emph{query complexity} lower bound for approximating the top $r$\ndimensional eigenspace of a matrix. We consider an oracle model where, given a\nsymmetric matrix $\\mathbf{M} \\in \\mathbb{R}^{d \\times d}$, an algorithm\n$\\mathsf{Alg}$ is allowed to make $\\mathsf{T}$ exact queries of the form\n$\\mathsf{w}^{(i)} = \\mathbf{M} \\mathsf{v}^{(i)}$ for $i$ in\n$\\{1,...,\\mathsf{T}\\}$, where $\\mathsf{v}^{(i)}$ is drawn from a distribution\nwhich depends arbitrarily on the past queries and measurements\n$\\{\\mathsf{v}^{(j)},\\mathsf{w}^{(i)}\\}_{1 \\le j \\le i-1}$. We show that for\nevery $\\mathtt{gap} \\in (0,1/2]$, there exists a distribution over matrices\n$\\mathbf{M}$ for which 1) $\\mathrm{gap}_r(\\mathbf{M}) = \\Omega(\\mathtt{gap})$\n(where $\\mathrm{gap}_r(\\mathbf{M})$ is the normalized gap between the $r$ and\n$r+1$-st largest-magnitude eigenvector of $\\mathbf{M}$), and 2) any algorithm\n$\\mathsf{Alg}$ which takes fewer than $\\mathrm{const} \\times \\frac{r \\log\nd}{\\sqrt{\\mathtt{gap}}}$ queries fails (with overwhelming probability) to\nidentity a matrix $\\widehat{\\mathsf{V}} \\in \\mathbb{R}^{d \\times r}$ with\northonormal columns for which $\\langle \\widehat{\\mathsf{V}}, \\mathbf{M}\n\\widehat{\\mathsf{V}}\\rangle \\ge (1 - \\mathrm{const} \\times\n\\mathtt{gap})\\sum_{i=1}^r \\lambda_i(\\mathbf{M})$. Our bound requires only that\n$d$ is a small polynomial in $1/\\mathtt{gap}$ and $r$, and matches the upper\nbounds of Musco and Musco '15. Moreover, it establishes a strict separation\nbetween convex optimization and \\emph{randomized}, \"strict-saddle\" non-convex\noptimization of which PCA is a canonical example: in the former, first-order\nmethods can have dimension-free iteration complexity, whereas in PCA, the\niteration complexity of gradient-based methods must necessarily grow with the\ndimension.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 03:00:06 GMT"}, {"version": "v2", "created": "Sat, 27 Jun 2020 20:55:06 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Simchowitz", "Max", ""], ["Alaoui", "Ahmed El", ""], ["Recht", "Benjamin", ""]]}, {"id": "1804.01238", "submitter": "Trevor Barron", "authors": "Trevor Barron, Oliver Obst, Heni Ben Amor", "title": "Information Maximizing Exploration with a Latent Dynamics Model", "comments": "Presented at the NIPS 2017 Deep Reinforcement Learning Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All reinforcement learning algorithms must handle the trade-off between\nexploration and exploitation. Many state-of-the-art deep reinforcement learning\nmethods use noise in the action selection, such as Gaussian noise in policy\ngradient methods or $\\epsilon$-greedy in Q-learning. While these methods are\nappealing due to their simplicity, they do not explore the state space in a\nmethodical manner. We present an approach that uses a model to derive reward\nbonuses as a means of intrinsic motivation to improve model-free reinforcement\nlearning. A key insight of our approach is that this dynamics model can be\nlearned in the latent feature space of a value function, representing the\ndynamics of the agent and the environment. This method is both theoretically\ngrounded and computationally advantageous, permitting the efficient use of\nBayesian information-theoretic methods in high-dimensional state spaces. We\nevaluate our method on several continuous control tasks, focusing on improving\nexploration.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 05:04:41 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Barron", "Trevor", ""], ["Obst", "Oliver", ""], ["Amor", "Heni Ben", ""]]}, {"id": "1804.01256", "submitter": "Thomas Guyet", "authors": "Thomas Guyet (LACODAM), Ren\\'e Quiniou (LACODAM)", "title": "NegPSpan: efficient extraction of negative sequential patterns with\n  embedding constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining frequent sequential patterns consists in extracting recurrent\nbehaviors, modeled as patterns, in a big sequence dataset. Such patterns inform\nabout which events are frequently observed in sequences, i.e. what does really\nhappen. Sometimes, knowing that some specific event does not happen is more\ninformative than extracting a lot of observed events. Negative sequential\npatterns (NSP) formulate recurrent behaviors by patterns containing both\nobserved events and absent events. Few approaches have been proposed to mine\nsuch NSPs. In addition, the syntax and semantics of NSPs differ in the\ndifferent methods which makes it difficult to compare them. This article\nprovides a unified framework for the formulation of the syntax and the\nsemantics of NSPs. Then, we introduce a new algorithm, NegPSpan, that extracts\nNSPs using a PrefixSpan depth-first scheme and enabling maxgap constraints that\nother approaches do not take into account. The formal framework allows for\nhighlighting the differences between the proposed approach wrt to the methods\nfrom the literature, especially wrt the state of the art approach eNSP.\nIntensive experiments on synthetic and real datasets show that NegPSpan can\nextract meaningful NSPs and that it can process bigger datasets than eNSP\nthanks to significantly lower memory requirements and better computation times.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 06:47:32 GMT"}, {"version": "v2", "created": "Wed, 25 Jul 2018 13:42:47 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Guyet", "Thomas", "", "LACODAM"], ["Quiniou", "Ren\u00e9", "", "LACODAM"]]}, {"id": "1804.01330", "submitter": "Thomas Krak", "authors": "Thomas Krak, Alexander Erreygers, Jasper De Bock", "title": "An Imprecise Probabilistic Estimator for the Transition Rate Matrix of a\n  Continuous-Time Markov Chain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating the transition rate matrix of a\ncontinuous-time Markov chain from a finite-duration realisation of this\nprocess. We approach this problem in an imprecise probabilistic framework,\nusing a set of prior distributions on the unknown transition rate matrix. The\nresulting estimator is a set of transition rate matrices that, for reasons of\nconjugacy, is easy to find. To determine the hyperparameters for our set of\npriors, we reconsider the problem in discrete time, where we can use the\nwell-known Imprecise Dirichlet Model. In particular, we show how the limit of\nthe resulting discrete-time estimators is a continuous-time estimator. It\ncorresponds to a specific choice of hyperparameters and has an exceptionally\nsimple closed-form expression.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 10:20:05 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 08:42:47 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Krak", "Thomas", ""], ["Erreygers", "Alexander", ""], ["De Bock", "Jasper", ""]]}, {"id": "1804.01382", "submitter": "Chaochen Wu", "authors": "Chaochen Wu", "title": "Vanlearning: A Machine Learning SaaS Application for People Without\n  Programming Backgrounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although we have tons of machine learning tools to analyze data, most of them\nrequire users have some programming backgrounds. Here we introduce a SaaS\napplication which allows users analyze their data without any coding and even\nwithout any knowledge of machine learning. Users can upload, train, predict and\ndownload their data by simply clicks their mouses. Our system uses data\npre-processor and validator to relieve the computational cost of our server.\nThe simple architecture of Vanlearning helps developers can easily maintain and\nextend it.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 01:17:16 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Wu", "Chaochen", ""]]}, {"id": "1804.01466", "submitter": "William Herlands", "authors": "William Herlands, Edward McFowland III, Andrew Gordon Wilson, Daniel\n  B. Neill", "title": "Gaussian Process Subset Scanning for Anomalous Pattern Detection in\n  Non-iid Data", "comments": "Presented at AISTATS 2018. 11 pages. Supplement to main paper is\n  included here as an appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying anomalous patterns in real-world data is essential for\nunderstanding where, when, and how systems deviate from their expected\ndynamics. Yet methods that separately consider the anomalousness of each\nindividual data point have low detection power for subtle, emerging\nirregularities. Additionally, recent detection techniques based on subset\nscanning make strong independence assumptions and suffer degraded performance\nin correlated data. We introduce methods for identifying anomalous patterns in\nnon-iid data by combining Gaussian processes with novel log-likelihood ratio\nstatistic and subset scanning techniques. Our approaches are powerful,\ninterpretable, and can integrate information across multiple data streams. We\nillustrate their performance on numeric simulations and three open source\nspatiotemporal datasets of opioid overdose deaths, 311 calls, and storm\nreports.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 15:23:16 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Herlands", "William", ""], ["McFowland", "Edward", "III"], ["Wilson", "Andrew Gordon", ""], ["Neill", "Daniel B.", ""]]}, {"id": "1804.01486", "submitter": "Andrew Beam", "authors": "Andrew L. Beam, Benjamin Kompa, Allen Schmaltz, Inbar Fried, Griffin\n  Weber, Nathan P. Palmer, Xu Shi, Tianxi Cai, Isaac S. Kohane", "title": "Clinical Concept Embeddings Learned from Massive Sources of Multimodal\n  Medical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are a popular approach to unsupervised learning of word\nrelationships that are widely used in natural language processing. In this\narticle, we present a new set of embeddings for medical concepts learned using\nan extremely large collection of multimodal medical data. Leaning on recent\ntheoretical insights, we demonstrate how an insurance claims database of 60\nmillion members, a collection of 20 million clinical notes, and 1.7 million\nfull text biomedical journal articles can be combined to embed concepts into a\ncommon space, resulting in the largest ever set of embeddings for 108,477\nmedical concepts. To evaluate our approach, we present a new benchmark\nmethodology based on statistical power specifically designed to test embeddings\nof medical concepts. Our approach, called cui2vec, attains state-of-the-art\nperformance relative to previous methods in most instances. Finally, we provide\na downloadable set of pre-trained embeddings for other researchers to use, as\nwell as an online tool for interactive exploration of the cui2vec embeddings\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 16:02:54 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 19:25:31 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 00:32:33 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Beam", "Andrew L.", ""], ["Kompa", "Benjamin", ""], ["Schmaltz", "Allen", ""], ["Fried", "Inbar", ""], ["Weber", "Griffin", ""], ["Palmer", "Nathan P.", ""], ["Shi", "Xu", ""], ["Cai", "Tianxi", ""], ["Kohane", "Isaac S.", ""]]}, {"id": "1804.01491", "submitter": "Zahra Ahmadi", "authors": "Zahra Ahmadi and Stefan Kramer", "title": "Online Multi-Label Classification: A Label Compression Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern applications deal with multi-label data, such as functional\ncategorizations of genes, image labeling and text categorization.\nClassification of such data with a large number of labels and latent\ndependencies among them is a challenging task, and it becomes even more\nchallenging when the data is received online and in chunks. Many of the current\nmulti-label classification methods require a lot of time and memory, which make\nthem infeasible for practical real-world applications. In this paper, we\npropose a fast linear label space dimension reduction method that transforms\nthe labels into a reduced encoded space and trains models on the obtained\npseudo labels. Additionally, it provides an analytical method to update the\ndecoding matrix which maps the labels into the original space and is used\nduring the test phase. Experimental results show the effectiveness of this\napproach in terms of running times and the prediction performance over\ndifferent measures.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 16:18:28 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Ahmadi", "Zahra", ""], ["Kramer", "Stefan", ""]]}, {"id": "1804.01526", "submitter": "Mario Drumond", "authors": "Mario Drumond, Tao Lin, Martin Jaggi, Babak Falsafi", "title": "Training DNNs with Hybrid Block Floating Point", "comments": "9 pages, 3 figures. Accepted in Neural Information Processing Systems\n  2018 (NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wide adoption of DNNs has given birth to unrelenting computing\nrequirements, forcing datacenter operators to adopt domain-specific\naccelerators to train them. These accelerators typically employ densely packed\nfull precision floating-point arithmetic to maximize performance per area.\nOngoing research efforts seek to further increase that performance density by\nreplacing floating-point with fixed-point arithmetic. However, a significant\nroadblock for these attempts has been fixed point's narrow dynamic range, which\nis insufficient for DNN training convergence. We identify block floating point\n(BFP) as a promising alternative representation since it exhibits wide dynamic\nrange and enables the majority of DNN operations to be performed with\nfixed-point logic. Unfortunately, BFP alone introduces several limitations that\npreclude its direct applicability. In this work, we introduce HBFP, a hybrid\nBFP-FP approach, which performs all dot products in BFP and other operations in\nfloating point. HBFP delivers the best of both worlds: the high accuracy of\nfloating point at the superior hardware density of fixed point. For a wide\nvariety of models, we show that HBFP matches floating point's accuracy while\nenabling hardware implementations that deliver up to 8.5x higher throughput.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 09:40:59 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2018 21:48:51 GMT"}, {"version": "v3", "created": "Mon, 28 May 2018 17:48:03 GMT"}, {"version": "v4", "created": "Sun, 2 Dec 2018 15:11:18 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Drumond", "Mario", ""], ["Lin", "Tao", ""], ["Jaggi", "Martin", ""], ["Falsafi", "Babak", ""]]}, {"id": "1804.01527", "submitter": "Jos\\'e Carlos Aradillas Jaramillo", "authors": "Jos\\'e Carlos Aradillas, Juan Jos\\'e Murillo-Fuentes, Pablo M. Olmos", "title": "Boosting Handwriting Text Recognition in Small Databases with Transfer\n  Learning", "comments": "ICFHR 2018 Conference", "journal-ref": null, "doi": "10.1109/ICFHR-2018.2018.00081", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we deal with the offline handwriting text recognition (HTR)\nproblem with reduced training datasets. Recent HTR solutions based on\nartificial neural networks exhibit remarkable solutions in referenced\ndatabases. These deep learning neural networks are composed of both\nconvolutional (CNN) and long short-term memory recurrent units (LSTM). In\naddition, connectionist temporal classification (CTC) is the key to avoid\nsegmentation at character level, greatly facilitating the labeling task. One of\nthe main drawbacks of the CNNLSTM-CTC (CLC) solutions is that they need a\nconsiderable part of the text to be transcribed for every type of calligraphy,\ntypically in the order of a few thousands of lines. Furthermore, in some\nscenarios the text to transcribe is not that long, e.g. in the Washington\ndatabase. The CLC typically overfits for this reduced number of training\nsamples. Our proposal is based on the transfer learning (TL) from the\nparameters learned with a bigger database. We first investigate, for a reduced\nand fixed number of training samples, 350 lines, how the learning from a large\ndatabase, the IAM, can be transferred to the learning of the CLC of a reduced\ndatabase, Washington. We focus on which layers of the network could be not\nre-trained. We conclude that the best solution is to re-train the whole CLC\nparameters initialized to the values obtained after the training of the CLC\nfrom the larger database. We also investigate results when the training size is\nfurther reduced. The differences in the CER are more remarkable when training\nwith just 350 lines, a CER of 3.3% is achieved with TL while we have a CER of\n18.2% when training from scratch. As a byproduct, the learning times are quite\nreduced. Similar good results are obtained from the Parzival database when\ntrained with this reduced number of lines and this new approach.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 11:20:28 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Aradillas", "Jos\u00e9 Carlos", ""], ["Murillo-Fuentes", "Juan Jos\u00e9", ""], ["Olmos", "Pablo M.", ""]]}, {"id": "1804.01557", "submitter": "Tobias D. Krafft", "authors": "Tobias D. Krafft", "title": "Qualit\\\"atsma{\\ss}e bin\\\"arer Klassifikationen im Bereich\n  kriminalprognostischer Instrumente der vierten Generation", "comments": "master's thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This master's thesis discusses an important issue regarding how algorithmic\ndecision making (ADM) is used in crime forecasting. In America forecasting\ntools are widely used by judiciary systems for making decisions about risk\noffenders based on criminal justice for risk offenders. By making use of such\ntools, the judiciary relies on ADM in order to make error free judgement on\noffenders. For this purpose, one of the quality measures for machine learning\ntechniques which is widly used, the $AUC$ (area under curve), is compared to\nand contrasted for results with the $PPV_k$ (positive predictive value).\nKeeping in view the criticality of judgement along with a high dependency on\ntools offering ADM, it is necessary to evaluate risk tools that aid in decision\nmaking based on algorithms. In this methodology, such an evaluation is\nconducted by implementing a common machine learning approach called binary\nclassifier, as it determines the binary outcome of the underlying juristic\nquestion. This thesis showed that the $PPV_k$ (positive predictive value)\ntechnique models the decision of judges much better than the $AUC$. Therefore,\nthis research has investigated whether there exists a classifier for which the\n$PPV_k$ deviates from $AUC$ by a large proportion. It could be shown that the\ndeviation can rise up to 0.75. In order to test this deviation on an already in\nused Classifier, data from the fourth generation risk assement tool COMPAS was\nused. The result were were quite alarming as the two measures derivate from\neach other by 0.48. In this study, the risk assessment evaluation of the\nforecasting tools was successfully conducted, carefully reviewed and examined.\nAdditionally, it is also discussed whether such systems used for the purpose of\nmaking decisions should be socially accepted or not.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 18:27:45 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Krafft", "Tobias D.", ""]]}, {"id": "1804.01575", "submitter": "Aubrey Gress", "authors": "Aubrey Gress and Ian Davidson", "title": "Probabilistic Formulations of Regression with Mixed Guidance", "comments": "Appeared in ICDM 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regression problems assume every instance is annotated (labeled) with a real\nvalue, a form of annotation we call \\emph{strong guidance}. In order for these\nannotations to be accurate, they must be the result of a precise experiment or\nmeasurement. However, in some cases additional \\emph{weak guidance} might be\ngiven by imprecise measurements, a domain expert or even crowd sourcing.\nCurrent formulations of regression are unable to use both types of guidance. We\npropose a regression framework that can also incorporate weak guidance based on\nrelative orderings, bounds, neighboring and similarity relations. Consider\nlearning to predict ages from portrait images, these new types of guidance\nallow weaker forms of guidance such as stating a person is in their 20s or two\npeople are similar in age. These types of annotations can be easier to generate\nthan strong guidance. We introduce a probabilistic formulation for these forms\nof weak guidance and show that the resulting optimization problems are convex.\nOur experimental results show the benefits of these formulations on several\ndata sets.\n", "versions": [{"version": "v1", "created": "Sun, 1 Apr 2018 20:36:33 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Gress", "Aubrey", ""], ["Davidson", "Ian", ""]]}, {"id": "1804.01592", "submitter": "Jan Vyb\\'iral", "authors": "Massimo Fornasier, Jan Vyb\\'iral, Ingrid Daubechies", "title": "Robust and Resource Efficient Identification of Shallow Neural Networks\n  by Fewest Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the structure identification and the uniform approximation of sums\nof ridge functions $f(x)=\\sum_{i=1}^m g_i(a_i\\cdot x)$ on ${\\mathbb R}^d$,\nrepresenting a general form of a shallow feed-forward neural network, from a\nsmall number of query samples. Higher order differentiation, as used in our\nconstructive approximations, of sums of ridge functions or of their\ncompositions, as in deeper neural network, yields a natural connection between\nneural network weight identification and tensor product decomposition\nidentification. In the case of the shallowest feed-forward neural network,\nsecond order differentiation and tensors of order two (i.e., matrices) suffice\nas we prove in this paper. We use two sampling schemes to perform approximate\ndifferentiation - active sampling, where the sampling points are universal,\nactively, and randomly designed, and passive sampling, where sampling points\nwere preselected at random from a distribution with known density. Based on\nmultiple gathered approximated first and second order differentials, our\ngeneral approximation strategy is developed as a sequence of algorithms to\nperform individual sub-tasks. We first perform an active subspace search by\napproximating the span of the weight vectors $a_1,\\dots,a_m$. Then we use a\nstraightforward substitution, which reduces the dimensionality of the problem\nfrom $d$ to $m$. The core of the construction is then the stable and efficient\napproximation of weights expressed in terms of rank-$1$ matrices $a_i \\otimes\na_i$, realized by formulating their individual identification as a suitable\nnonlinear program. We prove the successful identification by this program of\nweight vectors being close to orthonormal and we also show how we can\ncostructively reduce to this case by a whitening procedure, without loss of any\ngenerality.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 19:56:40 GMT"}, {"version": "v2", "created": "Wed, 10 Apr 2019 10:32:37 GMT"}, {"version": "v3", "created": "Thu, 6 May 2021 07:55:12 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Fornasier", "Massimo", ""], ["Vyb\u00edral", "Jan", ""], ["Daubechies", "Ingrid", ""]]}, {"id": "1804.01619", "submitter": "Yuansi Chen", "authors": "Yuansi Chen, Chi Jin and Bin Yu", "title": "Stability and Convergence Trade-off of Iterative Optimization Algorithms", "comments": "45 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overall performance or expected excess risk of an iterative machine\nlearning algorithm can be decomposed into training error and generalization\nerror. While the former is controlled by its convergence analysis, the latter\ncan be tightly handled by algorithmic stability. The machine learning community\nhas a rich history investigating convergence and stability separately. However,\nthe question about the trade-off between these two quantities remains open. In\nthis paper, we show that for any iterative algorithm at any iteration, the\noverall performance is lower bounded by the minimax statistical error over an\nappropriately chosen loss function class. This implies an important trade-off\nbetween convergence and stability of the algorithm -- a faster converging\nalgorithm has to be less stable, and vice versa. As a direct consequence of\nthis fundamental tradeoff, new convergence lower bounds can be derived for\nclasses of algorithms constrained with different stability bounds. In\nparticular, when the loss function is convex (or strongly convex) and smooth,\nwe discuss the stability upper bounds of gradient descent (GD) and stochastic\ngradient descent and their variants with decreasing step sizes. For Nesterov's\naccelerated gradient descent (NAG) and heavy ball method (HB), we provide\nstability upper bounds for the quadratic loss function. Applying existing\nstability upper bounds for the gradient methods in our trade-off framework, we\nobtain lower bounds matching the well-established convergence upper bounds up\nto constants for these algorithms and conjecture similar lower bounds for NAG\nand HB. Finally, we numerically demonstrate the tightness of our stability\nbounds in terms of exponents in the rate and also illustrate via a simulated\nlogistic regression problem that our stability bounds reflect the\ngeneralization errors better than the simple uniform convergence bounds for GD\nand NAG.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 22:23:40 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Chen", "Yuansi", ""], ["Jin", "Chi", ""], ["Yu", "Bin", ""]]}, {"id": "1804.01620", "submitter": "Eduardo Pavez", "authors": "Eduardo Pavez and Antonio Ortega", "title": "Active covariance estimation by random sub-sampling of variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study covariance matrix estimation for the case of partially observed\nrandom vectors, where different samples contain different subsets of vector\ncoordinates. Each observation is the product of the variable of interest with a\n$0-1$ Bernoulli random variable. We analyze an unbiased covariance estimator\nunder this model, and derive an error bound that reveals relations between the\nsub-sampling probabilities and the entries of the covariance matrix. We apply\nour analysis in an active learning framework, where the expected number of\nobserved variables is small compared to the dimension of the vector of\ninterest, and propose a design of optimal sub-sampling probabilities and an\nactive covariance matrix estimation algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 22:49:12 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Pavez", "Eduardo", ""], ["Ortega", "Antonio", ""]]}, {"id": "1804.01653", "submitter": "Rong Zhang", "authors": "Rong Zhang, Weiping Li, Tong Mo", "title": "Review of Deep Learning", "comments": "In Chinese. Have been published in the journal \"Information and\n  Control\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, China, the United States and other countries, Google and\nother high-tech companies have increased investment in artificial intelligence.\nDeep learning is one of the current artificial intelligence research's key\nareas. This paper analyzes and summarizes the latest progress and future\nresearch directions of deep learning. Firstly, three basic models of deep\nlearning are outlined, including multilayer perceptrons, convolutional neural\nnetworks, and recurrent neural networks. On this basis, we further analyze the\nemerging new models of convolution neural networks and recurrent neural\nnetworks. This paper then summarizes deep learning's applications in many areas\nof artificial intelligence, including speech processing, computer vision,\nnatural language processing and so on. Finally, this paper discusses the\nexisting problems of deep learning and gives the corresponding possible\nsolutions.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 02:23:59 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 15:34:03 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Zhang", "Rong", ""], ["Li", "Weiping", ""], ["Mo", "Tong", ""]]}, {"id": "1804.01675", "submitter": "Andrew Paplinski", "authors": "Yanan Li, Haixiang Guo, Andrew P Paplinski", "title": "Semi-Supervised Classification for oil reservoir", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the general problem of accurate identification of oil\nreservoirs. Recent improvements in well or borehole logging technology have\nresulted in an explosive amount of data available for processing. The\ntraditional methods of analysis of the logs characteristics by experts require\nsignificant amount of time and money and is no longer practicable. In this\npaper, we use the semi-supervised learning to solve the problem of\never-increasing amount of unlabelled data available for interpretation. The\nexperts are needed to label only a small amount of the log data. The neural\nnetwork classifier is first trained with the initial labelled data. Next,\nbatches of unlabelled data are being classified and the samples with the very\nhigh class probabilities are being used in the next training session,\nbootstrapping the classifier. The process of training, classifying, enhancing\nthe labelled data is repeated iteratively until the stopping criteria are met,\nthat is, no more high probability samples are found. We make an empirical study\non the well data from Jianghan oil field and test the performance of the neural\nnetwork semi-supervised classifier. We compare this method with other\nclassifiers. The comparison results show that our neural network\nsemi-supervised classifier is superior to other classification methods.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 05:41:39 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Li", "Yanan", ""], ["Guo", "Haixiang", ""], ["Paplinski", "Andrew P", ""]]}, {"id": "1804.01684", "submitter": "Philippe Thomas", "authors": "Philippe Thomas (CRAN), Hind Bril El Haouzi, Marie-Christine Suhner\n  (CRAN), Andr\\'e Thomas (CRAN), Emmanuel Zimmermann (CRAN), M\\'elanie Noyel", "title": "Using a Classifier Ensemble for Proactive Quality Monitoring and\n  Control: the impact of the choice of classifiers types, selection criterion,\n  and fusion process", "comments": null, "journal-ref": "Computers in Industry Computers in Industry, 99, pp.193 - 204", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent times, the manufacturing processes are faced with many external or\ninternal (the increase of customized product rescheduling , process\nreliability,..) changes. Therefore, monitoring and quality management\nactivities for these manufacturing processes are difficult. Thus, the managers\nneed more proactive approaches to deal with this variability. In this study, a\nproactive quality monitoring and control approach based on classifiers to\npredict defect occurrences and provide optimal values for factors critical to\nthe quality processes is proposed. In a previous work (Noyel et al. 2013), the\nclassification approach had been used in order to improve the quality of a\nlacquering process at a company plant; the results obtained are promising, but\nthe accuracy of the classification model used needs to be improved. One way to\nachieve this is to construct a committee of classifiers (referred to as an\nensemble) to obtain a better predictive model than its constituent models.\nHowever, the selection of the best classification methods and the construction\nof the final ensemble still poses a challenging issue. In this study, we focus\nand analyze the impact of the choice of classifier types on the accuracy of the\nclassifier ensemble; in addition, we explore the effects of the selection\ncriterion and fusion process on the ensemble accuracy as well. Several fusion\nscenarios were tested and compared based on a real-world case. Our results show\nthat using an ensemble classification leads to an increase in the accuracy of\nthe classifier models. Consequently, the monitoring and control of the\nconsidered real-world case can be improved.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 06:46:19 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Thomas", "Philippe", "", "CRAN"], ["Haouzi", "Hind Bril El", "", "CRAN"], ["Suhner", "Marie-Christine", "", "CRAN"], ["Thomas", "Andr\u00e9", "", "CRAN"], ["Zimmermann", "Emmanuel", "", "CRAN"], ["Noyel", "M\u00e9lanie", ""]]}, {"id": "1804.01712", "submitter": "Aditya Grover", "authors": "Aditya Grover, Ramki Gummadi, Miguel Lazaro-Gredilla, Dale Schuurmans,\n  Stefano Ermon", "title": "Variational Rejection Sampling", "comments": "AISTATS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning latent variable models with stochastic variational inference is\nchallenging when the approximate posterior is far from the true posterior, due\nto high variance in the gradient estimates. We propose a novel rejection\nsampling step that discards samples from the variational posterior which are\nassigned low likelihoods by the model. Our approach provides an arbitrarily\naccurate approximation of the true posterior at the expense of extra\ncomputation. Using a new gradient estimator for the resulting unnormalized\nproposal distribution, we achieve average improvements of 3.71 nats and 0.21\nnats over state-of-the-art single-sample and multi-sample alternatives\nrespectively for estimating marginal log-likelihoods using sigmoid belief\nnetworks on the MNIST dataset.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 07:53:41 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Grover", "Aditya", ""], ["Gummadi", "Ramki", ""], ["Lazaro-Gredilla", "Miguel", ""], ["Schuurmans", "Dale", ""], ["Ermon", "Stefano", ""]]}, {"id": "1804.01756", "submitter": "Yan Wu", "authors": "Yan Wu, Greg Wayne, Alex Graves, Timothy Lillicrap", "title": "The Kanerva Machine: A Generative Distributed Memory", "comments": "Published as a conference paper at ICLR 2018 (corrected typos in\n  revision)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end trained memory system that quickly adapts to new\ndata and generates samples like them. Inspired by Kanerva's sparse distributed\nmemory, it has a robust distributed reading and writing mechanism. The memory\nis analytically tractable, which enables optimal on-line compression via a\nBayesian update-rule. We formulate it as a hierarchical conditional generative\nmodel, where memory provides a rich data-dependent prior distribution.\nConsequently, the top-down memory and bottom-up perception are combined to\nproduce the code representing an observation. Empirically, we demonstrate that\nthe adaptive memory significantly improves generative models trained on both\nthe Omniglot and CIFAR datasets. Compared with the Differentiable Neural\nComputer (DNC) and its variants, our memory model has greater capacity and is\nsignificantly easier to train.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 10:07:05 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 12:23:40 GMT"}, {"version": "v3", "created": "Mon, 18 Jun 2018 09:52:40 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Wu", "Yan", ""], ["Wayne", "Greg", ""], ["Graves", "Alex", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1804.01825", "submitter": "Alexei Botchkarev", "authors": "Alexei Botchkarev", "title": "Evaluating Hospital Case Cost Prediction Models Using Azure Machine\n  Learning Studio", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.EC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ability for accurate hospital case cost modelling and prediction is critical\nfor efficient health care financial management and budgetary planning. A\nvariety of regression machine learning algorithms are known to be effective for\nhealth care cost predictions. The purpose of this experiment was to build an\nAzure Machine Learning Studio tool for rapid assessment of multiple types of\nregression models. The tool offers environment for comparing 14 types of\nregression models in a unified experiment: linear regression, Bayesian linear\nregression, decision forest regression, boosted decision tree regression,\nneural network regression, Poisson regression, Gaussian processes for\nregression, gradient boosted machine, nonlinear least squares regression,\nprojection pursuit regression, random forest regression, robust regression,\nrobust regression with mm-type estimators, support vector regression. The tool\npresents assessment results arranged by model accuracy in a single table using\nfive performance metrics. Evaluation of regression machine learning models for\nperforming hospital case cost prediction demonstrated advantage of robust\nregression model, boosted decision tree regression and decision forest\nregression. The operational tool has been published to the web and openly\navailable for experiments and extensions.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 02:40:43 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 04:00:10 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Botchkarev", "Alexei", ""]]}, {"id": "1804.01849", "submitter": "Filip Korzeniowski", "authors": "Filip Korzeniowski, David R. W. Sears, Gerhard Widmer", "title": "A Large-Scale Study of Language Models for Chord Prediction", "comments": "Accepted at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct a large-scale study of language models for chord prediction.\nSpecifically, we compare N-gram models to various flavours of recurrent neural\nnetworks on a comprehensive dataset comprising all publicly available datasets\nof annotated chords known to us. This large amount of data allows us to\nsystematically explore hyper-parameter settings for the recurrent neural\nnetworks---a crucial step in achieving good results with this model class. Our\nresults show not only a quantitative difference between the models, but also a\nqualitative one: in contrast to static N-gram models, certain RNN\nconfigurations adapt to the songs at test time. This finding constitutes a\nfurther step towards the development of chord recognition systems that are more\naware of local musical context than what was previously possible.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 13:51:10 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Korzeniowski", "Filip", ""], ["Sears", "David R. W.", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1804.01852", "submitter": "Michael Blot", "authors": "Michael Blot, David Picard, Matthieu Cord", "title": "GoSGD: Distributed Optimization for Deep Learning with Gossip Exchange", "comments": "Correction to do, and difficulties to change the document", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the issue of speeding up the training of convolutional neural\nnetworks by studying a distributed method adapted to stochastic gradient\ndescent. Our parallel optimization setup uses several threads, each applying\nindividual gradient descents on a local variable. We propose a new way of\nsharing information between different threads based on gossip algorithms that\nshow good consensus convergence properties. Our method called GoSGD has the\nadvantage to be fully asynchronous and decentralized.\n", "versions": [{"version": "v1", "created": "Wed, 4 Apr 2018 12:13:41 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 08:49:48 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Blot", "Michael", ""], ["Picard", "David", ""], ["Cord", "Matthieu", ""]]}, {"id": "1804.01874", "submitter": "Thanh Thi Nguyen", "authors": "Ngoc Duy Nguyen, Saeid Nahavandi, Thanh Nguyen", "title": "A Human Mixed Strategy Approach to Deep Reinforcement Learning", "comments": null, "journal-ref": "2018 IEEE International Conference on Systems, Man, and\n  Cybernetics (SMC)", "doi": "10.1109/SMC.2018.00682", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2015, Google's DeepMind announced an advancement in creating an autonomous\nagent based on deep reinforcement learning (DRL) that could beat a professional\nplayer in a series of 49 Atari games. However, the current manifestation of DRL\nis still immature, and has significant drawbacks. One of DRL's imperfections is\nits lack of \"exploration\" during the training process, especially when working\nwith high-dimensional problems. In this paper, we propose a mixed strategy\napproach that mimics behaviors of human when interacting with environment, and\ncreate a \"thinking\" agent that allows for more efficient exploration in the DRL\ntraining process. The simulation results based on the Breakout game show that\nour scheme achieves a higher probability of obtaining a maximum score than does\nthe baseline DRL algorithm, i.e., the asynchronous advantage actor-critic\nmethod. The proposed scheme therefore can be applied effectively to solving a\ncomplicated task in a real-world application.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 14:24:42 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Nguyen", "Ngoc Duy", ""], ["Nahavandi", "Saeid", ""], ["Nguyen", "Thanh", ""]]}, {"id": "1804.01882", "submitter": "Octavian-Eugen Ganea", "authors": "Octavian-Eugen Ganea, Gary B\\'ecigneul and Thomas Hofmann", "title": "Hyperbolic Entailment Cones for Learning Hierarchical Embeddings", "comments": "International Conference on Machine Learning (ICML) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning graph representations via low-dimensional embeddings that preserve\nrelevant network properties is an important class of problems in machine\nlearning. We here present a novel method to embed directed acyclic graphs.\nFollowing prior work, we first advocate for using hyperbolic spaces which\nprovably model tree-like structures better than Euclidean geometry. Second, we\nview hierarchical relations as partial orders defined using a family of nested\ngeodesically convex cones. We prove that these entailment cones admit an\noptimal shape with a closed form expression both in the Euclidean and\nhyperbolic spaces, and they canonically define the embedding learning process.\nExperiments show significant improvements of our method over strong recent\nbaselines both in terms of representational capacity and generalization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 19:25:10 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 16:51:12 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 22:57:37 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Ganea", "Octavian-Eugen", ""], ["B\u00e9cigneul", "Gary", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1804.01900", "submitter": "Davood Zabihzadeh", "authors": "Baida Hamdan, Davood Zabihzadeh, Monsefi Reza", "title": "Large Scale Local Online Similarity/Distance Learning Framework based on\n  Passive/Aggressive", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity/Distance measures play a key role in many machine learning,\npattern recognition, and data mining algorithms, which leads to the emergence\nof metric learning field. Many metric learning algorithms learn a global\ndistance function from data that satisfy the constraints of the problem.\nHowever, in many real-world datasets that the discrimination power of features\nvaries in the different regions of input space, a global metric is often unable\nto capture the complexity of the task. To address this challenge, local metric\nlearning methods are proposed that learn multiple metrics across the different\nregions of input space. Some advantages of these methods are high flexibility\nand the ability to learn a nonlinear mapping but typically achieves at the\nexpense of higher time requirement and overfitting problem. To overcome these\nchallenges, this research presents an online multiple metric learning\nframework. Each metric in the proposed framework is composed of a global and a\nlocal component learned simultaneously. Adding a global component to a local\nmetric efficiently reduce the problem of overfitting. The proposed framework is\nalso scalable with both sample size and the dimension of input data. To the\nbest of our knowledge, this is the first local online similarity/distance\nlearning framework based on PA (Passive/Aggressive). In addition, for\nscalability with the dimension of input data, DRP (Dual Random Projection) is\nextended for local online learning in the present work. It enables our methods\nto be run efficiently on high-dimensional datasets, while maintains their\npredictive performance. The proposed framework provides a straightforward local\nextension to any global online similarity/distance learning algorithm based on\nPA.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 15:11:11 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Hamdan", "Baida", ""], ["Zabihzadeh", "Davood", ""], ["Reza", "Monsefi", ""]]}, {"id": "1804.01926", "submitter": "Manon Kok", "authors": "Manon Kok and Arno Solin", "title": "Scalable Magnetic Field SLAM in 3D Using Gaussian Process Maps", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for scalable and fully 3D magnetic field simultaneous\nlocalisation and mapping (SLAM) using local anomalies in the magnetic field as\na source of position information. These anomalies are due to the presence of\nferromagnetic material in the structure of buildings and in objects such as\nfurniture. We represent the magnetic field map using a Gaussian process model\nand take well-known physical properties of the magnetic field into account. We\nbuild local maps using three-dimensional hexagonal block tiling. To make our\napproach computationally tractable we use reduced-rank Gaussian process\nregression in combination with a Rao-Blackwellised particle filter. We show\nthat it is possible to obtain accurate position and orientation estimates using\nmeasurements from a smartphone, and that our approach provides a scalable\nmagnetic field SLAM algorithm in terms of both computational complexity and map\nstorage.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 16:02:38 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2018 12:19:08 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Kok", "Manon", ""], ["Solin", "Arno", ""]]}, {"id": "1804.01947", "submitter": "Soheil Kolouri", "authors": "Soheil Kolouri, Phillip E. Pope, Charles E. Martin, Gustavo K. Rohde", "title": "Sliced-Wasserstein Autoencoder: An Embarrassingly Simple Generative\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study generative modeling via autoencoders while using the\nelegant geometric properties of the optimal transport (OT) problem and the\nWasserstein distances. We introduce Sliced-Wasserstein Autoencoders (SWAE),\nwhich are generative models that enable one to shape the distribution of the\nlatent space into any samplable probability distribution without the need for\ntraining an adversarial network or defining a closed-form for the distribution.\nIn short, we regularize the autoencoder loss with the sliced-Wasserstein\ndistance between the distribution of the encoded training samples and a\npredefined samplable distribution. We show that the proposed formulation has an\nefficient numerical solution that provides similar capabilities to Wasserstein\nAutoencoders (WAE) and Variational Autoencoders (VAE), while benefiting from an\nembarrassingly simple implementation.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 16:45:06 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 21:51:24 GMT"}, {"version": "v3", "created": "Wed, 27 Jun 2018 00:05:29 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Kolouri", "Soheil", ""], ["Pope", "Phillip E.", ""], ["Martin", "Charles E.", ""], ["Rohde", "Gustavo K.", ""]]}, {"id": "1804.01955", "submitter": "Przemyslaw Biecek", "authors": "Mateusz Staniak and Przemyslaw Biecek", "title": "Explanations of model predictions with live and breakDown packages", "comments": null, "journal-ref": "The R Journal (2018), 10 (2) p. 395-409", "doi": "10.32614/RJ-2018-072", "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex models are commonly used in predictive modeling. In this paper we\npresent R packages that can be used to explain predictions from complex black\nbox models and attribute parts of these predictions to input features. We\nintroduce two new approaches and corresponding packages for such attribution,\nnamely live and breakDown. We also compare their results with existing\nimplementations of state of the art solutions, namely lime that implements\nLocally Interpretable Model-agnostic Explanations and ShapleyR that implements\nShapley values.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 17:05:15 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 19:49:35 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Staniak", "Mateusz", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "1804.01963", "submitter": "Emmanuel Dufourq Mr", "authors": "Emmanuel Dufourq, Bruce A. Bassett", "title": "Automated Classification of Text Sentiment", "comments": "In \"2017 Annual Conference of the South African Institute of Computer\n  Scientists and Information\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ability to identify sentiment in text, referred to as sentiment analysis,\nis one which is natural to adult humans. This task is, however, not one which a\ncomputer can perform by default. Identifying sentiments in an automated,\nalgorithmic manner will be a useful capability for business and research in\ntheir search to understand what consumers think about their products or\nservices and to understand human sociology. Here we propose two new Genetic\nAlgorithms (GAs) for the task of automated text sentiment analysis. The GAs\nlearn whether words occurring in a text corpus are either sentiment or\namplifier words, and their corresponding magnitude. Sentiment words, such as\n'horrible', add linearly to the final sentiment. Amplifier words in contrast,\nwhich are typically adjectives/adverbs like 'very', multiply the sentiment of\nthe following word. This increases, decreases or negates the sentiment of the\nfollowing word. The sentiment of the full text is then the sum of these terms.\nThis approach grows both a sentiment and amplifier dictionary which can be\nreused for other purposes and fed into other machine learning algorithms. We\nreport the results of multiple experiments conducted on large Amazon data sets.\nThe results reveal that our proposed approach was able to outperform several\npublic and/or commercial sentiment analysis algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 17:21:48 GMT"}], "update_date": "2018-04-06", "authors_parsed": [["Dufourq", "Emmanuel", ""], ["Bassett", "Bruce A.", ""]]}, {"id": "1804.02047", "submitter": "Yu Cheng", "authors": "Xi Ouyang, Yu Cheng, Yifan Jiang, Chun-Liang Li, Pan Zhou", "title": "Pedestrian-Synthesis-GAN: Generating Pedestrian Data in Real Scene and\n  Beyond", "comments": "v2.0,adding supplementary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art pedestrian detection models have achieved great success in\nmany benchmarks. However, these models require lots of annotation information\nand the labeling process usually takes much time and efforts. In this paper, we\npropose a method to generate labeled pedestrian data and adapt them to support\nthe training of pedestrian detectors. The proposed framework is built on the\nGenerative Adversarial Network (GAN) with multiple discriminators, trying to\nsynthesize realistic pedestrians and learn the background context\nsimultaneously. To handle the pedestrians of different sizes, we adopt the\nSpatial Pyramid Pooling (SPP) layer in the discriminator. We conduct\nexperiments on two benchmarks. The results show that our framework can smoothly\nsynthesize pedestrians on background images of variations and different levels\nof details. To quantitatively evaluate our approach, we add the generated\nsamples into training data of the baseline pedestrian detectors and show the\nsynthetic images are able to improve the detectors' performance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 20:22:01 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 07:19:28 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Ouyang", "Xi", ""], ["Cheng", "Yu", ""], ["Jiang", "Yifan", ""], ["Li", "Chun-Liang", ""], ["Zhou", "Pan", ""]]}, {"id": "1804.02081", "submitter": "Dimitrios Berberidis", "authors": "Dimitris Berberidis, Athanasios N. Nikolakopoulos, Georgios B.\n  Giannakis", "title": "Adaptive Diffusions for Scalable Learning over Graphs", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2889984", "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion-based classifiers such as those relying on the Personalized\nPageRank and the Heat kernel, enjoy remarkable classification accuracy at\nmodest computational requirements. Their performance however is affected by the\nextent to which the chosen diffusion captures a typically unknown label\npropagation mechanism, that can be specific to the underlying graph, and\npotentially different for each class. The present work introduces a\ndisciplined, data-efficient approach to learning class-specific diffusion\nfunctions adapted to the underlying network topology. The novel learning\napproach leverages the notion of \"landing probabilities\" of class-specific\nrandom walks, which can be computed efficiently, thereby ensuring scalability\nto large graphs. This is supported by rigorous analysis of the properties of\nthe model as well as the proposed algorithms. Furthermore, a robust version of\nthe classifier facilitates learning even in noisy environments.\n  Classification tests on real networks demonstrate that adapting the diffusion\nfunction to the given graph and observed labels, significantly improves the\nperformance over fixed diffusions; reaching -- and many times surpassing -- the\nclassification accuracy of computationally heavier state-of-the-art competing\nmethods, that rely on node embeddings and deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 23:41:11 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 04:25:45 GMT"}, {"version": "v3", "created": "Wed, 9 Jan 2019 00:32:13 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Berberidis", "Dimitris", ""], ["Nikolakopoulos", "Athanasios N.", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1804.02086", "submitter": "Babak Esmaeili", "authors": "Babak Esmaeili, Hao Wu, Sarthak Jain, Alican Bozkurt, N. Siddharth,\n  Brooks Paige, Dana H. Brooks, Jennifer Dy, Jan-Willem van de Meent", "title": "Structured Disentangled Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep latent-variable models learn representations of high-dimensional data in\nan unsupervised manner. A number of recent efforts have focused on learning\nrepresentations that disentangle statistically independent axes of variation by\nintroducing modifications to the standard objective function. These approaches\ngenerally assume a simple diagonal Gaussian prior and as a result are not able\nto reliably disentangle discrete factors of variation. We propose a two-level\nhierarchical objective to control relative degree of statistical independence\nbetween blocks of variables and individual variables within blocks. We derive\nthis objective as a generalization of the evidence lower bound, which allows us\nto explicitly represent the trade-offs between mutual information between data\nand representation, KL divergence between representation and prior, and\ncoverage of the support of the empirical data distribution. Experiments on a\nvariety of datasets demonstrate that our objective can not only disentangle\ndiscrete variables, but that doing so also improves disentanglement of other\nvariables and, importantly, generalization even to unseen combinations of\nfactors.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 00:11:26 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 16:44:43 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 16:12:11 GMT"}, {"version": "v4", "created": "Wed, 12 Dec 2018 16:31:31 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Esmaeili", "Babak", ""], ["Wu", "Hao", ""], ["Jain", "Sarthak", ""], ["Bozkurt", "Alican", ""], ["Siddharth", "N.", ""], ["Paige", "Brooks", ""], ["Brooks", "Dana H.", ""], ["Dy", "Jennifer", ""], ["van de Meent", "Jan-Willem", ""]]}, {"id": "1804.02097", "submitter": "Luwan Zhang", "authors": "Luwan Zhang, Katherine Liao, Issac Kohane, Tianxi Cai", "title": "Multi-view Banded Spectral Clustering with Application to ICD9\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent development in methodology, community detection remains a\nchallenging problem. Existing literature largely focuses on the standard\nsetting where a network is learned using an observed adjacency matrix from a\nsingle data source. Constructing a shared network from multiple data sources is\nmore challenging due to the heterogeneity across populations. Additionally, no\nexisting method leverages the prior distance knowledge available in many\ndomains to help the discovery of the network structure. To bridge this gap, in\nthis paper we propose a novel spectral clustering method that optimally\ncombines multiple data sources while leveraging the prior distance knowledge.\nThe proposed method combines a banding step guided by the distance knowledge\nwith a subsequent weighting step to maximize consensus across multiple sources.\nIts statistical performance is thoroughly studied under a multi-view stochastic\nblock model. We also provide a simple yet optimal rule of choosing weights in\npractice. The efficacy and robustness of the method is fully demonstrated\nthrough extensive simulations. Finally, we apply the method to cluster the\nInternational classification of diseases, ninth revision (ICD9), codes and\nyield a very insightful clustering structure by integrating information from a\nlarge claim database and two healthcare systems.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 01:02:25 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 15:03:05 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Zhang", "Luwan", ""], ["Liao", "Katherine", ""], ["Kohane", "Issac", ""], ["Cai", "Tianxi", ""]]}, {"id": "1804.02101", "submitter": "Swapnil Mishra", "authors": "Swapnil Mishra, Marian-Andrei Rizoiu and Lexing Xie", "title": "Modeling Popularity in Asynchronous Social Media Streams with Recurrent\n  Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and predicting the popularity of online items is an important\nopen problem in social media analysis. Considerable progress has been made\nrecently in data-driven predictions, and in linking popularity to external\npromotions. However, the existing methods typically focus on a single source of\nexternal influence, whereas for many types of online content such as YouTube\nvideos or news articles, attention is driven by multiple heterogeneous sources\nsimultaneously - e.g. microblogs or traditional media coverage. Here, we\npropose RNN-MAS, a recurrent neural network for modeling asynchronous streams.\nIt is a sequence generator that connects multiple streams of different\ngranularity via joint inference. We show RNN-MAS not only to outperform the\ncurrent state-of-the-art Youtube popularity prediction system by 17%, but also\nto capture complex dynamics, such as seasonal trends of unseen influence. We\ndefine two new metrics: promotion score quantifies the gain in popularity from\none unit of promotion for a Youtube video; the loudness level captures the\neffects of a particular user tweeting about the video. We use the loudness\nlevel to compare the effects of a video being promoted by a single\nhighly-followed user (in the top 1% most followed users) against being promoted\nby a group of mid-followed users. We find that results depend on the type of\ncontent being promoted: superusers are more successful in promoting Howto and\nGaming videos, whereas the cohort of regular users are more influential for\nActivism videos. This work provides more accurate and explainable popularity\npredictions, as well as computational tools for content producers and marketers\nto allocate resources for promotion campaigns.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 01:12:28 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2018 21:41:16 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Mishra", "Swapnil", ""], ["Rizoiu", "Marian-Andrei", ""], ["Xie", "Lexing", ""]]}, {"id": "1804.02181", "submitter": "Hirokazu Kameoka", "authors": "Keisuke Oyamada, Hirokazu Kameoka, Takuhiro Kaneko, Kou Tanaka,\n  Nobukatsu Hojo, Hiroyasu Ando", "title": "Generative adversarial network-based approach to signal reconstruction\n  from magnitude spectrograms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of reconstructing a time-domain signal\n(or a phase spectrogram) solely from a magnitude spectrogram. Since magnitude\nspectrograms do not contain phase information, we must restore or infer phase\ninformation to reconstruct a time-domain signal. One widely used approach for\ndealing with the signal reconstruction problem was proposed by Griffin and Lim.\nThis method usually requires many iterations for the signal reconstruction\nprocess and depending on the inputs, it does not always produce high-quality\naudio signals. To overcome these shortcomings, we apply a learning-based\napproach to the signal reconstruction problem by modeling the signal\nreconstruction process using a deep neural network and training it using the\nidea of a generative adversarial network. Experimental evaluations revealed\nthat our method was able to reconstruct signals faster with higher quality than\nthe Griffin-Lim method.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 09:42:59 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Oyamada", "Keisuke", ""], ["Kameoka", "Hirokazu", ""], ["Kaneko", "Takuhiro", ""], ["Tanaka", "Kou", ""], ["Hojo", "Nobukatsu", ""], ["Ando", "Hiroyasu", ""]]}, {"id": "1804.02199", "submitter": "Luis Herranz", "authors": "Yaxing Wang, Joost van de Weijer, Luis Herranz", "title": "Mix and match networks: encoder-decoder alignment for zero-pair image\n  translation", "comments": "Accepted CVPR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of image translation between domains or modalities for\nwhich no direct paired data is available (i.e. zero-pair translation). We\npropose mix and match networks, based on multiple encoders and decoders aligned\nin such a way that other encoder-decoder pairs can be composed at test time to\nperform unseen image translation tasks between domains or modalities for which\nexplicit paired samples were not seen during training. We study the impact of\nautoencoders, side information and losses in improving the alignment and\ntransferability of trained pairwise translation models to unseen translations.\nWe show our approach is scalable and can perform colorization and style\ntransfer between unseen combinations of domains. We evaluate our system in a\nchallenging cross-modal setting where semantic segmentation is estimated from\ndepth images, without explicit access to any depth-semantic segmentation\ntraining pairs. Our model outperforms baselines based on pix2pix and CycleGAN\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 10:53:07 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Wang", "Yaxing", ""], ["van de Weijer", "Joost", ""], ["Herranz", "Luis", ""]]}, {"id": "1804.02204", "submitter": "Mustafa Haider", "authors": "Adnan Haider and Philip C. Woodland", "title": "Sequence Training of DNN Acoustic Models With Natural Gradient", "comments": "In Proceedings of IEEE ASRU 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network (DNN) acoustic models often use discriminative sequence\ntraining that optimises an objective function that better approximates the word\nerror rate (WER) than frame-based training. Sequence training is normally\nimplemented using Stochastic Gradient Descent (SGD) or Hessian Free (HF)\ntraining. This paper proposes an alternative batch style optimisation framework\nthat employs a Natural Gradient (NG) approach to traverse through the parameter\nspace. By correcting the gradient according to the local curvature of the\nKL-divergence, the NG optimisation process converges more quickly than HF.\nFurthermore, the proposed NG approach can be applied to any sequence\ndiscriminative training criterion. The efficacy of the NG method is shown using\nexperiments on a Multi-Genre Broadcast (MGB) transcription task that\ndemonstrates both the computational efficiency and the accuracy of the\nresulting DNN models.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 11:05:53 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Haider", "Adnan", ""], ["Woodland", "Philip C.", ""]]}, {"id": "1804.02246", "submitter": "Yifan Zhang", "authors": "Peilin Zhao, Yifan Zhang, Min Wu, Steven C. H. Hoi, Mingkui Tan, and\n  Junzhou Huang", "title": "Adaptive Cost-sensitive Online Classification", "comments": null, "journal-ref": "IEEE Transactions on Knowledge and Data Engineering, 2019", "doi": "10.1109/TKDE.2018.2826011", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cost-Sensitive Online Classification has drawn extensive attention in recent\nyears, where the main approach is to directly online optimize two well-known\ncost-sensitive metrics: (i) weighted sum of sensitivity and specificity; (ii)\nweighted misclassification cost. However, previous existing methods only\nconsidered first-order information of data stream. It is insufficient in\npractice, since many recent studies have proved that incorporating second-order\ninformation enhances the prediction performance of classification models. Thus,\nwe propose a family of cost-sensitive online classification algorithms with\nadaptive regularization in this paper. We theoretically analyze the proposed\nalgorithms and empirically validate their effectiveness and properties in\nextensive experiments. Then, for better trade off between the performance and\nefficiency, we further introduce the sketching technique into our algorithms,\nwhich significantly accelerates the computational speed with quite slight\nperformance loss. Finally, we apply our algorithms to tackle several online\nanomaly detection tasks from real world. Promising results prove that the\nproposed algorithms are effective and efficient in solving cost-sensitive\nonline classification problems in various real-world domains.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 13:09:55 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Zhao", "Peilin", ""], ["Zhang", "Yifan", ""], ["Wu", "Min", ""], ["Hoi", "Steven C. H.", ""], ["Tan", "Mingkui", ""], ["Huang", "Junzhou", ""]]}, {"id": "1804.02253", "submitter": "Konstantin Eckle", "authors": "Konstantin Eckle, Johannes Schmidt-Hieber", "title": "A comparison of deep networks with ReLU activation function and linear\n  spline-type methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) generate much richer function spaces than shallow\nnetworks. Since the function spaces induced by shallow networks have several\napproximation theoretic drawbacks, this explains, however, not necessarily the\nsuccess of deep networks. In this article we take another route by comparing\nthe expressive power of DNNs with ReLU activation function to piecewise linear\nspline methods. We show that MARS (multivariate adaptive regression splines) is\nimproper learnable by DNNs in the sense that for any given function that can be\nexpressed as a function in MARS with $M$ parameters there exists a multilayer\nneural network with $O(M \\log (M/\\varepsilon))$ parameters that approximates\nthis function up to sup-norm error $\\varepsilon.$ We show a similar result for\nexpansions with respect to the Faber-Schauder system. Based on this, we derive\nrisk comparison inequalities that bound the statistical risk of fitting a\nneural network by the statistical risk of spline-based methods. This shows that\ndeep networks perform better or only slightly worse than the considered spline\nmethods. We provide a constructive proof for the function approximations.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 13:28:15 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 09:11:59 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Eckle", "Konstantin", ""], ["Schmidt-Hieber", "Johannes", ""]]}, {"id": "1804.02261", "submitter": "Jose Perea", "authors": "Firas A. Khasawneh, Elizabeth Munch, Jose A. Perea", "title": "Chatter Classification in Turning Using Machine Learning and Topological\n  Data Analysis", "comments": null, "journal-ref": null, "doi": "10.1016/j.ifacol.2018.07.222", "report-no": null, "categories": "stat.ML cs.CG cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chatter identification and detection in machining processes has been an\nactive area of research in the past two decades. Part of the challenge in\nstudying chatter is that machining equations that describe its occurrence are\noften nonlinear delay differential equations. The majority of the available\ntools for chatter identification rely on defining a metric that captures the\ncharacteristics of chatter, and a threshold that signals its occurrence. The\ndifficulty in choosing these parameters can be somewhat alleviated by utilizing\nmachine learning techniques. However, even with a successful classification\nalgorithm, the transferability of typical machine learning methods from one\ndata set to another remains very limited. In this paper we combine supervised\nmachine learning with Topological Data Analysis (TDA) to obtain a descriptor of\nthe process which can detect chatter. The features we use are derived from the\npersistence diagram of an attractor reconstructed from the time series via\nTakens embedding. We test the approach using deterministic and stochastic\nturning models, where the stochasticity is introduced via the cutting\ncoefficient term. Our results show a 97% successful classification rate on the\ndeterministic model labeled by the stability diagram obtained using the\nspectral element method. The features gleaned from the deterministic model are\nthen utilized for characterization of chatter in a stochastic turning model\nwhere there are very limited analysis methods.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 18:13:07 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Khasawneh", "Firas A.", ""], ["Munch", "Elizabeth", ""], ["Perea", "Jose A.", ""]]}, {"id": "1804.02276", "submitter": "Fay\\c{c}al Ait Aoudia", "authors": "Fay\\c{c}al Ait Aoudia and Jakob Hoydis", "title": "End-to-End Learning of Communications Systems Without a Channel Model", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea of end-to-end learning of communications systems through neural\nnetwork -based autoencoders has the shortcoming that it requires a\ndifferentiable channel model. We present in this paper a novel learning\nalgorithm which alleviates this problem. The algorithm iterates between\nsupervised training of the receiver and reinforcement learning -based training\nof the transmitter. We demonstrate that this approach works as well as fully\nsupervised methods on additive white Gaussian noise (AWGN) and Rayleigh\nblock-fading (RBF) channels. Surprisingly, while our method converges slower on\nAWGN channels than supervised training, it converges faster on RBF channels.\nOur results are a first step towards learning of communications systems over\nany type of channel without prior assumptions.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 14:01:00 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 16:38:32 GMT"}, {"version": "v3", "created": "Wed, 5 Dec 2018 12:24:21 GMT"}], "update_date": "2018-12-06", "authors_parsed": [["Aoudia", "Fay\u00e7al Ait", ""], ["Hoydis", "Jakob", ""]]}, {"id": "1804.02370", "submitter": "Shuai Zheng", "authors": "Shuai Zheng, Chris Ding", "title": "Minimal Support Vector Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support Vector Machine (SVM) is an efficient classification approach, which\nfinds a hyperplane to separate data from different classes. This hyperplane is\ndetermined by support vectors. In existing SVM formulations, the objective\nfunction uses L2 norm or L1 norm on slack variables. The number of support\nvectors is a measure of generalization errors. In this work, we propose a\nMinimal SVM, which uses L0.5 norm on slack variables. The result model further\nreduces the number of support vectors and increases the classification\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 17:44:01 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Zheng", "Shuai", ""], ["Ding", "Chris", ""]]}, {"id": "1804.02386", "submitter": "Sina Dabiri", "authors": "Sina Dabiri, Kevin Heaslip", "title": "Inferring transportation modes from GPS trajectories using a\n  convolutional neural network", "comments": "12 pages, 3 figures, 7 tables, Transportation Research Part C:\n  Emerging Technologies", "journal-ref": "Transportation Research Part C: Emerging Technologies 86 (2018):\n  360-371", "doi": "10.1016/j.trc.2017.11.021", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Identifying the distribution of users' transportation modes is an essential\npart of travel demand analysis and transportation planning. With the advent of\nubiquitous GPS-enabled devices (e.g., a smartphone), a cost-effective approach\nfor inferring commuters' mobility mode(s) is to leverage their GPS\ntrajectories. A majority of studies have proposed mode inference models based\non hand-crafted features and traditional machine learning algorithms. However,\nmanual features engender some major drawbacks including vulnerability to\ntraffic and environmental conditions as well as possessing human's bias in\ncreating efficient features. One way to overcome these issues is by utilizing\nConvolutional Neural Network (CNN) schemes that are capable of automatically\ndriving high-level features from the raw input. Accordingly, in this paper, we\ntake advantage of CNN architectures so as to predict travel modes based on only\nraw GPS trajectories, where the modes are labeled as walk, bike, bus, driving,\nand train. Our key contribution is designing the layout of the CNN's input\nlayer in such a way that not only is adaptable with the CNN schemes but\nrepresents fundamental motion characteristics of a moving object including\nspeed, acceleration, jerk, and bearing rate. Furthermore, we ameliorate the\nquality of GPS logs through several data preprocessing steps. Using the clean\ninput layer, a variety of CNN configurations are evaluated to achieve the best\nCNN architecture. The highest accuracy of 84.8% has been achieved through the\nensemble of the best CNN configuration. In this research, we contrast our\nmethodology with traditional machine learning algorithms as well as the seminal\nand most related studies to demonstrate the superiority of our framework.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 18:26:12 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Dabiri", "Sina", ""], ["Heaslip", "Kevin", ""]]}, {"id": "1804.02395", "submitter": "Krzysztof Choromanski", "authors": "Krzysztof Choromanski, Mark Rowland, Vikas Sindhwani, Richard E.\n  Turner, Adrian Weller", "title": "Structured Evolution with Compact Architectures for Scalable Policy\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method of blackbox optimization via gradient approximation\nwith the use of structured random orthogonal matrices, providing more accurate\nestimators than baselines and with provable theoretical guarantees. We show\nthat this algorithm can be successfully applied to learn better quality compact\npolicies than those using standard gradient estimation techniques. The compact\npolicies we learn have several advantages over unstructured ones, including\nfaster training algorithms and faster inference. These benefits are important\nwhen the policy is deployed on real hardware with limited resources. Further,\ncompact policies provide more scalable architectures for derivative-free\noptimization (DFO) in high-dimensional spaces. We show that most robotics tasks\nfrom the OpenAI Gym can be solved using neural networks with less than 300\nparameters, with almost linear time complexity of the inference phase, with up\nto 13x fewer parameters relative to the Evolution Strategies (ES) algorithm\nintroduced by Salimans et al. (2017). We do not need heuristics such as fitness\nshaping to learn good quality policies, resulting in a simple and theoretically\nmotivated training mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 15:25:14 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 14:52:29 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Choromanski", "Krzysztof", ""], ["Rowland", "Mark", ""], ["Sindhwani", "Vikas", ""], ["Turner", "Richard E.", ""], ["Weller", "Adrian", ""]]}, {"id": "1804.02411", "submitter": "Dhagash Mehta", "authors": "Dhagash Mehta, Xiaojun Zhao, Edgar A. Bernal, David J. Wales", "title": "The Loss Surface of XOR Artificial Neural Networks", "comments": "19 pages, 6 figures. Submitted to journal in Oct, 2017", "journal-ref": "Phys. Rev. E 97, 052307 (2018)", "doi": "10.1103/PhysRevE.97.052307", "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training an artificial neural network involves an optimization process over\nthe landscape defined by the cost (loss) as a function of the network\nparameters. We explore these landscapes using optimisation tools developed for\npotential energy landscapes in molecular science. The number of local minima\nand transition states (saddle points of index one), as well as the ratio of\ntransition states to minima, grow rapidly with the number of nodes in the\nnetwork. There is also a strong dependence on the regularisation parameter,\nwith the landscape becoming more convex (fewer minima) as the regularisation\nterm increases. We demonstrate that in our formulation, stationary points for\nnetworks with $N_h$ hidden nodes, including the minimal network required to fit\nthe XOR data, are also stationary points for networks with $N_{h} +1$ hidden\nnodes when all the weights involving the additional nodes are zero. Hence,\nsmaller networks optimized to train the XOR data are embedded in the landscapes\nof larger networks. Our results clarify certain aspects of the classification\nand sensitivity (to perturbations in the input data) of minima and saddle\npoints for this system, and may provide insight into dropout and network\ncompression.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 18:11:23 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Mehta", "Dhagash", ""], ["Zhao", "Xiaojun", ""], ["Bernal", "Edgar A.", ""], ["Wales", "David J.", ""]]}, {"id": "1804.02464", "submitter": "Thomas Miconi", "authors": "Thomas Miconi, Jeff Clune, Kenneth O. Stanley", "title": "Differentiable plasticity: training plastic neural networks with\n  backpropagation", "comments": "Presented at ICML 2018", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning (ICML2018), Stockholm, Sweden, PMLR 80, 2018", "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we build agents that keep learning from experience, quickly and\nefficiently, after their initial training? Here we take inspiration from the\nmain mechanism of learning in biological brains: synaptic plasticity, carefully\ntuned by evolution to produce efficient lifelong learning. We show that\nplasticity, just like connection weights, can be optimized by gradient descent\nin large (millions of parameters) recurrent networks with Hebbian plastic\nconnections. First, recurrent plastic networks with more than two million\nparameters can be trained to memorize and reconstruct sets of novel,\nhigh-dimensional 1000+ pixels natural images not seen during training.\nCrucially, traditional non-plastic recurrent networks fail to solve this task.\nFurthermore, trained plastic networks can also solve generic meta-learning\ntasks such as the Omniglot task, with competitive results and little parameter\noverhead. Finally, in reinforcement learning settings, plastic networks\noutperform a non-plastic equivalent in a maze exploration task. We conclude\nthat differentiable plasticity may provide a powerful novel approach to the\nlearning-to-learn problem.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 21:43:13 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 00:50:53 GMT"}, {"version": "v3", "created": "Tue, 31 Jul 2018 16:55:11 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Miconi", "Thomas", ""], ["Clune", "Jeff", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "1804.02476", "submitter": "Alex Graves", "authors": "Alex Graves, Jacob Menick, Aaron van den Oord", "title": "Associative Compression Networks for Representation Learning", "comments": "Revised to clarify difference between ACN and IID loss", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Associative Compression Networks (ACNs), a new\nframework for variational autoencoding with neural networks. The system differs\nfrom existing variational autoencoders (VAEs) in that the prior distribution\nused to model each code is conditioned on a similar code from the dataset. In\ncompression terms this equates to sequentially transmitting the dataset using\nan ordering determined by proximity in latent space. Since the prior need only\naccount for local, rather than global variations in the latent space, the\ncoding cost is greatly reduced, leading to rich, informative codes. Crucially,\nthe codes remain informative when powerful, autoregressive decoders are used,\nwhich we argue is fundamentally difficult with normal VAEs. Experimental\nresults on MNIST, CIFAR-10, ImageNet and CelebA show that ACNs discover\nhigh-level latent features such as object class, writing style, pose and facial\nexpression, which can be used to cluster and classify the data, as well as to\ngenerate diverse and convincing samples. We conclude that ACNs are a promising\nnew direction for representation learning: one that steps away from IID\nmodelling, and towards learning a structured description of the dataset as a\nwhole.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 22:17:04 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 16:20:25 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Graves", "Alex", ""], ["Menick", "Jacob", ""], ["Oord", "Aaron van den", ""]]}, {"id": "1804.02477", "submitter": "Abhinav Verma", "authors": "Abhinav Verma, Vijayaraghavan Murali, Rishabh Singh, Pushmeet Kohli,\n  Swarat Chaudhuri", "title": "Programmatically Interpretable Reinforcement Learning", "comments": "Published at The 35th International Conference on Machine Learning\n  (ICML 2018)", "journal-ref": "PMLR 80:5045-5054", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a reinforcement learning framework, called Programmatically\nInterpretable Reinforcement Learning (PIRL), that is designed to generate\ninterpretable and verifiable agent policies. Unlike the popular Deep\nReinforcement Learning (DRL) paradigm, which represents policies by neural\nnetworks, PIRL represents policies using a high-level, domain-specific\nprogramming language. Such programmatic policies have the benefits of being\nmore easily interpreted than neural networks, and being amenable to\nverification by symbolic methods. We propose a new method, called Neurally\nDirected Program Search (NDPS), for solving the challenging nonsmooth\noptimization problem of finding a programmatic policy with maximal reward. NDPS\nworks by first learning a neural policy network using DRL, and then performing\na local search over programmatic policies that seeks to minimize a distance\nfrom this neural \"oracle\". We evaluate NDPS on the task of learning to drive a\nsimulated car in the TORCS car-racing environment. We demonstrate that NDPS is\nable to discover human-readable policies that pass some significant performance\nbars. We also show that PIRL policies can have smoother trajectories, and can\nbe more easily transferred to environments not encountered during training,\nthan corresponding policies discovered by DRL.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 22:17:18 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 02:27:26 GMT"}, {"version": "v3", "created": "Wed, 10 Apr 2019 09:09:46 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Verma", "Abhinav", ""], ["Murali", "Vijayaraghavan", ""], ["Singh", "Rishabh", ""], ["Kohli", "Pushmeet", ""], ["Chaudhuri", "Swarat", ""]]}, {"id": "1804.02484", "submitter": "Andrea Rocchetto", "authors": "Alessandro Rudi, Leonard Wossnig, Carlo Ciliberto, Andrea Rocchetto,\n  Massimiliano Pontil, Simone Severini", "title": "Approximating Hamiltonian dynamics with the Nystr\\\"om method", "comments": "v2: 22 pages, fixed typos in Eq.27 and 28 + other minor changes to\n  the presentation of the results; v3 final version accepted to Quantum; v4\n  DOIs added in order to comply with Quantum requirements", "journal-ref": "Quantum 4, 234 (2020)", "doi": "10.22331/q-2020-02-20-234", "report-no": null, "categories": "quant-ph cs.DS cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simulating the time-evolution of quantum mechanical systems is BQP-hard and\nexpected to be one of the foremost applications of quantum computers. We\nconsider classical algorithms for the approximation of Hamiltonian dynamics\nusing subsampling methods from randomized numerical linear algebra. We derive a\nsimulation technique whose runtime scales polynomially in the number of qubits\nand the Frobenius norm of the Hamiltonian. As an immediate application, we show\nthat sample based quantum simulation, a type of evolution where the Hamiltonian\nis a density matrix, can be efficiently classically simulated under specific\nstructural conditions. Our main technical contribution is a randomized\nalgorithm for approximating Hermitian matrix exponentials. The proof leverages\na low-rank, symmetric approximation via the Nystr\\\"om method. Our results\nsuggest that under strong sampling assumptions there exist classical\npoly-logarithmic time simulations of quantum computations.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 23:58:30 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 10:32:34 GMT"}, {"version": "v3", "created": "Wed, 5 Feb 2020 16:52:23 GMT"}, {"version": "v4", "created": "Mon, 17 Feb 2020 20:30:19 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Rudi", "Alessandro", ""], ["Wossnig", "Leonard", ""], ["Ciliberto", "Carlo", ""], ["Rocchetto", "Andrea", ""], ["Pontil", "Massimiliano", ""], ["Severini", "Simone", ""]]}, {"id": "1804.02485", "submitter": "Alex Lamb", "authors": "Alex Lamb, Jonathan Binas, Anirudh Goyal, Dmitriy Serdyuk, Sandeep\n  Subramanian, Ioannis Mitliagkas, Yoshua Bengio", "title": "Fortified Networks: Improving the Robustness of Deep Networks by\n  Modeling the Manifold of Hidden Representations", "comments": "Under Review ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep networks have achieved impressive results across a variety of important\ntasks. However a known weakness is a failure to perform well when evaluated on\ndata which differ from the training distribution, even if these differences are\nvery small, as is the case with adversarial examples. We propose Fortified\nNetworks, a simple transformation of existing networks, which fortifies the\nhidden layers in a deep network by identifying when the hidden states are off\nof the data manifold, and maps these hidden states back to parts of the data\nmanifold where the network performs well. Our principal contribution is to show\nthat fortifying these hidden states improves the robustness of deep networks\nand our experiments (i) demonstrate improved robustness to standard adversarial\nattacks in both black-box and white-box threat models; (ii) suggest that our\nimprovements are not primarily due to the gradient masking problem and (iii)\nshow the advantage of doing this fortification in the hidden layers instead of\nthe input space.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 00:11:05 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Lamb", "Alex", ""], ["Binas", "Jonathan", ""], ["Goyal", "Anirudh", ""], ["Serdyuk", "Dmitriy", ""], ["Subramanian", "Sandeep", ""], ["Mitliagkas", "Ioannis", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1804.02491", "submitter": "Ozan \\.Irsoy", "authors": "Ozan \\.Irsoy, Ethem Alpayd{\\i}n", "title": "Continuously Constructive Deep Neural Networks", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, deep learning algorithms update the network weights whereas\nthe network architecture is chosen manually, using a process of trial and\nerror. In this work, we propose two novel approaches that automatically update\nthe network structure while also learning its weights. The novelty of our\napproach lies in our parameterization where the depth, or additional\ncomplexity, is encapsulated continuously in the parameter space through control\nparameters that add additional complexity. We propose two methods: In tunnel\nnetworks, this selection is done at the level of a hidden unit, and in budding\nperceptrons, this is done at the level of a network layer; updating this\ncontrol parameter introduces either another hidden unit or another hidden\nlayer. We show the effectiveness of our methods on the synthetic two-spirals\ndata and on two real data sets of MNIST and MIRFLICKR, where we see that our\nproposed methods, with the same set of hyperparameters, can correctly adjust\nthe network complexity to the task complexity.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 02:09:16 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["\u0130rsoy", "Ozan", ""], ["Alpayd\u0131n", "Ethem", ""]]}, {"id": "1804.02527", "submitter": "Shixia Liu", "authors": "Jaegul Choo and Shixia Liu", "title": "Visual Analytics for Explainable Deep Learning", "comments": "IEEE Computer Graphics and Applications, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning has been advancing the state of the art in artificial\nintelligence to a new level, and humans rely on artificial intelligence\ntechniques more than ever. However, even with such unprecedented advancements,\nthe lack of explanation regarding the decisions made by deep learning models\nand absence of control over their internal processes act as major drawbacks in\ncritical decision-making processes, such as precision medicine and law\nenforcement. In response, efforts are being made to make deep learning\ninterpretable and controllable by humans. In this paper, we review visual\nanalytics, information visualization, and machine learning perspectives\nrelevant to this aim, and discuss potential challenges and future research\ndirections.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 07:52:04 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Choo", "Jaegul", ""], ["Liu", "Shixia", ""]]}, {"id": "1804.02528", "submitter": "Iraklis Klampanos", "authors": "Iraklis A. Klampanos, Athanasios Davvetas, Antonis Koukourikos,\n  Vangelis Karkaletsis", "title": "ANNETT-O: An Ontology for Describing Artificial Neural Network\n  Evaluation, Topology and Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models, while effective and versatile, are becoming\nincreasingly complex, often including multiple overlapping networks of\narbitrary depths, multiple objectives and non-intuitive training methodologies.\nThis makes it increasingly difficult for researchers and practitioners to\ndesign, train and understand them. In this paper we present ANNETT-O, a\nmuch-needed, generic and computer-actionable vocabulary for researchers and\npractitioners to describe their deep learning configurations, training\nprocedures and experiments. The proposed ontology focuses on topological,\ntraining and evaluation aspects of complex deep neural configurations, while\nkeeping peripheral entities more succinct. Knowledge bases implementing\nANNETT-O can support a wide variety of queries, providing relevant insights to\nusers. In addition to a detailed description of the ontology, we demonstrate\nits suitability to the task via a number of hypothetical use-cases of\nincreasing complexity.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 07:56:29 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 09:04:59 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Klampanos", "Iraklis A.", ""], ["Davvetas", "Athanasios", ""], ["Koukourikos", "Antonis", ""], ["Karkaletsis", "Vangelis", ""]]}, {"id": "1804.02549", "submitter": "Xin Wang", "authors": "Xin Wang, Jaime Lorenzo-Trueba, Shinji Takaki, Lauri Juvela, Junichi\n  Yamagishi", "title": "A comparison of recent waveform generation and acoustic modeling methods\n  for neural-network-based speech synthesis", "comments": "To appear in ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in speech synthesis suggest that limitations such as the\nlossy nature of the amplitude spectrum with minimum phase approximation and the\nover-smoothing effect in acoustic modeling can be overcome by using advanced\nmachine learning approaches. In this paper, we build a framework in which we\ncan fairly compare new vocoding and acoustic modeling techniques with\nconventional approaches by means of a large scale crowdsourced evaluation.\nResults on acoustic models showed that generative adversarial networks and an\nautoregressive (AR) model performed better than a normal recurrent network and\nthe AR model performed best. Evaluation on vocoders by using the same AR\nacoustic model demonstrated that a Wavenet vocoder outperformed classical\nsource-filter-based vocoders. Particularly, generated speech waveforms from the\ncombination of AR acoustic model and Wavenet vocoder achieved a similar score\nof speech quality to vocoded speech.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 12:16:50 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Wang", "Xin", ""], ["Lorenzo-Trueba", "Jaime", ""], ["Takaki", "Shinji", ""], ["Juvela", "Lauri", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1804.02605", "submitter": "Abhishek Chakrabortty", "authors": "Arun Kumar Kuchibhotla and Abhishek Chakrabortty", "title": "Moving Beyond Sub-Gaussianity in High-Dimensional Statistics:\n  Applications in Covariance Estimation and Linear Regression", "comments": "64 pages; Revised version (discussions added and some results\n  modified in Section 4, minor changes made throughout)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concentration inequalities form an essential toolkit in the study of high\ndimensional (HD) statistical methods. Most of the relevant statistics\nliterature in this regard is based on sub-Gaussian or sub-exponential tail\nassumptions. In this paper, we first bring together various probabilistic\ninequalities for sums of independent random variables under much weaker\nexponential type (namely sub-Weibull) tail assumptions. These results extract a\npart sub-Gaussian tail behavior in finite samples, matching the asymptotics\ngoverned by the central limit theorem, and are compactly represented in terms\nof a new Orlicz quasi-norm - the Generalized Bernstein-Orlicz norm - that\ntypifies such tail behaviors.\n  We illustrate the usefulness of these inequalities through the analysis of\nfour fundamental problems in HD statistics. In the first two problems, we study\nthe rate of convergence of the sample covariance matrix in terms of the maximum\nelementwise norm and the maximum k-sub-matrix operator norm which are key\nquantities of interest in bootstrap, HD covariance matrix estimation and HD\ninference. The third example concerns the restricted eigenvalue condition,\nrequired in HD linear regression, which we verify for all sub-Weibull random\nvectors through a unified analysis, and also prove a more general result\nrelated to restricted strong convexity in the process. In the final example, we\nconsider the Lasso estimator for linear regression and establish its rate of\nconvergence under much weaker than usual tail assumptions (on the errors as\nwell as the covariates), while also allowing for misspecified models and both\nfixed and random design. To our knowledge, these are the first such results for\nLasso obtained in this generality. The common feature in all our results over\nall the examples is that the convergence rates under most exponential tails\nmatch the usual ones under sub-Gaussian assumptions.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 00:27:45 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2018 01:40:10 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 20:56:42 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Kuchibhotla", "Arun Kumar", ""], ["Chakrabortty", "Abhishek", ""]]}, {"id": "1804.02617", "submitter": "Utkarsh Contractor", "authors": "Mehrad Moradshahi and Utkarsh Contractor", "title": "Language Modeling with Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have been promising in the field of\nimage generation, however, they have been hard to train for language\ngeneration. GANs were originally designed to output differentiable values, so\ndiscrete language generation is challenging for them which causes high levels\nof instability in training GANs. Consequently, past work has resorted to\npre-training with maximum-likelihood or training GANs without pre-training with\na WGAN objective with a gradient penalty. In this study, we present a\ncomparison of those approaches. Furthermore, we present the results of some\nexperiments that indicate better training and convergence of Wasserstein GANs\n(WGANs) when a weaker regularization term is enforcing the Lipschitz\nconstraint.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 03:18:13 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Moradshahi", "Mehrad", ""], ["Contractor", "Utkarsh", ""]]}, {"id": "1804.02665", "submitter": "Fady Medhat", "authors": "Fady Medhat, David Chesmore, John Robinson", "title": "Environmental Sound Recognition using Masked Conditional Neural Networks", "comments": "Boltzmann Machine, RBM, Conditional RBM, CRBM, Deep Neural Network,\n  DNN, Conditional Neural Network, CLNN, Masked Conditional Neural Net-work,\n  MCLNN, Environmental Sound Recognition, ESR, Advanced Data Mining and\n  Applications (ADMA) Year: 2017", "journal-ref": null, "doi": "10.1007/978-3-319-69179-4_26", "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network based architectures used for sound recognition are usually\nadapted from other application domains, which may not harness sound related\nproperties. The ConditionaL Neural Network (CLNN) is designed to consider the\nrelational properties across frames in a temporal signal, and its extension the\nMasked ConditionaL Neural Network (MCLNN) embeds a filterbank behavior within\nthe network, which enforces the network to learn in frequency bands rather than\nbins. Additionally, it automates the exploration of different feature\ncombinations analogous to handcrafting the optimum combination of features for\na recognition task. We applied the MCLNN to the environmental sounds of the\nESC-10 dataset. The MCLNN achieved competitive accuracies compared to\nstate-of-the-art convolutional neural networks and hand-crafted attempts.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 10:22:02 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 14:07:51 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Medhat", "Fady", ""], ["Chesmore", "David", ""], ["Robinson", "John", ""]]}, {"id": "1804.02668", "submitter": "Shahar Harel", "authors": "Shahar Harel, Kira Radinsky", "title": "Accelerating Prototype-Based Drug Discovery using Conditional Diversity\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3219819.3219882", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing a new drug is a lengthy and expensive process. As the space of\npotential molecules is very large (10^23-10^60), a common technique during drug\ndiscovery is to start from a molecule which already has some of the desired\nproperties. An interdisciplinary team of scientists generates hypothesis about\nthe required changes to the prototype. In this work, we develop an algorithmic\nunsupervised-approach that automatically generates potential drug molecules\ngiven a prototype drug. We show that the molecules generated by the system are\nvalid molecules and significantly different from the prototype drug. Out of the\ncompounds generated by the system, we identified 35 FDA-approved drugs. As an\nexample, our system generated Isoniazid - one of the main drugs for\nTuberculosis. The system is currently being deployed for use in collaboration\nwith pharmaceutical companies to further analyze the additional generated\nmolecules.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 11:08:08 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Harel", "Shahar", ""], ["Radinsky", "Kira", ""]]}, {"id": "1804.02686", "submitter": "Valentina Ros", "authors": "Valentina Ros, Gerard Ben Arous, Giulio Biroli, Chiara Cammarota", "title": "Complex energy landscapes in spiked-tensor and simple glassy models:\n  ruggedness, arrangements of local minima and phase transitions", "comments": "v2 with references added, typos corrected", "journal-ref": "Phys. Rev. X 9, 011003 (2019)", "doi": "10.1103/PhysRevX.9.011003", "report-no": null, "categories": "cond-mat.dis-nn math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study rough high-dimensional landscapes in which an increasingly stronger\npreference for a given configuration emerges. Such energy landscapes arise in\nglass physics and inference. In particular we focus on random Gaussian\nfunctions, and on the spiked-tensor model and generalizations. We thoroughly\nanalyze the statistical properties of the corresponding landscapes and\ncharacterize the associated geometrical phase transitions. In order to perform\nour study, we develop a framework based on the Kac-Rice method that allows to\ncompute the complexity of the landscape, i.e. the logarithm of the typical\nnumber of stationary points and their Hessian. This approach generalizes the\none used to compute rigorously the annealed complexity of mean-field glass\nmodels. We discuss its advantages with respect to previous frameworks, in\nparticular the thermodynamical replica method which is shown to lead to\npartially incorrect predictions.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 13:03:54 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 13:45:03 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Ros", "Valentina", ""], ["Arous", "Gerard Ben", ""], ["Biroli", "Giulio", ""], ["Cammarota", "Chiara", ""]]}, {"id": "1804.02693", "submitter": "Hassan Jaleel", "authors": "Hassan Jaleel and Jeff S. Shamma", "title": "Path to Stochastic Stability: Comparative Analysis of Stochastic\n  Learning Dynamics in Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic stability is a popular solution concept for stochastic learning\ndynamics in games. However, a critical limitation of this solution concept is\nits inability to distinguish between different learning rules that lead to the\nsame steady-state behavior. We address this limitation for the first time and\ndevelop a framework for the comparative analysis of stochastic learning\ndynamics with different update rules but same steady-state behavior. We present\nthe framework in the context of two learning dynamics: Log-Linear Learning\n(LLL) and Metropolis Learning (ML). Although both of these dynamics have the\nsame stochastically stable states, LLL and ML correspond to different\nbehavioral models for decision making. Moreover, we demonstrate through an\nexample setup of sensor coverage game that for each of these dynamics, the\npaths to stochastically stable states exhibit distinctive behaviors. Therefore,\nwe propose multiple criteria to analyze and quantify the differences in the\nshort and medium run behavior of stochastic learning dynamics. We derive and\ncompare upper bounds on the expected hitting time to the set of Nash equilibria\nfor both LLL and ML. For the medium to long-run behavior, we identify a set of\ntools from the theory of perturbed Markov chains that result in a hierarchical\ndecomposition of the state space into collections of states called cycles. We\ncompare LLL and ML based on the proposed criteria and develop invaluable\ninsights into the comparative behavior of the two dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 14:07:46 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Jaleel", "Hassan", ""], ["Shamma", "Jeff S.", ""]]}, {"id": "1804.02698", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Daisuke Igaue", "title": "Hierarchical Modular Reinforcement Learning Method and Knowledge\n  Acquisition of State-Action Rule for Multi-target Problem", "comments": "6pages, 10 figures, Proc. of IEEE 6th International Workshop on\n  Computational Intelligence and Applications (IWCIA2013)", "journal-ref": null, "doi": "10.1109/IWCIA.2013.6624799", "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical Modular Reinforcement Learning (HMRL), consists of 2 layered\nlearning where Profit Sharing works to plan a prey position in the higher layer\nand Q-learning method trains the state-actions to the target in the lower\nlayer. In this paper, we expanded HMRL to multi-target problem to take the\ndistance between targets to the consideration. The function, called `AT field',\ncan estimate the interests for an agent according to the distance between 2\nagents and the advantage/disadvantage of the other agent. Moreover, the\nknowledge related to state-action rules is extracted by C4.5. The action under\nthe situation is decided by using the acquired knowledge. To verify the\neffectiveness of proposed method, some experimental results are reported.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 14:39:13 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Ichimura", "Takumi", ""], ["Igaue", "Daisuke", ""]]}, {"id": "1804.02704", "submitter": "Fabrizio Maria Maggi", "authors": "Volodymyr Leno and Abel Armas-Cervantes and Marlon Dumas and Marcello\n  La Rosa and Fabrizio M. Maggi", "title": "Discovering Process Maps from Event Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated process discovery is a class of process mining methods that allow\nanalysts to extract business process models from event logs. Traditional\nprocess discovery methods extract process models from a snapshot of an event\nlog stored in its entirety. In some scenarios, however, events keep coming with\na high arrival rate to the extent that it is impractical to store the entire\nevent log and to continuously re-discover a process model from scratch. Such\nscenarios require online process discovery approaches. Given an event stream\nproduced by the execution of a business process, the goal of an online process\ndiscovery method is to maintain a continuously updated model of the process\nwith a bounded amount of memory while at the same time achieving similar\naccuracy as offline methods. However, existing online discovery approaches\nrequire relatively large amounts of memory to achieve levels of accuracy\ncomparable to that of offline methods. Therefore, this paper proposes an\napproach that addresses this limitation by mapping the problem of online\nprocess discovery to that of cache memory management, and applying well-known\ncache replacement policies to the problem of online process discovery. The\napproach has been implemented in .NET, experimentally integrated with the Minit\nprocess mining tool and comparatively evaluated against an existing baseline\nusing real-life datasets.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 15:23:52 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Leno", "Volodymyr", ""], ["Armas-Cervantes", "Abel", ""], ["Dumas", "Marlon", ""], ["La Rosa", "Marcello", ""], ["Maggi", "Fabrizio M.", ""]]}, {"id": "1804.02744", "submitter": "Sida Liu", "authors": "Sida Liu, Adrian Barbu", "title": "Unsupervised Learning of GMM with a Uniform Background Component", "comments": "36 pages, 16 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Mixture Models are one of the most studied and mature models in\nunsupervised learning. However, outliers are often present in the data and\ncould influence the cluster estimation. In this paper, we study a new model\nthat assumes that data comes from a mixture of a number of Gaussians as well as\na uniform ``background'' component assumed to contain outliers and other\nnon-interesting observations. We develop a novel method based on robust loss\nminimization that performs well in clustering such GMM with a uniform\nbackground. We give theoretical guarantees for our clustering algorithm to\nobtain best clustering results with high probability. Besides, we show that the\nresult of our algorithm does not depend on initialization or local optima, and\nthe parameter tuning is an easy task. By numeric simulations, we demonstrate\nthat our algorithm enjoys high accuracy and achieves the best clustering\nresults given a large enough sample size. Finally, experimental comparisons\nwith typical clustering methods on real datasets witness the potential of our\nalgorithm in real applications.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 19:27:39 GMT"}, {"version": "v2", "created": "Sun, 27 May 2018 14:42:25 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2018 00:19:16 GMT"}, {"version": "v4", "created": "Fri, 20 Mar 2020 19:15:55 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Liu", "Sida", ""], ["Barbu", "Adrian", ""]]}, {"id": "1804.02747", "submitter": "Krzysztof Chalupka", "authors": "Krzysztof Chalupka, Pietro Perona, Frederick Eberhardt", "title": "Fast Conditional Independence Test for Vector Variables with Large\n  Sample Sizes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present and evaluate the Fast (conditional) Independence Test (FIT) -- a\nnonparametric conditional independence test. The test is based on the idea that\nwhen $P(X \\mid Y, Z) = P(X \\mid Y)$, $Z$ is not useful as a feature to predict\n$X$, as long as $Y$ is also a regressor. On the contrary, if $P(X \\mid Y, Z)\n\\neq P(X \\mid Y)$, $Z$ might improve prediction results. FIT applies to\nthousand-dimensional random variables with a hundred thousand samples in a\nfraction of the time required by alternative methods. We provide an extensive\nevaluation that compares FIT to six extant nonparametric independence tests.\nThe evaluation shows that FIT has low probability of making both Type I and\nType II errors compared to other tests, especially as the number of available\nsamples grows. Our implementation of FIT is publicly available.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 20:03:07 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Chalupka", "Krzysztof", ""], ["Perona", "Pietro", ""], ["Eberhardt", "Frederick", ""]]}, {"id": "1804.02756", "submitter": "Nikita Puchkin", "authors": "Nikita Puchkin and Vladimir Spokoiny", "title": "An adaptive multiclass nearest neighbor classifier", "comments": "Accepted in ESAIM: Probability & Statistics. The original publication\n  is available at www.esaim-ps.org", "journal-ref": null, "doi": "10.1051/ps/2019021", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a problem of multiclass classification, where the training sample\n$S_n = \\{(X_i, Y_i)\\}_{i=1}^n$ is generated from the model $\\mathbb P(Y = m | X\n= x) = \\eta_m(x)$, $1 \\leq m \\leq M$, and $\\eta_1(x), \\dots, \\eta_M(x)$ are\nunknown $\\alpha$-Holder continuous functions.Given a test point $X$, our goal\nis to predict its label. A widely used $\\mathsf k$-nearest-neighbors classifier\nconstructs estimates of $\\eta_1(X), \\dots, \\eta_M(X)$ and uses a plug-in rule\nfor the prediction. However, it requires a proper choice of the smoothing\nparameter $\\mathsf k$, which may become tricky in some situations. In our\nsolution, we fix several integers $n_1, \\dots, n_K$, compute corresponding\n$n_k$-nearest-neighbor estimates for each $m$ and each $n_k$ and apply an\naggregation procedure. We study an algorithm, which constructs a convex\ncombination of these estimates such that the aggregated estimate behaves\napproximately as well as an oracle choice. We also provide a non-asymptotic\nanalysis of the procedure, prove its adaptation to the unknown smoothness\nparameter $\\alpha$ and to the margin and establish rates of convergence under\nmild assumptions.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 21:07:46 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 12:57:43 GMT"}, {"version": "v3", "created": "Wed, 7 Aug 2019 09:38:07 GMT"}, {"version": "v4", "created": "Sun, 3 Nov 2019 20:57:17 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Puchkin", "Nikita", ""], ["Spokoiny", "Vladimir", ""]]}, {"id": "1804.02763", "submitter": "Dabal Pedamonti", "authors": "Dabal Pedamonti", "title": "Comparison of non-linear activation functions for deep neural networks\n  on MNIST classification task", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Activation functions play a key role in neural networks so it becomes\nfundamental to understand their advantages and disadvantages in order to\nachieve better performances. This paper will first introduce common types of\nnon linear activation functions that are alternative to the well known sigmoid\nfunction and then evaluate their characteristics. Moreover deeper neural\nnetworks will be analysed because they positively influence the final\nperformances compared to shallower networks. They also strictly depend on the\nweight initialisation hence the effect of drawing weights from Gaussian and\nuniform distribution will be analysed making particular attention on how the\nnumber of incoming and outgoing connection to a node influence the whole\nnetwork.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 22:16:36 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Pedamonti", "Dabal", ""]]}, {"id": "1804.02772", "submitter": "Cheng Zhang", "authors": "Cheng Zhang, Cengiz \\\"Oztireli, Stephan Mandt, Giampiero Salvi", "title": "Active Mini-Batch Sampling using Repulsive Point Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convergence speed of stochastic gradient descent (SGD) can be improved by\nactively selecting mini-batches. We explore sampling schemes where similar data\npoints are less likely to be selected in the same mini-batch. In particular, we\nprove that such repulsive sampling schemes lowers the variance of the gradient\nestimator. This generalizes recent work on using Determinantal Point Processes\n(DPPs) for mini-batch diversification (Zhang et al., 2017) to the broader class\nof repulsive point processes. We first show that the phenomenon of variance\nreduction by diversified sampling generalizes in particular to non-stationary\npoint processes. We then show that other point processes may be computationally\nmuch more efficient than DPPs. In particular, we propose and investigate\nPoisson Disk sampling---frequently encountered in the computer graphics\ncommunity---for this task. We show empirically that our approach improves over\nstandard SGD both in terms of convergence speed as well as final model\nperformance.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 22:48:20 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 15:12:20 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Zhang", "Cheng", ""], ["\u00d6ztireli", "Cengiz", ""], ["Mandt", "Stephan", ""], ["Salvi", "Giampiero", ""]]}, {"id": "1804.02799", "submitter": "Christian H\\\"ager", "authors": "Christian H\\\"ager and Henry D. Pfister", "title": "Deep Learning of the Nonlinear Schr\\\"odinger Equation in Fiber-Optic\n  Communications", "comments": "5 pages, 5 figures, accepted for ISIT 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem in fiber-optic communications is to invert the nonlinear\nSchr\\\"odinger equation in real time to reverse the deterministic effects of the\nchannel. Interestingly, the popular split-step Fourier method (SSFM) leads to a\ncomputation graph that is reminiscent of a deep neural network. This\nobservation allows one to leverage tools from machine learning to reduce\ncomplexity. In particular, the main disadvantage of the SSFM is that its\ncomplexity using M steps is at least M times larger than a linear equalizer.\nThis is because the linear SSFM operator is a dense matrix. In previous work,\ntruncation methods such as frequency sampling, wavelets, or least-squares have\nbeen used to obtain \"cheaper\" operators that can be implemented using filters.\nHowever, a large number of filter taps are typically required to limit\ntruncation errors. For example, Ip and Kahn showed that for a 10 Gbaud signal\nand 2000 km optical link, a truncated SSFM with 25 steps would require 70-tap\nfilters in each step and 100 times more operations than linear equalization. We\nfind that, by jointly optimizing all filters with deep learning, the complexity\ncan be reduced significantly for similar accuracy. Using optimized 5-tap and\n3-tap filters in an alternating fashion, one requires only around 2-6 times the\ncomplexity of linear equalization, depending on the implementation.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 02:58:42 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["H\u00e4ger", "Christian", ""], ["Pfister", "Henry D.", ""]]}, {"id": "1804.02808", "submitter": "Tuomas Haarnoja", "authors": "Tuomas Haarnoja, Kristian Hartikainen, Pieter Abbeel, Sergey Levine", "title": "Latent Space Policies for Hierarchical Reinforcement Learning", "comments": "ICML 2018; Videos: https://sites.google.com/view/latent-space-deep-rl\n  Code: https://github.com/haarnoja/sac", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning hierarchical deep neural network policies\nfor reinforcement learning. In contrast to methods that explicitly restrict or\ncripple lower layers of a hierarchy to force them to use higher-level\nmodulating signals, each layer in our framework is trained to directly solve\nthe task, but acquires a range of diverse strategies via a maximum entropy\nreinforcement learning objective. Each layer is also augmented with latent\nrandom variables, which are sampled from a prior distribution during the\ntraining of that layer. The maximum entropy objective causes these latent\nvariables to be incorporated into the layer's policy, and the higher level\nlayer can directly control the behavior of the lower layer through this latent\nspace. Furthermore, by constraining the mapping from latent variables to\nactions to be invertible, higher layers retain full expressivity: neither the\nhigher layers nor the lower layers are constrained in their behavior. Our\nexperimental evaluation demonstrates that we can improve on the performance of\nsingle-layer policies on standard benchmark tasks simply by adding additional\nlayers, and that our method can solve more complex sparse-reward tasks by\nlearning higher-level policies on top of high-entropy skills optimized for\nsimple low-level objectives.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 04:00:30 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 19:24:16 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Haarnoja", "Tuomas", ""], ["Hartikainen", "Kristian", ""], ["Abbeel", "Pieter", ""], ["Levine", "Sergey", ""]]}, {"id": "1804.02948", "submitter": "Jochen Cremer", "authors": "Jochen L. Cremer, Ioannis Konstantelos, Simon H. Tindemans, Goran\n  Strbac", "title": "Sample-Derived Disjunctive Rules for Secure Power System Operation", "comments": "6 pages, accepted paper to IEEE PMAPS 2018", "journal-ref": null, "doi": "10.1109/PMAPS.2018.8440373", "report-no": null, "categories": "cs.SY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques have been used in the past using Monte Carlo\nsamples to construct predictors of the dynamic stability of power systems. In\nthis paper we move beyond the task of prediction and propose a comprehensive\napproach to use predictors, such as Decision Trees (DT), within a standard\noptimization framework for pre- and post-fault control purposes. In particular,\nwe present a generalizable method for embedding rules derived from DTs in an\noperation decision-making model. We begin by pointing out the specific\nchallenges entailed when moving from a prediction to a control framework. We\nproceed with introducing the solution strategy based on generalized disjunctive\nprogramming (GDP) as well as a two-step search method for identifying optimal\nhyper-parameters for balancing cost and control accuracy. We showcase how the\nproposed approach constructs security proxies that cover multiple contingencies\nwhile facing high-dimensional uncertainty with respect to operating conditions\nwith the use of a case study on the IEEE 39-bus system. The method is shown to\nachieve efficient system control at a marginal increase in system price\ncompared to an oracle model.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 12:51:53 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Cremer", "Jochen L.", ""], ["Konstantelos", "Ioannis", ""], ["Tindemans", "Simon H.", ""], ["Strbac", "Goran", ""]]}, {"id": "1804.02969", "submitter": "Tomas Kliegr", "authors": "Tom\\'a\\v{s} Kliegr, \\v{S}t\\v{e}p\\'an Bahn\\'ik, Johannes F\\\"urnkranz", "title": "A review of possible effects of cognitive biases on the interpretation\n  of rule-based machine learning models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the interpretability of machine learning models is often equated with\ntheir mere syntactic comprehensibility, we think that interpretability goes\nbeyond that, and that human interpretability should also be investigated from\nthe point of view of cognitive science. In particular, the goal of this paper\nis to discuss to what extent cognitive biases may affect human understanding of\ninterpretable machine learning models, in particular of logical rules\ndiscovered from data. Twenty cognitive biases are covered, as are possible\ndebiasing techniques that can be adopted by designers of machine learning\nalgorithms and software. Our review transfers results obtained in cognitive\npsychology to the domain of machine learning, aiming to bridge the current gap\nbetween these two areas. It needs to be followed by empirical studies\nspecifically focused on the machine learning domain.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 13:28:56 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2018 06:31:38 GMT"}, {"version": "v3", "created": "Wed, 27 Jun 2018 06:43:29 GMT"}, {"version": "v4", "created": "Thu, 3 Oct 2019 08:44:37 GMT"}, {"version": "v5", "created": "Thu, 25 Jun 2020 09:13:13 GMT"}, {"version": "v6", "created": "Mon, 7 Dec 2020 17:42:18 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Kliegr", "Tom\u00e1\u0161", ""], ["Bahn\u00edk", "\u0160t\u011bp\u00e1n", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1804.02998", "submitter": "Neil Caithness", "authors": "Neil Caithness and David Wallom", "title": "Anomaly Detection for Industrial Big Data", "comments": "9 pages; 11 figures", "journal-ref": "In Proceedings of the 7th International Conference on Data\n  Science, Technology and Applications - Volume 1: DATA (2018), ISBN\n  978-989-758-318-6, pages 285-293", "doi": "10.5220/0006835502850293", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the Industrial Internet of Things (IIoT) grows, systems are increasingly\nbeing monitored by arrays of sensors returning time-series data at\never-increasing 'volume, velocity and variety' (i.e. Industrial Big Data). An\nobvious use for these data is real-time systems condition monitoring and\nprognostic time to failure analysis (remaining useful life, RUL). (e.g. See\nwhite papers by Senseye.io, and output of the NASA Prognostics Center of\nExcellence (PCoE).) However, as noted by Agrawal and Choudhary 'Our ability to\ncollect \"big data\" has greatly surpassed our capability to analyze it,\nunderscoring the emergence of the fourth paradigm of science, which is\ndata-driven discovery.' In order to fully utilize the potential of Industrial\nBig Data we need data-driven techniques that operate at scales that process\nmodels cannot. Here we present a prototype technique for data-driven anomaly\ndetection to operate at industrial scale. The method generalizes to application\nwith almost any multivariate dataset based on independent ordinations of\nrepeated (bootstrapped) partitions of the dataset and inspection of the joint\ndistribution of ordinal distances.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 14:09:47 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Caithness", "Neil", ""], ["Wallom", "David", ""]]}, {"id": "1804.03022", "submitter": "Giovanni Saponaro", "authors": "Giovanni Saponaro, Pedro Vicente, Atabak Dehban, Lorenzo Jamone,\n  Alexandre Bernardino, Jos\\'e Santos-Victor", "title": "Learning at the Ends: From Hand to Tool Affordances in Humanoid Robots", "comments": "dataset available at htts://vislab.isr.tecnico.ulisboa.pt/, IEEE\n  International Conference on Development and Learning and on Epigenetic\n  Robotics (ICDL-EpiRob 2017)", "journal-ref": null, "doi": "10.1109/DEVLRN.2017.8329826", "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the open challenges in designing robots that operate successfully in\nthe unpredictable human environment is how to make them able to predict what\nactions they can perform on objects, and what their effects will be, i.e., the\nability to perceive object affordances. Since modeling all the possible world\ninteractions is unfeasible, learning from experience is required, posing the\nchallenge of collecting a large amount of experiences (i.e., training data).\nTypically, a manipulative robot operates on external objects by using its own\nhands (or similar end-effectors), but in some cases the use of tools may be\ndesirable, nevertheless, it is reasonable to assume that while a robot can\ncollect many sensorimotor experiences using its own hands, this cannot happen\nfor all possible human-made tools.\n  Therefore, in this paper we investigate the developmental transition from\nhand to tool affordances: what sensorimotor skills that a robot has acquired\nwith its bare hands can be employed for tool use? By employing a visual and\nmotor imagination mechanism to represent different hand postures compactly, we\npropose a probabilistic model to learn hand affordances, and we show how this\nmodel can generalize to estimate the affordances of previously unseen tools,\nultimately supporting planning, decision-making and tool selection tasks in\nhumanoid robots. We present experimental results with the iCub humanoid robot,\nand we publicly release the collected sensorimotor data in the form of a hand\nposture affordances dataset.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 14:28:15 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Saponaro", "Giovanni", ""], ["Vicente", "Pedro", ""], ["Dehban", "Atabak", ""], ["Jamone", "Lorenzo", ""], ["Bernardino", "Alexandre", ""], ["Santos-Victor", "Jos\u00e9", ""]]}, {"id": "1804.03065", "submitter": "Vatsal Sharan", "authors": "Vatsal Sharan, Parikshit Gopalan, Udi Wieder", "title": "Efficient Anomaly Detection via Matrix Sketching", "comments": "Updates for NeurIPS'18 camera-ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding anomalies in high-dimensional data using\npopular PCA based anomaly scores. The naive algorithms for computing these\nscores explicitly compute the PCA of the covariance matrix which uses space\nquadratic in the dimensionality of the data. We give the first streaming\nalgorithms that use space that is linear or sublinear in the dimension. We\nprove general results showing that \\emph{any} sketch of a matrix that satisfies\na certain operator norm guarantee can be used to approximate these scores. We\ninstantiate these results with powerful matrix sketching techniques such as\nFrequent Directions and random projections to derive efficient and practical\nalgorithms for these problems, which we validate over real-world data sets. Our\nmain technical contribution is to prove matrix perturbation inequalities for\noperators arising in the computation of these measures.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 15:47:36 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 16:46:19 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Sharan", "Vatsal", ""], ["Gopalan", "Parikshit", ""], ["Wieder", "Udi", ""]]}, {"id": "1804.03077", "submitter": "Dirk Tasche", "authors": "Dirk Tasche", "title": "A plug-in approach to maximising precision at the top and recall at the\n  top", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For information retrieval and binary classification, we show that precision\nat the top (or precision at k) and recall at the top (or recall at k) are\nmaximised by thresholding the posterior probability of the positive class. This\nfinding is a consequence of a result on constrained minimisation of the\ncost-sensitive expected classification error which generalises an earlier\nrelated result from the literature.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 16:10:45 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Tasche", "Dirk", ""]]}, {"id": "1804.03142", "submitter": "Alexander  Mathis", "authors": "Alexander Mathis, Pranav Mamidanna, Taiga Abe, Kevin M. Cury,\n  Venkatesh N. Murthy, Mackenzie W. Mathis and Matthias Bethge", "title": "Markerless tracking of user-defined features with deep learning", "comments": "Videos at http://www.mousemotorlab.org/deeplabcut", "journal-ref": "Nature Neuroscience, Technical Report, published: 20 August 2018", "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantifying behavior is crucial for many applications in neuroscience.\nVideography provides easy methods for the observation and recording of animal\nbehavior in diverse settings, yet extracting particular aspects of a behavior\nfor further analysis can be highly time consuming. In motor control studies,\nhumans or other animals are often marked with reflective markers to assist with\ncomputer-based tracking, yet markers are intrusive (especially for smaller\nanimals), and the number and location of the markers must be determined a\npriori. Here, we present a highly efficient method for markerless tracking\nbased on transfer learning with deep neural networks that achieves excellent\nresults with minimal training data. We demonstrate the versatility of this\nframework by tracking various body parts in a broad collection of experimental\nsettings: mice odor trail-tracking, egg-laying behavior in drosophila, and\nmouse hand articulation in a skilled forelimb task. For example, during the\nskilled reaching behavior, individual joints can be automatically tracked (and\na confidence score is reported). Remarkably, even when a small number of frames\nare labeled ($\\approx 200$), the algorithm achieves excellent tracking\nperformance on test frames that is comparable to human accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 17:10:39 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Mathis", "Alexander", ""], ["Mamidanna", "Pranav", ""], ["Abe", "Taiga", ""], ["Cury", "Kevin M.", ""], ["Murthy", "Venkatesh N.", ""], ["Mathis", "Mackenzie W.", ""], ["Bethge", "Matthias", ""]]}, {"id": "1804.03154", "submitter": "Tomohiro Hayase", "authors": "Tomohiro Hayase", "title": "Cauchy noise loss for stochastic optimization of random matrix models\n  via free deterministic equivalents", "comments": "29 pages, 13 figures, v3: minor correction. Submitted. Our simulation\n  code is available at https://github.com/ThayaFluss/cnl. Submitted to a\n  journal", "journal-ref": "Journal of Mathematical Analysis and Applications Volume 483,\n  Issue 2, 15 March 2020, 123597", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OA math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For random matrix models, the parameter estimation based on the traditional\nlikelihood functions is not straightforward in particular when we have only one\nsample matrix. We introduce a new parameter optimization method for random\nmatrix models which works even in such a case. The method is based on the\nspectral distribution instead of the traditional likelihood. In the method, the\nCauchy noise has an essential role because the free deterministic equivalent,\nwhich is a tool in free probability theory, allows us to approximate the\nspectral distribution perturbed by Cauchy noises by a smooth and accessible\ndensity function.\n  Moreover, we study an asymptotic property of determination gap, which has a\nsimilar role as generalization gap. Besides, we propose a new dimensionality\nrecovery method for the signal-plus-noise model, and experimentally demonstrate\nthat it recovers the rank of the signal part even if the true rank is not\nsmall. It is a simultaneous rank selection and parameter estimation procedure.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 18:00:08 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 11:21:26 GMT"}, {"version": "v3", "created": "Sun, 5 Aug 2018 10:05:13 GMT"}, {"version": "v4", "created": "Tue, 3 Sep 2019 15:12:37 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Hayase", "Tomohiro", ""]]}, {"id": "1804.03176", "submitter": "Gauthier Gidel", "authors": "Gauthier Gidel, Fabian Pedregosa and Simon Lacoste-Julien", "title": "Frank-Wolfe Splitting via Augmented Lagrangian Method", "comments": "Appears in: Proceedings of the 21st International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2018). 30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimizing a function over an intersection of convex sets is an important\ntask in optimization that is often much more challenging than minimizing it\nover each individual constraint set. While traditional methods such as\nFrank-Wolfe (FW) or proximal gradient descent assume access to a linear or\nquadratic oracle on the intersection, splitting techniques take advantage of\nthe structure of each sets, and only require access to the oracle on the\nindividual constraints. In this work, we develop and analyze the Frank-Wolfe\nAugmented Lagrangian (FW-AL) algorithm, a method for minimizing a smooth\nfunction over convex compact sets related by a \"linear consistency\" constraint\nthat only requires access to a linear minimization oracle over the individual\nconstraints. It is based on the Augmented Lagrangian Method (ALM), also known\nas Method of Multipliers, but unlike most existing splitting methods, it only\nrequires access to linear (instead of quadratic) minimization oracles. We use\nrecent advances in the analysis of Frank-Wolfe and the alternating direction\nmethod of multipliers algorithms to prove a sublinear convergence rate for\nFW-AL over general convex compact sets and a linear convergence rate for\npolytopes.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 18:33:29 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Gidel", "Gauthier", ""], ["Pedregosa", "Fabian", ""], ["Lacoste-Julien", "Simon", ""]]}, {"id": "1804.03184", "submitter": "Paidamoyo Chapfuwa", "authors": "Paidamoyo Chapfuwa, Chenyang Tao, Chunyuan Li, Courtney Page, Benjamin\n  Goldstein, Lawrence Carin, Ricardo Henao", "title": "Adversarial Time-to-Event Modeling", "comments": "Published in ICML 2018; Code:\n  https://github.com/paidamoyo/adversarial_time_to_event", "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:735-744, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Modern health data science applications leverage abundant molecular and\nelectronic health data, providing opportunities for machine learning to build\nstatistical models to support clinical practice. Time-to-event analysis, also\ncalled survival analysis, stands as one of the most representative examples of\nsuch statistical models. We present a deep-network-based approach that\nleverages adversarial learning to address a key challenge in modern\ntime-to-event modeling: nonparametric estimation of event-time distributions.\nWe also introduce a principled cost function to exploit information from\ncensored events (events that occur subsequent to the observation window).\nUnlike most time-to-event models, we focus on the estimation of time-to-event\ndistributions, rather than time ordering. We validate our model on both\nbenchmark and real datasets, demonstrating that the proposed formulation yields\nsignificant performance gains relative to a parametric alternative, which we\nalso propose.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 18:59:05 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 21:04:17 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Chapfuwa", "Paidamoyo", ""], ["Tao", "Chenyang", ""], ["Li", "Chunyuan", ""], ["Page", "Courtney", ""], ["Goldstein", "Benjamin", ""], ["Carin", "Lawrence", ""], ["Henao", "Ricardo", ""]]}, {"id": "1804.03193", "submitter": "Pu Zhao", "authors": "Pu Zhao, Sijia Liu, Yanzhi Wang, Xue Lin", "title": "An ADMM-Based Universal Framework for Adversarial Attacks on Deep Neural\n  Networks", "comments": "9 pages, 3 figures, in submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are known vulnerable to adversarial attacks. That\nis, adversarial examples, obtained by adding delicately crafted distortions\nonto original legal inputs, can mislead a DNN to classify them as any target\nlabels. In a successful adversarial attack, the targeted mis-classification\nshould be achieved with the minimal distortion added. In the literature, the\nadded distortions are usually measured by L0, L1, L2, and L infinity norms,\nnamely, L0, L1, L2, and L infinity attacks, respectively. However, there lacks\na versatile framework for all types of adversarial attacks.\n  This work for the first time unifies the methods of generating adversarial\nexamples by leveraging ADMM (Alternating Direction Method of Multipliers), an\noperator splitting optimization approach, such that L0, L1, L2, and L infinity\nattacks can be effectively implemented by this general framework with little\nmodifications. Comparing with the state-of-the-art attacks in each category,\nour ADMM-based attacks are so far the strongest, achieving both the 100% attack\nsuccess rate and the minimal distortion.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 19:23:01 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Zhao", "Pu", ""], ["Liu", "Sijia", ""], ["Wang", "Yanzhi", ""], ["Lin", "Xue", ""]]}, {"id": "1804.03194", "submitter": "Andreas Henelius", "authors": "Andreas Henelius and Emilia Oikarinen and Kai Puolam\\\"aki", "title": "Human-Guided Data Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The outcome of the explorative data analysis (EDA) phase is vital for\nsuccessful data analysis. EDA is more effective when the user interacts with\nthe system used to carry out the exploration. In the recently proposed paradigm\nof iterative data mining the user controls the exploration by inputting\nknowledge in the form of patterns observed during the process. The system then\nshows the user views of the data that are maximally informative given the\nuser's current knowledge. Although this scheme is good at showing surprising\nviews of the data to the user, there is a clear shortcoming: the user cannot\nsteer the process. In many real cases we want to focus on investigating\nspecific questions concerning the data. This paper presents the Human Guided\nData Exploration framework, generalising previous research. This framework\nallows the user to incorporate existing knowledge into the exploration process,\nfocus on exploring a subset of the data, and compare different complex\nhypotheses concerning relations in the data. The framework utilises a\ncomputationally efficient constrained randomisation scheme. To showcase the\nframework, we developed a free open-source tool, using which the empirical\nevaluation on real-world datasets was carried out. Our evaluation shows that\nthe ability to focus on particular subsets and being able to compare hypotheses\nare important additions to the interactive iterative data mining process.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 19:29:41 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Henelius", "Andreas", ""], ["Oikarinen", "Emilia", ""], ["Puolam\u00e4ki", "Kai", ""]]}, {"id": "1804.03201", "submitter": "Wei-Ning Hsu", "authors": "Wei-Ning Hsu and James Glass", "title": "Scalable Factorized Hierarchical Variational Autoencoder Training", "comments": "Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models have achieved great success in unsupervised learning\nwith the ability to capture complex nonlinear relationships between latent\ngenerating factors and observations. Among them, a factorized hierarchical\nvariational autoencoder (FHVAE) is a variational inference-based model that\nformulates a hierarchical generative process for sequential data. Specifically,\nan FHVAE model can learn disentangled and interpretable representations, which\nhave been proven useful for numerous speech applications, such as speaker\nverification, robust speech recognition, and voice conversion. However, as we\nwill elaborate in this paper, the training algorithm proposed in the original\npaper is not scalable to datasets of thousands of hours, which makes this model\nless applicable on a larger scale. After identifying limitations in terms of\nruntime, memory, and hyperparameter optimization, we propose a hierarchical\nsampling training algorithm to address all three issues. Our proposed method is\nevaluated comprehensively on a wide variety of datasets, ranging from 3 to\n1,000 hours and involving different types of generating factors, such as\nrecording conditions and noise types. In addition, we also present a new\nvisualization method for qualitatively evaluating the performance with respect\nto the interpretability and disentanglement. Models trained with our proposed\nalgorithm demonstrate the desired characteristics on all the datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 19:44:29 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 04:25:16 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Hsu", "Wei-Ning", ""], ["Glass", "James", ""]]}, {"id": "1804.03235", "submitter": "Rohan Anil", "authors": "Rohan Anil, Gabriel Pereyra, Alexandre Passos, Robert Ormandi, George\n  E. Dahl and Geoffrey E. Hinton", "title": "Large scale distributed neural network training through online\n  distillation", "comments": "Clarify that implementations should use available parallelism in\n  pseudo-code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques such as ensembling and distillation promise model quality\nimprovements when paired with almost any base model. However, due to increased\ntest-time cost (for ensembles) and increased complexity of the training\npipeline (for distillation), these techniques are challenging to use in\nindustrial settings. In this paper we explore a variant of distillation which\nis relatively straightforward to use as it does not require a complicated\nmulti-stage setup or many new hyperparameters. Our first claim is that online\ndistillation enables us to use extra parallelism to fit very large datasets\nabout twice as fast. Crucially, we can still speed up training even after we\nhave already reached the point at which additional parallelism provides no\nbenefit for synchronous or asynchronous stochastic gradient descent. Two neural\nnetworks trained on disjoint subsets of the data can share knowledge by\nencouraging each model to agree with the predictions the other model would have\nmade. These predictions can come from a stale version of the other model so\nthey can be safely computed using weights that only rarely get transmitted. Our\nsecond claim is that online distillation is a cost-effective way to make the\nexact predictions of a model dramatically more reproducible. We support our\nclaims using experiments on the Criteo Display Ad Challenge dataset, ImageNet,\nand the largest to-date dataset used for neural language modeling, containing\n$6\\times 10^{11}$ tokens and based on the Common Crawl repository of web data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 20:56:03 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2020 22:04:36 GMT"}], "update_date": "2020-08-24", "authors_parsed": [["Anil", "Rohan", ""], ["Pereyra", "Gabriel", ""], ["Passos", "Alexandre", ""], ["Ormandi", "Robert", ""], ["Dahl", "George E.", ""], ["Hinton", "Geoffrey E.", ""]]}, {"id": "1804.03236", "submitter": "Fernando Fernandes Neto", "authors": "Fernando Fernandes Neto", "title": "Building Function Approximators on top of Haar Scattering Networks", "comments": "7 pages, 5 figures, to appear in International Journal of Machine\n  Learning and Computing, vol. 8 number 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we propose building general-purpose function approximators on\ntop of Haar Scattering Networks. We advocate that this architecture enables a\nbetter comprehension of feature extraction, in addition to its implementation\nsimplicity and low computational costs. We show its approximation and feature\nextraction capabilities in a wide range of different problems, which can be\napplied on several phenomena in signal processing, system identification,\neconometrics and other potential fields.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 20:56:41 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Neto", "Fernando Fernandes", ""]]}, {"id": "1804.03273", "submitter": "Pin-Yu Chen", "authors": "Pin-Yu Chen and Dennis Wei", "title": "On the Supermodularity of Active Graph-based Semi-supervised Learning\n  with Stieltjes Matrix Regularization", "comments": "Accepted to IEEE ICASSP 2018. Pin-Yu Chen and Dennis Wei contribute\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active graph-based semi-supervised learning (AG-SSL) aims to select a small\nset of labeled examples and utilize their graph-based relation to other\nunlabeled examples to aid in machine learning tasks. It is also closely related\nto the sampling theory in graph signal processing. In this paper, we revisit\nthe original formulation of graph-based SSL and prove the supermodularity of an\nAG-SSL objective function under a broad class of regularization functions\nparameterized by Stieltjes matrices. Under this setting, supermodularity yields\na novel greedy label sampling algorithm with guaranteed performance relative to\nthe optimal sampling set. Compared to three state-of-the-art graph signal\nsampling and recovery methods on two real-life community detection datasets,\nthe proposed AG-SSL method attains superior classification accuracy given\nlimited sample budgets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 23:53:11 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Chen", "Pin-Yu", ""], ["Wei", "Dennis", ""]]}, {"id": "1804.03280", "submitter": "Milad Zafar Nezhad", "authors": "Milad Zafar Nezhad, Najibesadat Sadati, Kai Yang, Dongxiao Zhu", "title": "A Deep Active Survival Analysis Approach for Precision Treatment\n  Recommendations: Application of Prostate Cancer", "comments": null, "journal-ref": "Expert Systems with Applications Volume 115, January 2019, Pages\n  16-26", "doi": "10.1016/j.eswa.2018.07.070", "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Survival analysis has been developed and applied in the number of areas\nincluding manufacturing, finance, economics and healthcare. In healthcare\ndomain, usually clinical data are high-dimensional, sparse and complex and\nsometimes there exists few amount of time-to-event (labeled) instances.\nTherefore building an accurate survival model from electronic health records is\nchallenging. With this motivation, we address this issue and provide a new\nsurvival analysis framework using deep learning and active learning with a\nnovel sampling strategy. First, our approach provides better representation\nwith lower dimensions from clinical features using labeled (time-to-event) and\nunlabeled (censored) instances and then actively trains the survival model by\nlabeling the censored data using an oracle. As a clinical assistive tool, we\nintroduce a simple effective treatment recommendation approach based on our\nsurvival model. In the experimental study, we apply our approach on\nSEER-Medicare data related to prostate cancer among African-Americans and white\npatients. The results indicate that our approach outperforms significantly than\nbaseline models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 00:05:29 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Nezhad", "Milad Zafar", ""], ["Sadati", "Najibesadat", ""], ["Yang", "Kai", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "1804.03286", "submitter": "Nicholas Carlini", "authors": "Anish Athalye, Nicholas Carlini", "title": "On the Robustness of the CVPR 2018 White-Box Adversarial Example\n  Defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are known to be vulnerable to adversarial examples. In this\nnote, we evaluate the two white-box defenses that appeared at CVPR 2018 and\nfind they are ineffective: when applying existing techniques, we can reduce the\naccuracy of the defended models to 0%.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 04:54:29 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Athalye", "Anish", ""], ["Carlini", "Nicholas", ""]]}, {"id": "1804.03308", "submitter": "Angus Galloway", "authors": "Angus Galloway and Thomas Tanay and Graham W. Taylor", "title": "Adversarial Training Versus Weight Decay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance-critical machine learning models should be robust to input\nperturbations not seen during training. Adversarial training is a method for\nimproving a model's robustness to some perturbations by including them in the\ntraining process, but this tends to exacerbate other vulnerabilities of the\nmodel. The adversarial training framework has the effect of translating the\ndata with respect to the cost function, while weight decay has a scaling\neffect. Although weight decay could be considered a crude regularization\ntechnique, it appears superior to adversarial training as it remains stable\nover a broader range of regimes and reduces all generalization errors. Equipped\nwith these abstractions, we provide key baseline results and methodology for\ncharacterizing robustness. The two approaches can be combined to yield one\nsmall model that demonstrates good robustness to several white-box attacks\nassociated with different metrics.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 01:57:39 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 19:52:46 GMT"}, {"version": "v3", "created": "Mon, 23 Jul 2018 03:40:42 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Galloway", "Angus", ""], ["Tanay", "Thomas", ""], ["Taylor", "Graham W.", ""]]}, {"id": "1804.03329", "submitter": "Albert Gu", "authors": "Christopher De Sa, Albert Gu, Christopher R\\'e, Frederic Sala", "title": "Representation Tradeoffs for Hyperbolic Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperbolic embeddings offer excellent quality with few dimensions when\nembedding hierarchical data structures like synonym or type hierarchies. Given\na tree, we give a combinatorial construction that embeds the tree in hyperbolic\nspace with arbitrarily low distortion without using optimization. On WordNet,\nour combinatorial embedding obtains a mean-average-precision of 0.989 with only\ntwo dimensions, while Nickel et al.'s recent construction obtains 0.87 using\n200 dimensions. We provide upper and lower bounds that allow us to characterize\nthe precision-dimensionality tradeoff inherent in any hyperbolic embedding. To\nembed general metric spaces, we propose a hyperbolic generalization of\nmultidimensional scaling (h-MDS). We show how to perform exact recovery of\nhyperbolic points from distances, provide a perturbation analysis, and give a\nrecovery result that allows us to reduce dimensionality. The h-MDS approach\noffers consistently low distortion even with few dimensions across several\ndatasets. Finally, we extract lessons from the algorithms and theory above to\ndesign a PyTorch-based implementation that can handle incomplete information\nand is scalable.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 03:39:16 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 04:11:36 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["De Sa", "Christopher", ""], ["Gu", "Albert", ""], ["R\u00e9", "Christopher", ""], ["Sala", "Frederic", ""]]}, {"id": "1804.03334", "submitter": "Patrick M. Pilarski", "authors": "Alex Kearney, Vivek Veeriah, Jaden B. Travnik, Richard S. Sutton,\n  Patrick M. Pilarski", "title": "TIDBD: Adapting Temporal-difference Step-sizes Through Stochastic\n  Meta-descent", "comments": "Version as submitted to the 31st Conference on Neural Information\n  Processing Systems (NIPS 2017) on May 19, 2017. 9 pages, 5 figures. Extended\n  version in preparation for journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a method for adapting the step-sizes of temporal\ndifference (TD) learning. The performance of TD methods often depends on well\nchosen step-sizes, yet few algorithms have been developed for setting the\nstep-size automatically for TD learning. An important limitation of current\nmethods is that they adapt a single step-size shared by all the weights of the\nlearning system. A vector step-size enables greater optimization by specifying\nparameters on a per-feature basis. Furthermore, adapting parameters at\ndifferent rates has the added benefit of being a simple form of representation\nlearning. We generalize Incremental Delta Bar Delta (IDBD)---a vectorized\nadaptive step-size method for supervised learning---to TD learning, which we\nname TIDBD. We demonstrate that TIDBD is able to find appropriate step-sizes in\nboth stationary and non-stationary prediction tasks, outperforming ordinary TD\nmethods and TD methods with scalar step-size adaptation; we demonstrate that it\ncan differentiate between features which are relevant and irrelevant for a\ngiven task, performing representation learning; and we show on a real-world\nrobot prediction task that TIDBD is able to outperform ordinary TD methods and\nTD methods augmented with AlphaBound and RMSprop.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 04:01:07 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Kearney", "Alex", ""], ["Veeriah", "Vivek", ""], ["Travnik", "Jaden B.", ""], ["Sutton", "Richard S.", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1804.03346", "submitter": "Siddhartha Satpathi Mr", "authors": "Siddhartha Satpathi, Supratim Deb, R Srikant, and He Yan", "title": "Learning Latent Events from Network Message Logs", "comments": "To Appear in IEEE Transactions on Networking, Appeared in Workshop on\n  MiLeTS, SIGKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of separating error messages generated in large\ndistributed data center networks into error events. In such networks, each\nerror event leads to a stream of messages generated by hardware and software\ncomponents affected by the event. These messages are stored in a giant message\nlog. We consider the unsupervised learning problem of identifying the\nsignatures of events that generated these messages; here, the signature of an\nerror event refers to the mixture of messages generated by the event. One of\nthe main contributions of the paper is a novel mapping of our problem which\ntransforms it into a problem of topic discovery in documents. Events in our\nproblem correspond to topics and messages in our problem correspond to words in\nthe topic discovery problem. However, there is no direct analog of documents.\nTherefore, we use a non-parametric change-point detection algorithm, which has\nlinear computational complexity in the number of messages, to divide the\nmessage log into smaller subsets called episodes, which serve as the\nequivalents of documents. After this mapping has been done, we use a well-known\nalgorithm for topic discovery, called LDA, to solve our problem. We\ntheoretically analyze the change-point detection algorithm, and show that it is\nconsistent and has low sample complexity. We also demonstrate the scalability\nof our algorithm on a real data set consisting of $97$ million messages\ncollected over a period of $15$ days, from a distributed data center network\nwhich supports the operations of a large wireless service provider.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 05:44:53 GMT"}, {"version": "v2", "created": "Mon, 20 May 2019 23:23:46 GMT"}, {"version": "v3", "created": "Wed, 17 Jul 2019 20:06:20 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Satpathi", "Siddhartha", ""], ["Deb", "Supratim", ""], ["Srikant", "R", ""], ["Yan", "He", ""]]}, {"id": "1804.03429", "submitter": "Chongxuan Li", "authors": "Chongxuan Li and Max Welling and Jun Zhu and Bo Zhang", "title": "Graphical Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Graphical Generative Adversarial Networks (Graphical-GAN) to model\nstructured data. Graphical-GAN conjoins the power of Bayesian networks on\ncompactly representing the dependency structures among random variables and\nthat of generative adversarial networks on learning expressive dependency\nfunctions. We introduce a structured recognition model to infer the posterior\ndistribution of latent variables given observations. We generalize the\nExpectation Propagation (EP) algorithm to learn the generative model and\nrecognition model jointly. Finally, we present two important instances of\nGraphical-GAN, i.e. Gaussian Mixture GAN (GMGAN) and State Space GAN (SSGAN),\nwhich can successfully learn the discrete and temporal structures on visual\ndatasets, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 10:12:38 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 08:20:54 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Li", "Chongxuan", ""], ["Welling", "Max", ""], ["Zhu", "Jun", ""], ["Zhang", "Bo", ""]]}, {"id": "1804.03515", "submitter": "Philipp Probst", "authors": "Philipp Probst, Marvin Wright and Anne-Laure Boulesteix", "title": "Hyperparameters and Tuning Strategies for Random Forest", "comments": "19 pages, 2 figures", "journal-ref": "WIREs Data Mining Knowl Discov 2019", "doi": "10.1002/widm.1301", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The random forest algorithm (RF) has several hyperparameters that have to be\nset by the user, e.g., the number of observations drawn randomly for each tree\nand whether they are drawn with or without replacement, the number of variables\ndrawn randomly for each split, the splitting rule, the minimum number of\nsamples that a node must contain and the number of trees. In this paper, we\nfirst provide a literature review on the parameters' influence on the\nprediction performance and on variable importance measures.\n  It is well known that in most cases RF works reasonably well with the default\nvalues of the hyperparameters specified in software packages. Nevertheless,\ntuning the hyperparameters can improve the performance of RF. In the second\npart of this paper, after a brief overview of tuning strategies we demonstrate\nthe application of one of the most established tuning strategies, model-based\noptimization (MBO). To make it easier to use, we provide the tuneRanger R\npackage that tunes RF with MBO automatically. In a benchmark study on several\ndatasets, we compare the prediction performance and runtime of tuneRanger with\nother tuning implementations in R and RF with default hyperparameters.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 13:30:51 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 09:40:17 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Probst", "Philipp", ""], ["Wright", "Marvin", ""], ["Boulesteix", "Anne-Laure", ""]]}, {"id": "1804.03523", "submitter": "Bradley Gram-Hansen", "authors": "Bradley Gram-Hansen, Yuan Zhou, Tobias Kohn, Tom Rainforth, Hongseok\n  Yang, Frank Wood", "title": "Hamiltonian Monte Carlo for Probabilistic Programs with Discontinuities", "comments": "4 pages, 2 figures", "journal-ref": "Inaugural Conference on Probabilistic Programming, 2018", "doi": null, "report-no": null, "categories": "stat.CO cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamiltonian Monte Carlo (HMC) is arguably the dominant statistical inference\nalgorithm used in most popular \"first-order differentiable\" Probabilistic\nProgramming Languages (PPLs). However, the fact that HMC uses derivative\ninformation causes complications when the target distribution is\nnon-differentiable with respect to one or more of the latent variables. In this\npaper, we show how to use extensions to HMC to perform inference in\nprobabilistic programs that contain discontinuities. To do this, we design a\nSimple first-order Probabilistic Programming Language (SPPL) that contains a\nsufficient set of language restrictions together with a compilation scheme.\nThis enables us to preserve both the statistical and syntactic interpretation\nof if-else statements in the probabilistic program, within the scope of\nfirst-order PPLs. We also provide a corresponding mathematical formalism that\nensures any joint density denoted in such a language has a suitably low measure\nof discontinuities.\n", "versions": [{"version": "v1", "created": "Sat, 7 Apr 2018 09:22:56 GMT"}, {"version": "v2", "created": "Wed, 2 Jan 2019 16:32:10 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Gram-Hansen", "Bradley", ""], ["Zhou", "Yuan", ""], ["Kohn", "Tobias", ""], ["Rainforth", "Tom", ""], ["Yang", "Hongseok", ""], ["Wood", "Frank", ""]]}, {"id": "1804.03565", "submitter": "Sharmistha Dey Ms", "authors": "Sharmistha Dey", "title": "Predicting Gross Movie Revenue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  'There is no terror in the bang, only is the anticipation of it' - Alfred\nHitchcock.\n  Yet there is everything in correctly anticipating the bang a movie would make\nin the box-office. Movies make a high profile, billion dollar industry and\nprediction of movie revenue can be very lucrative. Predicted revenues can be\nused for planning both the production and distribution stages. For example,\nprojected gross revenue can be used to plan the remuneration of the actors and\ncrew members as well as other parts of the budget [1].\n  Success or failure of a movie can depend on many factors: star-power, release\ndate, budget, MPAA (Motion Picture Association of America) rating, plot and the\nhighly unpredictable human reactions. The enormity of the number of exogenous\nvariables makes manual revenue prediction process extremely difficult. However,\nin the era of computer and data sciences, volumes of data can be efficiently\nprocessed and modelled. Hence the tough job of predicting gross revenue of a\nmovie can be simplified with the help of modern computing power and the\nhistorical data available as movie databases [2].\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 19:44:57 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Dey", "Sharmistha", ""]]}, {"id": "1804.03578", "submitter": "Zihao Xiao", "authors": "Zihao Xiao, Jianfei Chen, Jun Zhu", "title": "Towards Training Probabilistic Topic Models on Neuromorphic Multi-chip\n  Systems", "comments": "Accepted by AAAI-18, oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.ET stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic topic models are popular unsupervised learning methods,\nincluding probabilistic latent semantic indexing (pLSI) and latent Dirichlet\nallocation (LDA). By now, their training is implemented on general purpose\ncomputers (GPCs), which are flexible in programming but energy-consuming.\nTowards low-energy implementations, this paper investigates their training on\nan emerging hardware technology called the neuromorphic multi-chip systems\n(NMSs). NMSs are very effective for a family of algorithms called spiking\nneural networks (SNNs). We present three SNNs to train topic models. The first\nSNN is a batch algorithm combining the conventional collapsed Gibbs sampling\n(CGS) algorithm and an inference SNN to train LDA. The other two SNNs are\nonline algorithms targeting at both energy- and storage-limited environments.\nThe two online algorithms are equivalent with training LDA by using\nmaximum-a-posterior estimation and maximizing the semi-collapsed likelihood,\nrespectively. They use novel, tailored ordinary differential equations for\nstochastic optimization. We simulate the new algorithms and show that they are\ncomparable with the GPC algorithms, while being suitable for NMS\nimplementation. We also propose an extension to train pLSI and a method to\nprune the network to obey the limited fan-in of some NMSs.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 15:01:50 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Xiao", "Zihao", ""], ["Chen", "Jianfei", ""], ["Zhu", "Jun", ""]]}, {"id": "1804.03599", "submitter": "Christopher Burgess", "authors": "Christopher P. Burgess, Irina Higgins, Arka Pal, Loic Matthey, Nick\n  Watters, Guillaume Desjardins, Alexander Lerchner", "title": "Understanding disentangling in $\\beta$-VAE", "comments": "Presented at the 2017 NIPS Workshop on Learning Disentangled\n  Representations", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new intuitions and theoretical assessments of the emergence of\ndisentangled representation in variational autoencoders. Taking a\nrate-distortion theory perspective, we show the circumstances under which\nrepresentations aligned with the underlying generative factors of variation of\ndata emerge when optimising the modified ELBO bound in $\\beta$-VAE, as training\nprogresses. From these insights, we propose a modification to the training\nregime of $\\beta$-VAE, that progressively increases the information capacity of\nthe latent code during training. This modification facilitates the robust\nlearning of disentangled representations in $\\beta$-VAE, without the previous\ntrade-off in reconstruction accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 15:48:18 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Burgess", "Christopher P.", ""], ["Higgins", "Irina", ""], ["Pal", "Arka", ""], ["Matthey", "Loic", ""], ["Watters", "Nick", ""], ["Desjardins", "Guillaume", ""], ["Lerchner", "Alexander", ""]]}, {"id": "1804.03615", "submitter": "Rong Zhu", "authors": "Rong Zhu and Jiming Jiang", "title": "Subsampled Optimization: Statistical Guarantees, Mean Squared Error\n  Approximation, and Sampling Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For optimization on large-scale data, exactly calculating its solution may be\ncomputationally difficulty because of the large size of the data. In this paper\nwe consider subsampled optimization for fast approximating the exact solution.\nIn this approach, one gets a surrogate dataset by sampling from the full data,\nand then obtains an approximate solution by solving the subsampled optimization\nbased on the surrogate. One main theoretical contributions are to provide the\nasymptotic properties of the approximate solution with respect to the exact\nsolution as statistical guarantees, and to rigorously derive an accurate\napproximation of the mean squared error (MSE) and an approximately unbiased MSE\nestimator. These results help us better diagnose the subsampled optimization in\nthe context that a confidence region on the exact solution is provided using\nthe approximate solution. The other consequence of our results is to propose an\noptimal sampling method, Hessian-based sampling, whose probabilities are\nproportional to the norms of Newton directions. Numerical experiments with\nleast-squares and logistic regression show promising performance, in line with\nour results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 16:18:10 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Zhu", "Rong", ""], ["Jiang", "Jiming", ""]]}, {"id": "1804.03629", "submitter": "Yeping Hu", "authors": "Yeping Hu, Wei Zhan, Masayoshi Tomizuka", "title": "Probabilistic Prediction of Vehicle Semantic Intention and Motion", "comments": "This paper has been submitted to the 2018 IEEE Intelligent Vehicles\n  (IV) Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately predicting the possible behaviors of traffic participants is an\nessential capability for future autonomous vehicles. The majority of current\nresearches fix the number of driving intentions by considering only a specific\nscenario. However, distinct driving environments usually contain various\npossible driving maneuvers. Therefore, a intention prediction method that can\nadapt to different traffic scenarios is needed. To further improve the overall\nvehicle prediction performance, motion information is usually incorporated with\nclassified intentions. As suggested in some literature, the methods that\ndirectly predict possible goal locations can achieve better performance for\nlong-term motion prediction than other approaches due to their automatic\nincorporation of environment constraints. Moreover, by obtaining the temporal\ninformation of the predicted destinations, the optimal trajectories for\npredicted vehicles as well as the desirable path for ego autonomous vehicle\ncould be easily generated. In this paper, we propose a Semantic-based Intention\nand Motion Prediction (SIMP) method, which can be adapted to any driving\nscenarios by using semantic-defined vehicle behaviors. It utilizes a\nprobabilistic framework based on deep neural network to estimate the\nintentions, final locations, and the corresponding time information for\nsurrounding vehicles. An exemplar real-world scenario was used to implement and\nexamine the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 17:05:53 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Hu", "Yeping", ""], ["Zhan", "Wei", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1804.03635", "submitter": "Ekaterina Lobacheva Ms", "authors": "Alexander Chistyakov, Ekaterina Lobacheva, Arseny Kuznetsov, Alexey\n  Romanenko", "title": "Semantic embeddings for program behavior patterns", "comments": "Published at Workshop track of ICLR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new feature extraction technique for program\nexecution logs. First, we automatically extract complex patterns from a\nprogram's behavior graph. Then, we embed these patterns into a continuous space\nby training an autoencoder. We evaluate the proposed features on a real-world\nmalicious software detection task. We also find that the embedding space\ncaptures interpretable structures in the space of pattern parts.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 17:26:54 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Chistyakov", "Alexander", ""], ["Lobacheva", "Ekaterina", ""], ["Kuznetsov", "Arseny", ""], ["Romanenko", "Alexey", ""]]}, {"id": "1804.03707", "submitter": "Shahab Asoodeh", "authors": "Shahab Asoodeh, Yi Huang, and Ishanu Chattopadhyay", "title": "A Tamper-Free Semi-Universal Communication System for Deletion Channels", "comments": "14 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of reliable communication between two legitimate\nparties over deletion channels under an active eavesdropping (aka jamming)\nadversarial model. To this goal, we develop a theoretical framework based on\nprobabilistic finite-state automata to define novel encoding and decoding\nschemes that ensure small error probability in both message decoding as well as\ntamper detecting. We then experimentally verify the reliability and\ntamper-detection property of our scheme.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 16:13:33 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Asoodeh", "Shahab", ""], ["Huang", "Yi", ""], ["Chattopadhyay", "Ishanu", ""]]}, {"id": "1804.03720", "submitter": "Alex Nichol", "authors": "Alex Nichol, Vicki Pfau, Christopher Hesse, Oleg Klimov, John Schulman", "title": "Gotta Learn Fast: A New Benchmark for Generalization in RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we present a new reinforcement learning (RL) benchmark based\non the Sonic the Hedgehog (TM) video game franchise. This benchmark is intended\nto measure the performance of transfer learning and few-shot learning\nalgorithms in the RL domain. We also present and evaluate some baseline\nalgorithms on the new benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 21:09:53 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 20:52:30 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Nichol", "Alex", ""], ["Pfau", "Vicki", ""], ["Hesse", "Christopher", ""], ["Klimov", "Oleg", ""], ["Schulman", "John", ""]]}, {"id": "1804.03728", "submitter": "Canyi Lu", "authors": "Canyi Lu, Jiashi Feng, Yudong Chen, Wei Liu, Zhouchen Lin, Shuicheng\n  Yan", "title": "Tensor Robust Principal Component Analysis with A New Tensor Nuclear\n  Norm", "comments": "arXiv admin note: text overlap with arXiv:1708.04181", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the Tensor Robust Principal Component Analysis\n(TRPCA) problem, which aims to exactly recover the low-rank and sparse\ncomponents from their sum. Our model is based on the recently proposed\ntensor-tensor product (or t-product). Induced by the t-product, we first\nrigorously deduce the tensor spectral norm, tensor nuclear norm, and tensor\naverage rank, and show that the tensor nuclear norm is the convex envelope of\nthe tensor average rank within the unit ball of the tensor spectral norm. These\ndefinitions, their relationships and properties are consistent with matrix\ncases. Equipped with the new tensor nuclear norm, we then solve the TRPCA\nproblem by solving a convex program and provide the theoretical guarantee for\nthe exact recovery. Our TRPCA model and recovery guarantee include matrix RPCA\nas a special case. Numerical experiments verify our results, and the\napplications to image recovery and background modeling problems demonstrate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 21:29:30 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 04:49:41 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Lu", "Canyi", ""], ["Feng", "Jiashi", ""], ["Chen", "Yudong", ""], ["Liu", "Wei", ""], ["Lin", "Zhouchen", ""], ["Yan", "Shuicheng", ""]]}, {"id": "1804.03740", "submitter": "Igor Fedorov", "authors": "Igor Fedorov, Bhaskar D. Rao", "title": "Multimodal Sparse Bayesian Dictionary Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of learning dictionaries for multimodal\ndatasets, i.e. datasets collected from multiple data sources. We present an\nalgorithm called multimodal sparse Bayesian dictionary learning (MSBDL). MSBDL\nleverages information from all available data modalities through a joint\nsparsity constraint. The underlying framework offers a considerable amount of\nflexibility to practitioners and addresses many of the shortcomings of existing\nmultimodal dictionary learning approaches. In particular, the procedure\nincludes the automatic tuning of hyperparameters and is unique in that it\nallows the dictionaries for each data modality to have different cardinality, a\nsignificant feature in cases when the dimensionality of data differs across\nmodalities. MSBDL is scalable and can be used in supervised learning settings.\nTheoretical results relating to the convergence of MSBDL are presented and the\nnumerical results provide evidence of the superior performance of MSBDL on\nsynthetic and real datasets compared to existing methods.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2018 22:27:21 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 00:30:44 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 01:54:44 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Fedorov", "Igor", ""], ["Rao", "Bhaskar D.", ""]]}, {"id": "1804.03758", "submitter": "Chen Ma", "authors": "Chen Ma, Junfeng Wen, Yoshua Bengio", "title": "Universal Successor Representations for Transfer Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of transfer reinforcement learning is to generalize from a set\nof previous tasks to unseen new tasks. In this work, we focus on the transfer\nscenario where the dynamics among tasks are the same, but their goals differ.\nAlthough general value function (Sutton et al., 2011) has been shown to be\nuseful for knowledge transfer, learning a universal value function can be\nchallenging in practice. To attack this, we propose (1) to use universal\nsuccessor representations (USR) to represent the transferable knowledge and (2)\na USR approximator (USRA) that can be trained by interacting with the\nenvironment. Our experiments show that USR can be effectively applied to new\ntasks, and the agent initialized by the trained USRA can achieve the goal\nconsiderably faster than random initialization.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 00:06:36 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Ma", "Chen", ""], ["Wen", "Junfeng", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1804.03761", "submitter": "Tatsunori Hashimoto", "authors": "Tatsunori B. Hashimoto, Steve Yadlowsky, John C. Duchi", "title": "Derivative free optimization via repeated classification", "comments": "At AISTATS2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an algorithm for minimizing a function using $n$ batched function\nvalue measurements at each of $T$ rounds by using classifiers to identify a\nfunction's sublevel set. We show that sufficiently accurate classifiers can\nachieve linear convergence rates, and show that the convergence rate is tied to\nthe difficulty of active learning sublevel sets. Further, we show that the\nbootstrap is a computationally efficient approximation to the necessary\nclassification scheme.\n  The end result is a computationally efficient derivative-free algorithm\nrequiring no tuning that consistently outperforms other approaches on\nsimulations, standard benchmarks, real-world DNA binding optimization, and\nairfoil design problems whenever batched function queries are natural.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 00:45:39 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Hashimoto", "Tatsunori B.", ""], ["Yadlowsky", "Steve", ""], ["Duchi", "John C.", ""]]}, {"id": "1804.03782", "submitter": "Sidi Lu", "authors": "Sidi Lu and Lantao Yu and Siyuan Feng and Yaoming Zhu and Weinan Zhang\n  and Yong Yu", "title": "CoT: Cooperative Training for Generative Modeling of Discrete Data", "comments": "Appearing as a Conference Paper on ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the generative models of sequential discrete data. To\ntackle the exposure bias problem inherent in maximum likelihood estimation\n(MLE), generative adversarial networks (GANs) are introduced to penalize the\nunrealistic generated samples. To exploit the supervision signal from the\ndiscriminator, most previous models leverage REINFORCE to address the\nnon-differentiable problem of sequential discrete data. However, because of the\nunstable property of the training signal during the dynamic process of\nadversarial training, the effectiveness of REINFORCE, in this case, is hardly\nguaranteed. To deal with such a problem, we propose a novel approach called\nCooperative Training (CoT) to improve the training of sequence generative\nmodels. CoT transforms the min-max game of GANs into a joint maximization\nframework and manages to explicitly estimate and optimize Jensen-Shannon\ndivergence. Moreover, CoT works without the necessity of pre-training via MLE,\nwhich is crucial to the success of previous methods. In the experiments,\ncompared to existing state-of-the-art methods, CoT shows superior or at least\ncompetitive performance on sample quality, diversity, as well as training\nstability.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 02:10:55 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 05:38:27 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 04:44:48 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Lu", "Sidi", ""], ["Yu", "Lantao", ""], ["Feng", "Siyuan", ""], ["Zhu", "Yaoming", ""], ["Zhang", "Weinan", ""], ["Yu", "Yong", ""]]}, {"id": "1804.03794", "submitter": "Yue Wang", "authors": "Yue Wang, Daniel Kifer, Jaewoo Lee", "title": "Differentially Private Confidence Intervals for Empirical Risk\n  Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of data mining with differential privacy produces results that\nare affected by two types of noise: sampling noise due to data collection and\nprivacy noise that is designed to prevent the reconstruction of sensitive\ninformation. In this paper, we consider the problem of designing confidence\nintervals for the parameters of a variety of differentially private machine\nlearning models. The algorithms can provide confidence intervals that satisfy\ndifferential privacy (as well as the more recently proposed concentrated\ndifferential privacy) and can be used with existing differentially private\nmechanisms that train models using objective perturbation and output\nperturbation.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 03:18:17 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Wang", "Yue", ""], ["Kifer", "Daniel", ""], ["Lee", "Jaewoo", ""]]}, {"id": "1804.03797", "submitter": "Chen Zhang", "authors": "Chen Zhang, Hao Yan, Seungho Lee, Jianjun Shi", "title": "Dynamic Multivariate Functional Data Modeling via Sparse Subspace\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate functional data from a complex system are naturally\nhigh-dimensional and have complex cross-correlation structure. The complexity\nof data structure can be observed as that (1) some functions are strongly\ncorrelated with similar features, while some others may have almost no\ncross-correlations with quite diverse features; and (2) the cross-correlation\nstructure may also change over time due to the system evolution. With this\nregard, this paper presents a dynamic subspace learning method for multivariate\nfunctional data modeling. In particular, we consider different functions come\nfrom different subspaces, and only functions of the same subspace have\ncross-correlations with each other. The subspaces can be automatically\nformulated and learned by reformatting the problem as a sparse regression. By\nallowing but regularizing the regression change over time, we can describe the\ncross-correlation dynamics. The model can be efficiently estimated by the fast\niterative shrinkage-thresholding algorithm (FISTA), and the features of every\nsubspace can be extracted using the smooth multi-channel functional PCA.\nNumerical studies together with case studies demonstrate the efficiency and\napplicability of the proposed methodology.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 03:32:16 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Zhang", "Chen", ""], ["Yan", "Hao", ""], ["Lee", "Seungho", ""], ["Shi", "Jianjun", ""]]}, {"id": "1804.03811", "submitter": "Jilei Yang", "authors": "Jilei Yang, Jie Peng", "title": "Estimating Time-Varying Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study time-varying graphical models based on data measured\nover a temporal grid. Such models are motivated by the needs to describe and\nunderstand evolving interacting relationships among a set of random variables\nin many real applications, for instance the study of how stocks interact with\neach other and how such interactions change over time.\n  We propose a new model, LOcal Group Graphical Lasso Estimation (loggle),\nunder the assumption that the graph topology changes gradually over time.\nSpecifically, loggle uses a novel local group-lasso type penalty to efficiently\nincorporate information from neighboring time points and to impose structural\nsmoothness of the graphs. We implement an ADMM based algorithm to fit the\nloggle model. This algorithm utilizes blockwise fast computation and\npseudo-likelihood approximation to improve computational efficiency. An R\npackage loggle has also been developed.\n  We evaluate the performance of loggle by simulation experiments. We also\napply loggle to S&P 500 stock price data and demonstrate that loggle is able to\nreveal the interacting relationships among stocks and among industrial sectors\nin a time period that covers the recent global financial crisis.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 04:54:56 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Yang", "Jilei", ""], ["Peng", "Jie", ""]]}, {"id": "1804.03836", "submitter": "Bamdev Mishra", "authors": "Anil R. Yelundur, Srinivasan H. Sengamedu and Bamdev Mishra", "title": "E-commerce Anomaly Detection: A Bayesian Semi-Supervised Tensor\n  Decomposition Approach using Natural Gradients", "comments": "Citations rendering", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly Detection has several important applications. In this paper, our\nfocus is on detecting anomalies in seller-reviewer data using tensor\ndecomposition. While tensor-decomposition is mostly unsupervised, we formulate\nBayesian semi-supervised tensor decomposition to take advantage of sparse\nlabeled data. In addition, we use Polya-Gamma data augmentation for the\nsemi-supervised Bayesian tensor decomposition. Finally, we show that the\nP\\'olya-Gamma formulation simplifies calculation of the Fisher information\nmatrix for partial natural gradient learning. Our experimental results show\nthat our semi-supervised approach outperforms state of the art unsupervised\nbaselines. And that the partial natural gradient learning outperforms\nstochastic gradient learning and Online-EM with sufficient statistics.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 06:55:06 GMT"}, {"version": "v2", "created": "Sat, 26 May 2018 18:15:42 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 08:47:20 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Yelundur", "Anil R.", ""], ["Sengamedu", "Srinivasan H.", ""], ["Mishra", "Bamdev", ""]]}, {"id": "1804.03958", "submitter": "Mark Kozdoba", "authors": "Mark Kozdoba, Shie Mannor", "title": "Interdependent Gibbs Samplers", "comments": "Added a reference to a previous work which considered a very similar\n  algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gibbs sampling, as a model learning method, is known to produce the most\naccurate results available in a variety of domains, and is a de facto standard\nin these domains. Yet, it is also well known that Gibbs random walks usually\nhave bottlenecks, sometimes termed \"local maxima\", and thus samplers often\nreturn suboptimal solutions. In this paper we introduce a variation of the\nGibbs sampler which yields high likelihood solutions significantly more often\nthan the regular Gibbs sampler.\n  Specifically, we show that combining multiple samplers, with certain\ndependence (coupling) between them, results in higher likelihood solutions.\nThis side-steps the well known issue of identifiability, which has been the\nobstacle to combining samplers in previous work. We evaluate the approach on a\nLatent Dirichlet Allocation model, and also on HMM's, where precise computation\nof likelihoods and comparisons to the standard EM algorithm are possible.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 12:38:50 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 08:47:13 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Kozdoba", "Mark", ""], ["Mannor", "Shie", ""]]}, {"id": "1804.03981", "submitter": "Muhammad Naveed Tabassum", "authors": "Muhammad Naveed Tabassum and Esa Ollila", "title": "Compressive Regularized Discriminant Analysis of High-Dimensional Data\n  with Applications to Microarray Studies", "comments": "5 pages, 2018 IEEE International Conference on Acoustics, Speech and\n  Signal Processing 15-20 April 2018 | Calgary, Alberta, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a modification of linear discriminant analysis, referred to as\ncompressive regularized discriminant analysis (CRDA), for analysis of\nhigh-dimensional datasets. CRDA is specially designed for feature elimination\npurpose and can be used as gene selection method in microarray studies. CRDA\nlends ideas from $\\ell_{q,1}$ norm minimization algorithms in the multiple\nmeasurement vectors (MMV) model and utilizes joint-sparsity promoting hard\nthresholding for feature elimination. A regularization of the sample covariance\nmatrix is also needed as we consider the challenging scenario where the number\nof features (variables) is comparable or exceeding the sample size of the\ntraining dataset. A simulation study and four examples of real-life microarray\ndatasets evaluate the performances of CRDA based classifiers. Overall, the\nproposed method gives fewer misclassification errors than its competitors,\nwhile at the same time achieving accurate feature selection.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 13:48:56 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Tabassum", "Muhammad Naveed", ""], ["Ollila", "Esa", ""]]}, {"id": "1804.03987", "submitter": "Husheng Li", "authors": "Husheng Li", "title": "Analysis on the Nonlinear Dynamics of Deep Neural Networks: Topological\n  Entropy and Chaos", "comments": "17 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theoretical explanation for deep neural network (DNN) is still an open\nproblem. In this paper DNN is considered as a discrete-time dynamical system\ndue to its layered structure. The complexity provided by the nonlinearity in\nthe dynamics is analyzed in terms of topological entropy and chaos\ncharacterized by Lyapunov exponents. The properties revealed for the dynamics\nof DNN are applied to analyze the corresponding capabilities of classification\nand generalization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 19:51:20 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 20:21:00 GMT"}, {"version": "v3", "created": "Tue, 8 Jan 2019 03:51:54 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Li", "Husheng", ""]]}, {"id": "1804.04012", "submitter": "Leshem Choshen", "authors": "Leshem Choshen and Lior Fox and Yonatan Loewenstein", "title": "DORA The Explorer: Directed Outreaching Reinforcement Action-Selection", "comments": "Final version for ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploration is a fundamental aspect of Reinforcement Learning, typically\nimplemented using stochastic action-selection. Exploration, however, can be\nmore efficient if directed toward gaining new world knowledge. Visit-counters\nhave been proven useful both in practice and in theory for directed\nexploration. However, a major limitation of counters is their locality. While\nthere are a few model-based solutions to this shortcoming, a model-free\napproach is still missing. We propose $E$-values, a generalization of counters\nthat can be used to evaluate the propagating exploratory value over\nstate-action trajectories. We compare our approach to commonly used RL\ntechniques, and show that using $E$-values improves learning and performance\nover traditional counters. We also show how our method can be implemented with\nfunction approximation to efficiently learn continuous MDPs. We demonstrate\nthis by showing that our approach surpasses state of the art performance in the\nFreeway Atari 2600 game.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 14:21:53 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Choshen", "Leshem", ""], ["Fox", "Lior", ""], ["Loewenstein", "Yonatan", ""]]}, {"id": "1804.04048", "submitter": "Chao Gan", "authors": "Chao Gan, Ruida Zhou, Jing Yang and Cong Shen", "title": "Cost-Aware Learning and Optimization for Opportunistic Spectrum Access", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate cost-aware joint learning and optimization for\nmulti-channel opportunistic spectrum access in a cognitive radio system. We\ninvestigate a discrete time model where the time axis is partitioned into\nframes. Each frame consists of a sensing phase, followed by a transmission\nphase. During the sensing phase, the user is able to sense a subset of channels\nsequentially before it decides to use one of them in the following transmission\nphase. We assume the channel states alternate between busy and idle according\nto independent Bernoulli random processes from frame to frame. To capture the\ninherent uncertainty in channel sensing, we assume the reward of each\ntransmission when the channel is idle is a random variable. We also associate\nrandom costs with sensing and transmission actions. Our objective is to\nunderstand how the costs and reward of the actions would affect the optimal\nbehavior of the user in both offline and online settings, and design the\ncorresponding opportunistic spectrum access strategies to maximize the expected\ncumulative net reward (i.e., reward-minus-cost). We start with an offline\nsetting where the statistics of the channel status, costs and reward are known\nbeforehand. We show that the the optimal policy exhibits a recursive double\nthreshold structure, and the user needs to compare the channel statistics with\nthose thresholds sequentially in order to decide its actions. With such\ninsights, we then study the online setting, where the statistical information\nof the channels, costs and reward are unknown a priori. We judiciously balance\nexploration and exploitation, and show that the cumulative regret scales in\nO(log T). We also establish a matched lower bound, which implies that our\nonline algorithm is order-optimal. Simulation results corroborate our\ntheoretical analysis.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 15:28:07 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Gan", "Chao", ""], ["Zhou", "Ruida", ""], ["Yang", "Jing", ""], ["Shen", "Cong", ""]]}, {"id": "1804.04058", "submitter": "Rizwan Sadiq", "authors": "Rizwan Sadiq, Mohsin Khan", "title": "Analyzing Self-Driving Cars on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies users' perception regarding a controversial product,\nnamely self-driving (autonomous) cars. To find people's opinion regarding this\nnew technology, we used an annotated Twitter dataset, and extracted the topics\nin positive and negative tweets using an unsupervised, probabilistic model\nknown as topic modeling. We later used the topics, as well as linguist and\nTwitter specific features to classify the sentiment of the tweets. Regarding\nthe opinions, the result of our analysis shows that people are optimistic and\nexcited about the future technology, but at the same time they find it\ndangerous and not reliable. For the classification task, we found Twitter\nspecific features, such as hashtags as well as linguistic features such as\nemphatic words among top attributes in classifying the sentiment of the tweets.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 23:31:44 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Sadiq", "Rizwan", ""], ["Khan", "Mohsin", ""]]}, {"id": "1804.04097", "submitter": "Laurent Schmalen", "authors": "Boris Karanov, Mathieu Chagnon, F\\'elix Thouin, Tobias A. Eriksson,\n  Henning B\\\"ulow, Domani\\c{c} Lavery, Polina Bayvel, Laurent Schmalen", "title": "End-to-end Deep Learning of Optical Fiber Communications", "comments": "submitted to IEEE/OSA Journal of Lightwave Technology", "journal-ref": "IEEE/OSA Journal of Lightwave Technology, vol. 36, no. 20, Oct.\n  2018", "doi": "10.1109/JLT.2018.2865109", "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we implement an optical fiber communication system as an\nend-to-end deep neural network, including the complete chain of transmitter,\nchannel model, and receiver. This approach enables the optimization of the\ntransceiver in a single end-to-end process. We illustrate the benefits of this\nmethod by applying it to intensity modulation/direct detection (IM/DD) systems\nand show that we can achieve bit error rates below the 6.7\\% hard-decision\nforward error correction (HD-FEC) threshold. We model all componentry of the\ntransmitter and receiver, as well as the fiber channel, and apply deep learning\nto find transmitter and receiver configurations minimizing the symbol error\nrate. We propose and verify in simulations a training method that yields robust\nand flexible transceivers that allow---without reconfiguration---reliable\ntransmission over a large range of link dispersions. The results from\nend-to-end deep learning are successfully verified for the first time in an\nexperiment. In particular, we achieve information rates of 42\\,Gb/s below the\nHD-FEC threshold at distances beyond 40\\,km. We find that our results\noutperform conventional IM/DD solutions based on 2 and 4 level pulse amplitude\nmodulation (PAM2/PAM4) with feedforward equalization (FFE) at the receiver. Our\nstudy is the first step towards end-to-end deep learning-based optimization of\noptical fiber communication systems.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 17:07:43 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 14:44:02 GMT"}, {"version": "v3", "created": "Fri, 3 Aug 2018 08:58:17 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Karanov", "Boris", ""], ["Chagnon", "Mathieu", ""], ["Thouin", "F\u00e9lix", ""], ["Eriksson", "Tobias A.", ""], ["B\u00fclow", "Henning", ""], ["Lavery", "Domani\u00e7", ""], ["Bayvel", "Polina", ""], ["Schmalen", "Laurent", ""]]}, {"id": "1804.04112", "submitter": "Jo\\~ao Gante", "authors": "Jo\\~ao Gante, Gabriel Falc\\~ao, and Leonel Sousa", "title": "Beamformed Fingerprint Learning for Accurate Millimeter Wave Positioning", "comments": "5 pages, 7 figures. Submitted to VTC2018-Fall (Chicago)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With millimeter wave wireless communications, the resulting radiation\nreflects on most visible objects, creating rich multipath environments, namely\nin urban scenarios. The radiation captured by a listening device is thus shaped\nby the obstacles encountered, which carry latent information regarding their\nrelative positions. In this paper, a system to convert the received millimeter\nwave radiation into the device's position is proposed, making use of the\naforementioned hidden information. Using deep learning techniques and a\npre-established codebook of beamforming patterns transmitted by a base station,\nthe simulations show that average estimation errors below 10 meters are\nachievable in realistic outdoors scenarios that contain mostly\nnon-line-of-sight positions, paving the way for new positioning systems.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 17:36:30 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Gante", "Jo\u00e3o", ""], ["Falc\u00e3o", "Gabriel", ""], ["Sousa", "Leonel", ""]]}, {"id": "1804.04118", "submitter": "Eshed Ohn-Bar", "authors": "Eshed Ohn-Bar and Kris Kitani and Chieko Asakawa", "title": "Personalized Dynamics Models for Adaptive Assistive Navigation Systems", "comments": "Oral Presentation in 2nd Conference on Robot Learning (CoRL, 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider an assistive system that guides visually impaired users through\nspeech and haptic feedback to their destination. Existing robotic and\nubiquitous navigation technologies (e.g., portable, ground, or wearable\nsystems) often operate in a generic, user-agnostic manner. However, to minimize\nconfusion and navigation errors, our real-world analysis reveals a crucial need\nto adapt the instructional guidance across different end-users with diverse\nmobility skills. To address this practical issue in scalable system design, we\npropose a novel model-based reinforcement learning framework for personalizing\nthe system-user interaction experience. When incrementally adapting the system\nto new users, we propose to use a weighted experts model for addressing\ndata-efficiency limitations in transfer learning with deep models. A real-world\ndataset of navigation by blind users is used to show that the proposed approach\nallows for (1) more accurate long-term human behavior prediction (up to 20\nseconds into the future) through improved reasoning over personal mobility\ncharacteristics, interaction with surrounding obstacles, and the current\nnavigation goal, and (2) quick adaptation at the onset of learning, when data\nis limited.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 17:55:00 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2018 12:20:33 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Ohn-Bar", "Eshed", ""], ["Kitani", "Kris", ""], ["Asakawa", "Chieko", ""]]}, {"id": "1804.04168", "submitter": "JinGuo Liu", "authors": "Jin-Guo Liu and Lei Wang", "title": "Differentiable Learning of Quantum Circuit Born Machine", "comments": "9 pages, 7 figures, Github page for code\n  https://github.com/GiggleLiu/QuantumCircuitBornMachine", "journal-ref": "Phys. Rev. A 98, 062324 (2018)", "doi": "10.1103/PhysRevA.98.062324", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum circuit Born machines are generative models which represent the\nprobability distribution of classical dataset as quantum pure states.\nComputational complexity considerations of the quantum sampling problem suggest\nthat the quantum circuits exhibit stronger expressibility compared to classical\nneural networks. One can efficiently draw samples from the quantum circuits via\nprojective measurements on qubits. However, similar to the leading implicit\ngenerative models in deep learning, such as the generative adversarial\nnetworks, the quantum circuits cannot provide the likelihood of the generated\nsamples, which poses a challenge to the training. We devise an efficient\ngradient-based learning algorithm for the quantum circuit Born machine by\nminimizing the kerneled maximum mean discrepancy loss. We simulated generative\nmodeling of the Bars-and-Stripes dataset and Gaussian mixture distributions\nusing deep quantum circuits. Our experiments show the importance of circuit\ndepth and gradient-based optimization algorithm. The proposed learning\nalgorithm is runnable on near-term quantum device and can exhibit quantum\nadvantages for generative modeling.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 19:01:11 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Liu", "Jin-Guo", ""], ["Wang", "Lei", ""]]}, {"id": "1804.04171", "submitter": "Christoph H. Lampert", "authors": "R\\'emy Sun and Christoph H. Lampert", "title": "KS(conf ): A Light-Weight Test if a ConvNet Operates Outside of Its\n  Specifications", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-12939-2_18", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision systems for automatic image categorization have become\naccurate and reliable enough that they can run continuously for days or even\nyears as components of real-world commercial applications. A major open problem\nin this context, however, is quality control. Good classification performance\ncan only be expected if systems run under the specific conditions, in\nparticular data distributions, that they were trained for. Surprisingly, none\nof the currently used deep network architectures has a built-in functionality\nthat could detect if a network operates on data from a distribution that it was\nnot trained for and potentially trigger a warning to the human users. In this\nwork, we describe KS(conf), a procedure for detecting such outside of the\nspecifications operation. Building on statistical insights, its main step is\nthe applications of a classical Kolmogorov-Smirnov test to the distribution of\npredicted confidence values. We show by extensive experiments using ImageNet,\nAwA2 and DAVIS data on a variety of ConvNets architectures that KS(conf)\nreliably detects out-of-specs situations. It furthermore has a number of\nproperties that make it an excellent candidate for practical deployment: it is\neasy to implement, adds almost no overhead to the system, works with all\nnetworks, including pretrained ones, and requires no a priori knowledge about\nhow the data distribution could change.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 19:05:51 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Sun", "R\u00e9my", ""], ["Lampert", "Christoph H.", ""]]}, {"id": "1804.04176", "submitter": "Zhiwei Xu", "authors": "Yonghong Tian, Zeyu Li, Zhiwei Xu, Xuying Meng, and Bing Zheng", "title": "Peeking the Impact of Points of Interests on Didi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the online car-hailing service, Didi, has emerged as a leader in\nthe sharing economy. Used by passengers and drivers extensive, it becomes\nincreasingly important for the car-hailing service providers to minimize the\nwaiting time of passengers and optimize the vehicle utilization, thus to\nimprove the overall user experience. Therefore, the supply-demand estimation is\nan indispensable ingredient of an efficient online car-hailing service. To\nimprove the accuracy of the estimation results, we analyze the implicit\nrelationships between the points of Interest (POI) and the supply-demand gap in\nthis paper. The different categories of POIs have positive or negative effects\non the estimation, we propose a POI selection scheme and incorporate it into\nXGBoost [1] to achieve more accurate estimation results. Our experiment\ndemonstrates our method provides more accurate estimation results and more\nstable estimation results than the existing methods.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2018 02:07:03 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Tian", "Yonghong", ""], ["Li", "Zeyu", ""], ["Xu", "Zhiwei", ""], ["Meng", "Xuying", ""], ["Zheng", "Bing", ""]]}, {"id": "1804.04205", "submitter": "Ziyi Zhao", "authors": "Ziyi Zhao, Krittaphat Pugdeethosapol, Sheng Lin, Zhe Li, Caiwen Ding,\n  Yanzhi Wang, Qinru Qiu", "title": "Learning Topics using Semantic Locality", "comments": "International Conference of Pattern Recognition (ICPR) in 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The topic modeling discovers the latent topic probability of the given text\ndocuments. To generate the more meaningful topic that better represents the\ngiven document, we proposed a new feature extraction technique which can be\nused in the data preprocessing stage. The method consists of three steps.\nFirst, it generates the word/word-pair from every single document. Second, it\napplies a two-way TF-IDF algorithm to word/word-pair for semantic filtering.\nThird, it uses the K-means algorithm to merge the word pairs that have the\nsimilar semantic meaning.\n  Experiments are carried out on the Open Movie Database (OMDb), Reuters\nDataset and 20NewsGroup Dataset. The mean Average Precision score is used as\nthe evaluation metric. Comparing our results with other state-of-the-art topic\nmodels, such as Latent Dirichlet allocation and traditional Restricted\nBoltzmann Machines. Our proposed data preprocessing can improve the generated\ntopic accuracy by up to 12.99\\%.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 20:23:23 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Zhao", "Ziyi", ""], ["Pugdeethosapol", "Krittaphat", ""], ["Lin", "Sheng", ""], ["Li", "Zhe", ""], ["Ding", "Caiwen", ""], ["Wang", "Yanzhi", ""], ["Qiu", "Qinru", ""]]}, {"id": "1804.04206", "submitter": "Boheng Zhang", "authors": "Boheng Zhang, Shenglei Huang, Shaohan Hu", "title": "Multi-scale Neural Networks for Retinal Blood Vessels Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing supervised approaches didn't make use of the low-level features\nwhich are actually effective to this task. And another deficiency is that they\ndidn't consider the relation between pixels, which means effective features are\nnot extracted. In this paper, we proposed a novel convolutional neural network\nwhich make sufficient use of low-level features together with high-level\nfeatures and involves atrous convolution to get multi-scale features which\nshould be considered as effective features. Our model is tested on three\nstandard benchmarks - DRIVE, STARE, and CHASE databases. The results presents\nthat our model significantly outperforms existing approaches in terms of\naccuracy, sensitivity, specificity, the area under the ROC curve and the\nhighest prediction speed. Our work provides evidence of the power of wide and\ndeep neural networks in retinal blood vessels segmentation task which could be\napplied on other medical images tasks.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 20:25:36 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Zhang", "Boheng", ""], ["Huang", "Shenglei", ""], ["Hu", "Shaohan", ""]]}, {"id": "1804.04212", "submitter": "Hugo Caselles-Dupr\\'e", "authors": "Hugo Caselles-Dupr\\'e, Florian Lesaint, Jimena Royo-Letelier", "title": "Word2Vec applied to Recommendation: Hyperparameters Matter", "comments": "This paper is published on the 12th ACM Conference on Recommender\n  Systems, Vancouver, Canada, 2nd-7th October 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Skip-gram with negative sampling, a popular variant of Word2vec originally\ndesigned and tuned to create word embeddings for Natural Language Processing,\nhas been used to create item embeddings with successful applications in\nrecommendation. While these fields do not share the same type of data, neither\nevaluate on the same tasks, recommendation applications tend to use the same\nalready tuned hyperparameters values, even if optimal hyperparameters values\nare often known to be data and task dependent. We thus investigate the marginal\nimportance of each hyperparameter in a recommendation setting through large\nhyperparameter grid searches on various datasets. Results reveal that\noptimizing neglected hyperparameters, namely negative sampling distribution,\nnumber of epochs, subsampling parameter and window-size, significantly improves\nperformance on a recommendation task, and can increase it by an order of\nmagnitude. Importantly, we find that optimal hyperparameters configurations for\nNatural Language Processing tasks and Recommendation tasks are noticeably\ndifferent.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 20:37:35 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 19:30:18 GMT"}, {"version": "v3", "created": "Wed, 29 Aug 2018 15:16:08 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Caselles-Dupr\u00e9", "Hugo", ""], ["Lesaint", "Florian", ""], ["Royo-Letelier", "Jimena", ""]]}, {"id": "1804.04235", "submitter": "Noam Shazeer", "authors": "Noam Shazeer and Mitchell Stern", "title": "Adafactor: Adaptive Learning Rates with Sublinear Memory Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In several recently proposed stochastic optimization methods (e.g. RMSProp,\nAdam, Adadelta), parameter updates are scaled by the inverse square roots of\nexponential moving averages of squared past gradients. Maintaining these\nper-parameter second-moment estimators requires memory equal to the number of\nparameters. For the case of neural network weight matrices, we propose\nmaintaining only the per-row and per-column sums of these moving averages, and\nestimating the per-parameter second moments based on these sums. We demonstrate\nempirically that this method produces similar results to the baseline.\nSecondly, we show that adaptive methods can produce larger-than-desired updates\nwhen the decay rate of the second moment accumulator is too slow. We propose\nupdate clipping and a gradually increasing decay rate scheme as remedies.\nCombining these methods and dropping momentum, we achieve comparable results to\nthe published Adam regime in training the Transformer model on the WMT 2014\nEnglish-German machine translation task, while using very little auxiliary\nstorage in the optimizer. Finally, we propose scaling the parameter updates\nbased on the scale of the parameters themselves.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 21:42:32 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Shazeer", "Noam", ""], ["Stern", "Mitchell", ""]]}, {"id": "1804.04241", "submitter": "Rodney LaLonde Iii", "authors": "Rodney LaLonde and Ulas Bagci", "title": "Capsules for Object Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) have shown remarkable results over the\nlast several years for a wide range of computer vision tasks. A new\narchitecture recently introduced by Sabour et al., referred to as a capsule\nnetworks with dynamic routing, has shown great initial results for digit\nrecognition and small image classification. The success of capsule networks\nlies in their ability to preserve more information about the input by replacing\nmax-pooling layers with convolutional strides and dynamic routing, allowing for\npreservation of part-whole relationships in the data. This preservation of the\ninput is demonstrated by reconstructing the input from the output capsule\nvectors. Our work expands the use of capsule networks to the task of object\nsegmentation for the first time in the literature. We extend the idea of\nconvolutional capsules with locally-connected routing and propose the concept\nof deconvolutional capsules. Further, we extend the masked reconstruction to\nreconstruct the positive input class. The proposed\nconvolutional-deconvolutional capsule network, called SegCaps, shows strong\nresults for the task of object segmentation with substantial decrease in\nparameter space. As an example application, we applied the proposed SegCaps to\nsegment pathological lungs from low dose CT scans and compared its accuracy and\nefficiency with other U-Net-based architectures. SegCaps is able to handle\nlarge image sizes (512 x 512) as opposed to baseline capsules (typically less\nthan 32 x 32). The proposed SegCaps reduced the number of parameters of U-Net\narchitecture by 95.4% while still providing a better segmentation accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 21:57:57 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["LaLonde", "Rodney", ""], ["Bagci", "Ulas", ""]]}, {"id": "1804.04262", "submitter": "Junichi Yamagishi Dr.", "authors": "Jaime Lorenzo-Trueba, Junichi Yamagishi, Tomoki Toda, Daisuke Saito,\n  Fernando Villavicencio, Tomi Kinnunen, Zhenhua Ling", "title": "The Voice Conversion Challenge 2018: Promoting Development of Parallel\n  and Nonparallel Methods", "comments": "Accepted for Speaker Odyssey 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the Voice Conversion Challenge 2018, designed as a follow up to\nthe 2016 edition with the aim of providing a common framework for evaluating\nand comparing different state-of-the-art voice conversion (VC) systems. The\nobjective of the challenge was to perform speaker conversion (i.e. transform\nthe vocal identity) of a source speaker to a target speaker while maintaining\nlinguistic information. As an update to the previous challenge, we considered\nboth parallel and non-parallel data to form the Hub and Spoke tasks,\nrespectively. A total of 23 teams from around the world submitted their\nsystems, 11 of them additionally participated in the optional Spoke task. A\nlarge-scale crowdsourced perceptual evaluation was then carried out to rate the\nsubmitted converted speech in terms of naturalness and similarity to the target\nspeaker identity. In this paper, we present a brief summary of the\nstate-of-the-art techniques for VC, followed by a detailed explanation of the\nchallenge tasks and the results that were obtained.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 00:14:10 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Lorenzo-Trueba", "Jaime", ""], ["Yamagishi", "Junichi", ""], ["Toda", "Tomoki", ""], ["Saito", "Daisuke", ""], ["Villavicencio", "Fernando", ""], ["Kinnunen", "Tomi", ""], ["Ling", "Zhenhua", ""]]}, {"id": "1804.04272", "submitter": "Lars Ruthotto", "authors": "Lars Ruthotto and Eldad Haber", "title": "Deep Neural Networks Motivated by Partial Differential Equations", "comments": "9 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial differential equations (PDEs) are indispensable for modeling many\nphysical phenomena and also commonly used for solving image processing tasks.\nIn the latter area, PDE-based approaches interpret image data as\ndiscretizations of multivariate functions and the output of image processing\nalgorithms as solutions to certain PDEs. Posing image processing problems in\nthe infinite dimensional setting provides powerful tools for their analysis and\nsolution. Over the last few decades, the reinterpretation of classical image\nprocessing problems through the PDE lens has been creating multiple celebrated\napproaches that benefit a vast area of tasks including image segmentation,\ndenoising, registration, and reconstruction.\n  In this paper, we establish a new PDE-interpretation of a class of deep\nconvolutional neural networks (CNN) that are commonly used to learn from\nspeech, image, and video data. Our interpretation includes convolution residual\nneural networks (ResNet), which are among the most promising approaches for\ntasks such as image classification having improved the state-of-the-art\nperformance in prestigious benchmark challenges. Despite their recent\nsuccesses, deep ResNets still face some critical challenges associated with\ntheir design, immense computational costs and memory requirements, and lack of\nunderstanding of their reasoning.\n  Guided by well-established PDE theory, we derive three new ResNet\narchitectures that fall into two new classes: parabolic and hyperbolic CNNs. We\ndemonstrate how PDE theory can provide new insights and algorithms for deep\nlearning and demonstrate the competitiveness of three new CNN architectures\nusing numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 01:40:55 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 21:51:10 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Ruthotto", "Lars", ""], ["Haber", "Eldad", ""]]}, {"id": "1804.04324", "submitter": "Makoto Naruse", "authors": "Makoto Naruse, Eiji Yamamoto, Takashi Nakao, Takuma Akimoto, Hayato\n  Saigo, Kazuya Okamura, Izumi Ojima, Georg Northoff, Hirokazu Hori", "title": "Local reservoir model for choice-based learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.data-an physics.optics q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making based on behavioral and neural observations of living systems\nhas been extensively studied in brain science, psychology, and other\ndisciplines. Decision-making mechanisms have also been experimentally\nimplemented in physical processes, such as single photons and chaotic lasers.\nThe findings of these experiments suggest that there is a certain common basis\nin describing decision making, regardless of its physical realizations. In this\nstudy, we propose a local reservoir model to account for choice-based learning\n(CBL). CBL describes decision consistency as a phenomenon where making a\ncertain decision increases the possibility of making that same decision again\nlater, which has been intensively investigated in neuroscience, psychology,\netc. Our proposed model is inspired by the viewpoint that a decision is\naffected by its local environment, which is referred to as a local reservoir.\nIf the size of the local reservoir is large enough, consecutive decision making\nwill not be affected by previous decisions, thus showing lower degrees of\ndecision consistency in CBL. In contrast, if the size of the local reservoir\ndecreases, a biased distribution occurs within it, which leads to higher\ndegrees of decision consistency in CBL. In this study, an analytical approach\non local reservoirs is presented, as well as several numerical demonstrations.\nFurthermore, a physical architecture for CBL based on single photons is\ndiscussed, and the effects of local reservoirs is numerically demonstrated.\nDecision consistency in human decision-making tasks and in recruiting empirical\ndata are evaluated based on local reservoir. In summary, the proposed local\nreservoir model paves a path toward establishing a foundation for computational\nmechanisms and the systematic analysis of decision making on different levels.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 05:35:14 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Naruse", "Makoto", ""], ["Yamamoto", "Eiji", ""], ["Nakao", "Takashi", ""], ["Akimoto", "Takuma", ""], ["Saigo", "Hayato", ""], ["Okamura", "Kazuya", ""], ["Ojima", "Izumi", ""], ["Northoff", "Georg", ""], ["Hori", "Hirokazu", ""]]}, {"id": "1804.04333", "submitter": "Mingming Gong", "authors": "Mingming Gong, Kun Zhang, Biwei Huang, Clark Glymour, Dacheng Tao,\n  Kayhan Batmanghelich", "title": "Causal Generative Domain Adaptation Networks", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An essential problem in domain adaptation is to understand and make use of\ndistribution changes across domains. For this purpose, we first propose a\nflexible Generative Domain Adaptation Network (G-DAN) with specific latent\nvariables to capture changes in the generating process of features across\ndomains. By explicitly modeling the changes, one can even generate data in new\ndomains using the generating process with new values for the latent variables\nin G-DAN. In practice, the process to generate all features together may\ninvolve high-dimensional latent variables, requiring dealing with distributions\nin high dimensions and making it difficult to learn domain changes from few\nsource domains. Interestingly, by further making use of the causal\nrepresentation of joint distributions, we then decompose the joint distribution\ninto separate modules, each of which involves different low-dimensional latent\nvariables and can be learned separately, leading to a Causal G-DAN (CG-DAN).\nThis improves both statistical and computational efficiency of the learning\nprocedure. Finally, by matching the feature distribution in the target domain,\nwe can recover the target-domain joint distribution and derive the learning\nmachine for the target domain. We demonstrate the efficacy of both G-DAN and\nCG-DAN in domain generation and cross-domain prediction on both synthetic and\nreal data experiments.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 06:10:46 GMT"}, {"version": "v2", "created": "Sat, 16 Jun 2018 21:49:19 GMT"}, {"version": "v3", "created": "Thu, 28 Jun 2018 06:38:11 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Gong", "Mingming", ""], ["Zhang", "Kun", ""], ["Huang", "Biwei", ""], ["Glymour", "Clark", ""], ["Tao", "Dacheng", ""], ["Batmanghelich", "Kayhan", ""]]}, {"id": "1804.04353", "submitter": "Rohith Aralikatti", "authors": "Rohith Aralikatti, Dilip Margam, Tanay Sharma, Thanda Abhinav, Shankar\n  M Venkatesan", "title": "Global SNR Estimation of Speech Signals using Entropy and Uncertainty\n  Estimates from Dropout Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates two novel methods to estimate the global SNR of\nspeech signals. In both methods, Deep Neural Network-Hidden Markov Model\n(DNN-HMM) acoustic model used in speech recognition systems is leveraged for\nthe additional task of SNR estimation. In the first method, the entropy of the\nDNN-HMM output is computed. Recent work on bayesian deep learning has shown\nthat a DNN-HMM trained with dropout can be used to estimate model uncertainty\nby approximating it as a deep Gaussian process. In the second method, this\napproximation is used to obtain model uncertainty estimates. Noise specific\nregressors are used to predict the SNR from the entropy and model uncertainty.\nThe DNN-HMM is trained on GRID corpus and tested on different noise profiles\nfrom the DEMAND noise database at SNR levels ranging from -10 dB to 30 dB.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 07:15:20 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Aralikatti", "Rohith", ""], ["Margam", "Dilip", ""], ["Sharma", "Tanay", ""], ["Abhinav", "Thanda", ""], ["Venkatesan", "Shankar M", ""]]}, {"id": "1804.04368", "submitter": "Henry Gouk", "authors": "Henry Gouk, Eibe Frank, Bernhard Pfahringer, Michael J. Cree", "title": "Regularisation of Neural Networks by Enforcing Lipschitz Continuity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate the effect of explicitly enforcing the Lipschitz continuity of\nneural networks with respect to their inputs. To this end, we provide a simple\ntechnique for computing an upper bound to the Lipschitz constant---for multiple\n$p$-norms---of a feed forward neural network composed of commonly used layer\ntypes. Our technique is then used to formulate training a neural network with a\nbounded Lipschitz constant as a constrained optimisation problem that can be\nsolved using projected stochastic gradient methods. Our evaluation study shows\nthat the performance of the resulting models exceeds that of models trained\nwith other common regularisers. We also provide evidence that the\nhyperparameters are intuitive to tune, demonstrate how the choice of norm for\ncomputing the Lipschitz constant impacts the resulting model, and show that the\nperformance gains provided by our method are particularly noticeable when only\na small amount of training data is available.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 08:18:30 GMT"}, {"version": "v2", "created": "Fri, 14 Sep 2018 16:53:04 GMT"}, {"version": "v3", "created": "Sun, 9 Aug 2020 16:47:10 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Gouk", "Henry", ""], ["Frank", "Eibe", ""], ["Pfahringer", "Bernhard", ""], ["Cree", "Michael J.", ""]]}, {"id": "1804.04378", "submitter": "Philippe Wenk", "authors": "Philippe Wenk, Alkis Gotovos, Stefan Bauer, Nico Gorbach, Andreas\n  Krause and Joachim M. Buhmann", "title": "Fast Gaussian Process Based Gradient Matching for Parameter\n  Identification in Systems of Nonlinear ODEs", "comments": "accepted at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter identification and comparison of dynamical systems is a challenging\ntask in many fields. Bayesian approaches based on Gaussian process regression\nover time-series data have been successfully applied to infer the parameters of\na dynamical system without explicitly solving it. While the benefits in\ncomputational cost are well established, a rigorous mathematical framework has\nbeen missing. We offer a novel interpretation which leads to a better\nunderstanding and improvements in state-of-the-art performance in terms of\naccuracy for nonlinear dynamical systems.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 08:54:20 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 16:06:03 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Wenk", "Philippe", ""], ["Gotovos", "Alkis", ""], ["Bauer", "Stefan", ""], ["Gorbach", "Nico", ""], ["Krause", "Andreas", ""], ["Buhmann", "Joachim M.", ""]]}, {"id": "1804.04380", "submitter": "Daniel Fleischer", "authors": "Alon Rozental, Daniel Fleischer", "title": "Amobee at SemEval-2018 Task 1: GRU Neural Network with a CNN Attention\n  Mechanism for Sentiment Classification", "comments": "8 pages, accepted to the 12th International Workshop on Semantic\n  Evaluation 2018", "journal-ref": null, "doi": "10.18653/v1/S18-1033", "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the participation of Amobee in the shared sentiment\nanalysis task at SemEval 2018. We participated in all the English sub-tasks and\nthe Spanish valence tasks. Our system consists of three parts: training\ntask-specific word embeddings, training a model consisting of\ngated-recurrent-units (GRU) with a convolution neural network (CNN) attention\nmechanism and training stacking-based ensembles for each of the sub-tasks. Our\nalgorithm reached 3rd and 1st places in the valence ordinal classification\nsub-tasks in English and Spanish, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 09:04:50 GMT"}], "update_date": "2019-05-07", "authors_parsed": [["Rozental", "Alon", ""], ["Fleischer", "Daniel", ""]]}, {"id": "1804.04421", "submitter": "Bruno Ordozgoiti", "authors": "Bruno Ordozgoiti, Alberto Mozo, Jes\\'us Garc\\'ia L\\'opez de Lacalle", "title": "Regularized Greedy Column Subset Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Column Subset Selection Problem provides a natural framework for\nunsupervised feature selection. Despite being a hard combinatorial optimization\nproblem, there exist efficient algorithms that provide good approximations. The\ndrawback of the problem formulation is that it incorporates no form of\nregularization, and is therefore very sensitive to noise when presented with\nscarce data. In this paper we propose a regularized formulation of this\nproblem, and derive a correct greedy algorithm that is similar in efficiency to\nexisting greedy methods for the unregularized problem. We study its adequacy\nfor feature selection and propose suitable formulations. Additionally, we\nderive a lower bound for the error of the proposed problems. Through various\nnumerical experiments on real and synthetic data, we demonstrate the\nsignificantly increased robustness and stability of our method, as well as the\nimproved conditioning of its output, all while remaining efficient for\npractical use.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 10:56:44 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Ordozgoiti", "Bruno", ""], ["Mozo", "Alberto", ""], ["de Lacalle", "Jes\u00fas Garc\u00eda L\u00f3pez", ""]]}, {"id": "1804.04435", "submitter": "Jiangchao Yao", "authors": "Jiangchao Yao, Ivor Tsang and Ya Zhang", "title": "Variational Composite Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in the latent variable model is challenging in the presence of the\ncomplex data structure or the intractable latent variable. Previous variational\nautoencoders can be low effective due to the straightforward encoder-decoder\nstructure. In this paper, we propose a variational composite autoencoder to\nsidestep this issue by amortizing on top of the hierarchical latent variable\nmodel. The experimental results confirm the advantages of our model.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 11:36:42 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Yao", "Jiangchao", ""], ["Tsang", "Ivor", ""], ["Zhang", "Ya", ""]]}, {"id": "1804.04438", "submitter": "Ari Morcos", "authors": "Avraham Ruderman, Neil C. Rabinowitz, Ari S. Morcos, Daniel Zoran", "title": "Pooling is neither necessary nor sufficient for appropriate deformation\n  stability in CNNs", "comments": "NIPS 2018 submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of our core assumptions about how neural networks operate remain\nempirically untested. One common assumption is that convolutional neural\nnetworks need to be stable to small translations and deformations to solve\nimage recognition tasks. For many years, this stability was baked into CNN\narchitectures by incorporating interleaved pooling layers. Recently, however,\ninterleaved pooling has largely been abandoned. This raises a number of\nquestions: Are our intuitions about deformation stability right at all? Is it\nimportant? Is pooling necessary for deformation invariance? If not, how is\ndeformation invariance achieved in its absence? In this work, we rigorously\ntest these questions, and find that deformation stability in convolutional\nnetworks is more nuanced than it first appears: (1) Deformation invariance is\nnot a binary property, but rather that different tasks require different\ndegrees of deformation stability at different layers. (2) Deformation stability\nis not a fixed property of a network and is heavily adjusted over the course of\ntraining, largely through the smoothness of the convolutional filters. (3)\nInterleaved pooling layers are neither necessary nor sufficient for achieving\nthe optimal form of deformation stability for natural image classification. (4)\nPooling confers too much deformation stability for image classification at\ninitialization, and during training, networks have to learn to counteract this\ninductive bias. Together, these findings provide new insights into the role of\ninterleaved pooling and deformation invariance in CNNs, and demonstrate the\nimportance of rigorous empirical testing of even our most basic assumptions\nabout the working of neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 11:44:05 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 13:03:50 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Ruderman", "Avraham", ""], ["Rabinowitz", "Neil C.", ""], ["Morcos", "Ari S.", ""], ["Zoran", "Daniel", ""]]}, {"id": "1804.04440", "submitter": "Neerav Karani", "authors": "Lin Zhang, Neerav Karani, Christine Tanner, Ender Konukoglu", "title": "Temporal Interpolation via Motion Field Prediction", "comments": "Submitted to 1st Conference on Medical Imaging with Deep Learning\n  (MIDL 2018), Amsterdam, The Netherlands", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Navigated 2D multi-slice dynamic Magnetic Resonance (MR) imaging enables high\ncontrast 4D MR imaging during free breathing and provides in-vivo observations\nfor treatment planning and guidance. Navigator slices are vital for\nretrospective stacking of 2D data slices in this method. However, they also\nprolong the acquisition sessions. Temporal interpolation of navigator slices an\nbe used to reduce the number of navigator acquisitions without degrading\nspecificity in stacking. In this work, we propose a convolutional neural\nnetwork (CNN) based method for temporal interpolation via motion field\nprediction. The proposed formulation incorporates the prior knowledge that a\nmotion field underlies changes in the image intensities over time. Previous\napproaches that interpolate directly in the intensity space are prone to\nproduce blurry images or even remove structures in the images. Our method\navoids such problems and faithfully preserves the information in the image.\nFurther, an important advantage of our formulation is that it provides an\nunsupervised estimation of bi-directional motion fields. We show that these\nmotion fields can be used to halve the number of registrations required during\n4D reconstruction, thus substantially reducing the reconstruction time.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 11:44:55 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Zhang", "Lin", ""], ["Karani", "Neerav", ""], ["Tanner", "Christine", ""], ["Konukoglu", "Ender", ""]]}, {"id": "1804.04448", "submitter": "Twan van Laarhoven", "authors": "Jeroen Manders, Twan van Laarhoven, Elena Marchiori", "title": "Adversarial Alignment of Class Prediction Uncertainties for Domain\n  Adaptation", "comments": "To appear in ICPRAM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider unsupervised domain adaptation: given labelled examples from a\nsource domain and unlabelled examples from a related target domain, the goal is\nto infer the labels of target examples. Under the assumption that features from\npre-trained deep neural networks are transferable across related domains,\ndomain adaptation reduces to aligning source and target domain at class\nprediction uncertainty level. We tackle this problem by introducing a method\nbased on adversarial learning which forces the label uncertainty predictions on\nthe target domain to be indistinguishable from those on the source domain.\nPre-trained deep neural networks are used to generate deep features having high\ntransferability across related domains. We perform an extensive experimental\nanalysis of the proposed method over a wide set of publicly available\npre-trained deep neural networks. Results of our experiments on domain\nadaptation tasks for image classification show that class prediction\nuncertainty alignment with features extracted from pre-trained deep neural\nnetworks provides an efficient, robust and effective method for domain\nadaptation.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 11:56:42 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 20:13:07 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Manders", "Jeroen", ""], ["van Laarhoven", "Twan", ""], ["Marchiori", "Elena", ""]]}, {"id": "1804.04452", "submitter": "Stefan Depeweg", "authors": "Stefan Depeweg, Constantin A. Rothkopf, Frank J\\\"akel", "title": "Solving Bongard Problems with a Visual Language and Pragmatic Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than 50 years ago Bongard introduced 100 visual concept learning\nproblems as a testbed for intelligent vision systems. These problems are now\nknown as Bongard problems. Although they are well known in the cognitive\nscience and AI communities only moderate progress has been made towards\nbuilding systems that can solve a substantial subset of them. In the system\npresented here, visual features are extracted through image processing and then\ntranslated into a symbolic visual vocabulary. We introduce a formal language\nthat allows representing complex visual concepts based on this vocabulary.\nUsing this language and Bayesian inference, complex visual concepts can be\ninduced from the examples that are provided in each Bongard problem. Contrary\nto other concept learning problems the examples from which concepts are induced\nare not random in Bongard problems, instead they are carefully chosen to\ncommunicate the concept, hence requiring pragmatic reasoning. Taking pragmatic\nreasoning into account we find good agreement between the concepts with high\nposterior probability and the solutions formulated by Bongard himself. While\nthis approach is far from solving all Bongard problems, it solves the biggest\nfraction yet.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 12:05:28 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Depeweg", "Stefan", ""], ["Rothkopf", "Constantin A.", ""], ["J\u00e4kel", "Frank", ""]]}, {"id": "1804.04458", "submitter": "Daniel Worrall", "authors": "Daniel Worrall and Gabriel Brostow", "title": "CubeNet: Equivariance to 3D Rotation and Translation", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D Convolutional Neural Networks are sensitive to transformations applied to\ntheir input. This is a problem because a voxelized version of a 3D object, and\nits rotated clone, will look unrelated to each other after passing through to\nthe last layer of a network. Instead, an idealized model would preserve a\nmeaningful representation of the voxelized object, while explaining the\npose-difference between the two inputs. An equivariant representation vector\nhas two components: the invariant identity part, and a discernable encoding of\nthe transformation. Models that can't explain pose-differences risk \"diluting\"\nthe representation, in pursuit of optimizing a classification or regression\nloss function.\n  We introduce a Group Convolutional Neural Network with linear equivariance to\ntranslations and right angle rotations in three dimensions. We call this\nnetwork CubeNet, reflecting its cube-like symmetry. By construction, this\nnetwork helps preserve a 3D shape's global and local signature, as it is\ntransformed through successive layers. We apply this network to a variety of 3D\ninference problems, achieving state-of-the-art on the ModelNet10 classification\nchallenge, and comparable performance on the ISBI 2012 Connectome Segmentation\nBenchmark. To the best of our knowledge, this is the first 3D rotation\nequivariant CNN for voxel representations.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 12:14:18 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Worrall", "Daniel", ""], ["Brostow", "Gabriel", ""]]}, {"id": "1804.04469", "submitter": "Twan van Laarhoven", "authors": "Twan van Laarhoven", "title": "Generative models for local network community detection", "comments": null, "journal-ref": "Phys. Rev. E 97, 042316 (2018)", "doi": "10.1103/PhysRevE.97.042316", "report-no": null, "categories": "cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local network community detection aims to find a single community in a large\nnetwork, while inspecting only a small part of that network around a given seed\nnode. This is much cheaper than finding all communities in a network. Most\nmethods for local community detection are formulated as ad-hoc optimization\nproblems. In this work, we instead start from a generative model for networks\nwith community structure. By assuming that the network is uniform, we can\napproximate the structure of unobserved parts of the network to obtain a method\nfor local community detection. We apply this local approximation technique to\ntwo variants of the stochastic block model. To our knowledge, this results in\nthe first local community detection methods based on probabilistic models.\nInterestingly, in the limit, one of the proposed approximations corresponds to\nconductance, a popular metric in this field. Experiments on real and synthetic\ndatasets show comparable or improved results compared to state-of-the-art local\ncommunity detection algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 12:34:57 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["van Laarhoven", "Twan", ""]]}, {"id": "1804.04503", "submitter": "Daniel Alabi", "authors": "Daniel Alabi, Nicole Immorlica, Adam Tauman Kalai", "title": "Unleashing Linear Optimizers for Group-Fair Learning and Optimization", "comments": "Accepted for presentation at the Conference on Learning Theory (COLT)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most systems and learning algorithms optimize average performance or average\nloss -- one reason being computational complexity. However, many objectives of\npractical interest are more complex than simply average loss. This arises, for\nexample, when balancing performance or loss with fairness across people. We\nprove that, from a computational perspective, optimizing arbitrary objectives\nthat take into account performance over a small number of groups is not\nsignificantly harder to optimize than average performance. Our main result is a\npolynomial-time reduction that uses a linear optimizer to optimize an arbitrary\n(Lipschitz continuous) function of performance over a (constant) number of\npossibly-overlapping groups. This includes fairness objectives over small\nnumbers of groups, and we further point out that other existing notions of\nfairness such as individual fairness can be cast as convex optimization and\nhence more standard convex techniques can be used. Beyond learning, our\napproach applies to multi-objective optimization, more generally.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 02:51:07 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 16:01:44 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Alabi", "Daniel", ""], ["Immorlica", "Nicole", ""], ["Kalai", "Adam Tauman", ""]]}, {"id": "1804.04512", "submitter": "Baptiste Wicht", "authors": "Baptiste Wicht and Jean Hennebert and Andreas Fischer", "title": "DLL: A Blazing Fast Deep Neural Network Library", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning Library (DLL) is a new library for machine learning with deep\nneural networks that focuses on speed. It supports feed-forward neural networks\nsuch as fully-connected Artificial Neural Networks (ANNs) and Convolutional\nNeural Networks (CNNs). It also has very comprehensive support for Restricted\nBoltzmann Machines (RBMs) and Convolutional RBMs. Our main motivation for this\nwork was to propose and evaluate novel software engineering strategies with\npotential to accelerate runtime for training and inference. Such strategies are\nmostly independent of the underlying deep learning algorithms. On three\ndifferent datasets and for four different neural network models, we compared\nDLL to five popular deep learning frameworks. Experimentally, it is shown that\nthe proposed framework is systematically and significantly faster on CPU and\nGPU. In terms of classification performance, similar accuracies as the other\nframeworks are reported.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2018 13:56:07 GMT"}], "update_date": "2018-04-15", "authors_parsed": [["Wicht", "Baptiste", ""], ["Hennebert", "Jean", ""], ["Fischer", "Andreas", ""]]}, {"id": "1804.04529", "submitter": "Panayotis Mertikopoulos", "authors": "E. Veronica Belmega, Panayotis Mertikopoulos, Romain Negrel, Luca\n  Sanguinetti", "title": "Online convex optimization and no-regret learning: Algorithms,\n  guarantees and applications", "comments": "34 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spurred by the enthusiasm surrounding the \"Big Data\" paradigm, the\nmathematical and algorithmic tools of online optimization have found widespread\nuse in problems where the trade-off between data exploration and exploitation\nplays a predominant role. This trade-off is of particular importance to several\nbranches and applications of signal processing, such as data mining,\nstatistical inference, multimedia indexing and wireless communications (to name\nbut a few). With this in mind, the aim of this tutorial paper is to provide a\ngentle introduction to online optimization and learning algorithms that are\nasymptotically optimal in hindsight - i.e., they approach the performance of a\nvirtual algorithm with unlimited computational power and full knowledge of the\nfuture, a property known as no-regret. Particular attention is devoted to\nidentifying the algorithms' theoretical performance guarantees and to establish\nlinks with classic optimization paradigms (both static and stochastic). To\nallow a better understanding of this toolbox, we provide several examples\nthroughout the tutorial ranging from metric learning to wireless resource\nallocation problems.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 14:22:35 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Belmega", "E. Veronica", ""], ["Mertikopoulos", "Panayotis", ""], ["Negrel", "Romain", ""], ["Sanguinetti", "Luca", ""]]}, {"id": "1804.04543", "submitter": "Aaron Lee", "authors": "Joanne C. Wen, Cecilia S. Lee, Pearse A. Keane, Sa Xiao, Yue Wu, Ariel\n  Rokem, Philip P. Chen, Aaron Y. Lee", "title": "Forecasting Future Humphrey Visual Fields Using Deep Learning", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0214875", "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: To determine if deep learning networks could be trained to forecast\na future 24-2 Humphrey Visual Field (HVF).\n  Participants: All patients who obtained a HVF 24-2 at the University of\nWashington.\n  Methods: All datapoints from consecutive 24-2 HVFs from 1998 to 2018 were\nextracted from a University of Washington database. Ten-fold cross validation\nwith a held out test set was used to develop the three main phases of model\ndevelopment: model architecture selection, dataset combination selection, and\ntime-interval model training with transfer learning, to train a deep learning\nartificial neural network capable of generating a point-wise visual field\nprediction.\n  Results: More than 1.7 million perimetry points were extracted to the\nhundredth decibel from 32,443 24-2 HVFs. The best performing model with 20\nmillion trainable parameters, CascadeNet-5, was selected. The overall MAE for\nthe test set was 2.47 dB (95% CI: 2.45 dB to 2.48 dB). The 100 fully trained\nmodels were able to successfully predict progressive field loss in glaucomatous\neyes up to 5.5 years in the future with a correlation of 0.92 between the MD of\npredicted and actual future HVF (p < 2.2 x 10 -16 ) and an average difference\nof 0.41 dB.\n  Conclusions: Using unfiltered real-world datasets, deep learning networks\nshow an impressive ability to not only learn spatio-temporal HVF changes but\nalso to generate predictions for future HVFs up to 5.5 years, given only a\nsingle HVF.\n", "versions": [{"version": "v1", "created": "Mon, 2 Apr 2018 21:05:22 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Wen", "Joanne C.", ""], ["Lee", "Cecilia S.", ""], ["Keane", "Pearse A.", ""], ["Xiao", "Sa", ""], ["Wu", "Yue", ""], ["Rokem", "Ariel", ""], ["Chen", "Philip P.", ""], ["Lee", "Aaron Y.", ""]]}, {"id": "1804.04563", "submitter": "Pierre-Antoine Ganaye", "authors": "Pierre-Antoine Ganaye, Micha\\\"el Sdika, Hugues Benoit-Cattin", "title": "Towards integrating spatial localization in convolutional neural\n  networks for brain image segmentation", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic segmentation is an established while rapidly evolving field in\nmedical imaging. In this paper we focus on the segmentation of brain Magnetic\nResonance Images (MRI) into cerebral structures using convolutional neural\nnetworks (CNN). CNNs achieve good performance by finding effective high\ndimensional image features describing the patch content only. In this work, we\npropose different ways to introduce spatial constraints into the network to\nfurther reduce prediction inconsistencies.\n  A patch based CNN architecture was trained, making use of multiple scales to\ngather contextual information. Spatial constraints were introduced within the\nCNN through a distance to landmarks feature or through the integration of a\nprobability atlas. We demonstrate experimentally that using spatial information\nhelps to reduce segmentation inconsistencies.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 15:20:48 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Ganaye", "Pierre-Antoine", ""], ["Sdika", "Micha\u00ebl", ""], ["Benoit-Cattin", "Hugues", ""]]}, {"id": "1804.04566", "submitter": "Carlo Vittorio Cannistraci", "authors": "Carlo Vittorio Cannistraci and Alessandro Muscoloni", "title": "Latent Geometry Inspired Graph Dissimilarities Enhance Affinity\n  Propagation Community Detection in Complex Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affinity propagation is one of the most effective unsupervised pattern\nrecognition algorithms for data clustering in high-dimensional feature space.\nHowever, the numerous attempts to test its performance for community detection\nin complex networks have been attaining results very far from the state of the\nart methods such as Infomap and Louvain. Yet, all these studies agreed that the\ncrucial problem is to convert the unweighted network topology in a\n'smart-enough' node dissimilarity matrix that is able to properly address the\nmessage passing procedure behind affinity propagation clustering. Here we\nintroduce a conceptual innovation and we discuss how to leverage network latent\ngeometry notions in order to design dissimilarity matrices for affinity\npropagation community detection. Our results demonstrate that the latent\ngeometry inspired dissimilarity measures we design bring affinity propagation\nto equal or outperform current state of the art methods for community\ndetection. These findings are solidly proven considering both synthetic\n'realistic' networks (with known ground-truth communities) and real networks\n(with community metadata), even when the data structure is corrupted by noise\nartificially induced by missing or spurious connectivity.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 15:23:39 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2018 13:55:56 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Cannistraci", "Carlo Vittorio", ""], ["Muscoloni", "Alessandro", ""]]}, {"id": "1804.04577", "submitter": "Dimitri Bertsekas", "authors": "Dimitri P. Bertsekas", "title": "Feature-Based Aggregation and Deep Reinforcement Learning: A Survey and\n  Some New Implementations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we discuss policy iteration methods for approximate solution of\na finite-state discounted Markov decision problem, with a focus on\nfeature-based aggregation methods and their connection with deep reinforcement\nlearning schemes. We introduce features of the states of the original problem,\nand we formulate a smaller \"aggregate\" Markov decision problem, whose states\nrelate to the features. We discuss properties and possible implementations of\nthis type of aggregation, including a new approach to approximate policy\niteration. In this approach the policy improvement operation combines\nfeature-based aggregation with feature construction using deep neural networks\nor other calculations. We argue that the cost function of a policy may be\napproximated much more accurately by the nonlinear function of the features\nprovided by aggregation, than by the linear function of the features provided\nby neural network-based reinforcement learning, thereby potentially leading to\nmore effective policy improvement.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 15:46:12 GMT"}, {"version": "v2", "created": "Sun, 22 Apr 2018 14:38:08 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 22:41:34 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Bertsekas", "Dimitri P.", ""]]}, {"id": "1804.04614", "submitter": "Amirhossein Javaheri", "authors": "Amirhossein Javaheri, Hadi Zayyani, Mario A. T. Figueiredo, Farrokh\n  Marvasti", "title": "Impulsive Noise Robust Sparse Recovery via Continuous Mixed Norm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the problem of sparse signal recovery in the presence\nof additive impulsive noise. The heavytailed impulsive noise is well modelled\nwith stable distributions. Since there is no explicit formulation for the\nprobability density function of $S\\alpha S$ distribution, alternative\napproximations like Generalized Gaussian Distribution (GGD) are used which\nimpose $\\ell_p$-norm fidelity on the residual error. In this paper, we exploit\na Continuous Mixed Norm (CMN) for robust sparse recovery instead of\n$\\ell_p$-norm. We show that in blind conditions, i.e., in case where the\nparameters of noise distribution are unknown, incorporating CMN can lead to\nnear optimal recovery. We apply Alternating Direction Method of Multipliers\n(ADMM) for solving the problem induced by utilizing CMN for robust sparse\nrecovery. In this approach, CMN is replaced with a surrogate function and\nMajorization-Minimization technique is incorporated to solve the problem.\nSimulation results confirm the efficiency of the proposed method compared to\nsome recent algorithms in the literature for impulsive noise robust sparse\nrecovery.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 16:40:07 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Javaheri", "Amirhossein", ""], ["Zayyani", "Hadi", ""], ["Figueiredo", "Mario A. T.", ""], ["Marvasti", "Farrokh", ""]]}, {"id": "1804.04622", "submitter": "Jovana Mitrovic", "authors": "Jovana Mitrovic, Dino Sejdinovic, Yee Whye Teh", "title": "Causal Inference via Kernel Deviance Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering the causal structure among a set of variables is a fundamental\nproblem in many areas of science. In this paper, we propose Kernel Conditional\nDeviance for Causal Inference (KCDC) a fully nonparametric causal discovery\nmethod based on purely observational data. From a novel interpretation of the\nnotion of asymmetry between cause and effect, we derive a corresponding\nasymmetry measure using the framework of reproducing kernel Hilbert spaces.\nBased on this, we propose three decision rules for causal discovery. We\ndemonstrate the wide applicability of our method across a range of diverse\nsynthetic datasets. Furthermore, we test our method on real-world time series\ndata and the real-world benchmark dataset Tubingen Cause-Effect Pairs where we\noutperform existing state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 16:51:04 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Mitrovic", "Jovana", ""], ["Sejdinovic", "Dino", ""], ["Teh", "Yee Whye", ""]]}, {"id": "1804.04640", "submitter": "Jaroslaw Zola", "authors": "Subhadeep Karan, Matthew Eichhorn, Blake Hurlburt, Grant Iraci,\n  Jaroslaw Zola", "title": "Fast Counting in Machine Learning Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose scalable methods to execute counting queries in machine learning\napplications. To achieve memory and computational efficiency, we abstract\ncounting queries and their context such that the counts can be aggregated as a\nstream. We demonstrate performance and scalability of the resulting approach on\nrandom queries, and through extensive experimentation using Bayesian networks\nlearning and association rule mining. Our methods significantly outperform\ncommonly used ADtrees and hash tables, and are practical alternatives for\nprocessing large-scale data.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 17:34:41 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 02:35:55 GMT"}, {"version": "v3", "created": "Mon, 7 Jan 2019 20:01:56 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Karan", "Subhadeep", ""], ["Eichhorn", "Matthew", ""], ["Hurlburt", "Blake", ""], ["Iraci", "Grant", ""], ["Zola", "Jaroslaw", ""]]}, {"id": "1804.04656", "submitter": "Taco Cohen", "authors": "Marysia Winkels, Taco S. Cohen", "title": "3D G-CNNs for Pulmonary Nodule Detection", "comments": null, "journal-ref": "International conference on Medical Imaging with Deep Learning,\n  2018", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) require a large amount of annotated data\nto learn from, which is often difficult to obtain in the medical domain. In\nthis paper we show that the sample complexity of CNNs can be significantly\nimproved by using 3D roto-translation group convolutions (G-Convs) instead of\nthe more conventional translational convolutions. These 3D G-CNNs were applied\nto the problem of false positive reduction for pulmonary nodule detection, and\nproved to be substantially more effective in terms of performance, sensitivity\nto malignant nodules, and speed of convergence compared to a strong and\ncomparable baseline architecture with regular convolutions, data augmentation\nand a similar number of parameters. For every dataset size tested, the G-CNN\nachieved a FROC score close to the CNN trained on ten times more data.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 12:02:36 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Winkels", "Marysia", ""], ["Cohen", "Taco S.", ""]]}, {"id": "1804.04659", "submitter": "Daning Cheng", "authors": "Cheng Daning, Xia Fen, Li Shigang, Zhang Yunquan", "title": "Asynch-SGBDT: Asynchronous Parallel Stochastic Gradient Boosting\n  Decision Tree based on Parameters Server", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In AI research and industry, machine learning is the most widely used tool.\nOne of the most important machine learning algorithms is Gradient Boosting\nDecision Tree, i.e. GBDT whose training process needs considerable\ncomputational resources and time. To shorten GBDT training time, many works\ntried to apply GBDT on Parameter Server. However, those GBDT algorithms are\nsynchronous parallel algorithms which fail to make full use of Parameter\nServer. In this paper, we examine the possibility of using asynchronous\nparallel methods to train GBDT model and name this algorithm as asynch-SGBDT\n(asynchronous parallel stochastic gradient boosting decision tree). Our\ntheoretical and experimental results indicate that the scalability of\nasynch-SGBDT is influenced by the sample diversity of datasets, sampling rate,\nstep length and the setting of GBDT tree. Experimental results also show\nasynch-SGBDT training process reaches a linear speedup in asynchronous parallel\nmanner when datasets and GBDT trees meet high scalability requirements.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 14:06:05 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 04:26:26 GMT"}, {"version": "v3", "created": "Fri, 17 Aug 2018 01:57:44 GMT"}, {"version": "v4", "created": "Thu, 18 Jul 2019 06:50:05 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Daning", "Cheng", ""], ["Fen", "Xia", ""], ["Shigang", "Li", ""], ["Yunquan", "Zhang", ""]]}, {"id": "1804.04725", "submitter": "Khalique Newaz", "authors": "Khalique Newaz, Mahboobeh Ghalehnovi, Arash Rahnama, Panos J.\n  Antsaklis and Tijana Milenkovic", "title": "Network-based protein structural classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental determination of protein function is resource-consuming. As an\nalternative, computational prediction of protein function has received\nattention. In this context, protein structural classification (PSC) can help,\nby allowing for determining structural classes of currently unclassified\nproteins based on their features, and then relying on the fact that proteins\nwith similar structures have similar functions. Existing PSC approaches rely on\nsequence-based or direct 3-dimensional (3D) structure-based protein features.\nIn contrast, we first model 3D structures of proteins as protein structure\nnetworks (PSNs). Then, we use network-based features for PSC. We propose the\nuse of graphlets, state-of-the-art features in many research areas of network\nscience, in the task of PSC. Moreover, because graphlets can deal only with\nunweighted PSNs, and because accounting for edge weights when constructing PSNs\ncould improve PSC accuracy, we also propose a deep learning framework that\nautomatically learns network features from weighted PSNs. When evaluated on a\nlarge set of ~9,400 CATH and ~12,800 SCOP protein domains (spanning 36 PSN\nsets), our proposed approaches are superior to existing PSC approaches in terms\nof accuracy, with comparable running time.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 20:55:26 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 01:54:52 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 17:56:40 GMT"}, {"version": "v4", "created": "Fri, 23 Aug 2019 17:03:07 GMT"}, {"version": "v5", "created": "Wed, 13 Nov 2019 17:06:14 GMT"}, {"version": "v6", "created": "Fri, 6 Mar 2020 23:28:32 GMT"}, {"version": "v7", "created": "Sun, 15 Mar 2020 18:48:27 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Newaz", "Khalique", ""], ["Ghalehnovi", "Mahboobeh", ""], ["Rahnama", "Arash", ""], ["Antsaklis", "Panos J.", ""], ["Milenkovic", "Tijana", ""]]}, {"id": "1804.04732", "submitter": "Xun Huang", "authors": "Xun Huang, Ming-Yu Liu, Serge Belongie, Jan Kautz", "title": "Multimodal Unsupervised Image-to-Image Translation", "comments": "Accepted by ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised image-to-image translation is an important and challenging\nproblem in computer vision. Given an image in the source domain, the goal is to\nlearn the conditional distribution of corresponding images in the target\ndomain, without seeing any pairs of corresponding images. While this\nconditional distribution is inherently multimodal, existing approaches make an\noverly simplified assumption, modeling it as a deterministic one-to-one\nmapping. As a result, they fail to generate diverse outputs from a given source\ndomain image. To address this limitation, we propose a Multimodal Unsupervised\nImage-to-image Translation (MUNIT) framework. We assume that the image\nrepresentation can be decomposed into a content code that is domain-invariant,\nand a style code that captures domain-specific properties. To translate an\nimage to another domain, we recombine its content code with a random style code\nsampled from the style space of the target domain. We analyze the proposed\nframework and establish several theoretical results. Extensive experiments with\ncomparisons to the state-of-the-art approaches further demonstrates the\nadvantage of the proposed framework. Moreover, our framework allows users to\ncontrol the style of translation outputs by providing an example style image.\nCode and pretrained models are available at https://github.com/nvlabs/MUNIT\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 21:17:54 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 18:44:12 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Huang", "Xun", ""], ["Liu", "Ming-Yu", ""], ["Belongie", "Serge", ""], ["Kautz", "Jan", ""]]}, {"id": "1804.04758", "submitter": "Takuma Oda", "authors": "Takuma Oda and Carlee Joe-Wong", "title": "MOVI: A Model-Free Approach to Dynamic Fleet Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern vehicle fleets, e.g., for ridesharing platforms and taxi companies,\ncan reduce passengers' waiting times by proactively dispatching vehicles to\nlocations where pickup requests are anticipated in the future. Yet it is\nunclear how to best do this: optimal dispatching requires optimizing over\nseveral sources of uncertainty, including vehicles' travel times to their\ndispatched locations, as well as coordinating between vehicles so that they do\nnot attempt to pick up the same passenger. While prior works have developed\nmodels for this uncertainty and used them to optimize dispatch policies, in\nthis work we introduce a model-free approach. Specifically, we propose MOVI, a\nDeep Q-network (DQN)-based framework that directly learns the optimal vehicle\ndispatch policy. Since DQNs scale poorly with a large number of possible\ndispatches, we streamline our DQN training and suppose that each individual\nvehicle independently learns its own optimal policy, ensuring scalability at\nthe cost of less coordination between vehicles. We then formulate a centralized\nreceding-horizon control (RHC) policy to compare with our DQN policies. To\ncompare these policies, we design and build MOVI as a large-scale realistic\nsimulator based on 15 million taxi trip records that simulates policy-agnostic\nresponses to dispatch decisions. We show that the DQN dispatch policy reduces\nthe number of unserviced requests by 76% compared to without dispatch and 20%\ncompared to the RHC approach, emphasizing the benefits of a model-free approach\nand suggesting that there is limited value to coordinating vehicle actions.\nThis finding may help to explain the success of ridesharing platforms, for\nwhich drivers make individual decisions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 00:54:22 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Oda", "Takuma", ""], ["Joe-Wong", "Carlee", ""]]}, {"id": "1804.04775", "submitter": "Connie Kou", "authors": "Connie Kou, Hwee Kuan Lee, Teck Khim Ng", "title": "A Compact Network Learning Model for Distribution Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the superior performance of deep learning in many applications,\nchallenges remain in the area of regression on function spaces. In particular,\nneural networks are unable to encode function inputs compactly as each node\nencodes just a real value. We propose a novel idea to address this shortcoming:\nto encode an entire function in a single network node. To that end, we design a\ncompact network representation that encodes and propagates functions in single\nnodes for the distribution regression task. Our proposed Distribution\nRegression Network (DRN) achieves higher prediction accuracies while being much\nmore compact and uses fewer parameters than traditional neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 02:31:10 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 05:38:54 GMT"}, {"version": "v3", "created": "Tue, 10 Jul 2018 08:24:19 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Kou", "Connie", ""], ["Lee", "Hwee Kuan", ""], ["Ng", "Teck Khim", ""]]}, {"id": "1804.04778", "submitter": "Chihiro Watanabe", "authors": "Chihiro Watanabe, Kaoru Hiramatsu, Kunio Kashino", "title": "Understanding Community Structure in Layered Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A layered neural network is now one of the most common choices for the\nprediction of high-dimensional practical data sets, where the relationship\nbetween input and output data is complex and cannot be represented well by\nsimple conventional models. Its effectiveness is shown in various tasks,\nhowever, the lack of interpretability of the trained result by a layered neural\nnetwork has limited its application area.\n  In our previous studies, we proposed methods for extracting a simplified\nglobal structure of a trained layered neural network by classifying the units\ninto communities according to their connection patterns with adjacent layers.\nThese methods provided us with knowledge about the strength of the relationship\nbetween communities from the existence of bundled connections, which are\ndetermined by threshold processing of the connection ratio between pairs of\ncommunities.\n  However, it has been difficult to understand the role of each community\nquantitatively by observing the modular structure. We could only know to which\nsets of the input and output dimensions each community was mainly connected, by\ntracing the bundled connections from the community to the input and output\nlayers. Another problem is that the finally obtained modular structure is\nchanged greatly depending on the setting of the threshold hyperparameter used\nfor determining bundled connections.\n  In this paper, we propose a new method for interpreting quantitatively the\nrole of each community in inference, by defining the effect of each input\ndimension on a community, and the effect of a community on each output\ndimension. We show experimentally that our proposed method can reveal the role\nof each part of a layered neural network by applying the neural networks to\nthree types of data sets, extracting communities from the trained network, and\napplying the proposed method to the community structure.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 03:10:00 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Watanabe", "Chihiro", ""], ["Hiramatsu", "Kaoru", ""], ["Kashino", "Kunio", ""]]}, {"id": "1804.04780", "submitter": "Bowei Xi", "authors": "Wutao Wei, Bowei Xi, Murat Kantarcioglu", "title": "Adversarial Clustering: A Grid Based Clustering Algorithm Against Active\n  Adversaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays more and more data are gathered for detecting and preventing cyber\nattacks. In cyber security applications, data analytics techniques have to deal\nwith active adversaries that try to deceive the data analytics models and avoid\nbeing detected. The existence of such adversarial behavior motivates the\ndevelopment of robust and resilient adversarial learning techniques for various\ntasks. Most of the previous work focused on adversarial classification\ntechniques, which assumed the existence of a reasonably large amount of\ncarefully labeled data instances. However, in practice, labeling the data\ninstances often requires costly and time-consuming human expertise and becomes\na significant bottleneck. Meanwhile, a large number of unlabeled instances can\nalso be used to understand the adversaries' behavior. To address the above\nmentioned challenges, in this paper, we develop a novel grid based adversarial\nclustering algorithm. Our adversarial clustering algorithm is able to identify\nthe core normal regions, and to draw defensive walls around the centers of the\nnormal objects utilizing game theoretic ideas. Our algorithm also identifies\nsub-clusters of attack objects, the overlapping areas within clusters, and\noutliers which may be potential anomalies.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 04:06:37 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Wei", "Wutao", ""], ["Xi", "Bowei", ""], ["Kantarcioglu", "Murat", ""]]}, {"id": "1804.04791", "submitter": "Vishnu Menon", "authors": "Vishnu Menon, Sheetal Kalyani", "title": "Fast, Parameter free Outlier Identification for Robust PCA", "comments": "13 pages. Submitted to IEEE JSTSP Special Issue on Data Science:\n  Robust Subspace Learning and Tracking: Theory, Algorithms, and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust PCA, the problem of PCA in the presence of outliers has been\nextensively investigated in the last few years. Here we focus on Robust PCA in\nthe column sparse outlier model. The existing methods for column sparse outlier\nmodel assumes either the knowledge of the dimension of the lower dimensional\nsubspace or the fraction of outliers in the system. However in many\napplications knowledge of these parameters is not available. Motivated by this\nwe propose a parameter free outlier identification method for robust PCA which\na) does not require the knowledge of outlier fraction, b) does not require the\nknowledge of the dimension of the underlying subspace, c) is computationally\nsimple and fast. Further, analytical guarantees are derived for outlier\nidentification and the performance of the algorithm is compared with the\nexisting state of the art methods.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 05:35:19 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Menon", "Vishnu", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "1804.04806", "submitter": "Yosuke Oyama", "authors": "Yosuke Oyama, Tal Ben-Nun, Torsten Hoefler, Satoshi Matsuoka", "title": "{\\mu}-cuDNN: Accelerating Deep Learning Frameworks with Micro-Batching", "comments": "11 pages, 14 figures. Part of the content have been published in IPSJ\n  SIG Technical Report, Vol. 2017-HPC-162, No. 22, pp. 1-9, 2017. (DOI:\n  http://id.nii.ac.jp/1001/00184814)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MS cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NVIDIA cuDNN is a low-level library that provides GPU kernels frequently used\nin deep learning. Specifically, cuDNN implements several equivalent convolution\nalgorithms, whose performance and memory footprint may vary considerably,\ndepending on the layer dimensions. When an algorithm is automatically selected\nby cuDNN, the decision is performed on a per-layer basis, and thus it often\nresorts to slower algorithms that fit the workspace size constraints. We\npresent {\\mu}-cuDNN, a transparent wrapper library for cuDNN, which divides\nlayers' mini-batch computation into several micro-batches. Based on Dynamic\nProgramming and Integer Linear Programming, {\\mu}-cuDNN enables faster\nalgorithms by decreasing the workspace requirements. At the same time,\n{\\mu}-cuDNN keeps the computational semantics unchanged, so that it decouples\nstatistical efficiency from the hardware efficiency safely. We demonstrate the\neffectiveness of {\\mu}-cuDNN over two frameworks, Caffe and TensorFlow,\nachieving speedups of 1.63x for AlexNet and 1.21x for ResNet-18 on P100-SXM2\nGPU. These results indicate that using micro-batches can seamlessly increase\nthe performance of deep learning, while maintaining the same memory footprint.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 07:20:44 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Oyama", "Yosuke", ""], ["Ben-Nun", "Tal", ""], ["Hoefler", "Torsten", ""], ["Matsuoka", "Satoshi", ""]]}, {"id": "1804.04849", "submitter": "Jos van der Westhuizen", "authors": "Jos van der Westhuizen and Joan Lasenby", "title": "The unreasonable effectiveness of the forget gate", "comments": "Corrected LSTM gradient derivations. Added link to code", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the success of the gated recurrent unit, a natural question is whether\nall the gates of the long short-term memory (LSTM) network are necessary.\nPrevious research has shown that the forget gate is one of the most important\ngates in the LSTM. Here we show that a forget-gate-only version of the LSTM\nwith chrono-initialized biases, not only provides computational savings but\noutperforms the standard LSTM on multiple benchmark datasets and competes with\nsome of the best contemporary models. Our proposed network, the JANET, achieves\naccuracies of 99% and 92.5% on the MNIST and pMNIST datasets, outperforming the\nstandard LSTM which yields accuracies of 98.5% and 91%.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 09:18:17 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 17:23:40 GMT"}, {"version": "v3", "created": "Thu, 13 Sep 2018 10:55:56 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["van der Westhuizen", "Jos", ""], ["Lasenby", "Joan", ""]]}, {"id": "1804.04878", "submitter": "Vikas Sindhwani", "authors": "Vikas Sindhwani, Stephen Tu and Mohi Khansari", "title": "Learning Contracting Vector Fields For Stable Imitation Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new non-parametric framework for learning incrementally stable\ndynamical systems x' = f(x) from a set of sampled trajectories. We construct a\nrich family of smooth vector fields induced by certain classes of matrix-valued\nkernels, whose equilibria are placed exactly at a desired set of locations and\nwhose local contraction and curvature properties at various points can be\nexplicitly controlled using convex optimization. With curl-free kernels, our\nframework may also be viewed as a mechanism to learn potential fields and\ngradient flows. We develop large-scale techniques using randomized kernel\napproximations in this context. We demonstrate our approach, called contracting\nvector fields (CVF), on imitation learning tasks involving complex\npoint-to-point human handwriting motions.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 10:40:45 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Sindhwani", "Vikas", ""], ["Tu", "Stephen", ""], ["Khansari", "Mohi", ""]]}, {"id": "1804.04888", "submitter": "Minh Nghia Nguyen", "authors": "Minh-Nghia Nguyen and Ngo Anh Vien", "title": "Scalable and Interpretable One-class SVMs with Deep Learning and Random\n  Fourier features", "comments": "Accepted at European Conference on Machine Learning and Principles\n  and Practice of Knowledge Discovery in Databases (ECML-PKDD) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One-class support vector machine (OC-SVM) for a long time has been one of the\nmost effective anomaly detection methods and extensively adopted in both\nresearch as well as industrial applications. The biggest issue for OC-SVM is\nyet the capability to operate with large and high-dimensional datasets due to\noptimization complexity. Those problems might be mitigated via dimensionality\nreduction techniques such as manifold learning or autoencoder. However,\nprevious work often treats representation learning and anomaly prediction\nseparately. In this paper, we propose autoencoder based one-class support\nvector machine (AE-1SVM) that brings OC-SVM, with the aid of random Fourier\nfeatures to approximate the radial basis kernel, into deep learning context by\ncombining it with a representation learning architecture and jointly exploit\nstochastic gradient descent to obtain end-to-end training. Interestingly, this\nalso opens up the possible use of gradient-based attribution methods to explain\nthe decision making for anomaly detection, which has ever been challenging as a\nresult of the implicit mappings between the input space and the kernel space.\nTo the best of our knowledge, this is the first work to study the\ninterpretability of deep learning in anomaly detection. We evaluate our method\non a wide range of unsupervised anomaly detection tasks in which our end-to-end\ntraining architecture achieves a performance significantly better than the\nprevious work using separate training.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 11:24:33 GMT"}, {"version": "v2", "created": "Sun, 14 Oct 2018 09:15:10 GMT"}], "update_date": "2018-10-16", "authors_parsed": [["Nguyen", "Minh-Nghia", ""], ["Vien", "Ngo Anh", ""]]}, {"id": "1804.04918", "submitter": "Chaochao Chen", "authors": "Chaochao Chen, Ziqi Liu, Peilin Zhao, Longfei Li, Jun Zhou, Xiaolong\n  Li", "title": "Distributed Collaborative Hashing and Its Applications in Ant Financial", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering, especially latent factor model, has been popularly\nused in personalized recommendation. Latent factor model aims to learn user and\nitem latent factors from user-item historic behaviors. To apply it into real\nbig data scenarios, efficiency becomes the first concern, including offline\nmodel training efficiency and online recommendation efficiency. In this paper,\nwe propose a Distributed Collaborative Hashing (DCH) model which can\nsignificantly improve both efficiencies. Specifically, we first propose a\ndistributed learning framework, following the state-of-the-art parameter server\nparadigm, to learn the offline collaborative model. Our model can be learnt\nefficiently by distributedly computing subgradients in minibatches on workers\nand updating model parameters on servers asynchronously. We then adopt hashing\ntechnique to speedup the online recommendation procedure. Recommendation can be\nquickly made through exploiting lookup hash tables. We conduct thorough\nexperiments on two real large-scale datasets. The experimental results\ndemonstrate that, comparing with the classic and state-of-the-art (distributed)\nlatent factor models, DCH has comparable performance in terms of recommendation\naccuracy but has both fast convergence speed in offline model training\nprocedure and realtime efficiency in online recommendation procedure.\nFurthermore, the encouraging performance of DCH is also shown for several\nreal-world applications in Ant Financial.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 12:37:51 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 03:21:25 GMT"}, {"version": "v3", "created": "Thu, 31 May 2018 03:52:47 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Chen", "Chaochao", ""], ["Liu", "Ziqi", ""], ["Zhao", "Peilin", ""], ["Li", "Longfei", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""]]}, {"id": "1804.04950", "submitter": "Huifeng Guo", "authors": "Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, Xiuqiang He, and\n  Zhenhua Dong", "title": "DeepFM: An End-to-End Wide & Deep Learning Framework for CTR Prediction", "comments": "14 pages. arXiv admin note: text overlap with arXiv:1703.04247", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning sophisticated feature interactions behind user behaviors is critical\nin maximizing CTR for recommender systems. Despite great progress, existing\nmethods have a strong bias towards low- or high-order interactions, or rely on\nexpertise feature engineering. In this paper, we show that it is possible to\nderive an end-to-end learning model that emphasizes both low- and high-order\nfeature interactions. The proposed framework, DeepFM, combines the power of\nfactorization machines for recommendation and deep learning for feature\nlearning in a new neural network architecture. Compared to the latest Wide &\nDeep model from Google, DeepFM has a shared raw feature input to both its\n\"wide\" and \"deep\" components, with no need of feature engineering besides raw\nfeatures. DeepFM, as a general learning framework, can incorporate various\nnetwork architectures in its deep component. In this paper, we study two\ninstances of DeepFM where its \"deep\" component is DNN and PNN respectively, for\nwhich we denote as DeepFM-D and DeepFM-P. Comprehensive experiments are\nconducted to demonstrate the effectiveness of DeepFM-D and DeepFM-P over the\nexisting models for CTR prediction, on both benchmark data and commercial data.\nWe conduct online A/B test in Huawei App Market, which reveals that DeepFM-D\nleads to more than 10% improvement of click-through rate in the production\nenvironment, compared to a well-engineered LR model. We also covered related\npractice in deploying our framework in Huawei App Market.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 01:12:13 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 13:39:20 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Guo", "Huifeng", ""], ["Tang", "Ruiming", ""], ["Ye", "Yunming", ""], ["Li", "Zhenguo", ""], ["He", "Xiuqiang", ""], ["Dong", "Zhenhua", ""]]}, {"id": "1804.04976", "submitter": "Daniele De Martini", "authors": "Mirto Musci, Daniele De Martini, Nicola Blago, Tullio Facchinetti and\n  Marco Piastra", "title": "Online Fall Detection using Recurrent Neural Networks", "comments": "6 pages, ICRA 2018", "journal-ref": null, "doi": "10.1109/TETC.2020.3027454", "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unintentional falls can cause severe injuries and even death, especially if\nno immediate assistance is given. The aim of Fall Detection Systems (FDSs) is\nto detect an occurring fall. This information can be used to trigger the\nnecessary assistance in case of injury. This can be done by using either\nambient-based sensors, e.g. cameras, or wearable devices. The aim of this work\nis to study the technical aspects of FDSs based on wearable devices and\nartificial intelligence techniques, in particular Deep Learning (DL), to\nimplement an effective algorithm for on-line fall detection. The proposed\nclassifier is based on a Recurrent Neural Network (RNN) model with underlying\nLong Short-Term Memory (LSTM) blocks. The method is tested on the publicly\navailable SisFall dataset, with extended annotation, and compared with the\nresults obtained by the SisFall authors.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 14:58:51 GMT"}], "update_date": "2020-10-05", "authors_parsed": [["Musci", "Mirto", ""], ["De Martini", "Daniele", ""], ["Blago", "Nicola", ""], ["Facchinetti", "Tullio", ""], ["Piastra", "Marco", ""]]}, {"id": "1804.05012", "submitter": "Phil Long", "authors": "Peter L. Bartlett, Steven N. Evans and Philip M. Long", "title": "Representing smooth functions as compositions of near-identity functions\n  with implications for deep network optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that any smooth bi-Lipschitz $h$ can be represented exactly as a\ncomposition $h_m \\circ ... \\circ h_1$ of functions $h_1,...,h_m$ that are close\nto the identity in the sense that each $\\left(h_i-\\mathrm{Id}\\right)$ is\nLipschitz, and the Lipschitz constant decreases inversely with the number $m$\nof functions composed. This implies that $h$ can be represented to any accuracy\nby a deep residual network whose nonlinear layers compute functions with a\nsmall Lipschitz constant. Next, we consider nonlinear regression with a\ncomposition of near-identity nonlinear maps. We show that, regarding Fr\\'echet\nderivatives with respect to the $h_1,...,h_m$, any critical point of a\nquadratic criterion in this near-identity region must be a global minimizer. In\ncontrast, if we consider derivatives with respect to parameters of a fixed-size\nresidual network with sigmoid activation functions, we show that there are\nnear-identity critical points that are suboptimal, even in the realizable case.\nInformally, this means that functional gradient methods for residual networks\ncannot get stuck at suboptimal critical points corresponding to near-identity\nlayers, whereas parametric gradient methods for sigmoidal residual networks\nsuffer from suboptimal critical points in the near-identity region.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 16:24:17 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 17:07:53 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Bartlett", "Peter L.", ""], ["Evans", "Steven N.", ""], ["Long", "Philip M.", ""]]}, {"id": "1804.05018", "submitter": "Sandro Pezzelle", "authors": "Sandro Pezzelle and Ionut-Teodor Sorodoc and Raffaella Bernardi", "title": "Comparatives, Quantifiers, Proportions: A Multi-Task Model for the\n  Learning of Quantities from Vision", "comments": "12 pages (references included). To appear in the Proceedings of\n  NAACL-HLT 2018", "journal-ref": "Proceedings of NAACL-HLT 2018", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work investigates whether different quantification mechanisms\n(set comparison, vague quantification, and proportional estimation) can be\njointly learned from visual scenes by a multi-task computational model. The\nmotivation is that, in humans, these processes underlie the same cognitive,\nnon-symbolic ability, which allows an automatic estimation and comparison of\nset magnitudes. We show that when information about lower-complexity tasks is\navailable, the higher-level proportional task becomes more accurate than when\nperformed in isolation. Moreover, the multi-task model is able to generalize to\nunseen combinations of target/non-target objects. Consistently with behavioral\nevidence showing the interference of absolute number in the proportional task,\nthe multi-task model no longer works when asked to provide the number of target\nobjects in the scene.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 16:36:52 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Pezzelle", "Sandro", ""], ["Sorodoc", "Ionut-Teodor", ""], ["Bernardi", "Raffaella", ""]]}, {"id": "1804.05020", "submitter": "Cody Wild", "authors": "Joshua Saxe, Richard Harang, Cody Wild, Hillary Sanders", "title": "A Deep Learning Approach to Fast, Format-Agnostic Detection of Malicious\n  Web Content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious web content is a serious problem on the Internet today. In this\npaper we propose a deep learning approach to detecting malevolent web pages.\nWhile past work on web content detection has relied on syntactic parsing or on\nemulation of HTML and Javascript to extract features, our approach operates\ndirectly on a language-agnostic stream of tokens extracted directly from static\nHTML files with a simple regular expression. This makes it fast enough to\noperate in high-frequency data contexts like firewalls and web proxies, and\nallows it to avoid the attack surface exposure of complex parsing and emulation\ncode. Unlike well-known approaches such as bag-of-words models, which ignore\nspatial information, our neural network examines content at hierarchical\nspatial scales, allowing our model to capture locality and yielding superior\naccuracy compared to bag-of-words baselines. Our proposed architecture achieves\na 97.5% detection rate at a 0.1% false positive rate, and classifies\nsmall-batched web pages at a rate of over 100 per second on commodity hardware.\nThe speed and accuracy of our approach makes it appropriate for deployment to\nendpoints, firewalls, and web proxies.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 16:39:24 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Saxe", "Joshua", ""], ["Harang", "Richard", ""], ["Wild", "Cody", ""], ["Sanders", "Hillary", ""]]}, {"id": "1804.05090", "submitter": "Shuai Zheng", "authors": "Shuai Zheng, Chris Ding, Feiping Nie", "title": "Regularized Singular Value Decomposition and Application to Recommender\n  System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singular value decomposition (SVD) is the mathematical basis of principal\ncomponent analysis (PCA). Together, SVD and PCA are one of the most widely used\nmathematical formalism/decomposition in machine learning, data mining, pattern\nrecognition, artificial intelligence, computer vision, signal processing, etc.\nIn recent applications, regularization becomes an increasing trend. In this\npaper, we present a regularized SVD (RSVD), present an efficient computational\nalgorithm, and provide several theoretical analysis. We show that although RSVD\nis non-convex, it has a closed-form global optimal solution. Finally, we apply\nRSVD to the application of recommender system and experimental result show that\nRSVD outperforms SVD significantly.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 18:54:30 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Zheng", "Shuai", ""], ["Ding", "Chris", ""], ["Nie", "Feiping", ""]]}, {"id": "1804.05092", "submitter": "Saman Sadeghyan", "authors": "Saman Sadeghyan", "title": "A new robust feature selection method using variance-based sensitivity\n  analysis", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Excluding irrelevant features in a pattern recognition task plays an\nimportant role in maintaining a simpler machine learning model and optimizing\nthe computational efficiency. Nowadays with the rise of large scale datasets,\nfeature selection is in great demand as it becomes a central issue when facing\nhigh-dimensional datasets. The present study provides a new measure of saliency\nfor features by employing a Sensitivity Analysis (SA) technique called the\nextended Fourier amplitude sensitivity test, and a well-trained Feedforward\nNeural Network (FNN) model, which ultimately leads to the selection of a\npromising optimal feature subset. Ideas of the paper are mainly demonstrated\nbased on adopting FNN model for feature selection in classification problems.\nBut in the end, a generalization framework is discussed in order to give\ninsights into the usage in regression problems as well as expressing how other\nfunction approximate models can be deployed. Effectiveness of the proposed\nmethod is verified by result analysis and data visualization for a series of\nexperiments over several well-known datasets drawn from UCI machine learning\nrepository.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 19:29:40 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Sadeghyan", "Saman", ""]]}, {"id": "1804.05120", "submitter": "Ibrahim Sobh", "authors": "Ibrahim M. Sobh, Nevin M. Darwish", "title": "Robust Dual View Deep Agent", "comments": "Proceeding of the 2nd International Sino-Egyptian Congress on\n  Agriculture, Veterinary Sciences and Engineering, 7-10 October 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent advance of machine learning using Deep Reinforcement\nLearning this paper proposes a modified architecture that produces more robust\nagents and speeds up the training process. Our architecture is based on\nAsynchronous Advantage Actor-Critic (A3C) algorithm where the total input\ndimensionality is halved by dividing the input into two independent streams. We\nuse ViZDoom, 3D world software that is based on the classical first person\nshooter video game, Doom, as a test case. The experiments show that in\ncomparison to single input agents, the proposed architecture succeeds to have\nthe same playing performance and shows more robust behavior, achieving\nsignificant reduction in the number of training parameters of almost 30%.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 21:13:42 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 06:03:40 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Sobh", "Ibrahim M.", ""], ["Darwish", "Nevin M.", ""]]}, {"id": "1804.05133", "submitter": "Paul McNicholas", "authors": "Vanessa S.E. Bierling and Paul D. McNicholas", "title": "A Latent Gaussian Mixture Model for Clustering Longitudinal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite mixture models have become a popular tool for clustering. Amongst\nother uses, they have been applied for clustering longitudinal data and\nclustering high-dimensional data. In the latter case, a latent Gaussian mixture\nmodel is sometimes used. Although there has been much work on clustering using\nlatent variables and on clustering longitudinal data, respectively, there has\nbeen a paucity of work that combines these features. An approach is developed\nfor clustering longitudinal data with many time points based on an extension of\nthe mixture of common factor analyzers model. A variation of the\nexpectation-maximization algorithm is used for parameter estimation and the\nBayesian information criterion is used for model selection. The approach is\nillustrated using real and simulated data.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 22:40:00 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Bierling", "Vanessa S. E.", ""], ["McNicholas", "Paul D.", ""]]}, {"id": "1804.05146", "submitter": "Alejandro Schuler", "authors": "Alejandro Schuler, Michael Baiocchi, Robert Tibshirani, Nigam Shah", "title": "A comparison of methods for model selection when estimating individual\n  treatment effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practitioners in medicine, business, political science, and other fields are\nincreasingly aware that decisions should be personalized to each patient,\ncustomer, or voter. A given treatment (e.g. a drug or advertisement) should be\nadministered only to those who will respond most positively, and certainly not\nto those who will be harmed by it. Individual-level treatment effects can be\nestimated with tools adapted from machine learning, but different models can\nyield contradictory estimates. Unlike risk prediction models, however,\ntreatment effect models cannot be easily evaluated against each other using a\nheld-out test set because the true treatment effect itself is never directly\nobserved. Besides outcome prediction accuracy, several metrics that can\nleverage held-out data to evaluate treatment effects models have been proposed,\nbut they are not widely used. We provide a didactic framework that elucidates\nthe relationships between the different approaches and compare them all using a\nvariety of simulations of both randomized and observational data. Our results\nshow that researchers estimating heterogenous treatment effects need not limit\nthemselves to a single model-fitting algorithm. Instead of relying on a single\nmethod, multiple models fit by a diverse set of algorithms should be evaluated\nagainst each other using an objective function learned from the validation set.\nThe model minimizing that objective should be used for estimating the\nindividual treatment effect for future individuals.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 01:28:47 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 20:38:50 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Schuler", "Alejandro", ""], ["Baiocchi", "Michael", ""], ["Tibshirani", "Robert", ""], ["Shah", "Nigam", ""]]}, {"id": "1804.05170", "submitter": "Bin Li", "authors": "Bin Li, Yueheng Lan, Weisi Guo, Chenglin Zhao", "title": "Model-Free Information Extraction in Enriched Nonlinear Phase-Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting anomalies and discovering driving signals is an essential component\nof scientific research and industrial practice. Often the underlying mechanism\nis highly complex, involving hidden evolving nonlinear dynamics and noise\ncontamination. When representative physical models and large labeled data sets\nare unavailable, as is the case with most real-world applications,\nmodel-dependent Bayesian approaches would yield misleading results, and most\nsupervised learning machines would also fail to reliably resolve the\nintricately evolving systems. Here, we propose an unsupervised machine-learning\napproach that operates in a well-constructed function space, whereby the\nevolving nonlinear dynamics are captured through a linear functional\nrepresentation determined by the Koopman operator. This breakthrough leverages\non the time-feature embedding and the ensuing reconstruction of a phase-space\nrepresentation of the dynamics, thereby permitting the reliable identification\nof critical global signatures from the whole trajectory. This dramatically\nimproves over commonly used static local features, which are vulnerable to\nunknown transitions or noise. Thanks to its data-driven nature, our method\nexcludes any prior models and training corpus. We benchmark the astonishing\naccuracy of our method on three diverse and challenging problems in: biology,\nmedicine, and engineering. In all cases, it outperforms existing\nstate-of-the-art methods. As a new unsupervised information processing\nparadigm, it is suitable for ubiquitous nonlinear dynamical systems or\nend-users with little expertise, which permits an unbiased excavation of\nunderlying working principles or intrinsic correlations submerged in unlabeled\ndata flows.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 05:58:15 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 02:16:14 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Li", "Bin", ""], ["Lan", "Yueheng", ""], ["Guo", "Weisi", ""], ["Zhao", "Chenglin", ""]]}, {"id": "1804.05214", "submitter": "Bharath Bhushan Damodaran", "authors": "Bharath Bhushan Damodaran", "title": "Fast Optimal Bandwidth Selection for RBF Kernel using Reproducing Kernel\n  Hilbert Space Operators for Kernel Based Classifiers", "comments": "Submitted to IEEE GRSL", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Kernel based methods have shown effective performance in many remote sensing\nclassification tasks. However their performance significantly depend on its\nhyper-parameters. The conventional technique to estimate the parameter comes\nwith high computational complexity. Thus, the objective of this letter is to\npropose an fast and efficient method to select the bandwidth parameter of the\nGaussian kernel in the kernel based classification methods. The proposed method\nis developed based on the operators in the reproducing kernel Hilbert space and\nit is evaluated on Support vector machines and PerTurbo classification method.\nExperiments conducted with hyperspectral datasets show that our proposed method\noutperforms the state-of-art method in terms in computational time and\nclassification performance.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 12:42:09 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Damodaran", "Bharath Bhushan", ""]]}, {"id": "1804.05251", "submitter": "Tian Guo", "authors": "Tian Guo, Tao Lin, Yao Lu", "title": "An interpretable LSTM neural network for autoregressive exogenous model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose an interpretable LSTM recurrent neural network,\ni.e., multi-variable LSTM for time series with exogenous variables. Currently,\nwidely used attention mechanism in recurrent neural networks mostly focuses on\nthe temporal aspect of data and falls short of characterizing variable\nimportance. To this end, our multi-variable LSTM equipped with tensorized\nhidden states is developed to learn variable specific representations, which\ngive rise to both temporal and variable level attention. Preliminary\nexperiments demonstrate comparable prediction performance of multi-variable\nLSTM w.r.t. encoder-decoder based baselines. More interestingly, variable\nimportance in real datasets characterized by the variable attention is highly\nin line with that determined by statistical Granger causality test, which\nexhibits the prospect of multi-variable LSTM as a simple and uniform end-to-end\nframework for both forecasting and knowledge discovery.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 17:33:46 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Guo", "Tian", ""], ["Lin", "Tao", ""], ["Lu", "Yao", ""]]}, {"id": "1804.05267", "submitter": "Marc Ortiz", "authors": "Marc Ortiz, Adri\\'an Cristal, Eduard Ayguad\\'e and Marc Casas", "title": "Low-Precision Floating-Point Schemes for Neural Network Training", "comments": "16 pages, 9 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The use of low-precision fixed-point arithmetic along with stochastic\nrounding has been proposed as a promising alternative to the commonly used\n32-bit floating point arithmetic to enhance training neural networks training\nin terms of performance and energy efficiency. In the first part of this paper,\nthe behaviour of the 12-bit fixed-point arithmetic when training a\nconvolutional neural network with the CIFAR-10 dataset is analysed, showing\nthat such arithmetic is not the most appropriate for the training phase. After\nthat, the paper presents and evaluates, under the same conditions, alternative\nlow-precision arithmetics, starting with the 12-bit floating-point arithmetic.\nThese two representations are then leveraged using local scaling in order to\nincrease accuracy and get closer to the baseline 32-bit floating-point\narithmetic. Finally, the paper introduces a simplified model in which both the\noutputs and the gradients of the neural networks are constrained to\npower-of-two values, just using 7 bits for their representation. The evaluation\ndemonstrates a minimal loss in accuracy for the proposed Power-of-Two neural\nnetwork, avoiding the use of multiplications and divisions and thereby,\nsignificantly reducing the training time as well as the energy consumption and\nmemory requirements during the training and inference phases.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 19:10:07 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Ortiz", "Marc", ""], ["Cristal", "Adri\u00e1n", ""], ["Ayguad\u00e9", "Eduard", ""], ["Casas", "Marc", ""]]}, {"id": "1804.05271", "submitter": "Shiqiang Wang", "authors": "Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K. Leung,\n  Christian Makaya, Ting He, Kevin Chan", "title": "Adaptive Federated Learning in Resource Constrained Edge Computing\n  Systems", "comments": "This version (excluding appendices) has been accepted for publication\n  in the IEEE Journal on Selected Areas in Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging technologies and applications including Internet of Things (IoT),\nsocial networking, and crowd-sourcing generate large amounts of data at the\nnetwork edge. Machine learning models are often built from the collected data,\nto enable the detection, classification, and prediction of future events. Due\nto bandwidth, storage, and privacy concerns, it is often impractical to send\nall the data to a centralized location. In this paper, we consider the problem\nof learning model parameters from data distributed across multiple edge nodes,\nwithout sending raw data to a centralized place. Our focus is on a generic\nclass of machine learning models that are trained using gradient-descent based\napproaches. We analyze the convergence bound of distributed gradient descent\nfrom a theoretical point of view, based on which we propose a control algorithm\nthat determines the best trade-off between local update and global parameter\naggregation to minimize the loss function under a given resource budget. The\nperformance of the proposed algorithm is evaluated via extensive experiments\nwith real datasets, both on a networked prototype system and in a larger-scale\nsimulated environment. The experimentation results show that our proposed\napproach performs near to the optimum with various machine learning models and\ndifferent data distributions.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 20:21:48 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 21:24:35 GMT"}, {"version": "v3", "created": "Sun, 17 Feb 2019 03:42:14 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Wang", "Shiqiang", ""], ["Tuor", "Tiffany", ""], ["Salonidis", "Theodoros", ""], ["Leung", "Kin K.", ""], ["Makaya", "Christian", ""], ["He", "Ting", ""], ["Chan", "Kevin", ""]]}, {"id": "1804.05283", "submitter": "Shiyong Ma", "authors": "Shiyong Ma, Zhen Zhang", "title": "OmicsMapNet: Transforming omics data to take advantage of Deep\n  Convolutional Neural Network for discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed OmicsMapNet approach to take advantage of existing deep leaning\nframeworks to analyze high-dimensional omics data as 2-dimensional images. The\nomics data of individual samples were first rearranged into 2D images in which\nmolecular features related in functions, ontologies, or other relationships\nwere organized in spatially adjacent and patterned locations. Deep learning\nneural networks were trained to classify the images. Molecular features\ninformative of classes of different phenotypes were subsequently identified. As\nan example, we used the KEGG BRITE database to rearrange RNA-Seq expression\ndata of TCGA diffuse glioma samples as treemaps to capture the functional\nhierarchical structure of genes in 2D images. Deep Convolutional Neural\nNetworks (CNN) were derived using tools from TensorFlow to learn the grade of\nTCGA LGG and GBM samples with relatively high accuracy. The most contributory\nfeatures in the trained CNN were confirmed in pathway analysis for their\nplausible functional involvement.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 22:22:21 GMT"}, {"version": "v2", "created": "Thu, 23 May 2019 19:46:16 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Ma", "Shiyong", ""], ["Zhang", "Zhen", ""]]}, {"id": "1804.05296", "submitter": "Samuel Finlayson", "authors": "Samuel G. Finlayson, Hyung Won Chung, Isaac S. Kohane, Andrew L. Beam", "title": "Adversarial Attacks Against Medical Deep Learning Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery of adversarial examples has raised concerns about the practical\ndeployment of deep learning systems. In this paper, we demonstrate that\nadversarial examples are capable of manipulating deep learning systems across\nthree clinical domains. For each of our representative medical deep learning\nclassifiers, both white and black box attacks were highly successful. Our\nmodels are representative of the current state of the art in medical computer\nvision and, in some cases, directly reflect architectures already seeing\ndeployment in real world clinical settings. In addition to the technical\ncontribution of our paper, we synthesize a large body of knowledge about the\nhealthcare system to argue that medicine may be uniquely susceptible to\nadversarial attacks, both in terms of monetary incentives and technical\nvulnerability. To this end, we outline the healthcare economy and the\nincentives it creates for fraud and provide concrete examples of how and why\nsuch attacks could be realistically carried out. We urge practitioners to be\naware of current vulnerabilities when deploying deep learning systems in\nclinical settings, and encourage the machine learning community to further\ninvestigate the domain-specific characteristics of medical learning systems.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 02:33:08 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 02:07:47 GMT"}, {"version": "v3", "created": "Mon, 4 Feb 2019 06:03:22 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Finlayson", "Samuel G.", ""], ["Chung", "Hyung Won", ""], ["Kohane", "Isaac S.", ""], ["Beam", "Andrew L.", ""]]}, {"id": "1804.05316", "submitter": "Shengdong Zhang", "authors": "Shengdong Zhang", "title": "From CDF to PDF --- A Density Estimation Method for High Dimensional\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CDF2PDF is a method of PDF estimation by approximating CDF. The original idea\nof it was previously proposed in [1] called SIC. However, SIC requires\nadditional hyper-parameter tunning, and no algorithms for computing higher\norder derivative from a trained NN are provided in [1]. CDF2PDF improves SIC by\navoiding the time-consuming hyper-parameter tuning part and enabling higher\norder derivative computation to be done in polynomial time. Experiments of this\nmethod for one-dimensional data shows promising results.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 07:38:11 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Zhang", "Shengdong", ""]]}, {"id": "1804.05320", "submitter": "Indrasis Chakraborty", "authors": "Indrasis Chakraborty, Rudrasis Chakraborty, Draguna Vrabie", "title": "Generative Adversarial Network based Autoencoder: Application to fault\n  detection problem for closed loop dynamical systems", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault detection problem for closed loop uncertain dynamical systems, is\ninvestigated in this paper, using different deep learning based methods.\nTraditional classifier based method does not perform well, because of the\ninherent difficulty of detecting system level faults for closed loop dynamical\nsystem. Specifically, acting controller in any closed loop dynamical system,\nworks to reduce the effect of system level faults. A novel Generative\nAdversarial based deep Autoencoder is designed to classify datasets under\nnormal and faulty operating conditions. This proposed network performs\nsignificantly well when compared to any available classifier based methods, and\nmoreover, does not require labeled fault incorporated datasets for training\npurpose. Finally, this aforementioned network's performance is tested on a high\ncomplexity building energy system dataset.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 08:28:15 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 03:21:28 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Chakraborty", "Indrasis", ""], ["Chakraborty", "Rudrasis", ""], ["Vrabie", "Draguna", ""]]}, {"id": "1804.05345", "submitter": "Cenk Baykal", "authors": "Cenk Baykal, Lucas Liebenwein, Igor Gilitschenski, Dan Feldman,\n  Daniela Rus", "title": "Data-Dependent Coresets for Compressing Neural Networks with\n  Applications to Generalization Bounds", "comments": "First two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an efficient coresets-based neural network compression algorithm\nthat sparsifies the parameters of a trained fully-connected neural network in a\nmanner that provably approximates the network's output. Our approach is based\non an importance sampling scheme that judiciously defines a sampling\ndistribution over the neural network parameters, and as a result, retains\nparameters of high importance while discarding redundant ones. We leverage a\nnovel, empirical notion of sensitivity and extend traditional coreset\nconstructions to the application of compressing parameters. Our theoretical\nanalysis establishes guarantees on the size and accuracy of the resulting\ncompressed network and gives rise to generalization bounds that may provide new\ninsights into the generalization properties of neural networks. We demonstrate\nthe practical effectiveness of our algorithm on a variety of neural network\nconfigurations and real-world data sets.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 12:22:23 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 05:52:18 GMT"}, {"version": "v3", "created": "Fri, 18 May 2018 14:41:51 GMT"}, {"version": "v4", "created": "Wed, 5 Sep 2018 18:01:41 GMT"}, {"version": "v5", "created": "Wed, 20 Feb 2019 18:23:51 GMT"}, {"version": "v6", "created": "Sat, 18 May 2019 00:12:21 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Baykal", "Cenk", ""], ["Liebenwein", "Lucas", ""], ["Gilitschenski", "Igor", ""], ["Feldman", "Dan", ""], ["Rus", "Daniela", ""]]}, {"id": "1804.05402", "submitter": "Shahar Mendelson", "authors": "Shahar Mendelson", "title": "Approximating the covariance ellipsoid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore ways in which the covariance ellipsoid ${\\cal B}=\\{v \\in\n\\mathbb{R}^d : \\mathbb{E} <X,v>^2 \\leq 1\\}$ of a centred random vector $X$ in\n$\\mathbb{R}^d$ can be approximated by a simple set. The data one is given for\nconstructing the approximating set consists of $X_1,...,X_N$ that are\nindependent and distributed as $X$.\n  We present a general method that can be used to construct such approximations\nand implement it for two types of approximating sets. We first construct a\n(random) set ${\\cal K}$ defined by a union of intersections of slabs\n$H_{z,\\alpha}=\\{v \\in \\mathbb{R}^d : |<z,v>| \\leq \\alpha\\}$ (and therefore\n${\\cal K}$ is actually the output of a neural network with two hidden layers).\nThe slabs are generated using $X_1,...,X_N$, and under minimal assumptions on\n$X$ (e.g., $X$ can be heavy-tailed) it suffices that $N = c_1d\n\\eta^{-4}\\log(2/\\eta)$ to ensure that $(1-\\eta) {\\cal K} \\subset {\\cal B}\n\\subset (1+\\eta){\\cal K}$. In some cases (e.g., if $X$ is rotation invariant\nand has marginals that are well behaved in some weak sense), a smaller sample\nsize suffices: $N = c_1d\\eta^{-2}\\log(2/\\eta)$.\n  We then show that if the slabs are replaced by randomly generated ellipsoids\ndefined using $X_1,...,X_N$, the same degree of approximation is true when $N\n\\geq c_2d\\eta^{-2}\\log(2/\\eta)$.\n  The construction we use is based on the small-ball method.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 18:07:44 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Mendelson", "Shahar", ""]]}, {"id": "1804.05433", "submitter": "Nicole M\\\"ucke", "authors": "Nicole M\\\"ucke", "title": "Adaptivity for Regularized Kernel Methods by Lepskii's Principle", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.26552.24325", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of {\\it adaptivity} in the framework of reproducing\nkernel Hilbert space (RKHS) regression. More precisely, we analyze estimators\narising from a linear regularization scheme $g_\\lam$. In practical\napplications, an important task is to choose the regularization parameter\n$\\lam$ appropriately, i.e. based only on the given data and independently on\nunknown structural assumptions on the regression function. An attractive\napproach avoiding data-splitting is the {\\it Lepskii Principle} (LP), also\nknown as the {\\it Balancing Principle} is this setting. We show that a modified\nparameter choice based on (LP) is minimax optimal adaptive, up to\n$\\log\\log(n)$. A convenient result is the fact that balancing in $L^2(\\nu)-$\nnorm, which is easiest, automatically gives optimal balancing in all stronger\nnorms, interpolating between $L^2(\\nu)$ and the RKHS. An analogous result is\nopen for other classical approaches to data dependent choices of the\nregularization parameter, e.g. for Hold-Out.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 21:27:04 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["M\u00fccke", "Nicole", ""]]}, {"id": "1804.05436", "submitter": "Yihong Wu", "authors": "Vivek Bagaria, Jian Ding, David Tse, Yihong Wu, Jiaming Xu", "title": "Hidden Hamiltonian Cycle Recovery via Linear Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DS math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the problem of hidden Hamiltonian cycle recovery, where there is\nan unknown Hamiltonian cycle in an $n$-vertex complete graph that needs to be\ninferred from noisy edge measurements. The measurements are independent and\ndistributed according to $\\calP_n$ for edges in the cycle and $\\calQ_n$\notherwise. This formulation is motivated by a problem in genome assembly, where\nthe goal is to order a set of contigs (genome subsequences) according to their\npositions on the genome using long-range linking measurements between the\ncontigs. Computing the maximum likelihood estimate in this model reduces to a\nTraveling Salesman Problem (TSP). Despite the NP-hardness of TSP, we show that\na simple linear programming (LP) relaxation, namely the fractional $2$-factor\n(F2F) LP, recovers the hidden Hamiltonian cycle with high probability as $n \\to\n\\infty$ provided that $\\alpha_n - \\log n \\to \\infty$, where $\\alpha_n\n\\triangleq -2 \\log \\int \\sqrt{d P_n d Q_n}$ is the R\\'enyi divergence of order\n$\\frac{1}{2}$. This condition is information-theoretically optimal in the sense\nthat, under mild distributional assumptions, $\\alpha_n \\geq (1+o(1)) \\log n$ is\nnecessary for any algorithm to succeed regardless of the computational cost.\n  Departing from the usual proof techniques based on dual witness construction,\nthe analysis relies on the combinatorial characterization (in particular, the\nhalf-integrality) of the extreme points of the F2F polytope. Represented as\nbicolored multi-graphs, these extreme points are further decomposed into\nsimpler \"blossom-type\" structures for the large deviation analysis and counting\narguments. Evaluation of the algorithm on real data shows improvements over\nexisting approaches.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2018 21:58:02 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Bagaria", "Vivek", ""], ["Ding", "Jian", ""], ["Tse", "David", ""], ["Wu", "Yihong", ""], ["Xu", "Jiaming", ""]]}, {"id": "1804.05464", "submitter": "Eric Mazumdar", "authors": "Eric Mazumdar and Lillian J. Ratliff and S. Shankar Sastry", "title": "On Gradient-Based Learning in Continuous Games", "comments": null, "journal-ref": "SIAM Journal on Mathematics of Data Science 2020 2:1, 103-131", "doi": "10.1137/18M1231298", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate a general framework for competitive gradient-based learning that\nencompasses a wide breadth of multi-agent learning algorithms, and analyze the\nlimiting behavior of competitive gradient-based learning algorithms using\ndynamical systems theory. For both general-sum and potential games, we\ncharacterize a non-negligible subset of the local Nash equilibria that will be\navoided if each agent employs a gradient-based learning algorithm. We also shed\nlight on the issue of convergence to non-Nash strategies in general- and\nzero-sum games, which may have no relevance to the underlying game, and arise\nsolely due to the choice of algorithm. The existence and frequency of such\nstrategies may explain some of the difficulties encountered when using gradient\ndescent in zero-sum games as, e.g., in the training of generative adversarial\nnetworks. To reinforce the theoretical contributions, we provide empirical\nresults that highlight the frequency of linear quadratic dynamic games (a\nbenchmark for multi-agent reinforcement learning) that admit global Nash\nequilibria that are almost surely avoided by policy gradient.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 01:14:17 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 03:54:44 GMT"}, {"version": "v3", "created": "Thu, 20 Feb 2020 18:26:35 GMT"}], "update_date": "2020-02-21", "authors_parsed": [["Mazumdar", "Eric", ""], ["Ratliff", "Lillian J.", ""], ["Sastry", "S. Shankar", ""]]}, {"id": "1804.05470", "submitter": "Anant Gupta", "authors": "Laura Graesser and Anant Gupta", "title": "Composable Unpaired Image to Image Translation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been remarkable recent work in unpaired image-to-image translation.\nHowever, they're restricted to translation on single pairs of distributions,\nwith some exceptions. In this study, we extend one of these works to a scalable\nmultidistribution translation mechanism. Our translation models not only\nconverts from one distribution to another but can be stacked to create\ncomposite translation functions. We show that this composite property makes it\npossible to generate images with characteristics not seen in the training set.\nWe also propose a decoupled training mechanism to train multiple distributions\nseparately, which we show, generates better samples than isolated joint\ntraining. Further, we do a qualitative and quantitative analysis to assess the\nplausibility of the samples. The code is made available at\nhttps://github.com/lgraesser/im2im2im.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 01:38:11 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Graesser", "Laura", ""], ["Gupta", "Anant", ""]]}, {"id": "1804.05474", "submitter": "Jonathan Shafer", "authors": "Ido Nachum, Jonathan Shafer, Amir Yehudayoff", "title": "A Direct Sum Result for the Information Complexity of Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How many bits of information are required to PAC learn a class of hypotheses\nof VC dimension $d$? The mathematical setting we follow is that of Bassily et\nal. (2018), where the value of interest is the mutual information\n$\\mathrm{I}(S;A(S))$ between the input sample $S$ and the hypothesis outputted\nby the learning algorithm $A$. We introduce a class of functions of VC\ndimension $d$ over the domain $\\mathcal{X}$ with information complexity at\nleast $\\Omega\\left(d\\log \\log \\frac{|\\mathcal{X}|}{d}\\right)$ bits for any\nconsistent and proper algorithm (deterministic or random). Bassily et al.\nproved a similar (but quantitatively weaker) result for the case $d=1$.\n  The above result is in fact a special case of a more general phenomenon we\nexplore. We define the notion of information complexity of a given class of\nfunctions $\\mathcal{H}$. Intuitively, it is the minimum amount of information\nthat an algorithm for $\\mathcal{H}$ must retain about its input to ensure\nconsistency and properness. We prove a direct sum result for information\ncomplexity in this context; roughly speaking, the information complexity sums\nwhen combining several classes.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 01:56:39 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Nachum", "Ido", ""], ["Shafer", "Jonathan", ""], ["Yehudayoff", "Amir", ""]]}, {"id": "1804.05482", "submitter": "Ignacio Ramirez", "authors": "Ignacio Ramirez", "title": "Binary Matrix Factorization via Dictionary Learning", "comments": "submitted for review to IEEE JSTSP on April 15th, 2018", "journal-ref": null, "doi": "10.1109/JSTSP.2018.2875674", "report-no": null, "categories": "stat.ML cs.CV cs.IR cs.IT cs.LG math.IT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Matrix factorization is a key tool in data analysis; its applications include\nrecommender systems, correlation analysis, signal processing, among others.\nBinary matrices are a particular case which has received significant attention\nfor over thirty years, especially within the field of data mining. Dictionary\nlearning refers to a family of methods for learning overcomplete basis (also\ncalled frames) in order to efficiently encode samples of a given type; this\narea, now also about twenty years old, was mostly developed within the signal\nprocessing field. In this work we propose two binary matrix factorization\nmethods based on a binary adaptation of the dictionary learning paradigm to\nbinary matrices. The proposed algorithms focus on speed and scalability; they\nwork with binary factors combined with bit-wise operations and a few auxiliary\ninteger ones. Furthermore, the methods are readily applicable to online binary\nmatrix factorization. Another important issue in matrix factorization is the\nchoice of rank for the factors; we address this model selection problem with an\nefficient method based on the Minimum Description Length principle. Our\npreliminary results show that the proposed methods are effective at producing\ninterpretable factorizations of various data types of different nature.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 02:36:24 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 01:13:05 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Ramirez", "Ignacio", ""]]}, {"id": "1804.05484", "submitter": "Yao Lu", "authors": "Yao Lu, Mehrtash Harandi, Richard Hartley, Razvan Pascanu", "title": "Block Mean Approximation for Efficient Second Order Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced optimization algorithms such as Newton method and AdaGrad benefit\nfrom second order derivative or second order statistics to achieve better\ndescent directions and faster convergence rates. At their heart, such\nalgorithms need to compute the inverse or inverse square root of a matrix whose\nsize is quadratic of the dimensionality of the search space. For high\ndimensional search spaces, the matrix inversion or inversion of square root\nbecomes overwhelming which in turn demands for approximate methods. In this\nwork, we propose a new matrix approximation method which divides a matrix into\nblocks and represents each block by one or two numbers. The method allows\nefficient computation of matrix inverse and inverse square root. We apply our\nmethod to AdaGrad in training deep neural networks. Experiments show\nencouraging results compared to the diagonal approximation.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 02:52:45 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 02:07:58 GMT"}, {"version": "v3", "created": "Wed, 29 Aug 2018 19:10:54 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Lu", "Yao", ""], ["Harandi", "Mehrtash", ""], ["Hartley", "Richard", ""], ["Pascanu", "Razvan", ""]]}, {"id": "1804.05494", "submitter": "Niharika Gauraha", "authors": "Niharika Gauraha and Ola Spjuth", "title": "conformalClassification: A Conformal Prediction R Package for\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conformalClassification package implements Transductive Conformal\nPrediction (TCP) and Inductive Conformal Prediction (ICP) for classification\nproblems. Conformal Prediction (CP) is a framework that complements the\npredictions of machine learning algorithms with reliable measures of\nconfidence. TCP gives results with higher validity than ICP, however ICP is\ncomputationally faster than TCP. The package conformalClassification is built\nupon the random forest method, where votes of the random forest for each class\nare considered as the conformity scores for each data point. Although the main\naim of the conformalClassification package is to generate CP errors (p-values)\nfor classification problems, the package also implements various diagnostic\nmeasures such as deviation from validity, error rate, efficiency, observed\nfuzziness and calibration plots. In future releases, we plan to extend the\npackage to use other machine learning algorithms, (e.g. support vector\nmachines) for model fitting.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 03:45:53 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Gauraha", "Niharika", ""], ["Spjuth", "Ola", ""]]}, {"id": "1804.05497", "submitter": "Jongyoon Song", "authors": "Jaekoo Lee, Byunghan Lee, Jongyoon Song, Jaesik Yoon, Yongsik Lee,\n  Donghun Lee, Sungroh Yoon", "title": "Deep Learning on Key Performance Indicators for Predictive Maintenance\n  in SAP HANA", "comments": "This version withdrawn by arXiv administrators because the author did\n  not have the right to agree to our license at the time of submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With a new era of cloud and big data, Database Management Systems (DBMSs)\nhave become more crucial in numerous enterprise business applications in all\nthe industries. Accordingly, the importance of their proactive and preventive\nmaintenance has also increased. However, detecting problems by predefined rules\nor stochastic modeling has limitations, particularly when analyzing the data on\nhigh-dimensional Key Performance Indicators (KPIs) from a DBMS. In recent\nyears, Deep Learning (DL) has opened new opportunities for this complex\nanalysis. In this paper, we present two complementary DL approaches to detect\nanomalies in SAP HANA. A temporal learning approach is used to detect abnormal\npatterns based on unlabeled historical data, whereas a spatial learning\napproach is used to classify known anomalies based on labeled data. We\nimplement a system in SAP HANA integrated with Google TensorFlow. The\nexperimental results with real-world data confirm the effectiveness of the\nsystem and models.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 03:55:42 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Lee", "Jaekoo", ""], ["Lee", "Byunghan", ""], ["Song", "Jongyoon", ""], ["Yoon", "Jaesik", ""], ["Lee", "Yongsik", ""], ["Lee", "Donghun", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1804.05515", "submitter": "Hongyu Xu", "authors": "Hongyu Xu, Zhangyang Wang, Haichuan Yang, Ding Liu and Ji Liu", "title": "Learning Simple Thresholded Features with Sparse Support Recovery", "comments": "Accepted by IEEE Transactions on Circuits and Systems for Video\n  Technology (TCSVT)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The thresholded feature has recently emerged as an extremely efficient, yet\nrough empirical approximation, of the time-consuming sparse coding inference\nprocess. Such an approximation has not yet been rigorously examined, and\nstandard dictionaries often lead to non-optimal performance when used for\ncomputing thresholded features. In this paper, we first present two theoretical\nrecovery guarantees for the thresholded feature to exactly recover the nonzero\nsupport of the sparse code. Motivated by them, we then formulate the Dictionary\nLearning for Thresholded Features (DLTF) model, which learns an optimized\ndictionary for applying the thresholded feature. In particular, for the $(k,\n2)$ norm involved, a novel proximal operator with log-linear time complexity\n$O(m\\log m)$ is derived. We evaluate the performance of DLTF on a vast range of\nsynthetic and real-data tasks, where DLTF demonstrates remarkable efficiency,\neffectiveness and robustness in all experiments. In addition, we briefly\ndiscuss the potential link between DLTF and deep learning building blocks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 06:20:55 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 22:10:17 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Xu", "Hongyu", ""], ["Wang", "Zhangyang", ""], ["Yang", "Haichuan", ""], ["Liu", "Ding", ""], ["Liu", "Ji", ""]]}, {"id": "1804.05544", "submitter": "Arvind Kumar Shekar", "authors": "Arvind Kumar Shekar, Cl\\'audio Rebelo de S\\'a, Hugo Ferreira, Carlos\n  Soares", "title": "Building robust prediction models for defective sensor data using\n  Artificial Neural Networks", "comments": "16 pages, 7 figures. Currently under review. This research has\n  obtained funding from the Electronic Components and Systems for European\n  Leadership (ECSEL) Joint Undertaking, the framework programme for research\n  and innovation Horizon 2020 (2014-2020) under grant agreement number\n  662189-MANTIS-2014-1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predicting the health of components in complex dynamic systems such as an\nautomobile poses numerous challenges. The primary aim of such predictive\nsystems is to use the high-dimensional data acquired from different sensors and\npredict the state-of-health of a particular component, e.g., brake pad. The\nclassical approach involves selecting a smaller set of relevant sensor signals\nusing feature selection and using them to train a machine learning algorithm.\nHowever, this fails to address two prominent problems: (1) sensors are\nsusceptible to failure when exposed to extreme conditions over a long periods\nof time; (2) sensors are electrical devices that can be affected by noise or\nelectrical interference. Using the failed and noisy sensor signals as inputs\nlargely reduce the prediction accuracy. To tackle this problem, it is\nadvantageous to use the information from all sensor signals, so that the\nfailure of one sensor can be compensated by another. In this work, we propose\nan Artificial Neural Network (ANN) based framework to exploit the information\nfrom a large number of signals. Secondly, our framework introduces a data\naugmentation approach to perform accurate predictions in spite of noisy\nsignals. The plausibility of our framework is validated on real life industrial\napplication from Robert Bosch GmbH.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 08:25:02 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Shekar", "Arvind Kumar", ""], ["de S\u00e1", "Cl\u00e1udio Rebelo", ""], ["Ferreira", "Hugo", ""], ["Soares", "Carlos", ""]]}, {"id": "1804.05567", "submitter": "Dmitry Babichev", "authors": "Dmitry Babichev, Francis Bach", "title": "Constant Step Size Stochastic Gradient Descent for Probabilistic\n  Modeling", "comments": "Published in Proc. UAI 2018, was accepted as oral presentation Camera\n  ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient methods enable learning probabilistic models from large\namounts of data. While large step-sizes (learning rates) have shown to be best\nfor least-squares (e.g., Gaussian noise) once combined with parameter\naveraging, these are not leading to convergent algorithms in general. In this\npaper, we consider generalized linear models, that is, conditional models based\non exponential families. We propose averaging moment parameters instead of\nnatural parameters for constant-step-size stochastic gradient descent. For\nfinite-dimensional models, we show that this can sometimes (and surprisingly)\nlead to better predictions than the best linear model. For infinite-dimensional\nmodels, we show that it always converges to optimal predictions, while\naveraging natural parameters never does. We illustrate our findings with\nsimulations on synthetic data and classical benchmarks with many observations.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 09:32:13 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 12:56:07 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Babichev", "Dmitry", ""], ["Bach", "Francis", ""]]}, {"id": "1804.05589", "submitter": "Vural Aksakalli", "authors": "Zeren D. Yenice, Niranjan Adhikari, Yong Kai Wong, Vural Aksakalli,\n  Alev Taskin Gumus, Babak Abbasi", "title": "SPSA-FSR: Simultaneous Perturbation Stochastic Approximation for Feature\n  Selection and Ranking", "comments": "The methodology introduced in this manuscript, both for feature\n  selection and feature ranking, has been implemented as the \"spFSR\" R package", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript presents the following: (1) an improved version of the Binary\nSimultaneous Perturbation Stochastic Approximation (SPSA) Method for feature\nselection in machine learning (Aksakalli and Malekipirbazari, Pattern\nRecognition Letters, Vol. 75, 2016) based on non-monotone iteration gains\ncomputed via the Barzilai and Borwein (BB) method, (2) its adaptation for\nfeature ranking, and (3) comparison against popular methods on public benchmark\ndatasets. The improved method, which we call SPSA-FSR, dramatically reduces the\nnumber of iterations required for convergence without impacting solution\nquality. SPSA-FSR can be used for feature ranking and feature selection both\nfor classification and regression problems. After a review of the current\nstate-of-the-art, we discuss our improvements in detail and present three sets\nof computational experiments: (1) comparison of SPSA-FS as a (wrapper) feature\nselection method against sequential methods as well as genetic algorithms, (2)\ncomparison of SPSA-FS as a feature ranking method in a classification setting\nagainst random forest importance, chi-squared, and information main methods,\nand (3) comparison of SPSA-FS as a feature ranking method in a regression\nsetting against minimum redundancy maximum relevance (MRMR), RELIEF, and linear\ncorrelation methods. The number of features in the datasets we use range from a\nfew dozens to a few thousands. Our results indicate that SPSA-FS converges to a\ngood feature set in no more than 100 iterations and therefore it is quite fast\nfor a wrapper method. SPSA-FS also outperforms popular feature selection as\nwell as feature ranking methods in majority of test cases, sometimes by a large\nmargin, and it stands as a promising new feature selection and ranking method.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 10:13:54 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Yenice", "Zeren D.", ""], ["Adhikari", "Niranjan", ""], ["Wong", "Yong Kai", ""], ["Aksakalli", "Vural", ""], ["Gumus", "Alev Taskin", ""], ["Abbasi", "Babak", ""]]}, {"id": "1804.05753", "submitter": "Taylor Pospisil", "authors": "Taylor Pospisil and Ann B. Lee", "title": "RFCDE: Random Forests for Conditional Density Estimation", "comments": "Fix URL in Arxiv abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random forests is a common non-parametric regression technique which performs\nwell for mixed-type data and irrelevant covariates, while being robust to\nmonotonic variable transformations. Existing random forest implementations\ntarget regression or classification. We introduce the RFCDE package for fitting\nrandom forest models optimized for nonparametric conditional density\nestimation, including joint densities for multiple responses. This enables\nanalysis of conditional probability distributions which is useful for\npropagating uncertainty and of joint distributions that describe relationships\nbetween multiple responses and covariates. RFCDE is released under the MIT\nopen-source license and can be accessed at https://github.com/tpospisi/rfcde .\nBoth R and Python versions, which call a common C++ library, are available.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 15:47:07 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 21:36:57 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Pospisil", "Taylor", ""], ["Lee", "Ann B.", ""]]}, {"id": "1804.05774", "submitter": "Sergio Ram\\'irez-Gallego", "authors": "Sergio Ram\\'irez-Gallego and Salvador Garc\\'ia and Ning Xiong and\n  Francisco Herrera", "title": "BELIEF: A distance-based redundancy-proof feature selection method for\n  Big Data", "comments": "30 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of Big Data era, data reduction methods are highly demanded\ngiven its ability to simplify huge data, and ease complex learning processes.\nConcretely, algorithms that are able to filter relevant dimensions from a set\nof millions are of huge importance. Although effective, these techniques suffer\nfrom the \"scalability\" curse as well.\n  In this work, we propose a distributed feature weighting algorithm, which is\nable to rank millions of features in parallel using large samples. This method,\ninspired by the well-known RELIEF algorithm, introduces a novel redundancy\nelimination measure that provides similar schemes to those based on entropy at\na much lower cost. It also allows smooth scale up when more instances are\ndemanded in feature estimations. Empirical tests performed on our method show\nits estimation ability in manifold huge sets --both in number of features and\ninstances--, as well as its simplified runtime cost (specially, at the\nredundancy detection step).\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 16:23:14 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Ram\u00edrez-Gallego", "Sergio", ""], ["Garc\u00eda", "Salvador", ""], ["Xiong", "Ning", ""], ["Herrera", "Francisco", ""]]}, {"id": "1804.05805", "submitter": "Wenjie Ruan", "authors": "Wenjie Ruan, Min Wu, Youcheng Sun, Xiaowei Huang, Daniel Kroening,\n  Marta Kwiatkowska", "title": "Global Robustness Evaluation of Deep Neural Networks with Provable\n  Guarantees for the $L_0$ Norm", "comments": "42 Pages, Github: https://github.com/TrustAI/L0-TRE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployment of deep neural networks (DNNs) in safety- or security-critical\nsystems requires provable guarantees on their correct behaviour. A common\nrequirement is robustness to adversarial perturbations in a neighbourhood\naround an input. In this paper we focus on the $L_0$ norm and aim to compute,\nfor a trained DNN and an input, the maximal radius of a safe norm ball around\nthe input within which there are no adversarial examples. Then we define global\nrobustness as an expectation of the maximal safe radius over a test data set.\nWe first show that the problem is NP-hard, and then propose an approximate\napproach to iteratively compute lower and upper bounds on the network's\nrobustness. The approach is \\emph{anytime}, i.e., it returns intermediate\nbounds and robustness estimates that are gradually, but strictly, improved as\nthe computation proceeds; \\emph{tensor-based}, i.e., the computation is\nconducted over a set of inputs simultaneously, instead of one by one, to enable\nefficient GPU computation; and has \\emph{provable guarantees}, i.e., both the\nbounds and the robustness estimates can converge to their optimal values.\nFinally, we demonstrate the utility of the proposed approach in practice to\ncompute tight bounds by applying and adapting the anytime algorithm to a set of\nchallenging problems, including global robustness evaluation, competitive $L_0$\nattacks, test case generation for DNNs, and local robustness evaluation on\nlarge-scale ImageNet DNNs. We release the code of all case studies via GitHub.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 17:24:51 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 16:57:22 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Ruan", "Wenjie", ""], ["Wu", "Min", ""], ["Sun", "Youcheng", ""], ["Huang", "Xiaowei", ""], ["Kroening", "Daniel", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "1804.05806", "submitter": "Linh Le", "authors": "Linh Le, Ying Xie", "title": "Deep Embedding Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel supervised learning method that is called\nDeep Embedding Kernel (DEK). DEK combines the advantages of deep learning and\nkernel methods in a unified framework. More specifically, DEK is a learnable\nkernel represented by a newly designed deep architecture. Compared with\npre-defined kernels, this kernel can be explicitly trained to map data to an\noptimized high-level feature space where data may have favorable features\ntoward the application. Compared with typical deep learning using SoftMax or\nlogistic regression as the top layer, DEK is expected to be more generalizable\nto new data. Experimental results show that DEK has superior performance than\ntypical machine learning methods in identity detection, classification,\nregression, dimension reduction, and transfer learning.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 17:25:24 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Le", "Linh", ""], ["Xie", "Ying", ""]]}, {"id": "1804.05810", "submitter": "Shang-Tse Chen", "authors": "Shang-Tse Chen, Cory Cornelius, Jason Martin, Duen Horng Chau", "title": "ShapeShifter: Robust Physical Adversarial Attack on Faster R-CNN Object\n  Detector", "comments": null, "journal-ref": "Joint European Conference on Machine Learning and Knowledge\n  Discovery in Databases, pp. 52-68, 2018", "doi": "10.1007/978-3-030-10925-7_4", "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the ability to directly manipulate image pixels in the digital input\nspace, an adversary can easily generate imperceptible perturbations to fool a\nDeep Neural Network (DNN) image classifier, as demonstrated in prior work. In\nthis work, we propose ShapeShifter, an attack that tackles the more challenging\nproblem of crafting physical adversarial perturbations to fool image-based\nobject detectors like Faster R-CNN. Attacking an object detector is more\ndifficult than attacking an image classifier, as it needs to mislead the\nclassification results in multiple bounding boxes with different scales.\nExtending the digital attack to the physical world adds another layer of\ndifficulty, because it requires the perturbation to be robust enough to survive\nreal-world distortions due to different viewing distances and angles, lighting\nconditions, and camera limitations. We show that the Expectation over\nTransformation technique, which was originally proposed to enhance the\nrobustness of adversarial perturbations in image classification, can be\nsuccessfully adapted to the object detection setting. ShapeShifter can generate\nadversarially perturbed stop signs that are consistently mis-detected by Faster\nR-CNN as other objects, posing a potential threat to autonomous vehicles and\nother safety-critical computer vision systems.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 17:29:43 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 02:22:39 GMT"}, {"version": "v3", "created": "Wed, 1 May 2019 03:41:44 GMT"}], "update_date": "2019-05-02", "authors_parsed": [["Chen", "Shang-Tse", ""], ["Cornelius", "Cory", ""], ["Martin", "Jason", ""], ["Chau", "Duen Horng", ""]]}, {"id": "1804.05816", "submitter": "Tanay Kumar Saha", "authors": "Tanay Kumar Saha and Thomas Williams and Mohammad Al Hasan and Shafiq\n  Joty and Nicholas K. Varberg", "title": "Models for Capturing Temporal Smoothness in Evolving Networks for\n  Learning Latent Representation of Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a dynamic network, the neighborhood of the vertices evolve across\ndifferent temporal snapshots of the network. Accurate modeling of this temporal\nevolution can help solve complex tasks involving real-life social and\ninteraction networks. However, existing models for learning latent\nrepresentation are inadequate for obtaining the representation vectors of the\nvertices for different time-stamps of a dynamic network in a meaningful way. In\nthis paper, we propose latent representation learning models for dynamic\nnetworks which overcome the above limitation by considering two different kinds\nof temporal smoothness: (i) retrofitted, and (ii) linear transformation. The\nretrofitted model tracks the representation vector of a vertex over time,\nfacilitating vertex-based temporal analysis of a network. On the other hand,\nlinear transformation based model provides a smooth transition operator which\nmaps the representation vectors of all vertices from one temporal snapshot to\nthe next (unobserved) snapshot-this facilitates prediction of the state of a\nnetwork in a future time-stamp. We validate the performance of our proposed\nmodels by employing them for solving the temporal link prediction task.\nExperiments on 9 real-life networks from various domains validate that the\nproposed models are significantly better than the existing models for\npredicting the dynamics of an evolving network.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 17:40:02 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Saha", "Tanay Kumar", ""], ["Williams", "Thomas", ""], ["Hasan", "Mohammad Al", ""], ["Joty", "Shafiq", ""], ["Varberg", "Nicholas K.", ""]]}, {"id": "1804.05834", "submitter": "Xiaolin Wang", "authors": "Xiaolin Wang", "title": "CytonRL: an Efficient Reinforcement Learning Open-source Toolkit\n  Implemented in C++", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an open-source enforcement learning toolkit named CytonRL\n(https://github.com/arthurxlw/cytonRL). The toolkit implements four recent\nadvanced deep Q-learning algorithms from scratch using C++ and NVIDIA's\nGPU-accelerated libraries. The code is simple and elegant, owing to an\nopen-source general-purpose neural network library named CytonLib. Benchmark\nshows that the toolkit achieves competitive performances on the popular Atari\ngame of Breakout.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2018 23:17:07 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Wang", "Xiaolin", ""]]}, {"id": "1804.05862", "submitter": "Wenda Zhou", "authors": "Wenda Zhou and Victor Veitch and Morgane Austern and Ryan P. Adams and\n  Peter Orbanz", "title": "Non-Vacuous Generalization Bounds at the ImageNet Scale: A PAC-Bayesian\n  Compression Approach", "comments": "16 pages, 1 figure. Accepted at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neural networks are highly overparameterized, with capacity to\nsubstantially overfit to training data. Nevertheless, these networks often\ngeneralize well in practice. It has also been observed that trained networks\ncan often be \"compressed\" to much smaller representations. The purpose of this\npaper is to connect these two empirical observations. Our main technical result\nis a generalization bound for compressed networks based on the compressed size.\nCombined with off-the-shelf compression algorithms, the bound leads to state of\nthe art generalization guarantees; in particular, we provide the first\nnon-vacuous generalization guarantees for realistic architectures applied to\nthe ImageNet classification problem. As additional evidence connecting\ncompression and generalization, we show that compressibility of models that\ntend to overfit is limited: We establish an absolute limit on expected\ncompressibility as a function of expected generalization error, where the\nexpectations are over the random choice of training examples. The bounds are\ncomplemented by empirical results that show an increase in overfitting implies\nan increase in the number of bits required to describe a trained network.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 18:01:12 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 17:27:12 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 02:37:14 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Zhou", "Wenda", ""], ["Veitch", "Victor", ""], ["Austern", "Morgane", ""], ["Adams", "Ryan P.", ""], ["Orbanz", "Peter", ""]]}, {"id": "1804.05929", "submitter": "Fang Liu", "authors": "Fang Liu, Sinong Wang, Swapna Buccapatnam and Ness Shroff", "title": "UCBoost: A Boosting Approach to Tame Complexity and Optimality for\n  Stochastic Bandits", "comments": "Accepted by IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we address the open problem of finding low-complexity\nnear-optimal multi-armed bandit algorithms for sequential decision making\nproblems. Existing bandit algorithms are either sub-optimal and computationally\nsimple (e.g., UCB1) or optimal and computationally complex (e.g., kl-UCB). We\npropose a boosting approach to Upper Confidence Bound based algorithms for\nstochastic bandits, that we call UCBoost. Specifically, we propose two types of\nUCBoost algorithms. We show that UCBoost($D$) enjoys $O(1)$ complexity for each\narm per round as well as regret guarantee that is $1/e$-close to that of the\nkl-UCB algorithm. We propose an approximation-based UCBoost algorithm,\nUCBoost($\\epsilon$), that enjoys a regret guarantee $\\epsilon$-close to that of\nkl-UCB as well as $O(\\log(1/\\epsilon))$ complexity for each arm per round.\nHence, our algorithms provide practitioners a practical way to trade optimality\nwith computational complexity. Finally, we present numerical results which show\nthat UCBoost($\\epsilon$) can achieve the same regret performance as the\nstandard kl-UCB while incurring only $1\\%$ of the computational cost of kl-UCB.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 20:44:28 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Liu", "Fang", ""], ["Wang", "Sinong", ""], ["Buccapatnam", "Swapna", ""], ["Shroff", "Ness", ""]]}, {"id": "1804.05958", "submitter": "Julia Kreutzer", "authors": "Julia Kreutzer, Shahram Khadivi, Evgeny Matusov, Stefan Riezler", "title": "Can Neural Machine Translation be Improved with User Feedback?", "comments": "Accepted at NAACL-HLT 2018 (Industry Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first real-world application of methods for improving neural\nmachine translation (NMT) with human reinforcement, based on explicit and\nimplicit user feedback collected on the eBay e-commerce platform. Previous work\nhas been confined to simulation experiments, whereas in this paper we work with\nreal logged feedback for offline bandit learning of NMT parameters. We conduct\na thorough analysis of the available explicit user judgments---five-star\nratings of translation quality---and show that they are not reliable enough to\nyield significant improvements in bandit learning. In contrast, we successfully\nutilize implicit task-based feedback collected in a cross-lingual search task\nto improve task-specific and machine translation quality metrics.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 21:55:45 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Kreutzer", "Julia", ""], ["Khadivi", "Shahram", ""], ["Matusov", "Evgeny", ""], ["Riezler", "Stefan", ""]]}, {"id": "1804.05965", "submitter": "Henry Gouk", "authors": "Henry Gouk, Bernhard Pfahringer, Eibe Frank, Michael Cree", "title": "MaxGain: Regularisation of Neural Networks by Constraining Activation\n  Magnitudes", "comments": "Accepted at ECML-PKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective regularisation of neural networks is essential to combat\noverfitting due to the large number of parameters involved. We present an\nempirical analogue to the Lipschitz constant of a feed-forward neural network,\nwhich we refer to as the maximum gain. We hypothesise that constraining the\ngain of a network will have a regularising effect, similar to how constraining\nthe Lipschitz constant of a network has been shown to improve generalisation. A\nsimple algorithm is provided that involves rescaling the weight matrix of each\nlayer after each parameter update. We conduct a series of studies on common\nbenchmark datasets, and also a novel dataset that we introduce to enable easier\nsignificance testing for experiments using convolutional networks. Performance\non these datasets compares favourably with other common regularisation\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 22:43:41 GMT"}, {"version": "v2", "created": "Sun, 1 Jul 2018 06:39:43 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Gouk", "Henry", ""], ["Pfahringer", "Bernhard", ""], ["Frank", "Eibe", ""], ["Cree", "Michael", ""]]}, {"id": "1804.05981", "submitter": "Siwei Lyu", "authors": "Siwei Lyu and Yiming Ying", "title": "A Univariate Bound of Area Under ROC", "comments": "UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Area under ROC (AUC) is an important metric for binary classification and\nbipartite ranking problems. However, it is difficult to directly optimizing AUC\nas a learning objective, so most existing algorithms are based on optimizing a\nsurrogate loss to AUC. One significant drawback of these surrogate losses is\nthat they require pairwise comparisons among training data, which leads to slow\nrunning time and increasing local storage for online learning. In this work, we\ndescribe a new surrogate loss based on a reformulation of the AUC risk, which\ndoes not require pairwise comparison but rankings of the predictions. We\nfurther show that the ranking operation can be avoided, and the learning\nobjective obtained based on this surrogate enjoys linear complexity in time and\nstorage. We perform experiments to demonstrate the effectiveness of the online\nand batch algorithms for AUC optimization based on the proposed surrogate loss.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 23:33:09 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 14:29:13 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Lyu", "Siwei", ""], ["Ying", "Yiming", ""]]}, {"id": "1804.06021", "submitter": "Yasin Abbasi-Yadkori", "authors": "Yasin Abbasi-Yadkori, Nevena Lazic, Csaba Szepesvari", "title": "Model-Free Linear Quadratic Control via Reduction to Expert Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free approaches for reinforcement learning (RL) and continuous control\nfind policies based only on past states and rewards, without fitting a model of\nthe system dynamics. They are appealing as they are general purpose and easy to\nimplement; however, they also come with fewer theoretical guarantees than\nmodel-based RL. In this work, we present a new model-free algorithm for\ncontrolling linear quadratic (LQ) systems, and show that its regret scales as\n$O(T^{\\xi+2/3})$ for any small $\\xi>0$ if time horizon satisfies $T>C^{1/\\xi}$\nfor a constant $C$. The algorithm is based on a reduction of control of Markov\ndecision processes to an expert prediction problem. In practice, it corresponds\nto a variant of policy iteration with forced exploration, where the policy in\neach phase is greedy with respect to the average of all previous value\nfunctions. This is the first model-free algorithm for adaptive control of LQ\nsystems that provably achieves sublinear regret and has a polynomial\ncomputation cost. Empirically, our algorithm dramatically outperforms standard\npolicy iteration, but performs worse than a model-based approach.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 02:52:38 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 17:50:23 GMT"}, {"version": "v3", "created": "Fri, 5 Oct 2018 19:50:23 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Abbasi-Yadkori", "Yasin", ""], ["Lazic", "Nevena", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1804.06027", "submitter": "Longfei Li", "authors": "Longfei Li, Peilin Zhao, Jun Zhou, Xiaolong Li", "title": "A Boosting Framework of Factorization Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Factorization Machines (FM) has become more and more popular for\nrecommendation systems, due to its effectiveness in finding informative\ninteractions between features. Usually, the weights for the interactions is\nlearnt as a low rank weight matrix, which is formulated as an inner product of\ntwo low rank matrices. This low rank can help improve the generalization\nability of Factorization Machines. However, to choose the rank properly, it\nusually needs to run the algorithm for many times using different ranks, which\nclearly is inefficient for some large-scale datasets. To alleviate this issue,\nwe propose an Adaptive Boosting framework of Factorization Machines (AdaFM),\nwhich can adaptively search for proper ranks for different datasets without\nre-training. Instead of using a fixed rank for FM, the proposed algorithm will\nadaptively gradually increases its rank according to its performance until the\nperformance does not grow, using boosting strategy. To verify the performance\nof our proposed framework, we conduct an extensive set of experiments on many\nreal-world datasets. Encouraging empirical results shows that the proposed\nalgorithms are generally more effective than state-of-the-art other\nFactorization Machines.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 03:23:40 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Li", "Longfei", ""], ["Zhao", "Peilin", ""], ["Zhou", "Jun", ""], ["Li", "Xiaolong", ""]]}, {"id": "1804.06095", "submitter": "Rachelle Rivero", "authors": "Rachelle Rivero and Tsuyoshi Kato", "title": "Parametric Models for Mutual Kernel Matrix Completion", "comments": "8 pages, 1 figure, 1 table", "journal-ref": null, "doi": "10.1587/transinf.2018EDP7139", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies utilize multiple kernel learning to deal with incomplete-data\nproblem. In this study, we introduce new methods that do not only complete\nmultiple incomplete kernel matrices simultaneously, but also allow control of\nthe flexibility of the model by parameterizing the model matrix. By imposing\nrestrictions on the model covariance, overfitting of the data is avoided. A\nlimitation of kernel matrix estimations done via optimization of an objective\nfunction is that the positive definiteness of the result is not guaranteed. In\nview of this limitation, our proposed methods employ the LogDet divergence,\nwhich ensures the positive definiteness of the resulting inferred kernel\nmatrix. We empirically show that our proposed restricted covariance models,\nemployed with LogDet divergence, yield significant improvements in the\ngeneralization performance of previous completion methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 08:08:05 GMT"}], "update_date": "2018-12-26", "authors_parsed": [["Rivero", "Rachelle", ""], ["Kato", "Tsuyoshi", ""]]}, {"id": "1804.06114", "submitter": "Cong Chen", "authors": "Cong Chen, Kim Batselier, Ching-Yun Ko and Ngai Wong", "title": "A Support Tensor Train Machine", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been growing interest in extending traditional vector-based machine\nlearning techniques to their tensor forms. An example is the support tensor\nmachine (STM) that utilizes a rank-one tensor to capture the data structure,\nthereby alleviating the overfitting and curse of dimensionality problems in the\nconventional support vector machine (SVM). However, the expressive power of a\nrank-one tensor is restrictive for many real-world data. To overcome this\nlimitation, we introduce a support tensor train machine (STTM) by replacing the\nrank-one tensor in an STM with a tensor train. Experiments validate and confirm\nthe superiority of an STTM over the SVM and STM.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 08:59:13 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Chen", "Cong", ""], ["Batselier", "Kim", ""], ["Ko", "Ching-Yun", ""], ["Wong", "Ngai", ""]]}, {"id": "1804.06188", "submitter": "Ondrej Kuzelka", "authors": "Ondrej Kuzelka, Yuyi Wang, Steven Schockaert", "title": "VC-Dimension Based Generalization Bounds for Relational Learning", "comments": "Longer version of paper accepted at ECML PKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications of relational learning, the available data can be seen\nas a sample from a larger relational structure (e.g. we may be given a small\nfragment from some social network). In this paper we are particularly concerned\nwith scenarios in which we can assume that (i) the domain elements appearing in\nthe given sample have been uniformly sampled without replacement from the\n(unknown) full domain and (ii) the sample is complete for these domain elements\n(i.e. it is the full substructure induced by these elements). Within this\nsetting, we study bounds on the error of sufficient statistics of relational\nmodels that are estimated on the available data. As our main result, we prove a\nbound based on a variant of the Vapnik-Chervonenkis dimension which is suitable\nfor relational data.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 12:09:02 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 13:14:25 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Kuzelka", "Ondrej", ""], ["Wang", "Yuyi", ""], ["Schockaert", "Steven", ""]]}, {"id": "1804.06207", "submitter": "Luis Moreira-Matias Dr.", "authors": "Jihed Khiari, Luis Moreira-Matias, Ammar Shaker, Bernard Zenko, Saso\n  Dzeroski", "title": "MetaBags: Bagged Meta-Decision Trees for Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles are popular methods for solving practical supervised learning\nproblems. They reduce the risk of having underperforming models in\nproduction-grade software. Although critical, methods for learning\nheterogeneous regression ensembles have not been proposed at large scale,\nwhereas in classical ML literature, stacking, cascading and voting are mostly\nrestricted to classification problems. Regression poses distinct learning\nchallenges that may result in poor performance, even when using well\nestablished homogeneous ensemble schemas such as bagging or boosting.\n  In this paper, we introduce MetaBags, a novel, practically useful stacking\nframework for regression. MetaBags is a meta-learning algorithm that learns a\nset of meta-decision trees designed to select one base model (i.e. expert) for\neach query, and focuses on inductive bias reduction. A set of meta-decision\ntrees are learned using different types of meta-features, specially created for\nthis purpose - to then be bagged at meta-level. This procedure is designed to\nlearn a model with a fair bias-variance trade-off, and its improvement over\nbase model performance is correlated with the prediction diversity of different\nexperts on specific input space subregions. The proposed method and\nmeta-features are designed in such a way that they enable good predictive\nperformance even in subregions of space which are not adequately represented in\nthe available training data.\n  An exhaustive empirical testing of the method was performed, evaluating both\ngeneralization error and scalability of the approach on synthetic, open and\nreal-world application datasets. The obtained results show that our method\nsignificantly outperforms existing state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 12:51:52 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Khiari", "Jihed", ""], ["Moreira-Matias", "Luis", ""], ["Shaker", "Ammar", ""], ["Zenko", "Bernard", ""], ["Dzeroski", "Saso", ""]]}, {"id": "1804.06216", "submitter": "Aleksander Wieczorek", "authors": "Aleksander Wieczorek and Mario Wieser and Damian Murezzan and Volker\n  Roth", "title": "Learning Sparse Latent Representations with the Deep Copula Information\n  Bottleneck", "comments": "Published as a conference paper at ICLR 2018. Aleksander Wieczorek\n  and Mario Wieser contributed equally to this work", "journal-ref": "Conference track - ICLR 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep latent variable models are powerful tools for representation learning.\nIn this paper, we adopt the deep information bottleneck model, identify its\nshortcomings and propose a model that circumvents them. To this end, we apply a\ncopula transformation which, by restoring the invariance properties of the\ninformation bottleneck method, leads to disentanglement of the features in the\nlatent space. Building on that, we show how this transformation translates to\nsparsity of the latent space in the new model. We evaluate our method on\nartificial and real data.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 13:09:19 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 12:10:32 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Wieczorek", "Aleksander", ""], ["Wieser", "Mario", ""], ["Murezzan", "Damian", ""], ["Roth", "Volker", ""]]}, {"id": "1804.06218", "submitter": "Jarek Duda dr", "authors": "Jarek Duda", "title": "Hierarchical correlation reconstruction with missing data, for example\n  for biology-inspired neuron", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning often needs to model density from a multidimensional data\nsample, including correlations between coordinates. Additionally, we often have\nmissing data case: that data points can miss values for some of coordinates.\nThis article adapts rapid parametric density estimation approach for this\npurpose: modelling density as a linear combination of orthonormal functions,\nfor which $L^2$ optimization says that (independently) estimated coefficient\nfor a given function is just average over the sample of value of this function.\nHierarchical correlation reconstruction first models probability density for\neach separate coordinate using all its appearances in data sample, then adds\ncorrections from independently modelled pairwise correlations using all samples\nhaving both coordinates, and so on independently adding correlations for\ngrowing numbers of variables using often decreasing evidence in data sample. A\nbasic application of such modelled multidimensional density can be imputation\nof missing coordinates: by inserting known coordinates to the density, and\ntaking expected values for the missing coordinates, or even their entire joint\nprobability distribution. Presented method can be compared with cascade\ncorrelations approach, offering several advantages in flexibility and accuracy.\nIt can be also used as artificial neuron: maximizing prediction capabilities\nfor only local behavior - modelling and predicting local connections.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 13:10:09 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 11:38:01 GMT"}, {"version": "v3", "created": "Wed, 16 May 2018 12:08:48 GMT"}, {"version": "v4", "created": "Sun, 27 May 2018 15:54:32 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Duda", "Jarek", ""]]}, {"id": "1804.06219", "submitter": "Elnura Irmatova", "authors": "Anwar Irmatov and Elnura Irmatova", "title": "Application of the Ranking Relative Principal Component Attributes\n  Network Model (REL-PCANet) for the Inclusive Development Index Estimation", "comments": "13 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2018, at the World Economic Forum in Davos it was presented a new\ncountries' economic performance metric named the Inclusive Development Index\n(IDI) composed of 12 indicators. The new metric implies that countries might\nneed to realize structural reforms for improving both economic expansion and\nsocial inclusion performance. That is why, it is vital for the IDI calculation\nmethod to have strong statistical and mathematical basis, so that results are\naccurate and transparent for public purposes. In the current work, we propose a\nnovel approach for the IDI estimation - the Ranking Relative Principal\nComponent Attributes Network Model (REL-PCANet). The model is based on RELARM\nand RankNet principles and combines elements of PCA, techniques applied in\nimage recognition and learning to rank mechanisms. Also, we define a new\napproach for estimation of target probabilities matrix to reflect dynamic\nchanges in countries' inclusive development. Empirical study proved that\nREL-PCANet ensures reliable and robust scores and rankings, thus is recommended\nfor practical implementation.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 14:44:28 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Irmatov", "Anwar", ""], ["Irmatova", "Elnura", ""]]}, {"id": "1804.06223", "submitter": "Scott Lee", "authors": "Scott H Lee, Matthew J Maenner, Charles M Heilig", "title": "A Comparison of Machine Learning Algorithms for the Surveillance of\n  Autism Spectrum Disorder", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0222907", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Centers for Disease Control and Prevention (CDC) coordinates a\nlabor-intensive process to measure the prevalence of autism spectrum disorder\n(ASD) among children in the United States. Random forests methods have shown\npromise in speeding up this process, but they lag behind human classification\naccuracy by about 5%. We explore whether more recently available document\nclassification algorithms can close this gap. We applied 8 supervised learning\nalgorithms to predict whether children meet the case definition for ASD based\nsolely on the words in their evaluations. We compared the algorithms'\nperformance across 10 random train-test splits of the data, using\nclassification accuracy, F1 score, and number of positive calls to evaluate\ntheir potential use for surveillance. Across the 10 train-test cycles, the\nrandom forest and support vector machine with Naive Bayes features (NB-SVM)\neach achieved slightly more than 87% mean accuracy. The NB-SVM produced\nsignificantly more false negatives than false positives (P = 0.027), but the\nrandom forest did not, making its prevalence estimates very close to the true\nprevalence in the data. The best-performing neural network performed similarly\nto the random forest on both measures. The random forest performed as well as\nmore recently available models like the NB-SVM and the neural network, and it\nalso produced good prevalence estimates. NB-SVM may not be a good candidate for\nuse in a fully-automated surveillance workflow due to increased false\nnegatives. More sophisticated algorithms, like hierarchical convolutional\nneural networks, may not be feasible to train due to characteristics of the\ndata. Current algorithms might perform better if the data are abstracted and\nprocessed differently and if they take into account information about the\nchildren in addition to their evaluations.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 13:24:03 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 11:47:22 GMT"}, {"version": "v3", "created": "Thu, 11 Oct 2018 14:08:54 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Lee", "Scott H", ""], ["Maenner", "Matthew J", ""], ["Heilig", "Charles M", ""]]}, {"id": "1804.06234", "submitter": "Ran Zhao", "authors": "Qidi Peng, Nan Rao, Ran Zhao", "title": "Cluster Analysis on Locally Asymptotically Self-similar Processes with\n  Known Number of Clusters", "comments": "arXiv admin note: substantial text overlap with arXiv:1801.09049", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct cluster analysis on a class of locally asymptotically self-similar\nstochastic processes, which includes multifractional Brownian motion as a\nrepresentative. When the true number of clusters is supposed to be known, a new\ncovariance-based dissimilarity measure is introduced, from which we obtain the\napproximately asymptotically consistent clustering algorithms. In simulation\nstudies, clustering data sampled from multifractional Brownian motions with\ndistinct functional Hurst parameters illustrates the approximated asymptotic\nconsistency of the proposed algorithms. Clustering global financial markets'\nequity indexes returns and sovereign CDS spreads provides a successful real\nworld application.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 23:09:12 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 17:42:24 GMT"}, {"version": "v3", "created": "Wed, 22 Aug 2018 23:44:34 GMT"}, {"version": "v4", "created": "Sun, 4 Nov 2018 05:48:08 GMT"}, {"version": "v5", "created": "Thu, 2 Jan 2020 05:05:33 GMT"}, {"version": "v6", "created": "Tue, 14 Jan 2020 06:02:12 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Peng", "Qidi", ""], ["Rao", "Nan", ""], ["Zhao", "Ran", ""]]}, {"id": "1804.06300", "submitter": "Yunbo Wang", "authors": "Yunbo Wang, Zhifeng Gao, Mingsheng Long, Jianmin Wang, Philip S. Yu", "title": "PredRNN++: Towards A Resolution of the Deep-in-Time Dilemma in\n  Spatiotemporal Predictive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PredRNN++, an improved recurrent network for video predictive\nlearning. In pursuit of a greater spatiotemporal modeling capability, our\napproach increases the transition depth between adjacent states by leveraging a\nnovel recurrent unit, which is named Causal LSTM for re-organizing the spatial\nand temporal memories in a cascaded mechanism. However, there is still a\ndilemma in video predictive learning: increasingly deep-in-time models have\nbeen designed for capturing complex variations, while introducing more\ndifficulties in the gradient back-propagation. To alleviate this undesirable\neffect, we propose a Gradient Highway architecture, which provides alternative\nshorter routes for gradient flows from outputs back to long-range inputs. This\narchitecture works seamlessly with causal LSTMs, enabling PredRNN++ to capture\nshort-term and long-term dependencies adaptively. We assess our model on both\nsynthetic and real video datasets, showing its ability to ease the vanishing\ngradient problem and yield state-of-the-art prediction results even in a\ndifficult objects occlusion scenario.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 14:52:19 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 02:17:17 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Wang", "Yunbo", ""], ["Gao", "Zhifeng", ""], ["Long", "Mingsheng", ""], ["Wang", "Jianmin", ""], ["Yu", "Philip S.", ""]]}, {"id": "1804.06309", "submitter": "Xin Li", "authors": "Pengfei Zhu, Xin Li, Pascal Poupart, Guanghui Miao", "title": "On Improving Deep Reinforcement Learning for POMDPs", "comments": "We are the authors of \"On Improving Deep Reinforcement Learning for\n  POMDPs\", identifier of which is arXiv:1704.07978. Last week, I wanted to\n  update the article with new version but created a new submission which\n  identifier is 1804.06309 by mistake", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (RL) recently emerged as one of the most\ncompetitive approaches for learning in sequential decision making problems with\nfully observable environments, e.g., computer Go. However, very little work has\nbeen done in deep RL to handle partially observable environments. We propose a\nnew architecture called Action-specific Deep Recurrent Q-Network (ADRQN) to\nenhance learning performance in partially observable domains. Actions are\nencoded by a fully connected layer and coupled with a convolutional observation\nto form an action-observation pair. The time series of action-observation pairs\nare then integrated by an LSTM layer that learns latent states based on which a\nfully connected layer computes Q-values as in conventional Deep Q-Networks\n(DQNs). We demonstrate the effectiveness of our new architecture in several\npartially observable domains, including flickering Atari games.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 15:08:36 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 13:15:51 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Zhu", "Pengfei", ""], ["Li", "Xin", ""], ["Poupart", "Pascal", ""], ["Miao", "Guanghui", ""]]}, {"id": "1804.06327", "submitter": "Andrew White", "authors": "Rainier Barrett, Shaoyi Jiang, Andrew D White", "title": "Classifying Antimicrobial and Multifunctional Peptides with Bayesian\n  Network Models", "comments": "19 pages, 7 figures, 1 table, supporting information included", "journal-ref": "Peptide Science, Volume 110, Issue 4, 2018", "doi": "10.1002/pep2.24079", "report-no": null, "categories": "stat.AP q-bio.BM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian network models are finding success in characterizing\nenzyme-catalyzed reactions, slow conformational changes, predicting enzyme\ninhibition, and genomics. In this work, we apply them to statistical modeling\nof peptides by simultaneously identifying amino acid sequence motifs and using\na motif-based model to clarify the role motifs may play in antimicrobial\nactivity. We construct models of increasing sophistication, demonstrating how\nchemical knowledge of a peptide system may be embedded without requiring new\nderivation of model fitting equations after changing model structure. These\nmodels are used to construct classifiers with good performance (94% accuracy,\nMatthews correlation coefficient of 0.87) at predicting antimicrobial activity\nin peptides, while at the same time being built of interpretable parameters. We\ndemonstrate use of these models to identify peptides that are potentially both\nantimicrobial and antifouling, and show that the background distribution of\namino acids could play a greater role in activity than sequence motifs do. This\nprovides an advancement in the type of peptide activity modeling that can be\ndone and the ease in which models can be constructed.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 15:40:00 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Barrett", "Rainier", ""], ["Jiang", "Shaoyi", ""], ["White", "Andrew D", ""]]}, {"id": "1804.06352", "submitter": "J\\\"org Bachmann", "authors": "J\\\"org P. Bachmann and Johann-Christoph Freytag", "title": "High Dimensional Time Series Generators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multidimensional time series are sequences of real valued vectors. They occur\nin different areas, for example handwritten characters, GPS tracking, and\ngestures of modern virtual reality motion controllers. Within these areas, a\ncommon task is to search for similar time series. Dynamic Time Warping (DTW) is\na common distance function to compare two time series. The Edit Distance with\nReal Penalty (ERP) and the Dog Keeper Distance (DK) are two more distance\nfunctions on time series. Their behaviour has been analyzed on 1-dimensional\ntime series. However, it is not easy to evaluate their behaviour in relation to\ngrowing dimensionality. For this reason we propose two new data synthesizers\ngenerating multidimensional time series. The first synthesizer extends the well\nknown cylinder-bell-funnel (CBF) dataset to multidimensional time series. Here,\neach time series has an arbitrary type (cylinder, bell, or funnel) in each\ndimension, thus for $d$-dimensional time series there are $3^{d}$ different\nclasses. The second synthesizer (RAM) creates time series with ideas adapted\nfrom Brownian motions which is a common model of movement in physics. Finally,\nwe evaluate the applicability of a 1-nearest neighbor classifier using DTW on\ndatasets generated by our synthesizers.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 16:24:14 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2018 15:46:52 GMT"}, {"version": "v3", "created": "Thu, 19 Apr 2018 06:46:24 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Bachmann", "J\u00f6rg P.", ""], ["Freytag", "Johann-Christoph", ""]]}, {"id": "1804.06364", "submitter": "Rodrigo de Bem", "authors": "Rodrigo de Bem, Arnab Ghosh, Thalaiyasingam Ajanthan, Ondrej Miksik,\n  Adnane Boukhayma, N. Siddharth and Philip Torr", "title": "DGPose: Deep Generative Models for Human Body Analysis", "comments": "IJCV 2020 special issue on 'Generating Realistic Visual Data of Human\n  Behavior' preprint. Keywords: deep generative models, semi-supervised\n  learning, human pose estimation, variational autoencoders, generative\n  adversarial networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative modelling for human body analysis is an emerging problem with\nmany interesting applications. However, the latent space learned by such\napproaches is typically not interpretable, resulting in less flexibility. In\nthis work, we present deep generative models for human body analysis in which\nthe body pose and the visual appearance are disentangled. Such a\ndisentanglement allows independent manipulation of pose and appearance, and\nhence enables applications such as pose-transfer without specific training for\nsuch a task. Our proposed models, the Conditional-DGPose and the Semi-DGPose,\nhave different characteristics. In the first, body pose labels are taken as\nconditioners, from a fully-supervised training set. In the second, our\nstructured semi-supervised approach allows for pose estimation to be performed\nby the model itself and relaxes the need for labelled data. Therefore, the\nSemi-DGPose aims for the joint understanding and generation of people in\nimages. It is not only capable of mapping images to interpretable latent\nrepresentations but also able to map these representations back to the image\nspace. We compare our models with relevant baselines, the ClothNet-Body and the\nPose Guided Person Generation networks, demonstrating their merits on the\nHuman3.6M, ChictopiaPlus and DeepFashion benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 16:43:35 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 19:48:00 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["de Bem", "Rodrigo", ""], ["Ghosh", "Arnab", ""], ["Ajanthan", "Thalaiyasingam", ""], ["Miksik", "Ondrej", ""], ["Boukhayma", "Adnane", ""], ["Siddharth", "N.", ""], ["Torr", "Philip", ""]]}, {"id": "1804.06378", "submitter": "Hamed Sarvari", "authors": "Hamed Sarvari, Carlotta Domeniconi, Giovanni Stilo", "title": "Graph-based Selective Outlier Ensembles", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ensemble technique is characterized by the mechanism that generates the\ncomponents and by the mechanism that combines them. A common way to achieve the\nconsensus is to enable each component to equally participate in the aggregation\nprocess. A problem with this approach is that poor components are likely to\nnegatively affect the quality of the consensus result. To address this issue,\nalternatives have been explored in the literature to build selective classifier\nand cluster ensembles, where only a subset of the components contributes to the\ncomputation of the consensus. Of the family of ensemble methods, outlier\nensembles are the least studied. Only recently, the selection problem for\noutlier ensembles has been discussed. In this work we define a new graph-based\nclass of ranking selection methods. A method in this class is characterized by\ntwo main steps: (1) Mapping the rankings onto a graph structure; and (2) Mining\nthe resulting graph to identify a subset of rankings. We define a specific\ninstance of the graph-based ranking selection class. Specifically, we map the\nproblem of selecting ensemble components onto a mining problem in a graph. An\nextensive evaluation was conducted on a variety of heterogeneous data and\nmethods. Our empirical results show that our approach outperforms\nstate-of-the-art selective outlier ensemble techniques.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 17:11:23 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Sarvari", "Hamed", ""], ["Domeniconi", "Carlotta", ""], ["Stilo", "Giovanni", ""]]}, {"id": "1804.06459", "submitter": "Zeyu Zheng", "authors": "Zeyu Zheng, Junhyuk Oh, Satinder Singh", "title": "On Learning Intrinsic Rewards for Policy Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many sequential decision making tasks, it is challenging to design reward\nfunctions that help an RL agent efficiently learn behavior that is considered\ngood by the agent designer. A number of different formulations of the\nreward-design problem, or close variants thereof, have been proposed in the\nliterature. In this paper we build on the Optimal Rewards Framework of Singh\net.al. that defines the optimal intrinsic reward function as one that when used\nby an RL agent achieves behavior that optimizes the task-specifying or\nextrinsic reward function. Previous work in this framework has shown how good\nintrinsic reward functions can be learned for lookahead search based planning\nagents. Whether it is possible to learn intrinsic reward functions for learning\nagents remains an open problem. In this paper we derive a novel algorithm for\nlearning intrinsic rewards for policy-gradient based learning agents. We\ncompare the performance of an augmented agent that uses our algorithm to\nprovide additive intrinsic rewards to an A2C-based policy learner (for Atari\ngames) and a PPO-based policy learner (for Mujoco domains) with a baseline\nagent that uses the same policy learners but with only extrinsic rewards. Our\nresults show improved performance on most but not all of the domains.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 20:04:09 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 17:50:24 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Zheng", "Zeyu", ""], ["Oh", "Junhyuk", ""], ["Singh", "Satinder", ""]]}, {"id": "1804.06461", "submitter": "Gang Chen", "authors": "Gang Chen and Yiming Peng and Mengjie Zhang", "title": "An Adaptive Clipping Approach for Proximal Policy Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Very recently proximal policy optimization (PPO) algorithms have been\nproposed as first-order optimization methods for effective reinforcement\nlearning. While PPO is inspired by the same learning theory that justifies\ntrust region policy optimization (TRPO), PPO substantially simplifies algorithm\ndesign and improves data efficiency by performing multiple epochs of\n\\emph{clipped policy optimization} from sampled data. Although clipping in PPO\nstands for an important new mechanism for efficient and reliable policy update,\nit may fail to adaptively improve learning performance in accordance with the\nimportance of each sampled state. To address this issue, a new surrogate\nlearning objective featuring an adaptive clipping mechanism is proposed in this\npaper, enabling us to develop a new algorithm, known as PPO-$\\lambda$.\nPPO-$\\lambda$ optimizes policies repeatedly based on a theoretical target for\nadaptive policy improvement. Meanwhile, destructively large policy update can\nbe effectively prevented through both clipping and adaptive control of a\nhyperparameter $\\lambda$ in PPO-$\\lambda$, ensuring high learning reliability.\nPPO-$\\lambda$ enjoys the same simple and efficient design as PPO. Empirically\non several Atari game playing tasks and benchmark control tasks, PPO-$\\lambda$\nalso achieved clearly better performance than PPO.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 20:24:27 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Chen", "Gang", ""], ["Peng", "Yiming", ""], ["Zhang", "Mengjie", ""]]}, {"id": "1804.06481", "submitter": "Yao Zhou", "authors": "Yao Zhou, Arun Reddy Nelakurthi, Jingrui He", "title": "Unlearn What You Have Learned: Adaptive Crowd Teaching with\n  Exponentially Decayed Memory Learners", "comments": "10 pages, KDD 18", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing demand for large amount of labeled data, crowdsourcing\nhas been used in many large-scale data mining applications. However, most\nexisting works in crowdsourcing mainly focus on label inference and incentive\ndesign. In this paper, we address a different problem of adaptive crowd\nteaching, which is a sub-area of machine teaching in the context of\ncrowdsourcing. Compared with machines, human beings are extremely good at\nlearning a specific target concept (e.g., classifying the images into given\ncategories) and they can also easily transfer the learned concepts into similar\nlearning tasks. Therefore, a more effective way of utilizing crowdsourcing is\nby supervising the crowd to label in the form of teaching. In order to perform\nthe teaching and expertise estimation simultaneously, we propose an adaptive\nteaching framework named JEDI to construct the personalized optimal teaching\nset for the crowdsourcing workers. In JEDI teaching, the teacher assumes that\neach learner has an exponentially decayed memory. Furthermore, it ensures\ncomprehensiveness in the learning process by carefully balancing teaching\ndiversity and learner's accurate learning in terms of teaching usefulness.\nFinally, we validate the effectiveness and efficacy of JEDI teaching in\ncomparison with the state-of-the-art techniques on multiple data sets with both\nsynthetic learners and real crowdsourcing workers.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 22:02:02 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 19:01:46 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Zhou", "Yao", ""], ["Nelakurthi", "Arun Reddy", ""], ["He", "Jingrui", ""]]}, {"id": "1804.06498", "submitter": "Mahdi Abavisani", "authors": "Mahdi Abavisani, Vishal M. Patel", "title": "Deep Multimodal Subspace Clustering Networks", "comments": null, "journal-ref": "IEEE Journal of Selected Topics in Signal Processing, vol. 12, no.\n  6, pp. 1601-1614, Dec. 2018", "doi": "10.1109/JSTSP.2018.2875385", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present convolutional neural network (CNN) based approaches for\nunsupervised multimodal subspace clustering. The proposed framework consists of\nthree main stages - multimodal encoder, self-expressive layer, and multimodal\ndecoder. The encoder takes multimodal data as input and fuses them to a latent\nspace representation. The self-expressive layer is responsible for enforcing\nthe self-expressiveness property and acquiring an affinity matrix corresponding\nto the data points. The decoder reconstructs the original input data. The\nnetwork uses the distance between the decoder's reconstruction and the original\ninput in its training. We investigate early, late and intermediate fusion\ntechniques and propose three different encoders corresponding to them for\nspatial fusion. The self-expressive layers and multimodal decoders are\nessentially the same for different spatial fusion-based approaches. In addition\nto various spatial fusion-based methods, an affinity fusion-based network is\nalso proposed in which the self-expressive layer corresponding to different\nmodalities is enforced to be the same. Extensive experiments on three datasets\nshow that the proposed methods significantly outperform the state-of-the-art\nmultimodal subspace clustering methods.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 23:04:33 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 21:53:14 GMT"}, {"version": "v3", "created": "Fri, 4 Jan 2019 20:19:14 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Abavisani", "Mahdi", ""], ["Patel", "Vishal M.", ""]]}, {"id": "1804.06500", "submitter": "Andrew Cotter", "authors": "Andrew Cotter, Heinrich Jiang, Karthik Sridharan", "title": "Two-Player Games for Efficient Non-Convex Constrained Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, constrained optimization has become increasingly relevant to\nthe machine learning community, with applications including Neyman-Pearson\nclassification, robust optimization, and fair machine learning. A natural\napproach to constrained optimization is to optimize the Lagrangian, but this is\nnot guaranteed to work in the non-convex setting, and, if using a first-order\nmethod, cannot cope with non-differentiable constraints (e.g. constraints on\nrates or proportions).\n  The Lagrangian can be interpreted as a two-player game played between a\nplayer who seeks to optimize over the model parameters, and a player who wishes\nto maximize over the Lagrange multipliers. We propose a non-zero-sum variant of\nthe Lagrangian formulation that can cope with non-differentiable--even\ndiscontinuous--constraints, which we call the \"proxy-Lagrangian\". The first\nplayer minimizes external regret in terms of easy-to-optimize \"proxy\nconstraints\", while the second player enforces the original constraints by\nminimizing swap regret.\n  For this new formulation, as for the Lagrangian in the non-convex setting,\nthe result is a stochastic classifier. For both the proxy-Lagrangian and\nLagrangian formulations, however, we prove that this classifier, instead of\nhaving unbounded size, can be taken to be a distribution over no more than m+1\nmodels (where m is the number of constraints). This is a significant\nimprovement in practical terms.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 23:13:28 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 20:54:06 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Cotter", "Andrew", ""], ["Jiang", "Heinrich", ""], ["Sridharan", "Karthik", ""]]}, {"id": "1804.06518", "submitter": "Holakou Rahmanian", "authors": "Corinna Cortes, Vitaly Kuznetsov, Mehryar Mohri, Holakou Rahmanian,\n  Manfred K. Warmuth", "title": "Online Non-Additive Path Learning under Full and Partial Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of online path learning with non-additive gains, which\nis a central problem appearing in several applications, including ensemble\nstructured prediction. We present new online algorithms for path learning with\nnon-additive count-based gains for the three settings of full information,\nsemi-bandit and full bandit with very favorable regret guarantees. A key\ncomponent of our algorithms is the definition and computation of an\nintermediate context-dependent automaton that enables us to use existing\nalgorithms designed for additive gains. We further apply our methods to the\nimportant application of ensemble structured prediction. Finally, beyond\ncount-based gains, we give an efficient implementation of the EXP3 algorithm\nfor the full bandit setting with an arbitrary (non-additive) gain.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 00:53:29 GMT"}, {"version": "v2", "created": "Thu, 19 Apr 2018 09:15:28 GMT"}, {"version": "v3", "created": "Tue, 18 Sep 2018 07:30:16 GMT"}, {"version": "v4", "created": "Tue, 19 Mar 2019 02:17:56 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Cortes", "Corinna", ""], ["Kuznetsov", "Vitaly", ""], ["Mohri", "Mehryar", ""], ["Rahmanian", "Holakou", ""], ["Warmuth", "Manfred K.", ""]]}, {"id": "1804.06537", "submitter": "Shujian Yu", "authors": "Shujian Yu, Kristoffer Wickstr{\\o}m, Robert Jenssen, Jose C. Principe", "title": "Understanding Convolutional Neural Networks with Information Theory: An\n  Initial Exploration", "comments": "Paper accepted by IEEE Transactions on Neural Networks and Learning\n  Systems (TNNLS). Code for 1) estimating information quantities, 2) plotting\n  the information plane, and 3) selecting convolutional filters, is available\n  from (MATLAB)\n  https://drive.google.com/drive/folders/1DJYshWIiijKWrFKrztW9FgTzGfMV3D8M?usp=sharing\n  or (Python) https://github.com/Wickstrom/InfExperiment", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The matrix-based Renyi's \\alpha-entropy functional and its multivariate\nextension were recently developed in terms of the normalized eigenspectrum of a\nHermitian matrix of the projected data in a reproducing kernel Hilbert space\n(RKHS). However, the utility and possible applications of these new estimators\nare rather new and mostly unknown to practitioners. In this paper, we first\nshow that our estimators enable straightforward measurement of information flow\nin realistic convolutional neural networks (CNN) without any approximation.\nThen, we introduce the partial information decomposition (PID) framework and\ndevelop three quantities to analyze the synergy and redundancy in convolutional\nlayer representations. Our results validate two fundamental data processing\ninequalities and reveal some fundamental properties concerning the training of\nCNN.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 03:16:17 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2018 05:25:38 GMT"}, {"version": "v3", "created": "Thu, 21 Mar 2019 05:55:51 GMT"}, {"version": "v4", "created": "Fri, 6 Sep 2019 16:46:11 GMT"}, {"version": "v5", "created": "Thu, 23 Jan 2020 19:15:06 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["Yu", "Shujian", ""], ["Wickstr\u00f8m", "Kristoffer", ""], ["Jenssen", "Robert", ""], ["Principe", "Jose C.", ""]]}, {"id": "1804.06546", "submitter": "Markus Beissinger", "authors": "Markus Beissinger", "title": "Deep Generative Networks For Sequence Prediction", "comments": "University of Pennsylvania Computer Science Master's thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis investigates unsupervised time series representation learning for\nsequence prediction problems, i.e. generating nice-looking input samples given\na previous history, for high dimensional input sequences by decoupling the\nstatic input representation from the recurrent sequence representation. We\nintroduce three models based on Generative Stochastic Networks (GSN) for\nunsupervised sequence learning and prediction. Experimental results for these\nthree models are presented on pixels of sequential handwritten digit (MNIST)\ndata, videos of low-resolution bouncing balls, and motion capture data. The\nmain contribution of this thesis is to provide evidence that GSNs are a viable\nframework to learn useful representations of complex sequential input data, and\nto suggest a new framework for deep generative models to learn complex\nsequences by decoupling static input representations from dynamic time\ndependency representations.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 04:28:09 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Beissinger", "Markus", ""]]}, {"id": "1804.06561", "submitter": "Song Mei", "authors": "Song Mei, Andrea Montanari, Phan-Minh Nguyen", "title": "A Mean Field View of the Landscape of Two-Layers Neural Networks", "comments": "103 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.stat-mech cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-layer neural networks are among the most powerful models in machine\nlearning, yet the fundamental reasons for this success defy mathematical\nunderstanding. Learning a neural network requires to optimize a non-convex\nhigh-dimensional objective (risk function), a problem which is usually attacked\nusing stochastic gradient descent (SGD). Does SGD converge to a global optimum\nof the risk or only to a local optimum? In the first case, does this happen\nbecause local minima are absent, or because SGD somehow avoids them? In the\nsecond, why do local minima reached by SGD have good generalization properties?\n  In this paper we consider a simple case, namely two-layers neural networks,\nand prove that -in a suitable scaling limit- SGD dynamics is captured by a\ncertain non-linear partial differential equation (PDE) that we call\ndistributional dynamics (DD). We then consider several specific examples, and\nshow how DD can be used to prove convergence of SGD to networks with nearly\nideal generalization error. This description allows to 'average-out' some of\nthe complexities of the landscape of neural networks, and can be used to prove\na general convergence result for noisy SGD.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 05:31:45 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 06:21:23 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Mei", "Song", ""], ["Montanari", "Andrea", ""], ["Nguyen", "Phan-Minh", ""]]}, {"id": "1804.06620", "submitter": "Giuseppe Casalicchio", "authors": "Giuseppe Casalicchio, Christoph Molnar, Bernd Bischl", "title": "Visualizing the Feature Importance for Black Box Models", "comments": "To Appear in Machine Learning and Knowledge Discovery in Databases:\n  European Conference, ECML PKDD 2018, Dublin, Ireland, September 10 to 14,\n  2018, Proceedings, Part I", "journal-ref": "Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n  2018. Lecture Notes in Computer Science, vol 11051", "doi": "10.1007/978-3-030-10925-7_40", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, a large amount of model-agnostic methods to improve the\ntransparency, trustability and interpretability of machine learning models have\nbeen developed. We introduce local feature importance as a local version of a\nrecent model-agnostic global feature importance method. Based on local feature\nimportance, we propose two visual tools: partial importance (PI) and individual\nconditional importance (ICI) plots which visualize how changes in a feature\naffect the model performance on average, as well as for individual\nobservations. Our proposed methods are related to partial dependence (PD) and\nindividual conditional expectation (ICE) plots, but visualize the expected\n(conditional) feature importance instead of the expected (conditional)\nprediction. Furthermore, we show that averaging ICI curves across observations\nyields a PI curve, and integrating the PI curve with respect to the\ndistribution of the considered feature results in the global feature\nimportance. Another contribution of our paper is the Shapley feature\nimportance, which fairly distributes the overall performance of a model among\nthe features according to the marginal contributions and which can be used to\ncompare the feature importance across different models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 09:35:38 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 14:30:25 GMT"}, {"version": "v3", "created": "Fri, 28 Dec 2018 15:54:54 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Casalicchio", "Giuseppe", ""], ["Molnar", "Christoph", ""], ["Bischl", "Bernd", ""]]}, {"id": "1804.06673", "submitter": "Markus Heinonen", "authors": "Markus Heinonen, Maria Osmala, Henrik Mannerstr\\\"om, Janne Wallenius,\n  Samuel Kaski, Juho Rousu, Harri L\\\"ahdesm\\\"aki", "title": "Bayesian Metabolic Flux Analysis reveals intracellular flux couplings", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metabolic flux balance analyses are a standard tool in analysing metabolic\nreaction rates compatible with measurements, steady-state and the metabolic\nreaction network stoichiometry. Flux analysis methods commonly place\nunrealistic assumptions on fluxes due to the convenience of formulating the\nproblem as a linear programming model, and most methods ignore the notable\nuncertainty in flux estimates. We introduce a novel paradigm of Bayesian\nmetabolic flux analysis that models the reactions of the whole genome-scale\ncellular system in probabilistic terms, and can infer the full flux vector\ndistribution of genome-scale metabolic systems based on exchange and\nintracellular (e.g. 13C) flux measurements, steady-state assumptions, and\ntarget function assumptions. The Bayesian model couples all fluxes jointly\ntogether in a simple truncated multivariate posterior distribution, which\nreveals informative flux couplings. Our model is a plug-in replacement to\nconventional metabolic balance methods, such as flux balance analysis (FBA).\nOur experiments indicate that we can characterise the genome-scale flux\ncovariances, reveal flux couplings, and determine more intracellular unobserved\nfluxes in C. acetobutylicum from 13C data than flux variability analysis. The\nCOBRA compatible software is available at github.com/markusheinonen/bamfa\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 12:19:34 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Heinonen", "Markus", ""], ["Osmala", "Maria", ""], ["Mannerstr\u00f6m", "Henrik", ""], ["Wallenius", "Janne", ""], ["Kaski", "Samuel", ""], ["Rousu", "Juho", ""], ["L\u00e4hdesm\u00e4ki", "Harri", ""]]}, {"id": "1804.06679", "submitter": "Bernhard C. Geiger", "authors": "Rana Ali Amjad and Kairen Liu and Bernhard C. Geiger", "title": "Understanding Neural Networks and Individual Neuron Importance via\n  Information-Ordered Cumulative Ablation", "comments": "12 pages; accepted for publication in IEEE Transactions on Neural\n  Networks and Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the use of three information-theoretic\nquantities -- entropy, mutual information with the class variable, and a class\nselectivity measure based on Kullback-Leibler divergence -- to understand and\nstudy the behavior of already trained fully-connected feed-forward neural\nnetworks. We analyze the connection between these information-theoretic\nquantities and classification performance on the test set by cumulatively\nablating neurons in networks trained on MNIST, FashionMNIST, and CIFAR-10. Our\nresults parallel those recently published by Morcos et al., indicating that\nclass selectivity is not a good indicator for classification performance.\nHowever, looking at individual layers separately, both mutual information and\nclass selectivity are positively correlated with classification performance, at\nleast for networks with ReLU activation functions. We provide explanations for\nthis phenomenon and conclude that it is ill-advised to compare the proposed\ninformation-theoretic quantities across layers. Furthermore, we show that\ncumulative ablation of neurons with ascending or descending\ninformation-theoretic quantities can be used to formulate hypotheses regarding\nthe joint behavior of multiple neurons, such as redundancy and synergy, with\ncomparably low computational cost. We also draw connections to the information\nbottleneck theory for neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 12:29:24 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 11:35:26 GMT"}, {"version": "v3", "created": "Wed, 3 Jul 2019 06:52:01 GMT"}, {"version": "v4", "created": "Wed, 9 Jun 2021 15:28:37 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Amjad", "Rana Ali", ""], ["Liu", "Kairen", ""], ["Geiger", "Bernhard C.", ""]]}, {"id": "1804.06739", "submitter": "Ohad Shamir", "authors": "Ohad Shamir", "title": "Are ResNets Provably Better than Linear Predictors?", "comments": "Comparison to previous arXiv version: Minor changes to incorporate\n  comments of NIPS 2018 reviewers (main results are unaffected)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A residual network (or ResNet) is a standard deep neural net architecture,\nwith state-of-the-art performance across numerous applications. The main\npremise of ResNets is that they allow the training of each layer to focus on\nfitting just the residual of the previous layer's output and the target output.\nThus, we should expect that the trained network is no worse than what we can\nobtain if we remove the residual layers and train a shallower network instead.\nHowever, due to the non-convexity of the optimization problem, it is not at all\nclear that ResNets indeed achieve this behavior, rather than getting stuck at\nsome arbitrarily poor local minimum. In this paper, we rigorously prove that\narbitrarily deep, nonlinear residual units indeed exhibit this behavior, in the\nsense that the optimization landscape contains no local minima with value above\nwhat can be obtained with a linear predictor (namely a 1-layer network).\nNotably, we show this under minimal or no assumptions on the precise network\narchitecture, data distribution, or loss function used. We also provide a\nquantitative analysis of approximate stationary points for this problem.\nFinally, we show that with a certain tweak to the architecture, training the\nnetwork with standard stochastic gradient descent achieves an objective value\nclose or better than any linear predictor.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 14:06:15 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 16:10:51 GMT"}, {"version": "v3", "created": "Fri, 11 May 2018 10:58:10 GMT"}, {"version": "v4", "created": "Thu, 27 Sep 2018 10:30:26 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Shamir", "Ohad", ""]]}, {"id": "1804.06755", "submitter": "Mathieu Guillame-Bert", "authors": "Mathieu Guillame-Bert and Olivier Teytaud", "title": "Exact Distributed Training: Random Forest with Billions of Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an exact distributed algorithm to train Random Forest models as\nwell as other decision forest models without relying on approximating best\nsplit search. We explain the proposed algorithm and compare it to related\napproaches for various complexity measures (time, ram, disk, and network\ncomplexity analysis). We report its running performances on artificial and\nreal-world datasets of up to 18 billions examples. This figure is several\norders of magnitude larger than datasets tackled in the existing literature.\nFinally, we empirically show that Random Forest benefits from being trained on\nmore data, even in the case of already gigantic datasets. Given a dataset with\n17.3B examples with 82 features (3 numerical, other categorical with high\narity), our implementation trains a tree in 22h.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 14:20:53 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Guillame-Bert", "Mathieu", ""], ["Teytaud", "Olivier", ""]]}, {"id": "1804.06769", "submitter": "Herbert Hu", "authors": "Guangneng Hu, Yu Zhang, Qiang Yang", "title": "CoNet: Collaborative Cross Networks for Cross-Domain Recommendation", "comments": "Deep transfer learning for recommender systems", "journal-ref": "CIKM 2018", "doi": "10.1145/3269206.3271684", "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cross-domain recommendation technique is an effective way of alleviating\nthe data sparse issue in recommender systems by leveraging the knowledge from\nrelevant domains. Transfer learning is a class of algorithms underlying these\ntechniques. In this paper, we propose a novel transfer learning approach for\ncross-domain recommendation by using neural networks as the base model. In\ncontrast to the matrix factorization based cross-domain techniques, our method\nis deep transfer learning, which can learn complex user-item interaction\nrelationships. We assume that hidden layers in two base networks are connected\nby cross mappings, leading to the collaborative cross networks (CoNet). CoNet\nenables dual knowledge transfer across domains by introducing cross connections\nfrom one base network to another and vice versa. CoNet is achieved in\nmulti-layer feedforward networks by adding dual connections and joint loss\nfunctions, which can be trained efficiently by back-propagation. The proposed\nmodel is thoroughly evaluated on two large real-world datasets. It outperforms\nbaselines by relative improvements of 7.84\\% in NDCG. We demonstrate the\nnecessity of adaptively selecting representations to transfer. Our model can\nreduce tens of thousands training examples comparing with non-transfer methods\nand still has the competitive performance with them.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 14:48:21 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 17:12:11 GMT"}, {"version": "v3", "created": "Tue, 4 Dec 2018 14:00:05 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Hu", "Guangneng", ""], ["Zhang", "Yu", ""], ["Yang", "Qiang", ""]]}, {"id": "1804.06776", "submitter": "Aya Abdelsalam Ismail", "authors": "Aya Abdelsalam Ismail, Timothy Wood and H\\'ector Corrada Bravo", "title": "Improving Long-Horizon Forecasts with Expectation-Biased LSTM Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  State-of-the-art forecasting methods using Recurrent Neural Net- works (RNN)\nbased on Long-Short Term Memory (LSTM) cells have shown exceptional performance\ntargeting short-horizon forecasts, e.g given a set of predictor features,\nforecast a target value for the next few time steps in the future. However, in\nmany applica- tions, the performance of these methods decays as the forecasting\nhorizon extends beyond these few time steps. This paper aims to explore the\nchallenges of long-horizon forecasting using LSTM networks. Here, we illustrate\nthe long-horizon forecasting problem in datasets from neuroscience and energy\nsupply management. We then propose expectation-biasing, an approach motivated\nby the literature of Dynamic Belief Networks, as a solution to improve\nlong-horizon forecasting using LSTMs. We propose two LSTM ar- chitectures along\nwith two methods for expectation biasing that significantly outperforms\nstandard practice.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 15:05:44 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Ismail", "Aya Abdelsalam", ""], ["Wood", "Timothy", ""], ["Bravo", "H\u00e9ctor Corrada", ""]]}, {"id": "1804.06802", "submitter": "Binxin Ru", "authors": "Diego Granziol, Binxin Ru, Stefan Zohren, Xiaowen Dong, Michael\n  Osborne, Stephen Roberts", "title": "Entropic Spectral Learning for Large-Scale Graphs", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph spectra have been successfully used to classify network types, compute\nthe similarity between graphs, and determine the number of communities in a\nnetwork. For large graphs, where an eigen-decomposition is infeasible,\niterative moment matched approximations to the spectra and kernel smoothing are\ntypically used. We show that the underlying moment information is lost when\nusing kernel smoothing. We further propose a spectral density approximation\nbased on the method of Maximum Entropy, for which we develop a new algorithm.\nThis method matches moments exactly and is everywhere positive. We demonstrate\nits effectiveness and superiority over existing approaches in learning graph\nspectra, via experiments on both synthetic networks, such as the\nErd\\H{o}s-R\\'{e}nyi and Barab\\'{a}si-Albert random graphs, and real-world\nnetworks, such as the social networks for Orkut, YouTube, and Amazon from the\nSNAP dataset.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 16:23:10 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 00:09:52 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Granziol", "Diego", ""], ["Ru", "Binxin", ""], ["Zohren", "Stefan", ""], ["Dong", "Xiaowen", ""], ["Osborne", "Michael", ""], ["Roberts", "Stephen", ""]]}, {"id": "1804.06819", "submitter": "Sao Mai Nguyen", "authors": "Sao Mai Nguyen and Pierre-Yves Oudeyer", "title": "Active choice of teachers, learning strategies and goals for a socially\n  guided intrinsic motivation learner", "comments": null, "journal-ref": "Paladyn, Springer Verlag, 2012, 3 (3), pp.136-146", "doi": "10.2478/s13230-013-0110-z", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an active learning architecture that allows a robot to actively\nlearn which data collection strategy is most efficient for acquiring motor\nskills to achieve multiple outcomes, and generalise over its experience to\nachieve new outcomes. The robot explores its environment both via interactive\nlearning and goal-babbling. It learns at the same time when, who and what to\nactively imitate from several available teachers, and learns when not to use\nsocial guidance but use active goal-oriented self-exploration. This is\nformalised in the framework of life-long strategic learning. The proposed\narchitecture, called Socially Guided Intrinsic Motivation with Active Choice of\nTeacher and Strategy (SGIM-ACTS), relies on hierarchical active decisions of\nwhat and how to learn driven by empirical evaluation of learning progress for\neach learning strategy. We illustrate with an experiment where a simulated\nrobot learns to control its arm for realising two kinds of different outcomes.\nIt has to choose actively and hierarchically at each learning episode: 1) what\nto learn: which outcome is most interesting to select as a goal to focus on for\ngoal-directed exploration; 2) how to learn: which data collection strategy to\nuse among self-exploration, mimicry and emulation; 3) once he has decided when\nand what to imitate by choosing mimicry or emulation, then he has to choose who\nto imitate, from a set of different teachers. We show that SGIM-ACTS learns\nsignificantly more efficiently than using single learning strategies, and\ncoherently selects the best strategy with respect to the chosen outcome, taking\nadvantage of the available teachers (with different levels of skills).\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 17:11:29 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Nguyen", "Sao Mai", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1804.06872", "submitter": "Bo Han", "authors": "Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor\n  Tsang, Masashi Sugiyama", "title": "Co-teaching: Robust Training of Deep Neural Networks with Extremely\n  Noisy Labels", "comments": "NIPS 2018 camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning with noisy labels is practically challenging, as the capacity\nof deep models is so high that they can totally memorize these noisy labels\nsooner or later during training. Nonetheless, recent studies on the\nmemorization effects of deep neural networks show that they would first\nmemorize training data of clean labels and then those of noisy labels.\nTherefore in this paper, we propose a new deep learning paradigm called\nCo-teaching for combating with noisy labels. Namely, we train two deep neural\nnetworks simultaneously, and let them teach each other given every mini-batch:\nfirstly, each network feeds forward all data and selects some data of possibly\nclean labels; secondly, two networks communicate with each other what data in\nthis mini-batch should be used for training; finally, each network back\npropagates the data selected by its peer network and updates itself. Empirical\nresults on noisy versions of MNIST, CIFAR-10 and CIFAR-100 demonstrate that\nCo-teaching is much superior to the state-of-the-art methods in the robustness\nof trained deep models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 18:42:31 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 13:37:50 GMT"}, {"version": "v3", "created": "Tue, 30 Oct 2018 09:14:05 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Han", "Bo", ""], ["Yao", "Quanming", ""], ["Yu", "Xingrui", ""], ["Niu", "Gang", ""], ["Xu", "Miao", ""], ["Hu", "Weihua", ""], ["Tsang", "Ivor", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1804.06893", "submitter": "Chiyuan Zhang", "authors": "Chiyuan Zhang and Oriol Vinyals and Remi Munos and Samy Bengio", "title": "A Study on Overfitting in Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent years have witnessed significant progresses in deep Reinforcement\nLearning (RL). Empowered with large scale neural networks, carefully designed\narchitectures, novel training algorithms and massively parallel computing\ndevices, researchers are able to attack many challenging RL problems. However,\nin machine learning, more training power comes with a potential risk of more\noverfitting. As deep RL techniques are being applied to critical problems such\nas healthcare and finance, it is important to understand the generalization\nbehaviors of the trained agents. In this paper, we conduct a systematic study\nof standard RL agents and find that they could overfit in various ways.\nMoreover, overfitting could happen \"robustly\": commonly used techniques in RL\nthat add stochasticity do not necessarily prevent or detect overfitting. In\nparticular, the same agents and learning algorithms could have drastically\ndifferent test performance, even when all of them achieve optimal rewards\nduring training. The observations call for more principled and careful\nevaluation protocols in RL. We conclude with a general discussion on\noverfitting in RL and a study of the generalization behaviors from the\nperspective of inductive bias.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 19:49:13 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 16:49:52 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Zhang", "Chiyuan", ""], ["Vinyals", "Oriol", ""], ["Munos", "Remi", ""], ["Bengio", "Samy", ""]]}, {"id": "1804.06896", "submitter": "Lu Duan", "authors": "Lu Duan, Haoyuan Hu, Yu Qian, Yu Gong, Xiaodong Zhang, Yinghui Xu,\n  Jiangwen Wei", "title": "A Multi-task Selected Learning Approach for Solving 3D Flexible Bin\n  Packing Problem", "comments": "8 pages, 34figures. arXiv admin note: text overlap with\n  arXiv:1708.05930", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A 3D flexible bin packing problem (3D-FBPP) arises from the process of\nwarehouse packing in e-commerce. An online customer's order usually contains\nseveral items and needs to be packed as a whole before shipping. In particular,\n5% of tens of millions of packages are using plastic wrapping as outer\npackaging every day, which brings pressure on the plastic surface minimization\nto save traditional logistics costs. Because of the huge practical\nsignificance, we focus on the issue of packing cuboid-shaped items orthogonally\ninto a least-surface-area bin. The existing heuristic methods for classic 3D\nbin packing don't work well for this particular NP-hard problem and designing a\ngood problem-specific heuristic is non-trivial. In this paper, rather than\ndesigning heuristics, we propose a novel multi-task framework based on Selected\nLearning to learn a heuristic-like policy that generates the sequence and\norientations of items to be packed simultaneously. Through comprehensive\nexperiments on a large scale real-world transaction order dataset and online AB\ntests, we show: 1) our selected learning method trades off the imbalance and\ncorrelation among the tasks and significantly outperforms the single task\nPointer Network and the multi-task network without selected learning; 2) our\nmethod obtains an average 5.47% cost reduction than the well-designed greedy\nalgorithm which is previously used in our online production system.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 07:00:42 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 02:52:27 GMT"}, {"version": "v3", "created": "Fri, 15 Feb 2019 06:20:39 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Duan", "Lu", ""], ["Hu", "Haoyuan", ""], ["Qian", "Yu", ""], ["Gong", "Yu", ""], ["Zhang", "Xiaodong", ""], ["Xu", "Yinghui", ""], ["Wei", "Jiangwen", ""]]}, {"id": "1804.06909", "submitter": "John Moore", "authors": "John Moore, Joel Pfeiffer, Kai Wei, Rishabh Iyer, Denis Charles, Ran\n  Gilad-Bachrach, Levi Boyles, Eren Manavoglu", "title": "Modeling and Simultaneously Removing Bias via Adversarial Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real world systems, the predictions of deployed Machine Learned models\naffect the training data available to build subsequent models. This introduces\na bias in the training data that needs to be addressed. Existing solutions to\nthis problem attempt to resolve the problem by either casting this in the\nreinforcement learning framework or by quantifying the bias and re-weighting\nthe loss functions. In this work, we develop a novel Adversarial Neural Network\n(ANN) model, an alternative approach which creates a representation of the data\nthat is invariant to the bias. We take the Paid Search auction as our working\nexample and ad display position features as the confounding features for this\nsetting. We show the success of this approach empirically on both synthetic\ndata as well as real world paid search auction data from a major search engine.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 20:33:37 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Moore", "John", ""], ["Pfeiffer", "Joel", ""], ["Wei", "Kai", ""], ["Iyer", "Rishabh", ""], ["Charles", "Denis", ""], ["Gilad-Bachrach", "Ran", ""], ["Boyles", "Levi", ""], ["Manavoglu", "Eren", ""]]}, {"id": "1804.06912", "submitter": "Gabriele Tolomei", "authors": "Gabriele Tolomei, Mounia Lalmas, Ayman Farahat, Andrew Haines", "title": "You Must Have Clicked on this Ad by Mistake! Data-Driven Identification\n  of Accidental Clicks on Mobile Ads with Applications to Advertiser Cost\n  Discounting and Click-Through Rate Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the cost per click (CPC) pricing model, an advertiser pays an ad network\nonly when a user clicks on an ad; in turn, the ad network gives a share of that\nrevenue to the publisher where the ad was impressed. Still, advertisers may be\nunsatisfied with ad networks charging them for \"valueless\" clicks, or so-called\naccidental clicks. [...] Charging advertisers for such clicks is detrimental in\nthe long term as the advertiser may decide to run their campaigns on other ad\nnetworks. In addition, machine-learned click models trained to predict which ad\nwill bring the highest revenue may overestimate an ad click-through rate, and\nas a consequence negatively impacting revenue for both the ad network and the\npublisher. In this work, we propose a data-driven method to detect accidental\nclicks from the perspective of the ad network. We collect observations of time\nspent by users on a large set of ad landing pages - i.e., dwell time. We notice\nthat the majority of per-ad distributions of dwell time fit to a mixture of\ndistributions, where each component may correspond to a particular type of\nclicks, the first one being accidental. We then estimate dwell time thresholds\nof accidental clicks from that component. Using our method to identify\naccidental clicks, we then propose a technique that smoothly discounts the\nadvertiser's cost of accidental clicks at billing time. Experiments conducted\non a large dataset of ads served on Yahoo mobile apps confirm that our\nthresholds are stable over time, and revenue loss in the short term is\nmarginal. We also compare the performance of an existing machine-learned click\nmodel trained on all ad clicks with that of the same model trained only on\nnon-accidental clicks. There, we observe an increase in both ad click-through\nrate (+3.9%) and revenue (+0.2%) on ads served by the Yahoo Gemini network when\nusing the latter. [...]\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 18:00:06 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Tolomei", "Gabriele", ""], ["Lalmas", "Mounia", ""], ["Farahat", "Ayman", ""], ["Haines", "Andrew", ""]]}, {"id": "1804.06913", "submitter": "Nhan Tran", "authors": "Javier Duarte, Song Han, Philip Harris, Sergo Jindariani, Edward\n  Kreinar, Benjamin Kreis, Jennifer Ngadiuba, Maurizio Pierini, Ryan Rivera,\n  Nhan Tran, Zhenbin Wu", "title": "Fast inference of deep neural networks in FPGAs for particle physics", "comments": "22 pages, 17 figures, 2 tables, JINST revision", "journal-ref": "JINST 13 P07027 (2018)", "doi": "10.1088/1748-0221/13/07/P07027", "report-no": "FERMILAB-PUB-18-089-E", "categories": "physics.ins-det cs.CV hep-ex stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results at the Large Hadron Collider (LHC) have pointed to enhanced\nphysics capabilities through the improvement of the real-time event processing\ntechniques. Machine learning methods are ubiquitous and have proven to be very\npowerful in LHC physics, and particle physics as a whole. However, exploration\nof the use of such techniques in low-latency, low-power FPGA hardware has only\njust begun. FPGA-based trigger and data acquisition (DAQ) systems have\nextremely low, sub-microsecond latency requirements that are unique to particle\nphysics. We present a case study for neural network inference in FPGAs focusing\non a classifier for jet substructure which would enable, among many other\nphysics scenarios, searches for new dark sector particles and novel\nmeasurements of the Higgs boson. While we focus on a specific example, the\nlessons are far-reaching. We develop a package based on High-Level Synthesis\n(HLS) called hls4ml to build machine learning models in FPGAs. The use of HLS\nincreases accessibility across a broad user community and allows for a drastic\ndecrease in firmware development time. We map out FPGA resource usage and\nlatency versus neural network hyperparameters to identify the problems in\nparticle physics that would benefit from performing neural network inference\nwith FPGAs. For our example jet substructure model, we fit well within the\navailable resources of modern FPGAs with a latency on the scale of 100 ns.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2018 18:00:02 GMT"}, {"version": "v2", "created": "Fri, 20 Apr 2018 16:46:35 GMT"}, {"version": "v3", "created": "Thu, 28 Jun 2018 21:43:10 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Duarte", "Javier", ""], ["Han", "Song", ""], ["Harris", "Philip", ""], ["Jindariani", "Sergo", ""], ["Kreinar", "Edward", ""], ["Kreis", "Benjamin", ""], ["Ngadiuba", "Jennifer", ""], ["Pierini", "Maurizio", ""], ["Rivera", "Ryan", ""], ["Tran", "Nhan", ""], ["Wu", "Zhenbin", ""]]}, {"id": "1804.06943", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Dayvid V. R. Oliveira, George D. C. Cavalcanti, Thyago N. Porpino,\n  Rafael M. O. Cruz and Robert Sabourin", "title": "K-Nearest Oracles Borderline Dynamic Classifier Ensemble Selection", "comments": "Paper accepted for publication on IJCNN 2018", "journal-ref": null, "doi": "10.1109/IJCNN.2018.8489737", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Ensemble Selection (DES) techniques aim to select locally competent\nclassifiers for the classification of each new test sample. Most DES techniques\nestimate the competence of classifiers using a given criterion over the region\nof competence of the test sample (its the nearest neighbors in the validation\nset). The K-Nearest Oracles Eliminate (KNORA-E) DES selects all classifiers\nthat correctly classify all samples in the region of competence of the test\nsample, if such classifier exists, otherwise, it removes from the region of\ncompetence the sample that is furthest from the test sample, and the process\nrepeats. When the region of competence has samples of different classes,\nKNORA-E can reduce the region of competence in such a way that only samples of\na single class remain in the region of competence, leading to the selection of\nlocally incompetent classifiers that classify all samples in the region of\ncompetence as being from the same class. In this paper, we propose two DES\ntechniques: K-Nearest Oracles Borderline (KNORA-B) and K-Nearest Oracles\nBorderline Imbalanced (KNORA-BI). KNORA-B is a DES technique based on KNORA-E\nthat reduces the region of competence but maintains at least one sample from\neach class that is in the original region of competence. KNORA-BI is a\nvariation of KNORA-B for imbalance datasets that reduces the region of\ncompetence but maintains at least one minority class sample if there is any in\nthe original region of competence. Experiments are conducted comparing the\nproposed techniques with 19 DES techniques from the literature using 40\ndatasets. The results show that the proposed techniques achieved interesting\nresults, with KNORA-BI outperforming state-of-art techniques.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 23:11:05 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Oliveira", "Dayvid V. R.", ""], ["Cavalcanti", "George D. C.", ""], ["Porpino", "Thyago N.", ""], ["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""]]}, {"id": "1804.07010", "submitter": "Maziar Raissi", "authors": "Maziar Raissi", "title": "Forward-Backward Stochastic Neural Networks: Deep Learning of\n  High-dimensional Partial Differential Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SY math.AP math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical numerical methods for solving partial differential equations suffer\nfrom the curse dimensionality mainly due to their reliance on meticulously\ngenerated spatio-temporal grids. Inspired by modern deep learning based\ntechniques for solving forward and inverse problems associated with partial\ndifferential equations, we circumvent the tyranny of numerical discretization\nby devising an algorithm that is scalable to high-dimensions. In particular, we\napproximate the unknown solution by a deep neural network which essentially\nenables us to benefit from the merits of automatic differentiation. To train\nthe aforementioned neural network we leverage the well-known connection between\nhigh-dimensional partial differential equations and forward-backward stochastic\ndifferential equations. In fact, independent realizations of a standard\nBrownian motion will act as training data. We test the effectiveness of our\napproach for a couple of benchmark problems spanning a number of scientific\ndomains including Black-Scholes-Barenblatt and Hamilton-Jacobi-Bellman\nequations, both in 100-dimensions.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 06:30:45 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Raissi", "Maziar", ""]]}, {"id": "1804.07045", "submitter": "Tommaso Dreossi", "authors": "Tommaso Dreossi, Somesh Jha, Sanjit A. Seshia", "title": "Semantic Adversarial Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fueled by massive amounts of data, models produced by machine-learning (ML)\nalgorithms, especially deep neural networks, are being used in diverse domains\nwhere trustworthiness is a concern, including automotive systems, finance,\nhealth care, natural language processing, and malware detection. Of particular\nconcern is the use of ML algorithms in cyber-physical systems (CPS), such as\nself-driving cars and aviation, where an adversary can cause serious\nconsequences. However, existing approaches to generating adversarial examples\nand devising robust ML algorithms mostly ignore the semantics and context of\nthe overall system containing the ML component. For example, in an autonomous\nvehicle using deep learning for perception, not every adversarial example for\nthe neural network might lead to a harmful consequence. Moreover, one may want\nto prioritize the search for adversarial examples towards those that\nsignificantly modify the desired semantics of the overall system. Along the\nsame lines, existing algorithms for constructing robust ML algorithms ignore\nthe specification of the overall system. In this paper, we argue that the\nsemantics and specification of the overall system has a crucial role to play in\nthis line of research. We present preliminary research results that support\nthis claim.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 09:15:58 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 18:14:19 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Dreossi", "Tommaso", ""], ["Jha", "Somesh", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1804.07059", "submitter": "Kaushalya Madhawa Mr", "authors": "Kaushalya Madhawa, Tsuyoshi Murata", "title": "Exploring Partially Observed Networks with Nonparametric Bandits", "comments": "15 pages, 6 figures, currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world networks such as social and communication networks are too large\nto be observed entirely. Such networks are often partially observed such that\nnetwork size, network topology, and nodes of the original network are unknown.\nIn this paper we formalize the Adaptive Graph Exploring problem. We assume that\nwe are given an incomplete snapshot of a large network and additional nodes can\nbe discovered by querying nodes in the currently observed network. The goal of\nthis problem is to maximize the number of observed nodes within a given query\nbudget. Querying which set of nodes maximizes the size of the observed network?\nWe formulate this problem as an exploration-exploitation problem and propose a\nnovel nonparametric multi-arm bandit (MAB) algorithm for identifying which\nnodes to be queried. Our contributions include: (1) $i$KNN-UCB, a novel\nnonparametric MAB algorithm, applies $k$-nearest neighbor UCB to the setting\nwhen the arms are presented in a vector space, (2) provide theoretical\nguarantee that $i$KNN-UCB algorithm has sublinear regret, and (3) applying\n$i$KNN-UCB algorithm on synthetic networks and real-world networks from\ndifferent domains, we show that our method discovers up to 40% more nodes\ncompared to existing baselines.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 09:57:34 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Madhawa", "Kaushalya", ""], ["Murata", "Tsuyoshi", ""]]}, {"id": "1804.07090", "submitter": "Amartya Sanyal", "authors": "Amartya Sanyal, Varun Kanade, Philip H. S. Torr, Puneet K. Dokania", "title": "Robustness via Deep Low-Rank Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the effect of the dimensionality of the representations\nlearned in Deep Neural Networks (DNNs) on their robustness to input\nperturbations, both adversarial and random. To achieve low dimensionality of\nlearned representations, we propose an easy-to-use, end-to-end trainable,\nlow-rank regularizer (LR) that can be applied to any intermediate layer\nrepresentation of a DNN. This regularizer forces the feature representations to\n(mostly) lie in a low-dimensional linear subspace. We perform a wide range of\nexperiments that demonstrate that the LR indeed induces low rank on the\nrepresentations, while providing modest improvements to accuracy as an added\nbenefit. Furthermore, the learned features make the trained model significantly\nmore robust to input perturbations such as Gaussian and adversarial noise (even\nwithout adversarial training). Lastly, the low-dimensionality means that the\nlearned features are highly compressible; thus discriminative features of the\ndata can be stored using very little memory. Our experiments indicate that\nmodels trained using the LR learn robust classifiers by discovering subspaces\nthat avoid non-robust features. Algorithmically, the LR is scalable, generic,\nand straightforward to implement into existing deep learning frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 11:17:41 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 09:58:25 GMT"}, {"version": "v3", "created": "Mon, 11 Jun 2018 07:37:02 GMT"}, {"version": "v4", "created": "Thu, 21 Mar 2019 14:56:14 GMT"}, {"version": "v5", "created": "Wed, 19 Feb 2020 17:37:41 GMT"}], "update_date": "2020-02-20", "authors_parsed": [["Sanyal", "Amartya", ""], ["Kanade", "Varun", ""], ["Torr", "Philip H. S.", ""], ["Dokania", "Puneet K.", ""]]}, {"id": "1804.07091", "submitter": "Bj\\\"orn Barz", "authors": "Bj\\\"orn Barz, Erik Rodner, Yanira Guanche Garcia, Joachim Denzler", "title": "Detecting Regions of Maximal Divergence for Spatio-Temporal Anomaly\n  Detection", "comments": "Accepted by TPAMI. Examples and code:\n  https://cvjena.github.io/libmaxdiv/", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence,\n  vol. 41, no. 5, pp. 1088-1101, 1 May 2019", "doi": "10.1109/TPAMI.2018.2823766", "report-no": null, "categories": "stat.ML cs.CV cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic detection of anomalies in space- and time-varying measurements is\nan important tool in several fields, e.g., fraud detection, climate analysis,\nor healthcare monitoring. We present an algorithm for detecting anomalous\nregions in multivariate spatio-temporal time-series, which allows for spotting\nthe interesting parts in large amounts of data, including video and text data.\nIn opposition to existing techniques for detecting isolated anomalous data\npoints, we propose the \"Maximally Divergent Intervals\" (MDI) framework for\nunsupervised detection of coherent spatial regions and time intervals\ncharacterized by a high Kullback-Leibler divergence compared with all other\ndata given. In this regard, we define an unbiased Kullback-Leibler divergence\nthat allows for ranking regions of different size and show how to enable the\nalgorithm to run on large-scale data sets in reasonable time using an interval\nproposal technique. Experiments on both synthetic and real data from various\ndomains, such as climate analysis, video surveillance, and text forensics,\ndemonstrate that our method is widely applicable and a valuable tool for\nfinding interesting events in different types of data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 11:23:07 GMT"}, {"version": "v2", "created": "Tue, 23 Jul 2019 07:23:39 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Barz", "Bj\u00f6rn", ""], ["Rodner", "Erik", ""], ["Garcia", "Yanira Guanche", ""], ["Denzler", "Joachim", ""]]}, {"id": "1804.07101", "submitter": "Karin Schnass", "authors": "Marie Christine Pali, Karin Schnass", "title": "Dictionary learning -- from local towards global and adaptive", "comments": "11 figures, 5 pages per figure including pseudocode", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the convergence behaviour of dictionary learning via the\nIterative Thresholding and K-residual Means (ITKrM) algorithm. On one hand it\nis proved that ITKrM is a contraction under much more relaxed conditions than\npreviously necessary. On the other hand it is shown that there seem to exist\nstable fixed points that do not correspond to the generating dictionary, which\ncan be characterised as very coherent. Based on an analysis of the residuals\nusing these bad dictionaries, replacing coherent atoms with carefully designed\nreplacement candidates is proposed. In experiments on synthetic data this\noutperforms random or no replacement and always leads to full dictionary\nrecovery. Finally the question how to learn dictionaries without knowledge of\nthe correct dictionary size and sparsity level is addressed. Decoupling the\nreplacement strategy of coherent or unused atoms into pruning and adding, and\nslowly carefully increasing the sparsity level, leads to an adaptive version of\nITKrM. In several experiments this adaptive dictionary learning algorithm is\nshown to recover a generating dictionary from randomly initialised dictionaries\nof various sizes on synthetic data and to learn meaningful dictionaries on\nimage data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 11:51:14 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 12:03:28 GMT"}, {"version": "v3", "created": "Wed, 21 Apr 2021 11:34:37 GMT"}], "update_date": "2021-04-22", "authors_parsed": [["Pali", "Marie Christine", ""], ["Schnass", "Karin", ""]]}, {"id": "1804.07125", "submitter": "Lucas Lacasa", "authors": "Jacopo Iacovacci, Lucas Lacasa", "title": "Visibility graphs for image processing", "comments": "16 pages, codes available upon request", "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  (early access 2019)", "doi": "10.1109/TPAMI.2019.2891742", "report-no": null, "categories": "physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The family of image visibility graphs (IVGs) have been recently introduced as\nsimple algorithms by which scalar fields can be mapped into graphs. Here we\nexplore the usefulness of such operator in the scenario of image processing and\nimage classification. We demonstrate that the link architecture of the image\nvisibility graphs encapsulates relevant information on the structure of the\nimages and we explore their potential as image filters and compressors. We\nintroduce several graph features, including the novel concept of Visibility\nPatches, and show through several examples that these features are highly\ninformative, computationally efficient and universally applicable for general\npattern recognition and image classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 12:53:10 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Iacovacci", "Jacopo", ""], ["Lacasa", "Lucas", ""]]}, {"id": "1804.07134", "submitter": "Gilles Kratzer", "authors": "Gilles Kratzer and Reinhard Furrer", "title": "varrank: an R package for variable ranking based on mutual information\n  with applications to observed systemic datasets", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes the R package varrank. It has a flexible\nimplementation of heuristic approaches which perform variable ranking based on\nmutual information. The package is particularly suitable for exploring\nmultivariate datasets requiring a holistic analysis. The core functionality is\na general implementation of the minimum redundancy maximum relevance (mRMRe)\nmodel. This approach is based on information theory metrics. It is compatible\nwith discrete and continuous data which are discretised using a large choice of\npossible rules. The two main problems that can be addressed by this package are\nthe selection of the most representative variables for modeling a collection of\nvariables of interest, i.e., dimension reduction, and variable ranking with\nrespect to a set of variables of interest.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 13:12:03 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Kratzer", "Gilles", ""], ["Furrer", "Reinhard", ""]]}, {"id": "1804.07144", "submitter": "Deepika Singh", "authors": "Deepika Singh, Erinc Merdivan, Ismini Psychoula, Johannes Kropf, Sten\n  Hanke, Matthieu Geist and Andreas Holzinger", "title": "Human Activity Recognition using Recurrent Neural Networks", "comments": null, "journal-ref": "International Cross-Domain Conference for Machine Learning and\n  Knowledge Extraction: CD-MAKE 2017", "doi": "10.1007/978-3-319-66808-6_18", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human activity recognition using smart home sensors is one of the bases of\nubiquitous computing in smart environments and a topic undergoing intense\nresearch in the field of ambient assisted living. The increasingly large amount\nof data sets calls for machine learning methods. In this paper, we introduce a\ndeep learning model that learns to classify human activities without using any\nprior knowledge. For this purpose, a Long Short Term Memory (LSTM) Recurrent\nNeural Network was applied to three real world smart home datasets. The results\nof these experiments show that the proposed approach outperforms the existing\nones in terms of accuracy and performance.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 13:20:09 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Singh", "Deepika", ""], ["Merdivan", "Erinc", ""], ["Psychoula", "Ismini", ""], ["Kropf", "Johannes", ""], ["Hanke", "Sten", ""], ["Geist", "Matthieu", ""], ["Holzinger", "Andreas", ""]]}, {"id": "1804.07152", "submitter": "Liu Weiyi", "authors": "Weiyi Liu, Zhining Liu, Toyotaro Suzumura, Guangmin Hu", "title": "Scalable attribute-aware network embedding with locality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adding attributes for nodes to network embedding helps to improve the ability\nof the learned joint representation to depict features from topology and\nattributes simultaneously. Recent research on the joint embedding has exhibited\na promising performance on a variety of tasks by jointly embedding the two\nspaces. However, due to the indispensable requirement of globality based\ninformation, present approaches contain a flaw of in-scalability. Here we\npropose \\emph{SANE}, a scalable attribute-aware network embedding algorithm\nwith locality, to learn the joint representation from topology and attributes.\nBy enforcing the alignment of a local linear relationship between each node and\nits K-nearest neighbors in topology and attribute space, the joint embedding\nrepresentations are more informative comparing with a single representation\nfrom topology or attributes alone. And we argue that the locality in\n\\emph{SANE} is the key to learning the joint representation at scale. By using\nseveral real-world networks from diverse domains, We demonstrate the efficacy\nof \\emph{SANE} in performance and scalability aspect. Overall, for performance\non label classification, SANE successfully reaches up to the highest F1-score\non most datasets, and even closer to the baseline method that needs label\ninformation as extra inputs, compared with other state-of-the-art joint\nrepresentation algorithms. What's more, \\emph{SANE} has an up to 71.4\\%\nperformance gain compared with the single topology-based algorithm. For\nscalability, we have demonstrated the linearly time complexity of \\emph{SANE}.\nIn addition, we intuitively observe that when the network size scales to\n100,000 nodes, the \"learning joint embedding\" step of \\emph{SANE} only takes\n$\\approx10$ seconds.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2018 23:59:50 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 00:40:08 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Liu", "Weiyi", ""], ["Liu", "Zhining", ""], ["Suzumura", "Toyotaro", ""], ["Hu", "Guangmin", ""]]}, {"id": "1804.07155", "submitter": "Ludmila Kuncheva", "authors": "Ludmila I. Kuncheva, \\'Alvar Arnaiz-Gonz\\'alez, Jos\\'e-Francisco\n  D\\'iez-Pastor, and Iain A. D. Gunn", "title": "Instance Selection Improves Geometric Mean Accuracy: A Study on\n  Imbalanced Data Classification", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A natural way of handling imbalanced data is to attempt to equalise the class\nfrequencies and train the classifier of choice on balanced data. For two-class\nimbalanced problems, the classification success is typically measured by the\ngeometric mean (GM) of the true positive and true negative rates. Here we prove\nthat GM can be improved upon by instance selection, and give the theoretical\nconditions for such an improvement. We demonstrate that GM is non-monotonic\nwith respect to the number of retained instances, which discourages systematic\ninstance selection. We also show that balancing the distribution frequencies is\ninferior to a direct maximisation of GM. To verify our theoretical findings, we\ncarried out an experimental study of 12 instance selection methods for\nimbalanced data, using 66 standard benchmark data sets. The results reveal\npossible room for new instance selection methods for imbalanced data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 13:32:50 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Kuncheva", "Ludmila I.", ""], ["Arnaiz-Gonz\u00e1lez", "\u00c1lvar", ""], ["D\u00edez-Pastor", "Jos\u00e9-Francisco", ""], ["Gunn", "Iain A. D.", ""]]}, {"id": "1804.07169", "submitter": "Magda Gregorova", "authors": "Magda Gregorov\\'a, Jason Ramapuram, Alexandros Kalousis, St\\'ephane\n  Marchand-Maillet", "title": "Large-scale Nonlinear Variable Selection via Kernel Random Features", "comments": "Final version for proceedings of ECML/PKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for input variable selection in nonlinear regression.\nThe method is embedded into a kernel regression machine that can model general\nnonlinear functions, not being a priori limited to additive models. This is the\nfirst kernel-based variable selection method applicable to large datasets. It\nsidesteps the typical poor scaling properties of kernel methods by mapping the\ninputs into a relatively low-dimensional space of random features. The\nalgorithm discovers the variables relevant for the regression task together\nwith learning the prediction model through learning the appropriate nonlinear\nrandom feature maps. We demonstrate the outstanding performance of our method\non a set of large-scale synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 13:51:45 GMT"}, {"version": "v2", "created": "Sat, 1 Sep 2018 08:27:25 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Gregorov\u00e1", "Magda", ""], ["Ramapuram", "Jason", ""], ["Kalousis", "Alexandros", ""], ["Marchand-Maillet", "St\u00e9phane", ""]]}, {"id": "1804.07193", "submitter": "Kavosh Asadi", "authors": "Kavosh Asadi, Dipendra Misra, Michael L. Littman", "title": "Lipschitz Continuity in Model-based Reinforcement Learning", "comments": "Accepted for the 35th International Conference on Machine Learning\n  (ICML 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the impact of learning Lipschitz continuous models in the context\nof model-based reinforcement learning. We provide a novel bound on multi-step\nprediction error of Lipschitz models where we quantify the error using the\nWasserstein metric. We go on to prove an error bound for the value-function\nestimate arising from Lipschitz models and show that the estimated value\nfunction is itself Lipschitz. We conclude with empirical results that show the\nbenefits of controlling the Lipschitz constant of neural-network models.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 14:29:41 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 04:02:26 GMT"}, {"version": "v3", "created": "Fri, 27 Jul 2018 12:40:44 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Asadi", "Kavosh", ""], ["Misra", "Dipendra", ""], ["Littman", "Michael L.", ""]]}, {"id": "1804.07209", "submitter": "Marco Ciccone", "authors": "Marco Ciccone, Marco Gallieri, Jonathan Masci, Christian Osendorfer,\n  Faustino Gomez", "title": "NAIS-Net: Stable Deep Networks from Non-Autonomous Differential\n  Equations", "comments": "NeurIPS 2018 (updated version): new results and proof on incremental\n  stability for ReLU case", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Non-Autonomous Input-Output Stable Network(NAIS-Net), a\nvery deep architecture where each stacked processing block is derived from a\ntime-invariant non-autonomous dynamical system. Non-autonomy is implemented by\nskip connections from the block input to each of the unrolled processing stages\nand allows stability to be enforced so that blocks can be unrolled adaptively\nto a pattern-dependent processing depth. NAIS-Net induces non-trivial,\nLipschitz input-output maps, even for an infinite unroll length. We prove that\nthe network is globally asymptotically stable so that for every initial\ncondition there is exactly one input-dependent equilibrium assuming $tanh$\nunits, and incrementally stable for ReL units. An efficient implementation that\nenforces the stability under derived conditions for both fully-connected and\nconvolutional layers is also presented. Experimental results show how NAIS-Net\nexhibits stability in practice, yielding a significant reduction in\ngeneralization gap compared to ResNets.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 15:07:14 GMT"}, {"version": "v2", "created": "Sun, 20 May 2018 10:34:05 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 03:59:39 GMT"}, {"version": "v4", "created": "Fri, 21 May 2021 16:03:38 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Ciccone", "Marco", ""], ["Gallieri", "Marco", ""], ["Masci", "Jonathan", ""], ["Osendorfer", "Christian", ""], ["Gomez", "Faustino", ""]]}, {"id": "1804.07213", "submitter": "Ting Kei Pong", "authors": "Tianxiang Liu, Ting Kei Pong, Akiko Takeda", "title": "A refined convergence analysis of pDCA$_e$ with applications to\n  simultaneous sparse recovery and outlier detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of minimizing a difference-of-convex (DC) function,\nwhich can be written as the sum of a smooth convex function with Lipschitz\ngradient, a proper closed convex function and a continuous possibly nonsmooth\nconcave function. We refine the convergence analysis in [38] for the proximal\nDC algorithm with extrapolation (pDCA$_e$) and show that the whole sequence\ngenerated by the algorithm is convergent when the objective is level-bounded,\n{\\em without} imposing differentiability assumptions in the concave part. Our\nanalysis is based on a new potential function and we assume such a function is\na Kurdyka-{\\L}ojasiewicz (KL) function. We also establish a relationship\nbetween our KL assumption and the one used in [38]. Finally, we demonstrate how\nthe pDCA$_e$ can be applied to a class of simultaneous sparse recovery and\noutlier detection problems arising from robust compressed sensing in signal\nprocessing and least trimmed squares regression in statistics. Specifically, we\nshow that the objectives of these problems can be written as level-bounded DC\nfunctions whose concave parts are {\\em typically nonsmooth}. Moreover, for a\nlarge class of loss functions and regularizers, the KL exponent of the\ncorresponding potential function are shown to be 1/2, which implies that the\npDCA$_e$ is locally linearly convergent when applied to these problems. Our\nnumerical experiments show that the pDCA$_e$ usually outperforms the proximal\nDC algorithm with nonmonotone linesearch [24, Appendix A] in both CPU time and\nsolution quality for this particular application.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 15:11:05 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Liu", "Tianxiang", ""], ["Pong", "Ting Kei", ""], ["Takeda", "Akiko", ""]]}, {"id": "1804.07237", "submitter": "Jiamiao Xu", "authors": "Jiamiao Xu, Shujian Yu, Xinge You, Mengjun Leng, Xiao-Yuan Jing and C.\n  L. Philip Chen", "title": "Multi-view Hybrid Embedding: A Divide-and-Conquer Approach", "comments": "This paper has been accepted by IEEE Transactions on Cybernetics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel cross-view classification algorithm where the gallery and\nprobe data come from different views. A popular approach to tackle this problem\nis the multi-view subspace learning (MvSL) that aims to learn a latent subspace\nshared by multi-view data. Despite promising results obtained on some\napplications, the performance of existing methods deteriorates dramatically\nwhen the multi-view data is sampled from nonlinear manifolds or suffers from\nheavy outliers. To circumvent this drawback, motivated by the\nDivide-and-Conquer strategy, we propose Multi-view Hybrid Embedding (MvHE), a\nunique method of dividing the problem of cross-view classification into three\nsubproblems and building one model for each subproblem. Specifically, the first\nmodel is designed to remove view discrepancy, whereas the second and third\nmodels attempt to discover the intrinsic nonlinear structure and to increase\ndiscriminability in intra-view and inter-view samples respectively. The kernel\nextension is conducted to further boost the representation power of MvHE.\nExtensive experiments are conducted on four benchmark datasets. Our methods\ndemonstrate overwhelming advantages against the state-of-the-art MvSL based\ncross-view classification approaches in terms of classification accuracy and\nrobustness.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 15:38:15 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2019 10:46:35 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Xu", "Jiamiao", ""], ["Yu", "Shujian", ""], ["You", "Xinge", ""], ["Leng", "Mengjun", ""], ["Jing", "Xiao-Yuan", ""], ["Chen", "C. L. Philip", ""]]}, {"id": "1804.07240", "submitter": "Mustafa Mohamad", "authors": "Mustafa A. Mohamad, Themistoklis P. Sapsis", "title": "A sequential sampling strategy for extreme event statistics in nonlinear\n  dynamical systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method for the evaluation of extreme event statistics associated\nwith nonlinear dynamical systems, using a small number of samples. From an\ninitial dataset of design points, we formulate a sequential strategy that\nprovides the 'next-best' data point (set of parameters) that when evaluated\nresults in improved estimates of the probability density function (pdf) for a\nscalar quantity of interest. The approach utilizes Gaussian process regression\nto perform Bayesian inference on the parameter-to-observation map describing\nthe quantity of interest. We then approximate the desired pdf along with\nuncertainty bounds utilizing the posterior distribution of the inferred map.\nThe 'next-best' design point is sequentially determined through an optimization\nprocedure that selects the point in parameter space that maximally reduces\nuncertainty between the estimated bounds of the pdf prediction. Since the\noptimization process utilizes only information from the inferred map it has\nminimal computational cost. Moreover, the special form of the metric emphasizes\nthe tails of the pdf. The method is practical for systems where the\ndimensionality of the parameter space is of moderate size, i.e. order O(10). We\napply the method to estimate the extreme event statistics for a very\nhigh-dimensional system with millions of degrees of freedom: an offshore\nplatform subjected to three-dimensional irregular waves. It is demonstrated\nthat the developed approach can accurately determine the extreme event\nstatistics using limited number of samples.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 15:48:17 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Mohamad", "Mustafa A.", ""], ["Sapsis", "Themistoklis P.", ""]]}, {"id": "1804.07262", "submitter": "Jarno Hartog", "authors": "Jarno Hartog, Harry van Zanten", "title": "Nonparametric Bayesian label prediction on a large graph using truncated\n  Laplacian regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes an implementation of a nonparametric Bayesian approach\nto solving binary classification problems on graphs. We consider a hierarchical\nBayesian approach with a prior that is constructed by truncating a series\nexpansion of the soft label function using the graph Laplacian eigenfunctions\nas basis functions. We compare our truncated prior to the untruncated Laplacian\nbased prior in simulated and real data examples to illustrate the improved\nscalability in terms of size of the underlying graph.\n", "versions": [{"version": "v1", "created": "Fri, 13 Apr 2018 09:36:43 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Hartog", "Jarno", ""], ["van Zanten", "Harry", ""]]}, {"id": "1804.07265", "submitter": "Te Han", "authors": "Te Han, Chao Liu, Wenguang Yang and Dongxiang Jiang", "title": "Deep Transfer Network with Joint Distribution Adaptation: A New\n  Intelligent Fault Diagnosis Framework for Industry Application", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": "10.1016/j.isatra.2019.08.012", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, an increasing popularity of deep learning model for\nintelligent condition monitoring and diagnosis as well as prognostics used for\nmechanical systems and structures has been observed. In the previous studies,\nhowever, a major assumption accepted by default, is that the training and\ntesting data are taking from same feature distribution. Unfortunately, this\nassumption is mostly invalid in real application, resulting in a certain lack\nof applicability for the traditional diagnosis approaches. Inspired by the idea\nof transfer learning that leverages the knowledge learnt from rich labeled data\nin source domain to facilitate diagnosing a new but similar target task, a new\nintelligent fault diagnosis framework, i.e., deep transfer network (DTN), which\ngeneralizes deep learning model to domain adaptation scenario, is proposed in\nthis paper. By extending the marginal distribution adaptation (MDA) to joint\ndistribution adaptation (JDA), the proposed framework can exploit the\ndiscrimination structures associated with the labeled data in source domain to\nadapt the conditional distribution of unlabeled target data, and thus guarantee\na more accurate distribution matching. Extensive empirical evaluations on three\nfault datasets validate the applicability and practicability of DTN, while\nachieving many state-of-the-art transfer results in terms of diverse operating\nconditions, fault severities and fault types.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 01:52:52 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Han", "Te", ""], ["Liu", "Chao", ""], ["Yang", "Wenguang", ""], ["Jiang", "Dongxiang", ""]]}, {"id": "1804.07270", "submitter": "Xingzhang Ren", "authors": "Xingzhang Ren, Chen Long, Leilei Zhang, Ye Wei, Dongdong Du, Jingxi\n  Liang, Shikun Zhang, Weiping Li", "title": "A Dynamic Boosted Ensemble Learning Method Based on Random Forest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a dynamic boosted ensemble learning method based on random forest\n(DBRF), a novel ensemble algorithm that incorporates the notion of hard example\nmining into Random Forest (RF) and thus combines the high accuracy of Boosting\nalgorithm with the strong generalization of Bagging algorithm. Specifically, we\npropose to measure the quality of each leaf node of every decision tree in the\nrandom forest to determine hard examples. By iteratively training and then\nremoving easy examples from training data, we evolve the random forest to focus\non hard examples dynamically so as to learn decision boundaries better. Data\ncan be cascaded through these random forests learned in each iteration in\nsequence to generate predictions, thus making RF deep. We also propose to use\nevolution mechanism and smart iteration mechanism to improve the performance of\nthe model. DBRF outperforms RF on three UCI datasets and achieved\nstate-of-the-art results compared to other deep models. Moreover, we show that\nDBRF is also a new way of sampling and can be very useful when learning from\nimbalanced data.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 16:55:21 GMT"}, {"version": "v2", "created": "Sat, 21 Apr 2018 14:55:36 GMT"}, {"version": "v3", "created": "Tue, 24 Apr 2018 16:19:36 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Ren", "Xingzhang", ""], ["Long", "Chen", ""], ["Zhang", "Leilei", ""], ["Wei", "Ye", ""], ["Du", "Dongdong", ""], ["Liang", "Jingxi", ""], ["Zhang", "Shikun", ""], ["Li", "Weiping", ""]]}, {"id": "1804.07275", "submitter": "Yuhong Guo", "authors": "Meng Ye and Yuhong Guo", "title": "Deep Triplet Ranking Networks for One-Shot Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the breakthroughs achieved by deep learning models in conventional\nsupervised learning scenarios, their dependence on sufficient labeled training\ndata in each class prevents effective applications of these deep models in\nsituations where labeled training instances for a subset of novel classes are\nvery sparse -- in the extreme case only one instance is available for each\nclass. To tackle this natural and important challenge, one-shot learning, which\naims to exploit a set of well labeled base classes to build classifiers for the\nnew target classes that have only one observed instance per class, has recently\nreceived increasing attention from the research community. In this paper we\npropose a novel end-to-end deep triplet ranking network to perform one-shot\nlearning. The proposed approach learns class universal image embeddings on the\nwell labeled base classes under a triplet ranking loss, such that the instances\nfrom new classes can be categorized based on their similarity with the one-shot\ninstances in the learned embedding space. Moreover, our approach can naturally\nincorporate the available one-shot instances from the new classes into the\nembedding learning process to improve the triplet ranking model. We conduct\nexperiments on two popular datasets for one-shot learning. The results show the\nproposed approach achieves better performance than the state-of-the- art\ncomparison methods.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 16:57:52 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Ye", "Meng", ""], ["Guo", "Yuhong", ""]]}, {"id": "1804.07323", "submitter": "Ekaterina Tolstaya", "authors": "Alec Koppel, Ekaterina Tolstaya, Ethan Stump, Alejandro Ribeiro", "title": "Nonparametric Stochastic Compositional Gradient Descent for Q-Learning\n  in Continuous Markov Decision Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Markov Decision Problems defined over continuous state and action\nspaces, where an autonomous agent seeks to learn a map from its states to\nactions so as to maximize its long-term discounted accumulation of rewards. We\naddress this problem by considering Bellman's optimality equation defined over\naction-value functions, which we reformulate into a nested non-convex\nstochastic optimization problem defined over a Reproducing Kernel Hilbert Space\n(RKHS). We develop a functional generalization of stochastic quasi-gradient\nmethod to solve it, which, owing to the structure of the RKHS, admits a\nparameterization in terms of scalar weights and past state-action pairs which\ngrows proportionately with the algorithm iteration index. To ameliorate this\ncomplexity explosion, we apply Kernel Orthogonal Matching Pursuit to the\nsequence of kernel weights and dictionaries, which yields a controllable error\nin the descent direction of the underlying optimization method. We prove that\nthe resulting algorithm, called KQ-Learning, converges with probability 1 to a\nstationary point of this problem, yielding a fixed point of the Bellman\noptimality operator under the hypothesis that it belongs to the RKHS. Under\nconstant learning rates, we further obtain convergence to a small Bellman error\nthat depends on the chosen learning rates. Numerical evaluation on the\nContinuous Mountain Car and Inverted Pendulum tasks yields convergent\nparsimonious learned action-value functions, policies that are competitive with\nthe state of the art, and exhibit reliable, reproducible learning behavior.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 18:24:18 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Koppel", "Alec", ""], ["Tolstaya", "Ekaterina", ""], ["Stump", "Ethan", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1804.07344", "submitter": "Wouter Kouw", "authors": "Wouter M. Kouw, Marco Loog", "title": "Effects of sampling skewness of the importance-weighted risk estimator\n  on model selection", "comments": "Conference paper, 6 pages, 5 figures", "journal-ref": "24th International Conference on Pattern Recognition (ICPR),\n  Beijing, 2018, pp. 1468 - 1473", "doi": "10.1109/ICPR.2018.8546186", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance-weighting is a popular and well-researched technique for dealing\nwith sample selection bias and covariate shift. It has desirable\ncharacteristics such as unbiasedness, consistency and low computational\ncomplexity. However, weighting can have a detrimental effect on an estimator as\nwell. In this work, we empirically show that the sampling distribution of an\nimportance-weighted estimator can be skewed. For sample selection bias\nsettings, and for small sample sizes, the importance-weighted risk estimator\nproduces overestimates for datasets in the body of the sampling distribution,\ni.e. the majority of cases, and large underestimates for data sets in the tail\nof the sampling distribution. These over- and underestimates of the risk lead\nto suboptimal regularization parameters when used for importance-weighted\nvalidation.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 19:23:06 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Kouw", "Wouter M.", ""], ["Loog", "Marco", ""]]}, {"id": "1804.07347", "submitter": "Bharath Bhushan Damodaran", "authors": "Chippy Jayaprakash, Bharath Bhushan Damodaran, Sowmya V and K P Soman", "title": "Randomized ICA and LDA Dimensionality Reduction Methods for\n  Hyperspectral Image Classification", "comments": "Submitted IEEE JSTARS", "journal-ref": "J. of Applied Remote Sensing, 14(3), 036507 (2020)", "doi": "10.1117/1.JRS.14.036507", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dimensionality reduction is an important step in processing the hyperspectral\nimages (HSI) to overcome the curse of dimensionality problem. Linear\ndimensionality reduction methods such as Independent component analysis (ICA)\nand Linear discriminant analysis (LDA) are commonly employed to reduce the\ndimensionality of HSI. These methods fail to capture non-linear dependency in\nthe HSI data, as data lies in the nonlinear manifold. To handle this, nonlinear\ntransformation techniques based on kernel methods were introduced for\ndimensionality reduction of HSI. However, the kernel methods involve cubic\ncomputational complexity while computing the kernel matrix, and thus its\npotential cannot be explored when the number of pixels (samples) are large. In\nliterature a fewer number of pixels are randomly selected to partial to\novercome this issue, however this sub-optimal strategy might neglect important\ninformation in the HSI. In this paper, we propose randomized solutions to the\nICA and LDA dimensionality reduction methods using Random Fourier features, and\nwe label them as RFFICA and RFFLDA. Our proposed method overcomes the\nscalability issue and to handle the non-linearities present in the data more\nefficiently. Experiments conducted with two real-world hyperspectral datasets\ndemonstrates that our proposed randomized methods outperform the conventional\nkernel ICA and kernel LDA in terms overall, per-class accuracies and\ncomputational time.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 19:36:08 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Jayaprakash", "Chippy", ""], ["Damodaran", "Bharath Bhushan", ""], ["V", "Sowmya", ""], ["Soman", "K P", ""]]}, {"id": "1804.07351", "submitter": "Seong Jae Hwang", "authors": "Seong Jae Hwang, Ronak Mehta, Hyunwoo J. Kim, Vikas Singh", "title": "Sampling-free Uncertainty Estimation in Gated Recurrent Units with\n  Exponential Families", "comments": "Version 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been a concerted effort to derive mechanisms in vision and\nmachine learning systems to offer uncertainty estimates of the predictions they\nmake. Clearly, there are enormous benefits to a system that is not only\naccurate but also has a sense for when it is not sure. Existing proposals\ncenter around Bayesian interpretations of modern deep architectures -- these\nare effective but can often be computationally demanding. We show how classical\nideas in the literature on exponential families on probabilistic networks\nprovide an excellent starting point to derive uncertainty estimates in Gated\nRecurrent Units (GRU). Our proposal directly quantifies uncertainty\ndeterministically, without the need for costly sampling-based estimation. We\ndemonstrate how our model can be used to quantitatively and qualitatively\nmeasure uncertainty in unsupervised image sequence prediction. To our\nknowledge, this is the first result describing sampling-free uncertainty\nestimation for powerful sequential models such as GRUs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 19:40:47 GMT"}, {"version": "v2", "created": "Sun, 2 Sep 2018 20:00:32 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Hwang", "Seong Jae", ""], ["Mehta", "Ronak", ""], ["Kim", "Hyunwoo J.", ""], ["Singh", "Vikas", ""]]}, {"id": "1804.07353", "submitter": "Yuqian Zhou", "authors": "Yuqian Zhou, Kuangxiao Gu, Thomas Huang", "title": "Unsupervised Representation Adversarial Learning Network: from\n  Reconstruction to Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A good representation for arbitrarily complicated data should have the\ncapability of semantic generation, clustering and reconstruction. Previous\nresearch has already achieved impressive performance on either one. This paper\naims at learning a disentangled representation effective for all of them in an\nunsupervised way. To achieve all the three tasks together, we learn the forward\nand inverse mapping between data and representation on the basis of a symmetric\nadversarial process. In theory, we minimize the upper bound of the two\nconditional entropy loss between the latent variables and the observations\ntogether to achieve the cycle consistency. The newly proposed RepGAN is tested\non MNIST, fashionMNIST, CelebA, and SVHN datasets to perform unsupervised\nclassification, generation and reconstruction tasks. The result demonstrates\nthat RepGAN is able to learn a useful and competitive representation. To the\nauthor's knowledge, our work is the first one to achieve both a high\nunsupervised classification accuracy and low reconstruction error on MNIST.\nCodes are available at https://github.com/yzhouas/RepGAN-tensorflow.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 19:42:22 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 16:44:38 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Zhou", "Yuqian", ""], ["Gu", "Kuangxiao", ""], ["Huang", "Thomas", ""]]}, {"id": "1804.07405", "submitter": "Byung-Hak Kim", "authors": "Byung-Hak Kim, Ethan Vizitei, Varun Ganapathi", "title": "GritNet: Student Performance Prediction with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student performance prediction - where a machine forecasts the future\nperformance of students as they interact with online coursework - is a\nchallenging problem. Reliable early-stage predictions of a student's future\nperformance could be critical to facilitate timely educational interventions\nduring a course. However, very few prior studies have explored this problem\nfrom a deep learning perspective. In this paper, we recast the student\nperformance prediction problem as a sequential event prediction problem and\npropose a new deep learning based algorithm, termed GritNet, which builds upon\nthe bidirectional long short term memory (BLSTM). Our results, from real\nUdacity students' graduation predictions, show that the GritNet not only\nconsistently outperforms the standard logistic-regression based method, but\nthat improvements are substantially pronounced in the first few weeks when\naccurate predictions are most challenging.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 23:35:04 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Kim", "Byung-Hak", ""], ["Vizitei", "Ethan", ""], ["Ganapathi", "Varun", ""]]}, {"id": "1804.07419", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Felipe N. Walmsley, George D. C. Cavalcanti, Dayvid V. R. Oliveira,\n  Rafael M. O. Cruz and Robert Sabourin", "title": "An Ensemble Generation Method Based on Instance Hardness", "comments": "Paper accepted for publication on IJCNN 2018", "journal-ref": null, "doi": "10.1109/IJCNN.2018.8489269", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Machine Learning, ensemble methods have been receiving a great deal of\nattention. Techniques such as Bagging and Boosting have been successfully\napplied to a variety of problems. Nevertheless, such techniques are still\nsusceptible to the effects of noise and outliers in the training data. We\npropose a new method for the generation of pools of classifiers based on\nBagging, in which the probability of an instance being selected during the\nresampling process is inversely proportional to its instance hardness, which\ncan be understood as the likelihood of an instance being misclassified,\nregardless of the choice of classifier. The goal of the proposed method is to\nremove noisy data without sacrificing the hard instances which are likely to be\nfound on class boundaries. We evaluate the performance of the method in\nnineteen public data sets, and compare it to the performance of the Bagging and\nRandom Subspace algorithms. Our experiments show that in high noise scenarios\nthe accuracy of our method is significantly better than that of Bagging.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 01:29:47 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 07:18:12 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Walmsley", "Felipe N.", ""], ["Cavalcanti", "George D. C.", ""], ["Oliveira", "Dayvid V. R.", ""], ["Cruz", "Rafael M. O.", ""], ["Sabourin", "Robert", ""]]}, {"id": "1804.07433", "submitter": "Gaurav Thakur", "authors": "Gagan Choudhury, David Lynch, Gaurav Thakur and Simon Tse", "title": "Two Use Cases of Machine Learning for SDN-Enabled IP/Optical Networks:\n  Traffic Matrix Prediction and Optical Path Performance Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe two applications of machine learning in the context of IP/Optical\nnetworks. The first one allows agile management of resources at a core\nIP/Optical network by using machine learning for short-term and long-term\nprediction of traffic flows and joint global optimization of IP and optical\nlayers using colorless/directionless (CD) flexible ROADMs. Multilayer\ncoordination allows for significant cost savings, flexible new services to meet\ndynamic capacity needs, and improved robustness by being able to proactively\nadapt to new traffic patterns and network conditions. The second application is\nimportant as we migrate our metro networks to Open ROADM networks, to allow\nphysical routing without the need for detailed knowledge of optical parameters.\nWe discuss a proof-of-concept study, where detailed performance data for\nwavelengths on a current flexible ROADM network is used for machine learning to\npredict the optical performance of each wavelength. Both applications can be\nefficiently implemented by using a SDN (Software Defined Network) controller.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 02:43:41 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 12:54:48 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Choudhury", "Gagan", ""], ["Lynch", "David", ""], ["Thakur", "Gaurav", ""], ["Tse", "Simon", ""]]}, {"id": "1804.07481", "submitter": "Fabrizio Carcillo", "authors": "Fabirzio Carcillo, Yann-A\\\"el Le Borgne, Olivier Caelen and Gianluca\n  Bontempi", "title": "Streaming Active Learning Strategies for Real-Life Credit Card Fraud\n  Detection: Assessment and Visualization", "comments": null, "journal-ref": "International Journal of Data Science and Analytics 2018", "doi": "10.1007/s41060-018-0116-z", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit card fraud detection is a very challenging problem because of the\nspecific nature of transaction data and the labeling process. The transaction\ndata is peculiar because they are obtained in a streaming fashion, they are\nstrongly imbalanced and prone to non-stationarity. The labeling is the outcome\nof an active learning process, as every day human investigators contact only a\nsmall number of cardholders (associated to the riskiest transactions) and\nobtain the class (fraud or genuine) of the related transactions. An adequate\nselection of the set of cardholders is therefore crucial for an efficient fraud\ndetection process. In this paper, we present a number of active learning\nstrategies and we investigate their fraud detection accuracies. We compare\ndifferent criteria (supervised, semi-supervised and unsupervised) to query\nunlabeled transactions. Finally, we highlight the existence of an\nexploitation/exploration trade-off for active learning in the context of fraud\ndetection, which has so far been overlooked in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 08:03:52 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Carcillo", "Fabirzio", ""], ["Borgne", "Yann-A\u00ebl Le", ""], ["Caelen", "Olivier", ""], ["Bontempi", "Gianluca", ""]]}, {"id": "1804.07580", "submitter": "Andrei Zinovyev Dr.", "authors": "Luca Albergante, Evgeny M. Mirkes, Huidong Chen, Alexis Martin, Louis\n  Faure, Emmanuel Barillot, Luca Pinello, Alexander N. Gorban, Andrei Zinovyev", "title": "Robust And Scalable Learning Of Complex Dataset Topologies Via Elpigraph", "comments": "32 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large datasets represented by multidimensional data point clouds often\npossess non-trivial distributions with branching trajectories and excluded\nregions, with the recent single-cell transcriptomic studies of developing\nembryo being notable examples. Reducing the complexity and producing compact\nand interpretable representations of such data remains a challenging task. Most\nof the existing computational methods are based on exploring the local data\npoint neighbourhood relations, a step that can perform poorly in the case of\nmultidimensional and noisy data. Here we present ElPiGraph, a scalable and\nrobust method for approximation of datasets with complex structures which does\nnot require computing the complete data distance matrix or the data point\nneighbourhood graph. This method is able to withstand high levels of noise and\nis capable of approximating complex topologies via principal graph ensembles\nthat can be combined into a consensus principal graph. ElPiGraph deals\nefficiently with large and complex datasets in various fields from biology,\nwhere it can be used to infer gene dynamics from single-cell RNA-Seq, to\nastronomy, where it can be used to explore complex structures in the\ndistribution of galaxies.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 12:45:15 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 11:19:23 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Albergante", "Luca", ""], ["Mirkes", "Evgeny M.", ""], ["Chen", "Huidong", ""], ["Martin", "Alexis", ""], ["Faure", "Louis", ""], ["Barillot", "Emmanuel", ""], ["Pinello", "Luca", ""], ["Gorban", "Alexander N.", ""], ["Zinovyev", "Andrei", ""]]}, {"id": "1804.07612", "submitter": "Dominic Masters", "authors": "Dominic Masters and Carlo Luschi", "title": "Revisiting Small Batch Training for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern deep neural network training is typically based on mini-batch\nstochastic gradient optimization. While the use of large mini-batches increases\nthe available computational parallelism, small batch training has been shown to\nprovide improved generalization performance and allows a significantly smaller\nmemory footprint, which might also be exploited to improve machine throughput.\n  In this paper, we review common assumptions on learning rate scaling and\ntraining duration, as a basis for an experimental comparison of test\nperformance for different mini-batch sizes. We adopt a learning rate that\ncorresponds to a constant average weight update per gradient calculation (i.e.,\nper unit cost of computation), and point out that this results in a variance of\nthe weight updates that increases linearly with the mini-batch size $m$.\n  The collected experimental results for the CIFAR-10, CIFAR-100 and ImageNet\ndatasets show that increasing the mini-batch size progressively reduces the\nrange of learning rates that provide stable convergence and acceptable test\nperformance. On the other hand, small mini-batch sizes provide more up-to-date\ngradient calculations, which yields more stable and reliable training. The best\nperformance has been consistently obtained for mini-batch sizes between $m = 2$\nand $m = 32$, which contrasts with recent work advocating the use of mini-batch\nsizes in the thousands.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 13:44:12 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Masters", "Dominic", ""], ["Luschi", "Carlo", ""]]}, {"id": "1804.07645", "submitter": "Decebal Constantin Mocanu", "authors": "Decebal Constantin Mocanu and Elena Mocanu", "title": "One-Shot Learning using Mixture of Variational Autoencoders: a\n  Generalization Learning approach", "comments": null, "journal-ref": "17th International Conference on Autonomous Agents and Multiagent\n  Systems (AAMAS 2018)", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning, even if it is very successful nowadays, traditionally needs\nvery large amounts of labeled data to perform excellent on the classification\ntask. In an attempt to solve this problem, the one-shot learning paradigm,\nwhich makes use of just one labeled sample per class and prior knowledge,\nbecomes increasingly important. In this paper, we propose a new one-shot\nlearning method, dubbed MoVAE (Mixture of Variational AutoEncoders), to perform\nclassification. Complementary to prior studies, MoVAE represents a shift of\nparadigm in comparison with the usual one-shot learning methods, as it does not\nuse any prior knowledge. Instead, it starts from zero knowledge and one labeled\nsample per class. Afterward, by using unlabeled data and the generalization\nlearning concept (in a way, more as humans do), it is capable to gradually\nimprove by itself its performance. Even more, if there are no unlabeled data\navailable MoVAE can still perform well in one-shot learning classification. We\ndemonstrate empirically the efficiency of our proposed approach on three\ndatasets, i.e. the handwritten digits (MNIST), fashion products\n(Fashion-MNIST), and handwritten characters (Omniglot), showing that MoVAE\noutperforms state-of-the-art one-shot learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 22:00:20 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Mocanu", "Decebal Constantin", ""], ["Mocanu", "Elena", ""]]}, {"id": "1804.07669", "submitter": "Yanwei Cui", "authors": "Yanwei Cui, Rogatien Tobossi, Olivia Vigouroux", "title": "Modelling customer online behaviours with neural networks: applications\n  to conversion prediction and advertising retargeting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we apply neural networks into digital marketing world for the\npurpose of better targeting the potential customers. To do so, we model the\ncustomer online behaviours using dedicated neural network architectures.\nStarting from user searched keywords in a search engine to the landing page and\ndifferent following pages, until the user left the site, we model the whole\nvisited journey with a Recurrent Neural Network (RNN), together with\nConvolution Neural Networks (CNN) that can take into account of the semantic\nmeaning of user searched keywords and different visited page names. With such\nmodel, we use Monte Carlo simulation to estimate the conversion rates of each\npotential customer in the future visiting. We believe our concept and the\npreliminary promising results in this paper enable the use of largely available\ncustomer online behaviours data for advanced digital marketing analysis.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 15:23:12 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Cui", "Yanwei", ""], ["Tobossi", "Rogatien", ""], ["Vigouroux", "Olivia", ""]]}, {"id": "1804.07672", "submitter": "Youngjoo Seo", "authors": "Youngjoo Seo, Manuel Morante, Yannis Kopsinis and Sergios Theodoridis", "title": "Unsupervised learning of the brain connectivity dynamic using residual\n  D-net", "comments": "10 pages, 5 figueres and 3 tables, under review in MIDL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel unsupervised learning method to learn the\nbrain dynamics using a deep learning architecture named residual D-net. As it\nis often the case in medical research, in contrast to typical deep learning\ntasks, the size of the resting-state functional Magnetic Resonance Image\n(rs-fMRI) datasets for training is limited. Thus, the available data should be\nvery efficiently used to learn the complex patterns underneath the brain\nconnectivity dynamics. To address this issue, we use residual connections to\nalleviate the training complexity through recurrent multi-scale representation.\nWe conduct two classification tasks to differentiate early and late stage Mild\nCognitive Impairment (MCI) from Normal healthy Control (NC) subjects. The\nexperiments verify that our proposed residual D-net indeed learns the brain\nconnectivity dynamics, leading to significantly higher classification accuracy\ncompared to previously published techniques.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 15:25:56 GMT"}, {"version": "v2", "created": "Thu, 28 Feb 2019 09:32:58 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Seo", "Youngjoo", ""], ["Morante", "Manuel", ""], ["Kopsinis", "Yannis", ""], ["Theodoridis", "Sergios", ""]]}, {"id": "1804.07675", "submitter": "Christian H\\\"ager", "authors": "Shen Li, Christian H\\\"ager, Nil Garcia, Henk Wymeersch", "title": "Achievable Information Rates for Nonlinear Fiber Communication via\n  End-to-end Autoencoder Learning", "comments": "3 pages, 4 figures, fixed typos, revised layout", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning is used to compute achievable information rates (AIRs) for a\nsimplified fiber channel. The approach jointly optimizes the input distribution\n(constellation shaping) and the auxiliary channel distribution to compute AIRs\nwithout explicit channel knowledge in an end-to-end fashion.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 15:30:06 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 08:58:55 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Li", "Shen", ""], ["H\u00e4ger", "Christian", ""], ["Garcia", "Nil", ""], ["Wymeersch", "Henk", ""]]}, {"id": "1804.07729", "submitter": "Tandri Gauksson", "authors": "Rima Alaifari, Giovanni S. Alberti and Tandri Gauksson", "title": "ADef: an Iterative Algorithm to Construct Adversarial Deformations", "comments": "ICLR 2019 conference paper. 25 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep neural networks have proven to be a powerful tool for many\nrecognition and classification tasks, their stability properties are still not\nwell understood. In the past, image classifiers have been shown to be\nvulnerable to so-called adversarial attacks, which are created by additively\nperturbing the correctly classified image. In this paper, we propose the ADef\nalgorithm to construct a different kind of adversarial attack created by\niteratively applying small deformations to the image, found through a gradient\ndescent step. We demonstrate our results on MNIST with convolutional neural\nnetworks and on ImageNet with Inception-v3 and ResNet-101.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 17:11:06 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 17:25:10 GMT"}, {"version": "v3", "created": "Fri, 11 Jan 2019 15:42:59 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Alaifari", "Rima", ""], ["Alberti", "Giovanni S.", ""], ["Gauksson", "Tandri", ""]]}, {"id": "1804.07757", "submitter": "Shuangtao Li", "authors": "Shuangtao Li, Yuanke Chen, Yanlin Peng, Lin Bai", "title": "Learning More Robust Features with Adversarial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, it has been found that neural networks can be easily fooled\nby adversarial examples, which is a potential safety hazard in some\nsafety-critical applications. Many researchers have proposed various method to\nmake neural networks more robust to white-box adversarial attacks, but an\neffective method have not been found so far. In this short paper, we focus on\nthe robustness of the features learned by neural networks. We show that the\nfeatures learned by neural networks are not robust, and find that the\nrobustness of the learned features is closely related to the resistance against\nadversarial examples of neural networks. We also find that adversarial training\nagainst fast gradients sign method (FGSM) does not make the leaned features\nvery robust, even if it can make the trained networks very resistant to FGSM\nattack. Then we propose a method, which can be seen as an extension of\nadversarial training, to train neural networks to learn more robust features.\nWe perform experiments on MNIST and CIFAR-10 to evaluate our method, and the\nexperiment results show that this method greatly improves the robustness of the\nlearned features and the resistance to adversarial attacks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 05:07:14 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Li", "Shuangtao", ""], ["Chen", "Yuanke", ""], ["Peng", "Yanlin", ""], ["Bai", "Lin", ""]]}, {"id": "1804.07758", "submitter": "Lucas Bechberger", "authors": "Lucas Bechberger and Elektra Kypridemou", "title": "Mapping Images to Psychological Similarity Spaces Using Neural Networks", "comments": "Accepted to AIC 2018 (http://aic2018.pa.icar.cnr.it/), see\n  http://ceur-ws.org/Vol-2418/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cognitive framework of conceptual spaces bridges the gap between symbolic\nand subsymbolic AI by proposing an intermediate conceptual layer where\nknowledge is represented geometrically. There are two main approaches for\nobtaining the dimensions of this conceptual similarity space: using similarity\nratings from psychological experiments and using machine learning techniques.\nIn this paper, we propose a combination of both approaches by using\npsychologically derived similarity ratings to constrain the machine learning\nprocess. This way, a mapping from stimuli to conceptual spaces can be learned\nthat is both supported by psychological data and allows generalization to\nunseen stimuli. The results of a first feasibility study support our proposed\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 06:29:05 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 07:54:46 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Bechberger", "Lucas", ""], ["Kypridemou", "Elektra", ""]]}, {"id": "1804.07759", "submitter": "Gengyu Lyu", "authors": "Gengyu Lyu, Songhe Feng, Congyang Lang", "title": "A Self-paced Regularization Framework for Partial-Label Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial label learning (PLL) aims to solve the problem where each training\ninstance is associated with a set of candidate labels, one of which is the\ncorrect label. Most PLL algorithms try to disambiguate the candidate label set,\nby either simply treating each candidate label equally or iteratively\nidentifying the true label. Nonetheless, existing algorithms usually treat all\nlabels and instances equally, and the complexities of both labels and instances\nare not taken into consideration during the learning stage. Inspired by the\nsuccessful application of self-paced learning strategy in machine learning\nfield, we integrate the self-paced regime into the partial label learning\nframework and propose a novel Self-Paced Partial-Label Learning (SP-PLL)\nalgorithm, which could control the learning process to alleviate the problem by\nranking the priorities of the training examples together with their candidate\nlabels during each learning iteration. Extensive experiments and comparisons\nwith other baseline methods demonstrate the effectiveness and robustness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 08:04:32 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 08:49:25 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Lyu", "Gengyu", ""], ["Feng", "Songhe", ""], ["Lang", "Congyang", ""]]}, {"id": "1804.07768", "submitter": "Stefano Carrazza", "authors": "Stefano Carrazza and Daniel Krefl", "title": "Sampling the Riemann-Theta Boltzmann Machine", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the visible sector probability density function of the\nRiemann-Theta Boltzmann machine corresponds to a gaussian mixture model\nconsisting of an infinite number of component multi-variate gaussians. The\nweights of the mixture are given by a discrete multi-variate gaussian over the\nhidden state space. This allows us to sample the visible sector density\nfunction in a straight-forward manner. Furthermore, we show that the visible\nsector probability density function possesses an affine transform property,\nsimilar to the multi-variate gaussian density.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 18:00:02 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 09:38:27 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Carrazza", "Stefano", ""], ["Krefl", "Daniel", ""]]}, {"id": "1804.07779", "submitter": "Daoming Lyu", "authors": "Fangkai Yang, Daoming Lyu, Bo Liu, Steven Gustafson", "title": "PEORL: Integrating Symbolic Planning and Hierarchical Reinforcement\n  Learning for Robust Decision-Making", "comments": "conference version accepted by IJCAI-ECAI-18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning and symbolic planning have both been used to build\nintelligent autonomous agents. Reinforcement learning relies on learning from\ninteractions with real world, which often requires an unfeasibly large amount\nof experience. Symbolic planning relies on manually crafted symbolic knowledge,\nwhich may not be robust to domain uncertainties and changes. In this paper we\npresent a unified framework {\\em PEORL} that integrates symbolic planning with\nhierarchical reinforcement learning (HRL) to cope with decision-making in a\ndynamic environment with uncertainties.\n  Symbolic plans are used to guide the agent's task execution and learning, and\nthe learned experience is fed back to symbolic knowledge to improve planning.\nThis method leads to rapid policy search and robust symbolic plans in complex\ndomains. The framework is tested on benchmark domains of HRL.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 18:16:43 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 16:46:13 GMT"}, {"version": "v3", "created": "Tue, 5 Jun 2018 20:38:43 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Yang", "Fangkai", ""], ["Lyu", "Daoming", ""], ["Liu", "Bo", ""], ["Gustafson", "Steven", ""]]}, {"id": "1804.07824", "submitter": "Yan Xu", "authors": "Patrick Koch, Oleg Golovidov, Steven Gardner, Brett Wujek, Joshua\n  Griffin, Yan Xu", "title": "Autotune: A Derivative-free Optimization Framework for Hyperparameter\n  Tuning", "comments": "10 Pages, 9 figures, accept by KDD 2018", "journal-ref": null, "doi": "10.1145/3219819.3219837", "report-no": null, "categories": "cs.LG cs.DC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning applications often require hyperparameter tuning. The\nhyperparameters usually drive both the efficiency of the model training process\nand the resulting model quality. For hyperparameter tuning, machine learning\nalgorithms are complex black-boxes. This creates a class of challenging\noptimization problems, whose objective functions tend to be nonsmooth,\ndiscontinuous, unpredictably varying in computational expense, and include\ncontinuous, categorical, and/or integer variables. Further, function\nevaluations can fail for a variety of reasons including numerical difficulties\nor hardware failures. Additionally, not all hyperparameter value combinations\nare compatible, which creates so called hidden constraints. Robust and\nefficient optimization algorithms are needed for hyperparameter tuning. In this\npaper we present an automated parallel derivative-free optimization framework\ncalled \\textbf{Autotune}, which combines a number of specialized sampling and\nsearch methods that are very effective in tuning machine learning models\ndespite these challenges. Autotune provides significantly improved models over\nusing default hyperparameter settings with minimal user interaction on\nreal-world applications. Given the inherent expense of training numerous\ncandidate models, we demonstrate the effectiveness of Autotune's search methods\nand the efficient distributed and parallel paradigms for training and tuning\nmodels, and also discuss the resource trade-offs associated with the ability to\nboth distribute the training process and parallelize the tuning process.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 20:56:33 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2018 18:20:17 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Koch", "Patrick", ""], ["Golovidov", "Oleg", ""], ["Gardner", "Steven", ""], ["Wujek", "Brett", ""], ["Griffin", "Joshua", ""], ["Xu", "Yan", ""]]}, {"id": "1804.07837", "submitter": "Zhiyuan Li", "authors": "Elad Hazan, Wei Hu, Yuanzhi Li, Zhiyuan Li", "title": "Online Improper Learning with an Approximation Oracle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the question of reducing online learning to approximate\noptimization of the offline problem. In this setting, we give two algorithms\nwith near-optimal performance in the full information setting: they guarantee\noptimal regret and require only poly-logarithmically many calls to the\napproximation oracle per iteration. Furthermore, these algorithms apply to the\nmore general improper learning problems. In the bandit setting, our algorithm\nalso significantly improves the best previously known oracle complexity while\nmaintaining the same regret.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 21:46:06 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Hazan", "Elad", ""], ["Hu", "Wei", ""], ["Li", "Yuanzhi", ""], ["Li", "Zhiyuan", ""]]}, {"id": "1804.07839", "submitter": "Jonathan Rubin", "authors": "Jonathan Rubin, Deepan Sanghavi, Claire Zhao, Kathy Lee, Ashequl\n  Qadir, Minnan Xu-Wilson", "title": "Large Scale Automated Reading of Frontal and Lateral Chest X-Rays using\n  Dual Convolutional Neural Networks", "comments": "First draft, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MIMIC-CXR dataset is (to date) the largest released chest x-ray dataset\nconsisting of 473,064 chest x-rays and 206,574 radiology reports collected from\n63,478 patients. We present the results of training and evaluating a collection\nof deep convolutional neural networks on this dataset to recognize multiple\ncommon thorax diseases. To the best of our knowledge, this is the first work\nthat trains CNNs for this task on such a large collection of chest x-ray\nimages, which is over four times the size of the largest previously released\nchest x-ray corpus (ChestX-Ray14). We describe and evaluate individual CNN\nmodels trained on frontal and lateral CXR view types. In addition, we present a\nnovel DualNet architecture that emulates routine clinical practice by\nsimultaneously processing both frontal and lateral CXR images obtained from a\nradiological exam. Our DualNet architecture shows improved performance in\nrecognizing findings in CXR images when compared to applying separate baseline\nfrontal and lateral classifiers.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 21:48:35 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 21:13:59 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Rubin", "Jonathan", ""], ["Sanghavi", "Deepan", ""], ["Zhao", "Claire", ""], ["Lee", "Kathy", ""], ["Qadir", "Ashequl", ""], ["Xu-Wilson", "Minnan", ""]]}, {"id": "1804.07846", "submitter": "Edward Collier", "authors": "Edward Collier, Robert DiBiano, Supratik Mukhopadhyay", "title": "CactusNets: Layer Applicability as a Metric for Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks trained over large datasets learn features that are both\ngeneric to the whole dataset, and specific to individual classes in the\ndataset. Learned features tend towards generic in the lower layers and specific\nin the higher layers of a network. Methods like fine-tuning are made possible\nbecause of the ability for one filter to apply to multiple target classes. Much\nlike the human brain this behavior, can also be used to cluster and separate\nclasses. However, to the best of our knowledge there is no metric for how\napplicable learned features are to specific classes. In this paper we propose a\ndefinition and metric for measuring the applicability of learned features to\nindividual classes, and use this applicability metric to estimate input\napplicability and produce a new method of unsupervised learning we call the\nCactusNet.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 22:05:27 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Collier", "Edward", ""], ["DiBiano", "Robert", ""], ["Mukhopadhyay", "Supratik", ""]]}, {"id": "1804.07870", "submitter": "Ian Goodfellow", "authors": "Ian Goodfellow", "title": "Gradient Masking Causes CLEVER to Overestimate Adversarial Perturbation\n  Size", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in research on adversarial examples is that vulnerability to\nadversarial examples is usually measured by running attack algorithms. Because\nthe attack algorithms are not optimal, the attack algorithms are prone to\noverestimating the size of perturbation needed to fool the target model. In\nother words, the attack-based methodology provides an upper-bound on the size\nof a perturbation that will fool the model, but security guarantees require a\nlower bound. CLEVER is a proposed scoring method to estimate a lower bound.\nUnfortunately, an estimate of a bound is not a bound. In this report, we show\nthat gradient masking, a common problem that causes attack methodologies to\nprovide only a very loose upper bound, causes CLEVER to overestimate the size\nof perturbation needed to fool the model. In other words, CLEVER does not\nresolve the key problem with the attack-based methodology, because it fails to\nprovide a lower bound.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 00:38:33 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Goodfellow", "Ian", ""]]}, {"id": "1804.07882", "submitter": "Rafael Menelau Oliveira E Cruz", "authors": "Rafael M. O. Cruz, Hiba H. Zakane, Robert Sabourin and George D. C.\n  Cavalcanti", "title": "Dynamic Ensemble Selection VS K-NN: why and when Dynamic Selection\n  obtains higher classification performance?", "comments": "Paper published on IPTA 2017", "journal-ref": null, "doi": "10.1109/IPTA.2017.8310100", "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple classifier systems focus on the combination of classifiers to obtain\nbetter performance than a single robust one. These systems unfold three major\nphases: pool generation, selection and integration. One of the most promising\nMCS approaches is Dynamic Selection (DS), which relies on finding the most\ncompetent classifier or ensemble of classifiers to predict each test sample.\nThe majority of the DS techniques are based on the K-Nearest Neighbors (K-NN)\ndefinition, and the quality of the neighborhood has a huge impact on the\nperformance of DS methods. In this paper, we perform an analysis comparing the\nclassification results of DS techniques and the K-NN classifier under different\nconditions. Experiments are performed on 18 state-of-the-art DS techniques over\n30 classification datasets and results show that DS methods present a\nsignificant boost in classification accuracy even though they use the same\nneighborhood as the K-NN. The reasons behind the outperformance of DS\ntechniques over the K-NN classifier reside in the fact that DS techniques can\ndeal with samples with a high degree of instance hardness (samples that are\nlocated close to the decision border) as opposed to the K-NN. In this paper,\nnot only we explain why DS techniques achieve higher classification performance\nthan the K-NN but also when DS should be used.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 03:15:25 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Cruz", "Rafael M. O.", ""], ["Zakane", "Hiba H.", ""], ["Sabourin", "Robert", ""], ["Cavalcanti", "George D. C.", ""]]}, {"id": "1804.07891", "submitter": "Tien Cuong Bui", "authors": "Tien-Cuong Bui, Van-Duc Le, Sang-Kyun Cha", "title": "A Deep Learning Approach for Forecasting Air Pollution in South Korea\n  Using LSTM", "comments": "6 pages, 5 figures, conference paper, Seoul & Daegu air quality\n  datasets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tackling air pollution is an imperative problem in South Korea, especially in\nurban areas, over the last few years. More specially, South Korea has joined\nthe ranks of the world's most polluted countries alongside with other Asian\ncapitals, such as Beijing or Delhi. Much research is being conducted in\nenvironmental science to evaluate the dangerous impact of particulate matters\non public health. Besides that, deterministic models of air pollutant behavior\nare also generated; however, this is both complex and often inaccurate. On the\ncontrary, deep recurrent neural network reveals potent potential on forecasting\nout-comes of time-series data and has become more prevalent. This paper uses\nRecurrent Neural Network (RNN) with Long Short-Term Memory units as a framework\nfor leveraging knowledge from time-series data of air pollution and\nmeteorological information in Daegu, Seoul, Beijing, and Shenyang.\nAdditionally, we use encoder-decoder model, which is similar to machine\ncomprehension problems, as a crucial part of our prediction machine. Finally,\nwe investigate the prediction accuracy of various configurations. Our\nexperiments prevent the efficiency of integrating multiple layers of RNN on\nprediction model when forecasting far timesteps ahead. This research is a\nsignificant motivation for not only continuing researching on urban air quality\nbut also help the government leverage that insight to enact beneficial policies\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 05:07:47 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 01:24:44 GMT"}, {"version": "v3", "created": "Thu, 10 May 2018 13:45:12 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Bui", "Tien-Cuong", ""], ["Le", "Van-Duc", ""], ["Cha", "Sang-Kyun", ""]]}, {"id": "1804.07931", "submitter": "Liqin Zhao", "authors": "Xiao Ma, Liqin Zhao, Guan Huang, Zhi Wang, Zelin Hu, Xiaoqiang Zhu,\n  Kun Gai", "title": "Entire Space Multi-Task Model: An Effective Approach for Estimating\n  Post-Click Conversion Rate", "comments": "accept by SIGIR-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating post-click conversion rate (CVR) accurately is crucial for ranking\nsystems in industrial applications such as recommendation and advertising.\nConventional CVR modeling applies popular deep learning methods and achieves\nstate-of-the-art performance. However it encounters several task-specific\nproblems in practice, making CVR modeling challenging. For example,\nconventional CVR models are trained with samples of clicked impressions while\nutilized to make inference on the entire space with samples of all impressions.\nThis causes a sample selection bias problem. Besides, there exists an extreme\ndata sparsity problem, making the model fitting rather difficult. In this\npaper, we model CVR in a brand-new perspective by making good use of sequential\npattern of user actions, i.e., impression -> click -> conversion. The proposed\nEntire Space Multi-task Model (ESMM) can eliminate the two problems\nsimultaneously by i) modeling CVR directly over the entire space, ii) employing\na feature representation transfer learning strategy. Experiments on dataset\ngathered from Taobao's recommender system demonstrate that ESMM significantly\noutperforms competitive methods. We also release a sampling version of this\ndataset to enable future research. To the best of our knowledge, this is the\nfirst public dataset which contains samples with sequential dependence of click\nand conversion labels for CVR modeling.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 09:59:29 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 12:54:14 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Ma", "Xiao", ""], ["Zhao", "Liqin", ""], ["Huang", "Guan", ""], ["Wang", "Zhi", ""], ["Hu", "Zelin", ""], ["Zhu", "Xiaoqiang", ""], ["Gai", "Kun", ""]]}, {"id": "1804.07933", "submitter": "Battista Biggio", "authors": "Huang Xiao, Battista Biggio, Gavin Brown, Giorgio Fumera, Claudia\n  Eckert, Fabio Roli", "title": "Is feature selection secure against training data poisoning?", "comments": null, "journal-ref": "Proc. of the 32nd ICML, Lille, France, 2015. JMLR: W&CP vol. 37", "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.GT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in adversarial settings is becoming an important task for\napplication domains where attackers may inject malicious data into the training\nset to subvert normal operation of data-driven technologies. Feature selection\nhas been widely used in machine learning for security applications to improve\ngeneralization and computational efficiency, although it is not clear whether\nits use may be beneficial or even counterproductive when training data are\npoisoned by intelligent attackers. In this work, we shed light on this issue by\nproviding a framework to investigate the robustness of popular feature\nselection methods, including LASSO, ridge regression and the elastic net. Our\nresults on malware detection show that feature selection methods can be\nsignificantly compromised under attack (we can reduce LASSO to almost random\nchoices of feature sets by careful insertion of less than 5% poisoned training\nsamples), highlighting the need for specific countermeasures.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 10:18:46 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Xiao", "Huang", ""], ["Biggio", "Battista", ""], ["Brown", "Gavin", ""], ["Fumera", "Giorgio", ""], ["Eckert", "Claudia", ""], ["Roli", "Fabio", ""]]}, {"id": "1804.07944", "submitter": "Akash Srivastava", "authors": "Akash Srivastava, Charles Sutton", "title": "Variational Inference In Pachinko Allocation Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Pachinko Allocation Machine (PAM) is a deep topic model that allows\nrepresenting rich correlation structures among topics by a directed acyclic\ngraph over topics. Because of the flexibility of the model, however,\napproximate inference is very difficult. Perhaps for this reason, only a small\nnumber of potential PAM architectures have been explored in the literature. In\nthis paper we present an efficient and flexible amortized variational inference\nmethod for PAM, using a deep inference network to parameterize the approximate\nposterior distribution in a manner similar to the variational autoencoder. Our\ninference method produces more coherent topics than state-of-art inference\nmethods for PAM while being an order of magnitude faster, which allows\nexploration of a wider range of PAM architectures than have previously been\nstudied.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 11:12:25 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Srivastava", "Akash", ""], ["Sutton", "Charles", ""]]}, {"id": "1804.08003", "submitter": "Aven Samareh", "authors": "Aven Samareh and Mahshid Salemi Parizi", "title": "Stability of the Stochastic Gradient Method for an Approximated Large\n  Scale Kernel Machine", "comments": "Submitted to Journal of Signal Processing Systems (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we measured the stability of stochastic gradient method (SGM)\nfor learning an approximated Fourier primal support vector machine. The\nstability of an algorithm is considered by measuring the generalization error\nin terms of the absolute difference between the test and the training error.\nOur problem is to learn an approximated kernel function using random Fourier\nfeatures for a binary classification problem via online convex optimization\nsettings. For a convex, Lipschitz continuous and smooth loss function, given\nreasonable number of iterations stochastic gradient method is stable. We showed\nthat with a high probability SGM generalizes well for an approximated kernel\nunder given assumptions.We empirically verified the theoretical findings for\ndifferent parameters using several data sets.\n", "versions": [{"version": "v1", "created": "Sat, 21 Apr 2018 17:50:46 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Samareh", "Aven", ""], ["Parizi", "Mahshid Salemi", ""]]}, {"id": "1804.08066", "submitter": "Guoxin Cui", "authors": "Guoxin Cui, Jun Xu, Wei Zeng, Yanyan Lan, Jiafeng Guo, Xueqi Cheng", "title": "MQGrad: Reinforcement Learning of Gradient Quantization in Parameter\n  Server", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most significant bottleneck in training large scale machine\nlearning models on parameter server (PS) is the communication overhead, because\nit needs to frequently exchange the model gradients between the workers and\nservers during the training iterations. Gradient quantization has been proposed\nas an effective approach to reducing the communication volume. One key issue in\ngradient quantization is setting the number of bits for quantizing the\ngradients. Small number of bits can significantly reduce the communication\noverhead while hurts the gradient accuracies, and vise versa. An ideal\nquantization method would dynamically balance the communication overhead and\nmodel accuracy, through adjusting the number bits according to the knowledge\nlearned from the immediate past training iterations. Existing methods, however,\nquantize the gradients either with fixed number of bits, or with predefined\nheuristic rules. In this paper we propose a novel adaptive quantization method\nwithin the framework of reinforcement learning. The method, referred to as\nMQGrad, formalizes the selection of quantization bits as actions in a Markov\ndecision process (MDP) where the MDP states records the information collected\nfrom the past optimization iterations (e.g., the sequence of the loss function\nvalues). During the training iterations of a machine learning algorithm, MQGrad\ncontinuously updates the MDP state according to the changes of the loss\nfunction. Based on the information, MDP learns to select the optimal actions\n(number of bits) to quantize the gradients. Experimental results based on a\nbenchmark dataset showed that MQGrad can accelerate the learning of a large\nscale deep neural network while keeping its prediction accuracies.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 04:04:33 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Cui", "Guoxin", ""], ["Xu", "Jun", ""], ["Zeng", "Wei", ""], ["Lan", "Yanyan", ""], ["Guo", "Jiafeng", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1804.08071", "submitter": "Weiyang Liu", "authors": "Weiyang Liu, Zhen Liu, Zhiding Yu, Bo Dai, Rongmei Lin, Yisen Wang,\n  James M. Rehg, Le Song", "title": "Decoupled Networks", "comments": "CVPR 2018 (Spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inner product-based convolution has been a central component of convolutional\nneural networks (CNNs) and the key to learning visual representations. Inspired\nby the observation that CNN-learned features are naturally decoupled with the\nnorm of features corresponding to the intra-class variation and the angle\ncorresponding to the semantic difference, we propose a generic decoupled\nlearning framework which models the intra-class variation and semantic\ndifference independently. Specifically, we first reparametrize the inner\nproduct to a decoupled form and then generalize it to the decoupled convolution\noperator which serves as the building block of our decoupled networks. We\npresent several effective instances of the decoupled convolution operator. Each\ndecoupled operator is well motivated and has an intuitive geometric\ninterpretation. Based on these decoupled operators, we further propose to\ndirectly learn the operator from data. Extensive experiments show that such\ndecoupled reparameterization renders significant performance gain with easier\nconvergence and stronger robustness.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 05:26:08 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Liu", "Weiyang", ""], ["Liu", "Zhen", ""], ["Yu", "Zhiding", ""], ["Dai", "Bo", ""], ["Lin", "Rongmei", ""], ["Wang", "Yisen", ""], ["Rehg", "James M.", ""], ["Song", "Le", ""]]}, {"id": "1804.08130", "submitter": "Nikolaos Freris", "authors": "Saif Eddin Jabari, Nikolaos M. Freris, and Deepthi Mary Dilip", "title": "Sparse Travel Time Estimation from Streaming Data", "comments": null, "journal-ref": "Transportation Science 2019", "doi": "10.1287/trsc.2019.0920", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address two shortcomings in online travel time estimation methods for\ncongested urban traffic. The first shortcoming is related to the determination\nof the number of mixture modes, which can change dynamically, within day and\nfrom day to day. The second shortcoming is the wide-spread use of Gaussian\nprobability densities as mixture components. Gaussian densities fail to capture\nthe positive skew in travel time distributions and, consequently, large numbers\nof mixture components are needed for reasonable fitting accuracy when applied\nas mixture components. They also assign positive probabilities to negative\ntravel times. To address these issues, this paper derives a mixture\ndistribution with Gamma component densities, which are asymmetric and supported\non the positive numbers. We use sparse estimation techniques to ensure\nparsimonious models and propose a generalization of Gamma mixture densities\nusing Mittag-Leffler functions, which provides enhanced fitting flexibility and\nimproved parsimony. In order to accommodate within-day variability and allow\nfor online implementation of the proposed methodology (i.e., fast computations\non streaming travel time data), we introduce a recursive algorithm which\nefficiently updates the fitted distribution whenever new data become available.\nExperimental results using real-world travel time data illustrate the efficacy\nof the proposed methods.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 16:21:02 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 18:12:51 GMT"}, {"version": "v3", "created": "Fri, 4 Jan 2019 22:48:34 GMT"}, {"version": "v4", "created": "Mon, 13 May 2019 15:45:18 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Jabari", "Saif Eddin", ""], ["Freris", "Nikolaos M.", ""], ["Dilip", "Deepthi Mary", ""]]}, {"id": "1804.08154", "submitter": "Yo Joong Choe", "authors": "Yo Joong Choe, Sivaraman Balakrishnan, Aarti Singh, Jean M. Vettel,\n  Timothy Verstynen", "title": "Local White Matter Architecture Defines Functional Brain Dynamics", "comments": "Accepted to the 2018 IEEE International Conference on Systems, Man,\n  and Cybernetics (SMC 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large bundles of myelinated axons, called white matter, anatomically connect\ndisparate brain regions together and compose the structural core of the human\nconnectome. We recently proposed a method of measuring the local integrity\nalong the length of each white matter fascicle, termed the local connectome. If\ncommunication efficiency is fundamentally constrained by the integrity along\nthe entire length of a white matter bundle, then variability in the functional\ndynamics of brain networks should be associated with variability in the local\nconnectome. We test this prediction using two statistical approaches that are\ncapable of handling the high dimensionality of data. First, by performing\nstatistical inference on distance-based correlations, we show that similarity\nin the local connectome between individuals is significantly correlated with\nsimilarity in their patterns of functional connectivity. Second, by employing\nvariable selection using sparse canonical correlation analysis and\ncross-validation, we show that segments of the local connectome are predictive\nof certain patterns of functional brain dynamics. These results are consistent\nwith the hypothesis that structural variability along axon bundles constrains\ncommunication between disparate brain regions.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 18:46:08 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2018 12:33:36 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Choe", "Yo Joong", ""], ["Balakrishnan", "Sivaraman", ""], ["Singh", "Aarti", ""], ["Vettel", "Jean M.", ""], ["Verstynen", "Timothy", ""]]}, {"id": "1804.08219", "submitter": "Dicong Qiu", "authors": "Dicong Qiu and Karthik Paga", "title": "Adaptive Performance Assessment For Drivers Through Behavioral Advantage", "comments": "10 pages, 3 figures. Appeared in the Proceedings of the 1st Hackauton\n  Machine Learning Hackathon (Hackauton 2018), Pittsburgh, United States, 2018.\n  First Place Winner (Fuel Efficiency Problem); Most Innovative Prize", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential positive impact of autonomous driving and driver assistance\ntechnolo- gies have been a major impetus over the last decade. On the flip\nside, it has been a challenging problem to analyze the performance of human\ndrivers or autonomous driving agents quantitatively. In this work, we propose a\ngeneric method that compares the performance of drivers or autonomous driving\nagents even if the environmental conditions are different, by using the driver\nbehavioral advantage instead of absolute metrics, which efficiently removes the\nenvironmental factors. A concrete application of the method is also presented,\nwhere the performance of more than 100 truck drivers was evaluated and ranked\nin terms of fuel efficiency, covering more than 90,000 trips spanning an\naverage of 300 miles in a variety of driving conditions and environments.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 01:57:30 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 17:04:48 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Qiu", "Dicong", ""], ["Paga", "Karthik", ""]]}, {"id": "1804.08233", "submitter": "Yang Liu", "authors": "Yang Liu, Qiang Qu and Chao Gao", "title": "N-fold Superposition: Improving Neural Networks by Reducing the Noise in\n  Feature Maps", "comments": "7 pages, 5 figures, submitted to ICALIP 2018", "journal-ref": "2018 International Conference on Audio, Language and Image\n  Processing (ICALIP), Shanghai, 2018, pp. 450-456", "doi": "10.1109/ICALIP.2018.8455505", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering the use of Fully Connected (FC) layer limits the performance of\nConvolutional Neural Networks (CNNs), this paper develops a method to improve\nthe coupling between the convolution layer and the FC layer by reducing the\nnoise in Feature Maps (FMs). Our approach is divided into three steps. Firstly,\nwe separate all the FMs into n blocks equally. Then, the weighted summation of\nFMs at the same position in all blocks constitutes a new block of FMs. Finally,\nwe replicate this new block into n copies and concatenate them as the input to\nthe FC layer. This sharing of FMs could reduce the noise in them apparently and\navert the impact by a particular FM on the specific part weight of hidden\nlayers, hence preventing the network from overfitting to some extent. Using the\nFermat Lemma, we prove that this method could make the global minima value\nrange of the loss function wider, by which makes it easier for neural networks\nto converge and accelerates the convergence process. This method does not\nsignificantly increase the amounts of network parameters (only a few more\ncoefficients added), and the experiments demonstrate that this method could\nincrease the convergence speed and improve the classification performance of\nneural networks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 03:03:13 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 00:29:29 GMT"}, {"version": "v3", "created": "Thu, 3 May 2018 08:04:34 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Liu", "Yang", ""], ["Qu", "Qiang", ""], ["Gao", "Chao", ""]]}, {"id": "1804.08369", "submitter": "K\\'aroly Zsolnai-Feh\\'er", "authors": "K\\'aroly Zsolnai-Feh\\'er, Peter Wonka and Michael Wimmer", "title": "Gaussian Material Synthesis", "comments": "Supplementary data and source code:\n  https://users.cg.tuwien.ac.at/zsolnai/gfx/gaussian-material-synthesis/", "journal-ref": "ACM Transactions on Graphics (SIGGRAPH 2018) 37 (4)", "doi": "10.1145/3197517.3201307", "report-no": "Zsolnai18", "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a learning-based system for rapid mass-scale material synthesis\nthat is useful for novice and expert users alike. The user preferences are\nlearned via Gaussian Process Regression and can be easily sampled for new\nrecommendations. Typically, each recommendation takes 40-60 seconds to render\nwith global illumination, which makes this process impracticable for real-world\nworkflows. Our neural network eliminates this bottleneck by providing\nhigh-quality image predictions in real time, after which it is possible to pick\nthe desired materials from a gallery and assign them to a scene in an intuitive\nmanner. Workflow timings against Disney's \"principled\" shader reveal that our\nsystem scales well with the number of sought materials, thus empowering even\nnovice users to generate hundreds of high-quality material models without any\nexpertise in material modeling. Similarly, expert users experience a\nsignificant decrease in the total modeling time when populating a scene with\nmaterials. Furthermore, our proposed solution also offers controllable\nrecommendations and a novel latent space variant generation step to enable the\nreal-time fine-tuning of materials without requiring any domain expertise.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 12:33:59 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Zsolnai-Feh\u00e9r", "K\u00e1roly", ""], ["Wonka", "Peter", ""], ["Wimmer", "Michael", ""]]}, {"id": "1804.08376", "submitter": "Tomas Iesmantas", "authors": "Tomas Iesmantas and Robertas Alzbutas", "title": "Convolutional capsule network for classification of breast cancer\n  histology images", "comments": "Submitted to ICIAR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatization of the diagnosis of any kind of disease is of great importance\nand it's gaining speed as more and more deep learning solutions are applied to\ndifferent problems. One of such computer aided systems could be a decision\nsupport too able to accurately differentiate between different types of breast\ncancer histological images - normal tissue or carcinoma. In this paper authors\npresent a deep learning solution, based on convolutional capsule network for\nclassification of four types of images of breast tissue biopsy when hematoxylin\nand eusin staining is applied. The cross-validation accuracy was achieved to be\n0.87 with equaly high sensitivity.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 12:48:49 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Iesmantas", "Tomas", ""], ["Alzbutas", "Robertas", ""]]}, {"id": "1804.08396", "submitter": "Mehdi Mohammadi", "authors": "Mehdi Mohammadi, Ala Al-Fuqaha, Jun-Seok Oh", "title": "Path Planning in Support of Smart Mobility Applications using Generative\n  Adversarial Networks", "comments": "8 pages, submitted to IEEE SmartData-2018 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes and evaluates the use of Generative Adversarial Networks\n(GANs) for path planning in support of smart mobility applications such as\nindoor and outdoor navigation applications, individualized wayfinding for\npeople with disabilities (e.g., vision impairments, physical disabilities,\netc.), path planning for evacuations, robotic navigations, and path planning\nfor autonomous vehicles. We propose an architecture based on GANs to recommend\naccurate and reliable paths for navigation applications. The proposed system\ncan use crowd-sourced data to learn the trajectories and infer new ones. The\nsystem provides users with generated paths that help them navigate from their\nlocal environment to reach a desired location. As a use case, we experimented\nwith the proposed method in support of a wayfinding application in an indoor\nenvironment. Our experiments assert that the generated paths are correct and\nreliable. The accuracy of the classification task for the generated paths is up\nto 99% and the quality of the generated paths has a mean opinion score of 89%.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 13:21:31 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Mohammadi", "Mehdi", ""], ["Al-Fuqaha", "Ala", ""], ["Oh", "Jun-Seok", ""]]}, {"id": "1804.08416", "submitter": "Zhaowei Zhu", "authors": "Zhaowei Zhu, Ting Liu, Shengda Jin, and Xiliang Luo", "title": "Learn and Pick Right Nodes to Offload", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task offloading is a promising technology to exploit the benefits of fog\ncomputing. An effective task offloading strategy is needed to utilize the\ncomputational resources efficiently. In this paper, we endeavor to seek an\nonline task offloading strategy to minimize the long-term latency. In\nparticular, we formulate a stochastic programming problem, where the\nexpectations of the system parameters change abruptly at unknown time instants.\nMeanwhile, we consider the fact that the queried nodes can only feed back the\nprocessing results after finishing the tasks. We then put forward an effective\nalgorithm to solve this challenging stochastic programming under the\nnon-stationary bandit model. We further prove that our proposed algorithm is\nasymptotically optimal in a non-stationary fog-enabled network. Numerical\nsimulations are carried out to corroborate our designs.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 05:18:09 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 11:49:29 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Zhu", "Zhaowei", ""], ["Liu", "Ting", ""], ["Jin", "Shengda", ""], ["Luo", "Xiliang", ""]]}, {"id": "1804.08420", "submitter": "Qiang Ning", "authors": "Qiang Ning, Zhongzhi Yu, Chuchu Fan, Dan Roth", "title": "Exploiting Partially Annotated Data for Temporal Relation Extraction", "comments": "[Final Version] short paper accepted by *SEM'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Annotating temporal relations (TempRel) between events described in natural\nlanguage is known to be labor intensive, partly because the total number of\nTempRels is quadratic in the number of events. As a result, only a small number\nof documents are typically annotated, limiting the coverage of various\nlexical/semantic phenomena. In order to improve existing approaches, one\npossibility is to make use of the readily available, partially annotated data\n(P as in partial) that cover more documents. However, missing annotations in P\nare known to hurt, rather than help, existing systems. This work is a case\nstudy in exploring various usages of P for TempRel extraction. Results show\nthat despite missing annotations, P is still a useful supervision signal for\nthis task within a constrained bootstrapping learning framework. The system\ndescribed in this system is publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2018 21:33:00 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 02:31:40 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Ning", "Qiang", ""], ["Yu", "Zhongzhi", ""], ["Fan", "Chuchu", ""], ["Roth", "Dan", ""]]}, {"id": "1804.08438", "submitter": "Tomi Kinnunen", "authors": "Tomi Kinnunen, Jaime Lorenzo-Trueba, Junichi Yamagishi, Tomoki Toda,\n  Daisuke Saito, Fernando Villavicencio, Zhenhua Ling", "title": "A Spoofing Benchmark for the 2018 Voice Conversion Challenge: Leveraging\n  from Spoofing Countermeasures for Speech Artifact Assessment", "comments": "Correction (bug fix) of a published ODYSSEY 2018 publication with the\n  same title and author list; more details in footnote in page 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice conversion (VC) aims at conversion of speaker characteristic without\naltering content. Due to training data limitations and modeling imperfections,\nit is difficult to achieve believable speaker mimicry without introducing\nprocessing artifacts; performance assessment of VC, therefore, usually involves\nboth speaker similarity and quality evaluation by a human panel. As a\ntime-consuming, expensive, and non-reproducible process, it hinders rapid\nprototyping of new VC technology. We address artifact assessment using an\nalternative, objective approach leveraging from prior work on spoofing\ncountermeasures (CMs) for automatic speaker verification. Therein, CMs are used\nfor rejecting `fake' inputs such as replayed, synthetic or converted speech but\ntheir potential for automatic speech artifact assessment remains unknown. This\nstudy serves to fill that gap. As a supplement to subjective results for the\n2018 Voice Conversion Challenge (VCC'18) data, we configure a standard\nconstant-Q cepstral coefficient CM to quantify the extent of processing\nartifacts. Equal error rate (EER) of the CM, a confusability index of VC\nsamples with real human speech, serves as our artifact measure. Two clusters of\nVCC'18 entries are identified: low-quality ones with detectable artifacts (low\nEERs), and higher quality ones with less artifacts. None of the VCC'18 systems,\nhowever, is perfect: all EERs are < 30 % (the `ideal' value would be 50 %). Our\npreliminary findings suggest potential of CMs outside of their original\napplication, as a supplemental optimization and benchmarking tool to enhance VC\ntechnology.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 13:54:47 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 17:14:57 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Kinnunen", "Tomi", ""], ["Lorenzo-Trueba", "Jaime", ""], ["Yamagishi", "Junichi", ""], ["Toda", "Tomoki", ""], ["Saito", "Daisuke", ""], ["Villavicencio", "Fernando", ""], ["Ling", "Zhenhua", ""]]}, {"id": "1804.08450", "submitter": "Dawei Yang", "authors": "Lei Huang, Dawei Yang, Bo Lang, Jia Deng", "title": "Decorrelated Batch Normalization", "comments": "Accepted to CVPR 2018. Code available at\n  https://github.com/umich-vl/DecorrelatedBN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN) is capable of accelerating the training of deep\nmodels by centering and scaling activations within mini-batches. In this work,\nwe propose Decorrelated Batch Normalization (DBN), which not just centers and\nscales activations but whitens them. We explore multiple whitening techniques,\nand find that PCA whitening causes a problem we call stochastic axis swapping,\nwhich is detrimental to learning. We show that ZCA whitening does not suffer\nfrom this problem, permitting successful learning. DBN retains the desirable\nqualities of BN and further improves BN's optimization efficiency and\ngeneralization ability. We design comprehensive experiments to show that DBN\ncan improve the performance of BN on multilayer perceptrons and convolutional\nneural networks. Furthermore, we consistently improve the accuracy of residual\nnetworks on CIFAR-10, CIFAR-100, and ImageNet.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 14:06:50 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Huang", "Lei", ""], ["Yang", "Dawei", ""], ["Lang", "Bo", ""], ["Deng", "Jia", ""]]}, {"id": "1804.08472", "submitter": "Liao Zhu", "authors": "Liao Zhu, Sumanta Basu, Robert A. Jarrow, Martin T. Wells", "title": "High-Dimensional Estimation, Basis Assets, and the Adaptive Multi-Factor\n  Model", "comments": null, "journal-ref": "The Quarterly Journal of Finance. Vol. 10, No. 04, 2050017 (2020)", "doi": "10.1142/S2010139220500172", "report-no": null, "categories": "q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes a new algorithm for the high-dimensional financial data --\nthe Groupwise Interpretable Basis Selection (GIBS) algorithm, to estimate a new\nAdaptive Multi-Factor (AMF) asset pricing model, implied by the recently\ndeveloped Generalized Arbitrage Pricing Theory, which relaxes the convention\nthat the number of risk-factors is small. We first obtain an adaptive\ncollection of basis assets and then simultaneously test which basis assets\ncorrespond to which securities, using high-dimensional methods. The AMF model,\nalong with the GIBS algorithm, is shown to have a significantly better fitting\nand prediction power than the Fama-French 5-factor model.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 14:34:39 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 14:40:34 GMT"}, {"version": "v3", "created": "Thu, 31 Jan 2019 03:41:03 GMT"}, {"version": "v4", "created": "Mon, 3 Feb 2020 00:21:11 GMT"}, {"version": "v5", "created": "Thu, 27 Feb 2020 21:25:33 GMT"}, {"version": "v6", "created": "Mon, 26 Apr 2021 02:40:50 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Zhu", "Liao", ""], ["Basu", "Sumanta", ""], ["Jarrow", "Robert A.", ""], ["Wells", "Martin T.", ""]]}, {"id": "1804.08501", "submitter": "James O' Neill", "authors": "James O' Neill and Danushka Bollegala", "title": "Dropping Networks for Transfer Learning", "comments": "9 pages, 3 figures Updated because the original table of results was\n  in the wrong order", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many tasks in natural language understanding require learning relationships\nbetween two sequences for various tasks such as natural language inference,\nparaphrasing and entailment. These aforementioned tasks are similar in nature,\nyet they are often modeled individually. Knowledge transfer can be effective\nfor closely related tasks. However, transferring all knowledge, some of which\nirrelevant for a target task, can lead to sub-optimal results due to\n\\textit{negative} transfer. Hence, this paper focuses on the transferability of\nboth instances and parameters across natural language understanding tasks by\nproposing an ensemble-based transfer learning method. \\newline The primary\ncontribution of this paper is the combination of both \\textit{Dropout} and\n\\textit{Bagging} for improved transferability in neural networks, referred to\nas \\textit{Dropping} herein. We present a straightforward yet novel approach\nfor incorporating source \\textit{Dropping} Networks to a target task for\nfew-shot learning that mitigates \\textit{negative} transfer. This is achieved\nby using a decaying parameter chosen according to the slope changes of a\nsmoothed spline error curve at sub-intervals during training. We compare the\nproposed approach against hard parameter sharing and soft parameter sharing\ntransfer methods in the few-shot learning case. We also compare against models\nthat are fully trained on the target task in the standard supervised learning\nsetup. The aforementioned adjustment leads to improved transfer learning\nperformance and comparable results to the current state of the art only using a\nfraction of the data from the target task.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 15:22:26 GMT"}, {"version": "v2", "created": "Sun, 6 May 2018 21:11:31 GMT"}, {"version": "v3", "created": "Sun, 16 Sep 2018 14:42:40 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Neill", "James O'", ""], ["Bollegala", "Danushka", ""]]}, {"id": "1804.08557", "submitter": "Jonas Greitemann", "authors": "Jonas Greitemann and Ke Liu and Lode Pollet", "title": "Probing hidden spin order with interpretable machine learning", "comments": "6 pages, 5 figures (+ 3 pages, 1 figure, 1 table Supplemental\n  Materials), published as PRB Rapid Communication (Editors' Suggestion)", "journal-ref": "Phys. Rev. B 99, 060404 (2019)", "doi": "10.1103/PhysRevB.99.060404", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.str-el physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search of unconventional magnetic and nonmagnetic states is a major topic\nin the study of frustrated magnetism. Canonical examples of those states\ninclude various spin liquids and spin nematics. However, discerning their\nexistence and the correct characterization is usually challenging. Here we\nintroduce a machine-learning protocol that can identify general nematic order\nand their order parameter from seemingly featureless spin configurations, thus\nproviding comprehensive insight on the presence or absence of hidden orders. We\ndemonstrate the capabilities of our method by extracting the analytical form of\nnematic order parameter tensors up to rank 6. This may prove useful in the\nsearch for novel spin states and for ruling out spurious spin liquid\ncandidates.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 16:51:47 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 15:54:40 GMT"}, {"version": "v3", "created": "Thu, 11 Oct 2018 17:19:46 GMT"}, {"version": "v4", "created": "Wed, 21 Nov 2018 16:12:24 GMT"}, {"version": "v5", "created": "Mon, 11 Feb 2019 17:12:33 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Greitemann", "Jonas", ""], ["Liu", "Ke", ""], ["Pollet", "Lode", ""]]}, {"id": "1804.08562", "submitter": "Edouard Delasalles", "authors": "Ali Ziat, Edouard Delasalles, Ludovic Denoyer, Patrick Gallinari", "title": "Spatio-Temporal Neural Networks for Space-Time Series Forecasting and\n  Relations Discovery", "comments": "accepted by: ICDM 2018 - IEEE International Conference on Data Mining\n  series (ICDM)", "journal-ref": "2017 IEEE International Conference on Data Mining (ICDM), New\n  Orleans, LA, 2017, pp. 705-714", "doi": "10.1109/ICDM.2017.80", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a dynamical spatio-temporal model formalized as a recurrent\nneural network for forecasting time series of spatial processes, i.e. series of\nobservations sharing temporal and spatial dependencies. The model learns these\ndependencies through a structured latent dynamical component, while a decoder\npredicts the observations from the latent representations. We consider several\nvariants of this model, corresponding to different prior hypothesis about the\nspatial relations between the series. The model is evaluated and compared to\nstate-of-the-art baselines, on a variety of forecasting problems representative\nof different application areas: epidemiology, geo-spatial statistics and\ncar-traffic prediction. Besides these evaluations, we also describe experiments\nshowing the ability of this approach to extract relevant spatial relations.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 16:56:25 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Ziat", "Ali", ""], ["Delasalles", "Edouard", ""], ["Denoyer", "Ludovic", ""], ["Gallinari", "Patrick", ""]]}, {"id": "1804.08597", "submitter": "Artur Garcez", "authors": "Artur d'Avila Garcez and Aimore Resende Riquetti Dutra and Eduardo\n  Alonso", "title": "Towards Symbolic Reinforcement Learning with Common Sense", "comments": "15 pages, 13 figures, 26 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning (deep RL) has made several breakthroughs in\nrecent years in applications ranging from complex control tasks in unmanned\nvehicles to game playing. Despite their success, deep RL still lacks several\nimportant capacities of human intelligence, such as transfer learning,\nabstraction and interpretability. Deep Symbolic Reinforcement Learning (DSRL)\nseeks to incorporate such capacities to deep Q-networks (DQN) by learning a\nrelevant symbolic representation prior to using Q-learning. In this paper, we\npropose a novel extension of DSRL, which we call Symbolic Reinforcement\nLearning with Common Sense (SRL+CS), offering a better balance between\ngeneralization and specialization, inspired by principles of common sense when\nassigning rewards and aggregating Q-values. Experiments reported in this paper\nshow that SRL+CS learns consistently faster than Q-learning and DSRL, achieving\nalso a higher accuracy. In the hardest case, where agents were trained in a\ndeterministic environment and tested in a random environment, SRL+CS achieves\nnearly 100% average accuracy compared to DSRL's 70% and DQN's 50% accuracy. To\nthe best of our knowledge, this is the first case of near perfect zero-shot\ntransfer learning using Reinforcement Learning.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 17:44:29 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Garcez", "Artur d'Avila", ""], ["Dutra", "Aimore Resende Riquetti", ""], ["Alonso", "Eduardo", ""]]}, {"id": "1804.08598", "submitter": "Anish Athalye", "authors": "Andrew Ilyas, Logan Engstrom, Anish Athalye, Jessy Lin", "title": "Black-box Adversarial Attacks with Limited Queries and Information", "comments": "ICML 2018. This supercedes the previous paper \"Query-efficient\n  Black-box adversarial examples.\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current neural network-based classifiers are susceptible to adversarial\nexamples even in the black-box setting, where the attacker only has query\naccess to the model. In practice, the threat model for real-world systems is\noften more restrictive than the typical black-box model where the adversary can\nobserve the full output of the network on arbitrarily many chosen inputs. We\ndefine three realistic threat models that more accurately characterize many\nreal-world classifiers: the query-limited setting, the partial-information\nsetting, and the label-only setting. We develop new attacks that fool\nclassifiers under these more restrictive threat models, where previous methods\nwould be impractical or ineffective. We demonstrate that our methods are\neffective against an ImageNet classifier under our proposed threat models. We\nalso demonstrate a targeted black-box attack against a commercial classifier,\novercoming the challenges of limited query access, partial information, and\nother practical issues to break the Google Cloud Vision API.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 17:46:34 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 18:17:09 GMT"}, {"version": "v3", "created": "Wed, 11 Jul 2018 13:51:00 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Ilyas", "Andrew", ""], ["Engstrom", "Logan", ""], ["Athalye", "Anish", ""], ["Lin", "Jessy", ""]]}, {"id": "1804.08603", "submitter": "Pranjal Awasthi", "authors": "Pranjal Awasthi and Aravindan Vijayaraghavan", "title": "Towards Learning Sparsely Used Dictionaries with Arbitrary Supports", "comments": "72 pages, fixed minor typos, and added a new reference in related\n  work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionary learning is a popular approach for inferring a hidden basis or\ndictionary in which data has a sparse representation. Data generated from the\ndictionary A (an n by m matrix, with m > n in the over-complete setting) is\ngiven by Y = AX where X is a matrix whose columns have supports chosen from a\ndistribution over k-sparse vectors, and the non-zero values chosen from a\nsymmetric distribution. Given Y, the goal is to recover A and X in polynomial\ntime. Existing algorithms give polytime guarantees for recovering incoherent\ndictionaries, under strong distributional assumptions both on the supports of\nthe columns of X, and on the values of the non-zero entries. In this work, we\nstudy the following question: Can we design efficient algorithms for recovering\ndictionaries when the supports of the columns of X are arbitrary?\n  To address this question while circumventing the issue of\nnon-identifiability, we study a natural semirandom model for dictionary\nlearning where there are a large number of samples $y=Ax$ with arbitrary\nk-sparse supports for x, along with a few samples where the sparse supports are\nchosen uniformly at random. While the few samples with random supports ensures\nidentifiability, the support distribution can look almost arbitrary in\naggregate. Hence existing algorithmic techniques seem to break down as they\nmake strong assumptions on the supports.\n  Our main contribution is a new polynomial time algorithm for learning\nincoherent over-complete dictionaries that works under the semirandom model.\nAdditionally the same algorithm provides polynomial time guarantees in new\nparameter regimes when the supports are fully random. Finally using these\ntechniques, we also identify a minimal set of conditions on the supports under\nwhich the dictionary can be (information theoretically) recovered from\npolynomial samples for almost linear sparsity, i.e., $k=\\tilde{O}(n)$.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 17:57:33 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 15:27:40 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Vijayaraghavan", "Aravindan", ""]]}, {"id": "1804.08606", "submitter": "Deepak Pathak", "authors": "Deepak Pathak, Parsa Mahmoudieh, Guanghao Luo, Pulkit Agrawal, Dian\n  Chen, Yide Shentu, Evan Shelhamer, Jitendra Malik, Alexei A. Efros, Trevor\n  Darrell", "title": "Zero-Shot Visual Imitation", "comments": "Oral presentation at ICLR 2018. Website at\n  https://pathak22.github.io/zeroshot-imitation/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current dominant paradigm for imitation learning relies on strong\nsupervision of expert actions to learn both 'what' and 'how' to imitate. We\npursue an alternative paradigm wherein an agent first explores the world\nwithout any expert supervision and then distills its experience into a\ngoal-conditioned skill policy with a novel forward consistency loss. In our\nframework, the role of the expert is only to communicate the goals (i.e., what\nto imitate) during inference. The learned policy is then employed to mimic the\nexpert (i.e., how to imitate) after seeing just a sequence of images\ndemonstrating the desired task. Our method is 'zero-shot' in the sense that the\nagent never has access to expert actions during training or for the task\ndemonstration at inference. We evaluate our zero-shot imitator in two\nreal-world settings: complex rope manipulation with a Baxter robot and\nnavigation in previously unseen office environments with a TurtleBot. Through\nfurther experiments in VizDoom simulation, we provide evidence that better\nmechanisms for exploration lead to learning a more capable policy which in turn\nimproves end task performance. Videos, models, and more details are available\nat https://pathak22.github.io/zeroshot-imitation/\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 17:58:26 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Pathak", "Deepak", ""], ["Mahmoudieh", "Parsa", ""], ["Luo", "Guanghao", ""], ["Agrawal", "Pulkit", ""], ["Chen", "Dian", ""], ["Shentu", "Yide", ""], ["Shelhamer", "Evan", ""], ["Malik", "Jitendra", ""], ["Efros", "Alexei A.", ""], ["Darrell", "Trevor", ""]]}, {"id": "1804.08607", "submitter": "Alexey Melnikov", "authors": "Alexey A. Melnikov, Adi Makmal, Hans J. Briegel", "title": "Benchmarking projective simulation in navigation problems", "comments": "8 pages, 10 figures", "journal-ref": "IEEE Access 6, 64639 (2018)", "doi": "10.1109/ACCESS.2018.2876494", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Projective simulation (PS) is a model for intelligent agents with a\ndeliberation capacity that is based on episodic memory. The model has been\nshown to provide a flexible framework for constructing reinforcement-learning\nagents, and it allows for quantum mechanical generalization, which leads to a\nspeed-up in deliberation time. PS agents have been applied successfully in the\ncontext of complex skill learning in robotics, and in the design of\nstate-of-the-art quantum experiments. In this paper, we study the performance\nof projective simulation in two benchmarking problems in navigation, namely the\ngrid world and the mountain car problem. The performance of PS is compared to\nstandard tabular reinforcement learning approaches, Q-learning and SARSA. Our\ncomparison demonstrates that the performance of PS and standard learning\napproaches are qualitatively and quantitatively similar, while it is much\neasier to choose optimal model parameters in case of projective simulation,\nwith a reduced computational effort of one to two orders of magnitude. Our\nresults show that the projective simulation model stands out for its simplicity\nin terms of the number of model parameters, which makes it simple to set up the\nlearning agent in unknown task environments.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 17:58:27 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Melnikov", "Alexey A.", ""], ["Makmal", "Adi", ""], ["Briegel", "Hans J.", ""]]}, {"id": "1804.08613", "submitter": "Yinghua Zhang", "authors": "Yinghua Zhang, Yu Zhang and Qiang Yang", "title": "Parameter Transfer Unit for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameters in deep neural networks which are trained on large-scale databases\ncan generalize across multiple domains, which is referred as \"transferability\".\nUnfortunately, the transferability is usually defined as discrete states and it\ndiffers with domains and network architectures. Existing works usually\nheuristically apply parameter-sharing or fine-tuning, and there is no\nprincipled approach to learn a parameter transfer strategy. To address the gap,\na parameter transfer unit (PTU) is proposed in this paper. The PTU learns a\nfine-grained nonlinear combination of activations from both the source and the\ntarget domain networks, and subsumes hand-crafted discrete transfer states. In\nthe PTU, the transferability is controlled by two gates which are artificial\nneurons and can be learned from data. The PTU is a general and flexible module\nwhich can be used in both CNNs and RNNs. Experiments are conducted with various\nnetwork architectures and multiple transfer domain pairs. Results demonstrate\nthe effectiveness of the PTU as it outperforms heuristic parameter-sharing and\nfine-tuning in most settings.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 07:25:32 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Zhang", "Yinghua", ""], ["Zhang", "Yu", ""], ["Yang", "Qiang", ""]]}, {"id": "1804.08615", "submitter": "Qing-Yong Wang", "authors": "Liang-Yong Xia, Qing-Yong Wang", "title": "QSAR Classification Modeling for Bioactivity of Molecular Structure via\n  SPL-Logsum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative structure-activity relationship (QSAR) modelling is effective\n'bridge' to search the reliable relationship related bioactivity to molecular\nstructure. A QSAR classification model contains a lager number of redundant,\nnoisy and irrelevant descriptors. To address this problem, various of methods\nhave been proposed for descriptor selection. Generally, they can be grouped\ninto three categories: filters, wrappers, and embedded methods. Regularization\nmethod is an important embedded technology, which can be used for continuous\nshrinkage and automatic descriptors selection. In recent years, the interest of\nresearchers in the application of regularization techniques is increasing in\ndescriptors selection , such as, logistic regression(LR) with $L_1$ penalty. In\nthis paper, we proposed a novel descriptor selection method based on self-paced\nlearning(SPL) with Logsum penalized LR for predicting the bioactivity of\nmolecular structure. SPL inspired by the learning process of humans and animals\nthat gradually learns from easy samples(smaller losses) to hard samples(bigger\nlosses) samples into training and Logsum regularization has capacity to select\nfew meaningful and significant molecular descriptors, respectively.\nExperimental results on simulation and three public QSAR datasets show that our\nproposed SPL-Logsum method outperforms other commonly used sparse methods in\nterms of classification performance and model interpretation.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 09:46:27 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 04:00:01 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Xia", "Liang-Yong", ""], ["Wang", "Qing-Yong", ""]]}, {"id": "1804.08617", "submitter": "Matthew W. Hoffman", "authors": "Gabriel Barth-Maron, Matthew W. Hoffman, David Budden, Will Dabney,\n  Dan Horgan, Dhruva TB, Alistair Muldal, Nicolas Heess, Timothy Lillicrap", "title": "Distributed Distributional Deterministic Policy Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work adopts the very successful distributional perspective on\nreinforcement learning and adapts it to the continuous control setting. We\ncombine this within a distributed framework for off-policy learning in order to\ndevelop what we call the Distributed Distributional Deep Deterministic Policy\nGradient algorithm, D4PG. We also combine this technique with a number of\nadditional, simple improvements such as the use of $N$-step returns and\nprioritized experience replay. Experimentally we examine the contribution of\neach of these individual components, and show how they interact, as well as\ntheir combined contributions. Our results show that across a wide variety of\nsimple control tasks, difficult manipulation tasks, and a set of hard\nobstacle-based locomotion tasks the D4PG algorithm achieves state of the art\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 11:57:21 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Barth-Maron", "Gabriel", ""], ["Hoffman", "Matthew W.", ""], ["Budden", "David", ""], ["Dabney", "Will", ""], ["Horgan", "Dan", ""], ["TB", "Dhruva", ""], ["Muldal", "Alistair", ""], ["Heess", "Nicolas", ""], ["Lillicrap", "Timothy", ""]]}, {"id": "1804.08619", "submitter": "Weichao Li", "authors": "Weichao Li, Fuxian Huang, Xi Li, Gang Pan and Fei Wu", "title": "State Distribution-aware Sampling for Deep Q-learning", "comments": "this paper has been submitted to neural processing letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical and challenging problem in reinforcement learning is how to learn\nthe state-action value function from the experience replay buffer and\nsimultaneously keep sample efficiency and faster convergence to a high quality\nsolution. In prior works, transitions are uniformly sampled at random from the\nreplay buffer or sampled based on their priority measured by\ntemporal-difference (TD) error. However, these approaches do not fully take\ninto consideration the intrinsic characteristics of transition distribution in\nthe state space and could result in redundant and unnecessary TD updates,\nslowing down the convergence of the learning procedure. To overcome this\nproblem, we propose a novel state distribution-aware sampling method to balance\nthe replay times for transitions with skew distribution, which takes into\naccount both the occurrence frequencies of transitions and the uncertainty of\nstate-action values. Consequently, our approach could reduce the unnecessary TD\nupdates and increase the TD updates for state-action value with more\nuncertainty, making the experience replay more effective and efficient.\nExtensive experiments are conducted on both classic control tasks and Atari\n2600 games based on OpenAI gym platform and the experimental results\ndemonstrate the effectiveness of our approach in comparison with the standard\nDQN approach.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 13:22:22 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Li", "Weichao", ""], ["Huang", "Fuxian", ""], ["Li", "Xi", ""], ["Pan", "Gang", ""], ["Wu", "Fei", ""]]}, {"id": "1804.08646", "submitter": "Beau Coker", "authors": "Beau Coker, Cynthia Rudin, Gary King", "title": "A Theory of Statistical Inference for Ensuring the Robustness of\n  Scientific Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference is the process of using facts we know to learn about facts we do\nnot know. A theory of inference gives assumptions necessary to get from the\nformer to the latter, along with a definition for and summary of the resulting\nuncertainty. Any one theory of inference is neither right nor wrong, but merely\nan axiom that may or may not be useful. Each of the many diverse theories of\ninference can be valuable for certain applications. However, no existing theory\nof inference addresses the tendency to choose, from the range of plausible data\nanalysis specifications consistent with prior evidence, those that\ninadvertently favor one's own hypotheses. Since the biases from these choices\nare a growing concern across scientific fields, and in a sense the reason the\nscientific community was invented in the first place, we introduce a new theory\nof inference designed to address this critical problem. We introduce hacking\nintervals, which are the range of a summary statistic one may obtain given a\nclass of possible endogenous manipulations of the data. Hacking intervals\nrequire no appeal to hypothetical data sets drawn from imaginary\nsuperpopulations. A scientific result with a small hacking interval is more\nrobust to researcher manipulation than one with a larger interval, and is often\neasier to interpret than a classical confidence interval. Some versions of\nhacking intervals turn out to be equivalent to classical confidence intervals,\nwhich means they may also provide a more intuitive and potentially more useful\ninterpretation of classical confidence intervals.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 18:13:41 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 02:28:23 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Coker", "Beau", ""], ["Rudin", "Cynthia", ""], ["King", "Gary", ""]]}, {"id": "1804.08682", "submitter": "Charles Fisher", "authors": "Charles K. Fisher, Aaron M. Smith, Jonathan R. Walsh", "title": "Boltzmann Encoded Adversarial Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann Machines (RBMs) are a class of generative neural network\nthat are typically trained to maximize a log-likelihood objective function. We\nargue that likelihood-based training strategies may fail because the objective\ndoes not sufficiently penalize models that place a high probability in regions\nwhere the training data distribution has low probability. To overcome this\nproblem, we introduce Boltzmann Encoded Adversarial Machines (BEAMs). A BEAM is\nan RBM trained against an adversary that uses the hidden layer activations of\nthe RBM to discriminate between the training data and the probability\ndistribution generated by the model. We present experiments demonstrating that\nBEAMs outperform RBMs and GANs on multiple benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 19:50:13 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Fisher", "Charles K.", ""], ["Smith", "Aaron M.", ""], ["Walsh", "Jonathan R.", ""]]}, {"id": "1804.08685", "submitter": "Daniele Cortesi", "authors": "Andrea Asperti, Daniele Cortesi, Francesco Sovrano", "title": "Crawling in Rogue's dungeons with (partitioned) A3C", "comments": "Accepted at the Fourth International Conference on Machine Learning,\n  Optimization, and Data Science (LOD 2018)", "journal-ref": null, "doi": "10.1007/978-3-030-13709-0_22", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rogue is a famous dungeon-crawling video-game of the 80ies, the ancestor of\nits gender. Rogue-like games are known for the necessity to explore partially\nobservable and always different randomly-generated labyrinths, preventing any\nform of level replay. As such, they serve as a very natural and challenging\ntask for reinforcement learning, requiring the acquisition of complex,\nnon-reactive behaviors involving memory and planning. In this article we show\nhow, exploiting a version of A3C partitioned on different situations, the agent\nis able to reach the stairs and descend to the next level in 98% of cases.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 19:59:51 GMT"}, {"version": "v2", "created": "Sun, 29 Apr 2018 08:39:04 GMT"}, {"version": "v3", "created": "Fri, 7 Sep 2018 15:38:04 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Asperti", "Andrea", ""], ["Cortesi", "Daniele", ""], ["Sovrano", "Francesco", ""]]}, {"id": "1804.08697", "submitter": "Aleksandr Aravkin", "authors": "Michelle Liu, Rajiv Kumar, Eldad Haber, and Aleksandr Aravkin", "title": "Simultaneous shot inversion for nonuniform geometries using fast data\n  interpolation", "comments": "16 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic optimization is key to efficient inversion in PDE-constrained\noptimization. Using 'simultaneous shots', or random superposition of source\nterms, works very well in simple acquisition geometries where all sources see\nall receivers, but this rarely occurs in practice. We develop an approach that\ninterpolates data to an ideal acquisition geometry while solving the inverse\nproblem using simultaneous shots. The approach is formulated as a joint inverse\nproblem, combining ideas from low-rank interpolation with full-waveform\ninversion. Results using synthetic experiments illustrate the flexibility and\nefficiency of the approach.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 20:03:46 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Liu", "Michelle", ""], ["Kumar", "Rajiv", ""], ["Haber", "Eldad", ""], ["Aravkin", "Aleksandr", ""]]}, {"id": "1804.08750", "submitter": "Aditya Chindhade", "authors": "Aditya Chindhade, Abhijeet Alshi, Aakash Bhatia, Kedar Dabhadkar,\n  Pranav Sivadas Menon", "title": "A machine learning model for identifying cyclic alternating patterns in\n  the sleeping brain", "comments": "Presented at HackAuton, Auton Lab, Carnegie Mellon University.\n  Problem credits: Philips", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electroencephalography (EEG) is a method to record the electrical signals in\nthe brain. Recognizing the EEG patterns in the sleeping brain gives insights\ninto the understanding of sleeping disorders. The dataset under consideration\ncontains EEG data points associated with various physiological conditions. This\nstudy attempts to generalize the detection of particular patterns associated\nwith the Non-Rapid Eye Movement (NREM) sleep cycle of the brain using a machine\nlearning model. The proposed model uses additional feature engineering to\nincorporate sequential information for training a classifier to predict the\noccurrence of Cyclic Alternating Pattern (CAP) sequences in the sleep cycle,\nwhich are often associated with sleep disorders.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 21:29:56 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Chindhade", "Aditya", ""], ["Alshi", "Abhijeet", ""], ["Bhatia", "Aakash", ""], ["Dabhadkar", "Kedar", ""], ["Menon", "Pranav Sivadas", ""]]}, {"id": "1804.08774", "submitter": "Vachik Dave", "authors": "Vachik S. Dave, Baichuan Zhang, Pin-Yu Chen and Mohammad Al Hasan", "title": "Neural-Brane: Neural Bayesian Personalized Ranking for Attributed\n  Network Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network embedding methodologies, which learn a distributed vector\nrepresentation for each vertex in a network, have attracted considerable\ninterest in recent years. Existing works have demonstrated that vertex\nrepresentation learned through an embedding method provides superior\nperformance in many real-world applications, such as node classification, link\nprediction, and community detection. However, most of the existing methods for\nnetwork embedding only utilize topological information of a vertex, ignoring a\nrich set of nodal attributes (such as, user profiles of an online social\nnetwork, or textual contents of a citation network), which is abundant in all\nreal-life networks. A joint network embedding that takes into account both\nattributional and relational information entails a complete network information\nand could further enrich the learned vector representations. In this work, we\npresent Neural-Brane, a novel Neural Bayesian Personalized Ranking based\nAttributed Network Embedding. For a given network, Neural-Brane extracts latent\nfeature representation of its vertices using a designed neural network model\nthat unifies network topological information and nodal attributes; Besides, it\nutilizes Bayesian personalized ranking objective, which exploits the proximity\nordering between a similar node-pair and a dissimilar node-pair. We evaluate\nthe quality of vertex embedding produced by Neural-Brane by solving the node\nclassification and clustering tasks on four real-world datasets. Experimental\nresults demonstrate the superiority of our proposed method over the\nstate-of-the-art existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 23:01:50 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2018 22:52:03 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Dave", "Vachik S.", ""], ["Zhang", "Baichuan", ""], ["Chen", "Pin-Yu", ""], ["Hasan", "Mohammad Al", ""]]}, {"id": "1804.08796", "submitter": "Theja Tulabandhula", "authors": "Mehrnaz Amjadi and Theja Tulabandhula", "title": "Block-Structure Based Time-Series Models For Graph Sequences", "comments": "40 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the computational and statistical trade-off for modeling single\ngraphs, for instance, using block models is relatively well understood,\nextending such results to sequences of graphs has proven to be difficult. In\nthis work, we take a step in this direction by proposing two models for graph\nsequences that capture: (a) link persistence between nodes across time, and (b)\ncommunity persistence of each node across time. In the first model, we assume\nthat the latent community of each node does not change over time, and in the\nsecond model we relax this assumption suitably. For both of these proposed\nmodels, we provide statistically and computationally efficient inference\nalgorithms, whose unique feature is that they leverage community detection\nmethods that work on single graphs. We also provide experimental results\nvalidating the suitability of our models and methods on synthetic and real\ninstances.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 01:14:16 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 16:34:31 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Amjadi", "Mehrnaz", ""], ["Tulabandhula", "Theja", ""]]}, {"id": "1804.08806", "submitter": "Charilaos Kanatsoulis", "authors": "Charilaos I. Kanatsoulis, Xiao Fu, Nicholas D. Sidiropoulos, Mingyi\n  Hong", "title": "Structured SUMCOR Multiview Canonical Correlation Analysis for\n  Large-Scale Data", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2018.2878544", "report-no": null, "categories": "cs.LG cs.IR eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sum-of-correlations (SUMCOR) formulation of generalized canonical\ncorrelation analysis (GCCA) seeks highly correlated low-dimensional\nrepresentations of different views via maximizing pairwise latent similarity of\nthe views. SUMCOR is considered arguably the most natural extension of\nclassical two-view CCA to the multiview case, and thus has numerous\napplications in signal processing and data analytics. Recent work has proposed\neffective algorithms for handling the SUMCOR problem at very large scale.\nHowever, the existing scalable algorithms cannot incorporate structural\nregularization and prior information -- which are critical for good performance\nin real-world applications. In this work, we propose a new computational\nframework for large-scale SUMCOR GCCA that can easily incorporate a suite of\nstructural regularizers which are frequently used in data analytics. The\nupdates of the proposed algorithm are lightweight and the memory complexity is\nalso low. In addition, the proposed algorithm can be readily implemented in a\nparallel fashion. We show that the proposed algorithm converges to a\nKarush-Kuhn-Tucker (KKT) point of the regularized SUMCOR problem. Judiciously\ndesigned simulations and real-data experiments are employed to demonstrate the\neffectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 01:47:55 GMT"}], "update_date": "2018-12-26", "authors_parsed": [["Kanatsoulis", "Charilaos I.", ""], ["Fu", "Xiao", ""], ["Sidiropoulos", "Nicholas D.", ""], ["Hong", "Mingyi", ""]]}, {"id": "1804.08833", "submitter": "Suchismit Mahapatra", "authors": "Suchismit Mahapatra, Varun Chandola", "title": "Learning Manifolds from Non-stationary Streaming Data", "comments": "27 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streaming adaptations of manifold learning based dimensionality reduction\nmethods, such as Isomap, are based on the assumption that a small initial batch\nof observations is enough for exact learning of the manifold, while remaining\nstreaming data instances can be cheaply mapped to this manifold. However, there\nare no theoretical results to show that this core assumption is valid.\nMoreover, such methods typically assume that the underlying data distribution\nis stationary. Such methods are not equipped to detect, or handle, sudden\nchanges or gradual drifts in the distribution that may occur when the data is\nstreaming. We present theoretical results to show that the quality of a\nmanifold asymptotically converges as the size of data increases. We then show\nthat a Gaussian Process Regression (GPR) model, that uses a manifold-specific\nkernel function and is trained on an initial batch of sufficient size, can\nclosely approximate the state-of-art streaming Isomap algorithms. The\npredictive variance obtained from the GPR prediction is then shown to be an\neffective detector of changes in the underlying data distribution. Results on\nseveral synthetic and real data sets show that the resulting algorithm can\neffectively learn lower dimensional representation of high dimensional data in\na streaming setting, while identifying shifts in the generative distribution.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 03:59:48 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 22:25:12 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 19:38:30 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Mahapatra", "Suchismit", ""], ["Chandola", "Varun", ""]]}, {"id": "1804.08838", "submitter": "Chunyuan Li", "authors": "Chunyuan Li, Heerad Farkhoor, Rosanne Liu, Jason Yosinski", "title": "Measuring the Intrinsic Dimension of Objective Landscapes", "comments": "Published in ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recently trained neural networks employ large numbers of parameters to\nachieve good performance. One may intuitively use the number of parameters\nrequired as a rough gauge of the difficulty of a problem. But how accurate are\nsuch notions? How many parameters are really needed? In this paper we attempt\nto answer this question by training networks not in their native parameter\nspace, but instead in a smaller, randomly oriented subspace. We slowly increase\nthe dimension of this subspace, note at which dimension solutions first appear,\nand define this to be the intrinsic dimension of the objective landscape. The\napproach is simple to implement, computationally tractable, and produces\nseveral suggestive conclusions. Many problems have smaller intrinsic dimensions\nthan one might suspect, and the intrinsic dimension for a given dataset varies\nlittle across a family of models with vastly different sizes. This latter\nresult has the profound implication that once a parameter space is large enough\nto solve a problem, extra parameters serve directly to increase the\ndimensionality of the solution manifold. Intrinsic dimension allows some\nquantitative comparison of problem difficulty across supervised, reinforcement,\nand other types of learning where we conclude, for example, that solving the\ninverted pendulum problem is 100 times easier than classifying digits from\nMNIST, and playing Atari Pong from pixels is about as hard as classifying\nCIFAR-10. In addition to providing new cartography of the objective landscapes\nwandered by parameterized models, the method is a simple technique for\nconstructively obtaining an upper bound on the minimum description length of a\nsolution. A byproduct of this construction is a simple approach for compressing\nnetworks, in some cases by more than 100 times.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 04:29:10 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Li", "Chunyuan", ""], ["Farkhoor", "Heerad", ""], ["Liu", "Rosanne", ""], ["Yosinski", "Jason", ""]]}, {"id": "1804.08841", "submitter": "Haoyang Liu", "authors": "Haoyang Liu and Rina Foygel Barber", "title": "Between hard and soft thresholding: optimal iterative thresholding\n  algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative thresholding algorithms seek to optimize a differentiable objective\nfunction over a sparsity or rank constraint by alternating between gradient\nsteps that reduce the objective, and thresholding steps that enforce the\nconstraint. This work examines the choice of the thresholding operator, and\nasks whether it is possible to achieve stronger guarantees than what is\npossible with hard thresholding. We develop the notion of relative concavity of\na thresholding operator, a quantity that characterizes the worst-case\nconvergence performance of any thresholding operator on the target optimization\nproblem. Surprisingly, we find that commonly used thresholding operators, such\nas hard thresholding and soft thresholding, are suboptimal in terms of\nworst-case convergence guarantees. Instead, a general class of thresholding\noperators, lying between hard thresholding and soft thresholding, is shown to\nbe optimal with the strongest possible convergence guarantee among all\nthresholding operators. Examples of this general class includes $\\ell_q$\nthresholding with appropriate choices of $q$, and a newly defined {\\em\nreciprocal thresholding} operator. We also investigate the implications of the\nimproved optimization guarantee in the statistical setting of sparse linear\nregression, and show that this new class of thresholding operators attain the\noptimal rate for computationally efficient estimators, matching the Lasso.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 05:19:44 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 17:04:50 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2018 01:06:22 GMT"}, {"version": "v4", "created": "Tue, 30 Jul 2019 19:54:59 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Liu", "Haoyang", ""], ["Barber", "Rina Foygel", ""]]}, {"id": "1804.09028", "submitter": "Einat Kermany", "authors": "Guy Hadash, Einat Kermany, Boaz Carmeli, Ofer Lavi, George Kour and\n  Alon Jacovi", "title": "Estimate and Replace: A Novel Approach to Integrating Deep Neural\n  Networks with Existing Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing applications include a huge amount of knowledge that is out of reach\nfor deep neural networks. This paper presents a novel approach for integrating\ncalls to existing applications into deep learning architectures. Using this\napproach, we estimate each application's functionality with an estimator, which\nis implemented as a deep neural network (DNN). The estimator is then embedded\ninto a base network that we direct into complying with the application's\ninterface during an end-to-end optimization process. At inference time, we\nreplace each estimator with its existing application counterpart and let the\nbase network solve the task by interacting with the existing application. Using\nthis 'Estimate and Replace' method, we were able to train a DNN end-to-end with\nless data and outperformed a matching DNN that did not interact with the\nexternal application.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 13:40:09 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Hadash", "Guy", ""], ["Kermany", "Einat", ""], ["Carmeli", "Boaz", ""], ["Lavi", "Ofer", ""], ["Kour", "George", ""], ["Jacovi", "Alon", ""]]}, {"id": "1804.09046", "submitter": "Felix M. Riese", "authors": "Sina Keller and Felix M. Riese and Johanna St\\\"otzer and Philipp M.\n  Maier and Stefan Hinz", "title": "Developing a machine learning framework for estimating soil moisture\n  with VNIR hyperspectral data", "comments": "Accepted at ISPRS TC I Midterm Symposium Karlsruhe (October 2018)", "journal-ref": "ISPRS Ann. Photogramm. Remote Sens. Spatial Inf. Sci., IV-1,\n  101-108, 2018", "doi": "10.5194/isprs-annals-IV-1-101-2018", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the potential of estimating the soil-moisture\ncontent based on VNIR hyperspectral data combined with LWIR data. Measurements\nfrom a multi-sensor field campaign represent the benchmark dataset which\ncontains measured hyperspectral, LWIR, and soil-moisture data conducted on\ngrassland site. We introduce a regression framework with three steps consisting\nof feature selection, preprocessing, and well-chosen regression models. The\nlatter are mainly supervised machine learning models. An exception are the\nself-organizing maps which combine unsupervised and supervised learning. We\nanalyze the impact of the distinct preprocessing methods on the regression\nresults. Of all regression models, the extremely randomized trees model without\npreprocessing provides the best estimation performance. Our results reveal the\npotential of the respective regression framework combined with the VNIR\nhyperspectral data to estimate soil moisture measured under real-world\nconditions. In conclusion, the results of this paper provide a basis for\nfurther improvements in different research directions.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 13:52:35 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 12:15:49 GMT"}, {"version": "v3", "created": "Wed, 11 Jul 2018 11:14:41 GMT"}, {"version": "v4", "created": "Thu, 12 Jul 2018 10:40:59 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Keller", "Sina", ""], ["Riese", "Felix M.", ""], ["St\u00f6tzer", "Johanna", ""], ["Maier", "Philipp M.", ""], ["Hinz", "Stefan", ""]]}, {"id": "1804.09060", "submitter": "Dacheng Tao", "authors": "Jingwei Zhang, Tongliang Liu, Dacheng Tao", "title": "An Information-Theoretic View for Deep Learning", "comments": "Add details in the proof of Theorem 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning has transformed computer vision, natural language processing,\nand speech recognition\\cite{badrinarayanan2017segnet, dong2016image,\nren2017faster, ji20133d}. However, two critical questions remain obscure: (1)\nwhy do deep neural networks generalize better than shallow networks; and (2)\ndoes it always hold that a deeper network leads to better performance?\nSpecifically, letting $L$ be the number of convolutional and pooling layers in\na deep neural network, and $n$ be the size of the training sample, we derive an\nupper bound on the expected generalization error for this network, i.e.,\n  \\begin{eqnarray*}\n  \\mathbb{E}[R(W)-R_S(W)] \\leq\n\\exp{\\left(-\\frac{L}{2}\\log{\\frac{1}{\\eta}}\\right)}\\sqrt{\\frac{2\\sigma^2}{n}I(S,W)\n}\n  \\end{eqnarray*} where $\\sigma >0$ is a constant depending on the loss\nfunction, $0<\\eta<1$ is a constant depending on the information loss for each\nconvolutional or pooling layer, and $I(S, W)$ is the mutual information between\nthe training sample $S$ and the output hypothesis $W$. This upper bound shows\nthat as the number of convolutional and pooling layers $L$ increases in the\nnetwork, the expected generalization error will decrease exponentially to zero.\nLayers with strict information loss, such as the convolutional layers, reduce\nthe generalization error for the whole network; this answers the first\nquestion. However, algorithms with zero expected generalization error does not\nimply a small test error or $\\mathbb{E}[R(W)]$. This is because\n$\\mathbb{E}[R_S(W)]$ is large when the information for fitting the data is lost\nas the number of layers increases. This suggests that the claim `the deeper the\nbetter' is conditioned on a small training error or $\\mathbb{E}[R_S(W)]$.\nFinally, we show that deep learning satisfies a weak notion of stability and\nthe sample complexity of deep neural networks will decrease as $L$ increases.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 14:13:19 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 09:27:38 GMT"}, {"version": "v3", "created": "Fri, 18 May 2018 09:40:26 GMT"}, {"version": "v4", "created": "Mon, 28 May 2018 12:58:28 GMT"}, {"version": "v5", "created": "Wed, 30 May 2018 11:57:48 GMT"}, {"version": "v6", "created": "Thu, 31 May 2018 13:04:59 GMT"}, {"version": "v7", "created": "Tue, 5 Jun 2018 01:57:20 GMT"}, {"version": "v8", "created": "Tue, 2 Oct 2018 12:49:32 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Zhang", "Jingwei", ""], ["Liu", "Tongliang", ""], ["Tao", "Dacheng", ""]]}, {"id": "1804.09081", "submitter": "Thomas Elsken", "authors": "Thomas Elsken, Jan Hendrik Metzen, Frank Hutter", "title": "Efficient Multi-objective Neural Architecture Search via Lamarckian\n  Evolution", "comments": "Published as a conference paper at ICLR, International Conference on\n  Learning Representations, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search aims at automatically finding neural architectures\nthat are competitive with architectures designed by human experts. While recent\napproaches have achieved state-of-the-art predictive performance for image\nrecognition, they are problematic under resource constraints for two reasons:\n(1)the neural architectures found are solely optimized for high predictive\nperformance, without penalizing excessive resource consumption, (2) most\narchitecture search methods require vast computational resources. We address\nthe first shortcoming by proposing LEMONADE, an evolutionary algorithm for\nmulti-objective architecture search that allows approximating the entire\nPareto-front of architectures under multiple objectives, such as predictive\nperformance and number of parameters, in a single run of the method. We address\nthe second shortcoming by proposing a Lamarckian inheritance mechanism for\nLEMONADE which generates children networks that are warmstarted with the\npredictive performance of their trained parents. This is accomplished by using\n(approximate) network morphism operators for generating children. The\ncombination of these two contributions allows finding models that are on par or\neven outperform both hand-crafted as well as automatically-designed networks.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 15:01:07 GMT"}, {"version": "v2", "created": "Tue, 24 Jul 2018 14:40:54 GMT"}, {"version": "v3", "created": "Sat, 22 Dec 2018 14:01:47 GMT"}, {"version": "v4", "created": "Tue, 26 Feb 2019 16:06:36 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Elsken", "Thomas", ""], ["Metzen", "Jan Hendrik", ""], ["Hutter", "Frank", ""]]}, {"id": "1804.09088", "submitter": "Evangelos Papalexakis", "authors": "Gisel Bastidas Guacho, Sara Abdali, Neil Shah, Evangelos E.\n  Papalexakis", "title": "Semi-supervised Content-based Detection of Misinformation via Tensor\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake news may be intentionally created to promote economic, political and\nsocial interests, and can lead to negative impacts on humans beliefs and\ndecisions. Hence, detection of fake news is an emerging problem that has become\nextremely prevalent during the last few years. Most existing works on this\ntopic focus on manual feature extraction and supervised classification models\nleveraging a large number of labeled (fake or real) articles. In contrast, we\nfocus on content-based detection of fake news articles, while assuming that we\nhave a small amount of labels, made available by manual fact-checkers or\nautomated sources. We argue this is a more realistic setting in the presence of\nmassive amounts of content, most of which cannot be easily factchecked. To that\nend, we represent collections of news articles as multi-dimensional tensors,\nleverage tensor decomposition to derive concise article embeddings that capture\nspatial/contextual information about each news article, and use those\nembeddings to create an article-by-article graph on which we propagate limited\nlabels. Results on three real-world datasets show that our method performs on\npar or better than existing models that are fully supervised, in that we\nachieve better detection accuracy using fewer labels. In particular, our\nproposed method achieves 75.43% of accuracy using only 30% of labels of a\npublic dataset while an SVM-based classifier achieved 67.43%. Furthermore, our\nmethod achieves 70.92% of accuracy in a large dataset using only 2% of labels.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 15:13:51 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Guacho", "Gisel Bastidas", ""], ["Abdali", "Sara", ""], ["Shah", "Neil", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "1804.09133", "submitter": "Zhiguang Wang", "authors": "Mehul Parsana, Krishna Poola, Yajun Wang, Zhiguang Wang", "title": "Improving Native Ads CTR Prediction by Large Scale Event Embedding and\n  Recurrent Networks", "comments": "This version has some language error, and the authors all agree to\n  withdraw it at the moment to further edit and update with some new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click through rate (CTR) prediction is very important for Native\nadvertisement but also hard as there is no direct query intent. In this paper\nwe propose a large-scale event embedding scheme to encode the each user\nbrowsing event by training a Siamese network with weak supervision on the\nusers' consecutive events. The CTR prediction problem is modeled as a\nsupervised recurrent neural network, which naturally model the user history as\na sequence of events. Our proposed recurrent models utilizing pretrained event\nembedding vectors and an attention layer to model the user history. Our\nexperiments demonstrate that our model significantly outperforms the baseline\nand some variants.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 16:50:54 GMT"}, {"version": "v2", "created": "Tue, 14 Aug 2018 07:30:11 GMT"}], "update_date": "2018-08-15", "authors_parsed": [["Parsana", "Mehul", ""], ["Poola", "Krishna", ""], ["Wang", "Yajun", ""], ["Wang", "Zhiguang", ""]]}, {"id": "1804.09148", "submitter": "Diego Saldana", "authors": "Diego Saldana Miranda", "title": "Automated Detection of Adverse Drug Reactions in the Biomedical\n  Literature Using Convolutional Neural Networks and Biomedical Word Embeddings", "comments": "Accepted as conference paper at SwissText 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring the biomedical literature for cases of Adverse Drug Reactions\n(ADRs) is a critically important and time consuming task in pharmacovigilance.\nThe development of computer assisted approaches to aid this process in\ndifferent forms has been the subject of many recent works. One particular area\nthat has shown promise is the use of Deep Neural Networks, in particular,\nConvolutional Neural Networks (CNNs), for the detection of ADR relevant\nsentences. Using token-level convolutions and general purpose word embeddings,\nthis architecture has shown good performance relative to more traditional\nmodels as well as Long Short Term Memory (LSTM) models. In this work, we\nevaluate and compare two different CNN architectures using the ADE corpus. In\naddition, we show that by de-duplicating the ADR relevant sentences, we can\ngreatly reduce overoptimism in the classification results. Finally, we evaluate\nthe use of word embeddings specifically developed for biomedical text and show\nthat they lead to a better performance in this task.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 17:18:01 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Miranda", "Diego Saldana", ""]]}, {"id": "1804.09154", "submitter": "Pier Luca Lanzi", "authors": "Edoardo Giacomello and Pier Luca Lanzi and Daniele Loiacono", "title": "DOOM Level Generation using Generative Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We applied Generative Adversarial Networks (GANs) to learn a model of DOOM\nlevels from human-designed content. Initially, we analysed the levels and\nextracted several topological features. Then, for each level, we extracted a\nset of images identifying the occupied area, the height map, the walls, and the\nposition of game objects. We trained two GANs: one using plain level images,\none using both the images and some of the features extracted during the\npreliminary analysis. We used the two networks to generate new levels and\ncompared the results to assess whether the network trained using also the\ntopological features could generate levels more similar to human-designed ones.\nOur results show that GANs can capture intrinsic structure of DOOM levels and\nappears to be a promising approach to level generation in first person shooter\ngames.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 17:20:52 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Giacomello", "Edoardo", ""], ["Lanzi", "Pier Luca", ""], ["Loiacono", "Daniele", ""]]}, {"id": "1804.09170", "submitter": "Avital Oliver", "authors": "Avital Oliver, Augustus Odena, Colin Raffel, Ekin D. Cubuk and Ian J.\n  Goodfellow", "title": "Realistic Evaluation of Deep Semi-Supervised Learning Algorithms", "comments": null, "journal-ref": "NeurIPS 2018 Proceedings", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning (SSL) provides a powerful framework for leveraging\nunlabeled data when labels are limited or expensive to obtain. SSL algorithms\nbased on deep neural networks have recently proven successful on standard\nbenchmark tasks. However, we argue that these benchmarks fail to address many\nissues that these algorithms would face in real-world applications. After\ncreating a unified reimplementation of various widely-used SSL techniques, we\ntest them in a suite of experiments designed to address these issues. We find\nthat the performance of simple baselines which do not use unlabeled data is\noften underreported, that SSL methods differ in sensitivity to the amount of\nlabeled and unlabeled data, and that performance can degrade substantially when\nthe unlabeled dataset contains out-of-class examples. To help guide SSL\nresearch towards real-world applicability, we make our unified reimplemention\nand evaluation platform publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 17:54:44 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 22:39:26 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 17:36:40 GMT"}, {"version": "v4", "created": "Mon, 17 Jun 2019 11:48:53 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Oliver", "Avital", ""], ["Odena", "Augustus", ""], ["Raffel", "Colin", ""], ["Cubuk", "Ekin D.", ""], ["Goodfellow", "Ian J.", ""]]}, {"id": "1804.09217", "submitter": "Thanh Nguyen", "authors": "Thanh V. Nguyen, Akshay Soni, Chinmay Hegde", "title": "On Learning Sparsely Used Dictionaries from Incomplete Samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing algorithms for dictionary learning assume that all entries of\nthe (high-dimensional) input data are fully observed. However, in several\npractical applications (such as hyper-spectral imaging or blood glucose\nmonitoring), only an incomplete fraction of the data entries may be available.\nFor incomplete settings, no provably correct and polynomial-time algorithm has\nbeen reported in the dictionary learning literature. In this paper, we provide\nprovable approaches for learning - from incomplete samples - a family of\ndictionaries whose atoms have sufficiently \"spread-out\" mass. First, we propose\na descent-style iterative algorithm that linearly converges to the true\ndictionary when provided a sufficiently coarse initial estimate. Second, we\npropose an initialization algorithm that utilizes a small number of extra fully\nobserved samples to produce such a coarse initial estimate. Finally, we\ntheoretically analyze their performance and provide asymptotic statistical and\ncomputational guarantees.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 19:06:50 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Nguyen", "Thanh V.", ""], ["Soni", "Akshay", ""], ["Hegde", "Chinmay", ""]]}, {"id": "1804.09238", "submitter": "Haitian Sun", "authors": "Haitian Sun, William W. Cohen, Lidong Bing", "title": "Semi-Supervised Learning with Declaratively Specified Entropy\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a technique for declaratively specifying strategies for\nsemi-supervised learning (SSL). The proposed method can be used to specify\nensembles of semi-supervised learning, as well as agreement constraints and\nentropic regularization constraints between these learners, and can be used to\nmodel both well-known heuristics such as co-training and novel domain-specific\nheuristics. In addition to representing individual SSL heuristics, we show that\nmultiple heuristics can also be automatically combined using Bayesian\noptimization methods. We show consistent improvements on a suite of\nwell-studied SSL benchmarks, including a new state-of-the-art result on a\ndifficult relation extraction task.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 20:19:09 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 04:22:50 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Sun", "Haitian", ""], ["Cohen", "William W.", ""], ["Bing", "Lidong", ""]]}, {"id": "1804.09278", "submitter": "Thomas Roxlo", "authors": "Thomas Roxlo and Matthew Reece", "title": "Opening the black box of neural nets: case studies in stop/top\n  discrimination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce techniques for exploring the functionality of a neural network\nand extracting simple, human-readable approximations to its performance. By\nperforming gradient ascent on the input space of the network, we are able to\nproduce large populations of artificial events which strongly excite a given\nclassifier. By studying the populations of these events, we then directly\nproduce what are essentially contour maps of the network's classification\nfunction. Combined with a suite of tools for identifying the input dimensions\ndeemed most important by the network, we can utilize these maps to efficiently\ninterpret the dominant criteria by which the network makes its classification.\n  As a test case, we study networks trained to discriminate supersymmetric stop\nproduction in the dilepton channel from Standard Model backgrounds. In the case\nof a heavy stop decaying to a light neutralino, we find individual neurons with\nlarge mutual information with $m_{T2}^{\\ell\\ell}$, a human-designed variable\nfor optimizing the analysis. The network selects events with significant\nmissing $p_T$ oriented azimuthally away from both leptons, efficiently\nrejecting $t\\overline{t}$ background. In the case of a light stop with\nthree-body decays to $Wb{\\widetilde \\chi}$ and little phase space, we find\nneurons that smoothly interpolate between a similar top-rejection strategy and\nan ISR-tagging strategy allowing for more missing momentum. We also find that a\nneural network trained on a stealth stop parameter point learns novel angular\ncorrelations.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 22:08:54 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Roxlo", "Thomas", ""], ["Reece", "Matthew", ""]]}, {"id": "1804.09314", "submitter": "Jingyu He", "authors": "Guanhao Feng, Jingyu He, Nicholas G. Polson", "title": "Deep Learning for Predicting Asset Returns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning searches for nonlinear factors for predicting asset returns.\nPredictability is achieved via multiple layers of composite factors as opposed\nto additive ones. Viewed in this way, asset pricing studies can be revisited\nusing multi-layer deep learners, such as rectified linear units (ReLU) or\nlong-short-term-memory (LSTM) for time-series effects. State-of-the-art\nalgorithms including stochastic gradient descent (SGD), TensorFlow and dropout\ndesign provide imple- mentation and efficient factor exploration. To illustrate\nour methodology, we revisit the equity market risk premium dataset of Welch and\nGoyal (2008). We find the existence of nonlinear factors which explain\npredictability of returns, in particular at the extremes of the characteristic\nspace. Finally, we conclude with directions for future research.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 01:52:34 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2018 14:50:14 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Feng", "Guanhao", ""], ["He", "Jingyu", ""], ["Polson", "Nicholas G.", ""]]}, {"id": "1804.09348", "submitter": "Toshihisa Tanaka", "authors": "Tomoya Wada, Kosuke Fukumori, Toshihisa Tanaka, and Simone Fiori", "title": "Generalized Gaussian Kernel Adaptive Filtering", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0237654", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper proposes generalized Gaussian kernel adaptive filtering,\nwhere the kernel parameters are adaptive and data-driven. The Gaussian kernel\nis parametrized by a center vector and a symmetric positive definite (SPD)\nprecision matrix, which is regarded as a generalization of the scalar width\nparameter. These parameters are adaptively updated on the basis of a proposed\nleast-square-type rule to minimize the estimation error. The main contribution\nof this paper is to establish update rules for precision matrices on the SPD\nmanifold in order to keep their symmetric positive-definiteness. Different from\nconventional kernel adaptive filters, the proposed regressor is a superposition\nof Gaussian kernels with all different parameters, which makes such regressor\nmore flexible. The kernel adaptive filtering algorithm is established together\nwith a l1-regularized least squares to avoid overfitting and the increase of\ndimensionality of the dictionary. Experimental results confirm the validity of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 04:55:56 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Wada", "Tomoya", ""], ["Fukumori", "Kosuke", ""], ["Tanaka", "Toshihisa", ""], ["Fiori", "Simone", ""]]}, {"id": "1804.09399", "submitter": "Hao-Wen Dong", "authors": "Hao-Wen Dong and Yi-Hsuan Yang", "title": "Convolutional Generative Adversarial Networks with Binary Neurons for\n  Polyphonic Music Generation", "comments": "A preliminary version of this paper appeared in ISMIR 2018. In this\n  version, we added an appendix to provide figures of sample results and\n  remarks on the end-to-end models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown recently that deep convolutional generative adversarial\nnetworks (GANs) can learn to generate music in the form of piano-rolls, which\nrepresent music by binary-valued time-pitch matrices. However, existing models\ncan only generate real-valued piano-rolls and require further post-processing,\nsuch as hard thresholding (HT) or Bernoulli sampling (BS), to obtain the final\nbinary-valued results. In this paper, we study whether we can have a\nconvolutional GAN model that directly creates binary-valued piano-rolls by\nusing binary neurons. Specifically, we propose to append to the generator an\nadditional refiner network, which uses binary neurons at the output layer. The\nwhole network is trained in two stages. Firstly, the generator and the\ndiscriminator are pretrained. Then, the refiner network is trained along with\nthe discriminator to learn to binarize the real-valued piano-rolls the\npretrained generator creates. Experimental results show that using binary\nneurons instead of HT or BS indeed leads to better results in a number of\nobjective measures. Moreover, deterministic binary neurons perform better than\nstochastic ones in both objective measures and a subjective test. The source\ncode, training data and audio examples of the generated results can be found at\nhttps://salu133445.github.io/bmusegan/ .\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 07:35:39 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2018 16:13:12 GMT"}, {"version": "v3", "created": "Sat, 6 Oct 2018 15:08:20 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Dong", "Hao-Wen", ""], ["Yang", "Yi-Hsuan", ""]]}, {"id": "1804.09400", "submitter": "Qiao Zheng", "authors": "Qiao Zheng, Herv\\'e Delingette, Nicolas Duchateau, Nicholas Ayache", "title": "3D Consistent & Robust Segmentation of Cardiac Images by Deep Learning\n  with Spatial Propagation", "comments": "Accepted for publication in IEEE Transactions on Medical Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method based on deep learning to perform cardiac segmentation on\nshort axis MRI image stacks iteratively from the top slice (around the base) to\nthe bottom slice (around the apex). At each iteration, a novel variant of U-net\nis applied to propagate the segmentation of a slice to the adjacent slice below\nit. In other words, the prediction of a segmentation of a slice is dependent\nupon the already existing segmentation of an adjacent slice. 3D-consistency is\nhence explicitly enforced. The method is trained on a large database of 3078\ncases from UK Biobank. It is then tested on 756 different cases from UK Biobank\nand three other state-of-the-art cohorts (ACDC with 100 cases, Sunnybrook with\n30 cases, RVSC with 16 cases). Results comparable or even better than the\nstate-of-the-art in terms of distance measures are achieved. They also\nemphasize the assets of our method, namely enhanced spatial consistency\n(currently neither considered nor achieved by the state-of-the-art), and the\ngeneralization ability to unseen cases even from other databases.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 07:39:36 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Zheng", "Qiao", ""], ["Delingette", "Herv\u00e9", ""], ["Duchateau", "Nicolas", ""], ["Ayache", "Nicholas", ""]]}, {"id": "1804.09401", "submitter": "Marco Fraccaro", "authors": "Marco Fraccaro, Danilo Jimenez Rezende, Yori Zwols, Alexander Pritzel,\n  S. M. Ali Eslami, Fabio Viola", "title": "Generative Temporal Models with Spatial Memory for Partially Observed\n  Environments", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In model-based reinforcement learning, generative and temporal models of\nenvironments can be leveraged to boost agent performance, either by tuning the\nagent's representations during training or via use as part of an explicit\nplanning mechanism. However, their application in practice has been limited to\nsimplistic environments, due to the difficulty of training such models in\nlarger, potentially partially-observed and 3D environments. In this work we\nintroduce a novel action-conditioned generative model of such challenging\nenvironments. The model features a non-parametric spatial memory system in\nwhich we store learned, disentangled representations of the environment.\nLow-dimensional spatial updates are computed using a state-space model that\nmakes use of knowledge on the prior dynamics of the moving agent, and\nhigh-dimensional visual observations are modelled with a Variational\nAuto-Encoder. The result is a scalable architecture capable of performing\ncoherent predictions over hundreds of time steps across a range of partially\nobserved 2D and 3D environments.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 07:40:37 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 15:17:22 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Fraccaro", "Marco", ""], ["Rezende", "Danilo Jimenez", ""], ["Zwols", "Yori", ""], ["Pritzel", "Alexander", ""], ["Eslami", "S. M. Ali", ""], ["Viola", "Fabio", ""]]}, {"id": "1804.09415", "submitter": "Christian Kuehn", "authors": "Boumediene Hamzi, Christian Kuehn, Sameh Mohamed", "title": "A Note on Kernel Methods for Multiscale Systems with Critical\n  Transitions", "comments": "15 pages, 4 figures; preprint, comments and suggestions very welcome!", "journal-ref": null, "doi": "10.1002/mma.5394", "report-no": null, "categories": "nlin.PS eess.SP math.DS physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the maximum mean discrepancy (MMD) in the context of critical\ntransitions modelled by fast-slow stochastic dynamical systems. We establish a\nnew link between the dynamical theory of critical transitions with the\nstatistical aspects of the MMD. In particular, we show that a formal\napproximation of the MMD near fast subsystem bifurcation points can be computed\nto leading-order. In particular, this leading order approximation shows that\nthe MMD depends intricately on the fast-slow systems parameters and one can\nonly expect to extract warning signs under rather stringent conditions.\nHowever, the MMD turns out to be an excellent binary classifier to detect the\nchange point induced by the critical transition. We cross-validate our results\nby numerical simulations for a van der Pol-type model.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 08:16:59 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Hamzi", "Boumediene", ""], ["Kuehn", "Christian", ""], ["Mohamed", "Sameh", ""]]}, {"id": "1804.09461", "submitter": "Huan Wang", "authors": "Huan Wang, Qiming Zhang, Yuehai Wang, Yu Lu, Haoji Hu", "title": "Structured Pruning for Efficient ConvNets via Incremental Regularization", "comments": "IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter pruning is a promising approach for CNN compression and\nacceleration by eliminating redundant model parameters with tolerable\nperformance degrade. Despite its effectiveness, existing regularization-based\nparameter pruning methods usually drive weights towards zero with large and\nconstant regularization factors, which neglects the fragility of the\nexpressiveness of CNNs, and thus calls for a more gentle regularization scheme\nso that the networks can adapt during pruning. To achieve this, we propose a\nnew and novel regularization-based pruning method, named IncReg, to\nincrementally assign different regularization factors to different weights\nbased on their relative importance. Empirical analysis on CIFAR-10 dataset\nverifies the merits of IncReg. Further extensive experiments with popular CNNs\non CIFAR-10 and ImageNet datasets show that IncReg achieves comparable to even\nbetter results compared with state-of-the-arts. Our source codes and trained\nmodels are available here: https://github.com/mingsun-tse/caffe_increg.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 09:59:45 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 03:09:41 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Wang", "Huan", ""], ["Zhang", "Qiming", ""], ["Wang", "Yuehai", ""], ["Lu", "Yu", ""], ["Hu", "Haoji", ""]]}, {"id": "1804.09502", "submitter": "Zejian Li", "authors": "Zejian Li, Yongchuan Tang, Yongxing He", "title": "Unsupervised Disentangled Representation Learning with Analogical\n  Relations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the disentangled representation of interpretable generative factors\nof data is one of the foundations to allow artificial intelligence to think\nlike people. In this paper, we propose the analogical training strategy for the\nunsupervised disentangled representation learning in generative models. The\nanalogy is one of the typical cognitive processes, and our proposed strategy is\nbased on the observation that sample pairs in which one is different from the\nother in one specific generative factor show the same analogical relation.\nThus, the generator is trained to generate sample pairs from which a designed\nclassifier can identify the underlying analogical relation. In addition, we\npropose a disentanglement metric called the subspace score, which is inspired\nby subspace learning methods and does not require supervised information.\nExperiments show that our proposed training strategy allows the generative\nmodels to find the disentangled factors, and that our methods can give\ncompetitive performances as compared with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 12:09:01 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Li", "Zejian", ""], ["Tang", "Yongchuan", ""], ["He", "Yongxing", ""]]}, {"id": "1804.09530", "submitter": "Sebastian Ruder", "authors": "Sebastian Ruder, Barbara Plank", "title": "Strong Baselines for Neural Semi-supervised Learning under Domain Shift", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel neural models have been proposed in recent years for learning under\ndomain shift. Most models, however, only evaluate on a single task, on\nproprietary datasets, or compare to weak baselines, which makes comparison of\nmodels difficult. In this paper, we re-evaluate classic general-purpose\nbootstrapping approaches in the context of neural networks under domain shifts\nvs. recent neural approaches and propose a novel multi-task tri-training method\nthat reduces the time and space complexity of classic tri-training. Extensive\nexperiments on two benchmarks are negative: while our novel method establishes\na new state-of-the-art for sentiment analysis, it does not fare consistently\nthe best. More importantly, we arrive at the somewhat surprising conclusion\nthat classic tri-training, with some additions, outperforms the state of the\nart. We conclude that classic approaches constitute an important and strong\nbaseline.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 13:06:29 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Ruder", "Sebastian", ""], ["Plank", "Barbara", ""]]}, {"id": "1804.09554", "submitter": "Aryan Mokhtari", "authors": "Aryan Mokhtari and Hamed Hassani and Amin Karbasi", "title": "Stochastic Conditional Gradient Methods: From Convex Minimization to\n  Submodular Maximization", "comments": "arXiv admin note: text overlap with arXiv:1711.01660", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers stochastic optimization problems for a large class of\nobjective functions, including convex and continuous submodular. Stochastic\nproximal gradient methods have been widely used to solve such problems;\nhowever, their applicability remains limited when the problem dimension is\nlarge and the projection onto a convex set is costly. Instead, stochastic\nconditional gradient methods are proposed as an alternative solution relying on\n(i) Approximating gradients via a simple averaging technique requiring a single\nstochastic gradient evaluation per iteration; (ii) Solving a linear program to\ncompute the descent/ascent direction. The averaging technique reduces the noise\nof gradient approximations as time progresses, and replacing projection step in\nproximal methods by a linear program lowers the computational complexity of\neach iteration. We show that under convexity and smoothness assumptions, our\nproposed method converges to the optimal objective function value at a\nsublinear rate of $O(1/t^{1/3})$. Further, for a monotone and continuous\nDR-submodular function and subject to a general convex body constraint, we\nprove that our proposed method achieves a $((1-1/e)OPT-\\eps)$ guarantee with\n$O(1/\\eps^3)$ stochastic gradient computations. This guarantee matches the\nknown hardness results and closes the gap between deterministic and stochastic\ncontinuous submodular maximization. Additionally, we obtain $((1/e)OPT -\\eps)$\nguarantee after using $O(1/\\eps^3)$ stochastic gradients for the case that the\nobjective function is continuous DR-submodular but non-monotone and the\nconstraint set is down-closed. By using stochastic continuous optimization as\nan interface, we provide the first $(1-1/e)$ tight approximation guarantee for\nmaximizing a monotone but stochastic submodular set function subject to a\nmatroid constraint and $(1/e)$ approximation guarantee for the non-monotone\ncase.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 13:52:29 GMT"}, {"version": "v2", "created": "Mon, 12 Nov 2018 18:40:07 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Mokhtari", "Aryan", ""], ["Hassani", "Hamed", ""], ["Karbasi", "Amin", ""]]}, {"id": "1804.09558", "submitter": "Raquel P\\'erez-Arnal", "authors": "Raquel P\\'erez-Arnal, Armand Vilalta, Dario Garcia-Gasulla, Ulises\n  Cort\\'es, Eduard Ayguad\\'e, Jesus Labarta", "title": "A Visual Distance for WordNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring the distance between concepts is an important field of study of\nNatural Language Processing, as it can be used to improve tasks related to the\ninterpretation of those same concepts. WordNet, which includes a wide variety\nof concepts associated with words (i.e., synsets), is often used as a source\nfor computing those distances. In this paper, we explore a distance for WordNet\nsynsets based on visual features, instead of lexical ones. For this purpose, we\nextract the graphic features generated within a deep convolutional neural\nnetworks trained with ImageNet and use those features to generate a\nrepresentative of each synset. Based on those representatives, we define a\ndistance measure of synsets, which complements the traditional lexical\ndistances. Finally, we propose some experiments to evaluate its performance and\ncompare it with the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2018 15:34:33 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 09:17:36 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["P\u00e9rez-Arnal", "Raquel", ""], ["Vilalta", "Armand", ""], ["Garcia-Gasulla", "Dario", ""], ["Cort\u00e9s", "Ulises", ""], ["Ayguad\u00e9", "Eduard", ""], ["Labarta", "Jesus", ""]]}, {"id": "1804.09593", "submitter": "Lauri Juvela", "authors": "Lauri Juvela, Vassilis Tsiaras, Bajibabu Bollepalli, Manu Airaksinen,\n  Junichi Yamagishi, Paavo Alku", "title": "Speaker-independent raw waveform model for glottal excitation", "comments": "Submitted to Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent speech technology research has seen a growing interest in using\nWaveNets as statistical vocoders, i.e., generating speech waveforms from\nacoustic features. These models have been shown to improve the generated speech\nquality over classical vocoders in many tasks, such as text-to-speech synthesis\nand voice conversion. Furthermore, conditioning WaveNets with acoustic features\nallows sharing the waveform generator model across multiple speakers without\nadditional speaker codes. However, multi-speaker WaveNet models require large\namounts of training data and computation to cover the entire acoustic space.\nThis paper proposes leveraging the source-filter model of speech production to\nmore effectively train a speaker-independent waveform generator with limited\nresources. We present a multi-speaker 'GlotNet' vocoder, which utilizes a\nWaveNet to generate glottal excitation waveforms, which are then used to excite\nthe corresponding vocal tract filter to produce speech. Listening tests show\nthat the proposed model performs favourably to a direct WaveNet vocoder trained\nwith the same model architecture and data.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 14:29:08 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Juvela", "Lauri", ""], ["Tsiaras", "Vassilis", ""], ["Bollepalli", "Bajibabu", ""], ["Airaksinen", "Manu", ""], ["Yamagishi", "Junichi", ""], ["Alku", "Paavo", ""]]}, {"id": "1804.09597", "submitter": "Alexander Jung", "authors": "Alexander Jung", "title": "On The Complexity of Sparse Label Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the computational complexity of sparse label\npropagation which has been proposed recently for processing network structured\ndata. Sparse label propagation amounts to a convex optimization problem and\nmight be considered as an extension of basis pursuit from sparse vectors to\nnetwork structured datasets. Using a standard first-order oracle model, we\ncharacterize the number of iterations for sparse label propagation to achieve a\nprescribed accuracy. In particular, we derive an upper bound on the number of\niterations required to achieve a certain accuracy and show that this upper\nbound is sharp for datasets having a chain structure (e.g., time series).\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 14:33:34 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 12:16:09 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Jung", "Alexander", ""]]}, {"id": "1804.09604", "submitter": "Ankita Mangal", "authors": "Ankita Mangal, Elizabeth A. Holm", "title": "A comparative study of feature selection methods for stress hotspot\n  classification in materials", "comments": "under review in Integrating Materials and Manufacturing Innovation", "journal-ref": null, "doi": "10.1007/s40192-018-0109-8", "report-no": null, "categories": "stat.ML cond-mat.mtrl-sci cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The first step in constructing a machine learning model is defining the\nfeatures of the data set that can be used for optimal learning. In this work we\ndiscuss feature selection methods, which can be used to build better models, as\nwell as achieve model interpretability. We applied these methods in the context\nof stress hotspot classification problem, to determine what microstructural\ncharacteristics can cause stress to build up in certain grains during uniaxial\ntensile deformation. The results show how some feature selection techniques are\nbiased and demonstrate a preferred technique to get feature rankings for\nphysical interpretations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 19:26:09 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Mangal", "Ankita", ""], ["Holm", "Elizabeth A.", ""]]}, {"id": "1804.09605", "submitter": "Kevin Schlegel", "authors": "Kevin Schlegel", "title": "When is there a Representer Theorem? Nondifferentiable Regularisers and\n  Banach spaces", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general regularised interpolation problem for learning a\nparameter vector from data. The well known representer theorem says that under\ncertain conditions on the regulariser there exists a solution in the linear\nspan of the data points. This is the core of kernel methods in machine learning\nas it makes the problem computationally tractable. Necessary and sufficient\nconditions for differentiable regularisers on Hilbert spaces to admit a\nrepresenter theorem have been proved. We extend those results to\nnondifferentiable regularisers on uniformly convex and uniformly smooth Banach\nspaces. This gives a (more) complete answer to the question when there is a\nrepresenter theorem. We then note that for regularised interpolation in fact\nthe solution is determined by the function space alone and independent of the\nregulariser, making the extension to Banach spaces even more valuable.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 14:47:25 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Schlegel", "Kevin", ""]]}, {"id": "1804.09618", "submitter": "Tomi Kinnunen", "authors": "Tomi Kinnunen, Kong Aik Lee, Hector Delgado, Nicholas Evans,\n  Massimiliano Todisco, Md Sahidullah, Junichi Yamagishi, Douglas A. Reynolds", "title": "t-DCF: a Detection Cost Function for the Tandem Assessment of Spoofing\n  Countermeasures and Automatic Speaker Verification", "comments": "Published in Odyssey 2018: the Speaker and Language Recognition\n  Workshop [cleaned up source files]", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CR cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ASVspoof challenge series was born to spearhead research in anti-spoofing\nfor automatic speaker verification (ASV). The two challenge editions in 2015\nand 2017 involved the assessment of spoofing countermeasures (CMs) in isolation\nfrom ASV using an equal error rate (EER) metric. While a strategic approach to\nassessment at the time, it has certain shortcomings. First, the CM EER is not\nnecessarily a reliable predictor of performance when ASV and CMs are combined.\nSecond, the EER operating point is ill-suited to user authentication\napplications, e.g. telephone banking, characterised by a high target user prior\nbut a low spoofing attack prior. We aim to migrate from CM- to ASV-centric\nassessment with the aid of a new tandem detection cost function (t-DCF) metric.\nIt extends the conventional DCF used in ASV research to scenarios involving\nspoofing attacks. The t-DCF metric has 6 parameters: (i) false alarm and miss\ncosts for both systems, and (ii) prior probabilities of target and spoof trials\n(with an implied third, nontarget prior). The study is intended to serve as a\nself-contained, tutorial-like presentation. We analyse with the t-DCF a\nselection of top-performing CM submissions to the 2015 and 2017 editions of\nASVspoof, with a focus on the spoofing attack prior. Whereas there is little to\nchoose between countermeasure systems for lower priors, system rankings derived\nwith the EER and t-DCF show differences for higher priors. We observe some\nranking changes. Findings support the adoption of the DCF-based metric into the\nroadmap for future ASVspoof challenges, and possibly for other biometric\nanti-spoofing evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 15:16:48 GMT"}, {"version": "v2", "created": "Thu, 11 Apr 2019 16:32:25 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Kinnunen", "Tomi", ""], ["Lee", "Kong Aik", ""], ["Delgado", "Hector", ""], ["Evans", "Nicholas", ""], ["Todisco", "Massimiliano", ""], ["Sahidullah", "Md", ""], ["Yamagishi", "Junichi", ""], ["Reynolds", "Douglas A.", ""]]}, {"id": "1804.09619", "submitter": "Ravdeep Pasricha", "authors": "Ravdeep Pasricha, Ekta Gujral, Evangelos E. Papalexakis", "title": "Identifying and Alleviating Concept Drift in Streaming Tensor\n  Decomposition", "comments": "16 Pages, Accepted at ECML-PKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decompositions are used in various data mining applications from\nsocial network to medical applications and are extremely useful in discovering\nlatent structures or concepts in the data. Many real-world applications are\ndynamic in nature and so are their data. To deal with this dynamic nature of\ndata, there exist a variety of online tensor decomposition algorithms. A\ncentral assumption in all those algorithms is that the number of latent\nconcepts remains fixed throughout the entire stream. However, this need not be\nthe case. Every incoming batch in the stream may have a different number of\nlatent concepts, and the difference in latent concepts from one tensor batch to\nanother can provide insights into how our findings in a particular application\nbehave and deviate over time. In this paper, we define \"concept\" and \"concept\ndrift\" in the context of streaming tensor decomposition, as the manifestation\nof the variability of latent concepts throughout the stream. Furthermore, we\nintroduce SeekAndDestroy, an algorithm that detects concept drift in streaming\ntensor decomposition and is able to produce results robust to that drift. To\nthe best of our knowledge, this is the first work that investigates concept\ndrift in streaming tensor decomposition. We extensively evaluate SeekAndDestroy\non synthetic datasets, which exhibit a wide variety of realistic drift. Our\nexperiments demonstrate the effectiveness of SeekAndDestroy, both in the\ndetection of concept drift and in the alleviation of its effects, producing\nresults with similar quality to decomposing the entire tensor in one shot.\nAdditionally, in real datasets, SeekAndDestroy outperforms other streaming\nbaselines, while discovering novel useful components.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 15:17:58 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 01:07:33 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Pasricha", "Ravdeep", ""], ["Gujral", "Ekta", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "1804.09629", "submitter": "Koulik Khamaru", "authors": "Koulik Khamaru, Martin J. Wainwright", "title": "Convergence guarantees for a class of non-convex and non-smooth\n  optimization problems", "comments": "50 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding critical points of functions that are\nnon-convex and non-smooth. Studying a fairly broad class of such problems, we\nanalyze the behavior of three gradient-based methods (gradient descent,\nproximal update, and Frank-Wolfe update). For each of these methods, we\nestablish rates of convergence for general problems, and also prove faster\nrates for continuous sub-analytic functions. We also show that our algorithms\ncan escape strict saddle points for a class of non-smooth functions, thereby\ngeneralizing known results for smooth functions. Our analysis leads to a\nsimplification of the popular CCCP algorithm, used for optimizing functions\nthat can be written as a difference of two convex functions. Our simplified\nalgorithm retains all the convergence properties of CCCP, along with a\nsignificantly lower cost per iteration. We illustrate our methods and theory\nvia applications to the problems of best subset selection, robust estimation,\nmixture density estimation, and shape-from-shading reconstruction.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 15:31:40 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Khamaru", "Koulik", ""], ["Wainwright", "Martin J.", ""]]}, {"id": "1804.09699", "submitter": "Huan Zhang", "authors": "Tsui-Wei Weng, Huan Zhang, Hongge Chen, Zhao Song, Cho-Jui Hsieh,\n  Duane Boning, Inderjit S. Dhillon, Luca Daniel", "title": "Towards Fast Computation of Certified Robustness for ReLU Networks", "comments": "Tsui-Wei Weng and Huan Zhang contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verifying the robustness property of a general Rectified Linear Unit (ReLU)\nnetwork is an NP-complete problem [Katz, Barrett, Dill, Julian and Kochenderfer\nCAV17]. Although finding the exact minimum adversarial distortion is hard,\ngiving a certified lower bound of the minimum distortion is possible. Current\navailable methods of computing such a bound are either time-consuming or\ndelivering low quality bounds that are too loose to be useful. In this paper,\nwe exploit the special structure of ReLU networks and provide two\ncomputationally efficient algorithms Fast-Lin and Fast-Lip that are able to\ncertify non-trivial lower bounds of minimum distortions, by bounding the ReLU\nunits with appropriate linear functions Fast-Lin, or by bounding the local\nLipschitz constant Fast-Lip. Experiments show that (1) our proposed methods\ndeliver bounds close to (the gap is 2-3X) exact minimum distortion found by\nReluplex in small MNIST networks while our algorithms are more than 10,000\ntimes faster; (2) our methods deliver similar quality of bounds (the gap is\nwithin 35% and usually around 10%; sometimes our bounds are even better) for\nlarger networks compared to the methods based on solving linear programming\nproblems but our algorithms are 33-14,000 times faster; (3) our method is\ncapable of solving large MNIST and CIFAR networks up to 7 layers with more than\n10,000 neurons within tens of seconds on a single CPU core.\n  In addition, we show that, in fact, there is no polynomial time algorithm\nthat can approximately find the minimum $\\ell_1$ adversarial distortion of a\nReLU network with a $0.99\\ln n$ approximation ratio unless\n$\\mathsf{NP}$=$\\mathsf{P}$, where $n$ is the number of neurons in the network.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 17:47:56 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 20:50:00 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 21:48:37 GMT"}, {"version": "v4", "created": "Tue, 2 Oct 2018 08:25:08 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Weng", "Tsui-Wei", ""], ["Zhang", "Huan", ""], ["Chen", "Hongge", ""], ["Song", "Zhao", ""], ["Hsieh", "Cho-Jui", ""], ["Boning", "Duane", ""], ["Dhillon", "Inderjit S.", ""], ["Daniel", "Luca", ""]]}, {"id": "1804.09720", "submitter": "Anders Johan Andreassen", "authors": "Anders Andreassen, Ilya Feige, Christopher Frye, Matthew D. Schwartz", "title": "JUNIPR: a Framework for Unsupervised Machine Learning in Particle\n  Physics", "comments": "37 pages, 24 figures", "journal-ref": null, "doi": "10.1140/epjc/s10052-019-6607-9", "report-no": null, "categories": "hep-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In applications of machine learning to particle physics, a persistent\nchallenge is how to go beyond discrimination to learn about the underlying\nphysics. To this end, a powerful tool would be a framework for unsupervised\nlearning, where the machine learns the intricate high-dimensional contours of\nthe data upon which it is trained, without reference to pre-established labels.\nIn order to approach such a complex task, an unsupervised network must be\nstructured intelligently, based on a qualitative understanding of the data. In\nthis paper, we scaffold the neural network's architecture around a\nleading-order model of the physics underlying the data. In addition to making\nunsupervised learning tractable, this design actually alleviates existing\ntensions between performance and interpretability. We call the framework\nJUNIPR: \"Jets from UNsupervised Interpretable PRobabilistic models\". In this\napproach, the set of particle momenta composing a jet are clustered into a\nbinary tree that the neural network examines sequentially. Training is\nunsupervised and unrestricted: the network could decide that the data bears\nlittle correspondence to the chosen tree structure. However, when there is a\ncorrespondence, the network's output along the tree has a direct physical\ninterpretation. JUNIPR models can perform discrimination tasks, through the\nstatistically optimal likelihood-ratio test, and they permit visualizations of\ndiscrimination power at each branching in a jet's tree. Additionally, JUNIPR\nmodels provide a probability distribution from which events can be drawn,\nproviding a data-driven Monte Carlo generator. As a third application, JUNIPR\nmodels can reweight events from one (e.g. simulated) data set to agree with\ndistributions from another (e.g. experimental) data set.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 18:00:01 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Andreassen", "Anders", ""], ["Feige", "Ilya", ""], ["Frye", "Christopher", ""], ["Schwartz", "Matthew D.", ""]]}, {"id": "1804.09753", "submitter": "Emmanuel Candes", "authors": "Emmanuel J. Candes and Pragya Sur", "title": "The phase transition for the existence of the maximum likelihood\n  estimate in high-dimensional logistic regression", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper rigorously establishes that the existence of the maximum\nlikelihood estimate (MLE) in high-dimensional logistic regression models with\nGaussian covariates undergoes a sharp `phase transition'. We introduce an\nexplicit boundary curve $h_{\\text{MLE}}$, parameterized by two scalars\nmeasuring the overall magnitude of the unknown sequence of regression\ncoefficients, with the following property: in the limit of large sample sizes\n$n$ and number of features $p$ proportioned in such a way that $p/n \\rightarrow\n\\kappa$, we show that if the problem is sufficiently high dimensional in the\nsense that $\\kappa > h_{\\text{MLE}}$, then the MLE does not exist with\nprobability one. Conversely, if $\\kappa < h_{\\text{MLE}}$, the MLE\nasymptotically exists with probability one.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 18:53:11 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Candes", "Emmanuel J.", ""], ["Sur", "Pragya", ""]]}, {"id": "1804.09758", "submitter": "Osman Dai", "authors": "Osman Emre Dai, Daniel Cullina, Negar Kiyavash, Matthias Grossglauser", "title": "Analysis of a Canonical Labeling Algorithm for the Alignment of\n  Correlated Erd\\H{o}s-R\\'enyi Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph alignment in two correlated random graphs refers to the task of\nidentifying the correspondence between vertex sets of the graphs. Recent\nresults have characterized the exact information-theoretic threshold for graph\nalignment in correlated Erd\\H{o}s-R\\'enyi graphs. However, very little is known\nabout the existence of efficient algorithms to achieve graph alignment without\nseeds.\n  In this work we identify a region in which a straightforward $O(n^{11/5} \\log\nn )$-time canonical labeling algorithm, initially introduced in the context of\ngraph isomorphism, succeeds in aligning correlated Erd\\H{o}s-R\\'enyi graphs.\nThe algorithm has two steps. In the first step, all vertices are labeled by\ntheir degrees and a trivial minimum distance alignment (i.e., sorting vertices\naccording to their degrees) matches a fixed number of highest degree vertices\nin the two graphs. Having identified this subset of vertices, the remaining\nvertices are matched using a alignment algorithm for bipartite graphs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 19:09:19 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 21:21:41 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Dai", "Osman Emre", ""], ["Cullina", "Daniel", ""], ["Kiyavash", "Negar", ""], ["Grossglauser", "Matthias", ""]]}, {"id": "1804.09770", "submitter": "Namita Lokare", "authors": "Namita Lokare, Jorge Silva, Ilknur Kaynar Kabul", "title": "RULLS: Randomized Union of Locally Linear Subspaces for Feature\n  Engineering", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feature engineering plays an important role in the success of a machine\nlearning model. Most of the effort in training a model goes into data\npreparation and choosing the right representation. In this paper, we propose a\nrobust feature engineering method, Randomized Union of Locally Linear Subspaces\n(RULLS). We generate sparse, non-negative, and rotation invariant features in\nan unsupervised fashion. RULLS aggregates features from a random union of\nsubspaces by describing each point using globally chosen landmarks. These\nlandmarks serve as anchor points for choosing subspaces. Our method provides a\nway to select features that are relevant in the neighborhood around these\nchosen landmarks. Distances from each data point to $k$ closest landmarks are\nencoded in the feature matrix. The final feature representation is a union of\nfeatures from all chosen subspaces.\n  The effectiveness of our algorithm is shown on various real-world datasets\nfor tasks such as clustering and classification of raw data and in the presence\nof noise. We compare our method with existing feature generation methods.\nResults show a high performance of our method on both classification and\nclustering tasks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 19:37:55 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Lokare", "Namita", ""], ["Silva", "Jorge", ""], ["Kabul", "Ilknur Kaynar", ""]]}, {"id": "1804.09784", "submitter": "Jianzhong Wang", "authors": "Jianzhong Wang", "title": "Mathematical Analysis on Out-of-Sample Extensions", "comments": "18 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $X=\\mathbf{X}\\cup\\mathbf{Z}$ be a data set in $\\mathbb{R}^D$, where\n$\\mathbf{X}$ is the training set and $\\mathbf{Z}$ is the test one. Many\nunsupervised learning algorithms based on kernel methods have been developed to\nprovide dimensionality reduction (DR) embedding for a given training set $\\Phi:\n\\mathbf{X} \\to \\mathbb{R}^d$ ( $d\\ll D$) that maps the high-dimensional data\n$\\mathbf{X}$ to its low-dimensional feature representation\n$\\mathbf{Y}=\\Phi(\\mathbf{X})$. However, these algorithms do not\nstraightforwardly produce DR of the test set $\\mathbf{Z}$. An out-of-sample\nextension method provides DR of $\\mathbf{Z}$ using an extension of the existent\nembedding $\\Phi$, instead of re-computing the DR embedding for the whole set\n$X$. Among various out-of-sample DR extension methods, those based on\nNystr\\\"{o}m approximation are very attractive. Many papers have developed such\nout-of-extension algorithms and shown their validity by numerical experiments.\nHowever, the mathematical theory for the DR extension still need further\nconsideration. Utilizing the reproducing kernel Hilbert space (RKHS) theory,\nthis paper develops a preliminary mathematical analysis on the out-of-sample DR\nextension operators. It treats an out-of-sample DR extension operator as an\nextension of the identity on the RKHS defined on $\\mathbf{X}$. Then the\nNystr\\\"{o}m-type DR extension turns out to be an orthogonal projection. In the\npaper, we also present the conditions for the exact DR extension and give the\nestimate for the error of the extension.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2018 19:20:52 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Wang", "Jianzhong", ""]]}, {"id": "1804.09812", "submitter": "Jaehoon Koo", "authors": "Jaehoon Koo, Diego Klabjan", "title": "Improved Classification Based on Deep Belief Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For better classification generative models are used to initialize the model\nand model features before training a classifier. Typically it is needed to\nsolve separate unsupervised and supervised learning problems. Generative\nrestricted Boltzmann machines and deep belief networks are widely used for\nunsupervised learning. We developed several supervised models based on DBN in\norder to improve this two-phase strategy. Modifying the loss function to\naccount for expectation with respect to the underlying generative model,\nintroducing weight bounds, and multi-level programming are applied in model\ndevelopment. The proposed models capture both unsupervised and supervised\nobjectives effectively. The computational study verifies that our models\nperform better than the two-phase training approach.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 21:53:55 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 04:08:38 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Koo", "Jaehoon", ""], ["Klabjan", "Diego", ""]]}, {"id": "1804.09813", "submitter": "Thibaut Vidal", "authors": "Daniel Gribel, Thibaut Vidal", "title": "HG-means: A scalable hybrid genetic algorithm for minimum sum-of-squares\n  clustering", "comments": "22 pages", "journal-ref": null, "doi": "10.1016/j.patcog.2018.12.022", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimum sum-of-squares clustering (MSSC) is a widely used clustering model,\nof which the popular K-means algorithm constitutes a local minimizer. It is\nwell known that the solutions of K-means can be arbitrarily distant from the\ntrue MSSC global optimum, and dozens of alternative heuristics have been\nproposed for this problem. However, no other algorithm has been predominantly\nadopted in the literature. This may be related to differences of computational\neffort, or to the assumption that a near-optimal solution of the MSSC has only\na marginal impact on clustering validity. In this article, we dispute this\nbelief. We introduce an efficient population-based metaheuristic that uses\nK-means as a local search in combination with problem-tailored crossover,\nmutation, and diversification operators. This algorithm can be interpreted as a\nmulti-start K-means, in which the initial center positions are carefully\nsampled based on the search history. The approach is scalable and accurate,\noutperforming all recent state-of-the-art algorithms for MSSC in terms of\nsolution quality, measured by the depth of local minima. This enhanced accuracy\nleads to clusters which are significantly closer to the ground truth than those\nof other algorithms, for overlapping Gaussian-mixture datasets with a large\nnumber of features. Therefore, improved global optimization methods appear to\nbe essential to better exploit the MSSC model in high dimension.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 21:54:21 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 23:27:51 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Gribel", "Daniel", ""], ["Vidal", "Thibaut", ""]]}, {"id": "1804.09843", "submitter": "Ben Athiwaratkun", "authors": "Ben Athiwaratkun and Andrew Gordon Wilson", "title": "Hierarchical Density Order Embeddings", "comments": "Published at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By representing words with probability densities rather than point vectors,\nprobabilistic word embeddings can capture rich and interpretable semantic\ninformation and uncertainty. The uncertainty information can be particularly\nmeaningful in capturing entailment relationships -- whereby general words such\nas \"entity\" correspond to broad distributions that encompass more specific\nwords such as \"animal\" or \"instrument\". We introduce density order embeddings,\nwhich learn hierarchical representations through encapsulation of probability\ndensities. In particular, we propose simple yet effective loss functions and\ndistance metrics, as well as graph-based schemes to select negative samples to\nbetter learn hierarchical density representations. Our approach provides\nstate-of-the-art performance on the WordNet hypernym relationship prediction\ntask and the challenging HyperLex lexical entailment dataset -- while retaining\na rich and interpretable density representation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 00:43:49 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Athiwaratkun", "Ben", ""], ["Wilson", "Andrew Gordon", ""]]}, {"id": "1804.09858", "submitter": "Zhou Honggang", "authors": "Honggang Zhou and Yunchun Li and Hailong Yang and Wei Li and Jie Jia", "title": "Generative Model for Heterogeneous Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative models (GMs) such as Generative Adversary Network (GAN) and\nVariational Auto-Encoder (VAE) have thrived these years and achieved high\nquality results in generating new samples. Especially in Computer Vision, GMs\nhave been used in image inpainting, denoising and completion, which can be\ntreated as the inference from observed pixels to corrupted pixels. However,\nimages are hierarchically structured which are quite different from many\nreal-world inference scenarios with non-hierarchical features. These inference\nscenarios contain heterogeneous stochastic variables and irregular mutual\ndependences. Traditionally they are modeled by Bayesian Network (BN). However,\nthe learning and inference of BN model are NP-hard thus the number of\nstochastic variables in BN is highly constrained. In this paper, we adapt\ntypical GMs to enable heterogeneous learning and inference in polynomial\ntime.We also propose an extended autoregressive (EAR) model and an EAR with\nadversary loss (EARA) model and give theoretical results on their\neffectiveness. Experiments on several BN datasets show that our proposed EAR\nmodel achieves the best performance in most cases compared to other GMs. Except\nfor black box analysis, we've also done a serial of experiments on Markov\nborder inference of GMs for white box analysis and give theoretical results.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 02:28:34 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Zhou", "Honggang", ""], ["Li", "Yunchun", ""], ["Yang", "Hailong", ""], ["Li", "Wei", ""], ["Jia", "Jie", ""]]}, {"id": "1804.09859", "submitter": "Takashi Shinozaki", "authors": "Takashi Shinozaki", "title": "Competitive Learning Enriches Learning Representation and Accelerates\n  the Fine-tuning of CNNs", "comments": "Appeared at NIPS 2017 Workshop: Deep Learning: Bridging Theory and\n  Practice", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose the integration of competitive learning into\nconvolutional neural networks (CNNs) to improve the representation learning and\nefficiency of fine-tuning. Conventional CNNs use back propagation learning, and\nit enables powerful representation learning by a discrimination task. However,\nit requires huge amount of labeled data, and acquisition of labeled data is\nmuch harder than that of unlabeled data. Thus, efficient use of unlabeled data\nis getting crucial for DNNs. To address the problem, we introduce unsupervised\ncompetitive learning into the convolutional layer, and utilize unlabeled data\nfor effective representation learning. The results of validation experiments\nusing a toy model demonstrated that strong representation learning effectively\nextracted bases of images into convolutional filters using unlabeled data, and\naccelerated the speed of the fine-tuning of subsequent supervised back\npropagation learning. The leverage was more apparent when the number of filters\nwas sufficiently large, and, in such a case, the error rate steeply decreased\nin the initial phase of fine-tuning. Thus, the proposed method enlarged the\nnumber of filters in CNNs, and enabled a more detailed and generalized\nrepresentation. It could provide a possibility of not only deep but broad\nneural networks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 02:28:48 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Shinozaki", "Takashi", ""]]}, {"id": "1804.09893", "submitter": "Haim Avron", "authors": "Haim Avron, Michael Kapralov, Cameron Musco, Christopher Musco, Ameya\n  Velingker, Amir Zandieh", "title": "Random Fourier Features for Kernel Ridge Regression: Approximation\n  Bounds and Statistical Guarantees", "comments": "An extended abstract of this work appears in the Proceedings of the\n  34th International Conference on Machine Learning (ICML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Fourier features is one of the most popular techniques for scaling up\nkernel methods, such as kernel ridge regression. However, despite impressive\nempirical results, the statistical properties of random Fourier features are\nstill not well understood. In this paper we take steps toward filling this gap.\nSpecifically, we approach random Fourier features from a spectral matrix\napproximation point of view, give tight bounds on the number of Fourier\nfeatures required to achieve a spectral approximation, and show how spectral\nmatrix approximation bounds imply statistical guarantees for kernel ridge\nregression.\n  Qualitatively, our results are twofold: on the one hand, we show that random\nFourier feature approximation can provably speed up kernel ridge regression\nunder reasonable assumptions. At the same time, we show that the method is\nsuboptimal, and sampling from a modified distribution in Fourier space, given\nby the leverage function of the kernel, yields provably better performance. We\nstudy this optimal sampling distribution for the Gaussian kernel, achieving a\nnearly complete characterization for the case of low-dimensional bounded\ndatasets. Based on this characterization, we propose an efficient sampling\nscheme with guarantees superior to random Fourier features in this regime.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 05:34:25 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 09:17:40 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Avron", "Haim", ""], ["Kapralov", "Michael", ""], ["Musco", "Cameron", ""], ["Musco", "Christopher", ""], ["Velingker", "Ameya", ""], ["Zandieh", "Amir", ""]]}, {"id": "1804.09904", "submitter": "Kohei Miyaguchi", "authors": "Kohei Miyaguchi, Kenji Yamanishi", "title": "High-dimensional Penalty Selection via Minimum Description Length\n  Principle", "comments": "Preprint before review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of penalty selection of regularization on the basis of\nthe minimum description length (MDL) principle. In particular, we consider that\nthe design space of the penalty function is high-dimensional. In this\nsituation, the luckiness-normalized-maximum-likelihood(LNML)-minimization\napproach is favorable, because LNML quantifies the goodness of regularized\nmodels with any forms of penalty functions in view of the minimum description\nlength principle, and guides us to a good penalty function through the\nhigh-dimensional space. However, the minimization of LNML entails two major\nchallenges: 1) the computation of the normalizing factor of LNML and 2) its\nminimization in high-dimensional spaces. In this paper, we present a novel\nregularization selection method (MDL-RS), in which a tight upper bound of LNML\n(uLNML) is minimized with local convergence guarantee. Our main contribution is\nthe derivation of uLNML, which is a uniform-gap upper bound of LNML in an\nanalytic expression. This solves the above challenges in an approximate manner\nbecause it allows us to accurately approximate LNML and then efficiently\nminimize it. The experimental results show that MDL-RS improves the\ngeneralization performance of regularized estimates specifically when the model\nhas redundant parameters.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 06:22:01 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Miyaguchi", "Kohei", ""], ["Yamanishi", "Kenji", ""]]}, {"id": "1804.10023", "submitter": "Iker Be\\~naran", "authors": "Iker Be\\~naran-Mu\\~noz, Jer\\'onimo Hern\\'andez-Gonz\\'alez and Aritz\n  P\\'erez", "title": "Candidate Labeling for Crowd Learning", "comments": "7 pages, 3 figures, to be published", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowdsourcing has become very popular among the machine learning community as\na way to obtain labels that allow a ground truth to be estimated for a given\ndataset. In most of the approaches that use crowdsourced labels, annotators are\nasked to provide, for each presented instance, a single class label. Such a\nrequest could be inefficient, that is, considering that the labelers may not be\nexperts, that way to proceed could fail to take real advantage of the knowledge\nof the labelers. In this paper, the use of candidate labeling for crowd\nlearning is proposed, where the annotators may provide more than a single label\nper instance to try not to miss the real label. The main hypothesis is that, by\nallowing candidate labeling, knowledge can be extracted from the labelers more\nefficiently by than in the standard crowd learning scenario. Empirical evidence\nwhich supports that hypothesis is presented.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 12:47:52 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 13:44:56 GMT"}], "update_date": "2018-08-09", "authors_parsed": [["Be\u00f1aran-Mu\u00f1oz", "Iker", ""], ["Hern\u00e1ndez-Gonz\u00e1lez", "Jer\u00f3nimo", ""], ["P\u00e9rez", "Aritz", ""]]}, {"id": "1804.10025", "submitter": "Anton Kocheturov", "authors": "Anton Kocheturov, Petar Momcilovic, Azra Bihorac, Panos M. Pardalos", "title": "Extended Vertical Lists for Temporal Pattern Mining from Multivariate\n  Time Series", "comments": "16 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal Pattern Mining (TPM) is the problem of mining predictive complex\ntemporal patterns from multivariate time series in a supervised setting. We\ndevelop a new method called the Fast Temporal Pattern Mining with Extended\nVertical Lists. This method utilizes an extension of the Apriori property which\nrequires a more complex pattern to appear within records only at places where\nall of its subpatterns are detected as well. The approach is based on a novel\ndata structure called the Extended Vertical List that tracks positions of the\nfirst state of the pattern inside records. Extensive computational results\nindicate that the new method performs significantly faster than the previous\nversion of the algorithm for TMP. However, the speed-up comes at the expense of\nmemory usage.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 12:49:26 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Kocheturov", "Anton", ""], ["Momcilovic", "Petar", ""], ["Bihorac", "Azra", ""], ["Pardalos", "Panos M.", ""]]}, {"id": "1804.10028", "submitter": "John Klein", "authors": "John Klein, Mahmoud Albardan, Benjamin Guedj and Olivier Colot", "title": "Decentralized learning with budgeted network load using Gaussian copulas\n  and classifier ensembles", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-43823-4_26", "report-no": null, "categories": "stat.ML cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine a network of learners which address the same classification task\nbut must learn from different data sets. The learners cannot share data but\ninstead share their models. Models are shared only one time so as to preserve\nthe network load. We introduce DELCO (standing for Decentralized Ensemble\nLearning with COpulas), a new approach allowing to aggregate the predictions of\nthe classifiers trained by each learner. The proposed method aggregates the\nbase classifiers using a probabilistic model relying on Gaussian copulas.\nExperiments on logistic regressor ensembles demonstrate competing accuracy and\nincreased robustness in case of dependent classifiers. A companion python\nimplementation can be downloaded at https://github.com/john-klein/DELCO\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 12:53:58 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2019 07:33:39 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 07:38:13 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Klein", "John", ""], ["Albardan", "Mahmoud", ""], ["Guedj", "Benjamin", ""], ["Colot", "Olivier", ""]]}, {"id": "1804.10070", "submitter": "Brian McFee", "authors": "Brian McFee, Justin Salamon, Juan Pablo Bello", "title": "Adaptive pooling operators for weakly labeled sound event detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sound event detection (SED) methods are tasked with labeling segments of\naudio recordings by the presence of active sound sources. SED is typically\nposed as a supervised machine learning problem, requiring strong annotations\nfor the presence or absence of each sound source at every time instant within\nthe recording. However, strong annotations of this type are both labor- and\ncost-intensive for human annotators to produce, which limits the practical\nscalability of SED methods.\n  In this work, we treat SED as a multiple instance learning (MIL) problem,\nwhere training labels are static over a short excerpt, indicating the presence\nor absence of sound sources but not their temporal locality. The models,\nhowever, must still produce temporally dynamic predictions, which must be\naggregated (pooled) when comparing against static labels during training. To\nfacilitate this aggregation, we develop a family of adaptive pooling\noperators---referred to as auto-pool---which smoothly interpolate between\ncommon pooling operators, such as min-, max-, or average-pooling, and\nautomatically adapt to the characteristics of the sound sources in question. We\nevaluate the proposed pooling operators on three datasets, and demonstrate that\nin each case, the proposed methods outperform non-adaptive pooling operators\nfor static prediction, and nearly match the performance of models trained with\nstrong, dynamic annotations. The proposed method is evaluated in conjunction\nwith convolutional neural networks, but can be readily applied to any\ndifferentiable model for time-series label prediction.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 14:01:12 GMT"}, {"version": "v2", "created": "Fri, 10 Aug 2018 16:35:17 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["McFee", "Brian", ""], ["Salamon", "Justin", ""], ["Bello", "Juan Pablo", ""]]}, {"id": "1804.10080", "submitter": "Sergey Novoselov", "authors": "Sergey Novoselov, Andrey Shulipa, Ivan Kremnev, Alexandr Kozlov, Vadim\n  Shchemelinin", "title": "On deep speaker embeddings for text-independent speaker recognition", "comments": "Submitted to Odyssey 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate deep neural network performance in the textindependent speaker\nrecognition task. We demonstrate that using angular softmax activation at the\nlast classification layer of a classification neural network instead of a\nsimple softmax activation allows to train a more generalized discriminative\nspeaker embedding extractor. Cosine similarity is an effective metric for\nspeaker verification in this embedding space. We also address the problem of\nchoosing an architecture for the extractor. We found that deep networks with\nresidual frame level connections outperform wide but relatively shallow\narchitectures. This paper also proposes several improvements for previous\nDNN-based extractor systems to increase the speaker recognition accuracy. We\nshow that the discriminatively trained similarity metric learning approach\noutperforms the standard LDA-PLDA method as an embedding backend. The results\nobtained on Speakers in the Wild and NIST SRE 2016 evaluation sets demonstrate\nrobustness of the proposed systems when dealing with close to real-life\nconditions.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 14:22:01 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Novoselov", "Sergey", ""], ["Shulipa", "Andrey", ""], ["Kremnev", "Ivan", ""], ["Kozlov", "Alexandr", ""], ["Shchemelinin", "Vadim", ""]]}, {"id": "1804.10109", "submitter": "Vincent Schellekens", "authors": "Vincent Schellekens and Laurent Jacques", "title": "Quantized Compressive K-Means", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2018.2847908", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent framework of compressive statistical learning aims at designing\ntractable learning algorithms that use only a heavily compressed\nrepresentation-or sketch-of massive datasets. Compressive K-Means (CKM) is such\na method: it estimates the centroids of data clusters from pooled, non-linear,\nrandom signatures of the learning examples. While this approach significantly\nreduces computational time on very large datasets, its digital implementation\nwastes acquisition resources because the learning examples are compressed only\nafter the sensing stage. The present work generalizes the sketching procedure\ninitially defined in Compressive K-Means to a large class of periodic\nnonlinearities including hardware-friendly implementations that compressively\nacquire entire datasets. This idea is exemplified in a Quantized Compressive\nK-Means procedure, a variant of CKM that leverages 1-bit universal quantization\n(i.e. retaining the least significant bit of a standard uniform quantizer) as\nthe periodic sketch nonlinearity. Trading for this resource-efficient signature\n(standard in most acquisition schemes) has almost no impact on the clustering\nperformances, as illustrated by numerical experiments.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 15:24:42 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 11:46:54 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Schellekens", "Vincent", ""], ["Jacques", "Laurent", ""]]}, {"id": "1804.10140", "submitter": "Lili Su", "authors": "Lili Su and Jiaming Xu", "title": "Securing Distributed Gradient Descent in High Dimensional Statistical\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider unreliable distributed learning systems wherein the training data\nis kept confidential by external workers, and the learner has to interact\nclosely with those workers to train a model. In particular, we assume that\nthere exists a system adversary that can adaptively compromise some workers;\nthe compromised workers deviate from their local designed specifications by\nsending out arbitrarily malicious messages.\n  We assume in each communication round, up to $q$ out of the $m$ workers\nsuffer Byzantine faults. Each worker keeps a local sample of size $n$ and the\ntotal sample size is $N=nm$. We propose a secured variant of the gradient\ndescent method that can tolerate up to a constant fraction of Byzantine\nworkers, i.e., $q/m = O(1)$. Moreover, we show the statistical estimation error\nof the iterates converges in $O(\\log N)$ rounds to $O(\\sqrt{q/N} +\n\\sqrt{d/N})$, where $d$ is the model dimension. As long as $q=O(d)$, our\nproposed algorithm achieves the optimal error rate $O(\\sqrt{d/N})$. Our results\nare obtained under some technical assumptions. Specifically, we assume\nstrongly-convex population risk. Nevertheless, the empirical risk (sample\nversion) is allowed to be non-convex. The core of our method is to robustly\naggregate the gradients computed by the workers based on the filtering\nprocedure proposed by Steinhardt et al. On the technical front, deviating from\nthe existing literature on robustly estimating a finite-dimensional mean\nvector, we establish a {\\em uniform} concentration of the sample covariance\nmatrix of gradients, and show that the aggregated gradient, as a function of\nmodel parameter, converges uniformly to the true gradient function. To get a\nnear-optimal uniform concentration bound, we develop a new matrix concentration\ninequality, which might be of independent interest.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 16:09:51 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 19:25:25 GMT"}, {"version": "v3", "created": "Thu, 9 May 2019 17:21:17 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Su", "Lili", ""], ["Xu", "Jiaming", ""]]}, {"id": "1804.10168", "submitter": "C\\'edric Beaulac", "authors": "C\\'edric Beaulac and Jeffrey S. Rosenthal", "title": "BEST : A decision tree algorithm that handles missing values", "comments": "To appear in Computational Statistics", "journal-ref": "Computational Statistics 2020", "doi": "10.1007/s00180-020-00987-z", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main contribution of this paper is the development of a new decision tree\nalgorithm. The proposed approach allows users to guide the algorithm through\nthe data partitioning process. We believe this feature has many applications\nbut in this paper we demonstrate how to utilize this algorithm to analyse data\nsets containing missing values. We tested our algorithm against simulated data\nsets with various missing data structures and a real data set. The results\ndemonstrate that this new classification procedure efficiently handles missing\nvalues and produces results that are slightly more accurate and more\ninterpretable than most common procedures without any imputations or\npre-processing.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 16:53:05 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 20:42:53 GMT"}, {"version": "v3", "created": "Wed, 31 Jul 2019 17:33:17 GMT"}, {"version": "v4", "created": "Tue, 14 Apr 2020 16:56:12 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Beaulac", "C\u00e9dric", ""], ["Rosenthal", "Jeffrey S.", ""]]}, {"id": "1804.10188", "submitter": "Sahil Garg", "authors": "Sahil Garg, Irina Rish, Guillermo Cecchi, Palash Goyal, Sarik\n  Ghazarian, Shuyang Gao, Greg Ver Steeg, Aram Galstyan", "title": "Modeling Psychotherapy Dialogues with Kernelized Hashcode\n  Representations: A Nonparametric Information-Theoretic Approach", "comments": "Response generative based model added, along with human evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel dialogue modeling framework, the first-ever nonparametric\nkernel functions based approach for dialogue modeling, which learns kernelized\nhashcodes as compressed text representations; unlike traditional deep learning\nmodels, it handles well relatively small datasets, while also scaling to large\nones. We also derive a novel lower bound on mutual information, used as a\nmodel-selection criterion favoring representations with better alignment\nbetween the utterances of participants in a collaborative dialogue setting, as\nwell as higher predictability of the generated responses. As demonstrated on\nthree real-life datasets, including prominently psychotherapy sessions, the\nproposed approach significantly outperforms several state-of-art neural network\nbased dialogue systems, both in terms of computational efficiency, reducing\ntraining time from days or weeks to hours, and the response quality, achieving\nan order of magnitude improvement over competitors in frequency of being chosen\nas the best model by human evaluators.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 17:39:28 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 00:32:09 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 03:58:19 GMT"}, {"version": "v4", "created": "Fri, 6 Jul 2018 14:54:22 GMT"}, {"version": "v5", "created": "Thu, 18 Oct 2018 15:23:28 GMT"}, {"version": "v6", "created": "Fri, 8 Mar 2019 02:16:21 GMT"}, {"version": "v7", "created": "Mon, 9 Sep 2019 19:43:38 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Garg", "Sahil", ""], ["Rish", "Irina", ""], ["Cecchi", "Guillermo", ""], ["Goyal", "Palash", ""], ["Ghazarian", "Sarik", ""], ["Gao", "Shuyang", ""], ["Steeg", "Greg Ver", ""], ["Galstyan", "Aram", ""]]}, {"id": "1804.10200", "submitter": "Y Cooper", "authors": "Y Cooper", "title": "The loss landscape of overparameterized neural networks", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore some mathematical features of the loss landscape of\noverparameterized neural networks. A priori one might imagine that the loss\nfunction looks like a typical function from $\\mathbb{R}^n$ to $\\mathbb{R}$ - in\nparticular, nonconvex, with discrete global minima. In this paper, we prove\nthat in at least one important way, the loss function of an overparameterized\nneural network does not look like a typical function. If a neural net has $n$\nparameters and is trained on $d$ data points, with $n>d$, we show that the\nlocus $M$ of global minima of $L$ is usually not discrete, but rather an $n-d$\ndimensional submanifold of $\\mathbb{R}^n$. In practice, neural nets commonly\nhave orders of magnitude more parameters than data points, so this observation\nimplies that $M$ is typically a very high-dimensional subset of $\\mathbb{R}^n$.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 17:58:45 GMT"}], "update_date": "2018-04-27", "authors_parsed": [["Cooper", "Y", ""]]}, {"id": "1804.10204", "submitter": "Jonathan Le Roux", "authors": "Zhong-Qiu Wang, Jonathan Le Roux, DeLiang Wang, John R. Hershey", "title": "End-to-End Speech Separation with Unfolded Iterative Phase\n  Reconstruction", "comments": "Submitted to Interspeech 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CL cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an end-to-end approach for single-channel\nspeaker-independent multi-speaker speech separation, where time-frequency (T-F)\nmasking, the short-time Fourier transform (STFT), and its inverse are\nrepresented as layers within a deep network. Previous approaches, rather than\ncomputing a loss on the reconstructed signal, used a surrogate loss based on\nthe target STFT magnitudes. This ignores reconstruction error introduced by\nphase inconsistency. In our approach, the loss function is directly defined on\nthe reconstructed signals, which are optimized for best separation. In\naddition, we train through unfolded iterations of a phase reconstruction\nalgorithm, represented as a series of STFT and inverse STFT layers. While mask\nvalues are typically limited to lie between zero and one for approaches using\nthe mixture phase for reconstruction, this limitation is less relevant if the\nestimated magnitudes are to be used together with phase reconstruction. We thus\npropose several novel activation functions for the output layer of the T-F\nmasking, to allow mask values beyond one. On the publicly-available wsj0-2mix\ndataset, our approach achieves state-of-the-art 12.6 dB scale-invariant\nsignal-to-distortion ratio (SI-SDR) and 13.1 dB SDR, revealing new\npossibilities for deep learning based phase reconstruction and representing a\nfundamental progress towards solving the notoriously-hard cocktail party\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 13:14:22 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Wang", "Zhong-Qiu", ""], ["Roux", "Jonathan Le", ""], ["Wang", "DeLiang", ""], ["Hershey", "John R.", ""]]}, {"id": "1804.10253", "submitter": "Elad Plaut", "authors": "Elad Plaut", "title": "From Principal Subspaces to Principal Components with Linear\n  Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The autoencoder is an effective unsupervised learning model which is widely\nused in deep learning. It is well known that an autoencoder with a single\nfully-connected hidden layer, a linear activation function and a squared error\ncost function trains weights that span the same subspace as the one spanned by\nthe principal component loading vectors, but that they are not identical to the\nloading vectors. In this paper, we show how to recover the loading vectors from\nthe autoencoder weights.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 19:28:02 GMT"}, {"version": "v2", "created": "Sat, 25 Aug 2018 20:23:27 GMT"}, {"version": "v3", "created": "Fri, 28 Dec 2018 19:02:12 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Plaut", "Elad", ""]]}, {"id": "1804.10266", "submitter": "Greg Ongie", "authors": "Greg Ongie, Daniel Pimentel-Alarc\\'on, Laura Balzano, Rebecca Willett,\n  Robert D. Nowak", "title": "Tensor Methods for Nonlinear Matrix Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the low-rank matrix completion (LRMC) problem, the low-rank assumption\nmeans that the columns (or rows) of the matrix to be completed are points on a\nlow-dimensional linear algebraic variety. This paper extends this thinking to\ncases where the columns are points on a low-dimensional nonlinear algebraic\nvariety, a problem we call Low Algebraic Dimension Matrix Completion (LADMC).\nMatrices whose columns belong to a union of subspaces are an important special\ncase. We propose a LADMC algorithm that leverages existing LRMC methods on a\ntensorized representation of the data. For example, a second-order tensorized\nrepresentation is formed by taking the Kronecker product of each column with\nitself, and we consider higher order tensorizations as well. This approach will\nsucceed in many cases where traditional LRMC is guaranteed to fail because the\ndata are low-rank in the tensorized representation but not in the original\nrepresentation. We provide a formal mathematical justification for the success\nof our method. In particular, we give bounds of the rank of these data in the\ntensorized representation, and we prove sampling requirements to guarantee\nuniqueness of the solution. We also provide experimental results showing that\nthe new approach outperforms existing state-of-the-art methods for matrix\ncompletion under a union of subspaces model.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 20:00:42 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 17:45:52 GMT"}, {"version": "v3", "created": "Fri, 4 Sep 2020 22:03:50 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Ongie", "Greg", ""], ["Pimentel-Alarc\u00f3n", "Daniel", ""], ["Balzano", "Laura", ""], ["Willett", "Rebecca", ""], ["Nowak", "Robert D.", ""]]}, {"id": "1804.10272", "submitter": "Quanshi Zhang", "authors": "Quanshi Zhang, Yu Yang, Qian Yu, Ying Nian Wu", "title": "Network Transplanting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on a new task, i.e., transplanting a\ncategory-and-task-specific neural network to a generic, modular network without\nstrong supervision. We design an functionally interpretable structure for the\ngeneric network. Like building LEGO blocks, we teach the generic network a new\ncategory by directly transplanting the module corresponding to the category\nfrom a pre-trained network with a few or even without sample annotations. Our\nmethod incrementally adds new categories to the generic network but does not\naffect representations of existing categories. In this way, our method breaks\nthe typical bottleneck of learning a net for massive tasks and categories, i.e.\nthe requirement of collecting samples for all tasks and categories at the same\ntime before the learning begins. Thus, we use a new distillation algorithm,\nnamely back-distillation, to overcome specific challenges of network\ntransplanting. Our method without training samples even outperformed the\nbaseline with 100 training samples.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 20:25:36 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 05:18:29 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Zhang", "Quanshi", ""], ["Yang", "Yu", ""], ["Yu", "Qian", ""], ["Wu", "Ying Nian", ""]]}, {"id": "1804.10279", "submitter": "Sahil Garg", "authors": "Sahil Garg, Amarjeet Singh, Fabio Ramos", "title": "Adaptive Sensing for Learning Nonstationary Environment Models", "comments": "ArXiv version of the paper written in 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most environmental phenomena, such as wind profiles, ozone concentration and\nsunlight distribution under a forest canopy, exhibit nonstationary dynamics\ni.e. phenomenon variation change depending on the location and time of\noccurrence. Non-stationary dynamics pose both theoretical and practical\nchallenges to statistical machine learning algorithms aiming to accurately\ncapture the complexities governing the evolution of such processes. In this\npaper, we address the sampling aspects of the problem of learning nonstationary\nspatio-temporal models, and propose an efficient yet simple algorithm - LISAL.\nThe core idea in LISAL is to learn two models using Gaussian processes (GPs)\nwherein the first is a nonstationary GP directly modeling the phenomenon. The\nsecond model uses a stationary GP representing a latent space corresponding to\nchanges in dynamics, or the nonstationarity characteristics of the first model.\nLISAL involves adaptively sampling the latent space dynamics using information\ntheory quantities to reduce the computational cost during the learning phase.\nThe relevance of LISAL is extensively validated using multiple real world\ndatasets.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 21:23:25 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Garg", "Sahil", ""], ["Singh", "Amarjeet", ""], ["Ramos", "Fabio", ""]]}, {"id": "1804.10299", "submitter": "Hafiz Imtiaz", "authors": "Hafiz Imtiaz and Anand D. Sarwate", "title": "Distributed Differentially-Private Algorithms for Matrix and Tensor\n  Factorization", "comments": "39 pages, in review for publication", "journal-ref": "IEEE Journal of Selected Topics in Signal Proessing 2018", "doi": "10.1109/JSTSP.2018.2877842", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many signal processing and machine learning applications, datasets\ncontaining private information are held at different locations, requiring the\ndevelopment of distributed privacy-preserving algorithms. Tensor and matrix\nfactorizations are key components of many processing pipelines. In the\ndistributed setting, differentially private algorithms suffer because they\nintroduce noise to guarantee privacy. This paper designs new and improved\ndistributed and differentially private algorithms for two popular matrix and\ntensor factorization methods: principal component analysis (PCA) and orthogonal\ntensor decomposition (OTD). The new algorithms employ a correlated noise design\nscheme to alleviate the effects of noise and can achieve the same noise level\nas the centralized scenario. Experiments on synthetic and real data illustrate\nthe regimes in which the correlated noise allows performance matching with the\ncentralized setting, outperforming previous methods and demonstrating that\nmeaningful utility is possible while guaranteeing differential privacy.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 22:40:35 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Imtiaz", "Hafiz", ""], ["Sarwate", "Anand D.", ""]]}, {"id": "1804.10318", "submitter": "Sahil Garg", "authors": "Sahil Garg", "title": "Efficiently Learning Nonstationary Gaussian Processes for Real World\n  Impact", "comments": "Draft is not suitable for public view at present. It requires\n  significant additions of experiment results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most real world phenomena such as sunlight distribution under a forest\ncanopy, minerals concentration, stock valuation, exhibit nonstationary dynamics\ni.e. phenomenon variation changes depending on the locality. Nonstationary\ndynamics pose both theoretical and practical challenges to statistical machine\nlearning algorithms that aim to accurately capture the complexities governing\nthe evolution of such processes. Typically the nonstationary dynamics are\nmodeled using nonstationary Gaussian Process models (NGPS) that employ local\nlatent dynamics parameterization to correspondingly model the nonstationary\nreal observable dynamics. Recently, an approach based on most likely induced\nlatent dynamics representation attracted research community's attention for a\nwhile. The approach could not be employed for large scale real world\napplications because learning a most likely latent dynamics representation\ninvolves maximization of marginal likelihood of the observed real dynamics that\nbecomes intractable as the number of induced latent points grows with problem\nsize. We have established a direct relationship between informativeness of the\ninduced latent dynamics and the marginal likelihood of the observed real\ndynamics. This opens up the possibility of maximizing marginal likelihood of\nobserved real dynamics indirectly by near optimally maximizing entropy or\nmutual information gain on the induced latent dynamics using greedy algorithms.\nTherefore, for an efficient yet accurate inference, we propose to build an\ninduced latent dynamics representation using a novel algorithm LISAL that\nadaptively maximizes entropy or mutual information on the induced latent\ndynamics and marginal likelihood of observed real dynamics in an iterative\nmanner. The relevance of LISAL is validated using real world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 01:25:41 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 01:07:07 GMT"}, {"version": "v3", "created": "Fri, 2 Nov 2018 09:29:20 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Garg", "Sahil", ""]]}, {"id": "1804.10328", "submitter": "Yichen Chen", "authors": "Yichen Chen, Lihong Li, Mengdi Wang", "title": "Scalable Bilinear $\\pi$ Learning Using State and Action Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate linear programming (ALP) represents one of the major algorithmic\nfamilies to solve large-scale Markov decision processes (MDP). In this work, we\nstudy a primal-dual formulation of the ALP, and develop a scalable, model-free\nalgorithm called bilinear $\\pi$ learning for reinforcement learning when a\nsampling oracle is provided. This algorithm enjoys a number of advantages.\nFirst, it adopts (bi)linear models to represent the high-dimensional value\nfunction and state-action distributions, using given state and action features.\nIts run-time complexity depends on the number of features, not the size of the\nunderlying MDPs. Second, it operates in a fully online fashion without having\nto store any sample, thus having minimal memory footprint. Third, we prove that\nit is sample-efficient, solving for the optimal policy to high precision with a\nsample complexity linear in the dimension of the parameter space.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 02:32:18 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Chen", "Yichen", ""], ["Li", "Lihong", ""], ["Wang", "Mengdi", ""]]}, {"id": "1804.10390", "submitter": "Masanori Onishi", "authors": "Masanori Onishi, Takeshi Ise", "title": "Automatic classification of trees using a UAV onboard camera and deep\n  learning", "comments": "9 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic classification of trees using remotely sensed data has been a dream\nof many scientists and land use managers. Recently, Unmanned aerial vehicles\n(UAV) has been expected to be an easy-to-use, cost-effective tool for remote\nsensing of forests, and deep learning has attracted attention for its ability\nconcerning machine vision. In this study, using a commercially available UAV\nand a publicly available package for deep learning, we constructed a machine\nvision system for the automatic classification of trees. In our method, we\nsegmented a UAV photography image of forest into individual tree crowns and\ncarried out object-based deep learning. As a result, the system was able to\nclassify 7 tree types at 89.0% accuracy. This performance is notable because we\nonly used basic RGB images from a standard UAV. In contrast, most of previous\nstudies used expensive hardware such as multispectral imagers to improve the\nperformance. This result means that our method has the potential to classify\nindividual trees in a cost-effective manner. This can be a usable tool for many\nforest researchers and managements.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 08:38:22 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Onishi", "Masanori", ""], ["Ise", "Takeshi", ""]]}, {"id": "1804.10454", "submitter": "Andreas Meinel", "authors": "Andreas Meinel, Henrich Kolkhorst, Michael Tangermann", "title": "Mining within-trial oscillatory brain dynamics to address the\n  variability of optimized spatial filters", "comments": null, "journal-ref": null, "doi": "10.1109/TNSRE.2019.2894914", "report-no": null, "categories": "eess.SP cs.LG q-bio.NC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven spatial filtering algorithms optimize scores such as the contrast\nbetween two conditions to extract oscillatory brain signal components. Most\nmachine learning approaches for filter estimation, however, disregard\nwithin-trial temporal dynamics and are extremely sensitive to changes in\ntraining data and involved hyperparameters. This leads to highly variable\nsolutions and impedes the selection of a suitable candidate for,\ne.g.,~neurotechnological applications. Fostering component introspection, we\npropose to embrace this variability by condensing the functional signatures of\na large set of oscillatory components into homogeneous clusters, each\nrepresenting specific within-trial envelope dynamics.\n  The proposed method is exemplified by and evaluated on a complex hand force\ntask with a rich within-trial structure. Based on electroencephalography data\nof 18 healthy subjects, we found that the components' distinct temporal\nenvelope dynamics are highly subject-specific. On average, we obtained seven\nclusters per subject, which were strictly confined regarding their underlying\nfrequency bands. As the analysis method is not limited to a specific spatial\nfiltering algorithm, it could be utilized for a wide range of\nneurotechnological applications, e.g., to select and monitor functionally\nrelevant features for brain-computer interface protocols in stroke\nrehabilitation.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 11:56:04 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2019 11:39:50 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Meinel", "Andreas", ""], ["Kolkhorst", "Henrich", ""], ["Tangermann", "Michael", ""]]}, {"id": "1804.10488", "submitter": "Shuai Li", "authors": "Shuai Li, Yasin Abbasi-Yadkori, Branislav Kveton, S. Muthukrishnan,\n  Vishwa Vinay, Zheng Wen", "title": "Offline Evaluation of Ranking Policies with Click Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many web systems rank and present a list of items to users, from recommender\nsystems to search and advertising. An important problem in practice is to\nevaluate new ranking policies offline and optimize them before they are\ndeployed. We address this problem by proposing evaluation algorithms for\nestimating the expected number of clicks on ranked lists from historical logged\ndata. The existing algorithms are not guaranteed to be statistically efficient\nin our problem because the number of recommended lists can grow exponentially\nwith their length. To overcome this challenge, we use models of user\ninteraction with the list of items, the so-called click models, to construct\nestimators that learn statistically efficiently. We analyze our estimators and\nprove that they are more efficient than the estimators that do not use the\nstructure of the click model, under the assumption that the click model holds.\nWe evaluate our estimators in a series of experiments on a real-world dataset\nand show that they consistently outperform prior estimators.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 13:19:34 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 18:15:29 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Li", "Shuai", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Kveton", "Branislav", ""], ["Muthukrishnan", "S.", ""], ["Vinay", "Vishwa", ""], ["Wen", "Zheng", ""]]}, {"id": "1804.10500", "submitter": "Xi Chen", "authors": "Xi Chen, Ali Ghadirzadeh, John Folkesson and Patric Jensfelt", "title": "Deep Reinforcement Learning to Acquire Navigation Skills for\n  Wheel-Legged Robots in Complex Environments", "comments": "Submitted to IROS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile robot navigation in complex and dynamic environments is a challenging\nbut important problem. Reinforcement learning approaches fail to solve these\ntasks efficiently due to reward sparsities, temporal complexities and\nhigh-dimensionality of sensorimotor spaces which are inherent in such problems.\nWe present a novel approach to train action policies to acquire navigation\nskills for wheel-legged robots using deep reinforcement learning. The policy\nmaps height-map image observations to motor commands to navigate to a target\nposition while avoiding obstacles. We propose to acquire the multifaceted\nnavigation skill by learning and exploiting a number of manageable navigation\nbehaviors. We also introduce a domain randomization technique to improve the\nversatility of the training samples. We demonstrate experimentally a\nsignificant improvement in terms of data-efficiency, success rate, robustness\nagainst irrelevant sensory data, and also the quality of the maneuver skills.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 13:40:20 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Chen", "Xi", ""], ["Ghadirzadeh", "Ali", ""], ["Folkesson", "John", ""], ["Jensfelt", "Patric", ""]]}, {"id": "1804.10535", "submitter": "Sahil Garg", "authors": "Sahil Garg and Amarjeet Singh and Fabio Ramos", "title": "Learning Non-Stationary Space-Time Models for Environmental Monitoring", "comments": "AAAI-12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the primary aspects of sustainable development involves accurate\nunderstanding and modeling of environmental phenomena. Many of these phenomena\nexhibit variations in both space and time and it is imperative to develop a\ndeeper understanding of techniques that can model space-time dynamics\naccurately. In this paper we propose NOSTILL-GP - NOn-stationary Space TIme\nvariable Latent Length scale GP, a generic non-stationary, spatio-temporal\nGaussian Process (GP) model. We present several strategies, for efficient\ntraining of our model, necessary for real-world applicability. Extensive\nempirical validation is performed using three real-world environmental\nmonitoring datasets, with diverse dynamics across space and time. Results from\nthe experiments clearly demonstrate general applicability and effectiveness of\nour approach for applications in environmental monitoring.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 14:45:11 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Garg", "Sahil", ""], ["Singh", "Amarjeet", ""], ["Ramos", "Fabio", ""]]}, {"id": "1804.10544", "submitter": "Sahil Garg", "authors": "Sahil Garg and Nora Ayanian", "title": "Persistent Monitoring of Stochastic Spatio-temporal Phenomena with a\n  Small Team of Robots", "comments": "Robotics Science and Systems, 2014 (RSS-14)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a solution for persistent monitoring of real-world\nstochastic phenomena, where the underlying covariance structure changes sharply\nacross time, using a small number of mobile robot sensors. We propose an\nadaptive solution for the problem where stochastic real-world dynamics are\nmodeled as a Gaussian Process (GP). The belief on the underlying covariance\nstructure is learned from recently observed dynamics as a Gaussian Mixture (GM)\nin the low-dimensional hyper-parameters space of the GP and adapted across time\nusing Sequential Monte Carlo methods. Each robot samples a belief point from\nthe GM and locally optimizes a set of informative regions by greedy\nmaximization of the submodular entropy function. The key contributions of this\npaper are threefold: adapting the belief on the covariance using Markov Chain\nMonte Carlo (MCMC) sampling such that particles survive even under sharp\ncovariance changes across time; exploiting the belief to transform the problem\nof entropy maximization into a decentralized one; and developing an\napproximation algorithm to maximize entropy on a set of informative regions in\nthe continuous space. We illustrate the application of the proposed solution\nthrough extensive simulations using an artificial dataset and multiple real\ndatasets from fixed sensor deployments, and compare it to three competing\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 14:55:38 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Garg", "Sahil", ""], ["Ayanian", "Nora", ""]]}, {"id": "1804.10556", "submitter": "Jing Lei", "authors": "Jing Lei", "title": "Convergence and Concentration of Empirical Measures under Wasserstein\n  Distance in Unbounded Functional Spaces", "comments": "35 pages", "journal-ref": "Bernoulli, Volume 26, Number 1 (2020), 767-798", "doi": "10.3150/19-BEJ1151", "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide upper bounds of the expected Wasserstein distance between a\nprobability measure and its empirical version, generalizing recent results for\nfinite dimensional Euclidean spaces and bounded functional spaces. Such a\ngeneralization can cover Euclidean spaces with large dimensionality, with the\noptimal dependence on the dimensionality. Our method also covers the important\ncase of Gaussian processes in separable Hilbert spaces, with rate-optimal upper\nbounds for functional data distributions whose coordinates decay geometrically\nor polynomially. Moreover, our bounds of the expected value can be combined\nwith mean-concentration results to yield improved exponential tail probability\nbounds for the Wasserstein error of empirical measures under Bernstein-type or\nlog Sobolev-type conditions.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 15:21:25 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 11:05:08 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Lei", "Jing", ""]]}, {"id": "1804.10574", "submitter": "Zhouyuan Huo", "authors": "Zhouyuan Huo, Bin Gu, Qian Yang, Heng Huang", "title": "Decoupled Parallel Backpropagation with Convergence Guarantee", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation algorithm is indispensable for the training of feedforward\nneural networks. It requires propagating error gradients sequentially from the\noutput layer all the way back to the input layer. The backward locking in\nbackpropagation algorithm constrains us from updating network layers in\nparallel and fully leveraging the computing resources. Recently, several\nalgorithms have been proposed for breaking the backward locking. However, their\nperformances degrade seriously when networks are deep. In this paper, we\npropose decoupled parallel backpropagation algorithm for deep learning\noptimization with convergence guarantee. Firstly, we decouple the\nbackpropagation algorithm using delayed gradients, and show that the backward\nlocking is removed when we split the networks into multiple modules. Then, we\nutilize decoupled parallel backpropagation in two stochastic methods and prove\nthat our method guarantees convergence to critical points for the non-convex\nproblem. Finally, we perform experiments for training deep convolutional neural\nnetworks on benchmark datasets. The experimental results not only confirm our\ntheoretical analysis, but also demonstrate that the proposed method can achieve\nsignificant speedup without loss of accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 16:05:26 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 07:32:15 GMT"}, {"version": "v3", "created": "Sat, 21 Jul 2018 17:02:49 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Huo", "Zhouyuan", ""], ["Gu", "Bin", ""], ["Yang", "Qian", ""], ["Huang", "Heng", ""]]}, {"id": "1804.10587", "submitter": "Sebastian Bock", "authors": "Sebastian Bock, Josef Goppold, Martin Wei{\\ss}", "title": "An improvement of the convergence proof of the ADAM-Optimizer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common way to train neural networks is the Backpropagation. This algorithm\nincludes a gradient descent method, which needs an adaptive step size. In the\narea of neural networks, the ADAM-Optimizer is one of the most popular adaptive\nstep size methods. It was invented in \\cite{Kingma.2015} by Kingma and Ba. The\n$5865$ citations in only three years shows additionally the importance of the\ngiven paper. We discovered that the given convergence proof of the optimizer\ncontains some mistakes, so that the proof will be wrong. In this paper we give\nan improvement to the convergence proof of the ADAM-Optimizer.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 16:53:51 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Bock", "Sebastian", ""], ["Goppold", "Josef", ""], ["Wei\u00df", "Martin", ""]]}, {"id": "1804.10653", "submitter": "Maxim Panov", "authors": "Ivan Nazarov, Boris Shirokikh, Maria Burkina, Gennady Fedonin and\n  Maxim Panov", "title": "Sparse Group Inductive Matrix Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of matrix completion with side information\n(\\textit{inductive matrix completion}). In real-world applications many\nside-channel features are typically non-informative making feature selection an\nimportant part of the problem. We incorporate feature selection into inductive\nmatrix completion by proposing a matrix factorization framework with\ngroup-lasso regularization on side feature parameter matrices. We demonstrate,\nthat the theoretical sample complexity for the proposed method is much lower\ncompared to its competitors in sparse problems, and propose an efficient\noptimization algorithm for the resulting low-rank matrix completion problem\nwith sparsifying regularizers. Experiments on synthetic and real-world datasets\nshow that the proposed approach outperforms other methods.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 19:16:46 GMT"}, {"version": "v2", "created": "Sat, 6 Oct 2018 17:31:27 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Nazarov", "Ivan", ""], ["Shirokikh", "Boris", ""], ["Burkina", "Maria", ""], ["Fedonin", "Gennady", ""], ["Panov", "Maxim", ""]]}, {"id": "1804.10689", "submitter": "Amy Zhang", "authors": "Amy Zhang, Harsh Satija and Joelle Pineau", "title": "Decoupling Dynamics and Reward for Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current reinforcement learning (RL) methods can successfully learn single\ntasks but often generalize poorly to modest perturbations in task domain or\ntraining procedure. In this work, we present a decoupled learning strategy for\nRL that creates a shared representation space where knowledge can be robustly\ntransferred. We separate learning the task representation, the forward\ndynamics, the inverse dynamics and the reward function of the domain, and show\nthat this decoupling improves performance within the task, transfers well to\nchanges in dynamics and reward, and can be effectively used for online\nplanning. Empirical results show good performance in both continuous and\ndiscrete RL domains.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 21:16:40 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 02:02:28 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Zhang", "Amy", ""], ["Satija", "Harsh", ""], ["Pineau", "Joelle", ""]]}, {"id": "1804.10690", "submitter": "Yao Hengshuai", "authors": "Donglai Zhu, Hengshuai Yao, Bei Jiang, Peng Yu", "title": "Negative Log Likelihood Ratio Loss for Deep Neural Network\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In deep neural network, the cross-entropy loss function is commonly used for\nclassification. Minimizing cross-entropy is equivalent to maximizing likelihood\nunder assumptions of uniform feature and class distributions. It belongs to\ngenerative training criteria which does not directly discriminate correct class\nfrom competing classes. We propose a discriminative loss function with negative\nlog likelihood ratio between correct and competing classes. It significantly\noutperforms the cross-entropy loss on the CIFAR-10 image classification task.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 21:24:59 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Zhu", "Donglai", ""], ["Yao", "Hengshuai", ""], ["Jiang", "Bei", ""], ["Yu", "Peng", ""]]}, {"id": "1804.10742", "submitter": "Igor Gitman", "authors": "Igor Gitman, Jieshi Chen, Eric Lei, Artur Dubrawski", "title": "Novel Prediction Techniques Based on Clusterwise Linear Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore different regression models based on Clusterwise\nLinear Regression (CLR). CLR aims to find the partition of the data into $k$\nclusters, such that linear regressions fitted to each of the clusters minimize\noverall mean squared error on the whole data. The main obstacle preventing to\nuse found regression models for prediction on the unseen test points is the\nabsence of a reasonable way to obtain CLR cluster labels when the values of\ntarget variable are unknown. In this paper we propose two novel approaches on\nhow to solve this problem. The first approach, predictive CLR builds a separate\nclassification model to predict test CLR labels. The second approach,\nconstrained CLR utilizes a set of user-specified constraints that enforce\ncertain points to go to the same clusters. Assuming the constraint values are\nknown for the test points, they can be directly used to assign CLR labels. We\nevaluate these two approaches on three UCI ML datasets as well as on a large\ncorpus of health insurance claims. We show that both of the proposed algorithms\nsignificantly improve over the known CLR-based regression methods. Moreover,\npredictive CLR consistently outperforms linear regression and random forest,\nand shows comparable performance to support vector regression on UCI ML\ndatasets. The constrained CLR approach achieves the best performance on the\nhealth insurance dataset, while enjoying only $\\approx 20$ times increased\ncomputational time over linear regression.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 05:07:42 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Gitman", "Igor", ""], ["Chen", "Jieshi", ""], ["Lei", "Eric", ""], ["Dubrawski", "Artur", ""]]}, {"id": "1804.10745", "submitter": "Vihari Piratla Mr.", "authors": "Shiv Shankar, Vihari Piratla, Soumen Chakrabarti, Siddhartha\n  Chaudhuri, Preethi Jyothi, Sunita Sarawagi", "title": "Generalizing Across Domains via Cross-Gradient Training", "comments": "The first two authors contributed equally; Accepted at ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CROSSGRAD, a method to use multi-domain training data to learn a\nclassifier that generalizes to new domains. CROSSGRAD does not need an\nadaptation phase via labeled or unlabeled data, or domain features in the new\ndomain. Most existing domain adaptation methods attempt to erase domain signals\nusing techniques like domain adversarial training. In contrast, CROSSGRAD is\nfree to use domain signals for predicting labels, if it can prevent overfitting\non training domains. We conceptualize the task in a Bayesian setting, in which\na sampling step is implemented as data augmentation, based on domain-guided\nperturbations of input instances. CROSSGRAD parallelly trains a label and a\ndomain classifier on examples perturbed by loss gradients of each other's\nobjectives. This enables us to directly perturb inputs, without separating and\nre-mixing domain signals while making various distributional assumptions.\nEmpirical evaluation on three different applications where this setting is\nnatural establishes that (1) domain-guided perturbation provides consistently\nbetter generalization to unseen domains, compared to generic instance\nperturbation methods, and that (2) data augmentation is a more stable and\naccurate method than domain adversarial training.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 05:20:53 GMT"}, {"version": "v2", "created": "Tue, 1 May 2018 05:51:52 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Shankar", "Shiv", ""], ["Piratla", "Vihari", ""], ["Chakrabarti", "Soumen", ""], ["Chaudhuri", "Siddhartha", ""], ["Jyothi", "Preethi", ""], ["Sarawagi", "Sunita", ""]]}, {"id": "1804.10776", "submitter": "Anees Kazi", "authors": "Anees Kazi, Shadi Albarqouni, Karsten Kortuem, Nassir Navab", "title": "Multi Layered-Parallel Graph Convolutional Network (ML-PGCN) for Disease\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural data from Electronic Health Records as complementary information\nto imaging data for disease prediction. We incorporate novel weighting layer\ninto the Graph Convolutional Networks, which weights every element of\nstructural data by exploring its relation to the underlying disease. We\ndemonstrate the superiority of our developed technique in terms of\ncomputational speed and obtained encouraging results where our method\noutperforms the state-of-the-art methods when applied to two publicly available\ndatasets ABIDE and Chest X-ray in terms of relative performance for the\naccuracy of prediction by 5.31 % and 8.15 % and for the area under the ROC\ncurve by 4.96 % and 10.36 % respectively. Additionally, the model is\nlightweight, fast and easily trainable.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 09:50:21 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Kazi", "Anees", ""], ["Albarqouni", "Shadi", ""], ["Kortuem", "Karsten", ""], ["Navab", "Nassir", ""]]}, {"id": "1804.10801", "submitter": "Chong Zhang", "authors": "Chong Zhang, Kay Chen Tan, Haizhou Li, and Geok Soon Hong", "title": "A Cost-Sensitive Deep Belief Network for Imbalanced Classification", "comments": "13 pages, 9 figures, accepted by IEEE TNNLS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Imbalanced data with a skewed class distribution are common in many\nreal-world applications. Deep Belief Network (DBN) is a machine learning\ntechnique that is effective in classification tasks. However, conventional DBN\ndoes not work well for imbalanced data classification because it assumes equal\ncosts for each class. To deal with this problem, cost-sensitive approaches\nassign different misclassification costs for different classes without\ndisrupting the true data sample distributions. However, due to lack of prior\nknowledge, the misclassification costs are usually unknown and hard to choose\nin practice. Moreover, it has not been well studied as to how cost-sensitive\nlearning could improve DBN performance on imbalanced data problems. This paper\nproposes an evolutionary cost-sensitive deep belief network (ECS-DBN) for\nimbalanced classification. ECS-DBN uses adaptive differential evolution to\noptimize the misclassification costs based on training data, that presents an\neffective approach to incorporating the evaluation measure (i.e. G-mean) into\nthe objective function. We first optimize the misclassification costs, then\napply them to deep belief network. Adaptive differential evolution optimization\nis implemented as the optimization algorithm that automatically updates its\ncorresponding parameters without the need of prior domain knowledge. The\nexperiments have shown that the proposed approach consistently outperforms the\nstate-of-the-art on both benchmark datasets and real-world dataset for fault\ndiagnosis in tool condition monitoring.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 13:31:45 GMT"}, {"version": "v2", "created": "Sat, 5 May 2018 04:19:23 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Zhang", "Chong", ""], ["Tan", "Kay Chen", ""], ["Li", "Haizhou", ""], ["Hong", "Geok Soon", ""]]}, {"id": "1804.10821", "submitter": "Ansgar Steland", "authors": "Ansgar Steland", "title": "On Convergence of Moments for Approximating Processes and Applications\n  to Surrogate Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study critera for a pair $ (\\{ X_n \\} $, $ \\{ Y_n \\}) $ of approximating\nprocesses which guarantee closeness of moments by generalizing known results\nfor the special case that $ Y_n = Y $ for all $n$ and $ X_n $ converges to $Y$\nin probability. This problem especially arises when working with surrogate\nmodels, e.g. to enrich observed data by simulated data, where the surrogates\n$Y_n$'s are constructed to justify that they approximate the $ X_n $'s.\n  The results of this paper deal with sequences of random variables. Since this\nframework does not cover many applications where surrogate models such as deep\nneural networks are used to approximate more general stochastic processes, we\nextend the results to the more general framework of random fields of stochastic\nprocesses. This framework especially covers image data and sequences of images.\nWe show that uniform integrability is sufficient, and this holds even for the\ncase of processes provided they satisfy a weak stationarity condition.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 15:36:56 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Steland", "Ansgar", ""]]}, {"id": "1804.10834", "submitter": "Sridhar Mahadevan", "authors": "Sridhar Mahadevan and Bamdev Mishra and Shalini Ghosh", "title": "A Unified Framework for Domain Adaptation using Metric Learning on\n  Manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework for domain adaptation, whereby both geometric\nand statistical differences between a labeled source domain and unlabeled\ntarget domain can be integrated by exploiting the curved Riemannian geometry of\nstatistical manifolds. Our approach is based on formulating transfer from\nsource to target as a problem of geometric mean metric learning on manifolds.\nSpecifically, we exploit the curved Riemannian manifold geometry of symmetric\npositive definite (SPD) covariance matrices. We exploit a simple but important\nobservation that as the space of covariance matrices is both a Riemannian space\nas well as a homogeneous space, the shortest path geodesic between two\ncovariances on the manifold can be computed analytically. Statistics on the SPD\nmatrix manifold, such as the geometric mean of two matrices can be reduced to\nsolving the well-known Riccati equation. We show how the Ricatti-based solution\ncan be constrained to not only reduce the statistical differences between the\nsource and target domains, such as aligning second order covariances and\nminimizing the maximum mean discrepancy, but also the underlying geometry of\nthe source and target domains using diffusions on the underlying source and\ntarget manifolds. A key strength of our proposed approach is that it enables\nintegrating multiple sources of variation between source and target in a\nunified way, by reducing the combined objective function to a nested set of\nRicatti equations where the solution can be represented by a cascaded series of\ngeometric mean computations. In addition to showing the theoretical optimality\nof our solution, we present detailed experiments using standard transfer\nlearning testbeds from computer vision comparing our proposed algorithms to\npast work in domain adaptation, showing improved results over a large variety\nof previous methods.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 17:41:27 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Mahadevan", "Sridhar", ""], ["Mishra", "Bamdev", ""], ["Ghosh", "Shalini", ""]]}, {"id": "1804.10839", "submitter": "Jefferson Hern\\'andez Enrique", "authors": "Jefferson Hernandez and Andres G. Abad", "title": "Learning from multivariate discrete sequential data using a restricted\n  Boltzmann machine model", "comments": "6 pages, 3 figures, Accepted as conference paper in IEEE-COLCACI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A restricted Boltzmann machine (RBM) is a generative neural-network model\nwith many novel applications such as collaborative filtering and acoustic\nmodeling. An RBM lacks the capacity to retain memory, making it inappropriate\nfor dynamic data modeling as in time-series analysis. In this paper we address\nthis issue by proposing the p-RBM model, a generalization of the regular RBM\nmodel, capable of retaining memory of p past states. We further show how to\ntrain the p-RBM model using contrastive divergence and test our model on the\nproblem of predicting the stock market direction considering 100 stocks of the\nNASDAQ-100 index. Obtained results show that the p-RBM offer promising\nprediction potential.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 18:38:27 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Hernandez", "Jefferson", ""], ["Abad", "Andres G.", ""]]}, {"id": "1804.10846", "submitter": "Miguel Hernan", "authors": "Miguel A. Hern\\'an, John Hsu, Brian Healy", "title": "Data science is science's second chance to get causal inference right: A\n  classification of data science tasks", "comments": null, "journal-ref": "Chance 32(1):42-49 (2019)", "doi": "10.1080/09332480.2019.1579578", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference from observational data is the goal of many data analyses in\nthe health and social sciences. However, academic statistics has often frowned\nupon data analyses with a causal objective. The introduction of the term \"data\nscience\" provides a historic opportunity to redefine data analysis in such a\nway that it naturally accommodates causal inference from observational data.\nLike others before, we organize the scientific contributions of data science\ninto three classes of tasks: Description, prediction, and counterfactual\nprediction (which includes causal inference). An explicit classification of\ndata science tasks is necessary to discuss the data, assumptions, and analytics\nrequired to successfully accomplish each task. We argue that a failure to\nadequately describe the role of subject-matter expert knowledge in data\nanalysis is a source of widespread misunderstandings about data science.\nSpecifically, causal analyses typically require not only good data and\nalgorithms, but also domain expert knowledge. We discuss the implications for\nthe use of data science to guide decision-making in the real world and to train\ndata scientists.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 20:23:45 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 00:24:09 GMT"}, {"version": "v3", "created": "Thu, 31 May 2018 03:25:08 GMT"}, {"version": "v4", "created": "Thu, 12 Jul 2018 10:26:31 GMT"}, {"version": "v5", "created": "Tue, 9 Oct 2018 19:01:23 GMT"}, {"version": "v6", "created": "Sun, 7 Apr 2019 03:10:51 GMT"}], "update_date": "2019-04-11", "authors_parsed": [["Hern\u00e1n", "Miguel A.", ""], ["Hsu", "John", ""], ["Healy", "Brian", ""]]}, {"id": "1804.10850", "submitter": "Tengfei Ma", "authors": "Tengfei Ma, Cao Xiao, Jiayu Zhou, Fei Wang", "title": "Drug Similarity Integration Through Attentive Multi-view Graph\n  Auto-Encoders", "comments": "IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug similarity has been studied to support downstream clinical tasks such as\ninferring novel properties of drugs (e.g. side effects, indications,\ninteractions) from known properties. The growing availability of new types of\ndrug features brings the opportunity of learning a more comprehensive and\naccurate drug similarity that represents the full spectrum of underlying drug\nrelations. However, it is challenging to integrate these heterogeneous, noisy,\nnonlinear-related information to learn accurate similarity measures especially\nwhen labels are scarce. Moreover, there is a trade-off between accuracy and\ninterpretability. In this paper, we propose to learn accurate and interpretable\nsimilarity measures from multiple types of drug features. In particular, we\nmodel the integration using multi-view graph auto-encoders, and add attentive\nmechanism to determine the weights for each view with respect to corresponding\ntasks and features for better interpretability. Our model has flexible design\nfor both semi-supervised and unsupervised settings. Experimental results\ndemonstrated significant predictive accuracy improvement. Case studies also\nshowed better model capacity (e.g. embed node features) and interpretability.\n", "versions": [{"version": "v1", "created": "Sat, 28 Apr 2018 22:14:29 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Ma", "Tengfei", ""], ["Xiao", "Cao", ""], ["Zhou", "Jiayu", ""], ["Wang", "Fei", ""]]}, {"id": "1804.10885", "submitter": "Haiyang Wang", "authors": "Haiyang Wang, Yong Tang, Ziyang Jia, Fei Ye", "title": "Dense Adaptive Cascade Forest: A Self Adaptive Deep Ensemble for\n  Classification Problems", "comments": "22 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent researches have shown that deep forest ensemble achieves a\nconsiderable increase in classification accuracy compared with the general\nensemble learning methods, especially when the training set is small. In this\npaper, we take advantage of deep forest ensemble and introduce the Dense\nAdaptive Cascade Forest (daForest). Our model has a better performance than the\noriginal Cascade Forest with three major features: first, we apply SAMME.R\nboosting algorithm to improve the performance of the model. It guarantees the\nimprovement as the number of layers increases. Second, our model connects each\nlayer to the subsequent ones in a feed-forward fashion, which enhances the\ncapability of the model to resist performance degeneration. Third, we add a\nhyper-parameters optimization layer before the first classification layer,\nmaking our model spend less time to set up and find the optimal\nhyper-parameters. Experimental results show that daForest performs\nsignificantly well, and in some cases, even outperforms neural networks and\nachieves state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 07:46:22 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 07:22:59 GMT"}, {"version": "v3", "created": "Wed, 14 Nov 2018 16:42:32 GMT"}, {"version": "v4", "created": "Wed, 5 Dec 2018 16:54:01 GMT"}, {"version": "v5", "created": "Tue, 14 May 2019 06:24:39 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Wang", "Haiyang", ""], ["Tang", "Yong", ""], ["Jia", "Ziyang", ""], ["Ye", "Fei", ""]]}, {"id": "1804.10905", "submitter": "Ashish Mani Dr.", "authors": "Arit Kumar Bishwas, Ashish Mani, and Vasile Palade", "title": "An Investigation on Support Vector Clustering for Big Data in Quantum\n  Paradigm", "comments": null, "journal-ref": "Quantum Information Processing volume 19, Article number: 108\n  (2020)", "doi": "10.1007/s11128-020-2606-x", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The support vector clustering algorithm is a well-known clustering algorithm\nbased on support vector machines using Gaussian or polynomial kernels. The\nclassical support vector clustering algorithm works well in general, but its\nperformance degrades when applied on big data. In this paper, we have\ninvestigated the performance of support vector clustering algorithm implemented\nin a quantum paradigm for possible run-time improvements. We have developed and\nanalyzed a quantum version of the support vector clustering algorithm. The\nproposed approach is based on the quantum support vector machine and quantum\nkernels (i.e., Gaussian and polynomial). The proposed quantum version of the\nSVM clustering method demonstrates a significant speed-up gain on the overall\nrun-time complexity as compared to the classical counterpart.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 11:09:40 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 12:42:55 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Bishwas", "Arit Kumar", ""], ["Mani", "Ashish", ""], ["Palade", "Vasile", ""]]}, {"id": "1804.10938", "submitter": "Dimitrios Kollias", "authors": "Dimitrios Kollias, Panagiotis Tzirakis, Mihalis A. Nicolaou,\n  Athanasios Papaioannou, Guoying Zhao, Bj\\\"orn Schuller, Irene Kotsia,\n  Stefanos Zafeiriou", "title": "Deep Affect Prediction in-the-wild: Aff-Wild Database and Challenge,\n  Deep Architectures, and Beyond", "comments": null, "journal-ref": null, "doi": "10.1007/s11263-019-01158-4", "report-no": null, "categories": "cs.CV cs.AI cs.HC eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic understanding of human affect using visual signals is of great\nimportance in everyday human-machine interactions. Appraising human emotional\nstates, behaviors and reactions displayed in real-world settings, can be\naccomplished using latent continuous dimensions (e.g., the circumplex model of\naffect). Valence (i.e., how positive or negative is an emotion) & arousal\n(i.e., power of the activation of the emotion) constitute popular and effective\naffect representations. Nevertheless, the majority of collected datasets this\nfar, although containing naturalistic emotional states, have been captured in\nhighly controlled recording conditions. In this paper, we introduce the\nAff-Wild benchmark for training and evaluating affect recognition algorithms.\nWe also report on the results of the First Affect-in-the-wild Challenge that\nwas organized in conjunction with CVPR 2017 on the Aff-Wild database and was\nthe first ever challenge on the estimation of valence and arousal in-the-wild.\nFurthermore, we design and extensively train an end-to-end deep neural\narchitecture which performs prediction of continuous emotion dimensions based\non visual cues. The proposed deep learning architecture, AffWildNet, includes\nconvolutional & recurrent neural network layers, exploiting the invariant\nproperties of convolutional features, while also modeling temporal dynamics\nthat arise in human behavior via the recurrent layers. The AffWildNet produced\nstate-of-the-art results on the Aff-Wild Challenge. We then exploit the AffWild\ndatabase for learning features, which can be used as priors for achieving best\nperformances both for dimensional, as well as categorical emotion recognition,\nusing the RECOLA, AFEW-VA and EmotiW datasets, compared to all other methods\ndesigned for the same goal. The database and emotion recognition models are\navailable at http://ibug.doc.ic.ac.uk/resources/first-affect-wild-challenge.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 14:18:07 GMT"}, {"version": "v2", "created": "Sun, 6 May 2018 01:27:00 GMT"}, {"version": "v3", "created": "Tue, 8 May 2018 09:50:53 GMT"}, {"version": "v4", "created": "Sat, 1 Sep 2018 13:26:39 GMT"}, {"version": "v5", "created": "Fri, 1 Feb 2019 12:39:52 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Kollias", "Dimitrios", ""], ["Tzirakis", "Panagiotis", ""], ["Nicolaou", "Mihalis A.", ""], ["Papaioannou", "Athanasios", ""], ["Zhao", "Guoying", ""], ["Schuller", "Bj\u00f6rn", ""], ["Kotsia", "Irene", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1804.10942", "submitter": "Hyeryung Jang", "authors": "Hyeryung Jang, HyungSeok Song, Yung Yi", "title": "Learning Data Dependency with Communication Cost", "comments": "33 pages, to appear at MobiHoc'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of recovering a graph that represents\nthe statistical data dependency among nodes for a set of data samples generated\nby nodes, which provides the basic structure to perform an inference task, such\nas MAP (maximum a posteriori). This problem is referred to as structure\nlearning. When nodes are spatially separated in different locations, running an\ninference algorithm requires a non-negligible amount of message passing,\nincurring some communication cost. We inevitably have the trade-off between the\naccuracy of structure learning and the cost we need to pay to perform a given\nmessage-passing based inference task because the learnt edge structures of data\ndependency and physical connectivity graph are often highly different. In this\npaper, we formalize this trade-off in an optimization problem which outputs the\ndata dependency graph that jointly considers learning accuracy and\nmessage-passing costs. We focus on a distributed MAP as the target inference\ntask, and consider two different implementations, ASYNC-MAP and SYNC-MAP that\nhave different message-passing mechanisms and thus different cost structures.\nIn ASYNC- MAP, we propose a polynomial time learning algorithm that is optimal,\nmotivated by the problem of finding a maximum weight spanning tree. In\nSYNC-MAP, we first prove that it is NP-hard and propose a greedy heuristic. For\nboth implementations, we then quantify how the probability that the resulting\ndata graphs from those learning algorithms differ from the ideal data graph\ndecays as the number of data samples grows, using the large deviation\nprinciple, where the decaying rate is characterized by some topological\nstructures of both original data dependency and physical connectivity graphs as\nwell as the degree of the trade-off. We validate our theoretical findings\nthrough extensive simulations, which confirms that it has a good match.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 14:34:35 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Jang", "Hyeryung", ""], ["Song", "HyungSeok", ""], ["Yi", "Yung", ""]]}, {"id": "1804.10961", "submitter": "Karthikeyan Natesan Ramamurthy", "authors": "Ming Yu and Karthikeyan Natesan Ramamurthy and Addie Thompson and\n  Aur\\'elie Lozano", "title": "Simultaneous Parameter Learning and Bi-Clustering for Multi-Response\n  Models", "comments": "15 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multi-response and multitask regression models, where the\nparameter matrix to be estimated is expected to have an unknown grouping\nstructure. The groupings can be along tasks, or features, or both, the last one\nindicating a bi-cluster or \"checkerboard\" structure. Discovering this grouping\nstructure along with parameter inference makes sense in several applications,\nsuch as multi-response Genome-Wide Association Studies. This additional\nstructure can not only can be leveraged for more accurate parameter estimation,\nbut it also provides valuable information on the underlying data mechanisms\n(e.g. relationships among genotypes and phenotypes in GWAS). In this paper, we\npropose two formulations to simultaneously learn the parameter matrix and its\ngroup structures, based on convex regularization penalties. We present\noptimization approaches to solve the resulting problems and provide numerical\nconvergence guarantees. Our approaches are validated on extensive simulations\nand real datasets concerning phenotypes and genotypes of plant varieties.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 16:37:29 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Yu", "Ming", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Thompson", "Addie", ""], ["Lozano", "Aur\u00e9lie", ""]]}, {"id": "1804.10969", "submitter": "Evgenii Zheltonozhskii", "authors": "Chaim Baskin, Eli Schwartz, Evgenii Zheltonozhskii, Natan Liss, Raja\n  Giryes, Alex M. Bronstein, Avi Mendelson", "title": "UNIQ: Uniform Noise Injection for Non-Uniform Quantization of Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3444943", "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a novel method for neural network quantization that emulates a\nnon-uniform $k$-quantile quantizer, which adapts to the distribution of the\nquantized parameters. Our approach provides a novel alternative to the existing\nuniform quantization techniques for neural networks. We suggest to compare the\nresults as a function of the bit-operations (BOPS) performed, assuming a\nlook-up table availability for the non-uniform case. In this setup, we show the\nadvantages of our strategy in the low computational budget regime. While the\nproposed solution is harder to implement in hardware, we believe it sets a\nbasis for new alternatives to neural networks quantization.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 17:38:20 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 20:11:25 GMT"}, {"version": "v3", "created": "Tue, 2 Oct 2018 20:19:13 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Baskin", "Chaim", ""], ["Schwartz", "Eli", ""], ["Zheltonozhskii", "Evgenii", ""], ["Liss", "Natan", ""], ["Giryes", "Raja", ""], ["Bronstein", "Alex M.", ""], ["Mendelson", "Avi", ""]]}, {"id": "1804.10974", "submitter": "Zihang Dai", "authors": "Zihang Dai, Qizhe Xie, Eduard Hovy", "title": "From Credit Assignment to Entropy Regularization: Two New Algorithms for\n  Neural Sequence Prediction", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this work, we study the credit assignment problem in reward augmented\nmaximum likelihood (RAML) learning, and establish a theoretical equivalence\nbetween the token-level counterpart of RAML and the entropy regularized\nreinforcement learning. Inspired by the connection, we propose two sequence\nprediction algorithms, one extending RAML with fine-grained credit assignment\nand the other improving Actor-Critic with a systematic entropy regularization.\nOn two benchmark datasets, we show the proposed algorithms outperform RAML and\nActor-Critic respectively, providing new alternatives to sequence prediction.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 18:27:43 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Dai", "Zihang", ""], ["Xie", "Qizhe", ""], ["Hovy", "Eduard", ""]]}, {"id": "1804.10988", "submitter": "Michael Blot", "authors": "Michael Blot, Thomas Robert, Nicolas Thome, Matthieu Cord", "title": "SHADE: Information Based Regularization for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization is a big issue for training deep neural networks. In this\npaper, we propose a new information-theory-based regularization scheme named\nSHADE for SHAnnon DEcay. The originality of the approach is to define a prior\nbased on conditional entropy, which explicitly decouples the learning of\ninvariant representations in the regularizer and the learning of correlations\nbetween inputs and labels in the data fitting term. Our second contribution is\nto derive a stochastic version of the regularizer compatible with deep\nlearning, resulting in a tractable training scheme. We empirically validate the\nefficiency of our approach to improve classification performances compared to\ncommon regularization schemes on several standard architectures.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 20:32:23 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 14:08:23 GMT"}, {"version": "v3", "created": "Mon, 14 May 2018 14:12:02 GMT"}, {"version": "v4", "created": "Tue, 22 May 2018 09:14:08 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Blot", "Michael", ""], ["Robert", "Thomas", ""], ["Thome", "Nicolas", ""], ["Cord", "Matthieu", ""]]}, {"id": "1804.11005", "submitter": "Sahil Garg", "authors": "Emilia M. Wysocka, Valery Dzutsati, Tirthankar Bandyopadhyay, Laura\n  Condon, Sahil Garg", "title": "Building Models for Biopathway Dynamics Using Intrinsic Dimensionality\n  Analysis", "comments": "Presented in Santa Fe Complex Systems Summer School (CSSS) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.IT math.IT q-bio.QM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important task for many if not all the scientific domains is efficient\nknowledge integration, testing and codification. It is often solved with model\nconstruction in a controllable computational environment. In spite of that, the\nthroughput of in-silico simulation-based observations become similarly\nintractable for thorough analysis. This is especially the case in molecular\nbiology, which served as a subject for this study. In this project, we aimed to\ntest some approaches developed to deal with the curse of dimensionality. Among\nthese we found dimension reduction techniques especially appealing. They can be\nused to identify irrelevant variability and help to understand critical\nprocesses underlying high-dimensional datasets. Additionally, we subjected our\ndata sets to nonlinear time series analysis, as those are well established\nmethods for results comparison. To investigate the usefulness of dimension\nreduction methods, we decided to base our study on a concrete sample set. The\nexample was taken from the domain of systems biology concerning dynamic\nevolution of sub-cellular signaling. Particularly, the dataset relates to the\nyeast pheromone pathway and is studied in-silico with a stochastic model. The\nmodel reconstructs signal propagation stimulated by a mating pheromone. In the\npaper, we elaborate on the reason of multidimensional analysis problem in the\ncontext of molecular signaling, and next, we introduce the model of choice,\nsimulation details and obtained time series dynamics. A description of used\nmethods followed by a discussion of results and their biological interpretation\nfinalize the paper.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2018 23:40:44 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 13:13:15 GMT"}, {"version": "v3", "created": "Sat, 3 Nov 2018 03:33:57 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Wysocka", "Emilia M.", ""], ["Dzutsati", "Valery", ""], ["Bandyopadhyay", "Tirthankar", ""], ["Condon", "Laura", ""], ["Garg", "Sahil", ""]]}, {"id": "1804.11021", "submitter": "Kiran Karra", "authors": "Kiran Karra, Lamine Mili", "title": "On the Effect of Suboptimal Estimation of Mutual Information in Feature\n  Selection and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new property of estimators of the strength of\nstatistical association, which helps characterize how well an estimator will\nperform in scenarios where dependencies between continuous and discrete random\nvariables need to be rank ordered. The new property, termed the estimator\nresponse curve, is easily computable and provides a marginal distribution\nagnostic way to assess an estimator's performance. It overcomes notable\ndrawbacks of current metrics of assessment, including statistical power, bias,\nand consistency. We utilize the estimator response curve to test various\nmeasures of the strength of association that satisfy the data processing\ninequality (DPI), and show that the CIM estimator's performance compares\nfavorably to kNN, vME, AP, and H_{MI} estimators of mutual information. The\nestimators which were identified to be suboptimal, according to the estimator\nresponse curve, perform worse than the more optimal estimators when tested with\nreal-world data from four different areas of science, all with varying\ndimensionalities and sizes.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 02:05:52 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 21:46:42 GMT"}, {"version": "v3", "created": "Sat, 9 Jan 2021 19:36:43 GMT"}], "update_date": "2021-01-12", "authors_parsed": [["Karra", "Kiran", ""], ["Mili", "Lamine", ""]]}, {"id": "1804.11062", "submitter": "Shujun Bi", "authors": "Yulan Liu, Shujun Bi and Shaohua Pan", "title": "Equivalent Lipschitz surrogates for zero-norm and rank optimization\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a mechanism to produce equivalent Lipschitz surrogates\nfor zero-norm and rank optimization problems by means of the global exact\npenalty for their equivalent mathematical programs with an equilibrium\nconstraint (MPECs). Specifically, we reformulate these combinatorial problems\nas equivalent MPECs by the variational characterization of the zero-norm and\nrank function, show that their penalized problems, yielded by moving the\nequilibrium constraint into the objective, are the global exact penalization,\nand obtain the equivalent Lipschitz surrogates by eliminating the dual variable\nin the global exact penalty. These surrogates, including the popular SCAD\nfunction in statistics, are also difference of two convex functions (D.C.) if\nthe function and constraint set involved in zero-norm and rank optimization\nproblems are convex. We illustrate an application by designing a multi-stage\nconvex relaxation approach to the rank plus zero-norm regularized minimization\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 06:57:35 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Liu", "Yulan", ""], ["Bi", "Shujun", ""], ["Pan", "Shaohua", ""]]}, {"id": "1804.11067", "submitter": "Trung Ngo Trong", "authors": "Trung Ngo Trong and Ville Hautam\\\"aki and Kristiina Jokinen", "title": "Staircase Network: structural language identification via hierarchical\n  attentive units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language recognition system is typically trained directly to optimize\nclassification error on the target language labels, without using the external,\nor meta-information in the estimation of the model parameters. However labels\nare not independent of each other, there is a dependency enforced by, for\nexample, the language family, which affects negatively on classification. The\nother external information sources (e.g. audio encoding, telephony or video\nspeech) can also decrease classification accuracy. In this paper, we attempt to\nsolve these issues by constructing a deep hierarchical neural network, where\ndifferent levels of meta-information are encapsulated by attentive prediction\nunits and also embedded into the training progress. The proposed method learns\nauxiliary tasks to obtain robust internal representation and to construct a\nvariant of attentive units within the hierarchical model. The final result is\nthe structural prediction of the target language and a closely related language\nfamily. The algorithm reflects a \"staircase\" way of learning in both its\narchitecture and training, advancing from the fundamental audio encoding to the\nlanguage family level and finally to the target language level. This process\nnot only improves generalization but also tackles the issues of imbalanced\nclass priors and channel variability in the deep neural network model. Our\nexperimental findings show that the proposed architecture outperforms the\nstate-of-the-art i-vector approaches on both small and big language corpora by\na significant margin.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 07:55:55 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Trong", "Trung Ngo", ""], ["Hautam\u00e4ki", "Ville", ""], ["Jokinen", "Kristiina", ""]]}, {"id": "1804.11130", "submitter": "Francesco Locatello", "authors": "Francesco Locatello, Damien Vincent, Ilya Tolstikhin, Gunnar R\\\"atsch,\n  Sylvain Gelly, Bernhard Sch\\\"olkopf", "title": "Competitive Training of Mixtures of Independent Deep Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common assumption in causal modeling posits that the data is generated by a\nset of independent mechanisms, and algorithms should aim to recover this\nstructure. Standard unsupervised learning, however, is often concerned with\ntraining a single model to capture the overall distribution or aspects thereof.\nInspired by clustering approaches, we consider mixtures of implicit generative\nmodels that ``disentangle'' the independent generative mechanisms underlying\nthe data. Relying on an additional set of discriminators, we propose a\ncompetitive training procedure in which the models only need to capture the\nportion of the data distribution from which they can produce realistic samples.\nAs a by-product, each model is simpler and faster to train. We empirically show\nthat our approach splits the training distribution in a sensible way and\nincreases the quality of the generated samples.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 11:41:48 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 09:06:42 GMT"}, {"version": "v3", "created": "Thu, 2 Aug 2018 08:29:20 GMT"}, {"version": "v4", "created": "Sun, 3 Mar 2019 11:20:02 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Locatello", "Francesco", ""], ["Vincent", "Damien", ""], ["Tolstikhin", "Ilya", ""], ["R\u00e4tsch", "Gunnar", ""], ["Gelly", "Sylvain", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1804.11132", "submitter": "Nicolas Dobigeon", "authors": "Tatsumi Uezato, Mathieu Fauvel and Nicolas Dobigeon", "title": "Hyperspectral unmixing with spectral variability using adaptive bundles\n  and double sparsity", "comments": null, "journal-ref": null, "doi": "10.1109/TGRS.2018.2889256", "report-no": null, "categories": "eess.IV physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral variability is one of the major issue when conducting hyperspectral\nunmixing. Within a given image composed of some elementary materials (herein\nreferred to as endmember classes), the spectral signature characterizing these\nclasses may spatially vary due to intrinsic component fluctuations or external\nfactors (illumination). These redundant multiple endmember spectra within each\nclass adversely affect the performance of unmixing methods. This paper proposes\na mixing model that explicitly incorporates a hierarchical structure of\nredundant multiple spectra representing each class. The proposed method is\ndesigned to promote sparsity on the selection of both spectra and classes\nwithin each pixel. The resulting unmixing algorithm is able to adaptively\nrecover several bundles of endmember spectra associated with each class and\nrobustly estimate abundances. In addition, its flexibility allows a variable\nnumber of classes to be present within each pixel of the hyperspectral image to\nbe unmixed. The proposed method is compared with other state-of-the-art\nunmixing methods that incorporate sparsity using both simulated and real\nhyperspectral data. The results show that the proposed method can successfully\ndetermine the variable number of classes present within each class and estimate\nthe corresponding class abundances.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 11:49:37 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Uezato", "Tatsumi", ""], ["Fauvel", "Mathieu", ""], ["Dobigeon", "Nicolas", ""]]}, {"id": "1804.11135", "submitter": "Thulasi Tholeti", "authors": "Thulasi Tholeti, Vishnu Raj, Sheetal Kalyani", "title": "A Centralized Multi-stage Non-parametric Learning Algorithm for\n  Opportunistic Spectrum Access", "comments": "9 pages, 7 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Owing to the ever-increasing demand in wireless spectrum, Cognitive Radio\n(CR) was introduced as a technique to attain high spectral efficiency. As the\nnumber of secondary users (SUs) connecting to the cognitive radio network is on\nthe rise, there is an imminent need for centralized algorithms that provide\nhigh throughput and energy efficiency of the SUs while ensuring minimum\ninterference to the licensed users. In this work, we propose a multi-stage\nalgorithm that - 1) effectively assigns the available channel to the SUs, 2)\nemploys a non-parametric learning framework to estimate the primary traffic\ndistribution to minimize sensing, and 3) proposes an adaptive framework to\nensure that the collision to the primary user is below the specified threshold.\nWe provide comprehensive empirical validation of the method with other\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 11:52:13 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 12:18:51 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Tholeti", "Thulasi", ""], ["Raj", "Vishnu", ""], ["Kalyani", "Sheetal", ""]]}, {"id": "1804.11188", "submitter": "Corentin Tallec", "authors": "Corentin Tallec, Yann Ollivier", "title": "Can recurrent neural networks warp time?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successful recurrent models such as long short-term memories (LSTMs) and\ngated recurrent units (GRUs) use ad hoc gating mechanisms. Empirically these\nmodels have been found to improve the learning of medium to long term temporal\ndependencies and to help with vanishing gradient issues. We prove that\nlearnable gates in a recurrent model formally provide quasi- invariance to\ngeneral time transformations in the input data. We recover part of the LSTM\narchitecture from a simple axiomatic approach. This result leads to a new way\nof initializing gate biases in LSTMs and GRUs. Ex- perimentally, this new\nchrono initialization is shown to greatly improve learning of long term\ndependencies, with minimal implementation effort.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 09:17:35 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Tallec", "Corentin", ""], ["Ollivier", "Yann", ""]]}, {"id": "1804.11195", "submitter": "Samir Farooq", "authors": "Samir Farooq, Samuel J. Weisenthal, Melissa Trayhan, Robert J. White,\n  Kristen Bush, Peter R. Mariuz, Martin S. Zand", "title": "Revealing patterns in HIV viral load data and classifying patients via a\n  novel machine learning cluster summarization method", "comments": "17 page paper with additional 10 pages of references and\n  supplementary material. 7 figures and 9 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  HIV RNA viral load (VL) is an important outcome variable in studies of HIV\ninfected persons. There exists only a handful of methods which classify\npatients by viral load patterns. Most methods place limits on the use of viral\nload measurements, are often specific to a particular study design, and do not\naccount for complex, temporal variation. To address this issue, we propose a\nset of four unambiguous computable characteristics (features) of time-varying\nHIV viral load patterns, along with a novel centroid-based classification\nalgorithm, which we use to classify a population of 1,576 HIV positive clinic\npatients into one of five different viral load patterns (clusters) often found\nin the literature: durably suppressed viral load (DSVL), sustained low viral\nload (SLVL), sustained high viral load (SHVL), high viral load suppression\n(HVLS), and rebounding viral load (RVL). The centroid algorithm summarizes\nthese clusters in terms of their centroids and radii. We show that this allows\nnew viral load patterns to be assigned pattern membership based on the distance\nfrom the centroid relative to its radius, which we term radial normalization\nclassification. This method has the benefit of providing an objective and\nquantitative method to assign viral load pattern membership with a concise and\ninterpretable model that aids clinical decision making. This method also\nfacilitates meta-analyses by providing computably distinct HIV categories.\nFinally we propose that this novel centroid algorithm could also be useful in\nthe areas of cluster comparison for outcomes research and data reduction in\nmachine learning.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2018 22:40:03 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Farooq", "Samir", ""], ["Weisenthal", "Samuel J.", ""], ["Trayhan", "Melissa", ""], ["White", "Robert J.", ""], ["Bush", "Kristen", ""], ["Mariuz", "Peter R.", ""], ["Zand", "Martin S.", ""]]}, {"id": "1804.11214", "submitter": "Yiming Xu", "authors": "Yiming Xu, Diego Klabjan", "title": "k-Nearest Neighbors by Means of Sequence to Sequence Deep Neural\n  Networks and Memory Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  k-Nearest Neighbors is one of the most fundamental but effective\nclassification models. In this paper, we propose two families of models built\non a sequence to sequence model and a memory network model to mimic the\nk-Nearest Neighbors model, which generate a sequence of labels, a sequence of\nout-of-sample feature vectors and a final label for classification, and thus\nthey could also function as oversamplers. We also propose 'out-of-core'\nversions of our models which assume that only a small portion of data can be\nloaded into memory. Computational experiments show that our models on\nstructured datasets outperform k-Nearest Neighbors, a feed-forward neural\nnetwork, XGBoost, lightGBM, random forest and a memory network, due to the fact\nthat our models must produce additional output and not just the label. On image\nand text datasets, the performance of our model is close to many\nstate-of-the-art deep models. As an oversampler on imbalanced datasets, the\nsequence to sequence kNN model often outperforms Synthetic Minority\nOver-sampling Technique and Adaptive Synthetic Sampling.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 15:13:29 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 19:19:19 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 19:31:51 GMT"}, {"version": "v4", "created": "Wed, 27 Nov 2019 00:16:11 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Xu", "Yiming", ""], ["Klabjan", "Diego", ""]]}, {"id": "1804.11237", "submitter": "Gardave Bhumbra", "authors": "Gardave S Bhumbra", "title": "Deep learning improved by biological activation functions", "comments": "11 pages, 4 figures. 18/05/2018: 9 pages, 5 figures. Eq. 1 corrected.\n  Changed name of biological activation functions. Weight initialisation\n  simplified: experiments repeated, all figures changed, overall results\n  unchanged, Methods shortened, Appendix removed. Added new Results section for\n  new experiments on CIFAR 10/100 data. Extended arguments in Discussion", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  `Biologically inspired' activation functions, such as the logistic sigmoid,\nhave been instrumental in the historical advancement of machine learning.\nHowever in the field of deep learning, they have been largely displaced by\nrectified linear units (ReLU) or similar functions, such as its exponential\nlinear unit (ELU) variant, to mitigate the effects of vanishing gradients\nassociated with error back-propagation. The logistic sigmoid however does not\nrepresent the true input-output relation in neuronal cells under physiological\nconditions. Here, bionodal root unit (BRU) activation functions are introduced,\nexhibiting input-output non-linearities that are substantially more\nbiologically plausible since their functional form is based on known\nbiophysical properties of neuronal cells.\n  In order to evaluate the learning performance of BRU activations, deep\nnetworks are constructed with identical architectures except differing in their\ntransfer functions (ReLU, ELU, and BRU). Multilayer perceptrons, stacked\nauto-encoders, and convolutional networks are used to test supervised and\nunsupervised learning based on the MNIST and CIFAR-10/100 datasets. Comparisons\nof learning performance, quantified using loss and error measurements,\ndemonstrate that bionodal networks both train faster than their ReLU and ELU\ncounterparts and result in the best generalised models even in the absence of\nformal regularisation. These results therefore suggest that revisiting the\ndetailed properties of biological neurones and their circuitry might prove\ninvaluable in the field of deep learning for the future.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 10:20:28 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 08:59:48 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Bhumbra", "Gardave S", ""]]}, {"id": "1804.11242", "submitter": "Bei Wang", "authors": "Mustafa Hajij, Paul Rosen, Bei Wang", "title": "Mapper on Graphs for Network Visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are an exceedingly popular type of data for representing\nrelationships between individuals, businesses, proteins, brain regions,\ntelecommunication endpoints, etc. Network or graph visualization provides an\nintuitive way to explore the node-link structures of network data for instant\nsense-making. However, naive node-link diagrams can fail to convey insights\nregarding network structures, even for moderately sized data of a few hundred\nnodes. We propose to apply the mapper construction--a popular tool in\ntopological data analysis--to graph visualization, which provides a strong\ntheoretical basis for summarizing network data while preserving their core\nstructures. We develop a variation of the mapper construction targeting\nweighted, undirected graphs, called mapper on graphs, which generates\nproperty-preserving summaries of graphs. We provide a software tool that\nenables interactive explorations of such summaries and demonstrates the\neffectiveness of our method for synthetic and real-world data. The mapper on\ngraphs approach we propose represents a new class of techniques that leverages\ntools from topological data analysis in addressing challenges in graph\nvisualization.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2018 19:18:36 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 00:36:22 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2019 15:19:11 GMT"}, {"version": "v4", "created": "Tue, 17 Dec 2019 07:22:53 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Hajij", "Mustafa", ""], ["Rosen", "Paul", ""], ["Wang", "Bei", ""]]}, {"id": "1804.11258", "submitter": "Xipeng Qiu", "authors": "Zhan Shi, Xinchi Chen, Xipeng Qiu, Xuanjing Huang", "title": "Toward Diverse Text Generation with Inverse Reinforcement Learning", "comments": "7 pages, IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text generation is a crucial task in NLP. Recently, several adversarial\ngenerative models have been proposed to improve the exposure bias problem in\ntext generation. Though these models gain great success, they still suffer from\nthe problems of reward sparsity and mode collapse. In order to address these\ntwo problems, in this paper, we employ inverse reinforcement learning (IRL) for\ntext generation. Specifically, the IRL framework learns a reward function on\ntraining data, and then an optimal policy to maximum the expected total reward.\nSimilar to the adversarial models, the reward and policy function in IRL are\noptimized alternately. Our method has two advantages: (1) the reward function\ncan produce more dense reward signals. (2) the generation policy, trained by\n\"entropy regularized\" policy gradient, encourages to generate more diversified\ntexts. Experiment results demonstrate that our proposed method can generate\nhigher quality texts than the previous methods.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 15:04:21 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 10:19:42 GMT"}, {"version": "v3", "created": "Thu, 7 Jun 2018 06:04:33 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Shi", "Zhan", ""], ["Chen", "Xinchi", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "1804.11259", "submitter": "Jessica Schrouff", "authors": "Jessica Schrouff and Janaina Mourao-Miranda", "title": "Interpreting weight maps in terms of cognitive or clinical neuroscience:\n  nonsense?", "comments": "conference article", "journal-ref": "2018 International Workshop on Pattern Recognition in Neuroimaging\n  (PRNI), Singapore, Singapore, 2018, pp. 1-4", "doi": "10.1109/PRNI.2018.8423944", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Since machine learning models have been applied to neuroimaging data,\nresearchers have drawn conclusions from the derived weight maps. In particular,\nweight maps of classifiers between two conditions are often described as a\nproxy for the underlying signal differences between the conditions. Recent\nstudies have however suggested that such weight maps could not reliably recover\nthe source of the neural signals and even led to false positives (FP). In this\nwork, we used semi-simulated data from ElectroCorticoGraphy (ECoG) to\ninvestigate how the signal-to-noise ratio and sparsity of the neural signal\naffect the similarity between signal and weights. We show that not all cases\nproduce FP and that it is unlikely for FP features to have a high weight in\nmost cases.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 15:06:35 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Schrouff", "Jessica", ""], ["Mourao-Miranda", "Janaina", ""]]}, {"id": "1804.11271", "submitter": "Alexander Matthews", "authors": "Alexander G. de G. Matthews, Mark Rowland, Jiri Hron, Richard E.\n  Turner, Zoubin Ghahramani", "title": "Gaussian Process Behaviour in Wide Deep Neural Networks", "comments": "This work substantially extends the work of Matthews et al. (2018)\n  published at the International Conference on Learning Representations (ICLR)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whilst deep neural networks have shown great empirical success, there is\nstill much work to be done to understand their theoretical properties. In this\npaper, we study the relationship between random, wide, fully connected,\nfeedforward networks with more than one hidden layer and Gaussian processes\nwith a recursive kernel definition. We show that, under broad conditions, as we\nmake the architecture increasingly wide, the implied random function converges\nin distribution to a Gaussian process, formalising and extending existing\nresults by Neal (1996) to deep networks. To evaluate convergence rates\nempirically, we use maximum mean discrepancy. We then compare finite Bayesian\ndeep networks from the literature to Gaussian processes in terms of the key\npredictive quantities of interest, finding that in some cases the agreement can\nbe very close. We discuss the desirability of Gaussian process behaviour and\nreview non-Gaussian alternative models from the literature.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 15:21:23 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 14:51:32 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Matthews", "Alexander G. de G.", ""], ["Rowland", "Mark", ""], ["Hron", "Jiri", ""], ["Turner", "Richard E.", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1804.11285", "submitter": "Ludwig Schmidt", "authors": "Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras, Kunal Talwar and\n  Aleksander M\\k{a}dry", "title": "Adversarially Robust Generalization Requires More Data", "comments": "Small changes for biblatex compatibility", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are often susceptible to adversarial perturbations of\ntheir inputs. Even small perturbations can cause state-of-the-art classifiers\nwith high \"standard\" accuracy to produce an incorrect prediction with high\nconfidence. To better understand this phenomenon, we study adversarially robust\nlearning from the viewpoint of generalization. We show that already in a simple\nnatural data model, the sample complexity of robust learning can be\nsignificantly larger than that of \"standard\" learning. This gap is information\ntheoretic and holds irrespective of the training algorithm or the model family.\nWe complement our theoretical results with experiments on popular image\nclassification datasets and show that a similar gap exists here as well. We\npostulate that the difficulty of training robust classifiers stems, at least\npartially, from this inherently larger sample complexity.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 15:55:59 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 05:24:33 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Schmidt", "Ludwig", ""], ["Santurkar", "Shibani", ""], ["Tsipras", "Dimitris", ""], ["Talwar", "Kunal", ""], ["M\u0105dry", "Aleksander", ""]]}, {"id": "1804.11313", "submitter": "Biswa Sengupta", "authors": "Biswa Sengupta and Karl J. Friston", "title": "How Robust are Deep Neural Networks?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional and Recurrent, deep neural networks have been successful in\nmachine learning systems for computer vision, reinforcement learning, and other\nallied fields. However, the robustness of such neural networks is seldom\napprised, especially after high classification accuracy has been attained. In\nthis paper, we evaluate the robustness of three recurrent neural networks to\ntiny perturbations, on three widely used datasets, to argue that high accuracy\ndoes not always mean a stable and a robust (to bounded perturbations,\nadversarial attacks, etc.) system. Especially, normalizing the spectrum of the\ndiscrete recurrent network to bound the spectrum (using power method, Rayleigh\nquotient, etc.) on a unit disk produces stable, albeit highly non-robust neural\nnetworks. Furthermore, using the $\\epsilon$-pseudo-spectrum, we show that\ntraining of recurrent networks, say using gradient-based methods, often result\nin non-normal matrices that may or may not be diagonalizable. Therefore, the\nopen problem lies in constructing methods that optimize not only for accuracy\nbut also for the stability and the robustness of the underlying neural network,\na criterion that is distinct from the other.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 16:39:31 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Sengupta", "Biswa", ""], ["Friston", "Karl J.", ""]]}, {"id": "1804.11326", "submitter": "Kristan Temme", "authors": "Vojtech Havlicek, Antonio D. C\\'orcoles, Kristan Temme, Aram W.\n  Harrow, Abhinav Kandala, Jerry M. Chow and Jay M. Gambetta", "title": "Supervised learning with quantum enhanced feature spaces", "comments": "Fixed typos, added figures and discussion about quantum error\n  mitigation", "journal-ref": "Nature. vol. 567, pp. 209-212 (2019)", "doi": "10.1038/s41586-019-0980-2", "report-no": null, "categories": "quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and quantum computing are two technologies each with the\npotential for altering how computation is performed to address previously\nuntenable problems. Kernel methods for machine learning are ubiquitous for\npattern recognition, with support vector machines (SVMs) being the most\nwell-known method for classification problems. However, there are limitations\nto the successful solution to such problems when the feature space becomes\nlarge, and the kernel functions become computationally expensive to estimate. A\ncore element to computational speed-ups afforded by quantum algorithms is the\nexploitation of an exponentially large quantum state space through controllable\nentanglement and interference. Here, we propose and experimentally implement\ntwo novel methods on a superconducting processor. Both methods represent the\nfeature space of a classification problem by a quantum state, taking advantage\nof the large dimensionality of quantum Hilbert space to obtain an enhanced\nsolution. One method, the quantum variational classifier builds on [1,2] and\noperates through using a variational quantum circuit to classify a training set\nin direct analogy to conventional SVMs. In the second, a quantum kernel\nestimator, we estimate the kernel function and optimize the classifier\ndirectly. The two methods present a new class of tools for exploring the\napplications of noisy intermediate scale quantum computers [3] to machine\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 17:14:09 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 21:48:09 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Havlicek", "Vojtech", ""], ["C\u00f3rcoles", "Antonio D.", ""], ["Temme", "Kristan", ""], ["Harrow", "Aram W.", ""], ["Kandala", "Abhinav", ""], ["Chow", "Jerry M.", ""], ["Gambetta", "Jay M.", ""]]}]